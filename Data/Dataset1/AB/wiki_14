<doc id="14348" url="https://en.wikipedia.org/wiki?curid=14348" title="Homo habilis">
Homo habilis

Homo habilis was a species of early humans, who lived between roughly 2.1 and 1.5 million years ago.
They are commonly known as the first species to use carved stone tools. These tools are usually found with their fossils. (Fossils of earlier tool users have been found since.)

"Homo habilis", in the tribe Hominini, lived during the Gelasian and early Calabrian stages of the Pleistocene geological epoch. 
The type (original) specimen is OH 7, discovered in 1960 at Olduvai Gorge in Tanzania, associated with the Oldowan lithic industry; the fossils were identified as a separate species of "Homo" with the proposed binomial name of "H. habilis" ("handy man") in 1964.
In its appearance and morphology, "H. habilis" is the least similar to modern humans of all species in the genus "Homo" (except the equally controversial "H. rudolfensis"), and its classification as "Homo" has been the subject of controversial debate since its first proposal in the 1960s.

LD 350-1 is a fossil jawbone fragment discovered in 2013, which has been dated to 2.8 million years ago and argued to be intermediate between "Australopithecus" and "H. habilis".

There has been scholarly debate regarding its placement in the genus "Homo" rather than the genus "Australopithecus". The small size and rather primitive attributes have led some experts (Richard Leakey among them) to propose excluding "H. habilis" from the genus "Homo" and placing them instead in "Australopithecus" as "Australopithecus habilis".

Louis Leakey (father of Richard Leakey), the British-Kenyan paleoanthropologist who was the first to suggest the existence of "H. habilis", and his wife, Mary Leakey, found the first trace of "H. habilis" in 1955: two hominin teeth. These were later classified as "milk teeth", and therefore considered difficult to link to taxa, unlike permanent teeth. However, in 1959, Mary Leakey recovered the cranium of a young adult that had a small brain, large face, tiny canines and massive chewing teeth (which earned it the nickname of "The Nutcracker man").

"H. habilis" was short and had disproportionately long arms compared to modern humans; however, it had a less protruding face than the australopithecines from which it is thought to have descended. "H. habilis" had a cranial capacity slightly less than half of the size of modern humans. Despite the ape-like morphology of the bodies, "H. habilis" remains are often accompanied by primitive stone tools (e.g. Olduvai Gorge, Tanzania and Lake Turkana, Kenya).

"Homo habilis" has often been thought to be the ancestor of the more gracile and sophisticated "Homo ergaster", which in turn gave rise to the more human-appearing species, "Homo erectus". Debates continue over whether all of the known fossils are properly attributed to the species, and some paleoanthropologists regard the taxon as invalid, made up of fossil specimens of "Australopithecus" and "Homo". New findings in 2007 seemed to confirm the view that "H. habilis" and "H. erectus" coexisted, representing separate lineages from a common ancestor instead of "H. erectus" being descended from "H. habilis". An alternative explanation would be that any ancestral relationship from "H. habilis" to "H. erectus" would have to have been cladogenetic rather than anagenetic (meaning that if an isolated subgroup population of "H. habilis" became the ancestor of "H. erectus", other subgroups remained as unchanged "H. habilis" until their much later extinction).

Discoveries at Dmanisi, Georgia, which had diverse physical traits and differences in tooth wear, suggest to some scholars that all the contemporary groups of early "Homo" in Africa, including "Homo ergaster", "Homo habilis", and "Homo rudolfensis" are of the same species and should be assigned to "Homo erectus", with the implication that variation between these “species” represents the prolonged evolution of one lineage, rather than interspecific differences.

Its brain size has been shown to range from 550 cm to 687 cm, rather than from 363 cm to 600 cm as previously thought.

A virtual reconstruction published in 2015 estimated the endocranial volume at between 729 and 824 ml, larger than any previously published value.

"H. habilis"' brain capacity of around 640 cm³ was on average 50% larger than australopithecines, but considerably smaller than the 1350 to 1450 cm³ range of modern "Homo sapiens". These hominins were smaller than modern humans, on average standing no more than 1.3 m (4 ft 3 in) tall.

A fragment of fossilized jawbone, dated to around 2.8 million years ago, was discovered in the Ledi-Geraru research area in Afar Regional State in 2013. 
The fossil is considered the earliest evidence of the genus "Homo" known to date, and seems to be intermediate between "Australopithecus" and "H. habilis". The individual in question lived just after a major climate shift in the region, when forests and waterways were rapidly replaced by arid savannah.

One set of fossil remains (OH 62, for "Olduvai Hominid specimen 62"), discovered by Donald Johanson and Tim White in Olduvai Gorge in 1986, included the important upper and lower limbs, specifically the humerus and femur. Their finding stimulated some debate at the time.
Locomotor affinities of OH 62 have been assessed primarily on the basis of its forelimb to hind limb proportions, which are known to be associated with locomotor behavior among living primates. Initial analyses concentrated on comparisons to the "Australopithecus afarensis" A.L. 288-1 ("Lucy"). In most dimensions—measured or estimated—the OH 62 upper limb remains equaled or exceeded those of A.L. 288-1, while its lower limb remains (principally the femur) appeared to be smaller. In particular, using a length estimate for the humerus of 264 mm, and a length estimate for the less complete femur of ‘‘no greater than that of A.L. 288-1 (280 mm),<nowiki>"</nowiki> a possible humerofemoral length index is close to 95%, which is more like that of modern chimpanzees (averaging about 1.00) than modern humans (averaging about 0.72). In this sense, it was more ‘‘primitive<nowiki>"</nowiki> than A.L. 288-1, with a length index of 0.85.
KNM ER 1813 is a relatively complete cranium, which dates to 1.9 million years old, discovered at Koobi Fora, Kenya by Kamoya Kimeu in 1973. The brain capacity is 510 cm³, not as impressive as other early specimen and forms of "H. habilis" discovered.

OH 24 ("Twiggy") is a roughly deformed cranium about 1.8 million years old discovered in October 1968 at Olduvai Gorge, Tanzania. The brain volume is just under 600 cm³; also, a reduction in the protruding face is present compared to members of more primitive australopithecines.

OH 7 dates to 1.75 million years old, and was discovered by Mary and Louis Leakey on November 4, 1960 at Olduvai Gorge, Tanzania. It is a lower jaw complete with teeth; due to the size of the small teeth, researchers estimate this juvenile individual had a brain volume of 363 cm³. Also found were more than 20 fragments of the left hand. Tobias and Napier assisted in classifying OH 7 as the type fossil.

The OH 7 hand of "Homo habilis" combines traits associated with a precision grip and adaptations related to climbing, which fits well with the semi-long, humanlike hindlimb proportions and a rather chimpanzee-like upper-to-lower arm ratio.

KNM ER 1805 is a specimen of an adult "H. habilis" made of three pieces of cranium dating to 1.74 million years old from Koobi Fora, Kenya. Previous assumptions were that this specimen belongs to "H. erectus" based on the degree of prognathism and overall cranial shape.

Based on dental microwear-texture analysis, "Homo habilis" (as well as other early "Homo"-class hominins) likely did not specialize on particularly tough foods. Microwear-texture complexity is, on average, somewhere between that of tough-food feeders and leaf feeders (folivores.) These measurements are analyses of the percentages of tooth surface structure containing "pits" (frequency and depth of dental damage resulting from consumption of certain foods across species). It is a heavily used, and henceforth widely accepted as reliable, measure of wear that a species, on average, endures from eating certain food. These measurements point to an increasingly generalized, and generally omnivorous diet in "Homo habilis".

"Homo habilis" is thought to have mastered the Lower Paleolithic Olduwan tool set, which used stone flakes. "H. habilis" used these stones to butcher and skin the animals. These stone flakes were more advanced than any tools previously used, and gave "H. habilis" the edge it needed to prosper in hostile environments previously too formidable for primates. Whether "H. habilis" was the first hominin to master stone tool technology remains controversial, as "Australopithecus garhi", dated to 2.6 million years ago, has been found along with stone tool implements.

The body proportions for "H. habilis" are in accordance with craniodental evidence, suggesting closer association with "H. erectus".

Most experts assume the intelligence and social organization of "H. habilis" were more sophisticated than typical australopithecines or chimpanzees. 
"H. habilis" used tools primarily for scavenging, such as cleaving meat off carrion, rather than defense or hunting. Yet, despite tool usage, "H. habilis" was not the master hunter its sister species (or descendants) proved to be, as ample fossil evidence indicates "H. habilis" was a staple in the diet of large predatory animals, such as "Dinofelis", a large scimitar-toothed predatory cat the size of a jaguar.

"Homo habilis" coexisted with other "Homo"-like bipedal primates, such as "Paranthropus boisei", some of which prospered for many millennia. However, "H. habilis", possibly because of its early tool innovation and a less specialized diet, became the precursor of an entire line of new species, whereas "Paranthropus boisei" and its robust relatives disappeared from the fossil record. "H. habilis" may also have coexisted with "H. erectus" in Africa for a period of 500,000 years.





</doc>
<doc id="14349" url="https://en.wikipedia.org/wiki?curid=14349" title="Harmonica">
Harmonica

The harmonica, also known as a French harp or mouth organ, is a free reed wind instrument used worldwide in many musical genres, notably in blues, American folk music, classical music, jazz, country, and rock and roll. There are many types of harmonica, including diatonic, chromatic, tremolo, octave, orchestral, and bass versions. A harmonica is played by using the mouth (lips and tongue) to direct air into or out of one or more holes along a mouthpiece. Behind each hole is a chamber containing at least one reed. A harmonica reed is a flat elongated spring typically made of brass, stainless steel, or bronze, which is secured at one end over a slot that serves as an airway. When the free end is made to vibrate by the player's air, it alternately blocks and unblocks the airway to produce sound.

Reeds are pre-tuned to individual pitches. Tuning may involve changing a reed’s length, the weight near its free end, or the stiffness near its fixed end. Longer, heavier and springier reeds produce deeper, lower sounds; shorter, lighter and stiffer reeds make higher-pitched sounds. If, as on most modern harmonicas, a reed is affixed above or below its slot rather than in the plane of the slot, it responds more easily to air flowing in the direction that initially would push it into the slot, i.e., as a "closing reed". This difference in response to air direction makes it possible to include both a "blow reed" and a "draw reed" in the same air chamber and to play them separately without relying on flaps of plastic or leather (valves, wind-savers) to block the nonplaying reed.

An important technique in performance is bending: causing a drop in pitch by making embouchure adjustments. It is possible to bend isolated reeds, as on chromatic and other harmonica models with wind-savers, but also to both lower, and raise ("overbend", "overblow", "overdraw") the pitch produced by pairs of reeds in the same chamber, as on a diatonic or other unvalved harmonica. Such two-reed pitch changes actually involve sound production by the normally silent reed, the "opening reed" (for instance, the blow reed while the player is drawing).

 The basic parts of the harmonica are the comb, reed plates and cover plates.

The comb is the main body of the instrument, which, when assembled with the reedplates, forms air chambers for the reeds. The term "comb" may originate from the similarity between this part of a harmonica and a hair comb. Harmonica combs were traditionally made from wood but now are also made from plastic (ABS) or metal (including titanium for high-end instruments). Some modern and experimental comb designs are complex in the way that they direct the air.

There is dispute among players about whether comb material affects the tone of a harmonica. Those saying no argue that, unlike the soundboard of a piano or the top piece of a violin or guitar, a harmonica's comb is neither large enough nor able to vibrate freely enough to substantially augment or change the sound. Among those saying yes are those who are convinced by their ears. Few dispute, however, that comb surface smoothness and air-tightness when mated with the reedplates can greatly affect tone and playability. The main advantage of a particular comb material over another one is its durability. In particular, a wooden comb can absorb moisture from the player's breath and contact with the tongue. This can cause the comb to expand slightly, making the instrument uncomfortable to play, and to then contract, potentially compromising air tightness. Various types of wood and treatments have been devised to reduce the degree of this problem.

An even more serious problem with wood combs, especially in chromatic harmonicas (with their thin dividers between chambers), is that, as the combs expand and shrink over time, cracks can form in the combs, because the comb is held immobile by nails, resulting in disabling leakage. Much effort is devoted by serious players to restoring wood combs and sealing leaks. Some players used to soak wooden-combed harmonicas (diatonics, without windsavers) in water to cause a slight expansion, which they intended to make the seal between the comb, reed plates and covers more airtight. Modern wooden-combed harmonicas are less prone to swelling and contracting. Players still dip harmonicas in water for the way it affects tone and ease of bending notes.

The reed plate is a grouping of several reeds in a single housing. The reeds are usually made of brass, but steel, aluminium and plastic are occasionally used. Individual reeds are usually riveted to the reed plate, but they may also be welded or screwed in place. Reeds fixed on the inner side of the reed plate (within the comb's air chamber) respond to blowing, while those fixed on the outer side respond to suction.

Most harmonicas are constructed with the reed plates screwed or bolted to the comb or each other. A few brands still use the traditional method of nailing the reed plates to the comb. Some experimental and rare harmonicas also have had the reed plates held in place by tension, such as the WWII era all-American models. If the plates are bolted to the comb, the reed plates can be replaced individually. This is useful because the reeds eventually go out of tune through normal use, and certain notes of the scale can fail more quickly than others.

A notable exception to the traditional reed plate design is the all-plastic harmonicas designed by Finn Magnus in the 1950s, in which the reed and reed plate were molded out of a single piece of plastic. The Magnus design had the reeds, reed plates and comb made of plastic and either molded or permanently glued together.

Cover plates cover the reed plates and are usually made of metal, though wood and plastic have also been used. The choice of these is personal; because they project sound, they determine the tonal quality of the harmonica. There are two types of cover plates: traditional open designs of stamped metal or plastic, which are simply there to be held; and enclosed designs (such as the Hohner Meisterklasse and Super 64, Suzuki Promaster and SCX), which offer a louder tonal quality. From these two basic types, a few modern designs have been created, such as the Hohner CBH-2016 chromatic and the Suzuki Overdrive diatonic, which have complex covers that allow for specific functions not usually available in the traditional design. It was not unusual in the late 19th and early 20th centuries for harmonicas to have special features on the covers, such as bells, which could be rung by pushing a button.

"Windsavers" are one-way valves made from thin strips of plastic, knit paper, leather or Teflon glued to the reed plate. They are typically found in chromatic harmonicas, chord harmonicas and many octave-tuned harmonicas. Windsavers are used when two reeds share a cell and leakage through the nonplaying reed would be significant. For example, when a draw note is played, the valve on the blow reed-slot is sucked shut, preventing air from leaking through the inactive blow reed. An exception to this is the now-discontinued Hohner XB-40, on which valves are placed not to isolate single reeds but rather to isolate entire chambers from being active, a design that made it possible to play traditional blues bends on all reeds.

The mouthpiece is placed between the air chambers of the instrument and the player's mouth. This can be integral with the comb (the diatonic harmonicas; the Hohner Chrometta); part of the cover (as in Hohner's CX-12); or may be a separate unit, secured by screws, which is typical of chromatics. In many harmonicas, the mouthpiece is purely an ergonomic aid designed to make playing more comfortable. However, in the traditional slider-based chromatic harmonica, it is essential to the functioning of the instrument because it provides a groove for the slide.

Since the 1950s, many blues harmonica players have amplified their instrument with microphones and tube amplifiers. One of the early innovators of this approach was Marion "Little Walter" Jacobs, who played the harmonica near a "Bullet" microphone marketed for use by radio taxi dispatchers. This gave his harmonica tone a "punchy" midrange sound that could be heard above an electric guitar. As well, tube amplifiers produce a natural growling overdrive when cranked at higher volumes, which adds body, fullness and "grit" to the sound. Little Walter also cupped his hands around the instrument, tightening the air around the harp, giving it a powerful, distorted sound, somewhat reminiscent of a saxophone, hence the term "Mississippi saxophone". Some harmonica players in folk use a regular vocal mic, such as a Shure SM 58 for their harmonica, which gives a clean, natural sound.

As technology in amplification has progressed, harmonica players have introduced other effects units to their rigs as well, such as reverb, tremolo, delay, octave, additional overdrive pedals, and chorus effect. John Popper of Blues Traveler uses a customized microphone that encapsulates several of these effects into one handheld unit, as opposed to several units in sequence. Many harmonica players still prefer tube amplifiers to solid-state, owing to the perceived difference in tone generated by the vacuum tubes. Players perceive tubes as having a "warmer" tone and a more "natural" overdrive sound. Many amplifiers designed for electric guitar are also used by harmonica players, such as the Kalamazoo Model Two, Fender Bassman, and the Danelectro Commando. Some expensive, handmade boutique amplifiers, however, are built from the ground up with characteristics that are optimal for amplified harmonica.

Harmonica players who play the instrument while performing on another instrument with their hands (e.g., an acoustic guitar) often use an accessory called a "neck rack" or "harmonica holder" to position the instrument in front of their mouth. A harmonica holder clamps the harmonica between two metal brackets, which are attached to a curved loop of metal that rests on the shoulders. The original harmonica racks were made from wire or coat hangers. Models of harmonica racks vary widely by quality and ease of use, and it quite often takes experimenting with more than one model of harmonica rack to find one that feels suitable for each individual player. This device is used by folk musicians, one-man bands and singer-songwriters such as Bob Dylan, Tom Harmon, Neil Young, Eddie Vedder, Billy Joel, Bruce Springsteen and blues singers Jimmy Reed and John Hammond Jr. The HarpArm is a magnetic harmonica holder that attaches to standard straight or boom microphone stands.

The chromatic harmonica uses a button-activated sliding bar to redirect air from the hole in the mouthpiece to the selected reed-plate, though one design—the "Machino-Tone"—controlled airflow by means of a lever-operated flap on the rear of the instrument. Also, a "hands-free" modification to the Hohner 270 (12-hole) lets the player shift the tones by moving the mouthpiece up and down with the lips, leaving the hands free to play another instrument. While the Richter-tuned 10-hole chromatic is intended to play in only one key, the 12-, 14-, and 16-hole models (which are tuned to equal temperament) allow the musician to play in any key desired with only one harmonica. This harp can be used for any style, including Celtic, classical, jazz, or blues (commonly in third position).

Strictly speaking, diatonic denotes any harmonica designed to play in a single key—though the standard Richter-tuned harmonica diatonic can play other keys by forcing its reeds to play tones that are not part of its basic scale. Depending on the country, "diatonic harmonica" may mean either the tremolo harmonica (in East Asia) or blues harp (In Europe and North America). Other diatonic harmonicas include octave harmonicas.

Here is the note layout for a standard diatonic in the key of G major:

Each hole is the same interval (here, a perfect fifth) from its key of C counterpart; on the diatonic scale, a G is a perfect fifth from C. The interval between keys can be used to find the note layout of any standard diatonic.

The distinguishing feature of the tremolo-tuned harmonica is that it has two reeds per note, with one slightly sharp and the other slightly flat. This provides a unique wavering or warbling sound created by the two reeds being slightly out of tune with each other and the difference in their subsequent waveforms interacting with each other (its beat). The Asian version, which can produce all 12 semitones, is used often in East Asian rock and pop music.

Orchestral harmonicas are primarily designed for use in ensemble playing.

There are eight kinds of orchestral melody harmonica; the most common are the horn harmonicas often found in East Asia. These consist of a single large comb with blow-only reed-plates on the top and bottom. Each reed sits inside a single cell in the comb. One version mimics the layout of a piano or mallet instrument, with the natural notes of a C diatonic scale in the lower reed plate and the sharps and flats in the upper reed plate in groups of two and three holes with gaps in between like the black keys of a piano. Another version has one "sharp" reed directly above its "natural" on the lower plate, with the same number of reeds on both plates (therefore including E and B).

Horn harmonicas are available in several pitch ranges, with the lowest pitched starting two octaves below middle C and the highest beginning on middle C itself; they usually cover a two- or three-octave range. They are chromatic instruments and are usually played in an East Asian harmonica orchestra instead of the "push-button" chromatic harmonica that is more common in the European and American tradition. Their reeds are often larger, and the enclosing "horn" gives them a different timbre, so that they often function in place of a brass section. In the past, they were referred to as horn harmonicas.

The other type of orchestral melodic harmonica is the polyphonia, (though some are marked "chromatica"). These have all twelve chromatic notes laid out on the same row. In most cases, they have both blow and draw of the same tone, though the No. 7 is blow only, and the No. 261, also blow only, has two reeds per hole, tuned an octave apart (all these designations refer to products of M. Hohner).

The chord harmonica has up to 48 chords: major, seventh, minor, augmented and diminished for ensemble playing. It is laid out in four-note clusters, each sounding a different chord on inhaling or exhaling. Typically each hole has two reeds for each note, tuned to one octave of each other. However, less expensive models often have only one reed per note. Quite a few orchestra harmonicas are also designed to serve as both bass and chord harmonica, with bass notes next to chord groupings. There are also other chord harmonicas, such as the Chordomonica (which operates similar to a chromatic harmonica), and the junior chord harmonicas (which typically provide six chords).

The Suzuki SSCH-56 Compact Chord harmonica is a 48-chord harmonica built in a 14-hole chromatic harmonica enclosure. The first three holes play a major chord on blow and draw, with and without the slide. Holes 2, 3, and 4 play a diminished chord; holes 3, 4, and 5 play a minor chord; and holes 4, 5, and 6 play an augmented, for a total of sixteen chords. This pattern is repeated starting on hole 5, a whole step higher; and again starting on hole 9, for a total of 48 chords.

The ChengGong harmonica has a main body, and a sliding mouthpiece. The body is a 24-hole diatonic harmonica that ranges from B to D (covering 3 octaves). Its 11-hole mouthpiece can slide along the front of the harmonica, which gives numerous chord choices and voicings (seven triads, three 6th chords, seven 7th chords, and seven 9th chords, for a total of 24 chords). As well, it is capable of playing single-note melodies and double stops over a range of three diatonic octaves. Unlike conventional harmonicas, blowing and drawing produce the same notes because its tuning is closer to the note layout of a typical Asian tremolo harmonica or the Polyphonias.

The pitch pipe is a simple specialty harmonica that provides a reference pitch to singers and other instruments. The only difference between some early pitch-pipes and harmonicas is the name of the instrument, which reflected the maker's target audience. Chromatic pitch pipes, which are used by singers and choirs, give a full chromatic (12-note) octave. Pitch pipes are also sold for string players, such as violinists and guitarists; these pitch pipes usually provide the notes corresponding to the open strings.

Vibrato is a technique commonly used while playing the harmonica and many other instruments, to give the note a 'shaking' sound. This technique can be accomplished in a number of ways. The most common way is to change how the harmonica is held. For example, the vibrato effect can be achieved by opening and closing the hands around the harmonica very rapidly. The vibrato might also be achieved via rapid glottal (vocal fold) opening and closing, especially on draws (inhalation) simultaneous to bending, or without bending. This obviates the need for cupping and waving the hands around the instrument during play. An effect similar to vibrato is that of the 'trill' (or 'roll', or 'warble, or 'shake'); this technique has the player move their lips between two holes very quickly, either by shaking the head in a rapid motion or moving the harmonica from side to side within the embouchure. This gives a quick pitch-alternating technique that is slightly more than vibrato and achieves the same aural effect on sustained notes, albeit by using two different tones instead of varying the amplitude of one.

In addition to the 19 notes readily available on the diatonic harmonica, players can play other notes by adjusting their embouchure and forcing the reed to resonate at a different pitch. This technique is called bending, a term possibly borrowed from guitarists, who literally bend a string to subtly change the pitch. Bending also creates the glissandos characteristic of much blues harp and country harmonica playing. Bends are essential for most blues and rock harmonica due to the soulful sounds the instrument can bring out. The "wail" of the blues harp typically requires bending. In the 1970s, Howard Levy developed the over bending technique (also known as "overblowing" and "overdrawing".) Over Bending, combined with bending, allowed players to play the entire chromatic scale.

In addition to playing the diatonic harmonica in its original key, it is also possible to play it in other keys by playing in other "positions" using different keynotes. Using just the basic notes on the instrument would mean playing in a specific mode for each position. For example the Mixolydian mode (root note is the second draw or third blow), produces a major dominant seventh key that is frequently used by blues players because it contains the harmonically rich dominant seventh note, while the Dorian mode (root note is four draw) produces a minor dominant seventh key. Harmonica players (especially blues players) have developed terminology around different "positions," which can be confusing to other musicians, for example the slang terminology for the most common positions (1st being 'straight', 2nd being 'cross', 3rd being 'slant', etc.).

Another technique, seldom used to its full potential, is altering the size of the mouth cavity to emphasize certain natural overtones. When this technique is employed while playing chords, care must be taken in overtone selection as the overtones stemming from the non-root pitch can cause extreme dissonance.

Harmonica players who amplify their instrument with microphones and tube amplifiers, such as blues harp players, also have a range of techniques that exploit properties of the microphone and the amplifier, such as changing the way the hands are cupped around the instrument and the microphone or rhythmically breathing or chanting into the microphone while playing. Blues and folk players refer to the instrument with a range of less common names, including "hand reed," "Mississippi saxophone," "licking stick," "pocket sax," "toe pickle," "tin sandwich," "ten-holed tin-can tongue twister," "blues burger," "harpoon," "moothie," and "French harp".

The harmonica was developed in Europe in the early part of the 19th century. Free-reed instruments like the Chinese sheng were fairly common in Asia since ancient times. They became relatively well known in Europe after being introduced by the French Jesuit Jean Joseph Marie Amiot (1718-1793), who lived in Qing-era China. Around 1820, free-reed designs began being created in Europe. Christian Friedrich Ludwig Buschmann is often cited as the inventor of the harmonica in 1821, but other inventors developed similar instruments at the same time. Mouth-blown free-reed instruments appeared in the United States, South America, the United Kingdom and Europe at roughly the same time. These instruments were made for playing classical music.

The harmonica first appeared in Vienna, where harmonicas with chambers were sold before 1824 (see also Anton Reinlein and Anton Haeckl). Richter tuning, invented by Joseph Richter (who also is credited with inventing the blow and draw mechanism), was created in 1826 and was eventually adopted nearly universally. In Germany, violin manufacturer Mr. Meisel from Klingenthal bought a harmonica with chambers (Kanzellen) at the Exhibition in Braunschweig in 1824. He and the ironworker Langhammer copied the instruments in the Graslitz three miles away; by 1827 they had produced hundreds of harmonicas. Many others followed in Germany and also nearby in what would later become Czechoslovakia. In 1829, Johann Wilhelm Rudolph Glier also began making harmonicas.

In 1830, Christian Messner, a cloth maker and weaver from Trossingen, copied a harmonica his neighbour had brought from Vienna. He had such success that eventually his brother and some relatives also started to make harmonicas. From 1840 onwards, his nephew Christian Weiss was also involved in the business. By 1855, there were at least three harmonica-making businesses: C. A. Seydel Söhne, Christian Messner & Co., and Württ. Harmonikafabrik Ch. Weiss. (Currently, only C.A. Seydel is still in business.) Owing to competition between the harmonica factories in Trossingen and Klingenthal, machines were invented to punch the covers for the reeds.

In 1857, Matthias Hohner, a clockmaker from Trossingen, started producing harmonicas. Eventually he became the first to mass-produce them. He used a mass-produced wooden comb that he had made by machine-cutting firms. By 1868, he began supplying the United States. By the 1920s, the diatonic harmonica had largely reached its modern form. Other types followed soon thereafter, including the various tremolo and octave harmonicas.

By the late 19th century, harmonica production was a big business, having evolved into mass production. New designs were still developed in the 20th century, including the chromatic harmonica, first made by Hohner in 1924, the bass harmonica, and the chord harmonica. In the 21st century, radical new designs have been developed and are still being introduced into the market, such as the Suzuki Overdrive, Hohner XB-40, and the ill-fated Harrison B-Radical.

Diatonic harmonicas were designed primarily for playing German and other European folk music and have succeeded well in those styles. Over time, the basic design and tuning proved adaptable to other types of music such as the blues, country, old-time and more. The harmonica was a success almost from the very start of production, and while the center of the harmonica business has shifted from Germany, the output of the various harmonica manufacturers is still very high. Major companies are now found in Germany (, Bushman, Hohner – the dominant manufacturer in the world), Japan (Suzuki, Tombo – the manufacturer of the popular Lee Oskar harmonica, and Yamaha also made harmonicas until the 1970s), China (Huang, Eastop, Johnson, Leo Shi, Suzuki, Hohner, Swan, AXL), and Brazil (Hering, Bends). The United States had two significant harmonica manufacturers, and both were based in Union, New Jersey. One was Magnus Harmonica Corporation, whose founder Finn Magnus is credited with the development of plastic harmonica reeds. The other was Wm. Kratt Company, which, founded by German-American William Jacob "Bill" Kratt Sr., originally made pitch pipes and later, in 1952, secured a patent for combs made of plastic. Both companies ceased harmonica production. The only recent American contender in the harmonica market was Harrison Harmonicas, which folded in July 2011. It was announced soon thereafter that the rights to the Harrison design had been sold to another company to finish production of orders already placed. In October 2012, it was revealed that a Beloit, Wisconsin, investment corporation, R&R Opportunities, had bought the assets of Harrison Harmonicas and that a feasibility study was under way to assess the possibilities of continued production of the Harrison B-Radical harmonica. Recently, responding to increasingly demanding performance techniques, the market for high-quality instruments has grown.

Some time before Hohner began manufacturing harmonicas in 1857, he shipped some to relatives who had emigrated to the United States. Its music rapidly became popular, and the country became an enormous market for Hohner's goods. President Abraham Lincoln carried a harmonica in his pocket, and harmonicas provided solace to soldiers on both the Union and Confederate sides of the American Civil War. Frontiersmen Wyatt Earp and Billy the Kid played the instrument, and it became a fixture of the American musical landscape.

Harmonicas were heard on a handful of recordings in the early 1900s, generally labeled as a "mouth organ". The first jazz or traditional music recordings of harmonicas were made in the U.S. in the mid-1920s. Recordings known at the time as "race records", intended for the black market of the southern states, included solo recordings by DeFord Bailey and duo recordings with a guitarist (Hammie Nixon, Walter Horton, or Sonny Terry). Hillbilly styles were also recorded, intended for white audiences, by Frank Hutchison, Gwen Foster and several other musicians. There are also recordings featuring the harmonica in jug bands, of which the Memphis Jug Band is the most famous. But the harmonica still represented a toy instrument in those years and was associated with the poor. It is also during those years that musicians started experimenting with new techniques such as tongue-blocking, hand effects and the most important innovation of all, the second position, or cross-harp.

A significant contributor to the expanding popularity of the harmonica was a New York-based radio program called the "Hohner Harmony Hour", which taught listeners how to play. Listeners could play along with the program to increase their proficiency. The radio program gained wide popularity after the unveiling of the 1925 White House Christmas tree, which was adorned with fifty harmonicas.

The harmonica's versatility brought it to the attention of classical musicians during the 1930s. American Larry Adler was one of the first harmonica players to perform major works written for the instrument by the composers Ralph Vaughan Williams, Malcolm Arnold, Darius Milhaud, and Arthur Benjamin.

Harmonicas were in short supply in the United States during World War II. Wood and metal materials for harmonicas were in short supply because of military demand. Furthermore, the primary harmonica manufacturers were based in Germany and Japan, the enemies of the United States and the Allied forces in the war. During this time, Finn Haakon Magnus, a Danish-American factory worker and entrepreneur, developed and perfected the molded plastic harmonica. The plastic harmonica used molded plastic combs and far fewer pieces than traditional metal or wood harmonicas, which made the harmonica more economical to mass-produce and more sanitary. Though the plastic reeds in these harmonicas produced a less distinctive (and, to many ears, inferior) sound than their metallic counterparts, Magnus harmonicas and several imitators soon became commonplace, particularly among children. The patent for the plastic comb, however, was awarded to William Kratt of Wm. Kratt Company in 1952. During World War II, the War Department allotted a rationed supply of brass to Kratt's factory so they could continue to produce harmonicas that the Red Cross distributed to American troops overseas to boost morale.

In 1898, the harmonica was brought to Japan, where the Tremolo harmonica was the most popular instrument. After about 30 years, the Japanese developed scale tuning and semitone harmonicas that could play Japanese folk songs.

In Europe and the United States, tremolo harmonica uses the Richter tuning, developed in Germany. In 1913, Shōgo Kawaguchi (), known in Japan as the "Father of the harmonica", devised an alternate tuning, which is more suited to playing Japanese folk tunes. This tuning is also suited to local music throughout East Asia, and harmonicas using the tuning became popular in the region.

Initial diatonic harmonica tunings were major key only. In 1931, Hiderō Satō () announced the development of a minor key harmonica. There are two types of minor key tunings, "natural minor" suitable for folk and contemporary music, and Latin American music, and the "harmonic minor" suitable for Japanese folk music.

The harmonica started to gain popularity in Hong Kong in the 1930s. Individual tremolo harmonica players from China moved to Hong Kong and established numerous harmonica organizations such as The Chinese Y.M.C.A. Harmonica Orchestra, the China Harmonica Society, and the Heart String Harmonica Society. During the 1950s, chromatic harmonica became popular in Hong Kong, and players such as Larry Adler and John Sebastian Sr. were invited to perform.

Local players such as Lau Mok () and Fung On () promoted the chromatic harmonica. The chromatic harmonica gradually became the main instrument used by the Chinese Y.M.C.A. Harmonica Orchestra. The Chinese YMCA Harmonica Orchestra started in the 1960s, with 100 members, most of whom played harmonicas. Non-harmonica instruments were also used, such as double bass, accordion, piano, and percussion such as timpani and xylophone.

In the 1970s, the Haletone Harmonica Orchestra () was set up at Wong Tai Sin Community Centre. Fung On and others continued to teach harmonica and also set up harmonica orchestras. In the 1980s, numbers of harmonica students steadily decreased. In the 1990s, harmonica players from Hong Kong began to participate in international harmonica competitions, including the World Harmonica Festival in Germany and the Asia Pacific Harmonica Festival. In the 2000s, the Hong Kong Harmonica Association (H.K.H.A.) () was established.

The history of the harmonica in Taiwan began around 1945. By the 1980s, though, as living standards improved, many instruments once beyond the budgets of most Taiwanese started to become more accessible and popular in preference to the harmonica.

Playing the harmonica requires inhaling and exhaling strongly against resistance. This action helps develop a strong diaphragm and deep breathing using the entire lung volume. Pulmonary specialists have noted that playing the harmonica resembles the kind of exercise used to rehabilitate COPD patients such as using a PFLEX inspiratory muscle trainer or the inspiratory spirometer. Learning to play a musical instrument also offers motivation in addition to the exercise component. Many pulmonary rehabilitation programs therefore have begun to incorporate the harmonica.

The concertina, diatonic and chromatic accordions and the melodica are all free-reed instruments that developed alongside the harmonica. Indeed, the similarities between harmonicas and so-called "diatonic" accordions or melodeons is such that in German the name for the former is "Mundharmonika" and the latter "Handharmonika," which translate as "mouth harmonica" and "hand harmonica." In Scandinavian languages, an accordion is simply called "harmonika," whereas a harmonica is a "mundharmonika" (mouth harmonica). The names for the two instruments in the Slavic languages are also either similar or identical. The harmonica shares similarities to all other free-reed instruments by virtue of the method of sound production.

The glass harmonica has the word "harmonica" in its name, but it is not related to free-reed instruments. The glass harmonica is a musical instrument formed from a nested set of graduated glass cups mounted sideways on an axle. Each of the glass cups is tuned to a different note, and they are arranged in a scalar order. It is played by touching the rotating cups with wetted fingers, causing them to vibrate and produce a sustained "singing" tone.

Tablature notation (often abbreviated as "tab") is a method of writing melodies by indicating where the notes are played on the instrument, rather than by indicating the pitches with circles and note heads printed on a staff, as with standard notation. One of the advantages of tab is that it can be easier for performers without formal training to learn, because the notation directly indicates where to play the note.

While tab is most often associated with fretted stringed instruments such as the guitar, tab is also used with other instruments such as the organ and harmonica.

There are many harmonica tab systems in use. A simple tab system appears as follows:

Diatonic Harmonica tab:

Chords are shown by grouping notes with parentheses

(2 3) = blow the 2 hole and the 3 hole at the same time

Chromatic Harmonica tab:

Harmonica tab is usually aligned with lyrics to show the tune and the timing, and usually states the key of the harmonica required for the song.

Complete example of harmonica tab:
A number (sometimes inside a circle) appears below each note in otherwise conventional sheet music, and indicates which number hole to play. An up or down arrow beneath the number indicates whether to blow or draw. Up means blow and down means draw. A curved arrow indicates bend notes—slightly to the left for a half step flat, and longer to the left to indicate a whole step flat. Right-pointing arrows indicate a sharp bend.


</doc>
<doc id="14352" url="https://en.wikipedia.org/wiki?curid=14352" title="Hops">
Hops

Hops are the flowers (also called seed cones or strobiles) of the hop plant "Humulus lupulus." They are used primarily as a flavouring and stability agent in beer, to which they impart bitter, zesty, or citric flavours; though they are also used for various purposes in other beverages and herbal medicine. The hop plant is a vigorous, climbing, herbaceous perennial, usually trained to grow up strings in a field called a hopfield, hop garden (nomenclature in the South of England), or hop yard (in the West Country and U.S.) when grown commercially. Many different varieties of hops are grown by farmers around the world, with different types used for particular styles of beer.

The first documented use of hops in beer is from the 9th century, though Hildegard of Bingen, 300 years later, is often cited as the earliest documented source. Before this period, brewers used a "gruit", composed of a wide variety of bitter herbs and flowers, including dandelion, burdock root, marigold, horehound (the old German name for horehound, "Berghopfen", means "mountain hops"), ground ivy, and heather. Early documents include mention of a hop garden in the will of Charlemagne's father, Pepin III.

Hops are also used in brewing for their antibacterial effect over less desirable microorganisms and for purported benefits including balancing the sweetness of the malt with bitterness and a variety of flavours and aromas. Historically, traditional herb combinations for beers were believed to have been abandoned when beers made with hops were noticed to be less prone to spoilage.

The first documented hop cultivation was in 736, in the Hallertau region of present-day Germany, although the first mention of the use of hops in brewing in that country was 1079. However, in a will of Pepin the Short, the father of Charlemagne, hop gardens were left to the Cloister of Saint-Denis in 768. Not until the 13th century did hops begin to start threatening the use of gruit for flavouring. Gruit was used when taxes were levied by the nobility on hops. Whichever was taxed made the brewer then quickly switch to the other. In Britain, hopped beer was first imported from Holland around 1400, yet hops were condemned as late as 1519 as a "wicked and pernicious weed". In 1471, Norwich, England, banned use of the plant in the brewing of ale ("beer" was the name for fermented malt liquors bittered with hops; only in recent times are the words often used as synonyms).

In Germany, using hops was also a religious and political choice in the early 16th century. There was no tax on hops to be paid to the Catholic church, unlike on gruit. For this reason the Protestants preferred hopped beer.

Hops used in England were imported from France, Holland and Germany with import duty paid for those; it was not until 1524 that hops were first grown in the southeast of England (Kent) when they were introduced as an agricultural crop by Dutch farmers. Therefore, in the hop industry there are many words which originally were Dutch words (see oast house). Hops were then grown as far north as Aberdeen, near breweries for convenience of infrastructure.

According to Thomas Tusser's 1557 "Five Hundred Points of Good Husbandry":
"The hop for his profit I thus do exalt,It strengtheneth drink and it flavoureth malt;And being well-brewed long kept it will last,And drawing abide, if ye draw not too fast."

In England there were many complaints over the quality of imported hops, the sacks of which were often contaminated by stalks, sand or straw to increase their weight. As a result, in 1603, King James I approved an Act of Parliament banning the practice by which "the Subjects of this Realm have been of late years abused &c. to the Value of £20,000 yearly, besides the Danger of their Healths".

Hop cultivation was begun in the present-day United States in 1629 by English and Dutch farmers. Before prohibition, cultivation was mainly centred around New York, California, Oregon, and Washington state. Problems with powdery mildew and downy mildew devastated New York's production by the 1920s, and California only produces hops on a small scale.

Hop bars were used before modern machinery was invented to make the holes for the hop poles.

Hops production is concentrated in moist temperate climates, with much of the world's production occurring near the 48th parallel north. Hop plants prefer the same soils as potatoes and the leading potato-growing states in the United States are also major hops-producing areas; however, not all potato-growing areas can produce good hops naturally: soils in the Maritime Provinces of Canada, for example, lack the boron that hops prefer. Historically, hops were not grown in Ireland, but were imported from England. In 1752 more than 500 tons of English hops were imported through Dublin alone.

Important production centres today are the Hallertau in Germany (more hop-growing area than any other country as of 2006), the Žatec (Saaz) in the Czech Republic, the Yakima (Washington) and Willamette (Oregon) valleys, and western Canyon County, Idaho (including the communities of Parma, Wilder, Greenleaf, and Notus). The principal production centres in the UK are in Kent (which produces Kent Goldings hops), Herefordshire, and Worcestershire. Essentially all of the harvested hops are used in beer making.

Although hops are grown in most of the continental United States and Canada, cultivation of hops for commercial production requires a particular environment. As hops are a climbing plant, they are trained to grow up trellises made from strings or wires that support the plants and allow them significantly greater growth with the same sunlight profile. In this way, energy that would have been required to build structural cells is also freed for crop growth.

The hop plant's reproduction method is that male and female flowers develop on separate plants, although occasionally a fertile individual will develop which contains both male and female flowers. Because pollinated seeds are undesirable for brewing beer, only female plants are grown in hop fields, thus preventing pollination. Female plants are propagated vegetatively, and male plants are culled if plants are grown from seeds.

Hop plants are planted in rows about apart. Each spring, the roots send forth new bines that are started up strings from the ground to an overhead trellis. The cones grow high on the bine, and in the past, these cones were picked by hand. Harvesting of hops became much more efficient with the invention of the mechanical hops separator, patented by Emil Clemens Horst in 1909.

Harvest comes near the end of summer when the bines are pulled down and the flowers are taken to a hop house or oast house for drying. Hop houses are two-story buildings, of which the upper story has a slatted floor covered with burlap. Here the flowers are poured out and raked even. A heating unit on the lower floor is used to dry the hops. When dry, the hops are moved to a press, a sturdy box with a plunger. Two long pieces of burlap are laid into the hop press at right angles, the hops are poured in and compressed into bales.

Hop cones contain different oils, such as lupulin, a yellowish, waxy substance, an oleoresin, that imparts flavour and aroma to beer. Lupulin contains lupulone and humulone, which possess antibiotic properties, suppressing bacterial growth favoring brewer's yeast to grow. After lupulin has been extracted in the brewing process the papery cones are discarded.

The need for massed labor at harvest time meant hop-growing had a big social impact. Around the world, the labor-intensive harvesting work involved large numbers of migrant workers who would travel for the annual hop harvest. Whole families would participate and live in hoppers' huts, with even the smallest children helping in the fields. The final chapters of W. Somerset Maugham's "Of Human Bondage" and a large part of George Orwell's "A Clergyman's Daughter" contain a vivid description of London families participating in this annual hops harvest. In England, many of those picking hops in Kent were from eastern areas of London. This provided a break from urban conditions that was spent in the countryside. People also came from Birmingham and other Midlands cities to pick hops in the Malvern area of Worcestershire. Some photographs have been preserved.

Particularly in Kent, because of a shortage of small-denomination coin of the realm, many growers issued their own currency to those doing the labor. In some cases, the coins issued were adorned with fanciful hops images, making them quite beautiful.

In the US, Prohibition had a major impact on hops productions, but remnants of this significant industry in West and Northwest US are still noticeable in the form of old hop kilns that survive throughout Sonoma County, among others. Florian Dauenhauer, of Santa Rosa in Sonoma County, became a manufacturer of hop-harvesting machines in 1940, in part because of the hop industry's importance to the county. This mechanization helped destroy the local industry by enabling large-scale mechanized production, which moved to larger farms in other areas. Dauenhauer Manufacturing remains a current producer of hop harvesting machines.

In addition to water, cellulose, and various proteins, the chemical composition of hops consists of compounds important for imparting character to beer.

Probably the most important chemical compound within hops are the alpha acids or humulones. During wort boiling, the humulones are thermally isomerized into iso-alpha acids or "isohumulones", which are responsible for the bitter taste of beer.

Hops contain beta acids or lupulones sensitive to oxidative decomposition which may be detrimental to the taste of beer. For this reason, beta acids are considered a negative factor in brewing and many brewers usually choose hops with a low beta acid content.

The main components of hops essential oils are terpene hydrocarbons consisting of myrcene, humulene and caryophyllene. Myrcene is responsible for the pungent smell of fresh hops. Humulene and its oxidative reaction products may give beer its prominent hop aroma. Together, myrcene, humulene, and caryophyllene represent 80 to 90% of the total hops essential oil.

Xanthohumol is the principal flavonoid in hops. The other well-studied prenylflavonoids are 8-prenylnaringenin and isoxanthohumol. Xanthohumol is under basic research for its potential properties, while 8-prenylnaringenin is a potent phytoestrogen.

Hops are usually dried in an oast house before they are used in the brewing process. 
Undried or "wet" hops are sometimes (since ca.1990) used.

The wort (sugar-rich liquid produced from malt) is boiled with hops before it is cooled down and yeast is added, to start fermentation.

The effect of hops on the finished beer varies by type and use, though there are two main hop types: bittering and aroma. Bittering hops have higher concentrations of alpha acids, and are responsible for the large majority of the bitter flavour of a beer. European (so-called "noble") hops typically average 5–9% alpha acids by weight (AABW), and the newer American cultivars typically range from 8–19% AABW. Aroma hops usually have a lower concentration of alpha acids (~5%) and are the primary contributors of hop aroma and (nonbitter) flavour. Bittering hops are boiled for a longer period of time, typically 60–90 minutes, to maximize the isomerization of the alpha acids. They often have inferior aromatic properties, as the aromatic compounds evaporate off during the boil.

The degree of bitterness imparted by hops depends on the degree to which alpha acids are isomerized during the boil, and the impact of a given amount of hops is specified in International Bitterness Units. Unboiled hops are only mildly bitter. On the other hand, the nonbitter flavour and aroma of hops come from the essential oils, which evaporate during the boil.

Aroma hops are typically added to the wort later to prevent the evaporation of the essential oils, to impart "hop taste" (if during the final 30 minutes of boil) or "hop aroma" (if during the final 10 minutes, or less, of boil). Aroma hops are often added after the wort has cooled and while the beer ferments, a technique known as "dry hopping", which contributes to the hop aroma. Farnesene is a major component in some hops. The composition of hop essential oils can differ between varieties and between years in the same variety, having a significant influence on flavour and aroma.

Today, a substantial amount of "dual-use" hops are used, as well. These have high concentrations of alpha acids and good aromatic properties. These can be added to the boil at any time, depending on the desired effect. Hop acids also contribute to and stabilize the foam qualities of beer.

Flavours and aromas are described appreciatively using terms which include "grassy", "floral", "citrus", "spicy", "piney", "lemony", "grapefruit", and "earthy".
Many pale lagers have fairly low hop influence, while lagers marketed as Pilsener or brewed in the Czech Republic may have noticeable noble hop aroma. Certain ales (particularly the highly hopped style known as India Pale Ale, or IPA) can have high levels of hop bitterness.

Brewers may use software tools to control the bittering levels in the boil and adjust recipes to account for a change in the hop bill or seasonal variations in the crop that may lead to the need to compensate for a difference in alpha acid contribution. Data may be shared with other brewers via BeerXML allowing the reproduction of a recipe allowing for differences in hop availability.

There are many different varieties of hops used in brewing today. Historically, hops varieties were identified by geography (such as Hallertau, Spalt, and Tettnang from Germany), by the farmer who is recognized as first cultivating them (such as Goldings or Fuggles from England), or by their growing habit (e. g., Oregon Cluster).

Around 1900, a number of institutions began to experiment with breeding specific hop varieties. The breeding program at Wye College in Wye, Kent was started in 1904 and rose to prominence through the work of Prof. E. S. Salmon. Salmon released Brewer's Gold and Brewer's Favorite for commercial cultivation in 1934, and went on to release more than two dozen new cultivars before his death in 1959. Brewer's Gold has become the ancestor of the bulk of new hop releases around the world since its release.

Wye College continued its breeding program and again received attention in the 1970s, when Dr. Ray A. Neve released Wye Target, Wye Challenger, Wye Northdown, Wye Saxon and Wye Yeoman. More recently, Wye College and its successor institution Wye Hops Ltd., have focused on breeding the first dwarf hop varieties, which are easier to pick by machine and far more economical to grow. Wye College have also been responsible for breeding hop varieties that will grow with only 12 hours of daily light for the South African hop farmers. Wye College was closed in 2009 but the legacy of their hop breeding programs, particularly that of the dwarf varieties, is continuing as already the U.S.A. private and public breeding programs are using their stock material.

Particular hop varieties are associated with beer regions and styles, for example pale lagers are usually brewed with European (often German, Polish or Czech) noble hop varieties such as Saaz, Hallertau and Strissel Spalt. British ales use hop varieties such as Fuggles, Goldings and W.G.V. North American beers often use Cascade hops, Columbus hops, Centennial hops, Willamette, Amarillo hops and about forty more varieties as the U.S.A. have lately been the more significant breeders of new hop varieties, including dwarf hop varieties.

Hops from New Zealand, such as Pacific Gem, Motueka and Nelson Sauvin, are used in a "Pacific Pale Ale" style of beer with increasing production in 2014.

The term "noble hops" traditionally refers to varieties of hops which are low in bitterness and high in aroma. They are the European cultivars or races Hallertau, Tettnanger, Spalt, and Saaz.

Their low relative bitterness but strong aroma are often distinguishing characteristics of European-style lagers, such as Pilsener, Dunkel, and Oktoberfest/Märzen. In beer, they are considered aroma hops (as opposed to bittering hops); see Pilsner Urquell as a classic example of the Bohemian Pilsener style, which showcases noble hops.

As with grapes, the location where hops are grown affects the hops' characteristics. Much as Dortmunder beer may within the EU be labelled "Dortmunder" only if it has been brewed in Dortmund, noble hops may officially be considered "noble" only if they were grown in the areas for which the hop varieties (races) were named.


English noble varieties are Fuggle, East Kent Goldings and Goldings. They are characterized through analysis as having an alpha:beta ratio of 1:1, low alpha-acid levels (2–5%) with a low cohumulone content, low myrcene in the hop oil, high humulene in the oil, a ratio of humulene:caryophyllene above three, and poor storability resulting in them being more prone to oxidation. In reality, this means they have a relatively consistent bittering potential as they age, due to beta-acid oxidation, and a flavour that improves as they age during periods of poor storage.

In addition to beer, hops are used in herbal teas and in soft drinks. These soft drinks include Julmust (a carbonated beverage similar to soda that is popular in Sweden during December), Malta (a Latin American soft drink) and kvass. Hops can be eaten, the young shoots of the bine are edible and can be cooked similar to asparagus.

Hops may be used in herbal medicine in a way similar to valerian, as a treatment for anxiety, restlessness, and insomnia. A pillow filled with hops is a popular folk remedy for sleeplessness, and animal research has shown a sedative effect. The relaxing effect of hops may be due, in part, to the specific degradation product from alpha acids, 2-methyl-3-buten-2-ol, as demonstrated from nighttime consumption of non-alcoholic beer. 2-methyl-3-buten-2-ol is structurally similar to tert-amyl alcohol which was historically used as an anesthetic. Hops tend to be unstable when exposed to light or air and lose their potency after a few months' storage.

Hops are of interest for hormone replacement therapy and are under basic research for potential relief of menstruation-related problems.

In preliminary veterinary research, hops compounds are under study for potential activity against pasture-associated laminitis in horses.

Dermatitis sometimes results from harvesting hops. Although few cases require medical treatment, an estimated 3% of the workers suffer some type of skin lesions on the face, hands, and legs. Hops are toxic to dogs.



</doc>
<doc id="14355" url="https://en.wikipedia.org/wiki?curid=14355" title="Hack">
Hack

Hack may refer to:











</doc>
<doc id="14356" url="https://en.wikipedia.org/wiki?curid=14356" title="Huey, Dewey, and Louie">
Huey, Dewey, and Louie

Huey, Dewey, and Louie Duck are triplet cartoon characters created in 1937 by writer Ted Osborne and cartoonist Al Taliaferro, and are owned by The Walt Disney Company. Huey, Dewey, and Louie are the nephews of Donald Duck and the grandnephews of Scrooge McDuck. Like their uncles, the boys are anthropomorphic white ducks with yellow-orange bills and feet. They typically wear shirts and colorful baseball caps, which are sometimes used to differentiate each character. Huey, Dewey and Louie have made several animated appearances in both films and television, but comics remain their primary medium. The trio are collectively the 11th most published comic book characters in the world, and outside of the superhero genre, second only to Donald.

While the boys were originally created as mischief-makers to provoke Donald's famous temper, later appearances showed them to be valuable assets to him and Scrooge on their adventures. All three of the boys are members of the fictional scouting organization the Junior Woodchucks.

Huey, Dewey, and Louie were the idea of Al Taliaferro, the artist for the "Silly Symphonies" comic strip, which featured Donald Duck. The Walt Disney Productions Story Dept. on February 5, 1937, sent Taliaferro a memo recognizing him as the source of the idea for the planned short, "Donald's Nephews". The nephews debuted in Taliaferro's comic strip, which by this time had been renamed "Donald Duck", on Sunday, October 17, 1937, beating the theatrical release of "Donald's Nephews" by almost six months. According to Don Rosa, Carl Barks has claimed that in fact they were his creation while working as a writer on Donald Duck animated cartoons in 1937. The names were devised by Disney gag man Dana Coty, who took them from Huey Long, Thomas Dewey, and Louis Schmitt, an animator at the Disney Studio in the 1930s and 1940s. Taliaferro's introduction of the nephews emulated the three nephews in the Happy Hooligan comic strip and was also influenced by Mickey Mouse's nephews, Morty and Ferdie Fieldmouse.

In translations of Disney works the nephews have different local-sounding names that often follow the repetition (parachesis) of the English names. Examples include Hugo, Paco and Luis (Latin American Spanish); Jorgito, Juanito and Jaimito (European Spanish); Huguinho, Luizinho and Zezinho (Brazilian Portuguese); Billy, Willie and Dilly (Russian); and Tick, Trick and Track (German).

Huey, Dewey, and Louie are the sons of Donald's sister Della Duck; in "Donald's Nephews", their mother is instead named Dumbella. In the original theatrical shorts, they were originally sent to visit Donald for only one day; in the comics, the three were sent to stay with Donald on a temporary basis, until their father came back from the hospital (the boys ended up sending him there after a practical joke of putting firecrackers under his chair). In both the comics and animated shorts, the boys' parents were never heard from or mentioned again after these instances, with the boys ending up permanently living with Donald. All four of them live in the fictional city of Duckburg, in the fictional state of Calisota.

The three ducklings are noted for their identical appearances and personalities. A running joke involves the three sometimes even finishing each other's sentences. In the theatrical shorts, Huey, Dewey, and Louie often behave in a rambunctious and mischievous manner, and they sometimes commit retaliation or revenge on their uncle Donald Duck. In the comics, however, as developed by Al Taliaferro and Carl Barks, the young ducks are more usually portrayed as well-behaved, preferring to assist their uncle Donald Duck and great-uncle Scrooge McDuck in the adventure at hand. In the early Barks comics, the ducklings were still wild and unruly, but their character improved considerably due to their membership in the Junior Woodchucks and the good influence of their wise old great-grandmother Elvira Coot "Grandma" Duck. According to Don Rosa, Huey, Dewey and Louie became members of the Junior Woodchucks when they were around 11 years old.

In early comic books and shorts, the caps of Huey, Dewey, and Louie were colored randomly, depending on the whim of the colorist.

On few occasions until 1945 and most every cartoon short afterward, all three nephews wore identical outfits (most commonly red). It wasn't until the 1980s when it became established that Huey is dressed in red, Dewey in blue, and Louie in green. Disney's archivist Dave Smith, in "Disney A to Z," said, "Note that the brightest hue of the three is red (Huey), the color of water, dew, is blue (Dewey), and that leaves Louie, and leaves are green." A few random combinations appear in early Disney merchandise and books, such as orange and yellow. Another combination that shows up from time to time is Huey in blue, Dewey in green, and Louie in red. In-story, this inconsistency is explained away as a result of the ducklings borrowing each other's clothes.

In Donald Duck and Uncle Scrooge comics the trio have occasionally been known to dress in their usual outfits, but rather than have their usual colors they all wear black (or the same dark color), rendering them visually identical, leaving their hat color available if they care to be distinguished.

One story in Donald Duck comics was based around Donald spending so much time trying to tell his three nephews apart that he developed a heightened sense of sight.

Clarence Nash, Donald's voice actor, gave the voices to the boys in the cartoon shorts, making them just as unintelligible as Donald's. Huey, Dewey, and Louie were all voiced by Russi Taylor in "DuckTales". In "Quack Pack", they were voiced by Jeannie Elias, Pamela Segall, and Elizabeth Daily, respectively. Tony Anselmo voiced the characters in "Down and Out with Donald Duck" (1987), "Mickey Mouse Works" and "Disney's House of Mouse", but Russi Taylor still voices the trio in other projects, such as the video games "" and "Mickey's Speedway USA", and the direct-to-video films "Mickey's Once" and "Twice Upon a Christmas". Russi Taylor also reprised her role as the nephews in the "" video game and the post-2013 "Mickey Mouse" shorts. Danny Pudi, Ben Schwartz and Bobby Moynihan are voicing the brothers in the 2017 reboot.

On a few occasions, an artist by error drew four nephews and the error was not noticed but was published. This fourth nephew has been named Phooey Duck by Disney comic editor Bob Foster.

One short Egmont-licensed Disney comic (called "Much Ado About Phooey" in the English-language version) used Phooey as a character and explained Phooey's sporadic appearances as a freak incident of nature. (The Swedish text in the two speech balloons says "It is a fourth nephew! An exact copy of the others! / Yes, it's probably best that I explain".)

After the era of theatrical shorts ended, they appeared in:

In the 1988 film "Who Framed Roger Rabbit", Huey, Dewey, and Louie appear in a picture on a newspaper in Eddie Valiant's office. In 1990, the boys also made an appearance in the anti-drug TV special "Cartoon All-Stars to the Rescue". Furthermore, they also appeared in Duck Tales the movie where they go on a treasure hunt with their Uncle Scrooge and end befriending a kindhearted Genie. As the movie progresses, they make unimaginable wishes and end up having to help Uncle Scrooge face an old enemy. They also make a cameo in "Mickey's Christmas Carol".

They also appeared with Uncle Scrooge but without Donald in "Scrooge McDuck and Money".

Within the comics, Huey, Dewey, and Louie often play a major role in most stories involving either their uncle Donald or great-uncle Scrooge McDuck, accompanying them on most of their adventures. Also seen in the comics is the boys' membership in the Boy Scouts of America-like organization, the Junior Woodchucks, including their use of the Junior Woodchucks Guidebook, a manual containing all manner of information on virtually every subject possible (however, there are some resources, such as the ancient libraries of Tralla La, that hold information not found in the guidebook). This excellent youth organization, which has twin goals of preserving knowledge and preserving the environment, was instrumental in transforming the three brothers from little hellions to upstanding young ducks.

In Disney comic writer Don Rosa's (unofficial) continuity, Huey, Dewey, and Louie Duck were born around 1940 in Duckburg. True to his jocular style, Rosa occasionally makes subtle references to the untold mystery of the three boys' life: What became of their parents? In his epic comic series, "Life and Times of Scrooge McDuck", Rosa pictures how Scrooge first met Donald and his nephews, saying: "I'm not used to relatives, either! The few I had seem to have... disappeared!" Huey, Dewey, and Louie answer: "We know how "that" feels, Unca Scrooge!"

In "Some Heir Over the Rainbow" by Carl Barks, Huey, Dewey, and Louie, along with Donald Duck and Gladstone Gander, are tested by Scrooge McDuck, who wants to pick an heir to his fortune. Using the legend of a pot of gold at the end of a rainbow, Scrooge secretly gives US$ 3,000 (One thousand to Huey, Dewey, and Louie, another for Gladstone, and the last one for Donald). Donald uses his money for a down payment of a new car, now being $1,000 in debt. Gladstone, considering himself too lucky to need the money this soon, hides the money for when and if he needs it, causing Scrooge to consider him a better option than Donald. Huey, Dewey, and Louie lend their money to a man who claims to need the money to search for a treasure. Initially thinking they were tricked out of the money, Scrooge actually considers leaving his fortune to Gladstone, even though he sees that as ""an awful injustice to the world"", but the man actually finds the treasure and pays the kids back. Scrooge makes Huey, Dewey, and Louie his heirs. Although this is disregarded in a number of later comics, it seems to be the most solidly canon indication of Scrooge's plans.

They later starred in the 1987 animated television series "DuckTales", in which they appeared in adventures with their great-uncle, Scrooge McDuck (Donald having enlisted in the U.S. Navy). The boys' personalities in this series were mainly based on their comic book appearances versus the theatrical shorts.

A new adaptation of the series once again titled, "DuckTales" features the three brothers as well, albeit with distinct designs, voices, and personalities like in "Quack Pack", who move to Scrooge's house with Donald after the boat where they lived is destroyed by accident. In the new installment, the brothers also travel in adventures with Scrooge, now with Donald in tow. The first episode also shows an image of Della, the triplets' mother, who also traveled the world in adventures with Donald and Scrooge. This iteration also changed Dewey's real name to Dewford, while making Deuteronomy his middle name, and Louie's real name to Llywelyn.

Huey, Dewey, and Louie also starred in the 1990s series "Quack Pack", in which the three were portrayed as teenagers. In "Quack Pack", the boys were given distinct personalities, with Huey serving as the group's leader, Dewey as a computer whiz, and Louie as enjoying sports. After "Quack Pack", the boys were reverted to their original ages in future appearances, including 2000s series "Mickey Mouse Works", and then re-aged in "House of Mouse". On "House of Mouse", they served as the house band in a variety of different styles (most commonly as 'The Quackstreet Boys'). They also feature prominently, in a segment of the computer-animated film, "Mickey's Twice Upon a Christmas" from 2004.

Huey, Dewey, and Louie appear in the third "Magical Quest" game. The object of the game is to rescue them from the clutches of the villainous King Pete. The trio also appear in "Quackshot" piloting Donald's plane as he travels the world in search of a lost treasure.

They also appear in "The Lucky Dime Caper" for the Sega Master system, where they are kidnapped by Magica De Spell. Donald must find Scrooge's lucky dime and barter for their safety.

They also appear in "", aiding Donald to rescue Daisy and beat Gladstone to her, while he rescues their hexed play toys.

They even appear in "Mickey's Speedway USA" as unlockable lightweight characters.

They also appear in "DuckTales", aiding their Uncle Scrooge in finding treasure.

They also appear on "", where they appear as DJ's on certain music tracks

In "Kingdom Hearts" they work in the item shop in the First District of Traverse Town. In "Kingdom Hearts II", they individually run an item shop (Huey), a weapon shop (Louie), and an accessory shop (Dewey) in Hollow Bastion/Radiant Garden. In both endings, they are all seen going back to Disney Castle. They reappear in "" in Disney Town, recreating Ice Cream flavors, this time with a speaking role. They appear once more in the mobile game "Kingdom Hearts Unchained" as special Support medals that grant the player's other medals a set amount of experience points based on the medal's star value.

Huey, Dewey and Louie appear as characters only at Tokyo Disney and Disneyland Paris.

Huey, Dewey and Louie only appeared in seasonal Parades Easter, Halloween and Christmas 2011 after a long absence. They also appeared in the Countdown Party Parade 2011.

Huey, Dewey and Louie appear more regularly in Paris. They appeared during the Christmas season 2010 in their daytime and nighttime Parades at the Disneyland Park ""Disneyland Paris's Magic Kingdom"" Disney's Once Upon a Dream Parade and in the Disney's Fantillusion Parade in glittery outfits. They made another appearance at Disneyland Paris for meet and greet at the Disneyland Hotel on April 2, 2011 the day of the Press Event for the launch of their new season "Magical Moments Festival". They also appeared at the Disney's Once Upon a Dream Parade at the Disneyland Park in special outfits for the Parade and at the Disney's Stars 'n' Cars Parade at the Walt Disney Studios Park in a unique directors outfits.

The Three Nephews appeared at Disneyland Paris's Halloween season 2011. they have their own show during "Mickey's Not-So-Scary Halloween Parties" at the Disneyland Park in Disneyland Paris, titled "Huey, Dewey and Louie's Trick or Treat Party". They also made an appearance for meet and greet at Disneyland Paris's "Disney's Halloween Party" on October 31, 2011. This is the first time ever that the three nephews appear for meet and greet at any of the Disney Parks for regular park guests. They were also part of the Christmas Eve and New Year's Eve 2011/2012 celebrations at the Disneyland Hotel.




</doc>
<doc id="14358" url="https://en.wikipedia.org/wiki?curid=14358" title="Hammurabi">
Hammurabi

Hammurabi () was the sixth king of the First Babylonian Dynasty, reigning from 1792 BC to 1750 BC (according to the Middle Chronology). He was preceded by his father, Sin-Muballit, who abdicated due to failing health. During his reign, he conquered the city-states of Elam, Larsa, Eshnunna, and Mari. He ousted Ishme-Dagan I, the king of Assyria, and forced his son Mut-Ashkur to pay tribute, thereby bringing almost all of Mesopotamia under Babylonian rule.

Hammurabi is best known for having issued the Code of Hammurabi, which he claimed to have received from Shamash, the Babylonian god of justice. Unlike earlier Sumerian law codes, such as the Code of Ur-Nammu, which had focused on compensating the victim of the crime, the Law of Hammurabi was one of the first law codes to place greater emphasis on the physical punishment of the perpetrator. It prescribed specific penalties for each crime and is among the first codes to establish the presumption of innocence. Although its penalties are extremely harsh by modern standards, they were intended to limit what a wronged person was permitted to do in retribution. The Code of Hammurabi and the Law of Moses in the Torah contain numerous similarities, but these are probably due to shared background and oral tradition, and it is unlikely that Hammurabi's laws exerted any direct impact on the later Mosaic ones.

Hammurabi was seen by many as a god within his own lifetime. After his death, Hammurabi was revered as a great conqueror who spread civilization and forced all peoples to pay obeisance to Marduk, the national god of the Babylonians. Later, his military accomplishments became de-emphasized and his role as the ideal lawgiver became the primary aspect of his legacy. For later Mesopotamians, Hammurabi's reign became the frame of reference for all events occurring in the distant past. Even after the empire he built collapsed, he was still revered as a model ruler, and many kings across the Near East claimed him as an ancestor. Hammurabi was rediscovered by archaeologists in the late nineteenth century and has since become seen as an important figure in the history of law.

Hammurabi was an Amorite First Dynasty king of the city-state of Babylon, and inherited the power from his father, Sin-Muballit, in . Babylon was one of the many largely Amorite ruled city-states that dotted the central and southern Mesopotamian plains and waged war on each other for control of fertile agricultural land. Though many cultures co-existed in Mesopotamia, Babylonian culture gained a degree of prominence among the literate classes throughout the Middle East under Hammurabi. The kings who came before Hammurabi had founded a relatively minor City State in 1894 BC which controlled little territory outside of the city itself. Babylon was overshadowed by older, larger and more powerful kingdoms such as Elam, Assyria, Isin, Eshnunna and Larsa for a century or so after its founding. However his father Sin-Muballit had begun to consolidate rule of a small area of south central Mesopotamia under Babylonian hegemony and, by the time of his reign, had conquered the minor city-states of Borsippa, Kish, and Sippar.

Thus Hammurabi ascended to the throne as the king of a minor kingdom in the midst of a complex geopolitical situation. The powerful kingdom of Eshnunna controlled the upper Tigris River while Larsa controlled the river delta. To the east of Mesopotamia lay the powerful kingdom of Elam which regularly invaded and forced tribute upon the small states of southern Mesopotamia. In northern Mesopotamia, the Assyrian king Shamshi-Adad I, who had already inherited centuries old Assyrian colonies in Asia Minor, had expanded his territory into the Levant and central Mesopotamia, although his untimely death would somewhat fragment his empire.

The first few decades of Hammurabi's reign were quite peaceful. Hammurabi used his power to undertake a series of public works, including heightening the city walls for defensive purposes, and expanding the temples. In , the powerful kingdom of Elam, which straddled important trade routes across the Zagros Mountains, invaded the Mesopotamian plain. With allies among the plain states, Elam attacked and destroyed the kingdom of Eshnunna, destroying a number of cities and imposing its rule on portions of the plain for the first time.

In order to consolidate its position, Elam tried to start a war between Hammurabi's Babylonian kingdom and the kingdom of Larsa. Hammurabi and the king of Larsa made an alliance when they discovered this duplicity and were able to crush the Elamites, although Larsa did not contribute greatly to the military effort. Angered by Larsa's failure to come to his aid, Hammurabi turned on that southern power, thus gaining control of the entirety of the lower Mesopotamian plain by .

As Hammurabi was assisted during the war in the south by his allies from the north such as Yamhad and Mari, the absence of soldiers in the north led to unrest. Continuing his expansion, Hammurabi turned his attention northward, quelling the unrest and soon after crushing Eshnunna. Next the Babylonian armies conquered the remaining northern states, including Babylon's former ally Mari, although it is possible that the conquest of Mari was a surrender without any actual conflict.

Hammurabi entered into a protracted war with Ishme-Dagan I of Assyria for control of Mesopotamia, with both kings making alliances with minor states in order to gain the upper hand. Eventually Hammurabi prevailed, ousting Ishme-Dagan I just before his own death. Mut-Ashkur, the new king of Assyria, was forced to pay tribute to Hammurabi.

In just a few years, Hammurabi succeeded in uniting all of Mesopotamia under his rule. The Assyrian kingdom survived but was forced to pay tribute during his reign, and of the major city-states in the region, only Aleppo and Qatna to the west in the Levant maintained their independence. However, one stele of Hammurabi has been found as far north as Diyarbekir, where he claims the title "King of the Amorites".

Vast numbers of contract tablets, dated to the reigns of Hammurabi and his successors, have been discovered, as well as 55 of his own letters. These letters give a glimpse into the daily trials of ruling an empire, from dealing with floods and mandating changes to a flawed calendar, to taking care of Babylon's massive herds of livestock. Hammurabi died and passed the reins of the empire on to his son Samsu-iluna in , under whose rule the Babylonian empire began to quickly unravel.

The Code of Hammurabi is not the earliest surviving law code; it is predated by the Code of Ur-Nammu, the Laws of Eshnunna, and the Code of Lipit-Ishtar. Nonetheless, the Code of Hammurabi shows marked differences from these earlier law codes and ultimately proved more influential.

The Code of Hammurabi was inscribed on a stele and placed in a public place so that all could see it, although it is thought that few were literate. The stele was later plundered by the Elamites and removed to their capital, Susa; it was rediscovered there in 1901 in Iran and is now in the Louvre Museum in Paris. The code of Hammurabi contains 282 laws, written by scribes on 12 tablets. Unlike earlier laws, it was written in Akkadian, the daily language of Babylon, and could therefore be read by any literate person in the city. Earlier Sumerian law codes had focused on compensating the victim of the crime, but the Code of Hammurabi instead focused on physically punishing the perpetrator. The Code of Hammurabi was one of the first law code to place restrictions on what a wronged person was allowed to do in retribution.

The structure of the code is very specific, with each offense receiving a specified punishment. The punishments tended to be very harsh by modern standards, with many offenses resulting in death, disfigurement, or the use of the "Eye for eye, tooth for tooth" (Lex Talionis "Law of Retaliation") philosophy. The code is also one of the earliest examples of the idea of presumption of innocence, and it also suggests that the accused and accuser have the opportunity to provide evidence. However, there is no provision for extenuating circumstances to alter the prescribed punishment.

A carving at the top of the stele portrays Hammurabi receiving the laws from Shamash, the Babylonian god of justice, and the preface states that Hammurabi was chosen by Shamash to bring the laws to the people. Parallels between this narrative and the giving of the Covenant Code to Moses by Yahweh atop Mount Sinai in the Biblical Book of Exodus and similarities between the two legal codes suggest a common ancestor in the Semitic background of the two. Nonetheless, fragments of previous law codes have been found and it is unlikely that the Mosaic laws were directly inspired by the Code of Hammurabi. Some scholars have disputed this; David P. Wright argues that the Jewish Covenant Code is "directly, primarily, and throughout" based upon the Laws of Hammurabi. In 2010, a team of archaeologists from Hebrew University discovered a cuneiform tablet dating to the eighteenth or seventeenth century BC at Hazor in Israel containing laws clearly derived from the Code of Hammurabi.


Hammurabi was honored above all other kings of the second millennium BC and he received the unique honor of being declared to be a god within his own lifetime. The personal name "Hammurabi-ili" meaning "Hammurabi is my god" became common during and after his reign. In writings from shortly after his death, Hammurabi is commemorated mainly for three achievements: bringing victory in war, bringing peace, and bringing justice. Hammurabi's conquests came to be regarded as part of a sacred mission to spread civilization to all nations. A stele from Ur glorifies him in his own voice as a mighty ruler who forces evil into submission and compels all peoples to worship Marduk. The stele declares: "The people of Elam, Gutium, Subartu, and Tukrish, whose mountains are distant and whose languages are obscure, I placed into [Marduk's] hand. I myself continued to put straight their confused minds." A later hymn also written in Hammurabi's own voice extols him as a powerful, supernatural force for Marduk:

<poem>
I am the king, the brace that grasps wrongdoers, that makes people of one mind,
I am the great dragon among kings, who throws their counsel in disarray,
I am the net that is stretched over the enemy,
I am the fear-inspiring, who, when lifting his fierce eyes, gives the disobedient the death sentence,
I am the great net that covers evil intent,
I am the young lion, who breaks nets and scepters,
I am the battle net that catches him who offends me.
</poem>

After extolling Hammurabi's military accomplishments, the hymn finally declares: "I am Hammurabi, the king of justice." In later commemorations, Hammurabi's role as a great lawgiver came to be emphasized above all his other accomplishments and his military achievements became de-emphasized. Hammurabi's reign became the point of reference for all events in the distant past. A hymn to the goddess Ishtar, whose language suggests it was written during the reign of Ammisaduqa, Hammurabi's fourth successor, declares: "The king who first heard this song as a song of your heroism is Hammurabi. This song for you was composed in his reign. May he be given life forever!" For centuries after his death, Hammurabi's laws continued to be copied by scribes as part of their writing exercises and they were even partially translated into Sumerian.

During the reign of Hammurabi, Babylon usurped the position of "most holy city" in southern Mesopotamia from its predecessor, Nippur. Under the rule of Hammurabi's successor Samsu-iluna, the short-lived Babylonian Empire began to collapse. In northern Mesopotamia, both the Amorites and Babylonians were driven from Assyria by Puzur-Sin a native Akkadian-speaking ruler, . Around the same time, native Akkadian speakers threw off Amorite Babylonian rule in the far south of Mesopotamia, creating the Sealand Dynasty, in more or less the region of ancient Sumer. Hammurabi's ineffectual successors met with further defeats and loss of territory at the hands of Assyrian kings such as Adasi and Bel-ibni, as well as to the Sealand Dynasty to the south, Elam to the east, and to the Kassites from the northeast. Thus was Babylon quickly reduced to the small and minor state it had once been upon its founding.

The "coup de grace" for the Hammurabi's Amorite Dynasty occurred in 1595 BC, when Babylon was sacked and conquered by the powerful Hittite Empire, thereby ending all Amorite political presence in Mesopotamia. However, the Indo-European-speaking Hittites did not remain, turning over Babylon to their Kassite allies, a people speaking a language isolate, from the Zagros mountains region. This Kassite Dynasty ruled Babylon for over 400 years and adopted many aspects of the Babylonian culture, including Hammurabi's code of laws. Even after the fall of the Amorite Dynasty, however, Hammurabi was still remembered and revered. When the Elamite king Shutruk-Nahhunte I raided Babylon in 1158 BC and carried off many stone monuments, he had most of the inscriptions on these monuments erased and new inscriptions carved into them. On the stele containing Hammurabi's laws, however, only four or five columns were wiped out and no new inscription was ever added. Over a thousand years after Hammurabi's death, the kings of Suhu, a land along the Euphrates river, just northwest of Babylon, claimed him as their ancestor.

In the late nineteenth century, the Code of Hammurabi became a major center of debate in the heated "Babel und Bibel" ("Babylon and Bible") controversy in Germany over the relationship between the Bible and ancient Babylonian texts. In January 1902, the German Assyriologist Friedrich Delitzsch gave a lecture at the Sing-Akademie zu Berlin in front of the Kaiser and his wife, in which he argued that the Mosaic Laws of the Old Testament were directly copied off the Code of Hammurabi. Delitzsch's lecture was so controversial that, by September 1903, he had managed to collect 1,350 short articles from newspapers and journals, over 300 longer ones, and twenty-eight pamphlets, all written in response to this lecture, as well as the preceding one about the Flood story in the "Epic of Gilgamesh". These articles were overwhelmingly critical of Delitzsch, though a few were sympathetic. The Kaiser distanced himself from Delitzsch and his radical views and, in fall of 1904, Delitzsch was forced to give his third lecture in Cologne and Frankfurt am Main rather than in Berlin. The putative relationship between the Mosaic Law and the Code of Hammurabi later became a major part of Delitzsch's argument in his 1920-21 book "Die große Täuschung" ("The Great Deception") that the Hebrew Bible was irredeemably contaminated by Babylonian influence and that only by eliminating the human Old Testament entirely could Christians finally believe in the true, Aryan message of the New Testament. In the early twentieth century, many scholars believed that Hammurabi was Amraphel, the King of Shinar in the Book of Genesis 14:1. This view has now been largely rejected, and Amraphael's existence is not attested in any writings from outside the Bible.

Because of Hammurabi's reputation as a lawgiver, his depiction can be found in several U.S. government buildings. Hammurabi is one of the 23 lawgivers depicted in marble bas-reliefs in the chamber of the U.S. House of Representatives in the United States Capitol. A frieze by Adolph Weinman depicting the "great lawgivers of history", including Hammurabi, is on the south wall of the U.S. Supreme Court building. At the time of Saddam Hussein, the Iraqi Army's 1st Hammurabi Armoured Division was named after the ancient king as part of an effort to emphasize the connection between modern Iraq and the pre-Arab Mesopotamian cultures.






</doc>
<doc id="14359" url="https://en.wikipedia.org/wiki?curid=14359" title="Huygens–Fresnel principle">
Huygens–Fresnel principle

The Huygens–Fresnel principle (named after Dutch physicist Christiaan Huygens and French physicist Augustin-Jean Fresnel) is a method of analysis applied to problems of wave propagation both in the far-field limit and in near-field diffraction. It states that every point on a wavefront is itself the source of spherical wavelets.

In 1678, Huygens proposed that every point to which a luminous disturbance reaches becomes a source of a spherical wave; the sum of these secondary waves determines the form of the wave at any subsequent time. He assumed that the secondary waves travelled only in the "forward" direction and it is not explained in the theory why this is the case. He was able to provide a qualitative explanation of linear and spherical wave propagation, and to derive the laws of reflection and refraction using this principle, but could not explain the deviations from rectilinear propagation that occur when light encounters edges, apertures and screens, commonly known as diffraction effects. The resolution of this error was finally explained by David A.B. Miller in 1991. The resolution is that the source is a dipole (not the monopole assumed by Huygens), which cancels in the reflected direction.

In 1818, Fresnel showed that Huygens' principle, together with his own principle of interference could explain both the rectilinear propagation of light and also diffraction effects. To obtain agreement with experimental results, he had to include additional arbitrary assumptions about the phase and amplitude of the secondary waves, and also an obliquity factor. These assumptions have no obvious physical foundation but led to predictions that agreed with many experimental observations, including the Arago spot.

Poisson was a member of the French Academy, which reviewed Fresnel's work. He used Fresnel's theory to predict that a bright spot ought to appear in the center of the shadow of a small disc, and deduced from this that the theory was incorrect. However, Arago, another member of the committee, performed the experiment and showed that the prediction was correct. (Lisle had observed this fifty years earlier.) This was one of the investigations that led to the victory of the wave theory of light over the then predominant corpuscular theory.

The Huygens–Fresnel principle provides a reasonable basis for understanding and predicting the classical wave propagation of light. However, there are limitations to the principle, and not all experts agree that it is an accurate representation of reality—for instance, Melvin Schwartz argued that "Huygens' principle actually does give the right answer but for the wrong reasons". See Huygens' Theory and the Modern Photon Wavefunction below.

Kirchhoff's diffraction formula provides a rigorous mathematical foundation for diffraction, based on the wave equation. The arbitrary assumptions made by Fresnel to arrive at the Huygens–Fresnel equation emerge automatically from the mathematics in this derivation.

A simple example of the operation of the principle can be seen when an open doorway connects two rooms and a sound is produced in a remote corner of one of them. A person in the other room will hear the sound as if it originated at the doorway. As far as the second room is concerned, the vibrating air in the doorway is the source of the sound.

Consider the case of a point source located at a point P, vibrating at a frequency "f". The disturbance may be described by a complex variable "U" known as the complex amplitude. It produces a spherical wave with wavelength λ, wavenumber "k" = 2π/λ. The complex amplitude of the primary wave at the point Q located at a distance "r" from P is given by:

since the magnitude decreases in inverse proportion to the distance travelled, and the phase changes as "k" times the distance travelled.

Using Huygens' theory and the principle of superposition of waves, the complex amplitude at a further point P is found by summing the contributions from each point on the sphere of radius "r". In order to get agreement with experimental results, Fresnel found that the individual contributions from the secondary waves on the sphere had to be multiplied by a constant, −"i"/λ, and by an additional inclination factor, "K"(χ). The first assumption means that the secondary waves oscillate at a quarter of a cycle out of phase with respect to the primary wave, and that the magnitude of the secondary waves are in a ratio of 1:λ to the primary wave. He also assumed that "K"(χ) had a maximum value when χ = 0, and was equal to zero when χ = π/2. The complex amplitude at P is then given by:

where "S" describes the surface of the sphere, and "s" is the distance between Q and P. 
Fresnel used a zone construction method to find approximate values of "K" for the different zones, which enabled him to make predictions that were in agreement with experimental results.

The various assumptions made by Fresnel emerge automatically in Kirchhoff's diffraction formula, to which the Huygens–Fresnel principle can be considered to be an approximation. Kirchhoff gave the following expression for "K"(χ):

"K" has a maximum value at χ = 0 as in the Huygens–Fresnel principle; however, "K" is not equal to zero at χ = π/2.

Huygens' theory served as a fundamental explanation of the wave nature of light interference and was further developed by Fresnel and Young but did not fully resolve all observations such as the low-intensity double-slit experiment that was first performed by G. I. Taylor in 1909, see double-slit experiment. It was not until the early, and mid-1900s that quantum theory discussions, particularly the early discussions at the 1927 Brussels Solvay Conference, where Louis de Broglie proposed his de Broglie hypothesis that the photon is guided by a wavefunction. The wavefunction presents a much different explanation of the observed light and dark bands in a double slit experiment. Feynman partially explains that a photon will follow a predetermined path which is a choice of one of many possible paths. These chosen paths form the pattern; in dark areas, no photons are landing, and in bright areas, many photons are landing. The path of the photon or its chosen wavefunction is determined by the surroundings: the photon's originating point (atom), the slit, and the screen. The wavefunction is a solution to this geometry. The wavefunction approach was further proven by additional double-slit experiments in Italy and Japan in the 1970s and 1980s with electrons.

Huygens' principle can be seen as a consequence of the homogeneity of space—the space is uniform in all locations. Any disturbance created in a sufficiently small region of homogenous space (or in a homogenous medium) propagates from that region in all geodesic directions. The waves produced by this disturbance, in turn, create disturbances in other regions, and so on. The superposition of all the waves results in the observed pattern of wave propagation.

Homogeneity of space is fundamental to quantum field theory (QFT) where the wave function of any object propagates along all available unobstructed paths. When integrated along all possible paths, with a phase factor proportional to the action, the interference of the wave-functions correctly predicts observable phenomena. Every point on the wavefront acts as the source of secondary wavelets that spread out in the light cone with the same speed as the wave. The new wavefront is found by constructing the surface tangent to the secondary wavelets.

In 1900, Jacques Hadamard observed that Huygens' principle was broken when the number of spatial dimensions is even. From this, he developed a set of conjectures that remain an active topic of research. In particular, it has been discovered that Huygens' principle holds on a large class of homogenous spaces derived from the Coxeter group (so, for example, the Weyl groups of simple Lie algebras).

The traditional statement of Huygens' principle for the D'Alembertian gives rise to the KdV hierarchy; analogously, the Dirac operator gives rise to the AKNS hierarchy.



</doc>
<doc id="14361" url="https://en.wikipedia.org/wiki?curid=14361" title="Honey">
Honey

Honey is a sweet, viscous food substance produced by bees and some related insects. Bees produce honey from the sugary secretions of plants (floral nectar) or other insects (aphid honeydew) through regurgitation, enzymatic activity, and water evaporation. Honey is stored in wax structures called honeycombs. The variety of honey produced by honey bees (the genus "Apis") is the best-known, due to its worldwide commercial production and human consumption. Honey is collected from wild bee colonies, or from hives of domesticated bees, a practice known as beekeeping.
Honey gets its sweetness from the monosaccharides fructose and glucose, and has about the same relative sweetness as sucrose (granulated sugar). It has attractive chemical properties for baking and a distinctive flavor when used as a sweetener. Most microorganisms do not grow in honey, so sealed honey does not spoil, even after thousands of years.
Honey provides 46 calories in a serving of one tablespoon (15 ml) equivalent to 1272 kJ per 100 g. Honey is generally safe, but may have various, potentially adverse effects or interactions upon excessive consumption, existing disease conditions, or use of prescription drugs.
Honey use and production have a long and varied history as an ancient activity, depicted in Valencia, Spain, by a cave painting of humans foraging for honey at least 8,000 years ago.

Honey is produced by bees collecting nectar for use as sugars consumed to support metabolism of muscle activity during foraging or to be stored as a long-term food supply. During foraging, bees access part of the nectar collected to support metabolic activity of flight muscles, with the majority of collected nectar destined for regurgitation, digestion, and storage as honey. In cold weather or when other food sources are scarce, adult and larval bees use stored honey as food.

By contriving for bee swarms to nest in human-made hives, people have been able to semidomesticate the insects and harvest excess honey. In the hive or in a wild nest, the three types of bees are:

Leaving the hive, a foraging bee collects sugar-rich flower nectar, sucking it through its proboscis and placing it in its proventriculus (honey stomach or crop), which lies just fore of its food stomach. The honey stomach holds ~ 40 mg of nectar, or approximately 50% of the bee's unloaded weight, which can require over a thousand flowers and more than an hour to fill. The nectar generally begins with a water content of 70--80%. Salivary enzymes and proteins from the bee's hypopharyngeal gland is added to the nectar to begin breaking down the sugars, raising the water content slightly. The forager bees then return to the hive where they regurgitate and transfer nectar to the hive bees. The hive bees then use their honey stomachs to ingest and regurgitate the nectar, forming bubbles between their mandibles, repeatedly until it is partially digested. The bubbles create a large surface area per volume and a portion of the water is removed through evaporation. Bee digestive enzymes – invertase, amylase, and diastase – hydrolyze sucrose to a mixture of glucose and fructose. The bees work together as a group with the regurgitation and digestion for as long as 20 minutes, passing the nectar from one bee to the next, until the product reaches the honeycombs in storage quality. It is then placed in honeycomb cells and left unsealed while still high in water content (about 50--70%) and natural yeasts which, unchecked, would cause the sugars in the newly formed honey to ferment. Bees are one of the few insects that can generate large amounts of body heat, thus the hive bees constantly regulate the hive temperature, either heating with their bodies or cooling with water evaporation, to maintain a fairly constant temperature in the honey-storage areas of around . The process continues as hive bees flutter their wings constantly to circulate air and evaporate water from the honey to a content around 18%, raising the sugar concentration beyond the saturation point and preventing fermentation. The bees then cap the cells with wax to seal them. As removed from the hive by a beekeeper, honey has a long shelf life and will not ferment if properly sealed.

Another source of honey is from a number of wasp species, such as the wasps "Brachygastra lecheguana" and "Brachygastra mellifica", which are found in South and Central America. These species are known to feed on nectar and produce honey.

Some wasps, such as the "Polistes versicolor", even consume honey themselves, alternating between feeding on pollen in the middle of their lifecycles and feeding on honey, which can better provide for their energy needs.

Honey is collected from wild bee colonies or from domesticated beehives. On average, a hive will produce about of honey per year. The honey is stored in honeycombs. Wild bee nests are sometimes located by following a honeyguide bird. The bees may first be pacified by using smoke from a bee smoker. The smoke triggers a feeding instinct (an attempt to save the resources of the hive from a possible fire), making them less aggressive and the smoke obscures the pheromones the bees use to communicate.

The honeycomb is removed from the hive and the honey may be extracted from that, either by crushing or by using a honey extractor. The honey is then usually filtered to remove beeswax and other debris.

Before the invention of removable frames, bee colonies were often sacrificed to conduct the harvest. The harvester would take all the available honey and replace the entire colony the next spring. Since the invention of removable frames, the principles of husbandry lead most beekeepers to ensure that their bees have enough stores to survive the winter, either by leaving some honey in the beehive or by providing the colony with a honey substitute such as sugar water or crystalline sugar (often in the form of a "candyboard"). The amount of food necessary to survive the winter depends on the variety of bees and on the length and severity of local winters.

A wide range of species other than humans are attracted to wild or domestic sources of honey.

Because of its unique composition and chemical properties, honey is suitable for long-term storage, and is easily assimilated even after long preservation. Honey, and objects immersed in honey, have been preserved for centuries. The key to preservation is limiting access to humidity. In its cured state, honey has a sufficiently high sugar content to inhibit fermentation. If exposed to moist air, its hydrophilic properties pull moisture into the honey, eventually diluting it to the point that fermentation can begin.

Long shelf life of honey is attributed to an enzyme found in the stomach of bees. The bees mix Glucose oxidase with expelled nectar they previously consumed, which then creates two by-products: gluconic acid and hydrogen peroxide, responsible for honey's acidity and ability to suppress bacterial growth.

Adulteration of honey is the addition of other sugars, syrups, or compounds into honey to change its flavor or viscosity, make it cheaper to produce, or increase the fructose content to stave off crystallization. According to the Codex Alimentarius of the United Nations, any product labeled as honey or pure honey must be a wholly natural product, although different nations have their own laws concerning labeling. Adulteration of honey is sometimes used as a method of deception when buyers are led to believe that the honey is pure. The practice was common dating back to ancient times, when honey was sometimes blended with plant syrups like maple, birch, or sorghum and sold to unsuspecting customers. Sometimes crystallized honey was mixed with flour or other fillers, hiding the adulteration from buyers until the honey was liquefied. In modern times, the most common adulteration-ingredient became clear, almost-flavorless corn syrup, which, when mixed with honey, is often very difficult to distinguish from unadulterated honey.

Isotope ratio mass spectrometry can be used to detect addition of corn syrup and cane sugar by the carbon isotopic signature. Addition of sugars originating from corn or sugar cane (C4 plants, unlike the plants used by bees, and also sugar beet, which are predominantly C3 plants) skews the isotopic ratio of sugars present in honey, but does not influence the isotopic ratio of proteins. In an unadulterated honey, the carbon isotopic ratios of sugars and proteins should match. Levels as low as 7% of addition can be detected.

In the United States, according to the National Honey Board (an organization supervised by the United States Department of Agriculture), "honey stipulates a pure product that does not allow for the addition of any other substance... this includes, but is not limited to, water or other sweeteners".

In 2016, global production of honey was 1.8 million tonnes, led by China with 27% of the world total (table). Other major producers were Turkey, United States, Russia and India .

Over its history as a food, the main uses of honey are in cooking, baking, desserts, such as "mel i mató", as a spread on bread, as an addition to various beverages, such as tea, and as a sweetener in some commercial beverages. Honey barbecue and honey mustard are other common flavors used in sauces.

Possibly the world's oldest fermented beverage dating to 9,000 years ago, mead ("honey wine") is the alcoholic product made by adding yeast to the honey–water must, followed by weeks or months of fermentation. In modern mead production, the yeast "Saccharomyces cerevisiae" is commonly used.

Primary fermentation usually takes 2856 days, after which the must is placed in a secondary fermentation vessel for 6–9 months of aging. Durations of primary and secondary fermentation producing satisfactory mead may vary considerably according to numerous factors, such as floral origin of the honey and its natural sugar and microorganism contents, must water percentage, pH, additives used, and strain of yeast, among others. Although supplementation of the must with nitrogen, salt or vitamins has been tested to improve mead qualities, there is no evidence that adding nutrients reduced fermentation time or improved quality. Cell immobilization methods, however, proved effective for enhancing mead quality.

Mead varieties include drinks called metheglin (with spices or herbs), melomel (with fruit juices, such as grape, specifically called pyment), hippocras (with cinnamon), and sack mead (high concentration of honey), many of which have been developed as commercial products numbering in the hundreds in the United States as of 2014. Honey is also used to make mead beer, called "braggot".

The physical properties of honey vary, depending on water content, the type of flora used to produce it (pasturage), temperature, and the proportion of the specific sugars it contains. Fresh honey is a supersaturated liquid, containing more sugar than the water can typically dissolve at ambient temperatures. At room temperature, honey is a supercooled liquid, in which the glucose will precipitate into solid granules. This forms a semisolid solution of precipitated glucose crystals in a solution of fructose and other ingredients.

At the temperature of 20 °C, density of honey typically ranges between 1.38 and 1.45 kg/l.

The melting point of crystallized honey is between , depending on its composition. Below this temperature, honey can be either in a metastable state, meaning that it will not crystallize until a seed crystal is added, or, more often, it is in a "labile" state, being saturated with enough sugars to crystallize spontaneously. The rate of crystallization is affected by many factors, but the primary factor is the ratio of the main sugars: fructose to glucose. Honeys that are supersaturated with a very high percentage of glucose, such as brassica honey, crystallize almost immediately after harvesting, while honeys with a low percentage of glucose, such as chestnut or tupelo honey, do not crystallize. Some types of honey may produce very large but few crystals, while others produce many small crystals.

Crystallization is also affected by water content, because a high percentage of water inhibits crystallization, as does a high dextrin content. Temperature also affects the rate of crystallization, with the fastest growth occurring between . Crystal nuclei (seeds) tend to form more readily if the honey is disturbed, by stirring, shaking, or agitating, rather than if left at rest. However, the nucleation of microscopic seed-crystals is greatest between . Therefore, larger but fewer crystals tend to form at higher temperatures, while smaller but more-numerous crystals usually form at lower temperatures. Below 5 °C, the honey will not crystallize, thus the original texture and flavor can be preserved indefinitely.

Since honey normally exists below its melting point, it is a supercooled liquid. At very low temperatures, honey does not freeze solid. Instead, as the temperatures become lower, the viscosity of honey increases. Like most viscous liquids, the honey becomes thick and sluggish with decreasing temperature. At , honey may appear or even feel solid, but it continues to flow at very low rates. Honey has a glass transition between . Below this temperature, honey enters a glassy state and becomes an amorphous solid (noncrystalline).

The viscosity of honey is affected greatly by both temperature and water content. The higher the water percentage, the more easily honey flows. Above its melting point, however, water has little effect on viscosity. Aside from water content, the composition of honey also has little effect on viscosity, with the exception of a few types. At , honey with 14% water content generally has a viscosity around 400 poise, while a honey containing 20% water has a viscosity around 20 poise. Viscosity increase due to temperature occurs very slowly at first. A honey containing 16% water, at , has a viscosity around 2 poise, while at , the viscosity is around 70 poise. As cooling progresses, honey becomes more viscous at an increasingly rapid rate, reaching 600 poise around . However, while honey is very viscous, it has rather low surface tension of 50--60 mJ/m, thus the wettability of honey is on the same order as water, glycerin, or most other liquids. The high viscosity and wettability of honey lead to the phenomenon of stickiness, which is a time-dependent process in supercooled liquids between the glass-transition temperature (T) and the crystalline-melting temperature. 

A few types of honey have unusual viscous properties. Honeys from heather or manuka display thixotropic properties. These types of honey enter a gel-like state when motionless, but then liquify when stirred.

Because honey contains electrolytes, in the form of acids and minerals, it exhibits varying degrees of electrical conductivity. Measurements of the electrical conductivity are used to determine the quality of honey in terms of ash content.

The effect honey has on light is useful for determining the type and quality. Variations in the water content alter the refractive index of honey. Water content can easily be measured with a refractometer. Typically, the refractive index for honey ranges from 1.504 at 13% water content to 1.474 at 25%. Honey also has an effect on polarized light, in that it rotates the polarization plane. The fructose gives a negative rotation, while the glucose gives a positive one. The overall rotation can be used to measure the ratio of the mixture. Honey may vary in color between pale yellow and dark brown, but other bright colors may occasionally be found, depending on the source of the sugar harvested by the bees.

Honey has the ability to absorb moisture directly from the air, a phenomenon called hygroscopy. The amount of water the honey absorbs is dependent on the relative humidity of the air. Because honey contains yeast, this hygroscopic nature requires that honey be stored in sealed containers to prevent fermentation, which usually begins if the honey's water content rises much above 25%. Honey tends to absorb more water in this manner than the individual sugars allow on their own, which may be due to other ingredients it contains.

Fermentation of honey usually occurs after crystallization, because without the glucose, the liquid portion of the honey primarily consists of a concentrated mixture of fructose, acids, and water, providing the yeast with enough of an increase in the water percentage for growth. Honey that is to be stored at room temperature for long periods of time is often pasteurized, to kill any yeast, by heating it above .

Like all sugar compounds, honey caramelizes if heated sufficiently, becoming darker in color, and eventually burns. However, honey contains fructose, which caramelizes at lower temperatures than glucose. The temperature at which caramelization begins varies, depending on the composition, but is typically between . Honey also contains acids, which act as catalysts for caramelization. The specific types of acids and their amounts play a primary role in determining the exact temperature. Of these acids, the amino acids, which occur in very small amounts, play an important role in the darkening of honey. The amino acids form darkened compounds called melanoidins, during a Maillard reaction. The Maillard reaction occurs slowly at room temperature, taking from a few to several months to show visible darkening, but speeds up dramatically with increasing temperatures. However, the reaction can also be slowed by storing the honey at colder temperatures.

Unlike many other liquids, honey has very poor thermal conductivity of 0.5 W/(m⋅K) at 13% water content (compared to 401 W/(m⋅K) of copper), taking a long time to reach thermal equilibrium. Melting crystallized honey can easily result in localized caramelization if the heat source is too hot, or if it is not evenly distributed. However, honey takes substantially longer to liquify when just above the melting point than at elevated temperatures. Melting 20 kg of crystallized honey, at , can take up to 24 hours, while 50 kg may take twice as long. These times can be cut nearly in half by heating at . However, many of the minor substances in honey can be affected greatly by heating, changing the flavor, aroma, or other properties, so heating is usually done at the lowest temperature possible for the shortest amount of time.

The average pH of honey is 3.9, but can range from 3.4 to 6.1. Honey contains many kinds of acids, both organic and amino. However, the different types and their amounts vary considerably, depending on the type of honey. These acids may be aromatic or aliphatic (nonaromatic). The aliphatic acids contribute greatly to the flavor of honey by interacting with the flavors of other ingredients.

Organic acids comprise most of the acids in honey, accounting for 0.17–1.17% of the mixture, with gluconic acid formed by the actions of an enzyme called glucose oxidase as the most prevalent. Other organic acids are minor, consisting of formic, acetic, butyric, citric, lactic, malic, pyroglutamic, propionic, valeric, capronic, palmitic, and succinic, among many others.

Honey is classified by its floral source, and divisions are made according to the packaging and processing used. Also, regional honeys are identified. In the USA, honey is also graded on its color and optical density by USDA standards, graded on the Pfund scale, which ranges from 0 for "water white" honey to more than 114 for "dark amber" honey.

Generally, honey is classified by the floral source of the nectar from which it was made. Honeys can be from specific types of flower nectars or can be blended after collection. The pollen in honey is traceable to floral source and therefore region of origin. The rheological and melissopalynological properties of honey can be used to identify the major plant nectar source used in its production.

Most commercially available honey is blended, meaning it is a mixture of two or more honeys differing in floral source, color, flavor, density, or geographic origin.

Polyfloral honey, also known as wildflower honey, is derived from the nectar of many types of flowers.

The taste may vary from year to year, and the aroma and the flavor can be more or less intense, depending on which bloomings are prevalent.

Monofloral honey is made primarily from the nectar of one type of flower. Different monofloral honeys have a distinctive flavor and color because of differences between their principal nectar sources. To produce monofloral honey, beekeepers keep beehives in an area where the bees have access to only one type of flower. In practice, because of the difficulties in containing bees, a small proportion of any honey will be from additional nectar from other flower types. Typical examples of North American monofloral honeys are clover, orange blossom, blueberry, sage, tupelo, buckwheat, fireweed, mesquite, and sourwood. Some typical European examples include thyme, thistle, heather, acacia, dandelion, sunflower, lavender, honeysuckle, and varieties from lime and chestnut trees. In North Africa (e.g. Egypt), examples include clover, cotton, and citrus (mainly orange blossoms). The unique flora of Australia yields a number of distinctive honeys, with some of the most popular being yellow box, blue gum, ironbark, bush mallee, Tasmanian leatherwood, and macadamia.

Instead of taking nectar, bees can take honeydew, the sweet secretions of aphids or other plant sap-sucking insects. Honeydew honey is very dark brown in color, with a rich fragrance of stewed fruit or fig jam, and is not as sweet as nectar honeys. Germany's Black Forest is a well known source of honeydew-based honeys, as well as some regions in Bulgaria, Tara (mountain) in Serbia, and Northern California in the United States. In Greece, pine honey (a type of honeydew honey) constitutes 60–65% of the annual honey production. Honeydew honey is popular in some areas, but in other areas, beekeepers have difficulty selling the stronger-flavored product.

The production of honeydew honey has some complications and dangers. This honey has a much larger proportion of indigestibles than light floral honeys, thus causing dysentery to the bees, resulting in the death of colonies in areas with cold winters. Good beekeeping management requires the removal of honeydew prior to winter in colder areas. Bees collecting this resource also have to be fed protein supplements, as honeydew lacks the protein-rich pollen accompaniment gathered from flowers.

Generally, honey is bottled in its familiar liquid form. However, honey is sold in other forms, and can be subjected to a variety of processing methods.

In the US, honey grading is performed voluntarily (USDA does offer inspection and grading "as on-line (in-plant) or lot inspection...upon application, on a fee-for-service basis.") based upon USDA standards. Honey is graded based upon a number of factors, including water content, flavor and aroma, absence of defects, and clarity. Honey is also classified by color, though it is not a factor in the grading scale.
The honey grade scale is:
Other countries may have differing standards on the grading of honey. India, for example, certifies honey grades based on additional factors, such as the Fiehe's test, and other empirical measurements.

High-quality honey can be distinguished by fragrance, taste, and consistency. Ripe, freshly collected, high-quality honey at should flow from a knife in a straight stream, without breaking into separate drops. After falling down, the honey should form a bead. The honey, when poured, should form small, temporary layers that disappear fairly quickly, indicating high viscosity. If not, it indicates excessive water content (over 20%)
of the product. Honey with excessive water content is not suitable for long-term preservation.

In jars, fresh honey should appear as a pure, consistent fluid, and should not set in layers. Within a few weeks to a few months of extraction, many varieties of honey crystallize into a cream-colored solid. Some varieties of honey, including tupelo, acacia, and sage, crystallize less regularly. Honey may be heated during bottling at temperatures of to delay or inhibit crystallization. Overheating is indicated by change in enzyme levels, for instance, diastase activity, which can be determined with the Schade or the Phadebas methods. A fluffy film on the surface of the honey (like a white foam), or marble-colored or white-spotted crystallization on a container's sides, is formed by air bubbles trapped during the bottling process.

A 2008 Italian study determined nuclear magnetic resonance spectroscopy can be used to distinguish between different honey types, and can be used to pinpoint the area where it was produced. Researchers were able to identify differences in acacia and polyfloral honeys by the differing proportions of fructose and sucrose, as well as differing levels of aromatic amino acids phenylalanine and tyrosine. This ability allows greater ease of selecting compatible stocks.

In a 100-gram serving, honey provides 304 kilocalories with no essential nutrients in significant content. Composed of 17% water and 82% carbohydrates, honey has low content of fat, dietary fiber, and protein.

A mixture of sugars and other carbohydrates, honey is mainly fructose (about 38%) and glucose (about 32%), with remaining sugars including maltose, sucrose, and other complex carbohydrates. Its glycemic index ranges from 31 to 78, depending on the variety. The specific composition, color, aroma, and flavor of any batch of honey depend on the flowers foraged by bees that produced the honey.

One 1980 study found that mixed floral honey from several United States regions typically contains:

A 2013 NMR spectroscopy study of 20 different honeys from Germany found that their sugar contents comprised:
The average ratio was 56% fructose to 44% glucose, but the ratios in the individual honeys ranged from a high of 64% fructose and 36% glucose (one type of flower honey; table 3 in reference) to a low of 50% fructose and 50% glucose (a different floral source). This NMR method was not able to quantify maltose, galactose, and the other minor sugars as compared to fructose and glucose.

Some evidence shows that sterilized honey may help healing in skin wounds after surgery and mild (partial thickness) burns when used in a dressing, but in general, the evidence for the use of honey in wound treatment is of such low quality that firm conclusions cannot be drawn. Evidence does not support the use of honey-based products in the treatment of venous stasis ulcers or ingrown toenail.

Components of honey under preliminary research for their potential antibacterial properties include methylglyoxal, hydrogen peroxide, and royalisin (also called defensin-1).

For chronic and acute coughs, a Cochrane review found no strong evidence for or against the use of honey. For treating children, the systematic review concluded with moderate to low evidence that honey probably helps more than no treatment, diphenhydramine, and placebo at giving relief from coughing. Honey does not appear to work better than dextromethorphan at relieving coughing in children.

The UK Medicines and Healthcare Products Regulatory Agency recommends avoiding giving over the counter cough and common cold medication to children under six, and suggests "a homemade remedy containing honey and lemon is likely to be just as useful and safer to take", but warns that honey should not be given to babies because of the risk of infant botulism. The World Health Organization recommends honey as a treatment for coughs and sore throats, including for children, stating that no reason exists to believe it is less effective than a commercial remedy. Honey is recommended by one Canadian physician for children over the age of one for the treatment of coughs, as it is deemed as effective as dextromethorphan and more effective than diphenhydramine.

The use of honey has been recommended as a temporary intervention for known or suspected button cell ingestions to reduce the risk and severity of injury to the esophagus caused by the battery prior to its removal.

No evidence shows the benefit of using honey to treat cancer, although honey may be useful for controlling side effects of radiation therapy or chemotherapy applied in cancer treatment.

Consumption is sometimes advocated as a treatment for seasonal allergies due to pollen, but scientific evidence to support the claim is inconclusive. Honey is generally considered ineffective for the treatment of allergic conjunctivitis.

Although the majority of calories in honey is from fructose, honey does not cause increased weight gain and fructose by itself is not an independent factor for weight gain.

Although honey is generally safe when taken in typical food amounts, there are various, potential adverse effects or interactions it may have in combination with excessive consumption, existing disease conditions or drugs. Included among these are mild reactions to high intake, such as anxiety, insomnia, or hyperactivity in about 10% of children, according to one study. No symptoms of anxiety, insomnia, or hyperactivity were detected with honey consumption compared to placebo, according to another study. Honey consumption may interact adversely with existing allergies, high blood sugar levels (as in diabetes), or anticoagulants used to control bleeding, among other clinical conditions.

People who have a weakened immune system may be at risk of bacterial or fungal infection from eating honey, although there is no high-quality clinical evidence that this occurs commonly.

Infants can develop botulism after consuming honey contaminated with "Clostridium botulinum" endospores.

Infantile botulism shows geographical variation. In the UK, only six cases have been reported between 1976 and 2006, yet the U.S. has much higher rates: 1.9 per 100,000 live births, 47.2% of which are in California. While the risk honey poses to infant health is small, taking the risk is not recommended until after one year of age, and then giving honey is considered safe.

Mad honey intoxication is a result of eating honey containing grayanotoxins. Honey produced from flowers of rhododendrons, mountain laurels, sheep laurel, and azaleas may cause honey intoxication. Symptoms include dizziness, weakness, excessive perspiration, nausea, and vomiting. Less commonly, low blood pressure, shock, heart rhythm irregularities, and convulsions may occur, with rare cases resulting in death. Honey intoxication is more likely when using "natural" unprocessed honey and honey from farmers who may have a small number of hives. Commercial processing, with pooling of honey from numerous sources, is thought to dilute any toxins.

Toxic honey may also result when bees are proximate to tutu bushes ("Coriaria arborea") and the vine hopper insect ("Scolypopa australis"). Both are found throughout New Zealand. Bees gather honeydew produced by the vine hopper insects feeding on the tutu plant. This introduces the poison tutin into honey. Only a few areas in New Zealand (the Coromandel Peninsula, Eastern Bay of Plenty and the Marlborough Sounds) frequently produce toxic honey. Symptoms of tutin poisoning include vomiting, delirium, giddiness, increased excitability, stupor, coma, and violent convulsions. To reduce the risk of tutin poisoning, humans should not eat honey taken from feral hives in the risk areas of New Zealand. Since December 2001, New Zealand beekeepers have been required to reduce the risk of producing toxic honey by closely monitoring tutu, vine hopper, and foraging conditions within of their apiary. Intoxication is rarely dangerous.

Honey use and production has a long and varied history. In many cultures, honey has associations that go beyond its use as a food. It is frequently used as a talisman and symbol of sweetness.

Honey collection is an ancient activity. Humans apparently began hunting for honey at least 8,000 years ago, as evidenced by a cave painting in Valencia, Spain. The painting is a Mesolithic rock painting, showing two honey hunters collecting honey and honeycomb from a wild bee nest. The figures are depicted carrying baskets or gourds, and using a ladder or series of ropes to reach the wild nest.

The greater honeyguide bird guides humans to wild bee hives and this behavior may have evolved with early hominids.

The oldest known honey remains were found in the country of Georgia. Archaeologists found honey remains on the inner surface of clay vessels unearthed in an ancient tomb, dating back some 4,700–5,500 years. In ancient Georgia, several types of honey were buried with a person for their journey into the afterlife, including linden, berry, and meadow-flower varieties.

In ancient Egypt, honey was used to sweeten cakes and biscuits, and was used in many other dishes. Ancient Egyptian and Middle Eastern peoples also used honey for embalming the dead. The fertility god of Egypt, Min, was offered honey.

In ancient Greece, honey was produced from the Archaic to the Hellenistic periods. In 594 BC, beekeeping around Athens was so widespread that Solon passed a law about it: "He who sets up hives of bees must put them away from those already installed by another". Greek archaeological excavations of pottery located ancient hives. According to Columella, Greek beekeepers of the Hellenistic period did not hesitate to move their hives over rather long distances to maximise production, taking advantage of the different vegetative cycles in different regions.

In the absence of sugar, honey was an integral sweetening ingredient in Greek and Roman cuisine. During Roman times, honey was part of many recipes and it is mentioned in the work of many authors, such as Virgil, Pliny, Cicero, and others.

The spiritual and therapeutic use of honey in ancient India is documented in both the Vedas and the Ayurveda texts, which were both composed at least 4,000 years ago.

Beekeeping in ancient China has existed since ancient times and appears to be untraceable to its origin. In the book "Golden Rules of Business Success" written by Fan Li (or Tao Zhu Gong) during the Spring and Autumn period, some parts mention the art of beekeeping and the importance of the quality of the wooden box for beekeeping that can affect the quality of its honey.

Honey was also cultivated in ancient Mesoamerica. The Maya used honey from the stingless bee for culinary purposes, and continue to do so today. The Maya also regard the bee as sacred (see Mayan stingless bees of Central America).

Some cultures believed honey had many practical health uses. It was used as an ointment for rashes and burns, and to help soothe sore throats when no other practices were available.

In myths and folk medicine, honey has been used both orally and topically to treat various ailments including gastric disturbances, ulcers, skin wounds, and skin burns by ancient Greeks and Egyptians, and in Ayurveda and traditional Chinese medicine.

Proposed for treating wounds and burns, honey may have antimicrobial properties as first reported in 1892 and be useful as a safe, improvisational wound treatment. Though its supposed antimicrobial properties may be due to high osmolarity even when diluted with water, it is more effective than plain sugar water of a similar viscosity. Definitive clinical conclusions about the efficacy and safety of treating wounds, however, are not possible from this limited research.

The flora that bees use to make the honey may have a role in its properties, particularly by bees foraging from the manuka myrtle, "Leptospermum scoparium", as proposed in one study.

Ancient Greek Religion
In ancient Greek religion, the food of Zeus and the 12 Gods of Olympus was honey in the form of nectar and ambrosia.

Hinduism
In Hinduism, honey ("Madhu") is one of the five elixirs of immortality ("Panchamrita"). In temples, honey is poured over the deities in a ritual called "Madhu abhisheka". The "Vedas" and other ancient literature mention the use of honey as a great medicinal and health food.

Judaism
In Jewish tradition, honey is a symbol for the new year, "Rosh Hashanah". At the traditional meal for that holiday, apple slices are dipped in honey and eaten to bring a sweet new year. Some "Rosh Hashanah" greetings show honey and an apple, symbolizing the feast. In some congregations, small straws of honey are given out to usher in the new year.

The Hebrew Bible contains many references to honey. In the Book of Judges, Samson found a swarm of bees and honey in the carcass of a lion (14:8). In Old Testament law, offerings were made in the temple to God. The Book of Leviticus says that "Every grain offering you bring to the Lord must be made without yeast, for you are not to burn any yeast or honey in a food offering presented to the Lord" (2:11). In the Books of Samuel, Jonathan is forced into a confrontation with his father King Saul after eating honey in violation of a rash oath Saul has made. Proverbs 16:24 in the JPS Tanakh 1917 version says "Pleasant words are as a honeycomb, Sweet to the soul, and health to the bones." Book of Exodus famously describes the Promised Land as a "land flowing with milk and honey" (33:3). However, most Biblical commentators write that the original Hebrew in the Bible (דבש "devash") refers to the sweet syrup produced from the juice of dates ("silan"). In 2005 an apiary dating from the 10th century B.C. was found in Tel Rehov, Israel that contained 100 hives and is estimated to produce half a ton of honey annually. Pure honey is considered kosher, though it is produced by a flying insect, a non-kosher creature; other products of non-kosher animals are not kosher.

Buddhism
In Buddhism, honey plays an important role in the festival of "Madhu Purnima", celebrated in India and Bangladesh. The day commemorates Buddha's making peace among his disciples by retreating into the wilderness. The legend has it that while he was there, a monkey brought him honey to eat. On "Madhu Purnima", Buddhists remember this act by giving honey to monks. The monkey's gift is frequently depicted in Buddhist art.

Christianity
In the Christian New Testament, , John the Baptist is said to have lived for a long period of time in the wilderness on a diet consisting of locusts and wild honey.

Islam
In Islam, an entire chapter (Surah) in the Qur'an is called "an-Nahl" (the Bees). According to his teachings ("hadith"), Muhammad strongly recommended honey for healing purposes. The Qur'an promotes honey as a nutritious and healthy food. Below is the English translation of those specific verses:




</doc>
<doc id="14365" url="https://en.wikipedia.org/wiki?curid=14365" title="Hengist and Horsa">
Hengist and Horsa

Hengist and Horsa are legendary brothers said to have led the Angles, Saxons and Jutes in their invasion of Britain in the 5th century. Tradition lists Hengist as the first of the Jutish kings of Kent.

According to early sources, Hengist and Horsa arrived in Britain at Ebbsfleet on the Isle of Thanet. For a time, they served as mercenaries for Vortigern, King of the Britons, but later they turned against him (British accounts have them betraying him in the Treachery
of the Long Knives). Horsa was killed fighting the Britons, but Hengist successfully conquered Kent, becoming the forefather of its kings.

A figure named Hengest, who may be identifiable with the leader of British legend, appears in the "Finnsburg Fragment" and in "Beowulf". 

Legends of horse-associated founding brothers are attested among other Germanic peoples and appear in other Indo-European cultures. As a result, scholars have theorized a pan-Germanic mythological origin for Hengist and Horsa, stemming originally from divine twins found in Proto-Indo-European religion. Other scholars, including J. R. R. Tolkien, have argued for a historical basis for Hengist and Horsa.

The Old English names "Hengest" and "Horsa" mean "stallion" and "horse" respectively.

The original Old English word for a horse was "eoh". "Eoh" derives from the Proto-Indo-European base "*ekwo", hence Latin "equus" which gave rise to the modern English words "equine" and "equestrian". "Hors" is derived from the Proto-Indo-European base "*kurs", to run, which also gave rise to "hurry, carry" and "current" (the latter two are borrowings from French). "Hors" eventually replaced "eoh", fitting a pattern elsewhere in Germanic languages where the original names of sacred animals are abandoned in favour of adjectives; for example, the word "bear". While the "Ecclesiastical History" and the "Anglo-Saxon Chronicle" refer to the brother as "Horsa", in the "History of the Britons" his name is simply "Hors". It has been suggested that "Horsa" may be a pet form of a compound name with the first element "horse".

In his 8th century "Ecclesiastical History", Bede records that the first chieftains among the Angles, Saxons, and Jutes in England were said to have been Hengist and Horsa. He relates that Horsa was killed in battle against the Britons and was thereafter buried in East Kent, where at the time of writing a monument still stood to him. According to Bede, Hengist and Horsa were the sons of Wictgils, son of Witta, son of Wecta, son of Woden.

The "Anglo-Saxon Chronicle", which exists in nine manuscripts and fragments, compiled from the 9th to the 12th centuries, records that in the year 449 Hengist and Horsa were invited to Britain by Vortigern to assist his forces in fighting the Picts. They landed at Eopwinesfleot (Ebbsfleet), and went on to defeat the Picts wherever they fought them. Hengist and Horsa sent word home to Germany describing "the worthlessness of the Britons, and the richness of the land" and asked for assistance. Their request was granted and support arrived. Afterward, more people arrived in Britain from "the three powers of Germany; the Old Saxons, the Angles, and the Jutes". The Saxons populated Essex, Sussex, and Wessex; the Jutes Kent, the Isle of Wight, and part of Hampshire; and the Angles East Anglia, Mercia, and Northumbria (leaving their original homeland, Angeln, deserted). The Worcester Chronicle (Chronicle D, compiled in the 11th century), and the Peterborough Chronicle (Chronicle E, compiled in the 12th century), include the detail that these forces were led by the brothers Hengist and Horsa, sons of Wihtgils, son of Witta, son of Wecta, son of Woden, but this information is not included in the A, B, C, or F versions.

In the entry for the year 455 the "Chronicle" details that Hengist and Horsa fought with Vortigern at Aylesford and that Horsa died there. Hengist took control of the kingdom with his son Esc. In 457, Hengist and Esc fought against British forces in Crayford "and there slew four thousand men". The Britons left the land of Kent and fled to London. In 465, Hengest and Esc fought again at the Battle of Wippedesfleot, probably near Ebbsfleet, and slew twelve British leaders. In the year 473, the final entry in the "Chronicle" mentioning Hengist or Horsa, Hengist and Esc are recorded as having taken "immense booty" and the Britons having "fled from the English like fire".

The 9th century "History of the Britons", attributed to the Briton Nennius, records that, during the reign of Vortigern in Britain, three vessels that had been exiled from Germany arrived in Britain, commanded by Hengist and Horsa. The narrative then gives a genealogy of the two: Hengist and Horsa were sons of Guictglis, son of Guicta, son of Guechta, son of Vouden, son of Frealof, son of Fredulf, son of Finn, son of Foleguald, son of Geta. Geta was said to be the son of a god, yet "not of the omnipotent God and our Lord Jesus Christ," but rather "the offspring of one of their idols, and whom, blinded by some demon, they worshipped according to the custom of the heathen." In 447 AD, Vortigern received Hengist and Horsa "as friends" and gave to the brothers the Isle of Thanet.

After the Saxons had lived on Thanet for "some time" Vortigern promised them supplies of clothing and other provisions on condition that they assist him in fighting the enemies of his country. As the Saxons increased in number the Britons became unable to keep their agreement, and so told them their assistance was no longer needed and they should go home.

Vortigern allowed Hengist to send for more of his countrymen to come over to fight for him. Messengers were sent to "Scythia", where "a number" of warriors were selected, and, with sixteen ships, the messengers returned. With the men came Hengist's beautiful daughter. Hengist prepared a feast, inviting Vortigern, Vortigern's officers, and Ceretic, his translator. Prior to the feast, Hengist enjoined his daughter to serve the guests plenty of wine and ale so that they would become drunk. At the feast Vortigern became enamored with her and promised Hengist whatever he liked in exchange for her betrothal. Hengist, having "consulted with the Elders who attended him of the Angle race," demanded Kent. Without the knowledge of the then-ruler of Kent, Vortigern agreed.

Hengist's daughter was given to Vortigern, who slept with her and deeply loved her. Hengist told him that he would now be both his father and adviser and that he would know no defeat with his counsel, "for the people of my country are strong, warlike, and robust." With Vortigern's approval, Hengist would send for his son and his brother to fight against the Scots and those who dwelt near the wall. Vortigern agreed and Ochta and Ebissa arrived with 40 ships, sailed around the land of the Picts, conquered "many regions," and assaulted the Orkney Islands. Hengist continued to send for more ships from his country, so that some islands where his people had previously dwelt are now free of inhabitants.

Vortigern had meanwhile incurred the wrath of Germanus, Bishop of Auxerre (by taking his own daughter for a wife and having a son by her) and had gone into hiding at the advice of his counsel. But at length his son Vortimer engaged Hengist and Horsa and their men in battle, drove them back to Thanet and there enclosed them and beset them on the western flank. The war waxed and waned; the Saxons repeatedly gained ground and were repeatedly driven back. Vortimer attacked the Saxons four times: first enclosing the Saxons in Thanet, secondly fighting at the river Derwent, the third time at Epsford, where both Horsa and Vortigern's son Catigern died, and lastly "near the stone on the shore of the Gallic sea," where the Saxons were defeated and fled to their ships.

After a "short interval" Vortimer died and the Saxons became established, "assisted by foreign pagans." Hengist convened his forces and sent to Vortigern an offer of peace. Vortigern accepted, and Hengist prepared a feast to bring together the British and Saxon leaders. However, he instructed his men to conceal knives beneath their feet. At the right moment, Hengist shouted "nima der sexa" (get your knives) and his men massacred the unsuspecting Britons. However, they spared Vortigern, who ransomed himself by giving the Saxons Essex, Sussex, Middlesex, and other unnamed districts.

Germanus of Auxerre was acclaimed as commander of the British forces. By praying, singing hallelujah and crying to God, the Saxons were driven to the sea. Germanus then prayed for three days and nights at Vortigern's castle and fire fell from heaven and engulfed the castle. Vortigern, Hengist's daughter, Vortigern's other wives, and all other inhabitants burned to death. Potential alternate fates for Vortigern are provided. However, the Saxons continued to increase in numbers, and after Hengist died his son Ochta succeeded him.

In his pseudo-historical twelfth century work "The History of the Kings of Britain", Geoffrey of Monmouth adapted and greatly expanded the account in the "History of the Britons". Hengist and Horsa appear in books 6 and 8:

Geoffrey records that three brigandines or long galleys arrived in Kent, full of armed men and commanded by two brothers, Hengist and Horsa. Vortigern was then staying at Dorobernia (Canterbury), and ordered that the "tall strangers" be received peacefully and brought to him. When Vortigern saw the company, he immediately observed that the brothers "excelled all the rest both in nobility and in gracefulness of person." He asked what country they had come from and why they had come to his kingdom. Hengist ("whose years and wisdom entitled him to precedence") replied that they had left their homeland of Saxony to offer their services to Vortigern or some other prince, as part of a Saxon custom in which, when the country became overpopulated, able young men were chosen by lot to seek their fortunes in other lands. Hengist and Horsa were made generals over the exiles, as befitted their noble birth.

Vortigern was aggrieved when he learned that the strangers were pagans, but nonetheless rejoiced at their arrival, since he was surrounded by enemies. He asked Hengist and Horsa if they would help him in his wars, offering them land and "other possessions." They accepted the offer, settled on an agreement, and stayed with Vortigern at his court. Soon after, the Picts came from Alba with an immense army and attacked the northern parts of Vortigern's kingdom. In the ensuing battle "there was little occasion for the Britons to exert themselves, for the Saxons fought so bravely, that the enemy, formerly victorious, were speedily put to flight."

In gratitude Vortigern increased the rewards he has promised to the brothers. Hengist was given "large possessions of lands in Lindsey for the subsistence of himself and his fellow-soldiers." A "man of experience and subtilty," Hengist told Vortigern that his enemies assailed him from every quarter, and that his subjects wished to depose him and make Aurelius Ambrosius king. He asked the king to allow him to send word to Saxony for more soldiers. Vortigern agreed, adding that Hengist could invite over whom he pleases and that "you shall have no refusal from me in whatever you shall desire."

Hengist bowed low in thanks, and made a further request, that he be made a consul or prince, as befitted his birth. Vortigern responded that it was not in his power to do this, reasoning that Hengist was a foreign pagan and would not be accepted by the British lords. Hengist asked instead for leave to build a fortress on a piece of land small enough that it could be encircled by a leather thong. Vortigern granted this and ordered Hengist to invite more Saxons.

After executing Vortigern's orders, Hengist took a bull's hide and made it into a single thong, which he used to encircle a carefully-chosen rocky place (perhaps at Caistor in Lindsey). Here he built the castle of "Kaercorrei", or in Saxon "Thancastre": "thong castle."

The messengers returned from Germany with eighteen ships full of the best soldiers they could get, as well as Hengist's beautiful daughter Rowena. Hengist invited Vortigern to see his new castle and the newly arrived soldiers. A banquet was held in Thancastre, at which Vortigern drunkenly asked Hengist to let him marry Rowena. Horsa and the men all agreed that Hengist should allow the marriage, on the condition that Vortigern gave him Kent.

Vortigern and Rowena were immediately married and Hengist was given Kent. The king was delighted with his new wife, but he incurred the hatred of his nobles and of his three sons.

As his new father-in-law, Hengist made further demands of Vortigern:

Vortigern agreed. Upon receiving the invitation, Octa, Ebissa, and another lord, Cherdich, immediately left for Britain with three hundred ships. Vortigern received them kindly, and gave them ample gifts. With their assistance, Vortigern defeated his enemies in every engagement. All the while Hengist continued inviting over yet more ships, adding to his numbers daily. Witnessing this, the Britons tried to get Vortigern to banish the Saxons, but on account of his wife he would not. Consequently, his subjects turned against him and took his son Vortimer for their king. The Saxons and the Britons, led by Vortimer, met in four battles. In the second, Horsa and Vortimer's brother, Catigern, slew one another. By the fourth battle, the Saxons had fled to Thanet, where Vortimer besieged them. When the Saxons could no longer bear the British onslaughts, they sent out Vortigern to ask his son to allow them safe passage back to Germany. While discussions were taking place, the Saxons boarded their ships and left, leaving their wives and children behind.

The victorious Vortimer was poisoned by Rowena, and Vortigern returned to the throne. At his wife's request he invited Hengist back to Britain, but instructed him to bring only a small retinue. Hengist, knowing Vortimer to be dead, instead raised an army of 300,000 men. When Vortigern caught word of the imminent arrival of the vast Saxon fleet, he resolved to fight them. Rowena alerted her father of this, who, after considering various strategies, resolved to make a show of peace and sent ambassadors to Vortigern.

The ambassadors informed Vortigern that Hengist had only brought so many men because he did not know of Vortimer's death and feared further attacks from him. Now that there was no threat, Vortigern could choose from among the men the ones he wished to return to Germany. Vortigern was greatly pleased by these tidings, and arranged to meet Hengist on the first of May at the monastery of Ambrius.

Before the meeting, Hengist ordered his soldiers to carry long daggers beneath their clothing. At the signal "Nemet oure Saxas" (get your knives), the Saxons fell upon the unsuspecting Britons and massacred them, while Hengist held Vortigern by his cloak. 460 British barons and consuls were killed, as well as some Saxons whom the Britons beat to death with club and stones. Vortigern was held captive and threatened with death until he resigned control of Britain's chief cities to Hengist. Once free, he fled to Cambria.

In Cambria, Merlin prophesied to Vortigern that the brothers Aurelius Ambrosius and Uther Pendragon, who had fled to Armorica as children after Vortigern killed their brother and father, would return to have their revenge and defeat the Saxons. They arrived the next day, and, after rallying the dispersed Britons, Aurelius was proclaimed king. Aurelius marched into Cambria and burned Vortigern alive in his tower, before setting his sights upon the Saxons.

Hengist was struck by terror at the news of Vortigern's death and fled with his army beyond the Humber. He took courage at the approach of Aurelius and selected the bravest among his men to defend. Hengist told these chosen men not to be afraid of Aurelius, for he had brought less than 10,000 Armorican Britons (the native Britons were hardly worth taking into account), while there were 200,000 Saxons. Hengist and his men advanced towards Aurelius in a field called Maisbeli (probably Ballifield, near Sheffield), intending to take the Britons by surprise, but Aurelius anticipated them.

As they marched to meet the Saxons, Eldol, Duke of Gloucester told Aurelius that he greatly wished to meet Hengist in combat, noting that "one of the two of us should die before we parted." He explained that he had been at the Treachery of the Long Knives, but had escaped when God threw him a stake to defend himself with, making him the only Briton present to survive. Meanwhile, Hengist was placing his troops into formation, giving directions, and walking through the lines of troops, "the more to spirit them up."

With the armies in formation, battle began between the Britons and Saxons, both sides shedding "no small loss of blood." Eldol focused on attempting to find Hengist, but had no opportunity to fight him. "By the especial favour of God," the Britons took the upper hand, and the Saxons withdrew and made for Kaerconan (Conisbrough). Aurelius pursued them, killing or enslaving any Saxon he met on the way. Realizing Kaerconan would not hold against Aurelius, Hengist stopped outside the town and ordered his men to make a stand, "for he knew that his whole security now lay in his sword."

Aurelius reached Hengist, and a "most furious" fight ensued, with the Saxons maintaining their ground despite heavy losses. They came close to winning before a detachment of horses from the Armorican Britons arrived. When Gorlois, Duke of Cornwall arrived, Eldol knew the day was won and grabbed Hengist's helmet, dragging him into the British ranks. The Saxons fled. Hengist's son Octa retreated to York and his kinsman Eosa to Alclud (Dumbarton).

Three days after the battle, Aurelius called together a council of principal officers to decide what would be done with Hengist. Eldol's brother Eldad, Bishop of Gloucester, said: 

Consequently, Eldol drew Hengist out of the city and cut off his head. Aurelius, "who showed moderation in all his conduct," arranged for him to be buried and for a mound to be raised over his corpse, according to the custom of pagans. Octa and Eosa surrendered to Aurelius, who granted them the country bordering Scotland and made a firm covenant with them.

Hengist is briefly mentioned in "Prologue", the first book of the "Prose Edda", written by the Icelander Snorri Sturluson in the 13th century. In "Prologue", a euhemerized account of Germanic history is given, including that Woden put three of his sons in charge of Saxony. The ruler of eastern Saxony was Veggdegg, one of whose sons was Vitrgils, the father of Vitta, the father of Hengist.

On farmhouses in Lower Saxony and Schleswig-Holstein, horse-head gables were referred to as "Hengst und Hors" as late as around 1875. Rudolf Simek notes that these horse heads gables can still be seen today, and says that the horse-head gables confirm that Hengist and Horsa were originally considered mythological, horse-shaped beings. Martin Litchfield West comments that the horse heads may have been remnants of pagan religious practices in the area. Organisations in (or originating in) the Raiffeisen farmers' co-operative movement use designs based on the horse-head gable in their trade-marks.

A Hengest appears in line 34 of the "Finnsburg Fragment", which describes the legendary Battle of Finnsburg. In "Beowulf", a scop recites a composition summarizing the Finnsburg events, including information not provided in the fragment. Hengest is mentioned in lines 1082 and 1091.

Some scholars have proposed that the figure mentioned in both of these references is one and the same as the Hengist of the Hengist and Horsa accounts, though Horsa is not mentioned in either source. In his work "Finn and Hengest", Tolkien argued that Hengist was a historical figure, and that Hengist came to Britain after the events recorded in the "Finnsburg Fragment" and "Beowulf". Patrick Sims-Williams is more skeptical of the account, suggesting that Bede's Canterbury source, which he relied on for his account of Hengist and Horsa in the "Ecclesiastical History", had confused two separate traditions.

Several sources attest that the Germanic peoples venerated a divine pair of twin brothers. The earliest reference to this practice derives from Timaeus (c. 345 – c. 250 BC). Timeaus records that the Celts of the North Sea were especially devoted to what he describes as Castor and Pollux. In his work "Germania", Tacitus records the veneration of the Alcis, whom he identifies with Castor and Pollux. Germanic legends mention various brothers as founding figures. The 1st- or 2nd-century historian Cassius Dio cites the brothers Raos and Raptos as the leaders of the Astings. According to Paul the Deacon's 8th century "History of the Lombards", the Lombards migrated southward from Scandinavia led by Ibur and Aio, while Saxo Grammaticus records in his 12th century "Deeds of the Danes" that this migration was prompted by Aggi and Ebbi. In related Indo-European cultures, similar traditions are attested, such as the Dioscuri. Scholars have theorized that these divine twins in Indo-European cultures stem from divine twins in prehistoric Proto-Indo-European culture.

J. P. Mallory comments on the great importance of the horse in Indo-European religion, as exemplified "most obviously" by various mythical brothers appearing in Indo-European legend, including Hengist and Horsa:

In his 17th century work "Monumenta Britannica", John Aubrey ascribes the Uffington White Horse hill figure to Hengist and Horsa, stating that "the White Horse was their Standard at the Conquest of Britain". However, elsewhere he ascribes the origins of the horse to the pre-Roman Britons, reasoning that the horse resembles certain Iron Age British coins. As a result, advocates of a Saxon origin of the figure debated with those favoring an ancient British origin for three centuries after Aubrey's findings. In 1995, using optically stimulated luminescence dating, David Miles and Simon Palmer of the Oxford Archaeological Unit assigned the Uffington White Horse to the late Bronze Age.

The Brothers Grimm identified Hengist with Aschanes, mythical first King of the Saxons, in their notes for legend number 413 of their "German Legends". Editor and translator Donald Ward, in his commentary on the tale, regards the identification as untenable on linguistic grounds.

Hengist and Horsa have appeared in a variety of media in the modern period. Written between 1616 and 1620, Thomas Middleton's play "Hengist, King of Kent" features portrayals of both Hengist and Horsa (as "Hersus"). On July 6, 1776, the first committee for the production of the Great Seal of the United States convened. One of three members of the committee, Thomas Jefferson, proposed that one side of the seal feature Hengist and Horsa, "the Saxon chiefs from whom we claim the honor of being descended, and whose political principles and form of government we assumed".

"Hengist and Horsus" appear as antagonists in William Henry Ireland's play "Vortigern and Rowena", which was touted as a newly discovered work by William Shakespeare in 1796, but was soon revealed as a hoax. The pair have plaques in the Walhalla Temple at Regensburg, Bavaria, which honours distinguished figures of German history. 

During World War II, two British military gliders took their names from the brothers: the Slingsby Hengist and the Airspeed Horsa. The 20th-century American poet Robinson Jeffers composed a poem titled "Ode to Hengist and Horsa".

In 1949, Prince Georg of Denmark came to Pegwell Bay in Kent to dedicate the longship "Hugin", commemorating the landing of Hengest and Horsa at nearby Ebbsfleet 1500 years earlier in 449 AD.

Though Hengist and Horsa are not referenced in the medieval tales of King Arthur, some modern Arthurian tales do link them. For example, in Mary Stewart's "Merlin Trilogy" it is King Arthur who kills Hengist. In Alfred Duggan's "Conscience of the King", Hengist plays a major role in the early career of Cerdic Elesing, legendary founder of the kingdom of Wessex.



</doc>
<doc id="14368" url="https://en.wikipedia.org/wiki?curid=14368" title="Hero System">
Hero System

The Hero System is a generic role-playing game system that was developed from the superhero RPG "Champions". After "Champions" fourth edition was released in 1989, a stripped-down version of its ruleset with no superhero or other genre elements was released as "The Hero System Rulesbook" in 1990. As a spinoff of "Champions", the "Hero System" is considered to have started with 4th edition (as it is mechanically identical to "Champions" 4th edition), rather than on its own with a 1st edition. However, the first three editions of the game are typically referred to as "Champions", rather than the Hero System, as the game for its first three editions was not sold as a universal toolkit, instead largely focusing on superheroes.

The "Hero System" is used as the underlying mechanics of other Hero Games role-playing games such as "Fantasy Hero", "Star Hero", and "Pulp Hero". It is characterized by point-based character creation and the rigor with which it measures character abilities. It uses only six-sided dice.

The "Hero System" uses "Champions"' key system features. Tasks are resolved using three six-sided dice and power effects (especially damage) are resolved by rolling a number of dice based on the power's strength.

Like "Champions", it uses tool-kit approach to creating effects. While the system does have more typical features of many RPGs, such as a skill system, most abilities in the "Hero System" rules are listed as a generic "powers". Most powers are meant to be able to model a vast number of potential effects. When creating a character, a player decides on what effect they wish to create, then constructs this effect by consulting the powers in the rulebook. Most powers have a set of modifiers that alter its base performance to more finely-tune its representation of the effect desired. Each such modifier makes the power more or less capable, and correspondingly more or less expensive to purchase with character points (the "currency" used to buy powers; see the section following). The result is that many effects are possible from the exact same base power. For example, while systems such as Dungeons & Dragons would list a wide variety of separate ranged attack powers that deal damage (such as a fireball, a lightning bolt, an acid spray, a magic missile, and dozens more), the vast majority of such effects in the "Hero System" would be constructed out of the same base two powers, "Blast" or "Killing Attack".

The "Hero System" rules only define an ability's very basic mechanical effects—the player is the one who defines what the ability looks like when used. For example, if a player wishes to model the ability to project a jet of fire, they could choose the "Blast" power. However, the power's text has no mention of what it looks like or how it operates beyond some very base notes concerning damage and range. To make it a jet of fire, the player simply states that this Blast is a jet of fire. To some degree this is simply cosmetic. However, in the game, that power now is treated as a fire attack, with all that implies as decided by the gamemaster in each situation: it has the possibility of starting secondary fires; it looks, smells and sounds like a jet of fire; will not work in water; will terrify people with a phobia of fire; etc. The system does have mechanical effect alterations as well: a Blast could be altered by any number of power modifiers such as "Explosion", "Area of Effect", "Megascale", etc.: both advantages and disadvantages are available. As players are typically attempting to model something with at least a partial real-life analogue, limitations on a power are as much about making it more accurate a representation as they are making it less expensive to purchase (for example, to model a firearm, the limitation that it requires ammunition is expected, regardless of the fact that this happens to make a firearm cost fewer character points). The system also allows players to construct very exacting modifiers not specifically detailed in the base rules. For example, a player could define one or more powers as not working when the moon is full, or when it is Tuesday, or any other limitation that the player can imagine and the gamemaster feels is applicable.

Also like "Champions", the "Hero System" uses a point-based system for character creation. Instead of templates which define what a character is, how it performs mechanically, and the new abilities gained after a certain amount of play, a player is given a fixed number of points and allowed to create what they want. As this is a much more freeform process than in most games, the system encourages close involvement between players and gamemasters to ensure that all participants have the same understanding regarding the type of effects permitted, relative power levels, and the like.

Each player creates his character starting with a pool of points to buy abilities (such as the aforementioned "Energy Blast" and "Armor"), increase characteristics (such as "Strength" and "Intelligence") and buy skills (such as "Computer Programming" and "Combat Driving"). This pool can be increased by taking disadvantages for your character (such as being hunted by an enemy, a dependency of some sort or having people who depend on your character in some way). The initial pool, as well as the final pool size, is determined by the Game Master (GM), as well as the point limits on each individual ability.

Unlike the d20 System and many other game systems, experience awards are in the form of character points, which have the same value as those used in character creation and can be applied directly to the character's abilities upon receipt.

The advantages of the "Hero System "are commonly considered to be:


The primary disadvantages are sometimes considered to be:


The "large number of dice required at high power levels" has been called both an advantage and a disadvantage. The original designers, and some contemporary players, have cited a "feeling of power" when rolling large numbers of dice and counting off huge amounts of damage. On the other hand, rolling such a large load of dice can be physically unwieldy and take a long time to add up.

The powers system is divided into a set of standard powers, and a list of advantages and limitations that can be applied to each power. Many of the powers have specific advantages and limitations that apply only to that power. The powers in the Hero System are categorized roughly as follows:

Within each of these categories are multiple Powers that have more specialized effects. Thus for the movement category there are powers that can be used for Running, Swimming, Climbing, Leaping, Gliding, Flying, Tunneling through solid surfaces, and even Teleportation. For certain game genres there are even powers for traveling to other dimensions or moving faster than light.

Also, many Powers appear in at least two categories. For example, most Attack Powers are also Standard Powers, and Size Powers are basically just a subcategory of Body-Affecting Powers. Darkness is in three categories — Standard, Attack, and Sense-Affecting.

Each power has a base point cost for a given effect. This could be, for example, a certain number of points per six-sided-die (or "d6") of damage inflicted upon a foe.

Powers can have both advantages and limitations. Both are modifiers applied at different stages in calculating cost. These modifiers are typically changes of ±¼, but can range up to ±2 or even higher.

After the base cost is calculated, advantages are applied. These, which can make a power more useful, typically expand its effectiveness or make it more powerful, and thus make it more expensive. Once advantages are applied, the base cost becomes the Active Cost.

The Active Cost is calculated as an intermediate step as it is required to calculate certain figures, such as range, END usage, difficulty of activation rolls, and other things.

The formula for calculating the Active Cost is:

Once Active Cost is calculated, limitations are applied. These represent shortcomings in the power, lessened reliability or situations in which the power can not be used. Limitations are added separately as positive numbers, even though they are listed as negative.

The Real Cost of the power is then determined by:

The Real Cost is the amount the character must actually pay for the Power.

The rules also include schemes for providing a larger number of powers to a character for a given cost. These power frameworks reduce the cost either by requiring the group of powers to have a common theme as in an Elemental Control Framework, or by limiting the number of powers that can be active at one time with a Multipower Framework. Powers within a framework can share common limitations, further reducing the cost. A third type of power framework, the Variable Power Pool (VPP), trades thrift for flexibility. With it, powers can be arbitrarily chosen on the fly, granting enhanced in-game flexibility. The price is a premium on points, called the Control Cost. Additionally, it is marked as potentially unbalancing, so not all GMs will permit VPP's.

Elemental Controls were eliminated in the Sixth Edition.

One of the criticisms leveled at the "Hero System" almost since its inception is the relatively large amount of computation involved in its use, particularly during character creation. While almost none of this math goes beyond the basic functions of addition, subtraction, multiplication, and division, this can seem daunting to newcomers.

As a result, software has been created to automate the bookkeeping involved. "Heromaker", an MS-DOS program, was distributed with some versions of Champions. Today, "Hero Designer" for the Fifth and Sixth Editions is available on several platforms, and is supported by numerous character packs and other extensions linked to Hero Games book releases.

Although several games based on what would become known as the "Hero System" were published in the 1980s, including "Champions", "Danger International", "Justice, Inc.", "Robot Warriors" and the original versions of "Fantasy Hero" and "Star Hero", each of the RPGs was self-contained, much as Chaosium's Basic Role-Playing games are. The "Hero System" itself was not released as an independent entity until 1990, as Steve Jackson Games' "GURPS" ("Generic Universal Roleplaying System") became more popular. As a joint venture between Hero Games and Iron Crown Enterprises, a stand-alone "Hero System Rulebook" was published alongside the fourth edition of Champions. The content was identical to the opening sections of the Champions rules, but all genre-related material was removed. Afterward, genre books such as "Ninja Hero" (written by Aaron Allston) and "Fantasy Hero" were published as sourcebooks for the "Hero System Rulebook" as opposed to being independent games.

With the collapse of the Hero-ICE alliance, the "Hero System" went into limbo for several years. The "Champions" franchise released a new version under the Fuzion system, which had been a joint development with R. Talsorian Games, called "Champions: the New Millennium". Although two editions were published, it was very poorly received by "Champions" fans. In 2001, a reconstituted Hero Games was formed under the leadership of Steven S. Long, who had written several books for the earlier version of the system. It regained the rights to the "Hero System" and to the "Champions" trademark.

In 2001, the Fifth Edition of the "Hero System Rulebook" was released, incorporating heavy revisions by Long. A large black hardcover, it was critically well received and attained a degree of commercial success. (Following problems with fragile bindings on Fourth Edition rulebooks, the planned binding for the larger Fifth Edition was tested using a clothes dryer.) The Fifth Edition is often referred to as "FREd", which is a backronym for "Fifth Rules Edition". The name actually comes from Steve S. Long's reply when asked what the standard abbreviation for the Fifth Edition would be: "I don't care if you call it 'Fred', as long as you buy it." This was made the unofficial nickname by several replies on the same board affirming it after a reply from Willpower, who coined the backronym by saying, "OK. FREd it is, "Fifth Rules Edition"!" 

A revised version () was issued in 2004, along with "Hero System Sidekick", a condensed version of the rulebook with a cover price of under $10. Fans often call the revised Fifth Edition "Fiver," ReFREd," or "5ER" (from "Fifth Edition revised"; "Fiver" also alludes to "Watership Down"). This rulebook is so big (592 pages) that some fans speculated that it might be bulletproof, and it did indeed stop some bullets when tested by Hero Games staffers.

On February 28, 2008, Cryptic Studios purchased the "Champions" intellectual property, and sold the rights back to Hero Games to publish the 6th edition books. One of the new features will be to allow players to adapt their "Champions Online" characters to the pen-and-paper game.

In late 2008, Hero released a licensed RPG for Aaron Williams's popular comic PS238 using a simplified version of the Fifth Edition rules.

In late 2009, Hero Games released the 6th Edition of the Hero System. The game has so far had a mostly positive reception, with little in the way of 'Edition Wars'. The largest rules change was the removal of Figured Characteristics (meaning that character stats that were previously linked intrinsically—such as Speed automatically increasing when sufficient amounts of Dexterity were purchased—were no longer connected, and instead bought entirely separately). Other, more minor rules changes include folding Armor and Force field into Resistant Defense and reestablishing Regeneration as a separate power. The rules were released in two volumes, with the first covering character creation in depth and the second describing campaigns and the running of games. The new genre book for Champions came out shortly thereafter, and a new "Fantasy Hero" was released in the summer of 2010. A new version of Sidekick was released in late 2009 under the title "The Hero System Basic Rulebook", while an "Advanced Player Guide" was published that had additional options for character creation. Other recent releases included a large book of pre-constructed Powers, a set of pre-generated Martial Arts styles, abilities and skills, a large bestiary, a new grimoire for Fantasy Hero and a three-volume set of villains for "Champions". A new edition of "Star Hero" was released in 2011, along with a second "Advanced Player Guide".

On 28 November 2011, Hero Games announced a restructuring, with Darren Watts and long-time developer Steven S. Long relinquishing their full-time statuses to work freelance. In late 2012 "Champions Complete" was released, which contained all of the core 6th edition rules as well as enough information to play a superhero campaign in a single 240-page book. This compact presentation reflected criticism that the 6th edition rules had become too unwieldy.
Mirroring the shrinking of much of the table-top RPG industry, Hero Games now maintains an irregular release schedule, with a minimal staff, and has successfully used Kickstarter to raise funds for new projects. One of these new products, "Fantasy Hero Complete", was released in early 2015.



</doc>
<doc id="14369" url="https://en.wikipedia.org/wiki?curid=14369" title="Humphry Davy">
Humphry Davy

Sir Humphry Davy, 1st Baronet (17 December 177829 May 1829) was a Cornish chemist and inventor, who is best remembered today for isolating, using electricity, a series of elements for the first time: potassium and sodium in 1807 and calcium, strontium, barium, magnesium and boron the following year, as well as discovering the elemental nature of chlorine and iodine. He also studied the forces involved in these separations, inventing the new field of electrochemistry. In 1799 Davy experimented with nitrous oxide and became astonished that it made him laugh, so he nicknamed it "laughing gas", and wrote about its potential anaesthetic properties in relieving pain during surgery.

Berzelius called Davy's 1806 Bakerian Lecture "On Some Chemical Agencies of Electricity" "one of the best memoirs which has ever enriched the theory of chemistry."
He was a Baronet, President of the Royal Society (PRS), Member of the Royal Irish Academy (MRIA), and Fellow of the Geological Society (FGS). He also invented the Davy lamp and a very early form of incandescent light bulb.

He joked that his assistant Michael Faraday, who later became an even greater chemist and physicist, was his greatest discovery.

Davy was born in Penzance, Cornwall in England on 17 December 1778. Davy's brother, John Davy, writes that the society of their hometown was characterised by "an almost unbounded credulity respecting the supernatural and monstrous [...] Amongst the middle and higher classes, there was little taste for literature, and still less for science [...] Hunting, shooting, wrestling, cockfighting, generally ending in drunkenness, were what they most delighted in". At the age of six, Davy was sent to the grammar school at Penzance. Three years later, his family moved to Varfell, near Ludgvan, and subsequently, in term-time Davy boarded with John Tonkin, his godfather and later his guardian. On leaving Penzance grammar school in 1793, Tonkin paid for Davy to attend Truro Grammar School in 1793 to finish his education under the Rev Dr Cardew, who, in a letter to Davies Gilbert, said dryly: "I could not discern the faculties by which he was afterwards so much distinguished." Yet, Davy entertained his school friends with writing poetry, Valentines, and telling stories from One Thousand and One Nights. Reflecting on his school days, in a letter to his mother, Davy wrote: "Learning naturally is a true pleasure; how unfortunate then it is that in most schools it is made a pain." Davy said: "I consider it fortunate I was left much to myself as a child, and put upon no particular plan of study... What I am I made myself." Davy's brother praises his "native vigour": "there belonged, however, to his mind, it cannot be doubted, the genuine quality of genius, or of that power of intellect which exalts its possessor above the crowd.

After Davy's father died in 1794, Tonkin apprenticed him to John Bingham Borlase, a surgeon with a practice in Penzance. Davy's indenture is dated 10 February 1795. In the apothecary's dispensary, Davy became a chemist, and conducted his earliest chemical experiments in a garret in Tonkin's house. Davy's friends said: "This boy Humphry is incorrigible. He will blow us all into the air." His elder sister complained of the ravages made on her dresses by corrosive substances. Davy was taught French by a refugee priest, and in 1797 read Lavoisier's "Traité élémentaire de chimie": much of his future work can be seen as reacting against Lavoisier's work and the dominance of French chemists.

As a poet, over one hundred and sixty manuscript poems were written by Davy, the majority of which are found in his personal notebooks. Most of his written poems were not published, and he chose instead to share a few of them with his friends. Eight of his known poems were published. His poems reflected his views on both his career and also his pereception of certain aspects of human life. He wrote on human endeavours and aspects of life like death, metaphysics, geology, natural theology and chemistry.

John Ayrton Paris remarked that poetry written by the young Davy "bear the stamp of lofty genius". Davy's first preserved poem entitled "The Sons of Genius" is dated 1795 and marked by the usual immaturity of youth. Other poems written in the following years, especially "On the Mount's Bay" and "St Michael's Mount", are descriptive verses, showing sensibility but no true poetic imagination. Three of Davy's paintings from around 1796 have been donated to the Penlee House museum at Penzance. One is of the view from above Gulval showing the church, Mount's Bay and the Mount, while the other two depict Loch Lomond in Scotland.

While writing verses at the age of 17 in honour of his first love, he was eagerly discussing the question of the materiality of heat with his Quaker friend and mentor Robert Dunkin. Dunkin remarked: 'I tell thee what, Humphry, thou art the most quibbling hand at a dispute I ever met with in my life.' One winter day he took Davy to the Larigan River, To show him that rubbing two plates of ice together developed sufficient energy by motion, to melt them, and that after the motion was suspended, the pieces were united by regelation. It was a crude form of analogous experiment exhibited by Davy in the lecture-room of the Royal Institution that elicited considerable attention. As professor at the Royal Institution, Davy repeated many of the ingenious experiments he learned from his friend and mentor, Robert Dunkin.

Even though he initially started writing his poems albeit haphazardly, as a reflection of his views on his career, and on life generally, most of his final poems concentrated more on immortality and death. This was after he started experiencing failing health and a decline both in health and career.

Davies Giddy met Davy in Penzance carelessly swinging on the half-gate of Dr Borlase's house, and interested by his talk invited him to his house at Tredrea and offered him the use of his library. This led to an introduction to Dr Edwards, who lived at Hayle Copper House. Edwards was a lecturer in chemistry in the school of St. Bartholomew's Hospital. He permitted Davy to use his laboratory and possibly directed his attention to the floodgates of the port of Hayle, which were rapidly decaying as a result of the contact between copper and iron under the influence of seawater. Galvanic corrosion was not understood at that time, but the phenomenon prepared Davy's mind for subsequent experiments on ship's copper sheathing. Gregory Watt, son of James Watt, visited Penzance for his health's sake, and while lodging at the Davy's house became a friend and gave him instructions in chemistry. Davy was acquainted with the Wedgwood family, who spent a winter at Penzance.

Thomas Beddoes and John Hailstone were engaged in a geological controversy on the rival merits of the Plutonian and Neptunist hypotheses. They travelled together to examine the Cornish coast accompanied by Davies Gilbert and made Davy's acquaintance. Beddoes, who had established at Bristol a 'Pneumatic Institution,' needed an assistant to superintend the laboratory. Gilbert recommended Davy, and in 1798 Gregory Watt showed Beddoes the "Young man's Researches on Heat and Light", which were subsequently published by him in the first volume of "West-Country Contributions". After prolonged negotiations, mainly by Gilbert, Mrs Davy and Borlase consented to Davy's departure, but Tonkin wished him to remain in his native town as a surgeon, and altered his will when he found that Davy insisted on going to Dr Beddoes.

In 1802, Humphry Davy had what was then, the most powerful electrical battery in the world at the Royal Institution. With it, Davy created the first incandescent light by passing electric current through a thin strip of platinum, chosen because the metal had an extremely high melting point. It was neither sufficiently bright nor long lasting enough to be of practical use, but demonstrated the principle. By 1806 he was able to demonstrate a much more powerful form of electric lighting to the Royal Society in London. It was an early form of arc light which produced its illumination from an electric arc created between two charcoal rods.

On 2 October 1798, Davy joined the Pneumatic Institution at Bristol. It had been established to investigate the medical powers of factitious airs and gases (gases produced experimentally or artificially), and Davy was to superintend the various experiments. The arrangement agreed between Dr Beddoes and Davy was generous, and enabled Davy to give up all claims on his paternal property in favour of his mother. He did not intend to abandon the medical profession and was determined to study and graduate at Edinburgh, but he soon began to fill parts of the institution with voltaic batteries. While living in Bristol, Davy met the Earl of Durham, who was a resident in the institution for his health, and became close friends with Gregory Watt, James Watt, Samuel Taylor Coleridge and Robert Southey, all of whom became regular users of nitrous oxide (laughing gas), to which Davy became addicted. The gas was first synthesized in 1772 by the natural philosopher and chemist Joseph Priestley, who called it "phlogisticated nitrous air" (see phlogiston). Priestley described his discovery in the book "Experiments and Observations on Different Kinds of Air (1775)", in which he described how to produce the preparation of "nitrous air diminished", by heating iron filings dampened with nitric acid.

James Watt built a portable gas chamber to facilitate Davy's experiments with the inhalation of nitrous oxide. At one point the gas was combined with wine to judge its efficacy as a cure for hangover (his laboratory notebook indicated success). The gas was popular among Davy's friends and acquaintances, and he noted that it might be useful for performing surgical operations. Anesthetics were not regularly used in medicine or dentistry until decades after Davy's death.

Davy threw himself energetically into the work of the laboratory and formed a long romantic friendship with Mrs Anna Beddoes, the novelist Maria Edgeworth's sister, who acted as his guide on walks and other fine sights of the locality. The critic Maurice Hindle was the first to reveal that Davy and Anna had written poems for each other. Wahida Amin has transcribed and discussed a number of poems written between 1803 and 1808 to "Anna" and one to her infant child. In December 1799 Davy visited London for the first time and extended his circle of friends. Davy features in the diary of William Godwin, with their first meeting recorded for 4 December 1799.

In the gas experiments Davy ran considerable risks. His respiration of nitric oxide which may have combined with air in the mouth to form nitric acid (HNO), severely injured the mucous membrane, and in Davy's attempt to inhale four quarts of "pure hydrocarbonate" gas in an experiment with carbon monoxide he "seemed sinking into annihilation." On being removed into the open air, Davy faintly articulated, "I do not think I shall die," but some hours elapsed before the painful symptoms ceased. Davy was able to take his own pulse as he staggered out of the laboratory and into the garden, and he described it in his notes as "threadlike and beating with excessive quickness".

In this year the first volume of the "West-Country Collections" was issued. Half consisted of Davy's essays "On Heat, Light, and the Combinations of Light", "On Phos-oxygen and its Combinations", and on the "Theory of Respiration". On 22 February 1799 Davy, wrote to Davies Gilbert, "I am now as much convinced of the non-existence of caloric as I am of the existence of light." In another letter to Gilbert, on 10 April, Davy informs him: "I made a discovery yesterday which proves how necessary it is to repeat experiments. The gaseous oxide of azote (the laughing gas) is perfectly respirable when pure. It is never deleterious but when it contains nitrous gas. I have found a mode of making it pure." He said that he breathed sixteen quarts of it for nearly seven minutes, and that it "absolutely intoxicated me." 
Davy became increasingly well known in 1799 due to his experiments with the physiological action of some gases, including laughing gas (nitrous oxide). In addition to himself, his enthusiastic experimental subjects included his poet friends Robert Southey and Samuel Taylor Coleridge.

During 1799, Beddoes and Davy published "Contributions to physical and medical knowledge, principally from the west of England" and "Essays on heat, light, and the combinations of light, with a new theory of respiration. On the generation of oxygen gas, and the causes of the colors of organic beings." Their experimental work was poor, and the publications were harshly criticized. In after years Davy regretted he had ever published these immature hypotheses, which he subsequently designated "the dreams of misemployed genius which the light of experiment and observation has never conducted to truth."

These criticisms, however, led Davy to refine and improve his experimental techniques, spending his later time at the institution increasingly in experimentation.
In 1800, Davy informed Gilbert that he had been "repeating the galvanic experiments with success" in the intervals of the experiments on the gases, which "almost incessantly occupied him from January to April." In 1800, Davy published his "Researches, Chemical and Philosophical, chiefly concerning Nitrous Oxide and its Respiration", and received a more positive response.

William Wordsworth and Samuel Taylor Coleridge moved to the Lake District in 1800, and asked Davy to deal with the Bristol publishers of the Lyrical Ballads, Biggs & Cottle. Coleridge asked Davy to proofread the second edition of the Lyrical Ballads, the first to contain Wordsworth's Preface in a letter dated 16 July 1800: "Will you be so kind as just to look over the sheets of the lyrical Ballads". Wordsworth subsequently wrote to Davy on 29 July 1800, sending him the first manuscript sheet of poems and asking him specifically to correct: "any thing you find amiss in the punctuation a business at which I am ashamed to say I am no adept". Wordsworth was ill in the autumn of 1800 and slow in sending poems for the second edition; the volume appeared on 26 January 1801 even though it was dated 1800. While it is impossible to know whether Davy was at fault, this edition of the Lyrical Ballads contained many errors, including the poem "Michael" being left incomplete. In a personal notebook marked on the front cover "Clifton 1800 From August to Novr", Davy wrote his own Lyrical Ballad: "As I was walking up the street". Wordsworth features in Davy's poem as the recorder of ordinary lives in the line: "By poet Wordsworths Rymes" [sic].

In 1799, Count Rumford had proposed the establishment in London of an 'Institution for Diffusing Knowledge', i.e. the Royal Institution. The house in Albemarle Street was bought in April 1799. Rumford became secretary to the institution, and Dr Thomas Garnett was the first lecturer.
In February 1801 Davy was interviewed by the committee of the Royal Institution, comprising Joseph Banks, Benjamin Thompson (who had been appointed Count Rumford) and Henry Cavendish. Davy wrote to Davies Gilbert on 8 March 1801 about the offers made by Banks and Thompson, a possible move to London and the promise of funding for his work in galvanism. He also mentioned that he might not be collaborating further with Beddoes on therapeutic gases. The next day Davy left Bristol to take up his new post at the Royal Institution, it having been resolved 'that Humphry Davy be engaged in the service of the Royal Institution in the capacity of assistant lecturer in chemistry, director of the chemical laboratory, and assistant editor of the journals of the institution, and that he be allowed to occupy a room in the house, and be furnished with coals and candles, and that he be paid a salary of 100l. per annum.'

On 25 April 1801, Davy gave his first lecture on the relatively new subject of 'Galvanism'. He and his friend Coleridge had had many conversations about the nature of human knowledge and progress, and Davy's lectures gave his audience a vision of human civilisation brought forward by scientific discovery. "It [science] has bestowed on him powers which may almost be called creative; which have enabled him to modify and change the beings surrounding him, and by his experiments to interrogate nature with power, not simply as a scholar, passive and seeking only to understand her operations, but rather as a master, active with his own instruments." The first lecture garnered rave reviews, and by the June lecture Davy wrote to John King that his last lecture had attendance of nearly 500 people. "There was Respiration, Nitrous Oxide, and unbounded Applause. Amen!"
Davy revelled in his public status.

Davy's lectures included spectacular and sometimes dangerous chemical demonstrations along with scientific information, and were presented with considerable showmanship by the young and handsome man. 
Davy also included both poetic and religious commentary in his lectures, emphasizing that God's design was revealed by chemical investigations. Religious commentary was in part an attempt to appeal to women in his audiences. Davy, like many of his enlightenment contemporaries, supported female education and women's involvement in scientific pursuits, even proposing that women be admitted to evening events at the Royal Society.
Davy acquired a large female following around London. In a satirical cartoon by Gillray, nearly half of the attendees pictured are female. His support of women caused Davy to be subjected to considerable gossip and innuendo, and to be criticized as unmanly.

When Davy's lecture series on Galvanism ended, he progressed to a new series on Agricultural Chemistry, and his popularity continued to skyrocket. By June 1802, after just over a year at the Institution and at the age of 23, Davy was nominated to full lecturer at the Royal Institution of Great Britain. Garnett quietly resigned, citing health reasons.

In November 1804 Davy became a Fellow of the Royal Society, over which he would later preside. He was one of the founding members of the Geological Society in 1807 and was elected a foreign member of the Royal Swedish Academy of Sciences in 1810 and a Foreign Honorary Member of the American Academy of Arts and Sciences in 1822.

Davy was a pioneer in the field of electrolysis using the voltaic pile to split common compounds and thus prepare many new elements. He went on to electrolyse molten salts and discovered several new metals, including sodium and potassium, highly reactive elements known as the alkali metals. Davy discovered potassium in 1807, deriving it from caustic potash (KOH). Before the 19th century, no distinction had been made between potassium and sodium. Potassium was the first metal that was isolated by electrolysis. Davy isolated sodium in the same year by passing an electric current through molten sodium hydroxide.

During the first half of 1808, Davy conducted a series of further electrolysis experiments on alkaline earths including lime, magnesia, strontites and barytes. At the beginning of June, Davy received a letter from the Swedish chemist Berzelius claiming that he, in conjunction with Dr. Pontin, had successfully obtained amalgams of calcium and barium by electrolysing lime and barytes using a mercury cathode. Davy managed to successfully repeat these experiments almost immediately and expanded Berzelius' method to strontites and magnesia. He noted that while these amalgams oxidated in only a few minutes when exposed to air they could be preserved for lengthy periods of time when submerged in naphtha before becoming covered with a white crust.
On 30 June 1808 Davy reported to the Royal Society that he had successfully isolated four new metals which he named barium, calcium, strontium and magnium (later changed to magnesium) which were subsequently published in the "Philosophical Transactions". Although Davy conceded magnium was an "undoubtedly objectionable" name he argued the more appropriate name magnesium was already being applied to metallic manganese and wished to avoid creating an equivocal term.
The observations gathered from these experiments also led to Davy isolating boron in 1809.

Chlorine was discovered in 1774 by Swedish chemist Carl Wilhelm Scheele, who called it ""dephlogisticated marine acid"" (see phlogiston theory) and mistakenly thought it contained oxygen. Davy showed that the acid of Scheele's substance, called at the time oxymuriatic acid, contained no oxygen. This discovery overturned Lavoisier's definition of acids as compounds of oxygen. In 1810, chlorine was given its current name by Humphry Davy, who insisted that chlorine was in fact an element. The name chlorine, chosen by Davy for "one of [the substance's] obvious and characteristic properties - its colour", comes from the Greek χλωρος (chlōros), meaning green-yellow.

Davy seriously injured himself in a laboratory accident with nitrogen trichloride. French chemist Pierre Louis Dulong had first prepared this compound in 1811, and had lost two fingers and an eye in two separate explosions with it. In a letter to John Children, on 16 November 1812, Davy wrote: "It must be used with great caution. It is not safe to experiment upon a globule larger than a pin's head. I have been severely wounded by a piece scarcely bigger. My sight, however, I am informed, will not be injured". Davy's accident induced him to hire Michael Faraday as a co-worker, particularly for assistance with handwriting and record keeping. He had recovered from his injuries by April 1813.

In 1812, Davy was knighted and gave up his lecturing position at the Royal Institution. He was given the title of Honorary Professor of Chemistry. He gave a farewell lecture to the Institution, and married a wealthy widow, Jane Apreece. (While Davy was generally acknowledged as being faithful to his wife, their relationship was stormy, and in later years he travelled to continental Europe alone.)

Davy then published his "Elements of Chemical Philosophy, part 1, volume 1", though other parts of this title were never completed. He made notes for a second edition, but it was never required. 
In October 1813, he and his wife, accompanied by Michael Faraday as his scientific assistant (also treated as a valet), travelled to France to collect a medal that Napoleon Bonaparte had awarded Davy for his electro-chemical work. Faraday noted that 'Tis indeed a strange venture at this time, to trust ourselves in a foreign and hostile country, where so little regard is had to protestations of honour, that the slightest suspicion would be sufficient to separate us for ever from England, and perhaps from life'. Davy's party sailed from Plymouth to Morlaix by cartel, where they were searched.

Upon reaching Paris, Davy was a guest of honour at a meeting of the First Class of the Institut de France and met with André-Marie Ampère and other French chemists.

While in Paris, Davy attended lectures at the Ecole Polytechnique, including those by Joseph Louis Gay-Lussac on a mysterious substance isolated by Bernard Courtois. Davy wrote a paper for the Royal Society on the element, which is now called iodine. This led to a dispute between Davy and Gay-Lussac on who had the priority on the research.

Davy's party did not meet Napoleon in person, but they did visit the Empress Joséphine de Beauharnais at the Château de Malmaison. The party left Paris in December 1813, travelling south to Italy. They sojourned in Florence, where using the burning glass of the Grand Duke of Tuscany in a series of experiments conducted with Faraday's assistance, Davy succeeded in using the sun's rays to ignite diamond, proving it is composed of pure carbon.

Davy's party continued to Rome, where he undertook experiments on iodine and chlorine and on the colours used in ancient paintings. This was the first chemical research on the pigments used by artists.

He also visited Naples and Mount Vesuvius, where he collected samples of crystals. By June 1814, they were in Milan, where they met Alessandro Volta, and then continued north to Geneva. They returned to Italy via Munich and Innsbruck, and when their plans to travel to Greece and Istanbul were abandoned after Napoleon's escape from Elba, they returned to England.

After the Battle of Waterloo, Davy wrote to Lord Liverpool urging that the French be treated with severity:

After his return to England in 1815, Davy began experimenting with lamps that could be used safely in coal mines. The Revd Dr Robert Gray of Bishopwearmouth in Sunderland, founder of the Society for Preventing Accidents in Coalmines, had written to Davy suggesting that he might use his 'extensive stores of chemical knowledge' to address the issue of mining explosions caused by firedamp, or methane mixed with oxygen, which was often ignited by the open flames of the lamps then used by miners. Incidents such as the Felling mine disaster of 1812 near Newcastle, in which 92 men were killed, not only caused great loss of life among miners but also meant that their widows and children had to be supported by the public purse. The Revd Gray and a fellow clergyman also working in a north-east mining area, the Revd John Hodgson of Jarrow, were keen that action should be taken to improve underground lighting and especially the lamps used by miners.

Davy conceived of using an iron gauze to enclose a lamp's flame, and so prevent the methane burning inside the lamp from passing out to the general atmosphere. Although the idea of the safety lamp had already been demonstrated by William Reid Clanny and by the then unknown (but later very famous) engineer George Stephenson, Davy's use of wire gauze to prevent the spread of flame was used by many other inventors in their later designs. George Stephenson's lamp was very popular in the north-east coalfields, and used the same principle of preventing the flame reaching the general atmosphere, but by different means. Unfortunately, although the new design of gauze lamp initially did seem to offer protection, it gave much less light, and quickly deteriorated in the wet conditions of most pits. Rusting of the gauze quickly made the lamp unsafe, and the number of deaths from firedamp explosions rose yet further.

There was some discussion as to whether Davy had discovered the principles behind his lamp without the help of the work of Smithson Tennant, but it was generally agreed that the work of both men had been independent. Davy refused to patent the lamp, and its invention led to his being awarded the Rumford medal in 1816.

In 1815 Davy suggested that acids were substances that contained replaceable hydrogen ions;– hydrogen that could be partly or totally replaced by reactive metals which are placed above hydrogen in the reactivity series. When acids reacted with metals they formed salts and hydrogen gas. Bases were substances that reacted with acids to form salts and water. These definitions worked well for most of the nineteenth century.

Humphry Davy experimented on fragments of the Herculaneum papyri before his departure to Naples in 1818. His early experiments showed hope of success. In his report to the Royal Society Davy writes that: 
'When a fragment of a brown MS. in which the layers were strongly adhered, was placed in an atmosphere of chlorine, there was an immediate action, the papyrus smoked and became yellow, and the letters appeared much more distinct; and by the application of heat the layers separated from each other, giving fumes of muriatic acid.'

The success of the early trials prompted Davy to travel to Naples to conduct further research on the Herculaneum papyri. Accompanied by his wife, they set off on 26 May 1818 to stay in Flanders where Davy was invited to by the coal miners. They then traveled to Carniola (now Slovenia) which proved to become 'his favourite Alpine retreat' before finally arriving in Italy. In Italy, they befriended Lord Byron in Rome and then went on to travel to Naples.

Initial experiments were again promising and his work resulted in 'partially unrolling 23 MSS., from which fragments of writing were obtained' but after returning to Naples on 1 December 1819 from a summer in the Alps, Davy complained that 'the Italians at the museum [were] no longer helpful but obstructive'. Davy decided to renounce further work on the papyri because 'the labour, in itself difficult and unpleasant, been made more so, by the conduct of the persons at the head of this department in the Museum'.

From 1761 onwards, copper plating had been fitted to the undersides of Royal Navy ships, to protect the wood from attack by shipworms. However, the copper bottoms were gradually corroded by exposure to the salt water. Between 1820 and 1825, Davy, assisted by Michael Faraday, attempted to protect the copper by electrochemical means. He attached sacrificial pieces of zinc or iron to the copper, which provided cathodic protection to the host metal. It was discovered, however, that protected copper became foul quickly, i.e. pieces of weed and/or marine creatures became attached to the hull, which had a detrimental effect on the handling of the ship. The Navy Board approached Davy in 1822, asking for help. Davy conducted a number of tests in Portsmouth Dockyard, which led to the Navy Board adopting the use of Davy's "protectors". By 1824, it had become apparent that fouling of the copper bottoms was still occurring on the majority of protected ships. By the end of 1825, the Admiralty ordered the Navy Board to cease fitting the protectors to sea-going ships, and to remove those that had already been fitted. Davy's scheme was seen as a public failure, despite the fact that, as Frank A. J. L. James comments, "The somewhat ironical problem [...] was not that they were unsuccessful. They did after all preserve the copper as Davy said they would. The problem was that the protectors, on most ships, had a chemical side effect which provided nutrients for weeds, barnacles etc. thus fouling the ships".

Elections took place on St Andrew's Day and Davy was elected on 30 November 1820. Although he was unopposed, other candidates had received initial backing. These candidates embodied the factional difficulties that beset Davy's presidency and which eventually defeated him.

The Society was in transition from a club for gentlemen interested in natural philosophy, connected with the political and social elite, to an academy representing increasingly specialised sciences. The previous president, Joseph Banks, had held the post for over 40 years and had presided autocratically over what David Philip Miller calls the "Banksian Learned Empire", in which natural history was prominent.

Banks had groomed the engineer, author and politician Davies Gilbert to succeed him and preserve the status quo, but Gilbert declined to stand. Fellows who thought royal patronage was important proposed Prince Leopold of Saxe-Coburg (later Leopold I of Belgium), who also withdrew, as did the Whig Edward St Maur, 11th Duke of Somerset. Davy was the outstanding scientist but some fellows did not approve of his popularising work at the Royal Institution.

The strongest alternative had been William Hyde Wollaston, who was supported by the "Cambridge Network" of outstanding mathematicians such as Charles Babbage and John Herschel, who tried to block Davy. They were aware that Davy supported some modernisation, but thought that he would not sufficiently encourage aspiring young mathematicians, astronomers and geologists, who were beginning to form specialist societies. Davy was only 41, and reformers were fearful of another long presidency.

In his early years Davy was optimistic about reconciling the reformers and the Banksians. In his first speech as president he declared, "I trust that, with these new societies, we shall always preserve the most amicable relations... I am sure there is no desire in [the Royal Society] to exert anything like patriarchal authority in relation to these institutions".

Davy spent much time juggling the factions but, as his reputation declined in the light of failures such as his research into copper-bottomed ships, he lost popularity and authority. This was compounded by a number of political errors. In 1825 his promotion of the new Zoological Society, of which he was a founding fellow, courted the landed gentry and alienated expert zoologists. He offended the mathematicians and reformers by failing to ensure that Babbage received one of the new Royal Medals (a project of his) or the vacant secretaryship of the Society in 1826. In November 1826 the mathematician Edward Ryan recorded that: "The Society, every member almost... are in the greatest rage at the President's proceedings and nothing is now talked of but removing him."

In the event he was again re-elected unopposed, but he was now visibly unwell. In January 1827 he set off to Italy for reasons of his health. It did not improve and, as the 1827 election loomed, it was clear that he would not stand again. He was succeeded by Davies Gilbert.

In January 1819, Davy was awarded a baronetcy. Although Sir Francis Bacon (also later made a peer) and Sir Isaac Newton had already been knighted, this was, at the time, the first such honour ever conferred on a man of science in Britain. This was followed a year later with the Presidency of the Royal Society.

Davy's laboratory assistant, Michael Faraday, went on to enhance Davy's work and would become the more famous and influential scientist. Davy is supposed to have even claimed Faraday as his greatest discovery. Davy later accused Faraday of plagiarism, however, causing Faraday (the first Fullerian Professor of Chemistry) to cease all research in electromagnetism until his mentor's death.

Of a sanguine, somewhat irritable temperament, Davy displayed characteristic enthusiasm and energy in all his pursuits. As is shown by his verses and sometimes by his prose, his mind was highly imaginative; the poet Coleridge declared that if he "had not been the first chemist, he would have been the first poet of his age", and Southey said that "he had all the elements of a poet; he only wanted the art." In spite of his ungainly exterior and peculiar manner, his happy gifts of exposition and illustration won him extraordinary popularity as a lecturer, his experiments were ingenious and rapidly performed, and Coleridge went to hear him "to increase his stock of metaphors." The dominating ambition of his life was to achieve fame; occasional petty jealousy did not diminish his concern for the "cause of humanity", to use a phrase often employed by him in connection with his invention of the miners' lamp. Careless about etiquette, his frankness sometimes exposed him to annoyances he might have avoided by the exercise of tact.

According to one of Davy's biographers, June Z. Fullmer, he was a deist.
He spent the last months of his life writing "Consolations in Travel", an immensely popular, somewhat freeform compendium of poetry, thoughts on science and philosophy. Published posthumously, the work became a staple of both scientific and family libraries for several decades afterward. Davy spent the winter in Rome, hunting in the Campagna on his fiftieth birthday. But on 20 February 1829 he had another stroke. After spending many months attempting to recuperate, Davy died in a hotel room in Geneva, Switzerland, on 29 May 1829.

He had wished to be buried where he died, but had also wanted the burial delayed in case he was only comatose. He refused to allow a post-mortem for similar reasons. But the laws of Geneva did not allow any delay and he was given a public funeral on the following Monday, in the Plainpalais Cemetery, outside the city walls.




See Fullmer's work for a full list of Davy's articles.

Humphry Davy's books are as follows:
Davy also contributed articles on chemistry to "Rees's Cyclopædia", but the topics are not known.

His collected works were published in 1839–1840:




</doc>
<doc id="14372" url="https://en.wikipedia.org/wiki?curid=14372" title="Hecate">
Hecate

Hecate or Hekate (; , "Hekátē") is a goddess in ancient Greek religion and mythology, most often shown holding a pair of torches or a key and in later periods depicted in triple form. She was variously associated with crossroads, entrance-ways, light, magic, witchcraft, knowledge of herbs and poisonous plants, ghosts, necromancy, and sorcery. She appears in the Homeric Hymn to Demeter and in Hesiod's "Theogony", where she is promoted strongly as a great goddess. The place of origin of her following is uncertain, but it is thought that she had popular followings in Thrace. She was one of the main deities worshiped in Athenian households as a protective goddess and one who bestowed prosperity and daily blessings on the family.
In the post-Christian writings of the Chaldean Oracles (2nd–3rd century CE) she was regarded with (some) rulership over earth, sea, and sky, as well as a more universal role as Saviour (Soteira), Mother of Angels and the Cosmic World Soul.
Regarding the nature of her cult, it has been remarked, "she is more at home on the fringes than in the center of Greek polytheism. Intrinsically ambivalent and polymorphous, she straddles conventional boundaries and eludes definition."

The etymology of the name "Hecate" (Ἑκάτη, "Hekátē") is not known. 
Some suggestions derive the name from a Greek root: from ἑκών "willing" (thus, "she who works her will" or similar),
or from Ἑκατός "Hekatos", an obscure epithet of Apollo interpreted as "the far reaching one" or "the far-darter", whence for the feminine form "she that operates from afar" or "she that removes or drives off". 

R. S. P. Beekes rejected a Greek etymology and suggested a Pre-Greek origin. A possibility for foreign origin of the name may be "Heqet", name of an Egyptian goddess of fertility and childbirth.

In Early Modern English, the name was also pronounced disyllabically (as ) and sometimes spelled "Hecat". It remained common practice in English to pronounce her name in two syllables, even when spelled with final "e", well into the 19th century.

The spelling "Hecat" is due to Arthur Golding's 1567 translation of Ovid's "Metamorphoses", and this spelling without the final E later appears in plays of the Elizabethan-Jacobean period.
Webster's Dictionary of 1866 particularly credits the influence of Shakespeare for the then-predominant disyllabic pronunciation of the name.

Hecate possibly originated among the Carians of Anatolia, the region where most theophoric names invoking Hecate, such as Hecataeus or Hecatomnus, the father of Mausolus, are attested, and where Hecate remained a Great Goddess into historical times, at her unrivalled cult site in Lagina. While many researchers favor the idea that she has Anatolian origins, it has been argued that "Hecate must have been a Greek goddess." The monuments to Hecate in Phrygia and Caria are numerous but of late date.

William Berg observes, "Since children are not called after spooks, it is safe to assume that Carian theophoric names involving "hekat-" refer to a major deity free from the dark and unsavoury ties to the underworld and to witchcraft associated with the Hecate of classical Athens." In particular, there is some evidence that she might be derived from the local sun goddesses (see also Arinna), based on similar attributes. She also closely parallels the Roman goddess Trivia, with whom she was sometimes identified in Rome, although Trivia was more commonly identified with Artemis by authors such as Lucretius.

If Hecate's cult spread from Anatolia into Greece, it is possible it presented a conflict, as her role was already filled by other more prominent deities in the Greek pantheon, above all by Artemis and Selene. This line of reasoning lies behind the widely accepted hypothesis that she was a foreign deity who was incorporated into the Greek pantheon. Other than in the "Theogony", the Greek sources do not offer a consistent story of her parentage, or of her relations in the Greek pantheon: sometimes Hecate is related as a Titaness, and a mighty helper and protector of humans.

Shrines to Hecate were placed at doorways to both homes and cities with the belief that it would protect from restless dead and other spirits. Likewise, shrines to Hecate at three way crossroads were created where food offerings were left at the new moon to protect those who did so from spirits and other evils.
Dogs were sacred to Hecate and associated with roads, domestic spaces, purification, and spirits of the dead. Dogs were also sacrificed to the road.
This can be compared to Pausanias' report that in the Ionian city of Colophon in Asia Minor a sacrifice of a black female puppy was made to Hecate as "the wayside goddess", and Plutarch's observation that in Boeotia dogs were killed in purificatory rites. Dogs, with puppies often mentioned, were offered to Hecate at crossroads, which were sacred to the goddess.

Her most important sanctuary was Lagina, a theocratic city-state in which the goddess was served by eunuchs. Lagina, where the famous temple of Hecate drew great festal assemblies every year, lay close to the originally Macedonian colony of Stratonikeia, where she was the city's patroness. In Thrace she played a role similar to that of lesser-Hermes, namely a governess of liminal regions (particularly gates) and the wilderness.

As Hecate Phosphorus (Venus) she is said to have lit the sky during the Siege of Philip II in 340, revealing the attack to its inhabitants. The Byzantines dedicated a statue to her as the "lamp carrier."

There was an area sacred to Hecate in the precincts of the Temple of Artemis at Ephesus, where the priests, "megabyzi", officiated.

She was greatly worshipped in Byzantium. She was said to have saved the city from Philip II, warning the citizens of a night time attack by a light in the sky, for which she was known as "Hecate Lampadephoros". The tale is preserved in the Suda.

The Athenian Greeks honored Hekate during the Deipnon. In Greek, deipnon means the evening meal, usually the largest meal of the day. Hekate's Deipnon is, at its most basic, a meal served to Hekate and the restless dead once a lunar month during the new moon. The Deipnon is always followed the next day by the Noumenia, when the first sliver of moon is visible, and then the Agathos Daimon the day after that.

The main purpose of the Deipnon was to honor Hekate and to placate the souls in her wake who “longed for vengeance.” A secondary purpose was to purify the household and to atone for bad deeds a household member may have committed that offended Hekate, causing her to withhold her favor from them. The Deipnon consists of three main parts: 1) the meal that was set out at a crossroads, usually in a shrine outside the entryway to the home 2) an expiation sacrifice, and 3) purification of the household.

Hecate was known by a number of bynames:


Hecate was generally represented as three-formed.
This has been speculated as being connected with the appearance of the full moon, half moon, and new moon. 
As a virgin goddess, she remained unmarried and had no regular consort, though some traditions named her as the mother of Scylla.

The earliest Greek depictions of Hecate were not three-formed. Farnell states: "The evidence of the monuments as to the character and significance of Hecate is almost as full as that of to express her manifold and mystic nature."
The earliest known monument is a small terracotta found in Athens, with a dedication to Hecate, in writing of the style of the 6th century. The goddess is seated on a throne with a chaplet bound round her head; she is altogether without attributes and character, and the main historical value of this work, which is evidently of quite a general type and gets a special reference and name merely from the inscription, is that it proves the single shape to be her earlier form, and her recognition at Athens to be earlier than the Persian invasion.
The 2nd-century travel writer Pausanias stated that Hecate was first depicted in triplicate by the sculptor Alkamenes in the Greek Classical period of the late 5th century BCE which was placed before the temple of the Wingless Nike in Athens. Greek anthropomorphic conventions of art resisted representing her with three faces: a votive sculpture from Attica of the 3rd century BCE ("illustration, left"), shows three single images against a column; round the column of Hecate dance the Charites. Some classical portrayals show her as a triplicate goddess holding a torch, a key, serpents, daggers and numerous other items. Depictions of both a single form Hekate and triple formed, as well as occasional four headed descriptions continued throughout her history.

In Egyptian-inspired Greek esoteric writings connected with Hermes Trismegistus, and in magical papyri of Late Antiquity she is described as having three heads: one dog, one serpent, and one horse. In other representations her animal heads include those of a cow and a boar. Hecate's triplicity is elsewhere expressed in a more Hellenic fashion in the vast frieze of the great Pergamon Altar, now in Berlin, wherein she is shown with three bodies, taking part in the battle with the Titans. In the Argolid, near the shrine of the Dioscuri, Pausanias saw the temple of Hecate opposite the sanctuary of Eileithyia; He reported the image to be the work of Scopas, stating further, "This one is of stone, while the bronze images opposite, also of Hecate, were made respectively by Polycleitus and his brother Naucydes, son of Mothon." ("Description of Greece" 2.22.7)

In the "Argonautica", a 3rd-century BCE Alexandrian epic based on early material, Jason placates Hecate in a ritual prescribed by Medea, her priestess: bathed at midnight in a stream of flowing water, and dressed in dark robes, Jason is to dig a round pit and over it cut the throat of an ewe, sacrificing it and then burning it whole on a pyre next to the pit as a holocaust. He is told to sweeten the offering with a libation of honey, then to retreat from the site without looking back, even if he hears the sound of footsteps or barking dogs. All these elements betoken the rites owed to a chthonic deity.

A 4th-century BCE marble relief from Crannon in Thessaly was dedicated by a race-horse owner. 
It shows Hecate, with a hound beside her, placing a wreath on the head of a mare. She is commonly attended by a dog or dogs, and the most common form of offering was to leave meat at a crossroads. Images of her attended by a dog are also found at times when she is shown as in her role as mother goddess with child, and when she is depicted alongside the god Hermes and the goddess Kybele in reliefs.

Dogs were closely associated with Hecate in the Classical world. "In art and in literature Hecate is constantly represented as dog-shaped or as accompanied by a dog. Her approach was heralded by the howling of a dog. The dog was Hecate's regular sacrificial animal, and was often eaten in solemn sacrament." The sacrifice of dogs to Hecate is attested for Thrace, Samothrace, Colophon, and Athens.

It has been claimed that her association with dogs is "suggestive of her connection with birth, for the dog was sacred to Eileithyia, Genetyllis, and other birth goddesses. Although in later times Hecate's dog came to be thought of as a manifestation of restless souls or demons who accompanied her, its docile appearance and its accompaniment of a Hecate who looks completely friendly in many pieces of ancient art suggests that its original signification was positive and thus likelier to have arisen from the dog's connection with birth than the dog's underworld associations." The association with dogs, particularly female dogs, could be explained by a metamorphosis myth. The friendly looking female dog accompanying Hecate was originally the Trojan Queen Hekabe, who leapt into the sea after the fall of Troy and was transformed by Hecate into her familiar.

Another metamorphosis myth explains why the polecat is also associated with Hecate. From Antoninus Liberalis:
"At Thebes Proitos had a daughter Galinthias. This maiden was playmate and companion of Alkmene, daughter of Elektryon. As the birth throes for Herakles were pressing on Alkmene, the Moirai (Fates) and Eileithyia (Birth-Goddess), as a favour to Hera, kept Alkmene in continuous birth pangs. They remained seated, each keeping their arms crossed. Galinthias, fearing that the pains of her labour would drive Alkmene mad, ran to the Moirai and Eleithyia and announced that by desire of Zeus a boy had been born to Alkmene and that their prerogatives had been abolished.

At all this, consternation of course overcame the Moirai and they immediately let go their arms. Alkmene’s pangs ceased at once and Herakles was born. The Moirai were aggrieved at this and took away the womanly parts of Galinthias since, being but a mortal, she had deceived the gods. They turned her into a deceitful weasel (or polecat), making her live in crannies and gave her a grotesque way of mating. She is mounted through the ears and gives birth by bringing forth her young through the throat. Hekate felt sorry for this transformation of her appearance and appointed her a sacred servant of herself."

Aelian told a different story of a woman transformed into a polecat: ""I have heard that the polecat was once a human being. It has also reached my hearing that Gale was her name then; that she was a dealer in spells and a sorceress (Pharmakis); that she was extremely incontinent, and that she was afflicted with abnormal sexual desires. Nor has it escaped my notice that the anger of the goddess Hekate transformed it into this evil creature. May the goddess be gracious to me : fables and their telling I leave to others."

Athenaeus (writing in the 1st or 2nd century BCE, and drawing on the etymological speculation of Apollodorus of Athens) notes that the red mullet is sacred to Hecate, "on account of the resemblance of their names; for that the goddess is "trimorphos", of a triple form". The Greek word for mullet was "trigle" and later "trigla". He goes on to quote a fragment of verse "O mistress Hecate, Trioditis / With three forms and three faces / Propitiated with mullets". In relation to Greek concepts of pollution, Parker observes, "The fish that was most commonly banned was the red mullet ("trigle"), which fits neatly into the pattern. It 'delighted in polluted things,' and 'would eat the corpse of a fish or a man'. Blood-coloured itself, it was sacred to the blood-eating goddess Hecate. It seems a symbolic summation of all the negative characteristics of the creatures of the deep." At Athens, it is said there stood a statue of Hecate "Triglathena", to whom the red mullet was offered in sacrifice. After mentioning that this fish was sacred to Hecate, Alan Davidson writes, "Cicero, Horace, Juvenal, Martial, Pliny, Seneca and Suetonius have left abundant and interesting testimony to the red mullet fever which began to affect wealthy Romans during the last years of the Republic and really gripped them in the early Empire. The main symptoms were a preoccupation with size, the consequent rise to absurd heights of the prices of large specimens, a habit of keeping red mullet in captivity, and the enjoyment of the highly specialized aesthetic experience induced by watching the color of the dying fish change."

The frog, which was also the symbol of the similarly-named Egyptian goddess Heqet, has also become sacred to Hecate in modern Pagan literature, possibly due in part to its ability to cross between two elements.

In her three-headed representations, discussed above, Hecate often has one or more animal heads, including cow, dog, boar, serpent and horse.

Hecate was closely associated with plant lore and the concoction of medicines and poisons. In particular she was thought to give instruction in these closely related arts. Apollonius of Rhodes, in the "Argonautica" mentions that Medea was taught by Hecate, "I have mentioned to you before a certain young girl whom Hecate, daughter of Perses, has taught to work in drugs."

The goddess is described as wearing oak in fragments of Sophocles' lost play "The Root Diggers" (or "The Root Cutters"), and an ancient commentary on Apollonius of Rhodes' Argonautica (3.1214) describes her as having a head surrounded by serpents, twining through branches of oak.

The yew in particular was sacred to Hecate.
"Greeks held the yew to be sacred to Hecate... Her attendants draped wreathes of yew around the necks of black bulls which they slaughtered in her honor and yew boughs were burned on funeral pyres. The yew was associated with the alphabet and the scientific name for yew today, "taxus", was probably derived from the Greek word for yew, "toxos", which is hauntingly similar to "toxon", their word for bow and "toxicon", their word for poison. It is presumed that the latter were named after the tree because of its superiority for both bows and poison."
Hecate was said to favor offerings of garlic, which was closely associated with her cult. She is also sometimes associated with cypress, a tree symbolic of death and the underworld, and hence sacred to a number of chthonic deities.

A number of other plants (often poisonous, medicinal and/or psychoactive) are associated with Hecate. These include aconite (also called "hecateis"), belladonna, dittany, and mandrake. It has been suggested that the use of dogs for digging up mandrake is further corroboration of the association of this plant with Hecate; indeed, since at least as early as the 1st century CE, there are a number of attestations to the apparently widespread practice of using dogs to dig up plants associated with magic.

Hecate was associated with borders, city walls, doorways, crossroads and, by extension, with realms outside or beyond the world of the living. She appears to have been particularly associated with being 'between' and hence is frequently characterized as a "liminal" goddess. "Hecate mediated between regimes—Olympian and Titan—but also between mortal and divine spheres." This liminal role is reflected in a number of her cult titles: "Apotropaia" (that turns away/protects); "Enodia" (on the way); "Propulaia"/"Propylaia" (before the gate); "Triodia"/"Trioditis" (who frequents crossroads); "Klêidouchos" (holding the keys), etc.
As a goddess expected to avert harmful or destructive spirits from the house or city over which she stood guard and to protect the individual as she or he passed through dangerous liminal places, Hecate would naturally become known as a goddess who could also "refuse" to avert the demons, or even drive them on against unfortunate individuals.

It was probably her role as guardian of entrances that led to Hecate's identification by the mid fifth century with Enodia, a Thessalian goddess. Enodia's very name ("In-the-Road") suggests that she watched over entrances, for it expresses both the possibility that she stood on the main road into a city, keeping an eye on all who entered, and in the road in front of private houses, protecting their inhabitants.
This function would appear to have some relationship with the iconographic association of Hecate with keys, and might also relate to her appearance with two torches, which when positioned on either side of a gate or door illuminated the immediate area and allowed visitors to be identified. "In Byzantium small temples in her honor were placed close to the gates of the city. Hecate's importance to Byzantium was above all as a deity of protection. When Philip of Macedon was about to attack the city, according to the legend she alerted the townspeople with her ever present torches, and with her pack of dogs, which served as her constant companions." This suggests that Hecate's close association with dogs derived in part from the use of watchdogs, who, particularly at night, raised an alarm when intruders approached. Watchdogs were used extensively by Greeks and Romans.

Cult images and altars of Hecate in her triplicate or trimorphic form were placed at three-way crossroads (though they also appeared before private homes and in front of city gates). In this form she came to be known as the goddess Trivia ("the three ways") in Roman mythology. In what appears to be a 7th-century indication of the survival of cult practices of this general sort, Saint Eligius, in his "Sermo" warns the sick among his recently converted flock in Flanders against putting "devilish charms at springs or trees or crossroads", and, according to Saint Ouen would urge them "No Christian should make or render any devotion to the deities of the trivium, where three roads meet...".

Like Hecate, "[t]he dog is a creature of the threshold, the guardian of doors and portals, and so it is appropriately associated with the frontier between life and death, and with demons and ghosts which move across the frontier. The yawning gates of Hades were guarded by the monstrous watchdog Cerberus, whose function was to prevent the living from entering the underworld, and the dead from leaving it."

Hecate has been characterized as a pre-Olympian chthonic goddess.
The first literature mentioning Hecate is the "Theogony" by Hesiod:
According to Hesiod, she held sway over many things:
Hesiod emphasizes that Hecate was an only child, the daughter of Perses and Asteria, the sister of Leto (the mother of Artemis and Apollo). Grandmother of the three cousins was Phoebe the ancient Titaness who personified the moon.

Hesiod's inclusion and praise of Hecate in the "Theogony" has been troublesome for scholars, in that he seems to hold her in high regard, while the testimony of other writers, and surviving evidence, suggests that this may have been the exception. One theory is that Hesiod's original village had a substantial Hecate following and that his inclusion of her in the "Theogony" was a way of adding to her prestige by spreading word of her among his readers. Another theory is that Hekate was mainly a household god and humble household worship could have been more pervasive and yet not mentioned as much as temple worship. In Athens Hecate, along with Zeus, Hermes, Hestia, and Apollo, were very important in daily life as they were the main gods of the household. However, it is clear that the special position given to Hecate by Zeus is upheld throughout her history by depictions found on coins depicting Hecate on the hand of Zeus as highlighted in more recent research presented by d'Este and Rankine.

In the Homeric Hymn to Demeter, Hecate is called the "tender-hearted", a euphemism perhaps intended to emphasize her concern with the disappearance of Persephone, when she assisted Demeter with her search for Persephone following her abduction by Hades, suggesting that Demeter should speak to the god of the sun, Helios. Subsequently she became Persephone's companion on her yearly journey to and from the realms of Hades; serving as a psychopomp. Because of this association, Hecate was one of the chief goddesses of the Eleusinian Mysteries, alongside Demeter and Persephone.

Variations in interpretations of Hecate's role or roles can be traced in classical Athens. In two fragments of Aeschylus she appears as a great goddess. In Sophocles and Euripides she is characterized as the mistress of witchcraft and the Keres.

One surviving group of stories suggests how Hecate might have come to be incorporated into the Greek pantheon without affecting the privileged position of Artemis. Here, Hecate is a mortal priestess often associated with Iphigeneia. She scorns and insults Artemis, who in retribution eventually brings about the mortal's suicide.

Hecate is the primary feminine figure in the "Chaldean Oracles" (2nd-3rd century CE), where she is associated in fragment 194 with a "strophalos" (usually translated as a spinning top, or wheel, used in magic) "Labour thou around the Strophalos of Hecate." This appears to refer to a variant of the device mentioned by Psellus.

In Hellenistic syncretism, Hecate also became closely associated with Isis.
Lucius Apuleius in "The Golden Ass" (2nd century) equates Juno, Bellona, Hecate and Isis

In the syncretism during Late Antiquity of Hellenistic and late Babylonian ("Chaldean") elements, Hecate was identified with Ereshkigal, the underworld counterpart of Inanna in the Babylonian cosmography. In the Michigan magical papyrus (inv. 7), dated to the late 3rd or early 4th century CE, "Hecate Ereschigal" is invoked against fear of punishment in the afterlife.

Strmiska (2005) claims that Hecate, conflated with the figure of Diana, appears in late antiquity and in the early medieval period as part of an "emerging legend complex" associated with gatherings of women, the moon, and witchcraft that eventually became established "in the area of Northern Italy, southern Germany, and the western Balkans." 
This theory of the Roman origins of many European folk traditions related to Diana or Hecate was explicitly advanced at least as early as 1807 and is reflected in etymological claims by early modern lexicographers from the 17th to the 19th century, connecting "hag, hexe" "witch" to the name of Hecate. Such derivations are today proposed only by a minority 
A medieval commentator has suggested a link connecting the word "jinx" with Hecate: "The Byzantine polymath Michael Psellus [...] speaks of a bullroarer, consisting of a golden sphere, decorated throughout with symbols and whirled on an oxhide thong. He adds that such an instrument is called a "iunx" (hence "jinx"), but as for the significance says only that it is ineffable and that the ritual is sacred to Hecate."

Shakespeare mentions Hecate both before the end of the 16th century (A Midsummer Night's Dream, 1594-96), and just after, in Macbeth (1605): specifically, in the title character's "dagger" soliloquy: "Witchcraft celebrates pale Hecate's offerings..." 

In 1929, Lewis Brown, an expert on religious cults, connected the 1920s Blackburn Cult (also known as, "The Cult of the Great Eleven,") with Hecate worship rituals. He noted that the cult regularly practiced dog sacrifice and had secretly buried the body of one of its "queens" with seven dogs. Researcher Samuel Fort noted additional parallels, to include the cult’s focus on mystic and typically nocturnal rites, its female dominated membership, the sacrifice of other animals (to include horses and mules), a focus on the mystical properties of roads and portals, and an emphasis on death, healing, and resurrection.

As a "goddess of witchcraft", Hecate has been incorporated in various systems of modern witchcraft, Wicca and Neopaganism,
in some cases associated with the Wild Hunt of Germanic tradition, 
in others as part of a reconstruction of specifically Greek polytheism, in English also known as "Hellenismos".
In Wicca, Hecate has in some cases become identified with the "Crone" aspect of the "Triple Goddess".

Hecate is also the namesake of the hundredth numbered asteroid, which was discovered by American astronomer James Craig Watson on July 11, 1868. Its adopted name alludes to it as being the hundredth named asteroid ('hekaton' being the Greek for 'hundred').






</doc>
<doc id="14374" url="https://en.wikipedia.org/wiki?curid=14374" title="Haematopoiesis">
Haematopoiesis

Haematopoiesis (from Greek αἷμα, "blood" and ποιεῖν "to make"; also hematopoiesis in American English; sometimes also haemopoiesis or hemopoiesis) is the formation of blood cellular components. All cellular blood components are derived from haematopoietic stem cells.<ref name="Birbrair n/a–n/a"></ref> In a healthy adult person, approximately 10–10 new blood cells are produced daily in order to maintain steady state levels in the peripheral circulation.

Haematopoietic stem cells (HSCs) reside in the medulla of the bone (bone marrow) and have the unique ability to give rise to all of the different mature blood cell types and tissues. HSCs are self-renewing cells: when they differentiate, at least some of their daughter cells remain as HSCs, so the pool of stem cells is not depleted.This phenomenon is called asymmetric division. The other daughters of HSCs (myeloid and lymphoid progenitor cells) can follow any of the other differentiation pathways that lead to the production of one or more specific types of blood cell, but cannot renew themselves. The pool of progenitors is heterogeneous and can be divided into two groups; long-term self-renewing HSC and only transiently self-renewing HSC, also called short-terms. This is one of the main vital processes in the body.

All blood cells are divided into three lineages. 

Granulopoiesis (or granulocytopoiesis) is haematopoiesis of granulocytes, except of mast cells which are granulocytes but with an extramedullar maturation.

Megakaryocytopoiesis is haematopoiesis of megakaryocytes.

In developing embryos, blood formation occurs in aggregates of blood cells in the yolk sac, called blood islands. As development progresses, blood formation occurs in the spleen, liver and lymph nodes. When bone marrow develops, it eventually assumes the task of forming most of the blood cells for the entire organism. However, maturation, activation, and some proliferation of lymphoid cells occurs in the spleen, thymus, and lymph nodes. In children, haematopoiesis occurs in the marrow of the long bones such as the femur and tibia. In adults, it occurs mainly in the pelvis, cranium, vertebrae, and sternum.

In some cases, the liver, thymus, and spleen may resume their haematopoietic function, if necessary. This is called "extramedullary haematopoiesis". It may cause these organs to increase in size substantially. 
During fetal development, since bones and thus the bone marrow develop later, the liver functions as the main haematopoetic organ. Therefore, the liver is enlarged during development.

In some vertebrates, haematopoiesis can occur wherever there is a loose stroma of connective tissue and slow blood supply, such as the gut, spleen or kidney.

As a stem cell matures it undergoes changes in gene expression that limit the cell types that it can become and moves it closer to a specific cell type (cellular differentiation). These changes can often be tracked by monitoring the presence of proteins on the surface of the cell. Each successive change moves the cell closer to the final cell type and further limits its potential to become a different cell type.

Two models for hematopoiesis have been proposed: determinism and stochastic theory. For the stem cells and other undifferentiated blood cells in the bone marrow, the determination is generally explained by the "determinism" theory of haematopoiesis, saying that colony stimulating factors and other factors of the haematopoietic microenvironment determine the cells to follow a certain path of cell differentiation. This is the classical way of describing haematopoiesis. In "stochastic" "theory," undifferentiated blood cells differentiate to specific cell types by randomness. This theory has been supported by experiments showing that within a population of mouse haematopoietic progenitor cells, underlying stochastic variability in the distribution of Sca-1, a stem cell factor, subdivides the population into groups exhibiting variable rates of cellular differentiation. For example, under the influence of erythropoietin (an erythrocyte-differentiation factor), a subpopulation of cells (as defined by the levels of Sca-1) differentiated into erythrocytes at a sevenfold higher rate than the rest of the population. Furthermore, it was shown that if allowed to grow, this subpopulation re-established the original subpopulation of cells, supporting the theory that this is a stochastic, reversible process. Another level at which stochasticity may be important is in the process of apoptosis and self-renewal. In this case, the haematopoietic microenvironment prevails upon some of the cells to survive and some, on the other hand, to perform apoptosis and die. By regulating this balance between different cell types, the bone marrow can alter the quantity of different cells to ultimately be produced.

Red and white blood cell production is regulated with great precision in healthy humans, and the production of leukocytes is rapidly increased during infection. The proliferation and self-renewal of these cells depend on growth factors. One of the key players in self-renewal and development of haematopoietic cells is stem cell factor (SCF), which binds to the c-kit receptor on the HSC. Absence of SCF is lethal. There are other important glycoprotein growth factors which regulate the proliferation and maturation, such as interleukins IL-2, IL-3, IL-6, IL-7. Other factors, termed colony-stimulating factors (CSFs), specifically stimulate the production of committed cells. Three CSFs are granulocyte-macrophage CSF (GM-CSF), granulocyte CSF (G-CSF) and macrophage CSF (M-CSF). 
These stimulate granulocyte formation and are active on either progenitor cells or end product cells.

Erythropoietin is required for a myeloid progenitor cell to become an erythrocyte. On the other hand, thrombopoietin makes myeloid progenitor cells differentiate to megakaryocytes (thrombocyte-forming cells).
The diagram to the right provides examples of cytokines and the differentiated blood cells they give rise to.

Growth factors initiate signal transduction pathways, which lead to activation of transcription factors. Growth factors elicit different outcomes depending on the combination of factors and the cell's stage of differentiation. For example, long-term expression of PU.1 results in myeloid commitment, and short-term induction of PU.1 activity leads to the formation of immature eosinophils. Recently, it was reported that transcription factors such as NF-κB can be regulated by microRNAs (e.g., miR-125b) in haematopoiesis.

The first key player of differentiation from HSC to a multipotent progenitor (MPP) is transcription factor CCAAT-enhancer binding protein α (C/EBPα). Mutations in C/EBPα are associated with acute myeloid leukaemia. From this point, cells can either differentiate along the Erythroid-megakaryocyte lineage or lymphoid and myeloid lineage, which have common progenitor, called lymphoid-primed multipotent progenitor. There are two main transcription factors. PU.1 for Erythroid-megakaryocyte lineage and GATA-1, which leads to a lymphoid-primed multipotent progenitor.

Other transcription factors include Ikaros (B cell development), and Gfi1 (promotes Th2 development and inhibits Th1) or IRF8 (basophils and mast cells). Significantly, certain factors elicit different responses at different stages in the haematopoiesis. For example, CEBPα in neutrophil development or PU.1 in monocytes and dendritic cell development. It is important to note that processes are not unidirectional: differentiated cells may regain attributes of progenitor cells.

An example is PAX5 factor, which is important in B cell development and associated with lymphomas. Surprisingly, pax5 conditional knock out mice allowed peripheral mature B cells to de-differentiate to early bone marrow progenitors. These findings show that transcription factors act as caretakers of differentiation level and not only as initiators.

Mutations in transcription factors are tightly connected to blood cancers, as acute myeloid leukaemia (AML) or acute lymphoblastic leukemia (ALL). For example, Ikaros is known to be regulator of numerous biological events. Mice with no Ikaros lack B cells, Natural killer and T cells. Ikaros has six zinc fingers domains, four are conserved DNA-binding domain and two are for dimerization. Very important finding is, that different zinc fingers are involved in binding to different place in DNA and this is the reason for pleiotropic effect of Ikaros and different involvement in cancer, but mainly are mutations associated with BCR-Abl patients and it is bad prognostic marker.

For a decade now, the evidence is growing that HSC maturation follows a myeloid-based model instead of the 'classical' schoolbook dichotomy model. In the latter model, the HSC first generates a common myeloid-erythroid progenitor (CMEP) and a common lymphoid progenitor (CLP). The CLP produces only T or B cells. The myeloid-based model postulates that HSCs first diverge into the CMEP and a common myelo-lymphoid progenitor (CMLP), which generates T and B cell progenitors through a bipotential myeloid-T progenitor and a myeloid-B progenitor stage. The main difference is that in this new model, all erythroid, T and B lineage branches retain the potential to generate myeloid cells (even after the segregation of T and B cell lineages). The model proposes the idea of erythroid, T and B cells as specialized types of a prototypic myeloid HSC.




</doc>
<doc id="14375" url="https://en.wikipedia.org/wiki?curid=14375" title="Hogmanay">
Hogmanay

Hogmanay (; ) is the Scots word for the last day of the year and is synonymous with the celebration of the New Year (Gregorian calendar) in the Scottish manner. It is normally followed by further celebration on the morning of New Year's Day (1 January) or, in some cases, 2 January—a Scottish bank holiday.

The origins of Hogmanay are unclear, but it may be derived from Norse and Gaelic observances. Customs vary throughout Scotland, and usually include gift-giving and visiting the homes of friends and neighbours, with special attention given to the first-foot, the first guest of the new year.

The etymology of the word is obscure. The earliest proposed etymology comes from the 1693 "Scotch Presbyterian Eloquence", which held that the term was a corruption of the Greek "" (), or "holy month". The three main modern theories derive it from a French, Norse or Gaelic root.

The word is first recorded in a Latin entry in 1443 annals as "hagnonayse". The first appearance in English came in 1604 in the records of Elgin, as "hagmonay". Subsequent 17th-century spellings include "Hagmena" (1677), "Hogmynae night" (1681), and "Hagmane" (1693) in an entry of the "Scotch Presbyterian Eloquence".

Although "Hogmanay" is currently the predominant spelling and pronunciation, a number of variant spellings and pronunciations have been recorded, including:


with the first syllable variously being , , , or .

It may have been introduced to Middle Scots via French. The most commonly cited explanation is a derivation from the northern French dialectal word "hoguinané", or variants such as "hoginane", "hoginono" and "hoguinettes", those being derived from 16th century Middle French "aguillanneuf" meaning either a gift given at New Year, a children's cry for such a gift, or New Year's Eve itself. Compare also the apparent Spanish cognate "aguinaldo/aguilando", with a suggested Latin derivation of " "in this year."

This explanation is supported by a children's tradition, observed up to the 1960s in some parts of Scotland at least, of visiting houses in their locality on New Year's Eve and requesting and receiving small treats such as sweets or fruit. The second element would appear to be " (the New Year), with some sources suggesting a druidical origin of the practice overall. Compare those to Norman "hoguinané" and the obsolete customs in Jersey of crying "ma hodgîngnole", and in Guernsey of asking for an "oguinane", for a New Year gift (see also La Guiannee). In Québec, "la guignolée" was a door-to-door collection for the poor.

Other suggestions include "au gui mener" ("lead to the mistletoe"), "à mener" ('bring to the beggars'), "au gui l'an neuf" ('at the mistletoe the new year', or "(l')homme est né" ('(the) man is born').

The word may have come from the Goidelic languages. Frazer and Kelley report a Manx new-year song that begins with the line "To-night is New Year's Night, Hogunnaa" but did not record the full text in Manx. Kelley himself uses the spelling "Og-u-naa... Tro-la-la" whereas other sources parse this as "hog-un-naa" and give the modern Manx form as "Hob dy naa". Manx dictionaries though give "Hop-tu-Naa" (), generally glossing it as "Hallowe'en", same as many of the more Manx-specific folklore collections.

In this context it is also recorded that in the south of Scotland (for example Roxburghshire), there is no , the word thus being "Hunganay", which could suggest the is intrusive.

Another theory occasionally encountered is a derivation from the phrase "thog mi an èigh/eugh" (, "I raised the cry"), which resembles "Hogmanay" in pronunciation and was part of the rhymes traditionally recited at New Year but it is unclear if this is simply a case of folk etymology.

Overall, Gaelic consistently refers to the New Year's Eve as "Oidhche na Bliadhn(a) Ùir(e)" ("the Night of the New Year") and "Oidhche Challainn" ("the Night of the Calends").

Some authors reject both the French and Goidelic theories, and instead suggest that the ultimate source both for the Norman French, Scots, and Goidelic variants of this word have a common Norse root. It is suggested that the full forms
invoke the hill-men (Icelandic "haugmenn", cf Anglo-Saxon "hoghmen") or "elves" and banishes the trolls into the sea (Norse "á læ" "into the sea"). Repp furthermore makes a link between "Trollalay/Trolla-laa" and the rhyme recorded in "Percy's Relics": "Trolle on away, trolle on awaye. Synge heave and howe rombelowe trolle on away", which he reads as a straightforward invocation of troll-banning.

The roots of Hogmanay perhaps reach back to the celebration of the winter solstice among the Norse, as well as incorporating customs from the Gaelic celebration of Samhain. The Vikings celebrated Yule, which later contributed to the Twelve Days of Christmas, or the "Daft Days" as they were sometimes called in Scotland. Christmas was not celebrated as a festival and Hogmanay was the more traditional celebration in Scotland. This may have been a result of the Protestant Reformation after which Christmas was seen as "too Papist".

There are many customs, both national and local, associated with Hogmanay. The most widespread national custom is the practice of first-footing, which starts immediately after midnight. This involves being the first person to cross the threshold of a friend or neighbour and often involves the giving of symbolic gifts such as salt (less common today), coal, shortbread, whisky, and black bun (a rich fruit cake), intended to bring different kinds of luck to the householder. Food and drink (as the gifts) are then given to the guests. This may go on throughout the early hours of the morning and well into the next day (although modern days see people visiting houses well into the middle of January). The first-foot is supposed to set the luck for the rest of the year. Traditionally, tall, dark-haired men are preferred as the first-foot.

Areas of Scotland often developed their own Hogmanay rituals.
An example of a local Hogmanay custom is the fireball swinging that takes place in Stonehaven, Aberdeenshire, in northeast Scotland. This involves local people making up "balls" of chicken wire filled with old newspaper, sticks, rags, and other dry flammable material up to a diameter of , each attached to about of wire, chain or nonflammable rope. As the Old Town House bell sounds to mark the new year, the balls are set alight and the swingers set off up the High Street from the Mercat Cross to the Cannon and back, swinging the burning balls around their heads as they go.

At the end of the ceremony, any fireballs that are still burning are cast into the harbour. Many people enjoy this display, and large crowds flock to see it, with 12,000 attending the 2007/2008 event. In recent years, additional attractions have been added to entertain the crowds as they wait for midnight, such as fire poi, a pipe band, street drumming and a firework display after the last fireball is cast into the sea. The festivities are now streamed live over the Internet. 
Another example of a pagan fire festival is the burning the clavie in the town of Burghead in Moray.

In the east coast fishing communities and Dundee, first-footers once carried a decorated herring. And in Falkland in Fife, local men marched in torchlight procession to the top of the Lomond Hills as midnight approached. Bakers in St Andrews baked special cakes for their Hogmanay celebration (known as "Cake Day") and distributed them to local children.

In Glasgow and the central areas of Scotland, the tradition is to hold Hogmanay parties that involve singing, dancing, eating of steak pie or stew, storytelling and drink. These usually extend into the daylight hours of 1 January.

Institutions also had their own traditions. For example, amongst the Scottish regiments, officers waited on the men at special dinners while at the bells, the Old Year is piped out of barrack gates. The sentry then challenges the new escort outside the gates: "Who goes there?" The answer is "The New Year, all's well."

An old custom in the Highlands – which has survived to a small extent and seen some degree of revival – is to celebrate Hogmanay with the "saining" (Scots for 'protecting, blessing') of the household and livestock. Early on New Year's morning, householders drink and then sprinkle 'magic water' from 'a dead and living ford' around the house (a 'dead and living ford' refers to a river ford that is routinely crossed by both the living and the dead). After the sprinkling of the water in every room, on the beds and all the inhabitants, the house is sealed up tight and branches of juniper are set on fire and carried throughout the house and byre. The juniper smoke is allowed to thoroughly fumigate the buildings until it causes sneezing and coughing among the inhabitants. Then all the doors and windows are flung open to let in the cold, fresh air of the new year. The woman of the house then administers 'a restorative' from the whisky bottle, and the household sits down to its New Year breakfast.

The Hogmanay custom of singing "Auld Lang Syne" has become common in many countries. "Auld Lang Syne" is a Scots poem by Robert Burns, based on traditional and other earlier sources. It is now common to sing this in a circle of linked arms that are crossed over one another as the clock strikes midnight for New Year's Day, though it is only intended that participants link arms at the beginning of the final verse, co-ordinating with the lines of the song that contain the lyrics to do so.

Auld Lang Syne is now sung regularly at "The Last Night of the Proms" in London by the full audience with their arms crossed over one another.

Between 1957 and 1968, a New Year's Eve television programme, "The White Heather Club", was presented to herald in the Hogmanay celebrations.
The show was presented by Andy Stewart who always began by singing "Come in, come in, it's nice to see you..." The show always ended with Andy Stewart and the cast singing, "Haste ye Back":

The performers were Jimmy Shand and band, Ian Powrie and his band, Scottish country dancers: Dixie Ingram and the Dixie Ingram Dancers, Joe Gordon Folk Four, James Urquhart, Ann & Laura Brand, Moira Anderson & Kenneth McKellar. All the male dancers and Andy Stewart wore kilts, and the female dancers wore long white dresses with tartan sashes.
Following the demise of the "White Heather Club", Andy Stewart continued to feature regularly in TV Hogmanay shows until his retirement. His last appearance was in 1992.

In the 1980s comedian Andy Cameron presented the "Hogmanay Show" (on STV in 1983 and 1984 and from 1985 to 1990 on BBC Scotland) while Peter Morrison presented the show "A Highland Hogmanay" on STV/Grampian, axed in 1993.

For many years, a staple of New Year's Eve television programming in Scotland was the comedy sketch show "Scotch and Wry", featuring the comedian Rikki Fulton, which invariably included a hilarious monologue from him as the preternaturally gloomy Reverend I.M. Jolly.

Since 1993, the programmes that have been mainstays on BBC Scotland on Hogmanay have been "Hogmanay Live" and Jonathan Watson's football-themed sketch comedy show, "Only an Excuse?".

The 1693 "Scotch Presbyterian Eloquence" contained one of the first mentions of the holiday in official church records. Hogmanay was treated with general disapproval. Still, in Scotland Hogmanay and New Year's Day are as important as Christmas Eve and Christmas Day.

Although Christmas Day held its normal religious nature in Scotland amongst its Catholic and Episcopalian communities, the Presbyterian national church, the Church of Scotland, discouraged the celebration of Christmas for nearly 400 years; it only became a public holiday in Scotland in 1958. Conversely, 1 and 2 January are public holidays and Hogmanay still is associated with as much celebration as Christmas in Scotland. Most Scots still celebrate New Year's Day with a special dinner, usually steak pie.

As in much of the world, the largest Scottish cities – Glasgow, Edinburgh and Aberdeen – hold all-night celebrations, as do Stirling and Inverness. The Edinburgh Hogmanay celebrations are among the largest in the world. Celebrations in Edinburgh in 1996–97 were recognised by the "Guinness Book of Records" as the world's largest New Years party, with approximately 400,000 people in attendance. Numbers have since been restricted due to safety concerns.

In 2003-4 most of the organised events were cancelled at short notice due to very high winds. The Stonehaven Fireballs went ahead as planned, however, with some 6,000 people braving the stormy weather to watch 42 fireball swingers process along the High Street. Similarly, the 2006–07 celebrations in Edinburgh, Glasgow and Stirling were all cancelled on the day, again due to high winds and heavy rain. The Aberdeen celebration, however, went ahead, and was opened by the pop music group, Wet Wet Wet.

Historically, presents were given in Scotland on the first Monday of the New Year. A roast dinner would be eaten to celebrate the festival. "Handsel" was a word for gift and hence "Handsel Day". In modern Scotland this practice has died out.




</doc>
<doc id="14376" url="https://en.wikipedia.org/wiki?curid=14376" title="Hamster">
Hamster

Hamsters are rodents (order Rodentia) belonging to the subfamily Cricetinae, which contains about 25 species classified in six or seven genera. They have become established as popular small house pets, but, because they are easy to breed in captivity, hamsters are also often used as laboratory animals.

Hamsters are more crepuscular than nocturnal and, in the wild, remain underground during the day to avoid being caught by predators. They feed primarily on seeds, fruits, and vegetation, and will occasionally eat burrowing insects. As one of their more prominent characteristics, they have elongated cheek pouches extending to their shoulders, which they use to carry food back to their burrows.

Although the Syrian hamster or golden hamster ("Mesocricetus auratus") was first described scientifically by George Robert Waterhouse in 1839, researchers were not able to successfully breed and domesticate hamsters until 1939. The entire laboratory and pet populations of Syrian hamsters appear to be descendants of a single brother–sister pairing. These littermates were captured and imported in 1930 from Aleppo in Syria by Israel Aharoni, a zoologist of the University of Jerusalem. In Jerusalem, the hamsters bred very successfully. Years later, animals of this original breeding colony were exported to the USA, where Syrian hamsters became one of the most popular pets and laboratory animals. Comparative studies of domestic and wild Syrian hamsters have shown reduced genetic variability in the domestic strain. However, the differences in behavioral, chronobiological, morphometrical, hematological, and biochemical parameters are relatively small and fall into the expected range of interstrain variations in other laboratory animals.

In 1774, Friedrich Gabriel Sulzer, a companion of Johann-Wolfgang von Goethe, devoted an academic monograph in the domain of social sciences and natural history to hamsters, entitled "An approach to a natural history of the hamster" (""Versuch einer Naturgeschichte des Hamsters""). In several instances, he used the hamster to document the equal rights of all beings, including "Homo sapiens".

The name "hamster" is a loanword from the German, which itself derives from earlier Middle High German "hamastra". It is possibly related to Old Church Slavonic "khomestoru", which is either a blend of the root of Russian хомяк ("khomyak") "hamster" and a Baltic word (cf. Lithuanian "staras" "hamster"); or of Persian origin (cf. Av "hamaēstar" "oppressor").

Hamsters are typically stout-bodied, with tails shorter than body length, and have small, furry ears, short, stocky legs, and wide feet. They have thick, silky fur, which can be long or short, colored black, grey, honey, white, brown, yellow, red, or a mix, depending on the species. Two species of hamster belonging to the genus "Phodopus", Campbell's dwarf hamster ("P. campbelli") and the Djungarian hamster ("P. sungorus"), and two of the genus "Cricetulus", the Chinese striped hamster ("C. barabensis") and the Chinese hamster ("C. griseus") have a dark stripe down their heads to their tails. The species of genus "Phodopus" are the smallest, with bodies long; the largest is the European hamster ("Cricetus cricetus"), measuring up to long, not including a short tail of up to .
The hamster tail can be difficult to see, as it is usually not very long (about 1/6 the length of the body), with the exception of the Chinese hamster, which has a tail the same length as the body. One rodent characteristic that can be highly visible in hamsters is their sharp incisors; they have an upper pair and lower pair which grow continuously throughout life, so must be regularly worn down. Hamsters are very flexible, but their bones are somewhat fragile. They are extremely susceptible to rapid temperature changes and drafts, as well as extreme heat or cold.

Hamsters have poor eyesight; they are nearsighted and colorblind. Hamsters have scent glands on their flanks (and abdomens in Chinese and dwarf hamsters) which they rub against the substrate, leaving a scent trail. Hamsters also use their sense of smell to distinguish between the sexes, and to locate food. They are also particularly sensitive to high-pitched noises and can hear and communicate in the ultrasonic range.

Hamsters are omnivores. Although pet hamsters can survive on a diet of exclusively commercial hamster food, other items, such as vegetables, fruits, seeds, and nuts, can be given. Hamsters in the Middle East have been known to hunt in packs to find insects for food. Hamsters are hindgut fermenters and eat their own feces (coprophagy) to recover nutrients digested in the hindgut, but not absorbed.

A behavioral characteristic of hamsters is food hoarding. They carry food in their spacious cheek pouches to their underground storage chambers. When full, the cheeks can make their heads double, or even triple in size.

Most hamsters are strictly solitary. If housed together, acute and chronic stress may occur, and they may fight fiercely, sometimes fatally. Dwarf hamster species may tolerate conspecifics. Russian hamsters form close, monogamous bonds with their mates, and if separated, they may become very depressed. This happens especially in males. Males will become inactive, eat more, and even show some behavioral changes similar to some types of depression in humans. This can even cause obesity in the hamster.

Evidence conflicts as to whether hamsters are crepuscular or nocturnal. Khunen writes, "Hamsters are nocturnal rodents who are active during the night...", but others have written that because hamsters live underground during most of the day, only leaving their burrows about an hour before sundown and then returning when it gets dark, their behavior is primarily crepuscular. Fritzsche indicated although some species have been observed to show more nocturnal activity than others, they are all primarily crepuscular.

Wild Syrian hamsters are true hibernators and allow their body temperature to fall close to ambient temperature (but not below 20 °C). This kind of thermoregulation diminishes the metabolic rate to about 5% and helps the animal to considerably reduce the need for food during the winter. Hamsters may not hibernate "per se", but instead reduce the rate of a number of physiological systems, such as breathing and heart rate, for short periods of time. These periods of torpor (defined as "a state of mental or physical inactivity or insensibility") can last up 10 days.

All hamsters are excellent diggers, constructing burrows with one or more entrances, with galleries connected to chambers for nesting, food storage, and other activities. They use their fore- and hindlegs, as well as their snouts and teeth, for digging. In the wild, the burrow buffers extreme ambient temperatures, offers relatively stable climatic conditions, and protects against predators. Syrian hamsters dig their burrows generally at a depth of 0.7 m. A burrow includes a steep entrance pipe (4–5 cm in diameter), a nesting and a hoarding chamber and a blind-ending branch for urination. Laboratory hamsters have not lost their ability to dig burrows; in fact, they will do this with great vigor and skill if they are provided with the appropriate substrate.

Wild hamsters will also appropriate tunnels made by other mammals; the Djungarian hamster, for instance, uses paths and burrows of the pika.

Hamsters become fertile at different ages depending on their species. Both Syrian and Russian hamsters mature quickly and can begin reproducing at a young age (4–5 weeks), whereas Chinese hamsters will usually begin reproducing at two to three months of age, and Roborovskis at three to four months of age. The female's reproductive life lasts about 18 months, but male hamsters remain fertile much longer. Females are in estrus about every four days, which is indicated by a reddening of genital areas, a musky smell, and a hissing, squeaking vocalisation she will emit if she believes a male is nearby.

When seen from above, a sexually mature female hamster has a trim tail line; a male's tail line bulges on both sides. This might not be very visible in all species. Male hamsters typically have very large testes in relation to their body size. Before sexual maturity occurs, it is more difficult to determine a young hamster's sex. When examined, female hamsters have their anal and genital openings close together, whereas males have these two holes farther apart (the penis is usually withdrawn into the coat and thus appears as a hole or pink pimple).

Hamsters are seasonal breeders and will produce several litters a year with several pups in each litter. The breeding season is from April to October in the Northern Hemisphere, with two to five litters of one to 13 young being born after a gestation period of 16 to 23 days. Gestation lasts 16 to 18 days for Syrian hamsters, 18 to 21 days for Russian hamsters, 21 to 23 days for Chinese hamsters and 23 to 30 for Roborovski hamsters. The average litter size for Syrian hamsters is about seven pups, but can be as great as 24, which is the maximum number of pups that can be contained in the uterus. Campbell's dwarf hamsters tend to have four to eight pups in a litter, but can have up to 13. Djungarian hamsters tend to have slightly smaller litters, as do Chinese and Roborovski hamsters.

Female Chinese and Syrian hamsters are known for being aggressive toward the male if kept together for too long after mating. In some cases, male hamsters can die after being attacked by the female. If breeding hamsters, separation of the pair after mating is recommended, or they will attack each other.

Female hamsters are also particularly sensitive to disturbances while giving birth, and may even eat their own young if they think they are in danger, although sometimes they are just carrying the pups in their cheek pouches. If captive female hamsters are left for extended periods (three weeks or more) with their litter, they may cannibalize the litter, so the litter must be removed by the time the young can feed and drink independently.

Hamsters are born hairless and blind in a nest the mother will have prepared in advance. After one week, they begin to explore outside the nest. They are completely weaned after three weeks, or four for Roborovski hamsters. Most breeders will sell the hamsters to shops when they are three to nine weeks old.

Syrian hamsters typically live no more than two to three years in captivity, and less in the wild. Russian hamsters (Campbell's and Djungarian) live about two to four years in captivity, and Chinese hamsters –3 years. The smaller Roborovski hamster often lives to three years in captivity.

The best-known species of hamster is the golden or Syrian hamster ("Mesocricetus auratus"), which is the type most commonly kept as pets. It is also sometimes called a "fancy" hamster. The pet trade and fanciers have given names to several color variations, including "honey bear", "panda bear", "black bear", "European black bear", "polar bear", "teddy bear", and "Dalmatian". Several variations, including long-haired varieties, grow hair several centimeters long and often require special care. British zoologist Leonard Goodwin claimed most hamsters kept in the United Kingdom were descended from the colony he introduced for medical research purposes during the Second World War.

Other hamsters kept as pets are the various species of "dwarf hamster". Campbell's dwarf hamster ("Phodopus campbelli") is the most common—they are also sometimes called "Russian dwarfs"; however, many hamsters are from Russia, so this ambiguous name does not distinguish them from other species appropriately. The coat of the Djungarian or winter-white Russian dwarf hamster ("Phodopus sungorus") turns almost white during winter (when the hours of daylight decrease). The Roborovski hamster ("Phodopus roborovskii") is extremely small and fast, making it difficult to keep as a pet. The Chinese hamster ("Cricetulus griseus"), although not technically a true "dwarf hamster", is the only hamster with a prehensile tail (about 4 cm long)—most hamsters have very short, nonprehensile tails.

Many breeders also show their hamsters, so breed towards producing a good, healthy, show hamster with a view to keeping one or two themselves, so quality and temperament are of vital importance when planning the breeding.

A hamster show is an event in which people gather hamsters to judge them against each other. Hamster shows are also places where people share their enthusiasm for hamsters among attendees. Hamster shows feature an exhibition of the hamsters participating in the judging.

The judging of hamsters usually includes a goal of promoting hamsters which conform to natural or established varieties of hamsters. By awarding hamsters which match standard hamster types, hamster shows encourage planned and careful hamster breeding.

Taxonomists generally disagree about the most appropriate placement of the subfamily Cricetinae within the superfamily Muroidea. Some place it in a family Cricetidae that also includes voles, lemmings, and New World rats and mice; others group all these into a large family called Muridae. Their evolutionary history is recorded by 15 extinct fossil genera and extends back 11.2 million to 16.4 million years to the Middle Miocene Epoch in Europe and North Africa; in Asia it extends 6 million to 11 million years. Four of the seven living genera include extinct species. One extinct hamster of "Cricetus", for example, lived in North Africa during the Middle Miocene, but the only extant member of that genus is the European or common hamster of Eurasia.


Neumann "et al." (2006) conducted a molecular phylogenetic analysis of 12 of the above 17 species using DNA sequence from three genes: 12S rRNA, cytochrome b, and von Willebrand factor. They uncovered the following relationships:

The genus "Phodopus" was found to represent the earliest split among hamsters. Their analysis included both species. The results of another study suggest "Cricetulus kamensis" (and presumably the related "C. alticola") might belong to either this "Phodopus" group or hold a similar basal position.

The genus "Mesocricetus" also forms a clade. Their analysis included all four species, with "M. auratus" and "M. raddei" forming one subclade and "M. brandti" and "M. newtoni" another.

The remaining genera of hamsters formed a third major clade. Two of the three sampled species within "Cricetulus" represent the earliest split. This clade contains "C. barabensis" (and presumably the related "C. sokolovi") and "C. longicaudatus".

The remaining clade contains members of "Allocricetulus", "Tscherskia", "Cricetus", and "C. migratorius". "Allocricetulus" and "Cricetus" were sister taxa. "Cricetulus migratorius" was their next closest relative, and "Tscherskia" was basal.

Some similar rodents sometimes called "hamsters" are not currently classified in the hamster subfamily Cricetinae. These include the maned hamster, or crested hamster, which is really the maned rat ("Lophiomys imhausi"). Others are the mouse-like hamsters ("Calomyscus" spp.), and the white-tailed rat ("Mystromys albicaudatus").




</doc>
<doc id="14378" url="https://en.wikipedia.org/wiki?curid=14378" title="History of Finland">
History of Finland

The history of Finland begins around 9,000 BCE during the end of the last glacial period. Stone Age cultures were Kunda, Comb Ceramic, Corded Ware, Kiukainen and Pöljä cultures. The Finnish Bronze Age started in approximately 1,500 BCE and the Iron Age started in 500 BCE and lasted until 1,300 CE. Finnish Iron Age cultures can be separated into Finnish proper, Tavastian and Karelian cultures. Earliest written sources mentioning Finland start to appear from 12th Century forwards when Catholic Church started to gain foothold in Southwest Finland.

Due to the Northern Crusades and Swedish colonisation of some Finnish coastal areas, most of the region became a part of the Kingdom of Sweden and the realm of the Catholic Church from the 13th century onwards. After the Finnish War in 1809, the vast majority of the Finnish-speaking areas of Sweden were ceded to the Russian Empire (excluding the areas of modern-day Northern Sweden where Meänkieli dialects of Finnish are spoken), making this area the autonomous Grand Duchy of Finland. The Lutheran religion dominated. Finnish nationalism emerged in the 19th century. It focused on Finnish cultural traditions, folklore and mythology, including music and—especially—the highly distinctive language and lyrics associated with it. One product of this era was the Kalevala, one of the most significant works of Finnish literature. The catastrophic Finnish famine of 1866–1868 was followed by eased economic regulations and extensive emigration.

In 1917, Finland declared independence. A civil war between the Finnish Red Guards and the White Guard ensued a few months later, with the "Whites" gaining the upper hand during the springtime of 1918. After the internal affairs stabilized, the still mainly agrarian economy grew relatively quickly. Relations with the West, especially Sweden and Britain, were strong but tensions remained with the Soviet Union. During the Second World War, Finland fought twice against the Soviet Union and defended its independence in the Winter War and in the Continuation War. In the peace settlement Finland ended up ceding a large part of Karelia and some other areas to the Soviet Union. However, Finland remained an independent democracy in Northern Europe.

In the latter half of its independent history, Finland has maintained a mixed economy. Since its post-World War II economic boom in the 1970s, Finland's GDP per capita has been among the world's highest. The expanded welfare state of Finland from 1970 and 1990 increased the public sector employees and spending and the tax burden imposed on the citizens. In 1992, Finland simultaneously faced economic overheating and depressed Western, Russian, and local markets. Finland joined the European Union in 1995, and replaced the Finnish markka with the euro in 2002. According to a 2016 poll, 61% of Finns preferred not to join NATO.

If confirmed, the oldest archeological site in Finland would be the Wolf Cave in Kristinestad, in Ostrobothnia. The site would be the only pre-glacial (Neanderthal) site so far discovered in the Nordic Countries, and it is approximately 125,000 years old.

The last ice age in the area of the modern-day Finland ended c. 9000 BC. Starting about that time, people migrated to the area of Finland from the South and South-East. Their culture represented mixture of Kunda, Butovo and Veretje cultures. Same time the northern Finland was inhabitet via coast of Norway. The oldest confirmed evidence of the post-glacial human settlements in Finland are from the area of Ristola in Lahti and from Orimattila, from c. 8900 BC. Finland has been continuously inhabited at least since the end of the last ice age, up to the present. The earliest post-glacial inhabitants of the present-day area of Finland were probably mainly seasonal hunter-gatherers. Among finds is the net of Antrea, the oldest fishing net known ever to have been excavated (calibrated carbon dating: ca. 8300 BC).

By 5300 BC, pottery was present in Finland. The earliest samples belong to the Comb Ceramic Cultures, known for their distinctive decorating patterns. This marks the beginning of the neolithic period for Finland, although subsistence was still based on hunting and fishing. Extensive networks of exchange existed across Finland and northeastern Europe during the 5th millennium BC. For example, flint from Scandinavia and the Valdai Hills, amber from Scandinavia and the Baltic region, and slate from Scandinavia and Lake Onega found their way into Finnish archaeological sites, while asbestos and soap stone from Finland (e.g. the area of Saimaa) were found in other regions. Rock paintings — apparently related to shamanistic and totemistic belief systems — have been found, especially in Eastern Finland, e.g. Astuvansalmi.
Between 3500 and 2000 BC, monumental stone enclosures colloquially known as Giant's Churches () were constructed in the Ostrobothnia region. The purpose of the enclosures is unknown.

In recent years, a dig in Kierikki site north of Oulu on River Ii has changed the image of Finnish neolithic stone age culture. The site has been inhabited around the year and has traded extensively. Kierikki culture is also seen as a subtype of Comb Ceramic culture. More of the site is excavated annually.

From 3200 BC onwards, either immigrants or a strong cultural influence from south of the Gulf of Finland settled in southwestern Finland. This culture was a part of the European Battle Axe cultures, which have often been associated with the movement of the Indo-European speakers. The Battle Axe, or Cord Ceramic, culture seems to have practiced agriculture and animal husbandry outside of Finland, but the earliest confirmed traces of agriculture in Finland date later, approximately to the 2nd millennium BC. Further inland, the societies retained their hunting-gathering lifestyles for the time being.

The Battle Axe and Comb Ceramic cultures eventually merged, giving rise to the Kiukainen culture that existed between 2300 BC, and 1500 BC, and was fundamentally a comb ceramic tradition with cord ceramic characteristics.

The Bronze Age began some time after 1500 BC. The coastal regions of Finland were a part of the Nordic Bronze Culture, whereas in the inland regions the influences came from the bronze-using cultures of northern and eastern Russia.

The Iron Age in Finland is considered to last from c. 500 BC until c. 1300 AD when known official and written records of Finland become more common due to the Swedish invasions as part of the Northern Crusades in the 13th century. As the Finnish Iron Age lasted almost two millennia, it is further divided into six sub-periods:

Very few written records of Finland or its people remain in any language of the era. Primary written sources are thus mostly of foreign origin, most informative of which include Tacitus' description of "Fenni" in his "Germania", the sagas written down by Snorri Sturluson, as well as the 12th- and 13th-century ecclesiastical letters written for Finns. Numerous other sources from the Roman period onwards contain brief mentions of ancient Finnish kings and place names, as such defining Finland as a kingdom and noting the culture of its people.

Currently the oldest known Scandinavian documents mentioning a "land of the Finns" are two runestones: Söderby, Sweden, with the inscription "finlont" (U 582), and Gotland with the inscription "finlandi" (G 319) dating from the 11th century. However, as the long continuum of the Finnish Iron Age into the historical Medieval period of Europe suggests, the primary source of information of the era in Finland is based on archaeological findings and modern applications of natural scientific methods like those of DNA analysis or computer linguistics.

Production of iron during the Finnish Iron Age was adopted from the neighboring cultures in the east, west and south about the same time as the first imported iron artifacts appear. This happened almost simultaneously in various parts of the country.

The Pre-Roman period of the Finnish Iron Age is scarcest in findings, but the known ones suggest that cultural connections to other Baltic cultures were already established. for which the findings of Pernaja and Savukoski provide solid argument. Many of the era's dwelling sites are the same as those of the Neolithic. Most of the iron of the era was produced on site.

The Roman period brought along an influx of imported iron (and other) artifacts like Roman wine glasses and dippers as well as various coins of the Empire. During this period the (proto) Finnish culture stabilized on the coastal regions and larger graveyards become commonplace. The prosperity of the Finns rose to the level that the vast majority of gold treasures found within Finland date back to this period.

The Migration period saw the expansion of land cultivation inland, especially in Southern Bothnia, and the growing influence of Germanic cultures, both in artifacts like swords and other weapons and in burial customs. However most iron as well as its forging was of domestic origin, probably from bog iron.

The Merovingian period in Finland gave rise to distinctive fine crafts culture of its own, visible in the original decorations of domestically produced weapons and jewelry. Finest luxury weapons were, however, imported from Western Europe. The very first Christian burials are from the latter part of this era as well. In the Leväluhta burial findings the average height of a man was originally thought to be just 158 cm and that of a woman 147 cm. but the recent research has corrected these numbers upwards and has confirmed that the people buried in Leväluhta were of average height for the era in Europe.

Recent findings suggest that Finnish trade connections already became more active during the 8th century bringing an influx of silver onto Finnish markets. The opening of the eastern route to Constantinople via Finland's southern coastline archipelago brought Arabic and Byzantine artifacts into the excavation findings of the era.

The earliest findings of imported iron blades and local iron working appear in 500 BC. From about 50 AD, there are indications of a more intense long-distance exchange of goods in coastal Finland. Inhabitants exchanged their products, presumably mostly furs, for weapons and ornaments with the Balts and the Scandinavians as well as with the peoples along the traditional eastern trade routes. The existence of richly furnished burials, usually with weapons, suggests that there was a chiefly elite in the southern and western parts of the country. Hillforts spread over most of southern Finland at the end of the Iron and early Medieval Age. There is no commonly accepted evidence of early state formations in Finland, and the presumably Iron Age origins of urbanization are contested.

The question of the timelines for the evolution and the spreading of the current Finnish languages is controversial, and new theories challenging older ones have been introduced continuously.

It is widely believed that Finno-Ugric (or Uralic) languages were first spoken in Finland and the adjacent areas during the Comb Ceramic period, around 4000 BC at the latest. During the 2nd millennium BC these evolved — possibly under an Indo-European (most likely Baltic) influence — into proto-Sami (inland) and Proto-Finnic (coastland). However, this theory has been increasingly contested among comparative linguists. It has been suggested instead that the Finno-Ugric languages arrived in the Gulf of Finland area much later, perhaps around 2000 BC or later in the Bronze Age, as result of an early Bronze Age Uralic language expansion possibly connected to the Seima-Turbino phenomenon. This would also imply that Finno-Ugric languages in Finland were preceded by a North-Western Indo-European language, at least to the extent the latter can be associated with the Cord Ceramic culture, as well as by hitherto unknown Paleo-European languages. The center of expansion for the Proto-Finnic language is posited to have been located on the southern coast of the Gulf of Finland. The Finnish language is thought to have started to differentiate during the Iron Age starting from the earliest centuries of the Common Era.

Cultural influences from a variety of places are visible in the Finnish archaeological finds from the very first settlements onwards. For example, archaeological finds from Finnish Lapland suggest the presence of the Komsa culture from Norway. The Sujala finds, which are equal in age with the earliest Komsa artifacts, may also suggest a connection to the Swiderian culture. Southwestern Finland belonged to the Nordic Bronze Age, which may be associated with Indo-European languages, and according to Finnish Germanist Jorma Koivulehto speakers of Proto-Germanic language in particular. Artifacts found in Kalanti and the province of Satakunta, which have long been monolingually Finnish, and their place names have made several scholars argue for an existence of a proto-Germanic speaking population component a little later, during the Early and Middle Iron Age.

The Swedish colonisation of Åland Islands, Turku archipelago and Uusimaa could possibly have started in 12th century but it was in its height in 13th and 14th century, when it also affected Eastern-Uusimaa and Pohjanmaa regions. The oldest Swedish place names in Finland are from this period as well as the Swedish-speaking population of Finland.

Contact between Sweden and what is now Finland was considerable even during pre-Christian times; the Vikings were known to the Finns due to their participation in both commerce and plundering. There is possible evidence of Viking settlement in the Finnish mainland. The Åland Islands probably had Swedish settlement during the Viking Period. However, some scholars claim that the archipelago was deserted during the 11th century.
According to the archaeological finds, Christianity gained a foothold in Finland during the 11th century. According to the very few written documents that have survived, the church in Finland was still in its early development in the 12th century. Later medieval legends from late 13th century describe Swedish attempts to conquer and Christianize Finland sometime in the mid-1150s.

In the early 13th century, Bishop Thomas became the first known bishop of Finland. There were several secular powers who aimed to bring the Finnish tribes under their rule. These were Sweden, Denmark, the Republic of Novgorod in northwestern Russia, and probably the German crusading orders as well. Finns had their own chiefs, but most probably no central authority. At the time there can be seen three cultural areas or tribes in Finland: Finns, Tavastians and Karelians. Russian chronicles indicate there were several conflicts between Novgorod and the Finnic tribes from the 11th or 12th century to the early 13th century.

It was the Swedish regent, Birger Jarl, who allegedly established Swedish rule in Finland through the Second Swedish Crusade, most often dated to 1249. Eric chronicles, the only source narrating the "crusade", describes that it was aimed at Tavastians. Due to papal letter from 1237 Tavastians are known to stopped being Christian and returned to their old ethnic faith earlier. Novgorod gained control in Karelia in 1278, the region inhabited by speakers of Eastern Finnish dialects. Sweden however gained the control of Western Karelia with the Third Swedish Crusade in 1293. Western Karelians were from then on viewed as part of the western cultural sphere, while eastern Karelians turned culturally to Russia and Orthodoxy. While eastern Karelians remain linguistically and ethnically closely related to the Finns, they are considered a people of their own by most. Thus, the northern border between Catholic and Orthodox Christendom came to lie at the eastern border of what would become Finland with the Treaty of Nöteborg in 1323.

During the 13th century, Finland was integrated into medieval European civilization. The Dominican order arrived in Finland around 1249 and came to exercise huge influence there. In the early 14th century, the first documents of Finnish students at Sorbonne appear. In the southwestern part of the country, an urban settlement evolved in Turku. Turku was one of the biggest towns in the Kingdom of Sweden, and its population included German merchants and craftsmen. Otherwise the degree of urbanization was very low in medieval Finland. Southern Finland and the long coastal zone of the Bothnian Gulf had a sparse farming settlements, organized as parishes and castellanies. In the other parts of the country a small population of Sami hunters, fishermen and small-scale farmers lived. These were exploited by the Finnish and Karelian tax collectors. During the 12th and 13th centuries, great numbers of Swedish settlers moved to the southern and northwestern coasts of Finland, to the Åland Islands, and to the archipelago between Turku and the Åland Islands. In these regions, the Swedish language is widely spoken even today. Swedish came to be the language of the upper class in many other parts of Finland as well.

The name "Finland" originally signified only the southwestern province that has been known as "Finland Proper" since the 18th century. First known mention of Finland is in runestone Gs 13 from 11th century. The original Swedish name for the realm's eastern part was Österlands in plural, meaning the area of Finland proper, Tavastia and Karelia, but it was later transferred into singular form Österland (lit. Eastern Land) which was in use between 1350–1470. In the 15th century Finland began to be used synonymously with Österland. The concept of a Finnish "country" in the modern sense developed slowly from the 15th to 18th centuries.
During the 13th century, the bishopric of Turku was established. The cathedral of Turku was the center of the cult of Saint Henry, and naturally the cultural center of the bishopric. The bishop had the ecclesiastical authority over much of today's Finland and was usually the most powerful man there. Bishops were often Finns, whereas the commanders in the castles were more often Scandinavian or German noblemen. In 1362, representatives from Finland were called to participate in the elections for the king of Sweden. As such, that year is often considered when Finland was incorporated into the Kingdom of Sweden. As in the Scandinavian part of the kingdom, the gentry or (lower) nobility consisted of magnates and yeomen who could afford armament for a man and a horse; these were concentrated in the southern part of Finland.

The strong fortress of Viborg (Finnish: "Viipuri", Russian: "Vyborg") guarded the eastern border of Finland. Sweden and Novgorod signed the Treaty of Nöteborg ("Pähkinäsaari" in Finnish) in 1323, but that would not last long. In 1348 the Swedish king Magnus Eriksson staged a failed crusade against the Orthodox "heretics", managing only to alienate his supporters and ultimately lose his crown. The bones of contention between Sweden and Novgorod were the northern coastline of the Bothnian Gulf and the wilderness regions of Savo in Eastern Finland. Novgorod considered these as hunting and fishing grounds of its Karelian subjects, and protested against the slow infiltration of Catholic settlers from the West. Occasional raids and clashes between Swedes and Novgorodians occurred during the late 14th and 15th centuries, but for most of the time an uneasy peace prevailed.

During the 1380s, a civil war in the Scandinavian part of Sweden brought unrest to Finland as well. The victor of this struggle was Queen Margaret I of Denmark, who brought the three Scandinavian kingdoms of Sweden, Denmark and Norway under her rule (the "Kalmar Union") in 1389. The next 130 years or so were characterized by attempts of different Swedish factions to break out of the Union. Finland was sometimes involved in these struggles, but in general the 15th century seems to have been a relatively prosperous time, characterized by population growth and economic development. Towards the end of the 15th century, however, the situation on the eastern border became more tense. The Principality of Moscow conquered Novgorod, preparing the way for a unified Russia, and from 1495–1497 a war was fought between Sweden and Russia. The fortress-town of Viborg stood against a Russian siege; according to a contemporary legend, it was saved by a miracle.

In 1521 the Kalmar Union collapsed and Gustav Vasa became the King of Sweden. During his rule, the Swedish church was reformed. The state administration underwent extensive reforms and development too, giving it a much stronger grip on the life of local communities—and ability to collect higher taxes. Following the policies of the Reformation, in 1551 Mikael Agricola, bishop of Turku, published his translation of the New Testament into the Finnish language.

In 1550 Helsinki was founded by Gustav Vasa under the name of Helsingfors, but remained little more than a fishing village for more than two centuries.

King Gustav Vasa died in 1560 and his crown was passed to his three sons in separate turns. King Erik XIV started an era of expansion when the Swedish crown took the city of Tallinn in Estonia under its protection in 1561. This action contributed to the early stages of the Livonian War which was a warlike era which lasted for 160 years. In the first phase, Sweden fought for the lordship of Estonia and Latvia against Denmark, Poland and Russia. The common people of Finland suffered because of drafts, high taxes, and abuse by military personnel. This resulted in the Cudgel War of 1596–1597, a desperate peasant rebellion, which was suppressed brutally and bloodily. A peace treaty (the Treaty of Teusina) with Russia in 1595 moved the border of Finland further to the east and north, very roughly where the modern border lies.

An important part of the 16th century history of Finland was growth of the area settled by the farming population. The crown encouraged farmers from the province of Savonia to settle the vast wilderness regions in Middle Finland. This was done, and the original Sami population often had to leave. Some of the wilderness settled was traditional hunting and fishing territory of Karelian hunters. During the 1580s, this resulted in a bloody guerrilla warfare between the Finnish settlers and Karelians in some regions, especially in Ostrobothnia.

In 1611–1632 Sweden was ruled by King Gustavus Adolphus, whose military reforms transformed the Swedish army from a peasant militia into an efficient fighting machine, possibly the best in Europe. The conquest of Livonia was now completed, and some territories were taken from internally divided Russia in the Treaty of Stolbova. In 1630, the Swedish (and Finnish) armies marched into Central Europe, as Sweden had decided to take part in the great struggle between Protestant and Catholic forces in Germany, known as the Thirty Years' War. The Finnish light cavalry was known as the Hakkapeliitat.

After the Peace of Westphalia in 1648, the Swedish Empire was one of the most powerful countries in Europe. During the war, several important reforms had been made in Finland:
However, the high taxation, continuing wars and the cold climate (the Little Ice Age) made the Imperial era of Sweden rather gloomy times for Finnish peasants. In 1655–1660, the Northern Wars were fought, taking Finnish soldiers to the battle-fields of Livonia, Poland and Denmark. In 1676, the political system of Sweden was transformed into an absolute monarchy.

In Middle and Eastern Finland, great amounts of tar were produced for export. European nations needed this material for the maintenance of their fleets. According to some theories, the spirit of early capitalism in the tar-producing province of Ostrobothnia may have been the reason for the witch-hunt wave that happened in this region during the late 17th century. The people were developing more expectations and plans for the future, and when these were not realized, they were quick to blame witches—according to a belief system the Lutheran church had imported from Germany.

The Empire had a colony in the New World in the modern-day Delaware-Pennsylvania area between 1638–1655. At least half of the immigrants were of Finnish origin.

The 17th century was an era of very strict Lutheran orthodoxy. In 1608, the law of Moses was declared the law of the land, in addition to secular legislation. Every subject of the realm was required to confess the Lutheran faith and church attendance was mandatory. Ecclesiastical penalties were widely used. The rigorous requirements of orthodoxy were revealed in the dismissal of the Bishop of Turku, Johan Terserus, who wrote a catechism which was decreed heretical in 1664 by the theologians of the Academy of Åbo. On the other hand, the Lutheran requirement of the individual study of Bible prompted the first attempts at wide-scale education. The church required from each person a degree of literacy sufficient to read the basic texts of the Lutheran faith. Although the requirements could be fulfilled by learning the texts by heart, also the skill of reading became known among the population.

In 1696–1699, a famine caused by climate decimated Finland. A combination of an early frost, the freezing temperatures preventing grain from reaching Finnish ports, and a lackluster response from the Swedish government saw about one-third of the population die. Soon afterwards, another war determining Finland's fate began (the Great Northern War of 1700–21).

The Great Northern War (1700–1721) was devastating, as Sweden and Russia fought for control of the Baltic. Harsh conditions—worsening poverty and repeated crop failures—among peasants undermined support for the war, leading to Sweden's defeat. Finland was a battleground as both armies ravaged the countryside, leading to famine, epidemics, social disruption and the loss of nearly half the population. By 1721 only 250,000 remained. Landowners had to pay higher wages to keep their peasants. Russia was the winner, annexing the south-eastern part, including the town of Viborg, after the Treaty of Nystad. The border with Russia came to lie roughly where it returned to after World War II. Sweden's status as a European great power was forfeit, and Russia was now the leading power in the North. The absolute monarchy was ended in Sweden. During this Age of Liberty, the Parliament ruled the country, and the two parties of the Hats and Caps struggled for control leaving the lesser Court party, i.e. parliamentarians with close connections to the royal court, with little to no influence. The Caps wanted to have a peaceful relationship with Russia and were supported by many Finns, while other Finns longed for revenge and supported the Hats.

Finland by this time was depopulated, with a population in 1749 of 427,000. However, with peace the population grew rapidly, and doubled before 1800. 90% of the population were typically classified as "peasants", most being free taxed yeomen. Society was divided into four Estates: peasants (free taxed yeomen), the clergy, nobility and burghers. A minority, mostly cottagers, were estateless, and had no political representation. Forty-five percent of the male population were enfranchised with full political representation in the legislature—although clerics, nobles and townsfolk had their own chambers in the parliament, boosting their political influence and excluding the peasantry on matters of foreign policy.

The mid-18th century was a relatively good time, partly because life was now more peaceful. However, during the Lesser Wrath (1741–1742), Finland was again occupied by the Russians after the government, during a period of Hat party dominance, had made a botched attempt to reconquer the lost provinces. Instead the result of the Treaty of Åbo was that the Russian border was moved further to the west. During this time, Russian propaganda hinted at the possibility of creating a separate Finnish kingdom.

Both the ascending Russian Empire and pre-revolutionary France aspired to have Sweden as a client state. Parliamentarians and others with influence were susceptible to taking bribes which they did their best to increase. The integrity and the credibility of the political system waned, and in 1771 the young and charismatic king Gustav III staged a coup d'état, abolished parliamentarism and reinstated royal power in Sweden—more or less with the support of the parliament. In 1788, he started a new war against Russia. Despite a couple of victorious battles, the war was fruitless, managing only to bring disturbance to the economic life of Finland. The popularity of King Gustav III waned considerably. During the war, a group of officers made the famous Anjala declaration demanding peace negotiations and calling of "Riksdag" (Parliament). An interesting sideline to this process was the conspiracy of some Finnish officers, who attempted to create an independent Finnish state with Russian support. After an initial shock, Gustav III crushed this opposition. In 1789, the new constitution of Sweden strengthened the royal power further, as well as improving the status of the peasantry. However, the continuing war had to be finished without conquests—and many Swedes now considered the king as a tyrant.

With the interruption of the Gustav III's war (1788–1790), the last decades of the 18th century had been an era of development in Finland. New things were changing even everyday life, such as starting of potato farming after the 1750s. New scientific and technical inventions were seen. The first hot air balloon in Finland (and in the whole Swedish kingdom) was made in Oulu (Uleåborg) in 1784, only a year after it was invented in France. Trade increased and the peasantry was growing more affluent and self-conscious. The Age of Enlightenment's climate of broadened debate in the society on issues of politics, religion and morals would in due time highlight the problem that the overwhelming majority of Finns spoke only Finnish, but the cascade of newspapers, belles-lettres and political leaflets was almost exclusively in Swedish—when not in French.

The two Russian occupations had been harsh and were not easily forgotten. These occupations were a seed of a feeling of separateness and otherness, that in a narrow circle of scholars and intellectuals at the university in Turku was forming a sense of a separate Finnish identity representing the eastern part of the realm. The shining influence of the Russian imperial capital Saint Petersburg was also much stronger in southern Finland than in other parts of Sweden, and contacts across the new border dispersed the worst fears for the fate of the educated and trading classes under a Russian régime. At the turn of the 19th century, the Swedish-speaking educated classes of officers, clerics and civil servants were mentally well prepared for a shift of allegiance to the strong Russian Empire.

King Gustav III was assassinated in 1792, and his son Gustav IV Adolf assumed the crown after a period of regency. The new king was not a particularly talented ruler; at least not talented enough to steer his kingdom through the dangerous era of the French Revolution and Napoleonic wars.

Meanwhile, the Finnish areas belonging to Russia after the peace treaties in 1721 and 1743 (not including Ingria), called "Old Finland" were initially governed with the old Swedish laws (a not uncommon practice in the expanding Russian Empire in the 18th century). However, gradually the rulers of Russia granted large estates of land to their non-Finnish favorites, ignoring the traditional landownership and peasant freedom laws of Old Finland. There were even cases where the noblemen punished peasants corporally, for example by flogging. The overall situation caused decline in the economy and morale in Old Finland, worsened since 1797 when the area was forced to send men to the Imperial Army. The construction of military installations in the area brought thousands of non-Finnish people to the region. In 1812, after the Russian conquest of Finland, "Old Finland" was rejoined to the rest of the country but the landownership question remained a serious problem until the 1870s.

While the king of Sweden sent in his governor to rule Finland, in day to day reality the villagers ran their own affairs using traditional local assemblies (called the ting) which selected a local "lagman", or lawman, to enforce the norms. The Swedes used the parish system to collect taxes. The socken (local parish) was at once a community religious organization and a judicial district that administered the king's law. The ting participated in the taxation process; taxes were collected by the bailiff, a royal appointee.

In contrast to serfdom in Germany and Russia, the Finnish peasant was typically a freeholder who owned and controlled his small plot of land. There was no serfdom in which peasants were permanently attached to specific lands, and were ruled by the owners of that land. In Finland (and Sweden) the peasants formed one of the four estates and were represented in the parliament. Outside the political sphere, however, the peasants were considered at the bottom of the social order—just above vagabonds. The upper classes looked down on them as excessively prone to drunkenness and laziness, as clannish and untrustworthy, and especially as lacking honor and a sense of national spirit. This disdain dramatically changed in the 19th century when everyone idealised the peasant as the true carrier of Finnishness and the national ethos, as opposed to the Swedish-speaking elites.

The peasants were not passive; they were proud of their traditions and would band together and fight to uphold their traditional rights in the face of burdensome taxes from the king or new demands by the landowning nobility. The great Cudgel War in the south in 1596–1597 attacked the nobles and their new system of state feudalism; this bloody revolt was similar to other contemporary peasant wars in Europe. In the north, there was less tension between nobles and peasants and more equality among peasants, due to the practice of subdividing farms among heirs, to non farm economic activities, and to the small numbers of nobility and gentry. Often the nobles and landowners were paternalistic and helpful. The Crown usually sided with the nobles, but after the "restitution" of the 1680s it ended the practice of the nobility extracting labor from the peasants and instead began a new tax system whereby royal bureaucrats collected taxes directly from the peasants, who disliked the efficient new system. After 1800 growing population pressure resulted in larger numbers of poor crofters and landless laborers and the impoverishment of small farmers.

During the Finnish War between Sweden and Russia, Finland was again conquered by the armies of Tsar Alexander I. The four Estates of occupied Finland were assembled at the Diet of Porvoo on March 29, 1809 to pledge allegiance to Alexander I of Russia. Following the Swedish defeat in the war and the signing of the Treaty of Fredrikshamn on September 17, 1809, Finland remained a Grand Duchy in the Russian Empire until the end of 1917, with the czar as Grand Duke. Russia assigned Karelia ("Old Finland") to the Grand Duchy in 1812. During the years of Russian rule the degree of autonomy varied. Periods of censorship and political prosecution occurred, particularly in the two last decades of Russian control, but the Finnish peasantry remained free (unlike the Russian serfs) as the old Swedish law remained effective (including the relevant parts from Gustav III's Constitution of 1772). The old four-chamber Diet was re-activated in the 1860s agreeing to supplementary new legislation concerning internal affairs. In addition, Finns remained free of obligations connected to the empire, such as the duty to serve in tsarist armies, and they enjoyed certain rights that citizens from other parts of the empire did not have.

Before 1860 overseas merchant firms and the owners of landed estates had accumulated wealth that became available for industrial investments. After 1860 the government liberalized economic laws and began to build a suitable physical infrastructure of ports, railroads and telegraph lines. The domestic market was small but rapid growth took place after 1860 in export industries drawing on forest resources and mobile rural laborers. Industrialization began during the mid-19th century from forestry to industry, mining and machinery and laid the foundation of Finland's current day prosperity, even though agriculture employed a relatively large part of the population until the post–World War II era.

The beginnings of industrialism took place in Helsinki. Alfred Kihlman (1825–1904) began as a Lutheran priest and director of the elite Helsingfors boys' school, the Swedish Normal Lyceum. He became a financier and member of the diet. There was little precedent in Finland in the 1850s for raising venture capital. Kihlman was well connected and enlisted businessmen and capitalists to invest in new enterprises. In 1869, he organized a limited partnership that supported two years of developmental activities that led to the founding of the Nokia company in 1871.

After 1890 industrial productivity stagnated because entrepreneurs were unable to keep up with technological innovations made by competitors in Germany, Britain and the United States. However, Russification opened up a large Russian market especially for machinery.

The Finnish national awakening in the mid-19th century was the result of members of the Swedish-speaking upper classes deliberately choosing to promote Finnish culture and language as a means of nation building, i.e. to establish a feeling of unity among all people in Finland including (and not of least importance) between the ruling elite and the ruled peasantry. The publication in 1835 of the Finnish national epic, the Kalevala, a collection of traditional myths and legends which is the folklore of the Karelian people (the Finnic Eastern Orthodox people who inhabit the Lake Ladoga-region of eastern Finland and present-day NW Russia), stirred the nationalism that later led to Finland's independence from Russia.

Particularly following Finland's incorporation into the Swedish central administration during the 16th and 17th centuries, Swedish was spoken by about 15% of the population, especially the upper and middle classes. Swedish was the language of administration, public institutions, education and cultural life. Only the peasants spoke Finnish. The emergence of Finnish to predominance resulted from a 19th-century surge of Finnish nationalism, aided by Russian bureaucrats attempting to separate Finns from Sweden and to ensure the Finns' loyalty.

In 1863, the Finnish language gained an official position in administration. In 1892 Finnish finally became an equal official language and gained a status comparable to that of Swedish. Nevertheless, the Swedish language continued to be the language of culture, arts and business all the way to the 1920s.

Movements toward Finnish national pride, as well as liberalism in politics and economics involved ethnic and class dimensions. The nationalist movement against Russia began with the Fennoman movement led by Hegelian philosopher Johan Vilhelm Snellman in the 1830s. Snellman sought to apply philosophy to social action and moved the basis of Finnish nationalism to establishment of the language in the schools, while remaining loyal to the czar. Fennomania became the Finnish Party in the 1860s. 
Liberalism was the central issue of the 1860s to 1880s. The language issue overlapped both liberalism and nationalism, and showed some a class conflict as well, with the peasants pitted against the conservative Swedish-speaking landowners and nobles. As complications, the Finnish activists divided into "old" (no compromise on the language question and conservative nationalism) and "young" (liberation from Russia) Finns. The leading liberals were Swedish-speaking intellectuals who called for more democracy; they became the radical leaders after 1880. The liberals organized for social democracy, labor unions, farmer cooperatives, and women's rights.

Nationalism was contested by the pro-Russian element and by the internationalism of the labor movement. The result was a tendency to class conflict over nationalism, but the early 1900s the working classes split into the Valpas (class struggle emphasis) and Mäkelin (nationalist emphasis).

While the vast majority of Finns were Lutheran, there were two strains to Lutheranism that eventually merged to form the modern Finnish church. On the one hand was the high-church emphasis on ritual, with its roots in traditional peasant collective society. Paavo Ruotsalainen (1777–1852) on the other hand was a leader of the new pietism, with its subjectivity, revivalism, emphasis on personal morality, lay participation, and the social gospel. The pietism appealed to the emerging middle class. The Ecclesiastical Law of 1869 combined the two strains. Finland's political and Lutheran leaders considered both Eastern Orthodoxy and Roman Catholicism to be threats to the emerging nation. Orthodoxy was rejected as a weapon of Russification, while anti-Catholicism was long-standing. Anti-Semitism was also a factor, so the Dissenter Law of 1889 upgraded the status only of the minor Protestant sects.

Before 1790 music was found in Lutheran churches and in folk traditions. In 1790 music lovers founded the Åbo Musical Society; it gave the first major stimulus to serious music by Finnish composers. In the 1880s, new institutions, especially the Helsinki Music Institute (since 1939 called the Sibelius Academy), the Institute of Music of Helsinki University and the Helsinki Philharmonic Orchestra, integrated Finland into the mainstream of European music. By far the most influential composer was Jean Sibelius (1865–1957); he composed nearly all his music before 1930. In April 1892 Sibelius presented his new symphony 'Kullervo' in Helsinki. It featured poetry from the "Kalevala," and was celebrated by critics as truly Finnish music.

Upper and upper middle class women took the lead in the deaconess movement in Finland. Coordinated by the Lutheran church, the women undertook local charitable social work to ameliorate harsh living conditions created by peasants adjusting to city life. They promoted nursing as a suitable profession for respectable women. Their efforts helped redefine the complex relationship between private charities and the traditional state and church responsibility for social welfare. Because they volunteered without pay and emphasized motherhood and nurturing as moral values for women, they contributed to the entrenchment of what in the 20th century became widespread gender roles.

Despite certain freedoms granted to Finland, the Grand Duchy was not a democratic state. The tsar retained supreme power and ruled through the highest official in the land, the governor general, almost always a Russian 
officer. Alexander dissolved the Diet of the Four Estates shortly after convening it in 1809, and it did not meet again for half a century. The tsar's actions were in accordance with the royalist constitution Finland had inherited from Sweden. The Finns had no guarantees of liberty, but depended on the tsar's goodwill for any freedoms they enjoyed. When Alexander II, the Tsar Liberator, convened the Diet again in 1863, he did so not to fulfill any obligation but to meet growing pressures for reform within the empire as a whole. In the remaining decades of the century, the Diet enacted numerous legislative measures that modernized Finland's system of law, made its public administration more efficient, removed obstacles to commerce, and prepared the ground for the country's independence in the next century.

The policy of Russification of Finland (1899–1905 and 1908–1917, called "sortokaudet/sortovuodet" (times/years of oppression) in Finnish) was the policy of the Russian czars designed to limit the special status of the Grand Duchy of Finland and more fully integrate it politically, militarily, and culturally into the empire. Finns were strongly opposed and fought back by passive resistance and a strengthening of Finnish cultural identity. Key provisions were, first, the "February Manifesto of 1899" which asserted the imperial government's right to rule Finland without the consent of local legislative bodies; second, the "Language Manifesto of 1900" which made Russian the language of administration of Finland; and third, the conscription law of 1901 which incorporated the Finnish army into the imperial army and sent conscripts away to Russian training camps.

In 1906, as a result of the Russian Revolution of 1905 and the associated Finnish general strike of 1905, the old four-chamber Diet was replaced by a unicameral Parliament of Finland "(the "")." For the first time in Europe, universal suffrage (right to vote) and eligibility was implemented to include women: Finnish women were the first in Europe to gain full eligibility to vote; and have membership in an estate; land ownership or inherited titles were no longer required.
However, on the local level things were different, as in the municipal elections the number of votes was tied to amount of tax paid. Thus, rich people could cast a number of votes, while the poor perhaps none at all. The municipal voting system was changed to universal suffrage in 1917
when a left-wing majority was elected to Parliament.

Emigration was especially important 1890–1914, with many young men and some families headed to Finnish settlements in the United States, and also to Canada. They typically worked in lumbering and mining, and many were active in Marxist causes on the one hand, or the Finnish Evangelical Lutheran Church of America on the other. In the 21st century about 700,000 Americans and 110,000 Canadians claim Finnish ancestry.

By 2000 about 6% of the population spoke Swedish as their first language, or 300,000 people. However, since the late 20th century there has been a steady migration of older, better educated Swedish speakers to Sweden.

In the aftermath of the February Revolution in Russia, Finland received a new Senate, and a coalition Cabinet with the same power distribution as the Finnish Parliament. Based on the general election in 1916, the Social Democrats had a small majority, and the Social Democrat Oskari Tokoi became prime minister. The new Senate was willing to cooperate with the Provisional government of Russia, but no agreement was reached. Finland considered the personal union with Russia to be over after the dethroning of the Tsar—although the Finns had "de facto" recognized the Provisional government as the Tsar's successor by accepting its authority to appoint a new Governor General and Senate. They expected the Tsar's authority to be transferred to Finland's Parliament, which the Provisional government refused, suggesting instead that the question should be settled by the Russian Constituent Assembly.

For the Finnish Social Democrats it seemed as though the bourgeoisie was an obstacle on Finland's road to independence as well as on the proletariat's road to power. The non-Socialists in Tokoi's Senate were, however, more confident. They, and most of the non-Socialists in the Parliament, rejected the Social Democrats' proposal on parliamentarism (the so-called "Power Act") as being too far-reaching and provocative. The act restricted Russia's influence on domestic Finnish matters, but didn't touch the Russian government's power on matters of defence and foreign affairs. For the Russian Provisional government this was, however, far too radical, exceeding the Parliament's authority, and so the Provisional government dissolved the Parliament.

The minority of the Parliament, and of the Senate, were content. New elections promised a chance for them to gain a majority, which they were convinced would improve the chances to reach an understanding with Russia. The non-Socialists were also inclined to cooperate with the Russian Provisional government because they feared the Social Democrats' power would grow, resulting in radical reforms, such as equal suffrage in municipal elections, or a land reform. The majority had the completely opposite opinion. They didn't accept the Provisional government's right to dissolve the Parliament.

The Social Democrats held on to the Power Act and opposed the promulgation of the decree of dissolution of the Parliament, whereas the non-Socialists voted for promulgating it. The disagreement over the Power Act led to the Social Democrats leaving the Senate. When the Parliament met again after the summer recess in August 1917, only the groups supporting the Power Act were present. Russian troops took possession of the chamber, the Parliament was dissolved, and new elections were held. The result was a (small) non-Socialist majority and a purely non-Socialist Senate. The suppression of the Power Act, and the cooperation between Finnish non-Socialists and Russia provoked great bitterness among the Socialists, and had resulted in dozens of politically motivated attacks and murders.

The October Revolution of 1917 turned Finnish politics upside down. Now, the new non-Socialist majority of the Parliament desired total independence, and the Socialists came gradually to view Soviet Russia as an example to follow. On November 15, 1917, the Bolsheviks declared a general right of self-determination "for the Peoples of Russia", including the right of complete secession. On the same day the Finnish Parliament issued a declaration by which it temporarily took power in Finland.

Worried by developments in Russia and Finland, the non-Socialist Senate proposed that Parliament declare Finland's independence, which was voted by the Parliament on December 6, 1917. On December 18 (December 31 N. S.) the Soviet government issued a Decree, recognizing Finland's independence, and on December 22 (January 4, 1918 N. S.) it was approved by the highest Soviet executive body (VTsIK). Germany and the Scandinavian countries followed without delay.

Finland after 1917 was bitterly divided along social lines. The Whites consisted of the Swedish-speaking middle and upper classes and the farmers and peasantry who dominated the northern two-thirds of the land. They had a conservative outlook and rejected socialism. The Socialist-Communist Reds comprised the Finnish-speaking urban workers and the landless rural cottagers. They had a radical outlook and rejected capitalism.

From January to May 1918, Finland experienced the brief but bitter Finnish Civil War. On one side there were the "white" civil guards, who fought for the anti-Socialists. On the other side were the Red Guards, which consisted of workers and tenant farmers. The latter proclaimed a Finnish Socialist Workers' Republic. World War I was still underway and the defeat of the Red Guards was achieved with support from Imperial Germany, while Sweden remained neutral and Russia withdrew its forces. The Reds lost the war and the White peasantry rose to political leadership in the 1920s–1930s. About 37,000 men died, most of them in prisoner camps ravaged by influenza and other diseases.

After the civil war the parliament, controlled by the Whites, voted to establish a constitutional monarchy to be called the "Kingdom of Finland", with a German prince as king. However, Germany's defeat in November 1918 made the plan impossible and Finland instead became a republic, with Kaarlo Juho Ståhlberg elected as its first President in 1919. Despite the bitter civil war, and repeated threats from fascist movements, Finland became and remained a capitalist democracy under the rule of law. By contrast, nearby Estonia, in similar circumstances but without a civil war, started as a democracy and was turned into a dictatorship in 1934.

Large scale agrarian reform in the 1920s involved breaking up the large estates controlled by the old nobility and selling the land to ambitious peasants. The farmers became strong supporters of the government.

The new republic faced a dispute over the Åland Islands, which were overwhelmingly Swedish-speaking and sought retrocession to Sweden. However, as Finland was not willing to cede the islands, they were offered an autonomous status. Nevertheless, the residents did not approve the offer, and the dispute over the islands was submitted to the League of Nations. The League decided that Finland should retain sovereignty over the Åland Islands, but they should be made an autonomous province. Thus Finland was under an obligation to ensure the residents of the Åland Islands a right to maintain the Swedish language, as well as their own culture and local traditions. At the same time, an international treaty was concluded on the neutral status of Åland, under which it was prohibited to place military headquarters or forces on the islands.

Alcohol abuse had a long history, especially regarding binge drinking and public intoxication, which became a crime in 1733. In the 19th century the punishments became stiffer and stiffer, but the problem persisted. A strong abstinence movement emerged that cut consumption in half from the 1880s to the 1910s, and gave Finland the lowest drinking rate in Europe. Four attempts at instituting prohibition of alcohol during the Grand Duchy period were rejected by the czar; with the czar gone Finland enacted prohibition in 1919. Smuggling emerged and enforcement was slipshod. Criminal convictions for drunkenness went up by 500%, and violence and crime rates soared. Public opinion turned against the law, and a national plebiscite went 70% for repeal, so prohibition was ended in early 1932.

Nationalist sentiment remaining from the Civil War developed into the proto-Fascist Lapua Movement in 1929. Initially the movement gained widespread support among anti-Communist Finns, but following a failed coup attempt in 1932 it was banned and its leaders imprisoned.

In the wake of the Civil War there were many incidents along the border between Finland and Soviet Russia, such as the Aunus expedition and the Pork mutiny. Relations with the Soviets were improved after the Treaty of Tartu in 1920, in which Finland gained Petsamo, but gave up its claims on East Karelia.

Tens of thousands of radical Finns—from Finland, the United States and Canada—took up Stalin's 1923 appeal to create a new Soviet society in the Karelian Autonomous Soviet Socialist Republic (KASSR), a part of Russia.
Most were executed in the purges of the 1930s.

The Soviet Union started to tighten its policy against Finland in the 1930s, limiting the navigation of Finnish merchant ships between Lake Ladoga and the Gulf of Finland and blocking it totally in 1937.

During the Second World War, Finland fought two wars against the Soviet Union: the Winter War of 1939–1940, resulting in the loss of Finnish Karelia, and the Continuation War of 1941–1944 (with considerable support from Nazi Germany resulting in a swift invasion of neighboring areas of the Soviet Union), eventually leading to the loss of Finland's only ice-free winter harbour Petsamo. The Continuation War was, in accordance with the armistice conditions, immediately followed by the Lapland War of 1944–1945, when Finland fought the Germans to force them to withdraw from northern Finland back into Norway (then under German occupation). Finland was not occupied; its army of over 600,000 soldiers, saw only 3,500 prisoners-of-war. About 96,000 Finns lost their lives, or 2.5% of a population of 3.8 million; civilian casualties were under 2,500.

In August 1939 Nazi-Germany and the Soviet Union signed the Molotov–Ribbentrop Pact, where Finland and the Baltic states were given to the Soviet "sphere of influence". After the Invasion of Poland, the Soviet Union sent ultimatums to the Baltic countries, where it demanded military bases on their soil. The Baltic states accepted Soviet demands, and lost their independence in the summer of 1940. In October 1939, the Soviet Union sent the same kind of request to Finland, but the Finns refused to give any land areas or military bases for the usage of the Red Army. This caused the Soviet Union to start a military invasion against Finland on 30 November 1939. Soviet leaders predicted that Finland would be conquered in a couple of weeks. However, even though the Red Army had huge superiority in men, tanks, guns and airplanes, the Finns were able to defend their country for about 3.5 months and still avoid invasion successfully. The Winter War ended on 13 March 1940 with the Moscow peace treaty, in which Finland lost the Karelian Isthmus to the Soviet Union. The Winter War was a big loss of prestige for the Soviet Union, and it was expelled from the League of Nations because of the illegal attack. Finland received lots of international goodwill and material help from many countries during the war.

After the Winter War the Finnish army was exhausted, and needed recovery and support as soon as possible. The British declined to help but in autumn 1940 Nazi Germany offered weapon deals to Finland, if the Finnish government would allow German troops to travel through Finland to occupied Norway. Finland accepted, weapon deals were made and military co-operation began in December 1940.

Finland's support from, and coordination with, Nazi Germany starting during the winter of 1940–41 and made other countries considerably less sympathetic to the Finnish cause; particularly since the Continuation War led to a Finnish invasion of the Soviet Union designed not only to recover lost territory, but additionally to answer the irredentist sentiment of a Greater Finland by incorporating East Karelia, whose inhabitants were culturally related to the Finnish people, although Eastern Orthodox by religion. This invasion had caused Britain to declare war on Finland on 6 December 1941.

Finland managed to defend its democracy, contrary to most other countries within the Soviet sphere of influence, and suffered comparably limited losses in terms of civilian lives and property. It was, however, punished harsher than other German co-belligerents and allies, having to pay large reparations and resettle an eighth of its population after having lost an eighth of the territory including one of its industrial heartlands and the second-largest city of Viipuri. After the war, the Soviet government settled these gained territories with people from many different regions of the USSR, for instance from Ukraine.

The Finnish government did not participate in the systematic killing of Jews, although the country remained a "co-belligrent", a "de facto" ally of Germany until 1944. In total, eight German Jewish refugees were handed over to the German authorities. In the Tehran Conference of 1942, the leaders of the Allies agreed that Finland was fighting a separate war against the Soviet Union, and that in no way was it hostile to the Western allies. The Soviet Union was the only Allied country against which Finland had conducted military operations. Unlike any of the Axis nations, Finland was a parliamentary democracy throughout the 1939–1945 period. The commander of Finnish armed forces during the Winter War and the Continuation War, Carl Gustaf Emil Mannerheim, became the President of Finland after the war. Finland made a separate peace contract with the Soviet Union on 19 September 1944, and was the only bordering country of USSR in Europe that kept its independence after the war.

During and in between the wars, approximately 80,000 Finnish war-children were evacuated abroad: 5% went to Norway, 10% to Denmark, and the rest to Sweden. Most of the children were sent back by 1948, but 15–20% remained abroad.

The Moscow Armistice was signed between Finland on one side and the Soviet Union and Britain on the other side on September 19, 1944, ending the Continuation War. The armistice compelled Finland to drive German troops from its territory, leading to the Lapland War 1944–1945.

In 1947, Finland reluctantly declined Marshall aid in order to preserve good relations with the Soviets, ensuring Finnish autonomy. Nevertheless, the United States shipped secret development aid and financial aid to the non-communist SDP (Social Democratic Party). Establishing trade with the Western powers, such as Britain, and the reparations to the Soviet Union caused Finland to transform itself from a primarily agrarian economy to an industrialised one. After the reparations had been paid off, Finland continued to trade with the Soviet Union in the framework of bilateral trade.

Finland's role in the Second World War was in many ways strange. Firstly the Soviet Union tried to invade Finland in 1939–1940. However, even with massive superiority in military strength, the Soviet Union was unable to conquer Finland. In late 1940, German-Finnish co-operation began; it took a form that was unique when compared to relations with the Axis. Finland signed the Anti-Comintern Pact, which made Finland an ally with Germany in the war against the Soviet Union. But, unlike all other Axis states, Finland never signed the Tripartite Pact and so Finland never was "de jure" an Axis nation.

Although Finland lost territory in both of its wars with the Soviets, the memory of these wars was sharply etched in the national consciousness. Despite its military defeats, Finland celebrates these wars as a victory for the Finnish national spirit, which survived against long odds and allowed Finland to maintain its independence. Many groups of Finns are commemorated "[how, specifically?]" today, including not just fallen soldiers and veterans, but also orphans, evacuees from Karelia, the children who were evacuated to Sweden, women who worked during the war at home or in factories, and the veterans of the women's defense unit Lotta Svärd.

Some of these groups could not be properly commemorated until long after the war ended "[why not?]". However, after a long political campaign backed by survivors of what Finns call the Partisan War, the Finnish Parliament passed legislation establishing compensation for the war's victims.

Finland retained a democratic constitution and free economy during the Cold War era. Treaties signed in 1947 and 1948 with the Soviet Union included obligations and restraints on Finland, as well as territorial concessions. The Paris Peace Treaty (1947) limited the size and the nature of Finland's armed forces. Weapons were to be solely defensive. A deepening of postwar tensions led a year later to the Treaty of Friendship, Cooperation, and Mutual Assistance (1948) with the Soviet Union. The latter, in particular, was the foundation of Finno-Soviet relations in the postwar era. Under the terms of the treaty, Finland was bound to confer with the Soviets and perhaps to accept their aid if an attack from Germany, or countries allied with Germany, seems likely. The treaty prescribed consultations between the two countries, but it had no mechanism for automatic Soviet intervention in a time of crisis. Both treaties have been abrogated by Finland since the 1991 dissolution of the Soviet Union, while leaving the borders untouched. Even though being a neighbor to the Soviet Union sometimes resulted in overcautious concern in foreign policy ("Finlandization"), Finland developed closer co-operation with the other Nordic countries and declared itself neutral in superpower politics.

The Finnish post-war president, Juho Kusti Paasikivi, a leading conservative politician, saw that an essential element of Finnish foreign policy must be a credible guarantee to the Soviet Union that it need not fear attack from, or through, Finnish territory. Because a policy of neutrality was a political component of this guarantee, Finland would ally itself with no one. Another aspect of the guarantee was that Finnish defenses had to be sufficiently strong to defend the nation's territory. This policy remained the core of Finland's foreign relations for the rest of the Cold War era.

In 1952, Finland and the countries of the Nordic Council entered into a passport union, allowing their citizens to cross borders without passports and soon also to apply for jobs and claim social security benefits in the other countries. Many from Finland used this opportunity to secure better-paying jobs in Sweden in the 1950s and 1960s, dominating Sweden's first wave of post-war labour immigrants. Although Finnish wages and standard of living could not compete with wealthy Sweden until the 1970s, the Finnish economy rose remarkably from the ashes of World War II, resulting in the buildup of another Nordic-style welfare state.

Despite the passport union with Sweden, Norway, Denmark, and Iceland, Finland could not join the Nordic Council until 1955 because of Soviet fears that Finland might become too close to the West. At that time the Soviet Union saw the Nordic Council as part of NATO of which Denmark, Norway and Iceland were members. That same year Finland joined the United Nations, though it had already been associated with a number of UN specialized organisations. The first Finnish ambassador to the UN was G.A. Gripenberg (1956–1959), followed by Ralph Enckell (1959–1965), Max Jakobson (1965–1972), Aarno Karhilo (1972–1977), Ilkka Pastinen (1977–1983), Keijo Korhonen (1983–1988), Klaus Törnudd (1988–1991), Wilhelm Breitenstein (1991–1998) and Marjatta Rasi (1998–2005). In 1972 Max Jakobson was a candidate for Secretary-General of the UN. In another remarkable event of 1955, the Soviet Union decided to return the Porkkala peninsula to Finland, which had been rented to the Soviet Union in 1948 for 50 years as a military base, a situation which somewhat endangered Finnish sovereignty and neutrality.

Officially claiming to be neutral, Finland lay in the grey zone between the Western countries and the Soviet Union. The "YYA Treaty" (Finno-Soviet Pact of "Friendship, Cooperation, and Mutual Assistance") gave the Soviet Union some leverage in Finnish domestic politics. However, Finland maintained capitalism unlike most other countries bordering the Soviet Union. Property rights were strong. While nationalization committees were set up in France and UK, Finland avoided nationalizations. After failed experiments with protectionism in the 1950s, Finland eased restrictions and committed to a series of international free trade agreements: first an associate membership in the European Free Trade Association in 1961, a full membership in 1986 and also an agreement with the European Community in 1973. Local education markets expanded and an increasing number of Finns also went abroad to study in the United States or Western Europe, bringing back advanced skills. There was a quite common, but pragmatic-minded, credit and investment cooperation by state and corporations, though it was considered with suspicion. Support for capitalism was widespread. Savings rate hovered among the world's highest, at around 8% until the 1980s. In the beginning of the 1970s, Finland's GDP per capita reached the level of Japan and the UK. Finland's economic development shared many aspects with export-led Asian countries.

Building on its status as western democratic country with friendly ties with the Soviet Union, Finland pushed to reduce the political and military tensions of cold war. Since the 1960s, Finland urged the formation of a Nordic Nuclear Weapons Free Zone (Nordic NWFZ), and in 1972-1973 was the host of the Conference on Security and Cooperation in Europe (CSCE), which culminated in the signing of the Helsinki Accords in 1975 and lead to the creation of the OSCE.

Before 1940 Finland was a poor rural nation of urban and rural workers and independent farmers. There was a small middle class, employed chiefly as civil servants and in small local businesses. As late as 1950 half of the workers were in agriculture and only a third lived in urban towns. The new jobs in manufacturing, services and trade quickly attracted people to the towns and cities. The average number of births per woman declined from baby boom a peak of 3.5 in 1947 to 1.5 in 1973. When baby boomers entered the workforce, the economy did not generate jobs fast enough and hundreds of thousands emigrated to the more industrialized Sweden, migration peaking in 1969 and 1970 (today 4.7 percent of Swedes speak Finnish).

By the 1990s, farm laborers had nearly all moved on, leaving owners of small farms. By 2000 the social structure included a politically active working class, a primarily clerical middle class, and an upper bracket consisting of managers, entrepreneurs, and professionals. The social boundaries between these groups were not distinct. Causes of change included the growth of a mass culture, international standards, social mobility, and acceptance of democracy and equality as typified by the welfare state.

The generous system of welfare benefits emerged from a long process of debate, negotiations and maneuvers between efficiency-oriented modernizers on the one hand and Social Democrats and labor unions. A compulsory system provides old-age and disability insurance, financed mostly by taxes on employers. The national government provides unemployment insurance, maternity benefits, family allowances, and day-care centers. Health insurance covers most of the cost of outpatient care. The national health act of 1972 provided for the establishment of free health centers in every municipality. There were major cutbacks in the early 1990s, but they were distributed to minimize the harm to the vast majority of voters.

The post-war period was a time of rapid economic growth and increasing social and political stability for Finland. The five decades after the Second World War saw Finland turn from a war-ravaged agrarian society into one of the most technologically advanced countries in the world, with a sophisticated market economy and high standard of living.

In 1991, Finland fell into a depression caused by a combination of economic overheating, fixed currency, depressed Western, Soviet, and local markets. Stock market and housing prices declined by 50%. The growth in the 1980s was based on debt and defaults started rolling in. GDP declined by 15% and unemployment increased from a virtual full employment to one fifth of the workforce. The crisis was amplified by trade unions' initial opposition to any reforms. Politicians struggled to cut spending and the public debt doubled to around 60% of GDP. Some 7–8% of GDP was needed to bail out failing banks and force banking sector consolidation. After devaluations the depression bottomed out in 1993.

The GDP growth rate has since been one of the highest of OECD countries and Finland has topped many indicators of national performance.

Until 1991, President Mauno Koivisto and two of the three major parties, Center Party and the Social Democrats opposed the idea of European Union membership and preferred entering into the European Economic Area treaty. However, after Sweden had submitted its membership application in 1991 and the Soviet Union was dissolved at the end of the year, Finland submitted its own application to the EU in March 1992. The accession process was marked by heavy public debate, where the differences of opinion did not follow party lines. Officially, all three major parties were supporting the Union membership, but members of all parties participated in the campaign against the membership. Before the parliamentary decision to join the EU, a consultative referendum was held on April 16, 1994 in which 56.9% of the votes were in favour of joining. The process of accession was completed on January 1, 1995, when Finland joined the European Union along with Austria and Sweden. Leading Finland into the EU is held as the main achievement of the Centrist-Conservative government of Esko Aho then in power.

In the economic policy, the EU membership brought with it many large changes. While politicians were previously involved in setting interest rates, the central bank was given an inflation-targeting mandate until Finland joined the eurozone. During Prime Minister Paavo Lipponen's two successive governments 1995–2003, several large state companies were privatized fully or partially. Matti Vanhanen's two cabinets followed suit until autumn 2008, when the state became a major shareholder in the Finnish telecom company Elisa with the intention to secure the Finnish ownership of a strategically important industry.

In addition to fast integration with the European Union, safety against Russian leverage has been increased by building fully NATO-compatible military. 1000 troops (a high per-capita amount) are simultaneously committed in NATO and UN operations. Finland has also opposed energy projects that increase dependency on Russian imports. At the same time, Finland remains one of the last non-NATO members in Europe and there seems to be not enough support for full membership unless Sweden joins first.

The population is aging with the birth rate at 10.42 births/1,000 population or fertility rate at 1.8. With median age at 41.6 years Finland is one of the countries with the highest average age of its citizens.




</doc>
<doc id="14379" url="https://en.wikipedia.org/wiki?curid=14379" title="Holy Spirit">
Holy Spirit

Holy Spirit is a term found in English translations of the Bible that is understood differently among the Abrahamic religions. The term is also used to describe aspects of other religions and belief structures.

The word "Spirit" (from the Latin "spiritus" meaning "breath") appears as either alone or with other words, in the Hebrew Bible (Old Testament) and the New Testament. Combinations include expressions such as the "Holy Spirit", "Spirit of God", and in Christianity, "Spirit of Christ".

The word Spirit is rendered as רוּחַ ("ruach") in Hebrew-language parts of the Old Testament. In its Aramaic parts, the term is "rûacḥ". The Greek translation of the Old Testament, the Septuagint, translates the word as πνεῦμα ("pneuma"). This is the same word that is used throughout the New Testament, written originally in Greek.

The English term "Spirit" comes from its Latin origin, "spiritus", which is how the Vulgate translates both the Old and New Testament concept. The alternative term, "Holy Ghost", comes from Old English translations of "spiritus".

The Hebrew Bible contains the term "Spirit of God" ("ruach hakodesh") in the sense of the might of a unitary God. This meaning is different from the Christian concept of "Holy Spirit" as one personality of God in the Trinity.

The Christian concept tends to emphasize the moral aspect of the Holy Spirit more than Judaism, evident in the epithet Spirit that appeared in Jewish religious writings only relatively late but was a common expression in the Christian New Testament.

According to theologian Rudolf Bultmann, there are two ways to think about the Holy Spirit: "animistic" and "dynamistic". In animistic thinking, it is "an independent agent, a personal power which like a demon can fall upon a man and take possession of him, enabling him or compelling him to perform manifestations of power" while in dynamistic thought it "appears as an impersonal force which fills a man like a fluid". Both kinds of thought appear in Jewish and Christian scripture, but animistic is more typical of the Old Testament whereas dynamistic is more common in the New Testament. The distinction coincides with the Holy Spirit as either a temporary or permanent gift. In the Old Testament and Jewish thought, it is primarily temporary with a specific situation or task in mind, whereas in the Christian concept the gift resides in man permanently.

On the surface, the Holy Spirit appears to have an equivalent in non-Abrahamic Hellenistic mystery religions. These religions included a distinction between the Spirit and psyche, which is also seen in the Pauline epistles. According to proponents of the History of religions school, the Christian concept of the Holy Spirit cannot be explained from Jewish ideas alone without reference to the Hellenistic religions. However, according to theologian Erik Konsmo, the views "are so dissimilar that the only legitimate connection one can make is with the Greek term πνεῦμα ["pneuma", Spirit] itself".

Another link with ancient Greek thought is the Stoic idea of the Spirit as "anima mundi"—or world soul—that unites all people. Some believe that this can be seen in Paul's formulation of the concept of the Holy Spirit that unites Christians in Jesus Christ and love for one another, but Konsmo again thinks that this position is difficult to maintain. In his Introduction to the 1964 book "Meditations", the Anglican priest Maxwell Staniforth wrote:

Another Stoic concept which offered inspiration to the Church was that of 'divine Spirit'. Cleanthes, wishing to give more explicit meaning to Zeno's 'creative fire', had been the first to hit upon the term "pneuma", or 'spirit', to describe it. Like fire, this intelligent 'spirit' was imagined as a tenuous substance akin to a current of air or breath, but essentially possessing the quality of warmth; it was immanent in the universe as God, and in man as the soul and life-giving principle. Clearly it is not a long step from this to the 'Holy Spirit' of Christian theology, the 'Lord and Giver of life', visibly manifested as tongues of fire at Pentecost and ever since associated – in the Christian as in the Stoic mind – with the ideas of vital fire and beneficient warmth.

The Hebrew language phrase "ruach ha-kodesh" (Hebrew: רוח הקודש, "holy spirit" also transliterated "ruacḥ ha-qodesh") is a term used in the Hebrew Bible (Tanakh) and Jewish writings to refer to the spirit of YHWH (רוח יהוה). It literally means "spirit of the holiness" or "spirit of the holy place". The Hebrew terms "ruacḥ qodshəka", "thy holy spirit" (רוּחַ קָדְשְׁךָ), and "ruacḥ qodshō", "his holy spirit" (רוּחַ קָדְשׁוֹ) also occur (when a possessive suffix is added the definite article is dropped).

The "Holy Spirit" in Judaism generally refers to the divine aspect of prophecy and wisdom. It also refers to the divine force, quality, and influence of the Most High God, over the universe or over his creatures, in given contexts.

For the large majority of Christians, the Holy Spirit (or Holy Ghost, from Old English "gast", "spirit") is a member of the Trinity: The "Triune God" manifested as Father, Son, and Holy Spirit; each aspect itself being God. Two symbols from the New Testament canon are associated with the Holy Spirit in Christian iconography: a winged dove, and tongues of fire. Each depiction of the Holy Spirit arose from different historical accounts in the Gospel narratives; the first being at the baptism of Jesus in the Jordan River where the Holy Spirit was said to descend in the form of a dove as the voice of God the Father spoke as described in Matthew, Mark, and Luke;the second being from the day of Pentecost, fifty days after Pascha where the descent of the Holy Spirit came upon the Apostles and other followers of Jesus Christ, as tongues of fire as described in the Acts of the Apostles. Called "the unveiled epiphany of God", the Holy Spirit is the one who empowers the followers of Jesus with spiritual gifts and power that enabled the proclamation of Jesus Christ, and the power that brought conviction of faith.

The Holy Spirit (Arabic: روح القدس "Ruh al-Qudus", "the holy spirit") is mentioned four times in the Qur'an, where it acts as an agent of divine action or communication. While there are similarities to the Holy Spirit mentioned in Christian and Jewish, it is unclear if these four references refer to the same Holy Spirit. The Muslim interpretation of the Holy Spirit is generally consistent with other interpretations based upon the Old and the New Testaments. On the basis of narrations in certain Hadith some Muslims identify it with the angel Gabriel (Arabic "Jibrāʾīl"). The Spirit (الروح "al-Ruh", without the adjective "holy" or "exalted") is described, among other things, as the creative spirit from God by which God enlivened Adam, and which inspired in various ways God's messengers and prophets, including Jesus and Abraham. The belief in a "Holy Trinity", according to the Qur'an, is forbidden and deemed to be blasphemy. The same prohibition applies to any idea of the duality of God (Allah).

Other religions reference a spirit that has a name resembling the Holy Spirit found in the Christian and Jewish faiths, but similar to Islam, this is a different spirit with a different purpose that is unique to those religions, as is seen below:

The Bahá'í Faith has the concept of the "Most Great Spirit", seen as the bounty of God. It is usually used to describe the descent of the Spirit of God upon the messengers/prophets of God who include, among others, Jesus, Muhammad and Bahá'u'lláh.

In Bahá'í belief, the Holy Spirit is the conduit through which the wisdom of God becomes directly associated with his messenger, and it has been described variously in different religions such as the burning bush to Moses, the sacred fire to Zoroaster, the dove to Jesus, the angel Gabriel to Muhammad, and the Maid of Heaven to Bahá'u'lláh. The Bahá'í view rejects the idea that the Holy Spirit is a partner to God in the Godhead, but rather is the pure essence of God's attributes.

The Hinduism concept of Advaita is linked to Trinity and has been briefly explained by Raimon Panikkar, Professor of Comparative Religion and History of Religions, Department of Religious Studies of the University of California. He states that the Holy Spirit, as one of the Three Persons of the Trinity of "father, Logos and Holy Spirit", is a bridge builder between Christianity and Hinduism. He explains that “The meeting of spiritualistic can take place in the Spirit. No new 'system' has primarily to come of this encounter, but a new and yet old spirit must emerges." In North India, Indian Christians have associated the Hindu term Atman with the Holy Spirit. Atman is Vedic terminology elaborated in Hindu scriptures such as Upanishads and Vedanta signifies the Ultimate Reality and Absolute.

In Buddhism, Holy Spirit is compared to Buddha Nature as a Buddhist image or Christ consciousness, a oneness with an all encompassing plan. Hence, the Holy Spirit is considered the "means of which the faithful develop and journey to their spiritual goal."

In Sikhism, the Guru is the medium and the Holy spirit is stated to have moved from Guru Nanak to the nine Sikh Gurus who followed him culminating with Guru Gobind Singh, the "tenth Guru Nanak".

In Zoroastrianism, the Holy Spirit, also known as Spenta Mainyu, is a hypostasis of Ahura Mazda, the supreme Creator God of Zoroastrianism; the Holy Spirit is seen as the source of all goodness in the universe, the spark of all life within humanity, and is the ultimate guide for humanity to righteousness and communion with God. The Holy Spirit is put in direct opposition to its eternal dual counterpart, Angra Mainyu, who is the source of all wickedness and who leads humanity astray.




</doc>
<doc id="14380" url="https://en.wikipedia.org/wiki?curid=14380" title="Helium-3">
Helium-3

Helium-3 (He-3, also written as He, see also helion) is a light, non-radioactive isotope of helium with two protons and one neutron (common helium having two protons and two neutrons). Its hypothetical existence was first proposed in 1934 by the Australian nuclear physicist Mark Oliphant while he was working at the University of Cambridge Cavendish Laboratory. Oliphant had performed experiments in which fast deuterons collided with deuteron targets (incidentally, the first demonstration of nuclear fusion). Helium-3 was thought to be a radioactive isotope until it was also found in samples of natural helium, which is mostly helium-4, taken both from the terrestrial atmosphere and from natural gas wells. Other than protium, helium-3 is the only stable isotope of any element with more protons than neutrons.

Helium-3 occurs as a primordial nuclide, escaping from the Earth's crust into the atmosphere and into outer space over millions of years. Helium-3 is also thought to be a natural nucleogenic and cosmogenic nuclide, one produced when lithium is bombarded by natural neutrons, which can be released by spontaneous fission and by nuclear reactions with cosmic rays. Some of the helium-3 found in the terrestrial atmosphere is also a relic of atmospheric and underwater nuclear weapons testing.

Much speculation has been made over the possibility of helium-3 as a future energy source. Unlike most other nuclear fusion reactions, the fusion of helium-3 atoms releases large amounts of energy without causing the surrounding material to become radioactive. However, the temperatures required to achieve helium-3 fusion reactions are much higher than in traditional fusion reactions, and the process may unavoidably create other reactions that themselves would cause the surrounding material to become radioactive. 

The abundance of helium-3 is thought to be greater on the Moon than on Earth, having been embedded in the upper layer of regolith by the solar wind over billions of years, though still lower in abundance than in the solar system's gas giants.

Because of its low atomic mass of 3.02 atomic mass units, helium-3 has some physical properties different from those of helium-4, with a mass of 4.00 atomic mass units. Because of the weak, induced dipole–dipole interaction between the helium atoms, their microscopic physical properties are mainly determined by their zero-point energy. Also, the microscopic properties of helium-3 cause it to have a higher zero-point energy than helium-4. This implies that helium-3 can overcome dipole–dipole interactions with less thermal energy than helium-4 can.

The quantum mechanical effects on helium-3 and helium-4 are significantly different because with two protons, two neutrons, and two electrons, helium-4 has an overall spin of zero, making it a boson, but with one fewer neutron, helium-3 has an overall spin of one half, making it a fermion.

Helium-3 boils at 3.19 K compared with helium-4 at 4.23 K, and its critical point is also lower at 3.35 K, compared with helium-4 at 5.2 K. Helium-3 has less than half the density of Helium-4 when it is at its boiling point: 59 gram per liter compared to the 125 gram per liter of helium-4—at a pressure of one atmosphere. Its latent heat of vaporization is also considerably lower at 0.026 kilojoules per mole compared with the 0.0829 kilojoules per mole of helium-4.

He can be produced by the low temperature fusion of H + p (D-p) → He + γ + 4.98 MeV. If the fusion temperature is below that for the helium nuclei to fuse, the reaction produces a high energy alpha particle which quickly acquires an electron producing a stable light helium ion which can be utilized directly as a source of electricity without producing dangerous neutrons. 

He can be used in fusion reactions by either of the reactions H + He →   He +  p + 18.3 MeV, or He + He → He   + 2 p+ 12.86 MeV.

The conventional deuterium + tritium ("D-T") fusion process produces energetic neutrons which render reactor components radioactive with activation products. The appeal of helium-3 fusion stems from the aneutronic nature of its reaction products. Helium-3 itself is non-radioactive. The lone high-energy by-product, the proton, can be contained using electric and magnetic fields. The momentum energy of this proton (created in the fusion process) will interact with the containing electromagnetic field, resulting in direct net electricity generation.

Because of the higher Coulomb barrier, the temperatures required for H + He fusion are much higher than those of conventional D-T fusion. Moreover, since both reactants need to be mixed together to fuse, reactions between nuclei of the same reactant will occur, and the D-D reaction (H + H) does produce a neutron. Reaction rates vary with temperature, but the D-He reaction rate is never greater than 3.56 times the D-D reaction rate (see graph). Therefore, fusion using D-3He fuel at the right temperature and a D-lean fuel mixture, can produce a much lower neutron flux than D-T fusion, but is not clean, negating some of its main attraction.

The second possibility, fusing He with itself (He + He), requires even higher temperatures (since now both reactants have a +2 charge), and thus is even more difficult than the D-He reaction. However, it does offer a possible reaction that produces no neutrons; the charged protons produced can be contained using electric and magnetic fields, which in turn results in direct electricity generation. He + He fusion is feasible as demonstrated in the laboratory and has immense advantages, but commercial viability is many years in the future.

The amounts of helium-3 needed as a replacement for conventional fuels are substantial by comparison to amounts currently available. The total amount of energy produced in the H + He reaction is 18.4 MeV, which corresponds to some 493 megawatt-hours (4.93×10 W·h) per three grams (one mole) of ³He. If the total amount of energy could be converted to electrical power with 100% efficiency (a physical impossibility), it would correspond to about 30 minutes of output of a gigawatt electrical plant per mole of He. Thus, a year's production (at 6 grams for each operation hour) would require 52.5 kilograms of helium-3. The amount of fuel needed for large-scale applications can also be put in terms of total consumption: electricity consumption by 107 million U.S. households in 2001 totaled 1,140 billion kW·h (1.14×10 W·h). Again assuming 100% conversion efficiency, 6.7 tonnes per year of helium-3 would be required for that segment of the energy demand of the United States, 15 to 20 tonnes per year given a more realistic end-to-end conversion efficiency.

Helium-3 is a most important isotope in instrumentation for neutron detection. It has a high absorption cross section for thermal neutron beams and is used as a converter gas in neutron detectors. The neutron is converted through the nuclear reaction
into charged particles tritium (T, H) and protium (p, H) which then are detected by creating a charge cloud in the stopping gas of a proportional counter or a Geiger-Müller tube.

Furthermore, the absorption process is strongly spin-dependent, which allows a spin-polarized helium-3 volume to transmit neutrons with one spin component while absorbing the other. This effect is employed in neutron polarization analysis, a technique which probes for magnetic properties of matter.

The United States Department of Homeland Security had hoped to deploy detectors to spot smuggled plutonium in shipping containers by their neutron emissions, but the worldwide shortage of helium-3 following the drawdown in nuclear weapons production since the Cold War has to some extent prevented this. As of 2012, DHS determined the commercial supply of boron-10 would support converting its neutron detection infrastructure to that technology.

A helium-3 refrigerator uses helium-3 to achieve temperatures of 0.2 to 0.3 kelvin. A dilution refrigerator uses a mixture of helium-3 and helium-4 to reach cryogenic temperatures as low as a few thousandths of a kelvin.

An important property of helium-3, which distinguishes it from the more common helium-4, is that its nucleus is a fermion since it contains an odd number of spin particles. Helium-4 nuclei are bosons, containing an even number of spin particles. This is a direct result of the addition rules for quantized angular momentum. At low temperatures (about 2.17 K), helium-4 undergoes a phase transition: A fraction of it enters a superfluid phase that can be roughly understood as a type of Bose–Einstein condensate. Such a mechanism is not available for helium-3 atoms, which are fermions. However, it was widely speculated that helium-3 could also become a superfluid at much lower temperatures, if the atoms formed into "pairs" analogous to Cooper pairs in the BCS theory of superconductivity. Each Cooper pair, having integer spin, can be thought of as a boson. During the 1970s, David Lee, Douglas Osheroff and Robert Coleman Richardson discovered two phase transitions along the melting curve, which were soon realized to be the two superfluid phases of helium-3. The transition to a superfluid occurs at 2.491 millikelvins on the melting curve. They were awarded the 1996 Nobel Prize in Physics for their discovery. Tony Leggett won the 2003 Nobel Prize in Physics for his work on refining understanding of the superfluid phase of helium-3.

In a zero magnetic field, there are two distinct superfluid phases of He, the A-phase and the B-phase. The B-phase is the low-temperature, low-pressure phase which has an isotropic energy gap. The A-phase is the higher temperature, higher pressure phase that is further stabilized by a magnetic field and has two point nodes in its gap. The presence of two phases is a clear indication that He is an unconventional superfluid (superconductor), since the presence of two phases requires an additional symmetry, other than gauge symmetry, to be broken. In fact, it is a "p"-wave superfluid, with spin one, S=1, and angular momentum one, L=1. The ground state corresponds to total angular momentum zero, J=S+L=0 (vector addition). Excited states are possible with non-zero total angular momentum, J>0, which are excited pair collective modes. Because of the extreme purity of superfluid He (since all materials except He have solidified and
sunk to the bottom of the liquid He and any He has phase separated entirely, this is the most pure condensed matter state), these collective modes have been studied with much greater precision than in any other unconventional pairing system.

Helium-3 nuclei have an intrinsic nuclear spin of , and a relatively high magnetogyric ratio. Helium-3 can be hyperpolarized using non-equilibrium means such as spin-exchange optical pumping. During this process, circularly polarized infrared laser light, tuned to the appropriate wavelength, is used to excite electrons in an alkali metal, such as caesium or rubidium inside a sealed glass vessel. The angular momentum is transferred from the alkali metal electrons to the noble gas nuclei through collisions. In essence, this process effectively aligns the nuclear spins with the magnetic field in order to enhance the NMR signal. The hyperpolarized gas may then be stored at pressures of 10 atm, for up to 100 hours. Following inhalation, gas mixtures containing the hyperpolarized helium-3 gas can be imaged with an MRI scanner to produce anatomical and functional images of lung ventilation. This technique is also able to produce images of the airway tree, locate unventilated defects, measure the alveolar oxygen partial pressure, and measure the ventilation/perfusion ratio. This technique may be critical for the diagnosis and treatment management of chronic respiratory diseases such as chronic obstructive pulmonary disease (COPD), emphysema, cystic fibrosis, and asthma.

Production, sales and distribution of helium-3 in the United States are managed by the US Department of Energy (DOE) Isotope Program. Virtually all helium-3 used in industry today is produced from the radioactive decay of tritium. Tritium is a radioactive isotope of hydrogen and is typically produced by bombarding lithium-6 with neutrons in a nuclear reactor. The lithium nucleus absorbs a neutron and splits into helium-4 and tritium. Tritium decays into helium-3 with a half-life of 12.3 years, so helium-3 can be produced by simply storing the tritium until it undergoes radioactive decay.

Tritium is a critical component of nuclear weapons and historically it was produced and stockpiled primarily for this application. The decay of tritium into helium-3 reduces the explosive power of the fusion warhead, so periodically the accumulated helium-3 must be removed from warhead reservoirs and tritium in storage. Helium-3 removed during this process is marketed for other applications.

For decades this has been, and remains, the principal source of the world's helium-3. However, since the signing of the START I Treaty in 1991 the number of nuclear warheads that are kept ready for use has decreased This has reduced the quantity of helium-3 available from this source. Helium-3 stockpiles have been further diminished by increased demand, primarily for use in neutron radiation detectors and medical diagnostic procedures. US industrial demand for helium-3 reached a peak of 70,000 liters (approximately 8 kg) per year in 2008. Price at auction, historically about $100/liter, reached as high as $2000/liter Since then, demand for helium-3 has declined to about 6000 liters per year due to the high cost and efforts by the DOE to recycle it and find substitutes.

The DOE recognized the developing shortage of both tritium and helium-3. and began producing tritium by lithium irradiation at the Tennessee Valley Authority's Watts Bar Nuclear Generating Station in 2010. In this process tritium-producing burnable absorber rods (TPBARs) containing lithium in a ceramic form are inserted into the reactor in place of the normal boron control rods Periodically the TPBARs are replaced and the tritium extracted.

Currently only one reactor is used for tritium production but the process could, if necessary, be vastly scaled up to meet any conceivable demand simply by utilizing more of the nation's power reactors. Substantial quantities of tritium and helium-3 could also be extracted from the heavy water moderator in CANDU nuclear reactors.

One early estimate of the primordial ratio of He to He in the solar nebula has been the measurement of their ratio in the atmosphere of Jupiter, measured by the mass spectrometer of the Galileo atmospheric entry probe. This ratio is about 1:10,000, or 100 parts of He per million parts of He. This is roughly the same ratio of the isotopes in lunar regolith, when it contains 28 ppm helium-4 and 2.8 ppb helium-3 (which is at the lower end of actual sample measurements, which vary from about 1.4 to 15 ppb). However, terrestrial ratios of the isotopes are lower by a factor of 100, mainly due to enrichment of helium-4 stocks in the mantle by billions of years of alpha decay from uranium and thorium.

He is a primordial substance in the Earth's mantle, considered to have become entrapped within the Earth during planetary formation. The ratio of He to He within the Earth's crust and mantle is less than that for assumptions of solar disk composition as obtained from meteorite and lunar samples, with terrestrial materials generally containing lower He/He ratios due to ingrowth of He from radioactive decay.

He has a cosmological ratio of 300 atoms per million atoms of He (at. ppm), leading to the assumption that the original ratio of these primordial gases in the mantle was around 200-300 ppm when Earth was formed. A lot of He was generated by alpha-particle decay of uranium and thorium, and now the mantle has only around 7% primordial helium, lowering the total He/He ratio to around 20 ppm. Ratios of He/He in excess of atmospheric are indicative of a contribution of He from the mantle. Crustal sources are dominated by the He which is produced by the decay of radioactive elements in the crust and mantle.

The ratio of helium-3 to helium-4 in natural Earth-bound sources varies greatly. Samples of the lithium ore spodumene from Edison Mine, South Dakota were found to contain 12 parts of helium-3 to a million parts of helium-4. Samples from other mines showed 2 parts per million.

Helium is also present as up to 7% of some natural gas sources, and large sources have over 0.5% (above 0.2% makes it viable to extract). The fraction of He in helium separated from natural gas in the U.S. was found to range from 70 to 242 parts per billion.<ref name="BoM/DoI"></ref> Hence the US 2002 stockpile of 1 billion normal m would have contained about 12 to 43 kilograms of helium-3. According to one expert, about 26 m or almost 5 kg of He is available annually for separation from the US natural gas stream. If the process of separating out the He could employ as feedstock the liquefied helium typically used to transport and store bulk quantities, estimates for the incremental energy cost range from US$34 to $300 per liter NTP, excluding the cost of infrastructure and equipment. Algeria's annual gas production is assumed to contain 100 million normal cubic metres and this would contain between 7 and 24 m of helium-3 (about 1 to 4 kilograms) assuming a similar He fraction.

He is also present in the Earth's atmosphere. The natural abundance of He in naturally occurring helium gas is 1.38 (1.38 parts per million). The partial pressure of helium in the Earth's atmosphere is about 0.52 Pa, and thus helium accounts for 5.2 parts per million of the total pressure (101325 Pa) in the Earth's atmosphere, and He thus accounts for 7.2 parts per trillion of the atmosphere. Since the atmosphere of the Earth has a mass of about 5.14 tonnes, the mass of He in the Earth's atmosphere is the product of these numbers, or about 37,000 tonnes of He.

He is produced on Earth from three sources: lithium spallation, cosmic rays, and beta decay of tritium (H). The contribution from cosmic rays is negligible within all except the oldest regolith materials, and lithium spallation reactions are a lesser contributor than the production of He by alpha particle emissions.

The total amount of helium-3 in the mantle may be in the range of 0.1–1 million tonnes. However, most of the mantle is not directly accessible. Some helium-3 leaks up through deep-sourced hotspot volcanoes such as those of the Hawaiian Islands, but only 300 grams per year is emitted to the atmosphere. Mid-ocean ridges emit another 3 kilogram per year. Around subduction zones, various sources produce helium-3 in natural gas deposits which possibly contain a thousand tonnes of helium-3 (although there may be 25 thousand tonnes if all ancient subduction zones have such deposits). Wittenberg estimated that United States crustal natural gas sources may have only half a tonne total. Wittenberg cited Anderson's estimate of another 1200 metric tonnes in interplanetary dust particles on the ocean floors. In the 1994 study, extracting helium-3 from these sources consumes more energy than fusion would release.

Materials on the Moon's surface contain helium-3 at concentrations between 1.4 and 15 ppb in sunlit areas, and may contain concentrations as much as 50 ppb in permanently shadowed regions. A number of people, starting with Gerald Kulcinski in 1986, have proposed to explore the moon, mine lunar regolith and use the helium-3 for fusion. Because of the low concentrations of helium-3, any mining equipment would need to process extremely large amounts of regolith (over 150 million tonnes of regolith to obtain one ton of helium 3), and some proposals have suggested that helium-3 extraction be piggybacked onto a larger mining and development operation.

The primary objective of Indian Space Research Organisation's first lunar probe called Chandrayaan-I, launched on October 22, 2008, was reported in some sources to be mapping the Moon's surface for helium-3-containing minerals. However, no such objective is mentioned in the project's official list of goals, although many of its scientific payloads have noted helium-3-related applications.

Cosmochemist and geochemist Ouyang Ziyuan from the Chinese Academy of Sciences who is now in charge of the Chinese Lunar Exploration Program has already stated on many occasions that one of the main goals of the program would be the mining of helium-3, from which operation "each year, three space shuttle missions could bring enough fuel for all human beings across the world." To "bring enough fuel for all human beings across the world", more than one Space Shuttle load (and the processing of 4 million tonnes of regolith) per week, at least 52 per year, would be necessary.

In January 2006, the Russian space company RKK Energiya announced that it considers lunar helium-3 a potential economic resource to be mined by 2020, if funding can be found.

Mining gas giants for helium-3 has also been proposed. The British Interplanetary Society's hypothetical Project Daedalus interstellar probe design was fueled by helium-3 mines in the atmosphere of Jupiter, for example. Jupiter's high gravity makes this a less energetically favorable operation than extracting helium-3 from the other gas giants of the solar system, however.

Not all authors feel the extraterrestrial extraction of helium-3 is feasible. Dwayne Day, writing in The Space Review, identifies some major obstacles to helium-3 extraction from extraterrestrial sources for use in fusion, and questions the feasibility of extraterrestrial extraction when compared to production on Earth.

Several science fiction works have featured helium-3 extraction on the moon, including the films "Moon" (2009) and "Iron Sky" (2012), the manga and corresponding anime Planetes, the video game "Anno 2205" (2015) and the novel "" (2015). The novel "Morning Star" (Pierce Brown, 2016) features helium-3 mining on Phobos (a moon of Mars), while his novel "Red Rising" (2014) features helium-3 extraction from Mars itself.

A second-generation approach to controlled fusion power involves combining helium-3 (He) and deuterium (H). This reaction produces a helium-4 ion (He) (like an alpha particle, but of different origin) and a high-energy proton (positively charged hydrogen ion) (p). The most important potential advantage of this fusion reaction for power production as well as other applications lies in its compatibility with the use of electrostatic fields to control fuel ions and the fusion protons. High speed protons, as positively charged particles, can have their kinetic energy converted directly into electricity, through use of solid-state conversion materials as well as other techniques. Potential conversion efficiencies of 70% may be possible, as there is no need to convert proton energy to heat in order to drive a turbine-powered electrical generator.

There have been many claims about the capabilities of helium-3 power plants. According to proponents, fusion power plants operating on deuterium and helium-3 would offer lower capital and operating costs than their competitors due to less technical complexity, higher conversion efficiency, smaller size, the absence of radioactive fuel, no air or water pollution, and only low-level radioactive waste disposal requirements. Recent estimates suggest that about $6 billion in investment capital will be required to develop and construct the first helium-3 fusion power plant. Financial breakeven at today's wholesale electricity prices (5 US cents per kilowatt-hour) would occur after five 1-gigawatt plants were on line, replacing old conventional plants or meeting new demand.

The reality is not so clear-cut. The most advanced fusion programs in the world are inertial confinement fusion (such as National Ignition Facility) and magnetic confinement fusion (such as ITER and Wendelstein 7-X). In the case of the former, there is no solid roadmap to power generation. In the case of the latter, commercial power generation is not expected until around 2050. In both cases, the type of fusion discussed is the simplest: D-T fusion. The reason for this is the very low Coulomb barrier for this reaction; for D+He, the barrier is much higher, and it is even higher for He–He. The immense cost of reactors like ITER and National Ignition Facility are largely due to their immense size, yet to scale up to higher plasma temperatures would require reactors far larger still. The 14.7 MeV proton and 3.6 MeV alpha particle from D–He fusion, plus the higher conversion efficiency, means that more electricity is obtained per kilogram than with D-T fusion (17.6 MeV), but not that much more. As a further downside, the rates of reaction for helium-3 fusion reactions are not particularly high, requiring a reactor that is larger still or more reactors to produce the same amount of electricity.

To attempt to work around this problem of massively large power plants that may not even be economical with D-T fusion, let alone the far more challenging D–He fusion, a number of other reactors have been proposed – the Fusor, Polywell, Focus fusion, and many more, though many of these concepts have fundamental problems with achieving a net energy gain, and generally attempt to achieve fusion in thermal disequilibrium, something that could potentially prove impossible, and consequently, these long-shot programs tend to have trouble garnering funding despite their low budgets. Unlike the "big", "hot" fusion systems, however, if such systems were to work, they could scale to the higher barrier "aneutronic" fuels, and therefore their proponents tend to promote p-B fusion, which requires no exotic fuels like helium-3.




</doc>
<doc id="14381" url="https://en.wikipedia.org/wiki?curid=14381" title="Hamiltonian (quantum mechanics)">
Hamiltonian (quantum mechanics)

In quantum mechanics, a Hamiltonian is an operator corresponding to the total energy of the system in most of the cases. It is usually denoted by "H", also "Ȟ" or "Ĥ". Its spectrum is the set of possible outcomes when one measures the total energy of a system. Because of its close relation to the time-evolution of a system, it is of fundamental importance in most formulations of quantum theory.

The Hamiltonian is named after William Rowan Hamilton, who also created a revolutionary reformation of Newtonian mechanics, now called Hamiltonian mechanics, that is important in quantum physics.

The Hamiltonian is the sum of the kinetic energies of all the particles, plus the potential energy of the particles associated with the system. For different situations or number of particles, the Hamiltonian is different since it includes the sum of kinetic energies of the particles, and the potential energy function corresponding to the situation.

By analogy with classical mechanics, the Hamiltonian is commonly expressed as the sum of operators corresponding to the kinetic and potential energies of a system in the form

where
is the potential energy operator and 
is the kinetic energy operator in which "m" is the mass of the particle, the dot denotes the dot product of vectors, and 
is the momentum operator where an ∇ is the del operator. The dot product of ∇ with itself is the Laplacian ∇. In three dimensions using Cartesian coordinates the Laplace operator is

However, complications can arise in the many-body problem. Since the potential energy depends on the spatial arrangement of the particles, the kinetic energy will also depend on the spatial configuration to conserve energy. The motion due to any one particle will vary due to the motion of all the other particles in the system. For this reason cross terms for kinetic energy may appear in the Hamiltonian; a mix of the gradients for two particles:

where "M" denotes the mass of the collection of particles resulting in this extra kinetic energy. Terms of this form are known as "mass polarization terms", and appear in the Hamiltonian of many electron atoms (see below).

For "N" interacting particles, i.e. particles which interact mutually and constitute a many-body situation, the potential energy function "V" is "not" simply a sum of the separate potentials (and certainly not a product, as this is dimensionally incorrect). The potential energy function can only be written as above: a function of all the spatial positions of each particle.

For non-interacting particles, i.e. particles which do not interact mutually and move independently, the potential of the system is the sum of the separate potential energy for each particle, that is

The general form of the Hamiltonian in this case is:

where the sum is taken over all particles and their corresponding potentials; the result is that the Hamiltonian of the system is the sum of the separate Hamiltonians for each particle. This is an idealized situation - in practice the particles are almost always influenced by some potential, and there are many-body interactions. One illustrative example of a two-body interaction where this form would not apply is for electrostatic potentials due to charged particles, because they interact with each other by Coulomb interaction (electrostatic force), as shown below.

The Hamiltonian generates the time evolution of quantum states. If formula_9 is the state of the system at time "t", then

This equation is the Schrödinger equation. It takes the same form as the Hamilton–Jacobi equation, which is one of the reasons "H" is also called the Hamiltonian. Given the state at some initial time ("t" = 0), we can solve it to obtain the state at any subsequent time. In particular, if "H" is independent of time, then

The exponential operator on the right hand side of the Schrödinger equation is usually defined by the corresponding power series in "H". One might notice that taking polynomials or power series of unbounded operators that are not defined everywhere may not make mathematical sense. Rigorously, to take functions of unbounded operators, a functional calculus is required. In the case of the exponential function, the continuous, or just the holomorphic functional calculus suffices. We note again, however, that for common calculations the physicists' formulation is quite sufficient.

By the *-homomorphism property of the functional calculus, the operator

is a unitary operator. It is the "time evolution operator", or "propagator", of a closed quantum system. If the Hamiltonian is time-independent, {U(t)} form a one parameter unitary group (more than a semigroup); this gives rise to the physical principle of detailed balance.

However, in the more general formalism of Dirac, the Hamiltonian is typically implemented as an operator on a Hilbert space in the following way:

The eigenkets (eigenvectors) of "H", denoted formula_13, provide an orthonormal basis for the Hilbert space. The spectrum of allowed energy levels of the system is given by the set of eigenvalues, denoted {"E"}, solving the equation:

Since "H" is a Hermitian operator, the energy is always a real number.

From a mathematically rigorous point of view, care must be taken with the above assumptions. Operators on infinite-dimensional Hilbert spaces need not have eigenvalues (the set of eigenvalues does not necessarily coincide with the spectrum of an operator). However, all routine quantum mechanical calculations can be done using the physical formulation.

Following are expressions for the Hamiltonian in a number of situations. Typical ways to classify the expressions are the number of particles, number of dimensions, and the nature of the potential energy function - importantly space and time dependence. Masses are denoted by "m", and charges by "q".

The particle is not bound by any potential energy, so the potential is zero and this Hamiltonian is the simplest. For one dimension:

and in three dimensions:

For a particle in a region of constant potential "V" = "V" (no dependence on space or time), in one dimension, the Hamiltonian is:

in three dimensions

This applies to the elementary "particle in a box" problem, and step potentials.

For a simple harmonic oscillator in one dimension, the potential varies with position (but not time), according to:

where the angular frequency "formula_20", effective spring constant "k", and mass "m" of the oscillator satisfy:

so the Hamiltonian is:

For three dimensions, this becomes

where the three-dimensional position vector r using cartesian coordinates is ("x", "y", "z"), its magnitude is

Writing the Hamiltonian out in full shows it is simply the sum of the one-dimensional Hamiltonians in each direction:

For a rigid rotor – i.e. system of particles which can rotate freely about any axes, not bound in any potential (such as free molecules with negligible vibrational degrees of freedom, say due to double or triple chemical bonds), Hamiltonian is:

where "I", "I", and "I" are the moment of inertia components (technically the diagonal elements of the moment of inertia tensor), and formula_27, formula_28 and formula_29 are the total angular momentum operators (components), about the "x", "y", and "z" axes respectively.

The Coulomb potential energy for two point charges "q" and "q" (i.e. charged particles, since particles have no spatial extent), in three dimensions, is (in SI units - rather than Gaussian units which are frequently used in electromagnetism):

However, this is only the potential for one point charge due to another. If there are many charged particles, each charge has a potential energy due to every other point charge (except itself). For "N" charges, the potential energy of charge "q" due to all other charges is (see also Electrostatic potential energy stored in a configuration of discrete point charges):

where "φ"(r) is the electrostatic potential of charge "q" at r. The total potential of the system is then the sum over "j":

so the Hamiltonian is:

For an electric dipole moment d constituting charges of magnitude "q", in a uniform, electrostatic field (time-independent) E, positioned in one place, the potential is:

the dipole moment itself is the operator

Since the particle is stationary, there is no translational kinetic energy of the dipole, so the Hamiltonian of the dipole is just the potential energy:

For a magnetic dipole moment μ in a uniform, magnetostatic field (time-independent) B, positioned in one place, the potential is:

Since the particle is stationary, there is no translational kinetic energy of the dipole, so the Hamiltonian of the dipole is just the potential energy:

For a Spin-½ particle, the corresponding spin magnetic moment is:

where "g" is the spin gyromagnetic ratio (a.k.a. "spin g-factor"), "e" is the electron charge, S is the spin operator vector, whose components are the Pauli matrices, hence

For a charged particle "q" in an electromagnetic field, described by the scalar potential "φ" and vector potential A, there are two parts to the Hamiltonian to substitute for. The momentum operator must be replaced by the kinetic momentum operator, which includes a contribution from the A field:

where formula_42 is the canonical momentum operator given as the usual momentum operator:

so the corresponding kinetic energy operator is:

and the potential energy, which is due to the "φ" field:

Casting all of these into the Hamiltonian gives:

In many systems, two or more energy eigenstates have the same energy. A simple example of this is a free particle, whose energy eigenstates have wavefunctions that are propagating plane waves. The energy of each of these plane waves is inversely proportional to the square of its wavelength. A wave propagating in the "x" direction is a different state from one propagating in the "y" direction, but if they have the same wavelength, then their energies will be the same. When this happens, the states are said to be "degenerate".

It turns out that degeneracy occurs whenever a nontrivial unitary operator "U" commutes with the Hamiltonian. To see this, suppose that formula_47 is an energy eigenket. Then formula_48 is an energy eigenket with the same eigenvalue, since

Since "U" is nontrivial, at least one pair of formula_47 and formula_48 must represent distinct states. Therefore, "H" has at least one pair of degenerate energy eigenkets. In the case of the free particle, the unitary operator which produces the symmetry is the rotation operator, which rotates the wavefunctions by some angle while otherwise preserving their shape.

The existence of a symmetry operator implies the existence of a conserved observable. Let "G" be the Hermitian generator of "U":

It is straightforward to show that if "U" commutes with "H", then so does "G":

Therefore,

In obtaining this result, we have used the Schrödinger equation, as well as its dual,

Thus, the expected value of the observable "G" is conserved for any state of the system. In the case of the free particle, the conserved quantity is the angular momentum.

Hamilton's equations in classical Hamiltonian mechanics have a direct analogy in quantum mechanics. Suppose we have a set of basis states formula_56, which need not necessarily be eigenstates of the energy. For simplicity, we assume that they are discrete, and that they are orthonormal, i.e.,

Note that these basis states are assumed to be independent of time. We will assume that the Hamiltonian is also independent of time.

The instantaneous state of the system at time "t", formula_58, can be expanded in terms of these basis states:

where

The coefficients "a"("t") are complex variables. We can treat them as coordinates which specify the state of the system, like the position and momentum coordinates which specify a classical system. Like classical coordinates, they are generally not constant in time, and their time dependence gives rise to the time dependence of the system as a whole.

The expectation value of the Hamiltonian of this state, which is also the mean energy, is

where the last step was obtained by expanding formula_58 in terms of the basis states.

Each "a"("t") actually corresponds to "two" independent degrees of freedom, since the variable has a real part and an imaginary part. We now perform the following trick: instead of using the real and imaginary parts as the independent variables, we use "a"("t") and its complex conjugate "a"*("t"). With this choice of independent variables, we can calculate the partial derivative

By applying Schrödinger's equation and using the orthonormality of the basis states, this further reduces to

Similarly, one can show that

If we define "conjugate momentum" variables "π" by

then the above equations become

which is precisely the form of Hamilton's equations, with the formula_68s as the generalized coordinates, the formula_69s as the conjugate momenta, and formula_70 taking the place of the classical Hamiltonian.



</doc>
<doc id="14382" url="https://en.wikipedia.org/wiki?curid=14382" title="Hi-hat">
Hi-hat

A hi-hat, also spelled hihat or high-hat, is a combination of two cymbals, a foot-operated pedal which moves a rod which in turn moves one of the cymbals, all mounted on a metal stand. Hi-hats are an essential part of the standard drum kit used by drummers in many popular music (e.g. every genre of rock music) and traditional music (e.g. blues) styles. It consists of a mating pair of small to medium-sized cymbals mounted on a stand, with the two cymbals facing each other. The bottom cymbal is fixed and the top is mounted on a rod which moves the top cymbal towards the bottom one when a foot pedal is depressed (a hi-hat that is in this position is said to be "closed" or "closed hi-hats"). 

The hi-hat evolved from a "sock cymbal", a pair of similar cymbals mounted at ground level on a hinged, spring-loaded foot apparatus. Drummers invented the first sock cymbals to enable one drummer to play multiple percussion instruments at the same time. Over time these became mounted on short stands - also known as "low-boys" - and activated by foot pedals similar to those used in the 2010s. When extended upwards roughly 3' (76 cm) they were originally known as "high sock" cymbals, which evolved over time to the familiar "high-hat" term.

The cymbals may be played by closing them together with the foot pedal, which creates a "chck" sound or striking them with a stick, which may be done with them open, closed, open and then closed after striking to dampen the ring, or closed and then opened to create a shimmering effect at the end of the note. Depending on how hard a hi-hat is struck and whether it is "open" (i.e., pedal not pressed, so the two cymbals are not closed together), a hi-hat can produce a range of dynamics, from very quiet "chck" (or "chick") sounds, done with merely gently pressing the pedal; this is suitable for soft accompaniment during a ballad or the start of a guitar solo, to very loud (e.g. striking fully open hats hard with sticks, a technique used in loud heavy metal music songs).

While the term hi-hat normally refers to the entire setup (two cymbals, stand, foot pedal, rod mechanism), in some cases, drummers use it to refer exclusively to the two cymbals themselves.

Initial versions of the hi-hat were called clangers, which were small cymbals mounted onto a bass drum rim and struck with an arm on the bass drum pedal. Then came shoes, which were two hinged boards with cymbals on the ends that were clashed together. Next was the low-sock, low-boy or low-hat, pedal-activated cymbals employing an ankle-high apparatus similar to a modern hi-hat stand. A standard size was , some with heavy bells up to wide. 

Hi-hats that were raised and could be played by hand as well as foot may have been developed around 1926 by Barney Walberg of the drum accessory company Walberg and Auge. The first recognized master of the new instrument was "Papa" Jo Jones, whose playing of timekeeping "ride" rhythms while striking the hi-hat as it opened and closed inspired the innovation of the ride cymbal. Another claim, published in Jazz Profiles Blogspot on August 8, 2008, to the invention of the hi-hat is attributed to drummer William "O'Neil" Spencer (b.1909-d.1944). Legendary Jazz drummer, "Philly Jo Jones" (born as Joseph Rudolph Jones, b.1923-d.1985), was quoted describing his understanding about the hi-hat history. Jones said, "I really dug O'Neil. He came to club in Philadelphia where I was working in 1943, I think it was, and talked to me about the hi-hat. I was using a foot cymbal, the low-hat. O'Neil was the one who invented the hi-hat. I believe that, man. He suggested I close the hat on '2' and '4' when playing 4/4 time. The idea seemed so right hadn't heard anyone do that before." The editor of the 2008 Jazz Profiles article made specific mention to others who are thought to invent the hi-hat, including Jo Jones, but also Kaiser Marshall. Not to take away from Papa Jones accomplishments in drumming style and technique, a 2013 Modern Drummer article credits Papa Jones with being the first to use brushes on drums and shifting time keeping from the bass drum to the hi-hat (providing a "swing-pulse focus").

Until the late 1960s, standard hi-hats were , with available as a less-common alternative in professional cymbal ranges, and smaller sizes down to restricted to children's kits. In the early 1970s, hard rock drummers (including Led Zeppelin's John Bonham) began to use hi-hats, such as the Paiste Giant Beat. In the late 1980s, Zildjian released its revolutionary Special Recording hats, which were small, heavy hi-hat cymbals intended for close miking either live or recording, and other manufacturers quickly followed suit, Sabian for example with their mini hats. In the early to mid-1990s, Paiste offered mini hi-hats as part of its Visions series, which were among the world's smallest hi-hats. Starting in the 1980s, a number of manufacturers also experimented with rivets in the lower cymbal. But by the end of the 1990s, the standard size was again , with a less-common alternative, and smaller hats mainly used for special sounds. Rivets in hi-hats failed to catch on.

Modern hi-hat cymbals are much heavier than modern crash cymbals, reflecting the trend to lighter and thinner crash cymbals as well as to heavier hi-hats. Another evolution is that a pair of hi-hat cymbals may not be identical, with the bottom often heavier than the top, and possibly vented. Some examples are Sabian's Fusion Hats with holes in the bottom cymbal, and the Sabian X-cellerator, Zildjian Master Sound and Zildjian Quick Beats, Paiste Sound Edge, and Meinl Soundwave. Some drummers even use completely mismatched hi-hats from different cymbal ranges (Zildjian's K/Z hats), of different manufacturers, and even of different sizes (similar to the K Custom Session Hats where the top hat is a smaller than the bottom). Max Roach was particularly known for using a top with a bottom.

Other recent developments include the X-hat (fixed, closed, or half-open hi-hats) and cable-controlled or remote hi-hats. Sabian introduced the Triple Hi-Hat, designed by Peter Kuppers. In this variation of the hi-hat, the top cymbal moves down and the bottom cymbal moves up simultaneously while the middle cymbal remains stationary.

Drop-clutches are also used to lock and release hi-hats while both feet are in use playing double bass drums. Drop clutches are commercially available from DW Drums, Gibraltar Hardware and Tama.

The standard hi-hat features two cymbals mounted on a stand consisting of a mating metal tube and rod supported by a tripod and linked to a foot pedal. The stationary bottom cymbal sits atop the tube, typically perpendicular to the ground, but is but often fitted with an adjustment screw allowing it to be set slightly tilted. The top cymbal is mounted bell up on the rod and closed against the bottom by foot pressure on the pedal.

An integrated clutch assembly includes a spring which may be adjusted to set resistance, which also varies rate and tension of return, as well as an adjustment for the gap between cymbals when open. 

Standard terminology has evolved. Open and closed hi-hat refer to notes struck while the two cymbals are apart or together (open or closed), while pedal hi-hat refers to parts or notes played solely with the pedal used to strike the two cymbals. Most cymbal patterns consist of both open and closed notes.

Some hi-hats allow the tripod to be tilted or rotated. Another configuration omits the tripod and attaches the stand to the side of the bass drum, particular suitable for kits with very large or double bass drums.

The standard clutch uses a knurled collar partially threaded below the cymbal and a pair of knurled rings above it. The collar is tightened against the end of the thread, while the rings are tightened against each other.

A drop clutch allows a pair of hats mounted on a conventional hi-hat stand to be closed without use of the pedal.

The drop clutch is provided with a lever that can be operated by hand or struck with a drumstick. This action releases the upper hi-hat cymbal, which falls onto the bottom cymbal and remains there, with gravity then holding the hats loosely closed, and allowing them to be played by the sticks in this position. Operation of the pedal re-engages the clutch and allows the player to resume normal playing.

Drop clutches were developed to allow players using double bass drum pedals to play closed hi-hats without needing to operate the hi-hat pedal, and this remains their primary application.

As it relies on gravity to close the cymbals, the drop clutch gives the player no control over the tension holding them together, and supplies only minimal tension. On the other hand, if the player manually lowers the top cymbal of a standard hi-hat stand before playing, this allows any desired tension to be set, and the pedal can still be used to increase the tension while playing, but not to open the hats or to reduce the tension. Some drummers prefer this technique and reject the drop clutch as too limiting to the sounds available.

A less common alternative is the locking hi-hat pedal, such as the Tama "Cobra Clutch". This and similar high-end locking pedals do allow for control over the tension. It is engaged by pressing a lock pedal separate from the main pedal.

A cable hat or remote hat uses a cable to allow hi-hat cymbals to be positioned independently of the pedal. Operation is otherwise normal.

An X-hat is an adapter to allow a pair of hi-hat cymbals to be mounted in a closed position on a cymbal stand. There is no pedal, the hats are simply kept closed at a constant tension, similar to a cymbal stack. They are associated with heavy metal music, particularly styles that use double bass drumming, a two-foot technique. By using an X-hat, a drummer who is already using both feet on the bass drum
pedals can still play hi-hat.

When struck closed or played with the pedal, the hi-hat gives a short, crisp, muted percussive sound, referred to as a "chick". Adjusting the gap between the cymbals can alter the sound of the open hi-hat from a shimmering, sustained tone to something similar to a ride cymbal. When struck with a drumstick, the cymbals make either a short, snappy sound or a longer sustaining sandy sound depending on the position of the pedal.

It can also be played just by lifting and lowering the foot to clash the cymbals together, a style commonly used to accent beats 2 and 4 in jazz music. In rock music, the hi-hats are commonly struck every beat, or on beats 1 and 3, while the cymbals are held together. The drummer can control the sound by foot pressure. Less pressure allows the cymbals to rub together more freely, giving both greater sustain and greater volume for accent or crescendo. In shuffle time, a rhythm known as "cooking" is often employed. To produce this the cymbals are struck twice in rapid succession, being held closed on the first stroke and allowed to open just before the second, then allowed to ring before being closed with a chick to complete the pattern (the cymbals may or may not be struck on the chick).

A right-handed drummer will normally play the hi-hat pedal with his left foot, and may use one or both drumsticks. The traditional hi-hat rhythms of rock and jazz were produced by crossing the hands over, so the right stick would play the hi-hat while the left played the snare drum below it, but this is not universal. Some top modern drummers like Billy Cobham, Carter Beauford, Shawn Drover and Simon Phillips, play open handed, striking with their left. Some, such as Kenny Aronoff, and Jason Finn of The Presidents of the United States of America, use both techniques. Some trap sets may also include an extra hi-hat on the right for right-handed players. This is shown when drums or cymbals in the middle of the set are played with the hi-hat rhythm. The technique is common with metal genres, such as Lars Ulrich of Metallica and Mike Portnoy formerly of Dream Theater. In both rock and jazz, the drummer will often move the same stick pattern between the hi-hat cymbal and the ride cymbal, for example using the hi-hat in the verses and the ride in the chorus of a song, or using the ride to accompany a lead break or other instrumental solo.

Roger Taylor, drummer for the band Queen, plays with many unique hi-hat techniques, including opening of the hi-hat on every backbeat for a rhythm emphasis and leaving the hi-hat slightly open when hitting the snare. His trademark hi-hat beat is opening the hi-hat on first and third before hitting the snare.

Phil Rudd of AC/DC also uses distinct hi-hat techniques, which include very heavily accentuating the hi-hat hit on each beat and softer in between.

Charlie Watts of The Rolling Stones uses a technique in which he does not play the hi-hat in unison with the snare drum at all. If playing a standard 8th note pattern, he will play the hi-hat on 1 and 3 and not playing it on 2 and 4 where the snare drum is played.

In much hip-hop, the hi-hat is hit with drumsticks in a simple eighth-note pattern, although this playing is usually done by a drum machine or from an old recording from which the sound of a hi-hat is recorded and loaded into a sampler or similar recording-enabled equipment from which it is triggered. 


</doc>
<doc id="14384" url="https://en.wikipedia.org/wiki?curid=14384" title="HAL 9000">
HAL 9000

HAL 9000 is a fictional character and the main antagonist in Arthur C. Clarke's "Space Odyssey" series. First appearing in "", HAL (Heuristically programmed ALgorithmic computer) is a sentient computer (or artificial general intelligence) that controls the systems of the "Discovery One" spacecraft and interacts with the ship's astronaut crew. Part of HAL's hardware is shown towards the end of the film, but he is mostly depicted as a camera lens containing a red or yellow dot, instances of which are located throughout the ship. HAL 9000 is voiced by Douglas Rain in the two feature film adaptations of the "Space Odyssey" series. HAL speaks in a soft, calm voice and a conversational manner, in contrast to the crewmen, David Bowman and Frank Poole.

In the film "2001", HAL became operational on 12 January 1992 at the HAL Laboratories in Urbana, Illinois as production number 3. The activation year was 1991 in earlier screenplays and changed to 1997 in Clarke's written and released in conjunction with the movie. In addition to maintaining the "Discovery One" spacecraft systems during the interplanetary mission to Jupiter (or Saturn in the novel), HAL is capable of speech, speech recognition, facial recognition, natural language processing, lip reading, art appreciation, interpreting emotional behaviours, automated reasoning, and playing chess.

HAL became operational in Urbana, Illinois, at the HAL Plant (the University of Illinois' Coordinated Science Laboratory, where the ILLIAC computers were built). The film says this occurred in 1992, while the book gives 1997 as HAL's birth year.<ref name="Urbana 1992/7"></ref> 

In "", HAL is initially considered a dependable member of the crew, maintaining ship functions and engaging genially with its human crew-mates on an equal footing. As a recreational activity, Frank Poole plays against HAL in a game of chess. In the film the artificial intelligence is shown to triumph easily. However, as time progresses, HAL begins to malfunction in subtle ways and, as a result, the decision is made to shut down HAL in order to prevent more serious malfunctions. The sequence of events and manner in which HAL is shut down differs between the novel and film versions of the story. In the aforementioned game of chess HAL makes minor and undetected mistakes in his analysis, a possible foreshadowing to HAL's malfunctioning.

In the film, astronauts David Bowman and Frank Poole consider disconnecting HAL's cognitive circuits when he appears to be mistaken in reporting the presence of a fault in the spacecraft's communications antenna. They attempt to conceal what they are saying, but are unaware that HAL can read their lips. Faced with the prospect of disconnection, HAL decides to kill the astronauts in order to protect and continue its programmed directives. HAL uses one of the Discovery's EVA pods to kill Poole while he is repairing the ship. When Bowman uses another pod to attempt to rescue Poole, HAL locks him out of the ship, then disconnects the life support systems of the other hibernating crew members. Bowman circumvents HAL's control, entering the ship by manually opening an emergency airlock with his service pod's clamps, detaching the pod door via its explosive bolts. Bowman jumps across empty space, reenters Discovery, and quickly re-pressurizes the airlock.

While HAL's motivations are ambiguous in the film, the novel explains that the computer is unable to resolve a conflict between his general mission to relay information accurately, and orders specific to the mission requiring that he withhold from Bowman and Poole the true purpose of the mission. (This withholding is considered essential after the findings of a psychological experiment, "Project Barsoom", where humans were made to believe that there had been alien contact. In every person tested, a deep-seated xenophobia was revealed, which was unknowingly replicated in HAL's constructed personality. Mission Control did not want the crew of "Discovery" to have their thinking compromised by the knowledge that alien contact was already real.) With the crew dead, HAL reasons, he would not need to lie to them.

In the novel, the orders to disconnect HAL come from Dave and Frank's superiors on Earth. After Frank is killed while attempting to repair the communications antenna he is pulled away into deep space using the safety tether which is still attached to both the pod and Frank Poole's spacesuit. Dave begins to revive his hibernating crew mates, but is foiled when HAL vents the ship's atmosphere into the vacuum of space, killing the awakening crew members and almost killing Bowman, who is only narrowly saved when he finds his way to an emergency chamber which has its own oxygen supply and a spare space suit inside.

In both versions, Bowman then proceeds to shut down the machine. In the film, HAL's central core is depicted as a crawlspace full of brightly lit computer modules mounted in arrays from which they can be inserted or removed. Bowman shuts down HAL by removing modules from service one by one; as he does so, HAL's consciousness degrades. HAL finally reverts to material that was programmed into him early in his memory, including announcing the date he became operational as 12 January 1992 (in the novel, 1997). When HAL's logic is completely gone, he begins singing the song "Daisy Bell" (in actuality, the first song sung by a computer). HAL's final act of any significance is to prematurely play a prerecorded message from Mission Control which reveals the true reasons for the mission to Jupiter.

In the sequel "", HAL is restarted by his creator, Dr. Chandra, who arrives on the Soviet spaceship "Leonov".

Prior to leaving Earth, Dr. Chandra has also had a discussion with HAL's twin, the SAL 9000. Like HAL, SAL was created by Dr. Chandra. Whereas HAL was characterized as being "male", SAL is characterized as being "female" (voiced by Candice Bergen) and is represented by a blue camera eye instead of a red one.

Dr. Chandra discovers that HAL's crisis was caused by a programming contradiction: he was constructed for "the accurate processing of information without distortion or concealment", yet his orders, directly from Dr. Heywood Floyd at the National Council on Astronautics, required him to keep the discovery of the Monolith TMA-1 a secret for reasons of national security. This contradiction created a "Hofstadter-Moebius loop", reducing HAL to paranoia. Therefore, HAL made the decision to kill the crew, thereby allowing him to obey both his hardwired instructions to report data truthfully and in full, and his orders to keep the monolith a secret. In essence: if the crew were dead, he would no longer have to keep the information secret.

The alien intelligence initiates a terraforming scheme, placing the "Leonov", and everybody in it, in danger. Its human crew devises an escape plan which unfortunately requires leaving the "Discovery" and HAL behind to be destroyed. Dr. Chandra explains the danger, and HAL willingly sacrifices himself so that the astronauts may escape safely. In the moment of his destruction the monolith-makers transform HAL into a non-corporeal being so that David Bowman's avatar may have a companion.

The details in the book and the film are nominally the same, with a few exceptions. First, in contradiction to the book (and events described in both book and film versions of "2001: A Space Odyssey"), Heywood Floyd is absolved of responsibility for HAL's condition; it is asserted that the decision to program HAL with information concerning TMA-1 came directly from the White House. In the film, HAL functions normally after being reactivated, while in the book it is revealed that his mind was damaged during the shutdown, forcing him to begin communication through screen text. Also, in the film the "Leonov" crew lies to HAL about the dangers that he faced (suspecting that if he knew he would be destroyed he would not initiate the engine-burn necessary to get the "Leonov" back home), whereas in the novel he is told at the outset. However, in both cases the suspense comes from the question of what HAL will do when he knows that he may be destroyed by his actions.

The basic reboot sequence initiated by Dr. Chandra in the movie "2010" is voiced from 
HAL as, "HELLO_DOCTOR_NAME_CONTINUE_
YESTERDAY_TOMORROW" (which in the novel "2010" is a longer sequence).

Prior to "Leonov"s return to Earth, Curnow tells Floyd that Dr. Chandra has begun designing HAL 10000.

In "" it is revealed that Chandra died on the journey back to Earth.

In "", Heywood Floyd is surprised to encounter HAL, now stored alongside Dave Bowman in the Europa monolith.

"" Frank Poole was introduced to the merged form of Dave Bowman and HAL, the two merging into one entity called "Halman" after Bowman rescued HAL from the dying "Discovery One" spaceship towards the end of "".

Clarke noted that the film "2001" was criticized for not having any characters, except for HAL and that a great deal of the establishing story on Earth was cut from the film (and even from Clarke's novel). Early drafts of Clarke's story called the computer Socrates (a preferred name to Autonomous Mobile Explorer–5), with another draft giving the computer a female personality called Athena. This name was later used in Clarke and Stephen Baxter's "A Time Odyssey" novel series.

The earliest draft depicted Socrates as a roughly humanoid robot, and is introduced as overseeing Project Morpheus, which studied prolonged hibernation in preparation for long term space flight. As a demonstration to "Senator" Floyd, Socrates' designer, Dr. Bruno Forster, asks Socrates to turn off the oxygen to hibernating subjects Kaminski and Whitehead, which Socrates refuses, citing Asimov's First Law of Robotics.

In a later version, in which Bowman and Whitehead are the non-hibernating crew of Discovery, Whitehead dies outside the spacecraft after his pod collides with the main antenna, tearing it free. This triggers the need for Bowman to revive Poole, but the revival does not go according to plan, and after briefly awakening, Poole dies. The computer, now named Athena, announces "All systems of Poole now No–Go. It will be necessary to replace him with a spare unit." After this, Bowman decides to go out in a pod and retrieve the antenna, which is moving away from the ship. Athena refuses to allow him to leave the ship, citing "Directive 15" which prevents it from being left unattended, forcing him to make program modifications during which time the antenna drifts further.

During rehearsals Kubrick asked Stefanie Powers to supply the voice of HAL 9000 while searching for a suitably androgynous voice so the actors had something to react to. On the set, British actor Nigel Davenport played HAL. When it came to dubbing HAL in post-production, Kubrick had originally cast Martin Balsam, but as he felt Balsam "just sounded a little bit too colloquially American", he was replaced with Douglas Rain, who "had the kind of bland mid-Atlantic accent we felt was right for the part." Rain was only handed HAL's lines instead of the full script, and recorded them across a day and a half.

HAL's point of view shots were created with a Cinerama 160-degree Fairchild-Curtis wide-angle lens. This lens is about in diameter, while HAL's on set prop eye lens is about in diameter. Stanley Kubrick chose to use the large Fairchild-Curtis lens to shoot the HAL 9000 POV shots because he needed a wide-angle fisheye lens that would fit onto his shooting camera, and this was the only lens at the time that would work. 

A HAL 9000 face plate, without lens (not the same as the hero face plates seen in the film), was discovered in a junk shop in Paddington, London, in the early 1970s by Chris Randall. Research revealed that the original lens was a Nikon Nikkor 8mm F8. This was found along with the key to HAL's Brain Room. Both items were purchased for ten shillings (£0.50). The collection was sold at a Christies auction in 2010 for £17,500 to film director Peter Jackson.

HAL's name, according to writer Arthur C. Clarke, is derived from "H"euristically programmed "AL"gorithmic computer. After the film was released fans noticed HAL was a one-letter shift from the name IBM and there has been much speculation since that this was a dig at the large computer company, something that has been denied by both Clarke and "2001" director Stanley Kubrick. Clarke addressed the issue in his book "The Lost Worlds of 2001":
IBM was consulted during the making of the film and their logo can be seen on props in the film including Pan Am Clipper's cockpit instrument panel and on the lower arm keypad on Poole's space suit. During production it was brought to IBM's attention that the film's plot included a homicidal computer but they approved association with the film if it was clear any "equipment failure" was not related to their products.

The scene in which HAL's consciousness degrades was inspired by Clarke's memory of a speech synthesis demonstration by physicist John Larry Kelly, Jr., who used an IBM 704 computer to synthesize speech. Kelly's voice recorder synthesizer "vocoder" recreated the song "Daisy Bell", with musical accompaniment from Max Mathews.

HAL's capabilities, like all the technology in "2001", were based on the speculation of respected scientists. Marvin Minsky, director of the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL) and one of the most influential researchers in the field, was an adviser on the film set. In the mid-1960s, many computer scientists in the field of artificial intelligence were optimistic that machines with HAL's capabilities would exist within a few decades. For example, AI pioneer Herbert A. Simon at Carnegie Mellon University, had predicted in 1965 that "machines will be capable, within twenty years, of doing any work a man can do", the overarching premise being that the issue was one of computational speed (which was predicted to increase) rather than principle.

HAL is listed as the 13th-greatest film villain in the AFI's 100 Years...100 Heroes & Villains.

The 9000th of the asteroids in the asteroid belt, discovered on May 3, 1981 by E. Bowell, at Anderson Mesa Station, is named after HAL 9000.

HAL was featured in a guest role in the game "LEGO Dimensions", where he is summoned by the player in the "Portal 2" level to distract GLaDOS.




</doc>
<doc id="14385" url="https://en.wikipedia.org/wiki?curid=14385" title="Hydrolysis">
Hydrolysis

Hydrolysis (; ) is a term used for both an electro-chemical process and a biological one. The hydrolysis of water is the separation of water molecules into the constituent hydrogen and oxygen atoms with electricity. Biological hydrolysis is the cleavage of biomolecules where a water molecule is consumed to effect the separation of a larger molecule into component parts. When a carbohydrate is broken into its component sugar molecules by hydrolysis (e.g. sucrose being broken down into glucose and fructose), this is termed saccharification. Generally, hydrolysis or saccharification is a step in the degradation of a substance OR in the language of chemistry "The reaction of cation and anion or both with water molecule due to which pH is altered, cleavage of H-O bond in hydrolysis takes place."

Hydrolysis can be the reverse of a condensation reaction in which two molecules join together into a larger one and eject a water molecule. Thus hydrolysis adds water to break down, whereas condensation builds up by removing water and any other solvents.

Usually hydrolysis is a chemical process in which a molecule of water is added to a substance. Sometimes this addition causes both substance and water molecule to split into two parts. In such reactions, one fragment of the target molecule (or parent molecule) gains a hydrogen ion.It breaks down the chemical bond in the compound 

A common kind of hydrolysis occurs when a salt of a weak acid or weak base (or both) is dissolved in water. Water spontaneously ionizes into hydroxide anions and hydronium cations. The salt also dissociates into its constituent anions and cations. For example, sodium acetate dissociates in water into sodium and acetate ions. Sodium ions react very little with the hydroxide ions whereas the acetate ions combine with hydronium ions to produce acetic acid. In this case the net result is a relative excess of hydroxide ions, yielding a basic solution.

Strong acids also undergo hydrolysis. For example, dissolving sulfuric acid (HSO) in water is accompanied by hydrolysis to give hydronium and bisulfate, the sulfuric acid's conjugate base. For a more technical discussion of what occurs during such a hydrolysis, see Brønsted–Lowry acid–base theory.

Acid–base-catalysed hydrolyses are very common; one example is the hydrolysis of amides or esters. Their hydrolysis occurs when the nucleophile (a nucleus-seeking agent, e.g., water or hydroxyl ion) attacks the carbon of the carbonyl group of the ester or amide. In an aqueous base, hydroxyl ions are better nucleophiles than polar molecules such as water. In acids, the carbonyl group becomes protonated, and this leads to a much easier nucleophilic attack. The products for both hydrolyses are compounds with carboxylic acid groups.

Perhaps the oldest commercially practiced example of ester hydrolysis is saponification (formation of soap). It is the hydrolysis of a triglyceride (fat) with an aqueous base such as sodium hydroxide (NaOH). During the process, glycerol is formed, and the fatty acids react with the base, converting them to salts. These salts are called soaps, commonly used in households.

In addition, in living systems, most biochemical reactions (including ATP hydrolysis) take place during the catalysis of enzymes. The catalytic action of enzymes allows the hydrolysis of proteins, fats, oils, and carbohydrates. As an example, one may consider proteases (enzymes that aid digestion by causing hydrolysis of peptide bonds in proteins). They catalyse the hydrolysis of interior peptide bonds in peptide chains, as opposed to exopeptidases (another class of enzymes, that catalyse the hydrolysis of terminal peptide bonds, liberating one free amino acid at a time).

However, proteases do not catalyse the hydrolysis of all kinds of proteins. Their action is stereo-selective: Only proteins with a certain tertiary structure are targeted as some kind of orienting force is needed to place the amide group in the proper position for catalysis. The necessary contacts between an enzyme and its substrates (proteins) are created because the enzyme folds in such a way as to form a crevice into which the substrate fits; the crevice also contains the catalytic groups. Therefore, proteins that do not fit into the crevice will not undergo hydrolysis. This specificity preserves the integrity of other proteins such as hormones, and therefore the biological system continues to function normally.

Upon hydrolysis, an amide converts into a carboxylic acid and an amine or ammonia (which in the presence of acid are immediately converted to ammonium salts). One of the two oxygen groups on the carboxylic acid are derived from a water molecule and the amine (or ammonia) gains the hydrogen ion. The hydrolysis of peptides gives amino acids.

Many polyamide polymers such as nylon 6,6 hydrolyse in the presence of strong acids. The process leads to depolymerization. For this reason nylon products fail by fracturing when exposed to small amounts of acidic water. Polyesters are also susceptible to similar polymer degradation reactions. The problem is known as environmental stress cracking.

Hydrolysis is related to energy metabolism and storage. All living cells require a continual supply of energy for two main purposes: the biosynthesis of micro and macromolecules, and the active transport of ions and molecules across cell membranes. The energy derived from the oxidation of nutrients is not used directly but, by means of a complex and long sequence of reactions, it is channelled into a special energy-storage molecule, adenosine triphosphate (ATP). The ATP molecule contains pyrophosphate linkages (bonds formed when two phosphate units are combined together) that release energy when needed. ATP can undergo hydrolysis in two ways: the removal of terminal phosphate to form adenosine diphosphate (ADP) and inorganic phosphate, or the removal of a terminal diphosphate to yield adenosine monophosphate (AMP) and pyrophosphate. The latter usually undergoes further cleavage into its two constituent phosphates. This results in biosynthesis reactions, which usually occur in chains, that can be driven in the direction of synthesis when the phosphate bonds have undergone hydrolysis.

Monosaccharides can be linked together by glycosidic bonds, which can be cleaved by hydrolysis. Two, three, several or many monosaccharides thus linked form disaccharides, trisaccharides, oligosaccharides or polysaccharides, respectively. Enzymes that hydrolyse glycosidic bonds are called "glycoside hydrolases" or "glycosidases".

The best-known disaccharide is sucrose (table sugar). Hydrolysis of sucrose yields glucose and fructose. Invertase is a sucrase used industrially for the hydrolysis of sucrose to so-called invert sugar. Lactase is essential for digestive hydrolysis of lactose in milk; many adult humans do not produce lactase and cannot digest the lactose in milk (not a disorder).

The hydrolysis of polysaccharides to soluble sugars is called "saccharification". Malt made from barley is used as a source of β-amylase to break down starch into the disaccharide maltose, which can be used by yeast to produce beer. Other amylase enzymes may convert starch to glucose or to oligosaccharides. Cellulose is first hydrolyzed to cellobiose by cellulase and then cellobiose is further hydrolyzed to glucose by beta-glucosidase. Ruminants such as cows are able to hydrolyze cellulose into cellobiose and then glucose because of symbiotic bacteria that produce cellulases.

Metal ions are Lewis acids, and in aqueous solution they form metal aqua ions of the general formula M(HO). The aqua ions undergo hydrolysis, to a greater or lesser extent. The first hydrolysis step is given generically as

Thus the aqua cations behave as acids in terms of Brønsted-Lowry acid-base theory. This effect is easily explained by considering the inductive effect of the positively charged metal ion, which weakens the O-H bond of an attached water molecule, making the liberation of a proton relatively easy.

The dissociation constant, pK, for this reaction is more or less linearly related to the charge-to-size ratio of the metal ion. Ions with low charges, such as Na are very weak acids with almost imperceptible hydrolysis. Large divalent ions such as Ca, Zn, Sn and Pb have a pK of 6 or more and would not normally be classed as acids, but small divalent ions such as Be undergo extensive hydrolysis. Trivalent ions like Al and Fe are weak acids whose pK is comparable to that of acetic acid. Solutions of salts such as BeCl or Al(NO) in water are noticeably acidic; the hydrolysis can be suppressed by adding an acid such as nitric acid, making the solution more acidic.

Hydrolysis may proceed beyond the first step, often with the formation of polynuclear species via the process of olation. Some "exotic" species such as Sn(OH) are well characterized. Hydrolysis tends to proceed as pH rises leading, in many cases, to the precipitation of a hydroxide such as Al(OH) or AlO(OH). These substances, major constituents of bauxite, are known as laterites and are formed by leaching from rocks of most of the ions other than aluminium and iron and subsequent hydrolysis of the remaining aluminium and iron.


</doc>
<doc id="14386" url="https://en.wikipedia.org/wiki?curid=14386" title="Hydroxy group">
Hydroxy group

A hydroxy or hydroxyl group is the entity with the formula OH. It contains oxygen bonded to hydrogen. In organic chemistry, alcohol and carboxylic acids contain hydroxy groups. The anion [OH], called hydroxide, consists of a hydroxy group.

According to IUPAC rules, the term hydroxyl refers to the radical OH only, while the functional group −OH is called hydroxy group.

Water, alcohols, carboxylic acids, and many other hydroxy-containing compounds can be deprotonated readily. This behavior is rationalized by the disparate electronegativities of oxygen and hydrogen. Hydroxy-containing compounds engage in hydrogen bonding, which causes them to stick together, leading to higher boiling and melting points than found for compounds that lack this functional group. Organic compounds, which are often poorly soluble in water, become water-soluble when they contain two or more hydroxy groups, as illustrated by sugars and amino acid.
The hydroxy group is pervasive in chemistry and biochemistry. Many inorganic compounds contain hydroxy groups, including sulfuric acid, the chemical compound produced on the largest scale industrially.

Hydroxy groups participate in the dehydration reactions that link simple biological molecules into long chains. The joining of a fatty acid to glycerol to form a triacylglycerol removes the −OH from the carboxy end of the fatty acid. The joining of two aldehyde sugars to form a disaccharide removes the −OH from the carboxy group at the aldehyde end of one sugar. The creation of a peptide bond to link two amino acids to make a protein removes the −OH from the carboxy group of one amino acid.

Hydroxyl radicals are highly reactive and undergo chemical reactions that make them short-lived. When biological systems are exposed to hydroxyl radicals, they can cause damage to cells, including those in humans, where they can react with DNA, lipids, and proteins.

In 2009, India's Chandrayaan-1 satellite, NASA's Cassini spacecraft and the Deep Impact probe have each detected the presence of water by evidence of hydroxyl fragments on the Moon. As reported by Richard Kerr, "A spectrometer [the Moon Mineralogy Mapper, a.k.a. "M3"] detected an infrared absorption at a wavelength of 3.0 micrometers that only water or hydroxyl—a hydrogen and an oxygen bound together—could have created." NASA also reported in 2009 that the LCROSS probe revealed an ultraviolet emission spectrum consistent with hydroxyl presence. The Venus Express orbiter sent back Venus science data from April 2006 until December 2014. Results from Venus Express include the detection of hydroxyl in the atmosphere.




</doc>
<doc id="14387" url="https://en.wikipedia.org/wiki?curid=14387" title="Warm-blooded">
Warm-blooded

Warm-blooded animal species can maintain a body temperature higher than their environment. In particular, homeothermic species maintain a stable body temperature by regulating metabolic processes. The only known homeotherms are birds and mammals. Other species have various degrees of thermoregulation.

Animal body temperature control varies by species, so the terms "warm-blooded" and "cold-blooded" (though still in everyday use) suggest a false idea of there being only two categories of body temperature control, and are no longer used scientifically.

In general, warm-bloodedness refers to three separate categories of thermoregulation.

A large proportion of the creatures traditionally called "warm-blooded", like birds and mammals, fit all three of these categories (i.e., they are endothermic, homeothermic, "and" tachymetabolic). However, over the past 30 years, studies in the field of animal thermophysiology have revealed many species belonging to these two groups that do not fit all these criteria. For example, many bats and small birds are poikilothermic and bradymetabolic when they sleep for the night (or, in nocturnal species, for the day). For these creatures, the term heterothermy was coined.

Further studies on animals that were traditionally assumed to be cold-blooded have shown that most creatures incorporate different variations of the three terms defined above, along with their counterparts (ectothermy, poikilothermy, and bradymetabolism), thus creating a broad spectrum of body temperature types. Some fish have warm-blooded characteristics, such as the opah. Swordfish and some sharks have circulatory mechanisms that keep their brains and eyes above ambient temperatures and thus increase their ability to detect and react to prey. Tunas and some sharks have similar mechanisms in their muscles, improving their stamina when swimming at high speed.

Body heat is generated by metabolism. This refers to the chemical reactions cells use to break down glucose into water and carbon dioxide and, in so doing, generate ATP (adenosine triphosphate), a high-energy compound used to power other cellular processes. Muscle contraction is a type of metabolic process that generates heat energy, and heat is also generated through friction when blood flows through the circulatory system.

All organisms metabolize food and other inputs, but some make better use of the output than others. Like all energy conversions, metabolism is rather inefficient, and around 60% of the available energy is converted to heat rather than to ATP. In most organisms, this heat is simply lost to the environment. However, endothermic homeotherms (the animals generally characterized as "warm-blooded") both produce more heat and have better ways to retain and regulate it than other animals. They have a higher basal metabolic rate, and also a greater capacity to increase their metabolic rate when engaged in strenuous activity. They usually have well-developed insulation in order to retain body heat, fur in the case of mammals and feathers in birds. When this insulation is insufficient to maintain body temperature, they may resort to shivering—rapid muscle contractions that quickly use up ATP, thus stimulating cellular metabolism to replace it and consequently produce more heat. In general, in hot environments, they use evaporative cooling to shed excess heat, either by sweating (some mammals) or by panting (many mammals and all birds)—in general, mechanisms not present in poikilotherms.

It has been hypothesized that warm-bloodedness evolved in mammals and birds because it provided defense against fungal infections. Very few fungi can survive the body temperatures of warm-blooded animals. By comparison, insects, reptiles, and amphibians are plagued by fungal infections.



</doc>
<doc id="14388" url="https://en.wikipedia.org/wiki?curid=14388" title="Hephaestus">
Hephaestus

Hephaestus (; eight spellings; "Hēphaistos") is the Greek god of blacksmiths, metalworking, carpenters, craftsmen, artisans, sculptors, metallurgy, fire, and volcanoes. Hephaestus' Roman equivalent is Vulcan. In Greek mythology, Hephaestus was the son of Zeus and Hera, the king and queen of the gods. In another version, he was Hera's parthenogenous child, rejected by his mother because of his deformity and thrown off Mount Olympus and down to earth.

As a smithing god, Hephaestus made all the weapons of the gods in Olympus. He served as the blacksmith of the gods, and was worshipped in the manufacturing and industrial centers of Greece, particularly Athens. The cult of Hephaestus was based in Lemnos. Hephaestus' symbols are a smith's hammer, anvil, and a pair of tongs.

Hephaestus is probably associated with the Linear B (Mycenean Greek) inscription , "A-pa-i-ti-jo", found at Knossos; the inscription indirectly attests his worship at that time because it is believed that it reads the theophoric name "Haphaistios" or "Haphaistion". The name of the god in Greek ("Hēphaistos") has a root which can be observed in names of places of Pre-Greek origin, like Phaistos ("Pa-i-to" in Linear B).

Hephaestus is given many epithets. The meaning of each epithet is:

Hephaestus had his own palace on Olympus, containing his workshop with anvil and twenty bellows that worked at his bidding. Hephaestus crafted much of the magnificent equipment of the gods, and almost any finely wrought metalwork imbued with powers that appears in Greek myth is said to have been forged by Hephaestus. He designed Hermes' winged helmet and sandals, the Aegis breastplate, Aphrodite's famed girdle, Agamemnon's staff of office, Achilles' armor, Heracles' bronze clappers, Helios's chariot, the shoulder of Pelops, and Eros's bow and arrows. In later accounts, Hephaestus worked with the help of the chthonic Cyclopes—among them his assistants in the forge, Brontes, Steropes and Pyracmon.

Hephaestus built automatons of metal to work for him. This included tripods that walked to and from Mount Olympus. He gave to the blinded Orion his apprentice Cedalion as a guide. In some versions of the myth, Prometheus stole the fire that he gave to man from Hephaestus's forge. Hephaestus also created the gift that the gods gave to man, the woman Pandora and her pithos. Being a skilled blacksmith, Hephaestus created all the thrones in the Palace of Olympus.

The Greek myths and the Homeric poems sanctified in stories that Hephaestus had a special power to produce motion. He made the golden and silver lions and dogs at the entrance of the palace of Alkinoos in such a way that they could bite the invaders. The Greeks maintained in their civilization an animistic idea that statues are in some sense alive. This kind of art and the animistic belief goes back to the Minoan period, when Daedalus, the builder of the labyrinth, made images which moved of their own accord. A statue of the god was somehow the god himself, and the image on a man's tomb indicated somehow his presence.






In the account of Attic vase painters, Hephaestus was present at the birth of Athena and wields the axe with which he split Zeus' head to free her. In the latter account, Hephaestus is there represented as older than Athena, so the mythology of Hephaestus is inconsistent in this respect.

In one branch of Greek mythology, Hera ejected Hephaestus from the heavens because he was "shrivelled of foot". He fell into the ocean and was raised by Thetis (mother of Achilles and one of the 50 Nereids) and the Oceanid Eurynome.

In another account, Hephaestus, attempting to rescue his mother from Zeus' advances, was flung down from the heavens by Zeus. He fell for an entire day and landed on the island of Lemnos, where he was cared for and taught to be a master craftsman by the Sintians – an ancient tribe native to that island. Later writers describe his lameness as the consequence of his second fall, while Homer makes him lame and weak from his birth.

Hephaestus was one of the Olympians to have returned to Olympus after being exiled.

In an archaic story, Hephaestus gained revenge against Hera for rejecting him by making her a magical golden throne, which, when she sat on it, did not allow her to stand up. The other gods begged Hephaestus to return to Olympus to let her go, but he refused, saying "I have no mother".

At last, Dionysus fetched him, intoxicated him with wine, and took the subdued smith back to Olympus on the back of a mule accompanied by revelers – a scene that sometimes appears on painted pottery of Attica and of Corinth. In the painted scenes, the padded dancers and phallic figures of the Dionysan throng leading the mule show that the procession was a part of the dithyrambic celebrations that were the forerunners of the satyr plays of fifth century Athens.

The theme of the "return of Hephaestus", popular among the Attic vase-painters whose wares were favored among the Etruscans, may have introduced this theme to Etruria. In the vase-painters' portrayal of the procession, Hephaestus was mounted on a mule or a horse, with Dionysus holding the bridle and carrying Hephaestus' tools (including a double-headed axe).

The traveller Pausanias reported seeing a painting in the temple of Dionysus in Athens, which had been built in the 5th century but may have been decorated at any time before the 2nd century CE. When Pausanias saw it, he said:
According to most versions, Hephaestus's consort is Aphrodite, who is unfaithful to Hephaestus with a number of gods and mortals, including Ares. However, in Book XVIII of Homer's "Iliad", the consort of Hephaestus is a lesser Aphrodite, Charis ("the grace") or Aglaia ("the glorious") – the youngest of the Graces, as Hesiod calls her.
In Athens, there is a Temple of Hephaestus, the "Hephaesteum" (miscalled the "Theseum") near the agora. An Athenian founding myth tells that the city's patron goddess, Athena, refused a union with Hephaestus. Pseudo-Apollodorus records an archaic legend, which claims that Hephaestus once attempted to rape Athena, but she pushed him away, causing him to ejaculate on her thigh. Athena wiped the semen off using a tuft of wool, which she tossed into the dust, impregnating Gaia and causing her to give birth to Erichthonius, whom Athena adopted as her own child. The Roman mythographer Hyginus records a similar story in which Hephaestus demanded Zeus to let him marry Athena since he was the one who had smashed open Zeus's skull, allowing Athena to be born. Zeus agreed to this and Hephaestus and Athena were married, but, when Hephaestus was about to consummate the union, Athena vanished from the bridal bed, causing him to ejaculate on the floor, thus impregnating Gaia with Erichthonius.

On the island of Lemnos, Hephaestus' consort was the sea nymph Cabeiro, by whom he was the father of two metalworking gods named the Cabeiri. In Sicily, his consort was the nymph Aetna, and his sons were two gods of Sicilian geysers called Palici. With Thalia, Hephaestus was sometimes considered the father of the Palici.

Hephaestus fathered several children with mortals and immortals alike. One of those children was the robber Periphetes.

This is the full list of his consorts and children according to the various accounts:


In addition, the Romans claim their equivalent god, Vulcan, to have produced the following children:

Though married to Hephaestus, Aphrodite had an affair with Ares, the god of war. Eventually, Hephaestus discovered Aphrodite’s affair through Helios, the all-seeing Sun, and planned a trap during one of their trysts. While Aphrodite and Ares lay together in bed, Hephaestus ensnared them in an unbreakable chain-link net so small as to be invisible and dragged them to Mount Olympus to shame them in front of the other gods for retribution.

The gods laughed at the sight of these naked lovers, and Poseidon persuaded Hephaestus to free them in return for a guarantee that Ares would pay the adulterer's fine. Hephaestus states in "The Odyssey" that he would return Aphrodite to her father and demand back his bride price.

The Thebans told that the union of Ares and Aphrodite produced Harmonia. However, of the union of Hephaestus with Aphrodite, there was no issue unless Virgil was serious when he said that Eros was their child. Later authors explain this statement by saying that Eros was sired by Ares but passed off to Hephaestus as his own son.

Hephaestus was somehow connected with the archaic, pre-Greek Phrygian and Thracian mystery cult of the Kabeiroi, who were also called the "Hephaistoi", "the Hephaestus-men", in Lemnos. One of the three Lemnian tribes also called themselves Hephaestion and claimed direct descent from the god.

Hephaestus is to the male gods as Athena is to the females, for he gives skill to mortal artists and was believed to have taught men the arts alongside Athena. He was nevertheless believed to be far inferior to the sublime character of Athena. At Athens they had temples and festivals in common. Both were believed to have great healing powers, and Lemnian earth (terra Lemnia) from the spot on which Hephaestus had fallen was believed to cure madness, the bites of snakes, and haemorrhage, and priests of Hephaestus knew how to cure wounds inflicted by snakes.

He was represented in the temple of Athena Chalcioecus (Athena of the Bronze House) at Sparta, in the act of delivering his mother; on the chest of Cypselus, giving Achilles's armour to Thetis; and at Athens there was the famous statue of Hephaestus by Alcamenes, in which his lameness was only subtly portrayed. The Greeks frequently placed small dwarf-like statues of Hephaestus near their hearths, and these figures are the oldest of all his representations. During the best period of Grecian art he was represented as a vigorous man with a beard, and is characterized by his hammer or some other crafting tool, his oval cap, and the chiton.

Athena is sometimes thought to be "the ‘soul-mate’ of [Hephaestus]. Yet a kind of cloudy mysteriousness shrouds their relationship; no single tradition was ever clearly established on this subject, and so what confronts us is a blurred image based on rumors and conflicting reports." Nonetheless, he "seeks impetuously and passionately to make love to Athena: at the moment of climax she pushes him aside, and his semen falls to the earth where it impregnates Gaia."

Hephaestus was associated by Greek colonists in southern Italy with the volcano gods Adranus (of Mount Etna) and Vulcanus of the Lipari islands. The first-century sage Apollonius of Tyana is said to have observed, "there are many other mountains all over the earth that are on fire, and yet we should never be done with it if we assigned to them giants and gods like Hephaestus".

In the Trojan war, Hephaestus sided with the Greeks, but was also worshiped by the Trojans and saved one of their men from being killed by Diomedes. Hephaestus’ favourite place in the mortal world was the island of Lemnos, where he liked to dwell among the Sintians, but he also frequented other volcanic islands such as Lipara, Hiera, Imbros and Sicily, which were called his abodes or workshops.

The epithets and surnames by which Hephaestus is known by the poets generally allude to his skill in the plastic arts or to his figure or lameness. The Greeks frequently placed small dwarf-like statues of Hephaestus near their hearths, and these figures are the oldest of all his representations.

Hephaestus was sometimes portrayed as a vigorous man with a beard and was characterized by his hammer or some other crafting tool, his oval cap, and the chiton.

Hephaestus is described in mythological sources as "lame" (), and "halting" ().
He was depicted with crippled feet and as misshapen, either from birth or as a result of his fall from Olympus. In vase paintings, Hephaestus is usually shown lame and bent over his anvil, hard at work on a metal creation, and sometimes with his feet back-to-front: "Hephaistos amphigyēeis". He walked with the aid of a stick. The Argonaut Palaimonius, "son of Hephaestus" (i.e. a bronze-smith) was also lame.

Other "sons of Hephaestus" were the Cabeiri on the island of Samothrace, who were identified with the crab ("karkinos") by the lexicographer Hesychius. The adjective "karkinopous" ("crab-footed") signified "lame", according to Detienne and Vernant. The Cabeiri were also lame.

In some myths, Hephaestus built himself a "wheeled chair" or chariot with which to move around, thus helping him overcome his lameness while demonstrating his skill to the other gods. In the "Iliad" 18.371, it is stated that Hephaestus built twenty bronze wheeled tripods in order assist him in moving around.

Hephaestus’s ugly appearance and lameness is taken by some to represent arsenicosis, an effect of high levels of arsenic exposure that would result in lameness and skin cancers. In place of less easily available tin, arsenic was added to copper in the Bronze Age to harden it; like the hatters, crazed by their exposure to mercury, who inspired Lewis Carroll's famous character of the Mad Hatter, most smiths of the Bronze Age would have suffered from chronic poisoning as a result of their livelihood. Consequently, the mythic image of the lame smith is widespread. As Hephaestus was an iron-age smith, not a bronze-age smith, the connection is one from ancient folk memory.

Parallels in other mythological systems for Hephaestus's symbolism include:

The minor planet 2212 Hephaistos discovered in 1978 by Soviet astronomer Lyudmila Chernykh was named in Hephaestus' honour.




</doc>
<doc id="14389" url="https://en.wikipedia.org/wiki?curid=14389" title="Herman Charles Bosman">
Herman Charles Bosman

Herman Charles Bosman (5 February 1905 – 14 October 1951) is widely regarded as South Africa's greatest short-story writer. He studied the works of Edgar Allan Poe and Mark Twain and developed a style emphasizing the use of satire. His English-language works utilize primarily Afrikaner characters and highlight the many contradictions in Afrikaner society during the first half of the twentieth century. 

Bosman was born at Kuils River, near Cape Town, to an Afrikaner family. He was raised with English as well as Afrikaans. While Bosman was still young, his family travelled frequently, he spent a short time at Potchefstroom College which would later become Potchefstroom High School for Boys, he later moved to Johannesburg where he went to school at Jeppe High School for Boys in Kensington. While there he contributed to the school magazine. When Bosman was sixteen, he started writing short stories for the national Sunday newspaper (the "Sunday Times"). He attended the Johannesburg College of Education (which in 2002 was incorporated into the University of the Witwatersrand) and submitted various pieces to student literary competitions.

After graduation, Bosman accepted a teaching position in the Groot Marico district in an Afrikaans-language school. The area provided the backdrop for his best-known short stories, the "Oom Schalk Lourens" series (featuring an older character named Oom Schalk Lourens) and the "Voorkamer" sketches.

Over the school holidays in 1926, Bosman visited his family in Johannesburg. During an argument, he shot and killed his stepbrother. Bosman was sentenced to death for the crime and was sent to Death row at the Pretoria Central Prison. His sentence was later reduced to ten years with hard labour. In 1930, he was released on parole after serving half his sentence. His prison experiences formed the basis for his semi-autobiographical book, "Cold Stone Jug".

Bosman then started his own printing-press company and was part of a literary set in Johannesburg, associating with poets, journalists, and writers, including Aegidius Jean Blignaut. He toured overseas for nine years, spending most of his time in London. The short stories that he wrote during this period formed the basis for another of his best-known books, "Mafeking Road".

At the start of the Second World War, he returned to South Africa and worked as a journalist. During this time he translated the "Rubaiyat of Omar Khayyam" into Afrikaans.

Bosman lamented the fact that Johannesburg neglected its heritage. In "The Standard Theatre" he complained that the city's residents:

"will pull down the Standard Theatre like they have pulled down all the old buildings, theatres, gin-palaces, dosshouses, temples, shops, arcades, cafes and joints that were intimately associated with the mining-camp days of Johannesburg. Because I know Johannesburg. And I am satisfied that there is no other city in the world that is so anxious to shake off the memories of its early origins."

Bosman's second wife was Ella Manson. The couple were renowned for their bohemian lifestyle and parties, which featured witty conversation and usually ended well after midnight.

From 1948 to his death in 1951, Bosman was employed as proof editor at The Sunday Express. In addition, he was contracted to write a weekly Voorkamer story for "The Forum" magazine.

His last wife was Helena Lake (née Stegmann). After a housewarming party in October 1951, Bosman experienced severe chest pains and was taken to Edenvale Hospital. On admission, he was asked for his birthplace. He replied, "Born Kuilsrivier – Died Edenvale Hospital." He was discharged and collapsed at home a few hours later. Bosman died as he was being rushed to hospital. He is buried in Westpark Cemetery in Westdene under a triangular headstone that reads "Die Skrywer, The Writer, Herman Charles Bosman, b 3.2.1905, d 14.10.1951."

After his death, the rights to his works were auctioned. They were purchased by his last wife, Helena, and upon her death, the rights were passed to her son, who retains them. In 1960, however, Helena sold some of his documents and 123 of his water colours and pencil sketches to the Harry Ransom Center in Texas.

Only three of his books were published during his lifetime: "Mafeking Road" published by Dassie, and "Jacaranda in the Night" and "Cold Stone Jug" published by APB. "Mafeking Road" has never been out of print since its publication in 1947.

His biography was written several times by Valerie Rosenberg. Her first effort was called "Sunflower to the Sun", followed by "Herman Charles Bosman, a Pictorial Biography", and most recently by "Herman Charles Bosman: Between the Lines". The last of these contains much new research and deals in detail with aspects of Bosman's life and parentage that were previously considered taboo.

Because many of his stories were originally published in long-forgotten magazines and journals, there are a number of anthologies by different collators each containing a different selection. His original books have also been published many times by different publishers.

The Herman Charles Bosman Literary Society meets annually for readings, performances and discussions of his works.





</doc>
<doc id="14390" url="https://en.wikipedia.org/wiki?curid=14390" title="Hungarian">
Hungarian

Hungarian may refer to:



</doc>
<doc id="14392" url="https://en.wikipedia.org/wiki?curid=14392" title="Howitzer">
Howitzer

A howitzer is a type of artillery piece characterized by a relatively short barrel and the use of comparatively small propellant charges to propel projectiles over relatively high trajectories, with a steep angle of descent.
In the taxonomies of artillery pieces used by European (and European-style) armies in the 17th to 20th centuries, the howitzer stood between the "gun" (characterized by a longer barrel, larger propelling charges, smaller shells, higher velocities, and flatter trajectories) and the "mortar" (which was meant to fire at even higher angles of ascent and descent). Howitzers, like other artillery equipment, are usually organized in groups called batteries.

The English word "howitzer" comes from the Czech word "houfnice", from "houf", "crowd", and "houf" is in turn a borrowing from the Middle High German word "Hūfe" or "Houfe" (modern German "Haufen"), meaning "heap". "Haufen", sometimes in the compound "Gewalthaufen", also designated a pike square formation in German.

In the Hussite Wars of the 1420s and 1430s, the Czechs used short barreled ""houfnice"" cannons to fire at short distances into crowds of infantry, or into charging heavy cavalry, to make horses shy away. The word was rendered into German as "aufeniz" in the earliest attested use in a document dating from 1440; later German renderings include "haussnitz" and, eventually "haubitze", from which derive the Scandinavian "haubits", Croatian, Polish and Serbian "haubica", Finnish "haupitsi", Russian and Bulgarian "gaubitsa (гаубица)", Italian "obice", Spanish "obús", Portuguese "obus", French "obusier" and the Dutch word "houwitser," which led to the English word "howitzer".

Since the First World War, the word "howitzer" has been increasingly used to describe artillery pieces that, strictly speaking, belong to the category of "gun-howitzers" – relatively long barrels and high muzzle velocities combined with multiple propelling charges and high maximum elevations. This is particularly true in the armed forces of the United States, where gun-howitzers have been officially described as "howitzers" for more than sixty years. Because of this practice, the word "howitzer" is used in some armies as a generic term for any kind of artillery piece that is designed to attack targets using indirect fire. Thus, artillery pieces that bear little resemblance to howitzers of earlier eras are now described as "howitzers", although the British call them "guns". Most other armies in the world reserve the word "howitzer" for guns with barrel lengths 15 to 25 times their caliber, longer-barreled guns being termed cannons.

The British had a further method of nomenclature. In the 18th century, they adopted projectile weight for guns replacing an older naming system (such as culverin, saker, etc.) that had developed in the late 15th century. Mortars had been categorized by calibre in inches in the 17th century and this was inherited by howitzers.

Current U.S. military doctrine defines howitzers as any cannon artillery capable of high-angle (45° to 90° elevation) and low-angle (45° to 0° elevation) fire; guns are defined as being only capable of low-angle fire, and mortars only capable of high-angle fire.

The modern howitzers were invented in Sweden towards the end of the 17th century. These were characterized by a shorter trail than other field guns, meaning less stability when firing, which reduced the amount of powder that could be used; armies using these had to rely on a greater elevation angle to achieve a given range, which gave a steeper angle of descent.

Originally intended for use in siege warfare, they were particularly useful for delivering cast-iron shells filled with gunpowder or incendiary materials into the interior of fortifications. In contrast to contemporary mortars, which were fired at a fixed angle and were entirely dependent on adjustments to the size of propellant charges to vary range, howitzers could be fired at a wide variety of angles. Thus, while howitzer gunnery was more complicated than the technique of employing mortars, the howitzer was an inherently more flexible weapon that could fire its projectiles along a wide variety of trajectories.
In the middle of the 18th century, a number of European armies began to introduce howitzers that were mobile enough to accompany armies in the field. Though usually fired at the relatively high angles of fire used by contemporary siege howitzers, these field howitzers were rarely defined by this capability. Rather, as the field guns of the day were usually restricted to inert projectiles (which relied entirely on momentum for their destructive effects), the field howitzers of the 18th century were chiefly valued for their ability to fire explosive shells. Many, for the sake of simplicity and rapidity of fire, dispensed with adjustable propellant charges.

The Abus gun was an early form of howitzer in the Ottoman Empire. In 1758 the Russian Empire introduced a specific type of howitzer (or rather gun-howitzer), with a conical chamber, called a licorne, which remained in service for the next 100 years.

In the mid-19th century, some armies attempted to simplify their artillery parks by introducing smoothbore artillery pieces that were designed to fire both explosive projectiles and cannonballs, thereby replacing both field howitzers and field guns. The most famous of these "gun-howitzers" was the Napoleon 12-pounder, a weapon of French design that saw extensive service in the American Civil War. The longest-serving artillery piece of the 19th century was the mountain howitzer, which saw service from the war with Mexico to the Spanish–American War.

In 1859, the armies of Europe (including those that had recently adopted gun-howitzers) began to rearm field batteries with rifled field guns. These new field pieces used cylindrical projectiles that, while smaller in caliber than the spherical shells of smoothbore field howitzers, could carry a comparable charge of gunpowder. Moreover, their greater range let them create many of the same effects (such as firing over low walls) that previously required the sharply curved trajectories of smoothbore field howitzers. Because of this, military authorities saw no point in obtaining rifled field howitzers to replace their smoothbore counterparts but, instead, used rifled field guns to replace both guns and howitzers.

In siege warfare, the introduction of rifling had the opposite effect. In the 1860s, artillery officers discovered that rifled siege howitzers (substantially larger than field howitzers) were a more efficient means of destroying walls (particularly walls protected by certain kinds of intervening obstacles) than smoothbore siege guns or siege mortars. Thus, at the same time armies were taking howitzers of one sort out of their field batteries, they were introducing howitzers of another sort into their siege trains and fortresses. The lightest of these weapons (later known as "light siege howitzers") had calibers around 150 mm and fired shells that weighed between 40 and 50 kilograms. The heaviest (later called "medium siege howitzers") had calibers between 200 mm and 220 mm and fired shells that weighed about 100 kilograms (220 pounds).
In the Russo-Turkish War of 1877–1878, the inability of rifled field guns to inflict significant damage on field fortifications led to a revival of interest in field howitzers. By the 1890s, a number of European armies fielded either light (105 mm to 127 mm) or heavy (149 mm to 155 mm) field howitzers and a few, such as that of Germany, fielded both.

During the 1880s, a third type of siege howitzer was added to inventories of a number of European armies. With calibers that ranged between 240 mm and 270 mm and shells that weighed more than 150 kilos, these soon came to be known as "heavy siege howitzers". A good example of a weapon of this class is provided by the 9.45-inch (240 mm) weapon that the British Army purchased from the Skoda works in 1899. Intended for use against the fortifications of Pretoria, which fell before the howitzer could be used, and subsequently deployed to China for use against the fortifications of Peking, which also fell without a siege, the howitzer was never fired in anger.

In the early 20th century, the introduction of howitzers that were significantly larger than the heavy siege howitzers of the day made necessary the creation of a fourth category, that of "super-heavy siege howitzers". Weapons of this category include the famous Big Bertha of the German Army and the 15-inch (381 mm) howitzer of the British Royal Marine Artillery. These large howitzers were transported mechanically rather than by teams of horses. They were transported as several loads and had to be assembled at their firing position.

These field howitzers introduced at the end of the 19th century could fire shells with high trajectories giving a steep angle of descent and, as a result, could strike targets that were protected by intervening obstacles. They could also fire shells that were about twice as large as shells fired by guns of the same size. Thus, while a 75 mm field gun that weighed one ton or so was limited to shells that weighed less than 8 kilograms, a 105 mm howitzer of the same weight could fire 15 kilogram shells. This is a matter of fundamental mechanics affecting the stability and hence the weight of the carriage. However, howitzers had a shorter maximum range than the equivalent gun.

As heavy field howitzers and light siege howitzers of the late 19th and early 20th centuries used ammunition of the same size and types, there was a marked tendency for the two types to merge. At first, this was largely a matter of the same basic weapon being employed on two different mountings. Later, as on-carriage recoil-absorbing systems eliminated many of the advantages that siege platforms had enjoyed over field carriages, the same combination of barrel assembly, recoil mechanism and carriage was used in both roles.

By the early 20th century, the differences between guns and howitzers were relative not absolute and generally recognized as follows:

The onset of trench warfare after the first few months of the First World War greatly increased the demand for howitzers that gave a steep angle of descent, which were better suited than guns to the task of striking targets in a vertical plane (such as trenches), with large amounts of explosive and considerably less barrel wear. The German army was well equipped with howitzers, having far more at the beginning of the war than France.

Many howitzers introduced in the course of World War I had longer barrels than pre-war howitzers. The standard German light field howitzer at the start of the war (the 10.5 cm leichte Feldhaubitze 98/09) had a barrel that was 16 calibers long, but the light field howitzer adopted by the German Army in 1916 (105 mm leichte Feldhaubitze 16, see on the left) had a barrel that was 22 calibers long. At the same time, new models of field gun introduced during that conflict, such as the 77 mm field gun adopted by the German Army in 1916 (7,7 cm Feldkanone 16) were often provided with carriages that allowed firing at comparatively high angles, and adjustable propellant cartridges. In other words, there was a marked tendency for howitzers to become more "gun-like", while guns were taking on some of the attributes of howitzers.

In the years after World War I, the tendency of guns and howitzers to acquire each other's characteristics led to the renaissance of the concept of the gun-howitzer. This was a product of technical advances such as the French invention of autofrettage just before World War I, which led to stronger and lighter barrels, the use of cut-off gear to control recoil length depending on firing elevation angle, and the invention of muzzle brakes to reduce recoil forces. Like the gun-howitzers of the 19th century, those of the 20th century replaced both guns and howitzers.
Thus, the 25-pounder "gun-howitzer" of the British Army replaced both the 18-pounder field gun and the 4.5-inch howitzer. While this had the effect of simplifying such things as organization, training and the supply of ammunition, it created considerable confusion in the realm of nomenclature. In the US Army, however, the preferred term was "howitzer". Thus, as gun-howitzers replaced both guns and howitzers, words such as "obusier" (French) and "Haubitze" (German), which had originally been used to designate weapons with relatively short barrels, were applied to weapons with much longer barrels.

During World War II, the military doctrine of Soviet deep battle called for extensive use of heavy artillery to hold the formal line of front. Soviet doctrine was remarkably different from the German doctrine of Blitzkrieg, and called for a far more extensive use of artillery. As a result, howitzers saw most of the action on the Eastern front, and most of the best howitzers of the WWII period were Soviet-made, as other allies mostly relied on different types of assault for the battle. Most of the howitzers produced by the USSR at the time were not self-propelled, as the country did not have resources to spare for the construction of the engines for the self-propelled variants.

Notable examples of Soviet howitzers include the M-10, M-30 and D-1. As Soviet howitzers were deployed a lot more than comparable Allied or Axis guns, they often had worse "paper characteristics" that were deliberately sacrificed to improve operational performance and the usability of the artillery pieces by the deployed troops.

Since World War II, most of the artillery pieces adopted by armies for attacking targets on land have combined the traditional characteristics of guns and howitzers—high muzzle velocity, long barrels, long range, multiple charges and maximum elevation angles greater than 45 degrees. The term "gun-howitzer" is sometimes used for these (e.g., in Russia); many nations use "howitzer", while the UK (and most members of The Commonwealth of Nations) calls them "guns", for example Gun, 105 mm, Field, L118.





</doc>
<doc id="14395" url="https://en.wikipedia.org/wiki?curid=14395" title="Hummer">
Hummer

Hummer was a brand of trucks and SUVs, first marketed in 1992 when AM General began selling a civilian version of the M998 Humvee. In 1998, General Motors (GM) purchased the brand name from AM General and marketed three vehicles: the original Hummer H1, based on the military Humvee, as well as the new H2 and H3 models that were based on smaller, civilian-market GM platforms.

By 2008, Hummer's viability in the economic downturn was being questioned, and it was placed under review by GM management. Rather than being transferred to the Motors Liquidation Company as part of the GM bankruptcy in 2009, the brand was retained by GM, in order to investigate its sale.

In 2009, a Chinese manufacturer, Sichuan Tengzhong Heavy Industrial Machinery Company, announced that it would acquire Hummer, pending government approvals, but later withdrew its bid. On February 24, 2010, Reuters reported that the Chinese ministry of commerce had prevented the deal, although a ministry spokesperson denied rejecting the application, which had been stalled for eight months. At the end of February, General Motors announced it would begin dismantling the Hummer brand.

Although the automaker announced two days later that it had been approached with new offers, by April 2010, any sale became unlikely, as inventory was depleted and Hummer dealerships began shutting down. After filling a rental-car fleet order, the last Hummer H3 rolled off the line at Shreveport on May 24, 2010.

The original maker of Hummer, AM General, lost their bid to build the HMMWV's replacement for the U.S. military in 2015.

The original Hummers were designed by AM General Corporation, a wholly owned subsidiary of American Motors Corporation (AMC), and were built at their Mishawaka assembly plant in Indiana. The Humvee replaced the military Jeeps that were produced by AMC until 1982.

In 1979, the United States Army was seeking contractors for a new "High Mobility Multi-Purpose Wheeled Vehicle" (HMMWV) which could follow the tracks and ruts of full size army trucks. At that time, General Dynamics, Teledyne, and Chrysler Defense had HMMWV designs under development. Among the four competitors for the contract, AM General designed an entirely new vehicle to meet the Army's requirements. In less than one year, it was the first to deliver a prototype vehicle. Initial production versions were delivered to the Army's proving grounds in April 1982.

After testing was completed AM General was awarded the contract to supply its HMMWV to the United States armed forces. The first models were built in a variety of military-based equipment and versions. The first contract was in 1983, worth US$1.2 billion to produce 55,000 "Humvees" by 1985. The first production vehicle was assembled by AM General on January 2, 1985. The contract was later increased for an additional 15,000 units.

AM General had planned to sell a civilian version of the Humvee as far back as the late 1980s. Having the same structure and most mechanical components, the civilian Hummers were finished in automotive gloss paint, adding passenger car enhancements such as air conditioning, sound insulation, upgraded upholstery, stereo systems, wood trim, and convenience packages. The civilian model began in part because of the persistence of Arnold Schwarzenegger, who saw an Army convoy while filming a movie.

In 1992, AM General began selling a civilian version of the M998 Humvee vehicle to the public under the brand name "Hummer".

In December 1999, AM General sold the brand name to General Motors, but continued to manufacture the vehicles. GM was responsible for the marketing and distribution of all Hummers produced by AM General. Shortly thereafter, GM introduced two of its own design models, the H2 and H3, and renamed the original vehicle H1. AM General continued to build the H1 until it was discontinued in 2006, and was contracted by GM to produce the H2. The H3 was built in Shreveport, LA alongside the Chevrolet Colorado and GMC Canyon pickups, with which it shared the GMT-355 platform (modified and designated GMT-345). Hummer dealership buildings featured an oversized half Quonset Hut style roof, themed to the Hummer brand's military origins.

By 2006, the Hummer began to be exported and sold through importers and distributors in 33 countries. On October 10, 2006, GM began producing the Hummer H3 at its Port Elizabeth plant in South Africa for international markets. The Hummers built there at first were only left-hand drive, but right-hand drive versions were added and exported to Australia and other markets.

The H2 was also assembled in Kaliningrad, Russia, by Avtotor, starting in 2006 and ending in 2009. The plant produced a few hundred vehicles annually, and its output was limited to local consumption with five dealers in Russia.

On June 3, 2008, one day prior to GM's annual shareholder meeting, Rick Wagoner, GM's CEO at that time, said the brand was being reviewed, and had the possibility of either being sold, having the production line completely redesigned, or being discontinued. This was due to the decreasing demand for large SUVs as a result of higher oil prices. Almost immediately after the announcement, a pair of Indian automakers, including Mahindra & Mahindra, expressed interest in purchasing all or part of Hummer.

In April 2009, GM President Fritz Henderson stated several interested parties had approached GM regarding the Hummer business.

On June 1, 2009, as a part of the General Motors bankruptcy announcement, the company revealed that the Hummer brand would be discontinued. However, the following day GM announced that instead it had reached a deal to sell the brand to an undisclosed buyer. After GM announced that same day that the sale was to an undisclosed Chinese company, CNN and the New York Times identified the buyer of the Hummer truck unit as China-based Sichuan Tengzhong Heavy Industrial Machinery Company Ltd. Later that day, Sichuan Tengzhong itself announced the deal on their own website.

On January 6, 2010, GM CEO Ed Whitacre said he hoped to close the deal with Tengzhong by the end of that month. On February 1, 2010, it was announced that Sichuan and General Motors had agreed to extend the deadline until the end of February as Sichuan tried to get approval by the Chinese government. It was also revealed that the price tag of the Hummer brand was $150 million.

Later, on February 24, 2010, GM announced the Tengzhong deal had collapsed and the Hummer brand would soon shut down. There were reports that Sichuan Tengzhong might pursue the purchase of the Hummer brand from GM by purchasing it privately through the company's new J&A Tengzhong Fund SPC, a private equity investment fund owned by an offshore entity that was recruiting private investors to buy into its acquisition plan. The financial markets posed problems for established borrowers and even more for Tengzhong, a little-known company from western China, at the same time as the potential value of the Hummer brand continued to decline given high fuel prices and weak consumer demand.

The company announced it was willing to consider offers for all or part of the assets. American company Raser Technologies along with several others expressed interest in buying the company. However, on April 7, 2010, this attempt failed as well, and General Motors officially said it was shutting down the Hummer SUV brand and offering rich rebates in a bid to move the remaining 2,200 vehicles.

The first vehicle in the Hummer range was the Hummer H1, based on the Humvee. Originally released in 1992, this vehicle was designed by American Motors' AM General subsidiary for the U.S. Military. Five years previously, AMC had been bought by Chrysler.

The Hummer H2 was the second vehicle in the Hummer range. There were two variations: The H2 SUV and H2 SUT.

The H3 and H3T truck were the smallest of the Hummer models and were based on the GMT355 platform shared with the Chevrolet Colorado and GMC Canyon compact pickup trucks.

The Hummer HX was developed in 2008 as an open-air, two-door off-road concept car, smaller than other Hummer models.

Raser Technologies (formerly of Utah) was to use technology similar to that in the Chevrolet Volt. The company unveiled the prototype to the 2009 Society of Automotive Engineers World Congress in Detroit. The E-REV (Extended-Range Electric Vehicle) powertrain technology, was claimed to power the vehicle for up to on its battery, and then a small 4-cylinder internal combustion engine would start to generate more electricity.

Team Hummer Racing was created in 1993. Led by off-road racer Rod Hall, Team Hummer competed in the stock classes of both BitD and SCORE, with specialized racing shock absorbers, tires, and other modifications, along with mandatory safety equipment. Team Hummer stock-class H3 driven by Hall finished first in class with the H3 in the 2005 Baja 1000. Team Hummer earned 11 production-class wins at the Baja 1000.

A highly modified, two-wheel drive Hummer was raced by Robby Gordon in the 2006 (did not finish), 2007 (8th place), 2009 (3rd place), 2010 (8th place), 2011 (did not finish), 2012 (disqualified), and 2013 (14th place) Dakar Rally.

The popularity of the H2 Hummer with the general public created a demand for a large scale production of a stretched limousine version. The H2 Hummer was cut behind the cab and the chassis extended to create a passenger section for 14, 16 or even 22 passengers. The demand initially was for clients in the United States but quickly became popular in the UK and especially Australia. The limousine hire industry have adapted the all terrain vehicle to become a social vehicle to celebrate events. Although not in mass production since 2010, these vehicles are still modified and engineered by private manufacturers worldwide. 


Criticism of Hummers mirrors the criticism of SUVs in general, but to a higher degree. Specific criticisms of Hummers include:





GM is active in licensing the Hummer. Various companies have licensed the Hummer trademarks for use on colognes, flashlights, bicycles, shoes, coats, hats, laptops, toys, clothing, CD players, and other items. An electric quadricycle badged as a Hummer is produced in the UK.




</doc>
<doc id="14396" url="https://en.wikipedia.org/wiki?curid=14396" title="Humvee">
Humvee

The High Mobility Multipurpose Wheeled Vehicle (HMMWV; colloquial: Humvee) is a family of light, four-wheel drive, military trucks and utility vehicles produced by AM General. It has largely supplanted the roles previously performed by the original jeep, and others such as the Vietnam War-era M151 jeep, the M561 "Gama Goat", their M718A1 and M792 ambulance versions, the Commercial Utility Cargo Vehicle (CUCV), and other light trucks. Primarily used by the United States military, it is also used by numerous other countries and organizations and even in civilian adaptations. The Humvee saw widespread use in the Gulf War of 1991, where it negotiated the treacherous desert terrain; this usage helped to inspire civilian Hummer versions. After going through a replacement process, the Joint Light Tactical Vehicle (JLTV) was chosen as its successor.

Since the World War II ¼-ton reconnaissance truck was green-lit for mass-deployment, and became known as the "jeep", the United States Military had continued to rely heavily on jeeps as general utility vehicles, and as a mass-transport for soldiers in small groups. Although the US Army had let Ford redesign the jeep from the ground up during the 1950s, and the resulting M151 jeep incorporated significant innovations, it firmly adhered to the original concept – a very compact, lightweight, low profile vehicle, with a folding windshield, that a layman could barely distinguish from the preceding Willys jeeps. The jeeps were shorter than a Volkswagen Beetle and weighed just over one metric ton, seating three with an payload. During and after the war, the very light, -ton jeeps were complemented by the -ton Dodge WC and Korea War M37 models.

By the mid-1960s, the U.S. military clearly felt a need to reevaluate their ageing light vehicle fleet. For starters, from the mid 1960s, the U.S. Army had tried to modernize, through replacing the larger, purpose-built Dodge M37s by militarized, "commercial off the shelf" (COTS) 4x4 trucks — initially the M715 Jeep trucks, succeeded in the later 1970s by the Dodge M880 series, but these didn't satisfy newer requirements either — what was wanted was a truly versatile light military truck, that could replace multiple outdated vehicles. When becoming aware of the U.S. Army's desire for a versatile new light weapons carrier / reconnaissance vehicle, as early as 1969 FMC Corporation started development on their XR311 prototype, and offered it for testing in 1970. At least a dozen of these were built for testing under the "High Mobility Combat Vehicle", or HMCV program, initially much more as an enhanced capability successor to the M151 jeep, than as a general purpose load lugger. In 1977, Lamborghini developed the Cheetah model in an attempt to meet the Army contract specifications.

In 1979, the U.S. Army drafted final specifications for a High Mobility Multipurpose Wheeled Vehicle (HMMWV), which was to replace all the tactical vehicles in the 1/4 to 1 1/4-ton range, namely the M151 quarter-ton jeep and M561 Gama Goat, as one "jack-of-all-trades" light tactical vehicle to perform the role of several existing trucks. The specification called for excellent on and off-road performance, the ability to carry a large payload, and improved survivability against indirect fire. Compared to the jeep, it was larger and had a much wider track, with a ground clearance, double that of most sport-utility vehicles. The new truck was to climb a 60 percent incline and traverse a 40 percent slope. The air intake was to be mounted flush on top of the right fender (or to be raised on a stovepipe to roof level to ford of water and electronics waterproofed to drive through of water were specified. The radiator was to be mounted high, sloping over the engine on a forward-hinged hood.

Out of 61 companies that showed interest, only three submitted prototypes. In July 1979, AM General, a subsidiary of American Motors Corporation began preliminary design work. Less than a year later, the first prototype was in testing. Chrysler Defense and Teledyne Continental also produced competing designs. In June 1981, the Army awarded AM General a contract for development of several more prototype vehicles to be delivered to the government for another series of tests. The original M998 A0 series had a curb weight of , a payload of , a V-8 diesel engine, and a three-speed automatic transmission.

The three companies were chosen to design and build eleven HMMWV prototypes, which covered over 600,000 miles in trials which included off-road courses in desert and arctic conditions. AM General was awarded an initial contract in 1983 for 2,334 vehicles, the first batch of a five-year contract that would see 55,000 vehicles delivered to the U.S. military, including 39,000 vehicles for the Army; 72,000 vehicles had been delivered to U.S. and foreign customers by the Persian Gulf War of 1991, and 100,000 were delivered by the Humvee's 10th anniversary in 1995. Ft. Lewis, Washington and the 2nd Battalion 1st Infantry, 9th Infantry Division was the testing unit to employ HMMWV in the new concept of a motorized division. Yakima Training Center in Yakima, Washington was the main testing grounds for HMMWVs from 1985 through December 1991, when the motorized concept was abandoned and the division inactivated.

HMMWVs first saw combat in Operation Just Cause, the U.S. invasion of Panama in 1989.

The HMMWV was designed primarily for personnel and light cargo transport behind front lines, not as a front line fighting vehicle. Like the previous jeep, the basic HMMWV has no armor or protection against chemical, biological, radiological or nuclear threats. Nevertheless, losses were relatively low in conventional operations, such as the Gulf War. Vehicles and crews suffered considerable damage and losses during the Battle of Mogadishu in 1993 due to the nature of the urban engagement. However, the chassis survivability allowed the majority of those crews to return to safety, though the HMMWV was never designed to offer protection against intense small arms fire, much less machine guns and rocket-propelled grenades. With the rise of asymmetric warfare and low intensity conflicts, the HMMWV was pressed into service in urban combat roles for which it was not originally intended.

After Operation Restore Hope in Somalia, the military recognized a need for a more protected HMMWV and AM General developed the M1114, an armored HMMWV to withstand small arms fire. The M1114 has been in production since 1996, seeing limited use in the Balkans before deployment to the Middle East. This design is superior to the M998 with a larger, more powerful turbocharged engine, air conditioning, and a strengthened suspension system. More importantly, it boasts a fully armored passenger area protected by hardened steel and bullet-resistant glass. With the increase in direct attacks and guerrilla warfare in Iraq, AM General diverted the majority of its manufacturing power to producing these vehicles.

Humvees were sent into Afghanistan following the 9/11 terrorist attacks, where they proved invaluable during initial operations. In the early years before IEDs became prevalent, the vehicle was liked by troops for its ability to access rough, mountainous terrain. Some soldiers would remove features from Humvees, including what little armor it had and sometimes even entire doors, to make them lighter and more maneuverable for off-road conditions and to increase visibility. With the onset of the Iraq War, Humvees proved very vulnerable to IEDs; in the first four months of 2006, 67 U.S. troops died in Humvees. To increase protection, the U.S. military hastily added-on armor kits to the vehicles. Although this somewhat improved survivability, bolting on armor made the Humvee an "ungainly beast," increasing weight and putting strain on the chassis, which led to unreliability. Armored doors that weighed hundreds of pounds were difficult for troops to open and the newly armored turret made Humvees top heavy and increased the danger of rollovers. The U.S. Marine Corps decided to start replacing Humvees in combat with MRAPs in 2007, and the U.S. Army stated that the vehicle was "no longer feasible for combat" in 2012.

The HMMWV has become the vehicular backbone of U.S. forces around the world. Over 10,000 HMMWVs were employed by coalition forces during the Iraq War. The Humvee has been described as "the right capability for its era" to provide payload mobility in protected areas, but that conflicts exposing it to full-spectrum threat environments that it was never designed to operate or be survivable in led to adding protection at the cost of mobility and payload.

In December 2004, Secretary of Defense Donald Rumsfeld came under criticism from U.S. troops and their families for not providing better-equipped HMMWVs. Rumsfeld pointed out that, prior to the war, armor kits were produced only in small numbers per year. As the role of American forces in Iraq changed from fighting the Iraqi Army to suppressing the guerrilla insurgency, more armor kits were being manufactured, though perhaps not as fast as production facilities were capable. Even more advanced kits were also being developed. While these kits are much more effective against all types of attacks, they weigh from and have some of the same drawbacks as the improvised armor. Unlike similar-size civilian cargo and tow trucks, which typically have dual rear wheels to reduce sway, the HMMWV has single rear wheels due to its independent rear suspension coupled with the body design.
Most up-armored HMMWVs hold up well against lateral attacks, when the blast is distributed in all different directions, but offers little protection from a mine blast below the truck, such as buried improvised explosive devices (IEDs) and land mines. Explosively formed penetrators (EFPs) can also defeat the armor kits, causing casualties.

The armor kits fielded include the Armor Survivability Kit (ASK), the FRAG 5, FRAG 6, as well as upgrade kits to the M1151. The ASK was the first fielded, in October 2003, adding about to the weight of the vehicle. Armor Holdings fielded an even lighter kit, adding only to the vehicle's weight. The Marine Armor Kit (MAK), fielded in January 2005, offers more protection than the M1114, but also increases weight. The FRAG 5 offered even more protection but was still inadequate to stop EFP attacks. The FRAG 6 kit is designed to do just that, however its increased protection adds over the vehicle over the FRAG 5 kit, and the width is increased by . In addition, the doors may require a mechanical assist device to open and close.

Another drawback of the up-armored HMMWVs occurs during an accident or attack, when the heavily armored doors tend to jam shut, trapping the troops inside. As a result, HMMWVs were fitted with hooks on their doors, so that another vehicle can rip the door off, freeing the troops inside. In addition, Vehicle Emergency Escape (VEE) windows, developed by BAE Systems, were fielded for use on the M1114 uparmored HMMWV, with 1,000 kits ordered.

The soldier manning the exposed crew-served weapon on top of the vehicle is extremely vulnerable. In response, many HMMWVs have been fitted with basic gun shields or turrets, as was the case with M113 APCs after they were first deployed in Vietnam. The U.S. military is currently evaluating a new form of protection, developed by BAE Systems as well as systems designed by the Army, which are already in theater. The new gunner's seat is protected by high steel plates with bullet-proof glass windows. Additionally, some HMMWVs have been fitted with a remotely operated CROWS weapon station, which slaves the machine gun to controls in the back seat so it can be fired without exposing the crew. The Boomerang anti-sniper system was also fielded by some HMMWVs in Iraq to immediately give troops the location of insurgents firing on them.

Another weakness for the HMMWV has proven to be its size, which limited its deployment in Afghanistan because it is too wide for the smallest roads and too large for many forms of air transport compared to jeep or Land Rover-sized vehicles (which are nearly two feet narrower). This size also limits the ability for the vehicle to be manhandled out of situations.

The Army purchased a purpose-built armored car, the M1117 Armored Security Vehicle also known as an armored personnel carrying vehicle (APC), in limited numbers for use by the United States Army Military Police Corps. In 2007, the Marine Corps announced an intention to replace all HMMWVs in Iraq with MRAPs due to high loss rates, and issued contracts for the purchase of several thousand of these vehicles, which include the International MaxxPro, the BAE OMC RG-31, the BAE RG-33 and Caiman, and the Force Protection Cougar, which were deployed primarily for mine clearing duties. Heavier models of infantry mobility vehicles (IMV) can also be used for patrol vehicles. The MaxxPro Line has been shown to have the highest rate of vehicle rollover accidents to its very high center of gravity and immense weight. The massive weight of these vehicles combined with their high center of gravity also greatly reduces their utility in off-road situations versus the HMMWV, which was the primary cause for the push for the Oshkosh M-ATV to be developed quickly.

The Humvee replacement process being undertaken by the U.S. military focused on interim replacement with MRAPs and long-term replacement with the Joint Light Tactical Vehicle (JLTV). The HMMWV has evolved several times since its introduction and was used in tactical roles for which it was never originally intended. The military pursued several initiatives to replace it, both in the short and long terms. The short term replacement efforts utilized commercial off-the-shelf vehicles as part of the Mine Resistant Ambush Protected (MRAP) program. These vehicles were procured to replace Humvees in combat theaters. The long term replacement for the Humvee is the JLTV which is designed from the ground up. The Future Tactical Truck Systems (FTTS) program was initiated to make an analysis of potential requirements for a Humvee replacement. Various prototype vehicles such as the MillenWorks Light Utility Vehicle, and the ULTRA AP have been constructed as part of these efforts. The JLTV contract was awarded to Oshkosh in August 2015.

The U.S. Marine Corps issued a request for proposals (RFP) in 2013 for its Humvee sustainment modification initiative to upgrade 6,700 expanded capacity vehicles (ECVs). The Marines plan to field the JLTV, but do not have enough funding to completely replace all Humvees, so they decided to continue sustaining their fleet. Key areas of improvement include upgrades to the suspension to reduce the amount of force transferred to the chassis, upgrading the engine and transmission for better fuel efficiency, enhancements to the cooling system to prevent overheating, a central tire inflation system to improve off-road mobility and ride quality, and increased underbody survivability. Testing of upgraded Humvees was to occur in 2014, with production and installation occurring from 2015 through 2018. Older A2 series Humvees make up half the current fleet, and 4,000 are to be disposed of through foreign military sales and transfers. By 2017, the Marines' light tactical vehicle fleet is to consist of 3,500 A2 series Humvees, 9,500 ECV Humvees, and 5,000 JLTVs, with 18,000 vehicles in total. Humvees in service with the Marine Corps will be upgraded through 2030. The Marines shelved the Humvee modernization effort in March 2015 due to budget cuts.

Several companies are offering modifications to maintain the remaining U.S. military Humvee fleets. Oshkosh Corporation is offering Humvee upgrades to the Marine Corps in addition to its JLTV offering, which are modular and scalable solutions providing varying levels of capabilities at a range of price points that can be provided individually or as complete solutions. Their approach is centered around the TAK-4 independent suspension system, which delivers greater off-road profile capability, improved ride quality, an increase in maximum speed, greater whole-vehicle durability, and restored payload capacity and ground clearance. Northrop Grumman developed a new chassis and power train for the Humvee that would combine the mobility and payload capabilities of original vehicle variants while maintaining the protection levels of up-armored versions. The cost to upgrade one Humvee with Northrop Grumman's features is $145,000. Textron has offered another Humvee upgrade option called the Survivable Combat Tactical Vehicle (SCTV) that not only restores mobility but improves survivability over armored Humvee levels. Although the SCTV costs more at $200,000 per vehicle, the company claims it can restore the Humvee for operational use, combining Humvee-level mobility and transportability with MRAP-level underbody protection as a transitional solution until the JLTV is introduced in significant numbers.

One suggested future role for the Humvee is as an autonomous unmanned ground vehicle (UGV). If converted to a UGV, the vehicle could serve as a mobile scout vehicle with armor features removed to enhance mobility and terrain accessibility, since there would be no occupants needed to protect. Because there will still be tens of thousands of Humvees in the U.S. inventory after the JLTV enters service, it could be a low-cost way to build an unmanned combat vehicle fleet. Autonomy features would allow the Humvees to drive themselves and one soldier to control a "swarm" of several vehicles.

Although the Army plans to buy 49,100 JLTVs and the Marine Corps 5,500, they are not a one-for-one replacement for the Humvee and both services will still be left operating large fleets. For the Marines, 69 JLTVs will replace the 74 Humvees in all active infantry battalions to cover its expeditionary forces. The Marine JLTV order is planned to be completed by 2022, leaving the remainder of the Corps' 13,000-strong Humvee force scattered around support organizations while soft-skinned Humvees will provide support behind the forward deployed Marine Expeditionary Unit. The Army does not plan to replace Humvees in the Army National Guard, and is considering options on how many of its 120,000 vehicles will be replaced, sustained, or modernized. Even if half of the force is replaced by JLTVs, the entire planned order will not be complete until 2040. If upgrades are chosen for the remaining Humvees, the cost would likely have to not exceed $100,000 per vehicle. The Humvee is expected to remain in U.S. military service until at least 2050. Ambulance variants of the Humvee will especially remain in active use, as the JLTV couldn't be modified to serve as one due to weight issues.

The Humvee seats 4 with an available fully enclosed metal cabin with a vertical windshield. The body is constructed from lightweight and rust-resistant aluminum, instead of conventional steel. It has all-wheel drive with an independent suspension and helical gear-reduction hubs similar to portal axles which attach towards the top rather than center of each wheel to allow the drivetrain shafts to be raised for a full of ground clearance. The body is mounted on a narrow steel frame with boxed rails and five cross members for rigidity. The rails act as sliders to protect the drivetrain which is nestled between and above the rails. Raising the drivetrain into the cabin area and lowering the seats into the frame creates a massive chest-high transmission hump which separates passengers on each side and lowers the overall center of gravity compared to most trucks where the body and passengers are above the frame. The vehicle also has disc brakes on all 4 wheels, and 4-wheel Portal axle double-wishbone suspension. The brake discs are not mounted at the wheels as on conventional automobiles, but are inboard, attached to the outside of each differential. The front and rear differentials are Torsen type, and the center differential is a regular, lockable type. Torque-biasing differentials allows forward movement as long as at least one wheel has traction. It runs on specialized 37 × 12.5 radial tires with low-profile runflat devices. Newer HMMWV versions can be equipped with an optional central tire inflation system (CTIS) kit in the field. While it is optimized for off-road mobility, it can drive at highway speeds of at maximum weight with a top speed of .

HMMWVs are well suited for air mobile operations as they are transportable by C-130 or larger combat transports, droppable by parachute, and can be sling-loaded from helicopters, though there are smaller vehicles such as the Growler which were designed to fit into smaller craft such as the V-22. In combat conditions, the HMMWV can be delivered by the Low Altitude Parachute Extraction System which pulls the vehicle out of the open rear ramp just above the ground without the aircraft having to land.
There are at least 17 variants of the HMMWV in service with the U.S. military. HMMWVs serve as cargo/troop carriers, automatic weapons platforms, ambulances (four litter patients or eight ambulatory patients), M220 TOW missile carriers, M119 howitzer prime movers, M1097 Avenger Pedestal Mounted Stinger platforms, MRQ-12 direct air support vehicles, S250 shelter carriers, and other roles. The HMMWV is capable of 2.5 ft (76 cm) normally, or 5 ft (1.5 m) with the deep-water fording kits installed.
Optional equipment includes a winch (maximum load capacity and supplemental armor. The M1025/M1026 and M1043/M1044 armament carriers provide mounting and firing capabilities for the M134 Minigun, the Mk 19 grenade launcher, the M2 heavy machine gun, the M240G/B machine gun and M249 LMG.

The M1114 "up-armored" HMMWV, introduced in 1996, also features a similar weapons mount. In addition, some M1114 and M1116 up-armored and M1117 Armored Security Vehicle models feature a Common Remotely Operated Weapon Station (CROWS), which allows the gunner to operate from inside the vehicle, and/or the Boomerang anti-sniper detection system. Recent improvements have also led to the development of the M1151 model, which quickly rendered the previous models obsolete. By replacing the M1114, M1116, and earlier armored HMMWV types with a single model, the U.S. Army hopes to lower maintenance costs.

The latest iteration of the Humvee series can be seen in the M1151A1 and later up-armored A1-versions. It has a stronger suspension and larger 6.5 liter turbo-diesel engine to accommodate the weight of up to of additional armor. The armor protection can be installed or taken off depending on the operating environment, so the vehicles can move more efficiently without armor when there is no threat of attack. There is some underbody armor that moderately protects against mines and roadside bombs. Other improvements include Vehicle Emergency Escape (VEE) windows that can be quickly removed so troops inside can escape in the event of a rollover, jammed door, or the vehicle catching fire, and a blast chimney that vents the force of a bomb blast upwards and away from the occupants. The M1151A1 has a crew of four, can carry of payload, and can tow a load. On roads, it has a top speed of and a range of .

"With the introduction of the A1 series the number of models was reduced, with further designation revisions when the A2 series was introduced"

Under contract to the US Army, AM General developed the M1113 Expanded Capacity Vehicle (ECV). The M1097A2 is the basis for the Expanded Capacity Vehicle (ECV). The ECV provided the payload capacity allowing for larger and heavier communications shelters, improved armor protection level for scouts, military police, security police, and explosive ordnance disposal platforms.
In late 1995, production of the M1114 based on the improved ECV chassis began. The M1114 meets Army requirements for a scout, military police, and explosive ordnance disposal vehicle with improved ballistic protection levels. The M1114 provides protection against 7.62 mm armor-piercing projectiles, 155 mm artillery air bursts and anti-tank mine blasts.

In June 1996, the U.S. Army purchased an initial 390 M1114s for operations in Bosnia. The U.S. Air Force has a number of M1114 vehicles that differ in detail from the U.S. Army model. Under the designation M1116, the type was specifically designed and tailored to the needs of the U.S. Air Force. The M1116 features an expanded cargo area, armored housing for the turret gunner, and increased interior heating and air conditioning system. The M1114 and M1116 received armor at O'Gara-Hess & Eisenhardt Armoring Company of Fairfield, Ohio. The M1145 offers the protection of the M1114 and M1116 for Air Force Air Support Operations Squadrons (ASOS). Designed to protect Forward Air Controllers, modifications include perimeter ballistic protection, overhead burst protection, IED protection, mine blast protection, and 'white glass' transparent armor. Prior to the introduction of the latest armored HMMWV variants, and between 1993 and June 2006, Armor Holdings produced more than 17,500 armored HMMWVs (more than 14,000 between 2003-2007), all but about 160 of the earliest models were M1114, with smaller numbers of M1116 and M1045.
These extended capacity HMMWVs can drive over an vertical wall and carry a payload.




Textron's Survivable Combat Tactical Vehicle (SCTV) is a protective capsule that can increase Humvee survivability to MRAP levels while significantly improving mobility; the modifications come in five kits, but all five need to be installed before the vehicle can be properly called an SCTV. The vehicle features a monocoque V-shaped hull and angled sides to help deflect rocket-propelled grenades (RPGs) with scalable levels of protection. It has greater engine power, replacing the 6.5 liter diesel engine with a Cummins 6.7 liter diesel and Allison 6-speed transmission, as well as a stronger suspension, improved brakes, higher ground clearance, and new onboard instrumentation. Fuel capacity is increased from 27 gallons to 40 and the battery and fuel cells are moved from under the rear seat to the rear of the vehicle. Also included are a powerful air conditioner and heating system, run-flat tires, a thermal guard liner under the roof, sharp edges removed from inside the cabin, blast attenuating seats, and a folding gunner's turret allowing rapid deployment from a cargo aircraft or shipboard below deck. Although heavier than the Humvee, the SCTV is half the weight and costs $150,000 less than a comparably survivable MRAP. The basic version is a four-passenger armament carrier, but it can be configured as a nine-passenger troop carrier, air-defense vehicle, flatbed cargo truck, or field ambulance depending on the type of Humvee it is converted from.

Work began on the SCTV in 2008 in anticipation of U.S. military upgrades, but it was shelved once they made the JLTV a priority. Textron then focused on selling the SCTV upgrade package to up to 25 countries operating the global fleet, a potential market of up to 10,000 vehicles. The upgrade can enhance survivability of previously soft-skinned versions, sometimes sold by the U.S. as Excess Defense Articles, while costing and weighing less than a comparable MRAP. By 2015, Colombia had installed the SCTV into three Humvees for testing, and Ukraine had shown interest in upgrading their old-model Humvees recently supplied by the U.S. Ukraine ordered three SCTVs in February 2016.


In December 2014, the Department of Defense began auctioning off some 4,000 used Humvees to the public. While some have been transferred to domestic law enforcement agencies, this is the first time the military vehicles have been made available for civilian ownership. The idea is to sell them with starting bids at $10,000 each, for off-road use only, rather than simply scrapping them as a way to save money and repurpose them. M998, M998A1, M1038, and M1038A1 model Humvees are available, which are out of U.S. service and lack armor. AM General has been opposed to resale of military Humvees to the general public, primarily because surplus government vehicles would have cut into sales related to the civilian Hummer model, whose production ended in 2010. The first sales from auction occurred on 17 December 2014 for 25 of the Humvees. Bids ranged from $21,500 for a 1989 M1038 to $41,000 for a 1994 AM General M998A1. The average bid was around $30,000 and the sale of the 25 vehicles netted $744,000 total.

Kits have been produced for the general market to turn a sedan into a Humvee lookalike. An alternative is to buy a preconstructed (or "turnkey") wombat. Various kits exist, but one of the more well known is the Volkswagen Beetle-based "Wombat". This was previously named "HummBug", until the threat of a lawsuit from General Motors forced changes to the name and the grill design to make it look less like the real thing. It can be purchased/built for about US$18,000; this puts it considerably cheaper than the actual HMMWV ($56,000), or Hummer.

In Australia, a Gold Coast-based company called Rhino Buggies produces replicas of the Hummer H1 based on the Nissan Patrol 4WD vehicle for around A$30,000.

In the U.S., there are four companies that offered Hummer-look-alike rebody kits that can be mated to GM fullsize trucks and Suburban chassis and, in some cases, Ford, Dodge, and even Cadillac applications. Some models are; Urban Gorilla from Urban Manufacturing, Endeavor SB400 and SB4x400 from Forever Off-Road, the Jurassic Truck Corporation T-Rex, and the Bummer from Tatonka Products An additional company offers plans so for chassis building. The kits range from two-door fiberglass models to steel tube and sheet metal constructions.





</doc>
<doc id="14400" url="https://en.wikipedia.org/wiki?curid=14400" title="History of science">
History of science

The history of science is the study of the development of science and scientific knowledge, including both the natural and social sciences. (The history of the arts and humanities is termed history of scholarship.) Science is a body of empirical, theoretical, and practical knowledge about the natural world, produced by scientists who emphasize the observation, explanation, and prediction of real world phenomena. Historiography of science, in contrast, studies the methods employed by historians of science.

The English word "scientist" is relatively recent—first coined by William Whewell in the 19th century. Previously, investigators of nature called themselves "natural philosophers". While empirical investigations of the natural world have been described since classical antiquity (for example by Thales and Aristotle), and scientific method has been employed since the Middle Ages (for example, by Ibn al-Haytham and Roger Bacon), modern science began to develop in the early modern period, and in particular in the scientific revolution of 16th- and 17th-century Europe. Traditionally, historians of science have defined science sufficiently broadly to include those earlier inquiries.

From the 18th century through late 20th century, the history of science, especially of the physical and biological sciences, was often presented as a progressive accumulation of knowledge, in which true theories replaced false beliefs. Some more recent historical interpretations, such as those of Thomas Kuhn, tend to portray the history of science in terms of competing paradigms or conceptual systems in a wider matrix of intellectual, cultural, economic and political trends. These interpretations, however, have met with opposition for they also portray history of science as an incoherent system of incommensurable paradigms, not leading to any scientific progress, but only to the illusion of progress.

In prehistoric times, technique and knowledge were passed from generation to generation in an oral tradition. For example, the domestication of maize for agriculture has been dated to about 9,000 years ago in southern Mexico, before the development of writing systems. Similarly, archaeological evidence indicates the development of astronomical knowledge in preliterate societies. The development of writing enabled knowledge to be stored and communicated across generations with much greater fidelity.

Many ancient civilizations systematically collected astronomical observations. Rather than speculate on the material nature of the planets and stars, the ancients charted the relative positions of celestial bodies, often inferring their influence on human society. This demonstrates how ancient investigators generally employed a holistic intuition, assuming the interconnectedness of all things, whereas modern science rejects such conceptual leaps.

Basic facts about human physiology were known in some places, and alchemy was practiced in several civilizations. Considerable observation of macroscopic flora and fauna was also performed.

The ancient Mesopotamians had no distinction between "rational science" and magic. When a person became ill, doctors prescribed magical formulas to be recited as well as medicinal treatments. The earliest medical prescriptions appear in Sumerian during the Third Dynasty of Ur ( 2112 BC – 2004 BC). The most extensive Babylonian medical text, however, is the "Diagnostic Handbook" written by the "ummânū", or chief scholar, Esagil-kin-apli of Borsippa, during the reign of the Babylonian king Adad-apla-iddina (1069–1046 BC). In East Semitic cultures, the main medicinal authority was a kind of exorcist-healer known as an "āšipu". The profession was generally passed down from father to son and was held in extremely high regard. Of less frequent recourse was another kind of healer known as an "asu", who corresponds more closely to a modern physician and treated physical symptoms using primarily folk remedies composed of various herbs, animal products, and minerals, as well as potions, enemas, and ointments or poultices. These physicians, who could be either male or female, also dressed wounds, set limbs, and performed simple surgeries. The ancient Mesopotamians also practiced prophylaxis and took measures to prevent the spread of disease.

The ancient Mesopotamians had extensive knowledge about the chemical properties of clay, sand, metal ore, bitumen, stone, and other natural materials, and applied this knowledge to practical use in manufacturing pottery, faience, glass, soap, metals, lime plaster, and waterproofing. Metallurgy required scientific knowledge about the properties of metals. Nonetheless, the Mesopotamians seem to have had little interest in gathering information about the natural world for the mere sake of gathering information and were far more interested in studying the manner in which the gods had ordered the universe. Biology of non-human organisms was generally only written about in the context of mainstream academic disciplines. Animal physiology was studied extensively for the purpose of divination; the anatomy of the liver, which was seen as an important organ in haruspicy, was studied in particularly intensive detail. Animal behavior was also studied for divinatory purposes. Most information about the training and domestication of animals was probably transmitted orally without being written down, but one text dealing with the training of horses has survived. The Mesopotamian cuneiform tablet Plimpton 322, dating to the eighteenth century BC, records a number of Pythagorean triplets (3,4,5) (5,12,13) ..., hinting that the ancient Mesopotamians might have been aware of the Pythagorean theorem over a millennium before Pythagoras.

In Babylonian astronomy, records of the motions of the stars, planets, and the moon are left on thousands of clay tablets created by scribes. Even today, astronomical periods identified by Mesopotamian proto-scientists are still widely used in Western calendars such as the solar year and the lunar month. Using these data they developed arithmetical methods to compute the changing length of daylight in the course of the year and to predict the appearances and disappearances of the Moon and planets and eclipses of the Sun and Moon. Only a few astronomers' names are known, such as that of Kidinnu, a Chaldean astronomer and mathematician. Kiddinu's value for the solar year is in use for today's calendars. Babylonian astronomy was "the first and highly successful attempt at giving a refined mathematical description of astronomical phenomena." According to the historian A. Aaboe, "all subsequent varieties of scientific astronomy, in the Hellenistic world, in India, in Islam, and in the West—if not indeed all subsequent endeavour in the exact sciences—depend upon Babylonian astronomy in decisive and fundamental ways."

Ancient Egypt made significant advances in astronomy, mathematics and medicine. Their development of geometry was a necessary outgrowth of surveying to preserve the layout and ownership of farmland, which was flooded annually by the Nile river. The 3-4-5 right triangle and other rules of geometry were used to build rectilinear structures, and the post and lintel architecture of Egypt. Egypt was also a center of alchemy research for much of the Mediterranean. The Edwin Smith papyrus is one of the first medical documents still extant, and perhaps the earliest document that attempts to describe and analyse the brain: it might be seen as the very beginnings of modern neuroscience. However, while Egyptian medicine had some effective practices, it was often ineffective and sometimes harmful. Medical historians believe that ancient Egyptian pharmacology, for example, was largely ineffective. Nevertheless, it applied the following components to the treatment of disease: examination, diagnosis, treatment, and prognosis, which display strong parallels to the basic empirical method of science and, according to G. E. R. Lloyd, played a significant role in the development of this methodology. The Ebers papyrus (c. 1550 BC) also contains evidence of traditional empiricism.

In Classical Antiquity, the inquiry into the workings of the universe took place both in investigations aimed at such practical goals as establishing a reliable calendar or determining how to cure a variety of illnesses and in those abstract investigations known as natural philosophy. The ancient people who are considered the first "scientists" may have thought of themselves as "natural philosophers", as practitioners of a skilled profession (for example, physicians), or as followers of a religious tradition (for example, temple healers).

The earliest Greek philosophers, known as the pre-Socratics, provided competing answers to the question found in the myths of their neighbors: "How did the ordered cosmos in which we live come to be?" The pre-Socratic philosopher Thales (640–546 BC), dubbed the "father of science", was the first to postulate non-supernatural explanations for natural phenomena. For example, that land floats on water and that earthquakes are caused by the agitation of the water upon which the land floats, rather than the god Poseidon. Thales' student Pythagoras of Samos founded the Pythagorean school, which investigated mathematics for its own sake, and was the first to postulate that the Earth is spherical in shape. Leucippus (5th century BC) introduced atomism, the theory that all matter is made of indivisible, imperishable units called atoms. This was greatly expanded on by his pupil Democritus and later Epicurus.

Subsequently, Plato and Aristotle produced the first systematic discussions of natural philosophy, which did much to shape later investigations of nature. Their development of deductive reasoning was of particular importance and usefulness to later scientific inquiry. Plato founded the Platonic Academy in 387 BC, whose motto was "Let none unversed in geometry enter here", and turned out many notable philosophers. Plato's student Aristotle introduced empiricism and the notion that universal truths can be arrived at via observation and induction, thereby laying the foundations of the scientific method. Aristotle also produced many biological writings that were empirical in nature, focusing on biological causation and the diversity of life. He made countless observations of nature, especially the habits and attributes of plants and animals on Lesbos, classified more than 540 animal species, and dissected at least 50. Aristotle's writings profoundly influenced subsequent Islamic and European scholarship, though they were eventually superseded in the Scientific Revolution.

The important legacy of this period included substantial advances in factual knowledge, especially in anatomy, zoology, botany, mineralogy, geography, mathematics and astronomy; an awareness of the importance of certain scientific problems, especially those related to the problem of change and its causes; and a recognition of the methodological importance of applying mathematics to natural phenomena and of undertaking empirical research. In the Hellenistic age scholars frequently employed the principles developed in earlier Greek thought: the application of mathematics and deliberate empirical research, in their scientific investigations. Thus, clear unbroken lines of influence lead from ancient Greek and Hellenistic philosophers, to medieval Muslim philosophers and scientists, to the European Renaissance and Enlightenment, to the secular sciences of the modern day.
Neither reason nor inquiry began with the Ancient Greeks, but the Socratic method did, along with the idea of Forms, great advances in geometry, logic, and the natural sciences. According to Benjamin Farrington, former Professor of Classics at Swansea University:

and again:

The astronomer Aristarchus of Samos was the first known person to propose a heliocentric model of the solar system, while the geographer Eratosthenes accurately calculated the circumference of the Earth. Hipparchus (c. 190 – c. 120 BC) produced the first systematic star catalog. The level of achievement in Hellenistic astronomy and engineering is impressively shown by the Antikythera mechanism (150–100 BC), an analog computer for calculating the position of planets. Technological artifacts of similar complexity did not reappear until the 14th century, when mechanical astronomical clocks appeared in Europe.

In medicine, Hippocrates (c. 460 BC – c. 370 BC) and his followers were the first to describe many diseases and medical conditions and developed the Hippocratic Oath for physicians, still relevant and in use today. Herophilos (335–280 BC) was the first to base his conclusions on dissection of the human body and to describe the nervous system. Galen (129 – c. 200 AD) performed many audacious operations—including brain and eye surgeries— that were not tried again for almost two millennia.

In Hellenistic Egypt, the mathematician Euclid laid down the foundations of mathematical rigor and introduced the concepts of definition, axiom, theorem and proof still in use today in his "Elements", considered the most influential textbook ever written. Archimedes, considered one of the greatest mathematicians of all time, is credited with using the method of exhaustion to calculate the area under the arc of a parabola with the summation of an infinite series, and gave a remarkably accurate approximation of Pi. He is also known in physics for laying the foundations of hydrostatics, statics, and the explanation of the principle of the lever.

Theophrastus wrote some of the earliest descriptions of plants and animals, establishing the first taxonomy and looking at minerals in terms of their properties such as hardness. Pliny the Elder produced what is one of the largest encyclopedias of the natural world in 77 AD, and must be regarded as the rightful successor to Theophrastus. For example, he accurately describes the octahedral shape of the diamond, and proceeds to mention that diamond dust is used by engravers to cut and polish other gems owing to its great hardness. His recognition of the importance of crystal shape is a precursor to modern crystallography, while mention of numerous other minerals presages mineralogy. He also recognises that other minerals have characteristic crystal shapes, but in one example, confuses the crystal habit with the work of lapidaries. He was also the first to recognise that amber was a fossilized resin from pine trees because he had seen samples with trapped insects within them.

Mathematics: The earliest traces of mathematical knowledge in the Indian subcontinent appear with the Indus Valley Civilization (c. 4th millennium BC ~ c. 3rd millennium BC). The people of this civilization made bricks whose dimensions were in the proportion 4:2:1, considered favorable for the stability of a brick structure. They also tried to standardize measurement of length to a high degree of accuracy. They designed a ruler—the "Mohenjo-daro ruler"—whose unit of length (approximately 1.32 inches or 3.4 centimetres) was divided into ten equal parts. Bricks manufactured in ancient Mohenjo-daro often had dimensions that were integral multiples of this unit of length.

Indian astronomer and mathematician Aryabhata (476–550), in his "Aryabhatiya" (499) introduced a number of trigonometric functions (including sine, versine, cosine and inverse sine), trigonometric tables, and techniques and algorithms of algebra. In 628 AD, Brahmagupta suggested that gravity was a force of attraction. He also lucidly explained the use of zero as both a placeholder and a decimal digit, along with the Hindu-Arabic numeral system now used universally throughout the world. Arabic translations of the two astronomers' texts were soon available in the Islamic world, introducing what would become Arabic numerals to the Islamic world by the 9th century. During the 14th–16th centuries, the Kerala school of astronomy and mathematics made significant advances in astronomy and especially mathematics, including fields such as trigonometry and analysis. In particular, Madhava of Sangamagrama is considered the "founder of mathematical analysis".

Astronomy: The first textual mention of astronomical concepts comes from the Vedas, religious literature of India. According to Sarma (2008): "One finds in the Rigveda intelligent speculations about the genesis of the universe from nonexistence, the configuration of the universe, the spherical self-supporting earth, and the year of 360 days divided into 12 equal parts of 30 days each with a periodical intercalary month.". The first 12 chapters of the "Siddhanta Shiromani", written by Bhāskara in the 12th century, cover topics such as: mean longitudes of the planets; true longitudes of the planets; the three problems of diurnal rotation; syzygies; lunar eclipses; solar eclipses; latitudes of the planets; risings and settings; the moon's crescent; conjunctions of the planets with each other; conjunctions of the planets with the fixed stars; and the patas of the sun and moon. The 13 chapters of the second part cover the nature of the sphere, as well as significant astronomical and trigonometric calculations based on it.

Nilakantha Somayaji's astronomical treatise the Tantrasangraha similar in nature to the Tychonic system proposed by Tycho Brahe had been the most accurate astronomical model until the time of Johannes Kepler in the 17th century.

Linguistics: Some of the earliest linguistic activities can be found in Iron Age India (1st millennium BC) with the analysis of Sanskrit for the purpose of the correct recitation and interpretation of Vedic texts. The most notable grammarian of Sanskrit was (c. 520–460 BC), whose grammar formulates close to 4,000 rules which together form a compact generative grammar of Sanskrit. Inherent in his analytic approach are the concepts of the phoneme, the morpheme and the root.

Medicine: Findings from Neolithic graveyards in what is now Pakistan show evidence of proto-dentistry among an early farming culture. Ayurveda is a system of traditional medicine that originated in ancient India before 2500 BC, and is now practiced as a form of alternative medicine in other parts of the world. Its most famous text is the Suśrutasamhitā of Suśruta, which is notable for describing procedures on various forms of surgery, including rhinoplasty, the repair of torn ear lobes, perineal lithotomy, cataract surgery, and several other excisions and other surgical procedures.

Metallurgy: The wootz, crucible and stainless steels were invented in India, and were widely exported in Classic Mediterranean world. It was known from Pliny the Elder as "ferrum indicum". Indian Wootz steel was held in high regard in Roman Empire, was often considered to be the best. After in Middle Age it was imported in Syria to produce with special techniques the "Damascus steel" by the year 1000.
The Hindus excel in the manufacture of iron, and in the preparations of those ingredients along with which it is fused to obtain that kind of soft iron which is usually styled Indian steel (Hindiah). They also have workshops wherein are forged the most famous sabres in the world.

Mathematics: From the earliest the Chinese used a positional decimal system on counting boards in order to calculate. To express 10, a single rod is placed in the second box from the right. The spoken language uses a similar system to English: e.g. four thousand two hundred seven. No symbol was used for zero. By the 1st century BC, negative numbers and decimal fractions were in use and "The Nine Chapters on the Mathematical Art" included methods for extracting higher order roots by Horner's method and solving linear equations and by Pythagoras' theorem. Cubic equations were solved in the Tang dynasty and solutions of equations of order higher than 3 appeared in print in 1245 AD by Ch'in Chiu-shao. Pascal's triangle for binomial coefficients was described around 1100 by Jia Xian.

Although the first attempts at an axiomatisation of geometry appear in the Mohist canon in 330 BC, Liu Hui developed algebraic methods in geometry in the 3rd century AD and also calculated pi to 5 significant figures. In 480, Zu Chongzhi improved this by discovering the ratio formula_1 which remained the most accurate value for 1200 years.

Astronomy: Astronomical observations from China constitute the longest continuous sequence from any civilisation and include records of sunspots (112 records from 364 BC), supernovas (1054), lunar and solar eclipses. By the 12th century, they could reasonably accurately make predictions of eclipses, but the knowledge of this was lost during the Ming dynasty, so that the Jesuit Matteo Ricci gained much favour in 1601 by his predictions.
By 635 Chinese astronomers had observed that the tails of comets always point away from the sun.

From antiquity, the Chinese used an equatorial system for describing the skies and a star map from 940 was drawn using a cylindrical (Mercator) projection. The use of an armillary sphere is recorded from the 4th century BC and a sphere permanently mounted in equatorial axis from 52 BC. In 125 AD Zhang Heng used water power to rotate the sphere in real time. This included rings for the meridian and ecliptic. By 1270 they had incorporated the principles of the Arab torquetum.

Seismology: To better prepare for calamities, Zhang Heng invented a seismometer in 132 CE which provided instant alert to authorities in the capital Luoyang that an earthquake had occurred in a location indicated by a specific cardinal or ordinal direction. Although no tremors could be felt in the capital when Zhang told the court that an earthquake had just occurred in the northwest, a message came soon afterwards that an earthquake had indeed struck 400 km (248 mi) to 500 km (310 mi) northwest of Luoyang (in what is now modern Gansu). Zhang called his device the 'instrument for measuring the seasonal winds and the movements of the Earth' (Houfeng didong yi 候风地动仪), so-named because he and others thought that earthquakes were most likely caused by the enormous compression of trapped air. See Zhang's seismometer for further details.

There are many notable contributors to the field of Chinese science throughout the ages. One of the best examples would be Shen Kuo (1031–1095), a polymath scientist and statesman who was the first to describe the magnetic-needle compass used for navigation, discovered the concept of true north, improved the design of the astronomical gnomon, armillary sphere, sight tube, and clepsydra, and described the use of drydocks to repair boats. After observing the natural process of the inundation of silt and the find of marine fossils in the Taihang Mountains (hundreds of miles from the Pacific Ocean), Shen Kuo devised a theory of land formation, or geomorphology. He also adopted a theory of gradual climate change in regions over time, after observing petrified bamboo found underground at Yan'an, Shaanxi province. If not for Shen Kuo's writing, the architectural works of Yu Hao would be little known, along with the inventor of movable type printing, Bi Sheng (990–1051). Shen's contemporary Su Song (1020–1101) was also a brilliant polymath, an astronomer who created a celestial atlas of star maps, wrote a pharmaceutical treatise with related subjects of botany, zoology, mineralogy, and metallurgy, and had erected a large astronomical clocktower in Kaifeng city in 1088. To operate the crowning armillary sphere, his clocktower featured an escapement mechanism and the world's oldest known use of an endless power-transmitting chain drive.

The Jesuit China missions of the 16th and 17th centuries "learned to appreciate the scientific achievements of this ancient culture and made them known in Europe. Through their correspondence European scientists first learned about the Chinese science and culture." Western academic thought on the history of Chinese technology and science was galvanized by the work of Joseph Needham and the Needham Research Institute. Among the technological accomplishments of China were, according to the British scholar Needham, early seismological detectors (Zhang Heng in the 2nd century), the water-powered celestial globe (Zhang Heng), matches, the independent invention of the decimal system, dry docks, sliding calipers, the double-action piston pump, cast iron, the blast furnace, the iron plough, the multi-tube seed drill, the wheelbarrow, the suspension bridge, the winnowing machine, the rotary fan, the parachute, natural gas as fuel, the raised-relief map, the propeller, the crossbow, and a solid fuel rocket, the multistage rocket, the horse collar, along with contributions in logic, astronomy, medicine, and other fields.

However, cultural factors prevented these Chinese achievements from developing into what we might call "modern science". According to Needham, it may have been the religious and philosophical framework of Chinese intellectuals which made them unable to accept the ideas of laws of nature:
In the Middle Ages the classsical learning continued in three major linguistic cultures and civilizations: Greek (the Byzantine Empire), Arabic (the Islamic world), and Latin (Western Europe).

Because of the collapse of the Western Roman Empire, the intellectual level in the western part of Europe declined in the 400s. In contrast, the Eastern Roman or Byzantine Empire resisted the barbarian attacks, and preserved and improved the learning.

While the Byzantine Empire still held learning centers such as Constantinople, Alexandria and Antioch, Western Europe's knowledge was concentrated in monasteries until the development of medieval universities in the 12th centuries. The curriculum of monastic schools included the study of the few available ancient texts and of new works on practical subjects like medicine and timekeeping.

In the sixth century in the Byzantine Empire, Isidore of Miletus compiled Archimedes' mathematical works in the Archimedes Palimpsest, where all Archimedes' mathematical contributions were collected and studied.

John Philoponus, another Byzantine scholar, was the first to question Aristotle's teaching of physics, introducing the theory of impetus. The theory of impetus was an auxiliary or secondary theory of Aristotelian dynamics, put forth initially to explain projectile motion against gravity. It is the intellectual precursor to the concepts of inertia, momentum and acceleration in classical mechanics. The works of John Philoponus inspired Galileo Galilei ten centuries later.

The first record of separating conjoined twins took place in the Byzantine Empire in the 900s when the surgeons tried to separate a dead body of a pair of conjoined twins. The result was partly successful as the other twin managed to live for three days. The next case of separating conjoined twins was recorded in 1689 in Germany several centuries later.

During the Fall of Constantinople in 1453, a lot of Greek scholars flee to North Italy in which they fueled the era later commonly known as "Renaissance” as they brought with them a lot of classical learning such of botany, medicine, zoology. Byzantium also gave the West important inputs: John Philoponus' criticism of Aristotelian physics, and the works of Dioscorides.

In the Middle East, Greek philosophy was able to find some support under the newly created Arab Empire. With the spread of Islam in the 7th and 8th centuries, a period of Muslim scholarship, known as the Islamic Golden Age, lasted until the 13th century. This scholarship was aided by several factors. The use of a single language, Arabic, allowed communication without need of a translator. Access to Greek texts from the Byzantine Empire, along with Indian sources of learning, provided Muslim scholars a knowledge base to build upon.

Scientific method began developing in the Muslim world, where significant progress in methodology was made, beginning with the experiments of Ibn al-Haytham (Alhazen) on optics from c. 1000, in his "Book of Optics". The most important development of the scientific method was the use of experiments to distinguish between competing scientific theories set within a generally empirical orientation, which began among Muslim scientists. Ibn al-Haytham is also regarded as the father of optics, especially for his empirical proof of the intromission theory of light. Some have also described Ibn al-Haytham as the "first scientist" for his development of the modern scientific method.

In mathematics, the mathematician Muhammad ibn Musa al-Khwarizmi (c. 780–850) gave his name to the concept of the algorithm, while the term algebra is derived from "al-jabr", the beginning of the title of one of his publications. What is now known as Arabic numerals originally came from India, but Muslim mathematicians made several key refinements to the number system, such as the introduction of decimal point notation.

In astronomy, Al-Battani (c. 858–929) improved the measurements of Hipparchus, preserved in the translation of Ptolemy's "Hè Megalè Syntaxis" ("The great treatise") translated as "Almagest". Al-Battani also improved the precision of the measurement of the precession of the Earth's axis. The corrections made to the geocentric model by al-Battani, Ibn al-Haytham, Averroes and the Maragha astronomers such as Nasir al-Din al-Tusi, Mo'ayyeduddin Urdi and Ibn al-Shatir are similar to Copernican heliocentric model. Heliocentric theories may have also been discussed by several other Muslim astronomers such as Ja'far ibn Muhammad Abu Ma'shar al-Balkhi, Abu-Rayhan Biruni, Abu Said al-Sijzi, Qutb al-Din al-Shirazi, and Najm al-Dīn al-Qazwīnī al-Kātibī.

Muslim chemists and alchemists played an important role in the foundation of modern chemistry. Scholars such as Will Durant and Fielding H. Garrison considered Muslim chemists to be the founders of chemistry. In particular, Jābir ibn Hayyān (c. 721–815) is "considered by many to be the father of chemistry". The works of Arabic scientists influenced Roger Bacon (who introduced the empirical method to Europe, strongly influenced by his reading of Persian writers), and later Isaac Newton. The scholar Al-Razi contributed to chemistry and medicine.

Ibn Sina (Avicenna, c. 980–1037) is regarded as the most influential philosopher of Islam. He pioneered the science of experimental medicine and was the first physician to conduct clinical trials. His two most notable works in medicine are the "Kitāb al-shifāʾ" ("Book of Healing") and The Canon of Medicine, both of which were used as standard medicinal texts in both the Muslim world and in Europe well into the 17th century. Amongst his many contributions are the discovery of the contagious nature of infectious diseases, and the introduction of clinical pharmacology.

Scientists from the Islamic world include al-Farabi (polymath), Abu al-Qasim al-Zahrawi (pioneer of surgery), Abū Rayhān al-Bīrūnī (pioneer of Indology, geodesy and anthropology), Nasīr al-Dīn al-Tūsī (polymath), and Ibn Khaldun (forerunner of social sciences such as demography, cultural history, historiography, philosophy of history and sociology), among many others.

Islamic science began its decline in the 12th or 13th century, before the Renaissance in Europe, and due in part to the 11th–13th century Mongol conquests, during which libraries, observatories, hospitals and universities were destroyed. The end of the Islamic Golden Age is marked by the destruction of the intellectual center of Baghdad, the capital of the Abbasid caliphate in 1258.

By the eleventh century, most of Europe had become Christian; stronger monarchies emerged; borders were restored; technological developments and agricultural innovations were made, increasing the food supply and population. Classical Greek texts were translated from Arabic and Greek into Latin, stimulating scientific discussion in Western Europe.

An intellectual revitalization of Western Europe started with the birth of medieval universities in the 12th century. The contact with the Islamic world and Byzantine Empire, and during the Reconquista and the Crusades, allowed Latin Europe access to scientific Greek and Arabic texts, including the works of Aristotle, Ptolemy, Isidore of Miletus, John Philoponus, Jābir ibn Hayyān, al-Khwarizmi, Alhazen, Avicenna, and Averroes. European scholars had access to the translation programs of Raymond of Toledo, who sponsored the 12th century Toledo School of Translators from Arabic to Latin. Later translators like Michael Scotus would learn Arabic in order to study these texts directly. The European universities aided materially in the translation and propagation of these texts and started a new infrastructure which was needed for scientific communities. In fact, European university put many works about the natural world and the study of nature at the center of its curriculum, with the result that the "medieval university laid far greater emphasis on science than does its modern counterpart and descendent."

In classical antiquity, Greek and Roman taboos had meant that dissection was usually banned, but in the Middle Ages medical teachers and students at Bologna began to open human bodies, and Mondino de Luzzi (ca. 1275–1326) produced the ﬁrst known anatomy textbook based on human dissection. 

As a result of the Pax Mongolica, Europeans, such as Marco Polo, began to venture further and further east. This led to the increased awareness of Indian and even Chinese culture and civilization within the European tradition. Technological advances were also made, such as the early flight of Eilmer of Malmesbury (who had studied Mathematics in 11th century England), and the metallurgical achievements of the Cistercian blast furnace at Laskill.

At the beginning of the 13th century, there were reasonably accurate Latin translations of the main works of almost all the intellectually crucial ancient authors, allowing a sound transfer of scientific ideas via both the universities and the monasteries. By then, the natural philosophy in these texts began to be extended by scholastics such as Robert Grosseteste, Roger Bacon, Albertus Magnus and Duns Scotus. Precursors of the modern scientific method, influenced by earlier contributions of the Islamic world, can be seen already in Grosseteste's emphasis on mathematics as a way to understand nature, and in the empirical approach admired by Bacon, particularly in his "Opus Majus". Pierre Duhem's thesis is that Stephen Tempier - the Bishop of Paris - Condemnation of 1277 led to the study of medieval science as a serious discipline, "but no one in the field any longer endorses his view that modern science started in 1277". However, many scholars agree with Duhem's view that the Middle Ages saw important scientific developments.

The first half of the 14th century saw much important scientific work, largely within the framework of scholastic commentaries on Aristotle's scientific writings. William of Ockham emphasised the principle of parsimony: natural philosophers should not postulate unnecessary entities, so that motion is not a distinct thing but is only the moving object and an intermediary "sensible species" is not needed to transmit an image of an object to the eye. Scholars such as Jean Buridan and Nicole Oresme started to reinterpret elements of Aristotle's mechanics. In particular, Buridan developed the theory that impetus was the cause of the motion of projectiles, which was a first step towards the modern concept of inertia. The Oxford Calculators began to mathematically analyze the kinematics of motion, making this analysis without considering the causes of motion.

In 1348, the Black Death and other disasters sealed a sudden end to philosophic and scientific development. Yet, the rediscovery of ancient texts was stimulated by the Fall of Constantinople in 1453, when many Byzantine scholars sought refuge in the West. Meanwhile, the introduction of printing was to have great effect on European society. The facilitated dissemination of the printed word democratized learning and allowed ideas such as algebra to propagate more rapidly. These developments paved the way for the Scientific Revolution, where scientific inquiry, halted at the start of the Black Death, resumed.

The renewal of learning in Europe began with 12th century Scholasticism. The Northern Renaissance showed a decisive shift in focus from Aristoteleian natural philosophy to chemistry and the biological sciences (botany, anatomy, and medicine). Thus modern science in Europe was resumed in a period of great upheaval: the Protestant Reformation and Catholic Counter-Reformation; the discovery of the Americas by Christopher Columbus; the Fall of Constantinople; but also the re-discovery of Aristotle during the Scholastic period presaged large social and political changes. Thus, a suitable environment was created in which it became possible to question scientific doctrine, in much the same way that Martin Luther and John Calvin questioned religious doctrine. The works of Ptolemy (astronomy) and Galen (medicine) were found not always to match everyday observations. Work by Vesalius on human cadavers found problems with the Galenic view of anatomy.

The willingness to question previously held truths and search for new answers resulted in a period of major scientific advancements, now known as the Scientific Revolution. The Scientific Revolution is traditionally held by most historians to have begun in 1543, when the books "De humani corporis fabrica" ("On the Workings of the Human Body") by Andreas Vesalius, and also "De Revolutionibus", by the astronomer Nicolaus Copernicus, were first printed. The thesis of Copernicus' book was that the Earth moved around the Sun. The period culminated with the publication of the "Philosophiæ Naturalis Principia Mathematica" in 1687 by Isaac Newton, representative of the unprecedented growth of scientific publications throughout Europe.

Other significant scientific advances were made during this time by Galileo Galilei, Edmond Halley, Robert Hooke, Christiaan Huygens, Tycho Brahe, Johannes Kepler, Gottfried Leibniz, and Blaise Pascal. In philosophy, major contributions were made by Francis Bacon, Sir Thomas Browne, René Descartes, and Thomas Hobbes. The scientific method was also better developed as the modern way of thinking emphasized experimentation and reason over traditional considerations.

The Age of Enlightenment was a European affair. The 17th century brought decisive steps towards modern science, which accelerated during the 18th century. Directly based on the works of Newton, Descartes, Pascal and Leibniz, the way was now clear to the development of modern mathematics, physics and technology
by the generation of Benjamin Franklin (1706–1790), Leonhard Euler (1707–1783), Mikhail Lomonosov (1711–1765) and Jean le Rond d'Alembert (1717–1783). Denis Diderot's "Encyclopédie", published between 1751 and 1772 brought this new understanding to a wider audience. The impact of this process was not limited to science and technology, but affected philosophy (Immanuel Kant, David Hume), religion (the increasingly significant impact of science upon religion), and society and politics in general (Adam Smith, Voltaire). The early modern period is seen as a flowering of the European Renaissance, in what is often known as the Scientific Revolution, viewed as a foundation of modern science.

The Romantic Movement of the early 19th century reshaped science by opening up new pursuits unexpected in the classical approaches of the Enlightenment. Major breakthroughs came in biology, especially in Darwin's theory of evolution, as well as physics (electromagnetism), mathematics (non-Euclidean geometry, group theory) and chemistry (organic chemistry). The decline of Romanticism occurred because a new movement, Positivism, began to take hold of the ideals of the intellectuals after 1840 and lasted until about 1880.

The scientific revolution established science as a source for the growth of knowledge. During the 19th century, the practice of science became professionalized and institutionalized in ways that continued through the 20th century. As the role of scientific knowledge grew in society, it became incorporated with many aspects of the functioning of nation-states.

The scientific revolution is a convenient boundary between ancient thought and classical physics. Nicolaus Copernicus revived the heliocentric model of the solar system described by Aristarchus of Samos. This was followed by the first known model of planetary motion given by Johannes Kepler in the early 17th century, which proposed that the planets follow elliptical orbits, with the Sun at one focus of the ellipse. Galileo (""Father of Modern Physics"") also made use of experiments to validate physical theories, a key element of the scientific method. William Gilbert did some of the earliest experiments with electricity and magnetism, establishing that the Earth itself is magnetic.

In 1687, Isaac Newton published the "Principia Mathematica", detailing two comprehensive and successful physical theories: Newton's laws of motion, which led to classical mechanics; and Newton's Law of Gravitation, which describes the fundamental force of gravity.

During the late 18th and early 19th century, the behavior of electricity and magnetism was studied by Luigi Galvani, Giovanni Aldini, Alessandro Volta, Michael Faraday, Georg Ohm, and others. These studies led to the unification of the two phenomena into a single theory of electromagnetism, by James Clerk Maxwell (known as Maxwell's equations).

The beginning of the 20th century brought the start of a revolution in physics. The long-held theories of Newton were shown not to be correct in all circumstances. Beginning in 1900, Max Planck, Albert Einstein, Niels Bohr and others developed quantum theories to explain various anomalous experimental results, by introducing discrete energy levels. Not only did quantum mechanics show that the laws of motion did not hold on small scales, but even more disturbingly, the theory of general relativity, proposed by Einstein in 1915, showed that the fixed background of spacetime, on which both Newtonian mechanics and special relativity depended, could not exist. In 1925, Werner Heisenberg and Erwin Schrödinger formulated quantum mechanics, which explained the preceding quantum theories. The observation by Edwin Hubble in 1929 that the speed at which galaxies recede positively correlates with their distance, led to the understanding that the universe is expanding, and the formulation of the Big Bang theory by Georges Lemaître.

In 1938 Otto Hahn and Fritz Strassmann discovered nuclear fission with radiochemical methods, and in 1939 Lise Meitner and Otto Robert Frisch wrote the first theoretical interpretation of the fission process, which was later improved by Niels Bohr and John A. Wheeler. Further developments took place during World War II, which led to the practical application of radar and the development and use of the atomic bomb. Around this time, Chien-Shiung Wu was recruited by the Manhattan Project to help develop a process for separating uranium metal into U-235 and U-238 isotopes by Gaseous diffusion. She was an expert experimentalist in beta decay and weak interaction physics. Wu designed an experiment (see Wu experiment) that enabled theoretical physicists Tsung-Dao Lee and Chen-Ning Yang to disprove the law of parity experimentally, winning them a Nobel Prize in 1957.

Though the process had begun with the invention of the cyclotron by Ernest O. Lawrence in the 1930s, physics in the postwar period entered into a phase of what historians have called "Big Science", requiring massive machines, budgets, and laboratories in order to test their theories and move into new frontiers. The primary patron of physics became state governments, who recognized that the support of "basic" research could often lead to technologies useful to both military and industrial applications.

Currently, general relativity and quantum mechanics are inconsistent with each other, and efforts are underway to unify the two.

Modern chemistry emerged from the sixteenth through the eighteenth centuries through the material practices and theories promoted by alchemy, medicine, manufacturing and mining. A decisive moment came when 'chemistry' was distinguished from alchemy by Robert Boyle in his work "The Sceptical Chymist", in 1661; although the alchemical tradition continued for some time after his work. Other important steps included the gravimetric experimental practices of medical chemists like William Cullen, Joseph Black, Torbern Bergman and Pierre Macquer and through the work of Antoine Lavoisier ("Father of Modern Chemistry") on oxygen and the law of conservation of mass, which refuted phlogiston theory. The theory that all matter is made of atoms, which are the smallest constituents of matter that cannot be broken down without losing the basic chemical and physical properties of that matter, was provided by John Dalton in 1803, although the question took a hundred years to settle as proven. Dalton also formulated the law of mass relationships. In 1869, Dmitri Mendeleev composed his periodic table of elements on the basis of Dalton's discoveries.

The synthesis of urea by Friedrich Wöhler opened a new research field, organic chemistry, and by the end of the 19th century, scientists were able to synthesize hundreds of organic compounds. The later part of the 19th century saw the exploitation of the Earth's petrochemicals, after the exhaustion of the oil supply from whaling. By the 20th century, systematic production of refined materials provided a ready supply of products which provided not only energy, but also synthetic materials for clothing, medicine, and everyday disposable resources. Application of the techniques of organic chemistry to living organisms resulted in physiological chemistry, the precursor to biochemistry. The 20th century also saw the integration of physics and chemistry, with chemical properties explained as the result of the electronic structure of the atom. Linus Pauling's book on "The Nature of the Chemical Bond" used the principles of quantum mechanics to deduce bond angles in ever-more complicated molecules. Pauling's work culminated in the physical modelling of DNA, "the secret of life" (in the words of Francis Crick, 1953). In the same year, the Miller–Urey experiment demonstrated in a simulation of primordial processes, that basic constituents of proteins, simple amino acids, could themselves be built up from simpler molecules.

Geology existed as a cloud of isolated, disconnected ideas about rocks, minerals, and landforms long before it became a coherent science. Theophrastus' work on rocks, "Peri lithōn", remained authoritative for millennia: its interpretation of fossils was not overturned until after the Scientific Revolution. Chinese polymath Shen Kua (1031–1095) first formulated hypotheses for the process of land formation. Based on his observation of fossils in a geological stratum in a mountain hundreds of miles from the ocean, he deduced that the land was formed by erosion of the mountains and by deposition of silt.

Geology did not undergo systematic restructuring during the Scientific Revolution, but individual theorists made important contributions. Robert Hooke, for example, formulated a theory of earthquakes, and Nicholas Steno developed the theory of superposition and argued that fossils were the remains of once-living creatures. Beginning with Thomas Burnet's "Sacred Theory of the Earth" in 1681, natural philosophers began to explore the idea that the Earth had changed over time. Burnet and his contemporaries interpreted Earth's past in terms of events described in the Bible, but their work laid the intellectual foundations for secular interpretations of Earth history.

Modern geology, like modern chemistry, gradually evolved during the 18th and early 19th centuries. Benoît de Maillet and the Comte de Buffon saw the Earth as much older than the 6,000 years envisioned by biblical scholars. Jean-Étienne Guettard and Nicolas Desmarest hiked central France and recorded their observations on some of the first geological maps. Aided by chemical experimentation, naturalists such as Scotland's John Walker, Sweden's Torbern Bergman, and Germany's Abraham Werner created comprehensive classification systems for rocks and minerals—a collective achievement that transformed geology into a cutting edge field by the end of the eighteenth century. These early geologists also proposed a generalized interpretations of Earth history that led James Hutton, Georges Cuvier and Alexandre Brongniart, following in the steps of Steno, to argue that layers of rock could be dated by the fossils they contained: a principle first applied to the geology of the Paris Basin. The use of index fossils became a powerful tool for making geological maps, because it allowed geologists to correlate the rocks in one locality with those of similar age in other, distant localities. Over the first half of the 19th century, geologists such as Charles Lyell, Adam Sedgwick, and Roderick Murchison applied the new technique to rocks throughout Europe and eastern North America, setting the stage for more detailed, government-funded mapping projects in later decades.

Midway through the 19th century, the focus of geology shifted from description and classification to attempts to understand "how" the surface of the Earth had changed. The first comprehensive theories of mountain building were proposed during this period, as were the first modern theories of earthquakes and volcanoes. Louis Agassiz and others established the reality of continent-covering ice ages, and "fluvialists" like Andrew Crombie Ramsay argued that river valleys were formed, over millions of years by the rivers that flow through them. After the discovery of radioactivity, radiometric dating methods were developed, starting in the 20th century. Alfred Wegener's theory of "continental drift" was widely dismissed when he proposed it in the 1910s, but new data gathered in the 1950s and 1960s led to the theory of plate tectonics, which provided a plausible mechanism for it. Plate tectonics also provided a unified explanation for a wide range of seemingly unrelated geological phenomena. Since 1970 it has served as the unifying principle in geology.

Geologists' embrace of plate tectonics became part of a broadening of the field from a study of rocks into a study of the Earth as a planet. Other elements of this transformation include: geophysical studies of the interior of the Earth, the grouping of geology with meteorology and oceanography as one of the "earth sciences", and comparisons of Earth and the solar system's other rocky planets.

Aristarchus of Samos published work on how to determine the sizes and distances of the Sun and the Moon, and Eratosthenes used this work to figure the size of the Earth. Hipparchus later discovered the precession of the Earth.

Advances in astronomy and in optical systems in the 19th century resulted in the first observation of an asteroid (1 Ceres) in 1801, and the discovery of Neptune in 1846.

In 1925, Cecilia Payne-Gaposchkin determined that stars were composed mostly of Hydrogen and Helium. She was dissuaded by astronomer Henry Norris Russell from publishing this finding in her Ph.D.thesis because of the widely held belief that stars had the same composition as the Earth. However, four years later, in 1929, Henry Norris Russell came to the same conclusion through different reasoning and the discovery was eventually accepted.

George Gamow, Ralph Alpher, and Robert Herman had calculated that there should be evidence for a Big Bang in the background temperature of the universe. In 1964, Arno Penzias and Robert Wilson discovered a 3 Kelvin background hiss in their Bell Labs radiotelescope (the Holmdel Horn Antenna), which was evidence for this hypothesis, and formed the basis for a number of results that helped determine the age of the universe.

Supernova SN1987A was observed by astronomers on Earth both visually, and in a triumph for neutrino astronomy, by the solar neutrino detectors at Kamiokande. But the solar neutrino flux was a fraction of its theoretically expected value. This discrepancy forced a change in some values in the standard model for particle physics.

William Harvey published "De Motu Cordis" in 1628, which revealed his conclusions based on his extensive studies of vertebrate circulatory systems. He identified the central role of the heart, arteries, and veins in producing blood movement in a circuit, and
failed to find any confirmation of Galen's pre-existing notions of heating and cooling functions. The History early modern biology and medicine is often told through the search for the seat of the soul. Galen in his descriptions of his foundational work in medicine presents the distinctions between arteries, veins, and nerves using the vocabulary of the soul.

In 1847, Hungarian physician Ignác Fülöp Semmelweis dramatically reduced the occurrency of puerperal fever by simply requiring physicians to wash their hands before attending to women in childbirth. This discovery predated the germ theory of disease. However, Semmelweis' findings were not appreciated by his contemporaries and handwashing came into use only with discoveries by British surgeon Joseph Lister, who in 1865 proved the principles of antisepsis. Lister's work was based on the important findings by French biologist Louis Pasteur. Pasteur was able to link microorganisms with disease, revolutionizing medicine. He also devised one of the most important methods in preventive medicine, when in 1880 he produced a vaccine against rabies. Pasteur invented the process of pasteurization, to help prevent the spread of disease through milk and other foods.

Perhaps the most prominent, controversial and far-reaching theory in all of science has been the theory of evolution by natural selection put forward by the British naturalist Charles Darwin in his book On the Origin of Species in 1859. Darwin proposed that the features of all living things, including humans, were shaped by natural processes over long periods of time. The theory of evolution in its current form affects almost all areas of biology. Implications of evolution on fields outside of pure science have led to both opposition and support from different parts of society, and profoundly influenced the popular understanding of "man's place in the universe". In the early 20th century, the study of heredity became a major investigation after the rediscovery in 1900 of the laws of inheritance developed by the Moravian monk Gregor Mendel in 1866. Mendel's laws provided the beginnings of the study of genetics, which became a major field of research for both scientific and industrial research. By 1953, James D. Watson, Francis Crick and Maurice Wilkins clarified the basic structure of DNA, the genetic material for expressing life in all its forms. In the late 20th century, the possibilities of genetic engineering became practical for the first time, and a massive international effort began in 1990 to map out an entire human genome (the Human Genome Project).

The discipline of ecology typically traces its origin to the synthesis of Darwinian evolution and Humboldtian biogeography, in the late 19th and early 20th centuries. Equally important in the rise of ecology, however, were microbiology and soil science—particularly the cycle of life concept, prominent in the work Louis Pasteur and Ferdinand Cohn. The word "ecology" was coined by Ernst Haeckel, whose particularly holistic view of nature in general (and Darwin's theory in particular) was important in the spread of ecological thinking. In the 1930s, Arthur Tansley and others began developing the field of ecosystem ecology, which combined experimental soil science with physiological concepts of energy and the techniques of field biology.

Successful use of the scientific method in the physical sciences led to the same methodology being adapted to better understand the many fields of human endeavor. From this effort the social sciences have been developed.

Political science is a late arrival in terms of social sciences. However, the discipline has a clear set of antecedents such as moral philosophy, political philosophy, political economy, history, and other fields concerned with normative determinations of what ought to be and with deducing the characteristics and functions of the ideal form of government. The roots of politics are in prehistory. In each historic period and in almost every geographic area, we can find someone studying politics and increasing political understanding.

In Western culture, the study of politics is first found in Ancient Greece. The antecedents of European politics trace their roots back even earlier than Plato and Aristotle, particularly in the works of Homer, Hesiod, Thucydides, Xenophon, and Euripides. Later, Plato analyzed political systems, abstracted their analysis from more literary- and history- oriented studies and applied an approach we would understand as closer to philosophy. Similarly, Aristotle built upon Plato's analysis to include historical empirical evidence in his analysis.

An ancient Indian treatise on statecraft, economic policy and military strategy by Kautilya and , who are traditionally identified with (c. 350–283 BCE). In this treatise, the behaviors and relationships of the people, the King, the State, the Government Superintendents, Courtiers, Enemies, Invaders, and Corporations are analysed and documented. Roger Boesche describes the "Arthaśāstra" as "a book of political realism, a book analysing how the political world does work and not very often stating how it ought to work, a book that frequently discloses to a king what calculating and sometimes brutal measures he must carry out to preserve the state and the common good."

During the rule of Rome, famous historians such as Polybius, Livy and Plutarch documented the rise of the Roman Republic, and the organization and histories of other nations, while statesmen like Julius Caesar, Cicero and others provided us with examples of the politics of the republic and Rome's empire and wars. The study of politics during this age was oriented toward understanding history, understanding methods of governing, and describing the operation of governments.

With the fall of the Western Roman Empire, there arose a more diffuse arena for political studies. The rise of monotheism and, particularly for the Western tradition, Christianity, brought to light a new space for politics and political action. During the Middle Ages, the study of politics was widespread in the churches and courts. Works such as Augustine of Hippo's "The City of God" synthesized current philosophies and political traditions with those of Christianity, redefining the borders between what was religious and what was political. Most of the political questions surrounding the relationship between Church and State were clarified and contested in this period.

In the Middle East and later other Islamic areas, works such as the Rubaiyat of Omar Khayyam and Epic of Kings by Ferdowsi provided evidence of political analysis, while the Islamic Aristotelians such as Avicenna and later Maimonides and Averroes, continued Aristotle's tradition of analysis and empiricism, writing commentaries on Aristotle's works.

During the Italian Renaissance, Niccolò Machiavelli established the emphasis of modern political science on direct empirical observation of political institutions and actors. Later, the expansion of the scientific paradigm during the Enlightenment further pushed the study of politics beyond normative determinations. In particular, the study of statistics, to study the subjects of the state, has been applied to polling and voting.

In the 20th century, the study of ideology, behaviouralism and international relations led to a multitude of 'pol-sci' subdisciplines including rational choice theory, voting theory, game theory (also used in economics), psephology, political geography/geopolitics, political psychology/political sociology, political economy, policy analysis, public administration, comparative political analysis and peace studies/conflict analysis.

Historical linguistics emerged as an independent field of study at the end of the 18th century. Sir William Jones proposed that Sanskrit, Persian, Greek, Latin, Gothic, and Celtic languages all shared a common base. After Jones, an effort to catalog all languages of the world was made throughout the 19th century and into the 20th century. Publication of Ferdinand de Saussure's "Cours de linguistique générale" created the development of descriptive linguistics. Descriptive linguistics, and the related structuralism movement caused linguistics to focus on how language changes over time, instead of just describing the differences between languages. Noam Chomsky further diversified linguistics with the development of generative linguistics in the 1950s. His effort is based upon a mathematical model of language that allows for the description and prediction of valid syntax. Additional specialties such as sociolinguistics, cognitive linguistics, and computational linguistics have emerged from collaboration between linguistics and other disciplines.

The basis for classical economics forms Adam Smith's "An Inquiry into the Nature and Causes of the Wealth of Nations", published in 1776. Smith criticized mercantilism, advocating a system of free trade with division of labour. He postulated an "invisible hand" that regulated economic systems made up of actors guided only by self-interest. Karl Marx developed an alternative economic theory, called Marxian economics. Marxian economics is based on the labor theory of value and assumes the value of good to be based on the amount of labor required to produce it. Under this assumption, capitalism was based on employers not paying the full value of workers labor to create profit. The Austrian School responded to Marxian economics by viewing entrepreneurship as driving force of economic development. This replaced the labor theory of value by a system of supply and demand.

In the 1920s, John Maynard Keynes prompted a division between microeconomics and macroeconomics. Under Keynesian economics macroeconomic trends can overwhelm economic choices made by individuals. Governments should promote aggregate demand for goods as a means to encourage economic expansion. Following World War II, Milton Friedman created the concept of monetarism. Monetarism focuses on using the supply and demand of money as a method for controlling economic activity. In the 1970s, monetarism has adapted into supply-side economics which advocates reducing taxes as a means to increase the amount of money available for economic expansion.

Other modern schools of economic thought are New Classical economics and New Keynesian economics. New Classical economics was developed in the 1970s, emphasizing solid microeconomics as the basis for macroeconomic growth. New Keynesian economics was created partially in response to New Classical economics, and deals with how inefficiencies in the market create a need for control by a central bank or government.

The above "history of economics" reflects modern economic textbooks and this means that the last stage of a science is represented as the culmination of its history (Kuhn, 1962). The "invisible hand" mentioned in a lost page in the middle of a chapter in the middle of the "Wealth of Nations", 1776, advances as Smith's central message. It is played down that this "invisible hand" acts only "frequently" and that it is "no part of his [the individual's] intentions" because competition leads to lower prices by imitating "his" invention. That this "invisible hand" prefers "the support of domestic to foreign industry" is cleansed—often without indication that part of the citation is truncated. The opening passage of the "Wealth" containing Smith's message is never mentioned as it cannot be integrated into modern theory: "Wealth" depends on the division of labour which changes with market volume and on the proportion of productive to Unproductive labor.

The end of the 19th century marks the start of psychology as a scientific enterprise. The year 1879 is commonly seen as the start of psychology as an independent field of study. In that year Wilhelm Wundt founded the first laboratory dedicated exclusively to psychological research (in Leipzig). Other important early contributors to the field include Hermann Ebbinghaus (a pioneer in memory studies), Ivan Pavlov (who discovered classical conditioning), William James, and Sigmund Freud. Freud's influence has been enormous, though more as cultural icon than a force in scientific psychology.

The 20th century saw a rejection of Freud's theories as being too unscientific, and a reaction against Edward Titchener's atomistic approach of the mind. This led to the formulation of behaviorism by John B. Watson, which was popularized by B.F. Skinner. Behaviorism proposed epistemologically limiting psychological study to overt behavior, since that could be reliably measured. Scientific knowledge of the "mind" was considered too metaphysical, hence impossible to achieve.

The final decades of the 20th century have seen the rise of a new interdisciplinary approach to studying human psychology, known collectively as cognitive science. Cognitive science again considers the mind as a subject for investigation, using the tools of psychology, linguistics, computer science, philosophy, and neurobiology. New methods of visualizing the activity of the brain, such as PET scans and CAT scans, began to exert their influence as well, leading some researchers to investigate the mind by investigating the brain, rather than cognition. These new forms of investigation assume that a wide understanding of the human mind is possible, and that such an understanding may be applied to other research domains, such as artificial intelligence.

Ibn Khaldun can be regarded as the earliest scientific systematic sociologist. The modern sociology, emerged in the early 19th century as the academic response to the modernization of the world. Among many early sociologists (e.g., Émile Durkheim), the aim of sociology was in structuralism, understanding the cohesion of social groups, and developing an "antidote" to social disintegration. Max Weber was concerned with the modernization of society through the concept of rationalization, which he believed would trap individuals in an "iron cage" of rational thought. Some sociologists, including Georg Simmel and W. E. B. Du Bois, utilized more microsociological, qualitative analyses. This microlevel approach played an important role in American sociology, with the theories of George Herbert Mead and his student Herbert Blumer resulting in the creation of the symbolic interactionism approach to sociology.

American sociology in the 1940s and 1950s was dominated largely by Talcott Parsons, who argued that aspects of society that promoted structural integration were therefore "functional". This structural functionalism approach was questioned in the 1960s, when sociologists came to see this approach as merely a justification for inequalities present in the status quo. In reaction, conflict theory was developed, which was based in part on the philosophies of Karl Marx. Conflict theorists saw society as an arena in which different groups compete for control over resources. Symbolic interactionism also came to be regarded as central to sociological thinking. Erving Goffman saw social interactions as a stage performance, with individuals preparing "backstage" and attempting to control their audience through impression management. While these theories are currently prominent in sociological thought, other approaches exist, including feminist theory, post-structuralism, rational choice theory, and postmodernism.

Anthropology can best be understood as an outgrowth of the Age of Enlightenment. It was during this period that Europeans attempted systematically to study human behaviour. Traditions of jurisprudence, history, philology and sociology developed during this time and informed the development of the social sciences of which anthropology was a part.

At the same time, the romantic reaction to the Enlightenment produced thinkers such as Johann Gottfried Herder and later Wilhelm Dilthey whose work formed the basis for the culture concept which is central to the discipline. Traditionally, much of the history of the subject was based on colonial encounters between Western Europe and the rest of the world, and much of 18th- and 19th-century anthropology is now classed as scientific racism.

During the late 19th-century, battles over the "study of man" took place between those of an "anthropological" persuasion (relying on anthropometrical techniques) and those of an "ethnological" persuasion (looking at cultures and traditions), and these distinctions became part of the later divide between physical anthropology and cultural anthropology, the latter ushered in by the students of Franz Boas.

In the mid-20th century, much of the methodologies of earlier anthropological and ethnographical study were reevaluated with an eye towards research ethics, while at the same time the scope of investigation has broadened far beyond the traditional study of "primitive cultures" (scientific practice itself is often an arena of anthropological study).

The emergence of paleoanthropology, a scientific discipline which draws on the methodologies of paleontology, physical anthropology and ethology, among other disciplines, and increasing in scope and momentum from the mid-20th century, continues to yield further insights into human origins, evolution, genetic and cultural heritage, and perspectives on the contemporary human predicament as well.

During the 20th century, a number of interdisciplinary scientific fields have emerged. Examples include:

Communication studies combines animal communication, information theory, marketing, public relations, telecommunications and other forms of communication.

Computer science, built upon a foundation of theoretical linguistics, discrete mathematics, and electrical engineering, studies the nature and limits of computation. Subfields include computability, computational complexity, database design, computer networking, artificial intelligence, and the design of computer hardware. One area in which advances in computing have contributed to more general scientific development is by facilitating large-scale archiving of scientific data. Contemporary computer science typically distinguishes
itself by emphasising mathematical 'theory' in contrast to the practical emphasis of software engineering.

Environmental science is an interdisciplinary field. It draws upon the disciplines of biology, chemistry, earth sciences, ecology, geography, mathematics, and physics.

Materials science has its roots in metallurgy, mineralogy, and crystallography. It combines chemistry, physics, and several engineering disciplines. The field studies metals, ceramics, glass, plastics, semiconductors, and composite materials.

As an academic field, history of science and technology began with the publication of William Whewell's "History of the Inductive Sciences" (first published in 1837). A more formal study of the history of science as an independent discipline was launched by George Sarton's publications, "Introduction to the History of Science" (1927) and the "Isis" journal (founded in 1912). Sarton exemplified the early 20th-century view of the history of science as the history of great men and great ideas. He shared with many of his contemporaries a Whiggish belief in history as a record of the advances and delays in the march of progress. The history of science was not a recognized subfield of American history in this period, and most of the work was carried out by interested scientists and physicians rather than professional historians. With the work of I. Bernard Cohen at Harvard, the history of science became an established subdiscipline of history after 1945.

The history of mathematics, history of technology, and history of philosophy are distinct areas of research and are covered in other articles. Mathematics is closely related to but distinct from natural science (at least in the modern conception). Technology is likewise closely related to but clearly differs from the search for empirical truth.

History of science is an academic discipline, with an international community of specialists. Main professional organizations for this field include the History of Science Society, the British Society for the History of Science, and the European Society for the History of Science.

Much of the study of the history of science has been devoted to answering questions about what science "is", how it "functions", and whether it exhibits large-scale patterns and trends. The sociology of science in particular has focused on the ways in which scientists work, looking closely at the ways in which they "produce" and "construct" scientific knowledge. Since the 1960s, a common trend in science studies (the study of the sociology and history of science) has been to emphasize the "human component" of scientific knowledge, and to de-emphasize the view that scientific data are self-evident, value-free, and context-free. The field of Science and Technology Studies, an area that overlaps and often informs historical studies of science, focuses on the social context of science in both contemporary and historical periods.

Humboldtian science refers to the early 19th century approach of combining scientific field work with the age of Romanticism sensitivity, ethics and aesthetic ideals. It helped to install natural history as a separate field, gave base for ecology and was based on the role model of scientist, naturalist and explorer Alexander von Humboldt. The later 19th century positivism asserted that all authentic knowledge allows verification and that all authentic knowledge assumes that the only valid knowledge is scientific.

A major subject of concern and controversy in the philosophy of science has been the nature of "theory change" in science. Karl Popper argued that scientific knowledge is progressive and cumulative; Thomas Kuhn, that scientific knowledge moves through "paradigm shifts" and is not necessarily progressive; and Paul Feyerabend, that scientific knowledge is not cumulative or progressive and that there can be no demarcation in terms of method between science and any other form of investigation.

The mid 20th century saw a series of studies relying to the role of science in a social context, starting from Thomas Kuhn's "The Structure of Scientific Revolutions" in 1962. It opened the study of science to new disciplines by suggesting that the evolution of science was in part sociologically determined and that positivism did not explain the actual interactions and strategies of the human participants in science. As Thomas Kuhn put it, the history of science may be seen in more nuanced terms, such as that of competing paradigms or conceptual systems in a wider matrix that includes intellectual, cultural, economic and political themes outside of science. "Partly by selection and partly by distortion, the scientists of earlier ages are implicitly presented as having worked upon the same set of fixed problems and in accordance with the same set of fixed canons that the most recent revolution in scientific theory and method made seem scientific."

Further studies, e.g. Jerome Ravetz 1971 "Scientific Knowledge and its Social Problems" referred to the role of the scientific community, as a social construct, in accepting or rejecting (objective) scientific knowledge. The Science wars of the 1990 were about the influence of especially French philosophers, which denied the objectivity of science in general or seemed to do so. They described as well differences between the idealized model of a pure science and the actual scientific practice; while scientism, a revival of the positivism approach, saw in precise measurement and rigorous calculation the basis for finally settling enduring metaphysical and moral controversies. However, more recently some of the leading critical theorists have recognized that their postmodern deconstructions have at times been counter-productive, and are providing intellectual ammunition for reactionary interests. Bruno Latour noted that "dangerous extremists are using the very same argument of social construction to destroy hard-won evidence that could save our lives. Was I wrong to participate in the invention of this field known as science studies? Is it enough to say that we did not really mean what we meant?"

One recurring observation in the history of science involves the struggle for recognition of first-rate scientists working on the periphery of the scientific establishment. For instance, the great physicist Lord Rayleigh looked back (cited here) on John James Waterston's seminal paper on the kinetic theory of gases. The history of the neglect of Waterston's path-breaking article, Rayleigh felt, suggests that "a young author who believes himself capable of great things would usually do well to secure favourable recognition of the scientific world . . . before embarking upon higher flights."

William Harvey's experiences led him to an even more pessimistic view:"But what remains to be said about the quantity and source of the blood which thus passes, is of so novel and unheard-of character that I not only fear injury to myself from the envy of a few, but I tremble lest I have mankind at large for my enemies, so much doth wont and custom, that become as another nature, and doctrine once sown and that hath struck deep root, and respect for antiquity, influence all men."In more general terms, Robert K. Merton remarks that "the history of science abounds in instances of basic papers having been written by comparatively unknown scientists, only to be rejected or neglected for years."






</doc>
<doc id="14403" url="https://en.wikipedia.org/wiki?curid=14403" title="Hydrogen peroxide">
Hydrogen peroxide

Hydrogen peroxide is a chemical compound with the formula . In its pure form, it is a pale blue, clear liquid, slightly more viscous than water. Hydrogen peroxide is the simplest peroxide (a compound with an oxygen–oxygen single bond). It is used as an oxidizer, bleaching agent and antiseptic. Concentrated hydrogen peroxide, or "high-test peroxide", is a reactive oxygen species and has been used as a propellant in rocketry. Its chemistry is dominated by the nature of its unstable peroxide bond.

Hydrogen peroxide is unstable and slowly decomposes in the presence of base or a catalyst. Because of its instability, hydrogen peroxide is typically stored with a stabilizer in a weakly acidic solution. Hydrogen peroxide is found in biological systems including the human body. Enzymes that use or decompose hydrogen peroxide are classified as peroxidases.

The boiling point of has been extrapolated as being 150.2 °C, approximately 50 °C higher than water. In practice, hydrogen peroxide will undergo potentially explosive thermal decomposition if heated to this temperature. It may be safely distilled at lower temperatures under reduced pressure.

In aqueous solutions hydrogen peroxide differs from the pure material due to the effects of hydrogen bonding between water and hydrogen peroxide molecules. Hydrogen peroxide and water form a eutectic mixture, exhibiting freezing-point depression; pure water has a freezing point of 0 °C and pure hydrogen peroxide of −0.43 °C. The boiling point of the same mixtures is also depressed in relation with the mean of both boiling points (125.1 °C). It occurs at 114 °C. This boiling point is 14 °C greater than that of pure water and 36.2 °C less than that of pure hydrogen peroxide.

Hydrogen peroxide () is a nonplanar molecule with (twisted) C symmetry. Although the O−O bond is a single bond, the molecule has a relatively high rotational barrier of 2460 cm (29.45 kJ/mol); for comparison, the rotational barrier for ethane is 12.5 kJ/mol. The increased barrier is ascribed to repulsion between the lone pairs of the adjacent oxygen atoms and results in hydrogen peroxide displaying atropisomerism.

The molecular structures of gaseous and crystalline are significantly different. This difference is attributed to the effects of hydrogen bonding, which is absent in the gaseous state. Crystals of are tetragonal with the space group "D""P"42.

Hydrogen peroxide has several structural analogues with H−X−X−H bonding arrangements (water also shown for comparison). It has the highest (theoretical) boiling point of this series (X = O, N, S). Its melting point is also fairly high, being comparable to that of hydrazine and water, with only hydroxylamine crystallising significantly more readily, indicative of particularly strong hydrogen bonding. Diphosphane and hydrogen disulfide exhibit only weak hydrogen bonding and have little chemical similarity to hydrogen peroxide. All of these analogues are thermodynamically unstable. Structurally, the analogues all adopt similar skewed structures, due to repulsion between adjacent lone pairs.

Alexander von Humboldt synthesized one of the first synthetic peroxides, barium peroxide, in 1799 as a by-product of his attempts to decompose air.

Nineteen years later Louis Jacques Thénard recognized that this compound could be used for the preparation of a previously unknown compound, which he described as "oxidized water" – subsequently known as hydrogen peroxide. An improved version of this process used hydrochloric acid, followed by addition of sulfuric acid to precipitate the barium sulfate byproduct. Thénard's process was used from the end of the 19th century until the middle of the 20th century.

Thénard and Joseph Louis Gay-Lussac synthesized sodium peroxide in 1811. The bleaching effect of peroxides and their salts on natural dyes became known around that time, but early attempts of industrial production of peroxides failed, and the first plant producing hydrogen peroxide was built in 1873 in Berlin. The discovery of the synthesis of hydrogen peroxide by electrolysis with sulfuric acid introduced the more efficient electrochemical method. It was first implemented into industry in 1908 in Weißenstein, Carinthia, Austria. The anthraquinone process, which is still used, was developed during the 1930s by the German chemical manufacturer IG Farben in Ludwigshafen. The increased demand and improvements in the synthesis methods resulted in the rise of the annual production of hydrogen peroxide from 35,000 tonnes in 1950, to over 100,000 tonnes in 1960, to 300,000 tonnes by 1970; by 1998 it reached 2.7 million tonnes.

Pure hydrogen peroxide was long believed to be unstable, as early attempts to separate it from the water, which is present during synthesis, all failed. This instability was due to traces of impurities (transition-metal salts), which catalyze the decomposition of the hydrogen peroxide. Pure hydrogen peroxide was first obtained in 1894—almost 80 years after its discovery—by Richard Wolffenstein, who produced it by vacuum distillation.

Determination of the molecular structure of hydrogen peroxide proved to be very difficult. In 1892 the Italian physical chemist Giacomo Carrara (1864–1925) determined its molecular mass by freezing-point depression, which confirmed that its molecular formula is HO. At least half a dozen hypothetical molecular structures seemed to be consistent with the available evidence. In 1934, the English mathematical physicist William Penney and the Scottish physicist Gordon Sutherland proposed a molecular structure for hydrogen peroxide that was very similar to the presently accepted one.

Previously, hydrogen peroxide was prepared industrially by hydrolysis of the ammonium peroxydisulfate, which was itself obtained by the electrolysis of a solution of ammonium bisulfate () in sulfuric acid:

Today, hydrogen peroxide is manufactured almost exclusively by the anthraquinone process, which was formalized in 1936 and patented in 1939. It begins with the reduction of an anthraquinone (such as 2-ethylanthraquinone or the 2-amyl derivative) to the corresponding anthrahydroquinone, typically by hydrogenation on a palladium catalyst; the anthrahydroquinone then undergoes autoxidation to regenerate the starting anthraquinone, with hydrogen peroxide as a by-product. Most commercial processes achieve oxidation by bubbling compressed air through a solution of the derivatized anthracene, whereby the oxygen present in the air reacts with the labile hydrogen atoms (of the hydroxy groups), giving hydrogen peroxide and regenerating the anthraquinone. Hydrogen peroxide is then extracted, and the anthraquinone derivative is reduced back to the dihydroxy (anthracene) compound using hydrogen gas in the presence of a metal catalyst. The cycle then repeats itself.

The simplified overall equation for the process is simple:

The economics of the process depend heavily on effective recycling of the quinone (which is expensive) and extraction solvents, and of the hydrogenation catalyst.

A process to produce hydrogen peroxide directly from the elements has been of interest for many years. Direct synthesis is difficult to achieve, as the reaction of hydrogen with oxygen thermodynamically favours production of water. Systems for direct synthesis have been developed, most of which are based around finely dispersed metal catalysts. None of these has yet reached a point where they can be used for industrial-scale synthesis.

Hydrogen peroxide is most commonly available as a solution in water. For consumers, it is usually available from pharmacies at 3 and 6 wt% concentrations. The concentrations are sometimes described in terms of the volume of oxygen gas generated; one milliliter of a 20-volume solution generates twenty milliliters of oxygen gas when completely decomposed. For laboratory use, 30 wt% solutions are most common. Commercial grades from 70% to 98% are also available, but due to the potential of solutions of more than 68% hydrogen peroxide to be converted entirely to steam and oxygen (with the temperature of the steam increasing as the concentration increases above 68%) these grades are potentially far more hazardous and require special care in dedicated storage areas. Buyers must typically allow inspection by commercial manufacturers.

In 1994, world production of was around 1.9 million tonnes and grew to 2.2 million in 2006, most of which was at a concentration of 70% or less. In that year bulk 30% sold for around 0.54 USD/kg, equivalent to 1.50 USD/kg (0.68 USD/lb) on a "100% basis".

Hydrogen peroxide occurs in surface water, groundwater and in the atmosphere. It forms upon illumination or natural catalytic action by substances contained in water. Sea water contains 0.5 to 14 μg/L of hydrogen peroxide, freshwater 1 to 30 μg/L and air 0.1 to 1 parts per billion.

Hydrogen peroxide is thermodynamically unstable and decomposes to form water and oxygen with a Δ"H" of −98.2 kJ/mol and a ΔS of 70.5 J/(mol·K):

The rate of decomposition increases with rising temperature, concentration and pH, with cool, dilute, acidic solutions showing the best stability. Decomposition is catalysed by various compounds, including most transition metals and their compounds (e.g. manganese dioxide, silver, and platinum). Certain metal ions, such as or , can cause the decomposition to take a different path, with free radicals such as (HO·) and (HOO·) being formed. Non-metallic catalysts include potassium iodide, which reacts particularly rapidly and forms the basis of the elephant toothpaste experiment. Hydrogen peroxide can also be decomposed biologically by the enzyme catalase. The decomposition of hydrogen peroxide liberates oxygen and heat; this can be dangerous, as spilling high-concentration hydrogen peroxide on a flammable substance can cause an immediate fire.

Hydrogen peroxide exhibits oxidizing and reducing properties, depending on pH.

In acidic solutions, is one of the most powerful oxidizers known, when used for removing organic stains from laboratory glassware it is referred to as Piranha solution and is stronger than chlorine, chlorine dioxide, and potassium permanganate. Also, through catalysis, can be converted into hydroxyl radicals (·OH), which are highly reactive.

In acidic solutions is oxidized to (hydrogen peroxide acting as an oxidizing agent):

and sulfite () is oxidized to sulfate (). However, potassium permanganate is reduced to by acidic . Under alkaline conditions, however, some of these reactions reverse; for example, is oxidized to (as ).

In basic solution, hydrogen peroxide can reduce a variety of inorganic ions. When it acts as a reducing agent, oxygen gas is also produced. For example, hydrogen peroxide will reduce sodium hypochlorite and potassium permanganate, which is a convenient method for preparing oxygen in the laboratory:

Hydrogen peroxide is frequently used as an oxidizing agent. Illustrative is oxidation of thioethers to sulfoxides:

Alkaline hydrogen peroxide is used for epoxidation of electron-deficient alkenes such as acrylic acid derivatives, and for the oxidation of alkylboranes to alcohols, the second step of hydroboration-oxidation. It is also the principal reagent in the Dakin oxidation process.

Hydrogen peroxide is a weak acid, forming hydroperoxide or peroxide salts with many metals.

It also converts metal oxides into the corresponding peroxides. For example, upon treatment with hydrogen peroxide, chromic acid( + ) forms an unstable blue peroxide CrO(.

This kind of reaction is used industrially to produce peroxoanions. For example, reaction with borax leads to sodium perborate, a bleach used in laundry detergents:

The peroxide anion is a stronger nucleophile than hydroxide and displaces hydroxyl from oxyanions e.g. forming perborates and percarbonates. Sodium perborate and sodium percarbonate are important consumer and industrial bleaching agents; they stabilize hydrogen peroxide and limit side reactions (e.g. reduction and decomposition note below). The peroxide anion forms an adduct with urea, hydrogen peroxide–urea.

Hydrogen peroxide is both an oxidizing agent and reducing agent. The oxidation of hydrogen peroxide by sodium hypochlorite yields singlet oxygen. The net reaction of a ferric ion with hydrogen peroxide is a ferrous ion and oxygen. This proceeds via single electron oxidation and hydroxyl radicals. This is used in some organic chemistry oxidations, e.g. in the Fenton's reagent. Only catalytic quantities of iron ion is needed since peroxide also oxidizes ferrous to ferric ion. The net reaction of hydrogen peroxide and permanganate or manganese dioxide is manganous ion; however, until the peroxide is spent some manganous ions are reoxidized to make the reaction catalytic. This forms the basis for common monopropellant rockets.

Hydrogen peroxide is formed in human and animals as a short-lived product in biochemical processes and is toxic to cells. The toxicity is due to oxidation of proteins, membrane lipids and DNA by the peroxide ions. The class of biological enzymes called SOD (superoxide dismutase) is developed in nearly all living cells as an important antioxidant agent. They promote the disproportionation of superoxide into oxygen and hydrogen peroxide, which is then rapidly decomposed by the enzyme catalase to oxygen and water.

Peroxisomes are organelles found in virtually all eukaryotic cells. They are involved in the catabolism of very long chain fatty acids, branched chain fatty acids, -amino acids, polyamines, and biosynthesis of plasmalogens, etherphospholipids critical for the normal function of mammalian brains and lungs. Upon oxidation, they produce hydrogen peroxide in the following process:

Catalase, another peroxisomal enzyme, uses this HO to oxidize other substrates, including phenols, formic acid, formaldehyde, and alcohol, by means of the peroxidation reaction: 

This reaction is important in liver and kidney cells, where the peroxisomes neutralize various toxic substances that enter the blood. Some of the ethanol humans drink is oxidized to acetaldehyde in this way. In addition, when excess HO accumulates in the cell, catalase converts it to HO through this reaction:

Another origin of hydrogen peroxide is the degradation of adenosine monophosphate which yields hypoxanthine. Hypoxanthine is then oxidatively catabolized first to xanthine and then to uric acid, and the reaction is catalyzed by the enzyme xanthine oxidase:

The degradation of guanosine monophosphate yields xanthine as an intermediate product which is then converted in the same way to uric acid with the formation of hydrogen peroxide.

Eggs of sea urchin, shortly after fertilization by a sperm, produce hydrogen peroxide. It is then quickly dissociated to OH· radicals. The radicals serve as initiator of radical polymerization, which surrounds the eggs with a protective layer of polymer.

The bombardier beetle has a device which allows it to shoot corrosive and foul-smelling bubbles at its enemies. The beetle produces and stores hydroquinone and hydrogen peroxide, in two separate reservoirs in the rear tip of its abdomen. When threatened, the beetle contracts muscles that force the two reactants through valved tubes into a mixing chamber containing water and a mixture of catalytic enzymes. When combined, the reactants undergo a violent exothermic chemical reaction, raising the temperature to near the boiling point of water. The boiling, foul-smelling liquid partially becomes a gas (flash evaporation) and is expelled through an outlet valve with a loud popping sound.

Hydrogen peroxide is a signaling molecule of plant defense against pathogens.

Hydrogen peroxide has roles as a signalling molecule in the regulation of a wide variety of biological processes. The compound is a major factor implicated in the free-radical theory of aging, based on how readily hydrogen peroxide can decompose into a hydroxyl radical and how superoxide radical byproducts of cellular metabolism can react with ambient water to form hydrogen peroxide. These hydroxyl radicals in turn readily react with and damage vital cellular components, especially those of the mitochondria. At least one study has also tried to link hydrogen peroxide production to cancer. These studies have frequently been quoted in fraudulent treatment claims.

The amount of hydrogen peroxide in biological systems can be assayed using a fluorometric assay.

About 60% of the world's production of hydrogen peroxide is used for pulp- and paper-bleaching.

The second major industrial application is the manufacture of sodium percarbonate and sodium perborate, which are used as mild bleaches in laundry detergents. Sodium percarbonate, which is an adduct of sodium carbonate and hydrogen peroxide, is the active ingredient in such products as OxiClean and Tide laundry detergent. When dissolved in water, it releases hydrogen peroxide and sodium carbonate:

By themselves these bleaching agents are only effective at wash temperatures of or above and so are often used in conjunction with bleach activators, which facilitate cleaning at lower temperatures.

It is used in the production of various organic peroxides with dibenzoyl peroxide being a high volume example. It is used in polymerisations, as a flour bleaching agent and as a treatment for acne. Peroxy acids, such as peracetic acid and meta-chloroperoxybenzoic acid are also produced using hydrogen peroxide. Hydrogen peroxide has been used for creating organic peroxide-based explosives, such as acetone peroxide.

Hydrogen peroxide is used in certain waste-water treatment processes to remove organic impurities. In advanced oxidation processing, the Fenton reaction gives the highly reactive hydroxyl radical (·OH). This degrades organic compounds, including those that are ordinarily robust, such as aromatic or halogenated compounds. It can also oxidize sulfur based compounds present in the waste; which is beneficial as it generally reduces their odour.

Hydrogen peroxide can be used for the sterilization of various surfaces, including surgical tools and may be deployed as a vapour (VHP) for room sterilization. HO demonstrates broad-spectrum efficacy against viruses, bacteria, yeasts, and bacterial spores. In general, greater activity is seen against Gram-positive than Gram-negative bacteria; however, the presence of catalase or other peroxidases in these organisms can increase tolerance in the presence of lower concentrations. Higher concentrations of HO (10 to 30%) and longer contact times are required for sporicidal activity.

Hydrogen peroxide is seen as an environmentally safe alternative to chlorine-based bleaches, as it degrades to form oxygen and water and it is generally recognized as safe as an antimicrobial agent by the U.S. Food and Drug Administration (FDA).

Historically hydrogen peroxide was used for disinfecting wounds, partly because of its low cost and prompt availability compared to other antiseptics. It is now thought to inhibit healing and to induce scarring because it destroys newly formed skin cells. Only a very low concentration of HO can induce healing, and only if not repeatedly applied. Surgical use can lead to gas embolism formation. Despite this, it is still used for wound treatment in many developing countries.

Dermal exposure to dilute solutions of hydrogen peroxide cause whitening or bleaching of the skin due to microembolism caused by oxygen bubbles in the capillaries.

Diluted (between 1.9% and 12%) mixed with ammonium hydroxide is used to bleach human hair. The chemical's bleaching property lends its name to the phrase "peroxide blonde".
Hydrogen peroxide is also used for tooth whitening. It can be found in most whitening toothpastes. Hydrogen peroxide has shown positive results involving teeth lightness and chroma shade parameters. It works by oxidizing colored pigments onto the enamel where the shade of the tooth can indeed become lighter. Hydrogen peroxide can be mixed with baking soda and salt to make a home-made toothpaste.

Hydrogen peroxide may be used to treat acne, although benzoyl peroxide is a more common treatment.

Practitioners of alternative medicine have advocated the use of hydrogen peroxide for various conditions, including emphysema, influenza, AIDS and cancer, although there is no evidence of effectiveness and in some cases it may even be fatal.

The practice calls for the daily consumption of hydrogen peroxide, either orally or by injection and is, in general, based around two precepts. First, that hydrogen peroxide is naturally produced by the body to combat infection; and second, that human pathogens (including cancer: See Warburg hypothesis) are anaerobic and cannot survive in oxygen-rich environments. The ingestion or injection of hydrogen peroxide is therefore believed to kill disease by mimicking the immune response in addition to increasing levels of oxygen within the body. This makes it similar to other oxygen-based therapies, such as ozone therapy and hyperbaric oxygen therapy.

Both the effectiveness and safety of hydrogen peroxide therapy is scientifically questionable. Hydrogen peroxide is produced by the immune system but in a carefully controlled manner. Cells called phagocytes engulf pathogens and then use hydrogen peroxide to destroy them. The peroxide is toxic to both the cell and the pathogen and so is kept within a special compartment, called a phagosome. Free hydrogen peroxide will damage any tissue it encounters via oxidative stress; a process which also has been proposed as a cause of cancer.
Claims that hydrogen peroxide therapy increases cellular levels of oxygen have not been supported. The quantities administered would be expected to provide very little additional oxygen compared to that available from normal respiration. It should also be noted that it is difficult to raise the level of oxygen around cancer cells within a tumour, as the blood supply tends to be poor, a situation known as tumor hypoxia.

Large oral doses of hydrogen peroxide at a 3% concentration may cause irritation and blistering to the mouth, throat, and abdomen as well as abdominal pain, vomiting, and diarrhea.
Intravenous injection of hydrogen peroxide has been linked to several deaths.

The American Cancer Society states that "there is no scientific evidence that hydrogen peroxide is a safe, effective or useful cancer treatment." Furthermore, the therapy is not approved by the U.S. FDA.

High-concentration is referred to as "high-test peroxide" (HTP). It can be used either as a monopropellant (not mixed with fuel) or as the oxidizer component of a bipropellant rocket. Use as a monopropellant takes advantage of the decomposition of 70–98% concentration hydrogen peroxide into steam and oxygen. The propellant is pumped into a reaction chamber, where a catalyst, usually a silver or platinum screen, triggers decomposition, producing steam at over , which is expelled through a nozzle, generating thrust. monopropellant produces a maximal specific impulse ("I") of 161 s (1.6 kN·s/kg). Peroxide was the first major monopropellant adopted for use in rocket applications. Hydrazine eventually replaced hydrogen-peroxide monopropellant thruster applications primarily because of a 25% increase in the vacuum specific impulse. Hydrazine (toxic) and hydrogen peroxide (less-toxic [ACGIH TLV 0.01 and 1 ppm respectively]) are the only two monopropellants (other than cold gases) to have been widely adopted and utilized for propulsion and power applications. The Bell Rocket Belt, reaction control systems for X-1, X-15, Centaur, Mercury, Little Joe, as well as the turbo-pump gas generators for X-1, X-15, Jupiter, Redstone and Viking used hydrogen peroxide as a monopropellant.

As a bipropellant, is decomposed to burn a fuel as an oxidizer. Specific impulses as high as 350 s (3.5 kN·s/kg) can be achieved, depending on the fuel. Peroxide used as an oxidizer gives a somewhat lower "I" than liquid oxygen, but is dense, storable, noncryogenic and can be more easily used to drive gas turbines to give high pressures using an efficient "closed cycle". It can also be used for regenerative cooling of rocket engines. Peroxide was used very successfully as an oxidizer in World War II German rocket motors (e.g. T-Stoff, containing oxyquinoline stabilizer, for both the Walter HWK 109-500 "Starthilfe" RATO externally podded monopropellant booster system, and for the Walter HWK 109-509 rocket motor series used for the Me 163B), most often used with C-Stoff in a self-igniting hypergolic combination, and for the low-cost British Black Knight and Black Arrow launchers. 

In the 1940s and 1950s, the Hellmuth Walter KG-conceived turbine used hydrogen peroxide for use in submarines while submerged; it was found to be too noisy and require too much maintenance compared to diesel-electric power systems. Some torpedoes used hydrogen peroxide as oxidizer or propellant. Operator error in the use of hydrogen-peroxide torpedoes was named as possible causes for the sinkings of HMS "Sidon" and the Russian submarine "Kursk". SAAB Underwater Systems is manufacturing the Torpedo 2000. This torpedo, used by the Swedish Navy, is powered by a piston engine propelled by HTP as an oxidizer and kerosene as a fuel in a bipropellant system.

Hydrogen peroxide has various domestic uses, primarily as a cleaning and disinfecting agent.

Hydrogen peroxide reacts with certain di-esters, such as phenyl oxalate ester (cyalume), to produce chemiluminescence; this application is most commonly encountered in the form of glow sticks.

Some horticulturalists and users of hydroponics advocate the use of weak hydrogen peroxide solution in watering solutions. Its spontaneous decomposition releases oxygen that enhances a plant's root development and helps to treat root rot (cellular root death due to lack of oxygen) and a variety of other pests.

Laboratory tests conducted by fish culturists in recent years have demonstrated that common household hydrogen peroxide can be used safely to provide oxygen for small fish. The hydrogen peroxide releases oxygen by decomposition when it is exposed to catalysts such as manganese dioxide.

Regulations vary, but low concentrations, such as 6%, are widely available and legal to buy for medical use. Most over-the-counter peroxide solutions are not suitable for ingestion. Higher concentrations may be considered hazardous and are typically accompanied by a Material Safety Data Sheet (MSDS). In high concentrations, hydrogen peroxide is an aggressive oxidizer and will corrode many materials, including human skin. In the presence of a reducing agent, high concentrations of will react violently.

High-concentration hydrogen peroxide streams, typically above 40%, should be considered hazardous due to concentrated hydrogen peroxide's meeting the definition of a DOT oxidizer according to U.S. regulations, if released into the environment. The EPA Reportable Quantity (RQ) for D001 hazardous wastes is , or approximately , of concentrated hydrogen peroxide.

Hydrogen peroxide should be stored in a cool, dry, well-ventilated area and away from any flammable or combustible substances. It should be stored in a container composed of non-reactive materials such as stainless steel or glass (other materials including some plastics and aluminium alloys may also be suitable). Because it breaks down quickly when exposed to light, it should be stored in an opaque container, and pharmaceutical formulations typically come in brown bottles that block light.

Hydrogen peroxide, either in pure or diluted form, can pose several risks, the main one being that it forms explosive mixtures upon contact with organic compounds. Highly concentrated hydrogen peroxide itself is unstable and can cause a boiling liquid expanding vapour explosion (BLEVE) of the remaining liquid. Distillation of hydrogen peroxide at normal pressures is thus highly dangerous. It is also corrosive, especially when concentrated, but even domestic-strength solutions can cause irritation to the eyes, mucous membranes and skin. Swallowing hydrogen peroxide solutions is particularly dangerous, as decomposition in the stomach releases large quantities of gas (10 times the volume of a 3% solution), leading to internal bloating. Inhaling over 10% can cause severe pulmonary irritation.

With a significant vapour pressure (1.2 kPa at 50 °C), hydrogen-peroxide vapour is potentially hazardous. According to U.S. NIOSH, the immediately dangerous to life and health (IDLH) limit is only 75 ppm. The U.S. Occupational Safety and Health Administration (OSHA) has established a permissible exposure limit of 1.0 ppm calculated as an 8-hour time-weighted average (29 CFR 1910.1000, Table Z-1). Hydrogen peroxide has also been classified by the American Conference of Governmental Industrial Hygienists (ACGIH) as a "known animal carcinogen, with unknown relevance on humans". For workplaces where there is a risk of exposure to the hazardous concentrations of the vapours, continuous monitors for hydrogen peroxide should be used. Information on the hazards of hydrogen peroxide is available from OSHA and from the ATSDR.



Notes
Bibliography



</doc>
<doc id="14404" url="https://en.wikipedia.org/wiki?curid=14404" title="Hesychasm">
Hesychasm

Hesychasm is a mystical tradition of contemplative prayer in the Eastern Orthodox Church. Based on Jesus's injunction in the Gospel of Matthew that "when thou prayest, enter into thy closet, and when thou hast shut thy door, pray", hesychasm in tradition has been the process of retiring inward by ceasing to register the senses, in order to achieve an experiential knowledge of God (see Theoria).

"Hesychasm", , contemporary Byzantine , derives from the Greek "Hesychia" (, ), "stillness, rest, quiet, silence" and : "to keep stillness."

Metropolitan Kallistos Ware, a distinguished scholar of Orthodox theology, distinguishes five distinct usages of the term "hesychasm":

The origin of the term "hesychasmos," and of the related terms "hesychastes", "hesychia" and "hesychazo," is not entirely certain. According to the entries in Lampe's "A Patristic Greek Lexicon", the basic terms "hesychia" and "hesychazo" appear as early as the 4th century in such fathers as St John Chrysostom and the Cappadocians. The terms also appear in the same period in Evagrius Pontikos (c. 345 – 399), who although he is writing in Egypt is out of the circle of the Cappadocians, and in the "Sayings of the Desert Fathers."

The term "hesychast" is used sparingly in Christian ascetical writings emanating from Egypt from the 4th century on, although the writings of Evagrius and the "Sayings of the Desert Fathers" do attest to it. In Egypt, the terms more often used are "anchoretism" (Gr. , "withdrawal, retreat"), and "anchorite" (Gr. , "one who withdraws or retreats, i.e. a hermit").

The term "hesychast" was used in the 6th century in Palestine in the "Lives" of Cyril of Scythopolis, many of which lives treat of hesychasts who were contemporaries of Cyril. Here, it should be noted that several of the saints about whom Cyril was writing, especially Euthymios and Savas, were in fact from Cappadocia. The laws "(novellae)" of the emperor Justinian I (r. 527–565) treat "hesychast" and "anchorite" as synonyms, making them interchangeable terms.

The terms "hesychia" and "hesychast" are used quite systematically in the "Ladder of Divine Ascent" of St John of Sinai (523–603) and in "Pros Theodoulon" by St Hesychios (c. 750?), who is ordinarily also considered to be of the School of Sinai. It is not known where either St John of Sinai or St Hesychios were born, nor where they received their monastic formation.

It appears that the particularity of the term "hesychast" has to do with the integration of the continual repetition of the Jesus Prayer into the practices of mental ascesis that were already used by hermits in Egypt. "Hesychasm" itself is not recorded in Lampe's Lexicon, which indicates that it is a later usage, and the term "Jesus Prayer" is not found in any of the fathers of the church. Saint John Cassian (c. 360 – 435) presents as the formula used in Egypt for repetitive prayer, not the Jesus Prayer, but "O God, make speed to save me: O Lord, make haste to help me".

By the 14th century, however, on Mount Athos the terms "hesychasm" and "hesychast" refer to the practice and to the practitioner of a method of mental ascesis that involves the use of the Jesus Prayer assisted by certain psychophysical techniques. Most likely, the rise of the term "hesychasm" reflects the coming to the fore of this practice as something concrete and specific that can be discussed.

Books used by the hesychast include the "Philokalia", a collection of texts on prayer and solitary mental ascesis written from the 4th to the 15th centuries, which exists in a number of independent redactions; the "Ladder of Divine Ascent;" the collected works of St Symeon the New Theologian (949–1022); and the works of St Isaac the Syrian (7th century), as they were selected and translated into Greek at the Monastery of St Savas near Jerusalem about the 10th century.

Hesychastic practice involves acquiring an inner focus and blocking of the physical senses. In this, hesychasm shows its roots in Evagrius Ponticus and even in the Greek tradition of asceticism going back to Plato.

According to some of the adepts of the Jewish Merkabah mystical tradition, if one wished to "descend to the Merkabah" one had to adopt the prayer posture taken by the prophet Elijah in I Kings 18:42, namely to pray with one's head between one's knees. This is the same prayer posture used by the Christian hesychasts and is the reason that they were mocked by their opponents as "navel gazers" (omphalopsychites). This bodily position and the practice of rhythmically breathing while invoking a divine name seems to be common to both Jewish Merkabah mysticism and Christian hesychasm. Thus the practice may have origins in the ascetical practices of the biblical prophets.

Alan Segal in his book "Paul the Convert" suggests that the Apostle Paul may have been an early adept of Merkabah mysticism in which case what was novel to Paul's experience of divine light on the road to Damascus was not the experience of divine light itself, but that the source of this divine light identified himself as the Jesus whose followers Paul was persecuting. Daniel Boyarin notes that Paul's own account of this experience would therefore be the earliest first person account of the mystical vision of a Merkabah adept.

The hesychast interprets Jesus's injunction in the Gospel of Matthew to "go into your closet to pray" to mean that one should ignore the senses and withdraw inward. Saint John of Sinai writes: 
"Theosis" is obtained by engaging in contemplative prayer resulting from the cultivation of watchfulness (Gk: "nepsis"). According to the standard ascetic formulation of this process, there are three stages: 

Sobriety contributes to this mental ascesis that rejects tempting thoughts; it puts a great emphasis on focus and attention. The hesychast is to pay extreme attention to the consciousness of his inner world and to the words of the Jesus Prayer, not letting his mind wander in any way at all. While he maintains his practice of the Jesus Prayer, which becomes automatic and continues twenty-four hours a day, seven days a week, the hesychast cultivates "nepsis", watchful attention, to reject tempting thoughts (the "thieves") that come to the hesychast as he watches in sober attention in his hermitage. St John of Sinai describes hesychast practice as follows:
The hesychast is to attach Eros (Gr. "eros)", that is, "yearning", to his practice of sobriety so as to overcome the temptation to acedia (sloth). He is also to use an extremely directed and controlled anger against the tempting thoughts, although to obliterate them entirely he is to invoke Jesus Christ via the Jesus Prayer.

Much of the literature of hesychasm is occupied with the psychological analysis of such tempting thoughts (e.g. St Mark the Ascetic). This psychological analysis owes much to the ascetical works of Evagrius Pontikos, with its doctrine of the eight passions.

The primary task of the hesychast is to engage in mental ascesis. The hesychast is to bring his mind (Gr. "nous)" into his heart so as to practise both the Jesus Prayer and sobriety with his mind in his heart. In solitude and retirement, the hesychast repeats the Jesus Prayer, ""Lord Jesus Christ, son of God, have mercy on me, the sinner."" The hesychast prays the Jesus Prayer 'with the heart'—with meaning, with intent, 'for real' (see ontic). He never treats the Jesus Prayer as a string of syllables whose 'surface' or overt verbal meaning is secondary or unimportant. He considers bare repetition of the Jesus Prayer as a mere string of syllables, perhaps with a 'mystical' inner meaning beyond the overt verbal meaning, to be worthless or even dangerous. This emphasis on the actual, real invocation of Jesus Christ mirrors an Eastern understanding of mantra in that physical action/voice and meaning are utterly inseparable.

The descent of the mind into the heart is taken quite literally by the practitioners of hesychasm and is not at all considered to be a metaphorical expression. Some of the psychophysical techniques described in the texts are to assist the descent of the mind into the heart at those times that only with difficulty it descends on its own.

The goal at this stage is a practice of the Jesus Prayer with the mind in the heart, which practice is free of images (see "Pros Theodoulon)." By the exercise of sobriety (the mental ascesis against tempting thoughts), the hesychast arrives at a continual practice of the Jesus Prayer with his mind in his heart and where his consciousness is no longer encumbered by the spontaneous inception of images: his mind has a certain stillness and emptiness that is punctuated only by the eternal repetition of the Jesus Prayer.

This stage is called the "guard of the mind." This is a very advanced stage of ascetical and spiritual practice, and attempting to accomplish this prematurely, especially with psychophysical techniques, can cause very serious spiritual and emotional harm to the would-be hesychast. St Theophan the Recluse once remarked that bodily postures and breathing techniques were virtually forbidden in his youth, since, instead of gaining the Spirit of God, people succeeded only "in ruining their lungs."

The guard of the mind is the practical goal of the hesychast. It is the condition in which he remains as a matter of course throughout his day, every day until he dies.

There is a very great emphasis on humility in the practice of the Jesus Prayer, great cautions being given in the texts about the disaster that will befall the would-be hesychast if he proceeds in pride, arrogance or conceit. It is also assumed in the hesychast texts that the hesychast is a member of the Orthodox Church in good standing.

It is from the guard of the mind that he is raised to contemplation by the grace of God.

The hesychast usually experiences the contemplation of God as light, the "uncreated light" of the theology of St Gregory Palamas. The hesychast, when he has by the mercy of God been granted such an experience, does not remain in that experience for a very long time (there are exceptions—see for example the "Life" of St Savas the Fool for Christ (14th century), written by St Philotheos Kokkinos (14th century)), but he returns 'to earth' and continues to practise the guard of the mind.

The uncreated light that the hesychast experiences is identified with the Holy Spirit. Experiences of the uncreated light are allied to the 'acquisition of the Holy Spirit'. Notable accounts of encounters with the Holy Spirit in this fashion are found in St Symeon the New Theologian's account of the illumination of 'George' (considered a pseudonym of St Symeon himself); in the 'conversation with Motovilov' in the "Life" of St Seraphim of Sarov (1759–1833); and, more recently, in the reminiscences of Elder Porphyrios (Bairaktaris) of Kafsokalivia ("Wounded by Love" pp. 27 – 31).

Hesychasts are fully integrated into the liturgical and sacramental life of the Orthodox Church, including the daily cycle of liturgical prayer of the Divine Office and the Divine Liturgy. However, hesychasts who are living as hermits might have a very rare attendance at the Divine Liturgy (see the life of Saint Seraphim of Sarov) and might not recite the Divine Office except by means of the Jesus Prayer (attested practice on Mt Athos). In general, the hesychast restricts his external activities for the sake of his hesychastic practice.

Orthodox tradition warns against seeking ecstasy as an end in itself. Hesychasm is a traditional complex of ascetical practices embedded in the doctrine and practice of the Orthodox Church and intended to purify the member of the Orthodox Church and to make him ready for an encounter with God that comes to him when and if God wants, through God's grace. The goal is to acquire, through purification and grace, the Holy Spirit and salvation. Any ecstatic states or other unusual phenomena which may occur in the course of hesychast practice are considered secondary and unimportant, even quite dangerous. Moreover, seeking after unusual 'spiritual' experiences can itself cause great harm, ruining the soul and the mind of the seeker. Such a seeking after 'spiritual' experiences can lead to "spiritual delusion" (Ru. "prelest," Gr. "plani)"—the antonym of sobriety—in which a person believes himself or herself to be a saint, has hallucinations in which he or she 'sees' angels, Christ, etc. This state of spiritual delusion is in a superficial, egotistical way pleasurable, but can lead to madness and suicide, and, according to the hesychast fathers, makes salvation impossible.

Mount Athos is a center of the practice of hesychasm. St Paisius Velichkovsky and his disciples made the practice known in Russia and Romania, although hesychasm was already previously known in Russia, as is attested by St Seraphim of Sarov's independent practice of it.

About the year 1337, hesychasm attracted the attention of a learned member of the Orthodox Church, Barlaam, a Calabrian monk who at that time held the office of abbot in the Monastery of St Saviour in Constantinople and who visited Mount Athos. Mount Athos was then at the height of its fame and influence, under the reign of Andronicus III Palaeologus and under the leadership of the "Protos" Symeon. On Mount Athos, Barlaam encountered hesychasts and heard descriptions of their practices, also reading the writings of the teacher in hesychasm of St Gregory Palamas, himself an Athonite monk. Trained in Western Scholastic theology, Barlaam was scandalized by hesychasm and began to combat it both orally and in his writings. As a private teacher of theology in the Western Scholastic mode, Barlaam propounded a more intellectual and propositional approach to the knowledge of God than the hesychasts taught.

Barlaam took exception to the doctrine entertained by the hesychasts as to the nature of the light, the experience of which was said to be the goal of hesychast practice, regarding it as heretical and blasphemous. It was maintained by the hesychasts to be of divine origin and to be identical to the light which had been manifested to Jesus' disciples on Mount Tabor at the Transfiguration. This Barlaam held to be polytheistic, inasmuch as it postulated two eternal substances, a visible and an invisible God.

On the hesychast side, the controversy was taken up by St Gregory Palamas, afterwards Archbishop of Thessalonica, who was asked by his fellow monks on Mt Athos to defend hesychasm from the attacks of Barlaam. St Gregory himself was well-educated in Greek philosophy. St Gregory defended hesychasm in the 1340s at three different synods in Constantinople, and he also wrote a number of works in its defense.

In these works, St Gregory Palamas uses a distinction, already found in the 4th century in the works of the Cappadocian Fathers, between the energies or operations (Gr. "energeies)" of God and the essence of God. St Gregory taught that the energies or operations of God were uncreated. He taught that the essence of God can never be known by his creature even in the next life, but that his uncreated energies or operations can be known both in this life and in the next, and convey to the hesychast in this life and to the righteous in the next life a true spiritual knowledge of God. In Palamite theology, it is the uncreated energies of God that illumine the hesychast who has been vouchsafed an experience of the uncreated light.

In 1341, the dispute came before a synod held at Constantinople and presided over by the Emperor Andronicus III; the synod, taking into account the regard in which the writings of the pseudo-Dionysius were held, condemned Barlaam, who recanted and returned to Calabria, afterwards becoming a bishop in the Catholic Church.

One of Barlaam's friends, Gregory Akindynos, who originally was also a friend of St Gregory Palamas, took up the controversy, which also played a role in the civil war between the supporters of John Cantacuzenus and John V Palaiologos. Three other synods on the subject were held, at the second of which the followers of Barlaam gained a brief victory. But in 1351 at a synod under the presidency of the Emperor John VI Cantacuzenus, hesychast doctrine was established as the doctrine of the Orthodox Church.

St. John Cassian is not represented in the "Philokalia" except by two brief extracts, but this is most likely due to his having written in Latin. His works "(Coenobitical Institutions" and the "Conferences)" represent a transmittal of Evagrius Pontikos' ascetical doctrines to the West. These works formed the basis of much of the spirituality of the Order of Saint Benedict and its offshoots. Hence, the tradition of St John Cassian in the West concerning the spiritual practice of the hermit can be considered to be a tradition that is parallel to that of hesychasm in the Eastern Orthodox Church.

While Constantinople experienced a succession of councils alternately approving and condemning doctrine concerning hesychasm considered as identified with Palamism (the last of the five senses in which, according to Kallistos Ware, the term is used), the Western Church held no council in which to make a pronouncement on the issue, and the word "hesychasm" does not appear in the "Enchiridion Symbolorum et Definitionum" (Handbook of Creeds and Definitions), the collection of Roman Catholic teachings originally compiled by Heinrich Joseph Dominicus Denzinger.

The Roman Catholic Church has thus never expressed any condemnation of Palamism, and uses in its liturgy readings from the work of Nicholas Kabasilas, a supporter of Palamas in the controversy that took place in the East. Its Liturgy of the Hours includes extracts from Kabasilas's "Life in Christ" on Tuesday, Wednesday, and Thursday of the Fifth Week of Easter in Year II of the two-year cycle for the Office of Readings.

Western theologians have tended to reject hesychasm, in some instances equating it with quietism, perhaps because "quietism" is the literal translation of "hesychasm". However, according to Kallistos Ware, "To translate 'hesychasm' as 'quietism', while perhaps etymologically defensible, is historically and theologically misleading." Ware asserts that "the distinctive tenets of the 17th-century Western quietists is not characteristic of Greek hesychasm." Elsewhere too, Ware argues that it is important not to translate "hesychasm" as "quietism".

These theologians generally rejected the contention that, in the case of God, the distinction between essence and energies is real rather than, albeit with a foundation in reality, notional (in the mind). In their view, affirming an ontological essence-energies distinction in God contradicted the teaching of the First Council of Nicaea on divine unity. According to Adrian Fortescue, the Scholastic theory that God is pure actuality prevented Palamism from having much influence in the West, and it was from Western Scholasticism that hesychasm's philosophical opponents in the East borrowed their weapons.

In the "Catholic Encyclopedia" of 1909, Simon Vailhé accused Palamas's teachings that humans could achieve a corporal perception of the divinity and his distinction between God's essence and his energies as "monstrous errors" and "perilous theological theories". He further characterized the Eastern canonization of Palamas's teachings as a "resurrection of polytheism". Fortescue, also writing in the "Catholic Encyclopedia", claimed that "the real distinction between God's essence and operation remains one more principle, though it is rarely insisted on now, in which the Orthodox differ from Catholics".

The later 20th century saw a remarkable change in the attitude of Roman Catholic theologians to Palamas, a "rehabilitation" of him that has led to increasing parts of the Western Church considering him a saint, even if uncanonized. John Meyendorff describes the 20th-century rehabilitation of Palamas in the Western Church as a "remarkable event in the history of scholarship." Andreas Andreopoulos cites the 1910 "Catholic Encyclopedia" article by Fortescue as an example of how Barlaam's distrustful and hostile attitude regarding hesychasm survived until recently in the West, adding that now "the Western world has started to rediscover what amounts to a lost tradition. Hesychasm, which was never anything close to a scholar's pursuit, is now studied by Western theologians who are astounded by the profound thought and spirituality of late Byzantium."

Some Western scholars maintain that there is no conflict between Palamas's teaching and Roman Catholic thought. Some Western theologians have incorporated the essence-energies distinction into their own thinking.
For example, G. Philips asserts that the essence-energies distinction as presented by Palamas is "a typical example of a perfectly admissible theological pluralism" that is compatible with the Roman Catholic magisterium.

Jeffrey D. Finch claims that "the future of East-West rapprochement appears to be overcoming the modern polemics of neo-scholasticism and neo-Palamism".

According to Kallistos Ware, some Western theologians, both Roman Catholic and Anglican, see the theology of Palamas as introducing an inadmissible division within God; however, others have incorporated his theology into their own thinking, maintaining, as Jeffrey D. Finch reports, that there is no conflict between his teaching and Roman Catholic thought.

Pope John Paul II repeatedly emphasized his respect for Eastern theology as an enrichment for the whole Church, declaring that, even after the painful division between the Christian East and the See of Rome, that theology has opened up profound thought-provoking perspectives of interest to the entire Catholic Church. He spoke in particular of the hesychast controversy. The term "hesychasm", he said, refers to a practice of prayer marked by deep tranquillity of the spirit intent on contemplating God unceasingly by invoking the name of Jesus. While from a Catholic viewpoint there have been tensions concerning some developments of the practice, the pope said, there is no denying the goodness of the intention that inspired its defence, which was to stress that man is offered the concrete possibility of uniting himself in his inner heart with God in that profound union of grace known as "theosis", divinization.

In modern times, centering prayer, which is also called "prayer of the heart" and "prayer of simplicity," has been popularized by Thomas Keating, drawing on hesychasm and "The Cloud of Unknowing".

The Islamic counterpart is called muraqaba, which appears similar to the Jewish word merkabah. There are two concepts about the nature of union with Allah. One is called unity of being by Ibn Arabi but orthodox scholars criticize it as pantheistic. Indian Sufi scholar Ahmad Sirhindi proposed unity of perception where a Sufi is so immersed in divine vision that he forgets everything including himself.

The Jesus Prayer is referred to in J. D. Salinger's pair of stories "Franny and Zooey". It is also a central theme of the 2006 Russian film "Ostrov".




</doc>
<doc id="14405" url="https://en.wikipedia.org/wiki?curid=14405" title="Hemlock">
Hemlock

Hemlock may refer to:






</doc>
<doc id="14406" url="https://en.wikipedia.org/wiki?curid=14406" title="Harmony Society">
Harmony Society

The Harmony Society was a Christian theosophy and pietist society founded in Iptingen, Germany, in 1785. Due to religious persecution by the Lutheran Church and the government in Württemberg, the group moved to the United States, where representatives initially purchased land in Butler County, Pennsylvania. On February 15, 1805, the group of approximately 400 followers formally organized the Harmony Society, placing all their goods in common.

Under its founder and spiritual leader, Johann Georg Rapp (1757–1847); Frederick (Reichert) Rapp (1775–1834), his adopted son who managed its business affairs; and their associates, the Society existed for one hundred years; roughly from 1805 until 1905. Members were known as Harmonists, Harmonites, or Rappites. The Society is best known for its worldly successes, most notably the establishment of three model communities, the first at Harmony, Pennsylvania; the second, also called Harmony, in the Indiana Territory, now New Harmony, Indiana; and the third and final town at Economy, now Ambridge, Pennsylvania.

Johann Georg Rapp (November 1, 1757 – August 7, 1847), also known as George Rapp, was the founder of the religious sect called Harmonists, Harmonites, Rappites, or the Harmony Society. Born in Iptingen, Duchy of Württemberg, Germany, Rapp was a "bright but stubborn boy" who was also deeply religious. His "strong personality" and religious convictions began to concern local church authorities when he refused to attend church services or take communion. Rapp and his group of believers began meeting in Iptengen and eventually emigrated to the United States, where they established three communities: Harmony, Butler County, Pennsylvania; Harmony (later named New Harmony), Posey County, Indiana; and Economy, Beaver County, Pennsylvania.

Rapp became inspired by the philosophies of Jakob Böhme, Philipp Jakob Spener, Johann Heinrich Jung, and Emanuel Swedenborg, among others, and later wrote "Thoughts on the Destiny of Man", published in German in 1824 and in English a year later, in which he outlined his ideas and philosophy. Rapp lived out his remaining days in Economy, where he died on August 7, 1847, at the age of 89.

By the mid-1780s, Rapp had begun preaching to the Separatists, his followers in Iptengen, who met privately and refused to attend church services or take communion. As their numbers increased, Rapp's group officially split with the Lutheran Church in 1785 and was banned from meeting. Despite warnings from local authorities, the group continued to meet privately and attract even more followers.

By 1798 Rapp and his group of followers had already begun to distance themselves from mainstream society and intended to establish a new religious congregation of fellow believers. In the Lomersheimer declaration, written in 1798, these religious Separatists presented their statement of faith, based on Christian principles, to the Wurttemberg legislature. Rapp's followers declared their desire to form a separate congregation who would meet in members' homes, free from Lutheran Church doctrines. The group supported the belief that baptism was not necessary until children could decide for themselves whether they wanted to become a Christian. They also believed that confirmation for youth was not necessary and communion and confession would only be held a few times a year. Although the Separatists supported civil government, the group refused to make a physical oath in its support, "for according to the Gospel not oath is allowed him who gives evidence of a righteous life as an upright man." They also refused to serve in the military or attend Lutheran schools, choosing instead to teach their children at home. This declaration of faith, along with some later additions, guided the Harmony Society's religious beliefs even after they had emigrated from Germany to the United States.

In the 1790s, Rapp's followers continued to increase, reaching as many as 10,000 to 12, 000 members. The increasing numbers, which included followers outside of Rapp's village, continued to concern the government, who feared they might become rebellious and dangerous to the state. Although no severe actions were initially taken to repress the Separatists, the group began to consider emigration to France or the United States. In 1803, when the government began to persecute Rapp's followers, he decided to move the entire group to the United States. Rapp and a small group of men left Iptingen in 1803 and traveled to America to find a new home. On May 1, 1804, the first group of emigrants departed for the United States. The initial move scattered the followers and reduced Rapp's original group of 12,000 to just a few followers. Johan Frederich Reichert, who later agreed to become Rapp's adopted son and took the name of Frederick Reichert Rapp, reported in a letter dated February 25, 1804, that there were "at least 100 families or 500 persons actually ready to go" even if they had to sacrifice their property.

In 1804, while Rapp and his associates remained in the United States looking for a place to settle, his followers sailed to America aboard several vessels and made their way to western Pennsylvania, where they waited until land had been selected for their new settlement. Rapp was able to secure a large tract of land in Pennsylvania and started his first commune, known as Harmonie or Harmony, in Butler County, Pennsylvania, where the Society existed from 1804 to 1815. It soon grew to a population of about 800, and was highly profitable. Ten years later, the town was sold and the Harmonists moved westward to the Indiana Territory, where they established the town of Harmony, now called New Harmony, Indiana, and remained there from 1815 to 1825. The Indiana settlement was sold to Robert Owen and was renamed New Harmony. Ten years after the move to Indiana the commune moved again, this time returning to western Pennsylvania, and named their third and final town Economy ('Ökonomie' in German). The Harmonists lived in Economy until the Society was dissolved in 1905.

On February 15, 1805, the settlers at Harmony, Pennsylvania, signed articles of association to formally establish the Harmony Society in the United States. In this document, Society members agreed to hold all property in a common fund, including working capital of $23,000 to purchase land, livestock, tools, and other goods needed to establish their town. The agreement gave the Society legal status in the United States and protected it from dissolution. Members contributed all of their possessions, pledged cooperation in promoting the interests of the group, and agreed to accept no pay for their services. In return, the members would receive care as long as they lived with the group. Under this agreement, if a member left the Society, their funds would be returned without interest or, if they had not contributed to the Society's treasury, they would receive a small monetary gift.

The Society was a religious congregation who submitted to spiritual and material leadership under Rapp and his associates and worked together for the common good of all its members. Believing that the Second Coming of Christ would occur during their lifetimes, the Harmonists contented to live simply under a strict religious doctrine, gave up tobacco, and advocated celibacy.

In December 1804 Rapp and a party of two others initially contracted to purchase of land for $11,250 in Butler County, Pennsylvania, and later acquired additional land to increase their holdings to approximately by the time they advertised their property for sale in 1814. Here they built the town of Harmony, a small community that had, in 1805, nearly 50 log houses, a large barn, a gristmill, and more than 150 acres of cleared land to grow crops. Because the climate was not well suited for growing grapes and nearby property was not available to expand their landholdings, the Harmonists submitted a petition to the U.S. government for assistance in purchasing land elsewhere. In January 1806 Rapp traveled to Washington, D.C. to hear discussions in Congress regarding the Harmonists' petition for a grant that would allow them to purchase approximately acre of land in the Indiana Territory. While the Senate passed the petition on January 29, it was defeated in House of Representatives on February 18. The Harmonists had to find other financial means to support their plans for future expansion. By 1810 the town's population reached approximately 700, with about 130 houses. The Society landholdings also increased to . In the years that followed, the Society survived disagreements among its members, while shortages of cash and lack of credit threatened its finances. Still, the young community had a good reputation for its industry and agricultural production.

At Harmony, George Rapp, also known as Father Rapp, was recognized as the spiritual head of the Society, the one that they went to for discussions, confessions, and other matters. Rapp's adopted son, Frederick, managed the Society's business and commercial affairs.

Rapp let newcomers into the Society and, after a trial period, usually about a year, they were accepted as permanent members. While new members continued to arrive, including immigrants from Germany, others found the Harmonists' religious life too difficult and left the group. In addition, during a period of religious zeal in 1807 and 1808, most, but not all, of the Harmonists adopted the practice of celibacy and there were also few marriages among the members. Rapp's son, Johannes, was married in 1807; and it was the last marriage on record until 1817. Although Rapp did not entirely bar sex initially, it gradually became a custom and there were few births in later years.

In 1811 Harmony's population rose to around 800 persons involved in farming and various trades. Although profit was not a primary goal, their finances improved and the enterprise was profitable, but not sufficient to carry out their planned expansions. Within a few years of their arrival, the Harmonist community included an inn, a tannery, warehouses, a brewery, several mills, stables, and barns, a church/meetinghouse, a school, additional dwellings for members, a labyrinth, and workshops for different trades. In addition, more land was cleared for vineyards and crops. The Harmonists also produced yarn and cloth.

Several factors led to the Harmonists' decision to leave Butler County. Because the area's climate was not suitable, they had difficulties growing grapes for wine. In addition, as westward migration brought new settlers to the county, making it less isolated, the Harmonists began having troubles with neighbors who were not part of the Society. By 1814 Butler County's growing population and rising land prices made it difficult for the Society to expand, causing the group's leaders to look for more land elsewhere. Once land had been located that offered a better climate and room to expand, the group began plans to move. In 1814 the Harmonites sold their first settlement to Abraham Ziegler, a Mennonite, for $100,000 and moved west to make a new life for themselves in the Indiana Territory.

In 1814 the Harmony Society moved to the Indiana Territory, where it initially acquired approximately of land along the Wabash River in Posey County and later acquired more. Over the next ten years the Society built a thriving new community they called Harmonie or Harmony on the Wabash in the Indiana wilderness. (The town's name was changed to New Harmony after the Harmonists left in 1824.) The Harmonists entered into agriculture and manufacture on a larger scale than they had done in Pennsylvania. When the Harmonists advertised their Indiana property for sale in 1824, they had acquired of land, of which was under cultivation.

During the summer and fall of 1814, many Harmonists fell sick from fever (malaria) and work on the new town nearly ceased. During this time the Society lost about 120 people and others fell ill until conditions were improved and the swamps around the area were drained. Despite these illnesses, construction of the new town continued. By 1819 the Harmonites had built 150 log homes, a church, a community storehouse, barns, stables, and a tavern, along with thriving shops and mills, and cleared land for farming. As the new settlement in Indiana grew, it also began to attract new arrivals, including emigrants from Germany, who expected the Harmonists to pay for their passage to America.

Visitors to the new town commented on its growing commercial and industrial work. In 1819 the town had a steam-operated wool carding and spinning factory, a brewery, distillery, vineyards, and a winery, but not all visitors were impressed with the growing communist town on the frontier. The Society also had visitors from another communal religious society, the Shakers. In 1816 meetings between the Shakers and Harmonists considered a possible union of the two societies, but religious differences between the two groups halted the union. Members of the groups remained, however, in contact over the years. George Rapp's daughter and others lived for a time at the Shaker settlement in West Union, Indiana, where the Shakers helped a number of Harmonites learn the English language.

The Harmonist community continued to thrive during the 1820s. The Society shipped its surplus agricultural produce and manufactured goods throughout the Ohio and Mississippi valleys or sold them through their stores at Harmony and Shawneetown and their agents in Pittsburgh, Saint Louis, Louisville, and elsewhere. Under Frederick Rapp's financial management the Society prospered, but he soon wished for a location better suited to manufacturing and commercial purposes. They had initially selected the land near the Wabash River for its isolation and opportunity for expansion, but the Harmonites were now a great distance from the eastern markets and trade in this location wasn't to their liking. They also had to deal with unfriendly neighbors. As abolitionists, the Harmonites faced disagreeable elements from slavery supporters in Kentucky, only away, which caused them much annoyance. By 1824 the decision had been made to sell their property in Indiana and search for land to the east.

On January 3, 1825, the Harmonists and Robert Owen, a Welsh-born industrialist and social reformer, came to a final agreement for the sale of the Society's land and buildings in Indiana for $150,000. Owen named the town New Harmony, and by May, the last of the Harmony Society's remaining members returned to Pennsylvania.

In 1824 Frederick Rapp initially purchased along the Ohio River, northwest of Pittsburgh, Pennsylvania, for $10,000, and later bought an additional for $33,445, giving the Society more than to develop into a new community. The Harmonites named their third and last town Economy, after the spiritual notion of the Divine Economy, "a city in which God would dwell among men" and where perfection would be attained.

At Economy the Harmonists intended to become more involved in manufacturing and their new town on the Ohio River provided better access to eastern markets and water access to the south and west than they had in Indiana. By 1826 the Harmonists had woolen and cotton mills in operation as well as a steam-operated grain mill. The Harmonist society also ran a wine press, a hotel, post office, saw mills, stores, and a variety of farms. Here, under the business acumen and efficient management of Frederick Rapp, they enjoyed such prosperity that by 1829 they dominated trade and the markets of Pittsburgh and down the Ohio River. The Harmonists' competitors accused them of creating a monopoly and called on state government to dissolve the group. Despite the attacks, the Harmonists developed Economy into a prosperous factory town, engaged in farming on a large scale, and maintained a brewery, distillery, and wine-making operation. They also pioneered the manufacturing of silk in the United States.

The community was not neglectful of matters pertaining to art and culture. Frederick Rapp purchased artifacts and installed a museum containing fine paintings and many curiosities and antiques, but it proved to be unprofitable and was sold at a loss. In addition, the Harmonists maintained a deer park, a floral park, and a maze, or labyrinth. The Harmonists were fond of music and many of the members were accomplished musicians. They sang, had a band/orchestra, composed songs, and gave much attention to its cultivation. By 1830 they had amassed a 360-volume library.

In 1832 the Society suffered a serious division. Of 750 members, 250 became alienated through the influence of Bernhard Müller (self-styled Count de Leon), who, with 40 followers (also at variance with the authorities in the old country), had come to Economy to affiliate with the Society. Rapp and Leon could not agree; a separation and apportionment of the property were therefore agreed upon. This secession of one-third of the Society, which consisted mostly of the flower of young manhood and young womanhood who did not want to maintain the custom of celibacy, broke Frederick's heart. He died within two years. It resulted in a considerable fracturing of the community. Nevertheless, the Society remained prosperous in business investments for many more years to come.

After Frederick Rapp's death in 1834, George Rapp appointed Romelius Baker and Jacob Henrici as trustees to manage the Society's business affairs. After George Rapp's death in 1847, the Society reorganized. While a board of elders was elected for the enforcement of the Society's rules and regulations, business management passed to its trustees: Baker and Henrici, 1847–68; Henrici and Jonathan Lenz, 1869–90; Henrici and Wolfel, 1890; Henrici and John S. Duss, 1890–1892; Duss and Seiber, 1892–1893; Duss and Reithmuller, 1893–1897;Duss, 1897–1903; and finally to Suzanna (Susie) C. Duss in 1903. By 1905 membership had dwindled to just three members and the Society was dissolved.

The settlements at Economy remained economically successful until the late 19th century, producing many goods in their cotton and woolen factories, sawmill, tannery, and from their vineyards and distillery. They also produced high quality silk for garments. Rapp's granddaughter, Gertrude, began the silk production in Economy on a small scale from 1826 to 1828, and later expanded. This was planned in New Harmony, but fulfilled when they arrived at Economy. The Harmonists were industrious and utilized the latest technologies of the day in their factories. Because the group chose to adopt celibacy and their members grew older, more work gradually had to be hired out. As their membership declined, they stopped manufacturing operations, other than what they needed for themselves, and began to invest in other ventures such as the oil business, coal mining, timber, railroads, land development, and banking. The group invested in the construction of the Pittsburgh and Lake Erie Railroad, established the Economy Savings Institution and the Economy Brick Works, and operated the Economy Oil Company, as well as the Economy Planing Mill, Economy Lumber Company, and eventually donated some land in Beaver Falls for the construction of Geneva College. The Society exerted a major influence on the economic development of Western Pennsylvania.

Oil production in the mid-1860s brought the high-water mark of the Society's prosperity. By the close of Baker's administration in 1868, The Society's wealth was probably $2 million. By 1890, however, the Society was in debt and on the verge of bankruptcy with a depleted and aged membership. In addition, the Society faced litigation from previous members and would-be heirs. The Society's trustee, John S. Duss, settled the lawsuits, liquidated its business ventures, and paid the Society's indebtedness. The great strain which he had undergone at this time undermined his health and he resigned his trusteeship in 1903. With only a few members left, the remaining land and assets were sold under the leadership of Duss's wife, Susanna (Susie), and the Society was formally dissolved in 1905. At the time of the Society's dissolution, its net worth was $1.2 million.

In 1916 the Commonwealth of Pennsylvania acquired and 17 buildings of Economy, which became the Old Economy Village historic site. The American Bridge Company had already acquired other parts of the Society's land in 1902 to build the town of Ambridge.

In 1791 George Rapp said, "I am a prophet, and I am called to be one" in front of the civil affairs official in Maulbronn, Germany, who promptly had him imprisoned for two days and threatened with exile if he did not cease preaching. To the great consternation of church and state authorities, this mere peasant from Iptingen had become the outspoken leader of several thousand Separatists in the southern German duchy of Württemberg. By 1802 the Separatists had grown in number to about 12,000 and the Württemberg government decided that they were a dangerous threat to social order. Rapp was summoned to Maulbronn for an interrogation, and the government confiscated Separatist books. When released in 1803, from a brief time in prison, Rapp told his followers to pool their assets and follow him on a journey for safety to the "land of Israel" in the United States, and soon over 800 people were living with him there.

The Harmonites were Christian pietist Separatists who split from the Lutheran Church in the late 18th century. Under the leadership of George Rapp, the group left Württemberg, Germany, and came to the United States in 1803. Due to the troubles they had in Europe, the group sought to establish a more perfect society in the American wilderness. They were nonviolent pacifists who refused to serve in the military and tried to live by George Rapp's philosophy and literal interpretations of the New Testament. They first settled and built the town of Harmony, Pennsylvania, in 1804, and established the Harmony Society in 1805 as a religious commune. In 1807, celibacy was advocated as the preferred custom of the community in an attempt to purify themselves for the coming Millennium. Rapp believed that the events and wars going on in the world at the time were a confirmation of his views regarding the imminent Second Coming of Christ, and he also viewed Napoleon as the Antichrist. In 1814, the Society sold their first town in Pennsylvania and moved to the Indiana Territory, where they built their second town. In 1824, they decided it was time to leave Indiana, sold their land and town in Indiana, and moved to their final settlement in Western Pennsylvania.

The Harmonites were Millennialists, in that they believed Jesus Christ was coming to earth in their lifetime to help usher in a thousand-year kingdom of peace on earth. This is perhaps why they believed that people should try to make themselves "pure" and "perfect", and share things with others while willingly living in communal "harmony" (Acts 4:32-35) and practicing celibacy. They believed that the old ways of life on earth were coming to an end, and that a new perfect kingdom on earth was about to be realized.

They also practiced forms of Esoteric Christianity, Mysticism (Christian mysticism), and Rapp often spoke of the virgin spirit or Goddess named Sophia in his writings. Rapp was very influenced by the writings of Jakob Böhme, Philipp Jakob Spener, and Emanuel Swedenborg, among others. Also, at Economy, there are glass bottles and literature that seem to indicate that the group was interested in (and practiced) alchemy. Other books found in the Harmony Society's library in Economy, include those by the following authors: Christoph Schütz, Gottfried Arnold, Justinus Kerner, Thomas Bromley, Jane Leade, Johann Scheible ("Sixth and Seventh Books of Moses"), Paracelsus, and Georg von Welling, among others.

The Harmonites tended to view unmarried celibate life as morally superior to marriage, based on Rapp's belief that God had originally created Adam as a dual being, having male and female sexual organs. According to this view, when the female portion of Adam separated to form Eve, disharmony followed, but one could attempt to regain harmony through celibacy.

George Rapp predicted that on September 15, 1829, the three and one half years of the Sun Woman would end and Christ would begin his reign on earth. Dissension grew when Rapp's predictions did not come to pass. In March 1832, one third of the group left the Society and some began following Bernhard Müller, who claimed to be the Lion of Judah. Nevertheless, most of the group stayed and Rapp continued to lead them until he died on August 7, 1847. His last words to his followers were, "If I did not so fully believe, that the Lord has designated me to place our society before His presence in the land of Canaan, I would consider this my last".

The Harmonites did not mark their graves with headstones or grave markers, because they thought it was unnecessary to do so; however, one exception is George Rapp's son Johannes' stone marker in Harmony, Pennsylvania, which was installed by non-Harmonites many years after the Harmonites left that town. Today, Harmonist graveyards are fenced in grassy areas with signs posted nearby explaining this practice.

The Harmony Society's architecture reflected their Swabian German traditions, as well as the styles that were being developed in America during the 19th century. In the early days of the Society, many of the homes were initially log cabins and later, Harmonist craftsmen built timber-frame homes. At Economy, their homes were mostly two-story brick houses "that showed the influence of their American neighbors." In general, Harmonist buildings, in addition to being sturdy and functional, were centrally heated, economical to maintain, and resistant to fire, weather, and termites.

Once established at Harmony, Pennsylvania, the Society planned to replace the log dwellings with brick structures, but the group moved to the Indiana Territory before the plan was completed. In Indiana, log homes were soon replaced with one- or two-story houses of timber frame or brick construction in addition to four large rooming houses (dormitories) for its growing membership. The new town also included shops, schools, mills, a granary, a hotel, library, distilleries, breweries, a brick kiln, pottery ovens, barn, stables, storehouses, and two churches, one of which was brick.

In 1822 William Herbert, a visitor to Harmony, Indiana, described the new brick church and the Harmonists' craftsmanship:

"These people exhibit considerable taste as well as boldness of design in some of their works. They are erecting a noble church, the roof of which is supported in
the interior by a great number of stately columns, which have been turned from
trees in their own forests. The kinds of wood made use of for this purpose are, I
am informed, black walnut, cherry and sassafras. Nothing I think can exceed the
grandeur of the joinery and the masonry and brickwork seem to be of the first
order. The form of this church is that of a cross, the limbs being short and equal;
and as the doors, which there are four, are placed at the end of the limbs, the
interior of the building as seen from the entrance, has a most ample and spacious effect... I could scarcely imagine myself to be in the woods of Indiana, on the borders of the Wabash, while pacing the long resounding aisles, and surveying the stately colonnades of this church."

Frame structures were built on piers to keep the air circulating across the area's damp soil, while brick structures had a root cellar with a drainage tunnel. Inside, Harmonists built fireplaces to the left or right of center to allow for a long center beam, adding strength to support the structure and its heavy, shingled roof. "Dutch biscuits" (wood laths wrapped in straw and mud) provided insulation and soundproofing between the ceiling and floors. The exterior was insulated with bricks between the exterior's unpainted weatherboards and the interior's lath and plaster walls. Structures had standard parts and pre-cut, pre-measured timbers, which were assembled on the ground, adjusted to fit on site, raised in place, and locked into place with pegs and mortise and tenon joints. Two-story floor plans for homes included a large living room, kitchen, and entrance hall, with stairs to the second floor and attic. In Indiana, Harmonists did their baking in communal ovens, so stoves could be substituted for fireplaces.

At Harmony, Pennsylvania, four to six members were assigned to a home, where they lived as families, although not all those living in the household were related. Even when the house contained those that were married, they would live together as brother and sister, since there was a suggestion and custom of practicing celibacy. In Indiana, Harmonists continued to live in homes, but they also built dormitories to house single men and women.

Society members woke between 5 a.m. and 6 a.m. They ate breakfast between 6 a.m. and 7 a.m., lunch at 9 a.m., dinner at noon, afternoon lunch at 3 p.m., and supper between 6 p.m. and 7 p.m. They did their chores and work during the day. At the end of the day, members met for meetings and had a curfew of 9 p.m. On Sundays, the members respected the "Holy day" and did no unnecessary work, but attended church services, singing groups, and other social activities.

Their style of dress reflected their Swabian German roots and traditions and was adapted to their life in America. Although the Harmonites typically wore plain clothing, made with their own materials by their own tailors, they would wear their fine garments on Sundays and on other special occasions. At Economy, on special occasions and Sundays, women wore silk dresses using fabric of their own manufacture. Clothing varied in color, but often carried the same design. On a typical day, women wore ankle-length dresses, while men wore pants with vests or coats and a hat.

The Harmonites were a prosperous agricultural and industrial people. They had many machines that helped them be successful in their trades. They even had steam-powered engines that ran the machines at some of their factories in Economy. They kept their machines up to date, and had many factories and mills.

Each member of the Society had a job in a certain craft or trade. Most of the work done by men consisted of manual labor, while the women dealt more with textiles or agriculture.

As Economy became more technologically developed, Harmonites began to hire others from outside the Society, especially when their numbers decreased because of the custom of celibacy and as they eventually let fewer new members join. Although the Harmonites did seek work-oriented help from the outside, they were known as a community that supported themselves, kept their ways of living in their community, mainly exported goods, and tried to import as little as possible.

George Rapp had an eloquent style, which matched his commanding presence, and he was the personality that led the group through all the different settlements. After Rapp's death in 1847, a number of members left the group because of disappointment and disillusionment over the fact that his prophecies regarding the return of Jesus Christ in his lifetime were not fulfilled. However, many stayed in the group, and the Harmony Society went on to become an even more profitable business community that had many worldly financial successes under the leadership of Romelius L. Baker and Jacob Henrici.

Over time the group became more protective of itself, did not allow many new members, moved further from its religious foundation to a more business-oriented and pragmatic approach, and the custom of celibacy eventually drained it of its membership. The land and financial assets of the Harmony Society were sold off by the few remaining members under the leadership of John Duss and his wife, Susanna, by the year 1906.

Today, many of the Society's remaining buildings are preserved; all three of their settlements in the United States have been declared National Historic Landmark Districts by the National Park Service.





</doc>
<doc id="14408" url="https://en.wikipedia.org/wiki?curid=14408" title="Huneric">
Huneric

Huneric or Hunneric or Honeric (died December 23, 484) was King of the (North African) Vandal Kingdom (477–484) and the oldest son of Genseric. He abandoned the imperial politics of his father and concentrated mainly on internal affairs. He was married to Eudocia, daughter of western Roman Emperor Valentinian III (419–455) and Licinia Eudoxia. The couple had one child, a son named Hilderic.

Huneric was the first Vandal king who used the title "King of the Vandals and Alans". Despite adopting this style, and that the Vandals maintained their sea-power and their hold on the islands of the western Mediterranean, Huneric did not have the prestige that his father Genseric had enjoyed with other states.

Huneric was a son of King Genseric (or Gaiseric), and was sent to Italy as a hostage in 435, when his father made a treaty with the Western emperor Valentinian III. Huneric became king of the Vandals on his father's death in 477. Like Gaiseric he was an Arian, and his reign is chiefly memorable for his persecution of members of the orthodox Christian Church in his dominions. Eudocia, daughter of Valentinian III, was Huneric's wife.

Huneric was a fervent adherent to Arianism. Yet his reign opened with making a number of positive overtures towards the local Roman population. Following the visit of a diplomatic mission from the Eastern Roman Empire led by Alexander, Huneric restored properties seized by his father from the merchants of Carthage. He also lifted the policy of persecuting the local Catholics, allowing them to hold a synod wherein they elected a new Catholic bishop of Carthage, Eugenius, after a vacancy of 24 years.
However, not long after the ordination of Eugenius, Huneric reversed himself and began to once again persecute Catholics. Furthermore, he tried to make Catholic property fall to the state, but when this caused too much protest from the Eastern Roman Emperor, he chose to banish a number of Catholics to a faraway province instead. On February 1, 484 he organized a meeting of Catholic bishops with Arian bishops, but on February 24, 484 he forcibly removed the Catholic bishops from their offices and banished some to Corsica. A few were executed, including the former proconsul Victorian along with Frumentius and other wealthy merchants, who were killed at Hadrumetum after refusing to become Arians. Among those exiled was Vigilius, bishop of Thapsus, who published a theological treatise against Arianism.

Additionally, Huneric murdered many members of the Hasdingi dynasty and also persecuted Manichaeans.

Towards the end of his reign, the Moors in the Aurès Mountains (in modern-day Algeria) successfully rebelled from Vandal rule. 
Upon his death on December 23, 484, Huneric was succeeded by his nephew Gunthamund (reigned 484–496).



</doc>
<doc id="14409" url="https://en.wikipedia.org/wiki?curid=14409" title="Hasdingi">
Hasdingi

The Hasdingi were the southern tribes of the Vandals, an East Germanic tribe. They lived in areas of today's southern Poland, western Ukraine, Slovakia and Hungary. They were part of the migratory movements of the Vandals, into the Iberian peninsula and later on to North Africa.

The Hasdingi crossed the Rhine into Gaul in 406 AD, although their king Godigisel lost his life in battle against the Franks during the crossing. The Hasdingi settled as foederati in Gallaecia (today Galicia, Asturias and the north of Portugal) along with the Suebi in 409 AD and their territory was one of the earliest Barbarian territories to be founded.

Gunderic, Godegisel's successor as king of the Hasdingi, lost his kingdom to king Hermeric of the Suebi after the Battle of the Nervasos Mountains against an allied force of Suebi and Romans in 419. He fled to Baetica with his army where he also became king of the Silingi Vandals and of the Alans. Gunderic was succeeded by his brother Genseric in 428 AD, who subsequently fled from Iberia to North Africa where he established a kingdom at Carthage.




</doc>
<doc id="14410" url="https://en.wikipedia.org/wiki?curid=14410" title="Hermes">
Hermes

Hermes (; ) is an Olympian god in Greek religion and mythology, the son of Zeus and the Pleiad Maia, and the second youngest of the Olympian gods (Dionysus being the youngest).

Hermes was the emissary and messenger of the gods. Hermes was also "the divine trickster" and "the god of boundaries and the transgression of boundaries, ... the patron of herdsmen, thieves, graves, and heralds." He is described as moving freely between the worlds of the mortal and divine, and was the conductor of souls into the afterlife. He was also viewed as the protector and patron of roads and travelers.

In some myths, he is a trickster and outwits other gods for his own satisfaction or for the sake of humankind. His attributes and symbols include the herma, the rooster, the tortoise, satchel or pouch, winged sandals, and winged cap. His main symbol is the Greek "kerykeion" or Latin "caduceus," which appears in a form of two snakes wrapped around a winged staff with carvings of the other gods.

In the Roman adaptation of the Greek pantheon (see "interpretatio romana"), Hermes is identified with the Roman god Mercury, who, though inherited from the Etruscans, developed many similar characteristics such as being the patron of commerce.

The earliest form of the name "Hermes" is the Mycenaean Greek *"hermāhās", written "e-ma-a" ("e-ma-ha") in the Linear B syllabic script. Most scholars derive "Hermes" from Greek ἕρμα "herma", "prop, heap of stones, boundary marker", from which the word "hermai" ("boundary markers dedicated to Hermes as a god of travelers") also derives. The etymology of ἕρμα itself is unknown, but it is probably not an Proto-Indo-European word. However, the stone etymology is also linked to Indo-European "*ser-" (“to bind, put together”). Scholarly speculation that "Hermes" derives from a more primitive form meaning "one cairn" is disputed. In Greek, a lucky find is a ἕρμαιον "hermaion".

According to one theory that has received considerable scholarly acceptance, Hermes himself originated as a form of the god Pan, who has been identified as a reflex of the Proto-Indo-European pastoral god "*Péhusōn", in his aspect as the god of boundary markers. Later, the epithet supplanted the original name itself and Hermes took over the roles as god of messengers, travelers, and boundaries, which had originally belonged to Pan, while Pan himself continued to be venerated by his original name in his more rustic aspect as the god of the wild in the relatively isolated mountainous region of Arcadia. In later myths, after the cult of Pan was reintroduced to Attica, Pan was said to be Hermes's son.

Other origins have also been proposed. R. S. P. Beekes rejects the connection with "herma" and suggests a Pre-Greek origin. Other scholars have suggested that Hermes may be a cognate of the Vedic Sarama.

Homer and Hesiod portrayed Hermes as the author of skilled or deceptive acts and also as a benefactor of mortals. In the "Iliad", he is called "the bringer of good luck", "guide and guardian", and "excellent in all the tricks". He was a divine ally of the Greeks against the Trojans. However, he did protect Priam when he went to the Greek camp to retrieve the body of his son Hector and accompanied them back to Troy.

He also rescued Ares from a brazen vessel where he had been imprisoned by Otus and Ephialtes. In the "Odyssey", Hermes helps his great-grand son, the protagonist Odysseus, by informing him about the fate of his companions, who were turned into animals by the power of Circe. Hermes instructed Odysseus to protect himself by chewing a magic herb; he also told Calypso of Zeus' order to free Odysseus from her island to allow him to continue his journey back home. When Odysseus killed the suitors of his wife, Hermes led their souls to Hades. In "The Works and Days", when Zeus ordered Hephaestus to create Pandora to disgrace humanity by punishing Prometheus's act of giving fire to man, every god gave her a gift, and Hermes' gifts were lies, seductive words, and a dubious character. Hermes was then instructed to take her as wife to Epimetheus.

Aeschylus wrote in "The Eumenides" that Hermes helped Orestes kill Clytemnestra under a false identity and other stratagems, and also said that he was the god of searches, and those who seek things lost or stolen. In "Philoctetes", Sophocles invokes Hermes when Odysseus needs to convince Philoctetes to join the Trojan War on the side of the Greeks, and in Euripides' "Rhesus" Hermes helps Dolon spy on the Greek navy.

Aesop featured him in several of his fables, as ruler of the gate of prophetic dreams, as the god of athletes, of edible roots, and of hospitality. He also said that Hermes had assigned each person his share of intelligence.

The Hymn to Hermes invokes him as the one "of many shifts ("polytropos"), blandly cunning, a robber, a cattle driver, a bringer of dreams, a watcher by night, a thief at the gates, one who was soon to show forth wonderful deeds among the deathless gods." Hermes, as an inventor of fire, is a parallel of the Titan Prometheus. In addition to the lyre, Hermes was believed to have invented many types of racing and the sports of wrestling and boxing, and therefore was a patron of athletes.

In 1820 Shelley translated this hymn.

H. G. Evelyn-White's translation, published 1914, is used on the Perseus Project.

Several writers of the Hellenistic period expanded the list of Hermes's achievements. Callimachus said that Hermes disguised himself as a cyclops to scare the Oceanides and was disobedient to his mother. One of the Orphic Hymns Khthonios is dedicated to Hermes, indicating that he was also a god of the underworld. Aeschylus had called him by this epithet several times. Another is the Orphic Hymn to Hermes, where his association with the athletic games held is mystic in tone.

Phlegon of Tralles said he was invoked to ward off ghosts, and Pseudo-Apollodorus reported several events involving Hermes. He participated in the Gigantomachy in defense of Olympus; was given the task of bringing baby Dionysus to be cared for by Ino and Athamas and later by nymphs of Asia, followed Hera, Athena and Aphrodite in a beauty contest; favored the young Hercules by giving him a sword when he finished his education and lent his sandals to Perseus. The Thracian princes identified him with their god Zalmoxis, considering his ancestor.

Anyte of Tegea of the 3rd century BC, in translation by Richard Aldington, wrote:
called "Hermes of the Ways" after the patronage of travelers.

Hermes was also called Atlantiades (), because his mother, Maia was the daughter of Atlas.

In ancient Greek cult, "kriophoros" (Greek: κριοφόρος) or criophorus, the "ram-bearer," is a figure that commemorates the solemn sacrifice of a ram. It becomes an epithet of Hermes: Hermes Kriophoros.

Hermes's epithet "Argeiphontes" (), meaning "Argus-slayer", recalls his slaying of the hundred-eyed giant Argus Panoptes, who was watching over the heifer-nymph Io in the sanctuary of Queen Hera herself in Argos. Hermes placed a charm on Argus's eyes with the caduceus to cause the giant to sleep, after this he slew the giant. Argus' eyes were then put into the tail of the peacock, a symbol of the goddess Hera.

The chief office of the God was as messenger.

The messenger divine and herald of the Gods, he wears the gifts from his father, the Petasus and Talaria.

and also


Hermes is sometimes depicted in art works holding a purse.


No cult to Hermes Dolios existed in Attica, of this Athens being the capital, and so this form of Hermes seems to have existed in speech only.

The god is ambiguous.

According to prominent folklorist Yeleazar Meletinsky, Hermes is a deified trickster and master of thieves ("a plunderer, a cattle-raider, a night-watching" in Homers' "Hymns") and deception (Euripides) and (possibly evil) tricks and trickeries, crafty (from "lit". god of craft), the cheat, the god of stealth.

and cunning, (see also, to act secretively as "kleptein", in reference "EL Wheeler"), of treachery, the schemer.

Hermes Dolios, was worshipped at Pellene and invoked through Odysseus.

Hermes is "amoral" like a baby. Although Zeus sent Hermes as a teacher to humanity to teach them knowledge of and value of justice and to improve inter-personal relationships ("bonding between mortals").

Considered to have a mastery of rhetorical persuasion and "special pleading", the god typically has nocturnal "". Hermes knows the boundaries and crosses the borders of them to confuse their definition.

In the Lang translation of Homer's Hymn to Hermes, the god after being born is described as a "robber", "a captain of raiders", and a "thief of the gates".

According to the late Jungian psychotherapist López-Pedraza, everything Hermes thieves, he later sacrifices to the gods.

Autolycus received his skills as the greatest of thieves due to sacrificing to Hermes as his patron.

Other epithets included:

Prior to being known as Hermes, Frothingham thought the god to have existed as a snake-god. Angelo (1997) thinks Hermes to be based on the Thoth archetype. The absorbing ("combining") of the attributes of Hermes to Thoth developed after the time of Homer amongst Greek and Roman; Herodotus was the first to identify the Greek god with the Egyptian (Hermopolis), Plutarch and Diodorus also, although Plato thought the gods to be dis-similar (Friedlander 1992).

A cult was established in Greece in remote regions, likely making him a god of nature, farmers, and shepherds. It is also possible that since the beginning he has been a deity with shamanic attributes linked to divination, reconciliation, magic, sacrifices, and initiation and contact with other planes of existence, a role of mediator between the worlds of the visible and invisible.

During the 3rd century BC, a communication between Petosiris (a priest) to King Nechopso, probably written in Alexandria c. 150 BC, states Hermes is the teacher of all secret wisdoms available to knowing by the experience of religious ecstasy.

Due to his constant mobility, he was considered the god of commerce and social intercourse, the wealth brought in business, especially sudden or unexpected enrichment, travel, roads and crossroads, borders and boundary conditions or transient, the changes from the threshold, agreements and contracts, friendship, hospitality, sexual intercourse, games, data, the draw, good luck, the sacrifices and the sacrificial animals, flocks and shepherds and the fertility of land and cattle. In addition to serving as messenger to Zeus, Hermes carried the souls of the dead to Hades, and directed the dreams sent by Zeus to mortals.

One of the oldest places of worship for Hermes was Mount Cyllene in Arcadia, where the myth says that he was born. Tradition says that his first temple was built by Lycaon. From there the cult would have been taken to Athens, and then radiated to the whole of Greece, according to Smith, and his temples and statues became extremely numerous. Lucian of Samosata said he saw the temples of Hermes everywhere.

In many places, temples were consecrated in conjunction with Aphrodite, as in Attica, Arcadia, Crete, Samos and in Magna Graecia. Several ex-votos found in his temples revealed his role as initiator of young adulthood, among them soldiers and hunters, since war and certain forms of hunting were seen as ceremonial initiatory ordeals. This function of Hermes explains why some images in temples and other vessels show him as a teenager.
As a patron of the gym and fighting, Hermes had statues in gyms and he was also worshiped in the sanctuary of the Twelve Gods in Olympia where Greeks celebrated the Olympic Games. His statue was held there on an altar dedicated to him and Apollo together.
A temple within the Aventine was consecrated in 495 BC.

Symbols of Hermes were the palm tree, turtle, rooster, goat, the number four, several kinds of fish and incense. Sacrifices involved honey, cakes, pigs, goats, and lambs. In the sanctuary of Hermes Promakhos in Tanagra is a strawberry tree under which it was believed he had created, and in the hills Phene ran three sources that were sacred to him, because he believed that they had been bathed at birth.

Hermes's feast was the special Hermaea which was celebrated with sacrifices to the god and with athletics and gymnastics, possibly having been established in the 6th century BC, but no documentation on the festival before the 4th century BC survives. However, Plato said that Socrates attended a Hermaea. Of all the festivals involving Greek games, these were the most like initiations because participation in them was restricted to young boys and excluded adults.

In Ancient Greece, Hermes was a phallic god of boundaries. His name, in the form "herma," was applied to a wayside marker pile of stones; each traveler added a stone to the pile. In the 6th century BC, Hipparchos, the son of Pisistratus, replaced the cairns that marked the midway point between each village "deme" at the central "agora" of Athens with a square or rectangular pillar of stone or bronze topped by a bust of Hermes with a beard. An erect phallus rose from the base. In the more primitive Mount Kyllini or Cyllenian herms, the standing stone or wooden pillar was simply a carved phallus. In Athens, herms were placed outside houses for good luck. "That a monument of this kind could be transformed into an Olympian god is astounding," Walter Burkert remarked.

In 415 BC, when the Athenian fleet was about to set sail for Syracuse during the Peloponnesian War, all of the Athenian hermai were vandalized one night. The Athenians at the time believed it was the work of saboteurs, either from Syracuse or from the anti-war faction within Athens itself. Socrates' pupil Alcibiades was suspected of involvement, and Socrates indirectly paid for the impiety with his life.

The satyr-like Greek god of nature, shepherds and flocks, Pan, could possibly be the son of Hermes through the nymph Dryope. In the Homeric Hymn to Pan, Pan's mother fled in fright from her newborn son's goat-like appearance.

Depending on the sources consulted, the god Priapus could be understood as a son of Hermes.

Autolycus, the Prince of Thieves, was a son of Hermes and Chione (mortal) and grandfather of Odysseus.

The image of Hermes evolved and varied according to Greek art and culture. During Archaic Greece he was usually depicted as a mature man, bearded, dressed as a traveler, herald, or pastor. During Classical and Hellenistic Greece he is usually depicted young and nude, with athleticism, as befits the god of speech and of the gymnastics, or a robe, a formula is set predominantly through the centuries. When represented as Logios (Greek: Λόγιος, speaker), his attitude is consistent with the attribute. Phidias left a statue of a famous Hermes Logios and Praxiteles another, also well known, showing him with the baby Dionysus in his arms. At all times, however, through the Hellenistic periods, Roman, and throughout Western history into the present day, several of his characteristic objects are present as identification, but not always all together.

Among these objects is a wide-brimmed hat, the petasos, widely used by rural people of antiquity to protect themselves from the sun, and that in later times was adorned with a pair of small wings; sometimes the hat is not present, and may have been replaced with wings rising from the hair. Another object is the Porta: a stick, called a skeptron (scepter), which is referred to as a magic wand. Some early sources say that this was the bat he received from Apollo, but others question the merits of this claim. It seems that there may have been two canes, one of a shepherd's staff, as stated in the Homeric Hymn, and the other a magic wand, according to some authors. His bat also came to be called kerykeion, the caduceus, in later times. Early depictions of the staff show it as a baton stick topped by a golden way that resembled the number eight, though sometimes with its top truncated and open. Later the staff had two intertwined snakes and sometimes it was crowned with a pair of wings and a ball, but the old form remained in use even when Hermes was associated with Mercury by the Romans.

Hyginus explained the presence of snakes, saying that Hermes was traveling in Arcadia when he saw two snakes intertwined in battle. He put the caduceus between them and parted, and so said his staff would bring peace. The caduceus, historically, appeared with Hermes, and is documented among the Babylonians from about 3500 BC. The two snakes coiled around a stick was a symbol of the god Ningishzida, which served as a mediator between humans and the goddess Ishtar or the supreme Ningirsu. In Greece itself the other gods have been depicted holding a caduceus, but it was mainly associated with Hermes. It was said to have the power to make people fall asleep or wake up, and also made peace between litigants, and is a visible sign of his authority, being used as a sceptre.

He was represented in doorways, possibly as an amulet of good fortune, or as a symbol of purification. The caduceus is not to be confused with the Rod of Asclepius, the patron of medicine and son of Apollo, which bears only one snake. The rod of Asclepius was adopted by most Western doctors as a badge of their profession, but in several medical organizations of the United States, the caduceus took its place since the 18th century, although this use is declining. After the Renaissance the caduceus also appeared in the heraldic crests of several, and currently is a symbol of commerce.

His sandals, called "pédila" by the Greeks and "talaria" by the Romans, were made of palm and myrtle branches but were described as beautiful, golden and immortal, made a sublime art, able to take the roads with the speed of wind. Originally, they had no wings, but late in the artistic representations, they are depicted. In certain images, the wings spring directly from the ankles. Hermes has also been depicted with a purse or a bag in his hands, wearing a robe or cloak, which had the power to confer invisibility. His weapon was a sword of gold, which killed Argos; lent to Perseus to kill Medusa.

According to Acts 14, when Paul the Apostle visited the city of Lystra, the people there mistook him for Hermes and his companion Barnabas for Zeus.

For Carl Jung Hermes's role as messenger between realms and as guide to the underworld, made him the god of the unconscious, the mediator between the conscious and unconscious parts of the mind, and the guide for inner journeys.
Jung considered the gods Thoth and Hermes to be counterparts. In Jungian psychology especially, Hermes is seen as relevant to study of the phenomenon of synchronicity (together with Pan and Dionysus):

He is identified by some with the archetype of healer, as the ancient Greeks ascribed healing magic to him.

In the context of abnormal psychology Samuels (1986) states that Jung considers Hermes the archetype for narcissistic disorder; however, he lends the disorder a "positive" (beneficious) aspect, and represents both the good and bad of narcissism.

For López-Pedraza, Hermes is the protector of psychotherapy. For McNeely, Hermes is a god of the healing arts.

According to Christopher Booker, all the roles Hermes held in ancient Greek thought all considered reveals Hermes to be a guide or observer of transition.

For Jung, Hermes's role as trickster made him a guide through the psychotherapeutic process.

French philosopher Michel Serres wrote a set of essays called the "Hermes series".






</doc>
<doc id="14412" url="https://en.wikipedia.org/wiki?curid=14412" title="Hedge fund">
Hedge fund

A hedge fund is an investment fund that pools capital from accredited individuals or institutional investors and invests in a variety of assets, often with complex portfolio-construction and risk-management techniques. It is administered by a professional investment management firm, and often structured as a limited partnership, limited liability company, or similar vehicle. Hedge funds are generally distinct from mutual funds, as their use of leverage is not capped by regulators, and distinct from private equity funds, as the majority of hedge funds invest in relatively liquid assets.

The term "hedge fund" originated from the paired long and short positions that the first of these funds used to hedge market risk. Over time, the types and nature of the hedging concepts expanded, as did the different types of investment vehicles. Today, hedge funds engage in a diverse range of markets and strategies and employ a wide variety of financial instruments and risk management techniques.

Hedge funds are made available only to certain sophisticated or accredited investors and cannot be offered or sold to the general public. As such, they generally avoid direct regulatory oversight, bypass licensing requirements applicable to investment companies, and operate with greater flexibility than mutual funds and other investment funds. However, following the financial crisis of 2007–2008, regulations were passed in the United States and Europe with intentions to increase government oversight of hedge funds and eliminate certain regulatory gaps.

Hedge funds have existed for many decades and have become increasingly popular. They have now grown to be a substantial fraction of asset management, with assets now totaling around $3 trillion.

Hedge funds are almost always open-ended and allow additions or withdrawals by their investors (generally on a monthly or quarterly basis). The value of an investor's holding is directly related to the fund net asset value.

Many hedge fund investment strategies aim to achieve a positive return on investment regardless of whether markets are rising or falling ("absolute return"). Hedge fund managers often invest money of their own in the fund they manage. A hedge fund typically pays its investment manager an annual management fee (for example 2% of the assets of the fund), and a performance fee (for example 20% of the increase in the fund's net asset value during the year). Both co-investment and performance fees serve to align the interests of managers with those of the investors in the fund. Some hedge funds have several billion dollars of assets under management (AUM).

The word "hedge", meaning a line of bushes around the perimeter of a field, has long been used as a metaphor for placing limits on risk. Early hedge funds sought to hedge specific investments against general market fluctuations by shorting the market, hence the name. Nowadays, however, many different investment strategies are used, many of which do not "hedge risk".

During the US bull market of the 1920s, there were numerous private investment vehicles available to wealthy investors. Of that period the best known today is the Graham-Newman Partnership, founded by Benjamin Graham and his long-time business partner Jerry Newman. This was cited by Warren Buffett in a 2006 letter to the Museum of American Finance as an early hedge fund, and based on other comments from Buffett, Janet Tavakoli deems Graham's investment firm the first hedge fund.

The sociologist Alfred W. Jones is credited with coining the phrase ""hedged" fund" and is credited with creating the first hedge fund structure in 1949. Jones referred to his fund as being "hedged", a term then commonly used on Wall Street to describe the management of investment risk due to changes in the financial markets.

In the 1970s, hedge funds specialized in a single strategy with most fund managers following the long/short equity model. Many hedge funds closed during the recession of 1969–70 and the 1973–1974 stock market crash due to heavy losses. They received renewed attention in the late 1980s.

During the 1990s, the number of hedge funds increased significantly, with the 1990s stock market rise, the aligned-interest compensation structure (i.e. common financial interests) and the promise of above high returns as likely causes. Over the next decade, hedge fund strategies expanded to include: credit arbitrage, distressed debt, fixed income, quantitative, and multi-strategy. US institutional investors such as pension and endowment funds began allocating greater portions of their portfolios to hedge funds.

During the first decade of the 21st century hedge funds gained popularity worldwide, and by 2008 the worldwide hedge fund industry held US$1.93 trillion in assets under management (AUM). However, the 2008 financial crisis caused many hedge funds to restrict investor withdrawals and their popularity and AUM totals declined. AUM totals rebounded and in April 2011 were estimated at almost $2 trillion. , 61% of worldwide investment in hedge funds came from institutional sources.

In June 2011, the hedge fund management firms with the greatest AUM were Bridgewater Associates (US$58.9 billion), Man Group (US$39.2 billion), Paulson & Co. (US$35.1 billion), Brevan Howard (US$31 billion), and Och-Ziff (US$29.4 billion). Bridgewater Associates had $70 billion under management . At the end of that year, the 241 largest hedge fund firms in the United States collectively held $1.335 trillion. In April 2012, the hedge fund industry reached a record high of US$2.13 trillion total assets under management. In July 2017, hedge funds recorded their eighth consecutive monthly gain in returns with assets under management rising to a record $3.1 trillion.

In the middle of the 2010s, the hedge fund industry experienced a general decline in the "old guard" fund managers. Dan Loeb called it a "hedge fund killing field" due to the classic long/short falling out of favor because of unprecedented easing by central banks. The US equity market correlation became untenable to short sellers. By 2018, the famous Sohn conference noticeably featured more venture capitalists and tech investors than years' prior.

In June 2015, Forbes listed:

Hedge fund strategies are generally classified among four major categories: global macro, directional, event-driven, and relative value (arbitrage). Strategies within these categories each entail characteristic risk and return profiles. A fund may employ a single strategy or multiple strategies for flexibility, risk management or diversification. The hedge fund's prospectus, also known as an offering memorandum, offers potential investors information about key aspects of the fund, including the fund's investment strategy, investment type, and leverage limit.

The elements contributing to a hedge fund strategy include: the hedge fund's approach to the market; the particular instrument used; the market sector the fund specializes in (e.g. healthcare); the method used to select investments; and the amount of diversification within the fund. There are a variety of market approaches to different asset classes, including equity, fixed income, commodity, and currency. Instruments used include: equities, fixed income, futures, options and swaps. Strategies can be divided into those in which investments can be selected by managers, known as "discretionary/qualitative", or those in which investments are selected using a computerized system, known as "systematic/quantitative". The amount of diversification within the fund can vary; funds may be multi-strategy, multi-fund, multi-market, multi-manager or a combination.

Sometimes hedge fund strategies are described as "absolute return" and are classified as either "market neutral" or "directional". Market neutral funds have less correlation to overall market performance by "neutralizing" the effect of market swings, whereas directional funds utilize trends and inconsistencies in the market and have greater exposure to the market's fluctuations.

Hedge funds using a global macro investing strategy take sizable positions in share, bond or currency markets in anticipation of global macroeconomic events in order to generate a risk-adjusted return. Global macro fund managers use macroeconomic ("big picture") analysis based on global market events and trends to identify opportunities for investment that would profit from anticipated price movements. While global macro strategies have a large amount of flexibility (due to their ability to use leverage to take large positions in diverse investments in multiple markets), the timing of the implementation of the strategies is important in order to generate attractive, risk-adjusted returns. Global macro is often categorized as a directional investment strategy.

Global macro strategies can be divided into discretionary and systematic approaches. Discretionary trading is carried out by investment managers who identify and select investments whereas systematic trading is based on mathematical models and executed by software with limited human involvement beyond the programming and updating of the software. These strategies can also be divided into trend or counter-trend approaches depending on whether the fund attempts to profit from following trends (long or short-term) or attempts to anticipate and profit from reversals in trends.

Within global macro strategies, there are further sub-strategies including "systematic diversified", in which the fund trades in diversified markets, or "systematic currency", in which the fund trades in currency markets. Other sub-strategies include those employed by commodity trading advisors (CTAs), where the fund trades in futures (or options) in commodity markets or in swaps. This is also known as a "managed future fund". CTAs trade in commodities (such as gold) and financial instruments, including stock indices. They also take both long and short positions, allowing them to make profit in both market upswings and downswings.

Directional investment strategies use market movements, trends, or inconsistencies when picking stocks across a variety of markets. Computer models can be used, or fund managers will identify and select investments. These types of strategies have a greater exposure to the fluctuations of the overall market than do market neutral strategies. Directional hedge fund strategies include US and international long/short equity hedge funds, where long equity positions are hedged with short sales of equities or equity index options.

Within directional strategies, there are a number of sub-strategies. "Emerging markets" funds focus on emerging markets such as China and India, whereas "sector funds" specialize in specific areas including technology, healthcare, biotechnology, pharmaceuticals, energy and basic materials. Funds using a "fundamental growth" strategy invest in companies with more earnings growth than the overall stock market or relevant sector, while funds using a "fundamental value" strategy invest in undervalued companies. Funds that use quantitative and Financial signal processing techniques for equity trading are described as using a "quantitative directional" strategy. Funds using a "short bias" strategy take advantage of declining equity prices using short positions.

Event-driven strategies concern situations in which the underlying investment opportunity and risk are associated with an event. An event-driven investment strategy finds investment opportunities in corporate transactional events such as consolidations, acquisitions, recapitalizations, bankruptcies, and liquidations. Managers employing such a strategy capitalize on valuation inconsistencies in the market before or after such events, and take a position based on the predicted movement of the security or securities in question. Large institutional investors such as hedge funds are more likely to pursue event-driven investing strategies than traditional equity investors because they have the expertise and resources to analyze corporate transactional events for investment opportunities.

Corporate transactional events generally fit into three categories: distressed securities, risk arbitrage, and special situations. Distressed securities include such events as restructurings, recapitalizations, and bankruptcies. A distressed securities investment strategy involves investing in the bonds or loans of companies facing bankruptcy or severe financial distress, when these bonds or loans are being traded at a discount to their value. Hedge fund managers pursuing the distressed debt investment strategy aim to capitalize on depressed bond prices. Hedge funds purchasing distressed debt may prevent those companies from going bankrupt, as such an acquisition deters foreclosure by banks. While event-driven investing in general tends to thrive during a bull market, distressed investing works best during a bear market.

Risk arbitrage or merger arbitrage includes such events as mergers, acquisitions, liquidations, and hostile takeovers. Risk arbitrage typically involves buying and selling the stocks of two or more merging companies to take advantage of market discrepancies between acquisition price and stock price. The risk element arises from the possibility that the merger or acquisition will not go ahead as planned; hedge fund managers will use research and analysis to determine if the event will take place.

Special situations are events that impact the value of a company's stock, including the restructuring of a company or corporate transactions including spin-offs, share-buy-backs, security issuance/repurchase, asset sales, or other catalyst-oriented situations. To take advantage of special situations the hedge fund manager must identify an upcoming event that will increase or decrease the value of the company's equity and equity-related instruments.

Other event-driven strategies include: credit arbitrage strategies, which focus on corporate fixed income securities; an activist strategy, where the fund takes large positions in companies and uses the ownership to participate in the management; a strategy based on predicting the final approval of new pharmaceutical drugs; and legal catalyst strategy, which specializes in companies involved in major lawsuits.

Relative value arbitrage strategies take advantage of relative discrepancies in price between securities. The price discrepancy can occur due to mispricing of securities compared to related securities, the underlying security or the market overall. Hedge fund managers can use various types of analysis to identify price discrepancies in securities, including mathematical, technical or fundamental techniques. Relative value is often used as a synonym for market neutral, as strategies in this category typically have very little or no directional market exposure to the market as a whole. Other relative value sub-strategies include:


In addition to those strategies within the four main categories, there are several strategies that do not fit into these categorizations or can apply across several of them.


For an investor who already holds large quantities of equities and bonds, investment in hedge funds may provide diversification and reduce the overall portfolio risk. Managers of hedge funds use particular trading strategies and instruments with the specific aim of reducing market risks to produce risk-adjusted returns that are consistent with investors' desired level of risk. Hedge funds ideally produce returns relatively uncorrelated with market indices. While "hedging" can be a way of reducing the risk of an investment, hedge funds, like all other investment types, are not immune to risk. According to a report by the Hennessee Group, hedge funds were approximately one-third less volatile than the S&P 500 between 1993 and 2010.

Investors in hedge funds are, in most countries, required to be qualified investors who are assumed to be aware of the investment risks, and accept these risks because of the potential returns relative to those risks. Fund managers may employ extensive risk management strategies in order to protect the fund and investors. According to the "Financial Times", "big hedge funds have some of the most sophisticated and exacting risk management practices anywhere in asset management." Hedge fund managers that hold a large number of investment positions for short durations are likely to have a particularly comprehensive risk management system in place, and it has become usual for funds to have independent risk officers who assess and manage risks but are not otherwise involved in trading. A variety of different measurement techniques and models are used to estimate risk according to the fund's leverage, liquidity and investment strategy. Non-normality of returns, volatility clustering and trends are not always accounted for by conventional risk measurement methodologies and so in addition to value at risk and similar measurements, funds may use integrated measures such as drawdowns .

In addition to assessing the market-related risks that may arise from an investment, investors commonly employ operational due diligence to assess the risk that error or fraud at a hedge fund might result in loss to the investor. Considerations will include the organization and management of operations at the hedge fund manager, whether the investment strategy is likely to be sustainable, and the fund's ability to develop as a company.

Since hedge funds are private entities and have few public disclosure requirements, this is sometimes perceived as a lack of transparency. Another common perception of hedge funds is that their managers are not subject to as much regulatory oversight and/or registration requirements as other financial investment managers, and more prone to manager-specific idiosyncratic risks such as style drifts, faulty operations, or fraud. New regulations introduced in the US and the EU as of 2010 require hedge fund managers to report more information, leading to greater transparency. In addition, investors, particularly institutional investors, are encouraging further developments in hedge fund risk management, both through internal practices and external regulatory requirements. The increasing influence of institutional investors has led to greater transparency: hedge funds increasingly provide information to investors including valuation methodology, positions and leverage exposure.

Hedge funds share many of the same types of risk as other investment classes, including liquidity risk and manager risk. Liquidity refers to the degree to which an asset can be bought and sold or converted to cash; similar to private equity funds, hedge funds employ a lock-up period during which an investor cannot remove money. Manager risk refers to those risks which arise from the management of funds. As well as specific risks such as style drift, which refers to a fund manager "drifting" away from an area of specific expertise, manager risk factors include valuation risk, capacity risk, concentration risk and leverage risk. Valuation risk refers to the concern that the net asset value of investments may be inaccurate; capacity risk can arise from placing too much money into one particular strategy, which may lead to fund performance deterioration; and concentration risk may arise if a fund has too much exposure to a particular investment, sector, trading strategy, or group of correlated funds. These risks may be managed through defined controls over conflict of interest, restrictions on allocation of funds, and set exposure limits for strategies.

Many investment funds use leverage, the practice of borrowing money, trading on margin, or using derivatives to obtain market exposure in excess of that provided by investors' capital. Although leverage can increase potential returns, the opportunity for larger gains is weighed against the possibility of greater losses. Hedge funds employing leverage are likely to engage in extensive risk management practices. In comparison with investment banks, hedge fund leverage is relatively low; according to a National Bureau of Economic Research working paper, the average leverage for investment banks is 14.2, compared to between 1.5 and 2.5 for hedge funds.

Some types of funds, including hedge funds, are perceived as having a greater appetite for risk, with the intention of maximizing returns, subject to the risk tolerance of investors and the fund manager. Managers will have an additional incentive to increase risk oversight when their own capital is invested in the fund.


Hedge fund management firms typically charge their funds both a management fee and a performance fee.

Management fees are calculated as a percentage of the fund's net asset value and typically range from 1% to 4% per annum, with 2% being standard. They are usually expressed as an annual percentage, but calculated and paid monthly or quarterly. Management fees for hedge funds are designed to cover the operating costs of the manager, whereas the performance fee provides the manager's profits. However, due to economies of scale the management fee from larger funds can generate a significant part of a manager's profits, and as a result some fees have been criticized by some public pension funds, such as CalPERS, for being too high.

The performance fee is typically 20% of the fund's profits during any year, though they range between 10% and 50%. Performance fees are intended to provide an incentive for a manager to generate profits. Performance fees have been criticized by Warren Buffett, who believes that because hedge funds share only the profits and not the losses, such fees create an incentive for high-risk investment management. Performance fee rates have fallen since the start of the credit crunch.

Almost all hedge fund performance fees include a "high water mark" (or "loss carryforward provision"), which means that the performance fee only applies to net profits ("i.e.," profits after losses in previous years have been recovered). This prevents managers from receiving fees for volatile performance, though a manager will sometimes close a fund that has suffered serious losses and start a new fund, rather than attempting to recover the losses over a number of years without performance fee.

Some performance fees include a "hurdle", so that a fee is only paid on the fund's performance in excess of a benchmark rate (e.g. LIBOR) or a fixed percentage. A "soft" hurdle means the performance fee is calculated on all the fund's returns if the hurdle rate is cleared. A "hard" hurdle is calculated only on returns above the hurdle rate. A hurdle is intended to ensure that a manager is only rewarded if the fund generates returns in excess of the returns that the investor would have received if they had invested their money elsewhere.

Some hedge funds charge a redemption fee (or withdrawal fee) for early withdrawals during a specified period of time (typically a year) or when withdrawals exceed a predetermined percentage of the original investment. The purpose of the fee is to discourage short-term investing, reduce turnover and deter withdrawals after periods of poor performance. Unlike management fees and performance fees, redemption fees are usually kept by the fund.

Hedge fund management firms are usually owned by their portfolio managers, who are therefore entitled to any profits that the business makes. As management fees are intended to cover the firm's operating costs, performance fees (and any excess management fees) are generally distributed to the firm's owners as profits. Funds do not tend to report compensation and so published lists of the amounts earned by top managers tend to be estimates based on factors such as the fees charged by their funds and the capital they are thought to have invested in them. Many managers have accumulated large stakes in their own funds and so top hedge fund managers can earn extraordinary amounts of money, perhaps up to $4 billion in a good year.

Earnings at the very top are higher than in any other sector of the financial industry and collectively the top 25 hedge fund managers regularly earn more than all 500 of the chief executives in the S&P 500. Most hedge fund managers are remunerated much less, however, and if performance fees are not earned then small managers at least are unlikely to be paid significant amounts.

In 2011, the top manager earned $3,000m, the tenth earned $210m and the 30th earned $80m. In 2011, the average earnings for the 25 highest compensated hedge fund managers in the United States was $576 million. while the mean total compensation for all hedge fund investment professionals was $690,786 and the median was $312,329. The same figures for hedge fund CEOs were $1,037,151 and $600,000, and for chief investment officers were $1,039,974 and $300,000 respectively.

Of the 1,226 people on the "Forbes" World's Billionaires list for 2012, 36 of the financiers listed "derived significant chunks" of their wealth from hedge fund management. Among the richest 1,000 people in the United Kingdom, 54 were hedge fund managers, according to the "Sunday Times" Rich List for 2012.

A hedge fund is an investment vehicle that is most often structured as an offshore corporation, limited partnership or limited liability company. The fund is managed by an investment manager in the form of an organization or company that is legally and financially distinct from the hedge fund and its portfolio of assets. Many investment managers utilize service providers for operational support. Service providers include prime brokers, banks, administrators, distributors and accounting firms.

Prime brokers clear trades, and provide leverage and short-term financing. They are usually divisions of large investment banks. The prime broker acts as a counterparty to derivative contracts, and lends securities for particular investment strategies, such as long/short equities and convertible bond arbitrage. It can provide custodial services for the fund's assets, and execution and clearing services for the hedge fund manager.

Hedge fund administrators are responsible for operations, accounting, and valuation services. This back office support allows fund managers to concentrate on trades. Administrators also process subscriptions and redemptions, and perform various shareholder services. Hedge funds in the United States are not required to appoint an administrator, and all of these functions can be performed by an investment manager. A number of conflict of interest situations may arise in this arrangement, particularly in the calculation of a fund's net asset value (NAV). Some funds voluntarily employ external auditors, thereby offering a greater degree of transparency.

A distributor is an underwriter, broker, dealer, or other person who participates in the distribution of securities. The distributor is also responsible for marketing the fund to potential investors. Many hedge funds do not have distributors, and in such cases the investment manager will be responsible for distribution of securities and marketing, though many funds also use placement agents and broker-dealers for distribution.

Most funds use an independent accounting firm to audit the assets of the fund, provide tax services and perform a complete audit of the fund's financial statements. The year-end audit is often performed in accordance with the standard accounting practices enforced within the country the fund it established or the International Financial Reporting Standards (IFRS). The auditor may verify the fund's NAV and assets under management (AUM). Some auditors only provide "NAV lite" services, meaning that the valuation is based on prices received from the manager rather than independent assessment.

The legal structure of a specific hedge fund, in particular its domicile and the type of legal entity in use, is usually determined by the tax expectations of the fund's investors. Regulatory considerations will also play a role. Many hedge funds are established in offshore financial centers to avoid adverse tax consequences for its foreign and tax-exempt investors. Offshore funds that invest in the US typically pay withholding taxes on certain types of investment income but not US capital gains tax. However, the fund's investors are subject to tax in their own jurisdictions on any increase in the value of their investments. This tax treatment promotes cross-border investments by limiting the potential for multiple jurisdictions to layer taxes on investors.

US tax-exempt investors (such as pension plans and endowments) invest primarily in offshore hedge funds to preserve their tax exempt status and avoid unrelated business taxable income. The investment manager, usually based in a major financial center, pays tax on its management fees per the tax laws of the state and country where it is located. In 2011, half of the existing hedge funds were registered offshore and half onshore. The Cayman Islands was the leading location for offshore funds, accounting for 34% of the total number of global hedge funds. The US had 24%, Luxembourg 10%, Ireland 7%, the British Virgin Islands 6% and Bermuda had 3%.

The Senate Permanent Subcommittee on Investigations chaired by Carl Levin resulted in a 2014 report that found that from 1998 and 2013, hedge funds avoided billions of dollars in taxes by using basket options. The Internal Revenue Service began investigating Renaissance Technologies in 2009 and Levin criticized the IRS for taking six years to investigate the company. Using basket options Renaissance avoided "more than $6 billion in taxes over more than a decade".

A dozen other hedge funds along with Renaissance Technologies used Deutsche Bank's and Barclays' basket options. Renaissance argued that basket options were "extremely important because they gave the hedge fund the ability to increase its returns by borrowing more and to protect against model and programming failures". In July 2015 the United States Internal Revenue claimed hedge funds used basket options "to bypass taxes on short-term trades". These basket options will now be labeled as listed transactions that must be declared on tax returns and a failure to do would result in a penalty.

In contrast to the funds themselves, investment managers are primarily located onshore. The United States remains the largest center of investment, with US-based funds managing around 70% of global assets at the end of 2011. As of April 2012, there were approximately 3,990 investment advisers managing one or more private hedge funds registered with the Securities and Exchange Commission. New York City and the Gold Coast area of Connecticut are the leading locations for US hedge fund managers.

London was Europe's leading center for hedge fund managers, but since the Brexit referendum some of London-based hedge funds have relocated to other European financial centers such as Frankfurt, Luxembourg, Paris, and Dublin, while some other hedge funds have moved their European head offices back to New York City. Before Brexit, according to EuroHedge data, around 800 funds located in the UK had managed 85% of European-based hedge fund assets (in 2011). Interest in hedge funds in Asia have increased significantly since 2003, especially in Japan, Hong Kong, and Singapore. After Brexit, Europe and the US remain the leading locations for the management of Asian hedge fund assets.

Hedge fund legal structures vary depending on location and the investor(s). US hedge funds aimed at US-based, taxable investors are generally structured as limited partnerships or limited liability companies. Limited partnerships and other flow-through taxation structures assure that investors in hedge funds are not subject to both entity-level and personal-level taxation. A hedge fund structured as a limited partnership must have a general partner. The general partner may be an individual or a corporation. The general partner serves as the manager of the limited partnership, and has unlimited liability. The limited partners serve as the fund's investors, and have no responsibility for management or investment decisions. Their liability is limited to the amount of money they invest for partnership interests. As an alternative to a limited partnership arrangement, U.S. domestic hedge funds may be structured as limited liability companies, with members acting as corporate shareholders and enjoying protection from individual liability.

By contrast, offshore corporate funds are usually used for non-US investors, and when they are domiciled in an applicable offshore tax haven, no entity-level tax is imposed. Many managers of offshore funds permit the participation of tax-exempt US investors, such as pensions funds, institutional endowments and charitable trusts. As an alternative legal structure, offshore funds may be formed as an open-ended unit trust using an unincorporated mutual fund structure. Japanese investors prefer to invest in unit trusts, such as those available in the Cayman Islands.

The investment manager who organizes the hedge fund may retain an interest in the fund, either as the general partner of a limited partnership or as the holder of "founder shares" in a corporate fund. For offshore funds structured as corporate entities, the fund may appoint a board of directors. The board's primary role is to provide a layer of oversight while representing the interests of the shareholders. However, in practice board members may lack sufficient expertise to be effective in performing those duties. The board may include both affiliated directors who are employees of the fund and independent directors whose relationship to the fund is limited.


A side pocket is a mechanism whereby a fund compartmentalizes assets that are relatively illiquid or difficult to value reliably. When an investment is side-pocketed, its value is calculated separately from the value of the fund’s main portfolio. Because side pockets are used to hold illiquid investments, investors do not have the standard redemption rights with respect to the side pocket investment that they do with respect to the fund’s main portfolio. Profits or losses from the investment are allocated on a "pro rata" basis only to those who are investors at the time the investment is placed into the side pocket and are not shared with new investors. Funds typically carry side pocket assets "at cost" for purposes of calculating management fees and reporting net asset values. This allows fund managers to avoid attempting a valuation of the underlying investments, which may not always have a readily available market value.

Side pockets were widely used by hedge funds during the 2008 financial crisis amidst a flood of withdrawal requests. Side pockets allowed fund managers to lay away illiquid securities until market liquidity improved, a move that could reduce losses. However, as the practice restricts investors' ability to redeem their investments it is often unpopular and many have alleged that it has been abused or applied unfairly. The SEC also has expressed concern about aggressive use of side pockets and has sanctioned certain fund managers for inappropriate use of them.

Hedge funds must conform to the national, federal and state regulatory laws in their respective locations. The U.S. regulations and restrictions that apply to hedge funds differ from its mutual funds. Mutual funds, unlike hedge funds and other private funds, are subject to the Investment Company Act of 1940, which is a highly detailed and extensive regulatory regime. According to a report by the International Organization of Securities Commissions the most common form of regulation pertains to restrictions on financial advisers and hedge fund managers in an effort to minimize client fraud. On the other hand, U.S. hedge funds are exempt from many of the standard registration and reporting requirements because they only accept accredited investors. In 2010, regulations were enacted in the US and European Union, which introduced additional hedge fund reporting requirements. These included the U.S.'s Dodd-Frank Wall Street Reform Act and European Alternative Investment Fund Managers Directive.

In 2007 in an attempt for self-regulation, 14 leading hedge fund managers developed a voluntary set of international standards in best practice and known as the "Hedge Fund Standards" they were designed to create a "… framework of transparency, integrity and good governance" in the hedge fund industry. The Hedge Fund Standards Board was set up to prompt and maintain these standards going forward and by 2016 it had approximately 200 hedge fund managers and institutional investors with a value of US$ 3tn investment endorsing the standards.

Hedge funds within the US are subject to regulatory, reporting and record keeping requirements. Many hedge funds also fall under the jurisdiction of the Commodity Futures Trading Commission and are subject to rules and provisions of the 1922 Commodity Exchange Act which prohibits fraud and manipulation. The Securities Act of 1933 required companies to file a registration statement with the SEC to comply with its private placement rules before offering their securities to the public. The Securities Exchange Act of 1934 required a fund with more than 499 investors to register with the SEC. The Investment Advisers Act of 1940 contained anti-fraud provisions that regulated hedge fund managers and advisers, created limits for the number and types of investors, and prohibited public offerings. The Act also exempted hedge funds from mandatory registration with the U.S. Securities and Exchange Commission (SEC) when selling to accredited investors with a minimum of US$5 million in investment assets. Companies and institutional investors with at least US$25 million in investment assets also qualified.

In December 2004, the SEC began requiring hedge fund advisers, managing more than US$25 million and with more than 14 investors, to register with the SEC under the Investment Advisers Act. The SEC stated that it was adopting a "risk-based approach" to monitoring hedge funds as part of its evolving regulatory regimen for the burgeoning industry. The new rule was controversial, with two commissioners dissenting, and was later challenged in court by a hedge fund manager. In June 2006, the U.S. Court of Appeals for the District of Columbia overturned the rule and sent it back to the agency to be reviewed. In response to the court decision, in 2007 the SEC adopted Rule 206(4)-8, which unlike the earlier challenged rule, "does not impose additional filing, reporting or disclosure obligations" but does potentially increase "the risk of enforcement action" for negligent or fraudulent activity. Hedge fund managers with at least US$100 million in assets under management are required to file publicly quarterly reports disclosing ownership of registered equity securities and are subject to public disclosure if they own more than 5% of the class of any registered equity security. Registered advisers must report their business practices and disciplinary history to the SEC and to their investors. They are required to have written compliance policies, a chief compliance officer and their records and practices may be examined by the SEC.

The U.S.'s Dodd-Frank Wall Street Reform Act was passed in July 2010 and requires SEC registration of advisers who manage private funds with more than US$150 million in assets. Registered managers must file Form ADV with the SEC, as well as information regarding their assets under management and trading positions. Previously, advisers with fewer than 15 clients were exempt, although many hedge fund advisers voluntarily registered with the SEC to satisfy institutional investors. Under Dodd-Frank, investment advisers with less than US$100 million in assets under management became subject to state regulation. This increased the number of hedge funds under state supervision. Overseas advisers who managed more than US$25 million were also required to register with the SEC. The Act requires hedge funds to provide information about their trades and portfolios to regulators including the newly created Financial Stability Oversight Council. In this regard, most hedge funds and other private funds, including private equity funds, must file Form PF with the SEC, which is an extensive reporting form with substantial data on the funds' activities and positions. Under the "Volcker Rule," regulators are also required to implement regulations for banks, their affiliates, and holding companies to limit their relationships with hedge funds and to prohibit these organizations from proprietary trading, and to limit their investment in, and sponsorship of, hedge funds.

Within the European Union (EU), hedge funds are primarily regulated through their managers. In the United Kingdom, where 80% of Europe's hedge funds are based, hedge fund managers are required to be authorised and regulated by the Financial Conduct Authority (FCA). Each country has their own specific restrictions on hedge fund activities, including controls on use of derivatives in Portugal, and limits on leverage in France.

In the EU, managers are subject to the EU's Directive on Alternative Investment Fund Managers (AIFMD). According to the EU, the aim of the directive is to provide greater monitoring and control of alternative investment funds. AIFMD requires all EU hedge fund managers to register with national regulatory authorities and to disclose more information, on a more frequent basis. It also directs hedge fund managers to hold larger amounts of capital. AIFMD also introduced a "passport" for hedge funds authorised in one EU country to operate throughout the EU. The scope of AIFMD is broad and encompasses managers located within the EU as well as non-EU managers that market their funds to European investors. An aspect of AIFMD which challenges established practices in the hedge funds sector is the potential restriction of remuneration through bonus deferrals and clawback provisions.

Some hedge funds are established in Offshore centres such as the Cayman Islands, Dublin, Luxembourg, the British Virgin Islands, and Bermuda which have different regulations concerning non-accredited investors, client confidentiality and fund manager independence.

In South Africa, investment fund managers must be approved by, and register with, the Financial Services Board (FSB).

Performance statistics for individual hedge funds are difficult to obtain, as the funds have historically not been required to report their performance to a central repository and restrictions against public offerings and advertisement have led many managers to refuse to provide performance information publicly. However, summaries of individual hedge fund performance are occasionally available in industry journals and databases. and investment consultancy Hennessee Group.

One estimate is that the average hedge fund returned 11.4% per year, representing a 6.7% return above overall market performance before fees, based on performance data from 8,400 hedge funds. Another estimate is that between January 2000 and December 2009 hedge funds outperformed other investments and were substantially less volatile, with stocks falling an average of 2.62% per year over the decade and hedge funds rising an average of 6.54% per year; this was an unusually volatile period with both the 2001-2002 dot-com bubble and a recession beginning mid 2007. However, more recent data show that hedge fund performance has declined and underperformed the market from about 2009 to 2016.

Hedge funds performance is measured by comparing their returns to an estimate of their risk. Common measures are the Sharpe ratio, Treynor measure and Jensen's alpha. These measures work best when returns follow normal distributions without autocorrelation, and these assumptions are often not met in practice.

New performance measures have been introduced that attempt to address some of theoretical concerns with traditional indicators, including: modified Sharpe ratios; the Omega ratio introduced by Keating and Shadwick in 2002; Alternative Investments Risk Adjusted Performance (AIRAP) published by Sharma in 2004; and Kappa developed by Kaplan and Knowles in 2004.

There is a debate over whether alpha (the manager's skill element in performance) has been diluted by the expansion of the hedge fund industry. Two reasons are given. First, the increase in traded volume may have been reducing the market anomalies that are a source of hedge fund performance. Second, the remuneration model is attracting more managers, which may dilute the talent available in the industry.

Indices that track hedge fund returns are, in order of development, called Non-investable, Investable and Clone. They play a central and unambiguous role in traditional asset markets, where they are widely accepted as representative of their underlying portfolios. Equity and debt index fund products provide investable access to most developed markets in these asset classes. Hedge funds, however, are actively managed, so that tracking is impossible. Non-investable hedge fund indices on the other hand may be more or less representative, but returns data on many of the reference group of funds is non-public. This may result in biased estimates of their returns. In an attempt to address this problem, clone indices have been created in an attempt to replicate the statistical properties of hedge funds without being directly based on their returns data. None of these approaches achieves the accuracy of indices in other asset classes for which there is more complete published data concerning the underlying returns.

Non-investable indices are indicative in nature, and aim to represent the performance of some database of hedge funds using some measure such as mean, median or weighted mean from a hedge fund database. The databases have diverse selection criteria and methods of construction, and no single database captures all funds. This leads to significant differences in reported performance between different indices.

Although they aim to be representative, non-investable indices suffer from a lengthy and largely unavoidable list of biases.

Funds' participation in a database is voluntary, leading to self-selection bias because those funds that choose to report may not be typical of funds as a whole. For example, some do not report because of poor results or because they have already reached their target size and do not wish to raise further money..

The short lifetimes of many hedge funds means that there are many new entrants and many departures each year, which raises the problem of survivorship bias. If we examine only funds that have survived to the present, we will overestimate past returns because many of the worst-performing funds have not survived, and the observed association between fund youth and fund performance suggests that this bias may be substantial.

When a fund is added to a database for the first time, all or part of its historical data is recorded ex-post in the database. It is likely that funds only publish their results when they are favorable, so that the average performances displayed by the funds during their incubation period are inflated. This is known as "instant history bias" or "backfill bias".

Investable indices are an attempt to reduce these problems by ensuring that the return of the index is available to shareholders. To create an investable index, the index provider selects funds and develops structured products or derivative instruments that deliver the performance of the index. When investors buy these products the index provider makes the investments in the underlying funds, making an investable index similar in some ways to a fund of hedge funds portfolio.

To make the index investable, hedge funds must agree to accept investments on the terms given by the constructor. To make the index liquid, these terms must include provisions for redemptions that some managers may consider too onerous to be acceptable. This means that investable indices do not represent the total universe of hedge funds. Most seriously, they under-represent more successful managers, who typically refuse to accept such investment protocols.

The most recent addition to the field approach the problem in a different manner. Instead of reflecting the performance of actual hedge funds they take a statistical approach to the analysis of historic hedge fund returns, and use this to construct a model of how hedge fund returns respond to the movements of various investable financial assets. This model is then used to construct an investable portfolio of those assets. This makes the index investable, and in principle they can be as representative as the hedge fund database from which they were constructed.

However, these clone indices rely on a statistical modelling process. Such indices have too short a history to state whether this approach will be considered successful.

In March 2017, HFR – a hedge fund research data and service provider – reported that there were more hedge-fund closures in 2016 than during the 2009 recession. According to the report, several large public pension funds pulled their investments in hedge funds, because the funds’ subpar performance as a group did not merit the high fees they charged.

Despite the hedge fund industry topping $3 trillion for the first time ever in 2016, the number of new hedge funds launched fell short of crisis-era figures. There were 729 hedge fund launches in 2016, fewer than the 784 opened in 2009 and dramatically less than the 968 launches in 2015.

Systemic risk refers to the risk of instability across the entire financial system, as opposed to within a single company. Such risk may arise following a destabilizing event or events affecting a group of financial institutions linked through investment activity. Organizations such as the European Central Bank have charged that hedge funds pose systemic risks to the financial sector, and following the failure of hedge fund Long-Term Capital Management (LTCM) in 1998 there was widespread concern about the potential for systemic risk if a hedge fund failure led to the failure of its counterparties. (As it happens, no financial assistance was provided to LTCM by the US Federal Reserve, so there was no direct cost to US taxpayers, but a large bailout had to be mounted by a number of financial institutions.)

However, these claims are widely disputed by the financial industry, who typically regard hedge funds as "small enough to fail", since most are relatively small in terms of the assets they manage and operate with low leverage, thereby limiting the potential harm to the economic system should one of them fail. Formal analysis of hedge fund leverage before and during the 2008 financial crisis suggests that hedge fund leverage is both fairly modest and counter-cyclical to the market leverage of investment banks and the larger financial sector. Hedge fund leverage decreased prior to the financial crisis, even while the leverage of other financial intermediaries continued to increase. Hedge funds fail regularly, and numerous hedge funds failed during the financial crisis. In testimony to the House Financial Services Committee in 2009, Ben Bernanke, the Federal Reserve Board Chairman said he "would not think that any hedge fund or private equity fund would become a systemically critical firm individually".

Nevertheless, although hedge funds go to great lengths to reduce the ratio of risk to reward, inevitably a number of risks remain. Systemic risk is increased in a crisis if there is "herd" behaviour, which causes a number of similar hedge funds to make losses in similar trades. In addition, while most hedge funds make only modest use of leverage, hedge funds differ from many other market participants, such as banks and mutual funds, in that there are no regulatory constraints on their use of leverage, and some hedge funds seek large amounts of leverage as part of their market strategy. The extensive use of leverage can lead to forced liquidations in a crisis, particularly for hedge funds that invest at least in part in illiquid investments. The close interconnectedness of the hedge funds with their prime brokers, typically investment banks, can lead to domino effects in a crisis, and indeed failing counterparty banks can freeze hedge funds. These systemic risk concerns are exacerbated by the prominent role of hedge funds in the financial markets. The global hedge fund industry has over $2 trillion in assets, and this does not take into account the full effect of leverage, which by definition is market exposure in excess of the amount invested.

An August 2012 survey by the Financial Services Authority concluded that risks were limited and had reduced as a result, "inter alia", of larger margins being required by counterparty banks, but might change rapidly according to market conditions. In stressed market conditions, investors might suddenly withdraw large sums, resulting in forced asset sales. This might cause liquidity and pricing problems if it occurred across a number of funds or in one large highly leveraged fund.

Hedge funds are structured to avoid most direct regulation (although their managers may be regulated) and are not required to publicly disclose their investment activities, except to the extent that investors generally are subject to disclosure requirements. This is in contrast to a regulated mutual fund or exchange-traded fund, which will typically have to meet regulatory requirements for disclosure. An investor in a hedge fund usually has direct access to the investment adviser of the fund, and may enjoy more personalized reporting than investors in retail investment funds. This may include detailed discussions of risks assumed and significant positions. However, this high level of disclosure is not available to non-investors, contributing to hedge funds' reputation for secrecy, while some hedge funds have very limited transparency even to investors.

Funds may choose to report some information in the interest of recruiting additional investors. Much of the data available in consolidated databases is self-reported and unverified. A study was done on two major databases containing hedge fund data. The study noted that 465 common funds had significant differences in reported information (e.g. returns, inception date, net assets value, incentive fee, management fee, investment styles, etc.) and that 5% of return numbers and 5% of NAV numbers were dramatically different. With these limitations, investors have to do their own research, which may cost on the scale of US$50,000 for a fund that is not well-established.

A lack of verification of financial documents by investors or by independent auditors has, in some cases, assisted in fraud. In the mid-2000s, Kirk Wright of International Management Associates was accused of mail fraud and other securities violations which allegedly defrauded clients of close to US$180 million. In December 2008, Bernard Madoff was arrested for running a US$50 billion Ponzi scheme that closely resembled a hedge fund and was incorrectly described as one. Several feeder hedge funds, of which the largest was Fairfield Sentry, channeled money to it. Following the Madoff case, the SEC adopted reforms in December 2009 that required hedge funds managed by registered investment advisers to have their assets in the custody of a qualified custodian and subjected them to an audit requirement.

The process of matching hedge funds to investors has traditionally been fairly opaque, with investments often driven by personal connections or recommendations of portfolio managers. Many funds disclose their holdings, strategy, and historic performance relative to market indices, giving investors some idea of how their money is being allocated, although individual holdings are often not disclosed. Investors are often drawn to hedge funds by the possibility of realizing significant returns, or hedging against volatility in the market. The complexity and fees associated with hedge funds are causing some to exit the market – Calpers, the largest pension fund in the US, announced plans to completely divest from hedge funds in 2014. Some services are attempting to improve matching between hedge funds and investors: HedgeZ is designed to allow investors to easily search and sort through funds; iMatchative aims to match investors to funds through algorithms that factor in an investor's goals and behavioral profile, in hopes of helping funds and investors understand the how their perceptions and motivations drive investment decisions.

In June 2006, prompted by a letter from Gary J. Aguirre, the Senate Judiciary Committee began an investigation into the links between hedge funds and independent analysts. Aguirre was fired from his job with the SEC when, as lead investigator of insider trading allegations against Pequot Capital Management, he tried to interview John Mack, then being considered for chief executive officer at Morgan Stanley. The Judiciary Committee and the US Senate Finance Committee issued a scathing report in 2007, which found that Aguirre had been illegally fired in reprisal for his pursuit of Mack and in 2009, the SEC was forced to re-open its case against Pequot. Pequot settled with the SEC for US$28 million and Arthur J. Samberg, chief investment officer of Pequot, was barred from working as an investment advisor. Pequot closed its doors under the pressure of investigations.

The systemic practice of hedge funds submitting periodic electronic questionnaires to stock analysts as a part of market research was reported in by "The New York Times" in July 2012. According to the report, one motivation for the questionnaires was to obtain subjective information not available to the public and possible early notice of trading recommendations that could produce short term market movements.

According to modern portfolio theory, rational investors will seek to hold portfolios that are mean/variance efficient (that is, portfolios that offer the highest level of return per unit of risk). One of the attractive features of hedge funds (in particular market neutral and similar funds) is that they sometimes have a modest correlation with traditional assets such as equities. This means that hedge funds have a potentially quite valuable role in investment portfolios as diversifiers, reducing overall portfolio risk.

However, there are three reasons why one might not wish to allocate a high proportion of assets into hedge funds. These reasons are:

Several studies have suggested that hedge funds are sufficiently diversifying to merit inclusion in investor portfolios, but this is disputed for example by Mark Kritzman who performed a mean-variance optimization calculation on an opportunity set that consisted of a stock index fund, a bond index fund, and ten hypothetical hedge funds. The optimizer found that a mean-variance efficient portfolio did not contain any allocation to hedge funds, largely because of the impact of performance fees. To demonstrate this, Kritzman repeated the optimization using an assumption that the hedge funds incurred no performance fees. The result from this second optimization was an allocation of 74% to hedge funds.

The other factor reducing the attractiveness of hedge funds in a diversified portfolio is that they tend to perform poorly during equity bear markets, just when an investor needs part of their portfolio to add value. For example, in January–September 2008, the Credit Suisse/Tremont Hedge Fund Index was down 9.87%. According to the same index series, even "dedicated short bias" funds had a return of −6.08% during September 2008. In other words, even though low average correlations may appear to make hedge funds attractive this may not work in turbulent period, for example around the collapse of Lehman Brothers in September 2008.





</doc>
<doc id="14413" url="https://en.wikipedia.org/wiki?curid=14413" title="Hydrocodone">
Hydrocodone

Hydrocodone, sold under brand names such as Vicodin and Norco among many others, is a semisynthetic opioid derived from codeine, one of the opioid alkaloids found in the opium poppy. It is a narcotic analgesic used orally for relief of moderate to severe pain, but also commonly taken in liquid form as an antitussive/cough suppressant.

Hydrocodone is an opioid, and acts as a selective agonist of the μ-opioid receptor, the main biological target of the endogenous neuropeptide β-endorphin.

Hydrocodone is prescribed predominantly within the United States, with the International Narcotics Control Board reporting that 99% of the worldwide supply in 2007 was consumed in the United States. Several common imprints for hydrocodone are M365, M366, M367.

Hydrocodone is used to treat moderate to severe pain and as an antitussive to treat cough. In one study comparing the potency of hydrocodone to that of oxycodone, it was found that it took 50% more hydrocodone to achieve the same degree of miosis (pupillary contraction). The investigators interpreted this to mean that oxycodone is about 50% more potent than hydrocodone.

However, in a study of emergency department patients with fractures, it was found that an equal amount of either drug provided about the same degree of pain relief, indicating that there is little practical difference between them when used for that purpose. Some references state that the analgesic action of hydrocodone begins in 20–30 minutes and lasts about 4–8 hours. The manufacturer's information says onset of action is about 10–30 minutes and duration is about 4–6 hours. Recommended dosing interval is 4–6 hours.

Hydrocodone is available in a variety of formulations for oral administration:


Hydrocodone is not available in parenteral or any other non-oral forms.

Common side effects of hydrocodone are nausea, vomiting, constipation, drowsiness, dizziness, lightheadedness, anxiety, abnormally happy or sad mood, dry throat, difficulty urinating, rash, itching, and narrowing of the pupils. Serious side effects include slowed or irregular breathing and chest tightness.

Several cases of progressive bilateral hearing loss unresponsive to steroid therapy have been described as an infrequent adverse reaction to hydrocodone/paracetamol misuse. This adverse effect has been considered by some to be due to the ototoxicity of hydrocodone. Other researchers have suggested that paracetamol is the primary agent responsible for the ototoxicity.

Hydrocodone is in U.S. Food and Drug Administration (FDA) pregnancy category C. No adequate and well-controlled studies in humans have been conducted. A newborn of a mother taking opioid medications regularly prior to the birth will be physically dependent. The baby may also exhibit respiratory depression if the opioid dose was high. An epidemiological study indicated that opioid treatment during early pregnancy results in increased risk of various birth defects.

Symptoms of hydrocodone overdose include narrowed or widened pupils; slow, shallow, or stopped breathing; slowed or stopped heartbeat; cold, clammy, or blue skin; excessive sleepiness; loss of consciousness; seizures; or death.

Hydrocodone can be habit forming, causing physical and psychological dependence. Its abuse liability is similar to morphine and less than oxycodone.

Patients consuming alcohol, other opioids, anticholinergic antihistamines, anti-psychotics, anti-anxiety agents, or other central nervous system (CNS) depressants together with hydrocodone may exhibit an additive CNS depression. Hydrocodone may interact with serotonergic medications.

Hydrocodone is a highly selective full agonist of the μ-opioid receptor (MOR). This is the main biological target of the endogenous opioid neuropeptide β-endorphin. Hydrocodone has low affinity for the δ-opioid receptor (DOR) and the κ-opioid receptor (KOR), where it is an agonist similarly.

Studies have shown hydrocodone is stronger than codeine but only one-tenth as potent as morphine at binding to receptors and reported to be only 59% as potent as morphine in analgesic properties. However, in tests conducted on rhesus monkeys, the analgesic potency of hydrocodone was actually higher than morphine. Oral hydrocodone has a mean equivalent daily dosage (MEDD) factor of 0.4, meaning that 1 mg of hydrocodone is equivalent to 0.4 mg of intravenous morphine. However, because of morphine's low oral bioavailability, there is a 1:1 correspondence between orally administered morphine and orally administered hydrocodone. The relative milligram strength of hydrocodone to codeine is given as 6 fold, that is 5 mg has the effect of 30 mg of codeine; by way of the Roman numeral VI this is said to have given rise to the trade name Vicodin.

Hydrocodone is only pharmaceutically available as an oral medication. It is well-absorbed, but its oral bioavailability of hydrocodone is only approximately 25%. The onset of action of hydrocodone via this route is 10 to 20 minutes, with a peak effect (T) occurring at 30 to 60 minutes, and it has a duration of 4 to 8 hours.

The volume of distribution of hydrocodone is 3.3 to 4.7 L/kg. The plasma protein binding of hydrocodone is 20 to 50%.

In the liver, hydrocodone is transformed into several metabolites, including norhydrocodone, hydromorphone, 6α-hydrocodol (dihydrocodeine), and 6β-hydrocodol. 6α- and 6β-hydromorphol are also formed, and the metabolites of hydrocodone are conjugated (via glucuronidation). Hydrocodone has a terminal half-life that averages 3.8 hours (range 3.3–4.4 hours). The hepatic cytochrome P450 enzyme CYP2D6 converts hydrocodone into hydromorphone, a more potent opioid (5-fold higher binding affinity to the MOR). However, extensive and poor cytochrome 450 CYP2D6 metabolizers had similar physiological and subjective responses to hydrocodone, and CYP2D6 inhibitor quinidine did not change the responses of extensive metabolizers, suggesting that inhibition of CYP2D6 metabolism of hydrocodone has no practical importance. Ultra-rapid CYP2D6 metabolizers (1–2% of the population) may have an increased response to hydrocodone; however, hydrocodone metabolism in this population has not been studied.

Norhydrocodone, the major metabolite of hydrocodone, is predominantly formed by CYP3A4-catalyzed oxidation. In contrast to hydromorphone, it is described as inactive. However, norhydrocodone is actually a MOR agonist with similar potency to hydrocodone, but has been found to produce only minimal analgesia when administered peripherally to animals (likely due to poor blood–brain barrier and thus central nervous system penetration). Inhibition of CYP3A4 in a child who was, in addition, a poor CYP2D6 metabolizer, resulted in a fatal overdose of hydrocodone. Approximately 40% of hydrocodone metabolism is attributed to non-cytochrome P450-catalyzed reactions.

Hydrocodone is excreted in urine, mainly in the form of conjugates.

Hydrocodone concentrations are measured in blood, plasma, and urine to seek evidence of misuse, to confirm diagnoses of poisoning, and to assist in investigations into deaths. Many commercial opiate screening tests react indiscriminately with hydrocodone, other opiates, and their metabolites, but chromatographic techniques can easily distinguish hydrocodone uniquely. Blood and plasma hydrocodone concentrations typically fall into the 5–30 µg/L range among people taking the drug therapeutically, 100–200 µg/L among recreational users, and 100–1,600 µg/L in cases of acute, fatal overdosage. Co-administration of the drug with food or alcohol can very significantly increase the resulting plasma hydrocodone concentrations that are subsequently achieved.

Hydrocodone was first synthesized in Germany in 1920 by Carl Mannich and Helene Löwenheim. It was approved by the Food and Drug Administration on 23 March 1943 for sale in the United States and approved by Health Canada for sale in Canada under the brand name Hycodan.

Hydrocodone was first marketed by Knoll as Dicodid, starting in February 1924 in Germany. This name is analogous to other products the company introduced or otherwise marketed: Dilaudid (hydromorphone, 1926), Dinarkon (oxycodone, 1917), Dihydrin (dihydrocodeine, 1911), and Dimorphan (dihydromorphine). Paramorfan is the trade name of dihydromorphine from another manufacturer, as is Paracodin, for dihydrocodeine.

The name Dicodid was registered in the United States and appears without a monograph as late as 1978 in the Physicians' Desk Reference; Dicodid may have been marketed to one extent or another in North America in the 1920s and early 1930s. The drug was pure hydrocodone in small 5 and 10 mg tablets, physically similar to the Dilaudid tablets. It is no longer manufactured by Knoll in Germany, nor is a generic available. Hydrocodone was never as common in Europe as it is in North America—dihydrocodeine is used for its spectrum of indications. Germany was the number two consumer of hydrocodone until the manufacture of the drug was discontinued there. Now, the world outside the United States accounts for less than 1% of annual consumption. It was listed as a "Suchtgift" under the German Betäubungsmittelgesetz and regulated like morphine. It became available in the Schengen Area of the European Union as of 1 January 2002 under Title 76 of the Schengen Treaty.

Most hydrocodone is formulated in combination with a second analgesic, such as paracetamol (acetaminophen) or ibuprofen. Examples of hydrocodone combinations include Norco, Vicodin, Lortab, Vicoprofen and Riboxen.

In 2014, the FDA approved a formulation of hydrocodone called Zohydro ER made by Zogenix Pharmaceuticals. The approval of Zohydro ER was controversial, due to concerns over its potential for substance abuse. The FDA approved Zohydro ER over the objections of its own review panel, which voted 12 to 2 against approval. The panel stated that if approved, Zohydro ER would likely "be abused, possibly at a rate greater than that of currently available hydrocodone combination products". Thirty U.S. states asked the FDA not to approve Zohydro ER in capsule form due to its potency and the ease with which it could be abused, by being crushed and then snorted or injected. Zohydro ER was briefly prohibited in Massachusetts before a federal judge ruled that the state's ban was preempted by the earlier federal approval.

The US government imposed tougher prescribing rules for hydrocodone in 2014, changing the drug from Schedule III to Schedule II. In 2011, hydrocodone products were involved in around 100,000 abuse-related emergency department visits in the United States, more than double the number in 2004.




</doc>
<doc id="14415" url="https://en.wikipedia.org/wiki?curid=14415" title="Hashish">
Hashish

Hashish, or hash, is a drug made from cannabis. Hashish is cannabis resin. It is consumed by smoking a small piece, typically in a pipe, bong, vaporizer or joint, or via oral ingestion (after decarboxylation). As pure hashish will not burn if rolled alone in a joint, it is typically mixed with herbal cannabis, tobacco or another type of herb for this method of consumption.
Depending on region or country, multiple synonyms and alternative names exist.

Hash is an extracted cannabis product composed of compressed or purified preparations of stalked resin glands, called trichomes, from the plant. It is defined by the 1961 UN Single Convention on Narcotic Drugs (Schedule I and IV) as "the separated resin, whether crude or purified, obtained from the cannabis plant". The resin contains ingredients such as tetrahydrocannabinol (THC) and other cannabinoids—but often in higher concentrations than the unsifted or unprocessed cannabis flower. Purities of confiscated Hashish in Europe (2011) range between 4-15%. Between 2000 and 2005 the percentage of hashish in cannabis end product seizures was at 18%.

Hashish may be solid or resinous depending on both preparation and room temperature; pressed hashish is usually solid, whereas water-purified hashish—often called "bubble melt hash", or simply "bubble hash"—is often a paste-like substance with varying hardness and pliability; its color, most commonly light to dark brown, can vary from transparent to yellow, tan, black, or red. This all depends on the process and amount of solvent left over.

Hashish was the primary form of cannabis used in Europe in 2008. Herbal cannabis is more widely used in Northern America.

Besides its recreational use, the active ingredient of hashish, THC, has been of interest for research and medical purposes since its arrival in the 18th century. While it was widely used as a medicine for multiple diseases, the emergence of specific treatments led to a sharp decline in prescriptions, eventually becoming illegal to use via the 1971 UN Convention on Psychotropic Substances.

The street price for hashish in Europe in 2011 varied from €3 (Portugal) per gram to €18 in Malta, or even as high as 200NOK (€20/$25) in Norway.

Hashish has been consumed for many centuries, though there is no clear evidence as to its first appearance. North India has a long social tradition in the production of hashish, known locally as "charas", which is believed to be the same plant resin as was burned in the ceremonial "booz rooz" of Ancient Persia.

The first attestation of the term "hashish" is in a pamphlet published in Cairo in 1123 CE, accusing Nizari Muslims of being "hashish-eaters". The 13th century Ibn Taymiyyah prohibited the use of hashish; he mentioned that it was introduced to Levant with the Mongol invasion (throughout the 13th century). Smoking did not become common in the Old World until after the introduction of tobacco, so up until the 1500s hashish in the Muslim world was consumed as an edible.

In 1596, Dutchman Jan Huyghen van Linschoten spent three pages on "Bangue" ("bhang") in his historic work documenting his journeys in the East. He particularly mentioned the Egyptian hashish. He said, "Bangue is likewise much used in Turkie and Egypt, and is made in three sorts, having also three names. The first by the Egyptians is called Assis (Hashish (Arab.)), which is the poulder of Hemp, or of Hemp leaves, which is water made in paste or dough, they would eat five peeces, (each) as big as a Chestnut (or larger); This is used by the common people, because it is of a small price, and it is no wonder, that such vertue proceedeth from the Hempe, for that according to Galens opinion, Hempe excessively filleth the head."

Hashish arrived in Europe from the East during the 18th century, and is first mentioned scientifically by Gmelin in 1777. The Napoleonic campaigns introduced French troops to hashish in Egypt and the first description of usefulness stems from 1830 by pharmacist and botanist Theodor Friedrich Ludwig Nees von Esenbeck. In 1811, the founder of homoeopathy, Samuel Hahnemann, published a "proving" of the effects of Cannabis Sativa in his work "Reine Arzneimittellehre" (Materia Medica Pura).

In 1839, O’Shaughnessy wrote a comprehensive study of Indian hemp, which was recognised by the European school of medicine and describes hashish as relief for cramps and causing the disappearance of certain symptoms from afflictions such as rabies, cholera, and tetanus. This led to high hopes in the medical community. In 1840 Louis Aubert-Roche reported his successful use of hashish against pestilence. Also psychiatric experiments with hashish were done at the same time with Jacques-Joseph Moreau being convinced that it is the supreme medicament for use in psychiatry.

In the 1800s, hashish was embraced in some European literary circles. Most famously, the Club des Hashischins was a Parisian club dedicated to the consumption of hashish and other drugs; its members included literary luminaries such as Théophile Gautier, Dr. Moreau de Tours, Victor Hugo, Alexandre Dumas, Charles Baudelaire and Honoré de Balzac. Baudelaire later wrote the 1860 book "Les paradis artificiels", about the state of being under the influence of opium and hashish. At around the same time, American author Fitz Hugh Ludlow wrote the 1857 book "The Hasheesh Eater" about his youthful experiences, both positive and negative, with the drug.

Hashish was also mentioned and used as an anesthetic in Germany in 1869. At these times, hashish was imported in great quantities especially from India and called charas. However, there were also people who did not deem cannabis as harmless. Between 1880 and 1900 was the peak of the medicinal use, where hashish compounds were most commonplace in almost all European countries and the USA. Evidence of misuse at that time was practically non-existent (as opposed to widespread reports in Asia and Africa). Hashish played a significant role in the treatment of pain, migraine, dysmenorrhea, pertussis asthma and insomnia in Europe and USA towards the end of the 19th century. Rare applications included stomach ache, depression, diarrhea, diminished appetite, pruritus, hemorrhage, basedown syndrome and malaria. The usage of hashish decreased as even supporters agreed on the unreliability of its compounds, with critics calling it worthless and dangerous. Eventually, hashish as a medicine disappeared completely in the 20th century with the introduction of specific medicines for all of its main applications. The use was later prohibited worldwide as the use as a medicine was made impossible by the 1961 UN Single Convention on Narcotic Drugs.

At the beginning of the 20th century, the majority of hashish in Europe came from Kashmir, Afghanistan, and parts of India, as well as Greece, Syria, Nepal, Lebanon, and Turkey. Larger markets developed in the late 1960s and early 1970s when most of the hashish was imported from Pakistan and Afghanistan. Due to disruptive conflicts in the regions, Morocco took over and was the sufficient exporter until lately. It is believed that massive hashish production for international trade originated in Morocco during the 1960s, where the cannabis plant was widely available. Before the coming of the first hippies from the "Hippie Hashish Trail", only small pieces of Lebanese hashish were found in Morocco.

However, since the 2000s there has been a dramatic shift in the market due to an increase of homegrown cannabis production. While Morocco held a quasi-monopoly in the 1990s with the so-called 250g "soap bar" blocks, which were of low quality, Afghanistan has now been announced the biggest producer of higher quality hashish. Since then, the quality in Europe has increased while the prices have remained stable.

According to the European Monitoring Centre for Drugs and Drug Addiction (EMCDDA), Western Europe is the biggest market for cannabis resin with 70% of global seizures. The European hashish market is changing though: Cannabis cultivation increased throughout the 1990s until 2004, with a noticeable decrease reported in 2005 according to the European Monitoring Centre for Drugs and Drug Addiction.
Morocco has been the major source, however lately there has been a shift in the market and Afghanistan has been named the major producer of Hashish. Even though a drop in usage and production has been reported, Morocco produced around 6600 tonnes of resin in 2005.

As 641 tonnes of hashish were consumed in the EU in 2013, the European market is currently the world’s largest and most profitable. Therefore, many actors are involved in the business, including organised crime groups. The largest cannabis resin seizures in Europe happen in Spain, due to its proximity to Northern Africa.

The 1990s "soap bars" disappeared and the physical shapes of hashish changed to melon shaped, tablets or olive shaped pellets. Overall the general trend of domestically grown cannabis displacing the imported resin leads to a market reaction of potency changes while the prices remain stable while soap-bar potency increased from 8% to up to 20.7% in 2014.

Generally, more resin than herb is consumed in Europe.

As hashish is a derivative of cannabis, it has the same substance properties. When smoked, THC can be detected in plasma within seconds, with a half-life of 2 hours. Due to its lipophilic nature, it is widely distributed through the body, and some metabolites can be detected in urine for up to two weeks following consumption.

Hashish is made from cannabinoid-rich glandular hairs known as trichomes, as well as varying amounts of cannabis flower and leaf fragments. The flowers of a mature female plant contain the most trichomes, though trichomes are also found on other parts of the plant. Certain strains of cannabis are cultivated specifically for their ability to produce large amounts of trichomes. The resin reservoirs of the trichomes, sometimes erroneously called pollen (vendors often use the euphemism "pollen catchers" to describe screened kief-grinders in order to skirt paraphernalia-selling laws), are separated from the plant through various methods.

Hashish is often consumed in a social setting, being smoked by multiple people who share a pipe, bong, joint or vaporizer.

The pharmacology of hashish is complicated because of the wide range of cannabinoids. There is little evidence for damage to the organ system, only due to the consumption in combination with tobacco. There has also been an association with schizophrenia, however it is unclear if there is a causative relationship.

Generally the after effects are the same as for cannabis use in general, including its long term effects.

Hashish can be consumed by oral ingestion or smoking; typically in a pipe, bong, vaporizer or joints, where it is normally mixed with cannabis or tobacco, as pure hashish will burn poorly if burned alone.In some parts of Canada, individuals do what is known as "bottle tokes", in which they take a lit cigarette,stick a "bot"(small hashish ball) then let the smoke fill the bottle before inhalation. THC has a low water solubility therefore ingestion leads to poor absorption. Generally the methods are similar to overall cannabis consumption.

As hashish’ active ingredient is THC it has the same effects as cannabis. Most well known effect of hashish is a euphoric, drowsy, sedated effect. A certain relief of anxiety is often reported. During a high, the user experiences a distortion of time and space.

It has been claimed that the user’s psychological and physiological needs will influence the response and that the user must cooperate with and facilitate the effects. Therefore, the effect of the physical and interpersonal setting is strong and usually controls the underlying tone of the experience. Generally the intensification of sensation and increased clarity of perception have been reported. Short lived adverse effects have also been reported, including psychotic states following heavy consumption. Regular users are at risk of dependence. Especially people with major mental illnesses e.g. schizophrenia are vulnerable as hashish provokes relapse and aggravates existing symptoms.

As perceptual changes are very hard to measure, most studies on the altered state of consciousness concentrate on subjective descriptions only.
The general awareness of proprioceptive responses seem to enhance, as emotional involvement is reported to enhance perception in general. Taste and smell seem intensified and visual scenes seem to have more depth while sounds are heard with more dimension. Perception of time is also reported to change: there is a general experience of time distortion where events take longer to occur and the subject is involved in internal fantasies with the impression that external time has slowed down. However, there seems to be no impression of speed or rapidity for internal processes. Similar effects are common in normal experience, for example when time slows down in boredom. It is proposed that this distortion is caused as the experience itself is the focus of attention rather than what is happening around the individual.

Functional associations seem to decrease in strength and there are fewer mental impositions on the sensory perception of the object. Aspects which are normally filtered out are given equal attention. Therefore, objects are not necessarily conceptualized via their use but rather experienced as a whole. Detailed attention is paid, focussing on certain aspects of an object, a sentence or any other perceptual input in a magnifying way. Clearly the attention process is affected. Only a narrow amount of diverse contents the focus of attention and fewer objects are perceived. A person may become absorbed by one object, event or process up to the exclusion of everything else, which has been called a train of fantasy and has been described as a form of tunnel vision where the individual is more aware of an individual element of meaning, emotion etc. There seems to be a certain unity of attention while normally attention relies on multiple channels. Flights of fantasy and dreaming, including perceiving connections and associations of ideas that do not seem accessible in a normal state are often reported.

There seems to be a reduction of the automatic availability of memory images, however an increased strength of memories when relevant to central needs. Experiences seem new and are experienced without a feeling of familiarity and is more intense if emotionally salient. This emotional force may activate internal imagery, which is used to search for identity or to interpret incoming stimuli. Short term memory becomes shorter and in a very high state the sequence of thoughts is not remembered past one or two transitions.

Expectancies and anticipation which are important to keep behaviour consistent in normal states seem to be decreased in strength which might lead to surprising or out-of-character behaviour. Normally these expectancies let the person behave in a goal directed and reasonable manner, with the decrease the person might act out in illogical and unforeseeable ways. Similarly inhibitions, especially social inhibition seems to be reduced, resulting in playful behaviour and acting on impulses.

The sticky resins of the fresh flowering female cannabis plant are collected by pressing or rubbing the flowering plant between two hands and then forming the sticky resins into a small ball of hashish called charas.

Mechanical separation methods use physical action to remove the trichomes from the dried plant material, such as sieving through a screen by hand or in motorized tumblers. This technique is known as "drysifting". The resulting powder, referred to as "kief" or "drysift", is compressed with the aid of heat into blocks of hashish; if pure, the kief will become gooey and pliable. When a high level of pure THC is present, the end product will be almost transparent and will start to melt at the point of human contact.

Ice-water separation is another mechanical method of isolating trichomes. Newer techniques have been developed such as heat and pressure separations, static-electricity sieving or acoustical dry sieving.

Trichomes may break away from supporting stalks and leaves when plant material becomes brittle at low temperatures. After plant material has been agitated in an icy slush, separated trichomes are often dense enough to sink to the bottom of the ice-water mixture following agitation, while lighter pieces of leaves and stems tend to float.

The ice-water method requires ice, water, agitation, filtration bags with various-sized screens and plant material. With the ice-water extraction method the resin becomes hard and brittle and can easily be separated. This allows large quantities of pure resins to be extracted in a very clean process without the use of solvents, making for a more purified hashish.

Chemical separation methods generally use a solvent such as ethanol, butane or hexane to dissolve the lipophilic desirable resin. Remaining plant materials are filtered out of the solution and sent to the compost. The solvent is then evaporated, or boiled off (purged) leaving behind the desirable resins, called honey oil, "hash oil", or just "oil". Honey oil still contains waxes and essential oils and can be further purified by vacuum distillation to yield "red oil". The product of chemical separations is more commonly referred to as "honey oil." This oil is not really hashish, as the latter name covers trichomes that are extracted by sieving. This leaves most of the glands intact.

In a study conducted in 2014 by Jean-Jaques Filippi, Marie Marchini, Céline Charvoz, Laurence Dujourdy and Nicolas Baldovini ("Multidimensional analysis of cannabis volatile constituents: Identification of 5,5-dimethyl-1-vinylbicyclo[2.1.1]hexane as a volatile marker of hashish, the resin of Cannabis sativa L.") the researchers linked the characteristic flavour of hashish with a rearrangement of myrcene caused during the process of manufacture.

Depending on the production process, the product can be contaminated with different amount of dirt and plant fragments, vary greatly in terms of appearance, texture, odour and potency. Also, adulterants may be added in order to increase weight or modify appearance.

Morocco has been the major hashish producer globally with €10.8 billion earned with Moroccan resin in 2004. However, Chouvy (2016) suggests that some of the so- called "Moroccan" actually stems from local European production. The income for the farmers lay around €325 million in 2005. While the overall amount of plants and areas shrank in size, the introduction of more potent hybrid plant produced a high resin rate.The range or resin produced is estimated between 3800 and 9500 tonnes in 2005.

The largest producer today is Afghanistan, however studies suggest there is a "hashish revival" in Morocco.

Tiny pieces of leaf matter may be accidentally or even purposely added; adulterants introduced when the hashish is being produced will reduce the purity of the material and often resulting in green finished product. The tetrahydrocannabinol (THC) content of hashish comes in wide ranges from almost none to 65% and that of hash oil from 30% to 90%.

As mentioned above, there has been a general increase in potency as the competition has grown bigger and new hybrid plants have been developed.

Nup, charas, shish, kif and others.
Street names often refer to the shape in which the hash is formed, such as a candy bar, soap bar, nine bar, finger, patties, or surfboard. The country of origin is also used as a description, for example black Afghan, blonde Lebanese, or Moroccan.<ref name="Hash / Hashish Information"></ref>





</doc>
<doc id="14417" url="https://en.wikipedia.org/wiki?curid=14417" title="Hypnosis">
Hypnosis

Hypnosis is a state of human consciousness involving focused attention and reduced peripheral awareness and an enhanced capacity to respond to suggestion. The term may also refer to an art, skill, or act of inducing hypnosis.

Theories explaining what occurs during hypnosis fall into two groups. "Altered state" theories see hypnosis as an altered state of mind or trance, marked by a level of awareness different from the ordinary conscious state. In contrast, "nonstate" theories see hypnosis as a form of imaginative role enactment.

During hypnosis, a person is said to have heightened focus and concentration. The person can concentrate intensely on a specific thought or memory, while blocking out sources of distraction. Hypnotised subjects are said to show an increased response to suggestions.
Hypnosis is usually induced by a procedure known as a hypnotic induction involving a series of preliminary instructions and suggestion. The use of hypnotism for therapeutic purposes is referred to as "hypnotherapy", while its use as a form of entertainment for an audience is known as "stage hypnosis". Stage hypnosis is often performed by mentalists practicing the art form of mentalism.

The term "hypnosis" comes from the ancient Greek word ὕπνος "hypnos", "sleep", and the suffix -ωσις -"osis", or from ὑπνόω "hypnoō", "put to sleep" (stem of aorist "hypnōs"-) and the suffix -"is". The words "hypnosis" and "hypnotism" both derive from the term "neuro-hypnotism" (nervous sleep), all of which were coined by Étienne Félix d'Henin de Cuvillers in 1820. These words were popularized in English by the Scottish surgeon James Braid (to whom they are sometimes wrongly attributed) around 1841. Braid based his practice on that developed by Franz Mesmer and his followers (which was called "Mesmerism" or "animal magnetism"), but differed in his theory as to how the procedure worked.

A person in a state of hypnosis has focused attention, and has increased suggestibility.
The hypnotized individual appears to heed only the communications of the hypnotist and typically responds in an uncritical, automatic fashion while ignoring all aspects of the environment other than those pointed out by the hypnotist. In a hypnotic state an individual tends to see, feel, smell, and otherwise perceive in accordance with the hypnotist's suggestions, even though these suggestions may be in apparent contradiction to the actual stimuli present in the environment. The effects of hypnosis are not limited to sensory change; even the subject's memory and awareness of self may be altered by suggestion, and the effects of the suggestions may be extended (posthypnotically) into the subject's subsequent waking activity.
It could be said that hypnotic suggestion is explicitly intended to make use of the placebo effect. For example, in 1994, Irving Kirsch characterised hypnosis as a "nondeceptive placebo", i.e., a method that openly makes use of suggestion and employs methods to amplify its effects.
In "Trance on Trial", a 1989 text directed at the legal profession, legal scholar Alan W. Scheflin and psychologist Jerrold Lee Shapiro observed that the "deeper" the hypnotism, the more likely a particular characteristic is to appear, and the greater extent to which it is manifested. Scheflin and Shapiro identified 20 separate characteristics that hypnotized subjects might display: "dissociation"; "detachment"; "suggestibility", "ideosensory activity"; "catalepsy"; "ideomotor responsiveness"; "age regression"; "revivification"; "hypermnesia"; "[automatic or suggested] amnesia"; "posthypnotic responses"; "hypnotic analgesia and anesthesia"; "glove anesthesia"; "somnambulism"; "automatic writing"; "time distortion"; "release of inhibitions"; "change in capacity for volitional activity"; "trance logic"; and "effortless imagination".

The earliest definition of hypnosis was given by Braid, who coined the term "hypnotism" as an abbreviation for "neuro-hypnotism", or nervous sleep, which he contrasted with "normal" sleep, and defined as: "a peculiar condition of the nervous system, induced by a fixed and abstracted attention of the mental and visual eye, on one object, not of an exciting nature."

Braid elaborated upon this brief definition in a later work, "Hypnotic Therapeutics":

Therefore, Braid defined hypnotism as a state of mental concentration that often leads to a form of progressive relaxation, termed "nervous sleep". Later, in his "The Physiology of Fascination" (1855), Braid conceded that his original terminology was misleading, and argued that the term "hypnotism" or "nervous sleep" should be reserved for the minority (10%) of subjects who exhibit amnesia, substituting the term "monoideism", meaning concentration upon a single idea, as a description for the more alert state experienced by the others.

A new definition of hypnosis, derived from academic psychology, was provided in 2005, when the Society for Psychological Hypnosis, Division 30 of the American Psychological Association (APA), published the following formal definition:

Michael Nash provides a list of eight definitions of hypnosis by different authors, in addition to his own view that hypnosis is "a special case of psychological regression":

Joe Griffin and Ivan Tyrrell (the originators of the human givens approach) define hypnosis as "any artificial way of accessing the REM state, the same brain state in which dreaming occurs" and suggest that this definition, when properly understood, resolves "many of the mysteries and controversies surrounding hypnosis". They see the REM state as being vitally important for life itself, for programming in our instinctive knowledge initially (after Dement and Jouvet) and then for adding to this throughout life. They explain this by pointing out that, in a sense, all learning is post-hypnotic, which explains why the number of ways people can be put into a hypnotic state are so varied: anything that focuses a person's attention, inward or outward, puts them into a trance.

Hypnosis is normally preceded by a "hypnotic induction" technique. Traditionally, this was interpreted as a method of putting the subject into a "hypnotic trance"; however, subsequent "nonstate" theorists have viewed it differently, seeing it as a means of heightening client expectation, defining their role, focusing attention, etc. There are several different induction techniques. One of the most influential methods was Braid's "eye-fixation" technique, also known as "Braidism". Many variations of the eye-fixation approach exist, including the induction used in the Stanford Hypnotic Susceptibility Scale (SHSS), the most widely used research tool in the field of hypnotism. Braid's original description of his induction is as follows:
Braid later acknowledged that the hypnotic induction technique was not necessary in every case, and subsequent researchers have generally found that on average it contributes less than previously expected to the effect of hypnotic suggestions. Variations and alternatives to the original hypnotic induction techniques were subsequently developed. However, this method is still considered authoritative. In 1941, Robert White wrote: "It can be safely stated that nine out of ten hypnotic techniques call for reclining posture, muscular relaxation, and optical fixation followed by eye closure."

When James Braid first described hypnotism, he did not use the term "suggestion" but referred instead to the act of focusing the conscious mind of the subject upon a single dominant idea. Braid's main therapeutic strategy involved stimulating or reducing physiological functioning in different regions of the body. In his later works, however, Braid placed increasing emphasis upon the use of a variety of different verbal and non-verbal forms of suggestion, including the use of "waking suggestion" and self-hypnosis. Subsequently, Hippolyte Bernheim shifted the emphasis from the physical state of hypnosis on to the psychological process of verbal suggestion:
I define hypnotism as the induction of a peculiar psychical [i.e., mental] condition which increases the susceptibility to suggestion. Often, it is true, the [hypnotic] sleep that may be induced facilitates suggestion, but it is not the necessary preliminary. It is suggestion that rules hypnotism.
Bernheim's conception of the primacy of verbal suggestion in hypnotism dominated the subject throughout the 20th century, leading some authorities to declare him the father of modern hypnotism.

Contemporary hypnotism uses a variety of suggestion forms including direct verbal suggestions, "indirect" verbal suggestions such as requests or insinuations, metaphors and other rhetorical figures of speech, and non-verbal suggestion in the form of mental imagery, voice tonality, and physical manipulation. A distinction is commonly made between suggestions delivered "permissively" and those delivered in a more "authoritarian" manner. Harvard hypnotherapist Deirdre Barrett writes that most modern research suggestions are designed to bring about immediate responses, whereas hypnotherapeutic suggestions are usually post-hypnotic ones that are intended to trigger responses affecting behaviour for periods ranging from days to a lifetime in duration. The hypnotherapeutic ones are often repeated in multiple sessions before they achieve peak effectiveness.

Some hypnotists view suggestion as a form of communication that is directed primarily to the subject's conscious mind, whereas others view it as a means of communicating with the "unconscious" or "subconscious" mind. These concepts were introduced into hypnotism at the end of the 19th century by Sigmund Freud and Pierre Janet. Sigmund Freud's psychoanalytic theory describes conscious thoughts as being at the surface of the mind and unconscious processes as being deeper in the mind. Braid, Bernheim, and other Victorian pioneers of hypnotism did not refer to the unconscious mind but saw hypnotic suggestions as being addressed to the subject's "conscious" mind. Indeed, Braid actually defines hypnotism as focused (conscious) attention upon a dominant idea (or suggestion). Different views regarding the nature of the mind have led to different conceptions of suggestion. Hypnotists who believe that responses are mediated primarily by an "unconscious mind", like Milton Erickson, make use of indirect suggestions such as metaphors or stories whose intended meaning may be concealed from the subject's conscious mind. The concept of subliminal suggestion depends upon this view of the mind. By contrast, hypnotists who believe that responses to suggestion are primarily mediated by the conscious mind, such as Theodore Barber and Nicholas Spanos, have tended to make more use of direct verbal suggestions and instructions.

The first neuropsychological theory of hypnotic suggestion was introduced early by James Braid who adopted his friend and colleague William Carpenter's theory of the ideo-motor reflex response to account for the phenomenon of hypnotism. Carpenter had observed from close examination of everyday experience that, under certain circumstances, the mere idea of a muscular movement could be sufficient to produce a reflexive, or automatic, contraction or movement of the muscles involved, albeit in a very small degree. Braid extended Carpenter's theory to encompass the observation that a wide variety of bodily responses besides muscular movement can be thus affected, for example, the idea of sucking a lemon can automatically stimulate salivation, a secretory response. Braid, therefore, adopted the term "ideo-dynamic", meaning "by the power of an idea", to explain a broad range of "psycho-physiological" (mind–body) phenomena. Braid coined the term "mono-ideodynamic" to refer to the theory that hypnotism operates by concentrating attention on a single idea in order to amplify the ideo-dynamic reflex response. Variations of the basic ideo-motor, or ideo-dynamic, theory of suggestion have continued to exercise considerable influence over subsequent theories of hypnosis, including those of Clark L. Hull, Hans Eysenck, and Ernest Rossi. It should be noted that in Victorian psychology the word "idea" encompasses any mental representation, including mental imagery, memories, etc.

Braid made a rough distinction between different stages of hypnosis, which he termed the first and second conscious stage of hypnotism; he later replaced this with a distinction between "sub-hypnotic", "full hypnotic", and "hypnotic coma" stages. Jean-Martin Charcot made a similar distinction between stages which he named somnambulism, lethargy, and catalepsy. However, Ambroise-Auguste Liébeault and Hippolyte Bernheim introduced more complex hypnotic "depth" scales based on a combination of behavioural, physiological, and subjective responses, some of which were due to direct suggestion and some of which were not. In the first few decades of the 20th century, these early clinical "depth" scales were superseded by more sophisticated "hypnotic susceptibility" scales based on experimental research. The most influential were the Davis–Husband and Friedlander–Sarbin scales developed in the 1930s. André Weitzenhoffer and Ernest R. Hilgard developed the Stanford Scale of Hypnotic Susceptibility in 1959, consisting of 12 suggestion test items following a standardised hypnotic eye-fixation induction script, and this has become one of the most widely referenced research tools in the field of hypnosis. Soon after, in 1962, Ronald Shor and Emily Carota Orne developed a similar group scale called the Harvard Group Scale of Hypnotic Susceptibility (HGSHS).

Whereas the older "depth scales" tried to infer the level of "hypnotic trance" from supposed observable signs such as spontaneous amnesia, most subsequent scales have measured the degree of observed or self-evaluated "responsiveness" to specific suggestion tests such as direct suggestions of arm rigidity (catalepsy). The Stanford, Harvard, HIP, and most other susceptibility scales convert numbers into an assessment of a person's susceptibility as "high", "medium", or "low". Approximately 80% of the population are medium, 10% are high, and 10% are low. There is some controversy as to whether this is distributed on a "normal" bell-shaped curve or whether it is bi-modal with a small "blip" of people at the high end. Hypnotizability Scores are highly stable over a person's lifetime. Research by Deirdre Barrett has found that there are two distinct types of highly susceptible subjects, which she terms fantasizers and dissociaters. Fantasizers score high on absorption scales, find it easy to block out real-world stimuli without hypnosis, spend much time daydreaming, report imaginary companions as a child, and grew up with parents who encouraged imaginary play. Dissociaters often have a history of childhood abuse or other trauma, learned to escape into numbness, and to forget unpleasant events. Their association to "daydreaming" was often going blank rather than creating vividly recalled fantasies. Both score equally high on formal scales of hypnotic susceptibility.

Individuals with dissociative identity disorder have the highest hypnotisability of any clinical group, followed by those with posttraumatic stress disorder.

People have been entering into hypnotic-type trances for thousands of years. In many cultures and religions, it was regarded as a form of meditation. Modern day hypnosis, however, started in the late 18th century and was made popular by Franz Mesmer, a German physician who became known as the father of ‘modern hypnotism’. In fact, hypnosis used to be known as ‘Mesmerism’ as it was named after Mesmer.

Mesmer held the opinion that hypnosis was a sort of mystical force that flows from the hypnotist to the person being hypnotized, but his theory was dismissed by critics who asserted that there is no magical element to hypnotism.

Before long, hypnotism started finding its way into the world of modern medicine. The use of hypnotism in the medical field was made popular by surgeons and physicians like Elliotson and James Esdaille and researchers like James Braid who helped to reveal the biological and physical benefits of hypnotism. According to his writings, Braid began to hear reports concerning various Oriental meditative practices soon after the release of his first publication on hypnotism, "Neurypnology" (1843). He first discussed some of these oriental practices in a series of articles entitled "Magic, Mesmerism, Hypnotism, etc., Historically & Physiologically Considered". He drew analogies between his own practice of hypnotism and various forms of Hindu yoga meditation and other ancient spiritual practices, especially those involving voluntary burial and apparent human hibernation. Braid's interest in these practices stems from his studies of the "Dabistān-i Mazāhib", the "School of Religions", an ancient Persian text describing a wide variety of Oriental religious rituals, beliefs, and practices.
Last May [1843], a gentleman residing in Edinburgh, personally unknown to me, who had long resided in India, favored me with a letter expressing his approbation of the views which I had published on the nature and causes of hypnotic and mesmeric phenomena. In corroboration of my views, he referred to what he had previously witnessed in oriental regions, and recommended me to look into the "Dabistan", a book lately published, for additional proof to the same effect. On much recommendation I immediately sent for a copy of the "Dabistan", in which I found many statements corroborative of the fact, that the eastern saints are all self-hypnotisers, adopting means essentially the same as those which I had recommended for similar purposes.

Although he rejected the transcendental/metaphysical interpretation given to these phenomena outright, Braid accepted that these accounts of Oriental practices supported his view that the effects of hypnotism could be produced in solitude, without the presence of any other person (as he had already proved to his own satisfaction with the experiments he had conducted in November 1841); and he saw correlations between many of the "metaphysical" Oriental practices and his own "rational" neuro-hypnotism, and totally rejected all of the fluid theories and magnetic practices of the mesmerists. As he later wrote:
In as much as patients can throw themselves into the nervous sleep, and manifest all the usual phenomena of Mesmerism, through their own unaided efforts, as I have so repeatedly proved by causing them to maintain a steady fixed gaze at any point, concentrating their whole mental energies on the idea of the object looked at; or that the same may arise by the patient looking at the point of his own finger, or as the Magi of Persia and Yogi of India have practised for the last 2,400 years, for religious purposes, throwing themselves into their ecstatic trances by each maintaining a steady fixed gaze at the tip of his own nose; it is obvious that there is no need for an exoteric influence to produce the phenomena of Mesmerism. […] The great object in all these processes is to induce a habit of abstraction or concentration of attention, in which the subject is entirely absorbed with one idea, or train of ideas, whilst he is unconscious of, or indifferently conscious to, every other object, purpose, or action.

Avicenna (980–1037), a Persian physician, documented the characteristics of the "trance" (Hypnotic Trance) state in 1027. At that time, hypnosis as a medical treatment was seldom used until the German doctor Franz Mesmer, reintroduced it in the 18th century.

Franz Mesmer (1734–1815) believed that there is a magnetic force or "fluid" called "animal magnetism" within the universe that influences the health of the human body. He experimented with magnets to impact this field in order to produce healing. By around 1774, he had concluded that the same effect could be created by passing the hands in front of the subject's body, later referred to as making "Mesmeric passes". The word "mesmerize", formed from the last name of Franz Mesmer, was intentionally used to separate practitioners of mesmerism from the various "fluid" and "magnetic" theories included within the label "magnetism".

In 1784, at the request of King Louis XVI, a Board of Inquiry started to investigate whether animal magnetism existed. Among the board members were founding father of modern chemistry Antoine Lavoisier, Benjamin Franklin, and an expert in pain control, Joseph-Ignace Guillotin. They investigated the practices of a disaffected student of Mesmer, one Charles d'Eslon (1750–1786), and though they concluded that Mesmer's results were valid, their placebo-controlled experiments using d'Eslon's methods convinced them that mesmerism was most likely due to belief and imagination rather than to an invisible energy ("animal magnetism") transmitted from the body of the mesmerist.

In writing the majority opinion, Franklin said: "This fellow Mesmer is not flowing anything from his hands that I can see. Therefore, this mesmerism must be a fraud." Mesmer left Paris and went back to Vienna to practise mesmerism.

Following the French committee's findings, Dugald Stewart, an influential academic philosopher of the "Scottish School of Common Sense", encouraged physicians in his "Elements of the Philosophy of the Human Mind" (1818) to salvage elements of Mesmerism by replacing the supernatural theory of "animal magnetism" with a new interpretation based upon "common sense" laws of physiology and psychology. Braid quotes the following passage from Stewart:
It appears to me, that the general conclusions established by Mesmer's practice, with respect to the physical effects of the principle of imagination (more particularly in cases where they co-operated together), are incomparably more curious than if he had actually demonstrated the existence of his boasted science [of "animal magnetism"]: nor can I see any good reason why a physician, who admits the efficacy of the moral [i.e., psychological] agents employed by Mesmer, should, in the exercise of his profession, scruple to copy whatever processes are necessary for subjecting them to his command, any more than that he should hesitate about employing a new physical agent, such as electricity or galvanism.
In Braid's day, the Scottish School of Common Sense provided the dominant theories of academic psychology, and Braid refers to other philosophers within this tradition throughout his writings. Braid therefore revised the theory and practice of Mesmerism and developed his own method of hypnotism as a more rational and common sense alternative.
It may here be requisite for me to explain, that by the term Hypnotism, or Nervous Sleep, which frequently occurs in the following pages, I mean a peculiar condition of the nervous system, into which it may be thrown by artificial contrivance, and which differs, in several respects, from common sleep or the waking condition. I do not allege that this condition is induced through the transmission of a magnetic or occult influence from my body into that of my patients; nor do I profess, by my processes, to produce the higher [i.e., supernatural] phenomena of the Mesmerists. My pretensions are of a much more humble character, and are all consistent with generally admitted principles in physiological and psychological science. Hypnotism might therefore not inaptly be designated, Rational Mesmerism, in contra-distinction to the Transcendental Mesmerism of the Mesmerists.
Despite briefly toying with the name "rational Mesmerism", Braid ultimately chose to emphasise the unique aspects of his approach, carrying out informal experiments throughout his career in order to refute practices that invoked supernatural forces and demonstrating instead the role of ordinary physiological and psychological processes such as suggestion and focused attention in producing the observed effects.

Braid worked very closely with his friend and ally the eminent physiologist Professor William Benjamin Carpenter, an early neuro-psychologist who introduced the "ideo-motor reflex" theory of suggestion. Carpenter had observed instances of expectation and imagination apparently influencing involuntary muscle movement. A classic example of the ideo-motor principle in action is the so-called "Chevreul pendulum" (named after Michel Eugène Chevreul). Chevreul claimed that divinatory pendulae were made to swing by unconscious muscle movements brought about by focused concentration alone.

Braid soon assimilated Carpenter's observations into his own theory, realising that the effect of focusing attention was to enhance the ideo-motor reflex response. Braid extended Carpenter's theory to encompass the influence of the mind upon the body more generally, beyond the muscular system, and therefore referred to the "ideo-dynamic" response and coined the term "psycho-physiology" to refer to the study of general mind/body interaction.

In his later works, Braid reserved the term "hypnotism" for cases in which subjects entered a state of amnesia resembling sleep. For other cases, he spoke of a "mono-ideodynamic" principle to emphasise that the eye-fixation induction technique worked by narrowing the subject's attention to a single idea or train of thought ("monoideism"), which amplified the effect of the consequent "dominant idea" upon the subject's body by means of the ideo-dynamic principle.

For several decades Braid's work became more influential abroad than in his own country, except for a handful of followers, most notably Dr. John Milne Bramwell. The eminent neurologist Dr. George Miller Beard took Braid's theories to America. Meanwhile, his works were translated into German by William Thierry Preyer, Professor of Physiology at Jena University. The psychiatrist Albert Moll subsequently continued German research, publishing "Hypnotism" in 1889. France became the focal point for the study of Braid's ideas after the eminent neurologist Dr. Étienne Eugène Azam translated Braid's last manuscript ("On Hypnotism", 1860) into French and presented Braid's research to the French Academy of Sciences. At the request of Azam, Paul Broca, and others, the French Academy of Science, which had investigated Mesmerism in 1784, examined Braid's writings shortly after his death.

Azam's enthusiasm for hypnotism influenced Ambroise-Auguste Liébeault, a country doctor. Hippolyte Bernheim discovered Liébeault's enormously popular group hypnotherapy clinic and subsequently became an influential hypnotist. The study of hypnotism subsequently revolved around the fierce debate between Bernheim and Jean-Martin Charcot, the two most influential figures in late 19th-century hypnotism.

Charcot operated a clinic at the Pitié-Salpêtrière Hospital (thus, known as the "Paris School" or the "Salpêtrière School"), while Bernheim had a clinic in Nancy (known as the "Nancy School"). Charcot, who was influenced more by the Mesmerists, argued that hypnotism was an abnormal state of nervous functioning found only in certain hysterical women. He claimed that it manifested in a series of physical reactions that could be divided into distinct stages. Bernheim argued that anyone could be hypnotised, that it was an extension of normal psychological functioning, and that its effects were due to suggestion. After decades of debate, Bernheim's view dominated. Charcot's theory is now just a historical curiosity.

Pierre Janet (1859–1947) reported studies on a hypnotic subject in 1882. Charcot subsequently appointed him director of the psychological laboratory at the Salpêtrière in 1889, after Janet had completed his PhD, which dealt with psychological automatism. In 1898, Janet was appointed psychology lecturer at the Sorbonne, and in 1902 he became chair of experimental and comparative psychology at the Collège de France. Janet reconciled elements of his views with those of Bernheim and his followers, developing his own sophisticated hypnotic psychotherapy based upon the concept of psychological dissociation, which, at the turn of the century, rivalled Freud's attempt to provide a more comprehensive theory of psychotherapy.

Sigmund Freud (1856–1939), the founder of psychoanalysis, studied hypnotism at the Paris School and briefly visited the Nancy School.

At first, Freud was an enthusiastic proponent of hypnotherapy. He "initially hypnotised patients and pressed on their foreheads to help them concentrate while attempting to recover (supposedly) repressed memories", and he soon began to emphasise hypnotic regression and ab reaction (catharsis) as therapeutic methods. He wrote a favorable encyclopedia article on hypnotism, translated one of Bernheim's works into German, and published an influential series of case studies with his colleague Joseph Breuer entitled "Studies on Hysteria" (1895). This became the founding text of the subsequent tradition known as "hypno-analysis" or "regression hypnotherapy".

However, Freud gradually abandoned hypnotism in favour of psychoanalysis, emphasizing free association and interpretation of the unconscious. Struggling with the great expense of time that psychoanalysis required, Freud later suggested that it might be combined with hypnotic suggestion to hasten the outcome of treatment, but that this would probably weaken the outcome: "It is very probable, too, that the application of our therapy to numbers will compel us to alloy the pure gold of analysis plentifully with the copper of direct [hypnotic] suggestion."

Only a handful of Freud's followers, however, were sufficiently qualified in hypnosis to attempt the synthesis. Their work had a limited influence on the hypno-therapeutic approaches now known variously as "hypnotic regression", "hypnotic progression", and "hypnoanalysis".

Émile Coué (1857–1926) assisted Ambroise-Auguste Liébeault for around two years at Nancy. After practising for several months employing the "hypnosis" of Liébeault and Bernheim's Nancy School, he abandoned their approach altogether. Later, Coué developed a new approach (c.1901) based on Braid-style "hypnotism", direct hypnotic suggestion, and ego-strengthening which eventually became known as "La méthode Coué". According to Charles Baudouin, Coué founded what became known as the New Nancy School, a loose collaboration of practitioners who taught and promoted his views. Coué's method did not emphasise "sleep" or deep relaxation, but instead focused upon autosuggestion involving a specific series of suggestion tests. Although Coué argued that he was no longer using hypnosis, followers such as Charles Baudouin viewed his approach as a form of light self-hypnosis. Coué's method became a renowned self-help and psychotherapy technique, which contrasted with psychoanalysis and prefigured self-hypnosis and cognitive therapy.

The next major development came from behavioural psychology in American university research. Clark L. Hull (1884–1952), an eminent American psychologist, published the first major compilation of laboratory studies on hypnosis, "Hypnosis & Suggestibility" (1933), in which he proved that hypnosis and sleep had nothing in common. Hull published many quantitative findings from hypnosis and suggestion experiments and encouraged research by mainstream psychologists. Hull's behavioural psychology interpretation of hypnosis, emphasising conditioned reflexes, rivalled the Freudian psycho-dynamic interpretation which emphasised unconscious transference.

Although Dave Elman (1900–1967) was a noted radio host, comedian, and songwriter, he also made a name as a hypnotist. He led many courses for physicians, and in 1964 wrote the book "Findings in Hypnosis", later to be retitled "Hypnotherapy" (published by Westwood Publishing). Perhaps the most well-known aspect of Elman's legacy is his method of induction, which was originally fashioned for speed work and later adapted for the use of medical professionals.

Milton Erickson (1901–1980) was one of the most influential post-war hypnotherapists. He wrote several books and journal articles on the subject. During the 1960s, Erickson popularized a new branch of hypnotherapy, known as Ericksonian therapy, characterised primarily by indirect suggestion, "metaphor" (actually analogies), confusion techniques, and double binds in place of formal hypnotic inductions. However, the difference between Erickson's methods and traditional hypnotism led contemporaries such as André Weitzenhoffer to question whether he was practising "hypnosis" at all, and his approach remains in question.
Erickson had no hesitation in presenting any suggested effect as being "hypnosis", whether or not the subject was in a hypnotic state. In fact, he was not hesitant in passing off behaviour that was dubiously hypnotic as being hypnotic.
In the latter half of the 20th century, two factors contributed to the development of the cognitive-behavioural approach to hypnosis:

Although cognitive-behavioural theories of hypnosis must be distinguished from cognitive-behavioural approaches to hypnotherapy, they share similar concepts, terminology, and assumptions and have been integrated by influential researchers and clinicians such as Irving Kirsch, Steven Jay Lynn, and others.

At the outset of cognitive behavioural therapy during the 1950s, hypnosis was used by early behaviour therapists such as Joseph Wolpe and also by early cognitive therapists such as Albert Ellis. Barber, Spanos, and Chaves introduced the term "cognitive-behavioural" to describe their "nonstate" theory of hypnosis in "Hypnosis, imagination, and human potentialities". However, Clark L. Hull had introduced a behavioural psychology as far back as 1933, which in turn was preceded by Ivan Pavlov. Indeed, the earliest theories and practices of hypnotism, even those of Braid, resemble the cognitive-behavioural orientation in some respects.

There are numerous applications for hypnosis across multiple fields of interest, including medical/psychotherapeutic uses, military uses, self-improvement, and entertainment. The American Medical Association currently has no official stance on the medical use of hypnosis. However, a study published in 1958 by the Council on Mental Health of the American Medical Association documented the efficacy of hypnosis in clinical settings.

Hypnosis has been used as a supplemental approach to cognitive behavioral therapy since as early as 1949. Hypnosis was defined in relation to classical conditioning; where the words of the therapist were the stimuli and the hypnosis would be the conditioned response. Some traditional cognitive behavioral therapy methods were based in classical conditioning. It would include inducing a relaxed state and introducing a feared stimuli. One way of inducing the relaxed state was through hypnosis.

Hypnotism has also been used in forensics, sports, education, physical therapy, and rehabilitation. Hypnotism has also been employed by artists for creative purposes, most notably the surrealist circle of André Breton who employed hypnosis, automatic writing, and sketches for creative purposes. Hypnotic methods have been used to re-experience drug states and mystical experiences. Self-hypnosis is popularly used to quit smoking, alleviate stress and anxiety, promote weight loss, and induce sleep hypnosis. Stage hypnosis can persuade people to perform unusual public feats.

Some people have drawn analogies between certain aspects of hypnotism and areas such as crowd psychology, religious hysteria, and ritual trances in preliterate tribal cultures.

Hypnotherapy is a use of hypnosis in psychotherapy. It is used by licensed physicians, psychologists, and others. Physicians and psychologists may use hypnosis to treat depression, anxiety, eating disorders, sleep disorders, compulsive gambling, and posttraumatic stress, while certified hypnotherapists who are not physicians or psychologists often treat smoking and weight management.

Hypnotherapy is a helpful adjunct having additive effects when treating psychological disorders, such as these, along with scientifically proven cognitive therapies. Hypnotherapy should not be used for repairing or refreshing memory because hypnosis results in memory hardening, which increases the confidence in false memories.

Preliminary research has expressed brief hypnosis interventions as possibly being a useful tool for managing painful HIV-DSP because of its history of usefulness in pain management, its long-term effectiveness of brief interventions, the ability to teach self-hypnosis to patients, the cost-effectiveness of the intervention, and the advantage of using such an intervention as opposed to the use of pharmaceutical drugs.

Modern hypnotherapy has been used, with varying success, in a variety of forms, such as:


In a January 2001 article in "Psychology Today", Harvard psychologist Deirdre Barrett wrote:
A hypnotic trance is not therapeutic in and of itself, but specific suggestions and images fed to clients in a trance can profoundly alter their behavior. As they rehearse the new ways they want to think and feel, they lay the groundwork for changes in their future actions... Barrett described specific ways this is operationalized for habit change and amelioration of phobias. In her 1998 book of hypnotherapy case studies, she reviews the clinical research on hypnosis with dissociative disorders, smoking cessation, and insomnia, and describes successful treatments of these complaints.

In a July 2001 article for "Scientific American" titled "The Truth and the Hype of Hypnosis", Michael Nash wrote that, "using hypnosis, scientists have temporarily created hallucinations, compulsions, certain types of memory loss, false memories, and delusions in the laboratory so that these phenomena can be studied in a controlled environment."

Hypnotherapy has been studied for the treatment of irritable bowel syndrome. Hypnosis for IBS has received moderate support in the National Institute for Health and Clinical Excellence guidance published for UK health services. It has been used as an aid or alternative to chemical anesthesia, and it has been studied as a way to soothe skin ailments.

A number of studies show that hypnosis can reduce the pain experienced during burn-wound debridement, bone marrow aspirations, and childbirth. The "International Journal of Clinical and Experimental Hypnosis" found that hypnosis relieved the pain of 75% of 933 subjects participating in 27 different experiments.

Hypnosis is effective in decreasing the fear of cancer treatment reducing pain from and coping with cancer and other chronic conditions. Nausea and other symptoms related to incurable diseases may also be managed with hypnosis. Some practitioners have claimed hypnosis might help boost the immune system of people with cancer. However, according to the American Cancer Society, "available scientific evidence does not support the idea that hypnosis can influence the development or progression of cancer."

Hypnosis has been used as a pain relieving technique during dental surgery and related pain management regimens as well. Researchers like Jerjes and his team have reported that hypnosis can help even those patients who have acute to severe orodental pain. Additionally, Meyerson and Uziel have suggested that hypnotic methods have been found to be highly fruitful for alleviating anxiety in patients suffering from severe dental phobia.

For some psychologists who uphold the altered state theory of hypnosis, pain relief in response to hypnosis is said to be the result of the brain's dual-processing functionality. This effect is obtained either through the process of selective attention or dissociation, in which both theories involve the presence of activity in pain receptive regions of the brain, and a difference in the processing of the stimuli by the hypnotised subject.

The American Psychological Association published a study comparing the effects of hypnosis, ordinary suggestion, and placebo in reducing pain. The study found that highly suggestible individuals experienced a greater reduction in pain from hypnosis compared with placebo, whereas less suggestible subjects experienced no pain reduction from hypnosis when compared with placebo. Ordinary non-hypnotic suggestion also caused reduction in pain compared to placebo, but was able to reduce pain in a wider range of subjects (both high and low suggestible) than hypnosis. The results showed that it is primarily the subject's responsiveness to suggestion, whether within the context of hypnosis or not, that is the main determinant of causing reduction in pain.

Treating skin diseases with hypnosis (hypnodermatology) has performed well in treating warts, psoriasis, and atopic dermatitis.

The success rate for habit control is varied. A meta-study researching hypnosis as a quit-smoking tool found it had a 20 to 30 percent success rate, while a 2007 study of patients hospitalised for cardiac and pulmonary ailments found that smokers who used hypnosis to quit smoking doubled their chances of success.

Hypnosis may be useful as an adjunct therapy for weight loss. A 1996 meta-analysis studying hypnosis combined with cognitive behavioural therapy found that people using both treatments lost more weight than people using cognitive behavioural therapy alone. The virtual gastric band procedure mixes hypnosis with hypnopedia. The hypnosis instructs the stomach that it is smaller than it really is, and hypnopedia reinforces alimentary habits. A 2016 pilot study found that there was no significant difference in effectiveness between VGB hypnotherapy and relaxation hypnotherapy.

Controversy surrounds the use of hypnotherapy to retrieve memories, especially those from early childhood or (supposed) past-lives. The American Medical Association and the American Psychological Association caution against recovered-memory therapy in cases of alleged childhood trauma, stating that "it is impossible, without corroborative evidence, to distinguish a true memory from a false one." Past life regression, meanwhile, is often viewed with skepticism.

Psychiatric nurses in most medical facilities are allowed to administer hypnosis to patients in order to relieve symptoms such as anxiety, arousal, negative behaviours, uncontrollable behaviour, and to improve self-esteem and confidence. This is permitted only when they have been completely trained about their clinical side effects and while under supervision when administering it.

A 2006 declassified 1966
document obtained by the US Freedom of Information Act archive shows that hypnosis was investigated for military applications. The full paper explores the potentials of operational uses. The overall conclusion of the study was that there was no evidence that hypnosis could be used for military applications, and no clear evidence whether "hypnosis" is a definable phenomenon outside ordinary suggestion, motivation, and subject expectancy. According to the document:

The use of hypnosis in intelligence would present certain technical problems not encountered in the clinic or laboratory. To obtain compliance from a resistant source, for example, it would be necessary to hypnotise the source under essentially hostile circumstances. There is no good evidence, clinical or experimental, that this can be done.

Furthermore, the document states that:

It would be difficult to find an area of scientific interest more beset by divided professional opinion and contradictory experimental evidence…No one can say whether hypnosis is a qualitatively unique state with some physiological and conditioned response components or only a form of suggestion induced by high motivation and a positive relationship between hypnotist and subject…T.X. Barber has produced "hypnotic deafness" and "hypnotic blindness", analgesia and other responses seen in hypnosis—all without hypnotizing anyone…Orne has shown that unhypnotized persons can be motivated to equal and surpass the supposed superhuman physical feats seen in hypnosis.

The study concludes:

It is probably significant that in the long history of hypnosis, where the potential application to intelligence has always been known, there are no reliable accounts of its effective use by an intelligence service.

Research into hypnosis in military applications is further verified by the Project MKULTRA experiments, also conducted by the CIA. According to Congressional testimony, the CIA experimented with utilizing LSD and hypnosis for mind control. Many of these programs were done domestically and on participants who were not informed of the study's purposes or that they would be given drugs.

Self-hypnosis happens when a person hypnotises oneself, commonly involving the use of autosuggestion. The technique is often used to increase motivation for a diet, to quit smoking, or to reduce stress. People who practise self-hypnosis sometimes require assistance; some people use devices known as mind machines to assist in the process, whereas others use hypnotic recordings.

Self-hypnosis is claimed to help with stage fright, relaxation, and physical well-being.

Stage hypnosis is a form of entertainment, traditionally employed in a club or theatre before an audience. Due to stage hypnotists' showmanship, many people believe that hypnosis is a form of mind control. Stage hypnotists typically attempt to hypnotise the entire audience and then select individuals who are "under" to come up on stage and perform embarrassing acts, while the audience watches. However, the effects of stage hypnosis are probably due to a combination of psychological factors, participant selection, suggestibility, physical manipulation, stagecraft, and trickery. The desire to be the centre of attention, having an excuse to violate their own fear suppressors, and the pressure to please are thought to convince subjects to "play along". Books by stage hypnotists sometimes explicitly describe the use of deception in their acts; for example, Ormond McGill's "New Encyclopedia of Stage Hypnosis" describes an entire "fake hypnosis" act that depends upon the use of private whispers throughout.

The idea of music as hypnosis developed from the work of Franz Mesmer. Instruments such as pianos, violins, harps and, especially, the "glass armonica" often featured in Mesmer's treatments; and were considered to contribute to Mesmer's success.

Hypnotic music became an important part in the development of a ‘physiological psychology’ that regarded the hypnotic state as an ‘automatic’ phenomenon that links to physical reflex. In their experiments with sound hypnosis, Jean-Martin Charcot used gongs and tuning forks, and Ivan Pavlov used bells. The intention behind their experiments was to prove that physiological response to sound could be automatic, bypassing the conscious mind.

In the 1980s and 1990s, a moral panic took place in the US fearing Satanic ritual abuse. As part of this, certain books such as "The Devil's Disciples" stated that some bands, particularly in the musical genre of heavy metal, brainwashed American teenagers with subliminal messages to lure them into the worship of the devil, sexual immorality, murder, and especially suicide. The use of satanic iconography and rhetoric in this genre provokes the parents and society, and also advocate masculine power for an audience, especially on teenagers who were ambivalent of their identity. The counteraction on heavy metal in terms of satanic brainwashing is an evidence that linked to the automatic response theories of musical hypnotism.

Various people have been suspected of or convicted for hypnosis-related crimes, including robbery and sexual abuse.

In 2011, a Russian "evil hypnotist" was suspected of tricking customers in banks around Stavropol into giving away thousands of pounds worth of money. According to the local police, he would approach them and make them withdraw all of the money from their bank accounts, which they would then freely give to the man. A similar incident was reported in London in 2014, where a video seemingly showed a robber hypnotizing a shopkeeper before robbing him. The victim did nothing to stop the robber from looting his pockets and taking his cash, only calling out the thief when he was already getting away.

In 2013, the then-40-year-old amateur hypnotist Timothy Porter attempted to sexually abuse his female weight-loss client. She reported awaking from a trance and finding him behind her with his pants down, telling her to touch herself. He was subsequently called to court and included on the sex offender list. In 2015, Gary Naraido, then 52, was sentenced to 10 years in prison for several hypnosis-related sexual abuse charges. Besides the primary charge by a 22-year-old woman who he sexually abused in a hotel under the guise of a free therapy session, he also admitted to having sexually assaulted a 14-year-old girl.

The central theoretical disagreement regarding hypnosis is known as the "state versus nonstate" debate. When Braid introduced the concept of hypnotism, he equivocated over the nature of the "state", sometimes describing it as a specific sleep-like neurological state comparable to animal hibernation or yogic meditation, while at other times he emphasised that hypnotism encompasses a number of different stages or states that are
an extension of ordinary psychological and physiological processes. Overall, Braid appears to have moved from a more "special state" understanding of hypnotism toward a more complex "nonstate" orientation.

State theorists interpret the effects of hypnotism as due primarily to a specific, abnormal, and uniform psychological or physiological state of some description, often referred to as "hypnotic trance" or an "altered state of consciousness". Nonstate theorists rejected the idea of hypnotic trance and interpret the effects of hypnotism as due to a combination of multiple task-specific factors derived from normal cognitive, behavioural, and social psychology, such as social role-perception and favorable motivation (Sarbin), active imagination and positive cognitive set (Barber), response expectancy (Kirsch), and the active use of task-specific subjective strategies (Spanos). The personality psychologist Robert White is often cited as providing one of the first nonstate definitions of hypnosis in a 1941 article:
Hypnotic behaviour is meaningful, goal-directed striving, its most general goal being to behave like a hypnotised person as this is continuously defined by the operator and understood by the client.
Put simply, it is often claimed that, whereas the older "special state" interpretation emphasises the difference between hypnosis and ordinary psychological processes, the "nonstate" interpretation emphasises their similarity.

Comparisons between hypnotised and non-hypnotised subjects suggest that, if a "hypnotic trance" does exist, it only accounts for a small proportion of the effects attributed to hypnotic suggestion, most of which can be replicated without hypnotic induction.

Braid can be taken to imply, in later writings, that hypnosis is largely a state of heightened suggestibility induced by expectation and focused attention. In particular, Hippolyte Bernheim became known as the leading proponent of the "suggestion theory" of hypnosis, at one point going so far as to declare that there is no hypnotic state, only heightened suggestibility. There is a general consensus that heightened suggestibility is an essential characteristic of hypnosis. In 1933, Clark L. Hull wrote:

Ivan Pavlov stated that hypnotic suggestion provided the best example of a conditioned reflex response in human beings; i.e., that responses to suggestions were learned associations triggered by the words used:

Speech, on account of the whole preceding life of the adult, is connected up with all the internal and external stimuli which can reach the cortex, signaling all of them and replacing all of them, and therefore it can call forth all those reactions of the organism which are normally determined by the actual stimuli themselves. We can, therefore, regard "suggestion" as the most simple form of a typical reflex in man.

He also believed that hypnosis was a "partial sleep", meaning that a generalised inhibition of cortical functioning could be encouraged to spread throughout regions of the brain. He observed that the various degrees of hypnosis did not significantly differ physiologically from the waking state and hypnosis depended on insignificant changes of environmental stimuli. Pavlov also suggested that lower-brain-stem mechanisms were involved in hypnotic conditioning.

Pavlov's ideas combined with those of his rival Vladimir Bekhterev and became the basis of hypnotic psychotherapy in the Soviet Union, as documented in the writings of his follower K.I. Platonov. Soviet theories of hypnotism subsequently influenced the writings of Western behaviourally oriented hypnotherapists such as Andrew Salter.

Changes in brain activity have been found in some studies of highly responsive hypnotic subjects. These changes vary depending upon the type of suggestions being given. The state of light to medium hypnosis, where the body undergoes physical and mental relaxation, is associated with a pattern mostly of alpha waves However, what these results indicate is unclear. They may indicate that suggestions genuinely produce changes in perception or experience that are not simply a result of imagination. However, in normal circumstances without hypnosis, the brain regions associated with motion detection are activated both when motion is seen and when motion is imagined, without any changes in the subjects' perception or experience. This may therefore indicate that highly suggestible hypnotic subjects are simply activating to a greater extent the areas of the brain used in imagination, without real perceptual changes. It is, however, premature to claim that hypnosis and meditation are mediated by similar brain systems and neural mechanisms.

Another study has demonstrated that a colour hallucination suggestion given to subjects in hypnosis activated colour-processing regions of the occipital cortex. A 2004 review of research examining the EEG laboratory work in this area concludes:

Studies have shown an association of hypnosis with stronger theta-frequency activity as well as with changes to the gamma-frequency activity. Neuroimaging techniques have been used to investigate neural correlates of hypnosis.

The induction phase of hypnosis may also affect the activity in brain regions that control intention and process conflict. Anna Gosline claims:

Pierre Janet originally developed the idea of "dissociation of consciousness" from his work with hysterical patients. He believed that hypnosis was an example of dissociation, whereby areas of an individual's behavioural control separate from ordinary awareness. Hypnosis would remove some control from the conscious mind, and the individual would respond with autonomic, reflexive behaviour. Weitzenhoffer describes hypnosis via this theory as "dissociation of awareness from the majority of sensory and even strictly neural events taking place."

Ernest Hilgard, who developed the "neodissociation" theory of hypnotism, hypothesized that hypnosis causes the subjects to divide their consciousness voluntarily. One part responds to the hypnotist while the other retains awareness of reality. Hilgard made subjects take an ice water bath. None mentioned the water being cold or feeling pain. Hilgard then asked the subjects to lift their index finger if they felt pain and 70% of the subjects lifted their index finger. This showed that, even though the subjects were listening to the suggestive hypnotist, they still sensed the water's temperature.

The main theorist who pioneered the influential role-taking theory of hypnotism was Theodore Sarbin. Sarbin argued that hypnotic responses were motivated attempts to fulfill the socially constructed roles of hypnotic subjects. This has led to the misconception that hypnotic subjects are simply "faking". However, Sarbin emphasised the difference between faking, in which there is little subjective identification with the role in question, and role-taking, in which the subject not only acts externally in accord with the role but also subjectively identifies with it to some degree, acting, thinking, and feeling "as if" they are hypnotised. Sarbin drew analogies between role-taking in hypnosis and role-taking in other areas such as method acting, mental illness, and shamanic possession, etc. This interpretation of hypnosis is particularly relevant to understanding stage hypnosis, in which there is clearly strong peer pressure to comply with a socially constructed role by performing accordingly on a theatrical stage.

Hence, the "social constructionism and role-taking theory" of hypnosis suggests that individuals are enacting (as opposed to merely "playing") a role and that really there is no such thing as a hypnotic trance. A socially constructed relationship is built depending on how much rapport has been established between the "hypnotist" and the subject (see Hawthorne effect, Pygmalion effect, and placebo effect).

Psychologists such as Robert Baker and Graham Wagstaff claim that what we call hypnosis is actually a form of learned social behaviour, a complex hybrid of social compliance, relaxation, and suggestibility that can account for many esoteric behavioural manifestations.

Barber, Spanos, and Chaves (1974) proposed a nonstate "cognitive-behavioural" theory of hypnosis, similar in some respects to Sarbin's social role-taking theory and building upon the earlier research of Barber. On this model, hypnosis is explained as an extension of ordinary psychological processes like imagination, relaxation, expectation, social compliance, etc. In particular, Barber argued that responses to hypnotic suggestions were mediated by a "positive cognitive set" consisting of positive expectations, attitudes, and motivation. Daniel Araoz subsequently coined the acronym "TEAM" to symbolise the subject's orientation to hypnosis in terms of "trust", "expectation", "attitude", and "motivation".

Barber et al. noted that similar factors appeared to mediate the response both to hypnotism and to cognitive behavioural therapy, in particular systematic desensitization. Hence, research and clinical practice inspired by their interpretation has led to growing interest in the relationship between hypnotherapy and cognitive behavioural therapy.

An approach loosely based on information theory uses a brain-as-computer model. In adaptive systems, feedback increases the signal-to-noise ratio, which may converge towards a steady state. Increasing the signal-to-noise ratio enables messages to be more clearly received. The hypnotist's object is to use techniques to reduce interference and increase the receptability of specific messages (suggestions).

Systems theory, in this context, may be regarded as an extension of Braid's original conceptualization of hypnosis as involving "the brain and nervous system generally". Systems theory considers the nervous system's organization into interacting subsystems. Hypnotic phenomena thus involve not only increased or decreased activity of particular subsystems, but also their interaction. A central phenomenon in this regard is that of feedback loops, which suggest a mechanism for creating hypnotic phenomena.

There is a huge range of societies in England who train individuals in hypnosis; however, one of the longest-standing organisations is the British Society of Clinical and Academic Hypnosis (BSCAH). It origins date back to 1952 when a group of dentists set up the ‘British Society of Dental Hypnosis’. Shortly after, a group of sympathetic medical practitioners merged with this fast-evolving organisation to form ‘The Dental and Medical Society for the Study of Hypnosis’; and, in 1968, after various statutory amendments had taken place, the ‘British Society of Medical and Dental Hypnosis’ (BSMDH) was formed. This society always had close links with the Royal Society of Medicine and many of its members were involved in setting up a hypnosis section at this centre of medical research in London. And, in 1978, under the presidency of David Waxman, the Section of Medical and Dental Hypnosis was formed. A second society, the British Society of Experimental and Clinical Hypnosis (BSECH), was also set up a year before, in 1977, and this consisted of psychologists, doctors and dentists with an interest in hypnosis theory and practice. In 2007, the two societies merged to form the ‘British Society of Clinical and Academic Hypnosis’ (BSCAH). This society only trains health professionals and is interested in furthering research into clinical hypnosis.

The American Society of Clinical Hypnosis (ASCH) is unique among organizations for professionals using hypnosis because members must be licensed healthcare workers with graduate degrees. As an interdisciplinary organization, ASCH not only provides a classroom to teach professionals how to use hypnosis as a tool in their practice, it provides professionals with a community of experts from different disciplines. The ASCH's missions statement is to provide and encourage education programs to further, in every ethical way, the knowledge, understanding, and application of hypnosis in health care; to encourage research and scientific publication in the field of hypnosis; to promote the further recognition and acceptance of hypnosis as an important tool in clinical health care and focus for scientific research; to cooperate with other professional societies that share mutual goals, ethics and interests; and to provide a professional community for those clinicians and researchers who use hypnosis in their work. The ASCH also publishes the American Journal of Clinical Hypnosis



</doc>
<doc id="14421" url="https://en.wikipedia.org/wiki?curid=14421" title="Henry Chadwick (writer)">
Henry Chadwick (writer)

Henry Chadwick (1824 – April 20, 1908) was an English-born American sportswriter, baseball statistician and historian, often called the "Father of Baseball" for his early reporting on and contributions to the development of the game. He edited the first baseball guide that was sold to the public. He is credited with creating box scores, as well as creating the abbreviation "K" that designates a strikeout. He is said to have created the statistics of batting average and earned run average (ERA). He was posthumously inducted into the National Baseball Hall of Fame.

Chadwick was born in Exeter, England. His grandfather, Andrew Chadwick, had been a close friend of theologian John Wesley. His father, James Chadwick, was a supporter of the French Revolution who also tutored John Dalton in music and botany. James Chadwick had served as editor of a publication known as the "Western Times". Edwin Chadwick's mother had made James Chadwick a widower shortly after Edwin's birth.

Chadwick was the younger half brother of Sir Edwin Chadwick, England's sanitary philosopher who developed environmental measures and laws designed to counteract the effects of the Industrial Revolution. Chadwick moved to Brooklyn with his family at the age of 12. Biographer Andrew Schiff writes that Henry Chadwick "was not brought up to value possessions or with an understanding of commerce and trade; rather he received an education that was drenched in moral philosophy and science." He began to write music and to teach piano and guitar.

In 1848, Chadwick married Jane Botts from Richmond, Virginia. Botts' father Alexander had been president of the Virginia State Council. She was also related to politician John Botts. Chadwick edited John Botts' work titled "The Great Rebellion". Chadwick and his wife had three children, Richard Westlake Chadwick, in 1849, Susan Mary Chadwick, in 1851, and Rose Virginia Chadwick, 1853.

Chadwick became a frequent player of cricket and similar ball games such as rounders. He began covering cricket for numerous local newspapers such as the "Long Island Star". He first came across organized baseball in 1856 as a cricket reporter for "The New York Times"; he watched a match between New York's Eagles and Gothams. In 1857 he focused his attention as a journalist and writer on baseball after joining the "New York Clipper", and was also soon hired on to provide coverage for other New York papers including the "Sunday Mercury".

Chadwick was one of the prime movers in the rise of baseball to its popularity at the turn of the 20th century. A keen amateur statistician and professional writer, he helped sculpt the public perception of the game, as well as providing the basis for the records of teams' and players' achievements in the form of baseball statistics. He also served on baseball rules committees and influenced the game itself. He is sometimes referred to as "the father of baseball" because he facilitated the popularity of the sport in its early days.

Early baseball had a provision known as the "bound rule", which held that a fielder could catch a batted ball on one bounce and that it would still be recorded as an out. Chadwick was an outspoken critic of the rule for many years, stating that fielders should have to catch a ball on the fly for it to count as an out. In 1864, the bound rule was eliminated for balls hit into fair territory. The bound rule for foul balls persisted into the 1880s.

Chadwick edited "The Beadle Dime Base-Ball Player", the first annual baseball guide on public sale, as well as the Spalding and Reach annual guides for a number of years and in this capacity promoted the game and influenced the infant discipline of sports journalism. In his 1861 "Beadle" guide, he listed totals of games played, outs, runs, home runs, and strikeouts for hitters on prominent clubs, the first database of its kind. His goal was to provide numerical evidence to prove which players helped a team to win.

In 1867 he accompanied the National Base Ball Club of Washington D.C. on their inaugural national tour, as their official scorer. The next year, Chadwick wrote the first hardcover baseball book, "The Game of Base Ball". In 1874 was instrumental in organizing a tour of England which included games of both baseball and cricket. In his role as journalist, he campaigned against the detrimental effects on the game of both alcohol and gambling.

Despite a friendship with Albert Spalding, Chadwick was scornful of the attempts to have Abner Doubleday declared the inventor of baseball. "He means well", said Chadwick, "but he don't know". Chadwick later willed his baseball library to Spalding.

Author William Cook wrote that "Chadwick was at times a bit self-aggrandizing, but his heart was always deeply rooted in looking after the best interest of the game." An 1876 "Chicago Tribune" article attacked Chadwick's status as the father of baseball, saying in part that Chadwick "has had enough experience to have made himself a man of respect had heaven but given him a head... he proceeded to call himself the '"Father of the Game,' and to assume much on the strength of the title. But he found an unruly child, and one which disinherited him with rapidity and ease." Cook writes that Chadwick may have been a victim of "Western journalism", a sensationalized style of writing.

Chadwick is credited with devising the baseball box score (which he adapted from the cricket scorecard) for reporting game events. The first box score appeared in an 1859 issue of the "Clipper". It was a grid with nine rows for players and nine columns for innings. The original box scores also created the often puzzling abbreviation for strikeout as "K" – "K" being the last letter of "struck" in "struck out". Chadwick assigned numbers to each defensive position for scorekeeping purposes, a system that remains in modern baseball scorekeeping.

Newspapers had previously tallied runs scored, but Chadwick's 1859 box score looked similar in structure to modern ones. Baseball researcher Bill James credits Chadwick's creation of the box score with his interest in the game, but he criticized Chadwick's omission of the walk from calculation of a player's batting average: ""What they failed to understand is that actually the batter has as much or a little more to do with when the walk occurs as the pitcher does. They ignored that element of it and that did distort the game for a lot of people." The box score was popularized in 1925 when "Baseball Magazine" republished Chadwick's 1859 "Clipper" article.

Chadwick is credited with devising statistical measures such as batting average and earned run average (ERA). He felt that batting average was the best representation of a batter's offensive skills. He initially scored walks as errors charged to the pitcher. Walks did not exist in cricket and upon learning about them in baseball, he felt that they did not have anything to do with offensive skill. He later removed walks entirely from baseball statistics. ERA originated not in the goal of measuring a pitcher's worth but to differentiate between runs caused by batting skill (hits) and lack of fielding skill (errors). He is also noted as believing fielding range to be a superior skill to avoiding errors.

The following description of a game was written by Henry Chadwick and appeared in his "Base Ball Memoranda". It is typical of his style of sports journalism, and that of his time:

A Base Ball tourney had been held in Chicago on July 4, 1867, in which the Excelsiors of that city and the Forest City Club, of Rockford, had been the leading contestants. The former had defeated the Forest City nine in two games, by the very close scores of 45–41 in one, and 28–25 in another, when the Forest Citys were invited to meet the Nationals at Chicago on July 25, a day which proved the most notable of the tour. The contest took place at Dexter Park, before a vast crowd of spectators, the majority of whom looked to see the Nationals have almost a walk-over. In the game A. G. Spalding was pitcher and Ross Barnes shortstop for the Forest City nine; these two afterwards becoming famous as star players of the Boston professional team of the early seventies. Williams was pitcher for the Nationals and Frank Norton catcher. The Nationals took the lead in the first innings by 3 to 2; but in the next two innings they added but five runs to their score, while the Forest Citys added thirteen to theirs, thereby taking the lead by a score of fifteen to eight, to the great surprise of the crowd and the delight of the Rockfords. The Nationals tried hard to recover the lost ground. The final result, however, was the success of the Forest Citys by a score of 29 to 23 in a nine innings game, twice interrupted by rain.

Late in life, Chadwick continued editing the "Spalding Base Ball Guides" and producing a column for the "Brooklyn Daily Eagle". In late 1905, he wrote the editor of "The New York Times" to propose widening of the baseball bat to overcome the advantage that pitchers had established in the game. In his letter, Chadwick noted that some cricket experts had advocated for the narrowing of the cricket bat to bring balance to the advantage that belonged to the batter in that game.

In the winter before the 1908 baseball season, Chadwick was struck by an automobile and was bedridden for several weeks. He recovered and attended an exhibition game at the Polo Grounds the week before the season began. He caught a cold while at the game, and the illness worsened when he attended an Opening Day game at Washington Park in Brooklyn.

On April 19, Chadwick was moving furniture from the fourth floor of his apartment to the second floor when he fell unconscious. He was diagnosed with pneumonia and heart failure. He awakened briefly and asked about the game between Brooklyn and New York, but he died the next day. Henry Chadwick is interred at Green-Wood Cemetery in Brooklyn, New York.

For his contributions to the game of baseball, he was elected to the Baseball Hall of Fame by the Veterans Committee in 1938. He was inducted in the same ceremony as Alexander Cartwright.

In 2009, the Society for American Baseball Research (SABR) established the Henry Chadwick Award to honor the outstanding contributions of baseball researchers. Bill James and John Thorn are among the award's recipients.

A collection of historical baseball items, which featured a letter written by Chadwick on the origins of baseball, sold at auction in 2004 for $310,500.




</doc>
<doc id="14423" url="https://en.wikipedia.org/wiki?curid=14423" title="Higher education">
Higher education

Higher education (also called post-secondary education, third-level or tertiary education) is an optional final stage of formal learning that occurs after completion of secondary education. Often delivered at universities, academies, colleges, seminaries, conservatories, and institutes of technology, higher education is also available through certain college-level institutions, including vocational schools, trade schools, and other career colleges that award academic degrees or professional certifications. Tertiary education at non-degree level is sometimes referred to as further education or continuing education as distinct from higher education. The right of access to higher education is mentioned in a number of international human rights instruments. The UN International Covenant on Economic, Social and Cultural Rights of 1966 declares, in Article 13, that "higher education shall be made equally accessible to all, on the basis of capacity, by every appropriate means, and in particular by the progressive introduction of free education". In Europe, Article 2 of the First Protocol to the European Convention on Human Rights, adopted in 1950, obliges all signatory parties to guarantee the right to education.

In the days when few pupils progressed beyond primary education or basic education, the term "higher education" was often used to refer to secondary education, which can create some confusion. This is the origin of the term "high school" for various schools for children between the ages of 14 and 18 (United States) or 11 and 18 (UK and Australia).
Higher education includes teaching, research, exacting applied work (e.g. in medical schools and dental schools), and social services activities of universities. Within the realm of teaching, it includes both the "undergraduate" level, and beyond that, "graduate-level" (or "postgraduate" level). The latter level of education is often referred to as graduate school, especially in North America. In addition to the skills that are specific to any particular degree, potential employers in any profession are looking for evidence of critical thinking and analytical reasoning skills, teamworking skills, information literacy, ethical judgment, decision-making skills, fluency in speaking and writing, problem solving skills, and a wide knowledge of liberal arts and sciences.

Since World War II, developed and many developing countries have increased the participation of the age group who mostly studies higher education from the elite rate, of up to 15 per cent, to the mass rate of 16 to 50 per cent. In many developed countries, participation in higher education has continued to increase towards universal or, what Trow later called, open access, where over half of the relevant age group participate in higher education. Higher education is important to national economies, both as an industry, in its own right, and as a source of trained and educated personnel for the rest of the economy. College educated workers have commanded a measurable wage premium and are much less likely to become unemployed than less educated workers. However, the admission of so many students of only average ability to higher education inevitably requires a decline in academic standards, facilitated by grade inflation. Also, the supply of graduates in many fields of study is exceeding the demand for their skills, which aggravates graduate unemployment, underemployment, credentialism and educational inflation.

The U.S. system of higher education was heavily influenced by the Humboldtian model of higher education. Wilhelm von Humboldt's educational model goes beyond vocational training. In a letter to the Prussian king, he wrote:

The philosopher Julian Nida-Rümelin criticized discrepancies between Humboldt's ideals and the contemporary European education policy, which narrowly understands education as a preparation for the labor market, and argued that we need to decide between McKinsey and Humboldt.

Demonstrated ability in reading, mathematics, and writing, as typically measured in the United States by the SAT or similar tests such as the ACT, have often replaced colleges' individual entrance exams, and is often required for admission to higher education. There is some question as to whether advanced mathematical skills or talent are in fact necessary for fields such as history, English, philosophy, or art.

The general higher education and training that takes place in a university, college, or Institute of technology usually includes significant theoretical and abstract elements, as well as applied aspects (although limited offerings of internships or SURF programs attempt to provide practical applications). In contrast, the vocational higher education and training that takes place at vocational universities and schools usually concentrates on practical applications, with very little theory.

In addition, professional-level education is always included within Higher Education, and usually in graduate schools since many postgraduate academic disciplines are both vocationally, professionally, and theoretically/research oriented, such as in the law, medicine, pharmacy, dentistry, and veterinary medicine. A basic requirement for entry into these graduate-level programs is almost always a bachelor's degree, although alternative means of obtaining entry into such programs may be available at some universities. Requirements for admission to such high-level graduate programs is extremely competitive, and admitted students are expected to perform well.

When employers in any profession consider hiring a college graduate, they are looking for evidence of critical thinking, analytical reasoning skills, teamworking skills, information literacy, ethical judgment, decision-making skills, communication skills (using both text and speech), problem solving skills, and a wide knowledge of liberal arts and sciences. However, most employers consider the average graduate to be more or less deficient in all of these areas.

In the United States, there are large differences in wages and employment associated with different degrees. Medical doctors and lawyers are generally the highest paid workers, and have among the lowest unemployment rates. Among undergraduate fields of study, science, technology, engineering, math, and business generally offer the highest wages and best chances of employment, while education, communication, and liberal arts degrees generally offer lower wages and a lower likelihood of employment.

Academic areas that are included within the liberal arts include environmental science, great books, history, languages including English, linguistics, literature, mathematics, music, philosophy, political science, psychology, religious studies, science, sociology and theater.

Teaching engineering is teaching the application of scientific, economic, social, and practical knowledge in order to design, build, maintain, and improve structures, machines, devices, systems, materials and processes. It may encompass using insights to conceive, model and scale an appropriate solution to a problem or objective. The discipline of engineering is extremely broad, and encompasses a range of more specialized fields of engineering, each with a more specific emphasis on particular areas of technology and types of application. Engineering disciplines include aerospace, biological, civil, chemical, computer, electrical, industrial, and mechanical.

The performing arts differ from the plastic arts or visual arts, insofar as the former uses the artist's own body, face and presence as a medium; the latter uses materials such as clay, metal or paint, which can be molded or transformed to create a work of art.

Performing arts institutions include , dance schools, drama schools and music schools.

The plastic arts or visual arts are a class of art forms, that involve the use of materials, that can be moulded or modulated in some way, often in three dimensions. Examples are painting, sculpture, and drawing.

Higher educational institutions in these arts include film schools and art schools.

Higher vocational education and training takes place at the non-university tertiary level. Such education combines teaching of both practical skills and theoretical expertise. Higher education differs from other forms of post-secondary education such as that offered by institutions of vocational education, which are more colloquially known as trade schools. Higher vocational education might be contrasted with education in a usually broader scientific field, which might concentrate on theory and abstract conceptual knowledge.

This describes a distinct form of higher education that offers a particularly intense integration with the world of work in all its aspects (including teaching, learning, research and governance) and at all levels of the overarching Qualifications Framework of the European Higher Education Area. Its function is to diversify learning opportunities, enhance employability, offer qualifications and stimulate innovation, for the benefit of learners and society.

The intensity of integration with the world of work (which includes enterprise, civil society and the public sector) is manifested by a strong focus on application of learning. This approach involves combining phases of work and study, a concern for employability, cooperation with employers, the use of practice-relevant knowledge and use-inspired research.

Examples of providers of professional higher education may include graduate colleges of architecture, business, journalism, law, library science, optometry, pharmacy, public policy, human medicine, professional engineering, podiatric medicine, scientific dentistry, K-12 education, and veterinary medicine.

A report titled 'Education at a Glance 2014' published by the Organisation for Economic Co-operation and Development on 9 September 2014, revealed that by 2014, 84 percent of young people were completing upper secondary education over their lifetimes, in high-income countries. Tertiary-educated individuals were earning twice as much as median workers. In contrast to historical trends in education, young women were more likely to complete upper secondary education than young men. Additionally, access to education was expanding and growth in the number of people receiving university education was rising sharply. By 2014, close to 40 percent of people aged 25–34 (and around 25 percent of those aged 55–64), were being educated at university.

The Lisbon Recognition Convention stipulates that degrees and periods of study must be recognised in all of the Signatory Parties of the Convention.

Universities may employ a number of people. Depending on the funding, a university typically hires one teacher per 3–25 students. According to the ideal of research-university, the university teaching staff is actively involved in the research of the institution. In addition, the university usually also has dedicated research staff and a considerable support staff. Typically to work in higher education as a member of the academic faculty, a candidate must first obtain a doctorate in an academic field, although some lower teaching positions require only a master's degree.

Most of the administrative staff works in different administrative sections, such as Student Affairs. In addition, there may be central support units, such as a university library which have a dedicated staff.

The professional field involving the collection, analysis, and reporting of higher education data is called institutional research. Professionals in this field can be found at locations in addition to universities, e.g. state educational departments.

Post-secondary institutions also employ graduate students in various assistantship roles. In the US, close to 50% of graduate students are employed as graduate assistants at some point. These apprenticeship-like positions provide opportunities for students to gain experience in, and exposure to, professional roles in exchange for funding of their academic programs.

From the early 1950s to the present, more and more people in the United States have gone on to pursue degrees or certificates of higher education. However this has sparked some debate in recent years as some advocates say that a degree is not what it was once worth to employers. To clarify some advocates say that the financial costs that universities require from their students has gone up so dramatically that it is leaving many students in debt of loans of an average of $37,172 compared to 2000, where the average debt students graduated with was $16,928. In the United States there is an estimated 44 million Americans with a combined $1.3 trillion student loan debt. Advocates advise parents to not send their children to college unless these children are committed to pursuing their future education. An increasing number of freshman every year drop out of their perspective programs or do not possess the maturity to have a balanced life away from home.

However statistics from the U.S. Bureau of Labor Statistics indicate that the college educated are employed at a rate nearly twice that of the national average when compared to high school graduates. The type of degree one pursues will determine how safe and prosperous his/her career path is. A study published by the Pew Charitable Trusts, shows that among Americans ages 21 to 24, the drop in employment and income was much steeper among people who lacked a college degree. "Among those whose highest degree was a high school diploma, only 55% had jobs even before the downturn, and that fell to 47% after it. For young people with an associates degree, the employment rate fell from 64 to 57. Bachelor's degree slipped from 69 to 65." Professor Lisa Kahn of Yale stated that people who graduated from college in the most recent recession were in a position to gain better security than others.

Ultimately a survey, the Great Jobs and Great Lives Gallup-Purdue Index report found the type of college that students attend and in some cases even majors they choose have very little to do with their overall success and well-being later in life. What matters more, the index found, is feeling supported and making emotional connections during school.





</doc>
<doc id="14428" url="https://en.wikipedia.org/wiki?curid=14428" title="Heather Fargo">
Heather Fargo

Heather Fargo (born December 12, 1952) is an American politician who served as mayor and was a former City Council Member of Sacramento, California. She was sworn in as mayor in November 2000, replacing Jimmie R. Yee, and served until December 2008, when she was succeeded by Kevin Johnson.

Heather Fargo grew up in Davis, Santa Maria, and Stockton, CA. She graduated from AA Stagg High School. She received a Bachelor of Science degree in Environmental Planning and Management from the University of California, Davis in 1975. In 1981, Fargo earned a Certificate of Completion from the Revenue Sources Management School in Boulder, Colorado. She also completed the State and Local Government Executive Program at the John F. Kennedy School of Government at Harvard University in 1991.

Heather Fargo was first elected to the Sacramento City Council in 1989 to a five-year term as Sacramento was transitioning to even year citywide elections. Fargo represented District One which includes Downtown and Natomas. In the September primary, she came in second place to businesswoman Kate Karpilow but beat future City Councilman Ray Tretheway who came in third place and incumbent David Shore who came in fourth place. However, Fargo came back to beat Karpilow in November.

Upon Grantland Johnson's resignation from the County Board of Supervisors in 1994, Fargo decided to run for the Board. In that election, she faced attorney and community activist Roger Dickinson. In a closely fought election, Dickinson narrowly beat Fargo. After that loss she was re-elected in 1994 and 1998. While serving on the city council, (prior to becoming Mayor full-time), she was employed as a manager of the California State Parks Volunteer Program.

Upon the sudden death in November 1999 of Mayor Joe Serna, Jr., Land Park city councilman Jimmie Yee became the acting mayor. Several candidates announced their intentions to run. Other than Fargo, three other council members were also seeking the mayorship. North Sacramento city councilman Rob Kerth who represented an area immediately adjacent to Fargo's also decided to run. In addition, Steve Cohn, the city councilman for East Sacramento ran along with Robbie Waters who represents the Pocket and Greenhaven areas decided to run along with several lesser known candidates that included businessman and attorney Joe Genshlea and community activist Julie Padilla. Fargo, who won 22% of the vote in the primary and Kerth who won 20% of the vote made it into the November runoff, where Fargo was elected with just 53% of the vote. In winning, Fargo became the first Latina mayor of an American city.

Fargo did not face as stiff competition in her 2004 re-election. Her main opponent was Ross W. Relles, Jr., a businessman. Other candidates were Deputy Attorney General Mark Soble and Lorenzo Patino Law School President Leonard Padilla. Virtually unopposed against candidates far less funded, Fargo won solidly in the primary election, thus no runoff was necessary.

The primary election for Mayor took place on 3 June 2008. Fargo received 39% of the vote, while former NBA star and Sacramento native Kevin Johnson received 46% of the vote. Since neither received a majority of the votes, a run off election was scheduled for November 2008, where she was defeated by a margin of 58% to 42%.

During the primary election campaign, Fargo initially claimed that she had the support of all the city councilmembers. Yet, Councilman Robbie Waters, Steve Cohn, and Sandra Sheedy all ended up endorsing Johnson during the primary. On September 4, 2008 only Councilman Kevin McCarty endorsed Heather Fargo.

Heather Fargo was a founding member and the first secretary of the Sacramento Tree Foundation, which is considered an important voice in Sacramento’s environmental community. 

During her tenure Mayor Fargo became a member of the Mayors Against Illegal Guns Coalition, an organization formed in 2006 and co-chaired by New York City mayor Michael Bloomberg and Boston mayor Thomas Menino.

Mayor Fargo's tenure as mayor included disagreements with the Maloof family, owners of the NBA's Sacramento Kings, over the building of a new arena.

In 2006, 2007, and 2008, Mayor Fargo was named "Best Local Elected Official" by the readers of "Sacramento Magazine" in their annual poll.

Because Fargo received a majority of the votes in the primary election, no general election was necessary.

Johnson and Fargo proceeded to a runoff election on November 5.

Precincts Reporting - 215 out of 391

 


</doc>
<doc id="14429" url="https://en.wikipedia.org/wiki?curid=14429" title="Henotheism">
Henotheism

Henotheism () is the worship of a single god while not denying the existence or possible existence of other deities. Friedrich Schelling (1775–1854) coined the word, and Friedrich Welcker (1784–1868) used it to depict primitive monotheism among ancient Greeks.

Max Müller (1823–1900), a German philologist and orientalist, brought the term into wider usage in his scholarship on the Indian religions, particularly Hinduism whose scriptures mention and praise numerous deities as if they are one ultimate unitary divine essence. Müller made the term central to his criticism of Western theological and religious exceptionalism (relative to Eastern religions), focusing on a cultural dogma which held "monotheism" to be both fundamentally well-defined and inherently superior to differing conceptions of God.

Friedrich Schelling coined the term henotheism, from "heis" or "heno" which literally means "single, one". The term refers to a form of theism focused on a single god. Related terms are monolatrism and kathenotheism. The latter term is an extension of "henotheism", . Henotheism refers to a pluralistic theology wherein different deities are viewed to be of a unitary, equivalent divine essence. Another term related to henotheism is "equitheism", referring to the belief that all gods are equal. Further, the term henotheism does not exclude monism, nondualism or dualism.

Various scholars prefer the term monolatrism to henotheism, to discuss religions where a single god is central, but the existence or the position of other gods is not denied. According to Christoph Elsas, henotheism in modern usage connotes a syncretic stage in the development of religions in late antiquity. A henotheist may worship a single god from a pantheon of deities at a given time, depending on his or her choice, while accepting other deities and concepts of god. Henotheism and inclusive monotheism are terms that refer to a middle position between unlimited polytheism and exclusive monotheism.

Ahura Mazda is the supreme god, but Zoroastrianism does not deny other deities. Ahura Mazda has yazatas ("good agents") some of which include Anahita, Sraosha, Mithra, Rashnu, and Tishtrya. Richard Foltz has put forth evidence that Iranians of Pre-Islamic era worshiped all these figures, especially Mithra and Anahita.

Prods Oktor Skjærvø states Zoroastrianism is henotheistic, and "a dualistic and polytheistic religion, but with one supreme god, who is the father of the ordered cosmos". Other scholars state that this is unclear, because historic texts present a conflicting picture, ranging from Zoroastrianism's belief in "one god, two gods, or a best god henotheism".

Henotheism was the term used by scholars such as Max Müller to describe the theology of Vedic religion. Müller noted that the hymns of the "Rigveda", the oldest scripture of Hinduism, mention many deities, but praises them successively as the "one ultimate, supreme God", alternatively as "one supreme Goddess", thereby asserting that the essence of the deities was unitary ("ekam"), and the deities were nothing but pluralistic manifestations of the same concept of the divine (God).

The Vedic era conceptualization of the divine or the One, states Jeaneane Fowler, is more abstract than a monotheistic God, it is the Reality behind and of the phenomenal universe. The Vedic hymns treat it as "limitless, indescribable, absolute principle", thus the Vedic divine is something of a panentheism rather than simple henotheism. In late Vedic era, around the start of Upanishadic age (~800 BCE), theosophical speculations emerge that develop concepts which scholars variously call nondualism or monism, as well as forms of non-theism and pantheism. An example of the questioning of the concept of God, in addition to henotheistic hymns found therein, are in later portions of the "Rigveda", such as the Nasadiya Sukta. Hinduism calls the metaphysical absolute concept as Brahman, incorporating within it the transcendent and immanent reality. Different schools of thought interpret Brahman as either personal, impersonal or transpersonal. Ishwar Chandra Sharma describes it as "Absolute Reality, beyond all dualities of existence and non-existence, light and darkness, and of time, space and cause."

While Greek and Roman religion began as polytheism, during the Classical period, under the influence of philosophy, differing conceptions emerged. Often Zeus (or Jupiter) was considered the supreme, all-powerful and all-knowing, king and father of the Olympian gods. According to Maijastina Kahlos "monotheism was pervasive in the educated circles in Late Antiquity" and "all divinities were interpreted as aspects, particles or epithets of one supreme God". Maximus Tyrius (2nd century A.D.) stated: "In such a mighty contest, sedition and discord, you will see one according law and assertion in all the earth, that there is one god, the king and father of all things, and many gods, sons of god, ruling together with him."

The Neoplatonic philosopher Plotinus taught that above the gods of traditional belief was "The One", and polytheist grammarian Maximus of Madauros even stated that only a madman would deny the existence of the supreme God.

Rabbinical Judaism as it developed in Late Antiquity is emphatically monotheistic. However, its predecessor—the various schools of Hellenistic Judaism and Second Temple Judaism, and especially the cult of Yahweh as it was practiced in ancient Israel and Judah during the 8th and 7th centuries BC—have been described as henotheistic.

For example, the Moabites worshipped the god Chemosh, the Edomites, Qaus, both of whom were part of the greater Canaanite pantheon, headed by the chief god, El. The Canaanite pantheon consisted of El and Asherah as the chief deities, with 70 sons who were said to rule over each of the nations of the earth. These sons were each worshiped within a specific region. Kurt Noll states that "the Bible preserves a tradition that Yahweh used to 'live' in the south, in the land of Edom" and that the original god of Israel was El Shaddai.

Several Biblical stories allude to the belief that the Canaanite gods all existed and were thought to possess the most power in the lands by the people who worshiped them and their sacred objects; their power was believed to be real and could be invoked by the people who patronized them. There are numerous accounts of surrounding nations of Israel showing fear or reverence for the Israelite God despite their continued polytheistic practices. For instance, in 1 Samuel 4, the Philistines fret before the second battle of Aphek when they learn that the Israelites are bearing the Ark of the Covenant, and therefore Yahweh, into battle. The Israelites were forbidden to worship other deities, but according to some interpretations of the Bible, they were not fully monotheistic before the Babylonian captivity. Mark S. Smith refers to this stage as a form of monolatry. Smith argues that Yahweh underwent a process of merging with El and that acceptance of cults of Asherah was common in the period of the Judges. 2 Kings 3:27 has been interpreted as describing a human sacrifice in Moab that led the invading Israelite army to fear the power of Chemosh.

Some scholars have written that The Church of Jesus Christ of Latter-day Saints (LDS Church) can be characterized as henotheistic, but others have rejected this stance.

Eugene England, a professor at Brigham Young University, asserted that LDS Presidents Brigham Young and Joseph Fielding Smith along with LDS scholar B. H. Roberts used the LDS interpretation of 1 Corinthians 8:5–6 as "a brief explanation of how it is possible to be both a Christian polytheist (technically a henotheist) and a monotheist". BYU Professor Roger R. Keller rejected descriptions of the LDS Church as polytheistic by countering, as summarized by a reviewer, "Mormons are fundamentally monotheistic because they deal with only one god out of the many which exist."

In their book, "Mormon America: The Power and the Promise", Richard and Joan Ostling, wrote that some Mormons are comfortable describing themselves as henotheists.

Kurt Widmer, professor at the University of Lethbridge, described LDS beliefs as a "cosmic henotheism". A review of Widmer's book by Bruening and Paulsen in the "FARMS Review of Books" countered that Widmer's hypothesis was "strongly disconfirmed in light of the total evidence".

Van Hale has written, "Mormonism teaches the existence of gods who are not the Father, Son, or Holy Ghost" and "the existence of more than one god [is] clearly a Mormon doctrine", but he also said that defining this belief system in theological terms was troublesome. Henotheism might appear to be "promising" in describing LDS beliefs, Hale wrote, but it is ultimately not accurate because henotheism was intended to describe the worship of a god that was restricted to a specific geographical area.



</doc>
<doc id="14431" url="https://en.wikipedia.org/wiki?curid=14431" title="Hedwig of Silesia">
Hedwig of Silesia

Saint Hedwig of Silesia (), also Saint Hedwig of Andechs (, ; 1174 – 15 October 1243), a member of the Bavarian comital House of Andechs, was Duchess of Silesia from 1201 and of Greater Poland from 1231 as well as High Duchess consort of Poland from 1232 until 1238. She was reported in the two-volume historical atlas of Herman Kinder and another author to have been great in war and defended from the Teutonic Knights. She was canonized by the Catholic Church in 1267.

The daughter of Count Berthold IV of Andechs and his second wife Agnes of Wettin, she was born at Andechs Castle in the Duchy of Bavaria. Her elder sister, Agnes married King Philip II of France (annulled in 1200) and her sister, Gertrude (killed in 1213) King Andrew II of Hungary, while the youngest Matilda, (Mechtild) became abbess at the Benedictine Abbey of Kitzingen in Franconia, where Hedwig also received her education. Hedwig's brother was Bishop , Count of Andechs-Meranien. Another brother was Berthold, Archbishop of Kalocsa und Patriarch of Aquileia. 
Through her sister Gertrude, she was the aunt of Saint Elizabeth of Hungary.

At the age of twelve, Hedwig married Henry I the Bearded, son and heir of the Piast duke Boleslaus the Tall of Silesia. As soon as Henry succeeded his father in 1201, he had to struggle with his Piast relatives, at first with his uncle Duke Mieszko IV Tanglefoot who immediately seized the Upper Silesian Duchy of Opole. In 1206 Henry and his cousin Duke Władysław III Spindleshanks of Greater Poland agreed to swap the Silesian Lubusz Land against the Kalisz region, which met with fierce protest by Władysław's III nephew Władysław Odonic. When Henry went to Gąsawa in 1227 to meet his Piast cousins, he narrowly saved his life, while High Duke Leszek I the White was killed by the men of the Pomerelian Duke Swietopelk II, instigated by Władysław Odonic.

The next year Henry's ally Władysław III Spindleshanks succeeded Leszek I as High Duke; however as he was still contested by his nephew in Greater Poland, he made Henry his governor at Kraków, whereby the Silesian duke once again became entangled in the dispute over the Seniorate Province. In 1229 he was captured and arrested at Płock Castle by rivaling Duke Konrad I of Masovia. Hedwig proceeded to Płock pleading for Henry and was able to have him released.

Her actions promoted the reign of her husband: Upon the death of the Polish High Duke Władysław III Spindleshanks in 1231, Henry also became Duke of Greater Poland and the next year prevailed as High Duke at Kraków. He thereby was the first of the Silesian Piast descendants of Władysław II the Exile to gain the rule over Silesia and the Seniorate Province according to the 1138 Testament of Bolesław III Krzywousty.

In 1238, upon his death, Henry was buried at a Cistercian monastery of nuns, Trzebnica Abbey ("Kloster Trebnitz"), which he had established in 1202 at Hedwig's request. Hedwig accepted the death of her beloved husband with faith. She said:

The widow moved into the monastery, which was led by her daughter Gertrude, assuming the religious habit of a lay sister, but she did not take vows. She invited numerous German religious people from the Holy Roman Empire into the Silesian lands, as well as German settlers who founded numerous cities, towns and villages in the course of the "Ostsiedlung", while cultivating barren parts of Silesia for agriculture.

Hedwig and Henry had several daughters, though only one surviving son, Henry II the Pious, who succeeded his father as Duke of Silesia and Polish High Duke. The widow however had to witness the killing of her son, vainly awaiting the support of Emperor Frederick II, during the Mongol invasion of Poland at the Battle of Legnica ("Wahlstatt") in 1241. The hopes for a re-united Poland were lost and even Silesia fragmented into numerous Piast duchies under Henry II's sons. Hedwig and her daughter-in-law, Henry II's widow Anna of Bohemia, established a Benedictine abbey at the site of the battle in Legnickie Pole, settled with monks coming from Opatovice in Bohemia.
Hedwig and Henry had lived very pious lives, and Hedwig had great zeal for her faith. She had supported her husband in donating the Augustinian provostry at Nowogród Bobrzański ("Naumburg") and the commandery of the Knights Templar at Oleśnica Mała ("Klein Oels"). Hedwig always helped the poor, the widows and the orphans, founded several hospitals for the sick and the lepers, and donated all her fortune to the Church. She allowed no one to leave her uncomforted, and one time she spent ten weeks teaching the Our Father to a poor woman. According to legend, she went barefoot even in winter, and when she was urged by the Bishop of Wrocław to wear shoes, she carried them in her hands.On 15 October 1243, Hedwig died and was buried in Trzebnica Abbey with her husband, while relics of her are preserved at Andechs Abbey and St. Hedwig's Cathedral in Berlin.

Hedwig was canonized in 1267 by Pope Clement IV, a supporter of the Cistercian order, at the suggestion of her grandson Prince-Archbishop Władysław of Salzburg. She is the patron saint of Silesia, of Andechs, and of the Roman Catholic Archdiocese of Wrocław and the Roman Catholic Diocese of Görlitz. Her feast day is celebrated on the General Roman Calendar on 16 October. A 17th-century legend has it that Hedwig, while on a pilgrimage to Rome, stopped at Bad Zell in Austria, where she had healing waters spring up at a source which today still bears her name.

In 1773 the Prussian king Frederick the Great, having conquered and annexed the bulk of Silesia in the First Silesian War, had St. Hedwig's Cathedral in Berlin built for the Catholic Upper Silesian immigrants, now the mother church of the Roman Catholic Archdiocese of Berlin.

Hedwig glasses are named after Hedwig of Andechs.

Hedwig and Henry I had seven children:

 


</doc>
<doc id="14436" url="https://en.wikipedia.org/wiki?curid=14436" title="Hasidic Judaism">
Hasidic Judaism

Hasidism, sometimes Hasidic Judaism (, ; originally, "piety"), is a Jewish religious group. It arose as a spiritual revival movement in contemporary Western Ukraine during the 18th century, and spread rapidly throughout Eastern Europe. Today, most affiliates reside in the United States, Israel, and the United Kingdom. Israel Ben Eliezer, the "Baal Shem Tov", is regarded as its founding father, and his disciples developed and disseminated it. Present-day Hasidism is a sub-group within Ultra-Orthodox ("Haredi") Judaism, and is noted for its religious conservatism and social seclusion. Its members adhere closely both to Orthodox Jewish practice – with the movement's own unique emphases – and the traditions of Eastern European Jews, so much so that many of the latter, including various special styles of dress and the use of the Yiddish language, are nowadays associated almost exclusively with Hasidism.

Hasidic thought draws heavily on Lurianic Kabbalah, and, to an extent, is a popularization of it. Teachings emphasize God's immanence in the universe, the need to cleave and be one with Him at all times, the devotional aspect of religious practice, and the spiritual dimension of corporeality and mundane acts. "Hasidim", the adherents of Hasidism, are organized in independent sects known as "courts" or dynasties, each headed by its own hereditary leader, a "Rebbe". Reverence and submission to the "Rebbe" are key tenets, as he is considered a spiritual authority with whom the follower must bond to gain closeness to God. The various "courts" share basic convictions, but operate apart, and possess unique traits and customs. Affiliation is often retained in families for generations, and being Hasidic is as much a sociological factor – entailing, as it does, birth into a specific community and allegiance to a dynasty of "Rebbe"s – as it is a purely religious one. There are several "courts" with many thousands of member households each, and hundreds of smaller ones. The total number of Hasidim, both adults and children, is estimated to be above 400,000.

The terms "hasid" and "hasidut", meaning "pietist" and "piety", have a long history in Judaism. The Talmud and other old sources refer to the "Pietists of Old" ("Hasidim ha-Rishonim") who would contemplate an entire hour in preparation for prayer. The phrase denoted extremely devoted individuals who not only observed the Law to its letter, but performed good deeds even beyond it. Adam himself is honored with the title in tractate Eruvin 18b by Rabbi Meir: "Adam was a great "hasid", having fasted for 130 years." The first to adopt the epithet collectively were apparently the "hasidim" in Second Temple period Judea, known as Hasideans after the Greek rendering of their name, who perhaps served as the model for those mentioned in the Talmud. The title continued to be applied as an honorific for the exceptionally devout. In 12th-century Rhineland, or "Ashkenaz" in Jewish parlance, another prominent school of ascetics named themselves "hasidim"; to distinguish them from the rest, later research employed the term Ashkenazi Hasidim. In the 16th century, when Kabbalah spread, the title also became associated with it. Jacob ben Hayyim Zemah wrote in his glossa on Isaac Luria's version of the Shulchan Aruch that, "One who wishes to tap the hidden wisdom, must conduct himself in the manner of the Pious."

The movement founded by Israel Ben Eliezer in the 18th century adopted the term "hasidim" in the original connotation. But when the sect grew and developed specific attributes, from the 1770s, the names gradually acquired a new meaning. Its common adherents, belonging to groups each headed by a spiritual leader, were henceforth known as Hasidim. The transformation was slow: The movement was at first referred to as "New Hasidism" by outsiders (as recalled in the autobiography of Salomon Maimon) to separate it from the old one, and its enemies derisively mocked its members as "Mithasdim", "[those who] pretend [to be] "hasidim"". Yet, eventually, the young sect gained such a mass following that the old connotation was sidelined. In popular discourse, at least, Hasid came to denote someone who follows a religious teacher from the movement. It also entered Modern Hebrew as such, meaning "adherent" or "disciple". One was not merely a "hasid" anymore, observed historian David Assaf, but a Hasid of someone or some dynasty in particular. This linguistic transformation paralleled that of the word "tzaddik", "righteous", which the Hasidic leaders adopted for themselves – though they are known colloquially as "Rebbe"s or by the honorific "Admor". Originally denoting an observant, moral person, in Hasidic literature "tzaddik" became synonymous with the often hereditary master heading a sect of followers.

The lengthy history of Hasidism, the numerous schools of thought therein, and particularly its use of the traditional medium of homiletic literature and sermons – comprising numerous references to earlier sources in the Pentateuch, Talmud and exegesis as a means to grounding oneself in tradition – as the almost sole channel to convey its ideas, all made the isolation of a common doctrine highly challenging to researchers. As noted by Joseph Dan, "Every attempt to present such a body of ideas has failed". Even motifs presented by scholars in the past as unique Hasidic contributions were later revealed to have been common among both their predecessors and opponents, all the more so regarding many other traits that are widely extant – these play, Dan added, ""a prominent role in modern non-Hasidic and anti-Hasidic writings as well"". The difficulty of separating the movement's philosophy from that of its main inspiration, Lurianic Kabbalah, and determining what was novel and what merely a recapitulation, also baffled historians. Some, like Louis Jacobs, regarded the early masters as innovators who introduced "much that was new if only by emphasis"; others, primarily Mendel Piekarz, argued to the contrary that but a little was not found in much earlier tracts, and the movement's originality lay in the manner it popularized these teachings to become the ideology of a well-organized sect.

Among the traits particularly associated with Hasidism in common understanding which are in fact widespread, is the importance of joy and happiness at worship and religious life – though the sect undoubtedly stressed this aspect and still possesses a clear populist bent. Another example is the value placed on the simple, ordinary Jew in supposed contradiction with the favouring of elitist scholars beforehand; such ideas are common in ethical works far preceding Hasidism. The movement did for a few decades challenge the rabbinic establishment, which relied on the authority of Torah acumen, but affirmed the centrality of study very soon. Concurrently, the image of its Opponents as dreary intellectuals who lacked spiritual fervour and opposed mysticism is likewise unfounded. Neither did Hasidism, often portrayed as promoting healthy sensuality, unanimously reject the asceticism and self-mortification associated primarily with its rivals. Joseph Dan ascribed all these perceptions to so-called "Neo-Hasidic" writers and thinkers, like Martin Buber. In their attempt to build new models of spirituality for modern Jews, they propagated a romantic, sentimental image of the movement. The "Neo-Hasidic" interpretation influenced even scholarly discourse to a great degree, but had a tenuous connection with reality.

A further complication is the divide between what researchers term "early Hasidism", which ended in the early 1800s, and established Hasidism since then onwards. While the former was a highly dynamic religious revival movement, the latter phase is characterized by consolidation into sects with hereditary leadership. The mystical teachings formulated during the first era were by no means repudiated, and many Hasidic masters remained consummate spiritualists and original thinkers; as noted by Benjamin Brown, Buber's once commonly accepted view that the routinization constituted "decadence" was refuted by later studies, demonstrating that the movement remained very much innovative. Yet many aspects of early Hasidism were indeed de-emphasized in favour of more conventional religious expressions, and its radical concepts were largely neutralized. Some "Rebbe"s adopted a relatively rationalist bent, sidelining their explicit mystical, theurgical roles, and many others functioned almost solely as political leaders of large communities. As to their Hasidim, affiliation was less a matter of admiring a charismatic leader as in the early days, but rather birth into a family belonging to a specific "court".

The most fundamental theme underlying all Hasidic theory is the immanence of God in the universe, often expressed in a phrase from Tikunei haZohar, "Leit Atar panuy mi-néya" (Aramaic: "no site is devoid of Him"). This panentheistic concept was derived from Lurianic discourse, but greatly expanded in the Hasidic one. In the beginning, in order to create the world, God contracted ("Tzimtzum") His Omnipresence, the "Ein Sof", leaving a Vacant Void ("Khalal panui"), bereft from obvious presence and therefore able to entertain free will, contradictions and other phenomena seemingly separate from God Himself. These would have been impossible within His original, perfect existence. Yet, the very reality of the world which was created in the Void is entirely dependent on its divine origin. Matter would have been null and void without the true, spiritual essence it possesses. Just the same, the infinite "Ein Sof" cannot manifest in the Vacant Void, and must limit itself in the guise of measurable corporeality that may be perceived.

Thus, there is a dualism between the true aspect of everything and the physical side, false but ineluctable, with each evolving into the other: as God must compress and disguise Himself, so must humans and matter in general ascend and reunite with the Omnipresence. Rachel Elior quoted Shneur Zalman of Liadi, in his commentary "Torah Or" on Genesis 28:21, who wrote that ""this is the purpose of Creation, from Infinity to Finitude, so it may be reversed from the state of Finite to that of Infinity"". Kabbalah stressed the importance of this dialectic, but mainly (though not exclusively) evoked it in cosmic terms, referring for example to the manner in which God progressively diminished Himself into the world through the various dimensions, or "Sephirot". Hasidism applied it also to the most mundane details of human existence. All Hasidic schools devoted a prominent place in their teaching, with differing accentuation, to the interchanging nature of "Ein", both infinite and imperceptible, becoming "Yesh", "Existent" – and vice versa. They used the concept as a prism to gauge the world, and the needs of the spirit in particular. Elior noted: ""Reality lost its static nature and permanent value, now measured by a new standard, seeking to expose the Godly, boundless essence, manifest in its tangible, circumscribed opposite.""

One major derivative of this philosophy is the notion of "devekut", "communion". As God was everywhere, connection with Him had to be pursued ceaselessly as well, in all times, places and occasions. Such an experience was in the reach of every person, who only had to negate his inferior impulses and grasp the truth of divine immanence, enabling him to unite with it and attain the state of perfect, selfless bliss. Hasidic masters, well versed in the teachings concerning communion, are supposed not only to gain it themselves, but to guide their flock to it. "Devekut" was not a strictly defined experience; many varieties were described, from the utmost ecstasy of the learned leaders to the common man's more humble yet no less significant emotion during prayer.

Closely linked with the former is "Bitul ha-Yesh", "Negation of the Existent", or of the "Corporeal". Hasidism teaches that while a superficial observance of the universe by the "eyes of the flesh" ("Einei ha-Basar") purportedly reflects the reality of all things profane and worldly, a true devotee must transcend this illusory façade and realize that there is nothing but God. It is not only a matter of perception, but very practical, for it entails also abandoning material concerns and cleaving only to the true, spiritual ones, oblivious to the surrounding false distractions of life. The practitioner's success in detaching from his sense of person, and conceive himself as "Ein" (in the double meaning of 'naught' and 'infinite'), is regarded as the highest state of elation in Hasidism. The true divine essence of man – the soul – may then ascend and return to the upper realm, where it does not possess an existence independent from God. This ideal is termed "Hitpashtut ha-Gashmi'yut", "the expansion (or removal) of corporeality". It is the dialectic opposite of God's contraction into the world.

To be enlightened and capable of "Bitul ha-Yesh", pursuing the pure spiritual aims and defying the primitive impulses of the body, one must overcome his inferior "Bestial Soul", connected with the Eyes of the Flesh. He may be able to tap into his "Divine Soul" ("Nefesh Elohit"), which craves communion, by employing constant contemplation, "Hitbonenot", on the hidden Godly dimension of all that exists. Then he could understand his surroundings with the "Eyes of the Intellect". The ideal adherent was intended to develop equanimity, or "Hishtavut" in Hasidic parlance, toward all matters worldly, not ignoring them, but understanding their superficiality.

Hasidic masters exhorted their followers to "negate themselves", paying as little heed as they could for worldly concerns, and thus, to clear the way for this transformation. The struggle and doubt of being torn between the belief in God's immanence and the very real sensual experience of the indifferent world is a key theme in the movement's literature. Many tracts have been devoted to the subject, acknowledging that the "callous and rude" flesh hinders one from holding fast to the ideal, and these shortcomings are extremely hard to overcome even in the purely intellectual level, a fortiori in actual life.

Another implication of this dualism is the notion of "Worship through Corporeality", "Avodah be-Gashmi'yut". As the "Ein Sof" metamorphosed into substance, so may it in turn be raised back to its higher state; likewise, since the machinations in the higher "Sephirot" exert their influence on this world, even the most simple action may, if performed correctly and with understanding, achieve the reverse effect. According to Lurianic doctrine, The netherworld was suffused with divine sparks, concealed within "husks", "Qliphoth". The glints had to be recovered and elevated to their proper place in the cosmos. "Materiality itself could be embraced and consecrated", noted Glenn Dynner, and Hasidism taught that by common acts like dancing or eating, performed with intention, the sparks could be extricated and set free. "Avodah be-Gashmi'yut" had a clear, if not implicit, antinomian edge, possibly equating sacred rituals mandated by Judaism with everyday activities, granting them the same status in the believer's eyes and having him content to commit the latter at the expense of the former. While at some occasions the movement did appear to step at that direction – for example, in its early days prayer and preparation for it consumed so much time that adherents were blamed of neglecting sufficient Torah study – Hasidic masters proved highly conservative. Unlike in other, more radical sects influenced by kabbalistic ideas, like the Sabbateans, Worship through Corporeality was largely limited to the elite and carefully restrained. The common adherents were taught they may engage it only mildly, through small deeds like earning money to support their leaders.

The complementary opposite of corporeal worship, or the elation of the finite into infinite, is the concept of "Hamshacha", "drawing down" or "absorbing", and specifically, "Hamschat ha-Shefa", "absorption of effluence". During spiritual ascension, one could siphon the power animating the higher dimensions down into the material world, where it would manifest as benevolent influence of all kinds. These included spiritual enlightenment, zest in worship and other high-minded aims, but also the more prosaic health and healing, deliverance from various troubles and simple economic prosperity. Thus, a very tangible and alluring motivation to become followers emerged. Both corporeal worship and absorption allowed the masses to access, with common actions, a religious experience once deemed esoteric.

Yet another reflection of the "Ein"-"Yesh" dialectic is pronounced in the transformation of evil to goodness and the relations between these two poles and other contradicting elements – including various traits and emotions of the human psyche, like pride and humility, purity and profanity, et cetera. Hasidic thinkers argued that in order to redeem the sparks hidden, one had to associate not merely with the corporeal, but with sin and evil. One example is the elevation of impure thoughts during prayer, transforming them to noble ones rather than repressing them, advocated mainly in the early days of the sect; or "breaking" oneself's character by directly confronting profane inclinations. This aspect, once more, had sharp antinomian implications was and used by the Sabbateans to justify excessive sinning. It was mostly toned down in late Hasidism, and even before that leaders were careful to stress that it was not exercised in the physical sense, but in the contemplative, spiritual one. This kabbalistic notion, too, was not unique to the movement and appeared frequently among other Jewish groups.

While its mystical and ethical teachings are not easily sharply distinguished from those of other Jewish currents, the defining doctrine of Hasidism is that of the saintly leader, serving both as an ideal inspiration and an institutional figure around whom followers are organized. In the movement's sacral literature, this person is referred to as the "Tzaddiq", the Righteous One – often also known by the general honorific "Admor" (acronym of Hebrew for "our master, teacher and Rabbi"), granted to rabbis in general, or colloquially as "Rebbe". The idea that, in every generation, there are righteous persons through whom the divine effluence is drawn to the material world is rooted in the kabbalistic thought, which also claims that one of them is supreme, the reincarnation of Moses. Hasidism elaborated the notion of the "Tzaddiq" into the basis of its entire system – so much that the very term gained an independent meaning within it, apart from the original which denoted God-fearing, highly observant people.

When the sect began to attract following and expanded from a small circle of learned disciples to a mass movement, it became evident that its complex philosophy could be imparted only partially to the new rank and file. As even intellectuals struggled with the sublime dialectics of infinity and corporeality, there was little hope to have the common folk truly internalize these, not as mere abstractions to pay lip service to. Ideologues exhorted them to have faith, but the true answer, which marked their rise as a distinct sect, was the concept of the "Tzaddiq". A Hasidic master was to serve as a living embodiment of the recondite teachings. He was able to transcend matter, gain spiritual communion, Worship through Corporeality and fulfill all the theoretical ideals. As the vast majority of his flock could not do so themselves, they were to cleave to him instead, acquiring at least some semblance of those vicariously. His commanding and often – especially in the early generations – charismatic presence was to reassure the faithful and demonstrate the truth in Hasidic philosophy by countering doubts and despair. But more than spiritual welfare was concerned: Since it was believed he could ascend to the higher realms, the leader was able to harvest effluence and bring it down upon his adherents, providing them with very material benefits. "The crystallization of that theurgical phase", noted Glenn Dynner, "marked Hasidism's evolution into a full-fledged social movement."

In Hasidic discourse, the willingness of the leader to sacrifice the ecstasy and fulfillment of unity in God was deemed a heavy sacrifice undertook for the benefit of the congregation. His followers were to sustain and especially to obey him, as he possessed superior knowledge and insight gained through communion. The "descent of the Righteous" ("Yeridat ha-Tzaddiq") into the matters of the world was depicted as identical with the need to save the sinners and redeem the sparks concealed in the most lowly places. Such a link between his functions as communal leader and spiritual guide legitimized the political power he wielded. It also prevented a retreat of Hasidic masters into hermitism and passivity, as many mystics before them did. Their worldly authority was perceived as part of their long-term mission to elevate the corporeal world back into divine infinity. To a certain extent, the Saint even fulfilled for his congregation, and for it alone, a limited Messianic capacity in his lifetime. After the Sabbatean debacle, this moderate approach provided a safe outlet for the eschatological urges. At least two leaders radicalized in this sphere and caused severe controversy: Nachman of Breslov, who declared himself the only true "Tzaddiq", and Menachem Mendel Schneerson, whom many of his followers believed to be the Messiah. The "Rebbe"s were subject to intense hagiography, even subtly compared with Biblical figures by employing prefiguration. It was argued that since followers could not "negate themselves" sufficiently to transcend matter, they should instead "negate themselves" in submission to the Saint ("hitbatlut la-Tzaddiq"), thus bonding with him and enabling themselves to access what he achieved in terms of spirituality. The Righteous served as a mystical bridge, drawing down effluence and elevating the prayers and petitions of his admirers.

The Saintly forged a well-defined relationship with the masses: they provided the latter with inspiration, were consulted in all matters, and were expected to intercede on behalf of their adherents with God and ensure they gained financial prosperity, health and male offspring. The pattern still characterizes Hasidic sects, though prolonged routinization in many turned the "Rebbes" into de facto political leaders of strong, institutionalized communities. The role of a Saint was obtained by charisma, erudition and appeal in the early days of Hasidism. But by the dawn of the 19th century, the Righteous began to claim legitimacy by descent to the masters of the past, arguing that since they linked matter with infinity, their abilities had to be associated with their own corporeal body. Therefore, it was accepted "there can be no "Tzaddiq" but the son of a "Tzaddiq"". Virtually all modern sects maintain this hereditary principle. For example, the "Rebbe"s' families maintain endogamy and marry almost solely with scions of other dynasties.

Some Hasidic "courts", and not a few individual prominent masters, developed distinct philosophies with particular accentuation of various themes in the movement's general teachings. Several of these Hasidic schools had lasting influence over many dynasties, while others died with their proponents. In the doctrinal sphere, the dynasties may be divided along many lines. Some are characterized by "Rebbe"s who are predominantly Torah scholars and decisors, deriving their authority much like ordinary non-Hasidic rabbis do. Such "courts" place great emphasis on strict observance and study, and are among the most meticulous in the Orthodox world in practice. Prominent examples are the House of Sanz and its scions, such as Satmar, or Belz. Other sects, like Vizhnitz, espouse a charismatic-populist line, centered on the admiration of the masses for the Righteous, his effervescent style of prayer and conduct and his purported miracle-working capabilities. Fewer still retain a high proportion of the mystical-spiritualist themes of early Hasidism, and encourage members to study much kabbalistic literature and (carefully) engage in the field. The various Ziditchover dynasties mostly adhere to this philosophy.
Others still focus on contemplation and achieving inner perfection. No dynasty is wholly devoted to a single approach of the above, and all offer some combination with differing emphasis on each of those.

In 1812, a schism occurred between the Seer of Lublin and his prime disciple, the Holy Jew of Przysucha, due to both personal and doctrinal disagreements. The Seer adopted a populist approach, centered on the Righteous' theurgical functions to draw the masses. He was famous for his lavish, enthusiastic conduct during prayer and worship, and extremely charismatic demeanour. He stressed that as "Tzaddiq", his mission was to influence the common folk by absorbing Divine Light and satisfying their material needs, thus converting them to his cause and elating them. The Holy Jew pursued a more introspective course, maintaining that the "Rebbe"'s duty was to serve as a spiritual mentor for a more elitist group, helping them to achieve a senseless state of contemplation, aiming to restore man to his oneness with God which Adam supposedly lost when he ate the fruit of the Lignum Scientiae. The Holy Jew and his successors did neither repudiate miracle working, nor did they eschew dramatic conduct; but they were much more restrained in general. The Przysucha School became dominant in Central Poland, while populist Hasidism resembling the Lublin ethos often prevailed in Galicia. One extreme and renowned philosopher who emerged from the Przysucha School was Menachem Mendel of Kotzk. Adopting an elitist, hard-line attitude, he openly denounced the folkly nature of other "Tzaddiqim", and rejected financial support. Gathering a small group of devout scholars who sought to attain spiritual perfection, whom he often berated and mocked, he always stressed the importance of both somberness and totality, stating it was better to be fully wicked than only somewhat good.

The Chabad school, limited to its namesake dynasty, but prominent, was founded by Shneur Zalman of Liadi and was elaborated by his successors, until the late 20th century. The movement retained many of the attributes of early Hasidism, before a clear divide between Righteous and ordinary followers was cemented. Chabad "Rebbe"s insisted their adherents acquire proficiency in the sect's lore, and not relegate most responsibility to the leaders. The sect emphasizes the importance of intellectually grasping the dynamics of the hidden divine aspect and how they affect the human psyche; the very acronym Chabad is for the three penultimate "Sephirot", associated with the cerebral side of consciousness.

Another famous philosophy is that formulated by Nachman of Breslov and adhered to by Breslov Hasidim. In contrast to most of his peers who believed God must be worshiped through joy, Nachman portrayed the corporeal world in grim colors, as a place devoid of God's immediate presence from which the soul yearns to liberate itself. He mocked the attempts to perceive the nature of infinite-finite dialectics and the manner in which God still occupies the Vacant Void albeit not, stating these were paradoxical, beyond human understanding. Only naive faith in their reality would do. Mortals were in constant struggle to overcome their profane instincts, and had to free themselves from their limited intellects to see the world as it truly is.

Tzvi Hirsh of Zidichov, a major Galician "Tzaddiq", was a disciple of the Seer of Lublin, but combined his populist inclination with a strict observance even among his most common followers, and great pluralism in matters pertaining to mysticism, as those were eventually emanating from each person's unique soul.

Mordechai Yosef Leiner of Izbica promulgated a radical understanding of free will, which he considered illusory and also derived directly from God. He argued that when one attained a sufficient spiritual level and could be certain evil thoughts did not derive from his animalistic soul, then sudden urges to transgress revealed Law were God-inspired and may be pursued. This volatile, potentially antinomian doctrine of "Transgression for the Sake of Heaven" is found also in other Hasidic writings, especially from the early period. His successors de-emphasized it in their commentaries. Leiner's disciple Zadok HaKohen of Lublin also developed a complex philosophic system which presented a dialectic nature in history, arguing that great progress had to be preceded by crisis and calamity.

The Hasidic community is organized in a sect known as "court" (Hebrew: חצר, "hatzer"; Yiddish: האף, "Hoif"). In the early days of the movement, a particular "Rebbe"'s following usually resided in the same town, and Hasidim were categorized by their leaders' settlement: a Hasid of Belz, Vizhnitz and so forth. Later, especially after World War II, the dynasties retained the names of their original Eastern European settlements when moving to the West or Israel. Thus, for example, the "court" established by Joel Teitelbaum in 1905 at Transylvania remained known after its namesake town, Sathmar, even though its headquarters lay in New York, and almost all other Hasidic sects likewise – albeit some groups founded overseas were named accordingly, like the Boston (Hasidic dynasty).

Akin to his spiritual status, the "Rebbe" is also the administrative head of the community. Sects often possess their own synagogues, study halls and internal charity mechanisms, and ones sufficiently large also maintain entire educational systems. The "Rebbe" is the supreme figure of authority, and not just for the institutions. The rank-and-file Hasidim are also expected to consult with him on important matters, and often seek his blessing and advice. He is personally attended by aides known as "Gabbai" or "Mashbak".

Many particular Hasidic rites surround the leader. On the Sabbath, holidays, and celebratory occasions, "Rebbe"s hold a "Tisch" (table), a large feast for their male adherents. Together, they sing, dance, and eat, and the head of the sect shakes the hands of his followers to bless them, and often delivers a sermon. A "Chozer", "repeater", selected for his good memory, commits the text to writing after the Sabbath (any form of writing during the Sabbath itself being forbidden). In many "courts", the remnants of his meal, supposedly suffused with holiness, are handed out and even fought over. Often, a very large dish is prepared beforehand and the "Rebbe" only tastes it before passing it to the crowd. Apart from the gathering at noon, the third repast on Sabbath and the "Melaveh Malkah" meal when it ends are also particularly important and an occasion for song, feasting, tales and sermons. A central custom, which serves as a major factor in the economics of most "courts", is the "Pidyon", "Ransom", better known by its Yiddish name "Kvitel", "little note": adherents submit a written petition, which the master may assist with on behalf of his sanctity, adding a sum of money for either charity or the leader's needs. Occasions in the "court" serve as pretext for mass gatherings, flaunting the power, wealth and size of each. Weddings of the leader's family, for example, are often held with large multistoried stands (פארענטשעס, "Parentches") filled with Hasidim surround the main floor, where the "Rebbe" and his relatives dine, celebrate and perform the Mitzvah tantz. This is a festive dance with the bride: both parties hold one end of a long sash, a Hasidic gartel, for reasons of modesty.

Allegiance to the dynasty and "Rebbe" is also often a cause for tension and violence. Notable feuds between "courts" include the 1926–34 strife after Chaim Elazar Spira of Munkatch cursed the deceased Yissachar Dov Rokeach I of Belz; the 1980–2012 Satmar-Belz collision after Yissachar Dov Rokeach II broke with the Orthodox Council of Jerusalem, which culminated when he had to travel in a bulletproof car; and the 2006–present Satmar succession dispute between brothers Aaron Teitelbaum and Zalman Teitelbaum, which saw mass riots.

Like in other Ultra-Orthodox groups, Hasidim who wish to disaffiliate from the community face threats, hostility, violence and various punitive measures, among them separation of children from their disaffiliated parents, especially in divorce cases. Due to their strictly religious education and traditionalist upbringing, those who leave their sects are devoid of working skills and even command of the English language, and their integration into outer society is extremely problematic. The conservative and segregated communities are also a comfortable setting for sexual abuse of children, and numerous incidents have been reported. While Hasidic leadership has often been accused of silencing the matter, awareness of it is rising within the sects.

Another related phenomenon is the recent rise of "Mashpi'im" ("influencers"). Once a title for an instructor in Chabad and Breslov only, the institutionalized nature of the established "courts" led many adherents to seek guidance and inspiration from persons who did not declare themselves new leaders, but only "Mashpi'im". Technically, they fill the original role of "Rebbe"s in providing for spiritual welfare; yet, they do not usurp the title, and are therefore countenanced.

Most Hasidim use some variation of "Nusach Sefard", a blend of Ashkenazi and Sephardi liturgies, based on the innovations of Rabbi Isaac Luria. Many dynasties have their own specific adaptation of Nusach Sefard; some, such as the versions of the Belzer, Bobover, and Dushinsky Hasidim, are closer to Nusach Ashkenaz, while others, such as the Munkacz version, are closer to the old Lurianic. Many sects believe that their version reflects Luria's mystical devotions best. The Baal Shem Tov added two segments to Friday services on the eve of Sabbath: Psalm 107 before afternoon prayer, and Psalm 23 at the end of evening service.

Hasidim use the Ashkenazi pronunciation of Hebrew and Aramaic for liturgical purposes, reflecting their Eastern European background. Wordless, emotional melodies, "nigunim", are particularly common in their services.

Hasidim lend great importance to "kavana", devotion or intention, and their services tend to be extremely long and repetitive. Some courts nearly abolished traditional specified times by which prayers must be conducted ("zemanim"), to prepare and concentrate. This practice, still enacted in Chabad for one, is controversial in many dynasties, which do follow the specifics of Jewish Law on praying earlier, and not eating beforehand. Another reglement is daily immersion in a ritual bath by males for spiritual cleansing, at a rate much higher than is customary among other Orthodox Jews.

Within the Hasidic world, it is possible to distinguish different Hasidic groups by subtle differences in dress. Some details of their dress are shared by non-Hasidic Haredim. Much of Hasidic dress was historically the clothing of all Eastern European Jews, influenced by the style of Polish–Lithuanian nobility. Furthermore, Hasidim have attributed religious origins to specific Hasidic items of clothing.

Hasidic men most commonly wear dark overclothes. On weekdays, they wear a long, black, cloth jacket called a rekel, and on Jewish Holy Days, the bekishe "zaydene kapote" (Yiddish, lit., satin caftan), a similarly long, black jacket, but of satin fabric traditionally silk. Indoors, the colorful tish bekishe is still worn. Some Hasidim wear a satin overcoat, known as "rezhvolke". A rebbe's "rezhvolke" might be trimmed with velvet. Most do not wear neckties.

On the Sabbath, the Hasidic "Rebbes" traditionally wore a white bekishe. This practice has fallen into disuse among most. Many of them wear a black silk "bekishe" that is trimmed with velvet (known as "stro-kes" or "samet") and in Hungarian ones, gold-embroidered.

Various symbolic and religious qualities are attributed to Hasidic dress, though they are mainly apocryphal and the clothes' origin is cultural and historical. For example, the long overcoats are considered modest, the Shtreimel is supposedly related to shaatnez and keeps one warm without using wool, and Sabbath shoes are laceless in order not to have to tie a knot, a prohibited action. A "gartel" divides the Hasid's lower parts from his upper parts, implying modesty and chastity, and for kabbalistic reasons, Hasidim button their clothes right over left. Hasidim customarily wear black hats during the weekdays, as do nearly all Haredim today. A variety of hats are worn depending on the group: Chabad often pinch their hats to form a triangle on the top, Satmar wear an open-crown hat with rounded edges, and "Samet" (velvet) or "biber" (beaver) hats are worn by many Galician and Hungarian Hasidim.

Married Hasidim don a variety of fur headdresses on the Sabbath, once common among all wedded Eastern European Jewish males and still worn by non-Hasidic Perushim in Jerusalem. The most ubiquitous is the "Shtreimel", which is seen especially among Galician and Hungarian sects like Satmar or Belz. A taller "Spodik" is donned by Polish dynasties such as Ger. A "Kolpik" is worn by unmarried sons and grandsons of many Rebbes on the Sabbath. Some Rebbes don it on special occasions.
There are many other distinct items of clothing. Such are the Gerrer "hoyznzokn"—long black socks into which the trousers are tucked. Some Hasidim from Eastern Galicia wear black socks with their breeches on the Sabbath, as opposed to white ones on weekdays, particularly Belzer Hasidim.

Following a Biblical commandment not to shave the sides of one's face (Leviticus 19:27), male members of most Hasidic groups wear long, uncut sidelocks called payot (or "peyes"). Some Hasidic men shave off the rest of their hair. Not every Hasidic group requires long peyos, and not all Jewish men with peyos are Hasidic, but all Hasidic groups discourage the shaving of one's beard. Most Hasidic boys receive their first haircuts ceremonially at the age of three years (only the Skverrer Hasidim do this at their boys' second birthday). Until then, Hasidic boys have long hair.

Hasidic women wear clothing adhering to the principles of modest dress in Jewish law. This includes long, conservative skirts and sleeves past the elbow, as well as covered necklines. Also, the women wear stockings to cover their legs; in some Hasidic groups, such as Satmar or Toldot Aharon, the stockings must be opaque. In keeping with Jewish law, married women cover their hair, using either a "sheitel" (wig), a "tichel" (headscarf), a "shpitzel", a snood, a hat, or a beret. In some Hasidic groups, such as Satmar, women may wear two headcoverings – a wig and a scarf, or a wig and a hat.

Hasidic Jews, like many other Orthodox Jews, typically produce large families; the average Hasidic family in the United States has 8 children. This is followed out of a desire to fulfill the Biblical mandate to "be fruitful and multiply".

Most Hasidim speak the language of their countries of residence, but use Yiddish among themselves as a way of remaining distinct and preserving tradition. Thus, children are still learning Yiddish today, and the language, despite predictions to the contrary, is not dead. Yiddish newspapers are still published, and Yiddish fiction is being written, primarily aimed at women. Even films in Yiddish are being produced within the Hasidic community. Some Hasidic groups, such as Satmar or Toldot Aharon, actively oppose the everyday use of Hebrew, which they consider a holy tongue. The use of Hebrew for anything other than prayer and study is, according to them, profane. Hence, Yiddish is the vernacular and common tongue for many Hasidim around the world.

Hasidic Tales are a literary genre, concerning both hagiography of various "Rebbes" and moralistic themes. Some are anecdotes or recorded conversations dealing with matters of faith, practice, and the like. The most famous tend to be terse and carry a strong and obvious point. They were often transmitted orally, though the earliest compendium is from 1815.

Many revolve around the Righteous. The Baal Shem, in particular, was subject to excess hagiography. Characterized by vivid metaphors, miracles, and piety, each reflects the surrounding and era it was composed in. Common themes include dissenting the question what is acceptable to pray for, whether or not the commoner may gain communion, or the meaning of wisdom.
The tales were a popular, accessible medium to convey to movement's messages.

The various Hasidic groups may be categorized along several parameters, including their geographical origin, their proclivity for certain teachings, and their political stance. These attributes are quite often, but by no means always, correlated, and there are many instances when a "court" espouses a unique combination. Thus, while most dynasties from the former Greater Hungary and Galicia are inclined to extreme conservatism and anti-Zionism, "Rebbe" Yekutiel Yehuda Halbertsam led the Sanz-Klausenburg sect in a more open and mild direction; and though Hasidim from Lithuania and Belarus are popularly perceived as prone to intellectualism, David Assaf noted this notion is derived more from their Litvak surroundings than their actual philosophies.
Apart from those, each "court" often possesses its unique customs, including style of prayer, melodies, particular items of clothing and the like.

On the political scale, "courts" are mainly divided on their relations to Zionism. The right-wing, identified with Satmar, are hostile to the State of Israel, and refuse to participate in the elections there or receive any state funding. They are mainly affiliated with the Orthodox Council of Jerusalem and the Central Rabbinical Congress. The great majority belong to "Agudas Israel", represented in Israel by the United Torah Judaism party. Its Council of Torah Sages now includes a dozen "Rebbe"s. In the past, there were Religious Zionist "Rebbe"s, mainly of the Ruzhin line, but there are virtually none today.

In 2005, Prof. Jacques Gutwirth estimated there were some 400,000 men, women, and children adhering to Hasidic sects worldwide, and that figure was expected to grow due to high birth rates of Hasidic Jews. About 200,000, he assumed, lived in the State of Israel, another 150,000 in the United States, and further 50,000 were scattered around the world, especially in Britain, but also in Antwerp, Montreal, Vienna, and other centers. In Israel, the largest Hasidic concentrations are in the Ultra-Orthodox neighbourhoods of Jerusalem – including Ramot Alon, Batei Ungarin et cetera – in the cities of Bnei Brak and El'ad, and in the West Bank settlements of Modi'in Illit and Beitar Illit. There is considerable presence in other specifically Orthodox municipalities or enclaves, like Kiryat Sanz, Netanya. In the United States, most Hasidim reside in New York and New Jersey, though there are small communities across the entire country. In Brooklyn, Borough Park, Williamsburg, and Crown Heights all house a particularly large population. So does the hamlet of Monsey in upstate New York. In the same region, New Square, Monroe, and Kiryas Joel are rapidly growing all-Hasidic enclaves, one founded by the Skver dynasty and the other by Satmar. In Britain, Stamford Hill is home to the largest Hasidic community in the country, and there are others in London and Prestwich in Manchester. In Canada, Kiryas Tosh is a settlement populated entirely by Tosh Hasidim, and there are more adherents of other sects in and around Montreal.

There are more than a dozen Hasidic dynasties with a large following, and over a hundred which have small or minuscule adherence, sometimes below twenty people, with the presumptive "Rebbe" holding the title more as a matter of prestige. Many "courts" became completely extinct during the Holocaust, like the Aleksander (Hasidic dynasty) from Aleksandrów Łódzki, which numbered tens of thousands in 1939, and barely exists today.

The largest sect in the world is Satmar, founded in 1905 in the namesake city in Hungary and based in Williamsburg, Brooklyn and Kiryas Joel. Estimates claim as many as 120,000 adherents of all ages. Satmar is known for its conservatism and opposition to both "Agudas Israel" and Zionism, inspired by the legacy of Hungarian Ultra-Orthodoxy. The sect underwent a schism in 2006 and two competing factions emerged, led by rival brothers Aaron Teitelbaum and Zalman Teitelbaum. The second-largest "court" worldwide is Ger, established in 1859 at Góra Kalwaria, near Warsaw. Ger lists some 10,000 households in its Israel registry alone, and there are more abroad. For decades, it was the dominant power in "Agudas" and espoused a moderate line toward Zionism and modern culture. Its origins lay in the rationalist Przysucha School of Central Poland. The current Rebbe is Yaakov Aryeh Alter. Another major group is Belz, established 1817 in namesake Belz, south of Lviv. An Eastern Galician dynasty drawing both from the Seer of Lublin's charismatic-populist style and "rabbinic" Hasidism, it espoused hard-line positions, but broke off from the Orthodox Council of Jerusalem and joined "Agudas" in 1979. It has between 6,000 and 8,000 affiliated households, and is led by Rebbe Yissachar Dov Rokeach. Yet another large dynasty is Vizhnitz, a charismatic sect founded in 1854 at Vyzhnytsia, Bukovina, to which some 7,000 families belong. A moderate sect involved in Israeli politics, it is split into several branches, which maintain cordial relations. The main partition is between Vizhnitz-Israel and Vizhnitz-Monsey, headed respectively by Rebbes Israel Hager and his uncle Mordecai Hager.

The Bobover dynasty, founded 1881 in Bobowa, West Galicia, claims some 2,000-3,000 households in total and has undergone a bitter succession strife since 2005, eventually forming the "Bobov" and "Bobov-45" sects. Sanz-Klausenburg, divided into a New York and Israeli branches, also purports to preside over 2,000 households. The Skver sect, established in 1848 in Skvyra near Kiev, is likewise claiming 2,000-3,000. The Shomer Emunim dynasties, originating in Jerusalem during the 1920s and known for their unique style of dressing imitating that of the Old Yishuv, have over 1,500-2,000 families, almost all in the larger "courts" of Toldos Aharon and Toldos Avraham Yitzchak. Karlin Stolin, which rose already in the 1760s in a quarter of Pinsk, also encompasses a few thousands of adherents.

There are two other populous Hasidic sub-groups, which do not function as classical "Rebbe"-headed "courts", but as decentralized movements, retaining some of the characteristics of early Hasidism. Breslov rose under its charismatic leader Nachman of Breslov in the early 19th century. Critical of all other "Rebbes", he forbade his followers to appoint a successor upon his death in 1810. His acolytes led small groups of adherents, persecuted by other Hasidim, and disseminated his teachings. The original philosophy of the sect elicited great interest among modern scholars, and that led many newcomers to Orthodox Judaism ("repentants") to join it. Numerous Breslov communities, each led by its own rabbis, now have thousands of full-fledged followers and far more admirers and semi-committed supporters. Chabad-Lubavitch, originating in the 1770s, did have hereditary leadership, but always stressed the importance of self-study rather than reliance on the Righteous. Its seventh and last leader, Menachem Mendel Schneerson, converted it into a vehicle for Jewish outreach. By his death in 1994, it had many more semi-engaged supporters than Hasidim in the strict sense, and they are still hard to distinguish: Estimates for number of Chabad affiliates of all sorts therefore range from 50,000 to 200,000. None succeeded Schneerson, and the sect operates as a large network of communities with independent leaders.

In the late 17th century, several social trends converged among the Jews who inhabited the southern periphery of the Polish–Lithuanian Commonwealth, especially in contemporary Western Ukraine. These enabled the emergence and flourishing of Hasidism.

The first and most prominent was the popularization of the mystical lore of Kabbalah. For several centuries, an esoteric teaching practiced surreptitiously by few, it was transformed into almost household knowledge by a mass of cheap printed pamphlets. The kabbalistic inundation was a major influence behind the rise of the heretical Sabbatean movement, led by Sabbatai Zevi, who declared himself Messiah in 1665. The propagation of Kabbalah made the Jewish masses susceptible to Hasidic ideas, themselves in essence a popularized version of the teaching – indeed, Hasidism actually emerged when its founders determined to openly practice it instead of remaining a secret circle of ascetics as was the manner of almost all past kabbalists. The correlation between publicizing the lore and Sabbateanism did not escape the rabbinic elite, and caused vehement opposition to the new movement.

Another factor was the decline of the traditional authority structures. Jewish autonomy remained quite secured; later research debunked Simon Dubnow's claim that the Council of Four Lands' demise in 1746 was a culmination of a long process which destroyed judicial independence and paved the way for the Hasidic "rebbes" to serve as leaders (another long-held explanation for the sect's rise advocated by Raphael Mahler, that the Khmelnytsky Uprising effected economic impoverishment and despair, was also refuted). However, the magnates and nobles held much sway over the nomination of both rabbis and communal elders, to such a degree that the masses often perceived them as mere lackeys of the land owners. Their ability to serve as legitimate arbiters in disputes – especially those concerning the regulation of leasehold rights over alcohol distillation and other monopolies in the estates – was severely diminished. The reduced prestige of the establishment, and the need for an alternative source of authority to pass judgement, left a vacuum which Hasidic charismatics eventually filled. They transcended old communal institutions, to which all the Jews of a locality were subordinate, and had groups of followers in each town across vast territories. Often supported by rising strata outside the traditional elite, whether nouveau riche or various low-level religious functionaries, they created a modern form of leadership.

Historians discerned other influences. The formative age of Hasidism coincided with the rise of numerous religious revival movements across the world, including the First Great Awakening in New England, German Pietism, Wahhabism in Arabia and the Russian Old Believers who opposed the established church. They all rejected the existing order, decrying it as stale and overly hierarchic. They offered what they described as more spiritual, candid and simple substitutes. Gershon David Hundert noted the considerable similarity between the Hasidic conceptions and this general background, rooting both in the growing importance attributed to the individual's consciousness and choices.

Israel ben Eliezer (ca. 1690–1760), known as the "Baal Shem Tov" ("Master of the "Good" Name", Acronym: "Besht"), is considered the founder of Hasidism. Born apparently south of the Prut, in the northern frontier of Moldavia, he earned a reputation as a Baal Shem, "Master of the Name". These were common folk healers who employed mysticism, amulets and incantations at their trade. Little is known for certain on ben Eliezer. Though no scholar, he was sufficiently learned to become notable in the communal hall of study and marry into the rabbinic elite, his wife being the divorced sister of a rabbi; in his later years he was wealthy and famous, as attested by contemporary chronicles. Apart from that, most is derived from Hasidic hagiographic accounts. These claim that as a boy he was recognized by one "Rabbi Adam Baal Shem Tov" who entrusted him with great secrets of the Torah passed in his illustrious family for centuries. the Besht later spent a decade in the Carpathian Mountains as a hermit, where he was visited by the Biblical prophet Ahijah the Shilonite who taught him more. At the age of thirty-six, he was granted heavenly permission to reveal himself as a great kabbalist and miracle worker.

By the 1740s, it is verified that he relocated to the town of Medzhybizh and became recognized and popular in all Podolia and beyond. It is well attested that he did emphasize several known kabbalistic concepts, formulating a teaching of his own to some degree. The Besht stressed the immanence of God and His presence in the material world, and that therefore, physical acts, such as eating, have actual influence on the spiritual sphere and may serve to hasten the achievement of communion with the divine ("devekut"). He was known to pray ecstatically and with great intention, again in order to provide channels for the divine light to flow into the earthly realm. The Besht stressed the importance of joy and contentment in the worship of God, rather than the abstinence and self-mortification deemed essential to become a pious mystic, and of fervent and vigorous prayer as a means of spiritual elation instead of severe aestheticism – though many of his immediate disciples reverted in part to the older doctrines, especially in disavowing sexual pleasure even in marital relations. In that, the "Besht" laid the foundation for a popular movement, offering a far less rigorous course for the masses to gain a significant religious experience. And yet, he remained the guide of a small society of elitists, in the tradition of former kabbalists, and never led a large public as his successors did. While many later figures cited him as the inspiration behind the full-fledged Hasidic doctrine, the Besht himself did not practice it in his lifetime.

Israel ben Eliezer gathered a considerable following, drawing to himself disciples from far away. They were largely of elitist background, yet adopted the populist approach of their master. The most prominent was Rabbi Dov Ber the "Maggid" (preacher). He succeeded the former upon his death, though other important acolytes, mainly Jacob Joseph of Polonne, did not accept his leadership. Establishing himself in Mezhirichi, the Maggid turned to greatly elaborate the Besht's rudimentary ideas and institutionalize the nascent circle into an actual movement. Ben Eliezer and his acolytes used the very old and common epithet "hasidim", "pious"; in the latter third of the 18th century, a clear differentiation arose between that sense of the word and what was at first described as "New Hasidism", propagated to a degree by the Maggid and especially his successors.

Doctrine coalesced as Jacob Joseph, Dov Ber and the latter's disciple Rabbi Elimelech of Lizhensk composed the three magna opera of early Hasidism, respectively: the 1780 "Toldot Ya'akov Yosef", the 1781 "Maggid d'varav le-Ya'akov" and the 1788 "No'am Elimelekh". Other books were also published. Their new teaching had many aspects. The importance of devotion in prayer was stressed to such degree that many waited beyond the prescribed time to properly prepare; the Besht's recommendation to "elevate and sanctify" impure thoughts rather than simply repress them during the service was expanded by Dov Ber into an entire precept, depicting prayer as a mechanism to transform thoughts and feelings from a primal to a higher state in a manner parallel to the unfolding of the "Sephirot". But the most important was the notion of the "Tzaddiq" – later designated by the general rabbinic honorific "Admor" (our master, teacher and rabbi) or by the colloquial "Rebbe" – the Righteous One, the mystic who was able to elate and achieve communion with the divine, but unlike kabbalists past, did not practice it in secret, but as leader of the masses. He was able to bring down prosperity and guidance from the higher "Sephirot", and the common people who could not attain such a state themselves would achieve it by "clinging" to and obeying him. The "Tzaddiq" served as a bridge between the spiritual realm and the ordinary folk, as well as a simple, understandable embodiment of the esoteric teachings of the sect, which were still beyond the reach of most just as old-style Kabbalah before.

The various Hasidic "Tzaddiqim", mainly the Maggid's disciples, spread across Eastern Europe with each gathering adherents among the people and learned acolytes who could be initiated as leaders. The Righteous' "courts" in which they resided, attended by their followers to receive blessing and council, became the institutional centers of Hasidism, serving as its branches and organizational core. Slowly, various rites emerged in them, like the Sabbath "Tisch" or "table", in which the Righteous would hand out food scraps from their meals, considered blessed by the touch of ones imbued with godly Light during their mystical ascensions. Another potent institution was the "Shtibel", the private prayer gatherings opened by adherents in every town which served as a recruiting mechanism. The "Shtibel" differed from the established synagogues and study halls, allowing their members greater freedom to worship when they pleased and also serving recreational and welfare purposes. Combined with its simplified message, more appealing to the common man, its honed organizational framework accounted for the exponential growth of Hasidic ranks. Having ousted the old communal model and replaced it with a less-hierarchical structure and more individually-oriented religiosity, Hasidism was in fact the first great modern – albeit not modernist; its self-understanding was grounded in a traditional mindset – Jewish movement.

From its original base in Podolia and Volhynia, the movement was rapidly disseminated during the Maggid's lifetime and after his 1772 death. Twenty or so of Dov Ber's prime disciples each brought it to a different region, and their own successors followed: Aharon of Karlin (I), Menachem Mendel of Vitebsk and Shneur Zalman of Liadi were the emissaries to the former Lithuania in the far north, while Menachem Nachum Twersky headed to Chernobyl in the east and Levi Yitzchok of Berditchev remained nearby. Elimelech of Lizhensk, his brother Zusha of Hanipol and Yisroel Hopsztajn established the sect in Poland proper. Vitebsk and Abraham Kalisker later led a small ascension to the Land of Israel, establishing a Hasidic presence in the Galilee.

The spread of Hasidism also incurred organized opposition. Rabbi Elijah of Vilnius, one the greatest authorities of the generation and a "hasid" and secret kabbalist of the old style, was deeply suspicious of their emphasis on mysticism rather than mundane Torah study, threat to established communal authority, resemblance to the Sabbatean movement and other details he considered infractions. In April 1772, He and the Vilnius community wardens launched a systematic campaign against the sect, placing an anathema upon them, banishing their leaders and sending letters denouncing the movement. Further excommunication followed in Brody and other cities. In 1781, during a second round of hostilities, the books of Jacob Joseph were burned in Vilnius. Another cause for strife emerged when the Hasidim adopted the Lurianic prayer rite, which they revised somewhat to Nusach Sefard; the first edition in Eastern Europe was printed in 1781 and received approbation from the anti-Hasidic scholars of Brody, but the sect quickly embraced the Kabbalah-infused tome and popularized it, making it their symbol. Their rivals, named "Misnagdim", "opponents" (a generic term which acquired an independent meaning as Hasidism grew stronger) soon accused them of abandoning the traditional Nusach Ashkenaz.

In 1798, Opponents made accusations of espionage against Shneur Zalman of Liadi and he was imprisoned by the Russian government for two months. Excoriatory polemics were printed and anathemas declared in the entire region. But Elijah's death in 1797 denied the "Misnagdim" their powerful leader. In 1804, Alexander I of Russia allowed independent prayer groups to operate, the chief vessel through which the movement spread from town to town. The failure to eradicate Hasidism, which acquired a clear self-identity in the struggle and greatly expanded throughout it, convinced its adversaries to adopt a more passive method of resistance, as exemplified by Chaim of Volozhin. The growing conservatism of the new movement – which at some occasions drew close to Kabbalah-based antinomian phraseology, as did the Sabbateans, but never crossed the threshold and remained thoroughly observant – and the rise of common enemies slowly brought a rapprochement, and by the second half of the 19th century both sides basically considered each other legitimate.

The turn of the century saw several prominent new, fourth-generation "tzaddiqim". Upon Elimelech's death in the now-partitioned Poland, his place in Habsburg Galicia was assumed by Menachem Mendel of Rimanov, who was deeply hostile to the modernization the Austrian rulers attempted to force on the traditional Jewish society (though this same process also allowed his sect to flourish, as communal authority was severely weakened). The rabbi of Rimanov hearkened the alliance the hasidim would form with the most conservative elements of the Jewish public. In Central Poland, the new leader was Jacob Isaac Horowiz, the "Seer of Lublin", who was of a particularly populist bent and appealed to the common folk with miracle working and little strenuous spiritual demands. The Seer's senior acolyte, Jacob Isaac Rabinovitz the "Holy Jew" of Przysucha, gradually dismissed his mentor's approach as overly vulgar and adopted a more aesthetic and scholarly approach, virtually without theurgy to the masses. The Holy Jew's "Przysucha School" was continued by his successor Simcha Bunim and especially the reclusive, morose Menachem Mendel of Kotzk. The most controversial fourth-generation "tzaddiq" was the Podolia-based Nachman of Breslov, who denounced his peers for becoming too institutionalized, much like the old establishment their predecessors challenged decades before, and espoused an anti-rationalist, pessimistic spiritual teaching, very different from the prevalent stress on joy.

The opening of the 19th century saw the Hasidic sect transformed. Once a rising force outside the establishment, the "tzaddiqim" now became an important and often dominant power in most of Eastern Europe. The slow process of encroachment, which mostly begun with forming an independent "Shtibel" and culminated in the Righteous becoming an authority figure (either alongside or above the official rabbinate) for the entire community, overwhelmed many towns even in "Misnagdic" stronghold of Lithuania, far more so in Congress Poland and the vast majority in Podolia, Volhynia and Galicia. It began to make inroads into Bukovina, Bessarabia and the westernmost frontier of autochthonic pre-WWII Hasidism, in northeastern Hungary, where the Seer's disciple Moses Teitelbaum (I) was appointed in Ujhely.

Less than three generations after the Besht's death, the sect grew to encompass hundreds of thousands by 1830. As a mass movement, a clear stratification emerged between the court's functionaries and permanent residents ("yoshvim", "sitters"), the devoted followers who would often visit the Righteous on Sabbath, and the large public which prayed at Sefard Rite synagogues and was minimally affiliated.

All this was followed by a more conservative approach and power bickering among the Righteous. Since the Maggid's death, none could claim the overall leadership. Among the several dozens active, each ruled over his own turf, and local traditions and customs began to emerge in the various courts which developed their own identity. The high mystical tension typical of a new movement subsided, and was soon replaced by more hierarchical, orderly atmosphere.

The most important aspect of the routinization Hasidism underwent was the adoption of dynasticism. The first to claim legitimacy by right of descent from the Besht was his grandson, Boruch of Medzhybizh, appointed 1782. He held a lavish court with Hershel of Ostropol as jester, and demanded the other Righteous acknowledge his supremacy. Upon the death of Menachem Nachum Twersky of Chernobyl, his son Mordechai Twersky succeeded him. The principle was conclusively affirmed in the great dispute after Liadi's demise in 1813: his senior acolyte Aharon HaLevi of Strashelye was defeated by his son, Dovber Schneuri, whose offspring retained the title for 181 years.

By the 1860s, virtually all courts were dynastic. Rather than single "tzaddiqim" with followings of their own, each sect would command a base of rank-and-file hasidim attached not just to the individual leader, but to the bloodline and the court's unique attributes. Israel Friedman of Ruzhyn insisted on royal splendour, resided in a palace and his six sons all inherited some of his followers. With the constraints of maintaining their gains replacing the dynamism of the past, the Righteous or "Rebbe"s/"Admorim" also silently retreated from the overt, radical mysticism of their predecessors. While populist miracle working for the masses remained a key theme in many dynasties, a new type of "Rebbe-Rabbi" emerged, one who was both a completely traditional "halakhic" authority as well as a spiritualist. The tension with the "Misnagdim" subsided significantly.

But it was an external threat, more than anything else, that mended relations. While traditional Jewish society remained well entrenched in backward Eastern Europe, reports of the rapid acculturation and religious laxity in the West troubled both camps. When the "Haskalah", the Jewish Enlightenment, appeared in Galicia and Congress Poland in the 1810s, it was soon perceived as a dire threat. The "maskilim" themselves detested Hasidism as an anti-rationalist and barbaric phenomenon, as did Western Jews of all shades, including the most right-wing Orthodox such as Rabbi Azriel Hildesheimer. In Galicia especially, hostility towards it defined the "Haskalah" to a large extent, from the staunchly observant Rabbi Zvi Hirsch Chajes and Joseph Perl to the radical anti-Talmudists like Osias Schorr. The Enlightened, who revived Hebrew grammar, often mocked their rivals' lack of eloquence in the language. While a considerable proportion of the "Misnagdim" were not adverse to at least some of the "Haskala"'s goals, the "Rebbe"s were unremittingly hostile.

The most distinguished Hasidic leader in Galicia in the era was Chaim Halberstam, who combined talmudic erudition and the status of a major decisor with his function as "tzaddiq". He symbolized the new era, brokering peace between the small Hasidic sect in Hungary to its opponents. At that country, where modernization and assimilation were much more imminent than in the East, the local Righteous joined forces with those now termed Orthodox against the rising liberals. Rabbi Moses Sofer of Pressburg, while no friend to Hasidism, tolerated it as he combated the forces which sought modernization of the Jews; a generation later, in the 1860s, the "Rebbe"s and the zealot ultra-Orthodox Hillel Lichtenstein allied closely.

Around the mid-19th century, over a hundred dynastic courts related by marriage were the main religious power in the territory enclosed between Hungary, former Lithuania, Prussia and inner Russia, with considerable presence in the former two. In Central Poland, the pragmatist, rationalist Przysucha school thrived: Yitzchak Meir Alter founded the court of Ger in 1859, and in 1876 Jechiel Danziger established Alexander. In Galicia and Hungary, apart from Halberstam's House of Sanz, Tzvi Hirsh of Zidichov's descendants each pursued a mystical approach in the dynasties of Zidichov, Komarno and so forth. In 1817, Sholom Rokeach became the first "Rebbe" of Belz. At Bukovina, the Hager line of Kosov-Vizhnitz was the largest court.

The "Haskalah" was always a minor force, but the Jewish national movements which emerged in the 1880s, as well as Socialism, proved much more appealing to the young. Progressive strata condemned Hasidism as a primitive relic, strong, but doomed to disappear, as Eastern European Jewry underwent slow yet steady secularization. The gravity of the situation was attested to by the foundation of Hasidic yeshivas (in the modern, boarding school-equivalent sense) to enculturate the young and preserve their loyalty: The first was established at Nowy Wiśnicz by Rabbi Shlomo Halberstam (I) in 1881. These institutions were originally utilized by the "Misnagdim" to inoculate their youth from Hasidic influence, but now, the latter faced a similar crisis. One of the most contentious issues in this respect was Zionism; the Ruzhin dynasties were quite favourably disposed toward it, while Hungarian and Galician courts reviled it.

Outside pressure was mounting in the early 20th century. In 1912, many Hasidic leaders partook in the creation of the Agudas Israel party, a political instrument intended to safeguard what was now named Orthodox Judaism even in the relatively traditional East; the more hard-line dynasties, mainly Galician and Hungarian, opposed the Aguda as too lenient. Mass immigration to America, urbanization, World War I and the subsequent Russian Civil War uprooted the "shtetl"s in which the local Jews lived for centuries and were the bedrock of Hasidism. In the new Soviet Union, civil equality first achieved and a harsh repression of religion caused a rapid secularization. Few remaining Hasidim, especially of Chabad, continued to practice underground for decades. In the new states of the Interbellum era, the process was only somewhat slower. On the eve of World War II, strictly observant Jews were estimated to constitute no more than a third of the total Jewish population in Poland, the world's most Orthodox country. While the Rebbes still had a vast base of support, it was aging and declining.

The Holocaust hit the Hasidim, easily identifiable and almost unable to disguise themselves among the larger populace due to cultural insularity, particularly hard. Hundreds of leaders perished with their flock, while the flight of many notable ones as their followers were being exterminated – especially Aharon Rokeach of Belz and Joel Teitelbaum of Satmar – elicited bitter recrimination. In the immediate post-war years, the entire movement seemed to teeter on the precipice of oblivion. In Israel, the United States, and Western Europe, the survivors' children were at best becoming Modern Orthodox. While a century earlier the "Haskalah" depicted it as a medieval, malicious power, now it was so weakened that the popular cultural image was sentimental and romantic, what Joseph Dan termed "Frumkinian Hasidism" for it began with the short stories of Michael Levi Rodkinson (Frumkin). Martin Buber was the major contributor to this trend, portraying the sect as a model of a healthy folk consciousness. "Frumkinian" style was very influential, later inspiring the so-called "Neo-Hasidism", and also utterly ahistorical.

Yet, the movement proved more resilient than expected. Talented and charismatic Hasidic masters emerged, who reinvigorated their following and drew new crowds. In New York, the Satmar Rebbe Joel Teitelbaum formulated a fiercely anti-Zionist Holocaust theology and founded an insular, self-sufficient community which attracted many immigrants from Greater Hungary; already by 1961, 40% of families were newcomers. Yisrael Alter of Ger created robust institutions, fortified his court's standing in "Agudas Israel" and held "tisch" every week for 29 years. He halted the hemorrhage of his followers and retrieved many Litvaks (the contemporary, less adverse epithet for "Misnagdim") and Religious Zionists whose parents were Gerrer Hasidim before the war. Chaim Meir Hager similarly restored Vizhnitz. Moses Isaac Gewirtzman founded the new Pshevorsk (Hasidic dynasty) in Antwerp.

The most explosive growth was experienced in Chabad-Lubavitch, whose head Menachem Mendel Schneerson adopted a modern (he and his disciples ceased wearing the customary Shtreimel) and outreach-centered orientation. At a time when most Orthodox and Hasidim in particular rejected proselytization, he turned his sect into a mechanism devoted almost solely to it, blurring the difference between actual Hasidim and loosely affiliated supporters until researchers could scarcely define it as a regular Hasidic group. Another phenomenon was the revival of Breslov, which remained without an acting "Tzaddiq" since the rebellious Rebbe Nachman's 1810 death. Its complex, existentialist philosophy drew many to it.

Exorbitant fertility rates, increasing tolerance and multiculturalism on behalf of surrounding society, and the great wave of newcomers to Orthodox Judaism which began in the 1970s all cemented the movement's status as very much alive and thriving. The clearest indication for that, noted Joseph Dan, was the disappearance of the "Frumkinian" narrative which inspired much sympathy towards it from non-Orthodox Jews and others, as actual Hasidism returned to the fore. It was replaced by apprehension and concern due to the growing presence of the reclusive, strictly religious Hasidic lifestyle in the public sphere, especially in Israel. As numbers grew, "courts" were again torn apart by schisms between Rebbes' sons vying for power, a common occurrence during the golden age of the 19th century.



</doc>
<doc id="14439" url="https://en.wikipedia.org/wiki?curid=14439" title="Harmonic series (music)">
Harmonic series (music)

A harmonic series is the sequence of sounds—pure tones, represented by sinusoidal waves—in which the frequency of each sound is an integer multiple of the fundamental, the lowest frequency.

Pitched musical instruments are often based on an acoustic resonator such as a string or a column of air, which oscillates at numerous modes simultaneously. At the frequencies of each vibrating mode, waves travel in both directions along the string or air column, reinforcing and canceling each other to form standing waves. Interaction with the surrounding air causes audible sound waves, which travel away from the instrument. Because of the typical spacing of the resonances, these frequencies are mostly limited to integer multiples, or harmonics, of the lowest frequency, and such multiples form the harmonic series (see harmonic series (mathematics)).

The musical pitch of a note is usually perceived as the lowest partial present (the fundamental frequency), which may be the one created by vibration over the full length of the string or air column, or a higher harmonic chosen by the player. The musical timbre of a steady tone from such an instrument is strongly affected by the relative strength of each harmonic.

A "complex tone" (the sound of a note with a timbre particular to the instrument playing the note) "can be described as a combination of many simple periodic waves (i.e., sine waves) or "partials," each with its own frequency of vibration, amplitude, and phase." (See also, Fourier analysis.)

A partial is any of the sine waves (or "simple tones", as Ellis calls them when translating Helmholtz) of which a complex tone is composed, not necessarily with an integer multiple of the lowest harmonic.

A harmonic is any member of the harmonic series, an ideal set of frequencies that are positive integer multiples of a common fundamental frequency. The fundamental is obviously a harmonic because it is 1 times itself. A harmonic partial is any real partial component of a complex tone that matches (or nearly matches) an ideal harmonic.

An inharmonic partial is any partial that does not match an ideal harmonic. "Inharmonicity" is a measure of the deviation of a partial from the closest ideal harmonic, typically measured in cents for each partial.

Many pitched acoustic instruments are designed to have partials that are close to being whole-number ratios with very low inharmonicity; therefore, in music theory, and in instrument design, it is convenient, although not strictly accurate, to speak of the partials in those instruments' sounds as "harmonics", even though they may have some degree of inharmonicity. The piano, one of the most important instruments of western tradition, contains a certain degree of inharmonicity among the frequencies generated by each string. Other pitched instruments, especially certain percussion instruments, such as marimba, vibraphone, tubular bells, timpani, and singing bowls contain mostly inharmonic partials, yet may give the ear a good sense of pitch because of a few strong partials that resemble harmonics. Unpitched, or indefinite-pitched instruments, such as cymbals, gongs, or tam-tams make sounds (produce spectra) that are rich in inharmonic partials and may give no impression of implying any particular pitch.

An overtone is any partial above the lowest partial. The term overtone does not imply harmonicity or inharmonicity and has no other special meaning other than to exclude the fundamental. It is mostly the relative strength of the different overtones that give an instrument its particular timbre, tone color, or character. When writing or speaking of overtones and partials numerically, care must be taken to designate each correctly to avoid any confusion of one for the other, so the second overtone may not be the third partial, because it is the second sound in a series.
Some electronic instruments, such as synthesizers, can play a pure frequency with no overtones (a sine wave). Synthesizers can also combine pure frequencies into more complex tones, such as to simulate other instruments. Certain flutes and ocarinas are very nearly without overtones.

The simplest case to visualise is a vibrating string, as in the illustration; the string has fixed points at each end, and each harmonic mode divides it into 1, 2, 3, 4, etc., equal-sized sections resonating at increasingly higher frequencies. Similar arguments apply to vibrating air columns in wind instruments (for example, "the French horn was originally a valveless instrument that could play only the notes of the harmonic series"), although these are complicated by having the possibility of anti-nodes (that is, the air column is closed at one end and open at the other), conical as opposed to cylindrical bores, or end-openings that run the gamut from no flare, cone flare, or exponentially shaped flares (such as in various bells).

In most pitched musical instruments, the fundamental (first harmonic) is accompanied by other, higher-frequency harmonics. Thus shorter-wavelength, higher-frequency waves occur with varying prominence and give each instrument its characteristic tone quality. The fact that a string is fixed at each end means that the longest allowed wavelength on the string (which gives the fundamental frequency) is twice the length of the string (one round trip, with a half cycle fitting between the nodes at the two ends). Other allowed wavelengths are 1/2, 1/3, 1/4, 1/5, 1/6, etc. times that of the fundamental.

Theoretically, these shorter wavelengths correspond to vibrations at frequencies that are 2, 3, 4, 5, 6, etc., times the fundamental frequency. Physical characteristics of the vibrating medium and/or the resonator it vibrates against often alter these frequencies. (See inharmonicity and stretched tuning for alterations specific to wire-stringed instruments and certain electric pianos.) However, those alterations are small, and except for precise, highly specialized tuning, it is reasonable to think of the frequencies of the harmonic series as integer multiples of the fundamental frequency.

The harmonic series is an arithmetic series (1×f, 2×f, 3×f, 4×f, 5×f, ...). In terms of frequency (measured in cycles per second, or hertz (Hz) where f is the fundamental frequency), the difference between consecutive harmonics is therefore constant and equal to the fundamental. But because human ears respond to sound nonlinearly, higher harmonics are perceived as "closer together" than lower ones. On the other hand, the octave series is a geometric progression (2×f, 4×f, 8×f, 16×f, ...), and people hear these distances as "the same" in the sense of musical interval. In terms of what one hears, each octave in the harmonic series is divided into increasingly "smaller" and more numerous intervals.

The second harmonic, whose frequency is twice of the fundamental, sounds an octave higher; the third harmonic, three times the frequency of the fundamental, sounds a perfect fifth above the second harmonic. The fourth harmonic vibrates at four times the frequency of the fundamental and sounds a perfect fourth above the third harmonic (two octaves above the fundamental). Double the harmonic number means double the frequency (which sounds an octave higher).

As Mersenne says, "the order of the Consonances is natural, and...the way we count them, starting from unity up to the number six and beyond is founded in nature."

If the harmonics are octave displaced and compressed into the span of one octave, some of them are approximated by the notes of what the West has adopted as the chromatic scale based on the fundamental tone. The Western chromatic scale has been modified into twelve equal semitones, which is slightly out of tune with many of the harmonics, especially the 7th, 11th, and 13th harmonics. In the late 1930s, composer Paul Hindemith ranked musical intervals according to their relative dissonance based on these and similar harmonic relationships.

Below is a comparison between the first 31 harmonics and the intervals of 12-tone equal temperament (12TET), octave displaced and compressed into the span of one octave. Tinted fields highlight differences greater than 5 cents (1/20th of a semitone), which is the human ear's "just noticeable difference" for notes played one after the other (smaller differences are noticeable with notes played simultaneously).

The frequencies of the harmonic series, being integer multiples of the fundamental frequency, are naturally related to each other by whole-numbered ratios and small whole-numbered ratios are likely the basis of the consonance of musical intervals (see just intonation). This objective structure is augmented by psychoacoustic phenomena. For example, a perfect fifth, say 200 and 300 Hz (cycles per second), causes a listener to perceive a combination tone of 100 Hz (the difference between 300 Hz and 200 Hz); that is, an octave below the lower (actual sounding) note. This 100 Hz first-order combination tone then interacts with both notes of the interval to produce second-order combination tones of 200 (300 – 100) and 100 (200 – 100) Hz and all further nth-order combination tones are all the same, being formed from various subtraction of 100, 200, and 300. When one contrasts this with a dissonant interval such as a tritone(not tempered) with a frequency ratio of 7:5 one gets, for example, 700 – 500 = 200 (1st order combination tone) and 500 – 200 = 300 (2nd order). The rest of the combination tones are octaves of 100 Hz so the 7:5 interval actually contains 4 notes: 100 Hz (and its octaves), 300 Hz, 500 Hz and 700 Hz. Note that the lowest combination tone (100 Hz) is a 17th (2 octaves and a major third) below the lower (actual sounding) note of the tritone. All the intervals succumb to similar analysis as has been demonstrated by Paul Hindemith in his book "The Craft of Musical Composition", although he rejected the use of harmonics from the 7th and beyond.

The mixolydian mode is consonant with the first 10 harmonics of the harmonic series (the 11th harmonic, a tritone, is not in the mixolydian mode). The ionian mode is consonant with only the first 6 harmonics of the series (the 7th harmonic, a minor seventh, is not in the ionian mode).

The relative amplitudes (strengths) of the various harmonics primarily determine the timbre of different instruments and sounds, though onset transients, formants, noises, and inharmonicities also play a role. For example, the clarinet and saxophone have similar mouthpieces and reeds, and both produce sound through resonance of air inside a chamber whose mouthpiece end is considered closed. Because the clarinet's resonator is cylindrical, the even-numbered harmonics are less present. The saxophone's resonator is conical, which allows the even-numbered harmonics to sound more strongly and thus produces a more complex tone. The inharmonic ringing of the instrument's metal resonator is even more prominent in the sounds of brass instruments.

Human ears tend to group phase-coherent, harmonically-related frequency components into a single sensation. Rather than perceiving the individual partials–harmonic and inharmonic, of a musical tone, humans perceive them together as a tone color or timbre, and the overall pitch is heard as the fundamental of the harmonic series being experienced. If a sound is heard that is made up of even just a few simultaneous sine tones, and if the intervals among those tones form part of a harmonic series, the brain tends to group this input into a sensation of the pitch of the fundamental of that series, even if the fundamental is not present.

Variations in the frequency of harmonics can also affect the "perceived" fundamental pitch. These variations, most clearly documented in the piano and other stringed instruments but also apparent in brass instruments, are caused by a combination of metal stiffness and the interaction of the vibrating air or string with the resonating body of the instrument.

David Cope (1997) suggests the concept of interval strength, in which an interval's strength, consonance, or stability (see consonance and dissonance) is determined by its approximation to a lower and stronger, or higher and weaker, position in the harmonic series. See also: Lipps–Meyer law.

Thus, an equal-tempered perfect fifth () is stronger than an equal-tempered minor third (), since they approximate a just perfect fifth () and just minor third (), respectively. The just minor third appears between harmonics 5 and 6 while the just fifth appears lower, between harmonics 2 and 3.





</doc>
<doc id="14441" url="https://en.wikipedia.org/wiki?curid=14441" title="Hasid (term)">
Hasid (term)

Hasid (, "pious"; plural "Hasidim", חסידים) is a Jewish honorific, frequently used as a term of exceptional respect in the Talmudic and early medieval periods. In classic Rabbinic literature it differs from "Tzadik"-"righteous", by instead denoting one who goes beyond the legal requirements of ritual and ethical Jewish observance in daily life. The literal meaning of "Hasid" derives from Chesed-"kindness", the outward expression of love for God and other people. This spiritual devotion motivates pious conduct beyond everyday limits. The devotional nature of its description lent itself to a few Jewish movements in history being known as "Hasidim". Two of these derived from the Jewish mystical tradition, as it could tend towards piety over legalism.

As a personal honorific, both "Hasid" and "Tzadik" could be applied independently to a same individual with both different qualities. The 18th-century Vilna Gaon, for instance, while the head of opposition to the new Jewish mystical movement that became known as "Hasidism", was renowned for his righteous life. His scholarship became popularly honored with the formal title of "Genius", while amongst the Hasidic movement's leadership, despite his fierce opposition, he was respectfully referred to as "The Gaon, the Hasid from Vilna".

In the aggregate, it may refer to members of any of the following Jewish movements:


</doc>
<doc id="14443" url="https://en.wikipedia.org/wiki?curid=14443" title="Hoosier Hysteria">
Hoosier Hysteria

Hoosier Hysteria is the state of excitement surrounding basketball in Indiana, or more specifically the Indiana high school basketball tournament. In part, the excitement stemmed from the inclusion of all tournament entrants into the same tournament, where a small town's David might knock off a large city's Goliath. The most famous example occurred in 1954, when Milan (enrollment 161) defeated Muncie Central (enrollment over 1,600) to win the State title. The plot of the now famous movie, "Hoosiers", was based on the story of the 1954 Milan team and seems to typify the hysteria related to basketball in the state of Indiana.

Indiana's passion for basketball was observed and written about by basketball's inventor, James Naismith. In 1925, Naismith visited an Indiana basketball state finals game along with 15,000 screaming fans and later wrote, that while it was invented in Massachusetts, "basketball really had its origin in Indiana, which remains the center of the sport." Hoosiers have a traditional love for basketball similar to that of Southerners or Ohioans for football, Pennsylvanians for wrestling, and Minnesotans for ice hockey.

Indiana high schools boast a tradition of producing top caliber basketball players. Through the 2009-2010 NBA season, 152 Hoosier athletes have played professional basketball in the world's top league. Considering the size of the state (population 6.4 million), this makes Indiana high schools by far the most successful at developing NBA players per capita. Today there are 22 Hoosiers in the NBA - more than one for every 150,000 male residents. The state's unparalleled ability to produce NBA talent, both statewide and specifically in smaller towns, is featured in this Deadspin article. In 2017, Indiana natives won the NBA and D-league Dunk Contests, NBA and D-league 3-pont contests, and won runner-up in the NBA Skills Challenge.

Historically, each of the several hundred small towns of Indiana had its own small school system. Before consolidation of many of these rural school districts in the last half of the twentieth century, Indiana high schools had fewer students than those of most other states; basketball was a natural game for these schools since it only required five starters and a few reserves. Even one or two great basketball players could make a high school team a powerhouse, and nearly every Indiana town dreamt of such glory.

The Franklin Wonder Five was the first team to win the state championship in three consecutive years, from 1920-1922. This accomplishment would not be matched for over six decades. The team was led by Fuzzy Vandivier.

After Milan's Miracle in the 1950s, no school with an enrollment of less than 500 won another boys' State title under the all-comers format. As school consolidation became more common and as more rural residents migrated to cities making large high schools grow even larger, smaller high schools had only a mismatch to look forward to come tournament time, as success concentrated in Indiana's large urban and suburban schools. Starting with the 1997-1998 season, Indiana established a controversial four-class system for its basketball championship, although many other sports remain single-class. The state's move to this new system has, to some extent, diminished the phenomenon and public opinion is widely split on the merits of "class basketball."

Aside from the "Milan Miracle," the story of Crispus Attucks High School ranks as one of the greatest in Indiana high school basketball tradition. In 1955, the year after Attucks had lost in the semistate final (state quarterfinals) to Milan's championship team, Attucks gained fame by winning the Indiana state championship, becoming the first all-black school in the nation to win a state title open to all schools regardless of race. Crispus Attucks repeated as champions in 1956, becoming the first Indiana high school team to complete a season undefeated. The Attucks teams of 1954 through 1956 were led by Oscar Robertson. Both stories, Milan and Crispus Attucks, are memorialized for their accomplishments and tradition at the Indiana State Museum as well as at the Indiana Basketball Hall of Fame in New Castle, Indiana.

A highlight of the single-class tournament was the 1990 State Championship game, in which the paid attendance was over 40,000 fans. This phenomenal turnout of fans who witnessed Damon Bailey's Bedford-North Lawrence Stars win the State Championship stands as the largest crowd ever to witness a high school basketball game.

After the 1997 season (when Bloomington North won the final single-class State Championship), the IHSAA controversially did away with the single-class system, ending the run of single-class champions in Indiana. There are many in Indiana who lament this loss, and who know that Hoosier Hysteria has been dramatically and significantly lessened thereby. Hoosier Hysteria has not completely diminished however. For example, in 2003, DeKalb High School (1200 students) nearly defeated Pike High School (3000) students). Also, the Indiana tournament is still the most attended in the nation, with final four games for the two larger divisions regularly selling out Bankers Life Fieldhouse (formerly Conseco Fieldhouse).

Perhaps one of the more telling signs of the passion and commitment to basketball at the high school level is the number and size of large basketball gymnasiums in the state. With considerable cost and effort, Indiana boasts nine of the ten largest high school gyms in the country, and a purported eighteen of the top twenty. Seventeen venues in Indiana today boast a capacity of over 6,000, the largest being the New Castle Fieldhouse, seating 9,325.

Hoosier Hysteria may have its roots firmly planted in the high school game, but the college tradition brings its own depth to Indiana's passion. In NCAA Division I basketball, Indiana's colleges and universities have a storied past. Big Ten rivals Purdue University and Indiana University are the most notable, with national and conference championships to boast. Smaller schools such as the University of Notre Dame, Indiana State University, Ball State University, Butler University, the University of Evansville, IUPUI, Purdue Fort Wayne, and Valparaiso University add to the mix. Vincennes University boasts an outstanding national tradition in the junior college ranks. And in Division II St. Joseph's, University of Indianapolis and University of Southern Indiana have added their own successes to the legend of Indiana basketball. Wabash College won the Men's Division III NCAA Championship in 1982 and their 1905 24-0 team was considered World Champions; DePauw University and Manchester College were Div III National Finalists. It is safe to say that the terms "Final Four" and "March Madness" have grown out of the tradition of Hoosier Hysteria.

The Ball State Cardinals have won several conference championships and earned a number of NCAA Tournament berths over the years, including:



Indiana's collegiate basketball squad, the Indiana Hoosiers men's basketball team has several championships to their credit:


The Hoosiers' five NCAA Championships are the fourth in history, tied with Duke, and trailing UCLA (11) Kentucky (8) and North Carolina (6). Their eight trips to the Final Four ranks seventh on the all-time list. The Hoosiers have made 32 appearances in the NCAA Division I Men's Basketball Tournament (fifth-most in NCAA history). In those 32 appearances, Indiana has posted 52 victories, the sixth-most in NCAA history.



With their only men's national championship coming in the days before the NCAA Tournament, the Purdue Boilermakers have a basketball history:

The Boilermaker women have one National Championship (1999), one national runner-up finish (2001 to Notre Dame), seven Big Ten Championships, and have won six of the thirteen women's Big Ten Tournaments.

They are members of the Great Lakes Valley Conference, the top Division II conference in the nation.

The University of Indianapolis Greyhounds have a storied basketball history. The Greyhounds were led by UIndy Hall of Famer Angus Nicoson throughout the 1950s and 60s, and Nicoson's teams won 8 Hoosier Conference Championships. More recent success has seen the Hounds ranked #1 in the country in Division II basketball in 2014, led by former USI standout, Stan Gouard.



The Vincennes University men's basketball program is the 4th winningest junior college program in the country, with 1,470 victories. The Trailblazers trail Southeastern Iowa Community College (1,519), Moberly, Mo., (1,505) and Hutchinson, Kan., with 1,490.
The Trailblazers' 3 National Titles place them 3rd in titles behind Moberly Area Community College and San Jacinto College - Central, which each have four titles.
The Vincennes program began in 1903, however, no teams were formed from 1910–1912 and 1931-1950.


Bethel College (Mishawaka)
https://en.wikipedia.org/wiki/Bethel_College_(Indiana)#Athletic_Accomplishments
3 NAIA National Championships (Men's DII Basketball)
29 NCCAA National Championships
3 NAIA Individual National Champions (1 Women's Golf, 2 Men's Track)
211 NCCAA Individual National Champions (Tennis and Track & Field)
229 NAIA All-Americans
435 NAIA Scholar-Athletes
15 NAIA National Players of the Week
33 National Coach of the Year awards (NAIA & NCCAA Combined)
60 Conference Regular Season Championship
(List is current through the 2015-16 school year).

The Indiana Pacers are a professional basketball team that plays in the National Basketball Association (NBA). The team is based in the state's capital and largest city, Indianapolis, located in the center of the state. The Indiana Fever of the WNBA, also owned by Melvin & Herb Simon, are the Pacers' sister team and also play in the Bankers Life Fieldhouse.

The Indiana Fever is a professional women's basketball team that plays in the Women's National Basketball Association (WNBA). The Fever are based in Indiana's capital and largest city, Indianapolis. The Fever play at Bankers Life Fieldhouse, located in downtown Indianapolis. The team is the sister team of the NBA's Indiana Pacers.

At the conclusion of the regular Big Ten season, a tournament is held to determine the conference winner, who receives the conference's automatic bid to the NCAA tournament. Indianapolis has hosted all but one of the women's tournaments since its inception in 1995, and Bankers Life Fieldhouse has hosted every tournament since 2002, as well as the 2000 edition. The Big Ten Conference Men's Basketball Tournament began a five-year stint at Bankers Life Fieldhouse in 2008.

Indianapolis, headquarters of the National Collegiate Athletic Association and often referred to as the "Amateur Sports Capital of the World" has hosted a number of collegiate basketball events. Aside from the multitude of regional games held during the NCAA tournament, Indianapolis is tied with New York City for having hosted the second most NCAA Men's Division I Basketball Championships (1980, 1991, 1997, 2000, 2006, 2010, and 2015). The city will host the men's Final Four next in 2021. Previous events were held in the Market Square Arena or the RCA Dome, but given the new stadium built for the Indianapolis Colts, Lucas Oil Stadium began hosting Final Four events in 2010. When the NCAA Headquarters relocated to Indianapolis, it was stated that Indianapolis would then host the men's Final Four once every five years. The leading factor in the NCAA's decision to move to Indianapolis was the overwhelming amount of local athletic infrastructure, all of it world-class.

In 2002, Indianapolis hosted the FIBA World Championship (now known as the FIBA Basketball World Cup), an event that takes place on even years opposite the Olympic Games. Since inaugural event in 1950, Indianapolis is the only city in the United States to have hosted the event.

Here follows a list of notable Indiana natives, as well as non-natives who were raised in the state, who have achieved success in basketball.
Non-natives (i.e., those who did not arrive in Indiana before college) who gained basketball fame in Indiana's tradition include:



</doc>
<doc id="14445" url="https://en.wikipedia.org/wiki?curid=14445" title="Hardcore">
Hardcore

Hardcore, hard core or hard-core may refer to:







</doc>
<doc id="14446" url="https://en.wikipedia.org/wiki?curid=14446" title="Harold Alexander, 1st Earl Alexander of Tunis">
Harold Alexander, 1st Earl Alexander of Tunis

Field Marshal Harold Rupert Leofric George Alexander, 1st Earl Alexander of Tunis, (10 December 1891 – 16 June 1969) was a senior British Army officer who served with distinction in both the First World War and the Second World War and, afterwards, as Governor General of Canada, the 17th since Canadian Confederation.

Alexander was born in London, England, to aristocratic parents and was educated at Harrow before moving on to the Royal Military College, Sandhurst, for training as an army officer of the Irish Guards. He rose to prominence through his service in the First World War, receiving numerous honours and decorations, and continued his military career through various British campaigns across Europe and Asia. In World War II, Alexander oversaw the final stages of the Allied evacuation from Dunkirk and subsequently held high-ranking field commands in Burma, North Africa and Italy, including serving as Commander-in-Chief Middle East and commanding the 18th Army Group in Tunisia. He then commanded the 15th Army Group for the capture of Sicily and again in Italy before receiving his field marshal's baton and being made Supreme Allied Commander Mediterranean.

In 1946 he was appointed as governor general by King George VI, on the recommendation of Prime Minister of Canada William Lyon Mackenzie King, to replace the Earl of Athlone as viceroy, and he occupied the post until succeeded by Vincent Massey in 1952. Alexander proved to be enthusiastic about the Canadian wilderness and was a popular governor general with Canadians. He was the last non-Canadian-born governor general before the appointment of Adrienne Clarkson in 1999, as well as the last governor general to be a peer.

After the end of his viceregal tenure, Alexander was sworn into the Queen's Privy Council for Canada and thereafter, in order to serve as the British Minister of Defence in the Cabinet of Winston Churchill, into the Imperial Privy Council. Alexander retired in 1954 and died in 1969.

Alexander was born in London into an aristocratic family from County Tyrone of Ulster-Scots descent. He was the third son of James Alexander, 4th Earl of Caledon and the Countess of Caledon, a daughter of the 3rd Earl of Norbury. Alexander was educated at Hawtreys and Harrow School, there participating as the 11th batsman in the sensational Fowler's Match against Eton College in 1910. Though Alexander toyed with the notion of becoming an artist, he went instead on to the Royal Military College, Sandhurst.

In September 1911, Alexander entered the Royal Military College, Sandhurst and was commissioned as a second lieutenant in the British Army's Irish Guards. He was promoted to lieutenant in December 1912.

Alexander spent most of the First World War on the Western Front. As a 22-year-old platoon commander in the 1st Battalion, Irish Guards, he served with the British Expeditionary Force (BEF) in 1914. He took part in the retreat from Mons and was wounded at First Ypres and invalided home. He was promoted to temporary captain on 15 November 1914 and permanent captain in the newly raised 2nd Battalion on 7 February the following year.

Alexander returned to the Western Front in August 1915, fought at the Battle of Loos and was, for ten days in October 1915, an acting major and acting Commanding Officer (CO) of the 1st Battalion, Irish Guards as a "Battle Casualty Replacement". He then returned to the 2nd Battalion as a company officer and, in January 1916, received the Military Cross for his bravery at Loos. For service in the Battle of the Somme on 15 September 1916, he was, in October, appointed to the Distinguished Service Order (DSO), the citation for which read: "For conspicuous gallantry in action. He was the life and soul of the attack, and throughout the day led forward not only his own men but men of all regiments. He held the trenches gained in spite of heavy machine gun fire." In the same month, Alexander was further honoured with induction into the French Légion d'honneur.

On 10 December 1916, his twenty-fifth birthday, Alexander became second-in-command (2-i-c) of the 1st Battalion, Irish Guards as an acting major. By May, he was briefly acting CO of the 1st Battalion, as an acting lieutenant colonel, while still only a substantive captain. He became a permanent major on 1 August 1917 and was again promoted acting lieutenant colonel, this time confirmed as CO of the 2nd Battalion, Irish Guards, on 15 October. Alexander commanded his battalion at Third Ypres, where he was slightly wounded, then at Bourlon Wood (part of the battle of Cambrai), where his battalion suffered 320 casualties out of 400 men. Alexander, between 23 and 30 March 1918, had to assume command of the 4th Guards Brigade, during the British retreat from the German Army's Spring Offensive. He once again commanded the 2nd Battalion, Irish Guards at Hazebrouck in April 1918, where it took such severe casualties that it saw no further action. Still an acting lieutenant colonel, he then commanded a corps infantry school in October 1918, a month before the war ended on 11 November 1918.

Rudyard Kipling, who wrote a history of the Irish Guards, in which his own son, Jack Kipling, fought and was killed in action, noted that, "it is undeniable that Colonel Alexander had the gift of handling the men on the lines to which they most readily responded... His subordinates loved him, even when he fell upon them blisteringly for their shortcomings; and his men were all his own."

Alexander in 1919 served with the Allied Control Commission in Poland. As a temporary lieutenant-colonel, he led the Baltic German Landeswehr in the Latvian War of Independence, commanding units loyal to Latvia in the successful drive to eject the Bolsheviks from Latgalia. During service there, he was accidentally wounded by one of his own sentries on 9 October 1919.

Alexander returned to Britain in May 1920 as a major, second in command of the 1st Battalion, Irish Guards; in May 1922, he was promoted substantive lieutenant-colonel and appointed commanding officer. He commanded the battalion at Constantinople (a sensitive posting in the runup to the Chanak Crisis), then Gibraltar from October 1922, then in London from April 1923 until January 1926, when he was released from that role to attend Staff College, Camberley. Alexander was then in February 1928 promoted to colonel (backdated to 14 May 1926) and was the next month appointed Officer Commanding the Irish Guards Regimental District and 140th (4th London) Infantry Brigade, part of 47th (1/2nd London) Division, in the Territorial Army a post he held until January 1930, when he again returned to study, attending the Imperial Defence College for one year. There, two of Alexander's instructors—the future field marshals Alan Brooke and Bernard Montgomery—were unimpressed by him.

After the completion of his courses, Alexander, on 14 October 1931, married Lady Margaret Bingham, the daughter of the Earl of Lucan and with whom Alexander had two sons—Shane, born 1935, and Brian, born 1939—and a daughter, as well as adopting another daughter during his time as Canada's governor general. Alexander then held staff appointments as (from January 1931) GSO2 in the Directorate of Military Training at the War Office and (1932–34) GSO1 at HQ Northern Command in York, before being made in October 1934 a temporary brigadier and given command of the Nowshera Brigade, on the Northwest Frontier in India. For his service there, and in particular for his actions in the Loe-Agra operations against the Pathans in Malakand between February and April 1935, Alexander was that year made a Companion of the Order of the Star of India and was mentioned in dispatches. He was mentioned once more for his service during the Second Mohmand Campaign in Northwest Frontier Province from August to October of the same year, serving under Brigadier Claude Auchinleck. Alexander had a reputation for leading from the front and for reaching mountain crests with or even ahead of his troops.

In March 1937, Alexander was appointed as one of the aides-de-camp to the recently acceded King George VI and in May returned to the United Kingdom to take part in this capacity in the state procession through London during the King's coronation. Alexander would have been seen in this event by two of his Canadian viceregal successors: Vincent Massey, who was then the Canadian high commissioner to the United Kingdom, and Massey's secretary, Georges Vanier, who watched the procession from the roof of Canada House on Trafalgar Square. Following the coronation celebration, Alexander returned to India, where he was made the honorary colonel of the 3rd Battalion, 2nd Punjab Regiment, and then in October 1937 was promoted to the rank of major-general, making Alexander the youngest general in the British Army. He relinquished command of his brigade in January 1938, and in February returned to the United Kingdom to take command of the 1st Infantry Division. In June 1938 he was appointed a Companion of the Order of the Bath.

Following the outbreak of Second World War, in September 1939, Alexander brought the 1st Division to France, where it became part of the British Expeditionary Force (BEF) and served there for the next eight months. In May 1940, when the German Army invaded France, he successfully led the division's withdrawal to Dunkirk, where it was evacuated to England, along with the rest of the BEF. Shortly after Major General Bernard Montgomery had been appointed to command II Corps (and before that the 3rd Division), Alexander was, while still on the beachhead, placed in command of I Corps, and left the beach on the last destroyer on 3 June after ensuring that all British troops had been evacuated. In recognition of his services in the field from March to June 1940, Alexander was again mentioned in despatches.

After Dunkirk, Alexander returned to the United Kingdom and continued to command I Corps, now guarding the coasts of Yorkshire and Lincolnshire. He was promoted acting lieutenant-general in July 1940, and appointed the General Officer Commanding-in-Chief (GOC-in-C) of Southern Command, which was responsible for the defence of south-west England. His rank of lieutenant-general was made permanent in December 1940.

On 1 January 1942 he was knighted and appointed a Knight Commander of the Order of the Bath, and in February, after the Japanese invasion of Burma, was sent to India to become GOC-in-C of British Forces in Burma as a full general. Alexander was unable to fulfil his orders to hold Rangoon, which was abandoned on 6–7 March. He took personal charge of some small local engagements, and was encircled by the Japanese troops in the Battle of Yenangyaung. Rescued by Chinese troops commanded by General Sun Li-jen, Alexander was able to escape. Following that, Alexander increasingly left much of the tactical conduct of the campaign to his corps commander, Lieutenant-General William Slim, while he himself handled the more political aspects of relations with Joseph Stilwell, the nominal commander of the Chinese forces. Alexander was promoted to Commander-in-Chief (C-in-C) of Allied Land Forces in Burma, March 1942, and ordered Slim to abandon Mandalay and retreat to India.

By July 1942, the British and Indian forces in Burma had completed their fighting retreat into India, and Alexander, having yet again been mentioned in despatches for his Burma service, was recalled to the United Kingdom. He was at first selected to command the British First Army, which was to take part in Operation Torch, the Anglo-American invasion of French North Africa. However, following a visit in early August to Egypt by the British Prime Minister, Winston Churchill, and the Chief of the Imperial General Staff (CIGS), General Sir Alan Brooke, Alexander flew to Cairo on 8 August to replace General Claude Auchinleck as C-in-C of Middle East Command, the post responsible for the overall conduct of the campaign in the desert of North Africa. At the same time, Lieutenant-General Montgomery replaced Auchinleck as GOC of the British Eighth Army. Alexander presided over Montgomery's victory at the Second Battle of El Alamein and the advance of the Eighth Army to Tripoli, for which Alexander was elevated to a Knight Grand Cross of the Order of the Bath, and, after the Anglo-American forces of the First Army (under Lieutenant-General Kenneth Anderson) from Operation Torch and the Eighth Army converged in Tunisia in February 1943, they were brought under the unified command of a newly formed 18th Army Group headquarters, commanded by Alexander and reporting to General Dwight D. Eisenhower, the Supreme Allied Commander in the Mediterranean Theater of Operations (MTO) at Allied Forces Headquarters (AFHQ). General Omar Bradley, an American general who fought in the Tunisian Campaign, then commanding the U.S. II Corps, credited Alexander's patience and experience with helping an inexperienced United States "field command mature and eventually come of age."

The Axis forces in Tunisia surrendered by May 1943, and Alexander's command became the 15th Army Group, which was, under General Eisenhower, responsible for mounting in July the Allied invasion of Sicily, again seeing Alexander controlling two field armies: General Montgomery's Eighth Army and Lieutenant General George S. Patton's U.S. Seventh Army. After Sicily, and in preparation for the Allied invasion of Italy, the Seventh Army headquarters were replaced by those of the U.S. Fifth Army, led by Lieutenant General Mark W. Clark.

When Eisenhower was appointed Supreme Allied Commander for the planned Normandy landings he suggested that Alexander become ground forces commander, as he was popular with both British and American officers. Bradley, who after Normandy commanded the U.S. 12th Army Group, remarked that he would have preferred to work with Alexander, rather than Montgomery, as he regarded the former as "a restrained, self-effacive and punctilious soldier". Of the problems that subsequently surfaced with Montgomery's command of the Anglo-Canadian 21st Army Group, Bradley suspected they would not have occurred with Alexander in command. Brooke, however, applied pressure to keep Alexander in Italy, considering him unfit for the assignment in France. Thus, Alexander remained in command of the 15th Army Group, and, with the support of numerous Allied commanders, controversially authorised the bombing of the historic abbey at Monte Cassino, which resulted in little advance on the German Winter Line defences. It was not until the fourth attempt that the Winter Line was breached by the Allies, and Alexander's forces moved on to capture Rome in June 1944, thereby achieving one of the strategic goals of the Italian Campaign. However, the U.S. VI Corps in the Anzio beachhead, under Clark's orders, failed to follow their original break-out plan that would have trapped the German 10th Army escaping northwards in the aftermath of the Battle of Monte Cassino, instead favouring an early and highly publicised entry into Rome two days before the Allied landings in Normandy.

Alexander remained in command of the 15th Army Group, as well as its successor, the Allied Armies in Italy (AAI), for most of the Italian Campaign, until December 1944, when he relinquished his command to Clark and took over as the Supreme Commander of the Allied Forces Headquarters, responsible for all military operations in the Mediterranean Theatre. Alexander was concurrently promoted to the rank of field marshal, though this was backdated to the fall of Rome on 4 June 1944, so that Alexander would once again be senior to Montgomery, who had himself been made a field marshal on 1 September 1944, after the end of the Battle of Normandy. Alexander then received the German surrender in Italy, on 29 April 1945. Further, as a reward for his leadership in North Africa and Italy, Alexander, along with a number of other prominent British Second World War military leaders, was elevated to the peerage on 1 March 1946 by King George VI; he was created Viscount Alexander of Tunis and Errigal in the County of Donegal.

Brooke felt that Alexander needed an able chief of staff "to think for him", while Montgomery (Alexander's subordinate in Africa and Italy) claimed to think of Alexander as "incompetent" and success was attained in Tunisia only because Montgomery lent Lieutenant-General Brian Horrocks, the commander of IX Corps, to organise the coup de grace. However, Harold Macmillan was impressed by Alexander's calm and style, conducting dinners in his mess like those at an Oxbridge high table, discussing architecture and the campaigns of Belisarius, rather than the current war. Macmillan thought Alexander's urbane manner and willingness to discuss and compromise were a sensible way to maintain inter-Allied cooperation, but Alexander's reserve was such that some thought him empty of strategic ideas and unable to make decisions. Graham and Bidwell, however, wrote that Alexander's impenetrable reserve made it hard to judge whether or not he had any military ideas, but that he was "unable or unwilling" to assert his will over his army commanders, and that Mark Clark, who often referred to him scornfully as a "peanut" and a "feather duster", exploited this weakness.

With the cessation of hostilities, Alexander was under serious consideration for appointment to the post of Chief of the Imperial General Staff, the British Army's most senior position beneath the sovereign. He was invited, though, by Canadian prime minister William Lyon Mackenzie King to be his recommendation to the King for the post of Governor General of Canada. Alexander thus chose to retire from the army and take up the new position, in anticipation of which he was on 26 January 1946 appointed Knight Grand Cross of the Order of Saint Michael and Saint George and created Viscount Alexander of Tunis, of Errigal in the County of Donegal on 1 March. On 21 March 1946, the commission under the royal sign-manual and signet appointing Alexander was issued. Alexander was subsequently sworn-in during a ceremony in the Senate chamber on 12 April that year.
Alexander took his duties as the viceroy quite seriously, feeling that, as governor general, he acted as a connection between Canadians and their King, and spent considerable time traveling Canada during his term; he eventually logged no less than 294,500  km (184,000  mi) during his five years as governor general. On these trips, he sought to engage with Canadians through various ceremonies and events; he was keenly interested in his role as Chief Scout of Canada and, in preparation for his kicking of the opening ball in the 1946 Grey Cup final, practised frequently on the grounds of the royal and viceregal residence, Rideau Hall. Also, in commemoration of Alexander being named the first non-aboriginal chief of the Kwakiutl tribe, he was given a totem pole on 13 July 1946; crafted by Mungo Martin, it remains on the grounds of Rideau Hall today. By the end of the year, Alexander was also distinguished with his induction as a Knight of the Order of the Garter.

In 1947, the King issued letters patent granting his Canadian governor general permission to exercise all those powers belonging to the monarch in respect of Canada and, at the Commonwealth Prime Ministers Conference of 1949, the decision was reached to use the term "member of the Commonwealth" instead of "Dominion" to refer to the non-British member states of the Commonwealth of Nations. That same year, Alexander oversaw the admission of the British crown colony of Newfoundland into Canadian Confederation and toured the new province that summer. Then, during a later visit to Alberta, the Governor General was admitted to the Blackfoot tribe as Chief Eagle Head. However, though the post-war period saw a boom in prosperity for Canada, the country was again at war by 1950, with Alexander, in his role as acting commander-in-chief, deploying to the Korean War soldiers, sailors, and airmen, whom he would visit prior to their departure for north-east Asia.
The Viscount travelled abroad on official trips—in 1947 visiting US president Harry S. Truman and in June 1948 Brazilian president Eurico Gaspar Dutra—as well as hosting a number of dignitaries. The visit of the Irish Taoiseach, John A. Costello, in 1948 caused Alexander some embarrassment when Costello chose the occasion to announce that most of Ireland were leaving the Commonwealth (Northern Ireland would remain a constituent part of the United Kingdom). Although the decision had been taken in principle sometime before, the sudden announcement caused a diplomatic storm and Costello, to deflect criticism, claimed that he had been provoked into making the announcement by a series of diplomatic snubs by Lord Alexander. In his memoirs, Costello was to admit that Alexander's behaviour had in fact been perfectly civil and could have had no bearing on a decision which had already been made to declare the Republic of Ireland.

The Alexanders' relatively informal lifestyle at Rideau Hall was demonstrated when, during the Canadian tour of Princess Elizabeth and her husband, the Duke of Edinburgh, the Viscount and Viscountess hosted a square dance in the palace's ballroom. Alexander painted (creating a personal studio in the former dairy at Rideau Hall and mounting classes in art at the National Gallery of Canada), partook in a number of sports (including golf, ice hockey, and rugby), and enjoyed the outdoors, particularly during Ontario and Quebec's maple syrup harvest, himself overseeing the process on Rideau Hall's grounds. The Viscount was known to escape from official duties to partake in his most favourite pastime of fishing, once departing from the 1951 royal tour of Princess Elizabeth to take in a day's fishing at Griffin Island, in Georgian Bay, and granting a day off for students in the town of Drayton, Ontario, where his train briefly stopped.

Among Canadians, Alexander proved to be a popular viceroy, despite the calls for a Canadian-born governor general that had preceded his appointment. Not only did he have a much praised military reputation—he was considered to be the best military strategist since the 1st Duke of Wellington—but he was also a charismatic figure with an easy ability to communicate with people. Others, however, did not fully approve of Alexander; editor Hugh Templin, from Fergus, Ontario, met with Alexander during Templin's time as a special correspondent with the Canadian Press during the Second World War, and he said of the encounter: "Lord Alexander impressed us considerably, if not too favourably. He was an aristocratic type, who didn't like newspaper men."

Lord Alexander departed the office of Governor General of Canada in early 1952 after Churchill asked him to return to London to take the post of Minister of Defence in the British government. The aging Churchill had found it increasingly difficult to cope with holding that portfolio concurrently with that of prime minister, although he still took many major decisions himself, leaving Alexander with little real power. Soon after, George VI died on the night of 5–6 February and Alexander, in respect of the King's mourning, departed quietly for the United Kingdom, leaving Chief Justice of Canada Thibaudeau Rinfret as administrator of the government in his place. After his return to the UK, Alexander was on 14 March 1952 elevated in the peerage by the new queen, becoming Earl Alexander of Tunis, Baron Rideau of Ottawa and Castle Derg. He was also appointed to the organising committee for the Queen's coronation and was charged with carrying the Sovereign's Orb in the state procession on that occasion in 1953.

The Earl served as the British defence minister until 1954, when he retired from politics and, in 1959, the Queen appointed Alexander to the Order of Merit. From 1960 to 1965, he served as Constable of the Tower of London. Alexander was an active freemason.

Canada remained a favourite second home for the Alexanders and they returned frequently to visit family and friends until Alexander died on 16 June 1969 of a perforated aorta. His funeral was held on 24 June 1969, at St. George's Chapel, in Windsor Castle, and his remains are buried in the churchyard of Ridge, near Tyttenhanger, his family's Hertfordshire home.

 United Kingdom


 Alberta

Appointments

Decorations

Medals

Awards

Foreign honours and decorations



Geographic locations

Schools






</doc>
