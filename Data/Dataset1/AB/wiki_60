<doc id="19855" url="https://en.wikipedia.org/wiki?curid=19855" title="Mars Attacks">
Mars Attacks

Mars Attacks is a science fiction-themed trading card series released in 1962. The cards feature artwork by science fiction artists Wally Wood and Norman Saunders. The cards form a story arc, which tell of the invasion of Earth by cruel, hideous Martians, under the command of a corrupt Martian government who conceal the fact from the Martian populace that Mars is doomed to explode and therefore proposes a colonization of Earth. The cards depict futuristic battle scenes and bizarre methods of Martian attack, torture and slaughter, as well as various Earth nations being attacked. The story concludes with an expeditionary force of humans volunteering to embark on a counterattack on Mars, in which the Earth force attacks the Martians in their manner (bayoneting and bullets). This necessitates the Martian invasion troops to be recalled to defend their homeworld. The Earth attack forces, after destroying the Martian cities and killing the Martians, depart just before Mars is destroyed in the predicted cataclysm, thus ensuring the peace and safety of Earth as the Martian race is doomed to extinction.

The cards proved popular with children, but depictions of explicit gore and implied sexual content caused an outcry, leading the company to halt production. The cards have since become collectors' items, with certain cards commanding over $3,500 at auction.

In the 1980s Topps began developing merchandise based on the "Mars Attacks" storyline, including mini-comic books and card reprints. An expanded set of 100 cards called "Mars Attacks Archives" was issued in 1994 by Topps and spawned a second round of merchandising. Director Tim Burton released a film called "Mars Attacks!" in 1996 based on the series, spawning a third round of merchandising. In 2012, Topps released a 50th anniversary expanded set of 75 cards called "Mars Attacks Heritage", leading to a fourth round of merchandising that continued into 2017 with the release of a sequel series, "Mars Attacks: The Revenge!"

The "Mars Attacks" trading card series was created by Topps in 1962. Product developer Len Brown, inspired by Wally Wood's cover for EC Comics' "Weird Science" #16, pitched the idea to Woody Gelman. Gelman and Brown created the story—with Brown writing the copy—and created rough sketches. They enlisted Wood to flesh out the sketches and Bob Powell to finish them. Norman Saunders painted the 55-card set.

The cards, which sold for five cents per pack of five, were test marketed by Topps through the dummy corporation Bubbles, Inc. under the name "Attack from Space". Sales were sufficient to expand the marketing and the name was changed to "Mars Attacks". The cards sparked parental and community outrage over their graphic violence and implied sexuality. Topps responded initially by repainting 13 of the cards to reduce the gore and sexuality. However, inquiries from a Connecticut district attorney caused Topps to halt production of the series altogether before the replacements could be printed.

In 1984, Rosem Enterprises issued a set of the 13 repainted cards from the original series and Renata Galasso issued a full reprint. Four years later, Topps, with Pocket Comics, issued a planned 54-issue mini-comic book serialization of the card series, each issue to have been based on 54 of the 55 cards (the exception was the checklist card (#55)). It was canceled after four issues due to poor sales and equally poor distribution, although the next four issues were announced on a dealer's sheet. Four new trading cards were made with the mini-comics, with a fifth one announced on the back of the fourth card which was never released.

In 1994, Topps re-released the cards as the expanded "Mars Attacks Archives", with the original 55 cards and 45 "New Visions" cards. The new cards are further divided into a #0 card, three subsets ("The Unpublished 11" (with 11 cards), "Mars Attacks: The Comics" (with 10 cards) and "Visions: New and Original" (with 22 cards)) and one card called "Norm Saunders: A Self-Portrait". Twenty-one artists collaborated on the new cards, including Zina Saunders, daughter of the original artist Norman Saunders. Topps Comics, in conjunction with the trading cards, issued a five-issue comic book miniseries written by Keith Giffen and drawn by Charles Adlard. Topps Comics continued the story in an ongoing series that lasted seven issues, a one-shot special and three more miniseries, one of them a crossover with the Martians battling the Image Comics superhero the Savage Dragon and another one a crossover with the Martians battling other characters from the Image Comics universe. "Wizard" magazine and Topps Comics also published a 1/2 issue and an Ace Edition issue (#65). In the same year as the "Archives" series (and shortly after its release), Screamin' Productions and Topps released a tie-in set of eight "Mars Attacks" vinyl model kits with an accompanying series of eight new trading cards, each one inside one of the kits. Bonus items that could be acquired by sending in proof-of-purchase certificates from all eight of the kits were two new nearly identical bonus cards (one regular-sized and one oversized) and a limited edition ninth model kit.

In 1996, Warner Bros. released Tim Burton's film "Mars Attacks!" In conjunction, two hardcover novels were released: "Mars Attacks: Martian Deathtrap" by Nathan Archer; and "Mars Attacks: War Dogs of the Golden Horde" by Ray W. Murrill. Each contained two new trading cards. A paperback movie tie-in novelization by the film's screenwriter was also published. Trendmasters produced a series of toy figures based on the film.

In 2012, to commemorate the franchise's 50th anniversary, Topps partnered with a variety of companies on comic books (via IDW Publishing), bobbleheads and vinyl dolls (Funko), action figures and plush toys (Mezco Toyz), costumes (Incogneato), statues and busts (Quarantine Studio), electronics skins (Gelaskins) and a commemorative hardcover book and 2013 calendar, both with nearly identical sets of four new trading cards (the book's cards having white borders and the calendar's cards having green borders) (Abrams Books). Topps also re-released the original 55-card series as the expanded "Mars Attacks Heritage", including two subsets ("Deleted Scenes" (with 10 cards) and "Guide to the New Universe" (with 15 cards)). In 2013, it issued "Mars Attacks: Invasion," a reboot series of 95 trading cards featuring a new story ("Mars Attacks: Invasion" (cards #1-58, plus a #0 promo card from the 2012 San Diego Comic-Con)) with new artwork cards (divided into "Mars Invades IDW" (cards #59-77 and #91-92) and "Art of Mars Attacks" (cards #78-90 and #93-95)) and including four new subsets ("Mars Attacks: Early Missions" (with six cards), "Mars Attacks Masterpieces" (with five cards), "Join the Fight!" (with four cards) and "Anatomy of a Martian" (also with six cards)). A second series of 81 trading cards, "Mars Attacks: Occupation", also featuring a new story ("Mars Attacks: Occupation" (cards #1-45) with new artwork cards (divided into "Art of Mars Attacks" (cards #46-63), "Factions" (cards #64-72), "Occupation Profiles" (cards #73-78) and "The Kickstarter Video" (cards #79-81)) and including six new subsets ("Mars Attacks Superstars", Mars Attacks: Then and Now!", "Mars Attacks All-Star Art" and "Dinosaurs Attack! vs. Mars Attacks" (each with nine cards (the last one of which was available as a foil card set)), "Attacky Packages" (with 13 cards; the last three cards were titled "Attacky Packages Old School" (this one was also available as a foil card set)) and "Mars Attacks/Judge Dredd" (with 18 cards)) was funded on Kickstarter in 2015 and released in 2016.

In 2015, Kreepsville Clothing released a line featuring "Mars Attacks" on dresses, tops, hats and other apparel. On October 27, 2016, "Day 10" of "13 Days of ERMA-Ween", an annual series of comic strips from the Brandon J. Santiago webcomic "Erma", focuses on the Martians of the "Mars Attacks" franchise, showing Erma Williams, the series' titular character, wearing a nurse's cap, preparing to dissect a living Martian with a buzz saw.

In 2017, to commemorate the franchise's 55th anniversary, Topps released a sequel series to the original 55-card series called "Mars Attacks: The Revenge!", which takes place five years after the first story. It contains 110 cards-the story itself (cards #1-55) and rough pencil art for the story cards (cards #P-1-P-55).





</doc>
<doc id="19856" url="https://en.wikipedia.org/wiki?curid=19856" title="Montreal Protocol">
Montreal Protocol

The Montreal Protocol on Substances that Deplete the Ozone Layer (a protocol to the Vienna Convention for the Protection of the Ozone Layer) is an international treaty designed to protect the ozone layer by phasing out the production of numerous substances that are responsible for ozone depletion. It was agreed on 26 August 1987, and entered into force on 26 January 1989, followed by a first meeting in Helsinki, May 1989. Since then, it has undergone eight revisions, in 1990 (London), 1991 (Nairobi), 1992 (Copenhagen), 1993 (Bangkok), 1995 (Vienna), 1997 (Montreal), 1998 (Australia), 1999 (Beijing) and 2016 (Kigali, adopted, but not in force). As a result of the international agreement, the ozone hole in Antarctica is slowly recovering. Climate projections indicate that the ozone layer will return to 1980 levels between 2050 and 2070. Due to its widespread adoption and implementation it has been hailed as an example of exceptional international co-operation, with Kofi Annan quoted as saying that "perhaps the single most successful international agreement to date has been the Montreal Protocol". In comparison, effective burden sharing and solution proposals mitigating regional conflicts of interest have been among the success factors for the ozone depletion challenge, where global regulation based on the Kyoto Protocol has failed to do so. In this case of the ozone depletion challenge, there was global regulation already being installed before a scientific consensus was established. Also, overall public opinion was convinced of possible imminent risks.

The two ozone treaties have been ratified by 197 parties, which includes 196 states and the European Union, making them the first universally ratified treaties in United Nations history.

These truly universal treaties have also been remarkable in the expedience of the policy-making process at the global scale, where only 14 years lapsed between a basic scientific research discovery (1973) and the international agreement signed (1985 & 1987).

The treaty is structured around several groups of halogenated hydrocarbons that deplete stratospheric ozone. All of the ozone depleting substances controlled by the Montreal Protocol contain either chlorine or bromine (substances containing only fluorine do not harm the ozone layer). Some ozone-depleting substances (ODSs) are not yet controlled by the Montreal Protocol, including nitrous oxide (N2O) For a table of ozone-depleting substances controlled by the Montreal Protocol see:

For each group of ODSs, the treaty provides a timetable on which the production of those substances must be shot out and eventually eliminated.

The stated purpose of the treaty is that the signatory states

"Recognizing that worldwide emissions of certain substances can significantly deplete and otherwise modify the ozone layer in a manner that is likely to result in adverse effects on human health and the environment. Determined to protect the ozone layer by taking precautionary measures to control equitably total global emissions of substances that deplete it with the ultimate objective of their elimination on the basis of developments in scientific knowledge"

"Acknowledging that special provision is required to meet the needs of developing countries"

shall accept a series of stepped limits on CFC use and production, including:

There was a faster phase-out of halon-1211, -2402, -1301, There was a slower phase-out (to zero by 2010) of other substances (halon 1211, 1301, 2402; CFCs 13, 111, 112, etc.) and some chemicals were given individual attention (Carbon tetrachloride; 1,1,1-trichloroethane). The phasing-out of the less damaging HCFCs only began in 1996 and will go on until a complete phasing-out is achieved by 2030.

There were a few exceptions for "essential uses", where no acceptable substitutes were initially found (for example, in the past metered dose inhalers commonly used to treat asthma and chronic obstructive pulmonary disease were exempt) or Halon fire suppression systems used in submarines and aircraft (but not in general industry).

The substances in Group I of Annex A are:


The provisions of the Protocol include the requirement that the Parties to the Protocol base their future decisions on the current scientific, environmental, technical, and economic information that is assessed through panels drawn from the worldwide expert communities. To provide that input to the decision-making process, advances in understanding on these topics were assessed in 1989, 1991, 1994, 1998 and 2002 in a series of reports entitled Scientific assessment of ozone depletion, by the Scientific Assessment Panel (SAP). 

In 1990 a Technology and Economic Assessment Panel was also established as the technology and economics advisory body to the Montreal Protocol Parties. The Technology and Economic Assessment Panel (TEAP) provides, at the request of Parties, technical information related to the alternative technologies that have been investigated and employed to make it possible to virtually eliminate use of Ozone Depleting Substances (such as CFCs and Halons), that harm the ozone layer. The TEAP is also tasked by the Parties every year to assess and evaluate various technical issues including evaluating nominations for essential use exemptions for CFCs and halons, and nominations for critical use exemptions for methyl bromide. TEAP’s annual reports are a basis for the Parties’ informed decision-making.

Numerous reports have been published by various inter-governmental, governmental and non-governmental organizations to catalogue and assess alternatives to the ozone depleting substances, since the substances have been used in various technical sectors, like in refrigeration, air conditioning, flexible and rigid foam, fire protection, aerospace, electronics, agriculture, and laboratory measurements

Under the Montreal Protocol on Substances that Deplete the Ozone Layer, especially Executive Committee (ExCom) 53/37 and ExCom 54/39, Parties to this Protocol agreed to set year 2013 as the time to freeze the consumption and production of HCFCs. They also agreed to start reducing its consumption and production in 2015. The time of freezing and reducing HCFCs is then known as 2013-2015.

The HCFCs are transitional CFCs replacements, used as refrigerants, solvents, blowing agents for plastic foam manufacture, and fire extinguishers. In terms of ozone depletion potential (ODP), in comparison to CFCs that have ODP 0.6 – 1.0, these HCFCs have lower ODPs (0.01 – 0.5). In terms of global warming potential (GWP), in comparison to CFCs that have GWP 4,680 – 10,720, HCFCs have lower GWPs (76 – 2,270).

Produced mostly in developed countries, hydrofluorocarbons (HFCs) replaced CFCs and HCFCs. HFCs pose no harm to the ozone layer because, unlike CFCs and HCFCs, they do not contain chlorine. They are however greenhouse gases, with a high global warming potential (GWP), comparable to that of CFCs and HCFCs. Thus, in 2009, a study calculated that a fast phasedown of high-GWP HFCs could potentially prevent the equivalent of up to 8.8 Gt CO2-eq "per year" in emissions by 2050. A proposed phasedown of HFCs was hence projected to avoid up to 0.5C of warming by 2100 under the high-HFC growth scenario, and up to 0.35C under the low-HFC growth scenario. Recognizing the opportunity presented for fast and effective phasing down of HFCs through the Montreal Protocol, starting in 2009 the Federated States of Micronesia proposed an amendment to phase down high-GWP HFCs, with the U.S., Canada, and Mexico following with a similar proposal in 2010.

After seven years of negotiations, in October 2016 at the 28th Meeting of the Parties to the Montreal Protocol in Kigali, the Parties to the Montreal Protocol adopted the Kigali Amendment whereby the Parties agreed to phasedown HFCs under the Montreal Protocol. The amendment to the legally-binding Montreal Protocol will ensure that industrialised countries bring down their HFC production and consumption by at least 85 per cent compared to their annual average values in the period 2011-2013. A group of developing countries including China, Brazil and South Africa are mandated to reduce their HFC use by 85 per cent of their average value in 2020-22 by the year 2045. India and some other developing countries — Iran, Iraq, Pakistan, and some oil economies like Saudi Arabia and Kuwait — will cut down their HFCs by 85 per cent of their values in 2024-26 by the year 2047.

On 17 November 2017, ahead of the 29th Meeting of the Parties of the Montreal Protocol, Sweden became the 20th Party to ratify the Kigali Amendment, pushing the Amendment over its ratification threshold ensuring that the Amendment will enter into force 1 January 2019.

In 1973, the chemists Frank Sherwood Rowland and Mario Molina, who were then at the University of California, Irvine, began studying the impacts of CFCs in the Earth's atmosphere. They discovered that CFC molecules were stable enough to remain in the atmosphere until they got up into the middle of the stratosphere where they would finally (after an average of 50–100 years for two common CFCs) be broken down by ultraviolet radiation releasing a chlorine atom. Rowland and Molina then proposed that these chlorine atoms might be expected to cause the breakdown of large amounts of ozone (O) in the stratosphere. Their argument was based upon an analogy to contemporary work by Paul J. Crutzen and Harold Johnston, which had shown that nitric oxide (NO) could catalyze the destruction of ozone. (Several other scientists, including Ralph Cicerone, Richard Stolarski, Michael McElroy, and Steven Wofsy had independently proposed that chlorine could catalyze ozone loss, but none had realized that CFCs were a potentially large source of chlorine.) Crutzen, Molina and Rowland were awarded the 1995 Nobel Prize for Chemistry for their work on this problem.

The environmental consequence of this discovery was that, since stratospheric ozone absorbs most of the ultraviolet-B (UV-B) radiation reaching the surface of the planet, depletion of the ozone layer by CFCs would lead to an increase in UV-B radiation at the surface, resulting in an increase in skin cancer and other impacts such as damage to crops and to marine phytoplankton.

But the Rowland-Molina hypothesis was strongly disputed by representatives of the aerosol and halocarbon industries. The chair of the board of DuPont was quoted as saying that ozone depletion theory is "a science fiction tale...a load of rubbish...utter nonsense". Robert Abplanalp, the president of Precision Valve Corporation (and inventor of the first practical aerosol spray can valve), wrote to the Chancellor of UC Irvine to complain about Rowland's public statements (Roan, p. 56.)

After publishing their pivotal paper in June 1974, Rowland and Molina testified at a
hearing before the U.S. House of Representatives in December 1974. As a result, significant funding was made available to study various aspects of the problem and to confirm the initial findings. In 1976, the U.S. National Academy of Sciences (NAS) released a report that confirmed the scientific credibility of the ozone depletion hypothesis. NAS continued to publish assessments of related science for the next decade.

Then, in 1985, British Antarctic Survey scientists Joe Farman, Brian Gardiner and Jonathan Shanklin published results of abnormally low ozone concentrations above Halley Bay near the South Pole. They speculated that this was connected to increased levels of CFCs in the atmosphere. It took several other attempts to establish the Antarctic losses as real and significant, especially after NASA had retrieved matching data from its satellite recordings. The impact of these studies, the metaphor 'ozone hole', and the colourful visual representation in a time lapse animation proved shocking enough for negotiators in Montreal, Canada to take the issue seriously.

Also in 1985, 20 nations, including most of the major CFC producers, signed the Vienna Convention, which established a framework for negotiating international regulations on ozone-depleting substances. After the discovery of the ozone hole 
by SAGE 2 it only took 18 months to reach a binding agreement in Montreal, Canada.

But the CFC industry did not give up that easily. As late as 1986, the Alliance for Responsible CFC Policy (an association representing the CFC industry founded by DuPont) was still arguing that the science was too uncertain to justify any action. In 1987, DuPont testified before the US Congress that "We believe there is no imminent crisis that demands unilateral regulation." And even in March 1988, Du Pont Chair Richard E. Heckert would write in a letter to the United States Senate, "we will not produce a product unless it can be made, used, handled and disposed of safely and consistent with appropriate safety, health and environmental quality criteria. At the moment, scientific evidence does not point to the need for dramatic CFC emission reductions. There is no available measure of the contribution of CFCs to any observed ozone change..."

The main objective of the "Multilateral Fund for the Implementation of the Montreal Protocol" is to assist developing country parties to the Montreal Protocol whose annual per capita consumption and production of ozone depleting substances (ODS) is less than 0.3 kg to comply with the control measures of the Protocol. Currently, 147 of the 196 Parties to the Montreal Protocol meet these criteria (they are referred to as Article 5 countries).

It embodies the principle agreed at the United Nations Conference on Environment and Development in 1992 that countries have a common but differentiated responsibility to protect and manage the global commons.

The Fund is managed by an Executive Committee with an equal representation of seven industrialized and seven Article 5 countries, which are elected annually by a Meeting of the Parties. The Committee reports annually to the Meeting of the Parties on its operations. The work of the Multilateral Fund on the ground in developing countries is carried out by four Implementing Agencies, which have contractual agreements with the Executive Committee:


Up to 20 percent of the contributions of contributing parties can also be delivered through their bilateral agencies in the form of eligible projects and activities.

The fund is replenished on a three-year basis by the donors. Pledges amount to US$3.1 billion over the period 1991 to 2005. Funds are used, for example, to finance the conversion of existing manufacturing processes, train personnel, pay royalties and patent rights on new technologies, and establish national ozone offices.

As of 23 June 2015, all countries in the United Nations, the Cook Islands, Holy See, Niue and the European Union have ratified the original Montreal Protocol (see external link below), with South Sudan being the last country to ratify the agreement, bringing the total to 197. These countries have also ratified the London, Copenhagen, Montreal, and Beijing amendments.

Since the Montreal Protocol came into effect, the atmospheric concentrations of the most important chlorofluorocarbons and related chlorinated hydrocarbons have either leveled off or decreased. Halon concentrations have continued to increase, as the halons presently stored in fire extinguishers are released, but their rate of increase has slowed and their abundances are expected to begin to decline by about 2020. Also, the concentration of the HCFCs increased drastically at least partly because for many uses (e.g. used as solvents or refrigerating agents) CFCs were substituted with HCFCs. While there have been reports of attempts by individuals to circumvent the ban, e.g. by smuggling CFCs from undeveloped to developed nations, the overall level of compliance has been high. Statistical analysis from 2010 show a clear positive signal from the Montreal Protocol to the stratospheric ozone. In consequence, the Montreal Protocol has often been called the most successful international environmental agreement to date. In a 2001 report, NASA found the ozone thinning over Antarctica had remained the same thickness for the previous three years, however in 2003 the ozone hole grew to its second largest size. The most recent (2006) scientific evaluation of the effects of the Montreal Protocol states, "The Montreal Protocol is working: There is clear evidence of a decrease in the atmospheric burden of ozone-depleting substances and some early signs of stratospheric ozone recovery." However, a more recent study seems to point to a relative increase in CFCs due to an unknown source. 

Reported in 1997, significant production of CFCs occurred in Russia for sale on the black market to the EU throughout the 90s. Related US production and consumption was enabled by fraudulent reporting due to poor enforcement mechanisms. Similar illegal markets for CFCs were detected in Taiwan, Korea, and Hong Kong. .

The Montreal Protocol is also expected to have effects on human health. A 2015 report by the U. S. Environmental Protection Agency estimates that the protection of the ozone layer under the treaty will prevent over 280 million cases of skin cancer, 1.5 million skin cancer deaths, and 45 million cataracts in the United States.

However, the hydrochlorofluorocarbons, or HCFCs, and hydrofluorocarbons, or HFCs, are now thought to contribute to anthropogenic global warming. On a molecule-for-molecule basis, these compounds are up to 10,000 times more potent greenhouse gases than carbon dioxide. The Montreal Protocol currently calls for a complete phase-out of HCFCs by 2030, but does not place any restriction on HFCs. Since the CFCs themselves are equally powerful greenhouse gases, the mere substitution of HFCs for CFCs does not significantly increase the rate of anthropogenic climate change, but over time a steady increase in their use could increase the danger that human activity will change the climate.

Policy experts have advocated for increased efforts to link ozone protection efforts to climate protection efforts. Policy decisions in one arena affect the costs and effectiveness of environmental improvements in the other.

In 2018, scientists monitoring the atmosphere following the 2010 phaseout date have reported evidence of continuing industrial production of CFC-11, likely in eastern Asia, with detrimental global effects on the ozone layer.

The year 2012 marked the 25th anniversary of the signing of the Montreal Protocol. Accordingly, the Montreal Protocol community organized a range of celebrations at the national, regional and international levels to publicize its considerable success to date and to consider the work ahead for the future.
Among its accomplishments are: The Montreal Protocol was the first international treaty to address a global environmental regulatory challenge; the first to embrace the "precautionary principle" in its design for science-based policymaking; the first treaty where independent experts on atmospheric science, environmental impacts, chemical technology, and economics, reported directly to Parties, without edit or censorship, functioning under norms of professionalism, peer review, and respect; the first to provide for national differences in responsibility and financial capacity to respond by establishing a multilateral fund for technology transfer; the first MEA with stringent reporting, trade, and binding chemical phase-out obligations for both developed and developing countries; and, the first treaty with a financial mechanism managed democratically by an Executive Board with equal representation by developed and developing countries.

Within 25 years of signing, parties to the MP celebrate significant milestones. Significantly, the world has phased-out 98% of the Ozone-Depleting Substances (ODS) contained in nearly 100 hazardous chemicals worldwide; every country is in compliance with stringent obligations; and, the MP has achieved the status of the first global regime with universal ratification; even the newest member state, South Sudan, ratified in 2013. UNEP received accolades for achieving global consensus that "demonstrates the world’s commitment to ozone protection, and more broadly, to global environmental protection".





</doc>
<doc id="19857" url="https://en.wikipedia.org/wiki?curid=19857" title="Moncton">
Moncton

Moncton (; ) is the largest city in the Canadian province of New Brunswick. Situated in the Petitcodiac River Valley, Moncton lies at the geographic centre of the Maritime Provinces. The city has earned the nickname "Hub City" due to its central inland location in the region and its history as a railway and land transportation hub for the Maritimes.

The city proper has a population of 71,889 (2016) and has a land area of . The Moncton CMA has a population of 144,810 (2016), making it the largest city and CMA in New Brunswick, and the second-largest city and CMA in the Maritime Provinces. The CMA includes the neighbouring city of Dieppe and the town of Riverview, as well as adjacent suburban areas in Westmorland and Albert counties.

Although the Moncton area was first settled in 1733, Moncton is considered to have been officially founded in 1766 with the arrival of Pennsylvania Dutch immigrants from Philadelphia. Initially an agricultural settlement, Moncton was not incorporated until 1855. The city was named for Lt. Col. Robert Monckton, the British officer who had captured nearby Fort Beauséjour a century earlier. A significant wooden shipbuilding industry had developed in the community by the mid-1840s, allowing for the civic incorporation in 1855, but the shipbuilding economy collapsed in the 1860s, causing the town to lose its civic charter in 1862. Moncton regained its charter in 1875 after the community's economy rebounded, mainly due to a growing railway industry. In 1871, the Intercolonial Railway of Canada had chosen Moncton to be its headquarters, and Moncton remained a railway town for well over a century until the closure of the Canadian National Railway (CNR) locomotive shops in the late 1980s.

Although the economy of Moncton was traumatized twice—by the collapse of the shipbuilding industry in the 1860s and by the closure of the CNR locomotive shops in the 1980s—the city was able to rebound strongly on both occasions. The city adopted the motto "Resurgo" after its rebirth as a railway town. The city's economy is stable and diversified, primarily based on its traditional transportation, distribution, retailing, and commercial heritage, and supplemented by strength in the educational, health care, financial, information technology, and insurance sectors. The strength of Moncton's economy has received national recognition and the local unemployment rate is consistently less than the national average.

Acadians settled the head of the Bay of Fundy in the 1670s. The first reference to the "Petcoucoyer River" was on the De Meulles map of 1686. Settlement of the Petitcodiac and Memramcook river valleys began about 1700, gradually extending inland and reaching the site of present-day Moncton in 1733. The first Acadian settlers in the Moncton area established a marshland farming community and chose to name their settlement "Le Coude" (The Elbow), an allusion to the 90° bend in the river near the site of the settlement.

In 1755, nearby Fort Beausejour was captured by British forces under the command of Lt. Col. Robert Monckton. The Beaubassin region including the Memramcook and Petitcodiac river valleys subsequently fell under English control. Later that year, Governor Charles Lawrence issued a decree ordering the expulsion of the Acadian population from Nova Scotia (including recently captured areas of Acadia such as le Coude). This action came to be known as the "Great Upheaval".

The reaches of the upper Petitcodiac River valley then came under the control of the Philadelphia Land Company (one of the principals of which was Benjamin Franklin) and in 1766 Pennsylvania Dutch settlers arrived to re-establish the pre-existing farming community at Le Coude. The Settlers consisted of eight families; Heinrick Stief (Steeves), Jacob Treitz (Trites), Matthias Sommer (Somers), Jacob Reicker (Ricker), Charles Jones (Schantz), George Wortmann (Wortman), Michael Lutz (Lutes), and George Koppel (Copple). There is a plaque dedicated in their honor at the mouth of Hall's Creek. They renamed the settlement "The Bend".
The Bend remained an agricultural settlement for nearly 80 more years. Even by 1836, there were only 20 households in the community. At this time, the Westmorland Road became open to year-round travel and a regular mail coach service was established between Saint John and Halifax. The Bend became an important transfer and rest station along the route. Over the next decade, lumbering and then shipbuilding would become important industries in the area.

The turning point for the community was when Joseph Salter took over (and expanded) a shipyard at the Bend in 1847. The expanded shipyard ultimately grew to employ about 400 workers. The Bend subsequently developed a service-based economy to support the shipyard and gradually began to acquire all the amenities of a growing town. The prosperity engendered by the wooden shipbuilding industry allowed The Bend to incorporate as the town of Moncton in 1855. The town was named for Lt. Col. Robert Monckton, but a clerical error at the time the town was incorporated resulted in the misspelling of the community's name, which has been perpetuated to the present day. The first mayor of Moncton was the shipbuilder Joseph Salter.

Two years later, in 1857, the European and North American Railway opened its line from Moncton to nearby Shediac; this was followed by a line from Moncton to Saint John opening in 1859. At about the time of the arrival of the railway, the popularity of steam-powered ships forced an end to the era of wooden shipbuilding. The Salter shipyard closed in 1858. The resulting industrial collapse caused Moncton to surrender its civic charter in 1862.

Moncton's economic depression did not last long and a second era of prosperity came to the area in 1871 when Moncton was selected to be the headquarters of the Intercolonial Railway of Canada (ICR). The arrival of the ICR in Moncton was a seminal event for the community. For the next 120 years, the history of the city would be firmly linked with that of the railway. In 1875, Moncton was able to reincorporate as a town and adopted the motto "Resurgo" (Latin for "I rise again"). One year later, the ICR line to Quebec was opened. The railway boom that emanated from this and the associated employment growth allowed Moncton to achieve city status on 23 April 1890.

Moncton grew rapidly during the early 20th century, particularly after provincial lobbying helped the city become the eastern terminus of the massive National Transcontinental Railway project in 1912. In 1918, the ICR and National Transcontinental Railway (NTR) were merged by the federal government into the newly formed Canadian National Railways (CNR) system. The ICR shops would become CNR's major locomotive repair facility for the Maritimes and Moncton became the headquarters for CNR's Maritime division. The T. Eaton Company's catalogue warehouse moved to the city in the early 1920s, employing over 700 people. Transportation and distribution became increasingly important to the Moncton economy throughout the middle part of the 20th century. The Moncton Airport opened in 1929 and quickly became an important fixture in the community. During the Second World War the Canadian Army built a large military supply base in the city to service the Maritime military establishment. The CNR continued to dominate the economy of the city with railway employment in Moncton peaked at nearly six thousand workers in the 1950s before beginning a slow decline.

Moncton was placed on the Trans-Canada Highway network in the early 1960s after Route 2 was built along the northern perimeter of the city. Later, the Route 15 was built between the city and Shediac. At the same time, the Petitcodiac River Causeway was constructed. The Université de Moncton was founded in 1963. This institution became an important resource in the development of Acadian culture in the area.

The late 1970s and the 1980s were a period of economic hardship for the city as several major employers closed or restructured. The Eatons catalogue division, CNR's locomotive shops facility and CFB Moncton were closed during this time throwing thousands of citizens out of work.

The city diversified in the early 1990s with the rise of information technology, led by call centres which made use of the city's bilingual workforce. By the late 1990s, retail, manufacturing and service expansion began to occur in all sectors and within a decade of the closure of the CNR locomotive shops Moncton had more than made up for its employment losses. This dramatic turnaround in the fortunes of the city has been termed the "Moncton Miracle".

The growth of the community has continued unabated since the 1990s and has actually been accelerating. The confidence of the community has been bolstered by its ability to host major events such as the Francophonie Summit in 1999, a Rolling Stones concert in 2005, the Memorial Cup in 2006 and both the IAAF World Junior Championships in Athletics and a neutral site regular season CFL football game in 2010. Positive developments include the Atlantic Baptist University (later renamed Crandall University) achieving full university status and relocating to a new campus in 1996, the Greater Moncton Airport opening a new terminal building and becoming a designated international airport in 2002, and the opening of the new Gunningsville Bridge to Riverview in 2005. In 2002, Moncton became Canada's first officially bilingual city. In the 2006 census, Moncton was designated a Census Metropolitan Area and became the largest metropolitan area in the province of New Brunswick.

Moncton lies in southeastern New Brunswick, at the geographic centre of the Maritime Provinces. The city is located along the north bank of the Petitcodiac River at a point where the river bends acutely from a west−east to north−south flow. This geographical feature has contributed significantly to historical names given to the community. "Petitcodiac" in the Mi'kmaq language has been translated as meaning "bends like a bow". The early Acadian settlers in the region named their community "Le Coude" which means "the elbow". Subsequent English immigrants changed the name of the settlement to "The Bend of the Petitcodiac" (or simply The Bend).

The Petitcodiac river valley at Moncton is broad and relatively flat, bounded by a long ridge to the north (Lutes Mountain) and by the rugged Caledonia Highlands to the south. Moncton lies at the original head of navigation on the river, however a causeway to Riverview (constructed in 1968) resulted in extensive sedimentation of the river channel downstream and rendered the Moncton area of the waterway unnavigable. On 14 April 2010, the causeway gates were opened in an effort to restore the silt-laden river.

There are many natural attractions near Moncton. Two major national parks, Fundy National Park and Kouchibouguac National Park, are within a one-hour drive of the city. The warmest salt water beaches north of Virginia can be found on the Northumberland Strait, only 15 minutes away at Parlee Beach in the nearby town of Shediac. New Brunswick's signature natural attraction, the Hopewell Rocks, are a half-hour's drive down the Petitcodiac river valley. Cape Enrage, located near Alma, includes a historic lighthouse, fossil cliffs, scenic vistas, and adventure tourism. The Sackville Waterfowl Park includes nature trails, a boardwalk over a freshwater marsh, and waterfowl viewing platforms. Other nearby attractions (within one hour of the city) include The Cape Jourimain National Wildlife Preserve, La Dune de Bouctouche Eco-Centre, (an ecotourism site and beach) and the Joggins Fossil Cliffs in Nova Scotia; a UNESCO world heritage site. The entire upper reaches of the Bay of Fundy, including the Petitcodiac River Valley and the City of Moncton are part of the UNESCO Fundy Biosphere Reserve. 

The Petitcodiac River exhibits one of North America's few tidal bores: a regularly occurring wave that travels up the river on the leading edge of the incoming tide. The bore is as a result of the extreme tides of the Bay of Fundy. Originally, the bore was very impressive, sometimes between in height and extending across the width of the Petitcodiac River in the Moncton area. This wave would occur twice a day at high tide, travelling at an average speed of and producing an audible roar. Unsurprisingly, the "bore" became a very popular early tourist attraction for the city, but when the Petitcodiac causeway was built in the 1960s, the river channel quickly silted in and reduced the bore so that it rarely exceeds in height. On 14 April 2010, the causeway gates were opened in an effort to restore the silt-laden river. A recent tidal bore since the opening of the causeway gates measured a wave, unseen for many years.

Despite being less than from the Bay of Fundy and less than from the Northumberland Strait, the climate tends to be more continental than maritime during the summer and winter seasons, with maritime influences somewhat tempering the transitional seasons of spring and autumn.

Moncton has a warm summer continental climate (Köppen climate classification "Dfb") with uniform precipitation distribution. Winter days are typically cold but generally sunny with solar radiation generating some warmth. Daytime high temperatures usually range a few degrees below the freezing point. Major snowfalls can result from nor'easter ocean storms moving up the east coast of North America. These major snowfalls typically average 20–30 cm (8–12 in) and are frequently mixed with rain or freezing rain. Spring is frequently delayed because the sea ice that forms in the nearby Gulf of St. Lawrence during the previous winter requires time to melt, and this will cool onshore winds, which can extend inland as far as Moncton. The ice burden in the gulf has diminished considerably over the course of the last decade (which may be a consequence of global warming), and the springtime cooling effect has weakened as a result. Daytime temperatures above freezing are typical by late February. Trees are usually in full leaf by late May. Summers are hot and humid due to the seasonal prevailing westerly winds strengthening the continental tendencies of the local climate. Daytime highs sometimes reach more than 30 °C (86 °F). Rainfall is generally modest, especially in late July and August, and periods of drought are not uncommon. Autumn daytime temperatures remain mild until late October. First snowfalls usually do not occur until late November and consistent snow cover on the ground does not happen until late December. The Fundy coast of New Brunswick occasionally experiences the effects of post-tropical storms. The stormiest weather of the year, with the greatest precipitation and the strongest winds, usually occurs during the fall/winter transition (November to mid-January).

The highest temperature ever recorded in Moncton was on August 18 & 19, 1935. The coldest temperature ever recorded was on February 5, 1948.

Moncton generally remains a "low rise" city. The city's skyline however encompasses many buildings and structures with varying architectural styles from many periods. The most dominant structure in the city is the Bell Aliant Tower, a microwave communications tower built in 1971. When it was constructed, it was the tallest microwave communications tower of its kind in North America. It remains the tallest structure in Moncton, dwarfing the neighbouring Place L’Assomption by . Indeed, the Bell Aliant Tower is also the tallest free-standing structure in all four Atlantic provinces. Assumption Place is a 20-story office building and is the headquarters of Assumption Mutual Life Insurance. This building is in height and is tied with Brunswick Square (Saint John) as the tallest building in the province. The Blue Cross Centre is a large nine-story building in Downtown Moncton. Although only nine stories tall, the building is architecturally distinctive, encompasses a full city block, and is the largest office building in the city in terms of square footage. It is the home of Medavie Blue Cross and the Moncton Public Library. There are about a half dozen other buildings in Moncton that range between eight and twelve stories in height, including the Delta Beausejour and Brunswick Crowne Plaza Hotels and the Terminal Plaza office complex.
The most popular park in the area is Centennial Park, which contains an artificial beach, lighted cross country skiing and hiking trails, the city's largest playground, lawn bowling and tennis facilities, a boating pond, a treetop adventure course, and Rocky Stone Field, a city owned 2,500 seat football stadium with artificial turf, and home to the Moncton Minor Football Association.
The city's other main parks are Mapleton Park in the city's north end, Irishtown Nature Park (one of the largest urban nature parks in Canada) and St. Anselme Park (located in Dieppe). The numerous neighbourhood parks throughout the metro Moncton area include Bore View Park (which overlooks the Petitcodiac River), and the downtown Victoria Park, which features a bandshell, flower gardens, fountain, and the city's cenotaph. There is an extensive system of hiking and biking trails in Metro Moncton. The Riverfront Trail is part of the Trans Canada Trail system, and various monuments and pavilions can be found along its length.

The population of Moncton is 71,889 (2016 Census). Along with Fredericton and Halifax, Moncton is one of only three Maritime cities to register a population increase in recent years.

Moncton is a bilingual city. About two-thirds of its residents are native English speakers, while the remaining third is French-speaking. Almost all Monctonians speak English (64.6%) or French (31.9%) as first languages; 1.6% speak both languages as a first language, and 6.9% speak another language. About 46% of the city population is bilingual and understands both English and French; the only other Canadian cities that approach this level of linguistic duality are Ottawa, Sudbury, and Montreal. Moncton became the first officially bilingual city in the country in 2002. The adjacent city of Dieppe is about 73% Francophone and has benefited from an ongoing rural depopulation of the Acadian Peninsula and areas in northern and eastern New Brunswick. The town of Riverview meanwhile is heavily (95%) Anglophone.

The census metropolitan area (CMA) grew by 4% between 2011 and 2016. The census metropolitan area had a population of 144,810 as of the 2016 national census, which makes it the largest metropolitan area in the province of New Brunswick and the second largest in the Maritime Provinces after Halifax. The CMA includes the city of Dieppe (population 25,384), town of Riverview (19,667), Moncton Parish (9,811), Memramcook (4,778), Coverdale Parish (4,466), and Salisbury (2,284).

Migration is mostly from other areas of New Brunswick (especially the north), Nova Scotia (13%), and Ontario (9%). 62% of new arrivals to the city are Anglophone and 38% are Francophone.

There are 2,990 Aboriginal people living in Moncton, who make up 4.3% of the city's population. There are 3,305 visible minorities in Moncton. Blacks and South Asians are the largest visible minority groups, comprising 1.7% and 0.7% of the city's population, respectively. There is also a growing Korean community in Moncton.

The underpinnings of the local economy are based on Moncton's heritage as a commercial, distribution, transportation, and retailing centre. This is due to Moncton's central location in the Maritimes: it has the largest catchment area in Atlantic Canada with 1.6 million people living within a three-hour drive of the city. The insurance, information technology, educational, and health care sectors also are major factors in the local economy with the city's two hospitals alone employing over five thousand people.

Moncton has garnered national attention because of the strength of its economy. The local unemployment rate averages around 6%, which is below the national average. In 2004 Canadian Business Magazine named it "The best city for business in Canada", and in 2007 FDi magazine named it the fifth most business friendly small-sized city in North America.

A number of nationally or regionally prominent corporations have their head offices in Moncton including Atlantic Lottery Corporation, Assumption Life Insurance, Medavie Blue Cross Insurance, Armour Transportation Systems and Major Drilling Group International. Moncton also has federal public service employment, with regional head offices for Corrections Canada, Transport Canada, the Gulf Fisheries Centre and the Atlantic Canada Opportunities Agency.

There are 37 call centres in the city which employ over 5000 people. Some of the larger centres include Asurion, Numeris (formerly BBM Canada), Exxon Mobil, Royal Bank of Canada, Tangerine Bank (formerly ING Direct), UPS, Fairmont Hotels and Resorts, Rogers Communications, and Sitel. A growing high tech sector includes companies such as Gtech, Nanoptix, International Game Technology, OAO Technology Solutions, BMM Test Labs, TrustMe, and BelTek Systems Design. TD Bank announced in 2018 a new banking services centre to be located in Moncton which will employ over 1,000 people (including a previously announced customer contact centre). 

Several arms of the Irving corporation have their head offices and/or major operations in greater Moncton. These include Midland Transport, Majesta/Royale Tissues, Irving Personal Care, Master Packaging, Brunswick News, and Cavendish Farms. Kent Building Supplies (an Irving subsidiary) opened their main distribution centre in the Caledonia Industrial Park in 2014. The Irving group of companies employs several thousand people in the Moncton region.

There are three large industrial parks in the metropolitan area. The Irving operations are concentrated in the Dieppe Industrial Park. The Moncton Industrial Park in the city's west end has been expanded. Molson/Coors opened a brewery in the Caledonia Industrial Park in 2007, its first new brewery in over fifty years. All three industrial parks also have large concentrations of warehousing and regional trucking facilities.

A new four-lane Gunningsville Bridge was opened in 2005, connecting downtown Riverview directly with downtown Moncton. On the Moncton side, the bridge connects with an extension of Vaughan Harvey Boulevard as well as to Assumption Boulevard and will serve as a catalyst for economic growth in the downtown area. This has become already evident as an expansion to the Blue Cross Centre was completed in 2006 and a Marriott Residence Inn opened in 2008. The new regional law courts on Assumption Blvd opened in 2011. Construction has begun on a new downtown 8,500 seat multipurpose events centre and arena on the site of the former Highfield Square shopping centre. This arena will open in 2018. On the Riverview side, the Gunningsville Bridge now connects to a new ring road around the town and is expected to serve as a catalyst for development in east Riverview.

The retail sector in Moncton has become one of the most important pillars of the local economy. Major retail projects such as Champlain Place in Dieppe and the Wheeler Park Power Centre on Trinity Drive have become major destinations for locals and for tourists alike.

Tourism is an important industry in Moncton and historically owes its origins to the presence of two natural attractions, the tidal bore of the Petitcodiac River (see above) and the optical illusion of Magnetic Hill. The tidal bore was the first phenomenon to become an attraction but the construction of the Petitcodiac causeway in the 1960s effectively extirpated the attraction. Magnetic Hill, on the city's northwest outskirts, is the city's most famous attraction. The Magnetic Hill area includes (in addition to the phenomenon itself), a golf course, major water park, zoo, and an outdoor concert facility. A $90 million casino/hotel/entertainment complex opened at Magnetic Hill in 2010.

Moncton's Capitol Theatre, an 800-seat restored 1920s-era vaudeville house on Main Street, is the main centre for cultural entertainment for the city. The theatre hosts a performing arts series and provides a venue for various theatrical performances as well as Symphony New Brunswick and the Atlantic Ballet Theatre of Canada. The adjacent Empress Theatre offers space for smaller performances and recitals. The Molson Canadian Centre at Casino New Brunswick provides a 2,000 seat venue for major touring artists and performing groups.

The Moncton-based Atlantic Ballet Theatre tours mainly in Atlantic Canada but also tours nationally and internationally on occasion. Théâtre l'Escaouette is a Francophone live theatre company which has its own auditorium and performance space on Botsford Street. The Anglophone Live Bait Theatre is based in the nearby university town of Sackville. There are several private dance and music academies in the metropolitan area, including the Capitol Theatre's own performing arts school.

The Aberdeen Cultural Centre is a major Acadian cultural cooperative containing multiple studios and galleries. Among other tenants, the Centre houses the Galerie Sans Nom, the principal private art gallery in the city.

The city's two main museums are the Moncton Museum at Resurgo Place on Mountain Road and the Musée acadien at Université de Moncton. The Moncton Museum reopened following major renovations and an expansion to include the Transportation Discovery Centre. The Discovery Centre includes many hands on exhibits highlighting the city's transportation heritage. The city also has several recognized historical sites. The Free Meeting House was built in 1821 and is a New England-style meeting house located adjacent to the Moncton Museum. The Thomas Williams House, a former home of a city industrialist built in 1883, is now maintained in period style and serves as a genealogical research centre and is also home to several multicultural organizations. The Treitz Haus is located on the riverfront adjacent to Bore View Park and has been dated to 1769 both by architectural style and by dendrochronology. It is the only surviving building from the Pennsylvania Dutch era and is the oldest surviving building in the province of New Brunswick.

In film production, the city has since 1974 been home to the National Film Board of Canada's French-language Studio Acadie.

Moncton is home to the Frye Festival, an annual bilingual literary celebration held in honour of world-renowned literary critic and favourite son Northrop Frye. This event attracts noted writers and poets from around the world and takes place in the month of April.

The Atlantic Nationals Automotive Extravaganza, held each July, is the largest annual gathering of classic cars in Canada. Other notable events include The Atlantic Seafood Festival in August, The HubCap Comedy Festival, and the World Wine Festival, both held in the spring.

Magnetic Hill is on the northwestern outskirts of Moncton and is now the city's most famous attraction. It is a gravity hill optical illusion, where the local topography gives the impression that you are going uphill when in fact you are going downhill.

The "Magnetic Hill Illusion" is a popular tourism draw and both the city and province have built major tourism developments on the surrounding properties to capitalize on this. The complex includes The "Magnetic Hill Zoo", a nationally accredited and award-winning zoo with over 400 animals displayed in themed exhibit areas. It is the largest zoo in Atlantic Canada, has well-developed and popular educational program, and was ranked as the fourth best zoo in Canada in 2007. Also on site is Magic Mountain, the largest water park in Atlantic Canada, with a half dozen large water slides, a lazy river, wave pool, children's splash pool, and a 36-hole mini-golf course. An adjacent amusement park is now under construction and will be completed in 2017. The Magnetic Hill Concert Site, a large outdoor concert facility which holds one or two large concerts every year is located nearby. The Rolling Stones performed there in 2005 in front of 85,000 fans. The Eagles played there in the summer of 2008 in front of 55,000 fans. AC/DC and Bon Jovi played at the hill in 2009, with the crowd for the AC/DC concert exceeding 70,000. The Magnetic Hill Concert Site has developed a reputation for holding the largest concert productions in the entire country. U2 played the final concert of their worldwide U2 360° Tour at Magnetic Hill on 30 July 2011. The Casino New Brunswick, which also encompasses a hotel and 2,000 seat entertainment venue also opened at Magnetic Hill in 2010. The performance space at the Casino New Brunswick has already hosted many top acts on the casino circuit.

At present, the major destinations for shopping enthusiasts in Greater Moncton are the Northwest Centre, and the Wheeler Park Power Centre in Moncton, and Champlain Place in Dieppe, which, at , is the largest shopping mall in Atlantic Canada and has over 160 stores and services. 
The Bass Pro Complex is adjacent to Champlain Place and is co-managed by Cadillac Fairview. It includes a Chapters bookstore, multiplex cinema complex and includes a Bass Pro Shop.

The Moncton Coliseum is a 6,554-seat arena which serves as a venue for major concerts and trade shows and is the home of the Moncton Wildcats of the Quebec Major Junior Hockey League. The CN Sportplex is a major recreational facility which has been built on the former CN Shops property. It includes ten ballfields, six soccer fields, an indoor rink complex with four ice surfaces (the Superior Propane Centre) and the Hollis Wealth Sports Dome, an indoor air supported multi-use building. The Sports Dome is large enough to allow for year-round football, soccer and golf activities. A newly constructed YMCA near the CN Sportsplex has extensive cardio and weight training facilities, as well as three indoor pools. The CEPS at Université de Moncton contains an indoor track and a swimming pool with diving towers. The new Moncton Stadium, also located at the U de M campus was built for the 2010 IAAF World Junior Track & Field Championships. It has a permanent seating for 10,000, but is expandable to a capacity of over 20,000 for events such as professional Canadian football. The only velodrome in Atlantic Canada is in Dieppe. The metro area has a total of 12 indoor hockey rinks and three curling clubs. Other public sporting and recreational facilities are scattered throughout the metropolitan area, including a new $18 million aquatic centre in Dieppe opened in 2009. Construction of a new 8,800 seat downtown arena and events centre is nearing completion and is expected to open in September, 2018.

Greater Moncton has many golfing facilities. There are nine 18-hole golf courses in the census metropolitan area, four of which are residential courses with courseside housing developments either existing or under construction. Both the Royal Oaks and Fox Creek golf clubs can be considered championship courses, with Royal Oaks being the first Rees Jones designed golf course in Canada. Other notable courses include the Moncton Golf & Country Club, Hillsborough Golf Club, Memramcook Valley Golf Club and the Mountain Woods Golf Club.

The Moncton Wildcats play major junior hockey in the Quebec Major Junior Hockey League (QMJHL). They won the President's Cup, the QMJHL championship in both 2006 and 2010. Historically there has been a longstanding presence of a Moncton-based team in the Maritime Junior A Hockey League, but the Dieppe Commandos (formerly known as the Moncton Beavers) relocated to Edmundston at the end of the 2017 season. Historically, Moncton also was home to a professional American Hockey League franchise from 1978 to 1994. The New Brunswick Hawks won the AHL Calder Cup by defeating the Binghamton Whalers in 1981-1982. The Moncton Mets played baseball in the New Brunswick Senior Baseball League and won the Canadian Senior Baseball Championship in 2006. In 2015, the Moncton Fisher Cats began play in the New Brunswick Senior Baseball League. They were formed by a merger between the Moncton Mets and the Hub City Brewers of the NBSBL. In 2011, the Moncton Miracles began play as one of the seven charter franchises of the professional National Basketball League of Canada. The franchise failed at the end of the 2016/17 season, to be immediately replaced by a new NBL franchise, the Moncton Magic, which will play their inaugural season in 2017/18. The Universite de Moncton has a number of active CIS university sports programs including hockey, soccer, and volleyball. These teams are a part of the Canadian Interuniversity Sport program.

Moncton has hosted many large sporting events. The 2006 Memorial Cup was held in Moncton with the hometown Moncton Wildcats losing in the championship final to rival Quebec Remparts. Moncton hosted the Canadian Interuniversity Sports (CIS) Men's University Hockey Championship in 2007 and 2008. The World Men's Curling Championship was held in Moncton in 2009; the second time this event has taken place in the city.

Moncton also hosted the 2010 IAAF World Junior Championships in Athletics. This was the largest sporting event ever held in Atlantic Canada, with athletes from over 170 countries in attendance. The new 10,000 seat capacity Moncton Stadium was built for this event on the Université de Moncton campus. The construction of this new stadium led directly to Moncton being awarded a regular season neutral site CFL game between the Toronto Argonauts and the Edmonton Eskimos, which was held on 26 September 2010. This was the first neutral site regular season game in the history of the Canadian Football League and was played before a capacity crowd of 20,750. Additional CFL regular season games were held in 2011 and 2013.

Moncton was one of only six Canadian cities chosen to host the 2015 FIFA Women's World Cup.

Major sporting events hosted by Moncton include:
The municipal government consists of a mayor and ten city councillors elected to four-year terms of office. The council is non-partisan with the mayor serving as the chairman, casting a ballot only in cases of a tie vote. There are four wards electing two councillors each with an additional two councillors selected at large by the general electorate. Day-to-day operation of the city is under the control of a City Manager.

The greater Moncton area contains nine of New Brunswick's 49 provincial electoral districts: Moncton Centre, Moncton East, Moncton South, Moncton Southwest, Moncton Northwest, Dieppe, Shediac Bay-Dieppe, Riverview and Albert. Of the nine members of the Legislative Assembly that represent greater Moncton, five belong to the Liberal party and four belong to the Progressive Conservative party.

Moncton is in the federal riding of Moncton—Riverview—Dieppe. Portions of Dieppe are in the federal riding of Beauséjour, and portions of Riverview are in the riding of Fundy Royal. In the current federal parliament, all three members from the metropolitan area belong to the Liberal party.

The current federal MP for Moncton—Riverview—Dieppe is Ginette Petitpas Taylor (Liberal), as of the 2015 federal election.

Aside from locally formed militia units, the military did not have a significant presence in the Moncton area until the beginning of the Second World War. In 1940, a large military supply base (later known as CFB Moncton) was constructed on a railway spur line north of downtown next to the CNR shops. This base served as the main supply depot for the large wartime military establishment in the Maritimes. In addition, two Commonwealth Air Training Plan bases were also built in the Moncton area during the war: No. 8 Service Flying Training School, RCAF, and No. 31 Personnel Depot, RAF. The RCAF also operated No. 5 Supply Depot in Moncton. A naval listening station was also constructed in Coverdale (Riverview) in 1941 to help in coordinating radar activities in the North Atlantic. Military flight training in the Moncton area terminated at the end of World War II and the naval listening station closed in 1971. CFB Moncton remained open to supply the maritime military establishment until just after the end of the Cold War.

With the closure of CFB Moncton in the early 1990s, the military presence in Moncton has been significantly reduced. The northern portion of the former base property has been turned over to the Canada Lands Corporation and is slowly being redeveloped. The southern part of the former base remains an active DND property and is now termed the Moncton Garrison. It is affiliated with CFB Gagetown. Resident components of the garrison include the 1 Engineer Support Unit(Regular force). The garrison also houses the 37 Canadian Brigade Group Headquarters (reserve force) and one of the 37 Brigades constituent units; the 8th Canadian Hussars (Princess Louise's), which is an armoured reconnaissance regiment. 3 Area support unit Det Moncton, and 42 Canadian Forces Health Services Center Det Moncton provide logistical support for the base. In 2013, the last regular forces units left the Moncton base, but the reserve units remain active and Moncton remains the 37 Canadian Brigade Unit headquarters.

There are two major regional referral and teaching hospitals in Moncton. The Moncton Hospital has approximately 381 inpatient beds and is affiliated with Dalhousie University Medical School. It is home to the Northumberland family medicine residency training program and is a site for third and fourth year clinical training for medical students in the Dalhousie Medicine New Brunswick Training Program. The hospital hosts UNB degree programs in nursing and medical x-ray technology and professional internships in fields such as dietetics. Specialized medical services at the hospital include neurosurgery, peripheral and neuro-interventional radiology, vascular surgery, thoracic surgery, hepatobiliary surgery, orthopedics, trauma, burn unit, medical oncology, neonatal intensive care, and adolescent psychiatry. A $48 million expansion to the hospital was completed in 2009 and contains a new laboratory, ambulatory care centre, and provincial level one trauma centre. A new oncology clinic was built at the hospital and opened in late 2014. The Moncton Hospital is managed by the Horizon Health Network (formerly the South East Regional Health Authority).

The Dr. Georges-L.-Dumont University Hospital Centre has about 302 beds and hosts a medical training program through the local CFMNB and distant Université de Sherbrooke Medical School. There are also degree programs in nursing, medical x-ray technology, medical laboratory technology and inhalotherapy which are administered by U de M. Specialized medical services include medical oncology, radiation oncology, orthopedics, vascular surgery, and nephrology. 
A cardiac cath lab is being studied for the hospital and a new PET/CT scanner has been installed. A $75 million expansion for ambulatory care, expanded surgery suites, and medical training is currently under construction. The hospital is also the location of the Atlantic Cancer Research Institute. This hospital is managed by Vitalité Health Network.

Moncton is served by the Greater Moncton Roméo LeBlanc International Airport (YQM). The airport was renamed for former Canadian Governor-General (and native son) Roméo LeBlanc in 2016. A new airport terminal with an international arrivals area was opened in 2002 by Her Majesty Queen Elizabeth II. The GMIA handles about 677,000 passengers per year, making it the second busiest airport in the Maritime provinces in terms of passenger volume. The GMIA is also the 10th busiest airport in Canada in terms of freight. Regular scheduled destinations include Halifax, Montreal, Ottawa, Toronto and Hamilton. Scheduled service providers include Air Canada, Air Canada Express, Westjet and Porter Airlines. Seasonal direct air service is provided to destinations in Cuba, Mexico, the Dominican Republic, Jamaica, and Florida, with operators including Sunwing Airlines, Air Transat, and Westjet. FedEx, UPS, and Purolator all have their Atlantic Canadian air cargo bases at the facility. The GMIA is the home of the Moncton Flight College; the largest pilot training institution in Canada, and is also the base for the regional RCMP air service, the New Brunswick Air Ambulance Service and the regional Transport Canada hangar and depot.

There is a second smaller aerodrome near Elmwood Drive. McEwen Airfield (CCG4) is a private airstrip used for general aviation. Skydive Moncton operates the province's only nationally certified sports parachute club out of this facility.

The Moncton Area Control Centre is one of only seven regional air traffic control centres in Canada. This centre monitors over 430,000 flights a year, 80% of which are either entering or leaving North American airspace.

Moncton lies on Route 2 of the Trans-Canada Highway, which leads to Nova Scotia in the east and to Fredericton and Quebec in the west. Route 15 intersects Route 2 at the eastern outskirts of Moncton, heads northeast leading to Shediac and northern New Brunswick, Route 16 connects to route 15 at Shediac and leads to Port Elgin and Prince Edward Island. Route 1 intersects Route 2 approximately west of the city and leads to Saint John and the U.S. border. Wheeler Boulevard (Route 15) serves as an internal ring road, extending from the Petitcodiac River Causeway to Dieppe before exiting the city and heading for Shediac. Inside the city it is an expressway bounded at either end by traffic circles.

The Metro Moncton Area is served by Codiac Transpo, which is operated by the City of Moncton. It operates 40 buses on 19 routes throughout Moncton, Dieppe, and Riverview.

Maritime Bus provides intercity service to the region. Moncton is the largest hub in the system. All other major centres in New Brunswick, as well as Charlottetown, Halifax, and Truro are served out of the Moncton terminal.

Freight rail transportation in Moncton is provided by Canadian National Railway. Although the presence of the CNR in Moncton has diminished greatly since the 1970s, the railway still maintains a large classification yard and intermodal facility in the west end of the city, and the regional headquarters for Atlantic Canada is still located here as well. Passenger rail transportation is provided by Via Rail Canada, with their train the "Ocean" serving the Moncton railway station three days per week to Halifax and to Montreal, Quebec. The downtown Via station has been refurbished and also serves as the terminal for the Maritime Bus intercity bus service.

Separate Anglophone and Francophone school boards administer greater Moncton's 35 public primary and secondary schools. The Francophone South School Board administers ten schools in the Moncton area. The Anglophone East School Board administers 25 schools in Greater Moncton. There are four Anglophone high schools in the metro Moncton area; Moncton High School, Harrison Trimble High School, Bernice MacNaughton High School, and Riverview High School. The area's Francophone high schools are École Mathieu-Martin and École L'Odyssée.

Four universities have campuses in the greater Moncton region.

Moncton is home to two campuses of the New Brunswick Community College system.

Moncton has six private vocational schools that offer practical training in a variety of fields. 

Moncton's daily newspaper is the "Times & Transcript", which has the highest circulation of any daily newspaper in New Brunswick. More than 60 percent of city households subscribe daily, and more than 90 percent of Moncton residents read the Times & Transcript at least once a week. The city's other publications include "L'Acadie Nouvelle", a French newspaper published in Caraquet in northern New Brunswick.

There are 16 broadcast radio stations in the city covering a variety of genres and interests, all on the FM dial. Ten of these stations are English and six are French.

Rogers Cable has its provincial headquarters and main production facilities in Moncton and broadcasts on two community channels, Cable 9 in French and Cable 10 in English. The French-language arm of the CBC, Radio-Canada, maintains its Atlantic Canadian headquarters in Moncton. There are three other broadcast television stations in Moncton and these represent all of the major national networks.

Moncton has been the home of a number of notable people, including National Hockey League Hall of Famer and NHL scoring champion Gordie Drillon, World and Olympic champion curler Russ Howard, distinguished literary critic and theorist Northrop Frye, former Governor-General of Canada Roméo LeBlanc, and former Supreme Court Justice Ivan Cleveland Rand, developer of the Rand Formula and Canada's representative on the UNSCOP commission. Trudy Mackay FRS , renowned quantitative geneticist, member of the Royal Society and National Academy of Sciences, and recipient of the prestigious Wolf Prize for agriculture (2016), was born in Moncton. Robb Wells, the actor who plays Ricky on the Showcase hit comedy "Trailer Park Boys" hails from Moncton, along with Chris Lee, Jacques Daigle, Julie Doiron, an indie rock musician, and Holly Dignard the actress who plays Nicole Miller on the CTV series "Whistler". Harry Currie, noted Canadian conductor, musician, educator, journalist and author was born in Moncton and graduated from MHS. Antonine Maillet, a francophone author, recipient of the Order of Canada and the "Prix Goncourt", the highest honour in francophone literature, is also from Moncton. France Daigle, another acclaimed Acadian novelist and playwright, was born and resides in Moncton, and is noted for her pioneering use of chiac in Acadian literature, was the recipient of the 2012 Governor General's Literary Prize in French Fiction, for her novel "Pour Sûr" (translated into English as "For Sure"). Canadian hockey star Sidney Crosby graduated from Harrison Trimble High School in Moncton.






</doc>
<doc id="19858" url="https://en.wikipedia.org/wiki?curid=19858" title="Model theory">
Model theory

In mathematics, model theory is the study of classes of mathematical structures (e.g. groups, fields, graphs, universes of set theory) from the perspective of mathematical logic. The objects of study are models of theories in a formal language. A set of sentences in a formal language is one of the components that form a theory. A model of a theory is a structure (e.g. an interpretation) that satisfies the sentences of that theory.

Model theory recognises and is intimately concerned with a duality: it examines semantical elements (meaning and truth) by means of syntactical elements (formulas and proofs) of a corresponding language.
Model theory developed rapidly during the 1990s, and a more modern definition is provided by Wilfrid Hodges (1997):

Other nearby areas of mathematics include combinatorics, number theory, arithmetic dynamics, analytic functions, and non-standard analysis.

In a similar way to proof theory, model theory is situated in an area of interdisciplinarity among mathematics, philosophy, and computer science. The most prominent professional organization in the field of model theory is the Association for Symbolic Logic.

This article focuses on finitary first order model theory of infinite structures. Finite model theory, which concentrates on finite structures, diverges significantly from the study of infinite structures in both the problems studied and the techniques used. Model theory in higher-order logics or infinitary logics is hampered by the fact that completeness and compactness do not in general hold for these logics. However, a great deal of study has also been done in such logics.

Informally, model theory can be divided into classical model theory, model theory applied to groups and fields, and geometric model theory. A missing subdivision is computable model theory, but this can arguably be viewed as an independent subfield of logic.

Examples of early theorems from classical model theory include Gödel's completeness theorem, the upward and downward Löwenheim–Skolem theorems, Vaught's two-cardinal theorem, Scott's isomorphism theorem, the omitting types theorem, and the Ryll-Nardzewski theorem. Examples of early results from model theory applied to fields are Tarski's elimination of quantifiers for real closed fields, Ax's theorem on pseudo-finite fields, and Robinson's development of non-standard analysis. An important step in the evolution of classical model theory occurred with the birth of stability theory (through Morley's theorem on uncountably categorical theories and Shelah's classification program), which developed a calculus of independence and rank based on syntactical conditions satisfied by theories.

During the last several decades applied model theory has repeatedly merged with the more pure stability theory. The result of this synthesis is called geometric model theory in this article (which is taken to include o-minimality, for example, as well as classical geometric stability theory). An example of a theorem from geometric model theory is Hrushovski's proof of the Mordell–Lang conjecture for function fields. The ambition of geometric model theory is to provide a "geography of mathematics" by embarking on a detailed study of definable sets in various mathematical structures, aided by the substantial tools developed in the study of pure model theory.

Fundamental concepts in universal algebra are signatures σ and σ-algebras. Since these concepts are formally defined in the article on structures, the present article is an informal introduction which consists of examples of the way these terms are used.

This is a very efficient way to define most classes of algebraic structures, because there is also the concept of σ-homomorphism, which correctly specializes to the usual notions of homomorphism for groups, semigroups, magmas and rings. For this to work, the signature must be chosen well.

Terms such as the σ-term "t"("u","v","w") given by are used to define identities but also to construct free algebras. An equational class is a class of structures which, like the examples above and many others, is defined as the class of all σ-structures which satisfy a certain set of identities. Birkhoff's theorem states:

An important non-trivial tool in universal algebra are ultraproducts formula_1, where "I" is an infinite set indexing a system of σ-structures "A", and "U" is an ultrafilter on "I".

While model theory is generally considered a part of mathematical logic, universal algebra, which grew out of Alfred North Whitehead's (1898) work on abstract algebra, is part of algebra. This is reflected by their respective MSC classifications. Nevertheless, model theory can be seen as an extension of universal algebra.

Finite model theory is the area of model theory which has the closest ties to universal algebra. Like some parts of universal algebra, and in contrast with the other areas of model theory, it is mainly concerned with finite algebras, or more generally, with finite σ-structures for signatures σ which may contain relation symbols as in the following example:

A σ-homomorphism is a map that commutes with the operations and preserves the relations in σ. This definition gives rise to the usual notion of graph homomorphism, which has the interesting property that a bijective homomorphism need not be invertible. Structures are also a part of universal algebra; after all, some algebraic structures such as ordered groups have a binary relation <. What distinguishes finite model theory from universal algebra is its use of more general logical sentences (as in the example above) in place of identities. (In a model-theoretic context an identity "t"="t<nowiki>'</nowiki>" is written as a sentence formula_3.)

The logics employed in finite model theory are often substantially more expressive than first-order logic, the standard logic for model theory of infinite structures.

Whereas universal algebra provides the semantics for a signature, logic provides the syntax. With terms, identities and quasi-identities, even universal algebra has some limited syntactic tools; first-order logic is the result of making quantification explicit and adding negation into the picture.

A first-order formula is built out of atomic formulas such as "R"("f"("x","y"),"z") or "y" = "x" + 1 by means of the Boolean connectives formula_4 and prefixing of quantifiers formula_5 or formula_6. A sentence is a formula in which each occurrence of a variable is in the scope of a corresponding quantifier. Examples for formulas are φ (or φ(x) to mark the fact that at most x is an unbound variable in φ) and ψ defined as follows:

(Note that the equality symbol has a double meaning here.) It is intuitively clear how to translate such formulas into mathematical meaning. In the σ-structure formula_9 of the natural numbers, for example, an element "n" satisfies the formula φ if and only if "n" is a prime number. The formula ψ similarly defines irreducibility. Tarski gave a rigorous definition, sometimes called "Tarski's definition of truth", for the satisfaction relation formula_10, so that one easily proves:

A set "T" of sentences is called a (first-order) theory. A theory is satisfiable if it has a model formula_13, i.e. a structure (of the appropriate signature) which satisfies all the sentences in the set "T". Consistency of a theory is usually defined in a syntactical way, but in first-order logic by the completeness theorem there is no need to distinguish between satisfiability and consistency. Therefore, model theorists often use "consistent" as a synonym for "satisfiable".

A theory is called categorical if it determines a structure up to isomorphism, but it turns out that this definition is not useful, due to serious restrictions in the expressivity of first-order logic. The Löwenheim–Skolem theorem implies that for every theory "T" having a countable signature which has an infinite model for some infinite cardinal number, then it has a model of size κ for any infinite cardinal number κ. Since two models of different sizes cannot possibly be isomorphic, only finitary structures can be described by a categorical theory.

Lack of expressivity (when compared to higher logics such as second-order logic) has its advantages, though. For model theorists, the Löwenheim–Skolem theorem is an important practical tool rather than the source of Skolem's paradox. In a certain sense made precise by Lindström's theorem, first-order logic is the most expressive logic for which both the Löwenheim–Skolem theorem and the compactness theorem hold.

As a corollary (i.e., its contrapositive), the compactness theorem says that every unsatisfiable first-order theory has a finite unsatisfiable subset. This theorem is of central importance in infinite model theory, where the words "by compactness" are commonplace. One way to prove it is by means of ultraproducts. An alternative proof uses the completeness theorem, which is otherwise reduced to a marginal role in most of modern model theory.

The first step, often trivial, for applying the methods of model theory to a class of mathematical objects such as groups, or trees in the sense of graph theory, is to choose a signature σ and represent the objects as σ-structures. The next step is to show that the class is an elementary class, i.e. axiomatizable in first-order logic (i.e. there is a theory "T" such that a σ-structure is in the class if and only if it satisfies "T"). E.g. this step fails for the trees, since connectedness cannot be expressed in first-order logic. Axiomatizability ensures that model theory can speak about the right objects. Quantifier elimination can be seen as a condition which ensures that model theory does not say too much about the objects.

A theory "T" has quantifier elimination if every first-order formula φ(x...,x) over its signature is equivalent modulo "T" to a first-order formula ψ(x...,x) without quantifiers, i.e. formula_14 holds in all models of "T". For example, the theory of algebraically closed fields in the signature σ=(×,+,−,0,1) has quantifier elimination because every formula is equivalent to a Boolean combination of equations between polynomials.

A substructure of a σ-structure is a subset of its domain, closed under all functions in its signature σ, which is regarded as a σ-structure by restricting all functions and relations in σ to the subset. An embedding of a σ-structure formula_15 into another σ-structure formula_16 is a map f: A → B between the domains which can be written as an isomorphism of formula_15 with a substructure of formula_16. Every embedding is an injective homomorphism, but the converse holds only if the signature contains no relation symbols.

If a theory does not have quantifier elimination, one can add additional symbols to its signature so that it does. Early model theory spent much effort on proving axiomatizability and quantifier elimination results for specific theories, especially in algebra. But often instead of quantifier elimination a weaker property suffices:

A theory "T" is called model-complete if every substructure of a model of "T" which is itself a model of "T" is an elementary substructure. There is a useful criterion for testing whether a substructure is an elementary substructure, called the Tarski–Vaught test. It follows from this criterion that a theory "T" is model-complete if and only if every first-order formula φ(x...,x) over its signature is equivalent modulo "T" to an existential first-order formula, i.e. a formula of the following form:
where ψ is quantifier free. A theory that is not model-complete may or may not have a model completion, which is a related model-complete theory that is not, in general, an extension of the original theory. A more general notion is that of model companions.

As observed in the section on first-order logic, first-order theories cannot be categorical, i.e. they cannot describe a unique model up to isomorphism, unless that model is finite. But two famous model-theoretic theorems deal with the weaker notion of κ-categoricity for a cardinal κ. A theory "T" is called κ-categorical if any two models of "T" that are of cardinality κ are isomorphic. It turns out that the question of κ-categoricity depends critically on whether κ is bigger than the cardinality of the language (i.e. formula_20 + |σ|, where |σ| is the cardinality of the signature). For finite or countable signatures this means that there is a fundamental difference between formula_20-cardinality and κ-cardinality for uncountable κ.

A few characterizations of formula_20-categoricity include:

This result, due independently to Engeler, Ryll-Nardzewski and Svenonius, is sometimes referred to as the Ryll-Nardzewski theorem.

Further, formula_20-categorical theories and their countable models have strong ties with oligomorphic groups. They are often constructed as Fraïssé limits.

Michael Morley's highly non-trivial result that (for countable languages) there is only "one" notion of uncountable categoricity was the starting point for modern model theory, and in particular classification theory and stability theory:

Uncountably categorical (i.e. κ-categorical for all uncountable cardinals κ) theories are from many points of view the most well-behaved theories. A theory that is both formula_20-categorical and uncountably categorical is called totally categorical.

Set theory (which is expressed in a countable language), if it is consistent, has a countable model; this is known as Skolem's paradox, since there are sentences in set theory which postulate the existence of uncountable sets and yet these sentences are true in our countable model. Particularly the proof of the independence of the continuum hypothesis requires considering sets in models which appear to be uncountable when viewed from "within" the model, but are countable to someone "outside" the model.

The model-theoretic viewpoint has been useful in set theory; for example in Kurt Gödel's work on the constructible universe, which, along with the method of forcing developed by Paul Cohen can be shown to prove the (again philosophically interesting) independence of the axiom of choice and the continuum hypothesis from the other axioms of set theory.

In the other direction, model theory itself can be formalized within ZFC set theory. The development of the fundamentals of model theory (such as the compactness theorem) rely on the axiom of choice, or more exactly the Boolean prime ideal theorem. Other results in model theory depend on set-theoretic axioms beyond the standard ZFC framework. For example, if the Continuum Hypothesis holds then every countable model has an ultrapower which is saturated (in its own cardinality). Similarly, if the Generalized Continuum Hypothesis holds then every model has a saturated elementary extension. Neither of these results are provable in ZFC alone. Finally, some questions arising from model theory (such as compactness for infinitary logics) have been shown to be equivalent to large cardinal axioms.

A field or a vector space can be regarded as a (commutative) group by simply ignoring some of its structure. The corresponding notion in model theory is that of a reduct of a structure to a subset of the original signature. The opposite relation is called an "expansion" - e.g. the (additive) group of the rational numbers, regarded as a structure in the signature {+,0} can be expanded to a field with the signature {×,+,1,0} or to an ordered group with the signature {+,0,<}.

Similarly, if σ' is a signature that extends another signature σ, then a complete σ'-theory can be restricted to σ by intersecting the set of its sentences with the set of σ-formulas. Conversely, a complete σ-theory can be regarded as a σ'-theory, and one can extend it (in more than one way) to a complete σ'-theory. The terms reduct and expansion are sometimes applied to this relation as well.

Given a mathematical structure, there are very often associated structures which can be constructed as a quotient of part of the original structure via an equivalence relation. An important example is a quotient group of a group.

One might say that to understand the full structure one must understand these quotients. When the equivalence relation is definable, we can give the previous sentence a precise meaning. We say that these structures are interpretable.

A key fact is that one can translate sentences from the language of the interpreted structures to the language of the original structure. Thus one can show that if a structure "M" interprets another whose theory is undecidable, then "M" itself is undecidable.

Gödel's completeness theorem (not to be confused with his incompleteness theorems) says that a theory has a model if and only if it is consistent, i.e. no contradiction is proved by the theory. This is the heart of model theory as it lets us answer questions about theories by looking at models and vice versa. One should not confuse the completeness theorem with the notion of a complete theory. A complete theory is a theory that contains every sentence or its negation. Importantly, one can find a complete consistent theory extending any consistent theory. However, as shown by Gödel's incompleteness theorems only in relatively simple cases will it be possible to have a complete consistent theory that is also recursive, i.e. that can be described by a recursively enumerable set of axioms. In particular, the theory of natural numbers has no recursive complete and consistent theory. Non-recursive theories are of little practical use, since it is undecidable if a proposed axiom is indeed an axiom, making proof-checking a supertask.

The compactness theorem states that a set of sentences S is satisfiable if every finite subset of S is satisfiable. In the context of proof theory the analogous statement is trivial, since every proof can have only a finite number of antecedents used in the proof. In the context of model theory, however, this proof is somewhat more difficult. There are two well known proofs, one by Gödel (which goes via proofs) and one by Malcev (which is more direct and allows us to restrict the cardinality of the resulting model).

Model theory is usually concerned with first-order logic, and many important results (such as the completeness and compactness theorems) fail in second-order logic or other alternatives. In first-order logic all infinite cardinals look the same to a language which is countable. This is expressed in the Löwenheim–Skolem theorems, which state that any countable theory with an infinite model formula_26 has models of all infinite cardinalities (at least that of the language) which agree with formula_26 on all sentences, i.e. they are 'elementarily equivalent'.

Fix an formula_28-structure formula_29, and a natural number formula_30. The set of definable subsets of formula_31 over some parameters formula_32 is a Boolean algebra. By Stone's representation theorem for Boolean algebras there is a natural dual notion to this. One can consider this to be the topological space consisting of maximal consistent sets of formulae over formula_32. We call this the space of (complete) formula_30-types over formula_32, and write formula_36.

Now consider an element formula_37. Then the set of all formulae formula_38 with parameters in formula_32 in free variables formula_40 so that formula_41 is consistent and maximal such. It is called the "type" of formula_42 over formula_32.

One can show that for any formula_30-type formula_45, there exists some elementary extension formula_46 of formula_29 and some formula_48 so that formula_45 is the type of formula_50 over formula_32.

Many important properties in model theory can be expressed with types. Further many proofs go via constructing models with elements that contain elements with certain types and then using these elements.

Illustrative Example: Suppose formula_29 is an algebraically closed field. The theory has quantifier elimination . This allows us to show that a type is determined exactly by the polynomial equations it contains. Thus the space of formula_30-types over a subfield formula_32 is bijective with the set of prime ideals of the polynomial ring formula_55. This is the same set as the spectrum of formula_55. Note however that the topology considered on the type space is the constructible topology: a set of types is basic open iff it is of the form formula_57 or of the form formula_58. This is finer than the Zariski topology.

Model theory as a subject has existed since approximately the middle of the 20th century. However some earlier research, especially in mathematical logic, is often regarded as being of a model-theoretical nature in retrospect. The first significant result in what is now model theory was a special case of the downward Löwenheim–Skolem theorem, published by Leopold Löwenheim in 1915. The compactness theorem was implicit in work by Thoralf Skolem, but it was first published in 1930, as a lemma in Kurt Gödel's proof of his completeness theorem. The Löwenheim–Skolem theorem and the compactness theorem received their respective general forms in 1936 and 1941 from Anatoly Maltsev.

The development of model theory can be traced to Alfred Tarski, a member of the Lwów–Warsaw school during the interbellum. Tarski's work included logical consequence, deductive systems, the algebra of logic, the theory of definability, and the semantic definition of truth, among other topics. His semantic methods culminated in the model theory he and a number of his Berkeley students developed in the 1950s and 60s. These modern concepts of model theory influenced Hilbert's program and modern mathematics.







</doc>
<doc id="19859" url="https://en.wikipedia.org/wiki?curid=19859" title="Moby-Dick">
Moby-Dick

Moby-Dick; or, The Whale is an 1851 novel by American writer Herman Melville. The book is sailor Ishmael's narrative of the obsessive quest of Ahab, captain of the whaling ship "Pequod", for revenge on Moby Dick, the white whale that on the ship's previous voyage bit off Ahab's leg at the knee. A contribution to the literature of the American Renaissance, the work's genre classifications range from late Romantic to early Symbolist. "Moby-Dick" was published to mixed reviews, was a commercial failure, and was out of print at the time of the author's death in 1891. Its reputation as a "Great American Novel" was established only in the 20th century, after the centennial of its author's birth. William Faulkner confessed he wished he had written the book himself, and D. H. Lawrence called it "one of the strangest and most wonderful books in the world" and "the greatest book of the sea ever written". Its opening sentence, "Call me Ishmael", is among world literature's most famous.

Melville began writing "Moby-Dick" in February 1850, and would eventually take 18 months to write the book, a full year more than he had first anticipated. Writing was interrupted by his making the acquaintance of Nathaniel Hawthorne in August 1850, and by the creation of the "Mosses from an Old Manse" essay as a first result of that friendship. The book is dedicated to Hawthorne, "in token of my admiration for his genius".

The basis for the work is Melville's 1841 whaling voyage aboard the "Acushnet". The novel also draws on whaling literature, and on literary inspirations such as Shakespeare and the Bible. The white whale is modeled on the notoriously hard-to-catch albino whale Mocha Dick, and the book's ending is based on the sinking of the whaleship "Essex" in 1820. The detailed and realistic descriptions of whale hunting and of extracting whale oil, as well as life aboard ship among a culturally diverse crew, are mixed with exploration of class and social status, good and evil, and the existence of God. In addition to narrative prose, Melville uses styles and literary devices ranging from songs, poetry, and catalogs to Shakespearean stage directions, soliloquies, and asides.

In October 1851, the chapter "The Town Ho's Story" was published in "Harper's New Monthly Magazine". The same month, the whole book was first published (in three volumes) as "The Whale" in London, and under its definitive title in a single-volume edition in New York in November. There are hundreds of differences between the two editions, most slight but some important and illuminating. The London publisher, Richard Bentley, censored or changed sensitive passages; Melville made revisions as well, including a last-minute change to the title for the New York edition. The whale, however, appears in the text of both editions as "Moby Dick", without the hyphen. One factor that led British reviewers to scorn the book was that it seemed to be told by a narrator who perished with the ship: the British edition lacked the Epilogue, which recounts Ishmael's survival. About 3,200 copies were sold during the author's life.

Ishmael travels in December from Manhattan Island to New Bedford with plans to sign up for a whaling voyage. The inn where he arrives is overcrowded, so he must share a bed with the tattooed Polynesian Queequeg, a harpooneer whose father was king of the fictional island of Rokovoko. The next morning, Ishmael and Queequeg attend Father Mapple's sermon on Jonah, then head for Nantucket. Ishmael signs up with the Quaker ship-owners Bildad and Peleg for a voyage on their whaler "Pequod". Peleg describes Captain Ahab: "He's a grand, ungodly, god-like man" who nevertheless "has his humanities". They hire Queequeg the following morning. A man named Elijah prophesies a dire fate should Ishmael and Queequeg join Ahab. While provisions are loaded, shadowy figures board the ship. On a cold Christmas Day, the "Pequod" leaves the harbor.

Ishmael discusses cetology (the zoological classification and natural history of the whale), and describes the crew members. The chief mate is 30-year-old Starbuck, a Nantucket Quaker with a realist mentality, whose harpooneer is Queequeg; second mate is Stubb, from Cape Cod, happy-go-lucky and cheerful, whose harpooneer is Tashtego, a proud, pure-blooded Indian from Gay Head, and the third mate is Flask, also from Martha's Vineyard, short, stout, whose harpooneer is Daggoo, a tall African, now a resident of Nantucket.

When Ahab finally appears on the quarterdeck, he announces he is out for revenge on the white whale which took one leg from the knee down and left him with a prosthesis fashioned from a whale's jawbone. Ahab will give the first man to sight Moby Dick a doubloon, a gold coin, which he nails to the mast. Starbuck objects that he has not come for vengeance but for profit. Ahab's purpose exercises a mysterious spell on Ishmael: "Ahab's quenchless feud seemed mine". Instead of rounding Cape Horn, Ahab heads for the equatorial Pacific Ocean via southern Africa. One afternoon, as Ishmael and Queequeg are weaving a mat — "its warp seemed necessity, his hand free will, and Queequeg's sword chance" — Tashtego sights a sperm whale. Five previously unknown men appear on deck and are revealed to be a special crew selected by Ahab. Their leader, Fedallah, a Parsee, is Ahab's harpooneer. The pursuit is unsuccessful.

Southeast of the Cape of Good Hope, the "Pequod" makes the first of nine sea-encounters, or "gams", with other ships: Ahab hails the "Goney" (Albatross) to ask whether they have seen the White Whale, but the trumpet through which her captain tries to speak falls into the sea before he can answer. Ishmael explains that because of Ahab's absorption with Moby Dick, he sails on without the customary "gam", which defines as a "social meeting of two (or more) Whale-ships", in which the two captains remain on one ship and the chief mates on the other. In the second gam off the Cape of Good Hope, with the "Town-Ho", a Nantucket whaler, the concealed story of a "judgment of God" is revealed, but only to the crew: a defiant sailor who struck an oppressive officer is flogged, and when that officer led the chase for Moby Dick, he fell from the boat and was killed by the whale.

Ishmael digresses on pictures of whales, brit (microscopic sea creatures on which whales feed), squid and — after four boats lowered in vain because Daggoo mistook a giant squid for the white whale — whale-lines. The next day, in the Indian Ocean, Stubb kills a sperm whale, and that night Fleece, the "Pequod"s black cook, prepares him a rare whale steak. Fleece delivers a sermon to the sharks that fight each other to feast on the whale's carcass, tied to the ship, saying that their nature is to be voracious, but they must overcome it. The whale is prepared, beheaded, and barrels of oil are tried out. Standing at the head of the whale, Ahab begs it to speak of the depths of the sea. The "Pequod" next encounters the "Jeroboam", which not only lost its chief mate to Moby Dick, but also is now plagued by an epidemic.

The whale carcass still lies in the water. Queequeg mounts it, tied to Ishmael's belt by a monkey-rope as if they were Siamese twins. Stubb and Flask kill a right whale whose head is fastened to a yardarm opposite the sperm whale's head. Ishmael compares the two heads in a philosophical way: the right whale is Lockean, stoic, and the sperm whale as Kantean, platonic. Tashtego cuts into the head of the sperm whale and retrieves buckets of oil. He falls into the head, and the head falls off the yardarm into the sea. Queequeg dives after him and frees his mate with his sword.

The "Pequod" next gams with the "Jungfrau" from Bremen. Both ships sight whales simultaneously, with the "Pequod" winning the contest. The three harpooneers dart their harpoons, and Flask delivers the mortal strike with a lance. The carcass sinks, and Queequeg barely manages to escape. The "Pequod"s next gam is with the French whaler "Bouton de Rose", whose crew is ignorant of the ambergris in the gut of the diseased whale in their possession. Stubb talks them out of it, but Ahab orders him away. Days later, an encounter with a harpooned whale prompts Pip, a little black cabin-boy from Alabama, to jump out of his whale boat. The whale must be cut loose, because the line has Pip so entangled in it. Furious, Stubb orders Pip to stay in the whale boat, but Pip later jumps again, and is left alone in the immense sea and has gone insane by the time he is picked up.

Cooled sperm oil congeals and must be squeezed back into liquid state; blubber is boiled in the try-pots on deck; the warm oil is decanted into casks, and then stowed in the ship. After the operation, the decks are scrubbed. The coin hammered to the main mast shows three Andes summits, one with a flame, one with a tower, and one a crowing cock. Ahab stops to look at the doubloon and interprets the coin as signs of his firmness, volcanic energy, and victory; Starbuck takes the high peaks as evidence of the Trinity; Stubb focuses on the zodiacal arch over the mountains; and Flask sees nothing of any symbolic value at all. The Manxman mutters in front of the mast, and Pip declines the verb "look".

The "Pequod" next gams with the "Samuel Enderby" of London, captained by Boomer, a down-to-earth fellow who lost his right arm to Moby Dick. Nevertheless, he carries no ill will toward the whale, which he regards not as malicious, but as awkward. Ahab puts an end to the gam by rushing back to his ship. The narrator now discusses the subjects of (1) whalers supply; (2) a glen in Tranque in the Arsacides islands full of carved whale bones, fossil whales, whale skeleton measurements; (3) the chance that the magnitude of the whale will diminish and that the leviathan might perish.

Leaving the "Samuel Enderby", Ahab wrenches his ivory leg and orders the carpenter to fashion him another. Starbuck informs Ahab of oil leakage in the hold. Reluctantly, Ahab orders the harpooneers to inspect the casks. Queequeg, sweating all day below decks, develops a chill and soon is almost mortally feverish. The carpenter makes a coffin for Queequeg, who fears an ordinary burial at sea. Queequeg tries it for size, with Pip sobbing and beating his tambourine, standing by and calling himself a coward while he praises Queequeg for his gameness. Yet Queequeg suddenly rallies, briefly convalesces, and leaps up, back in good health. Henceforth, he uses his coffin for a spare seachest, which is later caulked and pitched to replace the "Pequod"s life buoy.

The "Pequod" sails northeast toward Formosa and into the Pacific Ocean. Ahab, with one nostril, smells the musk from the Bashee isles, and with the other, the salt of the waters where Moby Dick swims. Ahab goes to Perth, the blacksmith, with a bag of racehorse shoenail stubs to be forged into the shank of a special harpoon, and with his razors for Perth to melt and fashion into a harpoon barb. Ahab tempers the barb in blood from Queequeg, Tashtego, and Daggoo.

The "Pequod" gams next with the "Bachelor", a Nantucket ship heading home full of sperm oil. Every now and then, the "Pequod" lowers for whales with success. On one of those nights in the whaleboat, Fedallah prophesies that neither hearse nor coffin can be Ahab's, that before he dies, Ahab must see two hearses — one not made by mortal hands and the other made of American wood — that Fedallah will precede his captain in death, and finally that only hemp can kill Ahab.

As the "Pequod" approaches the Equator, Ahab scolds his quadrant for telling him only where he is and not where he will be. He dashes it to the deck. That evening, an impressive typhoon attacks the ship. Lightning strikes the mast, setting the doubloon and Ahab's harpoon aglow. Ahab delivers a speech on the spirit of fire, seeing the lightning as a portent of Moby Dick. Starbuck sees the lightning as a warning, and feels tempted to shoot the sleeping Ahab with a musket. Next morning, when he finds that the lightning disoriented the compass, Ahab makes a new one out of a lance, a maul, and a sailmaker's needle. He orders the log be heaved, but the weathered line snaps, leaving the ship with no way to fix its location.

The "Pequod" is now heading southeast toward Moby Dick. A man falls overboard from the mast. The life buoy is thrown, but both sink. Now Queequeg proposes that his superfluous coffin be used as a new life buoy. Starbuck orders the carpenter take care it is lidded and caulked. Next morning, the ship meets in another truncated gam with the "Rachel", commanded by Captain Gardiner from Nantucket. The "Rachel" is seeking survivors from one of her whaleboats which had gone after Moby Dick. Among the missing is Gardiner's young son. Ahab refuses to join the search. Twenty-four hours a day, Ahab now stands and walks the deck, while Fedallah shadows him. Suddenly, a sea hawk grabs Ahab's slouched hat and flies off with it. Next, the "Pequod", in a ninth and final gam, meets the "Delight", badly damaged and with five of her crew left dead by Moby Dick. Her captain shouts that the harpoon which can kill the white whale has yet to be forged, but Ahab flourishes his special lance and once more orders the ship forward. Ahab shares a moment of contemplation with Starbuck. Ahab speaks about his wife and child, calls himself a fool for spending 40 years on whaling, and claims he can see his own child in Starbuck's eye. Starbuck tries to persuade Ahab to return to Nantucket to meet both their families, but Ahab simply crosses the deck and stands near Fedallah.

On the first day of the chase, Ahab smells the whale, climbs the mast, and sights Moby Dick. He claims the doubloon for himself, and orders all boats to lower except for Starbuck's. The whale bites Ahab's boat in two, tosses the captain out of it, and scatters the crew. On the second day of the chase, Ahab leaves Starbuck in charge of the "Pequod". Moby Dick smashes the three boats that seek him into splinters and tangles their lines. Ahab is rescued, but his ivory leg and Fedallah are lost. Starbuck begs Ahab to desist, but Ahab vows to slay the white whale, even if he would have to dive through the globe itself to get his revenge.

On the third day of the chase, Ahab sights Moby Dick at noon, and sharks appear, as well. Ahab lowers his boat for a final time, leaving Starbuck again on board. Moby Dick breaches and destroys two boats. Fedallah's corpse, still entangled in the fouled lines, is lashed to the whale's back, so Moby Dick turns out to be the hearse Fedallah prophesied. "Possessed by all the fallen angels", Ahab plants his harpoon in the whale's flank. Moby Dick smites the whaleboat, tossing its men into the sea. Only Ishmael is unable to return to the boat. He is left behind in the sea, and so is the only crewman of the "Pequod" to survive the final encounter. The whale now fatally attacks the "Pequod". Ahab then realizes that the destroyed ship is the hearse made of American wood in Fedallah's prophesy. The whale returns to Ahab, who stabs at him again. The line loops around Ahab's neck, and as the stricken whale swims away, the captain is drawn with him out of sight. Queequeg's coffin comes to the surface, the only thing to escape the vortex when "Pequod" sank. For an entire day, Ishmael floats on it, until the "Rachel", still looking for its lost seamen, rescues him.

Ishmael is the narrator, shaping his story with use of many different genres including sermons, stage plays, soliloquies, and emblematical readings. Repeatedly, Ishmael refers to his writing of the book: "But how can I hope to explain myself here; and yet, in some dim, random way, explain myself I must, else all these chapters might be naught." Scholar John Bryant calls him the novel's "central consciousness and narrative voice." Bezanson first distinguishes Ishmael as narrator from Ishmael as character, whom he calls "forecastle Ishmael", and who is the younger Ishmael of some years ago. Narrator Ishmael, then, is "merely young Ishmael grown older." A second distinction avoids confusion of either of both Ishmaels with the author Herman Melville. Bezanson warns readers to "resist any one-to-one equation of Melville and Ishmael."

According to critic Walter Bezanson, the chapter structure can be divided into "chapter sequences", "chapter clusters", and "balancing chapters". The simplest sequences are of narrative progression, then sequences of theme such as the three chapters on whale painting, and sequences of structural similarity, such as the five dramatic chapters beginning with "The Quarter-Deck" or the four chapters beginning with "The Candles". Chapter clusters are the chapters on the significance of the colour white, and those on the meaning of fire. Balancing chapters are chapters of opposites, such as "Loomings" versus the "Epilogue," or similars, such as "The Quarter-Deck" and "The Candles".

Scholar Lawrence Buell describes the arrangement of the non-narrative chapters as structured around three patterns: first, the nine meetings of the "Pequod" with ships that have encountered Moby Dick. Each has been more and more severely damaged, foreshadowing the "Pequod"s own fate. Second, the increasingly impressive encounters with whales. In the early encounters, the whaleboats hardly make contact; later there are false alarms and routine chases; finally, the massive assembling of whales at the edges of the China Sea in "The Grand Armada". A typhoon near Japan sets the stage for Ahab's confrontation with Moby Dick. The third pattern is the cetological documentation, so lavish that it can be divided into two subpatterns. These chapters start with the ancient history of whaling and a bibliographical classification of whales, getting closer with second-hand stories of the evil of whales in general and of Moby Dick in particular, a chronologically ordered commentary on pictures of whales. The climax to this section is chapter 57, "Of whales in paint etc.", which begins with the humble (a beggar in London) and ends with the sublime (the constellation Cetus). The next chapter ("Brit"), thus the other half of this pattern, begins with the book's first description of live whales, and next the anatomy of the sperm whale is studied, more or less from front to rear and from outer to inner parts, all the way down to the skeleton. Two concluding chapters set forth the whale's evolution as a species and claim its eternal nature.

Some "ten or more" of the chapters on whale killings, beginning at two-fifths of the book, are developed enough to be called "events". As Bezanson writes, "in each case a killing provokes either a chapter sequence or a chapter cluster of cetological lore growing out of the circumstance of the particular killing," thus these killings are "structural occasions for ordering the whaling essays and sermons".

Buell observes that the "narrative architecture" is an "idiosyncratic variant of the bipolar observer/hero narrative", that is, the novel is structured around the two main characters, Ahab and Ishmael, who are intertwined and contrasted with each other, with Ishmael the observer and narrator. As the story of Ishmael, remarks Robert Milder, it is a "narrative of education".

Bryant and Springer find that the book is structured around the two consciousnesses of Ahab and Ishmael, with Ahab as a force of linearity and Ishmael a force of digression. While both have an angry sense of being orphaned, they try to come to terms with this hole in their beings in different ways: Ahab with violence, Ishmael with meditation. And while the plot in "Moby-Dick" may be driven by Ahab's anger, Ishmael's desire to get a hold of the "ungraspable" accounts for the novel's lyricism. Buell sees a double quest in the book: Ahab's is to hunt Moby Dick, Ishmael's is "to understand what to make of both whale and hunt".

One of the most distinctive features of the book is the variety of genres. Bezanson mentions sermons, dreams, travel account, autobiography, Elizabethan plays, and epic poetry. He calls Ishmael's explanatory footnotes to establish the documentary genre "a Nabokovian touch".

A significant structural device is the series of nine meetings (gams) between the Pequod and other ships. These meetings are important in three ways. First, their placement in the narrative. The initial two meetings and the last two are both close to each other. The central group of five gams are separated by about 12 chapters, more or less. This pattern provides a structural element, remarks Bezanson, as if the encounters were "bones to the book's flesh". Second, Ahab's developing responses to the meetings plot the "rising curve of his passion" and of his monomania. Third, in contrast to Ahab, Ishmael interprets the significance of each ship individually: "each ship is a scroll which the narrator unrolls and reads." Bezanson sees no single way to account for the meaning of all of these ships. Instead, they may be interpreted as "a group of metaphysical parables, a series of biblical analogues, a masque of the situation confronting man, a pageant of the humors within men, a parade of the nations, and so forth, as well as concrete and symbolic ways of thinking about the White Whale".

Scholar Nathalia Wright sees the meetings and the significance of the vessels along other lines. She singles out the four vessels which have already encountered Moby Dick. The first, the "Jeroboam", is named after the predecessor of the biblical King Ahab. Her "prophetic" fate is "a message of warning to all who follow, articulated by Gabriel and vindicated by the "Samuel Enderby", the "Rachel", the "Delight", and at last the "Pequod"". None of the other ships has been completely destroyed because none of their captains shared Ahab's monomania; the fate of the "Jeroboam" reinforces the structural parallel between Ahab and his biblical namesake: "Ahab did more to provoke the Lord God of Israel to anger than all the kings of Israel that were before him" (I Kings 16:33).

An early enthusiast for the Melville Revival, British author E. M. Forster, remarked in 1927: ""Moby-Dick" is full of meanings: its meaning is a different problem." Yet he saw as "the essential" in the book "its prophetic song", which flows "like an undercurrent" beneath the surface action and morality.

Biographer Laurie Robertson-Lorant sees epistemology as the book's theme. Ishmael's taxonomy of whales merely demonstrates "the limitations of scientific knowledge and the impossibility of achieving certainty". She also contrasts Ishmael and Ahab's attitudes toward life, with Ishmael's open-minded and meditative, "polypositional stance" as antithetical to Ahab's monomania, adhering to dogmatic rigidity.

Melville biographer Delbanco cites race as an example of this search for truth beneath surface differences. All races are represented among the crew members of the "Pequod". Although Ishmael initially is afraid of Queequeg as a tattooed cannibal, he soon decides, "Better sleep with a sober cannibal than a drunken Christian." While it may be rare for a mid-19th century American book to feature black characters in a nonslavery context, slavery is frequently mentioned. The theme of race is primarily carried by Pip, the diminutive black cabin boy. When Pip has almost drowned, Ahab, genuinely touched by Pip's suffering, questions him gently, Pip "can only parrot the language of an advertisement for the return of a fugitive slave: 'Pip! Reward for Pip!'".

Editors Bryant and Springer suggest perception is a central theme, the difficulty of seeing and understanding, which makes deep reality hard to discover and truth hard to pin down. Ahab explains that, like all things, the evil whale wears a disguise: "All visible objects, man, are but pasteboard masks" — and Ahab is determined to "strike through the mask! How can the prisoner reach outside, except by thrusting through the wall? To me, the white whale is that wall" (Ch. 36, "The Quarter-Deck"). This theme pervades the novel, perhaps never so emphatically as in "The Doubloon" (Ch. 99), where each crewmember perceives the coin in a way shaped by his own personality. Later, the American edition has Ahab "discover no sign" (Ch. 133) of the whale when he is staring into the deep. In fact, Moby Dick is then swimming up at him. In the British edition, Melville changed the word "discover" to "perceive", and with good reason, for "discovery" means finding what is already there, but "perceiving", or better still, perception, is "a matter of shaping what exists by the way in which we see it". The point is not that Ahab would discover the whale as an object, but that he would perceive it as a symbol of his making.

Yet Melville does not offer easy solutions. Ishmael and Queequeg's sensual friendship initiates a kind of racial harmony that is shattered when the crew's dancing erupts into racial conflict in "Midnight, Forecastle" (Ch. 40). Fifty chapters later, Pip suffers mental disintegration after he is reminded that as a slave he would be worth less money than a whale. Commodified and brutalized, "Pip becomes the ship's conscience". His views of property are another example of wrestling with moral choice. In Chapter 89, Ishmael expounds the concept of the fast-fish and the loose-fish, which gives right of ownership to those who take possession of an abandoned fish or ship, and observes that the British Empire took possession of American Indian lands in colonial times in just the way that whalers take possession of an unclaimed whale.

The novel has also been read as being critical of the contemporary literary and philosophical movement Transcendentalism, attacking the thought of leading Transcendentalist Ralph Waldo Emerson in particular. The life and death of Ahab has been read as an attack on Emerson's philosophy of self reliance, for one, in its destructive potential and potential justification for egoism. Richard Chase writes that for Melville, 'Death–spiritual, emotional, physical–is the price of self-reliance when it is pushed to the point of solipsism, where the world has no existence apart from the all-sufficient self.' In that regard, Chase sees Melville's art as antithetical to that of Emerson's thought, in that Melville '[points] up the dangers of an exaggerated self-regard, rather than, as [...] Emerson loved to do, [suggested] the vital possibilities of the self.' Newton Arvin further suggests that self-reliance was, for Melville, really the '[masquerade in kingly weeds of] a wild egoism, anarchic, irresponsible, and destructive.'

An incomplete inventory of the language of "Moby-Dick" by editors Bryant and Springer includes "nautical, biblical, Homeric, Shakespearean, Miltonic, cetological" influences, and his style is "alliterative, fanciful, colloquial, archaic, and unceasingly allusive": Melville tests and exhausts the possibilities of grammar, quotes from a range of well-known or obscure sources, and swings from calm prose to high rhetoric, technical exposition, seaman's slang, mystic speculation, or wild prophetic archaism.

Many words that make up the vocabulary of "Moby-Dick" are Melville's own coinages, critic Newton Arvin recognizes, as if the English vocabulary were too limited for the complex things Melville had to express. Perhaps the most striking example is the use of verbal nouns, mostly plural, such as "allurings", "coincidings", and "leewardings". Equally abundant are unfamiliar adjectives and adverbs, including participial adjectives such as "officered", "omnitooled", and "uncatastrophied"; participial adverbs such as "intermixingly", "postponedly", and "uninterpenetratingly"; rarities such as the adjectives "unsmoothable", "spermy", and "leviathanic", and adverbs such as "sultanically", "Spanishly", and "Venetianly"; and adjectival compounds ranging from odd to magnificent, such as "the "message-carrying" air", "the "circus-running" sun", and ""teeth-tiered" sharks". It is rarer for Melville to create his own verbs from nouns, but he does this with what Arvin calls "irresistible effect", such as in "who didst "thunder" him higher than a throne", and "my fingers...began...to "serpentine" and "spiralize"". For Arvin, the essence of the writing style of "Moby-Dick" lies in

Arvin's categories have been slightly expanded by later critics, most notably Warner Berthoff. The superabundant vocabulary of the work can be broken down into strategies used individually and in combination. First, the original modification of words as "Leviathanism" and the exaggerated repetition of modified words, as in the series "pitiable", "pity", "pitied" and "piteous" (Ch. 81, "The Pequod Meets the Virgin"). Second, the use of existing words in new ways, as when the whale "heaps" and "tasks". Third, words lifted from specialized fields, as "fossiliferous". Fourth, the use of unusual adjective-noun combinations, as in "concentrating brow" and "immaculate manliness" (Ch. 26, "Knights and Squires"). Fifth, using the participial modifier to emphasize and to reinforce the already established expectations of the reader, as the words "preluding" and "foreshadowing" ("so still and subdued and yet somehow preluding was all the scene…"; "In this foreshadowing interval…").

Characteristic stylistic elements of another kind are the echoes and overtones. Responsible for this are both Melville's imitation of certain distinct styles and his habitual use of sources to shape his own work. His three most important sources, in order, are the Bible, Shakespeare, and Milton.

Another notable stylistic element are the several levels of rhetoric, the simplest of which is "a relatively straightforward "expository" style" that is evident of many passages in the cetological chapters, though they are "rarely sustained, and serve chiefly as transitions" between more sophisticated levels. One of these is the ""poetic"" level of rhetoric, which Bezanson sees "well exemplified" in Ahab's quarter-deck soliloquy, to the point that it can be set as blank verse. Set over a metrical patern, the rhythms are "evenly controlled—too evenly perhaps for prose," Bezanson suggests. A third level of rhetoric is the "idiomatic", and just as the poetic it hardly is present in pure form. Examples of this are "the consistently excellent idiom" of Stubb, such as in the way he encourages the rowing crew in a rhythm of speech that suggests "the beat of the oars takes the place of the metronomic meter". The fourth and final level of rhetoric is the "composite", "a magnificent blending" of the first three and possible other elements:

The Nantucketer, he alone resides and riots on the sea; he alone, in Bible language, goes down to it in ships; to and fro ploughing it as his own special plantation. "There" is his home; "there" lies his buisiness, which a Noah's flood would not interrupt, though it overwhelmed all the millions in China. He lives on the sea, as prairie cocks in the prairie; he hides among the waves, he climbs them as chamois hunters climb the Alps. For years he knows not the land; so that when he comes to it at last, it smells like another world, more strangely than the moon would to an Earthsman. With the landless gull, that at sunset folds her wings and is rocked to sleep between billows; so at nightfall, the Nantucketer, out of sight of land, furls his sails, and lays him to his rest, while under his very pillow rush herds of walruses and whales.
("Nantucket," Ch. 14).

This passage, from a chapter that Bezanson calls a comical "prose poem", blends "high and low with a relaxed assurance". Similar great passages include the "marvelous hymn to spiritual democracy" that can be found in the middle of "Knights and Squires".

The elaborate use of the Homeric simile may not have been learned from Homer himself, yet Matthiessen finds the writing "more consistently alive" on the Homeric than on the Shakespearean level, especially during the final chase the "controlled accumulation" of such similes emphasizes Ahab's hubris through a succession of land-images, for instance: "The ship tore on; leaving such a furrow in the sea as when a cannon-ball, missent, becomes a ploughshare and turns up the level field" ("The Chase – Second Day," Ch. 134). One paragraph-long simile describes how the 30 men of the crew became a single unit:

For as the one ship that held them all; though it was put together of all contrasting things—oak, and maple, and pine wood; iron, and pitch, and hemp—yet all these ran into each other in the one concrete hull, which shot on its way, both balanced and directed by the long central keel; even so, all the individualities of the crew, this man's valor, that man's fear; guilt and guiltiness, all varieties were welded into oneness, and were all directed to that fatal goal which Ahab their one lord and keel did point to.
("The Chase – Second Day," Ch. 134).

The final phrase fuses the two halves of the comparison, the men become identical with the ship, which follows Ahab's direction. The concentration only gives way to more imagery, with the "mastheads, like the tops of tall palms, were outspreadingly tufted with arms and legs". All these images contribute their "startling energy" to the advance of the narrative. When the boats are lowered, the imagery serves to dwarf everything but Ahab's will in the presence of Moby Dick. These similes, with their astonishing "imaginative abundance," are not only invaluable in creating the dramatic movement, Matthiessen observes: "They are no less notable for breadth; and the more sustained among them, for an heroic dignity."

The influence of Shakespeare on the book has been analyzed by F.O. Matthiessen in his 1941 study of the American Renaissance with such results that almost a half century later Bezanson still considered him "the richest critic on these matters." According to Matthiesen, then, Melville's "possession by Shakespeare went far beyond all other influences" in that it made Melville discover his own full strength "through the challenge of the most abundant imagination in history". Especially the influence of "King Lear" and "Macbeth" has attracted scholarly attention. On almost every page debts to Shakespeare can be discovered, whether hard or easy to recognize. Matthiessen points out that the "mere sounds, full of Leviathanism, but signifying nothing" at the end of "Cetology" (Ch.32) echo the famous phrase in "Macbeth": "Told by an idiot, full of sound and fury, Signifying nothing." As Matthiessen demonstrates, Ahab's first extended speech to the crew, in the "Quarter-Deck" (Ch.36), is "virtually blank verse, and can be printed as such":

But look ye, Starbuck, what is said in heat,
That thing unsays itself. There are men
From whom warm words are small indignity.
I mean not to incense thee. Let it go.
Look! see yonder Turkish cheeks of spotted tawn--
Living, breathing pictures painted by the sun.
The pagan leopards—the unrecking and
Unworshipping things, that live; and seek and give
No reason for the torrid life they feel!

Most importantly, through Shakespeare, Melville infused "Moby-Dick" with a power of expression he had not previously possessed. Reading Shakespeare, Matthiessen observes, had been "a catalytic agent" for Melville, one that transformed his writing "from limited reporting to the expression of profound natural forces". The extent to which Melville was in full possession of his powers is demonstrated by Matthiessen through the description of Ahab, which ends in language "that suggests Shakespeare's but is not an imitation of it: 'Oh, Ahab! what shall be grand in thee, it must needs be plucked from the skies and dived for in the deep, and featured in the unbodied air!' The imaginative richness of the final phrase seems particularly Shakespearean, "but its two key words appear only once each in the plays ... and to neither of these usages is Melville indebted for his fresh combination." Melville's assimilation of Shakespeare, Matthiessen concludes, gave "Moby-Dick" "a kind of diction that depended upon no source", and that could, as D.H. Lawrence put it, convey something "almost superhuman or inhuman, bigger than life". The prose is not based on anybody else's verse but on "a sense of speech rhythm".

In addition to this sense of rhythm, Melville acquired verbal resources which for Matthiessen showed that he "now mastered Shakespeare's mature secret of how to make language itself dramatic". He had learned three essential things, Matthiessen sums up:

The creation of Ahab, Melville biographer Leon Howard discovered, followed an observation by Coleridge in his lecture on "Hamlet": "one of Shakespeare's modes of creating characters is to conceive any one intellectual or moral faculty in "morbid" excess, and then to place himself...thus "mutilated" or "diseased", under given circumstances". Coleridge's vocabulary is echoed in some phrases that describe Ahab. Ahab seemed to have "what seems a half-wilful "over-ruling morbidness" at the bottom of his nature", and "all men tragically great", Melville added, "are made so through a certain "morbidness"; "all mortal greatness is but "disease"". In addition to this, in Howard's view, the self-references of Ishmael as a "tragic dramatist", and his defense of his choice of a hero who lacked "all outward majestical trappings" is evidence that Melville "consciously thought of his protagonist as a tragic hero of the sort found in "Hamlet" and "King Lear"".

"Moby-Dick" is based on Melville's experience on the whaler "Acushnet", however even the book's most factual accounts of whaling are not straight autobiography. On December 30, 1840, he signed on as a green hand for the maiden voyage of the "Acushnet", planned to last for 52 months. Its owner, Melvin O. Bradford, resembled Bildad, who signed on Ishmael, in that he was a Quaker: on several instances when he signed documents, he erased the word "swear" and replaced it with "affirm". But the shareholders of the "Acushnet" were relatively wealthy, whereas the owners of the "Pequod" included poor widows and orphaned children. Its captain was Valentine Pease, Jr., who was 43 years old at the start of the voyage. Although 26 men signed up as crew members, two did not show up for the ship's departure and were replaced by one new crew member. The crew was not as heterogenous or exotic as the crew of the "Pequod". Five of the crew were foreigners, four of them Portuguese, and the others were American, either at birth or naturalized. Three black men were in the crew, two seamen and the cook. Fleece, the cook of the "Pequod", was also black, so probably modeled on this Philadelphia-born William Maiden, who was 38 years old when he signed for the "Acushnet".

Only 11 of the 26 original crew members completed the voyage. The others either deserted or were regularly discharged. The First Officer, Frederic Raymond, left the ship after a "fight" with the captain. A first mate, actually called Edward C. Starbuck, was on an earlier voyage with Captain Pease, in the early 1830s, and was discharged at Tahiti under mysterious circumstances. The second mate on the "Acushnet" was John Hall, English-born but a naturalized American. He is identified as Stubb in an annotation in the book's copy of crew member Henry Hubbard, who, like Melville, had joined the voyage as a green hand. Hubbard also identified the model for Pip: John Backus, a little black man added to the crew during the voyage. Hubbard's annotation appears in the chapter "The Castaway" and reveals that Pip's falling into the water was authentic; Hubbard was with him in the same boat when the incident occurred.

Ahab seems to have had no model in real life, though his death may have been based on an actual event. On May 18, 1843, Melville was aboard "The Star", which sailed for Honolulu. Aboard were two sailors from the "Nantucket" who could have told him that they had seen their second mate "taken out of a whaleboat by a foul line and drowned". The model for the Whaleman's Chapel of chapter 7 is the Seamen's Bethel on Johnny Cake Hill. Melville attended a service there shortly before he shipped out on the "Acushnet", and he heard a sermon by the chaplain, 63-year-old Reverend Enoch Mudge, who is at least in part the model for Father Mapple. Even the topic of Jonah and the Whale may be authentic, for Mudge was a contributor to "Sailor's Magazine", which printed in December 1840 the ninth of a series of sermons on Jonah.

In addition to his own experience on the whaling ship "Acushnet", two actual events served as the genesis for Melville's tale. One was the sinking of the Nantucket ship "Essex" in 1820, after a sperm whale rammed her 2,000 miles (3,200 km) from the western coast of South America. First mate Owen Chase, one of eight survivors, recorded the events in his 1821 "Narrative of the Most Extraordinary and Distressing Shipwreck of the Whale-Ship Essex".

The other event was the alleged killing in the late 1830s of the albino sperm whale Mocha Dick, in the waters off the Chilean island of Mocha. Mocha Dick was rumored to have 20 or so harpoons in his back from other whalers, and appeared to attack ships with premeditated ferocity. One of his battles with a whaler served as subject for an article by explorer Jeremiah N. Reynolds in the May 1839 issue of "The Knickerbocker or New-York Monthly Magazine". Melville was familiar with the article, which described: Significantly, Reynolds writes a first-person narration that serves as a frame for the story of a whaling captain he meets. The captain resembles Ahab and suggests a similar symbolism and single-minded motivation in hunting this whale, in that when his crew first encounters Mocha Dick and cowers from him, the captain rallies them: 

Mocha Dick had over 100 encounters with whalers in the decades between 1810 and the 1830s. He was described as being gigantic and covered in barnacles. Although he was the most famous, Mocha Dick was not the only white whale in the sea, nor the only whale to attack hunters.

While an accidental collision with a sperm whale at night accounted for sinking of the "Union" in 1807, it was not until August 1851 that the whaler "Ann Alexander", while hunting in the Pacific off the Galápagos Islands, became the second vessel since the "Essex" to be attacked, holed, and sunk by a whale. Melville remarked, "Ye Gods! What a commentator is this "Ann Alexander" whale. What he has to say is short & pithy & very much to the point. I wonder if my evil art has raised this monster."

While Melville had already drawn on his different sailing experiences in his previous novels, such as "Mardi", he had never focused specifically on whaling. The 18 months he spent as an ordinary seaman aboard the whaler "Acushnet" in 1841–42, and one incident in particular, now served as inspiration. During a mid-ocean "gam" (rendezvous at sea between ships), he met Chase's son William, who lent him his father's book. Melville later wrote: 

The book was out of print, and rare. Melville let his interest in the book be known to his father-in-law, Lemuel Shaw, whose friend in Nantucket procured an imperfect but clean copy which Shaw gave to Melville in April 1851. Melville read this copy avidly, made copious notes in it, and had it bound, keeping it in his library for the rest of his life. 

"Moby-Dick" contains large sections—most of them narrated by Ishmael—that seemingly have nothing to do with the plot, but describe aspects of the whaling business. Although a successful earlier novel about Nantucket whalers had been written, "Miriam Coffin or The Whale-Fisherman" (1835) by Joseph C. Hart, which is credited with influencing elements of Melville's work, most accounts of whaling tended to be sensational tales of bloody mutiny, and Melville believed that no book up to that time had portrayed the whaling industry in as fascinating or immediate a way as he had experienced it.

Melville found the bulk of his data on whales and whaling in five books, the most important of which was by the English ship's surgeon Thomas Beale, "Natural History of the Sperm Whale" (1839), a book of reputed authority which Melville bought on July 10, 1850. "In scale and complexity," scholar Steven Olsen-Smith writes, "the significance of [this source] to the composition of "Moby-Dick" surpasses that of any other source book from which Melville is known to have drawn." According to scholar Howard P. Vincent, the general influence of this source is to supply the arrangement of whaling data in chapter groupings. Melville followed Beale's grouping closely, yet adapted it to what art demanded, and he changed the original's prosaic phrases into graphic figures of speech. The second most important whaling book is Frederick Debell Bennett, "A Whaling Voyage Round the Globe, from the Year 1833 to 1836" (1840), from which Melville also took the chapter organization, but in a lesser degree than he learned from Beale.

The third book was the one Melville reviewed for the "Literary World" in 1847, J. Ross Browne's "Etchings of a Whaling Cruise" (1846), which may have given Melville the first thought for a whaling book, and in any case contains passages embarrassingly similar to passages in "Moby-Dick". The fourth book, Reverend Henry T. Cheever's "The Whale and His Captors" (1850), was used for two episodes in "Moby-Dick" but probably appeared too late in the writing of the novel to be of much more use. Melville did plunder a fifth book, William Scoresby, Jr., "An Account of the Arctic Regions with a History and Description of the Northern Whale Fishery" (1820), though—unlike the other four books—its subject is the Greenland whale rather than the sperm whale. Although the book became the standard whaling reference soon after publication, Melville satirized and parodied it on several occasions—for instance in the description of narwhales in the chapter "Cetology", where he called Scoresby "Charley Coffin" and gave his account "a humorous twist of fact": "Scoresby will help out Melville several times, and on each occasion Melville will satirize him under a pseudonym." Vincent suggests several reasons for Melville's attitude towards Scoresby, including his dryness and abundance of irrelevant data, but the major reason seems to have been that the Greenland whale was the sperm whale's closest competitor for the public's attention, so Melville felt obliged to dismiss anything dealing with it.

The earliest surviving mention of the composition of what became "Moby-Dick" is the final paragraph of the letter Melville wrote to Richard Henry Dana, Jr. on May 1, 1850:

Some scholars have concluded that Melville composed "Moby-Dick" in two or even three stages. Reasoning from a series of inconsistencies and structural developments in the final version, they hypothesize that the work he mentioned to Dana was, in the words of Lawrence Buell, a "relatively straightforward" whaling adventure, but that reading Shakespeare and his encounters with Hawthorne inspired him to rewrite it as "an epic of cosmic encyclopedic proportions". Bezanson objects that the letter contains too many ambiguities to assume "that Dana's 'suggestion' would obviously be that Melville do for whaling what he had done for life on a man-of-war in "White-Jacket"". In addition, Dana had experienced how incomparable Melville was in dramatic story telling when he met him in Boston, so perhaps "his 'suggestion' was that Melville do a book that captured that gift". And the long sentence in the middle of the above quotation simply acknowledges that Melville is struggling with the problem, not of choosing between fact and fancy but of how to interrelate them. The most positive statements are that it will be a strange sort of a book and that Melville means to give the truth of the thing, but what thing exactly is not clear.

Melville may have found the plot before writing or developed it after the writing process was underway. Considering his elaborate use of sources, "it is safe to say" that they helped him shape the narrative, its plot included. Scholars John Bryant and Haskell Springer cite the development of the character Ishmael as another factor which prolonged Melville's process of composition and which can be deduced from the structure of the final version of the book. Ishmael, in the early chapters, is simply the narrator, just as the narrators in Melville's earlier sea adventures had been, but in later chapters becomes a mystical stage manager who is central to the tragedy.

Less than two months after mentioning the project to Dana, Melville reported in a letter of June 27 to Richard Bentley, his English publisher:

Nathaniel Hawthorne and his family had moved to a small red farmhouse near Lenox, Massachusetts, at the end of March 1850. He became friends with Oliver Wendell Holmes Sr. and Melville beginning on August 5, 1850, when the authors met at a picnic hosted by a mutual friend. Melville wrote an unsigned review of Hawthorne's short story collection "Mosses from an Old Manse" titled "Hawthorne and His Mosses", which appeared in "The Literary World" on August 17 and 24. Bezanson finds the essay "so deeply related to Melville's imaginative and intellectual world while writing "Moby-Dick"" that it could be regarded as a virtual preface and should be "everybody's prime piece of contextual reading". In the essay, Melville compares Hawthorne to Shakespeare and Dante, and his "self-projection" is evident in the repeats of the word "genius", the more than two dozen references to Shakespeare, and in the insistence that Shakespeare's "unapproachability" is nonsense for an American.

The most intense work on the book was done during the winter of 1850–1851, when Melville had changed the noise of New York City for a farm in Pittsfield, Massachusetts. The move may well have delayed finishing the book. During these months, he wrote several excited letters to Hawthorne, including one of June 1851 in which he summarizes his career: "What I feel most moved to write, that is banned, — it will not pay. Yet, altogether, write the "other" way I cannot. So the product is a final hash, and all my books are botches." This is the stubborn Melville who stood by "Mardi" and talked about his other, more commercial books with contempt. The letter also reveals how Melville experienced his development from his 25th year: "Three weeks have scarcely passed, at any time between then and now, that I have not unfolded within myself. But I feel that I am now come to the inmost leaf of the bulb, and that shortly the flower must fall to the mould." One other theory holds that getting to know Hawthorne first inspired him to write Ahab's tragic obsession into the book, but Bryant and Springer object that Melville already had experienced other encounters which could just as well have triggered his imagination, such as the Bible's Jonah and Job, Milton's Satan, Shakespeare's King Lear, Byron's heroes.

Theories of the composition of the book have been harpooned in three ways, first by raising objections against the use of evidence and the evidence itself. Scholar Robert Milder sees "insufficient evidence and doubtful methodology" at work. John Bryant finds "little concrete evidence, and nothing at all conclusive, to show that Melville radically altered the structure or conception of the book". A second type of objection is based upon Melville's intellectual development. Bezanson is not convinced that before he met Hawthorne, "Melville was "not" ready for the kind of book "Moby-Dick" became", because in his letters from the time Melville denounces his last two "straight narratives, "Redburn" and "White-Jacket", as two books written just for the money, and he firmly stood by "Mardi" as the kind of book he believed in. His language is already "richly steeped in 17th-century mannerisms", characteristics of "Moby-Dick". A third type calls upon the literary nature of passages used as evidence. According to Milder, the cetological chapters cannot be leftovers from an earlier stage of composition and any theory that they are "will eventually founder on the stubborn meaningfulness of these chapters", because no scholar adhering to the theory has yet explained how these chapters "can bear intimate thematic relation to a symbolic story not yet conceived". Buell finds that theories based on a combination of selected passages from letters and what are perceived as "loose ends" in the book not only "tend to dissolve into guesswork", but he also suggests that these so-called loose ends may be intended by the author: repeatedly the book mentions "the necessary unfinishedness of immense endeavors". Despite all this, Buell finds the evidence that Melville changed his ambitions during writing "on the whole convincing".

Melville first proposed the English publication in a 27 June 1850 letter to Richard Bentley, London publisher of his earlier works. Textual scholar G. Thomas Tanselle explains that for these earlier books, American proof sheets had been sent to the English publisher and that publication in the United States had been held off until the work had been set in type and published in England. This procedure was intended to provide the best (though still uncertain) claim for the English copyright of an American work. In the case of "Moby-Dick", Melville had taken almost a year longer than promised, and could not rely on Harpers to prepare the proofs as they had done for the earlier books. Indeed, Harpers had denied him an advance, and since he was already in debt to them for almost $700, he was forced to borrow money and to arrange for the typesetting and plating himself. John Bryant suggests that he did so "to reduce the number of hands playing with his text".

The final stages of composition overlapped with the early stages of publication. In June 1851, Melville wrote to Hawthorne that he was in New York to "work and slave on my 'Whale' while it is driving through the press". By the end of the month, "wearied with the long delay of printers", Melville came back to finish work on the book in Pittsfield. Three weeks later, the typesetting was almost done, as he announced to Bentley on 20 July: "I am now passing thro' the press, the closing sheets of my new work". While Melville was simultaneously writing and proofreading what had been set, the corrected proof would be plated, that is, the type fixed in final form. Since earlier chapters were already plated when he was revising the later ones, Melville must have "felt restricted in the kinds of revisions that were feasible".

On 3 July 1851, Bentley offered Melville ₤150 and "half profits", that is, half the profits that remained after the expenses of production and advertising. On 20 July, Melville accepted, after which Bentley drew up a contract on 13 August. Melville signed and returned the contract in early September, and then went to New York with the proof sheets, made from the finished plates, which he sent to London by his brother Allan on 10 September. For over a month, these proofs had been in Melville's possession, and because the book would be set anew in England, he could devote all his time to correcting and revising them. He still had no American publisher, so the usual hurry about getting the English publication to precede the American was not present. Only on 12 September was the Harper publishing contract signed. Bentley received the proof sheets with Melville's corrections and revisions marked on them on September 24. He published the book less than four weeks later.

In the October 1851 issue of "Harper's New Monthly Magazine" "The Town Ho's Story" was published, with a footnote reading: "From 'The Whale'. The title of a new work by Mr. Melville, in the press of Harper and Brothers, and now publishing in London by Mr. Bentley."

On 18 October, the English edition, "The Whale", was published in a printing of only 500 copies, fewer than Melville's previous books. Their slow sales had convinced Bentley that a smaller number was more realistic. The London "Morning Herald" on October 20 printed the earliest known review. On 14 November, the American edition, "Moby-Dick", was published and the same day reviewed in both the Albany "Argus" and the "Morning Courier and New-York Enquirer". On 19 November, Washington received the copy to be deposited for copyright purposes. The first American printing of 2,915 copies was almost the same as the first of "Mardi", but the first printing of Melville's other three Harper books had been a thousand copies more.

The English edition, set by Bentley's printers from the American page proofs with Melville's revisions and corrections, differs from the American edition in over 700 wordings and thousands of punctuation and spelling changes.

Excluding the preliminaries and the one extract, the three volumes of the English edition came to 927 pages and the single American volume to 635 pages. Accordingly, the dedication to Hawthorne in the American edition — "this book is inscribed to"— became "these volumes are inscribed to" in the English. The table of contents in the English edition generally follows the actual chapter titles in the American edition, but 19 titles in the American table of contents differ from the titles above the chapters themselves. This list was probably drawn up by Melville himself: the titles of chapters describing encounters of the "Pequod" with other ships had—apparently to stress the parallelisms between these chapters—been standardized to "The Pequod meets the...," with the exception of the already published 'The Town-Ho's Story'. For unknown reasons, the "Etymology" and "Extracts" were moved to the end of the third volume. An epigraph from "Paradise Lost", taken from the second of the two quotations from that work in the American edition, appears on the title page of each of the three English volumes. Melville's involvement with this rearrangement is not clear: if it was Bentley's gesture toward accommodating Melville, as Tanselle suggests, its selection put an emphasis on the quotation Melville may not have agreed with.

The largest of Melville's revisions is the addition to the English edition of a 139-word footnote in Chapter 87 explaining the word "gally". The edition also contains six short phrases and some 60 single words lacking in the American edition. In addition, about 35 changes produce genuine improvements, as opposed to mere corrections: "Melville may not have made every one of the changes in this category, but it seems certain that he was responsible for the great majority of them."

The British publisher hired one or more revisers who were, in the evaluation of scholar Steven Olsen-Smith, responsible for "unauthorized changes ranging from typographical errors and omissions to acts of outright censorship". According to biographer Robertson-Lorant, the result was that the English edition was "badly mutilated". The expurgations fall into four categories, ranked according to the apparent priorities of the censor:
These expurgations also meant that any corrections or revisions Melville may have marked upon these passages are now lost.

The final difference in the material not already plated is that the "Epilogue", thus Ishmael's miraculous survival, is omitted from the British edition. Obviously, the epilogue was not an afterthought supplied too late for the English edition, for it is referred to in "The Castaway": "in the sequel of the narrative, it will then be seen what like abandonment befell myself." Why the "Epilogue" is missing is unknown. Since nothing objectionable was in it, most likely it was somehow lost by Bentley's printer when the "Etymology" and "Extracts" were moved.

After the sheets had been sent, Melville changed the title. Probably late in September, Allan sent Bentley two pages of proof with a letter of which only a draft survives which informed him that Melville "has determined upon a new title & dedication—Enclosed you have proof of both—It is thought here that the new title will be a better "selling" title". After expressing his hope that Bentley would receive this change in time, Allan said that "Moby-Dick is a legitimate title for the book, being the name given to a particular whale who if I may so express myself is the hero of the volume". Biographer Hershel Parker suggests that the reason for the change was that Harper's had two years earlier published a book with a similar title, "The Whale and His Captors".

Changing the title was not a problem for the American edition, since the running heads throughout the book only showed the titles of the chapters, and the title page, which would include the publisher's name, could not be printed until a publisher was found. In October "Harper's New Monthly Magazine" printed chapter 54, "The Town-Ho's Story", with a footnote saying: "From "The Whale." The title of a new work by Mr. Melville". The one surviving leaf of proof, "a 'trial' page bearing the title 'The Whale' and the Harper imprint," shows that at this point, after the publisher had been found, the original title still stood. When Allan's letter arrived, no sooner than early October, Bentley had already announced "The Whale" in both the "Athenaem" and the "Spectator" of 4 and 11 October. Probably to accommodate Melville, Bentley inserted a half-title page in the first volume only, which reads "The Whale; or, Moby Dick".

The British printing of 500 copies sold fewer than 300 within the first four months. In 1852, some remaining sheets were bound in a cheaper casing, and in 1853, enough sheets were still left to issue a cheap edition in one volume. Bentley recovered only half on the ₤150 he advanced Melville, whose share from actual sales would have been just ₤38, and he did not print a new edition. Harper's first printing was 2,915 copies, including the standard 125 review copies. The selling price was $1.50, about a fifth of the price of the British three-volume edition. About 1,500 copies were sold within 11 days, and then sales slowed down to less than 300 the next year. After three years, the first edition was still available, almost 300 copies of which were lost when a fire broke out at the firm in December 1853. In 1855, a second printing of 250 copies was issued, in 1863, a third of 253 copies, and finally in 1871, a fourth printing of 277 copies, which sold so slowly that no new printing was ordered. "Moby-Dick" was out of print during the last four years of Melville's life, having sold 2,300 in its first year and a half and on average 27 copies a year for the next 34 years, totaling 3,215 copies.

Melville's earnings from the book add up to $1,260: the ₤150 advance from Bentley was equivalent to $703, and the American printings earned him $556, which was $100 less than he earned from any of his five previous books. Melville's widow received another $81 when the United States Book Company issued the book and sold almost 1,800 copies between 1892 and 1898.

The reception of "The Whale" in Britain and of "Moby-Dick" in the United States differed in two ways, according to Parker. First, British literary criticism was more sophisticated and developed than in the still young republic, with British reviewing done by "cadres of brilliant literary people" who were "experienced critics and trenchant prose stylists", while the United States had only "a handful of reviewers" capable enough to be called critics, and American editors and reviewers habitually echoed British opinion. American reviewing was mostly delegated to "newspaper staffers" or else by "amateur contributors more noted for religious piety than critical acumen." Second, the differences between the two editions caused "two distinct critical receptions."

Twenty-one reviews appeared in London, and later one in Dublin. The British reviewers, according to Parker, mostly regarded "The Whale" as "a phenomenal literary work, a philosophical, metaphysical, and poetic romance". The "Morning Advertiser" for October 24 was in awe of Melville's learning, of his "dramatic ability for producing a prose poem", and of the whale adventures which were "powerful in their cumulated horrors." To its surprise, "John Bull" found "philosophy in whales" and "poetry in blubber", and concluded that few books that claimed to be either philosophical or literary works "contain as much true philosophy and as much genuine poetry as the tale of the "Pequod"'s whaling expedition", making it a work "far beyond the level of an ordinary work of fiction". The "Morning Post" found it "one of the cleverest, wittiest, and most amusing of modern books", and predicted that it was a book "which will do great things for the literary reputation of its author".

Melville himself never saw these reviews, and Parker calls it a "bitter irony" that the reception overseas was "all he could possibly have hoped for, short of a few conspicuous proclamations that the distance between him and Shakespeare was by no means immeasurable."

One of the earliest reviews, by the extremely conservative critic Henry Chorley in the highly regarded London "Athenaeum", described it as 

According to the London "Literary Gazette and Journal of Science and Art" for December 6, 1851, "Mr. Melville cannot do without savages, so he makes half of his "dramatis personae" wild Indians, Malays, and other untamed humanities", who appeared in "an odd book, professing to be a novel; wantonly eccentric, outrageously bombastic; in places charmingly and vividly descriptive". Most critics regretted the extravagant digressions because they distracted from an otherwise interesting and even exciting narrative, but even critics who did not like the book as a whole recognized the genius evident in Melville's originality of imagination and expression.

One problem was that since the English edition omitted the epilogue, British reviewers read a book with a first-person narrator who apparently did not survive to tell the tale. The reviewer of the "Literary Gazette" asked how Ishmael, "who appears to have been drowned with the rest, communicated his notes to Mr. Bentley". The reviewer in the "Spectator" objected that "nothing should be introduced into a novel which it is physically impossible for the writer to have known: thus, he must not describe the conversation of miners in a pit if they "all" perish." The "Dublin University Magazine" asked "how does it happen that the author is alive to tell the story?" and the "Literary Gazette" declared that how the writer, "who appears to have been drowned with the rest, communicated his notes for publication to Mr. Bentley is not explained". A few other reviewers, who did not comment upon the apparent impossibility of Ishmael telling the story, pointed out violations of narrative conventions in other passages.

Other reviewers were fascinated enough with the book to accept its perceived flaws. "John Bull" praised the author for making literature out of unlikely and even unattractive matter, and the "Morning Post" found that delight far oustripped the improbable character of events. Though some reviewers viewed the characters, especially Ahab, as exaggerated, many understood it took an extraordinary character to undertake the battle with the white whale. Melville's style was usually praised regardless of the reviewer's judgment of the book, but some perceived the same tendency to over-doing here, and some found his style too American.

Some sixty reviews appeared in America, the criterion for counting as a review being more than two lines of comment. Only a couple of reviewers expressed themselves early enough not to be influenced by news of the British reception. Though "Moby-Dick" did contain the "Epilogue" and so accounted for Ishmael's survival, the British reviews influenced the American reception. The earliest American review, in the Boston "Post" for November 20, quoted the London "Athenaeum"s scornful review, not realizing that some of the criticism of "The Whale" did not pertain to "Moby-Dick". This last point, and the authority and influence of British criticism in American reviewing, is clear from the review's opening: "We have read nearly one half of this book, and are satisfied that the London Athenaeum is right in calling it 'an ill-compounded mixture of romance and matter-of-fact'". Though the "Post" quoted the greater portion of the review, it omitted the condensed extract of Melville's prose the "Athenaeum" had included to give readers an example of it. The "Post" deemed the price of one dollar and fifty cents far too much: "'The Whale' is not worth the money asked for it, either as a literary work or as a mass of printed paper".

The New York "North American Miscellany" for December summarized the verdict in the "Athenaeum". The reviewer of the December New York "Eclectic Magazine" had actually read "Moby-Dick" in full, and was puzzled why the "Athenaeum" was so scornful of the ending. The attack on "The Whale" by the "Spectator" was reprinted in the December New York "International Magazine", which inaugurated the influence of another unfavorable review. Rounding off what American readers were told about the British reception, in January "Harper's Monthly Magazine" attempted some damage control, and wrote that the book had "excited a general interest" among the London magazines.

The most influential American review, ranked according to the number of references to it, appeared in the weekly magazine "Literary World", which had printed Melville's "Mosses" essay the preceding year. The author of the unsigned review in two installments, on 15 and 22 November, was later identified as publisher Evert Duyckinck. The first half of the first installment was devoted to an event of remarkable coincidence: early in the month, between the publishing of the British and the American edition, a whale had sunk the New Bedford whaler "Ann Alexander" near Chile. In the second installment, Duyckinck described "Moby-Dick" as three books rolled into one: he was pleased with the book as far as it was a thorough account of the sperm whale, less so with it as far as the adventures of the "Pequod" crew were considered, perceiving the characters as unrealistic and expressing inappropriate opinions on religions, and condemned the essayistic rhapsodizing and moralizing with what he thought was little respect of what "must be to the world the most sacred associations of life violated and defaced." The review prompted Hawthorne to take the "unusually aggressive step of reproving Duyckinck" by criticizing the review in a letter to Duyckinck of December 1:

What a book Melville has written! It gives me an idea of much greater power than his preceding ones. It hardly seemed to me that the review of it, in the Literary World, did justice to its best points.

The Transendental socialist George Ripley published a review in the New York "Tribune" for 22 November, in which he compared the book favorable to "Mardi", because the "occasional touches of the subtle mysticism" was not carried on to excess but kept within boundaries by the solid realism of the whaling context. Ripley was almost surely also the author of the review in "Harper's" for December, which saw in Ahab's quest the "slight framework" for something else: "Beneath the whole story, the subtle, imaginative reader may perhaps find a pregnant allegory, intended to illustrate the mystery of human life." Among the handful of other favorable reviews was one in the "Albion" on 22 November which saw the book as a blend of truth and satire. Melville's friend Nathaniel Parker Willis, reviewing the book in the 29 November "Home Journal", found it "a very racy, spirited, curious and entertaining book...it enlists the curiosity, excites the sympathies, and often charms the fancy". In the 6 December "Spirit of the Times", editor William T. Porter praised the book, and all of Melville's five earlier works, as the writings "of a man who is at once philosopher, painter, and poet". Some other, shorter reviews mixed their praise with genuine reservations about the "irreverence and profane jesting", as the New Haven "Daily Palladium" for 17 November phrased it. Many reviewers, Parker observes, had come to the conclusion that Melville was capable of producing enjoyable romances, but they could not see in him the author of great literature.

Within a year after Melville's death, "Moby-Dick", along with "Typee", "Omoo", and "Mardi", was reprinted by Harper & Brothers, giving it a chance to be rediscovered. However, only New York's literary underground seemed to take much interest, just enough to keep Melville's name circulating for the next 25 years in the capital of American publishing. During this time, a few critics were willing to devote time, space, and a modicum of praise to Melville and his works, or at least those that could still be fairly easily obtained or remembered. Other works, especially the poetry, went largely forgotten.

In 1917, American author Carl Van Doren became the first of this period to proselytize about Melville's value. His 1921 study, "The American Novel", called "Moby-Dick" a pinnacle of American Romanticism.

In his 1923 idiosyncratic but influential "Studies in Classic American Literature", novelist, poet, and short story writer D. H. Lawrence celebrated the originality and value of American authors, among them Melville. Perhaps surprisingly, Lawrence saw "Moby-Dick" as a work of the first order despite his using the expurgated original English edition which also lacked the epilogue.

The Modern Library brought out "Moby-Dick" in 1926 and the Lakeside Press in Chicago commissioned Rockwell Kent to design and illustrate a striking three-volume edition which appeared in 1930. Random House then issued a one-volume trade version of Kent's edition, which in 1943 they reprinted as a less expensive Modern Library Giant.

The novel has been adapted or represented in art, film, books, cartoons, television, and more than a dozen versions in comic-book format. The first adaptation was the 1926 silent movie "The Sea Beast", starring John Barrymore, in which Ahab kills the whale and returns to marry his fiancée. The most famous adaptation was the John Huston 1956 film produced from a screenplay by author Ray Bradbury. The long list of adaptations, as Bryant and Springer put it, demonstrates that "the iconic image of an angry embittered American slaying a mythic beast seemed to capture the popular imagination", showing how "different readers in different periods of popular culture have rewritten "Moby-Dick"" to make it a "true cultural icon".

American author Ralph Ellison wrote a tribute to the book in the prologue of his 1952 novel "Invisible Man", where the narrator remembers a moment of truth under the influence of marijuana, and evocates a church service: "Brothers and sisters, my text this morning is the 'Blackness of Blackness.' And the congregation answers: 'That blackness is most black, brother, most black ...'" This scene, Ellison biographer Arnold Rampersad observes, "reprises a moment in the second chapter of "Moby-Dick"", where Ishmael wanders around New Bedford looking for a place to spend the night, and momentarily joins a congregation: "It was a negro church; and the preacher's text was about the blackness of darkness, and the weeping and wailing and teeth-gnashing there." According to Rampersad, it was Melville who "empowered Ellison to insist on a place in the American literary tradition" by his example of "representing the complexity of race and racism so acutely and generously in his text". Rampersaf also believes Ellison's choice of a first-person narrator was inspired above all by "Moby-Dick", and the novel even has a similar opening sentence with the narrator introducing himself ("I am an invisible man"). The oration by Ellison's blind preacher Barbee resembles Father Mapple's sermon in that both prepare the reader for what is to come.

American songwriter Bob Dylan elaborated on the book in his Nobel Prize Acceptance Speech of 2017, citing the book as one of the three books that influenced him most. Dylan's description of the book ends with an acknowledgment: "That theme, and all that it implies, would work its way into more than a few of my songs."





</doc>
<doc id="19862" url="https://en.wikipedia.org/wiki?curid=19862" title="Underground">
Underground

Underground most commonly refers to:

Underground may also refer to:











</doc>
<doc id="19863" url="https://en.wikipedia.org/wiki?curid=19863" title="Madeira River">
Madeira River

The Madeira River (, ) is a major waterway in South America, approximately long. The Madeira is one of the biggest tributaries of the Amazon, accounting for about 15% of the water in the basin. A map from Emanuel Bowen in 1747, held by the David Rumsey Map Collection, refers to the Madeira by the pre-colonial, indigenous name Cuyari: 
The River of Cuyari, called by the Portuguese Madeira or the Wood River, is formed by two great rivers, which join near its mouth. It was by this River, that the Nation of Topinambes passed into the River Amazon.
The mean inter-annual precipitations on the great basins vary from , the entire upper Madeira basin receiving . The greatest extremes of rainfall are between . At its head, the Madeira on its own is still one of the largest rivers of the world, with a mean inter-annual discharge of , i.e., per year, approximately half the discharge of the Congo River. The mean inter-annual contribution of the Bolivian Andes is , i.e., per year, representing 25% of the discharge of the entire upper Madeira basin. On the further course towards the Amazon, the mean discharge of the Madeira increases up to .

Between Guajará-Mirim and the falls of Teotônio, the Madeira receives the drainage of the north-eastern slopes of the Andes from Santa Cruz de la Sierra to Cuzco, the whole of the south-western slope of Brazilian Mato Grosso and the northern slope of the Chiquitos sierras. In total, the catchment area is 850,000 km, almost equal in area to France and Spain combined. The waters flow into the Madeira from many large rivers, the principal of which, (from east to west), are the Guaporé or Itenez, the Baures and Blanco, the Itonama or San Miguel, the Mamoré, Beni, and Mayutata or Madre de Dios, all of which are reinforced by numerous secondary but powerful affluents. The climate of the upper catchment area varies from humid in the western edge with the origin of the river's main stem by volume (Río Madre de Dios, Río Beni) to semi arid in the southernmost part with the andine headwaters of the main stem by length (Río Caine, Río Rocha, Río Grande, Mamoré).

All of the upper branches of the river Madeira find their way to the falls across the open, almost level Mojos and Beni plains, of which are yearly flooded to an average depth of about for a period of from three to four months.

From its source in the confluence of Beni and Mamoré rivers and downstream to Abuna river the Madeira flows northward forming border between Bolivia and Brazil. Below its confluence with the latter tributary the flow of river changes to north-eastward direction, inland of Rondônia state of Brazil. The section of the river from the border to Porto Velho has notable drop of bed and was not navigable. Before 2012 the falls of Teotônio and of San Antonio existed here, they had higher flow rate and bigger level drop than more famous Boyoma Falls in Africa. Currently these rapids are submerged by the reservoir of Santo Antônio Dam. Below Porto Velho the Madeira meanders north-eastward through the Rondônia and Amazonas states of north west Brazil to its junction with the Amazon.

The Rio Madeira Sustainable Development Reserve, created in 2006, extends along the north bank of the river opposite the town of Novo Aripuanã.
At its mouth is Ilha Tupinambaranas, an extensive marshy region formed by the Madeira’s distributaries.

The Madeira river rises more than 15 m (50 ft) during the rainy season, and ocean vessels may ascend it to the Falls of San Antonio, near Porto Velho, Brazil, above its mouth; but in the dry months, from June to November, it is only navigable for the same distance for craft drawing about 2 m (from 5 to 6 feet) of water. The Madeira-Mamoré Railroad runs in a loop around the unnavigable section to Guajará-Mirim on the Mamoré River, but is not functional, limiting shipping from the Atlantic at Porto Velho.

Today, it is also one of the Amazon Basin's most active waterways, and helps export close to 4 million tons of grains, which are loaded onto barges in Porto Velho, where both Cargill and Amaggi have loading facilities, and then shipped down the Madeira to the ports of Itacoatiara, near the mouth of the Madeira, just upstream on the left bank of the Amazon, or further down the Amazon, to the port of Santarem, at the mouth of the Tapajos River. From these two ports, Panamax type ships then export the grains - mainly soy and corn - to Europe and Asia. The Madeira waterway is also used to take fuel from the REMAN refinery (Petrobras) in Manaus, state capital of Amazonas, to Porto Velho, from where the states of Acre, Rondonia and parts of Mato Grosso are supplied mainly with gasoline (petrol) refined in Manaus. Cargo barges also use the Madeira on the route between Manaus and Porto Velho, which is 1,225 km along the Rio Negro, Amazon and Madeira, connecting Manaus' industrial district with the rest of Brazil, as Manaus is land-locked as far as logistics with the rest of the country are concerned, to bring in part of its raw materials, and export its produce to the major consumer centres of Sao Paulo and Rio de Janeiro. In 2012, the cargo amounted to 287,835 tons (both directions). The total tonnage shipped in 2012 on the Madeira accounted to 5,076,014.

Two large dams (see below) are under construction as part of the IIRSA regional integration project. The dam projects include large ship-locks capable of moving oceangoing vessels between the impounded reservoir and the downstream river. If the project is completed, "more than 4,000 km of waterways upstream from the dams in Brazil, Bolivia, and Peru would become navigable.".

As typical of Amazonian rivers with the primary headwaters in the Andes, the Madeira River is turbid because of high sediment levels and it is whitewater, but some of its tributaries are clearwater (e.g., Aripuanã and Ji-Paraná) or blackwater (e.g., Manicoré).

The Bolivian river dolphin, variously considered a subspecies of the Amazon river dolphin or a separate species, is restricted to the upper Madeira River system. It has been estimated that there are more than 900 fish species in the Madeira River Basin, making it one of the freshwater systems in the world with the highest species richness.

The river is the fifth title of the album Aguas da Amazonia.

In July 2007, plans have been approved by the Brazilian Government to construct two hydroelectric dams on the Madeira River, the Santo Antonio Dam near Porto Velho and the Jirau Dam about 100 km upstream. Both the Jirau and Santo Antonio dams are run-of-the-river projects that do not impound a large reservoir. Both dams also feature some environmental re-mediation efforts (such as fish ladders). As a consequence, it has been suggested that there has not been strong environmental opposition to the implementation of the Madeira river complex. Yet, if the fish ladders fail, "several valuable migratory fish species could suffer near-extinction as a result of the Madeira dams."

There are also concerns with deforestation and pressure on conservation areas and indigenous peoples' territories.
The Worldwatch institute has also criticized the fast-track approval process for "kindler, gentler dams with smaller reservoirs, designed to lessen social and environmental impacts", claiming that no project should "fast-track the licensing of new dams in Amazonia and allow projects to circumvent Brazil's tough environmental laws".



</doc>
<doc id="19864" url="https://en.wikipedia.org/wiki?curid=19864" title="Marañón River">
Marañón River

The Marañón River (, ) is the principal or mainstem source of the Amazon River, arising about 160 km to the northeast of Lima, Peru, and flowing through a deeply eroded Andean valley in a northwesterly direction, along the eastern base of the Cordillera of the Andes, as far as 5° 36′ southern latitude; from where it makes a great bend to the northeast, and cuts through the jungle Andes, until at the Pongo de Manseriche it flows into the flat Amazon basin. Although historically, the term "Marañon River" often was applied to the river all the way to the Atlantic Ocean, nowadays the Marañon River is generally thought to end at the confluence with the Ucayali River, after which most cartographers label the ensuing waterway the Amazon River.

The Marañón River is Peru's second longest river according to a 2005 statistical publication by the Instituto Nacional de Estadística e Informática.

The Marañon River was considered the source of the Amazon River starting with the 1707 map published by Padre Samuel Fritz, who indicated the great river “has its source on the southern shore of a lake that is called Lauricocha, near Huánuco." Fritz's reasoning was based on the fact that the Marañon River is the largest river branch one encounters when journeying upstream, something clearly evident on his map. For most of the 18th–19th centuries and into the 20th century, the Marañon River was generally considered the source of the Amazon. The Marañon River continues to claim the title of the "mainstem source" or "hydrological source" of the Amazon due to its contribution of the highest annual discharge rates.

The initial section of the Marañon contains a plethora of pongos, which are gorges in the jungle areas often with difficult rapids.
The Pongo de Manseriche is the final pongo on the Marañon located just before the river enters the flat Amazon basin. It is long and located between the confluence with the Rio Santiago, and the village of Borja. According to Captain Carbajal, who attempted ascent through the Pongo de Manseriche in the little steamer "Napo," in 1868, it is a vast rent in the Andes about 600 m (2000 ft) deep, narrowing in places to a width of only 30 m (100 ft), the precipices "seeming to close in at the top." Through this canyon the Marañón leaps along, at times, at the rate of 20 km/h (12 miles an hour). The pongo is known for wrecking many ships and many drownings.

Downstream of the Pongo de Manseriche the river often has islands, and there is usually nothing visible from its low banks but an immense forest-covered plain known as the "selva baja" ("low jungle") or Peruvian Amazonia. It is home to indigenous peoples such as the Urarina of the Chambira Basin , the Candoshi, and the Cocama-Cocamilla peoples.

A 552 km (343 mile) section of the Marañon River between Puente Copuma (Puchka confluence) and Corral Quemado is a class IV raftable river that is similar in many ways to the Grand Canyon of the United States and has been labeled the "Grand Canyon of the Amazon". Most of this section of the river is in a canyon that is up to 3000 m deep on both sides – over twice the depth of the Colorado's Grand Canyon. It is in dry desert-like terrain, much of which receives only 250–350 mm/rain per year (10–14"/year) with parts such as from Balsas to Jaén known as the hottest "infierno" area of Peru. The Marañon Grand Canyon section flows by the village of Calemar, where Peruvian writer Ciro Alegría based one of his most important novels: "La serpiente de oro" (1935).

One of the first popular descents of the Marañon River occurred In 1743 the Frenchman Charles Marie de La Condamine, who journeyed from the Chinchipe confluence all the way to the Atlantic Ocean. La Condamine did not descend the initial section of the Marañon by boat due to the plethora of pongos. From where he began his boating descent at the Chiriaco confluence, La Condamine still had to confront several pongos, including the Pongo de Huaracayo (or Guaracayo) and the Pongo de Manseriche.

The upper Marañon River has seen a number of descents. An attempt to paddle the river was made by Herbert Rittlinger in 1936. Sebastian Snow was an adventurer who journeyed down most of the river by trekking to Chiriaco River starting at the source near Lake Niñacocha. 

In 1976 and/or 1977 Laszlo Berty descended the section from Chagual to the jungle in raft. In 1977, a group composed of Tom Fisher, Steve Gaskill, Ellen Toll, and John Wasson spent over a month descending the river from Rondos to Nazareth with kayaks and a raft. In 2004, Tim Biggs and companions kayaked the entire river from the Nupe River to Iquitos. In 2012, Rocky Contos descended the entire river with various companions along the way.

The Marañon River may supply 20 hydroelectric mega-dams planned in the Andes, and it has been speculated that most of the power is destined for export to Brazil, Chile or Ecuador. Dam survey crews have drafted construction blueprints and the Environmental Impact Statements have been available since November 2009 for the Veracruz dam and since November 2011 the Chadin2 dam. 
A 2011 law stated "national demand" for the hydroelectric energy, while in 2013 Peruvian president Ollanta Humala explicitly made a connection with mining; the energy is to supply mines in the Cajamarca Region, La Libertad, Ancash Region and Piura Region. Construction of the 406 MW dam in Chaglla District started in 2012.

Opposition arose because the dams are expected to disrupt the major source of the Amazon, alter normal silt deposition into the lower river, damage habitat and migration patterns for fish and other aquatic life, displace thousands of residents along the river, and damage a national treasure "at least as nice as the Grand Canyon in the USA". Residents have launched efforts to halt the dams along the river with conservation groups such as SierraRios and International Rivers.

Potential ecological impacts of 151 new dams greater than 2 MW on five of the six major Andean tributaries of the Amazon over the next 20 years are estimated to be high, including the first major break in connectivity between Andean headwaters and lowland Amazon and deforestation due to infrastructure.


</doc>
<doc id="19865" url="https://en.wikipedia.org/wiki?curid=19865" title="March 6">
March 6





</doc>
<doc id="19866" url="https://en.wikipedia.org/wiki?curid=19866" title="Morona">
Morona

The Morona is a tributary to the Marañón River, and flows parallel to the Pastaza River and immediately to the west of it, and is the last stream of any importance on the northern side of the Amazon before reaching the Pongo de Manseriche.

It is formed from a multitude of water-courses which descend the slopes of the Ecuadorian Andes south of the gigantic volcano of Sangay; but it soon reaches the plain, which commences where it receives its Cusulima branch. The Morona is navigable for small craft for about 300 miles above its mouth, but it is extremely tortuous. Canoes may ascend many of its branches, especially the Cusuhma and the Miazal, the latter almost to the base of Sangay. The Morona has been the scene of many rude explorations, with the hope of finding it serviceable as a commercial route between the inter-Andean tableland of Ecuador and the Amazon river.


</doc>
<doc id="19867" url="https://en.wikipedia.org/wiki?curid=19867" title="Max Newman">
Max Newman

Maxwell Herman Alexander Newman, FRS, (7 February 1897 – 22 February 1984), generally known as Max Newman, was a British mathematician and codebreaker. His work in World War II led to the construction of Colossus, the world's first operational, programmable electronic computer, and he established the Royal Society Computing Machine Laboratory at the University of Manchester, which produced the world's first working, electronic stored-program electronic computer in 1948, the Manchester Baby.

Max Newman was born Maxwell Herman Alexander Neumann in Chelsea, London, England, to a Jewish family, on 7 February 1897. His father was Herman Alexander Neumann, originally from the German city of Bromberg (now in Poland) who had emigrated with his family to London at the age of 15. Herman worked as a secretary in a company, and married Sarah Ann (Pike), an English schoolteacher, in 1896.

The family moved to Dulwich in 1903, and Newman attended Goodrich Road school, then City of London School from 1908. At school, he excelled in classics and in mathematics. He played chess and the piano well.

Newman won a scholarship to study mathematics at St John's College, Cambridge in 1915, and in 1916 gained a First in Part I of the Cambridge Mathematical Tripos.

His studies were interrupted by World War I. His father was interned as an enemy alien after the start of the war in 1914, and upon his release he returned to Germany. In 1916, Herman changed his name by deed poll to the anglicised "Newman" and Sarah did likewise in 1920. In January 1917 Newman took up a teaching post at Archbishop Holgate's Grammar School in York, leaving in April 1918. He spent some months in the Royal Army Pay Corps, and then taught at Chigwell School for six months in 1919 before returning to Cambridge. He was called up for military service in February 1918, but claimed conscientious objection due to his beliefs and his father's country of origin, and thereby avoided any direct role in the fighting.

He resumed his interrupted studies in October 1919, and graduated in 1921 as a Wrangler (equivalent to a First) in Part II of the Mathematical Tripos, and gained distinction in Schedule B (the equivalent of Part III). His dissertation considered the use of "symbolic machines" in physics, foreshadowing his later interest in computing machines.

On 5 November 1923 he was elected a Fellow of St John's. He worked on the foundations of combinatorial topology, and proposed that a notion of equivalence be defined using only three elementary "moves". Newman's definition avoided difficulties that had arisen from previous definitions of the concept. Publishing over twenty papers established his reputation as an "expert in modern topology". Newman wrote "Elements of the topology of plane sets of points", a work on general topology and undergraduate text. He also published papers on mathematical logic, and solved a special case of Hilbert's fifth problem.

He was appointed a lecturer in mathematics at Cambridge in 1927, where his 1935 lectures on the Foundations of Mathematics and Gödel's theorem inspired Alan Turing to embark on his pioneering work on the "Entscheidungsproblem" (decision problem) using a hypothetical computing machine. In spring 1936, Newman was presented by Turing with a draft of "On Computable Numbers with an Application to the Entscheidungsproblem". He realised the paper's importance and helped ensure swift publication. Newman subsequently arranged for Turing to visit Princeton where Alonzo Church was working on the same problem but using his Lambda calculus. During this period, Newman started to share Turing's dream of building a stored-program computing machine.

During this time at Cambridge, he developed close friendships with Patrick Blackett, Henry Whitehead and Lionel Penrose.

In September 1937, Newman and his family accepted an invitation to work for six months at Princeton. At Princeton, he worked on the Poincaré Conjecture and, in his final weeks there, presented a proof. However, in July 1938, after he returned to Cambridge, Newman discovered that his proof was fatally flawed.

In 1939, Newman was elected a Fellow of the Royal Society.

In December 1934 he married Lyn Lloyd Irvine, a writer, with Patrick Blackett as best man. They had two sons, Edward (born 1935) and William (born 1939).

The United Kingdom declared war on Germany on 3 September 1939. Newman's father was Jewish, which was of particular concern in the face of Nazi Germany, and Lyn, Edward and William were evacuated to America in July 1940 (where they spent three years before returning to England in October 1943). After Oswald Veblen—maintaining 'that every able-bodied man ought to be carrying a gun or hand-grenade and fight for his country'—opposed moves to bring him to Princeton, Newman remained at Cambridge and at first continued research and lecturing.

By spring 1942, he was considering involvement in war work. He made enquiries. After Patrick Blackett recommended him to the Director of Naval Intelligence, Newman was sounded out by Frank Adcock in connection with the Government Code and Cypher School at Bletchley Park.

Newman was cautious, concerned to ensure that the work would be sufficiently interesting and useful, and there was also the possibility that his father's German nationality would rule out any involvement in top-secret work. The potential issues were resolved by the summer, and he agreed to arrive at Bletchley Park on 31 August 1942. Newman was invited by F. L. (Peter) Lucas to work on Enigma but decided to join Tiltman's group working on Tunny.

He was assigned to the Research Section and set to work on a German teleprinter cipher known as "Tunny". He joined the "Testery" in October. Newman enjoyed the company but disliked the work and found that it was not suited to his talents. He persuaded his superiors that Tutte's method could be mechanised, and he was assigned to develop a suitable machine in December 1942. Shortly afterwards, Edward Travis (then operational head of Bletchley Park) asked Newman to lead research into mechanised codebreaking.

When the war ended, Newman was presented with a silver tankard inscribed 'To MHAN from the Newmanry, 1943-45'.

Construction started in January 1943, and the first prototype was delivered in June 1943. It was operated in Newman's new section, termed the "Newmanry", was housed initially in Hut 11 and initially staffed by himself, Donald Michie, two engineers, and 16 Wrens. The Wrens nicknamed the machine the "Heath Robinson", after the cartoonist of the same name who drew humorous drawings of absurd mechanical devices.

The Robinson machines were limited in speed and reliability. Tommy Flowers of the Post Office Research Station, Dollis Hill had experience of thermionic valves and built an electronic machine, the Colossus computer which was installed in the Newmanry. This was a great success and ten were in use by the end of the war.

In September 1945, Newman was appointed head of the Mathematics Department and to the Fielden Chair of Pure Mathematics at the University of Manchester.

Newman lost no time in establishing the renowned Royal Society Computing Machine Laboratory at the University. In February 1946, he wrote to John von Neumann, expressing his desire to build a computing machine. The Royal Society approved Newman's grant application in July 1946. Frederic Calland Williams and Thomas Kilburn, experts in electronic circuit design, were recruited from the Telecommunications Research Establishment. Kilburn and Williams built Baby, the world's first electronic stored-program digital computer based on Alan Turing's and John von Neumann's ideas.

After the Automatic Computing Engine suffered delays and set backs, Turing accepted Newman's offer and joined the Computer Machine Laboratory in May 1948 as Deputy Director (there being no Director). Turing joined Kilburn and Williams to work on Baby's successor, the Manchester Mark I. Collaboration between the University and Ferranti later produced the Ferranti Mark I, the first mass-produced computer to go on sale.

Newman retired in 1964 to live in Comberton, near Cambridge. After Lyn's death in 1973 he married Margaret Penrose, widow of his friend Lionel Penrose.

He continued to do research on combinatorial topology during a period when England was a major centre of activity notably Cambridge under the leadership of Christopher Zeeman. Newman made important contributions leading to an invitation to present his work at the 1962 International Congress of Mathematicians in Stockholm at the age of 65, and proved a Generalized Poincaré conjecture for topological manifolds in 1966.

At the age of 85, Newman began to suffer from Alzheimer's disease. He died in Cambridge two years later.


The Newman Building at Manchester was named in his honour. The building housed the pure mathematicians from the Victoria University of Manchester between moving out of the Mathematics Tower in 2004 and July 2007 when the School of Mathematics moved into its new Alan Turing Building, where a lecture room is named in his honour.

In 1946, Newman declined the offer of an OBE as he considered the offer derisory. Alan Turing had been appointed an OBE six months earlier and Newman felt that it was inadequate recognition of Turing's contribution to winning the war, referring to it as the "ludicrous treatment of Turing".




</doc>
<doc id="19868" url="https://en.wikipedia.org/wiki?curid=19868" title="Measure">
Measure

Measure may refer to:






</doc>
<doc id="19869" url="https://en.wikipedia.org/wiki?curid=19869" title="Massachusetts Bay Transportation Authority">
Massachusetts Bay Transportation Authority

The Massachusetts Bay Transportation Authority (abbreviated MBTA and known colloquially as "the T") is the public agency responsible for operating most public transportation services in Greater Boston, Massachusetts. Earlier modes of public transportation in Boston were independently owned and operated; many were first folded into a single agency with the formation of the Metropolitan Transit Authority (MTA) in 1947. The MTA was replaced in 1964 with the present-day MBTA, which was established as an individual department within the Commonwealth of Massachusetts before becoming a division of the Massachusetts Department of Transportation (MassDOT) in 2009.

The MBTA and Philadelphia's Southeastern Pennsylvania Transportation Authority (SEPTA) are the only U.S. transit agencies that operate all five major types of terrestrial mass transit vehicles: light rail vehicles (the Ashmont–Mattapan High Speed and Green Lines); heavy rail trains (the Blue, Orange, and Red Lines); regional rail trains (the Commuter Rail); electric trolleybuses (the Silver Line); and motor buses (MBTA Bus). In 2016, the system averaged 1,277,200 passengers per weekday, of which the subway averaged 552,500 and the light-rail lines 226,500, making it the fourth-busiest subway system and the busiest light rail system in the United States. 

The MBTA is the largest consumer of electricity in Massachusetts, and the second-largest land owner (after the Department of Conservation and Recreation).
In 2007, its CNG bus fleet was the largest consumer of alternative fuels in the state. The MBTA operates an independent law enforcement agency, the Massachusetts Bay Transportation Authority Police.

Mass transportation in Boston was provided by private companies, often granted charters by the state legislature for limited monopolies, with powers of eminent domain to establish a right-of-way, until the creation of the MTA in 1947. Development of mass transportation both followed and shaped economic and population patterns.

Shortly after the steam locomotive became practical for mass transportation, the private Boston and Lowell Railroad was chartered in 1830, connecting Boston to Lowell, a major northerly mill town in northeast Massachusetts' Merrimack Valley, via one of the oldest railroads in North America. This marked the beginning of the development of American intercity railroads, which in Massachusetts would later become the MBTA Commuter Rail system and the Green Line "D" Branch.

Starting with the opening of the Cambridge Railroad on March 26, 1856, a profusion of streetcar lines appeared in Boston under chartered companies. Despite the change of companies, Boston is the city with the oldest continuously working streetcar system in the world. Many of these companies consolidated, and animal-drawn vehicles were converted to electric propulsion.

Streetcar congestion in downtown Boston led to the subways in 1897 and elevated rail in 1901. The Tremont Street Subway was the first rapid transit tunnel in the United States. Grade-separation added capacity and avoided delays caused by cross streets. The first elevated railway and the first rapid transit line in Boston were built three years before the first underground line of the New York City Subway, but 34 years after the first London Underground lines, and long after the first elevated railway in New York City, its Ninth Avenue El started operations on July 1, 1868 in Manhattan as an elevated cable car line.

Various extensions and branches were added at both ends, bypassing more surface tracks. As grade-separated lines were extended, street-running lines were cut back for faster downtown service. The last elevated heavy rail or "El" segments in Boston were at the extremities of the Orange Line: its northern end was relocated in 1975 from Everett to Malden, MA, and its southern end was relocated into the Southwest Corridor in 1987. However, the Green Line's Causeway Street Elevated remained in service until 2004, when it was relocated into a tunnel with an incline to reconnect to the Lechmere Viaduct. The Lechmere Viaduct and a short section of steel-framed elevated at its northern end remain in service, though the elevated section will be cut back slightly and connected to a northwards viaduct extension in 2017 as part of the Green Line Extension.

The old elevated railways proved to be an eyesore and required several sharp curves in Boston's twisty streets. The Atlantic Avenue Elevated was closed in 1938 amidst declining ridership and was demolished in 1942. As rail passenger service became increasingly unprofitable, largely due to rising automobile ownership, government takeover prevented abandonment and dismantlement. The MTA purchased and took over subway, elevated, streetcar, and bus operations from the Boston Elevated Railway in 1947.

In the 1950s, the MTA ran new subway extensions, while the last two streetcar lines running into the Pleasant Street Portal of the Tremont Street Subway were substituted with buses in 1953 and 1962. In 1958 the MTA purchased the Highland Branch from the Boston and Albany Railroad, reopening a year later as rapid transit line (now the Green Line "D" Branch).

While the operations of the MTA were relatively stable by the early 1960s, the privately operated commuter rail lines were in freefall. The New Haven Railroad, New York Central Railroad, and Boston and Maine Railroad were all financially struggling; deferred maintenance was hurting the mainlines while most branch lines had been discontinued. The 1945 Coolidge Commission plan assumed that most of the commuter rail lines would be replaced by shorter rapid transit extensions, or simply feed into them at reduced service levels. Passenger service on the entire Old Colony Railroad system serving the southeastern part of the state was abandoned by the New Haven Railroad in 1959, triggering calls for state intervention. Between January 1963 and March 1964, the Mass Transportation Commission tested different fare and service levels on the B&M and New Haven systems. Determining that commuter rail operations were important but could not be financially self-sustaining, the MTC recommended an expansion of the MTA to commuter rail territory.

On August 3, 1964, the MBTA succeeded the MTA, with an enlarged service area intended to subsidize continued commuter rail operations. The original 14-municipality MTA district was expanded to 78 cities and towns. Several lines were briefly cut back while contracts with out-of-district towns were reached, but, except for the outer portions of the Central Mass Branch (cut back from Hudson to South Sudbury), West Medway Branch (cut back from West Medway to Millis), Blackstone Line (cut back from Blackstone to Franklin), and B&M New Hampshire services (cut back from Portsmouth to Newburyport), these cuts were temporary; however, service on three branch lines (all of them with only one round trip daily: one morning rush-hour trip in to Boston, and one evening rush-hour trip back out to the suburbs) was dropped permanently between 1965 and 1976 (the Millis (the new name of the truncated West Medway Branch) and Dedham Branches were discontinued in 1967, while the Central Mass Branch was abandoned in 1971). The MBTA bought the Penn Central (New York Central and New Haven) commuter rail lines in January 1973, Penn Central equipment in April 1976, and all B&M commuter assets in December 1976; these purchases served to make the system state-owned with the private railroads retained solely as operators. Only two branch lines were abandoned after 1976: service on the Lexington Branch (also with only one round trip daily) was discontinued in January 1977 after a snowstorm blocked the line, while the Lowell Line's full-service Woburn Branch was eliminated in January 1981 due to poor track conditions.

The MBTA assigned colors to its four rapid transit lines in 1965, and lettered the branches of the Green Line from north to south. Shortages of streetcars, among other factors, caused bustitution of rail service on two branches of the Green Line. The "A" Branch ceased operating entirely in 1969 and was replaced by the 57 bus, while the "E" Branch was truncated from Arborway to Heath Street in 1985, with the section between Heath Street and Arborway being replaced by the 39 bus.

The MBTA purchased bus routes in the outer suburbs to the north and south from the Eastern Massachusetts Street Railway in 1968. As with the commuter rail system, many of the outlying routes were dropped shortly before or after the takeover due to low ridership and high operating costs.

In the 1970s, the MBTA received a boost from the Boston Transportation Planning Review area-wide re-evaluation of the role of mass transit relative to highways. Producing a moratorium on highway construction inside Route 128, numerous mass transit lines were planned for expansion by the Voorhees-Skidmore, Owings and Merrill-ESL consulting team. The removal of elevated lines continued, and the closure of the Washington Street Elevated in 1987 brought the end of rapid transit service to the Roxbury neighborhood. Between 1971 and 1985, the Red Line was extended both north and south, providing not only additional subway system coverage, but also major parking structures at several of the terminal and intermediate stations.

Between 1980 and 1981, Massachusetts Secretary of Transportation and MBTA Chairman Barry Locke and the Assistant Director of the MBTA's Real Estate Department Frank J. Walters, Jr. ran a number of kickback schemes at the MBTA. The kickbacks were discovered when MBTA General Manager James O'Leary accidentally opened an envelope meant for Locke that contained the proceeds from one of the schemes. A total of seventeen people and one corporation would be indicted for their roles in kickback schemes at the MBTA. Locke was convicted of five counts of bribery and sentenced to 7 to 10 years in prison. Locke is the only Massachusetts Cabinet Secretary to be convicted of a felony while in office since the state's adoption of the cabinet system in 1970.

By 1999, the district was expanded further to 175 cities and towns, adding most that were served by or adjacent to commuter rail lines, though the MBTA did not assume responsibility for local service in those communities adjacent to or served by commuter rail.

A turning point in funding occurred in 2000. Prior to July 1, 2000, the MBTA was reimbursed by the Commonwealth of Massachusetts for all costs above revenue collected (net cost of service). Beginning on that date, the T was granted a dedicated revenue stream consisting of amounts assessed on served cities and towns, along with a dedicated 20% portion of the 5% state sales tax. The MBTA now had to live within this "forward funding" budget.

The Commonwealth assigned to the MBTA responsibility for increasing public transit to compensate for increased automobile pollution from the Big Dig. The T submerged a nearby portion of the Green Line and rebuilt Haymarket and North Stations during Big Dig construction. However, these projects have strained the MBTA's limited resources, since the Big Dig project did not include funding for these improvements. Since 1988, the MBTA has been the fastest expanding transit system in the country, even as Greater Boston has been one of the slowest growing metropolitan areas in the United States.
When, in 2000, the MBTA's budget became limited, the agency began to run into debt from scheduled projects and obligatory Big Dig remediation work, which have now given the MBTA the highest debt of any transit authority in the country. In an effort to compensate, rates underwent an appreciable hike on January 1, 2007. Increasingly, local advocacy groups are calling on the state to assume $2.9 billion of the authority's now approximate debt of $9 billion, the interest on which severely limits funds available for required projects.

In 2006, the creation of the MetroWest Regional Transit Authority saw Framingham, Natick, Weston, Sudbury, Wayland, Marlborough, Ashland, Sherborn, Hopkinton, Holliston, and Southborough subtract their MWRTA assessment from their MBTA assessment. Communities that are also members of other RTAs such as CATA, MVRTA, LRTA, WRTA, GATRA, and BAT may also subtract their RTA assessment from their MBTA assessment. The amount of funding the MBTA received remained the same; the assessment on remaining cities and towns increased but is still allocated by the same formula.

On October 31, 2007, the MBTA reestablished commuter rail service to the Greenbush section of Scituate, the third branch of the Old Colony service.
Rail renovation on the Green Line "D" Branch took place in the summer of 2007. New, low-floor cars on the line were introduced on December 1, 2008.

In 2008, Daniel Grabauskas, then the MBTA General Manager, revealed that the MBTA cut trips from published train and bus schedules without informing passengers, referred to as “hidden service cuts”, saying this misrepresentation of service had been happening for years. Grabauskas said this practice has been ended.

On May 28, 2008, a westbound trolley on the Green Line "D" Branch slammed into a stopped train between the Waban and Woodland stations shortly after 6 p.m. At least seven people were injured, and the operator of the moving train, Terrese Edmonds, 24, was killed. On May 8, 2009, two Green Line trolleys collided between Park Street and Government Center when the driver of one of them, 24-year-old Aiden Quinn, was text messaging his girlfriend.
A rule banning cell phones for operators while driving their bus, train, or streetcar was put into place days later.
On June 26, 2009, Governor Deval Patrick signed a law to place the MBTA along with other state transportation agencies within the administrative authority of the Massachusetts Department of Transportation (MassDOT), with the MBTA now part of the Mass Transit division (MassTrans).
The 2009 transportation law continued the MBTA corporate structure and changed the MBTA board membership to the five Governor-appointed members of the Mass DOT Board.

Rhode Island, which has funded commuter rail service to Providence since 1988, paid for extensions of the Providence/Stoughton Line to T.F. Green Airport in 2010 and Wickford Junction in 2012. The Fairmount Line, located entirely in the southern reaches of Boston, has been undergoing an improvement project since 2002. The first new station, Talbot Avenue, opened in November 2012.

Immediately following the 2013 Boston Marathon bombings, the MBTA was partially shut down and National Guardsmen were deployed in various stations around the city. During the ensuing manhunt for Dzhokhar and Tamerlan Tsarnaev the MBTA was fully shut down until the stay-inside request for Watertown, Newton, Waltham, Cambridge, Belmont, and Boston was lifted. During the manhunt, MBTA buses were used to ferry police around the city. After the suspect was caught the MBTA resumed normal service. The next day the MBTA began displaying "BOSTON STRONG" and "WE ARE ONE BOSTON" on buses and subway cars, in addition to the destination that is normally displayed.

"See also:" List of MBTA bus routes

The MBTA bus system is the nation's sixth largest by ridership and comprises over 150 routes across the Greater Boston area. The area served by the MBTA's bus operations is somewhat larger than that served by its subway and light rail, but is significantly smaller than that served by the MBTA's commuter rail operation. At least eight other regional transit authorities also provide bus services within that larger area, these being the Rhode Island Public Transit Authority, Brockton Area Transit Authority, Cape Ann Transportation Authority, Greater Attleboro Taunton Regional Transit Authority, Lowell Regional Transit Authority, Merrimack Valley Regional Transit Authority, Montachusett Regional Transit Authority, and Worcester Regional Transit Authority. All of these authorities have their own fare structures and some subcontract operation to private bus companies. In many cases, their buses serve as feeders to the MBTA commuter rail.

Within MBTA's bus service area, transfers "from" the subway are free if using a CharlieCard (for local buses); transfers "to" the subway require paying the difference between bus and the higher subway fare (for local buses; if not using a CharlieCard, full subway fare must be paid in addition to full bus fare). Bus-to-bus transfers (for local buses) are free unless paying cash. Many of the outlying routes run express along major highways to downtown. The buses are colored yellow on maps and in station decor.

The Silver Line is the MBTA's first service designated as bus rapid transit (BRT), even though it lacks many of the characteristics of bus rapid transit. The first segment began operations in 2002, replacing the 49 bus, which in turn replaced the Washington Street Elevated section of the Orange Line. A full subway fare was charged, with free transfers to the subways downtown until January 1, 2007, when the fare system was revised to categorize the service as a "bus" for fare purposes. The "Washington Street" segment runs along various downtown streets, and mostly in dedicated bus lanes on Washington Street itself. Two Washington Street routes start at Dudley Station in Roxbury and one terminates at Downtown Crossing on Temple Place (SL5-the 2002 route) and one to South Station on Essex Street (SL4)

The "Waterfront" section opened at the end of 2004, and connects South Station to Logan Airport with route SL1 via Ted Williams Tunnel and South Boston (Design Center area) with route SL2. A new service to Chelsea opened April 21, 2018 via the same tunnel that SL1 uses and stops at the Airport Station of the Blue Line. The buses that run the Waterfront section are 2004-05 dual-mode buses, trackless trolley in the Silver Line tunnel and diesel outside. Service to Logan Airport began in June 2005. The Waterfront segment is classified as a "subway" for fare purposes. A transfer between segments is possible at South Station.

A "Phase III" tunneled segment was proposed to connect the two segments for through service, but it was controversial due to high cost and the fact that many did not consider Phase I to be adequate replacement service for the old Elevated. All Phase III tunneling proposals have been suspended due to lack of funds, as has the Urban Ring, which was intended to expand upon existing crosstown buses.

The MBTA contracts with private bus companies to provide subsidized service on certain routes outside of the usual fare structure. These are known collectively as the HI-RIDE Commuter Bus service, and are not numbered or mapped in the same way as integral bus services.

Four routes connecting to Harvard Station (Red Line) still run as trackless trolleys; there was once a much larger trackless trolley system. (See Trolleybuses in Greater Boston.)

In FY2005, there were on average 363,500 weekday boardings of MBTA-operated buses and trackless trolleys (not including the Silver Line), or 31.8% of the MBTA system. Another 4,400 boardings (0.38%) occurred on subsidized bus routes operated by private carriers.

The subway system has three heavy rail rapid transit lines (the Red, Orange and Blue Lines), and two light rail lines (the Green Line and the Ashmont–Mattapan High Speed Line, the latter designated an extension of the Red Line). The system operates according to a spoke-hub distribution paradigm, with the lines running radially between central Boston and its environs. It is common usage in Boston to refer to all four of the color-coded rail lines which run underground as "the subway" or "the T", regardless of the actual railcar equipment used.

All four subway lines cross downtown, forming a quadrilateral configuration, and the Orange and Green Lines (which run approximately parallel in that district) also connect directly at two stations just north of downtown. The Red Line and Blue Line are the only pair of subway lines which do not have a direct transfer connection to each other. Because the various subway lines do not consistently run in any given compass direction, it is customary to refer to line directions as "inbound" or "outbound". Inbound trains travel towards the four downtown transfer stations, and outbound trains travel away from these hub stations.

The Green Line has four branches in the west: "B" (Boston College), "C" (Cleveland Circle), "D" (Riverside), and "E" (Heath Street). The "A" Branch formerly went to Watertown, filling in the north-to-south letter assignment pattern, and the "E" Branch formerly continued beyond Heath Street to Arborway.

The Red Line has two branches in the south—Ashmont and Braintree, named after their terminal stations.

The colors were assigned on August 26, 1965 in conjunction with design standards developed by Cambridge Seven Associates, and have served as the primary identifier for the lines since the 1964 reorganization of the MTA into the MBTA. The Orange Line is so named because it used to run along Orange Street (now lower Washington Street), as the former "Orange Street" also was the street that joined the city to the mainland through Boston Neck in colonial times; the Green Line because it runs adjacent to parts of the Emerald Necklace park system; the Blue Line because it runs under Boston Harbor; and the Red Line because its northernmost station used to be at Harvard University, whose school color is crimson.

The four transit lines all use standard rail gauge, but are otherwise incompatible; trains of one line would have to be modified to run on another. Orange and Blue Line trains are similar enough that modification of some Blue Line trains for operation on the Orange Line was considered, although ultimately rejected for cost reasons. Also, some of the new Blue Line cars from Siemens Transportation were tested on the Orange Line after hours, before acceptance for revenue service on the Blue Line. There are no direct track connections between lines, except between the Red Line and Ashmont-Mattapan High Speed Line, but all except the Blue Line have little-used connections to the national rail network, which have been used for deliveries of railcars and supplies.

Opened in September 1897, the four-track-wide segment of the Green Line tunnel between Park Street and Boylston stations was the first subway in the United States, and has been designated a National Historic Landmark. The downtown portions of what are now the Green, Orange, Blue, and Red line tunnels were all in service by 1912. Additions to the rapid transit network occurred in most decades of the 1900s, and continue in the 2000s with the addition of Silver Line bus rapid transit and planned Green Line expansion. (See History and Future plans sections.)

In FY2005, there were on average 628,400 weekday boardings on the rapid transit and light rail lines (including the Silver Line Bus Rapid Transit), or 55.0% of the MBTA system.

On January 29, 2014, the MBTA completed a countdown clock display system, alerting passengers to arriving trains, at all 53 heavy rail subway stations (the Red, Blue and Orange Lines). The MBTA introduced countdown clocks in underground Green Line stations during 2015. Unlike the other countdown clocks which count down in minutes, the Green Line clocks count down the number of stops away the train is.

The MBTA Commuter Rail system is a regional rail network that reaches from Boston into the suburbs of eastern Massachusetts. The system consists of twelve main lines, three of which have two branches. The rail network operates according to a spoke-hub distribution paradigm, with the lines running radially outward from the city of Boston. Eight of the lines converge at South Station, with four of these passing through Back Bay station. The other four converge at North Station. There is no passenger connection between the two sides; the Grand Junction Railroad is used for non-revenue equipment moves accessing the maintenance facility. The North–South Rail Link has been proposed to connect the two halves of the system; it would be constructed under the Central Artery tunnel of the Big Dig.

Special MBTA trains are run over the Franklin Line and the Providence/Stoughton Line to Foxborough station for New England Patriots home games and other events at Gillette Stadium. The "CapeFLYER" intercity service, operated on summer weekends, uses MBTA equipment and operates over the Middleborough/Lakeville Line. Amtrak runs regularly scheduled intercity rail service over four lines: the "Lake Shore Limited" over the Framingham/Worcester Line, "Acela Express" and "Northeast Regional" services over the Providence/Stoughton Line, and the "Downeaster" over sections of the Lowell Line and Haverhill Line. Freight trains run by Pan Am Southern, Pan Am Railways, CSX Transportation, the Providence and Worcester Railroad, and the Fore River Railroad also use parts of the network.

The first commuter rail service in the United States was operated over what is now the Framingham/Worcester Line beginning in 1834. Within the next several decades, Boston was the center of a massive rail network, with eight trunk lines and dozens of branches. By 1900, ownership was consolidated under the Boston and Maine Railroad to the north, the New York Central Railroad to the west, and the New York, New Haven and Hartford Railroad to the south. Most branches and one trunk line – the former Old Colony Railroad main – had their passenger services discontinued during the middle of the 20th century. In 1964, the MBTA was formed to subsidize the failing suburban railroad operations, with an eye towards converting many to extensions of the existing rapid transit system. The first unified branding of the system was applied on October 8, 1974, with "MBTA Commuter Rail" naming and purple coloration analogous to the four subway lines. The system continued to shrink – mostly with the loss of marginal lines with one daily round trip – until 1981. The system has been expanded since, with four lines restored (Fairmount Line in 1979, Old Colony Lines in 1997, and Greenbush Line in 2007), six extended., and a number of stations added and rebuilt.

Several further expansions are planned or proposed. The South Coast Rail project, for which preliminary construction began in 2014, would extend the Stoughton section of the Providence/Stoughton Line to Taunton, with two branches to New Bedford and Fall River. Extensions of the Providence/Stoughton Line to Kingston, the Middleborough/Lakeville Line to Buzzards Bay, and the Lowell Line into New Hampshire are also proposed. Infill stations at Boston Landing, Blue Hill Avenue, West Station, and South Salem are under construction or planned.

Each commuter rail line has up to eleven fare zones, numbered 1A and 1 through 10. Riders are charged based on the number of zones they travel through. Tickets can be purchased on the train, from ticket counters or machines in some rail stations, or with a mobile app. If a local vendor or ticket machine is available, riders will pay a surcharge for paying with cash on board. Fares range from $2.25 to $12.50, with multi-ride and monthly passes available. In 2016, the system averaged 122,600 daily riders, making it the fourth-busiest commuter rail system in the nation.

The MBTA commuter rail network was the first in the nation to offer free on-board Wi-Fi. It offers Wi-Fi-enabled coaches on all train sets.

The MBTA Boat system comprises several ferry routes via Boston Harbor. One of these is an inner harbor service, linking the downtown waterfront with the Boston Navy Yard in Charlestown. The other routes are commuter routes, linking downtown to Hingham, Hull, and Salem. Some commuter services operate via Logan International Airport.

All boat services are operated by private sector companies under contract to the MBTA. In FY2005, the MBTA boat system carried 4,650 passengers (0.41% of total MBTA passengers) per weekday. The service is provided through contract of the MBTA by Boston Harbor Cruises (BHC).

The MBTA contracts out operation of "The Ride", an on-demand pickup and dropoff service for people with mobility challenges. Paratransit services carry 5,400 passengers on a typical weekday, or 0.47% of the MBTA system ridership. The three private service providers under contractual agreement with the MBTA for The Ride service are: Greater Lynn Senior Services (GLSS), Veterans Transportation LLC, and The Joint Venture of TTI/YCN, LLC.

In September 2016, the MBTA announced that paratransit users would be able to get rides from transportation network companies Uber and Lyft. Riders would pay $2 for a pickup within a few minutes (more for longer trips worth more than $15) instead of $3.15 for a scheduled pickup the next day. The MBTA would pay $13 instead of $31 per ride ($46 per trip when fixed costs of The Ride are considered).

Conventional bicycles are generally allowed on MBTA commuter rail, commuter boat, and rapid transit lines during off-peak hours and all day on weekends and holidays. However, bicycles are "not" allowed at any time on the Green Line, or the Ashmont–Mattapan High Speed Line segment of the Red Line. Buses equipped with bike racks at the front (including the Silver Line) may always accommodate bicycles, up to the capacity limit of the racks. The MBTA claims that 95% of its buses are now equipped with bike racks, except for trackless trolleys which still lack this capability.

Due to congestion and tight clearances, bicycles are banned from Park Street, Downtown Crossing, and Government Center stations at all times.

However, compact folding bicycles are permitted on all MBTA vehicles at all times, provided that they are kept completely folded for the duration of the trip, including passage through faregates. Gasoline-powered vehicles, bike trailers, and Segways are prohibited.

No special permit is required to take a bicycle onto an MBTA vehicle, but bicyclists are expected to follow the rules and hours of operation. Cyclists under 16 years old are supposed to be accompanied by a parent or legal guardian. Detailed rules, and an explanation of how to use front-of-bus bike racks and bike parking are on the MBTA website.

The MBTA says that over 95% of its stations are equipped with bike racks, many of them under cover from the weather. In addition, over a dozen stations are equipped with "Pedal & Park" fully enclosed areas protected with video surveillance and controlled door access, for improved security. To obtain access, a personally registered CharlieCard must be used. Registration is done online, and requires a valid email address and the serial number of the CharlieCard. All bike parking is free of charge.

, the MBTA operates park and ride facilities at 103 locations with a total capacity of 55,000 automobiles, and is the owner of the largest number of off-street paid parking spaces in New England. The number of spaces at stations with parking varies from a few dozen to over 2,500. The larger lots and garages are usually near a major highway exit, and most lots fill up during the morning rush hour. There are some 22,000 spaces on the southern portion of the commuter rail system, 9,400 on the northern portion and 14,600 at subway stations. The parking fee ranges from $4 to $7 per day, and overnight parking (maximum 7 days) is permitted at some stations. Management for a number of parking lots owned by the MBTA is handled by LAZ Parking Limited, LLC.

Customers parking in MBTA-owned and operated lots with existing cash "honor boxes" can pay for parking online or via phone while in their cars or once they board a train, bus, or commuter boat. , the MBTA switched from ParkMobile to PayByPhone as its provider for mobile parking payments by smartphone. Monthly parking permits are available, offering a modest discount. Detailed parking information by station is available online, including prices, estimated vacancy rate, and number of accessible and bicycle parking slots.

, the MBTA has a policy for electric vehicle charging stations in its parking spaces, but does not yet have such facilities available.

From time to time the MBTA has made various agreements with companies that contribute to commuting options. One company the MBTA selected was Zipcar; the MBTA provides Zipcar with a limited number of parking spaces at various subway stations throughout the system.

Traditionally, the MBTA has stopped running around 1 am each night, despite the fact that bars and clubs in most areas of Boston are open until 2 am. Like nearly all subways worldwide, the MBTA's subway does not have parallel express and local tracks, so much rail maintenance is only done when the trains are not running. An MBTA spokesperson has said, "with a 109-year-old system you have to be out there every night" to do necessary maintenance. The MBTA did experiment with "Night Owl" substitute bus service from 2001 to 2005, but abandoned it because of insufficient ridership, citing a $7.53 per rider cost to keep the service open, five times the cost per passenger of an average bus route.

A modified form of the MBTA's previous "Night Owl" service was experimentally reinstated starting in the spring of 2014—this time, all subway lines were proposed to run until 3 am on weekends, along with the 15 most heavily used bus lines and the para-transit service "The Ride".

Starting March 28, 2014, the late-night service began operation on a one-year trial basis, with service continuation depending on late-night ridership and on possible corporate sponsorship. , late-night ridership was stable, and much higher than the earlier failed experimental service. However, it is still unclear whether and on what basis the program might be extended past its first year. The extended hours program has not been implemented on the MBTA commuter rail operations.

In early 2016, the MBTA decided that Late-Night service would be canceled because of lack of funding. The last night for late-night service was on March 19, 2016. The last train left at 2 a.m. on March 19, 2016.

During Fiscal Year 2013, the entire MBTA system had a typical weekday passenger ridership of 1,297,650. The MBTA's rapid transit lines (Red, Green, Orange, and Blue) accounted for 59% of all rides, buses accounted for 30%, and commuter rail accounted for 10% of all rides. The MBTA's ferries and paratransit accounted for the remaining 1% of rides.

Passenger ridership has been steadily growing over the years, and between 2010 and 2013, the system saw passenger ridership grow 4.6% or an additional 57,000 daily passengers to the system.

The MBTA has various fare structures for its various types of service. The CharlieCard electronic farecard is accepted on the subway and bus systems, but not on commuter rail, ferry, or paratransit services. Passengers pay for subway and bus rides at faregates in station entrances or fareboxes in the front of vehicles; MBTA employees manually check tickets on the commuter rail and ferries.

Since the 1980s, the MBTA has offered discounted monthly passes on all modes for the convenience of daily commuters and other frequent riders. One-day and seven-day passes, intended primarily for tourists, are available for buses, subway, and inner harbor ferries.

The MBTA has periodically raised fares to match inflation and keep the system financially solvent. A substantial increase effective July 2012 raised public ire including an "Occupy the MBTA" protest. A transportation funding law passed in 2013 limits MBTA fare increases to 5% every two years. A 5% fare increase effective July 1, 2014 was implemented.

, all subway trips (Green Line, Blue Line, Orange Line, Red Line, Ashmont-Mattapan Line, and the Waterfront section of the Silver Line) cost $2.25 for CharlieCard holders and $2.75 for CharlieTicket or cash payers. Local bus and trackless trolley fares (including the Washington Street section of the Silver Line) are $1.70 for CharlieCard holders and $2.00 for others. All transfers between subway lines are free with all fare media. Passengers using CharlieCards can transfer free from a subway to a bus, and from a bus to a subway for the difference in price ("step-up fare"). CharlieTicket holders can transfer free between buses, but not between subway and bus, except between rapid transit and the Washington Street section of the Silver Line. Paying directly with cash is only available on buses, Green Line surface stops, and the Ashmont-Mattapan Line; a higher price is charged because it slows the process of boarding.

The MBTA operates "Inner Express" and "Outer Express" buses to suburbs outside the subway system. Inner Express bus trips cost $3.65 with a CharlieCard or $4.75 without; Outer Express trips cost $5.25 with and $6.80 without. Free transfers are available to the subway and local buses with a CharlieCard, and to local buses with a CharlieTicket.

CharlieTickets are available from ticket vending machines in MBTA rapid transit stations. CharlieCards are not dispensed by the machines, but are available free of charge on request at most MBTA Customer Service booths in stations, or at the CharlieCard Store at Downtown Crossing station. As given out, the CharlieCards are "empty", and must have value added at an MBTA ticket machine before they can be used.

The fare system, including on-board and in-station fare vending machines, was purchased from German-based Scheidt and Bachmann, which developed the technology. The CharlieCards were developed by Gemalto and later by Giesecke & Devrient. In 2006 electronic fares replaced metal tokens, which had been used on and off on transit systems in Boston for over a century.

Until 2007, not all subway fares were identical - passengers were not charged for boarding outbound Green Line trains at surface stops, while double fares were charged for the outer ends of the Green Line "D" Branch and the Red Line Braintree Branch. As part of a general fare hike effective January 1, 2007, the MBTA eliminated these inconsistent fares.

Commuter rail fares are on a zone-based system, with fares dependent on the distance from downtown. Rides between Zone 1A stations - South Station, Back Bay, most of the Fairmount Line, and eight other stations within several miles of downtown - cost $2.10, the same as a subway fare with a CharlieCard. Fares for other stations range from $5.75 from Zone 1 (~5–10 miles from downtown) to $14.50 from Zone 10 (~60 miles). All Massachusetts stations are Zone 8 or closer; only T.F. Green Airport and Wickford Junction in Rhode Island are Zone 9 and 10.

Interzone fares - for trips that do not go to Zone 1A - are offered at a substantial discount to encourage riders to take the commuter rail for less common commuting patterns for which transit is not usually taken. Discounted monthly passes are available for all trips; 10-ride passes at full price are also available for trips to Zone 1A. All monthly passes include unlimited trips on the subway and local bus; some outer-zone monthlies also offer free use of express buses and ferries. A cash-on-board surcharge of $3.00 is added for trips originating from stations with fare vending machines.

The Inner Harbor Ferry costs $3.25 per ride, and is grouped as a Zone 1A monthly commuter rail pass. Single rides cost $8.50 from Hull or Hingham to Boston, $17.00 from Hull or Hingham to Logan Airport, and $13.75 from Boston to Logan Airport.

Fares on The Ride, the MBTA's paratransit program, are structured differently from other modes. Passengers using The Ride must maintain an account with the MBTA in order to pay for service. Fares are $3.00 for "ADA trips" originating within of fixed-route bus or subway service and booked in advance, and $5.00 for "premium trips" booked the same day, or originating further away.

Discounted fares (, $1.10 for the subway, $1.10 for a subway-bus transfer, and $0.85 for local buses including transfer) as well as discounted monthly local bus and subway passes are available to seniors over 65, and passengers who are permanently disabled who utilize a special photo CharlieCard (called "Senior ID" and "Transportation Access Pass", respectively). Holders of these passes are also entitled to 50% off the Commuter Rail fares. Passengers who are legally blind ride for free on all MBTA services (including express buses and the Commuter Rail) with a "Blind Access Card".

Children under 12 ride for free with an adult (up to 2 per adult). Military personnel, public servants, and certain government officials ride at no charge upon presentation of proper ID, or if dressed in official work uniforms.

Middle school and high school students receive the aforementioned discounts on fares. Student discounts require a "Student CharlieCard" or "S-Card" issued through the holder's school which is valid year-round. From the first day of school until June 31 of the next year, students can buy a 30-day LinkPass for $30 that allows for unlimited usage of the bus and rapid transit lines until the last day of that month. From July 1 to August 31, students can only load money on and pay as they would with a standard CharlieCard. Passes expire on August 31 and are reissued by the school the following school year.

College students are not eligible for reduced fares, but some colleges offer a "Semester Pass" program.

A special "Youth Pass" program was introduced in 2017, allowing young adults less than 25 years old who reside in participating cities or towns to pay reduced fares.

Since the "forward funding" reform in 2000, the MBTA is funded primarily through 16% of the state sales tax excluding the meals tax (with minimum dollar amount guarantee), which is set at 6.25% statewide, and therefore equal to 1% of taxable non-meal purchases statewide. The authority is also funded by passenger fares and formula assessments of the cities and towns in its service area (excepting those which are assessed for the MetroWest Regional Transit Authority). Supplemental income is obtained from its parking lots (reserved for passengers), renting space to retail vendors in and around stations, rents from utility companies using MBTA rights of way, selling surplus land and movable property, advertising on vehicles and properties, and federal operating subsidies for special programs.

The FY2014 budget includes $1.422 Billion for operating expenses and $443.8M in debt and lease payments.

The Capital Investment Program is a rolling 5-year plan which programs capital expenses. The draft FY2009-2014 CIP allocates $3,795M, including $879M in projects funded from non-MBTA state sources (required for Clean Air Act compliance), and $299M in projects with one-time federal funding from the American Recovery and Reinvestment Act of 2009. Capital projects are paid for by federal grants, allocations from the general budget of the Commonwealth of Massachusetts (for legal commitments and expansion projects) and MBTA bonds (which are paid off through the operating budget).

The FY2010 budget was supplemented by $160 million in sales tax revenue when the statewide rate was raised from 5% to 6.25%, to avoid service cuts or a fare increase in a year when deferred debt payments were coming due.

The Boston Metropolitan Planning Organization is responsible for overall regional surface transportation planning. As required by federal law for projects to be eligible for federal funding (except earmarks), the MPO maintains a fiscally constrained 20+ year Regional Transportation Plan for surface transportation expansion, the current edition of which is called "Journey to 2030". The required 4-year MPO plan is called the Transportation Improvement Plan.

The MBTA maintains its own 25-year capital planning document, called the Program for Mass Transportation, which is fiscally unconstrained. The agency's 4-year plan is called the Capital Improvement Plan; it is the primary mechanism by which money is actually allocated to capital projects. Major capital spending projects must be approved by the MBTA Board, and except for unexpected needs, are usually included in the initial CIP.

In addition to federal funds programmed through the Boston MPO, and MBTA capital funds derived from fares, sales tax, municipal assessments, and other minor internal sources, the T receives funding from the Commonwealth of Massachusetts for certain projects. The state may fund items in the State Implementation Plan (SIP) - such as the Big Dig mitigation projects - which is the plan required under the Clean Air Act to reduce air pollution. (, all of Massachusetts is designated as a clean air "non-attainment" zone.)

In 2005, the administration of then-governor Mitt Romney announced a long range transportation plan that emphasized repair and maintenance over expansion.

Due to the financial constraints on the MBTA budget, it is expected that funds for all further expansion projects will be funded with money outside the MBTA's budget. A state transportation bond bill is being used to fund the Green Line extension to Somerville and Medford, and planning for commuter rail service to Fall River and New Bedford.

There is a proposal to extend the Blue Line northward to Lynn, Massachusetts, with two potential extension routes having been identified. One proposed path would run through marshland alongside the existing Newburyport/Rockport commuter rail line, while the other would extend the line along the remainder of the BRB&L right of way.

In addition, the MBTA has committed to designing an extension of the line's southern terminus westward to Charles/MGH, where it would connect with the Red Line. This was one of the mitigation measures the Commonwealth of Massachusetts agreed to as part of the Big Dig.

To settle a lawsuit with the Conservation Law Foundation to mitigate increased automobile emissions from the Big Dig, the Commonwealth of Massachusetts agreed to extend the Green Line north to Somerville and Medford, two suburbs currently under-served by the MBTA. This plan starts at a relocated Lechmere Station, and terminates at College Avenue in Medford and Union Square in Somerville. The original settlement-imposed deadline was December 31, 2014. There will be an expected daily ridership of 8,420. After projected costs increased to $3 billion, the project was halted in 2015 and scaled back. The revised project is expected to serve passengers beginning in late 2021.

Another mitigation project in the initial settlement was restoration of service on the "E" Branch between Heath Street and Arborway/Forest Hills. A revised settlement agreement resulted in the substitution of other projects with similar air quality benefits. The state Executive Office of Transportation promised to consider other transit enhancements in the Arborway corridor.

In 2018, the MBTA and MassDOT opened a new Silver Line route to Chelsea via East Boston and the Airport Blue Line station. Four new Silver Line stations were built in Chelsea—Eastern Avenue, Box District, Downtown Chelsea and Mystic Mall. A new Chelsea commuter rail station and transit hub will be constructed at the terminus of the new Silver Line route. Service began on April 21, 2018.

A planned Silver Line Phase III would have connected the two halves of the Silver Line via an underground busway from Boylston station on the Green Line to South Station. An initial proposed route involved a mile long tunnel connecting separate portals located at Charles and at Tremont streets. , planning of the Phase III tunnel has been suspended indefinitely, without any physical construction having begun, due to funding difficulties and community opposition.

The Urban Ring is a project of the Massachusetts Bay Transportation Authority and the Commonwealth of Massachusetts, to develop new public transportation routes that would provide improved circumferential connections among many existing transit lines that project radially from downtown Boston, allowing easier travel between locations outside of downtown. The project corridor passes through various neighborhoods of Boston, Chelsea, Everett, Malden, Medford, Somerville, Cambridge, and Brookline. The capital cost for this version of the plan is estimated at $2.2 billion, with a projected daily ridership of 170,000. Fifty-three percent of the route is either in a bus-only lane, dedicated busway, or tunnel. The Urban Ring would have a higher collective ridership than the Orange Line, Blue Line, or the entire commuter rail system.

There are several proposed extensions to current commuter rail lines. An extension of the Stoughton Line is proposed to serve Fall River, and New Bedford. Critics argue that building the extension does not make economic sense.

A extension of the Providence Line past Providence to T. F. Green Airport and Wickford Junction in Rhode Island opened in 2012. The Rhode Island Department of Transportation is also studying the feasibility of serving existing Amtrak stations in Kingston and Westerly as well as constructing new stations in Cranston, East Greenwich, and West Davisville. Federal funding has also been provided for preliminary planning of a new station in Pawtucket.

In September 2009, CSX Transportation and the Commonwealth of Massachusetts finalized a $100 million agreement to purchase CSX's Framingham to Worcester tracks, as well as some other track, to improve service on the Framingham/Worcester Line. A liability issue that had held up the agreement was resolved. There is also a project underway to upgrade the Fitchburg Line to have cab signaling and to construct a second track along a run near Acton which is shared with freight traffic, so that the Fitchburg to Boston trip will be able to take only about an hour. Completion is expected in December 2015.

The state of New Hampshire created the New Hampshire Rail Transit Authority and allocated money to build platforms at Nashua and Manchester. An article in "The Eagle-Tribune" claimed that Massachusetts was negotiating to buy property which has the potential to extend the Haverhill Line to Plaistow, New Hampshire.

Massachusetts agreed in 2005 to make improvements on the Fairmount Line part of its legally binding commitment to mitigate increased air pollution from the Big Dig. These improvements, including four new infill stations, were supposed to be complete by December 31, 2011. The total cost of the project was estimated at $79.4 million, and it was expected to divert 220 daily trips from automobiles to transit. , three of the new stations were open; the fourth station has been delayed by community opposition. In 2014, the MBTA announce it would purchase Diesel Multiple Unit (DMU) self-propelled rail cars for the Fairmount Line with eventual expansion to five other lines to be known as the Indigo Line.

No direct rail connection exists between North Station and South Station, effectively splitting the commuter rail network into separate pieces. A North–South Rail Link has been proposed to unite the two halves of the commuter rail system, to allow more convenient and efficient through-routed service. However, because of high cost, Massachusetts withdrew its sponsorship of the proposal in 2006, in communications with the United States Department of Transportation. Advocacy groups continue to press for the project as a better alternative than expanding South Station, which would also be costly but provide fewer overall improvements in service.

In 2015, Massachusetts Governor Charlie Baker signed new legislation creating a financial control board to oversee the MBTA. The Fiscal and Management Control Board started meeting in July 2015 and is charged with bringing financial stability to the agency. The Fiscal and Management Control Board reports to Massachusetts Secretary of Transportation Stephanie Pollack. Three of the five members of the MBTA Fiscal and Management Control Board are also members of the Massachusetts Department of Transportation. The Massachusetts Secretary of Transportation leads the executive management team of MassDOT in addition to serving in the Governor's Cabinet. The MBTA's executive management team is led by its General Manager, who is currently also serving as the MassDOT Rail and Transit Administrator, overseeing all public transit in the state.

The MBTA Advisory Board represents the cities and towns in the MBTA service district. The municipalities are assessed a total of $143M annually (). In return, the Advisory Board has veto power over the MBTA operating and capital budgets, including the power to reduce the overall amount.

The MBTA's buses are maintained and stored at several bus garages located throughout eastern Massachusetts:

Rail lines have their own maintenance facilities:

Major administrative facilities:

, the MBTA employs 6,346 workers, of which roughly 600 are in part-time jobs.

Structurally, the employees of the MBTA function as part of a handful of trade unions. The largest union of the MBTA is the Carmen’s Union (Local 589), representing bus and subway operators. This includes full and part-time bus drivers, motorpersons and streetcar motorpersons, full and part-time train attendants, and Customer Service Agents (CSAs). Further unions include the Machinists Union, Local 264; Electrical Workers Union, Local 717; the Welder's Union, Local 651; the Executive Union; the Office and Professional Employees International Union, Local 453; the Professional and Technical Engineers Union, Local 105; and the Office and Professional Employees Union, Local 6.

Within the authority, employees are ranked according to seniority (or "rating"). This is categorized by an employee's five-digit badge number, though some of the longest serving employees still have only four-digits. An employee's badge number indicates the relative length of employment with the MBTA; badges are issued in sequential order. The rating structure determines many different things, including the rank in which perks are to be offered to employee, such as: When offering the choice for quarter-annual route assignments ("picks"), overtime offerings, and even the rank to transfer new hires from part-time roles to a full-time role.

The MBTA maintains its own police force which actively patrols all areas and vehicles used by the Authority. MBTA Police conduct routine vehicle patrol, routine foot patrol, incident investigations, and specialized patrol with K-9 dogs, and other specialized methods of explosive and narcotics detection.

The MBTA also maintains several closed-circuit television facilities located throughout its service area. The cameras monitor various areas including trains stations, and MBTA vehicles throughout the system on a 24-hour basis. MBTA phone numbers pasted onto the front of the fare gates can place customers having a problem directly into contact with one of these operations centers.

Ahead of the MBTA's 2009 restructuring with the Massachusetts Department of Transportation (MassDOT), the MBTA had a total debenture of over US$8 billion. As a direct result, MBTA fares and parking fees have increased significantly. On July 1, 2012, MBTA fares went up as well as multiple service cuts, another fare hike took place on July 1, 2016.

When the Orange Line was rebuilt in the 1980s, it was rerouted from deteriorating elevated railway structures to instead follow existing rail right-of-way, to greatly reduce land acquisition and construction costs. This had the side effect of changing its course away from the lower income areas of Everett, Chelsea, and Roxbury (where residents are less likely to own cars, and depend more on public transit), toward the more affluent towns of Malden and Medford, as well as sections of the Jamaica Plain neighborhood (where car ownership is higher, and thus, reliance on public transit is far lower).

To mitigate this, the MBTA set up a new bus line served by articulated buses equipped with specialized dispatching equipment, and a few of the features of a Bus Rapid Transit (BRT) route. The MBTA named this new service the Silver Line, and classified it as though it were a high-capacity rail transit service, though it fails to meet full service standards for a BRT route. The Silver Line service has been criticized in many respects, most notably for its slow speed and the fact that it operates in mixed street traffic, subject to gridlock and collisions, earning it the nickname "Silver Lie" among some critics. A rating from the Institute for Transportation and Development Policy (ITDP) determined that the MBTA Silver Line was best classified as "Not BRT" after local decision makers gradually decided to do away with most BRT-specific features.

Transportation advocates in Boston have complained that rail transit riders cannot travel from one outlying area to another without first traveling to the downtown hub stations, changing lines, and traveling outbound again. Some of the radial transit lines, notably the Green Line, are so overcrowded that service is very slow, unreliable, and capacity-limited because of rush-hour "crush loads". There are several crosstown bus lines, such as the #1, #66, CT1, CT2, and CT3 routes, but they are slow, unreliable, and subject to bus bunching because they must operate in mixed street traffic.

The MBTA Urban Ring Project would provide faster and more reliable circumferential service, and relieve overcrowding in the downtown hub stations. This issue has been studied as early as 1972, in the Boston Transportation Planning Review, and has been in detailed planning stages since before 2000, but has only been partially implemented due to lack of funding. A similar problem also occurs in the Washington Metro system, where customers cannot travel between suburbs on the same side of Washington without going through downtown, and Chicago's Metra and CTA systems, where all lines lead into and out of the central business district, rather than around it.

In 1951, the growing subway network was the setting of "A Subway Named Mobius", a science fiction short story written by the American astronomer Armin Joseph Deutsch. The tale described a Boston subway train which accidentally became a "phantom" by becoming lost in the fourth dimension, analogous to a topological Mobius strip. In 2001, a half-century later, the narrative was awarded a Retro Hugo Award for Best Short Story at the World Science Fiction Convention.

In 1959, the satirical song "M.T.A." (informally known as "Charlie on the MTA") was a hit single, as performed by the folksingers the Kingston Trio. It tells the absurd story of a passenger named Charlie, who cannot pay a newly imposed 5-cent exit fare, and thus remains trapped in the subway system. The song was still well known in 2006, when the MBTA named its new electronic farecards the "CharlieCard" and "CharlieTicket".




</doc>
<doc id="19870" url="https://en.wikipedia.org/wiki?curid=19870" title="Meson">
Meson

In particle physics, mesons ( or ) are hadronic subatomic particles composed of one quark and one antiquark, bound together by strong interactions. Because mesons are composed of quark subparticles, they have physical size, notably a diameter of roughly one femtometer, which is about 1.2 times the size of a proton or neutron. All mesons are unstable, with the longest-lived lasting for only a few hundredths of a microsecond. Charged mesons decay (sometimes through mediating particles) to form electrons and neutrinos. Uncharged mesons may decay to photons. Both of these decays imply that color is no longer a property of the byproducts.

Outside the nucleus, mesons appear in nature only as short-lived products of very high-energy collisions between particles made of quarks, such as cosmic rays (high-energy protons and neutrons) and ordinary matter. Mesons are also frequently produced artificially in high-energy particle accelerators in the collisions of protons, antiprotons, or other particles.

Mesons are the associated quantum-field particles that transmit the nuclear force between hadrons that pull those together into a nucleus. Their effect is analogous to photons that are the force carriers that transmit the electromagnetic force of attraction between oppositely charged protons and electrons that allow individual atoms to exist, and further, to pull atoms together into molecules. Higher energy (more massive) mesons were created momentarily in the Big Bang, but are not thought to play a role in nature today. However, such heavy mesons are regularly created in particle accelerator experiments, in order to understand the nature of the heavier types of quark that compose the heavier mesons.

Mesons are part of the hadron particle family, and are defined simply as particles composed of two quarks. The other members of the hadron family are the baryons: subatomic particles composed of three quarks. Some experiments show evidence of exotic mesons, which do not have the conventional valence quark content of one quark and one antiquark.

Because quarks have a spin of , the difference in quark number between mesons and baryons results in conventional two-quark mesons being bosons, whereas baryons are fermions.

Each type of meson has a corresponding antiparticle (antimeson) in which quarks are replaced by their corresponding antiquarks and vice versa. For example, a positive pion () is made of one up quark and one down antiquark; and its corresponding antiparticle, the negative pion (), is made of one up antiquark and one down quark.

Because mesons are composed of quarks, they participate in both the weak and strong interactions. Mesons with net electric charge also participate in the electromagnetic interaction. Mesons are classified according to their quark content, total angular momentum, parity and various other properties, such as C-parity and G-parity. Although no meson is stable, those of lower mass are nonetheless more stable than the more massive, and hence are easier to observe and study in particle accelerators or in cosmic ray experiments. Mesons are also typically less massive than baryons, meaning that they are more easily produced in experiments, and thus exhibit certain higher-energy phenomena more readily than do baryons. For example, the charm quark was first seen in the J/Psi meson () in 1974, and the bottom quark in the upsilon meson () in 1977.

From theoretical considerations, in 1934 Hideki Yukawa predicted the existence and the approximate mass of the "meson" as the carrier of the nuclear force that holds atomic nuclei together. If there were no nuclear force, all nuclei with two or more protons would fly apart due to electromagnetic repulsion. Yukawa called his carrier particle the meson, from μέσος "mesos", the Greek word for "intermediate", because its predicted mass was between that of the electron and that of the proton, which has about 1,836 times the mass of the electron. Yukawa had originally named his particle the "mesotron", but he was corrected by the physicist Werner Heisenberg (whose father was a professor of Greek at the University of Munich). Heisenberg pointed out that there is no "tr" in the Greek word "mesos".

The first candidate for Yukawa's meson, now known in modern terminology as the muon, was discovered in 1936 by Carl David Anderson and others in the decay products of cosmic ray interactions. The mu meson had about the right mass to be Yukawa's carrier of the strong nuclear force, but over the course of the next decade, it became evident that it was not the right particle. It was eventually found that the "mu meson" did not participate in the strong nuclear interaction at all, but rather behaved like a heavy version of the electron, and was eventually classed as a lepton like the electron, rather than a meson. Physicists in making this choice decided that properties other than particle mass should control their classification.

There were years of delays in the subatomic particle research during World War II (1939–45), with most physicists working in applied projects for wartime necessities. When the war ended in August 1945, many physicists gradually returned to peacetime research. The first true meson to be discovered was what would later be called the "pi meson" (or pion). This discovery was made in 1947, by Cecil Powell, César Lattes, and Giuseppe Occhialini, who were investigating cosmic ray products at the University of Bristol in England, based on photographic films placed in the Andes mountains. Some of those mesons had about the same mass as the already-known meson, yet seemed to decay into it, leading physicist Robert Marshak to hypothesize in 1947 that it was actually a new and different meson. Over the next few years, more experiments showed that the pion was indeed involved in strong interactions. The pion (as a virtual particle) is also believed to be the primary force carrier for the nuclear force in atomic nuclei. Other mesons, such as the virtual rho mesons are involved in mediating this force as well, but to a lesser extent. Following the discovery of the pion, Yukawa was awarded the 1949 Nobel Prize in Physics for his predictions.

In the past, the word "meson" was sometimes used to mean "any" force carrier, such as the "Z meson", which is involved in mediating the weak interaction. However, this spurious usage has fallen out of favor, and mesons are now defined as particles composed of pairs of quarks and antiquarks.

Spin (quantum number S) is a vector quantity that represents the "intrinsic" angular momentum of a particle. It comes in increments of  "ħ". The "ħ" is often dropped because it is the "fundamental" unit of spin, and it is implied that "spin 1" means "spin 1 "ħ"". (In some systems of natural units, "ħ" is chosen to be 1, and therefore does not appear in equations.)

Quarks are fermions—specifically in this case, particles having spin ("S" = ). Because spin projections vary in increments of 1 (that is 1 "ħ"), a single quark has a spin vector of length , and has two spin projections ("S" = + and "S" = −). Two quarks can have their spins aligned, in which case the two spin vectors add to make a vector of length "S" = 1 and three spin projections ("S" = +1, "S" = 0, and "S" = −1), called the spin-1 triplet. If two quarks have unaligned spins, the spin vectors add up to make a vector of length S = 0 and only one spin projection ("S" = 0), called the spin-0 singlet. Because mesons are made of one quark and one antiquark, they can be found in triplet and singlet spin states.

There is another quantity of quantized angular momentum, called the orbital angular momentum (quantum number "L"), that comes in increments of 1 "ħ", which represent the angular momentum due to quarks orbiting around each other. The total angular momentum (quantum number "J") of a particle is therefore the combination of intrinsic angular momentum (spin) and orbital angular momentum. It can take any value from to , in increments of 1.

Particle physicists are most interested in mesons with no orbital angular momentum ("L" = 0), therefore the two groups of mesons most studied are the "S" = 1; "L" = 0 and "S" = 0; "L" = 0, which corresponds to "J" = 1 and "J" = 0, although they are not the only ones. It is also possible to obtain "J" = 1 particles from "S" = 0 and "L" = 1. How to distinguish between the "S" = 1, "L" = 0 and "S" = 0, "L" = 1 mesons is an active area of research in meson spectroscopy.

If the universe were reflected in a mirror, most of the laws of physics would be identical—things would behave the same way regardless of what we call "left" and what we call "right". This concept of mirror reflection is called parity ("P"). Gravity, the electromagnetic force, and the strong interaction all behave in the same way regardless of whether or not the universe is reflected in a mirror, and thus are said to conserve parity (P-symmetry). However, the weak interaction does" "distinguish "left" from "right", a phenomenon called parity violation (P-violation).

Based on this, one might think that, if the wavefunction for each particle (more precisely, the quantum field for each particle type) were simultaneously mirror-reversed, then the new set of wavefunctions would perfectly satisfy the laws of physics (apart from the weak interaction). It turns out that this is not quite true: In order for the equations to be satisfied, the wavefunctions of certain types of particles have to be multiplied by −1, in addition to being mirror-reversed. Such particle types are said to have "negative" or "odd" parity ("P" = −1, or alternatively "P" = −), whereas the other particles are said to have "positive" or "even" parity ("P" = +1, or alternatively "P" = +).

For mesons, the parity is related to the orbital angular momentum by the relation:

where the "L" is a result of the parity of the corresponding spherical harmonic of the wavefunction. The "+ 1" comes from the fact that, according to the Dirac equation, a quark and an antiquark have opposite intrinsic parities. Therefore, the intrinsic parity of a meson is the product of the intrinsic parities of the quark (+1) and antiquark (−1). As these are different, their product is −1, and so it contributes the "+ 1" that appears in the exponent.

As a consequence, all mesons with no orbital angular momentum ("L" = 0) have odd parity ("P" = −1).

C-parity is only defined for mesons that are their own antiparticle (i.e. neutral mesons). It represents whether or not the wavefunction of the meson remains the same under the interchange of their quark with their antiquark. If
then, the meson is "C even" (C = +1). On the other hand, if
then the meson is "C odd" (C = −1).

C-parity rarely is studied on its own, but more commonly in combination with P-parity into CP-parity. CP-parity was thought to be conserved, but was later found to be violated in weak interactions.

G parity is a generalization of the C-parity. Instead of simply comparing the wavefunction after exchanging quarks and antiquarks, it compares the wavefunction after exchanging the meson for the corresponding antimeson, regardless of quark content.

If
then, the meson is "G even" (G = +1). On the other hand, if
then the meson is "G odd" (G = −1).

The concept of isospin was first proposed by Werner Heisenberg in 1932 to explain the similarities between protons and neutrons under the strong interaction. Although they had different electric charges, their masses were so similar that physicists believed that they were actually the same particle. The different electric charges were explained as being the result of some unknown excitation similar to spin. This unknown excitation was later dubbed "isospin" by Eugene Wigner in 1937. When the first mesons were discovered, they too were seen through the eyes of isospin and so the three pions were believed to be the same particle, but in different isospin states.

This belief lasted until Murray Gell-Mann proposed the quark model in 1964 (containing originally only the u, d, and s quarks). The success of the isospin model is now understood to be the result of the similar masses of the u and d quarks. Because the u and d quarks have similar masses, particles made of the same number of them also have similar masses. The exact specific u and d quark composition determines the charge, because u quarks carry charge + whereas d quarks carry charge −. For example, the three pions all have different charges ( (), (a quantum superposition of and states), ()), but have similar masses (c. ) as they are each made of a same number of total of up and down quarks and antiquarks. Under the isospin model, they were considered to be a single particle in different charged states.

The mathematics of isospin was modeled after that of spin. Isospin projections varied in increments of 1 just like those of spin, and to each projection was associated a "charged state". Because the "pion particle" had three "charged states", it was said to be of isospin "I" = 1. Its "charged states" , , and , corresponded to the isospin projections "I" = +1, "I" = 0, and "I" = −1 respectively. Another example is the "rho particle", also with three charged states. Its "charged states" , , and , corresponded to the isospin projections "I" = +1, "I" = 0, and "I" = −1 respectively. It was later noted that the isospin projections were related to the up and down quark content of particles by the relation

where the "n"'s are the number of up and down quarks and antiquarks.

In the "isospin picture", the three pions and three rhos were thought to be the different states of two particles. However, in the quark model, the rhos are excited states of pions. Isospin, although conveying an inaccurate picture of things, is still used to classify hadrons, leading to unnatural and often confusing nomenclature. Because mesons are hadrons, the isospin classification is also used, with "I" = + for up quarks and down antiquarks, and "I" = − for up antiquarks and down quarks.

The strangeness quantum number "S" (not to be confused with spin) was noticed to go up and down along with particle mass. The higher the mass, the lower the strangeness (the more s quarks). Particles could be described with isospin projections (related to charge) and strangeness (mass) (see the uds nonet figures). As other quarks were discovered, new quantum numbers were made to have similar description of udc and udb nonets. Because only the u and d mass are similar, this description of particle mass and charge in terms of isospin and flavour quantum numbers only works well for the nonets made of one u, one d and one other quark and breaks down for the other nonets (for example ucb nonet). If the quarks all had the same mass, their behaviour would be called "symmetric", because they would all behave in exactly the same way with respect to the strong interaction. However, as quarks do not have the same mass, they do not interact in the same way (exactly like an electron placed in an electric field will accelerate more than a proton placed in the same field because of its lighter mass), and the symmetry is said to be broken.

It was noted that charge ("Q") was related to the isospin projection ("I"), the baryon number ("B") and flavour quantum numbers ("S", "C", "B"′, "T") by the Gell-Mann–Nishijima formula:

where "S", "C", "B"′, and "T" represent the strangeness, charm, bottomness and topness flavour quantum numbers respectively. They are related to the number of strange, charm, bottom, and top quarks and antiquark according to the relations:

meaning that the Gell-Mann–Nishijima formula is equivalent to the expression of charge in terms of quark content:

Mesons are classified into groups according to their isospin ("I"), total angular momentum ("J"), parity ("P"), G-parity ("G") or C-parity ("C") when applicable, and quark (q) content. The rules for classification are defined by the Particle Data Group, and are rather convoluted. The rules are presented below, in table form for simplicity.

Mesons are classified into types according to their spin configurations. Some specific configurations are given special names based on the mathematical properties of their spin configuration.

Flavourless mesons are mesons made of pair of quark and antiquarks of the same flavour (all their flavour quantum numbers are zero: "S" = 0, "C" = 0, "B"′ = 0, "T" = 0). The rules for flavourless mesons are:
In addition:

Flavoured mesons are mesons made of pair of quark and antiquarks of different flavours. The rules are simpler in this case: the main symbol depends on the heavier quark, the superscript depends on the charge, and the subscript (if any) depends on the lighter quark. In table form, they are:

In addition:

There is experimental evidence for particles that are hadrons (i.e., are composed of quarks) and are color-neutral with zero baryon number, and thus by conventional definition are mesons. Yet, these particles do not consist of a single quark/antiquark pair, as all the other conventional mesons discussed above do. A tentative category for these particles is exotic mesons.

There are at least five exotic meson resonances that have been experimentally confirmed to exist by two or more independent experiments. The most statistically significant of these is the Z(4430), discovered by the Belle experiment in 2007 and confirmed by LHCb in 2014. It is a candidate for being a tetraquark: a particle composed of two quarks and two antiquarks. See the main article above for other particle resonances that are candidates for being exotic mesons.





</doc>
<doc id="19871" url="https://en.wikipedia.org/wiki?curid=19871" title="Marvel Super Heroes (role-playing game)">
Marvel Super Heroes (role-playing game)

Marvel Super Heroes (MSHRPG) is a role playing game set in the Marvel Universe, first published by TSR as "" under license from Marvel Comics in 1984. In 1986, TSR published an expanded edition, entitled the "Marvel Superheroes Advanced Game". Jeff Grubb designed both editions, and Steve Winter wrote both editions. Both use the same game system.

The basic game was designed to let players assume the roles of superheroes from Marvel Comics, such as Spider-Man, Daredevil, Hulk, Captain America, the Fantastic Four, the X-Men, and 
others. 
The game was designed to be easy to understand, and the simplest version, found in the 16-page "Battle Book" of the Basic Set, contains a bare-bones combat system sufficient to resolve comic book style superheroic fights.

Most game situations are resolved by rolling percentile dice and comparing the results against a column of the colorful "Universal Results Table". The column used is determined by the attribute used; different tasks are resolved by reference to different attributes. All characters have seven basic attributes:

Fighting, which determines hit probability in and defense against hand-to-hand attacks.

Agility, which determines hit probability in and defense against ranged attacks, feats of agility vs. the environment, and similar acrobatics.

Strength, which determines damage inflicted by hand-to-hand attacks as well as the success of tasks such as grappling or the lifting and breaking of heavy objects.

Endurance, which determines resistance to physical damage (e.g., poison, disease, death) it also determined how long a character can fight and how fast a character could move at top speed by exerting themselves.

Reason, which determines the success of tasks relating to knowledge, puzzle-solving, and advanced technology.

Intuition, which determines the success of tasks relating to awareness, perception, and instinct.

Psyche, which determines the success of tasks relating to willpower, psionics, and magic.

Players sometimes refer to this set of attributes, or the game system as a whole, by the acronym "FASERIP". Attribute scores for the majority of characters range from 1 to 100, where normal human ability is Typical (6), and peak (non-superheroic) human ability is Excellent (20). However, the designers minimize use of the numerical figures, instead preferring adjectives in the Marvel Comics tradition, such as "Incredible" (scores from 36-45) and "Amazing" (46-62). A "Typical" (5-7) attribute has a 50% base chance for success at most tasks relating to that attribute. For example, a character with "Typical" fighting skill has a base chance of 50% to connect with a punch. As an attribute increases, the chance of success increases by about 5% per 10 points. Thus a character with an "Amazing" (50) attribute has a 75% chance of success at tasks relating to that attribute.

Beyond the seven attributes, characters possessed superpowers, such as Spider-Man's wall crawling, or Mister Fantastic's elasticity. The powers function on a mostly "ad hoc" basis, and thus each character's description gives considerable space to a description of how his or her powers work in the game.

Each character had an origin, which put ceilings on a character's abilities and superpowers. The origins included: Altered Humans (normal people who acquired powers, such as Spider-Man or the Fantastic Four), High-Tech Wonders (normal people whose powers come from devices, e.g., Iron Man), Mutants (persons born with superpowers, such as the X-Men), Robots (created beings such as the Vision and Ultron), and Aliens (a blanket term used to cover non-humans, including extra-dimensional beings such as Thor and Hercules).

The game also features a simple skill system, referred to as Talents. Talents have to be learned and cover a wide range of areas of knowledge from Archery to Zoology. A Talent raises a character's ability by one rank when attempting actions related to that Talent. For example, a character uses his Agility score when attempting ranged attacks. A character with an Agility of Excellent would normally roll on that column when attacking with a rifle. However, if the character has the "Guns" Talent, they would treat their Agility as the next higher power rank (Remarkable). The GM is free to determine if a character would be unable to attempt an action without the appropriate Talent (such as a character with no medical background attempting to make a pill that can cure a rare disease).

Characters also had two variable attributes: Resources and Popularity. These attributes were described using the same terms as the character's seven attributes ("Poor," "Amazing," "Unearthly," etc.). But unlike the seven physical and mental attributes which changed very slowly, if at all, Resources and Popularity could change very quickly.

The first of the variables, Resources, represented the character's wealth and ability to obtain goods or services. Rather than have the player keep track of how much money the character had in the bank or with him, the Advanced Game assumed the character had enough money coming in to cover his basic living expenses. The Resources ability was used when the character wished to purchase something out of the ordinary like a new car or house. For example, the referee might decide a character with Typical resources would probably be unable to purchase a brand new sports car, but with a Yellow Resources roll might be able to afford a used car in good condition. The game books note that a character's Resources score can change for a variety of reasons, such as winning the lottery or having a major business transaction go bad.

The second variable, Popularity, reflected how much the character was liked (or disliked) in the Marvel Universe. Popularity could be used to influence non-player characters. A superhero with a high rating, like Captain America (whose popularity is Unearthly-the highest most characters can achieve), might be able to use his Popularity to gain entrance to a club because the general population of the Marvel Universe admires him. If he were to try the same thing as his secret identity Steve Rogers (whose Popularity is only Typical), he would probably be unable to do it. Villains also had a Popularity score, which was usually negative (a bouncer might let Doctor Doom or Magneto into the aforementioned club simply out of fear). There were several ways Popularity could change. For example, if Doctor Doom defeated Spider-Man in front of the general public, Spidey's Popularity would go down for a short time. But if everyone's favorite web-slinger managed to foil one of Doctor Doom's plans and the word got out, he would enjoy a temporary Popularity boost. Since mutants were generally feared and distrusted in the Marvel Universe, these characters start with a Popularity of 0 and have a hard time improving this attribute.

The game was intended to be played using existing Marvel characters as the heroes. The and "Advanced Set" both contained fairly simple systems for creating original superheroes, based on random ability rolls (as in "Dungeons & Dragons"). In addition, the Basic Set Campaign Book also allowed players to create original heroes by simply describing the desired kind of hero, and working together with the GM to assign the appropriate abilities, powers, and talents.

"The Ultimate Powers Book", by David Edward Martin, expanded and organized the game's list of powers, making a fairly comprehensive survey of comic book-style super-powers. Players were given a wide variety of body types, secret origins, weaknesses, and powers. The "UPB" gave a much greater range to characters one could create. Additionally, the book suffered from editing problems and omissions; several errata and partial revisions were released in the pages of TSR's "Dragon" magazine in issue #122 "The Ultimate Addenda to the Ultimate Powers Book", issue #134 "The Ultimate Addenda's Addenda", issue #150 "Death Effects on Superheroes", and issue #151 "Son of the Ultimate Addenda".

The game's equivalent of experience points was "Karma", a pool of points initially determined as the sum of a character's three mental attributes (Reason, Intuition, and Psyche).

The basic system allowed players to increase their chances of success at most tasks by spending points of Karma. For example, a player who wanted to make sure he would hit a villain in a critical situation could spend however many Karma points were necessary to raise the dice roll to the desired result. Additional Karma points were distributed by the referee at the end of game sessions, typically as rewards for accomplishing heroic goals, such as defeating villains, saving innocents, and foiling crimes. Conversely, Karma could be lost for unheroic actions such as fleeing from a villain, or failing to stop a crime: in fact, in a notable departure from many RPGs (but strongly in keeping with the genre), all Karma was lost if a hero killed someone or allowed someone to die.

In the Advanced Game, Karma points could also be spent to permanently increase character attributes and powers (at a relatively moderate cost, ten times the attribute number raised, powers were steeper, at twenty times the number). The Karma system thus united two RPG mechanics—"Action" or "Hero" points (which allow players to control random outcomes) and character advancement (e.g., "experience points")—in one system. Though this system could frustrate both referees and players (the former because a player willing and able to spend Karma could effectively overcome any challenge at least once; the latter because advancement was slow compared with most other RPGs), it had the virtue of emulating two central features of super-hero comics, namely, that heroes almost always win, even in improbable circumstances, and that heroes' power levels remain mostly static. Furthermore, the system encouraged players to keep their characters' behavior to the equivalent concept of their alignment by giving an incentive to behave heroically and morally correct.

Marvel Superheroes was driven by two primary game mechanics: column shifts and colored results. Both essentially influenced the difficulty of an action.

A column shift is used when a character is attempting an exceptionally hard or easy action. A column shift to the left indicates a penalty, while a shift to the right indicates a bonus. For example, Reed Richards (Mr. Fantastic) has an Intuition of Excellent, making him significantly more perceptive than the average person whose Intuition is Typical (two ranks lower). The GM might determine that spotting a trap hidden beneath a few sticks and leaves will be fairly easy, and give the player running Mr. Fantastic a +1 column shift. His Intuition will be treated as Remarkable (the next column to the right). However, a trap buried underground might be considerably harder to spot, and the GM might give the player a -1 column shift penalty. In this case, Mr. Fantastic's Intuition will only be treated as Good (the column to the left).

The column for each ability is divided into four colors: white, green, yellow, and red. A white result is always a failure or unfavorable outcome. In most cases, getting a green result was all that was needed to succeed at a particular action. Yellow and red results usually indicated more favorable results that could knock back, stun, or even kill an opponent. However, the GM could determine that succeeding at an exceptionally hard task might require a yellow or red result.

Additional rules in the "Campaign Book" of the , and the subsequent Advanced Set, used the same game mechanic to resolve non-violent tasks. For example, if a superhero needs to figure out how to operate a piece of alien technology, the hero would have to succeed at a Reason roll, where the chance of success is modified by the complexity of the device.

The original Marvel Super Heroes game received extensive support from TSR, covering a wide variety of Marvel Comics characters and settings, including a "Gamer's Handbook of the Marvel Universe" patterned after Marvel's "Official Handbook of the Marvel Universe". MSH even received its own column in the (at the time) TSR-published gaming magazine, Dragon, called "The Marvel-phile", which usually spotlighted a character or group of characters that hadn't yet appeared in a published game product.

Steve Kenson commented that "it's a testament to the game's longevity that it still has enthusiastic fan support on the Internet and an active play community more than a decade after its last product was published. Even more so that it continues to set a standard by which new superhero roleplaying games are measured. Like modern comic book writers and artists following the greats of the Silver Age, modern RPG designers have a tough act to follow."

Before losing the MSH license back to Marvel Comics, TSR published a different game using their SAGA System game engine, called the "Marvel Super Heroes Adventure Game". This version, written by Mike Selinker, was published in the late 1990s as a card-based version of the Marvel role-playing game (though a method of converting characters from the prior format to the SAGA System was included in the core rules). Though critically praised in various reviews at the time, it never reached a large market and has since faded into obscurity.

In 2003, after the gaming license had reverted to Marvel Comics, the "Marvel Universe Roleplaying Game" was published by Marvel Comics. This edition uses mechanics that are totally different from any previous versions, using a diceless game mechanic that incorporated a Karma-based resolution system of "stones" (or tokens) to represent character effort. Since its initial publication, a few additional supplements were published by Marvel Comics. However, Marvel stopped supporting the game a little over a year after its initial release, despite going through several printings of the core rulebook.

In August 2011, Margaret Weis Productions acquired the licence to publish an RPG based on Marvel superheroes, and "Marvel Heroic Roleplaying" was released beginning in 2012. Margaret Weis Productions, however, found that although the game was critically acclaimed, winning two Origins Awards, "Marvel Heroic Roleplaying: Civil War" "didn’t garner the level of sales necessary to sustain the rest of the line" so they brought the game to a close at the end of April 2013.


</doc>
<doc id="19873" url="https://en.wikipedia.org/wiki?curid=19873" title="Measure (mathematics)">
Measure (mathematics)

In mathematical analysis, a measure on a set is a systematic way to assign a number to each suitable subset of that set, intuitively interpreted as its size. In this sense, a measure is a generalization of the concepts of length, area, and volume. A particularly important example is the Lebesgue measure on a Euclidean space, which assigns the conventional length, area, and volume of Euclidean geometry to suitable subsets of the -dimensional Euclidean space . For instance, the Lebesgue measure of the interval in the real numbers is its length in the everyday sense of the word – specifically, 1.

Technically, a measure is a function that assigns a non-negative real number or to (certain) subsets of a set ("see" Definition below). It must further be countably additive: the measure of a 'large' subset that can be decomposed into a finite (or countably infinite) number of 'smaller' disjoint subsets, is the sum of the measures of the "smaller" subsets. In general, if one wants to associate a "consistent" size to "each" subset of a given set while satisfying the other axioms of a measure, one only finds trivial examples like the counting measure. This problem was resolved by defining measure only on a sub-collection of all subsets; the so-called "measurable" subsets, which are required to form a -algebra. This means that countable unions, countable intersections and complements of measurable subsets are measurable. Non-measurable sets in a Euclidean space, on which the Lebesgue measure cannot be defined consistently, are necessarily complicated in the sense of being badly mixed up with their complement. Indeed, their existence is a non-trivial consequence of the axiom of choice.

Measure theory was developed in successive stages during the late 19th and early 20th centuries by Émile Borel, Henri Lebesgue, Johann Radon, and Maurice Fréchet, among others. The main applications of measures are in the foundations of the Lebesgue integral, in Andrey Kolmogorov's axiomatisation of probability theory and in ergodic theory. In integration theory, specifying a measure allows one to define integrals on spaces more general than subsets of Euclidean space; moreover, the integral with respect to the Lebesgue measure on Euclidean spaces is more general and has a richer theory than its predecessor, the Riemann integral. Probability theory considers measures that assign to the whole set the size 1, and considers measurable subsets to be events whose probability is given by the measure. Ergodic theory considers measures that are invariant under, or arise naturally from, a dynamical system.

Let be a set and a -algebra over . A function from to the extended real number line is called a measure if it satisfies the following properties:


One may require that at least one set has finite measure. Then the empty set automatically has measure zero because of countable additivity, because
which implies (since the sum on the right thus converges to a finite value) that formula_1.

If only the second and third conditions of the definition of measure above are met, and takes on at most one of the values , then is called a signed measure.

The pair is called a measurable space, the members of Σ are called measurable sets. If formula_6 and formula_7 are two measurable spaces, then a function formula_8 is called measurable if for every -measurable set formula_9, the inverse image is -measurable – i.e.: formula_10. In this setup, the composition of measurable functions is measurable, making the measurable spaces and measurable functions a category, with the measurable spaces as objects and the set of measurable functions as arrows. See also Measurable function#Term usage variations about another setup.

A triple is called a measure space. A probability measure is a measure with total measure one – i.e. . A probability space is a measure space with a probability measure.

For measure spaces that are also topological spaces various compatibility conditions can be placed for the measure and the topology. Most measures met in practice in analysis (and in many cases also in probability theory) are Radon measures. Radon measures have an alternative definition in terms of linear functionals on the locally convex space of continuous functions with compact support. This approach is taken by Bourbaki (2004) and a number of other sources. For more details, see the article on Radon measures.

Some important measures are listed here.


Other 'named' measures used in various theories include: Borel measure, Jordan measure, ergodic measure, Euler measure, Gaussian measure, Baire measure, Radon measure, Young measure, and Loeb measure.
In physics an example of a measure is spatial distribution of mass (see e.g., gravity potential), or another non-negative extensive property, conserved (see conservation law for a list of these) or not. Negative values lead to signed measures, see "generalizations" below.


Let be a measure.

If and are measurable sets with then

For any countable sequence of (not necessarily disjoint) measurable sets in Σ:

If are measurable sets and is a subset of for all , then the union of the sets is measurable, and

If are measurable sets and for all , then the intersection of the sets is measurable; furthermore, if at least one of the has finite measure, then

This property is false without the assumption that at least one of the has finite measure. For instance, for each , let , which all have infinite Lebesgue measure, but the intersection is empty.

A measure space is called finite if is a finite real number (rather than ∞). Nonzero finite measures are analogous to probability measures in the sense that any finite measure is proportional to the probability measure formula_15. A measure is called "σ-finite" if can be decomposed into a countable union of measurable sets of finite measure. Analogously, a set in a measure space is said to have a "σ-finite measure" if it is a countable union of sets with finite measure.

For example, the real numbers with the standard Lebesgue measure are σ-finite but not finite. Consider the closed intervals for all integers ; there are countably many such intervals, each has measure 1, and their union is the entire real line. Alternatively, consider the real numbers with the counting measure, which assigns to each finite set of reals the number of points in the set. This measure space is not σ-finite, because every set with finite measure contains only finitely many points, and it would take uncountably many such sets to cover the entire real line. The σ-finite measure spaces have some very convenient properties; σ-finiteness can be compared in this respect to the Lindelöf property of topological spaces. They can be also thought of as a vague generalization of the idea that a measure space may have 'uncountable measure'.
A measure is said to be s-finite if it is a countable sum of bounded measures. S-finite measures are more general than sigma-finite ones and have applications in the theory of stochastic processes.

A measurable set is called a "null set" if . A subset of a null set is called a "negligible set". A negligible set need not be measurable, but every measurable negligible set is automatically a null set. A measure is called "complete" if every negligible set is measurable.

A measure can be extended to a complete one by considering the σ-algebra of subsets which differ by a negligible set from a measurable set , that is, such that the symmetric difference of and is contained in a null set. One defines to equal .

Measures are required to be countably additive. However, the condition can be strengthened as follows.
For any set formula_16 and any set of nonnegative formula_17 define:
That is, we define the sum of the formula_19 to be the supremum of all the sums of finitely many of them.

A measure formula_20 on formula_21 is formula_22-additive if for any formula_23 and any family of disjoint sets formula_24 the following hold:
Note that the second condition is equivalent to the statement that the ideal of null sets is formula_22-complete.

If the axiom of choice is assumed to be true, it can be proved that not all subsets of Euclidean space are Lebesgue measurable; examples of such sets include the Vitali set, and the non-measurable sets postulated by the Hausdorff paradox and the Banach–Tarski paradox.

For certain purposes, it is useful to have a "measure" whose values are not restricted to the non-negative reals or infinity. For instance, a countably additive set function with values in the (signed) real numbers is called a "signed measure", while such a function with values in the complex numbers is called a "complex measure". Measures that take values in Banach spaces have been studied extensively. A measure that takes values in the set of self-adjoint projections on a Hilbert space is called a "projection-valued measure"; these are used in functional analysis for the spectral theorem. When it is necessary to distinguish the usual measures which take non-negative values from generalizations, the term positive measure is used. Positive measures are closed under conical combination but not general linear combination, while signed measures are the linear closure of positive measures.

Another generalization is the "finitely additive measure", which are sometimes called contents. This is the same as a measure except that instead of requiring "countable" additivity we require only "finite" additivity. Historically, this definition was used first. It turns out that in general, finitely additive measures are connected with notions such as Banach limits, the dual of "L" and the Stone–Čech compactification. All these are linked in one way or another to the axiom of choice.

A charge is a generalization in both directions: it is a finitely additive, signed measure.




</doc>
<doc id="19876" url="https://en.wikipedia.org/wiki?curid=19876" title="Motorcycle">
Motorcycle

A motorcycle, often called a bike, motorbike, or cycle, is a two- or three-wheeled motor vehicle. Motorcycle design varies greatly to suit a range of different purposes: long distance travel, commuting, cruising, sport including racing, and off-road riding. Motorcycling is riding a motorcycle and related social activity such as joining a motorcycle club and attending motorcycle rallies.

In 1894, Hildebrand & Wolfmüller became the first series production motorcycle, and the first to be called a motorcycle. In 2014, the three top motorcycle producers globally by volume were Honda, Yamaha (both from Japan), and Hero MotoCorp (India).

In developing countries, motorcycles are considered utilitarian due to lower prices and greater fuel economy. Of all the motorcycles in the world, 58% are in the Asia-Pacific and Southern and Eastern Asia regions, excluding car-centric Japan.

According to the US Department of Transportation the number of fatalities per vehicle mile traveled was 37 times higher for motorcycles than for cars.

The term motorcycle has different legal definitions depending on jurisdiction (see #Legal definitions and restrictions).

There are three major types of motorcycle: street, off-road, and dual purpose. Within these types, there are many sub-types of motorcycles for different purposes. There is often a racing counterpart to each type, such as road racing and street bikes, or motocross and dirt bikes.

Street bikes include cruisers, sportbikes, scooters and mopeds, and many other types. Off-road motorcycles include many types designed for dirt-oriented racing classes such as motocross and are not street legal in most areas. Dual purpose machines like the dual-sport style are made to go off-road but include features to make them legal and comfortable on the street as well.

Each configuration offers either specialised advantage or broad capability, and each design creates a different riding posture.

In some countries the use of pillions (rear seats) is restricted.

The first internal combustion, petroleum fueled motorcycle was the Daimler "Reitwagen". It was designed and built by the German inventors Gottlieb Daimler and Wilhelm Maybach in Bad Cannstatt, Germany in 1885. This vehicle was unlike either the safety bicycles or the boneshaker bicycles of the era in that it had zero degrees of steering axis angle and no fork offset, and thus did not use the principles of bicycle and motorcycle dynamics developed nearly 70 years earlier. Instead, it relied on two outrigger wheels to remain upright while turning.

The inventors called their invention the "Reitwagen" ("riding car"). It was designed as an expedient testbed for their new engine, rather than a true prototype vehicle.
The first commercial design for a self-propelled cycle was a three-wheel design called the Butler Petrol Cycle, conceived of Edward Butler in England in 1884. He exhibited his plans for the vehicle at the Stanley Cycle Show in London in 1884. The vehicle was built by the Merryweather Fire Engine company in Greenwich, in 1888.

The Butler Petrol Cycle was a three-wheeled vehicle, with the rear wheel directly driven by a , displacement, bore × stroke, flat twin four-stroke engine (with magneto ignition replaced by coil and battery) equipped with rotary valves and a float-fed carburettor (five years before Maybach) and Ackermann steering, all of which were state of the art at the time. Starting was by compressed air. The engine was liquid-cooled, with a radiator over the rear driving wheel. Speed was controlled by means of a throttle valve lever. No braking system was fitted; the vehicle was stopped by raising and lowering the rear driving wheel using a foot-operated lever; the weight of the machine was then borne by two small castor wheels. The driver was seated between the front wheels. It wasn't, however, a success, as Butler failed to find sufficient financial backing.

Many authorities have excluded steam powered, electric motorcycles or diesel-powered two-wheelers from the definition of a 'motorcycle', and credit the Daimler "Reitwagen" as the world's first motorcycle. Given the rapid rise in use of electric motorcycles worldwide, defining only internal-combustion powered two-wheelers as 'motorcycles' is increasingly problematic.

If a two-wheeled vehicle with steam propulsion is considered a motorcycle, then the first motorcycles built seem to be the French Michaux-Perreaux steam velocipede which patent application was filled in December 1868, constructed around the same time as the American Roper steam velocipede, built by Sylvester H. Roper Roxbury, Massachusetts.
who demonstrated his machine at fairs and circuses in the eastern U.S. in 1867, Roper built about 10 steam cars and cycles from the 1860s until his death in 1896.

In 1894, Hildebrand & Wolfmüller became the first series production motorcycle, and the first to be called a motorcycle (). Excelsior Motor Company, originally a bicycle manufacturing company based in Coventry, England, began production of their first motorcycle model in 1896. The first production motorcycle in the US was the Orient-Aster, built by Charles Metz in 1898 at his factory in Waltham, Massachusetts.

In the early period of motorcycle history, many producers of bicycles adapted their designs to accommodate the new internal combustion engine. As the engines became more powerful and designs outgrew the bicycle origins, the number of motorcycle producers increased. Many of the nineteenth century inventors who worked on early motorcycles often moved on to other inventions. Daimler and Roper, for example, both went on to develop automobiles.

At the turn of the 19th century the first major mass-production firms were set up. In 1898, Triumph Motorcycles in England began producing motorbikes, and by 1903 it was producing over 500 bikes. Other British firms were Royal Enfield, Norton and Birmingham Small Arms Company who began motorbike production in 1899, 1902 and 1910, respectively. Indian began production in 1901 and Harley-Davidson was established two years later. By the outbreak of World War I, the largest motorcycle manufacturer in the world was Indian,
producing over 20,000 bikes per year.

During the First World War, motorbike production was greatly ramped up for the war effort to supply effective communications with front line troops. Messengers on horses were replaced with despatch riders on motorcycles carrying messages, performing reconnaissance and acting as a military police. American company Harley-Davidson was devoting over 50% of its factory output toward military contract by the end of the war. The British company Triumph Motorcycles sold more than 30,000 of its Triumph Type H model to allied forces during the war. With the rear wheel driven by a belt, the Model H was fitted with a air-cooled four-stroke single-cylinder engine. It was also the first Triumph without pedals.

The Model H in particular, is regarded by many as having been the first "modern motorcycle". Introduced in 1915 it had a 550 cc side-valve four-stroke engine with a three-speed gearbox and belt transmission. It was so popular with its users that it was nicknamed the "Trusty Triumph."

By 1920, Harley-Davidson was the largest manufacturer, with their motorcycles being sold by dealers in 67 countries.
By the late 1920s or early 1930s, DKW in Germany took over as the largest manufacturer.

In the 1950s, streamlining began to play an increasing part in the development of racing motorcycles and the "dustbin fairing" held out the possibility of radical changes to motorcycle design. NSU and Moto Guzzi were in the vanguard of this development, both producing very radical designs well ahead of their time.
NSU produced the most advanced design, but after the deaths of four NSU riders in the 1954–1956 seasons, they abandoned further development and quit Grand Prix motorcycle racing.

Moto Guzzi produced competitive race machines, and by 1957 nearly all the Grand Prix races were being won by streamlined machines. The following year, 1958, full enclosure fairings were banned from racing by the FIM in the light of the safety concerns.

From the 1960s through the 1990s, small two-stroke motorcycles were popular worldwide, partly as a result of East German MZs Walter Kaaden's engine work in the 1950s. 

In the 21st century, the motorcycle industry is mainly dominated by the Chinese motorcycle industry and by Japanese motorcycle companies. In addition to the large capacity motorcycles, there is a large market in smaller capacity (less than 300 cc) motorcycles, mostly concentrated in Asian and African countries and produced in China and India. A Japanese example is the 1958 Honda Super Cub, which went on to become the biggest selling vehicle of all time, with its 60 millionth unit produced in April 2008.
Today, this area is dominated by mostly with Hero MotoCorp emerging as the world's largest manufacturer of two wheelers. Its Splendor model has sold more than 8.5 million to date. Other major producers are Bajaj and TVS Motors.

Motorcycle construction is the engineering, manufacturing, and assembly of components and systems for a motorcycle which results in the performance, cost, and aesthetics desired by the designer. With some exceptions, construction of modern mass-produced motorcycles has standardised on a steel or aluminium frame, telescopic forks holding the front wheel, and disc brakes. Some other body parts, designed for either aesthetic or performance reasons may be added. A petrol powered engine typically consisting of between one and four cylinders (and less commonly, up to eight cylinders) coupled to a manual five- or six-speed sequential transmission drives the swingarm-mounted rear wheel by a chain, driveshaft, or belt.

Motorcycle fuel economy varies greatly with engine displacement and riding style. A streamlined, fully faired Matzu Matsuzawa Honda XL125 achieved in the Craig Vetter Fuel Economy Challenge "on real highways in real conditions."
Due to low engine displacements (), and high power-to-mass ratios, motorcycles offer good fuel economy. Under conditions of fuel scarcity like 1950s Britain and modern developing nations, motorcycles claim large shares of the vehicle market.

Very high fuel economy equivalents are often derived by electric motorcycles. Electric motorcycles are nearly silent, zero-emission electric motor-driven vehicles. Operating range and top speed are limited by battery technology. Fuel cells and petroleum-electric hybrids are also under development to extend the range and improve performance of the electric drive system.

A 2013 survey of 4,424 readers of the US "Consumer Reports" magazine collected reliability data on 4,680 motorcycles purchased new from 2009 to 2012. The most common problem areas were accessories, brakes, electrical (including starters, charging, ignition), and fuel systems, and the types of motorcycles with the greatest problems were touring, off-road/dual sport, sport-touring, and cruisers. There were not enough sport bikes in the survey for a statistically significant conclusion, though the data hinted at reliability as good as cruisers. These results may be partially explained by accessories including such equipment as fairings, luggage, and auxiliary lighting, which are frequently added to touring, adventure touring/dual sport and sport touring bikes. Trouble with fuel systems is often the result of improper winter storage, and brake problems may also be due to poor maintenance. Of the five brands with enough data to draw conclusions, Honda, Kawasaki and Yamaha were statistically tied, with 11 to 14% of those bikes in the survey experiencing major repairs. Harley-Davidsons had a rate of 24%, while BMWs did worst, with 30% of those needing major repairs. There were not enough Triumph and Suzuki motorcycles surveyed for a statistically sound conclusion, though it appeared Suzukis were as reliable as the other three Japanese brands while Triumphs were comparable to Harley-Davidson and BMW. Three fourths of the repairs in the survey cost less than US$200 and two thirds of the motorcycles were repaired in less than two days. In spite of their relatively worse reliability in this survey, Harley-Davidson and BMW owners showed the greatest owner satisfaction, and three fourths of them said they would buy the same bike again, followed by 72% of Honda owners and 60 to 63% of Kawasaki and Yamaha owners.

Different types of motorcycles have different dynamics and these play a role in how a motorcycle performs in given conditions. For example, one with a longer wheelbase provides the feeling of more stability by responding less to disturbances. Motorcycle tyres have a large influence over handling.

Motorcycles must be leaned in order to make turns. This lean is induced by the method known as countersteering, in which the rider momentarily steers the handlebars in the direction opposite of the desired turn. This practice is counterintuitive and therefore often confusing to novices and even many experienced motorcyclists.

With such short wheelbase, motorcycles can generate enough torque at the rear wheel, and enough stopping force at the front wheel, to lift the opposite wheel off the road. These actions, if performed on purpose, are known as wheelies and stoppies (or endos) respectively.

Various features and accessories may be attached to a motorcycle either as OEM (factory-fitted) or aftermarket. Such accessories are selected by the owner to enhance the motorcycle's appearance, safety, performance, or comfort, and may include anything from mobile electronics to sidecars and trailers.

Motorcycles have a higher rate of fatal accidents than automobiles or trucks and buses. United States Department of Transportation data for 2005 from the Fatality Analysis Reporting System show that for passenger cars, 18.62 fatal crashes occur per 100,000 registered vehicles. For motorcycles this figure is higher at 75.19 per 100,000 registered vehicles four times higher than for cars.
The same data shows that 1.56 fatalities occur per 100 million vehicle miles travelled for passenger cars, whereas for motorcycles the figure is 43.47 which is 28 times higher than for cars (37 times more deaths per mile travelled in 2007).
Furthermore, for motorcycles the accident rates have increased significantly since the end of the 1990s, while the rates have dropped for passenger cars.

The most common configuration of motorcycle accidents in the United States is when a motorist pulls out or turns in front of a motorcyclist, violating their right-of-way. This is sometimes called a , an acronym formed from the motorists' common response of "Sorry mate, I didn't see you".
Motorcyclists can anticipate and avoid some of these crashes with proper training, increasing their visibility to other traffic, keeping to the speed limits, and not consuming alcohol or other drugs before riding.
The United Kingdom has several organisations dedicated to improving motorcycle safety by providing advanced rider training beyond what is necessary to pass the basic motorcycle licence test. These include the Institute of Advanced Motorists (IAM) and the Royal Society for the Prevention of Accidents (RoSPA). Along with increased personal safety, riders with these advanced qualifications may benefit from reduced insurance costs 

In South Africa, the Think Bike campaign is dedicated to increasing both motorcycle safety and the awareness of motorcycles on the country's roads. The campaign, while strongest in the Gauteng province, has representation in Western Cape, KwaZulu Natal and the Free State. It has dozens of trained marshals available for various events such as cycle races and is deeply involved in numerous other projects such as the annual Motorcycle Toy Run.
Motorcycle safety education is offered throughout the United States by organisations ranging from state agencies to non-profit organisations to corporations. Most states use the courses designed by the Motorcycle Safety Foundation (MSF), while Oregon and Idaho developed their own. All of the training programs include a Basic Rider Course, an Intermediate Rider Course and an Advanced Rider Course.

In Ireland, since 2010, in the UK and some Australian jurisdictions, such as Victoria, New South Wales,
the Australian Capital Territory, Tasmania
and the Northern Territory, it is compulsory to complete a basic rider training course before being issued a Learners Licence, after which they can ride on public roads.

In Canada, motorcycle rider training is compulsory in Quebec and Manitoba only, but all provinces and territories have graduated licence programs which place restrictions on new drivers until they have gained experience. Eligibility for a full motorcycle licence or endorsement for completing a Motorcycle Safety course varies by province. The Canada Safety Council, a non-profit safety organisation, offers the Gearing Up program across Canada and is endorsed by the Motorcycle and Moped Industry Council. Training course graduates may qualify for reduced insurance premiums.

The motorcyclist's riding position depends on rider body-geometry (anthropometry) combined with the geometry of the motorcycle itself. These factors create a set of three basic postures.


Factors of a motorcycle's ergonomic geometry that determine the seating posture include the height, angle and location of footpegs, seat and handlebars. Factors in a rider's physical geometry that contribute to seating posture include torso, arm, thigh and leg length, and overall rider height.

A motorcycle is broadly defined by law in most countries for the purposes of registration, taxation and rider licensing as a powered two-wheel motor vehicle. Most countries distinguish between mopeds of 49 cc and the more powerful, larger vehicles (scooters do not count as a separate category). Many jurisdictions include some forms of three-wheeled cars as motorcycles.

Motorcycles and scooters' low fuel consumption has attracted interest in the United States from environmentalists and those affected by increased fuel prices.
Piaggio Group Americas supported this interest with the launch of a "Vespanomics" website and platform, claiming lower per-mile carbon emissions of 0.4 lb/mile (113 g/km) less than the average car, a 65% reduction, and better fuel economy.

However, a motorcycle's exhaust emissions may contain 10–20 times more oxides of nitrogen (NOx), carbon monoxide, and unburned hydrocarbons than exhaust from a similar-year passenger car or SUV.
This is because many motorcycles lack a catalytic converter, and the emission standard is much more permissive for motorcycles than for other vehicles. While catalytic converters have been installed in most gasoline-powered cars and trucks since 1975 in the United States, they can present fitment and heat difficulties in motorcycle applications. 

United States Environmental Protection Agency 2007 certification result reports for all vehicles versus on highway motorcycles (which also includes scooters), the average certified emissions level for 12,327 vehicles tested was 0.734. The average "Nox+Co End-Of-Useful-Life-Emissions" for 3,863 motorcycles tested was 0.8531. 54% of the tested 2007-model motorcycles were equipped with a catalytic converter.

The following table shows maximum acceptable legal emissions of the combination of hydrocarbons, oxides of nitrogen, and carbon monoxide for new motorcycles sold in the United States with 280 cc or greater piston displacement.

The maximum acceptable legal emissions of hydrocarbon and carbon monoxide for new Class I and II motorcycles (50 cc–169 cc and 170 cc–279 cc respectively) sold in the United States are as follows:
European emission standards for motorcycles are similar to those for cars. New motorcycles must meet Euro III standards,
while cars must meet Euro V standards. Motorcycle emission controls are being updated and it has been proposed to update to Euro IV in 2012 and Euro V in 2015.


</doc>
<doc id="19877" url="https://en.wikipedia.org/wiki?curid=19877" title="Map">
Map

A map is a symbolic depiction emphasizing relationships between elements of some space, such as objects, regions, or themes.

Many maps are static, fixed to paper or some other durable medium, while others are dynamic or interactive. Although most commonly used to depict geography, maps may represent any space, real or imagined, without regard to context or scale, such as in brain mapping, DNA mapping, or computer network topology mapping. The space being mapped may be two dimensional, such as the surface of the earth, three dimensional, such as the interior of the earth, or even more abstract spaces of any dimension, such as arise in modeling phenomena having many independent variables.

Although the earliest maps known are of the heavens, geographic maps of territory have a very long tradition and exist from ancient times. The word "map" comes from the medieval Latin "Mappa mundi", wherein "mappa" meant napkin or cloth and "mundi" the world. Thus, "map" became the shortened term referring to a two-dimensional representation of the surface of the world.

Cartography or "map-making" is the study and practice of crafting representations of the Earth upon a flat surface (see History of cartography), and one who makes maps is called a cartographer.

Road maps are perhaps the most widely used maps today, and form a subset of navigational maps, which also include aeronautical and nautical charts, railroad network maps, and hiking and bicycling maps. In terms of quantity, the largest number of drawn map sheets is probably made up by local surveys, carried out by municipalities, utilities, tax assessors, emergency services providers, and other local agencies. Many national surveying projects have been carried out by the military, such as the British Ordnance Survey: a civilian government agency, internationally renowned for its comprehensively detailed work.

In addition to location information maps may also be used to portray contour lines indicating constant values of elevation, temperature, rainfall, etc.

The orientation of a map is the relationship between the directions on the map and the corresponding compass directions in reality. The word "orient" is derived from Latin "oriens", meaning east. In the Middle Ages many maps, including the T and O maps, were drawn with east at the top (meaning that the direction "up" on the map corresponds to East on the compass). The most common cartographic convention is that north is at the top of a map.

Maps not oriented with north at the top:

Many maps are drawn to a scale expressed as a ratio, such as 1:10,000, which means that 1 unit of measurement on the map corresponds to 10,000 of that same unit on the ground. The scale statement can be accurate when the region mapped is small enough for the curvature of the Earth to be neglected, such as a city map. Mapping larger regions, where curvature cannot be ignored, requires projections to map from the curved surface of the Earth to the plane. The impossibility of flattening the sphere to the plane without distortion means that the map cannot have constant scale. Rather, on most projections the best that can be attained is accurate scale along one or two paths on the projection. Because scale differs everywhere, it can only be measured meaningfully as point scale per location. Most maps strive to keep point scale variation within narrow bounds. Although the scale statement is nominal it is usually accurate enough for most purposes unless the map covers a large fraction of the earth. At the scope of a world map, scale as a single number is practically meaningless throughout most of the map. Instead, it usually refers to the scale along the equator.

Large scale maps, (e.g. 1:10,000), cover relatively small regions in great detail and small scale maps, (e.g. 1:10,000,000), cover large regions such as nations, continents and the whole globe. The large/small terminology arose from the practice of writing scales as numerical fractions: 1/10,000 is larger than 1/10,000,000. There is no exact dividing line between large and small but 1/100,000 might well be considered as a medium scale. Examples of large scale maps are the 1:25,000 maps produced for hikers; on the other hand maps intended for motorists at 1:250,000 or 1:1,000,000 are small scale.

It is important to recognize that even the most accurate maps sacrifice a certain amount of accuracy in scale to deliver a greater visual usefulness to its user. For example, the width of roads and small streams are exaggerated when they are too narrow to be shown on the map at true scale; that is, on a printed map they would be narrower than could be perceived by the naked eye. The same applies to computer maps where the smallest unit is the pixel. A narrow stream say must be shown to have the width of a pixel even if at the map scale it would be a small fraction of the pixel width.
Some maps, called cartograms, have the scale deliberately distorted to reflect information other than land area or distance. For example, this map (at the right) of Europe has been distorted to show population distribution, while the rough shape of the continent is still discernible.

Another example of distorted scale is the famous London Underground map. The basic geographical structure is respected but the tube lines (and the River Thames) are smoothed to clarify the relationships between stations. Near the center of the map stations are spaced out more than near the edges of map.

Further inaccuracies may be deliberate. For example, cartographers may simply omit military installations or remove features solely in order to enhance the clarity of the map. For example, a road map may not show railroads, smaller waterways or other prominent non-road objects, and even if it does, it may show them less clearly (e.g. dashed or dotted lines/outlines) than the main roads. Known as decluttering, the practice makes the subject matter that the user is interested in easier to read, usually without sacrificing overall accuracy. Software-based maps often allow the user to toggle decluttering between ON, OFF and AUTO as needed. In AUTO the degree of decluttering is adjusted as the user changes the scale being displayed.

Maps of the world or large areas are often either 'political' or 'physical'. The most important purpose of the political map is to show territorial borders; the purpose of the physical is to show features of geography such as mountains, soil type or land use including infrastructure such as roads, railroads and buildings. Topographic maps show elevations and relief with contour lines or shading. Geological maps show not only the physical surface, but characteristics of the underlying rock, fault lines, and subsurface structures.
Maps that depict the surface of the Earth also use a projection, a way of translating the three-dimensional real surface of the geoid to a two-dimensional picture. Perhaps the best-known world-map projection is the Mercator projection, originally designed as a form of nautical chart.
Aeroplane pilots use aeronautical charts based on a Lambert conformal conic projection, in which a cone is laid over the section of the earth to be mapped. The cone intersects the sphere (the earth) at one or two parallels which are chosen as standard lines. This allows the pilots to plot a great-circle route approximation on a flat, two-dimensional chart.

From the last quarter of the 20th century, the indispensable tool of the cartographer has been the computer. Much of cartography, especially at the data-gathering survey level, has been subsumed by Geographic Information Systems (GIS). The functionality of maps has been greatly advanced by technology simplifying the superimposition of spatially located variables onto existing geographical maps. Having local information such as rainfall level, distribution of wildlife, or demographic data integrated within the map allows more efficient analysis and better decision making. In the pre-electronic age such superimposition of data led Dr. John Snow to identify the location of an outbreak of cholera. Today, it is used by agencies of the human kind, as diverse as wildlife conservationists and militaries around the world.

Even when GIS is not involved, most cartographers now use a variety of computer graphics programs to generate new maps.

Interactive, computerised maps are commercially available, allowing users to "zoom in" or "zoom out" (respectively meaning to increase or decrease the scale), sometimes by replacing one map with another of different scale, centered where possible on the same point. In-car global navigation satellite systems are computerised maps with route-planning and advice facilities which monitor the user's position with the help of satellites. From the computer scientist's point of view, zooming in entails one or a combination of:


For example:

"See also: Webpage (Graphics), PDF (Layers), MapQuest, Google Maps, Google Earth, OpenStreetMap or Yahoo! Maps."

The maps that reflect the territorial distribution of climatic conditions based on the results of long-term observations are climatic maps. Climatic maps can be compiled both for individual climatic features (temperature, precipitation, humidity) and for combinations of them at the earth’s surface and in the upper layers of the atmosphere. Climatic maps afford a very convenient overview of the climatic features in a large region and permit values of climatic features to be compared in different parts of the region. Through interpolation the maps can be used to determine the values of climatic features in any particular spot.

Climatic maps generally apply to individual months and to the year as a whole, sometimes to the four seasons, to the growing period, and so forth. On maps compiled from the observations of ground meteorological stations, atmospheric pressure is converted to sea level. Air temperature maps are compiled both from the actual values observed on the surface of the earth and from values converted to sea level. The pressure field in free atmosphere is represented either by maps of the distribution of pressure at different standard altitudes—for example, at every kilometer above sea level—or by maps of baric topography on which altitudes (more precisely geopotentials) of the main isobaric surfaces (for example, 900, 800, and 700 millibars) counted off from sea level are plotted. The temperature, humidity, and wind on aeroclimatic maps may apply either to standard altitudes or to the main isobaric surfaces.

Isolines are drawn on maps of such climatic features as the long-term mean values (of atmospheric pressure, temperature, humidity, total precipitation, and so forth) to connect points with equal values of the feature in question—for example, isobars for pressure, isotherms for temperature, and isohyets for precipitation. Isoamplitudes are drawn on maps of amplitudes (for example, annual amplitudes of air temperature—that is, the differences between the mean temperatures of the warmest and coldest month). Isanomals are drawn on maps of anomalies (for example, deviations of the mean temperature of each place from the mean temperature of the entire latitudinal zone). Isolines of frequency are drawn on maps showing the frequency of a particular phenomenon (for example, annual number of days with a thunderstorm or snow cover). Isochrones are drawn on maps showing the dates of onset of a given phenomenon (for example, the first frost and appearance or disappearance of the snow cover) or the date of a particular value of a meteorological element in the course of a year (for example, passing of the mean daily air temperature through zero). Isolines of the mean numerical value of wind velocity or isotachs are drawn on wind maps (charts); the wind resultants and directions of prevailing winds are indicated by arrows of different length or arrows with different plumes; lines of flow are often drawn. Maps of the zonal and meridional components of wind are frequently compiled for the free atmosphere. Atmospheric pressure and wind are usually combined on climatic maps. Wind roses, curves showing the distribution of other meteorological elements, diagrams of the annual course of elements at individual stations, and the like are also plotted on climatic maps.

Maps of climatic regionalization, that is, division of the earth’s surface into climatic zones and regions according to some classification of climates, are a special kind of climatic map.

Climatic maps are often incorporated into climatic atlases of varying geographic range (globe, hemispheres, continents, countries, oceans) or included in comprehensive atlases. Besides general climatic maps, applied climatic maps and atlases have great practical value. Aeroclimatic maps, aeroclimatic atlases, and agroclimatic maps are the most numerous.

The various features shown on a map are represented by conventional signs or symbols. For example, colors can be used to indicate a classification of roads. Those signs are usually explained in the margin of the map, or on a separately published characteristic sheet.

Some cartographers prefer to make the map cover practically the entire screen or sheet of paper, leaving no room "outside" the map for information about the map as a whole.
These cartographers typically place such information in an otherwise "blank" region "inside" the mapcartouche, map legend, title, compass rose, bar scale, etc.
In particular, some maps contain smaller "sub-maps" in otherwise blank regions—often one at a much smaller scale showing the whole globe and where the whole map fits on that globe, and a few showing "regions of interest" at a larger scale in order to show details that wouldn't otherwise fit.
Occasionally sub-maps use the same scale as the large map—a few maps of the contiguous United States include a sub-map to the same scale for each of the two non-contiguous states.

To communicate spatial information effectively, features such as rivers, lakes, and cities need to be labeled. Over centuries cartographers have developed the art of placing names on even the densest of maps. Text placement or name placement can get mathematically very complex as the number of labels and map density increases. Therefore, text placement is time-consuming and labor-intensive, so cartographers and GIS users have developed automatic label placement to ease this process.

Maps exist of the Solar System, and other cosmological features such as star maps. In addition maps of other bodies such as the Moon and other planets are technically not "geo"graphical maps.

Diagrams such as schematic diagrams and Gantt charts and treemaps display logical relationships between items, rather than geographical relationships. Topological in nature, only the connectivity is significant. The London Underground map and similar subway maps around the world are a common example of these maps.

General-purpose maps provide many types of information on one map. Most atlas maps, wall maps, and road maps fall into this category. The following are some features that might be shown on general-purpose maps: bodies of water, roads, railway lines, parks, elevations, towns and cities, political boundaries, latitude and longitude, national and provincial parks. These maps give a broad understanding of location and features of an area. The reader may gain an understanding of the type of landscape, the location of urban places, and the location of major transportation routes all at once.


Some countries required that all published maps represent their national claims regarding border disputes. For example:

In 2010, the People's Republic of China began requiring that all online maps served from within China be hosted there, making them subject to Chinese laws.










</doc>
<doc id="19881" url="https://en.wikipedia.org/wiki?curid=19881" title="Management">
Management

Management (or managing) is the administration of an organization, whether it is a business, a not-for-profit organization, or government body. Management includes the activities of setting the strategy of an organization and coordinating the efforts of its employees (or of volunteers) to accomplish its objectives through the application of available resources, such as financial, natural, technological, and human resources. The term "management" may also refer to those people who manage an organization.

Social scientists study management as an academic discipline, investigating areas such as social organization and organizational leadership. Some people study management at colleges or universities; major degrees in management include the Bachelor of Commerce (B.Com.) and Master of Business Administration (MBA.) and, for the public sector, the Master of Public Administration (MPA) degree. Individuals who aim to become management specialists or experts, management researchers, or professors may complete the Doctor of Management (DM), the Doctor of Business Administration (DBA), or the PhD in Business Administration or Management.

Larger organizations generally have three levels of managers, which are typically organized in a hierarchical, pyramid structure:


In smaller organizations, an individual manager may have a much wider scope. A single manager may perform several roles or even all of the roles commonly observed in a large organization.

Views on the definition and scope of management include:

Management involves identifying the mission, objective, procedures, rules and manipulation
of the human capital of an enterprise to contribute to the success of the enterprise. This implies effective communication: an enterprise environment (as opposed to a physical or mechanical mechanism) implies human motivation and implies some sort of successful progress or system outcome. As such, management is not the manipulation of a mechanism (machine or automated program), not the herding of animals, and can occur either in a legal or in an illegal enterprise or environment. From an individual's perspective, management does not need to be seen solely from an enterprise point of view, because management is an essential function to improve one's life and relationships. Management is therefore everywhere and it has a wider range of application. Based on this, management must have humans. Communication and a positive endeavor are two main aspects of it either through enterprise or independent pursuit. Plans, measurements, motivational psychological tools, goals, and economic measures (profit, etc.) may or may not be necessary components for there to be management. At first, one views management functionally, such as measuring quantity, adjusting plans, meeting goals. This applies even in situations where planning does not take place. From this perspective, Henri Fayol (1841–1925)
considers management to consist of six functions:


In another way of thinking, Mary Parker Follett (1868–1933), allegedly defined management as "the art of getting things done through people".
She described management as philosophy.

Critics, however, find this definition useful but far too narrow. The phrase "management is what managers do" occurs widely,
suggesting the difficulty of defining management without circularity, the shifting nature of definitions and the connection of managerial practices with the existence of a managerial cadre or of a class.

One habit of thought regards management as equivalent to "business administration" and thus excludes management in places outside commerce, as for example in charities and in the public sector. More broadly, every organization must "manage" its work, people, processes, technology, etc. to maximize effectiveness. Nonetheless, many people refer to university departments that teach management as "business schools". Some such institutions (such as the Harvard Business School) use that name, while others (such as the Yale School of Management) employ the broader term "management".

English-speakers may also use the term "management" or "the management" as a collective word describing the managers of an organization, for example of a corporation.
Historically this use of the term often contrasted with the term "labor" – referring to those being managed.

But in the present era the concept of management is identified in the wide areas and its frontiers have been pushed to a broader range. Apart from profitable organizations even non-profitable organizations (NGOs) apply management concepts. The concept and its uses are not constrained. Management on the whole is the process of planning, organizing, coordinating, leading and controlling.

In profitable organizations, management's primary function is the satisfaction of a range of stakeholders. This typically involves making a profit (for the shareholders), creating valued products at a reasonable cost (for customers), and providing great employment opportunities for employees. In nonprofit management, add the importance of keeping the faith of donors. In most models of management and governance, shareholders vote for the board of directors, and the board then hires senior management. Some organizations have experimented with other methods (such as employee-voting models) of selecting or reviewing managers, but this is rare.

Some see management (by definition) as a late-modern (in the sense of late modernity) conceptualization. On those terms it cannot have a pre-modern history - only harbingers (such as stewards). Others, however, detect management-like thought among ancient Sumerian traders and the builders of the pyramids of ancient Egypt. Slave-owners through the centuries faced the problems of exploiting/motivating a dependent but sometimes unenthusiastic or recalcitrant workforce, but many pre-industrial enterprises, given their small scale, did not feel compelled to face the issues of management systematically. However, innovations such as the spread of Hindu numerals (5th to 15th centuries) and the codification of double-entry book-keeping (1494) provided tools for management assessment, planning and control.

Machiavelli wrote about how to make organisations efficient and effective. The principles that Machiavelli set forth in "Discourses" (1531) can apply in adapted form to the management of organisations today:

With the changing workplaces of industrial revolutions in the 18th and 19th centuries, military theory and practice contributed approaches to managing the newly-popular factories.

Given the scale of most commercial operations and the lack of mechanized record-keeping and recording before the industrial revolution, it made sense for most owners of enterprises in those times to carry out management functions by and for themselves. But with growing size and complexity of organizations, a distinction between owners (individuals, industrial dynasties or groups of shareholders) and day-to-day managers (independent specialists in planning and control) gradually became more common.

The English verb "manage" comes from the Italian "maneggiare" (to handle, especially tools or a horse), which derives from the two Latin words "manus" (hand) and "agere" (to act). The French word for housekeeping, "ménagerie", derived from "ménager" ("to keep house"; compare "ménage" for "household"), also encompasses taking care of domestic animals. "Ménagerie" is the French translation of Xenophon's famous book "Oeconomicus" () on household matters and husbandry. The French word "mesnagement" (or "ménagement") influenced the semantic development of the English word "management" in the 17th and 18th centuries.

Management (according to some definitions) has existed for millennia, and several writers have produced background works that have contributed to modern management theories. Some theorists have cited as providing lessons for civilian managers. For example, Chinese general Sun Tzu in his 6th-century BC work "The Art of War" recommends (when re-phrased in modern terminology) being aware of and acting on strengths and weaknesses of both a manager's organization and a foe's. The writings of influential Chinese Legalist philosopher Shen Buhai may be considered to embody a rare premodern example of abstract theory of administration.

Various ancient and medieval civilizations produced "mirrors for princes" books, which aimed to advise new monarchs on how to govern. Plato described job specialization in 350 BC, and Alfarabi listed several leadership traits in AD 900. Other examples include the Indian "Arthashastra" by Chanakya (written around 300 BC), and "The Prince" by Italian author
Niccolò Machiavelli (c. 1515).

Written in 1776 by Adam Smith, a Scottish moral philosopher, "The Wealth of Nations" discussed efficient organization of work through division of labour.
Smith described how changes in processes could boost productivity in the manufacture of pins. While individuals could produce 200 pins per day, Smith analyzed the steps involved in manufacture and, with 10 specialists, enabled production of 48,000 pins per day.

Classical economists such as Adam Smith (1723–1790) and John Stuart Mill (1806–1873) provided a theoretical background to resource-allocation, production, and pricing issues. About the same time, innovators like Eli Whitney (1765–1825), James Watt (1736–1819), and Matthew Boulton (1728–1809) developed elements of technical production such as standardization, quality-control procedures, cost-accounting, interchangeability of parts, and work-planning. Many of these aspects of management existed in the pre-1861 slave-based sector of the US economy. That environment saw 4 million people, as the contemporary usages had it, "managed" in profitable quasi-mass production.

Salaried managers as an identifiable group first became prominent in the late 19th century.

By about 1900 one finds managers trying to place their theories on what they regarded as a thoroughly scientific basis (see scientism for perceived limitations of this belief). Examples include Henry R. Towne's "Science of management" in the 1890s, Frederick Winslow Taylor's "The Principles of Scientific Management" (1911), Lillian Gilbreth's "Psychology of Management" (1914), Frank and Lillian Gilbreth's "Applied motion study" (1917), and Henry L. Gantt's charts (1910s). J. Duncan wrote the first college management-textbook in 1911. In 1912 Yoichi Ueno introduced Taylorism to Japan and became the first management consultant of the "Japanese-management style". His son Ichiro Ueno pioneered Japanese quality assurance.

The first comprehensive theories of management appeared around 1920. The Harvard Business School offered the first Master of Business Administration degree (MBA) in 1921. People like Henri Fayol (1841–1925) and Alexander Church (1866-1936) described the various branches of management and their inter-relationships. In the early-20th century, people like Ordway Tead (1891–1973), Walter Scott (1869-1955) and J. Mooney applied the principles of psychology to management. Other writers, such as Elton Mayo (1880–1949), Mary Parker Follett (1868–1933), Chester Barnard (1886–1961), Max Weber (1864–1920), who saw what he called the "administrator" as bureaucrat, Rensis Likert (1903–1981), and Chris Argyris (born 1923) approached the phenomenon of management from a sociological perspective.

Peter Drucker (1909–2005) wrote one of the earliest books on applied management: "Concept of the Corporation" (published in 1946). It resulted from Alfred Sloan (chairman of General Motors until 1956) commissioning a study of the organisation. Drucker went on to write 39 books, many in the same vein.

H. Dodge, Ronald Fisher (1890–1962), and Thornton C. Fry introduced statistical techniques into management-studies. In the 1940s, Patrick Blackett worked in the development of the applied-mathematics science of operations research, initially for military operations. Operations research, sometimes known as "management science" (but distinct from Taylor's scientific management), attempts to take a scientific approach to solving decision-problems, and can apply directly to multiple management problems, particularly in the areas of logistics and operations.

Some of the more developments include the Theory of Constraints, management by objectives, reengineering, Six Sigma, the Viable system model, and various information-technology-driven theories such as agile software development, as well as group-management theories such as Cog's Ladder.

As the general recognition of managers as a class solidified during the 20th century and gave perceived practitioners of the art/science of management a certain amount of prestige, so the way opened for popularised systems of management ideas to peddle their wares. In this context many management fads may have had more to do with pop psychology than with scientific theories of management.

Towards the end of the 20th century, business management came to consist of six separate branches, namely:


In the 21st century observers find it increasingly difficult to subdivide management into functional categories in this way. More and more processes simultaneously involve several categories. Instead, one tends to think in terms of the various processes, tasks, and objects subject to management.

Branches of management theory also exist relating to nonprofits and to government: such as public administration, public management, and educational management. Further, management programs related to civil-society organizations have also spawned programs in nonprofit management and social entrepreneurship.

Note that many of the assumptions made by management have come under attack from business-ethics viewpoints, critical management studies, and anti-corporate activism.

As one consequence, workplace democracy (sometimes referred to as Workers' self-management) has become both more common and more advocated, in some places distributing all management functions among workers, each of whom takes on a portion of the work. However, these models predate any current political issue, and may occur more naturally than does a command hierarchy. All management embraces to some degree a democratic principle—in that in the long term, the majority of workers must support management. Otherwise, they leave to find other work or go on strike. Despite the move toward workplace democracy, command-and-control organization structures remain commonplace as "de facto" organization structures. Indeed, the entrenched nature of command-and-control is evident in the way that recent layoffs have been conducted with management ranks affected far less than employees at the lower levels. In some cases, management has even rewarded itself with bonuses after laying off lower-level workers.

According to leadership-academic Manfred F.R. Kets de Vries, a contemporary senior-management team will almost inevitably have some personality disorders.

According to Fayol, management operates through five basic functions: planning, organizing, coordinating, commanding, and controlling.

Figurehead, leader
Nerve centre, disseminator
Entrepreneur, negotiator, allocator

Management skills include:



Most organizations have three management levels: first-level, middle-level, and top-level managers. First-line managers are the lowest level of management and manage the work of nonmanagerial individuals who are directly involved with the production or creation of the organization's products. First-line managers are often called supervisors, but may also be called line managers, office managers, or even foremen. Middle managers include all levels of management between the first-line level and the top level of the organization. These managers manage the work of first-line managers and may have titles such as department head, project leader, plant manager, or division manager. Top managers are responsible for making organization-wide decisions and establishing the plans and goals that affect the entire organization. These individuals typically have titles such as executive vice president, president, managing director, chief operating officer, chief executive officer, or chairman of the board.

These managers are classified in a hierarchy of authority, and perform different tasks. In many organizations, the number of managers in every level resembles a pyramid. Each level is explained below in specifications of their different responsibilities and likely job titles.

The top or senior layer of management consists of the board of directors (including non-executive directors and executive directors), president, vice-president, CEOs and other members of the C-level executives. Different organizations have various members in their C-suite, which may include a Chief Financial Officer, Chief Technology Officer, and so on. They are responsible for controlling and overseeing the operations of the entire organization. They set a "tone at the top" and develop strategic plans, company policies, and make decisions on the overall direction of the organization. In addition, top-level managers play a significant role in the mobilization of outside resources. Senior managers are accountable to the shareholders, the general public and to public bodies that oversee corporations and similar organizations. Some members of the senior management may serve as the public face of the organization, and they may make speeches to introduce new strategies or appear in marketing.

The board of directors is typically primarily composed of non-executives who owe a fiduciary duty to shareholders and are not closely involved in the day-to-day activities of the organization, although this varies depending on the type (e.g., public versus private), size and culture of the organization. These directors are theoretically liable for breaches of that duty and typically insured under directors and officers liability insurance. Fortune 500 directors are estimated to spend 4.4 hours per week on board duties, and median compensation was $212,512 in 2010. The board sets corporate strategy, makes major decisions such as major acquisitions, and hires, evaluates, and fires the top-level manager (Chief Executive Officer or CEO). The CEO typically hires other positions. However, board involvement in the hiring of other positions such as the Chief Financial Officer (CFO) has increased. In 2013, a survey of over 160 CEOs and directors of public and private companies found that the top weaknesses of CEOs were "mentoring skills" and "board engagement", and 10% of companies never evaluated the CEO. The board may also have certain employees (e.g., internal auditors) report to them or directly hire independent contractors; for example, the board (through the audit committee) typically selects the auditor.

Helpful skills of top management vary by the type of organization but typically include a broad understanding of competition, world economies, and politics. In addition, the CEO is responsible for implementing and determining (within the board's framework) the broad policies of the organization. Executive management accomplishes the day-to-day details, including: instructions for preparation of department budgets, procedures, schedules; appointment of middle level executives such as department managers; coordination of departments; media and governmental relations; and shareholder communication.

Consist of general managers, branch managers and department managers. They are accountable to the top management for their department's function. They devote more time to organizational and directional functions. Their roles can be emphasized as executing organizational plans in conformance with the company's policies and the objectives of the top management, they define and discuss information and policies from top management to lower management, and most importantly they inspire and provide guidance to lower level managers towards better performance.

Middle management is the midway management of a categorized organization, being secondary to the senior management but above the deepest levels of operational members. An operational manager may be well-thought-out by middle management, or may be categorized as non-management operate, liable to the policy of the specific organization. Efficiency of the middle level is vital in any organization, since they bridge the gap between top level and bottom level staffs.

Their functions include:

Lower managers include supervisors, section leaders, forepersons and team leaders. They focus on controlling and directing regular employees. They are usually responsible for assigning employees' tasks, guiding and supervising employees on day-to-day activities, ensuring the quality and quantity of production and/or service, making recommendations and suggestions to employees on their work, and channeling employee concerns that they cannot resolve to mid-level managers or other administrators. First-level or "front line" managers also act as role models for their employees. In some types of work, front line managers may also do some of the same tasks that employees do, at least some of the time. For example, in some restaurants, the front line managers will also serve customers during a very busy period of the day.

Front-line managers typically provide:

Some front-line managers may also provide career planning for employees who aim to rise within the organization.

Colleges and universities around the world offer bachelor's degrees, graduate degrees, diplomas and certificates in management, generally within their colleges of business, business schools or faculty of management but also in other related departments. In the 2010s, there has been an increase in online management education and training in the form of electronic educational technology ( also called e-learning). Online education has increased the accessibility of management training to people who do not live near a college or university, or who cannot afford to travel to a city where such training is available.

While some professions require academic credentials in order to work in the profession (e.g., law, medicine, engineering, which require, respectively the Bachelor of Law, Doctor of Medicine and Bachelor of Engineering degrees), management and administration positions do not necessarily require the completion of academic degrees. Some well-known senior executives in the US who did not complete a degree include Steve Jobs, Bill Gates and Mark Zuckerberg. However, many managers and executives have completed some type of business or management training, such as a Bachelor of Commerce or a Master of Business Administration degree. Some major organizations, including companies, not-for-profit organizations and governments, require applicants to managerial or executive positions to hold at minimum Bachelor's degree in a field related to administration or management, or in the case of business jobs, a Bachelor of Commerce or a similar degree.

At the undergraduate level, the most common business program is the Bachelor of Commerce (B.Com.). A B.Com. is typically a four-year program that includes courses that give students an overview of the role of managers in planning and directing within an organization. Course topics include accounting, financial management, statistics, marketing, strategy, and other related areas. There are many other undergraduate degrees that include the study of management, such as Bachelor of Arts degrees with a major in business administration or management and Bachelor of Public Administration (B.P.A), a degree designed for individuals aiming to work as bureaucrats in the government jobs. Many colleges and universities also offer certificates and diplomas in business administration or management, which typically require one to two years of full-time study.

At the graduate level students aiming at careers as managers or executives may choose to specialize in major subareas of management or business administration such as entrepreneurship, human resources, international business, organizational behavior, organizational theory, strategic management, accounting, corporate finance, entertainment, global management, healthcare management, investment management, sustainability and real estate. A Master of Business Administration (MBA) is the most popular professional degree at the master's level and can be obtained from many universities in the United States. MBA programs provide further education in management and leadership for graduate students. Other master's degrees in business and management include Master of Management (MM) and the Master of Science (M.Sc.) in business administration or management, which is typically taken by students aiming to become researchers or professors. There are also specialized master's degrees in administration for individuals aiming at careers outside of business, such as the Master of Public Administration (MPA) degree (also offered as a Master of Arts in Public Administration in some universities), for students aiming to become managers or executives in the public service and the Master of Health Administration, for students aiming to become managers or executives in the health care and hospital sector.

Management doctorates are the most advanced terminal degrees in the field of business and management. Most individuals obtaining management doctorates take the programs to obtain the training in research methods, statistical analysis and writing academic papers that they will need to seek careers as researchers, senior consultants and/or professors in business administration or management. There are three main types of management doctorates: the Doctor of Management (D.M.), the Doctor of Business Administration (D.B.A.), and the Ph.D. in Business Administration or Management. In the 2010s, doctorates in business administration and management are available with many specializations.

While management trends can change so fast, the long term trend in management has been defined by a market embracing diversity and a rising service industry. Managers are currently being trained to encourage greater equality for minorities and women in the workplace, by offering increased flexibility in working hours, better retraining, and innovative (and usually industry-specific) performance markers. Managers destined for the service sector are being trained to use unique measurement techniques, better worker support and more charismatic leadership styles. Human resources finds itself increasingly working with management in a training capacity to help collect management data on the success (or failure) of management actions with employees.




</doc>
<doc id="19883" url="https://en.wikipedia.org/wiki?curid=19883" title="Mineralogy">
Mineralogy

Mineralogy is a subject of geology specializing in the scientific study of chemistry, crystal structure, and physical (including optical) properties of minerals and mineralized artifacts. Specific studies within mineralogy include the processes of mineral origin and formation, classification of minerals, their geographical distribution, as well as their utilization.

Early writing on mineralogy, especially on gemstones, comes from ancient Babylonia, the ancient Greco-Roman world, ancient and medieval China, and Sanskrit texts from ancient India and the ancient Islamic World. Books on the subject included the "Naturalis Historia" of Pliny the Elder, which not only described many different minerals but also explained many of their properties, and Kitab al Jawahir (Book of Precious Stones) by Persian scientist Al Biruni. The German Renaissance specialist Georgius Agricola wrote works such as "De re metallica" ("On Metals", 1556) and "De Natura Fossilium" ("On the Nature of Rocks", 1546) which began the scientific approach to the subject. Systematic scientific studies of minerals and rocks developed in post-Renaissance Europe. The modern study of mineralogy was founded on the principles of crystallography (the origins of geometric crystallography, itself, can be traced back to the mineralogy practiced in the eighteenth and nineteenth centuries) and to the microscopic study of rock sections with the invention of the microscope in the 17th century.

Nicholas Steno first observed the law of constancy of interfacial angles (also known as the first law of crystallography) in quartz crystals in 1669. This was later generalized and established experimentally by Jean-Baptiste L. Romé de l'Islee in 1783. René Just Haüy, the "father of modern crystallography", showed that crystals are periodic and established that the orientations of crystal faces can be expressed in terms of rational numbers, as later encoded in the Miller indices. In 1814, Jöns Jacob Berzelius introduced a classification of minerals based on their chemistry rather than their crystal structure. William Nicol developed the Nicol prism, which polarizes light, in 1827–1828 while studying fossilized wood; Henry Clifton Sorby showed that thin sections of minerals could be identified by their optical properties using a polarizing microscope. James D. Dana published his first edition of "A System of Mineralogy" in 1837, and in a later edition introduced a chemical classification that is still the standard. X-ray diffraction was demonstrated by Max von Laue in 1912, and developed into a tool for analyzing the crystal structure of minerals by the father/son team of William Henry Bragg and William Lawrence Bragg.

More recently, driven by advances in experimental technique (such as neutron diffraction) and available computational power, the latter of which has enabled extremely accurate atomic-scale simulations of the behaviour of crystals, the science has branched out to consider more general problems in the fields of inorganic chemistry and solid-state physics. It, however, retains a focus on the crystal structures commonly encountered in rock-forming minerals (such as the perovskites, clay minerals and framework silicates). In particular, the field has made great advances in the understanding of the relationship between the atomic-scale structure of minerals and their function; in nature, prominent examples would be accurate measurement and prediction of the elastic properties of minerals, which has led to new insight into seismological behaviour of rocks and depth-related discontinuities in seismograms of the Earth's mantle. To this end, in their focus on the connection between atomic-scale phenomena and macroscopic properties, the "mineral sciences" (as they are now commonly known) display perhaps more of an overlap with materials science than any other discipline.

 
An initial step in identifying a mineral is to examine its physical properties, many of which can be measured on a hand sample. These can be classified into density (often given as specific gravity); measures of mechanical cohesion (hardness, tenacity, cleavage, fracture, parting); macroscopic visual properties (luster, color, streak, luminescence, diaphaneity); magnetic and electric properties; radioactivity and solubility in hydrogen chloride ().

"Hardness" is determined by comparison with other minerals. In the Mohs scale, a standard set of minerals are numbered in order of increasing hardness from 1 (talc) to 10 (diamond). A harder mineral will scratch a softer, so an unknown mineral can be placed in this scale by which minerals it scratches and which scratch it. A few minerals such as calcite and kyanite have a hardness that depends significantly on direction. Hardness can also be measured on an absolute scale using a sclerometer; compared to the absolute scale, the Mohs scale is nonlinear.

"Tenacity" refers to the way a mineral behaves when it is broken, crushed, bent or torn. A mineral can be brittle, malleable, sectile, ductile, flexible or elastic. An important influence on tenacity is the type of chemical bond ("e.g.," ionic or metallic). Of the other measures of mechanical cohesion, "cleavage" is the tendency to break along certain crystallographic planes. It is described by the quality ("e.g.", perfect or fair) and the orientation of the plane in crystallographic nomenclature. "Parting" is the tendency to break along planes of weakness due to pressure, twinning or exsolution. Where these two kinds of break do not occur, "fracture" is a less orderly form that may be "conchoidal" (having smooth curves resembling the interior of a shell), "fibrous", "splintery", "hackly" (jagged with sharp edges), or "uneven".

If the mineral is well crystallized, it will also have a distinctive crystal habit (for example, hexagonal, columnar, botryoidal) that reflects the crystal structure or internal arrangement of atoms. It is also affected by crystal defects and twinning. Many crystals are polymorphic, having more than one possible crystal structure depending on factors such as pressure and temperature.

The crystal structure is the arrangement of atoms in a crystal. It is represented by a lattice of points which repeats a basic pattern, called a unit cell, in three dimensions. The lattice can be characterized by its symmetries and by the dimensions of the unit cell. These dimensions are represented by three "Miller indices". The lattice remains unchanged by certain symmetry operations about any given point in the lattice: reflection, rotation, inversion, and rotary inversion, a combination of rotation and reflection. Together, they make up a mathematical object called a "crystallographic point group" or "crystal class". There are 32 possible crystal classes. In addition, there are operations that displace all the points: translation, screw axis, and glide plane. In combination with the point symmetries, they form 230 possible space groups.

Most geology departments have X-ray powder diffraction equipment to analyze the crystal structures of minerals. X-rays have wavelengths that are the same order of magnitude as the distances between atoms. Diffraction, the constructive and destructive interference between waves scattered at different atoms, leads to distinctive patterns of high and low intensity that depend on the geometry of the crystal. In a sample that is ground to a powder, the X-rays sample a random distribution of all crystal orientations. Powder diffraction can distinguish between minerals that may appear the same in a hand sample, for example quartz and its polymorphs tridymite and cristobalite.

Isomorphous minerals of different compositions have similar powder diffraction patterns, the main difference being in spacing and intensity of lines. For example, the (halite) crystal structure is space group "Fm3m"; this structure is shared by sylvite (), periclase (), bunsenite (), galena (), alabandite (), chlorargyrite (), and osbornite ().

A few minerals are chemical elements, including sulfur, copper, silver, and gold, but the vast majority are compounds. The classical method for identifying composition is "wet chemical analysis", which involves dissolving a mineral in an acid such as hydrochloric acid (). The elements in solution are then identified using colorimetry, volumetric analysis or gravimetric analysis.

Since 1960, most chemistry analysis is done using instruments. One of these, atomic absorption spectroscopy, is similar to wet chemistry in that the sample must still be dissolved, but it is much faster and cheaper. The solution is vaporized and its absorption spectrum is measured in the visible and ultraviolet range. Other techniques are X-ray fluorescence, electron microprobe analysis and optical emission spectrography.

In addition to macroscopic properties such as color or lustre, minerals have properties that require a polarizing microscope to observe.

When light passes from air or a vacuum into a transparent crystal, some of it is reflected at the surface and some refracted. The latter is a bending of the light path that occurs because the speed of light changes as it goes into the crystal; Snell's law relates the bending angle to the Refractive index, the ratio of speed in a vacuum to speed in the crystal. Crystals whose point symmetry group falls in the cubic system are "isotropic": the index does not depend on direction. All other crystals are "anisotropic": light passing through them is broken up into two plane polarized rays that travel at different speeds and refract at different angles.

A polarizing microscope is similar to an ordinary microscope, but it has two plane-polarized filters, a ("polarizer") below the sample and an analyzer above it, polarized perpendicular to each other. Light passes successively through the polarizer, the sample and the analyzer. If there is no sample, the analyzer blocks all the light from the polarizer. However, an anisotropic sample will generally change the polarization so some of the light can pass through. Thin sections and powders can be used as samples.

When an isotropic crystal is viewed, it appears dark because it does not change the polarization of the light. However, when it is immersed in a calibrated liquid with a lower index of refraction and the microscope is thrown out of focus, a bright line called a "Becke line" appears around the perimeter of the crystal. By observing the presence or absence of such lines in liquids with different indices, the index of the crystal can be estimated, usually to within .

Systematic mineralogy is the identification and classification of minerals by their properties. Historically, mineralogy was heavily concerned with taxonomy of the rock-forming minerals. In 1959, the International Mineralogical Association formed the Commission of New Minerals and Mineral Names to rationalize the nomenclature and regulate the introduction of new names. In July 2006, it was merged with the Commission on Classification of Minerals to form the Commission on New Minerals, Nomenclature, and Classification. There are over 6,000 named and unnamed minerals, and about 100 are discovered each year. The "Manual of Mineralogy" places minerals in the following classes: native elements, sulfides, sulfosalts, oxides and hydroxides, halides, carbonates, nitrates and borates, sulfates, chromates, molybdates and tungstates, phosphates, arsenates and vanadates, and silicates.

The environments of mineral formation and growth are highly varied, ranging from slow crystallization at the high temperatures and pressures of igneous melts deep within the Earth's crust to the low temperature precipitation from a saline brine at the Earth's surface.

Various possible methods of formation include:


Biomineralogy is a cross-over field between mineralogy, paleontology and biology. It is the study of how plants and animals stabilize minerals under biological control, and the sequencing of mineral replacement of those minerals after deposition. It uses techniques from chemical mineralogy, especially isotopic studies, to determine such things as growth forms in living plants and animals as well as things like the original mineral content of fossils.

A new approach to mineralogy called "mineral evolution" explores the co-evolution of the geosphere and biosphere, including the role of minerals in the origin of life and processes as mineral-catalyzed organic synthesis and the selective adsorption of organic molecules on mineral surfaces.

Minerals are essential to various needs within human society, such as minerals used as ores for essential components of metal products used in various commodities and machinery, essential components to building materials such as limestone, marble, granite, gravel, glass, plaster, cement, etc. Minerals are also used in fertilizers to enrich the growth of agricultural crops.

Mineral collecting is also a recreational study and collection hobby, with clubs and societies representing the field. Museums, such as the Smithsonian National Museum of Natural History Hall of Geology, Gems, and Minerals, the Natural History Museum of Los Angeles County, the Natural History Museum, London, and the private Mim Mineral Museum in Beirut, Lebanon, have popular collections of mineral specimens on permanent display.




</doc>
<doc id="19886" url="https://en.wikipedia.org/wiki?curid=19886" title="Maple syrup">
Maple syrup

Maple syrup is a syrup usually made from the xylem sap of sugar maple, red maple, or black maple trees, although it can also be made from other maple species. In cold climates, these trees store starch in their trunks and roots before winter; the starch is then converted to sugar that rises in the sap in late winter and early spring. Maple trees are tapped by drilling holes into their trunks and collecting the exuded sap, which is processed by heating to evaporate much of the water, leaving the concentrated syrup.

Maple syrup was first collected and used by the indigenous peoples of North America, and the practice was adopted by European settlers, who gradually refined production methods. Technological improvements in the 1970s further refined syrup processing. The Canadian province of Quebec is by far the largest producer, responsible for 70 percent of the world's output; Canadian exports of maple syrup in 2016 were C$ 487 million (about US$ 360 million), with Quebec accounting for some 90 percent of this total. Vermont is the largest producer in the United States, generating about six percent of the global supply.

Maple syrup is graded according to the Canada, United States, or Vermont scales based on its density and translucency. Sucrose is the most prevalent sugar in maple syrup. In Canada, syrups must be made exclusively from maple sap to qualify as maple syrup and must also be at least 66 percent sugar. In the United States, a syrup must be made almost entirely from maple sap to be labelled as "maple", though states such as Vermont and New York have more restrictive definitions.

Maple syrup is often used as a condiment for pancakes, waffles, French toast, oatmeal or porridge. It is also used as an ingredient in baking and as a sweetener or flavouring agent. Culinary experts have praised its unique flavour, although the chemistry responsible is not fully understood.

Three species of maple trees are predominantly used to produce maple syrup: the sugar maple ("Acer saccharum"), the black maple ("A. nigrum"), and the red maple ("A. rubrum"), because of the high sugar content (roughly two to five percent) in the sap of these species. The black maple is included as a subspecies or variety in a more broadly viewed concept of "A. saccharum", the sugar maple, by some botanists. Of these, the red maple has a shorter season because it buds earlier than sugar and black maples, which alters the flavour of the sap.

A few other (but not all) species of maple ("Acer") are also sometimes used as sources of sap for producing maple syrup, including the box elder or Manitoba maple ("Acer negundo"), the silver maple ("A. saccharinum"), and the bigleaf maple ("A. macrophyllum"). Similar syrups may also be produced from birch or palm trees, among other sources.

Indigenous peoples living in northeastern North America were the first groups known to have produced maple syrup and maple sugar. According to aboriginal oral traditions, as well as archaeological evidence, maple tree sap was being processed into syrup long before Europeans arrived in the region. There are no authenticated accounts of how maple syrup production and consumption began, but various legends exist; one of the most popular involves maple sap being used in place of water to cook venison served to a chief. Other stories credit the development of maple syrup production to Nanabozho, Glooskap, or the squirrel. Aboriginal tribes developed rituals around sugar-making, celebrating the Sugar Moon (the first full moon of spring) with a Maple Dance. Many aboriginal dishes replaced the salt traditional in European cuisine with maple sugar or syrup.

The Algonquians recognized maple sap as a source of energy and nutrition. At the beginning of the spring thaw, they used stone tools to make V-shaped incisions in tree trunks; they then inserted reeds or concave pieces of bark to run the sap into buckets, which were often made from birch bark. The maple sap was concentrated either by dropping hot cooking stones into the buckets or by leaving them exposed to the cold temperatures overnight and disposing of the layer of ice that formed on top.

In the early stages of European colonization in northeastern North America, local Indigenous peoples showed the arriving colonists how to tap the trunks of certain types of maples during the spring thaw to harvest the sap. André Thevet, the "Royal Cosmographer of France", wrote about Jacques Cartier drinking maple sap during his Canadian voyages. By 1680, European settlers and fur traders were involved in harvesting maple products. However, rather than making incisions in the bark, the Europeans used the method of drilling tapholes in the trunks with augers. During the 17th and 18th centuries, processed maple sap was used primarily as a source of concentrated sugar, in both liquid and crystallized-solid form, as cane sugar had to be imported from the West Indies.

Maple sugaring parties typically began to operate at the start of the spring thaw in regions of woodland with sufficiently large numbers of maples. Syrup makers first bored holes in the trunks, usually more than one hole per large tree; they then inserted wooden spouts into the holes and hung a wooden bucket from the protruding end of each spout to collect the sap. The buckets were commonly made by cutting cylindrical segments from a large tree trunk and then hollowing out each segment's core from one end of the cylinder, creating a seamless, watertight container. Sap filled the buckets, and was then either transferred to larger holding vessels (barrels, large pots, or hollowed-out wooden logs), often mounted on sledges or wagons pulled by draft animals, or carried in buckets or other convenient containers. The sap-collection buckets were returned to the spouts mounted on the trees, and the process was repeated for as long as the flow of sap remained "sweet". The specific weather conditions of the thaw period were, and still are, critical in determining the length of the sugaring season. As the weather continues to warm, a maple tree's normal early spring biological process eventually alters the taste of the sap, making it unpalatable, perhaps due to an increase in amino acids.

The boiling process was very time-consuming. The harvested sap was transported back to the party's base camp, where it was then poured into large vessels (usually made from metal) and boiled to achieve the desired consistency. The sap was usually transported using large barrels pulled by horses or oxen to a central collection point, where it was processed either over a fire built out in the open or inside a shelter built for that purpose (the "sugar shack").

Around the time of the American Civil War (1861-1865), syrup makers started using large, flat sheet metal pans as they were more efficient for boiling than heavy, rounded iron kettles, because of a greater surface area for evaporation. Around this time, cane sugar replaced maple sugar as the dominant sweetener in the US; as a result, producers focused marketing efforts on maple syrup. The first evaporator, used to heat and concentrate sap, was patented in 1858. In 1872, an evaporator was developed that featured two pans and a metal arch or firebox, which greatly decreased boiling time. Around 1900, producers bent the tin that formed the bottom of a pan into a series of flues, which increased the heated surface area of the pan and again decreased boiling time. Some producers also added a finishing pan, a separate batch evaporator, as a final stage in the evaporation process.

Buckets began to be replaced with plastic bags, which allowed people to see at a distance how much sap had been collected. Syrup producers also began using tractors to haul vats of sap from the trees being tapped (the sugarbush) to the evaporator. Some producers adopted motor-powered tappers and metal tubing systems to convey sap from the tree to a central collection container, but these techniques were not widely used. Heating methods also diversified: modern producers use wood, oil, natural gas, propane, or steam to evaporate sap. Modern filtration methods were perfected to prevent contamination of the syrup.

A large number of technological changes took place during the 1970s. Plastic tubing systems that had been experimental since the early part of the century were perfected, and the sap came directly from the tree to the evaporator house. Vacuum pumps were added to the tubing systems, and preheaters were developed to recycle heat lost in the steam. Producers developed reverse-osmosis machines to take a portion of water out of the sap before it was boiled, increasing processing efficiency.

Improvements in tubing and vacuum pumps, new filtering techniques, "supercharged" preheaters, and better storage containers have since been developed. Research continues on pest control and improved woodlot management. In 2009, researchers at the University of Vermont unveiled a new type of tap that prevents backflow of sap into the tree, reducing bacterial contamination and preventing the tree from attempting to heal the bore hole. Experiments show that it may be possible to use saplings in a plantation instead of mature trees, dramatically boosting productivity per acre.

Open pan evaporation methods have been streamlined since colonial days, but remain basically unchanged. Sap must first be collected and boiled down to obtain pure syrup without chemical agents or preservatives. Maple syrup is made by boiling between 20 and 50 volumes of sap (depending on its concentration) over an open fire until 1 volume of syrup is obtained, usually at a temperature over the boiling point of water. As the boiling point of water varies with changes in air pressure the correct value for pure water is determined at the place where the syrup is being produced, each time evaporation is begun and periodically throughout the day. Syrup can be boiled entirely over one heat source or can be drawn off into smaller batches and boiled at a more controlled temperature.

Boiling the syrup is a tightly controlled process, which ensures appropriate sugar content. Syrup boiled too long will eventually crystallize, whereas under-boiled syrup will be watery, and will quickly spoil. The finished syrup has a density of 66° on the Brix scale (a hydrometric scale used to measure sugar solutions). The syrup is then filtered to remove sugar sand, crystals made up largely of sugar and calcium malate. These crystals are not toxic, but create a "gritty" texture in the syrup if not filtered out.

In addition to open pan evaporation methods, many large producers use the more fuel efficient reverse osmosis procedure to separate the water from the sap.

The higher the sugar content of the sap, the smaller the volume of sap is needed to obtain the same amount of syrup. 57 units of sap with 1.5 percent sugar content will yield 1 unit of syrup, but only 25 units of sap with a 3.5 percent sugar content are needed to obtain one unit of syrup. The sap's sugar content is highly variable and will fluctuate even within the same tree.

The filtered syrup is graded and packaged while still hot, usually at a temperature of or greater. The containers are turned over after being sealed to sterilize the cap with the hot syrup. Packages can be made of metal, glass, or coated plastic, depending on volume and target market. The syrup can also be heated longer and further processed to create a variety of other maple products, including maple sugar, maple butter or cream, and maple candy or taffy.

Off-flavours can sometimes develop during the production of maple syrup, resulting from contaminants in the boiling apparatus (such as disinfectants), microorganisms, fermentation products, metallic can flavours, and "buddy sap", an off-flavour occurring late in the syrup season when tree budding has begun. In some circumstances, it is possible to remove off-flavours through processing.

Maple syrup production is centred in northeastern North America; however, given the correct weather conditions, it can be made wherever suitable species of maple trees grow.

A maple syrup production farm is called a "sugarbush" or "sugarwood". Sap is often boiled in a "sugar house" (also known as a "sugar shack", "sugar shanty", or "cabane à sucre"), a building louvered at the top to vent the steam from the boiling sap.

Maples are usually tapped beginning at 30 to 40 years of age. Each tree can support between one and three taps, depending on its trunk diameter. The average maple tree will produce of sap per season, up to per day. This is roughly equal to seven percent of its total sap. Seasons last for four to eight weeks, depending on the weather. During the day, starch stored in the roots for the winter rises through the trunk as sugary sap, allowing it to be tapped. Sap is not tapped at night because the temperature drop inhibits sap flow, although taps are typically left in place overnight. Some producers also tap in autumn, though this practice is less common than spring tapping. Maples can continue to be tapped for sap until they are over 100 years old.

Until the 1930s, the United States produced most of the world's maple syrup. Today, after rapid growth in the 1990s, Canada produces more than 80 percent of the world's maple syrup, producing about in 2016. The vast majority of this comes from the province of Quebec, which is the world's largest producer, with about 70 percent of global production.

As of 2016, Quebec had some 7,300 producers working with 13,500 farmers, collectively making over of syrup. Production in Quebec is controlled through a supply management system, with producers receiving quota allotments from the Federation of Quebec Maple Syrup Producers ("Fédération des producteurs acéricoles du Québec", FPAQ), which also maintains reserves of syrup, although there is a black-market trade in Quebec product. In 2017, the FPAQ mandated increased output of maple syrup production, attempting to establish Quebec's dominance in the world market. Canada exported more than C$362 million of maple syrup in 2016. The provinces of Ontario, Nova Scotia, New Brunswick, and Prince Edward Island produce smaller amounts of syrup.

The Canadian provinces of Manitoba and Saskatchewan produce maple syrup using the sap of the box elder or Manitoba maple ("Acer negundo"). A Manitoba maple tree's yield is usually less than half that of a similar sugar maple tree. Manitoba maple syrup has a slightly different flavour from sugar-maple syrup, because it contains less sugar and the tree's sap flows more slowly. British Columbia is home to a growing maple sugar industry using sap from the bigleaf maple, which is native to the West Coast of the United States and Canada.

Vermont is the biggest US producer, with over during the 2013 season, followed by New York with and Maine with . Wisconsin, Ohio, New Hampshire, Michigan, Pennsylvania, Massachusetts, and Connecticut all produced marketable quantities of maple syrup of less than each in 2013. As of 2003, Vermont produced about 5.5 percent of the global syrup supply.

Maple syrup has been produced on a small scale in some other countries, notably Japan and South Korea. However, in South Korea in particular, it is traditional to consume maple sap, called "gorosoe", instead of processing it into syrup.

In 2015, 64 percent of Canadian maple syrup exports went to the United States (a value of C$229 million), 8 percent to Germany (C$31 million), 6 percent to Japan (C$26 million), and 5 percent to the United Kingdom (C$16 million).

Under Canadian Maple Product Regulations, containers of maple syrup must include the words “maple syrup”, its grade name and net quantity in litres or millilitres, on the main display panel with a minimum font size of 1.6mm. If the maple syrup is of Canada Grade A level, the name of the colour class must appear on the label in both English and French. Also, the lot number or production code, and either: (1) the name and address of the sugar bush establishment, packing or shipper establishment, or (2) the first dealer and the registration number of the packing establishment, must be labeled on any display panel other than the bottom.

Following an effort from the International Maple Syrup Institute (IMSI) and many maple syrup producer associations, both Canada and the United States have altered their laws regarding the classification of maple syrup to be uniform. Whereas in the past each state or province had their own laws on the classification of maple syrup, now those laws define a unified grading system. This had been a work in progress for several years, and most of the finalization of the new grading system was made in 2014. The Canadian Food Inspection Agency (CFIA) announced in the "Canada Gazette" on 28 June 2014 that rules for the sale of maple syrup would be amended to include new descriptors, at the request of the IMSI.

As of December 31, 2014, the CFIA and as of March 2, 2015, the United States Department of Agriculture (USDA) Agricultural Marketing Service issued revised standards intended to harmonize Canada-United States regulations on the classification of maple syrup as follows:


As long as maple syrup does not have an off-flavour, is of a uniform colour, and is free from turbidity and sediment, it can be labelled as one of the A grades. If it exhibits any problems, it does not meet Grade A requirements, and then must be labelled as Processing Grade maple syrup and may not be sold in containers smaller than 5 gallons. If maple syrup does not meet the requirements of Processing Grade maple syrup (including a fairly characteristic maple taste), it is classified as Substandard.

As of February 2015, this grading system has been accepted and made law by most maple-producing states and provinces, other than Ontario, Quebec, and Ohio. Vermont, in an effort to "jump-start" the new grading regulations, adopted the new grading system as of January 1, 2014, after the grade changes passed the Senate and House in 2013. Maine passed a bill to take effect as soon as both Canada and the United States adopted the new grades. They are allowing a one-year grace period. In New York, the new grade changes became law on January 1, 2015, with a one-year grace period. New Hampshire did not require legislative approval and so the new grade laws became effective as of December 16, 2014, and producer compliance was required as of January 1, 2016.

Golden and Amber grades typically have a milder flavour than Dark and Very dark, which are both dark and have an intense maple flavour. The darker grades of syrup are used primarily for cooking and baking, although some specialty dark syrups are produced for table use. Syrup harvested earlier in the season tends to yield a lighter colour. With the new grading system, the classification of maple syrup depends ultimately on its internal transmittance at 560 nm wavelength through a 10 mm sample. Golden has to have 75 percent or more transmittance, Amber has to have 50.0 to 74.9 percent transmittance, Dark has to have 25.0 to 49.9 percent transmittance, and Very Dark is any product less than 25.0 percent transmittance.

In Canada, maple syrup was classified prior to December 31, 2014, by the Canadian Food Inspection Agency (CFIA) as one of three grades, each with several colour classes:

Producers in Ontario or Quebec may have followed either federal or provincial grading guidelines. Quebec's and Ontario's guidelines differed slightly from the federal:


A typical year's yield for a maple syrup producer will be about 25 to 30 percent of each of the #1 colours, 10 percent #2 Amber, and 2 percent #3 Dark.

The United States used (some states still do, as they await state regulation) different grading standards. Maple syrup was divided into two major grades: 

In Massachusetts, the Grade B was renamed as "Grade A Very Dark, Strong Taste."

The Vermont Agency of Agriculture Food and Markets used a similar grading system of colour, and is roughly equivalent, especially for lighter syrups, but using letters: "AA", "A", etc. The Vermont grading system differed from the US system in maintaining a slightly higher standard of product density (measured on the Baumé scale). New Hampshire maintained a similar standard, but not a separate state grading scale. The Vermont-graded product had 0.9 percent more sugar and less water in its composition than US-graded. One grade of syrup not for table use, called commercial or Grade C, was also produced under the Vermont system.

In Canada, the packing of maple syrup must follow the “Packing” conditions stated in the Maple Products Regulations, or utilize the equivalent Canadian or imported grading system.

As stated in the Maple Products Regulations, Canadian maple syrup can be classified as “Canadian Grade A” and “Canadian Processing Grade”. Any maple syrup container under these classifications should be filled to at least 90% of the bottle size while still containing the net quantity of syrup product as stated on the label. Every container of maple syrup must be new if it has a capacity of 5 litres or less or is marked with a grade name. Every container of maple sugar must also be new if it has a capacity of less than 5 kg or is either exported out of Canada or conveyed from one province to another.

Each maple syrup product must be verified clean if it follows a grade name or if it is exported out of the province in which it was originally manufactured.

The basic ingredient in maple syrup is the sap from the xylem of sugar maple or various other species of maple trees. It consists primarily of sucrose and water, with small amounts of the monosaccharides glucose and fructose from the invert sugar created in the boiling process.

In a 100g amount, maple syrup provides 260 calories and is composed of 32 percent water by weight, 67 percent carbohydrates (90 percent of which are sugars), and no appreciable protein or fat (table). Maple syrup is generally low in overall micronutrient content, although manganese and riboflavin are at high levels along with moderate amounts of zinc and calcium (right table). It also contains trace amounts of amino acids which increase in content as sap flow occurs.

Maple syrup contains a wide variety of volatile organic compounds, including vanillin, hydroxybutanone, and propionaldehyde. It is not yet known exactly what compounds are responsible for maple syrup's distinctive flavour, however its primary flavour contributing compounds are maple furanone, strawberry furanone, and maltol.

New compounds have been identified in maple syrup, one of which is quebecol, a natural phenolic compound created when the maple sap is boiled to create syrup.

One author described maple syrup as "a unique ingredient, smooth- and silky-textured, with a sweet, distinctive flavour – hints of caramel with overtones of toffee will not do – and a rare colour, amber set alight. Maple flavour is, well, maple flavour, uniquely different from any other." Agriculture Canada has developed a "flavour wheel" that details 91 unique flavours that can be present in maple syrup. These flavours are divided into 13 families: vanilla, empyreumatic (burnt), milky, fruity, floral, spicy, foreign (deterioration or fermentation), foreign (environment), maple, confectionery, plant (herbaceous), plant (forest, humus or cereals), and plant (ligneous). These flavours are evaluated using a procedure similar to wine tasting. Other culinary experts praise its unique flavour.

Maple syrup and its various artificial imitations are widely used as toppings for pancakes, waffles, and French toast in North America. They can also be used to flavour a variety of foods, including fritters, ice cream, hot cereal, fresh fruit, and sausages. It is also used as sweetener for granola, applesauce, baked beans, candied sweet potatoes, winter squash, cakes, pies, breads, tea, coffee, and hot toddies. Maple syrup can also be used as a replacement for honey in wine (mead).

In Canada, maple syrup must be made entirely from maple sap, and syrup must have a density of 66° on the Brix scale to be marketed as maple syrup. In the United States, maple syrup must be made almost entirely from maple sap, although small amounts of substances such as salt may be added. Labeling laws prohibit imitation syrups from having "maple" in their names unless the finished product contains 10 percent or more of natural maple syrup.

"Maple-flavoured" syrups include maple syrup, but may contain additional ingredients. "Pancake syrup", "waffle syrup", "table syrup", and similarly named syrups are substitutes which are less expensive than maple syrup. In these syrups, the primary ingredient is most often high-fructose corn syrup flavoured with sotolon; they have little genuine maple content, and are usually thickened above the viscosity of maple syrup.

Imitation syrups are generally cheaper than maple syrup, with less natural flavour. In the United States, consumers generally prefer imitation syrups, likely because of the significantly lower cost and sweeter flavour; they typically cost about $8 per gallon (), whereas authentic maple syrup costs $40 to $60 per gallon (2015 prices).

In 2016, maple syrup producers from nine US states petitioned the Food and Drug Administration (FDA) to regulate labeling of products containing maple syrup or using the word "maple" in manufactured products, indicating that imitation maple products contained insignificant amounts of natural maple syrup. In September 2016, the FDA published a consumer advisory to carefully inspect the ingredient list of products labeled as "maple".

Maple products are considered emblematic of Canada, in particular Quebec, and are frequently sold in tourist shops and airports as souvenirs from Canada. The sugar maple's leaf has come to symbolize Canada, and is depicted on the country's flag. Several US states, including West Virginia, New York, Vermont and Wisconsin, have the sugar maple as their state tree. A scene of sap collection is depicted on the Vermont state quarter, issued in 2001.

Maple syrup and maple sugar were used during the American Civil War and by abolitionists in the years before the war because most cane sugar and molasses were produced by Southern slaves. Because of food rationing during the Second World War, people in the northeastern United States were encouraged to stretch their sugar rations by sweetening foods with maple syrup and maple sugar, and recipe books were printed to help housewives employ this alternative source.





</doc>
<doc id="19888" url="https://en.wikipedia.org/wiki?curid=19888" title="Matthew">
Matthew

Matthew may refer to:





</doc>
<doc id="19890" url="https://en.wikipedia.org/wiki?curid=19890" title="Male (disambiguation)">
Male (disambiguation)

Male, in biology, is the half of a reproduction system that produces sperm cells.

Male may also refer to:







</doc>
<doc id="19891" url="https://en.wikipedia.org/wiki?curid=19891" title="Macron (diacritic)">
Macron (diacritic)

A macron () is a diacritical mark: it is a straight bar placed above a letter, usually a vowel. Its name derives , since it was originally used to mark long or heavy syllables in Greco-Roman metrics. It now more often marks a long vowel. In the International Phonetic Alphabet, the macron is used to indicate a mid-tone; the sign for a long vowel is instead a modified triangular colon .

The opposite is the breve , which marks a short or light syllable or a short vowel.

In Greco-Roman metrics and in the description of the metrics of other literatures, the macron was introduced and is still widely used to mark a long (heavy) syllable. Even relatively recent classical Greek and Latin dictionaries are still concerned with indicating only the length (weight) of syllables; that is why most still do not indicate the length of vowels in syllables that are otherwise metrically determined. Many textbooks about Ancient Rome and Greece use the macron even if it was not actually used at that time.

The following languages or transliteration systems use the macron to mark long vowels:



The following languages or alphabets use the macron to mark tones:


Sometimes the macron marks an omitted "n" or "m", like the tilde:

The macron is used in the orthography of a number of vernacular languages of the Solomon Islands and Vanuatu, particularly those first transcribed by Anglican missionaries. The macron has no unique value, and is simply used to distinguish between two different phonemes.

Thus, in several languages of the Banks Islands, including Mwotlap, the simple "m" stands for , but an "m" with a macron (m̄) is a rounded labial-velar nasal ; while the simple "n" stands for the common alveolar nasal , an "n" with macron (n̄) represents the velar nasal ; the vowel ē stands for a (short) higher by contrast with plain "e" ; likewise ō contrasts with plain "o" .

In Hiw orthography, the consonant "r̄" stands for the prestopped velar lateral approximant .
In Araki, the same symbol "r̄" encodes the alveolar trill – by contrast with "r", which encodes the alveolar flap .

In Bislama (orthography before 1995), Lamenu and Lewo, a macron is used on two letters "". "m̄" represents , and "p̄" represents . The orthography after 1995 (which has no diacritics) has these written as "mw" and "pw".

In Kokota, "ḡ" is used for the velar stop , but "g" without macron is the voiced velar fricative .

In Marshallese, a macron is used on four letters – ' – whose pronunciations differ from the unmarked '. Marshallese uses a vertical vowel system with three to four vowel phonemes, but traditionally their allophones have been written out, so vowel letters with macron are used for some of these allophones. Though the standard diacritic involved is a macron, there are no other diacritics used "above" letters, so in practice other diacritics can and have been used in less polished writing or print, yielding nonstandard letters like ", depending on displayability of letters in computer fonts.


Also, in some instances, a diacritic will be written like a macron, although it represents another diacritic whose standard form is different:


In medical prescriptions and other handwritten notes, macrons mean:

The overline is a typographical symbol similar to the macron, used in a number of ways in mathematics and science, for example in Hermann–Mauguin notation.

In music, the tenuto marking resembles the macron.

The macron is also used in German lute tablature to distinguish repeating alphabetic characters.

The Unicode Standard encodes combining and precomposed macron characters:

Macron-related Unicode characters not included in the table above:

In LaTeX a macron is created with the command "\=", for example: M\=aori for Māori.
In OpenOffice, if the extension Compose Special Characters is installed, a macron may be added by following the letter with a hyphen and pressing the user’s predefined shortcut key for composing special characters. A macron may also be added by following the letter with the character’s four-digit hex-code, and pressing the user’s predefined shortcut key for adding unicode characters.




</doc>
<doc id="19894" url="https://en.wikipedia.org/wiki?curid=19894" title="Mosque">
Mosque

A mosque (; from ) is a place of worship for Muslims. There are strict and detailed requirements in Sunni jurisprudence (, "fiqh") for a place of worship to be considered a mosque, with places that do not meet these requirements regarded as musallas. There are stringent restrictions on the uses of the area formally demarcated as the mosque (which is often a small portion of the larger complex), and in the Islamic "Sharī‘ah" (, Law), after an area is formally designated as a mosque, it remains so until the Last Day.

Many mosques have elaborate domes, minarets, and prayer halls, in varying styles of architecture. Mosques originated on the Arabian Peninsula, but are now found in all inhabited continents. The mosque serves as a place where Muslims can come together for "Ṣalāh" (, meaning "prayer") as well as a center for information, education, social welfare, and dispute settlement. The "Imām" (, Leader) leads the congregation in prayer.

The word 'mosque' entered the English language from the French word "mosqueé" that was probably derived from Italian "moschea", a variant of Italian "moscheta", from either Middle Armenian մզկիթ ("mzkit‘") or Medieval ("masgídion") or Spanish "mezquita", from (meaning "place of worship" or "prostration in prayer"), either from Nabataean "masgdhā́" or from Arabic (meaning "to bow down in prayer"), probably ultimately from Aramaic "sghēdh".

The first mosque in the world is often considered to be the area around the "Ka‘bah" (, 'Cube') in Mecca, which is now known as "Al-Masjid Al-Ḥarâm" (, the Sacred Mosque). A Hadith in Sahih al-Bukhari states that the "Kaaba" was the First Mosque on Earth, and the Second Mosque was the Temple in Jerusalem. Since as early as 638 AD, the Sacred Mosque has been expanded on several occasions to accommodate the increasing number of Muslims who either live in the area or make the annual pilgrimage known as "Ḥajj" () to the city. Others regard the first mosque in history to be the Quba Mosque in present-day Medina since it was the first structure built by Muhammad upon his emigration from Mecca in 622, though the Mosque of the Companions in the Eritrean city of Massawa may have been constructed at around the same time.

The Islamic Prophet Muhammad went on to establish another mosque in Medina, which is now known as the Masjid an-Nabawi, or the Prophet's Mosque. Built on the site of his home, Muhammad participated in the construction of the mosque himself and helped pioneer the concept of the mosque as the focal point of the Islamic city. The Masjid al-Nabawi introduced some of the features still common in today's mosques, including the niche at the front of the prayer space known as the "mihrab" and the tiered pulpit called the "minbar". The Masjid al-Nabawi was also constructed with a large courtyard, a motif common among mosques built since then.

Mosques had been built in Iraq and North Africa by the end of the 7th century, as Islam spread outside the Arabian Peninsula with early caliphates. The Imam Husayn Shrine in Karbala is reportedly one of the oldest mosques in Iraq, although its present formtypical of Persian architectureonly goes back to the 11th century. The shrine, while still operating as a mosque, remains one of the holiest sites for Shia Muslims, as it honors the death of the third Shia imam, and Prophet Muhammad's grandson, Hussein ibn Ali. The Mosque of Amr ibn al-As was reportedly the first mosque in Egypt, serving as a religious and social center for Fustat (present-day Cairo) during its prime. Like the Imam Husayn Shrine, though, nothing of its original structure remains. With the later Shia Fatimid Caliphate, mosques throughout Egypt evolved to include schools (known as "madrasas"), hospitals, and tombs.

The Great Mosque of Kairouan in present-day Tunisia was reportedly the first mosque built in northwest Africa, with its present form (dating from the 9th century) serving as a model for other Islamic places of worship in the Maghreb. It was the first to incorporate a square minaret (as opposed to the more common circular minaret) and includes naves akin to a basilica. Those features can also be found in Andalusian mosques, including the Grand Mosque of Cordoba, as they tended to reflect the architecture of the Moors instead of their Visigoth predecessors. Still, some elements of Visigothic architecture, like horseshoe arches, were infused into the mosque architecture of Spain and the Maghreb.

The first mosque in East Asia was reportedly established in the 8th century in Xi'an. However, the Great Mosque of Xi'an, whose current building dates from the 18th century, does not replicate the features often associated with mosques elsewhere. Indeed, minarets were initially prohibited by the state. Following traditional Chinese architecture, the Great Mosque of Xi'an, like many other mosques in eastern China, resembles a pagoda, with a green roof instead of the yellow roof common on imperial structures in China. Mosques in western China were more likely to incorporate elements, like domes and minarets, traditionally seen in mosques elsewhere.

A similar integration of foreign and local influences could be seen on the Indonesian islands of Sumatra and Java, where mosques, including the Demak Great Mosque, were first established in the 15th century. Early Javanese mosques took design cues from Hindu, Buddhist, and Chinese architectural influences, with tall timber, multi-level roofs similar to the pagodas of Balinese Hindu temples; the ubiquitous Islamic dome did not appear in Indonesia until the 19th century. In turn, the Javanese style influenced the styles of mosques in Indonesia's Austronesian neighbors—Malaysia, Brunei, and the Philippines.
Muslim empires were instrumental in the evolution and spread of mosques. Although mosques were first established in India during the 7th century, they were not commonplace across the subcontinent until the arrival of the Mughals in the 16th and 17th centuries. Reflecting their Timurid origins, Mughal-style mosques included onion domes, pointed arches, and elaborate circular minarets, features common in the Persian and Central Asian styles. The Jama Masjid in Delhi and the Badshahi Mosque in Lahore, built in a similar manner in the mid-17th century, remain two of the largest mosques on the Indian subcontinent.

The Umayyad Caliphate was particularly instrumental in spreading Islam and establishing mosques within the Levant, as the Umayyads constructed among the most revered mosques in the region — Al-Aqsa Mosque and Dome of the Rock in Jerusalem, and the Umayyad Mosque in Damascus. The designs of the Dome of the Rock and the Umayyad Mosque were influenced by Byzantine architecture, a trend that continued with the rise of the Ottoman Empire.

Several of the early mosques in the Ottoman Empire were originally churches or cathedrals from the Byzantine Empire, with the Hagia Sophia (one of those converted cathedrals) informing the architecture of mosques from after the Ottoman conquest of Constantinople. Still, the Ottomans developed their own architectural style characterized by large central rotundas (sometimes surrounded by multiple smaller domes), pencil-shaped minarets, and open facades.

Mosques from the Ottoman period are still scattered across Eastern Europe, but the most rapid growth in the number of mosques in Europe has occurred within the past century as more Muslims have migrated to the continent. Many major European cities are home to mosques, like the Grand Mosque of Paris, that incorporate domes, minarets, and other features often found with mosques in Muslim-majority countries. The first mosque in North America was founded by Albanian Americans in 1915, but the continent's oldest surviving mosque, the Mother Mosque of America, only dates back to the 1930s. As in Europe, the number of American mosques has rapidly increased in recent decades as Muslim immigrants, particularly from South Asia, have come in the United States. Greater than forty percent of mosques in the United States were constructed after 2000.

According to early Muslim historians, towns that surrendered without resistance and made treaties with the Muslims were allowed to retain their churches and the towns captured by Muslims had many of their churches converted to mosques. One of the earliest examples of these kinds of conversions was in Damascus, Syria, where in 705 Umayyad caliph Al-Walid I bought the church of St. John from the Christians and had it rebuilt as a mosque in exchange for building a number of new churches for the Christians in Damascus. Overall, Abd al-Malik ibn Marwan (Al-Waleed's father) is said to have transformed 10 churches in Damascus into mosques.

The process of turning churches into mosques were especially intensive in the villages where most of the inhabitants converted to Islam. The Abbasid caliph al-Ma'mun turned many churches into mosques. Ottoman Turks converted nearly all churches, monasteries, and chapels in Constantinople, including the famous Hagia Sophia, into mosques immediately after capturing the city in 1453. In some instances mosques have been established on the places of Jewish or Christian sanctuaries associated with Biblical personalities who were also recognized by Islam.

Mosques have also been converted for use by other religions, notably in southern Spain, following the conquest of the Moors in 1492. The most prominent of them is the Great Mosque of Cordoba. Outside of the Iberian Peninsula, such instances also occurred in southeastern Europe once regions were no longer under Muslim rule.

The "masjid jāmi‘" (), a central mosque, can play a role in religious activities such as teaching the Quran and educating future imams.

There are two holidays ("Eids") in the Islamic calendar: "ʻĪd al-Fiṭr" () and "ʿĪd al-Aḍḥā" (), during which there are special prayers held at mosques in the morning. These Eid prayers are supposed to be offered in large groups, and so, in the absence of an outdoor "Eidgah" (), a large mosque will normally host them for their congregants as well as the congregants of smaller local mosques. Some mosques will even rent convention centers or other large public buildings to hold the large number of Muslims who attend. Mosques, especially those in countries where Muslims are the majority, will also host Eid prayers outside in courtyards, town squares or on the outskirts of town in an "Eidgah".

Islam's holiest month, "Ramaḍān" (), is observed through many events. As Muslims must fast during the day during Ramadan, mosques will host "Ifṭār" () dinners after sunset and the fourth required prayer of the day, that is "Maghrib" (). Food is provided, at least in part, by members of the community, thereby creating daily potluck dinners. Because of the community contribution necessary to serve "iftar" dinners, mosques with smaller congregations may not be able to host the "iftar" dinners daily. Some mosques will also hold "Suḥūr" () meals before dawn to congregants attending the first required prayer of the day, "Fajr" (). As with iftar dinners, congregants usually provide the food for suhoor, although able mosques may provide food instead. Mosques will often invite poorer members of the Muslim community to share in beginning and breaking the fasts, as providing charity during Ramadan is regarded in Islam as especially honorable.
Following the last obligatory daily prayer ("‘Ishâ’" ()) special, optional "Ṫarâwîḥ" () prayers are offered in larger mosques. During each night of prayers, which can last for up to two hours each night, usually one member of the community who has memorized the entire Quran (a Hafiz) will recite a segment of the book. Sometimes, several such people (not necessarily of the local community) take turns to do this. During the last ten days of Ramadan, larger mosques will host all-night programs to observe Laylat al-Qadr, the night Muslims believe that Muhammad first received Quranic revelations. On that night, between sunset and sunrise, mosques employ speakers to educate congregants in attendance about Islam. Mosques or the community usually provide meals periodically throughout the night
During the last ten days of Ramadan, larger mosques within the Muslim community will host "I‘ṫikāf" (), a practice in which at least one Muslim man from the community must participate. Muslims performing itikaf are required to stay within the mosque for ten consecutive days, often in worship or learning about Islam. As a result, the rest of the Muslim community is responsible for providing the participants with food, drinks, and whatever else they need during their stay.

The third of the Five Pillars of Islam states that Muslims are required to give approximately one-fortieth of their wealth to charity as "Zakâṫ" (). Since mosques form the center of Muslim communities, they are where Muslims go to both give "zakat" and, if necessary, collect it. Before the holiday of "Eid ul-Fitr", mosques also collect a special "zakat" that is supposed to assist in helping poor Muslims attend the prayers and celebrations associated with the holiday.

The frequency by which Muslims attend mosque services vary greatly around the world. In some countries, weekly attendance at religious services are common among Muslims while in others, attendance is rare.

In the United States in particular, it has been shown in a study done by the Institute for Social Policy and Understanding that Muslim Americans who regularly attend mosques are more likely to work with their neighbors to solve community problems (49 vs. 30 percent), be registered to vote (74 vs. 49 percent), and plan to vote (92 vs. 81 percent). Overall, “there is no correlation between Muslim attitudes toward violence and their frequency of mosque attendance.” 

When it comes to mosque attendance, data shows that American Muslim women and American Muslim men attend the mosque at similar rates (45% for men and 35% for women). Additionally, when compared to the general public looking at the attendance of religious services, young Muslim Americans attend the mosque at closer rates to older Muslim Americans.

The late 20th century saw an increase in the number of mosques used for political purposes. Today, civic participation is commonly promoted in mosques in the Western world. Because of the importance in the community, mosques are used for preaching peaceful coexistence with non-believers, even in times of adversity.

Large mosques sometimes play a political role as well. In Islamic countries like Bangladesh, Pakistan, Iran, and Saudi Arabia, political subjects are preached by imams at Friday congregations on a regular basis. In other Islamic countries, imams are usually banned from mentioning political issues.

Countries with a minority Muslim population are more likely than Muslim-majority countries of the Greater Middle East to use mosques as a way to promote civic participation. American mosques host voter registration and civic participation drives that promote involving Muslims, who are often first- or second-generation immigrants, in the political process. As a result of these efforts as well as attempts at mosques to keep Muslims informed about the issues facing the Muslim community, regular mosque attendants are more likely to participate in protests, sign petitions, and otherwise be involved in politics.

Nevertheless, a link between political views and mosque attendance can still be seen in other parts of the world. Following the al-Askari Mosque bombing in February 2006, imams and other Islamic leaders used mosques and Friday prayers as vehicles to call for calm and peace in the midst of widespread violence.

As they are considered important to the Muslim community, mosques, like other places of worship, can be at the heart of social conflicts. The Babri Mosque was the subject of such a conflict up until the early 1990s when it was demolished. Before a mutual solution could be devised, the mosque was destroyed on December 6, 1992 as the mosque was built by Babur allegedly on the site of a previous Hindu temple marking the birthplace of Rama. The controversy surrounded the mosque was directly linked to rioting in Bombay (present-day Mumbai) as well as bombings in 1993 that killed 257 people.

Bombings in February 2006 and June 2007 seriously damaged Iraq's al-Askari Mosque and exacerbated existing tensions. Other mosque bombings in Iraq, both before and after the February 2006 bombing, have been part of the conflict between the country's groups of Muslims. However, mosque bombings have not been exclusive to Iraq; in June 2005, a suicide bomber killed at least 19 people at an Afghan Shia mosque near Jade Maivand. In April 2006, two explosions occurred at India's Jama Masjid.

Following the September 11 attacks, several American mosques were targeted in attacks ranging from simple vandalism to arson. Furthermore, the Jewish Defense League was suspected of plotting to bomb the King Fahd Mosque in Culver City, California. Similar attacks occurred throughout the United Kingdom following the 7 July 2005 London bombings. Outside the Western world, in June 2001, the Hassan Bek Mosque was the target of vandalism and attacks by hundreds of Israelis after a suicide bomber killed 19 people in a night club in Tel Aviv. Although mosquegoing is highly encouraged for men, it is permitted to stay at home when one feels at risk from Islamophobic persecution.

Although the Saudi involvement in Sunni mosques around the world can be traced back to the 1960s, it was not until later in the 20th century that the government of Saudi Arabia became a large influence in foreign Sunni mosques. Beginning in the 1980s, the Saudi Arabian government began to finance the construction of Sunni mosques in countries around the world. An estimated US$45 billion has been spent by the Saudi Arabian government financing mosques and Sunni Islamic schools in foreign countries. "Ain al-Yaqeen", a Saudi newspaper, reported in 2002 that Saudi funds may have contributed to building as many as 1,500 mosques and 2,000 other Islamic centers.

Saudi citizens have also contributed significantly to mosques in the Islamic world, especially in countries where they see Muslims as poor and oppressed. Following the fall of the Soviet Union, in 1992, mosques in war-torn Afghanistan saw many contributions from Saudi citizens. The King Fahd Mosque in Culver City, California and the Islamic Cultural Center of Italy in Rome represent two of Saudi Arabia's largest investments in foreign mosques as former Saudi king Fahd bin Abdul Aziz al-Saud contributed US$8 million and US$50 million to the two mosques, respectively.

In the western world, and in the United States in particular, Anti-Muslim sentiment and targeted domestic policy has created challenges for mosques and those looking to build them. There has been government and police surveillance of mosques in the US and local attempts to ban mosques and block constructions, despite data showing that in fact, most Americans opposing banning the building of mosques (79%) and the surveillance of U.S. mosques (63%) as shown in a 2018 study done by the Institute for Social Policy and Understanding.

"Arab-plan" or hypostyle mosques are the earliest type of mosques, pioneered under the Umayyad Dynasty. These mosques have square or rectangular plans with an enclosed courtyard and covered prayer hall. Historically, in the warm Middle Eastern and Mediterranean climates, the courtyard served to accommodate the large number of worshippers during Friday prayers. Most early hypostyle mosques had flat roofs on prayer halls, which required the use of numerous columns and supports. One of the most notable hypostyle mosques is the Great Mosque of Cordoba in Spain, the building being supported by over 850 columns. Frequently, hypostyle mosques have outer arcades so that visitors can enjoy the shade. Arab-plan mosques were constructed mostly under the Umayyad and Abbasid dynasties; subsequently, however, the simplicity of the Arab plan limited the opportunities for further development, the mosques consequently losing popularity.

The first departure within mosque design started in Persia (Iran). The Persians had inherited a rich architectural legacy from the earlier Persian dynasties, and they began incorporating elements from earlier Parthian and Sassanid designs into their mosques, influenced by buildings such as the Palace of Ardashir and the Sarvestan Palace. Thus, Islamic architecture witnessed the introduction of such structures as domes and large, arched entrances, referred to as "iwans". During Seljuq rule, as Islamic mysticism was on the rise, the four-iwan arrangement took form. The four-iwan format, finalized by the Seljuqs, and later inherited by the Safavids, firmly established the courtyard façade of such mosques, with the towering gateways at every side, as more important than the actual buildings themselves. They typically took the form of a square-shaped central courtyard with large entrances at each side, giving the impression of gateways to the spiritual world. The Persians also introduced Persian gardens into mosque designs. Soon, a distinctly Persian style of mosques started appearing that would significantly influence the designs of later Timurid, and also Mughal, mosque designs.

The Ottomans introduced central dome mosques in the 15th century. These mosques have a large dome centered over the prayer hall. In addition to having a large central dome, a common feature is smaller domes that exist off-center over the prayer hall or throughout the rest of the mosque, where prayer is not performed. This style was heavily influenced by Byzantine architecture with its use of large central domes. Hajja Soad's mosque took a pyramid shape that is a creative style in Islamic architecture.

The Faisal Mosque in Islamabad, Pakistan, in a relatively unusual design fuses contemporary lines with the more traditional look of an Arab Bedouin's tent, with its large triangular prayer hall and four minarets. However, unlike traditional mosque design, it lacks a dome. The mosque's architecture is a departure from the long history of South Asian Islamic architecture.

Mosques built in Southeast Asia often represent the Indonesian-Javanese style architecture, which are different from the ones found throughout the Greater Middle East. The ones found in Europe and North America appear to have various styles but most are built on Western architectural designs, some are former churches or other buildings that were used by non-Muslims. In Africa, most mosques are old but the new ones are built in imitation of those of the Middle East. This can be seen in the Abuja National Mosque in Nigeria and others.

A common feature in mosques is the minaret, the tall, slender tower that usually is situated at one of the corners of the mosque structure. The top of the minaret is always the highest point in mosques that have one, and often the highest point in the immediate area. The tallest minaret in the world is located at the Hassan II Mosque in Casablanca, Morocco. It has a height of and completed in 1993, it was designed by Michel Pinseau.
The first mosques had no minarets, and even nowadays the most conservative Islamic movements, like Wahhabis, avoid building minarets, seeing them as ostentatious and hazardous in case of collapse. The first minaret was constructed in 665 in Basra during the reign of the Umayyad caliph Muawiyah I. Muawiyah encouraged the construction of minarets, as they were supposed to bring mosques on par with Christian churches with their bell towers. Consequently, mosque architects borrowed the shape of the bell tower for their minarets, which were used for essentially the same purpose—calling the faithful to prayer. The oldest standing minaret in the world is the minaret of the Great Mosque of Kairouan in Tunisia, built between the 8th and the 9th century, it is a massive square tower consisting of three superimposed tiers of gradual size and decor.

Before the five required daily prayers, a "Mu’adhdhin" () calls the worshippers to prayer from the minaret. In many countries like Singapore where Muslims are not the majority, mosques are prohibited from loudly broadcasting the "Adhān" (, Call to Prayer), although it is supposed to be said loudly to the surrounding community. The "adhan" is required before every prayer. However, nearly every mosque assigns a "muezzin" for each prayer to say the "adhan" as it is a recommended practice or "Sunnah" () of the Islamic prophet Muhammad. At mosques that do not have minarets, the "adhan" is called instead from inside the mosque or somewhere else on the ground. The "Iqâmah" (), which is similar to the "adhan" and said immediately before the start of prayer, is usually not said from the minaret even if a mosque has one.
A "miḥrāb" (), also spelled as "mehrab" is a semicircular niche in the wall of a mosque that indicates the "qiblah" (, the direction of the Kaaba) in Mecca, and hence the direction that Muslims should face when praying. The wall in which a "mihrab" appears is thus the ""qibla" wall." "Mihrab"s should not be confused with the "minbar" (), which is the raised platform from which an Imam (leader of prayer) addresses the congregation.

The domes, often placed directly above the main prayer hall, may signify the vaults of the heaven and sky. As time progressed, domes grew, from occupying a small part of the roof near the mihrab to encompassing the whole roof above the prayer hall. Although domes normally took on the shape of a hemisphere, the Mughals in India popularized onion-shaped domes in South Asia which has gone on to become characteristic of the Arabic architectural style of dome. Some mosques have multiple, often smaller, domes in addition to the main large dome that resides at the center.

The prayer hall, also known as the "muṣallá" (), rarely has furniture; chairs and pews are generally absent from the prayer hall so as to allow as many worshipers as possible to line the room. Some mosques have Islamic calligraphy and Quranic verses on the walls to assist worshippers in focusing on the beauty of Islam and its holiest book, the Quran, as well as for decoration.
Often, a limited part of the prayer hall is sanctified formally as a masjid in the sharia sense (although the term masjid is also used for the larger mosque complex as well). Once designated, there are onerous limitations on the use of this formally designated masjid, and it may not be used for any purpose other than worship; restrictions that do not necessarily apply to the rest of the prayer area, and to the rest of the mosque complex (although such uses may be restricted by the conditions of the "waqf" that owns the mosque).

In many mosques, especially the early congregational mosques, the prayer hall is in the hypostyle form (the roof held up by a multitude of columns). One of the finest examples of the hypostyle-plan mosques is the Great Mosque of Kairouan (also known as the Mosque of Uqba) in Tunisia.

Usually opposite the entrance to the prayer hall is the "qiblah" wall, the visually emphasized area inside the prayer hall. The qiblah wall should, in a properly oriented mosque, be set perpendicular to a line leading to Mecca, the location of the Kaaba. Congregants pray in rows parallel to the qiblah wall and thus arrange themselves so they face Mecca. In the qiblah wall, usually at its center, is the mihrab, a niche or depression indicating the direction of Mecca. Usually the mihrab is not occupied by furniture either. Sometimes, especially during Friday prayers, a raised "minbar" or pulpit is located to the side of the mihrab for a "Khaṭīb" (), or some other speaker to offer a "Khuṭbah" (, Sermon). The mihrab serves as the location where the imam leads the five daily prayers on a regular basis.

As ritual purification precedes all prayers, mosques often have ablution fountains or other facilities for washing in their entryways or courtyards. However, worshippers at much smaller mosques often have to use restrooms to perform their ablutions. In traditional mosques, this function is often elaborated into a freestanding building in the center of a courtyard. This desire for cleanliness extends to the prayer halls where shoes are disallowed to be worn anywhere other than the cloakroom. Thus, foyers with shelves to put shoes and racks to hold coats are commonplace among mosques.

Modern mosques have a variety of amenities available to their congregants. As mosques are supposed to appeal to the community, they may also have additional facilities, from health clinics to libraries to gymnasiums, to serve the community.

Certain symbols are represented in a mosque's architecture to allude to different aspects of the Islamic religion. One of these feature symbols is the spiral. The "cosmic spiral" found in designs and on minarets is a references to heaven as it has "no beginning and no end". Mosques also often have floral patterns or images of fruit and vegetables. These are allusions to the paradise after death.

Mosques, in accordance with Islamic practices, institute a number of rules intended to keep Muslims focused on worshiping God. While there are several rules, such as those regarding not allowing shoes in the prayer hall, that are universal, there are many other rules that are dealt with and enforced in a variety of ways from mosque to mosque.

Appointment of a prayer leader is considered desirable, but not always obligatory. The permanent prayer leader (imam) must be a free honest individual and is authoritative in religious matters. In mosques constructed and maintained by the government, the prayer leader is appointed by the ruler; in private mosques, however, appointment is made by members of the congregation through majority voting. According to the Hanafi school of Islamic jurisprudence, the individual who built the mosque has a stronger claim to the title of imam, but this view is not shared by the other schools.

Leadership at prayer falls into three categories, depending on the type of prayer: five daily prayers, Friday prayer, or optional prayers. According to the Hanafi and Maliki school of Islamic jurisprudence, appointment of a prayer leader for Friday service is mandatory because otherwise the prayer is invalid. The Shafi'i and Hanbali schools, however, argue that the appointment is not necessary and the prayer is valid as long as it is performed in a congregation. A slave may lead a Friday prayer, but Muslim authorities disagree over whether the job can be done by a minor. An imam appointed to lead Friday prayers may also lead at the five daily prayers; Muslim scholars agree to the leader appointed for five daily services may lead the Friday service as well.

All Muslim authorities hold the consensus opinion that only men may lead prayer for men. Nevertheless, women prayer leaders are allowed to lead prayer in front of all-female congregations.

All mosques have rules regarding cleanliness, as it is an essential part of the worshippers' experience. Muslims before prayer are required to cleanse themselves in an ablution process known as "wudu". However, even to those who enter the prayer hall of a mosque without the intention of praying, there are still rules that apply. Shoes must not be worn inside the carpeted prayer hall. Some mosques will also extend that rule to include other parts of the facility even if those other locations are not devoted to prayer. Congregants and visitors to mosques are supposed to be clean themselves. It is also undesirable to come to the mosque after eating something that smells, such as garlic.

Islam requires that its adherents wear clothes that portray modesty. Men are supposed to come to the mosque wearing loose and clean clothes that do not reveal the shape of the body. Likewise, it is recommended that women at a mosque wear loose clothing that covers to the wrists and ankles, and cover their heads with a "Ḥijāb" (), or other covering. Many Muslims, regardless of their ethnic background, wear Middle Eastern clothing associated with Arabic Islam to special occasions and prayers at mosques.

As mosques are places of worship, those within the mosque are required to remain respectful to those in prayer. Loud talking within the mosque, as well as discussion of topics deemed disrespectful, is forbidden in areas where people are praying. In addition, it is disrespectful to walk in front of or otherwise disturb Muslims in prayer. The walls within the mosque have few items, except for possibly Islamic calligraphy, so Muslims in prayer are not distracted. Muslims are also discouraged from wearing clothing with distracting images and symbols so as not to divert the attention of those standing behind them during prayer. In many mosques, even the carpeted prayer area has no designs, its plainness helping worshippers to focus.

There is nothing written in the Qurʼan about the issue of space in mosques and gender separation. However, traditional rules have segregated women and men. By traditional rules, women are most often told to occupy the rows behind the men. In part, this was a practical matter as the traditional posture for prayerkneeling on the floor, head to the groundmade mixed-gender prayer uncomfortably revealing for many women and distracting for some men. Traditionalists try to argue that Muhammad preferred women to pray at home rather than at a mosque, and they cite a "ḥadīth" () in which Muhammad supposedly said: "The best mosques for women are the inner parts of their houses," although women were active participants in the mosque started by Muhammad. Muhammad told Muslims not to forbid women from entering mosques. They are allowed to go in. The second Sunni caliph ʻUmar at one time prohibited women from attending mosques especially at night because he feared they may be sexually harassed or assaulted by men, so he required them to pray at home. Sometimes a special part of the mosque was railed off for women; for example, the governor of Mecca in 870 had ropes tied between the columns to make a separate place for women.

Many mosques today will put the women behind a barrier or partition or in another room. Mosques in South and Southeast Asia put men and women in separate rooms, as the divisions were built into them centuries ago. In nearly two-thirds of American mosques, women pray behind partitions or in separate areas, not in the main prayer hall; some mosques do not admit women at all due to the lack of space and the fact that some prayers, such as the Friday Jumuʻah, are mandatory for men but optional for women. Although there are sections exclusively for women and children, the Grand Mosque in Mecca is desegregated.

Under most interpretations of "sharia", non-Muslims are permitted to enter mosques provided that they respect the place and the people inside it. A dissenting opinion and minority view is presented by followers of the Maliki school of Islamic jurisprudence, who argue that non-Muslims may not be allowed into mosques under any circumstances.

The Quran addresses the subject of non-Muslims, and particularly polytheists, in mosques in two verses in its ninth chapter, Sura At-Tawba. The seventeenth verse of the chapter prohibits those who "join gods with Allah"—polytheists—from entering mosques:
The twenty-eighth verse of the same chapter is more specific as it only considers polytheists in the Sacred Mosque, the Masjid al-Haram in Mecca:
According to Ahmad ibn Hanbal, these verses were followed to the letter at the times of Muhammad, when Jews and Christians, considered monotheists, were still allowed to the Masjid al-Haram. However, the Umayyad caliph Umar II later forbade non-Muslims from entering mosques, and his ruling remains in practice in present-day Saudi Arabia. Today, the decision on whether non-Muslims should be allowed to enter mosques varies. With few exceptions, mosques in the Arabian Peninsula as well as Morocco do not allow entry to non-Muslims. For example, the Hassan II Mosque in Casablanca is one of only two mosques in Morocco currently open to non-Muslims.

However, there are also many other places in the West as well as the Islamic world where non-Muslims are welcome to enter mosques. Most mosques in the United States, for example, report receiving non-Muslim visitors every month. Many mosques throughout the United States welcome non-Muslims as a sign of openness to the rest of the community as well as to encourage conversions to Islam.

In modern-day Saudi Arabia, the Grand Mosque and all of Mecca are open only to Muslims. Likewise, the Al-Masjid al-Nabawi and the city of Medina that surrounds it are also off-limits to those who do not practice Islam. For mosques in other areas, it has most commonly been taken that non-Muslims may only enter mosques if granted permission to do so by Muslims and if they have a legitimate reason. All entrants regardless of religious affiliation are expected to respect the rules and decorum for mosques.

In modern Turkey, non-Muslim tourists are allowed to enter any mosque, but there are some strict rules. Visiting a mosque is allowed only between prayers; visitors are required to wear long trousers and not to wear shoes, women must cover their heads; visitors are not allowed to interrupt praying Muslims, especially by taking photos of them; no loud talk is allowed; and no references to other religions are allowed (no crosses on necklaces, no cross gestures, etc.) Similar rules apply to mosques in Malaysia, where larger mosques that are also tourist attractions (such as the Masjid Negara) provide robes and headscarves for visitors who are deemed inappropriately attired.

In certain times and places, non-Muslims were expected to behave a certain way in the vicinity of a mosque: in some Moroccan cities, Jews were required to remove their shoes when passing by a mosque; in 18th-century Egypt, Jews and Christians had to dismount before several mosques in veneration of their sanctity.

The association of the mosque with education remained one of its main characteristics throughout history, and the school became an indispensable appendage to the mosque. From the earliest days of Islam, the mosque was the center of the Muslim community, a place for prayer, meditation, religious instruction, political discussion, and a school. Anywhere Islam took hold, mosques were established; and basic religious and educational instruction began.






</doc>
<doc id="19895" url="https://en.wikipedia.org/wiki?curid=19895" title="Molecular cloud">
Molecular cloud

A molecular cloud, sometimes called a stellar nursery (if star formation is occurring within), is a type of interstellar cloud, the density and size of which permit the formation of molecules, most commonly molecular hydrogen (H). This is in contrast to other areas of the interstellar medium that contain predominantly ionized gas.

Molecular hydrogen is difficult to detect by infrared and radio observations, so the molecule most often used to determine the presence of H is carbon monoxide (CO). The ratio between CO luminosity and H mass is thought to be constant, although there are reasons to doubt this assumption in observations of some other galaxies.

Within molecular clouds are regions with higher density, where lots of dust and gas cores reside, called clumps. These clumps are the beginning of star formation, if gravity can overcome the high density and force the dust and gas to collapse.

Within the Milky Way, molecular gas clouds account for less than one percent of the volume of the interstellar medium (ISM), yet it is also the densest part of the medium, comprising roughly half of the total gas mass interior to the Sun's galactic orbit. The bulk of the molecular gas is contained in a ring between from the center of the Milky Way (the Sun is about 8.5 kiloparsecs from the center). Large scale CO maps of the galaxy show that the position of this gas correlates with the spiral arms of the galaxy. That molecular gas occurs predominantly in the spiral arms suggests that molecular clouds must form and dissociate on a timescale shorter than 10 million years—the time it takes for material to pass through the arm region.
Vertically to the plane of the galaxy, the molecular gas inhabits the narrow midplane of the galactic disc with a characteristic scale height, "Z", of approximately 50 to 75 parsecs, much thinner than the warm atomic ("Z "from 130 to 400 parsecs) and warm ionized ("Z "around 1000 parsecs) gaseous components of the ISM. The exception to the ionized-gas distribution are H II regions, which are bubbles of hot ionized gas created in molecular clouds by the intense radiation given off by young massive stars and as such they have approximately the same vertical distribution as the molecular gas.

This distribution of molecular gas is averaged out over large distances; however, the small scale distribution of the gas is highly irregular with most of it concentrated in discrete clouds and cloud complexes.

A vast assemblage of molecular gas with a mass of approximately 10 to 10 times the mass of the Sun is called a giant molecular cloud (GMC). GMCs are around 15 to 600 light-years in diameter (5 to 200 parsecs). Whereas the average density in the solar vicinity is one particle per cubic centimetre, the average density of a GMC is a hundred to a thousand times as great. Although the Sun is much more dense than a GMC, the volume of a GMC is so great that it contains much more mass than the Sun. The substructure of a GMC is a complex pattern of filaments, sheets, bubbles, and irregular clumps.

The densest parts of the filaments and clumps are called "molecular cores", while the densest molecular cores are called "dense molecular cores" and have densities in excess of 10 to 10 particles per cubic centimeter. Observationally, typical molecular cores are traced with CO and dense molecular cores are traced with ammonia. The concentration of dust within molecular cores is normally sufficient to block light from background stars so that they appear in silhouette as dark nebulae.

GMCs are so large that "local" ones can cover a significant fraction of a constellation; thus they are often referred to by the name of that constellation, e.g. the Orion Molecular Cloud (OMC) or the Taurus Molecular Cloud (TMC). These local GMCs are arrayed in a ring in the neighborhood of the Sun coinciding with the Gould Belt. The most massive collection of molecular clouds in the galaxy forms an asymmetrical ring about the galactic center at a radius of 120 parsecs; the largest component of this ring is the Sagittarius B2 complex. The Sagittarius region is chemically rich and is often used as an exemplar by astronomers searching for new molecules in interstellar space.

Isolated gravitationally-bound small molecular clouds with masses less than a few hundred times that of the Sun are called Bok globules. The densest parts of small molecular clouds are equivalent to the molecular cores found in GMCs and are often included in the same studies.

In 1984 IRAS identified a new type of diffuse molecular cloud. These were diffuse filamentary clouds that are visible at high galactic latitudes. These clouds have a typical density of 30 particles per cubic centimeter.

The formation of stars occurs exclusively within molecular clouds. This is a natural consequence of their low temperatures and high densities, because the gravitational force acting to collapse the cloud must exceed the internal pressures that are acting "outward" to prevent a collapse. There is observed evidence that the large, star-forming clouds are confined to a large degree by their own gravity (like stars, planets, and galaxies) rather than by external pressure. The evidence comes from the fact that the "turbulent" velocities inferred from CO linewidth scale in the same manner as the orbital velocity (a virial relation).

The physics of molecular clouds is poorly understood and much debated. Their internal motions are governed by turbulence in a cold, magnetized gas, for which the turbulent motions are highly supersonic but comparable to the speeds of magnetic disturbances. This state is thought to lose energy rapidly, requiring either an overall collapse or a steady reinjection of energy. At the same time, the clouds are known to be disrupted by some process—most likely the effects of massive stars—before a significant fraction of their mass has become stars.

Molecular clouds, and especially GMCs, are often the home of astronomical masers.


</doc>
<doc id="19897" url="https://en.wikipedia.org/wiki?curid=19897" title="Minoru Yamasaki">
Minoru Yamasaki

Minoru Yamasaki (December 1, 1913February 6, 1986) was an American architect, best known for designing the original World Trade Center in New York City and several other large-scale projects. Yamasaki was one of the most prominent architects of the 20th century. He and fellow architect Edward Durell Stone are generally considered to be the two master practitioners of "New Formalism".

Yamasaki was born in Seattle, Washington, the son of John Tsunejiro Yamasaki and Hana Yamasaki, Japanese descendants. The family later moved to Auburn, Washington and he graduated from Garfield Senior High School in Seattle. He enrolled in the University of Washington program in architecture in 1929, and graduated with a Bachelor of Architecture (B.Arch.) in 1934. During his college years, he was strongly encouraged by faculty member Lionel Pries. He earned money to pay for his tuition by working at an Alaskan salmon cannery.

After moving to New York City in the 1930s, he enrolled at New York University for a master's degree in architecture and got a job with the architecture firm Shreve, Lamb & Harmon, designers of the Empire State Building. In 1945, Yamasaki moved to Detroit, where he was hired by Smith, Hinchman & Grylls. The firm helped Yamasaki avoid internment as a Japanese-American during World War II, and he himself sheltered his parents in New York City. Yamasaki left the firm in 1949, and started his own partnership. One of the first projects he designed at his own firm was Ruhl's Bakery at 7 Mile Road and Monica Street in Detroit. In 1964, Yamasaki received a D.F.A. from Bates College.

His firm, Yamasaki & Associates, closed on December 31, 2009.

His first internationally recognized design, the Pacific Science Center with its iconic arches, was constructed by the City of Seattle for the 1962 Seattle World's Fair. His first significant project was the Pruitt–Igoe housing project in St. Louis, Missouri, 1955. Despite his love of Japanese traditional design, this was a stark, modernist concrete structure. The housing project experienced so many problems that it was demolished in 1972, less than twenty years after its completion. Its destruction is considered by some to be the beginning of postmodern architecture.

In 1955, he also designed the "sleek" terminal at Lambert–St. Louis International Airport which led to his 1959 commission to design the Dhahran International Airport in Saudi Arabia. In the 1950s, Yamasaki was commissioned by the Reynolds Company to design an aluminum-wrapped building in Southfield, Michigan, which would "symbolize the auto industry's past and future progress with aluminum." The three-story glass building wrapped in aluminum, known as the Reynolds Metals Company's Great Lakes Sales Headquarters Building, was also supposed to reinforce the company's main product and showcase its admirable characteristics of strength and beauty. During this period, he created a number of office buildings which led to his innovative design of the towers of the World Trade Center in 1964, which began construction March 21, 1966. The first of the towers was finished in 1970. Many of his buildings feature superficial details inspired by the pointed arches of Gothic architecture, and make use of extremely narrow vertical windows. This narrow-windowed style arose from his own personal fear of heights. One particular design challenge of the World Trade Center's design related to the efficacy of the elevator system, which was unique in the world. Yamasaki integrated the fastest elevators at the time, running at 1,700 feet per minute. Instead of placing a large traditional elevator shaft in the core of each tower, Yamasaki created the Twin Towers' "Skylobby" system. The Skylobby design created three separate, connected elevator systems which would serve different segments of the building, depending on which floor was chosen, saving approximately 70% of the space used for a traditional shaft. The space saved was then used for office space.

In 1978, Yamasaki designed the Federal Reserve Bank tower in Richmond, Virginia. The work was designed with a similar appearance as the World Trade Center complex, with its narrow fenestration, and now stands at .

Yamasaki was a member of the Pennsylvania Avenue Commission, created in 1961 to restore the grand avenue in Washington, D.C., but resigned after disagreements and disillusionment with the design by committee approach.

After partnering with Emery Roth and Sons on the design of the World Trade Center, they collaborated on other projects including new buildings at Bolling Air Force Base in Washington, D.C.

The campus for the University of Regina was designed in tandem with Yamasaki's plan for Wascana Centre, a park built around Wascana Lake in Regina, Saskatchewan. The original campus design was approved in 1962. Yamasaki was awarded contracts to design the first three buildings: the Classroom Building; the Laboratory Building; and the Dr. John Archer Library, which were built between 1963 and 1967.

Yamasaki designed two notable synagogues during this period, North Shore Congregation Israel in Glencoe, Illinois in 1964 and Temple Beth El, in Bloomfield Hills, Michigan in 1973. He designed a number of buildings on the campus of Carleton College in Northfield, Minnesota between 1958 and 1968.

Yamasaki was first married in 1941 and had two other marriages before remarrying his first wife in 1969. He died of stomach cancer in 1986. His son, Taro Yamasaki, is a Pulitzer Prize-winning photographer.






</doc>
<doc id="19898" url="https://en.wikipedia.org/wiki?curid=19898" title="Madeira">
Madeira

Madeira ( , ; ) is a Portuguese archipelago situated in the north Atlantic Ocean, southwest of Portugal. Its total population was estimated in 2011 at 267,785. The capital of Madeira is Funchal, which is located on the main island's south coast.

The archipelago is just under north of Tenerife, Canary Islands. Bermuda and Madeira, a few time zones apart, are the only land in the Atlantic on the 32nd parallel north. Since 1976, the archipelago has been one of the two autonomous regions of Portugal (the other being the Azores, located to the northwest). It includes the islands of Madeira, Porto Santo, and the Desertas, administered together with the separate archipelago of the Savage Islands. The region has political and administrative autonomy through the Administrative Political Statue of the Autonomous Region of Madeira provided for in the Portuguese Constitution. The autonomous region is an integral part of the European Union, having pronounced status as an outermost region of the European Union, as detailed in Article 299-2 of the Treaty of the European Union.

Madeira was claimed by Portuguese sailors in the service of Prince Henry the Navigator in 1419 and settled after 1420. The archipelago is considered to be the first territorial discovery of the exploratory period of the Age of Discovery.

Today, it is a popular year-round resort, being visited every year by about 1.4 million tourists, almost five times its population. The region is noted for its Madeira wine, gastronomy, historical and cultural value, flora and fauna, landscapes (Laurel forest) which are classified as a UNESCO World Heritage Site, and embroidery artisans. Guinness World Records attributed to the 8-minute fireworks show that marked the passing of the year in Madeira, from 2006 to 2007, the title of 'Greatest Fireworks Show in the World' which it held this title until 2012. The main harbour in Funchal has long been the leading Portuguese port in cruise liner dockings, receiving more than half a million tourists though its main port in 2017, being an important stopover for commercial and trans-Atlantic passenger cruises between Europe, the Caribbean and North Africa. In addition, the International Business Centre of Madeira also known as the Madeira Free Trade Zone, was created formally in the 1980s as a tool of regional economic policy. It consists of a set of incentives, mainly tax-related, granted with the objective of attracting foreign direct investment based on international services into Madeira.

In 2018 the island of Madeira was for the fifth time named Europe’s Leading Island Destination by the World Travel Awards considered to be the 'Oscars of Tourism' according to the Wall Street Journal.

Plutarch in his "Parallel Lives" ("Sertorius", 75 AD) referring to the military commander Quintus Sertorius (d. 72 BC), relates that after his return to Cádiz, he met sailors who spoke of idyllic Atlantic islands: "The islands are said to be two in number separated by a very narrow strait and lie 10,000 furlongs (2,011.68 km) from Africa. They are called the Isles of the Blest."

Archeological evidence suggests that the islands may have been visited by the Vikings sometime between 900 and 1030.

During the reign of King Edward III of England, lovers Robert Machim and Anna d'Arfet were said to flee from England to France in 1346. They were driven off their course by a violent storm and their ship went aground along the coast of an island that may have been Madeira. Later this legend was the basis of the naming of the city of Machico, in memory of the young lovers.

Knowledge of some Atlantic islands, such as Madeira, existed before their formal discovery and settlement, as the islands were shown on maps as early as 1339.
In 1418, two captains under service to Prince Henry the Navigator, João Gonçalves Zarco and Tristão Vaz Teixeira, were driven off course by a storm to an island which they named Porto Santo (English: "holy harbour") in gratitude for divine deliverance from a shipwreck. The following year, an organised expedition, under the captaincy of Zarco, Vaz Teixeira, and Bartolomeu Perestrello, traveled to the island to claim it on behalf of the Portuguese Crown. Subsequently, the new settlers observed "a heavy black cloud suspended to the southwest." Their investigation revealed it to be the larger island they called Madeira.

The first Portuguese settlers began colonizing the islands around 1420 or 1425.

Grain production began to fall and the ensuing crisis forced Henry the Navigator to order other commercial crops to be planted so that the islands could be profitable. These specialised plants, and their associated industrial technology, created one of the major revolutions on the islands and fuelled Portuguese industry. Following the introduction of the first water-driven sugar mill on Madeira, sugar production increased to over 6,000 "arrobas" (an "arroba" was equal to 11 to 12 kilograms) by 1455, using advisers from Sicily and financed by Genoese capital. (Genoa acted as an integral part of the island economy until the 17th century.) The accessibility of Madeira attracted Genoese and Flemish traders, who were keen to bypass Venetian monopolies.

Sugarcane production was the primary engine of the island's economy, increasing the demand for labour. African slaves were used during portions of the island's history to cultivate sugar cane, and the proportion of imported slaves reached 10% of the total population of Madeira by the 16th century.

Barbary corsairs from North Africa, who enslaved Europeans from ships and coastal communities throughout the Mediterranean region, captured 1,200 people in Porto Santo in 1617. After the 17th century, as Portuguese sugar production was shifted to Brazil, São Tomé and Príncipe and elsewhere, Madeira's most important commodity product became its wine.

The British first amicably occupied the island in 1801 whereafter Colonel William Henry Clinton became governor. A detachment of the 85th Regiment of Foot under Lieutenant-colonel James Willoughby Gordon garrisoned the island.
After the Peace of Amiens, British troops withdrew in 1802, only to reoccupy Madeira in 1807 until the end of the Peninsular War in 1814.

On 31 December 1916, during the Great War, a German U-boat, , captained by Max Valentiner, entered Funchal harbour on Madeira. "U-38" torpedoed and sank three ships, bringing the war to Portugal by extension. The ships sunk were:

After attacking the ships, "U-38" bombarded Funchal for two hours from a range of about . Batteries on Madeira returned fire and eventually forced "U-38" to withdraw.

On 12 December 1917, two German U-boats, "SM U-156" and "SM U-157" (captained by Max Valentiner), again bombarded Funchal. This time the attack lasted around 30 minutes. The U-boats fired 40 shells. There were three fatalities and 17 wounded; a number of houses and Santa Clara church were hit.

Charles I (Karl I), the last Emperor of the Austro-Hungarian Empire, went to Madeira after the war. Determined to prevent an attempt to restore Charles to the throne, the Council of Allied Powers agreed he could go into exile on Madeira because it was isolated in the Atlantic and easily guarded. He died there on 1 April 1922 and his coffin lies in a chapel of the church in Monte.

On 1 July 1976, following the democratic revolution of 1974, Portugal granted political autonomy to Madeira, celebrated on Madeira Day. The region now has its own government and legislative assembly. 

On 20 February 2010 at least 42 people died and 100 were injured by an extreme weather event that affected the Island.
Drought conditions, coupled with hot and windy weather in summer, have caused numerous wildfires in recent years. The largest of the fires in August 2010 burned through 95 percent of the Funchal Ecological Park, a 1,000-hectare preserve set aside to restore native vegetation to the island.

In July 2012 Madeira was suffering again from severe drought. Wildfires broke out on 18 July, in the midst of temperatures up to 40 °C (more than 100 °F) and high winds. By 20 July, fires had spread to the nearby island of Porto Santo, and firefighters were sent from mainland Portugal to contain the multiple blazes.

In October 2012, it was reported that there was a dengue fever epidemic on the island. There was a total of 2,168 cases reported of dengue fever since the start in October 2012. The number of cases was on the decline since mid November 2012 and by 4 February 2013, no new cases had been reported.

In August 2013, a hospital and some private homes were evacuated as a wildfire approached Funchal. A number of homes were destroyed when the fire hit Monte, a suburb of Funchal.

In August 2016, wildfires caused over 1,000 people to be evacuated, destroyed 150 homes, and led to the death of three people, all of whom are said to have been elderly. The wildfires threatened Funchal and other administrative regions of Madeira, such as Calheta.

In August 2017, a falling tree killed at least 13 people and injured 49 at a religious ceremony. People had gathered outside the Church of Our Lady of Monte in Monte, to celebrate the Roman Catholic Feast of the Assumption, which takes place on Tuesday and is a public holiday. The Lady of the Mount festival is the island's biggest.

In 2019 Madeira island celebrates six centuries since its formal discovery by the Portuguese, an event expected to be widely celebrated. It will also host the World Travel Awards Europe Gala Ceremony 2019, an event expected to boost its profile on the global stage of the tourism industry.

The archipelago of Madeira is located from the African coast and from the European continent (approximately a one-and-a-half hour flight from the Portuguese capital of Lisbon). Madeira is on the same parallel as Bermuda a few time zones farther west in the Atlantic. The two archipelagos are the only land in the Atlantic on the 32nd parallel north. Madeira is found in the extreme south of the Tore-Madeira Ridge, a bathymetric structure of great dimensions oriented along a north-northeast to south-southwest axis that extends for . This submarine structure consists of long geomorphological relief that extends from the abyssal plain to 3500 metres; its highest submersed point is at a depth of about 150 metres (around latitude 36ºN). The origins of the Tore-Madeira Ridge are not clearly established, but may have resulted from a morphological "buckling" of the lithosphere.

Madeira (740.7 km²), including Ilhéu de Agostinho, Ilhéu de São Lourenço, Ilhéu Mole (northwest); Total population: 262,456 (2011 Census).

Porto Santo (42.5 km²), including Ilhéu de Baixo ou da Cal, Ilhéu de Ferro, Ilhéu das Cenouras, Ilhéu de Fora, Ilhéu de Cima; Total population: 5483 (2011 Census).

Desertas Islands (14.2 km²), including the three uninhabited islands: Deserta Grande Island, Bugio Island and Ilhéu de Chão;

Savage Islands (3.6 km²), archipelago 280 km south-southeast of Madeira Island including three main islands and 16 uninhabited islets in two groups: the Northwest Group (Selvagem Grande Island, Ilhéu de Palheiro da Terra, Ilhéu de Palheiro do Mar) and the Southeast Group (Selvagem Pequena Island, Ilhéu Grande, Ilhéu Sul, Ilhéu Pequeno, Ilhéu Fora, Ilhéu Alto, Ilhéu Comprido, Ilhéu Redondo, Ilhéu Norte).

The island of Madeira is at the top of a massive shield volcano that rises about from the floor of the Atlantic Ocean, on the Tore underwater mountain range. The volcano formed atop an east-west rift in the oceanic crust along the African Plate, beginning during the Miocene epoch over 5 million years ago, continuing into the Pleistocene until about 700,000 years ago. This was followed by extensive erosion, producing two large amphitheatres open to south in the central part of the island. Volcanic activity later resumed, producing scoria cones and lava flows atop the older eroded shield. The most recent volcanic eruptions were on the west-central part of the island only 6,500 years ago, creating more cinder cones and lava flows.

It is the largest island of the group with an area of , a length of (from Ponte de São Lourenço to Ponte do Pargo), while approximately at its widest point (from Ponte da Cruz to Ponte São Jorge), with a coastline of . It has a mountain ridge that extends along the centre of the island, reaching at its highest point (Pico Ruivo), while much lower (below 200 metres) along its eastern extent. The primitive volcanic foci responsible for the central mountainous area, consisted of the peaks: Ruivo (1,862 m), Torres (1,851 m), Arieiro (1,818 m), Cidrão (1,802 m), Cedro (1,759 m), Casado (1,725 m), Grande (1,657 m), Ferreiro (1,582 m). At the end of this eruptive phase, an island circled by reefs was formed, its marine vestiges are evident in a calcareous layer in the area of Lameiros, in São Vicente (which was later explored for calcium oxide production). Sea cliffs, such as Cabo Girão, valleys and ravines extend from this central spine, making the interior generally inaccessible. Daily life is concentrated in the many villages at the mouths of the ravines, through which the heavy rains of autumn and winter usually travel to the sea.

Madeira has been classified as a Mediterranean climate (Köppen climate classification: "Csa"/"Csb"). Based on differences in sun exposure, humidity, and annual mean temperature, there are clear variations between north- and south-facing regions, as well as between some islands. The islands are strongly influenced by the Gulf Stream and Canary Current, giving mild year-round temperatures; according to the Instituto de Meteorologia (IM), the average annual temperature at Funchal weather station is for the 1980–2010 period. Porto Santo has at least one weather station with a semiarid climate ("BSh"). On the highest windward slopes of Madeira, rainfall exceeds 1,250 mm (50 inches) per year, mostly falling between October and April. In most winters snowfall occurs in the mountains of Madeira.

In the south, there is very little left of the indigenous subtropical rainforest which once covered the whole island (the original settlers set fire to the island to clear the land for farming) and gave it the name it now bears ("Madeira" means "wood" in Portuguese). However, in the north, the valleys contain native trees of fine growth. These "laurisilva" forests, called "lauraceas madeirense", notably the forests on the northern slopes of Madeira Island, are designated as a World Heritage Site by UNESCO.The paleobotanical record of Madeira reveals that laurissilva forests has existed in this island for at least 1.8 million years. Critically endangered species such as the vine "Jasminum azoricum" or the rowan "sorbus maderensis" are endemic to Madeira.

The Madeiran wall lizard ("Lacerta dugesii") is a species of lizard in the Lacertidae family. The species is endemic to the Island where it is very common, and is the only small lizard, ranging from sea coasts to altitudes of . It is usually found in rocky places or among scrub and may climb into trees. It is also found in gardens and on the walls of buildings. It feeds on small invertebrates such as ants and also eats some vegetable matter. The tail is easily shed and the stump regenerates slowly. The colouring is variable and tends to match the colour of the animal's surroundings, being some shade of brown or grey with occasionally a greenish tinge. Most animals are finely flecked with darker markings. The underparts are white or cream, sometimes with dark spots, with some males having orange or red underparts and blue throats, but these bright colours may fade if the animal is disturbed. The Madeiran wall lizard grows to a snout-to-vent length of about with a tail about 1.7 times the length of its body. Females lay two to three clutches of eggs in a year with the juveniles being about when they hatch.

The island of Madeira is wet in the northwest, but dry in the southeast. In the 16th century the Portuguese started building levadas or aqueducts to carry water to the agricultural regions in the south. Madeira is very mountainous, and building the levadas was difficult and often convicts or slaves were used. Many are cut into the sides of mountains, and it was also necessary to dig of tunnels, some of which are still accessible.

Today the levadas not only supply water to the southern parts of the island, but provide hydro-electric power. There are over of levadas and they provide a network of walking paths. Some provide easy and relaxing walks through the countryside, but others are narrow, crumbling ledges where a slip could result in serious injury or death.

Two of the most popular levadas to hike are the "Levada do Caldeirão Verde" and the "Levada do Caldeirão do Inferno", which should not be attempted by hikers prone to vertigo or without torches and helmets. The "Levada do Caniçal" is a much easier walk, running from Maroços to the "Caniçal Tunnel". It is known as the "mimosa levada", because mimosa trees are found all along the route.

Administratively, Madeira (with a population of 267,302 inhabitants in 2011) and covering an area of is organised into eleven municipalities:

Funchal is the capital and principal city of the Autonomous Region of Madeira, located along the southern coast of the island of Madeira. It is a modern city, located within a natural geological "amphitheatre" composed of vulcanological structure and fluvial hydrological forces. Beginning at the harbour (Porto de Funchal), the neighbourhoods and streets rise almost , along gentle slopes that helped to provide a natural shelter to the early settlers.

The island was settled by Portuguese people, especially farmers from the Minho region, meaning that Madeirans (), as they are called, are ethnically Portuguese, though they have developed their own distinct regional identity and cultural traits.

The region has a total population of just under 270,000, the majority of whom live on the main island of Madeira where the population density is ; meanwhile only around 5,000 live on the Porto Santo island where the population density is .

About 247,000 (96%) of the population are Catholic and Funchal is the location of the Catholic cathedral.

Madeirans migrated to the United States, Venezuela, Brazil, British Guiana, St. Vincent and Trinidad. Madeiran immigrants in North America mostly clustered in the New England and mid-Atlantic states, Toronto, Northern California, and Hawaii. The city of New Bedford is especially rich in Madeirans, hosting the Museum of Madeira Heritage, as well as the annual Madeiran and Luso-American celebration, the Feast of the Blessed Sacrament, the world's largest celebration of Madeiran heritage, regularly drawing crowds of tens of thousands to the city's Madeira Field.

In 1846, when a famine struck Madeira over 6,000 of the inhabitants migrated to British Guiana. In 1891 they numbered 4.3% of the population. In 1902 in Honolulu, Hawaii there were 5,000 Portuguese people, mostly Madeirans. In 1910 this grew to 21,000.

1849 saw an emigration of Protestant religious exiles from Madeira to the United States, by way of Trinidad and other locations in the West Indies. Most of them settled in Illinois with financial and physical aid of the American Protestant Society, headquartered in New York City. In the late 1830s the Reverend Robert Reid Kalley, from Scotland, a Presbyterian minister as well as a physician, made a stop at Funchal, Madeira on his way to a mission in China, with his wife, so that she could recover from an illness. The Rev. Kalley and his wife stayed on Madeira where he began preaching the Protestant gospel and converting islanders from Catholicism. Eventually, the Rev. Kalley was arrested for his religious conversion activities and imprisoned. Another missionary from Scotland, William Hepburn Hewitson, took on Protestant ministerial activities in Madeira. By 1846, about 1,000 Protestant Madeirenses, who were discriminated against and the subjects of mob violence because of their religious conversions, chose to immigrate to Trinidad and other locations in the West Indies in answer for a call for sugar plantation workers. The Madeirenses exiles did not fare well in the West Indies. The tropical climate was unfamiliar and they found themselves in serious economic difficulties. By 1848, the American Protestant Society raised money and sent the Rev. Manuel J. Gonsalves, a Baptist minister and a naturalized U.S. citizen from Madeira, to work with the Rev. Arsenio da Silva, who had emigrated with the exiles from Madeira, to arrange to resettle those who wanted to come to the United States. The Rev. da Silva died in early 1849. Later in 1849, the Rev. Gonsalves was then charged with escorting the exiles from Trinidad to be settled in Sangamon and Morgan counties in Illinois on land purchased with funds raised by the American Protestant Society. Accounts state that anywhere from 700 to 1,000 exiles came to the United States at this time.

There are several large Madeiran communities around the world, such as the number in the UK, including Jersey, the Portuguese British community mostly made up of Madeirans celebrate Madeira Day.

Madeira is part of the Schengen Area.

The Venezuelan (14.4%), British (14.2%), Brazilian (12.1%) and German (7.0%) nationalities constituted the largest foreign communities residing in the Autonomous Region of Madeira in 2017. The Venezuelan community showed a sharp increase (38.0%). In terms of geographical distribution, it is in Funchal that the foreign population mainly concentrates (59.2% of the total of the Region), followed by Santa Cruz (13.8%), Calheta (7.3%) and Porto Santo (4.0%). The foreign population with resident status in the Autonomous Region of Madeira totaled 6,720 (up by 10.0% from 2016), distributed between residence permits (6,692) and long-stay visas (28).

The setting-up of a free trade zone has led to the installation, under more favourable conditions, of infrastructure, production shops and essential services for small and medium-sized industrial enterprises. The International Business Centre of Madeira comprises presently three sectors of investment: the Industrial Free Trade Zone, the International Shipping Register – MAR and the International Services. Madeira's tax regime has been approved by the European Commission as legal State Aid and its deadline has recently been extended by the E.C. until the end of 2027. The International Business Centre of Madeira, also known as Madeira Free Trade Zone, was created formally in the 1980s as a tool of regional economic policy. It consists of a set of incentives, mainly of a tax nature, granted with the objective of attracting inward investment into Madeira, recognized as the most efficient mechanism to modernize, diversify and internationalize the regional economy. The decision to create the International Business Centre of Madeira was the result of a thorough process of analysis and study. Other small island economies, with similar geographical and economic restraints, had successfully implemented projects of attraction of foreign direct investment based on international services activities, becoming therefore examples of successful economic policies. 

Since the beginning, favorable operational and fiscal conditions have been offered in the context of a preferential tax regime, fully recognized and approved by the European Commission in the framework of State aid for regional purposes and under the terms of the Ultra-peripheral Regions set in the Treaties, namely Article 299 of the Treaty on European Union. The IBC of Madeira has therefore been fully integrated in the Portuguese and EU legal systems and, as a consequence, it is regulated and supervised by the competent Portuguese and EU authorities in a transparent and stable business environment, marking a clear difference from the so-called "tax havens" and "offshore jurisdictions", since its inception. In 2015, the European Commission authorized the new state aid regime for new companies incorporated between 2015 and 2020 and the extension of the deadline of the tax reductions until the end of 2027. The present tax regime is outlined in Article 36°-A of the Portuguese Tax Incentives Statute. Available data clearly demonstrates the contribution that this development programme has brought to the local economy over its 20 years of existence: impact in the local labour market, through the creation of qualified jobs for the young population but also for madeiran professionals who have returned to Madeira thanks to the opportunities now created; an increase in productivity due to the transfer of know how and the implementation of new business practices and technologies; indirect influence on other sectors of activity: business tourism benefits from the visits of investors and their clients and suppliers, and other sectors such as real estate, telecommunications and other services benefit from the growth of their client base; impact on direct sources of revenue: the companies attracted by the IBC of Madeira represent over 40% of the revenue in terms of corporate income tax for the Government of Madeira and nearly 3.000 jobs, most of which qualified, amongst other benefits. Also there are above average salaries paid by the companies in the IBC of Madeira in comparison with the wages paid in the other sectors of activity in Madeira. 

Madeira has been a significant recipient of European Union funding, totalling up to €2 billion. In 2012, it was reported that despite a population of just 250,000, the local administration owes some €6 billion. Furthermore, the Portuguese treasury (IGCP) assumed Madeira's debt management between 2012 and 2015. The region continues to work with the central government on a long-term plan to reduce its debt levels and commercial debt stock. Moody's notes that the region has made significant fiscal consolidation efforts and that its tax revenue collection has increased significantly in recent years due to tax rate hikes. Madeira's tax revenues increased by 41% between 2012 and 2016, helping the region to reduce its deficit to operating revenue ratio to 10% in 2016 from 77% in 2013.

Tourism is an important sector in the region's economy, contributing 20% to the region's GDP, providing support throughout the year for commercial, transport and other activities and constituting a significant market for local products. The share in Gross Value Added of hotels and restaurants (9%) also highlights this phenomenon. The island of Porto Santo, with its long beach and its climate, is entirely devoted to tourism.

Visitors are mainly from the European Union, with German, British, Scandinavian and Portuguese tourists providing the main contingents. The average annual occupancy rate was 60.3% in 2008, reaching its maximum in March and April, when it exceeds 70%. 
Whale watching has become very popular in recent years. Many species of dolphins, such as common dolphin, spotted dolphin, striped dolphin, bottlenose dolphin, short-finned pilot whale, and whales such as Bryde's whale, Sei whale, fin whale, sperm whale, beaked whales can be spotted near the coast or offshore.

Electricity on Madeira is provided solely through EEM (Empresa de Electricidade da Madeira, SA, which holds a monopoly for the provision of electrical supply on the autonomous region) and consists largely of fossil fuels, but with a significant supply of seasonal hydroelectricity from the levada system, wind power and a small amount of solar. In 2011, renewable energy formed 26.5% of the electricity used in Madeira.

The Islands have two airports, Cristiano Ronaldo International Airport and Porto Santo Airport, on the islands of Madeira and Porto Santo respectively. From Cristiano Ronaldo International Airport the most frequent flights are to Lisbon. There are also direct flights to over 30 other airports in Europe and nearby islands.

Transport between the two main islands is by plane, or ferries from the Porto Santo Line, the latter also carrying vehicles. Visiting the interior of the islands is now easy thanks to construction of the "Vias Rápidas", major roads that cross the island. Modern roads reach all points of interest on the islands.

Funchal has an extensive public transportation system. Bus companies, including Horários do Funchal which has been operating for over a hundred years, have regularly scheduled routes to all points of interest on the island.

Folklore music in Madeira is widespread and mainly uses local musical instruments such as the machete, rajao, brinquinho and cavaquinho, which are used in traditional folkloric dances like the "bailinho da Madeira".

Emigrants from Madeira also influenced the creation of new musical instruments. In the 1880s, the ukulele was created, based on two small guitar-like instruments of Madeiran origin, the cavaquinho and the rajao. The ukulele was introduced to the Hawaiian Islands by Portuguese immigrants from Madeira and Cape Verde. Three immigrants in particular, Madeiran cabinet makers Manuel Nunes, José do Espírito Santo, and Augusto Dias, are generally credited as the first ukulele makers. Two weeks after they disembarked from the "SS Ravenscrag" in late August 1879, the "Hawaiian Gazette" reported that "Madeira Islanders recently arrived here, have been delighting the people with nightly street concerts."

Because of the geographic situation of Madeira in the Atlantic Ocean, the island has an abundance of fish of various kinds. The species that are consumed the most are espada (black scabbardfish), blue fin tuna, white marlin, blue marlin, albacore, bigeye tuna, wahoo, spearfish, skipjack tuna and many others are found in the local dishes as they are found up and down the coast of Madeira. Espada is often served with banana. Bacalhau is also popular, as it is in Portugal.

There are many meat dishes on Madeira, one of the most popular being espetada. Espetada is traditionally made of large chunks of beef rubbed in garlic, salt and bay leaf and marinated for 4 to 6 hours in Madeira wine, red wine vinegar and olive oil then skewered onto a bay laurel stick and left to grill over smouldering wood chips. These are so integral a part of traditional eating habits that a special iron stand is available with a T-shaped end, each branch of the "T" having a slot in the middle to hold a brochette (espeto in Portuguese); a small plate is then placed underneath to collect the juices. The brochettes are very long and have a V-shaped blade in order to pierce the meat more easily. It is usually accompanied with the local bread called bolo do caco.

Other popular dishes in Madeira include açorda, feijoada, carne de vinha d'alhos.

Traditional pastries in Madeira usually contain local ingredients, one of the most common being "mel de cana", literally "sugarcane honey" (molasses). The traditional cake of Madeira is called "Bolo de Mel", which translates as (Sugarcane) "Honey Cake" and according to custom, is never cut with a knife, but broken into pieces by hand. It is a rich and heavy cake. The cake commonly well known as "Madeira Cake" in England also finds its naming roots in the Island of Madeira.

Malasadas are a Madeiran creation which were taken around the world by emigrants to places such as Hawaii. In Madeira, Malasadas are mainly consumed during the Carnival of Madeira. Pastéis de nata, as in the rest of Portugal, are also very popular.

Milho frito is a very popular dish in Madeira which is very similar to the Italian dish polenta. Açorda Madeirense is another popular local dish.

Madeira is a fortified wine, produced in the Madeira Islands; varieties may be sweet or dry. It has a history dating back to the Age of Exploration when Madeira was a standard port of call for ships heading to the New World or East Indies. To prevent the wine from spoiling, neutral grape spirits were added. However, wine producers of Madeira discovered, when an unsold shipment of wine returned to the islands after a round trip, that the flavour of the wine had been transformed by exposure to heat and movement. Today, Madeira is noted for its unique winemaking process which involves heating the wine and deliberately exposing the wine to some levels of oxidation. Most countries limit the use of the term "Madeira" to those wines that come from the Madeira Islands, to which the European Union grants Protected Designation of Origin (PDO) status.

A local beer called Coral is produced by the Madeira Brewery, which dates from 1872. It has achieved 2 Monde Selection Grand Gold Medals, 24 Monde Selection Gold Medals and 2 Monde Selection Silver Medals. Other alcoholic drinks are also popular in Madeira, such as the locally created Poncha, Niquita, Pé de Cabra, Aniz, as well as Portuguese drinks such as Macieira Brandy, Licor Beirão.

Laranjada is a type of carbonated soft drink with an orange flavour, its name being derived from the Portuguese word "laranja" ("orange"). Launched in 1872 it was the first soft drink to be produced in Portugal, and remains very popular to the present day. Brisa drinks, a brand name, are also very popular and come in a range of flavours.

There is also a huge coffee culture in Madeira. Like in mainland Portugal, popular coffee-based drinks include Garoto, Galão, Bica, Café com Cheirinho, Mazagran, Chinesa and many more.

Madeira Island has the following sister provinces:

Portugal has issued postage stamps for Madeira during several periods, beginning in 1868.

The following people were either born or have lived part of their lives in Madeira:





</doc>
<doc id="19901" url="https://en.wikipedia.org/wiki?curid=19901" title="M16 rifle">
M16 rifle

The M16 rifle, officially designated Rifle, Caliber 5.56 mm, M16, is a United States military adaptation of the ArmaLite AR-15 rifle. The original M16 was a selective fire 5.56mm rifle with a 20-round magazine.

In 1964, the M16 entered U.S. military service and the following year was deployed for jungle warfare operations during the Vietnam War. In 1969, the M16A1 replaced the M14 rifle to become the U.S. military's standard service rifle. The M16A1 improvements include a bolt-assist, chrome plated bore and a new 30-round magazine.

In 1983, the U.S. Marine Corps adopted the M16A2 rifle and the U.S. Army adopted it in 1986. The M16A2 fires the improved 5.56×45mm NATO (M855/SS109) cartridge and has a new adjustable rear sight, case deflector, heavy barrel, improved handguard, pistol grip and buttstock, as well as a semi-auto and three-round burst only fire selector. Adopted in 1998, the M16A4 is the fourth generation of the M16 series. It is equipped with a removable carrying handle and Picatinny rail for mounting optics and other ancillary devices.

The M16 has also been widely adopted by other militaries around the world. Total worldwide production of M16s has been approximately 8 million, making it the most-produced firearm of its 5.56 mm caliber. The U.S. military has largely replaced the M16 in combat units with a shorter and lighter version named M4 carbine.

After World War II, the United States military started looking for a single automatic rifle to replace the M1 Garand, M1/M2 Carbines, M1918 Browning Automatic Rifle, M3 "Grease Gun" and Thompson submachine gun. However, early experiments with select-fire versions of the M1 Garand proved disappointing. During the Korean War, the select-fire M2 carbine largely replaced the submachine gun in US service and became the most widely used Carbine variant. However, combat experience suggested that the .30 Carbine round was under-powered. American weapons designers concluded that an intermediate round was necessary, and recommended a small-caliber, high-velocity cartridge.

However, senior American commanders having faced fanatical enemies and experienced major logistical problems during WWII and the Korean War, insisted that a single powerful .30 caliber cartridge be developed, that could not only be used by the new automatic rifle, but by the new general-purpose machine gun (GPMG) in concurrent development. This culminated in the development of the 7.62×51mm NATO cartridge.

The U.S. Army then began testing several rifles to replace the obsolete M1 Garand. Springfield Armory's T44E4 and heavier T44E5 were essentially updated versions of the Garand chambered for the new 7.62 mm round, while Fabrique Nationale submitted their FN FAL as the T48. ArmaLite entered the competition late, hurriedly submitting several AR-10 prototype rifles in the fall of 1956 to the U.S. Army's Springfield Armory for testing.
The AR-10 featured an innovative straight-line barrel/stock design, forged aluminum alloy receivers and with phenolic composite stocks. It had rugged elevated sights, an oversized aluminum flash suppressor and recoil compensator, and an adjustable gas system. The final prototype featured an upper and lower receiver with the now-familiar hinge and takedown pins, and the charging handle was on top of the receiver placed inside of the carry handle. For a 7.62mm NATO rifle, the AR-10 was incredibly lightweight at only 6.85 lbs. empty. Initial comments by Springfield Armory test staff were favorable, and some testers commented that the AR-10 was the best lightweight automatic rifle ever tested by the Armory.

In the end the U.S. Army chose the T44 now named M14 rifle which was an improved M1 Garand with a 20-round magazine and automatic fire capability. The U.S. also adopted the M60 general purpose machine gun (GPMG). Its NATO partners adopted the FN FAL and HK G3 rifles, as well as the FN MAG and Rheinmetall MG3 GPMGs.

The first confrontations between the AK-47 and the M14 came in the early part of the Vietnam War. Battlefield reports indicated that the M14 was uncontrollable in full-auto and that soldiers could not carry enough ammunition to maintain fire superiority over the AK-47. And, while the M2 carbine offered a high rate of fire, it was under-powered and ultimately outclassed by the AK-47. A replacement was needed: a medium between the traditional preference for high-powered rifles such as the M14, and the lightweight firepower of the M2 Carbine.

As a result, the Army was forced to reconsider a 1957 request by General Willard G. Wyman, commander of the U.S. Continental Army Command (CONARC) to develop a .223 inch caliber (5.56 mm) select-fire rifle weighing when loaded with a 20-round magazine. The 5.56 mm round had to penetrate a standard U.S. helmet at 500 yards (460 meters) and retain a velocity in excess of the speed of sound, while matching or exceeding the wounding ability of the .30 Carbine cartridge.

This request ultimately resulted in the development of a scaled-down version of the Armalite AR-10, named ArmaLite AR-15 rifle. However, despite overwhelming evidence that the AR-15 could bring more firepower to bear than the M14, the Army opposed the adoption of the new rifle. In January 1963, Secretary of Defense Robert McNamara concluded that the AR-15 was the superior weapon system and ordered a halt to M14 production. At the time, the AR-15 was the only rifle available that could fulfill the requirement of a universal infantry weapon for issue to all services.

After modifications (most notably, the charging handle was re-located from under the carrying handle like AR-10 to the rear of the receiver), the new redesigned rifle was subsequently adopted as the M16 Rifle. "(The M16) was much lighter compared to the M14 it replaced, ultimately allowing Soldiers to carry more ammunition. The air-cooled, gas-operated, magazine-fed assault rifle was made of steel, aluminum alloy and composite plastics, truly cutting-edge for the time. Designed with full and semi-automatic capabilities, the weapon initially did not respond well to wet and dirty conditions, sometimes even jamming in combat. After a few minor modifications, the weapon gained in popularity among troops on the battlefield."

Despite its early failures the M16 proved to be a revolutionary design and stands as the longest continuously serving rifle in American military history. It has been adopted by many U.S. allies and the 5.56×45mm NATO cartridge has become not only the NATO standard, but "the standard assault-rifle cartridge in much of the world." It also led to the development of small-caliber high-velocity service rifles by every major army in the world, including the USSR and People's Republic of China. It is a benchmark against which other assault rifles are judged.

In July 1960, General Curtis LeMay was impressed by a demonstration of the ArmaLite AR-15. In the summer of 1961, General LeMay was promoted to U.S. Air Force, Chief of Staff, and requested 80,000 AR-15s. However, General Maxwell D. Taylor, Chairman of the Joint Chiefs of Staff, advised President John F. Kennedy that having "two" different calibers within the military system at the same time would be problematic and the request was rejected. In October 1961, William Godel, a senior man at the Advanced Research Projects Agency, sent 10 AR-15s to South Vietnam. The reception was enthusiastic, and in 1962, another 1,000 AR-15s were sent. United States Army Special Forces personnel filed battlefield reports lavishly praising the AR-15 and the stopping-power of the 5.56 mm cartridge, and pressed for its adoption.

The damage caused by the 5.56 mm bullet was originally believed to be caused by "tumbling" due to the slow 1 in rifling twist rate. However, any pointed lead core bullet will "tumble" after penetration in flesh, because the center of gravity is towards the rear of the bullet. The large wounds observed by soldiers in Vietnam were actually caused by bullet fragmentation, which was created by a combination of the bullet's velocity and construction. These wounds were so devastating, that the photographs remained classified into the 1980s.

However, despite overwhelming evidence that the AR-15 could bring more firepower to bear than the M14, the Army opposed the adoption of the new rifle. U.S. Secretary of Defense Robert McNamara now had two conflicting views: the ARPA report favoring the AR-15 and the Army's position favoring the M14. Even President Kennedy expressed concern, so McNamara ordered Secretary of the Army Cyrus Vance to test the M14, the AR-15 and the AK-47. The Army reported that only the M14 was suitable for service, but Vance wondered about the impartiality of those conducting the tests. He ordered the Army Inspector General to investigate the testing methods used; the Inspector General confirmed that the testers were biased towards the M14.

In January 1963, Secretary McNamara received reports that M14 production was insufficient to meet the needs of the armed forces and ordered a halt to M14 production. At the time, the AR-15 was the only rifle that could fulfill a requirement of a "universal" infantry weapon for issue to all services. McNamara ordered its adoption, despite receiving reports of several deficiencies, most notably the lack of a chrome-plated chamber.

After modifications (most notably, the charging handle was re-located from under the carrying handle like AR-10 to the rear of the receiver), the new redesigned rifle was renamed the "Rifle, Caliber 5.56 mm, M16". Inexplicably, the modification to the new M16 did not include a chrome-plated barrel. Meanwhile, the Army relented and recommended the adoption of the M16 for jungle warfare operations. However, the Army insisted on the inclusion of a forward assist to help push the bolt into battery in the event that a cartridge failed to seat into the chamber. The Air Force, Colt and Eugene Stoner believed that the addition of a forward assist was an unjustified expense. As a result, the design was split into two variants: the Air Force's M16 without the forward assist, and the XM16E1 with the forward assist for the other service branches.

In November 1963, McNamara approved the U.S. Army's order of 85,000 XM16E1s; and to appease General LeMay, the Air Force was granted an order for another 19,000 M16s. In March 1964, the M16 rifle went into production and the Army accepted delivery of the first batch of 2,129 rifles later that year, and an additional 57,240 rifles the following year.

In 1964, the Army was informed that DuPont could not mass-produce the IMR 4475 stick powder to the specifications demanded by the M16. Therefore, Olin Mathieson Company provided a high-performance ball propellant. While the Olin WC 846 powder achieved the desired per second muzzle velocity, it produced much more fouling, that quickly jammed the M16s action (unless the rifle was cleaned well and often).

In March 1965, the Army began to issue the XM16E1 to infantry units. However, the rifle was initially delivered without adequate cleaning kits or instructions because Colt had claimed the M16 was self-cleaning. As a result, reports of stoppages in combat began to surface. The most severe problem, was known as "failure to extract"—the spent cartridge case remained lodged in the chamber after the rifle was fired. Documented accounts of dead U.S. troops found next to disassembled rifles eventually led to a Congressional investigation.

In February 1967, the improved XM16E1 was standardized as the M16A1. The new rifle had a chrome-plated chamber and bore to eliminate corrosion and stuck cartridges and other, minor, modifications. New cleaning kits, powder solvents and lubricants were also issued. Intensive training programs in weapons cleaning were instituted including a comic book-style operations manual. As a result, reliability problems greatly diminished and the M16A1 rifle achieved widespread acceptance by U.S. troops in Vietnam.

In 1969, the M16A1 officially replaced the M14 rifle to become the U.S. military's standard service rifle. In 1970, the new WC 844 powder was introduced to reduce fouling.

During the early part of its career, the M16 had a reputation for poor reliability and a malfunction rate of two per 1000 rounds fired. The M16's action works by passing high pressure propellant gasses tapped from the barrel down a tube and into the carrier group within the upper receiver, and is commonly referred to as a "direct impingement gas system". The gas goes from the gas tube, through the bolt carrier key, and into the inside of the carrier where it expands in a donut shaped gas cylinder. Because the bolt is prevented from moving forward by the barrel, the carrier is driven to the rear by the expanding gases and thus converts the energy of the gas to movement of the rifle's parts. The back part of the bolt forms a piston head and the cavity in the bolt carrier is the piston sleeve. It is more correct to call it an "internal piston" system." This design is much lighter and more compact than a gas-piston design. However, this design requires that combustion byproducts from the discharged cartridge be blown into the receiver as well. This accumulating carbon and vaporized metal build-up within the receiver and bolt-carrier negatively affects reliability and necessitates more intensive maintenance on the part of the individual soldier. The channeling of gasses into the bolt carrier during operation increases the amount of heat that is deposited in the receiver while firing the M16 and causes essential lubricant to be "burned off". This requires frequent and generous applications of appropriate lubricant. Lack of proper lubrication is the most common source of weapon stoppages or jams.

The original M16 fared poorly in the jungles of Vietnam and was infamous for reliability problems in the harsh environment. As a result, it became the target of a Congressional investigation. The investigation found that:

When these issues were addressed and corrected by the M16A1, the reliability problems decreased greatly. According to a 1968 Department of Army report, the M16A1 rifle achieved widespread acceptance by U.S. troops in Vietnam. "Most men armed with the M16 in Vietnam rated this rifle's performance high, however, many men entertained some misgivings about the M16's reliability. When asked what weapon they preferred to carry in combat, 85 percent indicated that they wanted either the M16 or its [smaller] submachine gun version, the XM177E2." Also "the M14 was preferred by 15 percent, while less than one percent wished to carry either the Stoner rifle, the AK-47, the carbine or a pistol." In March 1970, the "President's Blue Ribbon Defense Panel" concluded that the issuance of the M16 saved the lives of 20,000 U.S. servicemen during the Vietnam War, who would have otherwise died had the M14 remained in service. However, the M16 rifle's reputation continues to suffer.
After the introduction of the M4 Carbine, it was found that the shorter barrel length of 14.5 inches also has a negative effect on reliability, as the gas port is located closer to the chamber than the gas port of the standard length M16 rifle: 7.5 inches instead of 13 inches. This affects the M4's timing and increases the amount of stress and heat on the critical components, thereby reducing reliability. In a 2002 assessment the USMC found that the M4 malfunctioned three times more often than the M16A4 (the M4 failed 186 times for 69,000 rounds fired, while the M16A4 failed 61 times). Thereafter, the Army and Colt worked to make modifications to the M4s and M16A4s in order to address the problems found. In tests conducted in 2005 and 2006 the Army found that on average, the new M4s and M16s fired approximately 5,000 rounds between stoppages.

In December 2006, the Center for Naval Analyses (CNA) released a report on U.S. small arms in combat. The CNA conducted surveys on 2,608 troops returning from combat in Iraq and Afghanistan over the past 12 months. Only troops who fired their weapons at enemy targets were allowed to participate. 1,188 troops were armed with M16A2 or A4 rifles, making up 46 percent of the survey. 75 percent of M16 users (891 troops) reported they were satisfied with the weapon. 60 percent (713 troops) were satisfied with handling qualities such as handguards, size, and weight. Of the 40 percent dissatisfied, most were with its size. Only 19 percent of M16 users (226 troops) reported a stoppage, while 80 percent of those that experienced a stoppage said it had little impact on their ability to clear the stoppage and re-engage their target. Half of the M16 users never experienced failures of their magazines to feed. 83 percent (986 troops) did not need their rifles repaired while in theater. 71 percent (843 troops) were confident in the M16's reliability, defined as level of soldier confidence their weapon will fire without malfunction, and 72 percent (855 troops) were confident in its durability, defined as level of soldier confidence their weapon will not break or need repair. Both factors were attributed to high levels of soldiers performing their own maintenance. 60 percent of M16 users offered recommendations for improvements. Requests included greater bullet lethality, new-built instead of rebuilt rifles, better quality magazines, decreased weight, and a collapsible stock. Some users recommended shorter and lighter weapons such as M4 carbine. Some issues have been addressed with the issuing of the Improved STANAG magazine in March 2009, and the M855A1 Enhanced Performance Round in June 2010.

In early 2010, two journalists from "The New York Times" spent three months with soldiers and Marines in Afghanistan. While there, they questioned around 100 infantry troops about the reliability of their M16 rifles, as well as the M4 carbine. The troops did not report reliability problems with their rifles. While only 100 troops were asked, they engaged in daily fighting in Marja, including least a dozen intense engagements in Helmand Province, where the ground is covered in fine powdered sand (called "moon dust" by troops) that can stick to firearms. Weapons were often dusty, wet, and covered in mud. Intense firefights lasted hours with several magazines being expended. Only one soldier reported a jam when his M16 was covered in mud after climbing out of a canal. The weapon was cleared and resumed firing with the next chambered round. Furthermore, the Marine Chief Warrant Officer responsible for weapons training and performance of the Third Battalion, Sixth Marines, reported that "We've had nil in the way of problems; we've had no issues." with his battalion's 350 M16s and 700 M4s.

The M16 is a lightweight, 5.56 mm, air-cooled, gas-operated, magazine-fed assault rifle, with a rotating bolt. The M16's receivers are made of 7075 aluminum alloy, its barrel, bolt, and bolt carrier of steel, and its handguards, pistol grip, and buttstock of plastics.

The M16A1 was especially lightweight at with a loaded 30-round magazine. This was significantly less than the M14 that it replaced at with a loaded 20-round magazine. It is also lighter when compared to the AKM's with a loaded 30-round magazine.

The M16A2 weighs loaded with a 30-round magazine, because of the adoption of a thicker barrel profile. The thicker barrel is more resistant to damage when handled roughly and is also slower to overheat during sustained fire. Unlike a traditional "bull" barrel that is thick its entire length, the M16A2's barrel is only thick forward of the handguards. The barrel profile under the handguards remained the same as the M16A1 for compatibility with the M203 grenade launcher.

Early model M16 barrels had a rifling twist of 4 grooves, right hand twist, 1 turn in 14 inches (1:355.6 mm) bore – as it was the same rifling used by the .222 Remington sporting round. This was shown to make the light .223 Remington bullet yaw in flight at long ranges and it was soon replaced. Later models had an improved rifling with 6 grooves, right hand twist, 1 turn in 12 inches (1:304.8 mm) for increased accuracy and was optimized for use with the standard U.S. M193 cartridge. Current models are optimized for the heavier NATO SS109 bullet and have 6 grooves, right hand twist, 1 turn in 7 in (1:177.8 mm). Weapons designed to accept both the M193 or SS109 rounds (like civilian market clones) usually have a 6-groove, right hand twist, 1 turn in 9 inches (1:228.6 mm) bore, although 1:8 inches and 1:7 inches twist rates are available as well.

"The (M16's) Stoner system provides a very symmetric design that allows straight line movement of the operating components. This allows recoil forces to drive straight to the rear. Instead of connecting or other mechanical parts driving the system, high pressure gas performs this function, reducing the weight of moving parts and the rifle as a whole." The M16's straight-line recoil design, where the recoil spring is located in the stock directly behind the action, and serves the dual function of operating spring and recoil buffer. The stock being in line with the bore also reduces muzzle rise, especially during automatic fire. Because recoil does not significantly shift the point of aim, faster follow-up shots are possible and user fatigue is reduced. Also, current model M16 flash-suppressors also act as compensators to reduce recoil further.

The M16's most distinctive ergonomic feature is the carrying handle and rear sight assembly on top of the receiver. This is a by-product of the original design, where the carry handle served to protect the charging handle. As the line of sight is over the bore, the M16 has an inherent parallax problem. At closer ranges (typically inside 15–20 meters), the shooter must compensate by aiming high to place shots where desired. The M16 has a 500 mm (19.75 inches) sight radius. The M16 uses an L-type flip, aperture rear sight and it is adjustable with two settings, 0 to 300 meters and 300 to 400 meters. The front sight is a post adjustable for elevation in the field. The rear sight can be adjusted in the field for windage. The sights can be adjusted with a bullet tip or pointed tool, as troops are trained to zero their own rifles. The sight picture is the same as the M14, M1 Garand, M1 Carbine and the M1917 Enfield. The M16 also has a "Low Light Level Sight System", which includes a front sight post with a small glass vial of (glow-in-the-dark) radioactive Tritium H3 and a larger aperture rear sight. The M16 can also mount a scope on the carrying handle. With the advent of the M16A2, a new fully adjustable rear sight was added, allowing the rear sight to be dialed in for specific range settings between 300 and 800 meters and to allow windage adjustments without the need of a tool or cartridge. Modern versions such as M16A4 have a detachable carrying handle and use Picatinny rails, which allows for the use of various scopes and sighting devices. The current U.S. Army and Air Force issue M4 Carbine comes with the M68 Close Combat Optic and Back-up Iron Sight. The U.S. Marine Corps uses the ACOG Rifle Combat Optic and the U.S. Navy uses EOTech Holographic Weapon Sight.

The M16 rifle is considered to be very accurate. Its light recoil, high-velocity and flat trajectory allow shooters to take head shots out to 300 meters. Newer M16s use the newer M855 cartridge increasing their effective range to 600 meters. They are more accurate than their predecessors and are capable of shooting 1–3 inch groups at 100 yards. "In Fallujah, [Iraq] Marines with ACOG-equipped M16A4s created a stir by taking so many head shots that until the wounds were closely examined, some observers thought the insurgents had been executed." The newest M855A1 EPR cartridge is even more accurate and during testing "...has shown that, on average, 95 percent of the rounds will hit within an 8 × 8-inch target at 600 meters."

The 5.56×45mm cartridge had several advantages over the 7.62×51mm NATO round used in the M14 rifle. It enabled each soldier to carry more ammunition and was easier to control during automatic or burst fire. The 5.56×45mm NATO cartridge can also produce massive wounding effects when the bullet impacts at high speed and yaws ("tumbles") in tissue leading to fragmentation and rapid transfer of energy.

The original ammunition for the M16 was the 55-grain M193 cartridge. When fired from a 20" barrel at ranges of up to 100 meters, the thin-jacketed lead-cored round traveled fast enough (above 2900 ft/s) that the force of striking a human body would cause the round to yaw (or tumble) and fragment into about a dozen pieces of various sizes thus created wounds that were out of proportion to its caliber. These wounds were so devastating that many considered the M16 to be an inhumane weapon. As the 5.56mm round's velocity decreases, so does the number of fragments that it produces. The 5.56mm round does not normally fragment at distances beyond 200 meters or at velocities below 2500 ft/s, and its lethality becomes largely dependent on shot placement.

With the development of the M16A2, the new 62-grain M855 cartridge was adopted in 1983. The heavier bullet had more energy, and was made with a steel core to penetrate Soviet body armor. However, this caused less fragmentation on impact and reduced effects against targets without armor, both of which lessened kinetic energy transfer and wounding ability. Some soldiers and Marines coped with this through training, with requirements to shoot vital areas three times to guarantee killing the target.

However, there have been repeated and consistent reports of the M855's inability to wound effectively (i.e. fragment) when fired from the short barreled M4 carbine (even at close ranges). The M4's 14.5" barrel length reduces muzzle velocity to about 2900 ft/s. This reduced wounding ability is one reason that, despite the Army's transition to short-barrel M4's, the Marine Corps has decided to continue using the M16A4 with its 20″ barrel as the 5.56×45mm M855 is largely dependent upon high velocity in order to wound effectively.

In 2003, the U.S. Army contended that the lack of lethality of the 5.56×45mm was more a matter of perception than fact. With good shot placement to the head and chest, the target was usually defeated without issue. The majority of failures were the result of hitting the target in non-vital areas such as extremities. However, a minority of failures occurred in spite of multiple hits to the chest. In 2006, a study found that 20% of soldiers using the M4 Carbine wanted more lethality or stopping power. In June 2010, the U.S. Army announced it began shipping its new 5.56mm, lead-free, M855A1 Enhanced Performance Round to active combat zones. This upgrade is designed to maximize performance of the 5.56×45mm round, to extend range, improve accuracy, increase penetration and to consistently fragment in soft-tissue when fired from not only standard length M16s, but also the short-barreled M4 carbines. The U.S. Army has been so impressed with the new M855A1 EPR round that they're now developing a 7.62 NATO variant.

The M16's magazine was meant to be a lightweight, disposable item. As such, it is made of pressed/stamped aluminum and was not designed to be durable. The M16 originally used a 20-round magazine which was later replaced by a bent 30-round design. As a result, the magazine follower tends to rock or tilt, causing malfunctions. Many non-U.S. and commercial magazines have been developed to effectively mitigate these shortcomings (e.g., H&K's all-stainless-steel magazine, Magpul's polymer P-MAG, etc.).

Production of the 30-round magazine started late 1967 but did not fully replace the 20-round magazine until the mid-1970s. Standard USGI aluminum 30-round M16 magazines weigh empty and are long. The newer plastic magazines are about a half inch longer. The newer steel magazines are about 0.5 inch longer and four ounces heavier. The M16's magazine has become the unofficial NATO STANAG magazine and is currently used by many Western Nations, in numerous weapon systems.

In 2009, the U.S. Military began fielding an "improved magazine" identified by a tan-colored follower. "The new follower incorporates an extended rear leg and modified bullet protrusion for improved round stacking and orientation. The self-leveling/anti-tilt follower minimizes jamming while a wider spring coil profile creates even force distribution. The performance gains have not added weight or cost to the magazines."

In July 2016, the U.S. Army introduced another improvement, the new Enhanced Performance Magazine, which it says will result in a 300% increase in reliability in the M4 Carbine. Developed by the United States Army Armament Research, Development and Engineering Center and the Army Research Laboratory in 2013, it is tan colored with blue follower to distinguish it from earlier, incompatible magazines.

Most M16 rifles have a barrel threaded in 1⁄2-28" threads to incorporate the use of a muzzle device such as a flash suppressor or sound suppressor. The initial flash suppressor design had three tines or prongs and was designed to preserve the shooter's night vision by disrupting the flash. Unfortunately it was prone to breakage and getting entangled in vegetation. The design was later changed to close the end to avoid this and became known as the "A1" or "bird cage" flash suppressor on the M16A1. Eventually on the M16A2 version of the rifle, the bottom port was closed to reduce muzzle climb and prevent dust from rising when the rifle was fired in the prone position. For these reasons, the U.S. military declared the A2 flash suppressor as a compensator or a muzzle brake; but it is more commonly known as the "GI" or "A2" flash suppressor.

The M16's Vortex Flash Hider weighs 3 ounces, is 2.25 inches long, and does not require a lock washer to attach to barrel. It was developed in 1984, and is one of the earliest privately designed muzzle devices. The U.S. military uses the Vortex Flash Hider on M4 carbines and M16 rifles. A version of the Vortex has been adopted by the Canadian Military for the Colt Canada C8 CQB rifle. Other flash suppressors developed for the M16 include the Phantom Flash Suppressor by Yankee Hill Machine (YHM) and the KX-3 by Noveske Rifleworks.

The threaded barrel allows sound suppressors with the same thread pattern to be installed directly to the barrel; however this can result in complications such as being unable to remove the suppressor from the barrel due to repeated firing on full auto or three-round burst. A number of suppressor manufacturers have designed "direct-connect" sound suppressors which can be installed over an existing M16's flash suppressor as opposed to using the barrel's threads.

All current M16 type rifles can mount under-barrel 40 mm grenade-launchers, such as the M203 and M320. Both use the same 40 mm grenades as the older, stand-alone M79 grenade launcher. The M16 can also mount under-barrel 12 gauge shotguns such as KAC Masterkey or the M26 Modular Accessory Shotgun System.

The M234 Riot Control Launcher is an M16-series rifle attachment firing an M755 blank round. The M234 mounts on the muzzle, bayonet lug and front sight post of the M16. It fires either the M734 64 mm Kinetic Riot Control or the M742 64 mm CSI Riot Control Ring Airfoil Projectiles. The latter produces a 4 to 5 foot tear gas cloud on impact. The main advantage to using Ring Airfoil Projectiles is that their design does not allow them be thrown back by rioters with any real effect. The M234 is no longer used by U.S. forces. It has been replaced by the M203 40 mm grenade launcher and nonlethal ammunition.

The M16 is 44.25 inches (1124 mm) long with an M7 bayonet attached. The M7 bayonet is based on earlier designs such as the M4, M5, & M6 bayonets, all of which are direct descendants of the M3 Fighting Knife and have spear-point blade with a half sharpened secondary edge. The newer M9 bayonet has a clip-point blade with saw teeth along the spine, and can be used as a multi-purpose knife and wire-cutter when combined with its scabbard. The current USMC OKC-3S bayonet bears a resemblance to the Marines' iconic Ka-Bar fighting knife with serrations near the handle.

For use as an ad-hoc automatic rifle, the M16 and M16A1 could be equipped with the XM3 bipod, later standardized as the "Bipod, M3" (1966) and "Rifle Bipod M3" (1983). Weighing only 0.6 lbs, the simple and non-adjustable bipod clamped unto the barrel of the rifle to allow for supported fire.

The M3 bipod continues to be referenced in at least one official manual as late as 1985, where it is stated one of the most stable firing positions is "the prone biped [sic] supported for automatic fire."

In March 1970, the U.S. recommended that all NATO forces adopt the 5.56×45mm cartridge. This shift represented a change in the philosophy of the military's long-held position about caliber size. By the mid 1970s, other armies were looking at M16-style weapons. A NATO standardization effort soon started and tests of various rounds were carried out starting in 1977. The U.S. offered the 5.56×45mm M193 round, but there were concerns about its penetration in the face of the wider introduction of body armor. In the end the Belgian 5.56×45mm SS109 round was chosen (STANAG 4172) in October 1980. The SS109 round was based on the U.S. cartridge but included a new stronger, heavier, 62 grain bullet design, with better long range performance and improved penetration (specifically, to consistently penetrate the side of a steel helmet at 600 meters). Due to its design and lower muzzle velocity (about 3110 ft/s) the Belgian SS109 round is considered more humane because it is less likely to fragment than the U.S. M193 round. The NATO 5.56×45mm standard ammunition produced for U.S. forces is designated M855.

In October 1980, shortly after NATO accepted the 5.56×45mm NATO rifle cartridge. Draft Standardization Agreement 4179 (STANAG 4179) was proposed to allow NATO members to easily share rifle ammunition and magazines down to the individual soldier level. The magazine chosen to become the "STANAG magazine" was originally designed for the U.S. M16 rifle. Many NATO member nations, but not all, subsequently developed or purchased rifles with the ability to accept this type of magazine. However, the standard was never ratified and remains a 'Draft STANAG'.

All current M16 type rifles are designed to fire STANAG 22 mm rifle grenades from their integral flash hiders without the use of an adapter. These 22 mm grenade types range from anti-tank rounds to simple finned tubes with a fragmentation hand grenade attached to the end. They come in the "standard" type which are propelled by a blank cartridge inserted into the chamber of the rifle. They also come in the "bullet trap" and "shoot through" types, as their names imply, they use live ammunition. The U.S. military does not generally use rifle grenades; however, they are used by other nations.

The NATO Accessory Rail STANAG 4694, or Picatinny rail STANAG 2324, or a "Tactical Rail" is a bracket used on M16 type rifles to provide a standardized mounting platform. The rail comprises a series of ridges with a T-shaped cross-section interspersed with flat "spacing slots". Scopes are mounted either by sliding them on from one end or the other; by means of a "rail-grabber" which is clamped to the rail with bolts, thumbscrews or levers; or onto the slots between the raised sections. The rail was originally for scopes. However, once established, the use of the system was expanded to other accessories, such as tactical lights, laser aiming modules, night vision devices, reflex sights, foregrips, bipods, and bayonets.

Currently, the M16 is in use by 15 NATO countries and more than 80 countries worldwide.

The weapon that eventually became the M16 series was basically a scaled down AR-10 with an ambidextrous charging handle located within the carrying handle, a narrower front sight "A" frame, and no flash suppressor.

Colt's first two models produced after the acquisition of the rifle from ArmaLite were the 601 and 602, and these rifles were in many ways clones of the original ArmaLite rifle (in fact, these rifles were often found stamped "Colt ArmaLite AR-15, Property of the U.S. Government caliber .223", with no reference to them being M16s). The 601 and 602 are easily identified by their flat lower receivers without raised surfaces around the magazine well and occasionally green or brown furniture. The 601 was adopted first of any of the rifles by the USAF, and was quickly supplemented with the XM16 (Colt Model 602) and later the M16 (Colt Model 604) as improvements were made. There was also a limited purchase of 602s, and a number of both of these rifles found their way to a number of Special Operations units then operating in South East Asia, most notably the U.S. Navy SEALs. The only major difference between the 601 and 602 is the switch from the original 1:14-inch rifling twist to the more common 1:12-inch twist. These weapons were equipped with a triangular charging handle and a bolt hold open device that lacked a raised lower engagement surface. The bolt hold open device had a slanted and serrated surface that had to be engaged with a bare thumb, index finger, or thumb nail because of the lack of this surface. The U.S. Air Force continued to use the ArmaLite AR-15 marked rifles in various configurations into the 1990s.

This was the first M16 variant adopted operationally, originally by the U.S. Air Force. It was equipped with triangular handguards, butt stocks without a compartment for the storage of a cleaning kit, a three-pronged flash suppressor, full auto, and no forward assist. Bolt carriers were originally chrome plated and slick-sided, lacking forward assist notches. Later, the chrome plated carriers were dropped in favor of Army issued notched and parkerized carriers though the interior portion of the bolt carrier is still chrome-lined. The Air Force continued to operate these weapons until around 2001, at which time the Air Force converted all of its M16s to the M16A2 configuration.

The M16 was also adopted by the British SAS, who used it during the Falklands War.

The U.S. Army XM16E1 was essentially the same weapon as the M16 with the addition of a forward assist and corresponding notches in the bolt carrier. The M16A1 was the finalized production model in 1967.

To address issues raised by the XM16E1's testing cycle, a closed, bird-cage flash suppressor replaced the XM16E1's three-pronged flash suppressor which caught on twigs and leaves. Various other changes were made after numerous problems in the field. Cleaning kits were developed and issued while barrels with chrome-plated chambers and later fully lined bores were introduced.

With these and other changes, the malfunction rate slowly declined and new soldiers were generally unfamiliar with early problems. A rib was built into the side of the receiver on the XM16E1 to help prevent accidentally pressing the magazine release button while closing the ejection port cover. This rib was later extended on production M16A1s to help in preventing the magazine release from inadvertently being pressed. The hole in the bolt that accepts the cam pin was crimped inward on one side, in such a way that the cam pin may not be inserted with the bolt installed backwards, which would cause failures to eject until corrected. The M16A1 saw limited use in training capacities until the early 2000s, but is no longer in active service with the U.S., although is still standard issue in many world armies.

The development of the M16A2 rifle was originally requested by the United States Marine Corps as a result of combat experience in Vietnam with the XM16E1 and M16A1. It was officially adopted by the Department of Defense as the "US Rifle, 5.56mm, M16A2" in 1982. The Marines were the first branch of the U.S. Armed Forces to adopt it, in the early/mid-1980s, with the United States Army following suit in the late 1980s. 

Modifications to the M16A2 were extensive. In addition to the new rifling, the barrel was made with a greater thickness in front of the front sight post, to resist bending in the field and to allow a longer period of sustained fire without overheating. The rest of the barrel was maintained at the original thickness to enable the M203 grenade launcher to be attached. A new adjustable rear sight was added, allowing the rear sight to be dialed in for specific range settings between 300 and 800 meters to take full advantage of the ballistic characteristics of the new SS109 rounds and to allow windage adjustments without the need of a tool or cartridge. The weapon's reliability allowed it to be widely used around the Marine Corps' special operations divisions as well. The flash suppressor was again modified, this time to be closed on the bottom so it would not kick up dirt or snow when being fired from the prone position, and acting as a recoil compensator. The front grip was modified from the original triangular shape to a round one, which better fit smaller hands and could be fitted to older models of the M16. The new handguards were also symmetrical so armories need not separate left- and right-hand spares. The handguard retention ring was tapered to make it easier to install and uninstall the handguards. A notch for the middle finger was added to the pistol grip, as well as more texture to enhance the grip. The buttstock was lengthened by . The new buttstock became ten times stronger than the original due to advances in polymer technology since the early 1960s. Original M16 stocks were made from fiberglass-impregnated resin; the newer stocks were engineered from DuPont Zytel glass-filled thermoset polymers. The new stock included a fully textured polymer buttplate for better grip on the shoulder, and retained a panel for accessing a small compartment inside the stock, often used for storing a basic cleaning kit. The heavier bullet reduces muzzle velocity from , to about . The A2 uses a faster 1:7 twist rifling to allow use of a trajectory-matched tracer round. A spent case deflector was incorporated into the upper receiver immediately behind the ejection port to prevent cases from striking left-handed users. The action was also modified, replacing the fully automatic setting with a three-round burst setting. When using a fully automatic weapon, inexperienced troops often hold down the trigger and "spray" when under fire. The U.S. Army concluded that three-shot groups provide an optimum combination of ammunition conservation, accuracy, and firepower. The USMC has retired the M16A2 in favor of the newer M16A4; a few M16A2s remain in service with the U.S. Army Reserve and National Guard, Air Force, Navy and Coast Guard.

The M16A3 is a modified version of the M16A2 adopted in small numbers by the U.S. Navy SEAL, Seabee, and Security units. It features the M16A1 trigger group providing "safe", "semi-automatic" and "fully automatic" modes instead of the A2's "safe", "semi-automatic", and "burst" modes.

The M16A4 is the fourth generation of the M16 series. It is equipped with a removable carrying handle and a full length quad Picatinny rail for mounting optics and other ancillary devices. The FN M16A4, using safe/semi/burst selective fire, became standard issue for the U.S. Marine Corps and is the current issue to Marine Corps recruits in both MCRD San Diego and MCRD Parris Island as well as candidates at Officer Candidate School in Quantico, Virginia.

Military issue rifles are also equipped with a Knight's Armament Company M5 RAS hand guard, allowing vertical grips, lasers, tactical lights, and other accessories to be attached, coining the designation M16A4 MWS (or Modular Weapon System) in U.S. Army field manuals.

Colt also produces M16A4 models for international purchases, with specifics selective fire:

A study of significant changes to Marine M16A4 rifles released in February 2015 outlined several new features that could be added from inexpensive and available components. Those features included: a muzzle compensator in place of the flash suppressor to manage recoil and allow for faster follow-on shots, though at the cost of noise and flash signature and potential overpressure in close quarters; a heavier and/or free-floating barrel to increase accuracy from 4.5 MOA to potentially 2 MOA; changing the reticle on the Rifle Combat Optic from chevron-shaped to the semi-circle with a dot at the center used in the M27 IAR's Squad Day Optic so as not to obscure the target at long distance; using a trigger group with a more consistent pull force, even a reconsideration of the burst capability; and the addition of ambidextrous charging handles and bolt catch releases for easier use with left-handed shooters.

In 2014, Marine units were provided with a limited number of adjustable stocks in place of the traditional fixed stock for their M16A4s to issue to smaller Marines who would have trouble comfortably reaching the trigger when wearing body armor. The adjustable stocks were added as a standard authorized accessory, meaning units can use operations and maintenance funds to purchase more if needed.

The Marine Corps had long maintained the full-length M16 as their standard infantry rifle, but in October 2015 the switch to the M4 carbine was approved as the standard-issue weapon, giving Marine infantrymen a smaller and more compact weapon. Enough M4s are already in the inventory to re-equip all necessary units by September 2016, and M16A4s will be moved to support and non-infantry Marines.

In Vietnam, some soldiers were issued a carbine version of the M16 named XM177. The XM177 had a shorter barrel and a telescoping stock, which made it substantially more compact. It also possessed a combination flash hider/sound moderator to reduce problems with muzzle flash and loud report. The Air Force's GAU-5/A (XM177) and the Army's XM177E1 variants differed over the latter's inclusion of a forward assist, although some GAU-5s do have the forward assist. The final Air Force GAU-5/A and Army XM177E2 had an barrel with a longer flash/sound suppressor. The lengthening of the barrel was to support the attachment of Colt's own XM148 40 mm grenade launcher. These versions were also known as the Colt Commando model commonly referenced and marketed as the CAR-15. The variants were issued in limited numbers to special forces, helicopter crews, Air Force pilots, Air Force Security Police Military Working Dog (MWD) handlers, officers, radio operators, artillerymen, and troops other than front line riflemen. Some USAF GAU-5A/As were later equipped with even longer 1/12 rifled barrels as the two shorter versions were worn out. The barrel allowed the use of MILES gear and for bayonets to be used with the sub-machine guns (as the Air Force described them). By 1989, the Air Force started to replace the earlier barrels with 1/7 rifled models for use with the M855-round. The weapons were given the redesignation of GUU-5/P.

These were effectively used by the British Special Air Service during the Falklands War.

The M4 carbine was developed from various outgrowths of these designs, including a number of -barreled A1 style carbines. The XM4 (Colt Model 727) started its trials in the mid-1980s, with a barrel of . Officially adopted as a replacement for the M3 "Grease Gun" (and the Beretta M9 and M16A2 for select troops) in 1994, it was used with great success in the Balkans and in more recent conflicts, including the Afghanistan and Iraq theaters. The M4 carbine has a three-round burst firing mode, while the M4A1 carbine has a fully automatic firing mode. Both have a Picatinny rail on the upper receiver, allowing the carry handle/rear sight assembly to be replaced with other sighting devices.

Colt also returned to the original "Commando" idea, with its Model 733, essentially a modernized XM177E2 with many of the features introduced on the M16A2.

The Diemaco C7 and C8 are updated variants of the M16 developed and used by the Canadian Forces and are now manufactured by Colt Canada. The C7 is a further development of the experimental M16A1E1. Like earlier M16s, it can be fired in either semi-automatic or automatic mode, instead of the burst function selected for the M16A2. The C7 also features the structural strengthening, improved handguards, and longer stock developed for the M16A2. Diemaco changed the trapdoor in the buttstock to make it easier to access and a spacer of is available to adjust stock length to user preference. The most easily noticeable external difference between American M16A2s and Diemaco C7s is the retention of the A1 style rear sights. Not easily apparent is Diemaco's use of hammer-forged barrels. The Canadians originally desired to use a heavy barrel profile instead.

The C7 has been developed to the C7A1, with a Weaver rail on the upper receiver for a C79 optical sight, and to the C7A2, with different furniture and internal improvements. The Diemaco produced Weaver rail on the original C7A1 variants does not meet the M1913 "Picatinny" standard, leading to some problems with mounting commercial sights. This is easily remedied with minor modification to the upper receiver or the sight itself. Since Diemaco's acquisition by Colt to form Colt Canada, all Canadian produced flattop upper receivers are machined to the M1913 standard.

The C8 is the carbine version of the C7. The C7 and C8 are also used by "Hærens Jegerkommando", "Marinejegerkommandoen" and FSK (Norway), Military of Denmark (all branches), the Royal Netherlands Army and Netherlands Marine Corps as its main infantry weapon. Following trials, variants became the weapon of choice of the British SAS.

The Heckler & Koch HK416 is an assault rifle designed and manufactured by Heckler & Koch. It is based on the M16, and was originally conceived as an improvement based on the Colt M4 carbine family issued to the U.S. military, with the notable inclusion of an HK-proprietary short-stroke gas piston system derived from the Heckler & Koch G36. The HK416 was used by U.S. Navy SEALs to kill Osama bin Laden.

The Mk 4 Mod 0 was a variant of the M16A1 produced for the U.S. Navy SEALs during the Vietnam War and adopted in April 1970. It differed from the basic M16A1 primarily in being optimized for maritime operations and coming equipped with a sound suppressor. Most of the operating parts of the rifle were coated in Kal-Guard, a hole of was drilled through the stock and buffer tube for drainage, and an O-ring was added to the end of the buffer assembly. The weapon could reportedly be carried to the depth of 200 feet (60 m) in water without damage. The initial Mk 2 Mod 0 Blast Suppressor was based on the U.S. Army's Human Engineering Lab's (HEL) M4 noise suppressor. The HEL M4 vented gas directly from the action, requiring a modified bolt carrier. A gas deflector was added to the charging handle to prevent gas from contacting the user. Thus, the HEL M4 suppressor was permanently mounted though it allowed normal semi-automatic and automatic operation. If the HEL M4 suppressor were removed, the weapon would have to be manually loaded after each single shot. On the other hand, the Mk 2 Mod 0 blast suppressor was considered an integral part of the Mk 4 Mod 0 rifle, but it would function normally if the suppressor were removed. The Mk 2 Mod 0 blast suppressor also drained water much more quickly and did not require any modification to the bolt carrier or to the charging handle. In the late 1970s, the Mk 2 Mod 0 blast suppressor was replaced by the Mk 2 blast suppressor made by Knight's Armament Company (KAC). The KAC suppressor can be fully submerged and water will drain out in less than eight seconds. It will operate without degradation even if the rifle is fired at the maximum rate of fire. The U.S. Army replaced the HEL M4 with the much simpler Studies in Operational Negation of Insurgency and Counter-Subversion (SIONICS) MAW-A1 noise and flash suppressor.

Developed to increase the effective range of soldiers in the designated marksman role, the U.S. Navy developed the Mark 12 Special Purpose Rifle (SPR). Configurations in service vary, but the core of the Mark 12 SPR is an 18" heavy barrel with muzzle brake and free float tube. This tube relieves pressure on the barrel caused by standard handguards and greatly increases the potential accuracy of the system. Also common are higher magnification optics ranging from the 6× power Trijicon ACOG to the Leupold Mark 4 Tactical rifle scopes. Firing Mark 262 Mod 0 ammunition with a 77gr Open tip Match bullet, the system has an official effective range of 600+ meters. However published reports of confirmed kills beyond 800 m from Iraq and Afghanistan are not uncommon.

The M231 Firing Port Weapon (FPW) is an adapted version of the M16 assault rifle for firing from ports on the M2 Bradley. The infantry's normal M16s are too long for use in a "buttoned up" fighting vehicle, so the FPW was developed to provide a suitable weapon for this role.

With the expanding Vietnam War, Colt developed two rifles of the M16 pattern for evaluation as possible light sniper or designated marksman rifles. The Colt Model 655 M16A1 Special High Profile was essentially a standard A1 rifle with a heavier barrel and a scope bracket that attached to the rifle's carry handle. The Colt Model 656 M16A1 Special Low Profile had a special upper receiver with no carrying handle. Instead, it had a low-profile iron sight adjustable for windage and a Weaver base for mounting a scope, a precursor to the Colt and Picatinny rails. It also had a hooded front iron sight in addition to the heavy barrel. Both rifles came standard with either a Leatherwood/Realist scope 3–9× Adjustable Ranging Telescope. Some of them were fitted with a Sionics noise and flash suppressor. Neither of these rifles were ever standardized.

These weapons can be seen in many ways to be predecessors of the U.S. Army's SDM-R and the USMC's SAM-R weapons.


The M16 is the most commonly manufactured 5.56×45mm rifle in the world. Currently, the M16 is in use by 15 NATO countries and more than 80 countries worldwide. Together, numerous companies in the United States, Canada, and China have produced more than 8,000,000 rifles of all variants. Approximately 90% are still in operation. The M16 replaced both the M14 rifle and M2 carbine as standard infantry rifle of the U.S. armed forces. Although, the M14 continues to see limited service, mostly in sniper, designated marksman, and ceremonial roles.





</doc>
<doc id="19903" url="https://en.wikipedia.org/wiki?curid=19903" title="Marlon Brando">
Marlon Brando

Marlon Brando Jr. (April 3, 1924 – July 1, 2004) was an American actor and film director. He is credited with bringing realism to film acting and helping to popularize the Stanislavski system of acting having studied with Stella Adler in the 1940s. Regarded for his cultural influence on 20th century film, Brando's Academy Award-winning performances include that of Terry Malloy in "On the Waterfront" (1954) and Don Vito Corleone in "The Godfather" (1972). Brando was an activist for many causes, notably the civil rights movement and various Native American movements.

He initially gained acclaim and an Academy Award nomination for reprising the role of Stanley Kowalski in the 1951 film adaptation of Tennessee Williams' play "A Streetcar Named Desire", a role that he originated successfully on Broadway. He received further praise for his performance as Terry Malloy in "On the Waterfront", and his portrayal of the rebellious motorcycle gang leader Johnny Strabler in "The Wild One" proved to be a lasting image in popular culture. Brando received Academy Award nominations for playing Emiliano Zapata in "Viva Zapata!"; Mark Antony in Joseph L. Mankiewicz's 1953 film adaptation of Shakespeare's "Julius Caesar"; and Air Force Major Lloyd Gruver in "Sayonara" (1957), an adaption of James Michener's 1954 novel. Brando was included in a list of Top Ten Money Making Stars three times in the 1950s, coming in at number 10 in 1954, number 6 in 1955, and number 4 in 1958.

The 1960s saw Brando's career take a downturn. He directed and starred in the cult western film "One-Eyed Jacks", a critical and commercial flop, after which he delivered a series of box-office failures, beginning with the 1962 film adaptation of the novel "Mutiny on the Bounty". After 10 years, during which he did not appear in a successful film, he won his second Academy Award for playing Vito Corleone in Francis Ford Coppola's "The Godfather", a role critics consider among his greatest. "The Godfather" was then one of the most commercially successful films of all time. With that and his Oscar-nominated performance in "Last Tango in Paris", Brando re-established himself in the ranks of top box-office stars, placing sixth and tenth in the Money Making Stars poll in 1972 and 1973, respectively. Brando took a four-year hiatus before appearing in "The Missouri Breaks" (1976). After this, he was content with being a highly paid character actor in cameo roles, such as in "Superman" (1978) and "The Formula" (1980), before taking a nine-year break from motion pictures. According to the "Guinness Book of World Records", Brando was paid a record $3.7 million ($ million in inflation-adjusted dollars) and 11.75% of the gross profits for 13 days' work on "Superman". He finished out the 1970s with his controversial performance as Colonel Kurtz in another Coppola film, "Apocalypse Now", a box-office hit for which he was highly paid and which helped finance his career layoff during the 1980s.

Brando was ranked by the American Film Institute as the fourth-greatest movie star among male movie stars whose screen debuts occurred in or before 1950. He was one of six professional actors, along with Charlie Chaplin, Ronald Reagan, Lucille Ball, Frank Sinatra, and Marilyn Monroe, named in 1999 by "Time" magazine as one of its .

Brando was born on April 3, 1924, in Omaha, Nebraska, to Marlon Brando, Sr. (1895–1965), a pesticide and chemical feed manufacturer, and Dorothy Julia (née Pennebaker; 1897–1954). Brando had two older sisters, Jocelyn Brando (1919–2005) and Frances (1922–1994). His ancestry was German, Dutch, English, and Irish. His patrilineal immigrant ancestor, Johann Wilhelm Brandau, arrived in New York in the early 1700s from the Palatinate in Germany. Brando was raised a Christian Scientist.

His mother, known as Dodie, was unconventional for her time; she smoked, wore trousers and drove cars. An actress herself and even a theatre administrator, she helped Henry Fonda begin his acting career. However, she was an alcoholic and often had to be brought home from Chicago bars by her husband. In his autobiography, "Songs My Mother Taught Me", Brando expressed sadness when writing about his mother: "The anguish that her drinking produced was that she preferred getting drunk to caring for us." Dodie and Brando's father eventually joined Alcoholics Anonymous. Brando harbored far more enmity for his father, stating, "I was his namesake, but nothing I did ever pleased or even interested him. He enjoyed telling me I couldn't do anything right. He had a habit of telling me I would never amount to anything." Brando's parents moved to Evanston, Illinois, when his father's work took him to Chicago, but separated when Brando was 11 years old. His mother took the three children to Santa Ana, California, where they lived with her mother. In 1937, Brando's parents reconciled and moved together to Libertyville, Illinois, a small town north of Chicago. In 1939 and 1941, he worked as an usher at the town's only movie theatre, The Liberty.

Brando, whose childhood nickname was "Bud", was a mimic from his youth. He developed an ability to absorb the mannerisms of kids he played with and display them dramatically while staying in character. He was introduced to neighborhood boy Wally Cox and the two were unlikely closest friends until Cox's death in 1973. In the 2007 TCM biopic, "Brando: The Documentary", childhood friend George Englund recalls Brando's earliest acting as imitating the cows and horses on the family farm as a way to distract his mother from drinking. His sister Jocelyn was the first to pursue an acting career, going to study at the American Academy of Dramatic Arts in New York City. She appeared on Broadway, then films and television. Brando's sister Frances left college in California to study art in New York. Brando had been held back a year in school and was later expelled from Libertyville High School for riding his motorcycle through the corridors.

He was sent to Shattuck Military Academy, where his father had studied before him. Brando excelled at theatre and did well in the school. In his final year (1943), he was put on probation for being insubordinate to a visiting army colonel during maneuvers. He was confined to his room, but snuck into town and was caught. The faculty voted to expel him, though he was supported by the students, who thought expulsion was too harsh. He was invited back for the following year, but decided instead to drop out of high school. Brando worked as a ditch-digger as a summer job arranged by his father. He tried to enlist in the Army, but his induction physical revealed that a football injury he had sustained at Shattuck had left him with a trick knee. He was classified 4-F and not inducted.

Brando decided to follow his sisters to New York, studying at the American Theatre Wing Professional School, part of the Dramatic Workshop of the New School, with influential German director Erwin Piscator. In a 1988 documentary, "Marlon Brando: The Wild One", Brando's sister Jocelyn remembered, "He was in a school play and enjoyed it ... So he decided he would go to New York and study acting because that was the only thing he had enjoyed. That was when he was 18." In the A&E "Biography" episode on Brando, George Englund said Brando fell into acting in New York because "he was accepted there. He wasn't criticized. It was the first time in his life that he heard good things about himself."

Brando was an avid student and proponent of Stella Adler, from whom he learned the techniques of the Stanislavski system. This technique encouraged the actor to explore both internal and external aspects to fully realize the character being portrayed. Brando's remarkable insight and sense of realism were evident early on. Adler used to recount that when teaching Brando, she had instructed the class to act like chickens, and added that a nuclear bomb was about to fall on them. Most of the class clucked and ran around wildly, but Brando sat calmly and pretended to lay an egg. Asked by Adler why he had chosen to react this way, he said, "I'm a chicken—what do I know about bombs?" Despite being commonly regarded as a Method actor, Brando disagreed. He claimed to have abhorred Lee Strasberg's teachings:

Brando was the first to bring a natural approach to acting on film. According to Dustin Hoffman in his online Masterclass, Brando would often talk to camera men and fellow actors about their weekend even after the director would call action. Once Brando felt he could deliver the dialogue as natural as that conversation he would start the dialogue. In his 2015 documentary, "Listen To Me Marlon", he said before that actors were like breakfast cereals. He was calling them predictable. Critics would later say this was Brando being difficult, but actors who worked opposite would say it was just all part of his technique.

Brando used his Stanislavski System skills for his first summer stock roles in Sayville, New York, on Long Island. Brando established a pattern of erratic, insubordinate behavior in the few shows he had been in. His behavior had him kicked out of the cast of the New School's production in Sayville, but he was soon afterwards discovered in a locally produced play there. Then, in 1944, he made it to Broadway in the bittersweet drama "I Remember Mama", playing the son of Mady Christians. The Lunts wanted Brando to play the role of Alfred Lunt's son in "O Mistress Mine", and Lunt even coached him for his audition, but Brando's reading during the audition was so desultory that they couldn't hire him. New York Drama Critics voted him "Most Promising Young Actor" for his role as an anguished veteran in "Truckline Café", although the play was a commercial failure. In 1946, he appeared on Broadway as the young hero in the political drama "A Flag is Born", refusing to accept wages above the Actors' Equity rate. In that same year, Brando played the role of Marchbanks alongside Katharine Cornell in her production's revival of "Candida", one of her signature roles. Cornell also cast him as the Messenger in her production of Jean Anouilh's "Antigone" that same year. He was also offered the opportunity to portray one of the principal characters in the Broadway premiere of Eugene O'Neill's "The Iceman Cometh", but turned the part down after falling asleep while trying to read the massive script and pronouncing the play "ineptly written and poorly constructed".

In 1945, Brando's agent recommended he take a co-starring role in "The Eagle Has Two Heads" with Tallulah Bankhead, produced by Jack Wilson. Bankhead had turned down the role of Blanche Dubois in "A Streetcar Named Desire", which Williams had written for her, to tour the play for the 1946–1947 season. Bankhead recognized Brando's potential, despite her disdain (which most Broadway veterans shared) for method acting, and agreed to hire him even though he auditioned poorly. The two clashed greatly during the pre-Broadway tour, with Bankhead reminding Brando of his mother, being her age and also having a drinking problem. Wilson was largely tolerant of Brando's behavior, but he reached his limit when Brando mumbled through a dress rehearsal shortly before the November 28, 1946, opening. "I don't care what your grandmother did," Wilson exclaimed, "and that Method stuff, I want to know what you're going to do!" Brando in turn raised his voice, and acted with great power and passion. "It was marvelous," a cast member recalled. "Everybody hugged him and kissed him. He came ambling offstage and said to me, 'They don't think you can act unless you can yell.'"

Critics were not as kind, however. A review of Brando's performance in the opening assessed that Brando was "still building his character, but at present fails to impress." One Boston critic remarked of Brando's prolonged death scene, "Brando looked like a car in midtown Manhattan searching for a parking space." He received better reviews at subsequent tour stops, but what his colleagues recalled was only occasional indications of the talent he would later demonstrate. "There were a few times when he was really magnificent," Bankhead admitted to an interviewer in 1962. "He was a great young actor when he wanted to be, but most of the time I couldn't even hear him on the stage."

Brando displayed his apathy for the production by demonstrating some shocking onstage manners. He "tried everything in the world to ruin it for her," Bankhead's stage manager claimed. "He nearly drove her crazy: scratching his crotch, picking his nose, doing anything." After several weeks on the road, they reached Boston, by which time Bankhead was ready to dismiss him. This proved to be one of the greatest blessings of his career, as it freed him up to play the role of Stanley Kowalski in Tennessee Williams's 1947 play "A Streetcar Named Desire", directed by Elia Kazan. Bankhead had recommended him to Williams for the role of Stanley, thinking he was perfect for the part.

Pierpont writes that John Garfield was first choice for the role, but "made impossible demands." It was Kazan's decision to fall back on the far less experienced (and technically too young for the role) Brando. In a letter dated August 29, 1947, Williams confided to his agent Audrey Wood: "It had not occurred to me before what an excellent value would come through casting a very young actor in this part. It humanizes the character of Stanley in that it becomes the brutality and callousness of youth rather than a vicious old man ... A new value came out of Brando's reading which was by far the best reading I have ever heard." Brando based his portrayal of Kowalski on the boxer Rocky Graziano, whom he had studied at a local gymnasium. Graziano did not know who Brando was, but attended the production with tickets provided by the young man. He said, "The curtain went up and on the stage is that son of a bitch from the gym, and he's playing me."

In 1947, Brando performed a screen test for an early Warner Brothers script for the novel "Rebel Without a Cause" (1944), which bore no relation to the film eventually produced in 1955. The screen test is included as an extra in the 2006 DVD release of "A Streetcar Named Desire".

Brando's first screen role was a bitter paraplegic veteran in "The Men" (1950). He spent a month in bed at the Birmingham Army Hospital in Van Nuys to prepare for the role. "The New York Times" reviewer Bosley Crowther wrote that Brando as Ken "is so vividly real, dynamic and sensitive that his illusion is complete" and noted, "Out of stiff and frozen silences he can lash into a passionate rage with the tearful and flailing frenzy of a taut cable suddenly cut."

By Brando's own account, it may have been because of this film that his draft status was changed from 4-F to 1-A. He had had surgery on his trick knee, and it was no longer physically debilitating enough to incur exclusion from the draft. When Brando reported to the induction center, he answered a questionnaire by saying his race was "human", his color was "Seasonal-oyster white to beige", and he told an Army doctor that he was psychoneurotic. When the draft board referred him to a psychiatrist, Brando explained that he had been expelled from military school and had severe problems with authority. Coincidentally, the psychiatrist knew a doctor friend of Brando. Brando avoided military service during the Korean War.

Early in his career, Brando began using cue cards instead of memorizing his lines. Despite the objections of several of the film directors he worked with, Brando felt that this helped bring realism and spontaneity to his performances. He felt otherwise he would appear to be reciting a writer's speech. In the TV documentary "The Making of Superman: The Movie", Brando explained: 

However, some thought Brando used the cards out of laziness or an inability to memorize his lines. Once on "The Godfather" set, Brando was asked why he wanted his lines printed out. He responded, "Because I can read them that way."

Brando brought his performance as Stanley Kowalski to the screen in Tennessee William's "A Streetcar Named Desire" (1951). The role is regarded as one of Brando's greatest. The reception of Brando's performance was so positive that Brando quickly became a male sex symbol in Hollywood. The role earned him his first Academy Award nomination in the Best Actor category.
He was also nominated the next year for "Viva Zapata!" (1952), a fictionalized account of the life of Mexican revolutionary Emiliano Zapata. It recounted his peasant upbringing, his rise to power in the early 20th century, and death. The film was directed by Elia Kazan and co-starred Anthony Quinn. In the biopic "Marlon Brando: The Wild One", Sam Shaw says, "Secretly, before the picture started, he went to Mexico to the very town where Zapata lived and was born in and it was there that he studied the speech patterns of people, their behavior, movement." Most critics focused on the actor rather than the film, with "Time" and "Newsweek" publishing rave reviews.

Years later, in his autobiography, Brando remarked: "Tony Quinn, whom I admired professionally and liked personally, played my brother, but he was extremely cold to me while we shot that picture. During our scenes together, I sensed a bitterness toward me, and if I suggested a drink after work, he either turned me down or else was sullen and said little. Only years later did I learn why." Brando related that, to create on-screen tension between the two, "Gadg" (Kazan) had told Quinn—who had taken over the role of Stanley Kowalski on Broadway after Brando had finished—that Brando had been unimpressed with his work. After achieving the desired effect, Kazan never told Quinn that he had misled him. It was only many years later, after comparing notes, that Brando and Quinn realized the deception.

Brando's next film, "Julius Caesar" (1953), received highly favorable reviews. Brando portrayed Mark Antony. While most acknowledged Brando's talent, some critics felt Brando's "mumbling" and other idiosyncrasies betrayed a lack of acting fundamentals and, when his casting was announced, many remained dubious about his prospects for success. Directed by Joseph L. Mankiewicz and co-starring British stage actor John Gielgud, Brando delivered an impressive performance, especially during Antony's noted "Friends, Romans, countrymen ..." speech. Gielgud was so impressed that he offered Brando a full season at the Hammersmith Theatre, an offer he declined. In his biography on the actor, Stefan Kanfer writes, "Marlon's autobiography devotes one line to his work on that film: Among all those British professionals, 'for me to walk onto a movie set and play Mark Anthony was asinine'—yet another example of his persistent self-denigration, and wholly incorrect." Kanfer adds that after a screening of the film, director John Huston commented, "Christ! It was like a furnace door opening—the heat came off the screen. I don't know another actor who could do that." During the filming of "Julius Caesar", Brando learned that Elia Kazan had cooperated with congressional investigators, naming a whole string of "subversives" to the House Committee on Un-American Activities. By all accounts, Brando was upset by his mentor's decision, but he worked with him again in "On The Waterfront". "None of us is perfect," he later wrote in his memoir, "and I think that Gadg has done injury to others, but mostly to himself."

In 1953, Brando also starred in "The Wild One", riding his own Triumph Thunderbird 6T motorcycle. Triumph's importers were ambivalent at the exposure, as the subject matter was rowdy motorcycle gangs taking over a small town. The film was criticized for its perceived gratuitous violence at the time, with "Time" stating, "The effect of the movie is not to throw light on the public problem, but to shoot adrenaline through the moviegoer's veins." Brando allegedly did not see eye to eye with the Hungarian director László Benedek and did not get on with costar Lee Marvin.

To Brando's expressed puzzlement, the movie inspired teen rebellion and made him a role model to the nascent rock-and-roll generation and future stars such as James Dean and Elvis Presley. After the movie's release, the sales of leather jackets and blue jeans skyrocketed. Reflecting on the movie in his autobiography, Brando concluded that it had not aged very well but said:

In 1954, Brando starred in "On the Waterfront", a crime drama film about union violence and corruption among longshoremen. The film was directed by Elia Kazan and written by Budd Schulberg; it also stars Karl Malden, Lee J. Cobb, Rod Steiger and, in her film debut, Eva Marie Saint. When initially offered the role, Brando—still stung by Kazan's testimony to HUAC—demurred and the part of Terry Malloy nearly went to Frank Sinatra. According to biographer Stefan Kanfer, the director believed that Sinatra, who grew up in Hoboken, would work as Malloy, but eventually producer Sam Spiegel wooed Brando to the part, signing him for $100,000. "Kazan made no protest because, he subsequently confessed, 'I always preferred Brando to anybody.'"
Brando won the Oscar for his role as Irish-American stevedore Terry Malloy in "On the Waterfront". His performance, spurred on by his rapport with Eva Marie Saint and Kazan's direction, was praised as a "tour de force". For the famous "I coulda been a contender" scene, he convinced Kazan that the scripted scene was unrealistic. Schulberg's script had Brando acting the entire scene with his character being held at gunpoint by his brother Charlie, played by Rod Steiger. Brando insisted on gently pushing away the gun, saying that Terry would never believe that his brother would pull the trigger and doubting that he could continue his speech while fearing a gun on him. Kazan let Brando improvise and later expressed deep admiration for Brando's instinctive understanding, saying:
Upon its release, "On the Waterfront" received glowing reviews from critics and was a commercial success, earning an estimated $4.2 million in rentals at the North American box office in 1954. In his July 29, 1954, review, "The New York Times" critic A. H. Weiler praised the film, calling it "an uncommonly powerful, exciting, and imaginative use of the screen by gifted professionals." Film critic Roger Ebert lauded the film, stating that Brando and Kazan changed acting in American films forever and added it to his "Great Movies" list. In his autobiography, Brando was typically dismissive of his performance: "On the day Gadg showed me the complete picture, I was so depressed by my performance I got up and left the screening room ... I thought I was a huge failure." After Brando won the Academy Award for Best Actor, the statue was stolen. Much later, it turned up at a London auction house, which contacted the actor and informed him of its whereabouts.

Brando would later say in his 2015 documentary, Listen to me Marlon, that he felt the part in "On the Waterfront" that won him an Oscar was to him personally, not good, and that he knew he had done better acting. In the behind the scenes of "On the Waterfront" film experts and critics would say he would change lines because he didn't like the script, and that he'd let the director know by having regular conversations. However, this was a way for Brando to prepare before a scene by warming up before starting the dialogue, in order to deliver it as natural as possible. Brando often saw a shrink, and reportedly wasn't there for some of the shooting of the scene when the close up was on the opposite actor. This is why this part of his technique is recognized mistakenly as him being difficult, and not a part of his approach.

Following "On the Waterfront", Brando remained a top box office draw, but critics increasingly felt his performances were half-hearted, lacking the intensity and commitment found in his earlier work, especially in his work with Kazan. He portrayed Napoleon in the 1954 film "Désirée". According to co-star Jean Simmons, Brando's contract forced him to star in the movie. He put little effort into the role, claiming he didn't like the script, and later dismissed the entire movie as "superficial and dismal". Brando was especially contemptuous of director Henry Koster.

Brando and Simmons were paired together again in the film adaptation of the musical "Guys and Dolls" (1955). "Guys and Dolls" would be Brando's first and last musical role. "Time" found the picture "false to the original in its feeling", remarking that Brando "sings in a faraway tenor that sometimes tends to be flat." Appearing in Edward Murrow's "Person to Person" interview in early 1955, he admitted to having problems with his singing voice, which he called "pretty terrible." In the 1965 documentary "Meet Marlon Brando", he revealed that the final product heard in the movie was a result of countless singing takes being cut into one and later joked, "I couldn't hit a note with a baseball bat; some notes I missed by extraordinary margins ... They sewed my words together on one song so tightly that when I mouthed it in front of the camera, I nearly asphyxiated myself". Relations between Brando and costar Frank Sinatra were also frosty, with Stefan Kanfer observing, "The two men were diametrical opposites: Marlon required multiple takes; Frank detested repeating himself." Upon their first meeting Sinatra reportedly scoffed, "Don't give me any of that Actors Studio shit." Brando later famously quipped, "Frank is the kind of guy, when he dies, he's going to heaven and give God a hard time for making him bald." Frank Sinatra famously called Brando "the world's most overrated actor", and referred to him as "mumbles". The film was commercially though not critically successful, costing $5.5 million to make and grossing $13 million.

Brando played Sakini, a Japanese interpreter for the U.S. Army in postwar Japan, in "The Teahouse of the August Moon" (1956). Pauline Kael was not particularly impressed by the movie, but noted "Marlon Brando starved himself to play the pixie interpreter Sakini, and he looks as if he's enjoying the stunt—talking with a mad accent, grinning boyishly, bending forward, and doing tricky movements with his legs. He's harmlessly genial (and he is certainly missed when he's offscreen), though the fey, roguish role doesn't allow him to do what he's great at and it's possible that he's less effective in it than a lesser actor might have been." In "Sayonara" (1957) he appeared as a United States Air Force officer. "Newsweek" found the film a "dull tale of the meeting of the twain", but it was nevertheless a box office success. According to Stefan Kanfer's biography of the actor, Brando's manager Jay Kanter negotiated a profitable contract with ten percent of the gross going to Brando, which put him in the millionaire category. The movie was controversial due to openly discussing interracial marriage, but proved a great success, earning 10 Academy Award nominations, with Brando being nominated for Best Actor. The film went on to win four Academy Awards. "Teahouse" and "Sayonara" were the first in a string of films Brando would strive to make over the next decade which contained socially relevant messages, and he formed a partnership with Paramount to establish his own production company called Pennebaker, its declared purpose to develop films that contained "social value that would improve the world." The name was a tribute in honor of his mother, who had died in 1954. By all accounts, Brando was devastated by her death, with biographer Peter Manso telling A&E's "Biography", "She was the one who could give him approval like no one else could and, after his mother died, it seems that Marlon stops caring." Brando appointed his father to run Pennebaker. In the same A&E special, George Englund claims that Brando gave his father the job because "it gave Marlon a chance to take shots at him, to demean and diminish him".

In 1958, Brando appeared in "The Young Lions", dyeing his hair blonde and assuming a German accent for the role, which he later admitted was not convincing. The film is based on the novel by Irwin Shaw, and Brando's portrayal of the character Christian Diestl was controversial for its time. He later wrote, "The original script closely followed the book, in which Shaw painted all Germans as evil caricatures, especially Christian, whom he portrayed as a symbol of everything that was bad about Nazism; he was mean, nasty, vicious, a cliché of evil ... I thought the story should demonstrate that there are no inherently 'bad' people in the world, but they can easily be misled." Shaw and Brando even appeared together for a televised interview with CBS correspondent David Schoenbrun and, during a bombastic exchange, Shaw charged that, like most actors, Brando was incapable of playing flat-out villainy; Brando responded by stating "Nobody creates a character but an actor. I play the role; now he exists. He is my creation." "The Young Lions" also features Brando's only appearance in a film with friend and rival Montgomery Clift (although they shared no scenes together). Brando closed out the decade by appearing in "The Fugitive Kind" (1960) opposite Anna Magnani. The film was based on another play by Tennessee Williams but was hardly the success "A Streetcar Named Desire" had been, with the "Los Angeles Times" labeling Williams's personae "psychologically sick or just plain ugly" and "The New Yorker" calling it a "cornpone melodrama".

In 1961, Brando made his directorial debut in the western "One-Eyed Jacks". The picture was originally directed by Stanley Kubrick, but he was fired early in the production. Paramount then made Brando the director. Brando portrays the lead character Rio, and Karl Malden plays his partner "Dad" Longworth. The supporting cast features Katy Jurado, Ben Johnson, and Slim Pickens. Brando's penchant for multiple retakes and character exploration as an actor carried over into his directing, however, and the film soon went over budget; Paramount expected the film to take three months to complete but shooting stretched to six and the cost doubled to more than six million dollars. Brando's inexperience as an editor also delayed postproduction and Paramount eventually took control of the film. Brando later wrote, "Paramount said it didn't like my version of the story; I'd had everyone lie except Karl Malden. The studio cut the movie to pieces and made him a liar, too. By then, I was bored with the whole project and walked away from it." "One-Eyed Jacks" was poorly reviewed by critics. While the film did solid business, it ran so over budget that it lost money.

Brando's revulsion with the film industry reportedly boiled over on the set of his next film, Metro-Goldwyn-Mayer's remake of "Mutiny on the Bounty", which was filmed in Tahiti. The actor was accused of deliberately sabotaging nearly every aspect of the production. On June 16, 1962, "The Saturday Evening Post" ran an article by Bill Davidson with the headline "Six million dollars down the drain: the mutiny of Marlon Brando". "Mutiny" director Lewis Milestone claimed that the executives "deserve what they get when they give a ham actor, a petulant child, complete control over an expensive picture." " Mutiny on the Bounty" nearly capsized MGM and, while the project had indeed been hampered with delays other than Brando's behavior, the accusations would dog the actor for years as studios began to fear Brando's difficult reputation. Critics also began taking note of his fluctuating weight.

Distracted by his personal life and becoming disillusioned with his career, Brando began to view acting as a means to a financial end. Critics protested when he started accepting roles in films many perceived as being beneath his talent, or criticized him for failing to live up to the better roles. Previously only signing short term deals with film studios, in 1961 Brando uncharacteristically signed a five-picture deal with Universal Studios that would haunt him for the rest of the decade. "The Ugly American" (1963) was the first of these films. Based on the 1958 novel of the same name that Pennebaker had optioned, the film, which featured Brando's sister Jocelyn, was rated fairly positively but died at the box office. Brando was nominated for a Golden Globe for his performance. All of Brando's other Universal films during this period, including "Bedtime Story" (1964), "The Appaloosa" (1966), "A Countess from Hong Kong" (1967) and "The Night of the Following Day" (1969), were also critical and commercial flops. "Countess" in particular was a disappointment for Brando, who had looked forward to working with one of his heroes, director Charlie Chaplin. The experience turned out to be an unhappy one; Brando was horrified at Chaplin's didactic style of direction and his authoritarian approach. Brando had also appeared in the spy thriller "Morituri" in 1965; that, too, failed to attract an audience.

Brando acknowledged his professional decline, writing later, "Some of the films I made during the sixties were successful; some weren't. Some, like "The Night of the Following Day", I made only for the money; others, like "Candy", I did because a friend asked me to and I didn't want to turn him down ... In some ways I think of my middle age as the Fuck You Years." "Candy" was especially appalling for many; a 1968 sex farce film directed by Christian Marquand and based on the 1958 novel by Terry Southern, the film satirizes pornographic stories through the adventures of its naive heroine, Candy, played by Ewa Aulin. It is generally regarded as the nadir of Brando's career. "The Washington Post" observed: "Brando's self-indulgence over a dozen years is costing him and his public his talents." In the March 1966 issue of "The Atlantic", Pauline Kael wrote that in his rebellious days, Brando "was antisocial because he knew society was crap; he was a hero to youth because he was strong enough not to take the crap", but now Brando and others like him had become "buffoons, shamelessly, pathetically mocking their public reputations." In an earlier review of "The Appaloosa" in 1966, Kael wrote that the actor was "trapped in another dog of a movie ... Not for the first time, Mr. Brando gives us a heavy-lidded, adenoidally openmouthed caricature of the inarticulate, stalwart loner." Although he feigned indifference, Brando was hurt by the critical mauling, admitting in the 2015 film "Listen to Me Marlon", "They can hit you every day and you have no way of fighting back. I was very convincing in my pose of indifference, but I was very sensitive and it hurt a lot."

While Brando had lost much of his critical and commercial appeal in the 1960s, he still gave some memorable performances. Brando portrayed a repressed gay army officer in "Reflections in a Golden Eye", directed by John Huston and costarring Elizabeth Taylor. The role turned out as one of his most acclaimed in years, with Stanley Crouch marveling, "Brando's main achievement was to portray the taciturn but stoic gloom of those pulverized by circumstances." The film overall received mixed reviews. Another notable film was "The Chase" (1966), which paired the actor with Arthur Penn, Robert Duvall, Jane Fonda and Robert Redford. The film deals with themes of racism, sexual revolution, small-town corruption, and vigilantism. The film was received mostly positively.

Brando cited "Burn!" (1969) as his personal favorite of the films he had made, writing in his autobiography, "I think I did some of the best acting I've ever done in that picture, but few people came to see it." Brando dedicated a full chapter to the film in his memoir, stating that the director, Gillo Pontecorvo, was the best director he had ever worked with next to Kazan and Bernardo Bertolucci. Brando also detailed his clashes with Pontecorvo on the set and how "we nearly killed each other." Loosely based on events in the history of Guadeloupe, the film got a hostile reception from critics. In 1971, Michael Winner directed him in the British horror film "The Nightcomers" with Stephanie Beacham, Thora Hird, Harry Andrews and Anna Palk. It is a prequel to "The Turn of the Screw", which later became the 1961 film "The Innocents". Brando's performance earned him a nomination for a Best Actor BAFTA, but the film bombed at the box office.

During the 1970s, Brando was considered "unbankable". Critics were becoming increasingly dismissive of his work and he had not appeared in a box office hit since "The Young Lions" in 1958, the last year he had ranked as one of the Top Ten Box Office Stars and the year of his last Academy Award nomination, for "Sayonara." Brando's performance as Vito Corleone, the "Don," in "The Godfather" (1972), Francis Ford Coppola's adaptation of Mario Puzo's 1969 best-selling novel of the same name, was a career turning point, putting him back in the Top Ten and winning him his second Best Actor Oscar.

Paramount production chief Robert Evans, who had given Puzo an advance to write "The Godfather" so that Paramount would own the film rights, hired Coppola after many major directors had turned the film down. Evans wanted an Italian-American director who could provide the film with cultural authenticity. Coppola also came cheap. Evans was conscious of the fact that Paramount's last Mafia film, "The Brotherhood" (1968) had been a box office bomb, and he believed it was partly due to the fact that the director, Martin Ritt, and the star, Kirk Douglas, were Jews and the film lacked an authentic Italian flavor. The studio originally intended the film to be a low-budget production set in contemporary times without any major actors, but the phenomenal success of the novel gave Evans the clout to turn "The Godfather" into a prestige picture.

Coppola had developed a list of actors for all the roles, and his list of potential Dons included the Oscar-winning Italian-American Ernest Borgnine, the Italian-American Frank de Kova (best known for playing Chief Wild Eagle on the TV sitcom "F-Troop"), John Marley (a Best Supporting Oscar-nominee for Paramount's 1970 hit film "Love Story" who was cast as the film producer Jack Woltz in the picture), the Italian-American Richard Conte (who was cast as Don Corleone's deadly rival Don Emilio Barzini), and Italian film producer Carlo Ponti. Coppola admitted in a 1975 interview, "We finally figured we had to lure the "best" actor in the world. It was that simple. That boiled down to Laurence Olivier or Marlon Brando, who "are" the greatest actors in the world." The holographic copy of Coppola's cast list shows Brando's name underlined.

Evans told Coppola that he had been thinking of Brando for the part two years earlier, and Puzo had imagined Brando in the part when he wrote the novel and had actually written to him about the part, so Coppola and Evans narrowed it down to Brando. (Ironically, Olivier would compete with Brando for the Best Actor Oscar for his part in "Sleuth." He bested Brando at the 1972 New York Film Critics Circle Awards.) Albert S. Ruddy, whom Paramount assigned to produce the film, agreed with the choice of Brando. However, Paramount studio heads were opposed to casting Brando due to his reputation for difficulty and his long string of box office flops. Brando also had "One-Eyed Jacks" working against him, a troubled production that lost money for Paramount when it was released in 1961. Paramount Pictures President Stanley Jaffe told an exasperated Coppola, "As long as I'm president of this studio, Marlon Brando will not be in this picture, and I will no longer allow you to discuss it."

Jaffe eventually set three conditions for the casting of Brando: That he would have to take a fee far below what he typically received; he'd have to agree to accept financial responsibility for any production delays his behavior cost; and he had to submit to a screen test. Coppola convinced Brando to a videotaped "make-up" test, in which Brando did his own makeup (he used cotton balls to simulate the character's puffed cheeks). Coppola had feared Brando might be too young to play the Don, but was electrified by the actor's characterization as the head of a crime family. Even so, he had to fight the studio in order to cast the temperamental actor. Brando had doubts himself, stating in his autobiography, "I had never played an Italian before, and I didn't think I could do it successfully." Eventually, Charles Bluhdorn, the president of Paramount parent Gulf+Western, was won over to letting Brando have the role; when he saw the screen test, he asked in amazement, "What are we watching? Who is this old guinea?" Brando was signed for a low fee of $50,000, but in his contract, he was given a percentage of the gross on a sliding scale: 1% of the gross for each $10 million over a $10 million threshold, up to 5% if the picture exceeded $60 million. According to Evans, Brando sold back his points in the picture for $100,000, as he was in dire need of funds. "That $100,000 cost him $11 million," Evans claimed.

In a 1994 interview that can be found on the Academy of Achievement website, Coppola insisted, ""The Godfather" was a very unappreciated movie when we were making it. They were very unhappy with it. They didn't like the cast. They didn't like the way I was shooting it. I was always on the verge of getting fired." When word of this reached Brando, he threatened to walk off the picture, writing in his memoir, "I strongly believe that directors are entitled to independence and freedom to realize their vision, though Francis left the characterizations in our hands and we had to figure out what to do." In a 2010 television interview with Larry King, Al Pacino also talked about how Brando's support helped him keep the role of Michael Corleone in the movie—despite the fact Coppola wanted to fire him. Brando was on his best behavior during filming, buoyed by a cast that included Pacino, Robert Duvall, James Caan, and Diane Keaton. In the "Vanity Fair" article "The Godfather Wars", Mark Seals writes, "With the actors, as in the movie, Brando served as the head of the family. He broke the ice by toasting the group with a glass of wine. 'When we were young, Brando was like the godfather of actors,' says Robert Duvall. 'I used to meet with Dustin Hoffman in Cromwell's Drugstore, and if we mentioned his name once, we mentioned it 25 times in a day.' Caan adds, 'The first day we met Brando everybody was in awe.'"

Brando's performance was glowingly reviewed by critics. "I thought it would be interesting to play a gangster, maybe for the first time in the movies, who wasn't like those bad guys Edward G. Robinson played, but who is kind of a hero, a man to be respected," Brando recalled in his autobiography. "Also, because he had so much power and unquestioned authority, I thought it would be an interesting contrast to play him as a gentle man, unlike Al Capone, who beat up people with baseball bats." Duvall later marveled to A&E's "Biography", "He minimized the sense of beginning. In other words he, like, deemphasized the word "action". He would go in front of that camera just like he was before. "Cut!" It was all the same. There was really no beginning. I learned a lot from watching that." Brando won the Academy Award for Best Actor for his performance, but he declined it, becoming the second actor to refuse a Best Actor award (after George C. Scott for "Patton"). He boycotted the award ceremony, instead sending aboriginal American rights activist Sacheen Littlefeather, who appeared in full Apache attire, to state Brando's reasons, which were based on his objection to the depiction of aboriginal Americans by Hollywood and television.

The actor followed "The Godfather" with Bernardo Bertolucci's 1972 film "Last Tango in Paris" opposite Maria Schneider, but Brando's highly noted performance threatened to be overshadowed by an uproar over the sexual content of the film. Brando portrays a recent American widower named Paul, who begins an anonymous sexual relationship with a young, betrothed Parisian woman named Jeanne. As with previous films, Brando refused to memorize his lines for many scenes; instead, he wrote his lines on cue cards and posted them around the set for easy reference, leaving Bertolucci with the problem of keeping them out of the picture frame. The film features several intense, graphic scenes involving Brando, including Paul anally raping Jeanne using butter as a lubricant, which, it was alleged was not consensual, and Paul's angry, emotionally charged final confrontation with the corpse of his dead wife. The controversial movie was a hit, however, and Brando made the list of Top Ten Box Office Stars for the last time. The voting membership of the Academy of Motion Picture Arts & Sciences again nominated Brando for Best Actor, his seventh nomination. Although Brando won the 1973 New York Film Critics Circle Awards, the actor did not appear at the ceremony or send a representative to pick up the award if he won.

Critic Pauline Kael, in her famous "New Yorker" review, wrote "The movie breakthrough has finally come. Bertolucci and Brando have altered the face of an art form." Brando confessed in his autobiography, "To this day I can't say what "Last Tango in Paris" was about," and added the film "required me to do a lot of emotional arm wrestling with myself, and when it was finished, I decided that I wasn't ever again going to destroy myself emotionally to make a movie. I felt I had violated my innermost self and I didn't want to suffer like that anymore ... You can't fake it."

In 1973, Brando was devastated by the death of his childhood best friend Wally Cox. Brando slept in Cox's pajamas and wrenched his ashes from his widow. She was going to sue for their return, but finally said "I think Marlon needs the ashes more than I do."

In 1976, Brando appeared in "The Missouri Breaks" with his friend Jack Nicholson. The movie also reunited the actor with director Arthur Penn. As biographer Stefan Kanfer describes, Penn had difficulty controlling Brando, who seemed intent on going over the top with his border-ruffian-turned-contract-killer Robert E. Lee Clayton: "Marlon made him a cross-dressing psychopath. Absent for the first hour of the movie, Clayton enters on horseback, dangling upside down, caparisoned in white buckskin, Littlefeather-style. He speaks in an Irish accent for no apparent reason. Over the next hour, also for no apparent reason, Clayton assumes the intonation of a British upper-class twit and an elderly frontier woman, complete with a granny dress and matching bonnet. Penn, who believed in letting actors do their thing, indulged Marlon all the way." Critics were unkind, with "The Observer" calling Brando's performance "one of the most extravagant displays of "grandedamerie" since Sarah Bernhardt", while "The Sun" complained, "Marlon Brando at fifty-two has the sloppy belly of a sixty-two-year-old, the white hair of a seventy-two-year-old, and the lack of discipline of a precocious twelve-year-old." However, Kanfer noted: "Even though his late work was met with disapproval, a re-examination shows that often, in the middle of the most pedestrian scene, there would be a sudden, luminous occurrence, a flash of the old Marlon that showed how capable he remained."

In 1977, Brando made a rare television appearance in the miniseries "", portraying George Lincoln Rockwell; he won a Primetime Emmy Award for Outstanding Supporting Actor in a Miniseries or a Movie for his performance. In 1978, he narrated the English version of "Raoni", a French-Belgian documentary film directed by Jean-Pierre Dutilleux and Luiz Carlos Saldanha that focused on the life of Raoni Metuktire and issues surrounding the survival of the indigenous Indian tribes of north central Brazil. Brando portrayed Superman's father Jor-El in the 1978 film "Superman". He agreed to the role only on assurance that he would be paid a large sum for what amounted to a small part, that he would not have to read the script beforehand, and that his lines would be displayed somewhere off-camera. It was revealed in a documentary contained in the 2001 DVD release of "Superman" that he was paid $3.7 million for two weeks of work. Brando also filmed scenes for the movie's sequel, "Superman II", but after producers refused to pay him the same percentage he received for the first movie, he denied them permission to use the footage. "I asked for my usual percentage," he recollected in his memoir, "but they refused, and so did I." However, after Brando's death, the footage was reincorporated into the 2006 re-cut of the film, "" and in the 2006 "loose sequel" "Superman Returns", in which both used and unused archive footage of him as Jor-El from the first two "Superman" films was remastered for a scene in the Fortress of Solitude, and Brando's voice-overs were used throughout the film.

Brando starred as Colonel Walter E. Kurtz in Francis Ford Coppola's Vietnam epic "Apocalypse Now" (1979). He plays a highly decorated U.S. Army Special Forces officer who goes renegade, running his own operation based in Cambodia and is feared by the U.S. military as much as the Vietnamese. Brando was paid $1 million a week for 3 weeks work. The film drew attention for its lengthy and troubled production, as Eleanor Coppola's documentary "Hearts of Darkness: A Filmmaker's Apocalypse" documents: Brando showed up on the set overweight, Martin Sheen suffered a heart attack, and severe weather destroyed several expensive sets. The film's release was also postponed several times while Coppola edited millions of feet of footage. In the documentary, Coppola talks about how astonished he was when an overweight Brando turned up for his scenes and, feeling desperate, decided to portray Kurtz, who appears emaciated in the original story, as a man who had indulged every aspect of himself. Coppola: "He was already heavy when I hired him and he promised me that he was going to get in shape and I imagined that I would, if he were heavy, I could use that. But he was "so" fat, he was very, very shy about it ... He was very, very adamant about how he didn't want to portray himself that way." Brando admitted to Coppola that he had not read the book, "Heart of Darkness", as the director had asked him to, and the pair spent days exploring the story and the character of Kurtz, much to the actor's financial benefit, according to producer Fred Roos: "The clock was ticking on this deal he had and we had to finish him within three weeks or we'd go into this very expensive overage ... And Francis and Marlon would be talking about the character and whole days would go by. And this is at Marlon's urging—and yet he's getting paid for it."

Upon release, "Apocalypse Now" earned critical acclaim, as did Brando's performance. His whispering of Kurtz's final words ""The horror! The horror!"", has become particularly famous. Roger Ebert, writing in the "Chicago Sun-Times", defended the movie's controversial "denouement", opining that the ending, "with Brando's fuzzy, brooding monologues and final violence, feels more satisfactory than any conventional ending possibly could."

After appearing as oil tycoon Adam Steiffel in 1980's "The Formula", which was poorly received critically, Brando announced his retirement from acting. However, he returned in 1989 in "A Dry White Season", based on André Brink's 1979 anti-apartheid novel. Brando agreed to do the film for free, but fell out with director Euzhan Palcy over how the film was edited; he even made a rare television appearance in an interview with Connie Chung to voice his disapproval. In his memoir, he maintained that Palcy "had cut the picture so poorly, I thought, that the inherent drama of this conflict was vague at best." Brando received praise for his performance, earning an Academy Award nomination for Best Supporting Actor and winning the Best Actor Award at the Tokyo Film Festival. Brando also scored enthusiastic reviews for his caricature of his Vito Corleone role as Carmine Sabatini in 1990's "The Freshman." In his original review, Roger Ebert wrote, "There have been a lot of movies where stars have repeated the triumphs of their parts—but has any star ever done it more triumphantly than Marlon Brando does in "The Freshman"?" "Variety" also praised Brando's performance as Sabatini and noted, "Marlon Brando's sublime comedy performance elevates "The Freshman" from screwball comedy to a quirky niche in film history." Brando also starred alongside his friend Johnny Depp in the box office hit "Don Juan DeMarco" (1995) and in Depp's controversial "The Brave" (1997), which was never released in the United States. Later performances, such as his appearance in "" (1992) (for which he was nominated for a Raspberry as "Worst Supporting Actor"), "The Island of Dr. Moreau" (in which he won a "Worst Supporting Actor" Raspberry) (1996), and his barely recognizable appearance in "Free Money" (1998), resulted in some of the worst reviews of his career. However, his last completed film, "The Score" (2001), was received generally positively. In the film, in which he portrays a fence, he starred with Robert De Niro, who had portrayed Vito Corleone in "The Godfather Part II".
Brando conceived the idea of a novel called "Fan-Tan" with director Donald Cammell in 1979, which was not released until 2005.

Brando's notoriety, his troubled family life, and his obesity attracted more attention than his late acting career. He gained a great deal of weight in the 1970s and by the early to mid-1990s he weighed over and suffered from Type 2 diabetes. He had a history of weight fluctuation throughout his career that, by and large, he attributed to his years of stress-related overeating followed by compensatory dieting. He also earned a reputation for being difficult on the set, often unwilling or unable to memorize his lines and less interested in taking direction than in confronting the film director with odd demands.

He also dabbled with some innovation in his last years. He had several patents issued in his name from the U.S. Patent and Trademark Office, all of which involve a method of tensioning drumheads, in June 2002 – November 2004. (For example, see and its equivalents).

In 2004, Brando recorded voice tracks for the character Mrs. Sour in the unreleased animated film "Big Bug Man". This was his last role and his only role as a female character.

The actor was a longtime close friend of entertainer Michael Jackson and paid regular visits to his Neverland Ranch, resting there for weeks at a time. Brando also participated in the singer's two-day solo career 30th-anniversary celebration concerts in 2001, and starred in his 13-minute-long music video, "You Rock My World," in the same year. On Jackson's 30th anniversary concert, Brando gave a rambling speech to the audience on humanitarian work which received a poor reaction and was unaired.

The actor's son, Miko, was Jackson's bodyguard and assistant for several years, and was a friend of the singer. "The last time my father left his house to go anywhere, to spend any kind of time, it was with Michael Jackson", Miko stated. "He loved it ... He had a 24-hour chef, 24-hour security, 24-hour help, 24-hour kitchen, 24-hour maid service. Just carte blanche." "Michael was instrumental helping my father through the last few years of his life. For that I will always be indebted to him. Dad had a hard time breathing in his final days, and he was on oxygen much of the time. He loved the outdoors, so Michael would invite him over to Neverland. Dad could name all the trees there, and the flowers, but being on oxygen it was hard for him to get around and see them all, it's such a big place. So Michael got Dad a golf cart with a portable oxygen tank so he could go around and enjoy Neverland. They'd just drive around—Michael Jackson, Marlon Brando, with an oxygen tank in a golf cart."

In April 2001, Brando was hospitalized with pneumonia.

In 2004, Brando signed with Tunisian film director Ridha Behi and began pre-production on a project to be titled "Brando and Brando". Up to a week before his death, he was working on the script in anticipation of a July/August 2004 start date. Production was suspended in July 2004 following Brando's death, at which time Behi stated that he would continue the film as an homage to Brando, with a new title of "Citizen Brando".

On July 1, 2004, Brando died of respiratory failure from pulmonary fibrosis with congestive heart failure at the UCLA Medical Center. The cause of death was initially withheld, with his lawyer citing privacy concerns. He also suffered from failing eyesight caused by diabetes and liver cancer. Shortly before his death and despite needing an oxygen mask to breathe, he recorded his voice to appear in "The Godfather: The Game", once again as Don Vito Corleone. However, Brando only recorded one line due to his health and an impersonator was hired to finish his lines. Some lines from his character were directly lifted from the film.

Karl Malden—a fellow actor in "A Streetcar Named Desire", "On the Waterfront", and "One-Eyed Jacks" (the only film directed by Brando)—talks in a documentary accompanying the DVD of "A Streetcar Named Desire" about a phone call he received from Brando shortly before Brando's death. A distressed Brando told Malden he kept falling over. Malden wanted to come over, but Brando put him off, telling him there was no point. Three weeks later, Brando was dead. Shortly before his death, he had apparently refused permission for tubes carrying oxygen to be inserted into his lungs, which, he was told, was the only way to prolong his life.

Brando was cremated, and his ashes were put in with those of his childhood friend, comedian and actor Wally Cox and another longtime friend, Sam Gilman. They were then scattered partly in Tahiti and partly in Death Valley. In 2007, a 165-minute biopic of Brando for Turner Classic Movies, "Brando: The Documentary", produced by Mike Medavoy (the executor of Brando's will), was released.

Brando was known for his tumultuous personal life and his large number of wives, girlfriends and children. He was the father to eleven children, three of whom were adopted. In 1976, he told a French journalist, "Homosexuality is so much in fashion, it no longer makes news. Like a large number of men, I, too, have had homosexual experiences, and I am not ashamed. I have never paid much attention to what people think about me. But if there is someone who is convinced that Jack Nicholson and I are lovers, may they continue to do so. I find it amusing."

In "Songs My Mother Taught Me", Brando wrote he met Marilyn Monroe at a party where she played piano, unnoticed by anybody else there, that they had an affair and maintained an intermittent relationship for many years, and that he received a telephone call from her several days before she died. He also claimed numerous other romances, although he did not discuss his marriages, his wives, or his children in his autobiography.

He met nisei actress and dancer Reiko Sato in the early 1950s; in 1954 Dorothy Kilgallen reported they were an item. Though their relationship cooled, they remained friends for the rest of Sato's life, with her dividing her time between Los Angeles and Tetiaroa in her later years.

Brando met actress Rita Moreno in 1954, beginning their torrid love affair. Moreno revealed in her memoir that when she became pregnant by Brando, he arranged for an abortion. After a botched abortion she tried to commit suicide by overdosing on his sleeping pills. Years after they broke up Moreno played his love interest in the film "The Night of the Following Day".

Brando married actress Anna Kashfi in 1957. Kashfi was born in Calcutta and moved to Wales from India in 1947. She is said to have been the daughter of a Welsh steel worker of Irish descent, William O'Callaghan, who had been superintendent on the Indian State railways. However, in her book, "Brando for Breakfast", she claimed that she really is half Indian and that the press incorrectly thought that her stepfather, O'Callaghan, was her biological father. She said that her biological father was Indian and that she was the result of an "unregistered alliance" between her parents. Brando and Kashfi had a son, Christian Brando, on May 11, 1958; they divorced in 1959.

In 1960, Brando married Movita Castaneda, a Mexican-American actress seven years his senior; they were divorced in 1962. Castaneda had appeared in the first "Mutiny on the Bounty" film in 1935, some 27 years before the 1962 remake with Brando as Fletcher Christian. They had two children together: Miko Castaneda Brando (born 1961) and Rebecca Brando (born 1966).

Tahitian actress Tarita Teriipaia, who played Brando's love interest in "Mutiny on the Bounty", became his third wife on August 10, 1962. She was 20 years old, 18 years younger than Brando, who was reportedly delighted by her naïveté. Because Teriipaia was a native French speaker, Brando became fluent in the language and gave numerous interviews in French. Teriipaia became the mother of two of his children: Simon Teihotu Brando (born 1963) and Tarita Cheyenne Brando (born 1970). Brando also adopted Teriipaia's daughter, Maimiti Brando (born 1977) and niece, Raiatua Brando (born 1982). Brando and Teriipaia divorced in July 1972.

Brando had a long-term relationship with his housekeeper Maria Cristina Ruiz, with whom he had three children: Ninna Priscilla Brando (born May 13, 1989), Myles Jonathan Brando (born January 16, 1992), and Timothy Gahan Brando (born January 6, 1994). Brando also adopted Petra Brando-Corval (born 1972), the daughter of his assistant Caroline Barrett and novelist James Clavell.

Brando's close friendship with Wally Cox was the subject of rumors. Brando told a journalist: "If Wally had been a woman, I would have married him and we would have lived happily ever after." Two of Cox's wives, however, dismissed the suggestion that the love was more than platonic.

Brando's grandson Tuki Brando (born 1990), son of Cheyenne Brando, is a fashion model. His numerous grandchildren also include Michael Brando (born 1988), son of Christian Brando, Prudence Brando and Shane Brando, children of Miko C. Brando, the children of Rebecca Brando, and the three children of Teihotu Brando among others.

Stephen Blackehart has been reported to be the son of Brando but Blackehart disputes this claim.
Brando earned a reputation as a 'bad boy' for his public outbursts and antics. According to "Los Angeles" magazine, "Brando was rock and roll before anybody knew what rock and roll was." His behavior during the filming of "Mutiny on the Bounty" (1962) seemed to bolster his reputation as a difficult star. He was blamed for a change in director and a runaway budget, though he disclaimed responsibility for either. On June 12, 1973, Brando broke paparazzo Ron Galella's jaw. Galella had followed Brando, who was accompanied by talk show host Dick Cavett, after a taping of "The Dick Cavett Show" in New York City. He reportedly paid a $40,000 out-of-court settlement and suffered an infected hand as a result. Galella wore a football helmet the next time he photographed Brando at a gala benefiting the American Indians Development Association.

The filming of "Mutiny on the Bounty" affected Brando's life in a profound way, as he fell in love with Tahiti and its people. He bought a 12-island atoll, Tetiaroa, and in 1970 hired an award-winning young Los Angeles architect, Bernard Judge, to build his home and natural village there without despoiling the environment. An environmental laboratory protecting sea birds and turtles was established and student groups were welcomed there for many years. Tragically, the 1983 hurricane destroyed many of the structures including his resort. A hotel using Brando's name, The Brando Resort was officially opened to the public in 2014. Brando was an active ham radio operator, with the call signs KE6PZH and FO5GJ (the latter from his island). He was listed in the Federal Communications Commission (FCC) records as Martin Brandeaux to preserve his privacy.

In the A&E "Biography" episode on Brando, biographer Peter Manso comments, "On the one hand, being a celebrity allowed Marlon to take his revenge on the world that had so deeply hurt him, so deeply scarred him. On the other hand he hated it because he knew it was false and ephemeral." In the same program another biographer, David Thomson, relates, "Many, many people who worked with him, and came to work with him with the best intentions, went away in despair saying he's a spoiled kid. It has to be done his way or he goes away with some vast story about how he was wronged, he was offended, and I think that fits with the psychological pattern that he was a wronged kid."

In 1946, Brando performed in Ben Hecht's Zionist play "A Flag is Born". He attended some fundraisers for John F. Kennedy in the 1960 presidential election. In August 1963, he participated in the March on Washington along with fellow celebrities Harry Belafonte, James Garner, Charlton Heston, Burt Lancaster and Sidney Poitier. Along with Paul Newman, Brando also participated in the freedom rides.

In the aftermath of the 1968 assassination of Martin Luther King, Jr., Brando made one of the strongest commitments to furthering King's work. Shortly after King's death, he announced that he was bowing out of the lead role of a major film ("The Arrangement") (1969) which was about to begin production in order to devote himself to the civil rights movement. "I felt I'd better go find out where it is; what it is to be black in this country; what this rage is all about," Brando said on the late-night ABC-TV talk show "Joey Bishop Show". In A&E's "Biography" episode on Brando, actor and co-star Martin Sheen states, "I'll never forget the night that Reverend King was shot and I turned on the news and Marlon was walking through Harlem with Mayor Lindsay. And there were snipers and there was a lot of unrest and he kept walking and talking through those neighborhoods with Mayor Lindsay. It was one of the most incredible acts of courage I ever saw, and it meant a lot and did a lot."

Brando's participation in the civil rights movement actually began well before King's death. In the early 1960s, he contributed thousands of dollars to both the Southern Christian Leadership Conference (S.C.L.C.) and to a scholarship fund established for the children of slain Mississippi N.A.A.C.P. leader Medgar Evers. In 1964 Brando was arrested at a "fish-in" held to protest a broken treaty that had promised Native Americans fishing rights in Puget Sound. By this time, Brando was already involved in films that carried messages about human rights: "Sayonara", which addressed interracial romance, and "The Ugly American", depicting the conduct of U.S. officials abroad and the deleterious effect on the citizens of foreign countries. For a time, he was also donating money to the Black Panther Party and considered himself a friend of founder Bobby Seale. Brando ended his financial support for the group over his perception of its increasing radicalization, specifically a passage in a Panther pamphlet put out by Eldridge Cleaver advocating indiscriminate violence, "for the Revolution."

At the 1973 Academy Awards ceremony, Brando refused to accept the Oscar for his performance in "The Godfather". Sacheen Littlefeather represented him at the ceremony. She appeared in full Apache attire and stated that owing to the "poor treatment of Native Americans in the film industry", Brando would not accept the award. This occurred while the standoff at Wounded Knee was ongoing. The event grabbed the attention of the US and the world media. This was considered a major event and victory for the movement by its supporters and participants.

Outside of his film work, Brando appeared before the California Assembly in support of a fair housing law and personally joined picket lines in demonstrations protesting discrimination in housing developments.

He was also an activist against apartheid. In 1964, he favored a boycott of his films in South Africa to prevent them from being shown to a segregated audience. He took part at a 1975 protest rally against American investments in South Africa and for the release of Nelson Mandela. In 1989, Brando also starred in the film "A Dry White Season", based upon André Brink's novel of the same name.

In an interview in "Playboy" magazine in January 1979, Brando said: "You've seen every single race besmirched, but you never saw an image of the kike because the Jews were ever so watchful for that—and rightly so. They never allowed it to be shown on screen. The Jews have done so much for the world that, I suppose, you get extra disappointed because they didn't pay attention to that."
Brando made a similar comment on "Larry King Live" in April 1996, saying "Hollywood is run by Jews; it is owned by Jews, and they should have a greater sensitivity about the issue of—of people who are suffering. Because they've exploited—we have seen the—we have seen the nigger and greaseball, we've seen the chink, we've seen the slit-eyed dangerous Jap, we have seen the wily Filipino, we've seen everything, but we never saw the kike. Because they knew perfectly well, that that is where you draw the wagons around." Larry King, who is Jewish, replied, "When you say—when you say something like that, you are playing right in, though, to anti-Semitic people who say the Jews are—" Brando interrupted: "No, no, because I will be the first one who will appraise the Jews honestly and say 'Thank God for the Jews'."
Jay Kanter, Brando's agent, producer, and friend, defended him in "Daily Variety": "Marlon has spoken to me for hours about his fondness for the Jewish people, and he is a well-known supporter of Israel." Similarly, Louie Kemp, in his article for "Jewish Journal", wrote: "You might remember him as Don Vito Corleone, Stanley Kowalski or the eerie Col. Walter E. Kurtz in 'Apocalypse Now', but I remember Marlon Brando as a mensch and a personal friend of the Jewish people when they needed it most." In an interview with "NBC Today" one day after Brando's death, King also defended Brando's comments, saying that they had been blown out of proportion and taken out of context.

Brando was one of the most respected actors of the post-war era. He is listed by the American Film Institute as the fourth greatest male star whose screen debut occurred before or during 1950 (it occurred in 1950). He earned respect among critics for his memorable performances and charismatic screen presence. He helped popularize Method acting. He is regarded as one of the greatest cinema actors of the 20th century.

"Encyclopedia Britannica" describes him as "the most celebrated of the method actors, and his slurred, mumbling delivery marked his rejection of classical dramatic training. His true and passionate performances proved him one of the greatest actors of his generation". It also notes the apparent paradox of his talent: "He is regarded as the most influential actor of his generation, yet his open disdain for the acting profession... often manifested itself in the form of questionable choices and uninspired performances. Nevertheless, he remains a riveting screen presence with a vast emotional range and an endless array of compulsively watchable idiosyncrasies."

Marlon Brando is a cultural icon with an enduring popularity. His rise to national attention in the 1950s had a profound effect on American culture.
According to film critic Pauline Kael, "Brando represented a reaction against the post-war mania for security. As a protagonist, the Brando of the early fifties had no code, only his instincts. He was a development from the gangster leader and the outlaw. He was antisocial because he knew society was crap; he was a hero to youth because he was strong enough not to take the crap ... Brando represented a contemporary version of the free American ... Brando is still the most exciting American actor on the screen." Sociologist Dr. Suzanne Mcdonald-Walker states: "Marlon Brando, sporting leather jacket, jeans, and moody glare, became a cultural icon summing up 'the road' in all its maverick glory." His portrayal of the gang leader Johnny Strabler in "The Wild One" has become an iconic image, used both as a symbol of rebelliousness and a fashion accessory that includes a Perfecto style motorcycle jacket, a tilted cap, jeans and sunglasses. Johnny's haircut inspired a craze for sideburns, followed by James Dean and Elvis Presley, among others. Dean copied Brando's acting style extensively and Presley used Brando's image as a model for his role in "Jailhouse Rock". The "I coulda been a contender" scene from "On the Waterfront", according to the author of" Brooklyn Boomer", Martin H. Levinson, is "one of the most famous scenes in motion picture history, and the line itself has become part of America's cultural lexicon." An example of the endurance of Brando's popular "Wild One" image was the 2009 release of replicas of the leather jacket worn by Brando's Johnny Strabler character. The jackets were marketed by Triumph, the manufacturer of the Triumph Thunderbird motorcycles featured in "The Wild One", and were officially licensed by Brando's estate.

Brando was also considered a male sex symbol. Linda Williams writes: "Marlon Brando [was] the quintessential American male sex symbol of the late fifties and early sixties".

Brando has also been immortalized in music; most notably, he was mentioned in the lyrics of "Vogue" by Madonna. 

In his autobiography "Songs My Mother Taught Me", Brando observed:
He also confessed that, while having great admiration for the theater, he did not return to it after his initial success primarily because the work left him drained emotionally:
Brando repeatedly credited Stella Adler and her understanding of the Stanislavsky acting technique for bringing realism to American cinema, but also added:
In the 2015 documentary "Listen to Me Marlon", Brando shared his thoughts on playing a death scene, stating, "That's a tough scene to play. You have to make 'em believe that you are dying ... Try to think of the most intimate moment you've ever had in your life." Brando's favorite actors were Spencer Tracy, John Barrymore, Fredric March, James Cagney and Paul Muni.

Upon his death in 2004, Brando left an estate valued at $21.6 million. Brando's estate still earned about $9 million in 2005, the year following his death, according to "Forbes". That year Brando was named one of the top-earning deceased celebrities in the world by the magazine.

Brando was named the fourth greatest male star whose screen debut occurred before or during 1950 by the American Film Institute, and part of "TIME" magazine's . He was also named one of the top 10 "Icons of the Century" by "Variety" magazine.


Notes
Citations
Bibliography



</doc>
<doc id="19904" url="https://en.wikipedia.org/wiki?curid=19904" title="Meteorology">
Meteorology

Meteorology is a branch of the atmospheric sciences which includes atmospheric chemistry and atmospheric physics, with a major focus on weather forecasting. The study of meteorology dates back millennia, though significant progress in meteorology did not occur until the 18th century. The 19th century saw modest progress in the field after weather observation networks were formed across broad regions. Prior attempts at prediction of weather depended on historical data. It wasn't until after the elucidation of the laws of physics and, more particularly, the development of the computer, allowing for the automated solution of a great many equations that model the weather, in the latter half of the 20th century that significant breakthroughs in weather forecasting were achieved.

Meteorological phenomena are observable weather events that are explained by the science of meteorology. Meteorological phenomena are described and quantified by the variables of Earth's atmosphere: temperature, air pressure, water vapour, mass flow, and the variations and interactions of those variables, and how they change over time. Different spatial scales are used to describe and predict weather on local, regional, and global levels.
Meteorology, climatology, atmospheric physics, and atmospheric chemistry are sub-disciplines of the atmospheric sciences. Meteorology and hydrology compose the interdisciplinary field of hydrometeorology. The interactions between Earth's atmosphere and its oceans are part of a coupled ocean-atmosphere system. Meteorology has application in many diverse fields such as the military, energy production, transport, agriculture, and construction.

The word "meteorology" is from Greek μετέωρος "metéōros" "meteor" and -λογία "-logia" "-(o)logy", i.e. "the study of things in the air".

The ability to predict rains and floods based on annual cycles was evidently used by humans at least from the time of agricultural settlement if not earlier. Early approaches to predicting weather were based on astrology and were practiced by priests. Cuneiform inscriptions on Babylonian tablets included associations between thunder and rain. The Chaldeans differentiated the 22° and 46° halos.

Ancient Indian Upanishads contain mentions of clouds and seasons. The Samaveda mentions sacrifices to be performed when certain phenomena were noticed. Varāhamihira's classical work "Brihatsamhita", written about 500 AD, provides evidence of weather observation.

In 350 BC, Aristotle wrote "Meteorology". Aristotle is considered the founder of meteorology. One of the most impressive achievements described in the "Meteorology" is the description of what is now known as the hydrologic cycle.

The book De Mundo (composed before 250 BC or between 350 and 200 BC) noted

The Greek scientist Theophrastus compiled a book on weather forecasting, called the "Book of Signs". The work of Theophrastus remained a dominant influence in the study of weather and in weather forecasting for nearly 2,000 years. In 25 AD, Pomponius Mela, a geographer for the Roman Empire, formalized the climatic zone system. According to Toufic Fahd, around the 9th century, Al-Dinawari wrote the "Kitab al-Nabat" ("Book of Plants"), in which he deals with the application of meteorology to agriculture during the Muslim Agricultural Revolution. He describes the meteorological character of the sky, the planets and constellations, the sun and moon, the lunar phases indicating seasons and rain, the "anwa" (heavenly bodies of rain), and atmospheric phenomena such as winds, thunder, lightning, snow, floods, valleys, rivers, lakes.

Early attempts at predicting weather were often related to prophesy and divining and sometimes based on astrological ideas. Admiral FitzRoy tried to separate scientific approaches from prophetic ones.

Ptolemy wrote on the atmospheric refraction of light in the context of astronomical observations. In 1021, Alhazen showed that atmospheric refraction is also responsible for twilight; he estimated that twilight begins when the sun is 19 degrees below the horizon, and also used a geometric determination based on this to estimate the maximum possible height of the Earth's atmosphere as 52,000 "passim" (about 49 miles, or 79 km).

St. Albert the Great was the first to propose that each drop of falling rain had the form of a small sphere, and that this form meant that the rainbow was produced by light interacting with each raindrop. Roger Bacon was the first to calculate the angular size of the rainbow. He stated that a rainbow summit can not appear higher than 42 degrees above the horizon. In the late 13th century and early 14th century, Kamāl al-Dīn al-Fārisī and Theodoric of Freiberg were the first to give the correct explanations for the primary rainbow phenomenon. Theoderic went further and also explained the secondary rainbow. In 1716, Edmund Halley suggested that aurorae are caused by "magnetic effluvia" moving along the Earth's magnetic field lines.

In 1441, King Sejong's son, Prince Munjong, invented the first standardized rain gauge. These were sent throughout the Joseon Dynasty of Korea as an official tool to assess land taxes based upon a farmer's potential harvest. In 1450, Leone Battista Alberti developed a swinging-plate anemometer, and was known as the first "anemometer". In 1607, Galileo Galilei constructed a thermoscope. In 1611, Johannes Kepler wrote the first scientific treatise on snow crystals: "Strena Seu de Nive Sexangula (A New Year's Gift of Hexagonal Snow)". In 1643, Evangelista Torricelli invented the mercury barometer. In 1662, Sir Christopher Wren invented the mechanical, self-emptying, tipping bucket rain gauge. In 1714, Gabriel Fahrenheit created a reliable scale for measuring temperature with a mercury-type thermometer. In 1742, Anders Celsius, a Swedish astronomer, proposed the "centigrade" temperature scale, the predecessor of the current Celsius scale. In 1783, the first hair hygrometer was demonstrated by Horace-Bénédict de Saussure. In 1802–1803, Luke Howard wrote "On the Modification of Clouds", in which he assigns cloud types Latin names. In 1806, Francis Beaufort introduced his system for classifying wind speeds. Near the end of the 19th century the first cloud atlases were published, including the "International Cloud Atlas", which has remained in print ever since. The April 1960 launch of the first successful weather satellite, TIROS-1, marked the beginning of the age where weather information became available globally.

In 1648, Blaise Pascal rediscovered that atmospheric pressure decreases with height, and deduced that there is a vacuum above the atmosphere. In 1738, Daniel Bernoulli published "Hydrodynamics", initiating the Kinetic theory of gases and established the basic laws for the theory of gases. In 1761, Joseph Black discovered that ice absorbs heat without changing its temperature when melting. In 1772, Black's student Daniel Rutherford discovered nitrogen, which he called "phlogisticated air", and together they developed the phlogiston theory. In 1777, Antoine Lavoisier discovered oxygen and developed an explanation for combustion. In 1783, in Lavoisier's essay "Reflexions sur le phlogistique", he deprecates the phlogiston theory and proposes a caloric theory. In 1804, Sir John Leslie observed that a matte black surface radiates heat more effectively than a polished surface, suggesting the importance of black body radiation. In 1808, John Dalton defended caloric theory in "A New System of Chemistry" and described how it combines with matter, especially gases; he proposed that the heat capacity of gases varies inversely with atomic weight. In 1824, Sadi Carnot analyzed the efficiency of steam engines using caloric theory; he developed the notion of a reversible process and, in postulating that no such thing exists in nature, laid the foundation for the second law of thermodynamics.

In 1494, Christopher Columbus experienced a tropical cyclone, which led to the first written European account of a hurricane. In 1686, Edmund Halley presented a systematic study of the trade winds and monsoons and identified solar heating as the cause of atmospheric motions. In 1735, an "ideal" explanation of global circulation through study of the trade winds was written by George Hadley. In 1743, when Benjamin Franklin was prevented from seeing a lunar eclipse by a hurricane, he decided that cyclones move in a contrary manner to the winds at their periphery. Understanding the kinematics of how exactly the rotation of the Earth affects airflow was partial at first. Gaspard-Gustave Coriolis published a paper in 1835 on the energy yield of machines with rotating parts, such as waterwheels. In 1856, William Ferrel proposed the existence of a circulation cell in the mid-latitudes, and the air within deflected by the Coriolis force resulting in the prevailing westerly winds. Late in the 19th century, the motion of air masses along isobars was understood to be the result of the large-scale interaction of the pressure gradient force and the deflecting force. By 1912, this deflecting force was named the Coriolis effect. Just after World War I, a group of meteorologists in Norway led by Vilhelm Bjerknes developed the Norwegian cyclone model that explains the generation, intensification and ultimate decay (the life cycle) of mid-latitude cyclones, and introduced the idea of fronts, that is, sharply defined boundaries between air masses. The group included Carl-Gustaf Rossby (who was the first to explain the large scale atmospheric flow in terms of fluid dynamics), Tor Bergeron (who first determined how rain forms) and Jacob Bjerknes.

In the late 16th century and first half of the 17th century a range of meteorological instruments was invented – the thermometer, barometer, hydrometer, as well as wind and rain gauges. In the 1650s natural philosophers started using these instruments to systematically record weather observations. Scientific academies established weather diaries and organised observational networks. In 1654, Ferdinando II de Medici established the first "weather observing" network, that consisted of meteorological stations in Florence, Cutigliano, Vallombrosa, Bologna, Parma, Milan, Innsbruck, Osnabrück, Paris and Warsaw. The collected data were sent to Florence at regular time intervals. In the 1660s Robert Hooke of the Royal Society of London sponsored networks of weather observers. Hippocrates' treatise "Airs, Waters, and Places" had linked weather to disease. Thus early meteorologists attempted to correlate weather patterns with epidemic outbreaks, and the climate with public health. 

During the Age of Enlightenment meteorology tried to rationalise traditional weather lore, including astrological meteorology. But there were also attempts to establish a theoretical understanding of weather phenomena. Edmond Halley and George Hadley tried to explain trade winds. They reasoned that the rising mass of heated equator air is replaced by an inflow of cooler air from high latitudes. A flow of warm air at high altitude from equator to poles in turn established an early picture of circulation. Frustration with the lack of discipline among weather observers, and the poor quality of the instruments, led the early modern nation states to organise large observation networks. Thus by the end of the 18th century meteorologists had access to large quantities of reliable weather date. In 1832, an electromagnetic telegraph was created by Baron Schilling. The arrival of the electrical telegraph in 1837 afforded, for the first time, a practical method for quickly gathering surface weather observations from a wide area.

This data could be used to produce maps of the state of the atmosphere for a region near the Earth's surface and to study how these states evolved through time. To make frequent weather forecasts based on these data required a reliable network of observations, but it was not until 1849 that the Smithsonian Institution began to establish an observation network across the United States under the leadership of Joseph Henry. Similar observation networks were established in Europe at this time. The Reverend William Clement Ley was key in understanding of cirrus clouds and early understandings of Jet Streams. Charles Kenneth Mackinnon Douglas, known as 'CKM' Douglas read Ley's papers after his death and carried on the early study of weather systems.
Nineteenth century researchers in meteorology were drawn from military or medical backgrounds, rather than trained as dedicated scientists. In 1854, the United Kingdom government appointed Robert FitzRoy to the new office of "Meteorological Statist to the Board of Trade" with the task of gathering weather observations at sea. FitzRoy's office became the United Kingdom Meteorological Office in 1854, the second oldest national meteorological service in the world (the Central Institution for Meteorology and Geodynamics (ZAMG) in Austria was founded in 1851 and is the oldest weather service in the world). The first daily weather forecasts made by FitzRoy's Office were published in "The Times" newspaper in 1860. The following year a system was introduced of hoisting storm warning cones at principal ports when a gale was expected.

Over the next 50 years many countries established national meteorological services. The India Meteorological Department (1875) was established to follow tropical cyclone and monsoon. The Finnish Meteorological Central Office (1881) was formed from part of Magnetic Observatory of Helsinki University. Japan's Tokyo Meteorological Observatory, the forerunner of the Japan Meteorological Agency, began constructing surface weather maps in 1883. The United States Weather Bureau (1890) was established under the United States Department of Agriculture. The Australian Bureau of Meteorology (1906) was established by a Meteorology Act to unify existing state meteorological services.

In 1904, Norwegian scientist Vilhelm Bjerknes first argued in his paper "Weather Forecasting as a Problem in Mechanics and Physics" that it should be possible to forecast weather from calculations based upon natural laws.

It was not until later in the 20th century that advances in the understanding of atmospheric physics led to the foundation of modern numerical weather prediction. In 1922, Lewis Fry Richardson published "Weather Prediction By Numerical Process", after finding notes and derivations he worked on as an ambulance driver in World War I. He described how small terms in the prognostic fluid dynamics equations that govern atmospheric flow could be neglected, and a numerical calculation scheme that could be devised to allow predictions. Richardson envisioned a large auditorium of thousands of people performing the calculations. However, the sheer number of calculations required was too large to complete without electronic computers, and the size of the grid and time steps used in the calculations led to unrealistic results. Though numerical analysis later found that this was due to numerical instability.

Starting in the 1950s, numerical forecasts with computers became feasible. The first weather forecasts derived this way used barotropic (single-vertical-level) models, and could successfully predict the large-scale movement of midlatitude Rossby waves, that is, the pattern of atmospheric lows and highs. In 1959, the UK Meteorological Office received its first computer, a Ferranti Mercury. 

In the 1960s, the chaotic nature of the atmosphere was first observed and mathematically described by Edward Lorenz, founding the field of chaos theory. These advances have led to the current use of ensemble forecasting in most major forecasting centers, to take into account uncertainty arising from the chaotic nature of the atmosphere. Mathematical models used to predict the long term weather of the Earth (climate models), have been developed that have a resolution today that are as coarse as the older weather prediction models. These climate models are used to investigate long-term climate shifts, such as what effects might be caused by human emission of greenhouse gases.

Meteorologists are scientists who study meteorology. The American Meteorological Society published and continually updates an authoritative electronic "Meteorology Glossary". Meteorologists work in government agencies, private consulting and research services, industrial enterprises, utilities, radio and television stations, and in education. In the United States, meteorologists held about 9,400 jobs in 2009.

Meteorologists are best known by the public for weather forecasting. Some radio and television weather forecasters are professional meteorologists, while others are reporters (weather specialist, weatherman, etc.) with no formal meteorological training. The American Meteorological Society and National Weather Association issue "Seals of Approval" to weather broadcasters who meet certain requirements.

Each science has its own unique sets of laboratory equipment. In the atmosphere, there are many things or qualities of the atmosphere that can be measured. Rain, which can be observed, or seen anywhere and anytime was one of the first atmospheric qualities measured historically. Also, two other accurately measured qualities are wind and humidity. Neither of these can be seen but can be felt. The devices to measure these three sprang up in the mid-15th century and were respectively the rain gauge, the anemometer, and the hygrometer. Many attempts had been made prior to the 15th century to construct adequate equipment to measure the many atmospheric variables. Many were faulty in some way or were simply not reliable. Even Aristotle noted this in some of his work as the difficulty to measure the air.

Sets of surface measurements are important data to meteorologists. They give a snapshot of a variety of weather conditions at one single location and are usually at a weather station, a ship or a weather buoy. The measurements taken at a weather station can include any number of atmospheric observables. Usually, temperature, pressure, wind measurements, and humidity are the variables that are measured by a thermometer, barometer, anemometer, and hygrometer, respectively. Professional stations may also include air quality sensors (carbon monoxide, carbon dioxide, methane, ozone, dust, and smoke), ceilometer (cloud ceiling), falling precipitation sensor, flood sensor, lightning sensor, microphone (explosions, sonic booms, thunder), pyranometer/pyrheliometer/spectroradiometer (IR/Vis/UV photodiodes), rain gauge/snow gauge, scintillation counter (background radiation, fallout, radon), seismometer (earthquakes and tremors), transmissometer (visibility), and a GPS clock for data logging. Upper air data are of crucial importance for weather forecasting. The most widely used technique is launches of radiosondes. Supplementing the radiosondes a network of aircraft collection is organized by the World Meteorological Organization.

Remote sensing, as used in meteorology, is the concept of collecting data from remote weather events and subsequently producing weather information. The common types of remote sensing are Radar, Lidar, and satellites (or photogrammetry). Each collects data about the atmosphere from a remote location and, usually, stores the data where the instrument is located. Radar and Lidar are not passive because both use EM radiation to illuminate a specific portion of the atmosphere. Weather satellites along with more general-purpose Earth-observing satellites circling the earth at various altitudes have become an indispensable tool for studying a wide range of phenomena from forest fires to El Niño.

The study of the atmosphere can be divided into distinct areas that depend on both time and spatial scales. At one extreme of this scale is climatology. In the timescales of hours to days, meteorology separates into micro-, meso-, and synoptic scale meteorology. Respectively, the geospatial size of each of these three scales relates directly with the appropriate timescale.

Other subclassifications are used to describe the unique, local, or broad effects within those subclasses.
Microscale meteorology is the study of atmospheric phenomena on a scale of about or less. Individual thunderstorms, clouds, and local turbulence caused by buildings and other obstacles (such as individual hills) are modeled on this scale.

Mesoscale meteorology is the study of atmospheric phenomena that has horizontal scales ranging from 1 km to 1000 km and a vertical scale that starts at the Earth's surface and includes the atmospheric boundary layer, troposphere, tropopause, and the lower section of the stratosphere. Mesoscale timescales last from less than a day to weeks. The events typically of interest are thunderstorms, squall lines, fronts, precipitation bands in tropical and extratropical cyclones, and topographically generated weather systems such as mountain waves and sea and land breezes.

Synoptic scale meteorology predicts atmospheric changes at scales up to 1000 km and 10 sec (28 days), in time and space. At the synoptic scale, the Coriolis acceleration acting on moving air masses (outside of the tropics) plays a dominant role in predictions. The phenomena typically described by synoptic meteorology include events such as extratropical cyclones, baroclinic troughs and ridges, frontal zones, and to some extent jet streams. All of these are typically given on weather maps for a specific time. The minimum horizontal scale of synoptic phenomena is limited to the spacing between surface observation stations.

Global scale meteorology is the study of weather patterns related to the transport of heat from the tropics to the poles. Very large scale oscillations are of importance at this scale. These oscillations have time periods typically on the order of months, such as the Madden–Julian oscillation, or years, such as the El Niño–Southern Oscillation and the Pacific decadal oscillation. Global scale meteorology pushes into the range of climatology. The traditional definition of climate is pushed into larger timescales and with the understanding of the longer time scale global oscillations, their effect on climate and weather disturbances can be included in the synoptic and mesoscale timescales predictions.

Numerical Weather Prediction is a main focus in understanding air–sea interaction, tropical meteorology, atmospheric predictability, and tropospheric/stratospheric processes. The Naval Research Laboratory in Monterey, California, developed a global atmospheric model called Navy Operational Global Atmospheric Prediction System (NOGAPS). NOGAPS is run operationally at Fleet Numerical Meteorology and Oceanography Center for the United States Military. Many other global atmospheric models are run by national meteorological agencies.

Boundary layer meteorology is the study of processes in the air layer directly above Earth's surface, known as the atmospheric boundary layer (ABL). The effects of the surface – heating, cooling, and friction – cause turbulent mixing within the air layer. Significant movement of heat, matter, or momentum on time scales of less than a day are caused by turbulent motions. Boundary layer meteorology includes the study of all types of surface–atmosphere boundary, including ocean, lake, urban land and non-urban land for the study of meteorology.

Dynamic meteorology generally focuses on the fluid dynamics of the atmosphere. The idea of air parcel is used to define the smallest element of the atmosphere, while ignoring the discrete molecular and chemical nature of the atmosphere. An air parcel is defined as a point in the fluid continuum of the atmosphere. The fundamental laws of fluid dynamics, thermodynamics, and motion are used to study the atmosphere. The physical quantities that characterize the state of the atmosphere are temperature, density, pressure, etc. These variables have unique values in the continuum.

Weather forecasting is the application of science and technology to predict the state of the atmosphere at a future time and given location. Humans have attempted to predict the weather informally for millennia and formally since at least the 19th century. Weather forecasts are made by collecting quantitative data about the current state of the atmosphere and using scientific understanding of atmospheric processes to project how the atmosphere will evolve.

Once an all-human endeavor based mainly upon changes in barometric pressure, current weather conditions, and sky condition, forecast models are now used to determine future conditions. Human input is still required to pick the best possible forecast model to base the forecast upon, which involves pattern recognition skills, teleconnections, knowledge of model performance, and knowledge of model biases. The chaotic nature of the atmosphere, the massive computational power required to solve the equations that describe the atmosphere, error involved in measuring the initial conditions, and an incomplete understanding of atmospheric processes mean that forecasts become less accurate as the difference in current time and the time for which the forecast is being made (the "range" of the forecast) increases. The use of ensembles and model consensus help narrow the error and pick the most likely outcome.

There are a variety of end uses to weather forecasts. Weather warnings are important forecasts because they are used to protect life and property. Forecasts based on temperature and precipitation are important to agriculture, and therefore to commodity traders within stock markets. Temperature forecasts are used by utility companies to estimate demand over coming days. On an everyday basis, people use weather forecasts to determine what to wear. Since outdoor activities are severely curtailed by heavy rain, snow, and wind chill, forecasts can be used to plan activities around these events, and to plan ahead and survive them.

Aviation meteorology deals with the impact of weather on air traffic management. It is important for air crews to understand the implications of weather on their flight plan as well as their aircraft, as noted by the Aeronautical Information Manual:
"The effects of ice on aircraft are cumulative—thrust is reduced, drag increases, lift lessens, and weight increases. The results are an increase in stall speed and a deterioration of aircraft performance. In extreme cases, 2 to 3 inches of ice can form on the leading edge of the airfoil in less than 5 minutes. It takes but 1/2 inch of ice to reduce the lifting power of some aircraft by 50 percent and increases the frictional drag by an equal percentage."

Meteorologists, soil scientists, agricultural hydrologists, and agronomists are persons concerned with studying the effects of weather and climate on plant distribution, crop yield, water-use efficiency, phenology of plant and animal development, and the energy balance of managed and natural ecosystems. Conversely, they are interested in the role of vegetation on climate and weather.

Hydrometeorology is the branch of meteorology that deals with the hydrologic cycle, the water budget, and the rainfall statistics of storms. A hydrometeorologist prepares and issues forecasts of accumulating (quantitative) precipitation, heavy rain, heavy snow, and highlights areas with the potential for flash flooding. Typically the range of knowledge that is required overlaps with climatology, mesoscale and synoptic meteorology, and other geosciences.

The multidisciplinary nature of the branch can result in technical challenges, since tools and solutions from each of the individual disciplines involved may behave slightly differently, be optimized for different hard- and software platforms and use different data formats. There are some initiatives - such as the DRIHM project - that are trying to address this issue.

Nuclear meteorology investigates the distribution of radioactive aerosols and gases in the atmosphere.

Maritime meteorology deals with air and wave forecasts for ships operating at sea. Organizations such as the Ocean Prediction Center, Honolulu National Weather Service forecast office, United Kingdom Met Office, and JMA prepare high seas forecasts for the world's oceans.

Military meteorology is the research and application of meteorology for military purposes. In the United States, the United States Navy's Commander, Naval Meteorology and Oceanography Command oversees meteorological efforts for the Navy and Marine Corps while the United States Air Force's Air Force Weather Agency is responsible for the Air Force and Army.

Environmental meteorology mainly analyzes industrial pollution dispersion physically and chemically based on meteorological parameters such as temperature, humidity, wind, and various weather conditions.

Meteorology applications in renewable energy includes basic research, "exploration", and potential mapping of wind power and solar radiation for wind and solar energy.



"Please see weather forecasting for weather forecast sites."


</doc>
<doc id="19908" url="https://en.wikipedia.org/wiki?curid=19908" title="Mount">
Mount

Mount is often used as part of the name of specific mountains, e.g. Mount Everest.

Mount or Mounts may also refer to:







</doc>
<doc id="19916" url="https://en.wikipedia.org/wiki?curid=19916" title="Meitnerium">
Meitnerium

Meitnerium is a synthetic chemical element with symbol Mt and atomic number 109. It is an extremely radioactive synthetic element (an element not found in nature that can be created in a laboratory). The most stable known isotope, meitnerium-278, has a half-life of 7.6 seconds, although the unconfirmed meitnerium-282 may have a longer half-life of 67 seconds. The GSI Helmholtz Centre for Heavy Ion Research near Darmstadt, Germany, first created this element in 1982. It is named after Lise Meitner.

In the periodic table, meitnerium is a d-block transactinide element. It is a member of the 7th period and is placed in the group 9 elements, although no chemical experiments have yet been carried out to confirm that it behaves as the heavier homologue to iridium in group 9 as the seventh member of the 6d series of transition metals. Meitnerium is calculated to have similar properties to its lighter homologues, cobalt, rhodium, and iridium.

Meitnerium was first synthesized on August 29, 1982 by a German research team led by Peter Armbruster and Gottfried Münzenberg at the Institute for Heavy Ion Research (Gesellschaft für Schwerionenforschung) in Darmstadt. The team bombarded a target of bismuth-209 with accelerated nuclei of iron-58 and detected a single atom of the isotope meitnerium-266:

This work was confirmed three years later at the Joint Institute for Nuclear Research at Dubna (then in the Soviet Union).

Using Mendeleev's nomenclature for unnamed and undiscovered elements, meitnerium should be known as "eka-iridium". In 1979, during the Transfermium Wars (but before the synthesis of meitnerium), IUPAC published recommendations according to which the element was to be called "unnilennium" (with the corresponding symbol of "Une"), a systematic element name as a placeholder, until the element was discovered (and the discovery then confirmed) and a permanent name was decided on. Although widely used in the chemical community on all levels, from chemistry classrooms to advanced textbooks, the recommendations were mostly ignored among scientists in the field, who either called it "element 109", with the symbol of "E109", "(109)" or even simply "109", or used the proposed name "meitnerium".

The naming of meitnerium was discussed in the element naming controversy regarding the names of elements 104 to 109, but "meitnerium" was the only proposal and thus was never disputed. The name "meitnerium" (Mt) was suggested by the GSI team in September 1992 in honor of the Austrian physicist Lise Meitner, a co-discoverer of protactinium (with Otto Hahn), and one of the discoverers of nuclear fission. In 1994 the name was recommended by IUPAC, and was officially adopted in 1997. It is thus the only element named specifically after a non-mythological woman (curium being named for both Pierre and Marie Curie).

Meitnerium has no stable or naturally occurring isotopes. Several radioactive isotopes have been synthesized in the laboratory, either by fusing two atoms or by observing the decay of heavier elements. Eight different isotopes of meitnerium have been reported with atomic masses 266, 268, 270, and 274–278, two of which, meitnerium-268 and meitnerium-270, have known but unconfirmed metastable states. A ninth isotope with atomic mass 282 is unconfirmed. Most of these decay predominantly through alpha decay, although some undergo spontaneous fission.

All meitnerium isotopes are extremely unstable and radioactive; in general, heavier isotopes are more stable than the lighter. The most stable known meitnerium isotope, Mt, is also the heaviest known; it has a half-life of 7.6 seconds. (The unconfirmed Mt is yet heavier and appears to have an even longer half-life of 67 seconds.) A metastable nuclear isomer, Mt, has been reported to also have a half-life of over a second. The isotopes Mt and Mt have half-lives of 0.72 and 0.44 seconds respectively. The remaining four isotopes have half-lives between 1 and 20 milliseconds. The undiscovered isotope Mt has been predicted to be the most stable towards beta decay; no known meitnerium isotope has been observed to undergo beta decay. Some unknown isotopes, such as Mt, Mt, Mt, and Mt, are predicted to have half-lives longer than the known isotopes. Before its discovery, Mt and Mt were predicted to have half-lives of 20 seconds and 1 minute respectively, but they were later found to have half-lives of only 0.44 seconds and 5 milliseconds respectively.

Meitnerium is the seventh member of the 6d series of transition metals. Since element 112 (copernicium) has been shown to be a group 12 metal, it is expected that all the elements from 104 to 111 would continue a fourth transition metal series, with meitnerium as part of the platinum group metals. Calculations on its ionization potentials and atomic and ionic radii are similar to that of its lighter homologue iridium, thus implying that meitnerium's basic properties will resemble those of the other group 9 elements, cobalt, rhodium, and iridium.

Prediction of the probable chemical properties of meitnerium has not received much attention recently. Meitnerium is expected to be a noble metal. Based on the most stable oxidation states of the lighter group 9 elements, the most stable oxidation states of meitnerium are predicted to be the +6, +3, and +1 states, with the +3 state being the most stable in aqueous solutions. In comparison, rhodium and iridium show a maximum oxidation state of +6, while the most stable states are +4 and +3 for iridium and +3 for rhodium. The oxidation state +9, represented only by iridium in [IrO], might be possible for its congener meitnerium in the nonafluoride (MtF) and the [MtO] cation, although [IrO] is expected to be more stable than these meitnerium compounds. The tetrahalides of meitnerium have also been predicted to have similar stabilities to those of iridium, thus also allowing a stable +4 state. It is further expected that the maximum oxidation states of elements from bohrium (element 107) to darmstadtium (element 110) may be stable in the gas phase but not in aqueous solution.

Meitnerium is expected to be a solid under normal conditions and assume a face-centered cubic crystal structure, similarly to its lighter congener iridium. It should be a very heavy metal with a density of around 37.4 g/cm, which would be the second-highest of any of the 118 known elements, second only to that predicted for its neighbor hassium (41 g/cm). In comparison, the densest known element that has had its density measured, osmium, has a density of only 22.61 g/cm. This results from meitnerium's high atomic weight, the lanthanide and actinide contractions, and relativistic effects, although production of enough meitnerium to measure this quantity would be impractical, and the sample would quickly decay. Meitnerium is also predicted to be paramagnetic.

Theoreticians have predicted the covalent radius of meitnerium to be 6 to 10 pm larger than that of iridium. The atomic radius of meitnerium is expected to be around 128 pm.

Meitnerium is the first element on the periodic table whose chemistry has not yet been investigated. Unambiguous determination of the chemical characteristics of meitnerium has yet to have been established due to the short half-lives of meitnerium isotopes and a limited number of likely volatile compounds that could be studied on a very small scale. One of the few meitnerium compounds that are likely to be sufficiently volatile is meitnerium hexafluoride (), as its lighter homologue iridium hexafluoride () is volatile above 60 °C and therefore the analogous compound of meitnerium might also be sufficiently volatile; a volatile octafluoride () might also be possible. For chemical studies to be carried out on a transactinide, at least four atoms must be produced, the half-life of the isotope used must be at least 1 second, and the rate of production must be at least one atom per week. Even though the half-life of Mt, the most stable known meitnerium isotope, is 7.6 seconds, long enough to perform chemical studies, another obstacle is the need to increase the rate of production of meitnerium isotopes and allow experiments to carry on for weeks or months so that statistically significant results can be obtained. Separation and detection must be carried out continuously to separate out the meitnerium isotopes and have automated systems experiment on the gas-phase and solution chemistry of meitnerium, as the yields for heavier elements are predicted to be smaller than those for lighter elements; some of the separation techniques used for bohrium and hassium could be reused. However, the experimental chemistry of meitnerium has not received as much attention as that of the heavier elements from copernicium to livermorium.

The Lawrence Berkeley National Laboratory attempted to synthesize the isotope Mt in 2002–2003 for a possible chemical investigation of meitnerium because it was expected that it might be more stable than the isotopes around it as it has 162 neutrons, a magic number for deformed nuclei; its half-life was predicted to be a few seconds, long enough for a chemical investigation. However, no atoms of Mt were detected, and this isotope of meitnerium is currently unknown.

An experiment determining the chemical properties of a transactinide would need to compare a compound of that transactinide with analogous compounds of some of its lighter homologues: for example, in the chemical characterization of hassium, hassium tetroxide (HsO) was compared with the analogous osmium compound, osmium tetroxide (OsO). In a preliminary step towards determining the chemical properties of meitnerium, the GSI attempted sublimation of the rhodium compounds rhodium(III) oxide (RhO) and rhodium(III) chloride (RhCl). However, macroscopic amounts of the oxide would not sublimate until 1000 °C and the chloride would not until 780 °C, and then only in the presence of carbon aerosol particles: these temperatures are far too high for such procedures to be used on meitnerium, as most of the current methods used for the investigation of the chemistry of superheavy elements do not work above 500 °C.

Following the 2014 successful synthesis of seaborgium hexacarbonyl, Sg(CO), studies were conducted with the stable transition metals of groups 7 through 9, suggesting that carbonyl formation could be extended to further probe the chemistries of the early 6d transition metals from rutherfordium to meitnerium inclusive. Nevertheless, the challenges of low half-lives and difficult production reactions make meitnerium difficult to access for radiochemists, though the isotopes Mt and Mt are long-lived enough for chemical research and may be produced in the decay chains of Ts and Mc respectively. Mt is likely more suitable, since producing tennessine requires a rare and rather short-lived berkelium target.



</doc>
<doc id="19918" url="https://en.wikipedia.org/wiki?curid=19918" title="Megabyte">
Megabyte

The megabyte is a multiple of the unit byte for digital information. Its recommended unit symbol is MB. The unit prefix "mega" is a multiplier of (10) in the International System of Units (SI). Therefore, one megabyte is one million bytes of information. This definition has been incorporated into the International System of Quantities.

However, in the computer and information technology fields, several other definitions are used that arose for historical reasons of convenience. A common usage has been to designate one megabyte as (2 B), a measurement that conveniently expresses the binary multiples inherent in digital computer memory architectures. However, most standards bodies have deprecated this usage in favor of a set of binary prefixes, in which this quantity is designated by the unit mebibyte (MiB). Less common is a convention that used the megabyte to mean 1000×1024 () bytes.

The megabyte is commonly used to measure either 1000 bytes or 1024 bytes. The interpretation of using base 1024 originated as a compromise technical jargon for the byte multiples that needed to be expressed by the powers of 2 but lacked a convenient name. As 1024 (2) approximates 1000 (10), roughly corresponding to the SI prefix kilo-, it was a convenient term to denote the binary multiple. In 1998 the International Electrotechnical Commission (IEC) proposed standards for binary prefixes requiring the use of megabyte to strictly denote 1000 bytes and mebibyte to denote 1024 bytes. By the end of 2009, the IEC Standard had been adopted by the IEEE, EU, ISO and NIST. Nevertheless, the term megabyte continues to be widely used with different meanings:

In this convention, one thousand megabytes (1000 MB) is equal to one gigabyte (1 GB), where 1 GB is one billion bytes.


In this convention, one thousand and twenty-four megabytes (1024 MB) is equal to one gigabyte (1 GB), where 1 GB is 1024 bytes.


Semiconductor memory doubles in size for each address lane added to an integrated circuit package, which favors counts that are powers of two. The capacity of a disk drive is the product of the sector size, number of sectors per track, number of tracks per side, and the number of disk platters in the drive. Changes in any of these factors would not usually double the size. Sector sizes were set as powers of two (most common 512 bytes or 4096 bytes) for convenience in processing. It was a natural extension to give the capacity of a disk drive in multiples of the sector size, giving a mix of decimal and binary multiples when expressing total disk capacity.

Depending on compression methods and file format, a megabyte of data can roughly be:

The human genome consists of DNA representing 800 MB of data. The parts that differentiate one person from another can be compressed to 4 MB.




</doc>
<doc id="19919" url="https://en.wikipedia.org/wiki?curid=19919" title="Monosaccharide">
Monosaccharide

Monosaccharides (, from Greek "monos": single, "sacchar": sugar), also called simple sugars, are the most basic units of carbohydrates. They are fundamental units of carbohydrates and cannot be further hydrolyzed to simpler compounds. The general formula is . They are the simplest form of sugar and are usually colorless, water-soluble, and crystalline solids. Some monosaccharides have a sweet taste. Examples of monosaccharides include glucose (dextrose), fructose (levulose), and galactose. Monosaccharides are the building blocks of disaccharides (such as sucrose and lactose) and polysaccharides (such as cellulose and starch). Further, each carbon atom that supports a hydroxyl group (so, all of the carbons except for the primary and terminal carbon) is chiral, giving rise to a number of isomeric forms, all with the same chemical formula. For instance, galactose and glucose are both aldohexoses, but have different physical structures and chemical properties.

With few exceptions (e.g., deoxyribose), monosaccharides have this chemical formula: C(HO), where conventionally "x" ≥ 3. Monosaccharides can be classified by the number "x" of carbon atoms they contain: triose (3), tetrose (4), pentose (5), hexose (6), heptose (7), and so on.

The most important monosaccharide, glucose, is a hexose. Examples of heptoses include the ketoses , mannoheptulose and sedoheptulose. Monosaccharides with eight or more carbons are rarely observed as they are quite unstable. In aqueous solutions monosaccharides exist as rings if they have more than four carbons.

Simple monosaccharides have a linear and unbranched carbon skeleton with one carbonyl (C=O) functional group, and one hydroxyl (OH) group on each of the remaining carbon atoms. Therefore, the molecular structure of a simple monosaccharide can be written as H(CHOH)(C=O)(CHOH)H, where "n" + 1 + "m" = "x"; so that its elemental formula is CHO.

By convention, the carbon atoms are numbered from 1 to "x" along the backbone, starting from the end that is closest to the C=O group. Monosaccharides are the simplest units of carbohydrates and the simplest form of sugar.

If the carbonyl is at position 1 (that is, "n" or "m" is zero), the molecule begins with a formyl group H(C=O)− and is technically an aldehyde. In that case, the compound is termed an aldose. Otherwise, the molecule has a keto group, a carbonyl −(C=O)− between two carbons; then it is formally a ketone, and is termed a ketose. Ketoses of biological interest usually have the carbonyl at position 2.

The various classifications above can be combined, resulting in names such as "aldohexose" and "ketotriose".

A more general nomenclature for open-chain monosaccharides combines a Greek prefix to indicate the number of carbons (tri-, tetr-, pent-, hex-, etc.) with the suffixes "-ose" for aldoses and "-ulose" for ketoses. In the latter case, if the carbonyl is not at position 2, its position is then indicated by a numeric infix. So, for example, H(C=O)(CHOH)H is pentose, H(CHOH)(C=O)(CHOH)H is pentulose, and H(CHOH)(C=O)(CHOH)H is pent-3-ulose.

Two monosaccharides with equivalent molecular graphs (same chain length and same carbonyl position) may still be distinct stereoisomers, whose molecules differ in the three-dimensional arrangement of the bonds of certain atoms. This happens only if the molecule contains a stereogenic center, specifically a carbon atom that is chiral (connected to four distinct molecular sub-structures). Those four bonds can have any of two configurations in space distinguished by their handedness. In a simple open-chain monosaccharide, every carbon is chiral except the first and the last atoms of the chain, and (in ketoses) the carbon with the keto group.

For example, the triketose H(CHOH)(C=O)(CHOH)H (glycerone, dihydroxyacetone) has no stereogenic center, and therefore exists as a single stereoisomer. The other triose, the aldose H(C=O)(CHOH)H (glyceraldehyde), has one chiral carbon — the central one, number 2 — which is bonded to groups −H, −OH, −C(OH)H, and −(C=O)H. Therefore, it exists as two stereoisomers whose molecules are mirror images of each other (like a left and a right glove). Monosaccharides with four or more carbons may contain multiple chiral carbons, so they typically have more than two stereoisomers. The number of distinct stereoisomers with the same diagram is bounded by 2, where "c" is the total number of chiral carbons.

The Fischer projection is a systematic way of drawing the skeletal formula of an acyclic monosaccharide so that the handedness of each chiral carbon is well specified. Each stereoisomer of a simple open-chain monosaccharide can be identified by the positions (right or left) in the Fischer diagram of the chiral hydroxyls (the hydroxyls attached to the chiral carbons).

Most stereoisomers are themselves chiral (distinct from their mirror images). In the Fischer projection, two mirror-image isomers differ by having the positions of all chiral hydroxyls reversed right-to-left. Mirror-image isomers are chemically identical in non-chiral environments, but usually have very different biochemical properties and occurrences in nature.

While most stereoisomers can be arranged in pairs of mirror-image forms, there are some non-chiral stereoisomers that are identical to their mirror images, in spite of having chiral centers. This happens whenever the molecular graph is symmetrical, as in the 3-ketopentoses H(CHOH)(CO)(CHOH)H, and the two halves are mirror images of each other. In that case, mirroring is equivalent to a half-turn rotation. For this reason, there are only three distinct 3-ketopentose stereoisomers, even though the molecule has two chiral carbons.

Distinct stereoisomers that are not mirror-images of each other usually have different chemical properties, even in non-chiral environments. Therefore, each mirror pair and each non-chiral stereoisomer may be given a specific monosaccharide name. For example, there are 16 distinct aldohexose stereoisomers, but the name "glucose" means a specific pair of mirror-image aldohexoses. In the Fischer projection, one of the two glucose isomers has the hydroxyl at left on C3, and at right on C4 and C5; while the other isomer has the reversed pattern. These specific monosaccharide names have conventional three-letter abbreviations, like "Glu" for glucose and "Thr" for threose.

Generally, a monosaccharide with "n" asymmetrical carbons has 2 stereoisomers. The number of open chain stereoisomers for an aldose monosaccharide is larger by one than that of a ketose monosaccharide of the same length. Every ketose will have 2 stereoisomers where "n" > 2 is the number of carbons. Every aldose will have 2 stereoisomers where "n" > 2 is the number of carbons.
These are also referred to as epimers which have the different arrangement of −OH and −H groups at the asymmetric or chiral carbon atoms (this does not apply to those carbons having the carbonyl functional group).

Like many chiral molecules, the two stereoisomers of glyceraldehyde will gradually rotate the polarization direction of linearly polarized light as it passes through it, even in solution. The two stereoisomers are identified with the prefixes - and -, according to the sense of rotation: -glyceraldehyde is dextrorotatory (rotates the polarization axis clockwise), while -glyceraldehyde is levorotatory (rotates it counterclockwise).
The - and - prefixes are also used with other monosaccharides, to distinguish two particular stereoisomers that are mirror-images of each other. For this purpose, one considers the chiral carbon that is furthest removed from the C=O group. Its four bonds must connect to −H, −OH, −C(OH)H, and the rest of the molecule. If the molecule can be rotated in space so that the directions of those four groups match those of the analog groups in -glyceraldehyde's C2, then the isomer receives the - prefix. Otherwise, it receives the - prefix.

In the Fischer projection, the - and - prefixes specifies the configuration at the carbon atom that is second from bottom: - if the hydroxyl is on the right side, and - if it is on the left side.

Note that the - and - prefixes do not indicate the direction of rotation of polarized light, which is a combined effect of the arrangement at all chiral centers. However, the two enantiomers will always rotate the light in opposite directions, by the same amount. See also .

A monosaccharide often switches from the acyclic (open-chain) form to a cyclic form, through a nucleophilic addition reaction between the carbonyl group and one of the hydroxyls of the same molecule. The reaction creates a ring of carbon atoms closed by one bridging oxygen atom. The resulting molecule has an hemiacetal or hemiketal group, depending on whether the linear form was an aldose or a ketose. The reaction is easily reversed, yielding the original open-chain form.

In these cyclic forms, the ring usually has 5 or 6 atoms. These forms are called furanoses and pyranoses, respectively — by analogy with furan and pyran, the simplest compounds with the same carbon-oxygen ring (although they lack the double bonds of these two molecules). For example, the aldohexose glucose may form a hemiacetal linkage between the hydroxyl on carbon 1 and the oxygen on carbon 4, yielding a molecule with a 5-membered ring, called glucofuranose. The same reaction can take place between carbons 1 and 5 to form a molecule with a 6-membered ring, called glucopyranose. Cyclic forms with a 7-atom ring (the same of oxepane), rarely encountered, are called heptoses.

For many monosaccharides (including glucose), the cyclic forms predominate, in the solid state and in solutions, and therefore the same name commonly is used for the open- and closed-chain isomers. Thus, for example, the term "glucose" may signify glucofuranose, glucopyranose, the open-chain form, or a mixture of the three.

Cyclization creates a new stereogenic center at the carbonyl-bearing carbon. The −OH group that replaces the carbonyl's oxygen may end up in two distinct positions relative to the ring's midplane. Thus each open-chain monosaccharide yields two cyclic isomers (anomers), denoted by the prefixes α- and β-. The molecule can change between these two forms by a process called mutarotation, that consists in a reversal of the ring-forming reaction followed by another ring formation.

The stereochemical structure of a cyclic monosaccharide can be represented in a Haworth projection. In this diagram, the α-isomer for the pyranose form of a D-aldohexose has the -OH of the anomeric carbon below the plane of the carbon atoms, while the β-isomer has the -OH of the anomeric carbon above the plane. Pyranoses typically adopt a chair conformation, similar to that of cyclohexane. In this conformation, the α-isomer has the -OH of the anomeric carbon in an axial position, whereas the β-isomer has the OH- of the anomeric carbon in equatorial position (considering D-aldohexose sugars).

A large number of biologically important modified monosaccharides exist:






</doc>
<doc id="19924" url="https://en.wikipedia.org/wiki?curid=19924" title="Microscopium">
Microscopium

Microscopium is a minor constellation in the Southern Celestial Hemisphere, one of twelve created in the 18th century by French astronomer Nicolas Louis de Lacaille and one of several depicting scientific instruments. Its name is a Latinised form of the Greek word for microscope. Its stars are faint and hardly visible from most of the non-tropical Northern Hemisphere.

The constellation's brightest star is Gamma Microscopii of apparent magnitude 4.68, a yellow giant 2.5 times the Sun's mass located around 381 light-years distant. It passed within 1.14 and 3.45 light-years of the Sun some 3.9 million years ago, possibly disturbing the outer Solar System. Two star systems—WASP-7 and HD 205739—have planets, while two others—the young red dwarf star AU Microscopii and the sunlike HD 202628—have debris disks. AU Microscopii and the binary red dwarf system AT Microscopii are probably a wide triple system and members of the Beta Pictoris moving group. Nicknamed "Speedy Mic", BO Microscopii is a star with an extremely fast rotation period of 9 hours 7 minutes.

Microscopium is a small constellation bordered by Capricornus to the north, Piscis Austrinus and Grus to the west, Sagittarius to the east, and Indus to the south, touching on Telescopium to the southeast. The recommended three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is 'Mic'. The official constellation boundaries, as set by Eugène Delporte in 1930, are defined by a polygon of four segments ("illustrated in infobox"). In the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates are between −27.45° and −45.09°. The whole constellation is visible to observers south of latitude 45°N. Given that its brightest stars are of fifth magnitude, the constellation is invisible to the naked eye in areas with polluted skies.

French astronomer Nicolas Louis de Lacaille charted and designated ten stars with the Bayer designations Alpha through to Iota in 1756. A star in neighbouring Indus that Lacaille had labelled Nu Indi turned out to be in Microscopium, so Gould renamed it Nu Microscopii. Francis Baily considered Gamma and Epsilon Microscopii to belong to the neighbouring constellation Piscis Austrinus, but subsequent cartographers did not follow this. In his 1725 "Catalogus Britannicus", John Flamsteed labelled the stars 1, 2, 3 and 4 Piscis Austrini, which became Gamma Microscopii, HR 8076, HR 8110 and Epsilon Microscopii respectively. Within the constellation's borders, there are 43 stars brighter than or equal to apparent magnitude 6.5.

Depicting the eyepiece of the microscope is Gamma Microscopii, which—at magnitude of 4.68—is the brightest star in the constellation. Having spent much of its 620-million-year lifespan as a blue-white main sequence star, it has swollen and cooled to become a yellow giant of spectral type G6III, with a diameter ten times that of the Sun. Measurement of its parallax yields a distance of 229±4 light years from Earth. At around 2.5 times the mass of the Sun, it likely passed within 1.14 and 3.45 light-years of the Sun some 3.9 million years ago, possibly massive enough and close enough to disturb the Oort cloud. Alpha Microscopii is also an ageing yellow giant star of spectral type G7III with an apparent magnitude of 4.90. Located 380±30 light-years away from Earth, it has swollen to 17.5 times the diameter of the Sun. Alpha has a 10th magnitude companion, visible in 7.5 cm telescopes, though this is a coincidental closeness rather than a true binary system. Epsilon Microscopii lies 182±2 light years away, and is a white star of apparent magnitude 4.7, and spectral type A1V. Theta and Theta Microscopii make up a wide double whose components are splittable to the naked eye. Both are white A-class magnetic spectrum variable stars with strong metallic lines, similar to Cor Caroli. They mark the constellation's specimen slide.

Many notable objects are too faint to be seen with the naked eye. AX Microscopii, better known as Lacaille 8760, is a red dwarf which lies only 12.9 light-years from the Solar System. At magnitude 6.68, it is the brightest red dwarf in the sky. BO Microscopii is a rapidly rotating star that has 80% the diameter of the Sun. Nicknamed "Speedy Mic", it has a rotation period of 9 hours 7 minutes. An active star, it has prominent stellar flares that average 100 times stronger than those of the Sun, and are emitting energy mainly in the X-ray and ultraviolet bands of the spectrum. AT Microscopii is a binary star system, both members of which are flare star red dwarfs. The system lies close to and may form a very wide triple system with AU Microscopii, a young star which appears to be a planetary system in the making with a debris disk. The three stars are candidate members of the Beta Pictoris moving group, one of the nearest associations of stars that share a common motion through space.

The Astronomical Society of Southern Africa in 2003 reported that observations of four of the Mira variables in Microscopium were very urgently needed as data on their light curves was incomplete. Two of them—R and S Microscopii—are challenging stars for novice amateur astronomers, and the other two U and RY Microscopii are more difficult still. Another red giant, T Microscopii, is a semiregular variable that ranges between magnitudes 7.7 and 9.6 over 344 days. Of apparent magnitude 11, DD Microscopii is a symbiotic star system composed of an orange giant of spectral type K2III and white dwarf in close orbit, with the smaller star ionizing the stellar wind of the larger star. The system has a low metallicity. Combined with its high galactic latitude, this indicates that the star system has its origin in the galactic halo of the Milky Way.

HD 205739 is a yellow-white main sequence star of spectral type F7V that is around 1.22 times as massive and 2.3 times as luminous as the Sun. It has a Jupiter-sized planet with an orbital period of 280 days that was discovered by the radial velocity method. WASP-7 is a star of spectral type F5V with an apparent magnitude of 9.54, about 1.28 times as massive as the Sun. Its hot Jupiter planet—WASP-7b—was discovered by transit method and found to orbit the star every 4.95 days. HD 202628 is a sunlike star of spectral type G2V with a debris disk that ranges from 158 to 220 AU distant. Its inner edge is sharply defined, indicating a probable planet orbiting between 86 and 158 AU from the star.

Describing Microscopium as "totally unremarkable", astronomer Patrick Moore concluded there was nothing of interest for amateur observers. NGC 6925 is a barred spiral galaxy of apparent magnitude 11.3 which is lens-shaped, as it lies almost edge-on to observers on Earth, 3.7 degrees west-northwest of Alpha Microscopii. SN 2011ei, a Type II Supernova in NGC 6925, was discovered by Stu Parker in New Zealand in July 2011. NGC 6923 lies nearby and is a magnitude fainter still. The Microscopium Void is a roughly rectangular region of relatively empty space, bounded by incomplete sheets of galaxies from other voids. The Microscopium Supercluster is an overdensity of galaxy clusters that was first noticed in the early 1990s. The component Abell clusters 3695 and 3696 are likely to be gravitationally bound, while the relations of Abell clusters 3693 and 3705 in the same field are unclear.

The Microscopids are a minor meteor shower that appear from June to mid-July.

The stars that comprise Microscopium are in a region previously considered the hind feet of Sagittarius, a neighbouring constellation. John Ellard Gore wrote that al-Sufi seems to have reported that Ptolemy had seen the stars but he (Al Sufi) did not pinpoint their positions. Microscopium itself was introduced in 1751–52 by Lacaille with the French name "le Microscope", after he had observed and catalogued 10,000 southern stars during a two-year stay at the Cape of Good Hope. He devised fourteen new constellations in uncharted regions of the Southern Celestial Hemisphere not visible from Europe. All but one honoured instruments that symbolised the Age of Enlightenment. Commemorating the compound microscope, the Microscope's name had been Latinised by Lacaille to "Microscopium" by 1763.


</doc>
<doc id="19925" url="https://en.wikipedia.org/wiki?curid=19925" title="IC 342/Maffei Group">
IC 342/Maffei Group

The IC 342/Maffei Group (also known as the IC 342 Group or the Maffei 1 Group) is the nearest group of galaxies to the Local Group. The group can be described as a binary group; the member galaxies are mostly concentrated around either IC 342 or Maffei 1, both of which are the brightest galaxies within the group. The group is part of the Virgo Supercluster.

The table below lists galaxies that have been identified as associated with the IC342/Maffei 1 Group by I. D. Karachentsev. Note that Karachentsev divides this group into two subgroups centered around IC 342 and Maffei 1.

Additionally, KKH 37 is listed as possibly being a member of the IC 342 Subgroup, and KKH 6 is listed as possibly being a member of the Maffei 1 Subgroup.

As seen from Earth, the group lies near the plane of the Milky Way (a region sometimes called the Zone of Avoidance). Consequently, the light from many of the galaxies is severely affected by dust obscuration within the Milky Way. This complicates observational studies of the group, as uncertainties in the dust obscuration also affect measurements of the galaxies' luminosities and distances as well as other related quantities.

Moreover, the galaxies within the group have historically been difficult to identify. Many galaxies have only been discovered using late 20th century astronomical instrumentation. For example, while many fainter, more distant galaxies, such as the galaxies in the New General Catalogue, were already identified visually by the end of the nineteenth century, Maffei 1 and Maffei 2 were only discovered in 1968 using infrared photographic images of the region. Furthermore, it is difficult to determine whether some objects near IC 342 or Maffei 1 are galaxies associated with the IC 342/Maffei Group or diffuse foreground objects within the Milky Way that merely look like galaxies. For example, the objects MB 2 and Camelopardalis C were once thought to be dwarf galaxies in the IC 342/Maffei Group but are now known to be objects within the Milky Way.

Since the IC 342/Maffei Group and the Local Group are located physically close to each other, the two groups may have influenced each other's evolution during the early stages of galaxy formation. An analysis of the velocities and distances to the IC 342/Maffei Group as measured by M. J. Valtonen and collaborators suggested that IC 342 and Maffei 1 were moving faster than what could be accounted for in the expansion of the universe. They therefore suggested that IC 342 and Maffei 1 were ejected from the Local Group after a violent gravitational interaction with the Andromeda Galaxy during the early stages of the formation of the two groups.

However, this interpretation is dependent on the distances measured to the galaxies in the group, which in turn is dependent on accurately measuring the degree to which interstellar dust in the Milky Way obscures the group. More recent observations have demonstrated that the dust obscuration may have been previously overestimated, so the distances may have been underestimated. If these new distance measurements are correct, then the galaxies in the IC 342/Maffei Group appear to be moving at the rate expected from the expansion of the universe, and the scenario of a collision between the IC 342/Maffei Group and the Local Group would be implausible.


</doc>
<doc id="19926" url="https://en.wikipedia.org/wiki?curid=19926" title="M81 Group">
M81 Group

The M81 Group is a galaxy group in the constellations Ursa Major and Camelopardalis that includes the galaxies Messier 81 and Messier 82, as well as several other galaxies with high apparent brightnesses. The approximate center of the group is located at a distance of 3.6 Mpc, making it one of the nearest groups to the Local Group. The group is estimated to have a total mass of (1.03 ± 0.17).
The M81 Group, the Local Group, and other nearby groups all lie within the Virgo Supercluster (i.e. the Local Supercluster).

The table below lists galaxies that have been identified as associated with the M81 Group by I. D. Karachentsev.

Note that the object names used in the above table differ from the names used by Karachentsev. NGC, IC, UGC, and PGC numbers have been used in many cases to allow for easier referencing.

Messier 81, Messier 82, and NGC 3077 are all strongly interacting with each other. The gravitational interactions have stripped some hydrogen gas away from all three galaxies, leading to the formation of filamentary gas structures within the group. Moreover, the interactions have also caused some interstellar gas to fall into the centers of Messier 82 and NGC 3077, which has led to strong starburst activity (or the formation of many stars) within the centers of these two galaxies.



</doc>
<doc id="19929" url="https://en.wikipedia.org/wiki?curid=19929" title="Mensa">
Mensa

Mensa or Mensae (genitive form) may refer to:



</doc>
<doc id="19930" url="https://en.wikipedia.org/wiki?curid=19930" title="Metre (poetry)">
Metre (poetry)

In poetry, metre is the basic rhythmic structure of a verse or lines in verse. Many traditional verse forms prescribe a specific verse metre, or a certain set of metres alternating in a particular order. The study and the actual use of metres and forms of versification are both known as prosody. (Within linguistics, "prosody" is used in a more general sense that includes not only poetic metre but also the rhythmic aspects of prose, whether formal or informal, that vary from language to language, and sometimes between poetic traditions.)

An assortment of features can be identified when classifying poetry and its metre.

The metre of most poetry of the Western world and elsewhere is based on patterns of syllables of particular types. The familiar type of metre in English-language poetry is called qualitative metre, with stressed syllables coming at regular intervals (e.g. in iambic pentameters, usually every even-numbered syllable). Many Romance languages use a scheme that is somewhat similar but where the position of only one particular stressed syllable (e.g. the last) needs to be fixed. The metre of the old Germanic poetry of languages such as Old Norse and Old English was radically different, but was still based on stress patterns.

Some classical languages, in contrast, used a different scheme known as quantitative metre, where patterns were based on syllable weight rather than stress. In the dactylic hexameters of Classical Latin and Classical Greek, for example, each of the six feet making up the line was either a dactyl (long-short-short) or a spondee (long-long): a "long syllable" was literally one that took longer to pronounce than a short syllable: specifically, a syllable consisting of a long vowel or diphthong or followed by two consonants. The stress pattern of the words made no difference to the metre. A number of other ancient languages also used quantitative metre, such as Sanskrit and Classical Arabic (but not Biblical Hebrew).

Finally, non-stressed languages that have little or no differentiation of syllable length, such as French or Chinese, base their verses on the number of syllables only. The most common form in French is the Alexandrine, with twelve syllables a verse, and in classical Chinese five characters, and thus five syllables. But since each Chinese character is pronounced using one syllable in a certain tone, classical Chinese poetry also had more strictly defined rules, such as parallelism or antithesis between lines.

In many Western classical poetic traditions, the metre of a verse can be described as a sequence of "feet", each foot being a specific sequence of syllable types — such as relatively unstressed/stressed (the norm for English poetry) or long/short (as in most classical Latin and Greek poetry).

Iambic pentameter, a common metre in English poetry, is based on a sequence of five "iambic feet" or "iambs", each consisting of a relatively unstressed syllable (here represented with "×" above the syllable) followed by a relatively stressed one (here represented with "/" above the syllable) — "da-DUM" = "× /" :

This approach to analyzing and classifying metres originates from Ancient Greek tragedians and poets such as Homer, Pindar, Hesiod, and Sappho.

However some metres have an overall rhythmic pattern to the line that cannot easily be described using feet. This occurs in Sanskrit poetry; see Vedic metre and Sanskrit metre. (Although this poetry is in fact specified using feet, each "foot" is more or less equivalent to an entire line.) It also occurs in some Western metres, such as the hendecasyllable favoured by Catullus and Martial, which can be described as:

x x — ∪ ∪ — ∪ — ∪ — —

If the line has only one foot, it is called a "monometer"; two feet, "dimeter"; three is "trimeter"; four is "tetrameter"; five is "pentameter"; six is "hexameter", seven is "heptameter" and eight is "octameter". For example, if the feet are iambs, and if there are five feet to a line, then it is called a iambic pentameter. If the feet are primarily "dactyls" and there are six to a line, then it is a dactylic hexameter.

Sometimes a natural pause occurs in the middle of a line rather than at a line-break. This is a caesura (cut). A good example is from "The Winter's Tale" by William Shakespeare; the caesurae are indicated by '/':
In Latin and Greek poetry, a caesura is a break within a foot caused by the end of a word.

Each line of traditional Germanic alliterative verse is divided into two half-lines by a caesura. This can be seen in Piers Plowman:

By contrast with caesura, enjambment is incomplete syntax at the end of a line; the meaning runs over from one poetic line to the next, without terminal punctuation. Also from Shakespeare's "The Winter's Tale":
Poems with a well-defined overall metric pattern often have a few lines that violate that pattern. A common variation is the "inversion" of a foot, which turns an iamb ("da-DUM") into a trochee ("DUM-da"). Another common variation is a "headless" verse, which lacks the first syllable of the first foot. Yet a third variation is catalexis, where the end of a line is shortened by a foot, or two or part thereof - an example of this is at the end of each verse in Keats' 'La Belle Dame sans Merci':

Versification in Classical Sanskrit poetry is of three kinds.


Standard traditional works on metre are Pingala's Chandaḥśāstra and Kedāra's Vṛttaratnākara. The most exhaustive compilations, such as the modern ones by Patwardhan and Velankar contain over 600 metres. This is a substantially larger repertoire than in any other metrical tradition.

The metrical "feet" in the classical languages were based on the length of time taken to pronounce each syllable, which were categorized according to their weight as either "long" syllables or "short" syllables (indicated as "dum" and "di" below). These are also called "heavy" and "light" syllables, respectively, to distinguish from long and short vowels. The foot is often compared to a musical measure and the long and short syllables to whole notes and half notes. In English poetry, feet are determined by emphasis rather than length, with stressed and unstressed syllables serving the same function as long and short syllables in classical metre.

The basic unit in Greek and Latin prosody is a mora, which is defined as a single short syllable. A long syllable is equivalent to two morae. A long syllable contains either a long vowel, a diphthong, or a short vowel followed by two or more consonants. Various rules of elision sometimes prevent a grammatical syllable from making a full syllable, and certain other lengthening and shortening rules (such as correption) can create long or short syllables in contexts where one would expect the opposite.

The most important Classical metre is the dactylic hexameter, the metre of Homer and Virgil. This form uses verses of six feet. The word "dactyl" comes from the Greek word "daktylos" meaning "finger", since there is one long part followed by two short stretches. The first four feet are dactyls ("daa-duh-duh"), but can be spondees ("daa-daa"). The fifth foot is almost always a dactyl. The sixth foot is either a spondee or a trochee ("daa-duh"). The initial syllable of either foot is called the "ictus", the basic "beat" of the verse. There is usually a caesura after the ictus of the third foot. The opening line of the "Æneid" is a typical line of dactylic hexameter:

In this example, the first and second feet are dactyls; their first syllables, "Ar" and "rum" respectively, contain short vowels, but count as long because the vowels are both followed by two consonants. The third and fourth feet are spondees, the first of which is divided by the main caesura of the verse. The fifth foot is a dactyl, as is nearly always the case. The final foot is a spondee.

The dactylic hexameter was imitated in English by Henry Wadsworth Longfellow in his poem "Evangeline":
Notice how the first line:

Follows this pattern:

Also important in Greek and Latin poetry is the dactylic pentameter. This was a line of verse, made up of two equal parts, each of which contains two dactyls followed by a long syllable, which counts as a half foot. In this way, the number of feet amounts to five in total. Spondees can take the place of the dactyls in the first half, but never in the second. The long syllable at the close of the first half of the verse always ends a word, giving rise to a caesura.

Dactylic pentameter is never used in isolation. Rather, a line of dactylic pentameter follows a line of dactylic hexameter in the elegiac distich or elegiac couplet, a form of verse that was used for the composition of elegies and other tragic and solemn verse in the Greek and Latin world, as well as love poetry that was sometimes light and cheerful. An example from Ovid's "Tristia":

The Greeks and Romans also used a number of lyric metres, which were typically used for shorter poems than elegiacs or hexameter. In Aeolic verse, one important line was called the hendecasyllabic, a line of eleven syllables. This metre was used most often in the Sapphic stanza, named after the Greek poet Sappho, who wrote many of her poems in the form. A hendecasyllabic is a line with a never-varying structure: two trochees, followed by a dactyl, then two more trochees. In the Sapphic stanza, three hendecasyllabics are followed by an "Adonic" line, made up of a dactyl and a trochee. This is the form of Catullus 51 (itself an homage to Sappho 31):

The Sapphic stanza was imitated in English by Algernon Charles Swinburne in a poem he simply called "Sapphics":

The metrical system of Classical Arabic poetry, like those of classical Greek and Latin, is based on the weight of syllables classified as either "long" or "short". The basic principles of Arabic poetic metre "Arūḍ" or Arud ( ') Science of Poetry ( '), were put forward by Al-Farahidi (786 - 718 AD) who did so after noticing that poems consisted of repeated syllables in each verse. In his first book, "Al-Ard" ( ""), he described 15 types of verse. Al-Akhfash described one extra, the 16th.

A short syllable contains a short vowel with no following consonants. For example, the word "kataba," which syllabifies as "ka-ta-ba", contains three short vowels and is made up of three short syllables. A long syllable contains either a long vowel or a short vowel followed by a consonant as is the case in the word "maktūbun" which syllabifies as "mak-tū-bun". These are the only syllable types possible in Classical Arabic phonology which, by and large, does not allow a syllable to end in more than one consonant or a consonant to occur in the same syllable after a long vowel. In other words, syllables of the type "-āk-" or "-akr-" are not found in classical Arabic.

Each verse consists of a certain number of metrical feet ("tafāʿīl" or "ʾaǧzāʾ") and a certain combination of possible feet constitutes a metre ("baḥr").

The traditional Arabic practice for writing out a poem's metre is to use a concatenation of various derivations of the verbal root "F-ʿ-L" (فعل). Thus, the following hemistich

قفا نبك من ذكرى حبيبٍ ومنزلِ

Would be traditionally scanned as:

فعولن مفاعيلن فعولن مفاعلن

That is, Romanized and with traditional Western scansion:

Classical Arabic has sixteen established metres. Though each of them allows for a certain amount of variation, their basic patterns are as follows, using:

The terminology for metrical system used in classical and classical-style Persian poetry is the same as that of Classical Arabic, even though these are quite different in both origin and structure. This has led to serious confusion among prosodists, both ancient and modern, as to the true source and nature of the Persian meters, the most obvious error being the assumption that they were copied from Arabic.

Persian poetry is quantitative, and the metrical patterns are made of long and short syllables, much as in Classical Greek, Latin and Arabic. "Anceps" positions in the line, however, that is places where either a long or short syllable can be used (marked "x" in the schemes below), are not found in Persian verse except in some metres at the beginning of a line.

Persian poetry is written in couplets, with each half-line (hemistich) being 10-14 syllables long. Except in the ruba'i (quatrain), where either of two very similar metres may be used, the same metre is used for every line in the poem. Rhyme is always used, sometimes with double rhyme or internal rhymes in addition. In some poems, known as masnavi, the two halves of each couplet rhyme, with a scheme "aa", "bb", "cc" and so on. In lyric poetry, the same rhyme is used throughout the poem at the end of each couplet, but except in the opening couplet, the two halves of each couplet do not rhyme; hence the scheme is "aa", "ba", "ca", "da". A "ruba'i" (quatrain) also usually has the rhyme "aa, ba".

A particular feature of classical Persian prosody, not found in Latin, Greek or Arabic, is that instead of two lengths of syllables (long and short), there are three lengths (short, long, and overlong). Overlong syllables can be used anywhere in the line in place of a long + a short, or in the final position in a line or half line. When a metre has a pair of short syllables (u u), it is common for a long syllable to be substituted, especially at the end of a line or half-line.

About 30 different metres are commonly used in Persian. 70% of lyric poems are written in one of the following seven metres:

"Masnavi" poems (that is, long poems in rhyming couplets) are always written in one of the shorter 11 or 10-syllable metres (traditionally seven in number) such as the following:

The two metres used for "ruba'iyat" (quatrains), which are only used for this, are the following, of which the second is a variant of the first:

Classical Chinese poetic metric may be divided into fixed and variable length line types, although the actual scansion of the metre is complicated by various factors, including linguistic changes and variations encountered in dealing with a tradition extending over a geographically extensive regional area for a continuous time period of over some two-and-a-half millennia. Beginning with the earlier recorded forms: the Classic of Poetry tends toward couplets of four-character lines, grouped in rhymed quatrains; and, the Chuci follows this to some extent, but moves toward variations in line length. Han Dynasty poetry tended towards the variable line-length forms of the folk ballads and the Music Bureau yuefu. Jian'an poetry, Six Dynasties poetry, and Tang Dynasty poetry tend towards a poetic metre based on fixed-length lines of five, seven, (or, more rarely six) characters/verbal units tended to predominate, generally in couplet/quatrain-based forms, of various total verse lengths. The Song poetry is specially known for its use of the "ci", using variable line lengths which follow the specific pattern of a certain musical song's lyrics, thus "ci" are sometimes referred to as "fixed-rhythm" forms. Yuan poetry metres continued this practice with their "qu" forms, similarly fixed-rhythm forms based on now obscure or perhaps completely lost original examples (or, ur-types). Not that Classical Chinese poetry ever lost the use of the "shi" forms, with their metrical patterns found in the "old style poetry" ("gushi") and the regulated verse forms of ("lüshi" or "jintishi"). The regulated verse forms also prescribed patterns based upon linguistic tonality. The use of caesura is important in regard to the metrical analysis of Classical Chinese poetry forms.

The metric system of Old English poetry was different from that of modern English, and related more to the verse forms of most of the older Germanic languages such as Old Norse. It used alliterative verse, a metrical pattern involving varied numbers of syllables but a fixed number (usually four) of strong stresses in each line. The unstressed syllables were relatively unimportant, but the caesurae (breaks between the half-lines) played a major role in Old English poetry.

In place of using feet, alliterative verse divided each line into two half-lines. Each half-line had to follow one of five or so patterns, each of which defined a sequence of stressed and unstressed syllables, typically with two stressed syllables per half line. Unlike typical Western poetry, however, the number of unstressed syllables could vary somewhat. For example, the common pattern "DUM-da-DUM-da" could allow between one and five unstressed syllables between the two stresses.

The following is a famous example, taken from The Battle of Maldon, a poem written shortly after the date of that battle (AD 991):

<poem style="margin-left: 2em">
"Hige sceal þe heardra," || "heorte þe cēnre,"
"mōd sceal þe māre," || "swā ūre mægen lȳtlað"

("Will must be the harder, courage the bolder,
spirit must be the more, as our might lessens.")
</poem>

In the quoted section, the stressed syllables have been underlined. (Normally, the stressed syllable must be long if followed by another syllable in a word. However, by a rule known as "syllable resolution", two short syllables in a single word are considered equal to a single long syllable. Hence, sometimes two syllables have been underlined, as in "hige" and "mægen".) The German philologist Eduard Sievers (died 1932) identified five different patterns of half-line in Anglo-Saxon alliterative poetry. The first three half-lines have the type A pattern "DUM-da-(da-)DUM-da", while the last one has the type C pattern "da-(da-da-)DUM-DUM-da", with parentheses indicating optional unstressed syllables that have been inserted. Note also the pervasive pattern of alliteration, where the first and/or second stressed syllables alliterate with the third, but not with the fourth.

Most English metre is classified according to the same system as Classical metre with an important difference. English is an accentual language, and therefore beats and offbeats (stressed and unstressed syllables) take the place of the long and short syllables of classical systems. In most English verse, the metre can be considered as a sort of back beat, against which natural speech rhythms vary expressively. The most common characteristic feet of English verse are the iamb in two syllables and the anapest in three. (See Foot (prosody) for a complete list of the metrical feet and their names.)

The number of metrical systems in English is not agreed upon. The four major types are: accentual verse, accentual-syllabic verse, syllabic verse and quantitative verse. The alliterative verse of Old English could also be added to this list, or included as a special type of accentual verse. Accentual verse focuses on the number of stresses in a line, while ignoring the number of offbeats and syllables; accentual-syllabic verse focuses on regulating both the number of stresses and the total number of syllables in a line; syllabic verse only counts the number of syllables in a line; quantitative verse regulates the patterns of long and short syllables (this sort of verse is often considered alien to English). It is to be noted, however, that the use of foreign metres in English is all but exceptional.

The most frequently encountered metre of English verse is the iambic pentameter, in which the metrical norm is five iambic feet per line, though metrical substitution is common and rhythmic variations practically inexhaustible. John Milton's "Paradise Lost", most sonnets, and much else besides in English are written in iambic pentameter. Lines of unrhymed iambic pentameter are commonly known as blank verse. Blank verse in the English language is most famously represented in the plays of William Shakespeare and the great works of Milton, though Tennyson ("Ulysses", "The Princess") and Wordsworth ("The Prelude") also make notable use of it.

A rhymed pair of lines of iambic pentameter make a heroic couplet, a verse form which was used so often in the 18th century that it is now used mostly for humorous effect (although see Pale Fire for a non-trivial case). The most famous writers of heroic couplets are Dryden and Pope.

Another important metre in English is the ballad metre, also called the "common metre", which is a four-line stanza, with two pairs of a line of iambic tetrameter followed by a line of iambic trimeter; the rhymes usually fall on the lines of trimeter, although in many instances the tetrameter also rhymes. This is the metre of most of the Border and Scots or English ballads. In hymnody it is called the "common metre", as it is the most common of the named hymn metres used to pair many hymn lyrics with melodies, such as "Amazing Grace":

Emily Dickinson is famous for her frequent use of ballad metre:

In French poetry, metre is determined solely by the number of syllables in a line. A silent 'e' counts as a syllable before a consonant, but is elided before a vowel (where "h aspiré" counts as a consonant). At the end of a line, the "e" remains unelided but is hypermetrical (outside the count of syllables, like a feminine ending in English verse), in that case, the rhyme is also called "feminine", whereas it is called "masculine" in the other cases.

The most frequently encountered metre in Classical French poetry is the alexandrine, composed of two hemistiches of six syllables each. Two famous alexandrines are

(the daughter of Minos and Pasiphae), and

Classical French poetry also had a complex set of rules for rhymes that goes beyond how words merely sound. These are usually taken into account when describing the metre of a poem.

In Spanish poetry the metre is determined by the number of syllables the verse has. Still it is the phonetic accent in the last word of the verse that decides the final count of the line. If the accent of the final word is at the last syllable, then the poetic rule states that one syllable shall be added to the actual count of syllables in the said line, thus having a higher number of poetic syllables than the number of grammatical syllables. If the accent lies on the second to last syllable of the last word in the verse, then the final count of poetic syllables will be the same as the grammatical number of syllables. Furthermore, if the accent lies on the third to last syllable, then one syllable is subtracted from the actual count, having then less poetic syllables than grammatical syllables.

Spanish poetry uses poetic licenses, unique to Romance languages, to change the number of syllables by manipulating mainly the vowels in the line.

Regarding these poetic licenses one must consider three kinds of phenomena: (1) syneresis, (2) dieresis and (3) hiatus

There are many types of licenses, used either to add or subtract syllables, that may be applied when needed after taking in consideration the poetic rules of the last word. Yet all have in common that they only manipulate vowels that are close to each other and not interrupted by consonants.

Some common metres in Spanish verse are:

In Italian poetry, metre is determined solely by the position of the last accent in a line, the position of the other accents being however important for verse equilibrium. Syllables are enumerated with respect to a verse which ends with a paroxytone, so that a Septenary (having seven syllables) is defined as a verse whose last accent falls on the sixth syllable: it may so contain eight syllables ("Ei fu. Siccome immobile") or just six ("la terra al nunzio sta"). Moreover, when a word ends with a vowel and the next one starts with a vowel, they are considered to be in the same syllable (synalepha): so "Gli anni e i giorni" consists of only four syllables ("Gli an" "ni e i" "gior" "ni"). Even-syllabic verses have a fixed stress pattern. Because of the mostly trochaic nature of the Italian language, verses with an even number of syllables are far easier to compose, and the Novenary is usually regarded as the most difficult verse.

Some common metres in Italian verse are:

Apart from Ottoman poetry, which was heavily influenced by Persian traditions and created a unique Ottoman style, traditional Turkish poetry features a system in which the number of syllables in each verse must be the same, most frequently 7, 8, 11, 14 syllables. These verses are then divided into syllable groups depending on the number of total syllables in a verse: 4+3 for 7 syllables, 4+4 or 5+3 for 8, 4+4+3 or 6+5 for 11 syllables. The end of each group in a verse is called a "durak" (stop), and must coincide with the last syllable of a word.

The following example is by Faruk Nafiz Çamlıbel (died 1973), one of the most devoted users of traditional Turkish metre:

In this poem the 6+5 metre is used, so that there is a word-break ("durak" = "stop" or caesura) after the sixth syllable of every line, as well as at the end of each line.

In the Ottoman Turkish language, the structures of the poetic foot (تفعل "tef'ile") and of poetic metre (وزن "vezin") were imitated from Persian poetry. About twelve of the commonest Persian metres were used for writing Turkish poetry. As was the case with Persian, no use at all was made of the commonest metres of Arabic poetry (the "tawīl", "basīt", "kāmil", and "wāfir"). However, the terminology used to described the metres was indirectly borrowed from the Arabic poetic tradition through the medium of the Persian language.

As a result, Ottoman poetry, also known as Dîvân poetry, was generally written in quantitative, mora-timed metre. The moras, or syllables, are divided into three basic types:


In writing out a poem's poetic metre, open syllables are symbolized by "." and closed syllables are symbolized by "–". From the different syllable types, a total of sixteen different types of poetic foot—the majority of which are either three or four syllables in length—are constructed, which are named and scanned as follows:

These individual poetic feet are then combined in a number of different ways, most often with four feet per line, so as to give the poetic metre for a line of verse. Some of the most commonly used metres are the following:


Portuguese poetry uses a syllabic metre in which the verse is classified according to the last stressed syllable. The Portuguese system is quite similar to those of Spanish and Italian, as they are closely related languages. The most commonly used verses are:

Metrical texts are first attested in early Indo-European languages. The earliest known unambiguously metrical texts, and at the same time the only metrical texts with a claim of dating to the Late Bronze Age, are the hymns of the Rigveda. That the texts of the Ancient Near East (Sumerian, Egyptian or Semitic) should not exhibit metre is surprising, and may be partly due to the nature of Bronze Age writing. There were, in fact, attempts to reconstruct metrical qualities of the poetic portions of the Hebrew Bible, e.g. by Gustav Bickell or Julius Ley, but they remained inconclusive (see Biblical poetry). Early Iron Age metrical poetry is found in the Iranian Avesta and in the Greek works attributed to Homer and Hesiod.
Latin verse survives from the Old Latin period (c. 2nd century BC), in the Saturnian metre. Persian poetry arises in the Sassanid era. Tamil poetry of the early centuries AD may be the earliest known non-Indo-European

Medieval poetry was metrical without exception, spanning traditions as diverse as European Minnesang, Trouvère or Bardic poetry, Classical Persian and Sanskrit poetry, Tang dynasty Chinese poetry or the Japanese Nara period "Man'yōshū". Renaissance and Early Modern poetry in Europe is characterized by a return to templates of Classical Antiquity, a tradition begun by Petrarca's generation and continued into the time of Shakespeare and Milton.

Not all poets accept the idea that metre is a fundamental part of poetry. 20th-century American poets Marianne Moore, William Carlos Williams and Robinson Jeffers believed that metre was an artificial construct imposed upon poetry rather than being innate to poetry. In an essay titled "Robinson Jeffers, & The Metric Fallacy" Dan Schneider echoes Jeffers' sentiments: "What if someone actually said to you that all music was composed of just 2 notes? Or if someone claimed that there were just 2 colors in creation? Now, ponder if such a thing were true. Imagine the clunkiness & mechanicality of such music. Think of the visual arts devoid of not just color, but sepia tones, & even shades of gray." Jeffers called his technique "rolling stresses".

Moore went further than Jeffers, openly declaring her poetry was written in syllabic form, and wholly denying metre. These syllabic lines from her famous poem illustrate her contempt for metre and other poetic tools. Even the syllabic pattern of this poem does not remain perfectly consistent:

Williams tried to form poetry whose subject matter was centered on the lives of common people. He came up with the concept of the variable foot. Williams spurned traditional metre in most of his poems, preferring what he called "colloquial idioms." Another poet that turned his back on traditional concepts of metre was Britain's Gerard Manley Hopkins. Hopkins' major innovation was what he called sprung rhythm. He claimed most poetry was written in this older rhythmic structure inherited from the Norman side of the English literary heritage, based on repeating groups of two or three syllables, with the stressed syllable falling in the same place on each repetition. Sprung rhythm is structured around feet with a variable number of syllables, generally between one and four syllables per foot, with the stress always falling on the first syllable in a foot.




</doc>
<doc id="19932" url="https://en.wikipedia.org/wiki?curid=19932" title="Majed Moqed">
Majed Moqed

A former law student, Majed Mashaan Ghanem Moqed (, ; also transliterated as Moqued) (June 18, 1977 – September 11, 2001) was one of five hijackers of American Airlines Flight 77 as part of the September 11 attacks.

A Saudi, Moqed was studying law at a university in Saudi Arabia before joining Al-Qaeda in 1999 and being chosen to participate in the 9/11 attacks. He arrived in the United States in May 2001 and helped with the planning of how the attacks would be carried out.

On September 11, 2001, Moqed boarded American Airlines Flight 77 and assisted in the hijacking of the plane so that it could be crashed into the Pentagon.

Moqed was a law student from the small town of Al-Nakhil, Saudi Arabia (west of Medina), studying at King Fahd University's Faculty of Administration and Economics. Before he dropped out, he was apparently recruited into al-Qaeda in 1999 along with friend Satam al-Suqami, with whom he had earlier shared a college room. 

The two trained at Khalden, a large training facility near Kabul that was run by Ibn al-Shaykh al-Libi. A friend in Saudi Arabia claimed he was last seen there in 2000, before leaving to study English in the United States. In November 2000, Moqed and Suqami flew into Iran from Bahrain together.

Some time late in 2000, Moqed traveled to the United Arab Emirates, where he purchased traveler's cheques presumed to have been paid for by 9/11 financier Mustafa Ahmed al-Hawsawi. Five other hijackers also passed through the UAE and purchased travellers cheques, including Wail al-Shehri, Saeed al-Ghamdi, Hamza al-Ghamdi, Ahmed al-Haznawi and Ahmed al-Nami.

Known as "al-Ahlaf" during the preparations, Moqed then moved in with hijackers Salem al-Hazmi, Abdulaziz al-Omari and Khalid al-Mihdhar in an apartment in Paterson, New Jersey.

According to the FBI, Moqed first arrived in the United States on May 2, 2001.

In March 2001, Moqed, Hani Hanjour, Hazmi and Ahmed al-Ghamdi rented a minivan and travelled to Fairfield, Connecticut. There they met a contact in the parking lot of a local convenience store who provided them with false IDs. (This was possibly Eyad Alrababah, a Jordanian charged with document fraud).

Moqed was one of the five hijackers who asked for a state identity card on August 2, 2001. On August 24, both Mihdhar and Moqed tried to purchase flight tickets from the American Airlines online ticket-merchant, but had technical difficulties resolving their address and gave up.

Employees at Advance Travel Service in Totowa, New Jersey later claimed that Moqed and Hanjour had both purchased tickets there. They claimed that Hani Hanjour spoke very little English, and Moqed did most of the speaking. Hanjour requested a seat in the front row of the airplane. Their credit card failed to authorize, and after being told the agency did not accept personal cheques, the pair left to withdraw cash. They returned shortly afterwards and paid $1842.25 total in cash. 
During this time, Moqed was staying in Room 343 of the "Valencia Motel". On September 2, Moqed paid cash for a $30 weekly membership at Gold's Gym in Greenbelt, Maryland.

Three days later he was seen on an ATM camera with Hani Hanjour. After the attacks, employees at an adult video store, "Adult Lingerie Center", in Beltsville claimed that Moqed had been in the store three times, although there were no transactions slips that confirmed this.

On September 11, 2001, Moqed arrived at Washington Dulles International Airport.

According to the 9/11 Commission Report, Moqed set off the metal detector at the airport and was screened with a hand-wand. He passed the cursory inspection, and was able board his flight at 7:50. He was seated in 12A, adjacent to Mihdhar who was in 12B. Moqed helped to hijack the plane and assisted Hani Hanjour in crashing the plane into the Pentagon at 9:37 A.M., killing 189 people (64 on the plane and 125 on the ground).

The flight was scheduled to depart at 08:10, but ended up departing 10 minutes late from Gate D26 at Dulles. The last normal radio communications from the aircraft to air traffic control occurred at 08:50:51. At 08:54, Flight 77 began to deviate from its normal, assigned flight path and turned south, and then hijackers set the flight's autopilot heading for Washington, D.C. Passenger Barbara Olson called her husband, United States Solicitor General Theodore Olson, and reported that the plane had been hijacked and that the assailants had box cutters and knives. At 09:37, American Airlines Flight 77 crashed into the west facade of the Pentagon, killing all 64 aboard (including the hijackers), along with 125 on the ground in the Pentagon. In the recovery process at the Pentagon, remains of all five Flight 77 hijackers were identified through a process of elimination, as not matching any DNA samples for the victims, and put into custody of the FBI.

After the attacks his family told Arab News that Moqed had been a fan of sports, and enjoyed travelling. Additionally, the U.S. announced it had found a "Kingdom of Saudi Arabia Student Identity Card" bearing Moqed's name in the rubble surrounding the Pentagon. They also stated that it appeared to have been a forgery.




</doc>
<doc id="19933" url="https://en.wikipedia.org/wiki?curid=19933" title="Matthew Perry (disambiguation)">
Matthew Perry (disambiguation)

Matthew Perry (born 1969) is Canadian-American television and film actor.

Matthew Perry or Matt Perry may also refer to:




</doc>
<doc id="19935" url="https://en.wikipedia.org/wiki?curid=19935" title="Mimeograph">
Mimeograph

The stencil duplicator or mimeograph machine (often abbreviated to mimeo) is a low-cost duplicating machine that works by forcing ink through a stencil onto paper. The mimeograph process should not be confused with the spirit duplicator process.

Mimeographs, along with spirit duplicators and hectographs, were a common technology in printing small quantities, as in office work, classroom materials, and church bulletins. Early fanzines were printed with this technology, because it was widespread and cheap. In the late 1960s, mimeographs, spirit duplicators, and hectographs began to be gradually displaced by photocopying.

Use of stencils is an ancient art, butthrough chemistry, papers, and pressestechniques advanced rapidly in the late nineteenth century:

A description of the Papyrograph method of duplication was published by David Owen: 

A major beneficiary of the invention of synthetic dyes was a document reproduction technique known as stencil duplicating. Its earliest form was invented in 1874 by Eugenio de Zuccato, a young Italian studying law in London, who called his device the Papyrograph. Zuccato’s system involved writing on a sheet of varnished paper with caustic ink, which ate through the varnish and paper fibers, leaving holes where the writing had been. This sheet – which had now become a stencil – was placed on a blank sheet of paper, and ink rolled over it so that the ink oozed through the holes, creating a duplicate on the second sheet.

The process was commercialized and Zuccato applied for a patent in 1895 having stencils prepared by typewriting.

Thomas Edison received US patent 180,857 for Autographic Printing on August 8, 1876. The patent covered the electric pen, used for making the stencil, and the flatbed duplicating press. In 1880 Edison obtained a further patent, US 224,665: "Method of Preparing Autographic Stencils for Printing," which covered the making of stencils using a file plate, a grooved metal plate on which the stencil was placed which perforated the stencil when written on with a blunt metal stylus.

The word mimeograph was first used by Albert Blake Dick when he licensed Edison's patents in 1887.

Dick received Trademark Registration no. 0356815 for the term "Mimeograph" in the US Patent Office. It is currently listed as a dead entry, but shows the A.B. Dick Company of Chicago as the owner of the name.

Over time, the term became generic and is now an example of a genericized trademark. ("Roneograph," also "Roneo machine," was another trademark used for mimeograph machines, the name being a contraction of Rotary Neostyle.)

In 1891, David Gestetner patented his Automatic Cyclostyle. This was one of the first rotary machines that retained the flatbed, which passed back and forth under inked rollers. This invention provided for more automated, faster reproductions since the pages were produced and moved by rollers instead of pressing one single sheet at a time.

By 1900, two primary types of mimeographs had come into use: a single-drum machine and a dual-drum machine. The single-drum machine used a single drum for ink transfer to the stencil, and the dual-drum machine used two drums and silk-screens to transfer the ink to the stencils. The single drum (example Roneo) machine could be easily used for multi-color work by changing the drum - each of which contained ink of a different color. This was spot color for mastheads. Colors could not be mixed.

The mimeograph became popular because it was much cheaper than traditional print - there was neither typesetting nor skilled labor involved. One individual with a typewriter and the necessary equipment became his own printing factory, allowing for greater circulation of printed material.

The image transfer medium was originally a stencil made from waxed mulberry paper. Later this became an immersion-coated long-fibre paper, with the coating being a plasticized nitrocellulose. This flexible waxed or coated sheet is backed by a sheet of stiff card stock, with the two sheets bound at the top.

Once prepared, the stencil is wrapped around the ink-filled drum of the rotary machine. When a blank sheet of paper is drawn between the rotating drum and a pressure roller, ink is forced through the holes on the stencil onto the paper. Early flatbed machines used a kind of squeegee. The ink originally had a lanolin base. and later became an oil in water emulsion. This emulsion commonly used Turkey-Red Oil (Sulfated Castor Oil) which gives it a distinctive and heavy scent.

For printed copy, a stencil assemblage is placed in a typewriter. The part of the mechanism which lifts the ribbon must be disabled so that the bare, sharp type element strikes the stencil directly. The impact of the type element displaces the coating, making the tissue paper permeable to the oil-based ink. This is called "cutting a stencil."

A variety of specialized styluses were used on the stencil to render lettering, illustrations, or other artistic features by hand against a textured plastic backing plate.

Mistakes can be corrected by brushing them out with a specially formulated correction fluid, and retyping once it has dried. ("Obliterine" was a popular brand of correction fluid in Australia and the United Kingdom.)

Stencils were also made with a thermal process; an infrared method similar to that used by early photocopiers. The common machine was a Thermofax.

Another device, called an electrostencil machine, sometimes was used to make mimeo stencils from a typed or printed original. It worked by scanning the original on a rotating drum with a moving optical head and burning through the blank stencil with an electric spark in the places where the optical head detected ink. It was slow and produced ozone. Text from electrostencils had lower resolution than that from typed stencils, although the process was good for reproducing illustrations. A skilled mimeo operator using an electrostencil and a very coarse halftone screen could make acceptable printed copies of a photograph.

During the declining years of the mimeograph, some people made stencils with early computers and dot-matrix impact printers.

Unlike spirit duplicators (where the only ink available is depleted from the master image), mimeograph technology works by forcing a replenishable supply of ink through the stencil master. In theory, the mimeography process could be continued indefinitely, especially if a durable stencil master were used (e.g. a thin metal foil). In practice, most low-cost mimeo stencils gradually wear out over the course of producing several hundred copies. Typically the stencil deteriorates gradually, producing a characteristic degraded image quality until the stencil tears, abruptly ending the print run. If further copies are desired at this point, another stencil must be made.

Often, the stencil material covering the interiors of closed letterforms (e.g. "a", "b", "d", "e", "g", etc.) would fall away during continued printing, causing ink-filled letters in the copies. The stencil would gradually stretch, starting near the top where the mechanical forces were greatest, causing a characteristic "mid-line sag" in the textual lines of the copies, that would progress until the stencil failed completely. The Gestetner Company (and others) devised various methods to make mimeo stencils more durable.

Compared to spirit duplication, mimeography produced a darker, more legible image. Spirit duplicated images were usually tinted a light purple or lavender, which gradually became lighter over the course of some dozens of copies. Mimeography was often considered "the next step up" in quality, capable of producing hundreds of copies. Print runs beyond that level were usually produced by professional printers or, as the technology became available, xerographic copiers.

Mimeographed images generally have much better durability than spirit-duplicated images, since the inks are more resistant to ultraviolet light. The primary preservation challenge is the low-quality paper often used, which would yellow and degrade due to residual acid in the treated pulp from which the paper was made. In the worst case, old copies can crumble into small particles when handled. Mimeographed copies have moderate durability when acid-free paper is used.

Gestetner, Risograph, and other companies still make and sell highly automated mimeograph-like machines that are externally similar to photocopiers. The modern version of a mimeograph, called a digital duplicator, or copyprinter, contains a scanner, a thermal head for stencil cutting, and a large roll of stencil material entirely inside the unit. The stencil material consists of a very thin polymer film laminated to a long-fibre non-woven tissue. It makes the stencils and mounts and unmounts them from the print drum automatically, making it almost as easy to operate as a photocopier. The Risograph is the best known of these machines.

Although mimeographs remain more economical and energy-efficient in mid-range quantities, easier-to-use photocopying and offset printing have replaced mimeography almost entirely in developed countries. Mimeograph machines continue to be used in developing countries because it is a simple, cheap, and robust technology. Many mimeographs can be hand-cranked, requiring no electricity.

Mimeographs and the closely related but distinctly different spirit duplicator process were both used extensively in schools to copy homework assignments and tests. They were also commonly used for low-budget amateur publishing, including club newsletters and church bulletins. They were especially popular with science fiction fans, who used them extensively in the production of fanzines in the middle 20th century, before photocopying became inexpensive.

Letters and typographical symbols were sometimes used to create illustrations, in a precursor to ASCII art. Because changing ink color in a mimeograph could be a laborious process, involving extensively cleaning the machine or, on newer models, replacing the drum or rollers, and then running the paper through the machine a second time, some fanzine publishers experimented with techniques for painting several colors on the pad, notably Shelby Vick, who created a kind of plaid "Vicolor".




</doc>
<doc id="19937" url="https://en.wikipedia.org/wiki?curid=19937" title="Meteorite">
Meteorite

A meteorite is a solid piece of debris from an object, such as a comet, asteroid, or meteoroid, that originates in outer space and survives its passage through the atmosphere to reach the surface of a planet or moon. When the object enters the atmosphere, various factors such as friction, pressure, and chemical interactions with the atmospheric gases cause it to heat up and radiate that energy. It then becomes a meteor and forms a fireball, also known as a shooting star or falling star; astronomers call the brightest examples "bolides". Meteorites vary greatly in size. For geologists, a bolide is a meteorite large enough to create a crater.

Meteorites that are recovered after being observed as they transit the atmosphere and impact the Earth are called meteorite falls. All others are known as meteorite finds. , there were about 1,140 witnessed falls that have specimens in the world's collections. , there are more than 38,660 well-documented meteorite finds.

Meteorites have traditionally been divided into three broad categories: stony meteorites that are rocks, mainly composed of silicate minerals; iron meteorites that are largely composed of metallic iron-nickel; and stony-iron meteorites that contain large amounts of both metallic and rocky material. Modern classification schemes divide meteorites into groups according to their structure, chemical and isotopic composition and mineralogy. Meteorites smaller than 2 mm are classified as micrometeorites. Extraterrestrial meteorites are such objects that have impacted other celestial bodies, whether or not they have passed through an atmosphere. They have been found on the Moon and Mars.

Meteorites are always named for the places they were found, usually a nearby town or geographic feature. In cases where many meteorites were found in one place, the name may be followed by a number or letter (e.g., Allan Hills 84001 or Dimmitt (b)). The name designated by the Meteoritical Society is used by scientists, catalogers, and most collectors.

Most meteoroids disintegrate when entering the Earth's atmosphere. Usually, five to ten a year are observed to fall and are subsequently recovered and made known to scientists. Few meteorites are large enough to create large impact craters. Instead, they typically arrive at the surface at their terminal velocity and, at most, create a small pit.

Large meteoroids may strike the earth with a significant fraction of their escape velocity (second cosmic velocity), leaving behind a hypervelocity impact crater. The kind of crater will depend on the size, composition, degree of fragmentation, and incoming angle of the impactor. The force of such collisions has the potential to cause widespread destruction. The most frequent hypervelocity cratering events on the Earth are caused by iron meteoroids, which are most easily able to transit the atmosphere intact. Examples of craters caused by iron meteoroids include Barringer Meteor Crater, Odessa Meteor Crater, Wabar craters, and Wolfe Creek crater; iron meteorites are found in association with all of these craters. In contrast, even relatively large stony or icy bodies like small comets or asteroids, up to millions of tons, are disrupted in the atmosphere, and do not make impact craters. Although such disruption events are uncommon, they can cause a considerable concussion to occur; the famed Tunguska event probably resulted from such an incident. Very large stony objects, hundreds of meters in diameter or more, weighing tens of millions of tons or more, can reach the surface and cause large craters, but are very rare. Such events are generally so energetic that the impactor is completely destroyed, leaving no meteorites. (The very first example of a stony meteorite found in association with a large impact crater, the Morokweng crater in South Africa, was reported in May 2006.)
Several phenomena are well documented during witnessed meteorite falls too small to produce hypervelocity craters. The fireball that occurs as the meteoroid passes through the atmosphere can appear to be very bright, rivaling the sun in intensity, although most are far dimmer and may not even be noticed during daytime. Various colors have been reported, including yellow, green, and red. Flashes and bursts of light can occur as the object breaks up. Explosions, detonations, and rumblings are often heard during meteorite falls, which can be caused by sonic booms as well as shock waves resulting from major fragmentation events. These sounds can be heard over wide areas, with a radius of a hundred or more kilometers. Whistling and hissing sounds are also sometimes heard, but are poorly understood. Following passage of the fireball, it is not unusual for a dust trail to linger in the atmosphere for several minutes.
As meteoroids are heated during atmospheric entry, their surfaces melt and experience ablation. They can be sculpted into various shapes during this process, sometimes resulting in shallow thumbprint-like indentations on their surfaces called regmaglypts. If the meteoroid maintains a fixed orientation for some time, without tumbling, it may develop a conical "nose cone" or "heat shield" shape. As it decelerates, eventually the molten surface layer solidifies into a thin fusion crust, which on most meteorites is black (on some achondrites, the fusion crust may be very light colored). On stony meteorites, the heat-affected zone is at most a few mm deep; in iron meteorites, which are more thermally conductive, the structure of the metal may be affected by heat up to below the surface. Reports vary; some meteorites are reported to be "burning hot to the touch" upon landing, while others are alleged to have been cold enough to condense water and form a frost. Meteorites from multiple falls, such as Bjurbole, Tagish Lake, and Buzzard Coulee, have been found having fallen on lake and sea ice, perhaps suggesting that they were not hot when they fell.

Meteoroids that experience disruption in the atmosphere may fall as meteorite showers, which can range from only a few up to thousands of separate individuals. The area over which a meteorite shower falls is known as its strewn field. Strewn fields are commonly elliptical in shape, with the major axis parallel to the direction of flight. In most cases, the largest meteorites in a shower are found farthest down-range in the strewn field.

Most meteorites are stony meteorites, classed as chondrites and achondrites. Only about 6% of meteorites are iron meteorites or a blend of rock and metal, the stony-iron meteorites. Modern classification of meteorites is complex. The review paper of Krot et al. (2007) summarizes modern meteorite taxonomy.

About 86% of the meteorites are chondrites, which are named for the small, round particles they contain. These particles, or chondrules, are composed mostly of silicate minerals that appear to have been melted while they were free-floating objects in space. Certain types of chondrites also contain small amounts of organic matter, including amino acids, and presolar grains. Chondrites are typically about 4.55 billion years old and are thought to represent material from the asteroid belt that never coalesced into large bodies. Like comets, chondritic asteroids are some of the oldest and most primitive materials in the solar system. Chondrites are often considered to be "the building blocks of the planets".

About 8% of the meteorites are achondrites (meaning they do not contain chondrules), some of which are similar to terrestrial igneous rocks. Most achondrites are also ancient rocks, and are thought to represent crustal material of differentiated planetesimals. One large family of achondrites (the HED meteorites) may have originated on the parent body of the Vesta Family, although this claim is disputed. Others derive from unidentified asteroids. Two small groups of achondrites are special, as they are younger and do not appear to come from the asteroid belt. One of these groups comes from the Moon, and includes rocks similar to those brought back to Earth by Apollo and Luna programs. The other group is almost certainly from Mars and constitutes the only materials from other planets ever recovered by humans.

About 5% of meteorites that have been seen to fall are iron meteorites composed of iron-nickel alloys, such as kamacite and/or taenite. Most iron meteorites are thought to come from the cores of planetesimals that were once molten. As with the Earth, the denser metal separated from silicate material and sank toward the center of the planetesimal, forming its core. After the planetesimal solidified, it broke up in a collision with another planetesimal. Due to the low abundance of iron meteorites in collection areas such as Antarctica, where most of the meteoric material that has fallen can be recovered, it is possible that the percentage of iron-meteorite falls is lower than 5%. This would be explained by a recovery bias; laypeople are more likely to notice and recover solid masses of metal than most other meteorite types. The abundance of iron meteorites relative to total Antarctic finds is 0.4% 

Stony-iron meteorites constitute the remaining 1%. They are a mixture of iron-nickel metal and silicate minerals. One type, called pallasites, is thought to have originated in the boundary zone above the core regions where iron meteorites originated. The other major type of stony-iron meteorites is the mesosiderites.

Tektites (from Greek "tektos", molten) are not themselves meteorites, but are rather natural glass objects up to a few centimeters in size that were formed—according to most scientists—by the impacts of large meteorites on Earth's surface. A few researchers have favored tektites originating from the Moon as volcanic ejecta, but this theory has lost much of its support over the last few decades.

In March 2015, NASA scientists reported that, for the first time, complex organic compounds found in DNA and RNA, including uracil, cytosine and thymine, have been formed in the laboratory under outer space conditions, using starting chemicals, such as pyrimidine, found in meteorites. Pyrimidine, like polycyclic aromatic hydrocarbons (PAHs), the most carbon-rich chemical found in the Universe, may have been formed in red giants or in interstellar dust and gas clouds, according to the scientists.

In January 2018, researchers found that 4.5 billion-year-old meteorites found on Earth contained liquid water along with prebiotic complex organic substances that may be ingredients for life.

Most meteorite falls are recovered on the basis of eyewitness accounts of the fireball or the impact of the object on the ground, or both. Therefore, despite the fact that meteorites fall with virtually equal probability everywhere on Earth, verified meteorite falls tend to be concentrated in areas with high human population densities such as Europe, Japan, and northern India.

A small number of meteorite falls have been observed with automated cameras and recovered following calculation of the impact point. The first of these was the Přibram meteorite, which fell in Czechoslovakia (now the Czech Republic) in 1959. In this case, two cameras used to photograph meteors captured images of the fireball. The images were used both to determine the location of the stones on the ground and, more significantly, to calculate for the first time an accurate orbit for a recovered meteorite.

Following the Pribram fall, other nations established automated observing programs aimed at studying infalling meteorites. One of these was the "Prairie Network", operated by the Smithsonian Astrophysical Observatory from 1963 to 1975 in the midwestern US. This program also observed a meteorite fall, the "Lost City" chondrite, allowing its recovery and a calculation of its orbit. Another program in Canada, the Meteorite Observation and Recovery Project, ran from 1971 to 1985. It too recovered a single meteorite, "Innisfree", in 1977. Finally, observations by the European Fireball Network, a descendant of the original Czech program that recovered Pribram, led to the discovery and orbit calculations for the "Neuschwanstein" meteorite in 2002.
NASA has an automated system that detects meteors and calculates the orbit, magnitude, ground track, and other parameters over the southeast USA, which often detects a number of events each night.

Until the twentieth century, only a few hundred meteorite finds had ever been discovered. More than 80% of these were iron and stony-iron meteorites, which are easily distinguished from local rocks. To this day, few stony meteorites are reported each year that can be considered to be "accidental" finds. The reason there are now more than 30,000 meteorite finds in the world's collections started with the discovery by Harvey H. Nininger that meteorites are much more common on the surface of the Earth than was previously thought.

Nininger's strategy was to search for meteorites in the Great Plains of the United States, where the land was largely cultivated and the soil contained few rocks. Between the late 1920s and the 1950s, he traveled across the region, educating local people about what meteorites looked like and what to do if they thought they had found one, for example, in the course of clearing a field. The result was the discovery of over 200 new meteorites, mostly stony types.

In the late 1960s, Roosevelt County, New Mexico in the Great Plains was found to be a particularly good place to find meteorites. After the discovery of a few meteorites in 1967, a public awareness campaign resulted in the finding of nearly 100 new specimens in the next few years, with many being by a single person, Ivan Wilson. In total, nearly 140 meteorites were found in the region since 1967. In the area of the finds, the ground was originally covered by a shallow, loose soil sitting atop a hardpan layer. During the dustbowl era, the loose soil was blown off, leaving any rocks and meteorites that were present stranded on the exposed surface.

A few meteorites were found in Antarctica between 1912 and 1964. In 1969, the 10th Japanese Antarctic Research Expedition found nine meteorites on a blue ice field near the Yamato Mountains. With this discovery, came the realization that movement of ice sheets might act to concentrate meteorites in certain areas. After a dozen other specimens were found in the same place in 1973, a Japanese expedition was launched in 1974 dedicated to the search for meteorites. This team recovered nearly 700 meteorites.

Shortly thereafter, the United States began its own program to search for Antarctic meteorites, operating along the Transantarctic Mountains on the other side of the continent: the Antarctic Search for Meteorites (ANSMET) program. European teams, starting with a consortium called "EUROMET" in the late 1980s, and continuing with a program by the Italian Programma Nazionale di Ricerche in Antartide have also conducted systematic searches for Antarctic meteorites.

The Antarctic Scientific Exploration of China has conducted successful meteorite searches since 2000. A Korean program (KOREAMET) was launched in 2007 and has collected a few meteorites. The combined efforts of all of these expeditions have produced more than 23,000 classified meteorite specimens since 1974, with thousands more that have not yet been classified. For more information see the article by Harvey (2003).

At about the same time as meteorite concentrations were being discovered in the cold desert of Antarctica, collectors discovered that many meteorites could also be found in the hot deserts of Australia. Several dozen meteorites had already been found in the Nullarbor region of Western and South Australia. Systematic searches between about 1971 and the present recovered more than 500 others, ~300 of which are currently well characterized. The meteorites can be found in this region because the land presents a flat, featureless, plain covered by limestone. In the extremely arid climate, there has been relatively little weathering or sedimentation on the surface for tens of thousands of years, allowing meteorites to accumulate without being buried or destroyed. The dark colored meteorites can then be recognized among the very different looking limestone pebbles and rocks.

In 1986–87, a German team installing a network of seismic stations while prospecting for oil discovered about 65 meteorites on a flat, desert plain about southeast of Dirj (Daraj), Libya. A few years later, a desert enthusiast saw photographs of meteorites being recovered by scientists in Antarctica, and thought that he had seen similar occurrences in northern Africa. In 1989, he recovered about 100 meteorites from several distinct locations in Libya and Algeria. Over the next several years, he and others who followed found at least 400 more meteorites. The find locations were generally in regions known as regs or hamadas: flat, featureless areas covered only by small pebbles and minor amounts of sand. Dark-colored meteorites can be easily spotted in these places. In the case of several meteorite fields, such as Dar el Gani, Dhofar, and others, favorable light-colored geology consisting of basic rocks (clays, dolomites, and limestones) makes meteorites particularly easy to identify.

Although meteorites had been sold commercially and collected by hobbyists for many decades, up to the time of the Saharan finds of the late 1980s and early 1990s, most meteorites were deposited in or purchased by museums and similar institutions where they were exhibited and made available for scientific research. The sudden availability of large numbers of meteorites that could be found with relative ease in places that were readily accessible (especially compared to Antarctica), led to a rapid rise in commercial collection of meteorites. This process was accelerated when, in 1997, meteorites coming from both the Moon and Mars were found in Libya. By the late 1990s, private meteorite-collecting expeditions had been launched throughout the Sahara. Specimens of the meteorites recovered in this way are still deposited in research collections, but most of the material is sold to private collectors. These expeditions have now brought the total number of well-described meteorites found in Algeria and Libya to more than 500.

Meteorite markets came into existence in the late 1990s, especially in Morocco. This trade was driven by Western commercialization and an increasing number of collectors. The meteorites were supplied by nomads and local people who combed the deserts looking for specimens to sell. Many thousands of meteorites have been distributed in this way, most of which lack any information about how, when, or where they were discovered. These are the so-called "Northwest Africa" meteorites. When they get classified, they are named "Northwest Africa" (abbreviated NWA) followed by a number. It is generally accepted that NWA meteorites originate in Morocco, Algeria, Western Sahara, Mali, and possibly even further afield. Nearly all of these meteorites leave Africa through Morocco. Scores of important meteorites, including Lunar and Martian ones, have been discovered and made available to science via this route. A few of the more notable meteorites recovered include Tissint and Northwest Africa 7034. Tissint was the first witnessed Martian meteorite fall in over fifty years; NWA 7034 is the oldest meteorite known to come from Mars, and is a unique water-bearing regolith breccia.

In 1999, meteorite hunters discovered that the desert in southern and central Oman were also favorable for the collection of many specimens. The gravel plains in the Dhofar and Al Wusta regions of Oman, south of the sandy deserts of the Rub' al Khali, had yielded about 5,000 meteorites as of mid-2009. Included among these are a large number of lunar and Martian meteorites, making Oman a particularly important area both for scientists and collectors. Early expeditions to Oman were mainly done by commercial meteorite dealers, however international teams of Omani and European scientists have also now collected specimens.

The recovery of meteorites from Oman is currently prohibited by national law, but a number of international hunters continue to remove specimens now deemed national treasures. This new law provoked a small international incident, as its implementation preceded any public notification of such a law, resulting in the prolonged imprisonment of a large group of meteorite hunters, primarily from Russia, but whose party also consisted of members from the US as well as several other European countries.

Beginning in the mid-1960s, amateur meteorite hunters began scouring the arid areas of the southwestern United States. To date, meteorites numbering possibly into the thousands have been recovered from the Mojave, Sonoran, Great Basin, and Chihuahuan Deserts, with many being recovered on dry lake beds. Significant finds include the three tonne Old Woman meteorite, currently on display at the Desert Discovery Center in Barstow, California. Other rare finds include the Los Angeles meteorite, a Martian meteorite, Superior Valley 014 Acapulcoite, one of two of its type found within the United States, and the Blue Eagle meteorite, the first Rumuruti-type chondrite yet found in the Americas.
A number of finds from the American Southwest have yet to be formally submitted to the Meteorite Nomenclature Committee, as many finders think it is unwise to publicly state the coordinates of their discoveries for fear of confiscation by the federal government and competition with other hunters at published find sites. 
Several of the meteorites found recently are currently on display in the Griffith Observatory in Los Angeles.

Meteorite falls may have been the source of cultish worship. The cult in the Temple of Artemis at Ephesus, one of the Seven Wonders of the Ancient World, possibly originated with the observation and recovery of a meteorite that was understood by contemporaries to have fallen to the earth from Jupiter, the principal Roman deity.
There are reports that a sacred stone was enshrined at the temple that may have been a meteorite. The Black Stone set into the wall of the Kaaba has often been presumed to be a meteorite, but the little available evidence for this is inconclusive. Although the use of the metal found in meteorites is also recorded in myths of many countries and cultures where the celestial source was often acknowledged, scientific documentation only began in the last few centuries.

The oldest known iron artifacts are nine small beads hammered from meteoritic iron. They were found in northern Egypt and have been securely dated to 3200 BC.

In the 1970s, a stone meteorite was uncovered during an archaeological dig at Danebury Iron Age hillfort, Danebury England. It was found deposited part way down in an Iron Age pit (c. 1200 BC). Since it must have been deliberately placed there, this could indicate one of the first (known) human finds of a meteorite in Europe.

Some Native Americans treated meteorites as ceremonial objects. In 1915, a iron meteorite was found in a Sinagua (c. 1100–1200 AD) burial cyst near Camp Verde, Arizona, respectfully wrapped in a feather cloth. A small pallasite was found in a pottery jar in an old burial found at Pojoaque Pueblo, New Mexico. Nininger reports several other such instances, in the Southwest US and elsewhere, such as the discovery of Native American beads of meteoric iron found in Hopewell burial mounds, and the discovery of the Winona meteorite in a Native American stone-walled crypt.
Indigenous peoples often prized iron-nickel meteorites as an easy, if limited, source of iron metal. For example, the Inuit used chips of the Cape York meteorite to form cutting edges for tools and spear tips.

Two of the oldest recorded meteorite falls in Europe are the Elbogen (1400) and Ensisheim (1492) meteorites. The German physicist, Ernst Florens Chladni, was the first to publish (in 1794) the then audacious idea that meteorites were rocks from space. His booklet was ""On the Origin of the Iron Masses Found by Pallas and Others Similar to it, and on Some Associated Natural Phenomena"". In this he compiled all available data on several meteorite finds and falls concluded that they must have their origins in outer space. The scientific community of the time responded with resistance and mockery. It took nearly ten years before a general acceptance of the origin of meteorites was achieved through the work of the French scientist Jean-Baptiste Biot and the British chemist, Edward Howard. Biot's study, initiated by the French Academy of Sciences, was compelled by a fall of thousands of meteorites on 26 April 1803 from the skies of L'Aigle, France.

One of the leading theories for the cause of the Cretaceous–Paleogene extinction event that included the dinosaurs is a large meteorite impact. The Chicxulub Crater has been identified as the site of this impact. There has been a lively scientific debate as to whether other major extinctions, including the ones at the end of the Permian and Triassic periods might also have been the result of large impact events, but the evidence is much less compelling than for the end Cretaceous extinction.

There are several reported instances of falling meteorites having killed people and livestock, but a few of these appear more credible than others. The most infamous reported fatality from a meteorite impact is that of an Egyptian dog that was killed in 1911, although this report is highly disputed. This meteorite fall was identified in the 1980s as Martian in origin. There is substantial evidence that the meteorite known as Valera (Venezuela 1972, see Meteorite fall) hit and killed a cow upon impact, nearly dividing the animal in two, and similar unsubstantiated reports of a horse being struck and killed by a stone of the New Concord fall also abound. Throughout history, many first- and second-hand reports of meteorites falling on and killing both humans and other animals abound. One example is from 1490 AD in China, which purportedly killed thousands of people. John Lewis has compiled some of these reports, and summarizes, "No one in recorded history has ever been killed by a meteorite in the presence of a meteoriticist and a medical doctor" and "reviewers who make sweeping negative conclusions usually do not cite any of the primary publications in which the eyewitnesses describe their experiences, and give no evidence of having read them".

The first known modern case of a human hit by a space rock occurred on 30 November 1954 in Sylacauga, Alabama. A stone chondrite crashed through a roof and hit Ann Hodges in her living room after it bounced off her radio. She was badly bruised. The Hodges meteorite, or Sylacauga meteorite, is currently on exhibit at the Alabama Museum of Natural History.

Another claim was put forth by a young boy who stated that he had been hit by a small (~3-gram) stone of the Mbale meteorite fall from Uganda, and who stood to gain nothing from this assertion. The stone reportedly fell through banana leaves before striking the boy on the head, causing little to no pain, as it was small enough to have been slowed by both friction with the atmosphere as well as that with banana leaves, before striking the boy.

Several persons have since claimed to have been struck by "meteorites" but no verifiable meteorites have resulted.

Most meteorites date from the oldest times in the solar system and are by far the oldest material available on the planet. Despite their age, they are fairly vulnerable to terrestrial environment: water, salt, and oxygen attack the meteorites as soon they reach the ground.

The terrestrial alteration of meteorites is called weathering. In order to quantify the degree of alteration that a meteorite experienced, several qualitative weathering indices have been applied to Antarctic and desertic samples.

The most known weathering scale, used for ordinary chondrites, ranges from W0 (pristine state) to W6 (heavy alteration).

"Fossil" meteorites are sometimes discovered by geologists. They represent the deeply weathered remains of meteorites that fell to Earth in the remote past and were preserved in sedimentary deposits sufficiently well that they can be recognized through mineralogical and geochemical studies. One limestone quarry in Sweden has produced an anomalously large number (more than a hundred) fossil meteorites from the Ordovician, nearly all of which are deeply weathered L-chondrites that still resemble the original meteorite under a petrographic microscope, but which have had their original material almost entirely replaced by terrestrial secondary mineralization. The extraterrestrial provenance was demonstrated in part through isotopic analysis of relict spinel grains, a mineral that is common in meteorites, is insoluble in water, and is able to persist chemically unchanged in the terrestrial weathering environment. One of these fossil meteorites, dubbed Österplana 065, appears to represent a distinct type of meteorite that is "extinct" in the sense that it is no longer falling to Earth, the parent body having already been completely depleted from reservoir of Near Earth Objects.


Apart from meteorites fallen onto the Earth, two tiny fragments of asteroids were found among the samples collected on the Moon; these were the Bench Crater meteorite (Apollo 12, 1969) and the Hadley Rille meteorite (Apollo 15, 1971).




</doc>
<doc id="19938" url="https://en.wikipedia.org/wiki?curid=19938" title="Mega-">
Mega-

Mega is a unit prefix in metric systems of units denoting a factor of one million (10 or ). It has the unit symbol M. It was confirmed for use in the International System of Units (SI) in 1960. "Mega" comes from the Greek , meaning "great".


When units occur in exponentiation, such as in square and cubic forms, any multiples-prefix is considered part of the unit, and thus included in the exponentiation.

In some fields of computing, "mega" may sometimes denote 1,048,576 (2) of information units, for example, a megabyte, a megaword, but denotes (10) units of other quantities, for example, transfer rates: = . The prefix "mebi-" has been suggested as a prefix for 2 to avoid ambiguity.




</doc>
<doc id="19940" url="https://en.wikipedia.org/wiki?curid=19940" title="Maciej Płażyński">
Maciej Płażyński

Maciej Płażyński (; 10 February 1958 – 10 April 2010) was a Polish liberal-conservative politician.

Płażyński was born in Młynary. He began his political career in 1980 / 1981 as one of the leaders of the Students' Solidarity; he was governor of the Gdańsk Voivodship from August 1990 to July 1996, and was elected to the Sejm (the lower house of the Polish parliament) in September 1997. To date he is longest serving Marshal of the Sejm of the Third Republic of Poland

In January 2001, he founded the Civic Platform political party with Donald Tusk and Andrzej Olechowski. He left Civic Platform for personal reasons and at the time of his death was an independent MP. He was member of Kashubian-Pomeranian Association. He was later chosen as a chairman of the Association "Polish Community".

Maciej Płażyński was married to Elżbieta Płażyńska and together they had three children: Jakub, Katarzyna, and Kacper.

He was listed on the flight manifest of the Tupolev Tu-154 of the 36th Special Aviation Regiment carrying the President of Poland Lech Kaczyński which crashed while landing at Smolensk-North airport near Pechersk near Smolensk, Russia, on 10 April 2010, killing all aboard.

In 2000, Płażyński was awarded the Order of Merit of the Italian Republic, First Class. He received the titles of honorary citizen of Młynary, Puck, Pionki and Lidzbark Warmiński.

On 16 April 2010 he was posthumously awarded the Grand Cross of the Order of Polonia Restituta. He was also awarded a Gold Medal of Gloria Artis.




</doc>
<doc id="19941" url="https://en.wikipedia.org/wiki?curid=19941" title="Mark Bingham">
Mark Bingham

Mark Kendall Bingham (May 22, 1970 – September 11, 2001) was an American public relations executive who founded his own company, the Bingham Group. During the September 11 attacks in 2001, he was a passenger on board United Airlines Flight 93. Bingham was among the passengers who, along with Todd Beamer, Tom Burnett and Jeremy Glick, formed the plan to retake the plane from the hijackers, and led the effort that resulted in the crash of the plane into a field near Shanksville, Pennsylvania, thwarting the hijackers plan to crash the plane into a building in Washington, D.C., most likely either the U.S. Capitol Building or the White House.

Both for his presence on United 93, as well as his athletic physique, Bingham has been widely honored posthumously for having "smashed the gay stereotype mold and really opened the door to many others who came after him."

Mark Bingham was born in 1970, the only child of mother Alice Hoagland and father Gerald Bingham. When Mark was two years old, his parents divorced. Raised by his mother and her family, Mark grew up in Miami, Florida, and Southern California before moving to the San Jose area in 1983. Bingham was an aspiring filmmaker growing up, and began using a video camera as a teenager as a personal diary through which he expressed himself and documented his life and the lives of his family and friends. He accumulated hundreds of hours of video documenting the final decade and a half of his life. He graduated from Los Gatos High School as a two-year captain of his rugby team in 1988. As an undergraduate at the University of California, Berkeley, Bingham played on two of Coach Jack Clark's national-championship-winning rugby teams in the early 1990s. He also joined the Chi Psi fraternity, eventually becoming its president. Upon graduation at the age of twenty-one, Bingham came out as gay to his family and friends.

A large athlete at and , Bingham also played for the gay-inclusive rugby union team San Francisco Fog RFC. Bingham played No. 8 in their first two friendly matches. He played in their first tournament, and taught his teammates his favorite rugby songs.

Bingham had recently opened a satellite office of his public relations firm in New York City, and was spending more time on the East Coast. He discussed plans with his friend Scott Glaessgen to form a New York City rugby team, the Gotham Knights.

On the morning of September 11, Bingham overslept and nearly missed his flight, on his way to San Francisco to be an usher in his fraternity brother Joseph Salama's wedding. He arrived at the Terminal A at 7:40am, ran to Gate 17, and was the last passenger to board United Airlines Flight 93, taking seat 4D, next to passenger Tom Burnett.

United Flight 93 was scheduled to depart at 8:00am, but the Boeing 757 did not depart until 42 minutes later due to runway traffic delays. Four minutes later, American Airlines Flight 11 crashed into the World Trade Center's North Tower. Fifteen minutes later, at 9:03 am, as United Flight 175 crashed into the South Tower, United 93 was climbing to cruising altitude, heading west over New Jersey and into Pennsylvania. At 9:25 am, Flight 93 was above eastern Ohio, and pilots Jason Dahl and LeRoy Homer received an alert, "beware of cockpit intrusion," on the cockpit computer device ACARS (Aircraft Communications and Reporting System). Three minutes later, Cleveland controllers could hear screams over the cockpit's open microphone. Moments later, the hijackers, led by the Lebanese Ziad Samir Jarrah, took over the plane's controls and told passengers, "Keep remaining sitting. We have a bomb on board". Bingham and the other passengers were herded into the back of the plane. Within six minutes, the plane changed course and was heading for Washington, D.C. Several of the passengers made phone calls to loved ones, who informed them about the two planes that had crashed into the World Trade Center. Bingham phoned his mother, who, according to Hoagland, said: "Hi mom, I love you very much, I'm calling you from the plane. We've been taken over. There are three men that say that they have a bomb."

After the hijackers veered the plane sharply south, the passengers decided to act. Bingham, along with Todd Beamer, Tom Burnett and Jeremy Glick, formed a plan to take the plane back from the hijackers. They were joined by other passengers, including Lou Nacke, Rich Guadagno, Alan Beaven, Honor Elizabeth Wainio, Linda Gronlund, and William Cashman, along with flight attendants Sandra Bradshaw and Cee Cee Ross-Lyles, in discussing their options and voting on a course of action, ultimately deciding to storm the cockpit and take over the plane.

According to the "9/11 Commission Report", after the plane's voice data recorder was recovered, it revealed pounding and crashing sounds against the cockpit door and shouts and screams in English. "Let's get them!" a passenger cries. A hijacker shouts, "Allah akbar!" ("God is great"). Jarrah repeatedly pitched the plane to knock passengers off their feet, but the passengers apparently managed to invade the cockpit, where one was heard shouting, "In the cockpit. If we don't, we'll die." At 10:02 am, a hijacker ordered, "Pull it down! Pull it down!" The 9/11 Commission later reported that the plane's control wheel was turned hard to the right, causing it to roll on its back and plow into an empty field in Shanksville, Pennsylvania at 580 miles an hour, killing everyone on board. The plane was twenty minutes of flying time away from its suspected target, the White House or the U.S. Capitol Building in Washington, D.C. According to Vice President Dick Cheney, President George W. Bush had given the order to shoot the plane down had it continued its path to Washington.

Bingham was survived by his parents, and Hoglan family members who played a part in his upbringing: his grandparents Betty and Herbert Hoglan, his aunt Candyce Hoglan, his uncles Lee, Linden and Vaughn Hoglan. He is survived as well by his stepmother and various stepsiblings. and his former partner of six years, Paul Holm, who said Bingham had risked his life to protect the lives of others on occasions prior to 9/11, having twice successfully protected Holm from attempted muggings, one at gunpoint. Holm described Bingham as a brave, competitive man, saying, "He hated to lose—at anything." He was known to proudly display a scar he received after being gored at the Running of the Bulls in Pamplona, Spain. He is buried at Madronia Cemetery, Saratoga, California.
U.S. Senators John McCain and Barbara Boxer honored Bingham on September 17, 2001, in a ceremony for San Francisco Bay Area victims of the attacks, presenting a folded American flag to Paul Holm.

The Mark Kendall Bingham Memorial Tournament (referred to as the Bingham Cup), a biennial international rugby union competition predominantly for gay and bisexual men, was established in 2002 in his memory.

Bingham, along with the other passengers on Flight 93, was posthumously awarded the Arthur Ashe Courage Award in 2002.

The Eureka Valley Recreation Center's Gymnasium in San Francisco was renamed the Mark Bingham Gymnasium in August 2002.

Singer Melissa Etheridge dedicated the song "Tuesday Morning" in 2004 to his memory.

Beginning in 2005, the Mark Bingham Award for Excellence in Achievement has been awarded by the California Alumni Association of the University of California, Berkeley to a young alumnus or alumna at its annual Charter Gala.

At the National 9/11 Memorial, Bingham and other passengers from Flight 93 are memorialized at the South Pool, on Panel S-67.

At the Flight 93 National Memorial in Pennsylvania, Bingham's name is located on one of the 40 8-foot-tall panels of polished, 3-inch thick granite that comprise the Memorial's Wall of Names.

The 2013 feature-length documentary "The Rugby Player" focuses on Bingham and the bond he had with his mother, Alice Hoagland, a former United Airlines flight attendant who, following his death, became a nationally known authority on airline safety and a champion of LGBT rights. Directed by Scott Gracheff, the film relies on the vast amount of video footage Bingham himself shot beginning in his teens until weeks before his death. The film's alternate title, "With You", is a popular rugby term, and one of Bingham's favorite expressions.





</doc>
<doc id="19942" url="https://en.wikipedia.org/wiki?curid=19942" title="Manner of articulation">
Manner of articulation

In articulatory phonetics, the manner of articulation is the configuration and interaction of the articulators (speech organs such as the tongue, lips, and palate) when making a speech sound. One parameter of manner is "stricture," that is, how closely the speech organs approach one another. Others include those involved in the r-like sounds (taps and trills), and the sibilancy of fricatives.

The concept of manner is mainly used in the discussion of consonants, although the movement of the articulators will also greatly alter the resonant properties of the vocal tract, thereby changing the formant structure of speech sounds that is crucial for the identification of vowels. For consonants, the place of articulation and the degree of phonation of voicing are considered separately from manner, as being independent parameters. Homorganic consonants, which have the same place of articulation, may have different manners of articulation. Often nasality and laterality are included in manner, but some phoneticians, such as Peter Ladefoged, consider them to be independent.

From greatest to least stricture, speech sounds may be classified along a cline as stop consonants (with "occlusion", or blocked airflow), fricative consonants (with partially blocked and therefore strongly turbulent airflow), approximants (with only slight turbulence), and vowels (with full unimpeded airflow). Affricates often behave as if they were intermediate between stops and fricatives, but phonetically they are sequences of a stop and fricative.

Over time, sounds in a language may move along this cline toward less stricture in a process called lenition, or towards more stricture in a process called fortition.

Sibilants are distinguished from other fricatives by the shape of the tongue and how the airflow is directed over the teeth. Fricatives at coronal places of articulation may be sibilant or non-sibilant, sibilants being the more common.

Flaps (also called taps) are similar to very brief stops. However, their articulation and behavior are distinct enough to be considered a separate manner, rather than just length. The main articulatory difference between flaps and stops is that, due to the greater length of stops compared to flaps, a build-up of air pressure occurs behind a stop which does not occur behind a flap. This means that when the stop is released, there is a burst of air as the pressure is relieved, while for flaps there is no such burst.

Trills involve the vibration of one of the speech organs. Since trilling is a separate parameter from stricture, the two may be combined. Increasing the stricture of a typical trill results in a trilled fricative. Trilled affricates are also known.

Nasal airflow may be added as an independent parameter to any speech sound. It is most commonly found in nasal occlusives and nasal vowels, but nasalized fricatives, taps, and approximants are also found. When a sound is not nasal, it is called "oral."

Laterality is the release of airflow at the side of the tongue. This can be combined with other manners, resulting in lateral approximants (such as the pronunciation of the letter L in the English word "let"), lateral flaps, and lateral fricatives and affricates.



Manners of articulation with substantial obstruction of the airflow (stops, fricatives, affricates) are called obstruents. These are prototypically voiceless, but voiced obstruents are extremely common as well. Manners without such obstruction (nasals, liquids, approximants, and also vowels) are called sonorants because they are nearly always voiced. Voiceless sonorants are uncommon, but are found in Welsh and Classical Greek (the spelling "rh"), in Standard Tibetan (the "lh" of Lhasa), and the "wh" in those dialects of English that distinguish "which" from "witch".

Sonorants may also be called resonants, and some linguists prefer that term, restricting the word 'sonorant' to non-vocoid resonants (that is, nasals and liquids, but not vowels or semi-vowels). Another common distinction is between occlusives (stops, nasals and affricates) and continuants (all else).

All of these manners of articulation are pronounced with an airstream mechanism called pulmonic egressive, meaning that the air flows outward, and is powered by the lungs (actually the ribs and diaphragm). Other airstream mechanisms are possible. Sounds that rely on some of these include:





</doc>
<doc id="19943" url="https://en.wikipedia.org/wiki?curid=19943" title="Mostaganem Province">
Mostaganem Province

Mostaganem () is a province ("wilaya") of Algeria. The capital is Mostaganem. Other localities include Ain Nouissi, Ain Tadles, Tazgait and Stidia.

The province is divided into 10 districts ("daïras"), which are further divided into 32 "communes" or municipalities.



</doc>
<doc id="19945" url="https://en.wikipedia.org/wiki?curid=19945" title="Motherboard">
Motherboard

A motherboard (sometimes alternatively known as the mainboard, system board, baseboard, planar board or logic board, or colloquially, a mobo) is the main printed circuit board (PCB) found in general purpose microcomputers and other expandable systems. It holds and allows communication between many of the crucial electronic components of a system, such as the central processing unit (CPU) and memory, and provides connectors for other peripherals. Unlike a backplane, a motherboard usually contains significant sub-systems such as the central processor, the chipset's input/output and memory controllers, interface connectors, and other components integrated for general purpose use and applications.

"Motherboard" specifically refers to a PCB with expansion capability and as the name suggests, this board is often referred to as the "mother" of all components attached to it, which often include peripherals, interface cards, and daughtercards: sound cards, video cards, network cards, hard drives, or other forms of persistent storage; TV tuner cards, cards providing extra USB or FireWire slots and a variety of other custom components.

Similarly, the term "mainboard" is applied to devices with a single board and no additional expansions or capability, such as controlling boards in laser printers, televisions, washing machines and other embedded systems with limited expansion abilities.

Prior to the invention of the microprocessor, a digital computer consisted of multiple printed circuit boards in a card-cage case with components connected by a backplane, a set of interconnected sockets. In very old designs, copper wires were the discrete connections between card connector pins, but printed circuit boards soon became the standard practice. The Central Processing Unit (CPU), memory, and peripherals were housed on individual printed circuit boards, which were plugged into the backplane. The ubiquitous S-100 bus of the 1970s is an example of this type of backplane system.

The most popular computers of the 1980s such as the Apple II and IBM PC had published schematic diagrams and other documentation which permitted rapid reverse-engineering and third-party replacement motherboards. Usually intended for building new computers compatible with the exemplars, many motherboards offered additional performance or other features and were used to upgrade the manufacturer's original equipment.

During the late 1980s and early 1990s, it became economical to move an increasing number of peripheral functions onto the motherboard. In the late 1980s, personal computer motherboards began to include single ICs (also called Super I/O chips) capable of supporting a set of low-speed peripherals: keyboard, mouse, floppy disk drive, serial ports, and parallel ports. By the late 1990s, many personal computer motherboards included consumer grade embedded audio, video, storage, and networking functions without the need for any expansion cards at all; higher-end systems for 3D gaming and computer graphics typically retained only the graphics card as a separate component. Business PCs, workstations, and servers were more likely to need expansion cards, either for more robust functions, or for higher speeds; those systems often had fewer embedded components.

Laptop and notebook computers that were developed in the 1990s integrated the most common peripherals. This even included motherboards with no upgradeable components, a trend that would continue as smaller systems were introduced after the turn of the century (like the tablet computer and the netbook). Memory, processors, network controllers, power source, and storage would be integrated into some systems.

A motherboard provides the electrical connections by which the other components of the system communicate. Unlike a backplane, it also contains the central processing unit and hosts other subsystems and devices.

A typical desktop computer has its microprocessor, main memory, and other essential components connected to the motherboard. Other components such as external storage, controllers for video display and sound, and peripheral devices may be attached to the motherboard as plug-in cards or via cables; in modern microcomputers it is increasingly common to integrate some of these peripherals into the motherboard itself.

An important component of a motherboard is the microprocessor's supporting chipset, which provides the supporting interfaces between the CPU and the various buses and external components. This chipset determines, to an extent, the features and capabilities of the motherboard.

Modern motherboards include:

Additionally, nearly all motherboards include logic and connectors to support commonly used input devices, such as USB for mouse devices and keyboards. Early personal computers such as the Apple II or IBM PC included only this minimal peripheral support on the motherboard. Occasionally video interface hardware was also integrated into the motherboard; for example, on the Apple II and rarely on IBM-compatible computers such as the IBM PC Jr. Additional peripherals such as disk controllers and serial ports were provided as expansion cards.

Given the high thermal design power of high-speed computer CPUs and components, modern motherboards nearly always include heat sinks and mounting points for fans to dissipate excess heat.

Motherboards are produced in a variety of sizes and shapes called computer form factor, some of which are specific to individual computer manufacturers. However, the motherboards used in IBM-compatible systems are designed to fit various case sizes. , most desktop computer motherboards use the ATX standard form factor — even those found in Macintosh and Sun computers, which have not been built from commodity components. A case's motherboard and power supply unit (PSU) form factor must all match, though some smaller form factor motherboards of the same family will fit larger cases. For example, an ATX case will usually accommodate a microATX motherboard.

Laptop computers generally use highly integrated, miniaturized and customized motherboards. This is one of the reasons that laptop computers are difficult to upgrade and expensive to repair. Often the failure of one laptop component requires the replacement of the entire motherboard, which is usually more expensive than a desktop motherboard due to the large number of integrated components and their custom shape and size. The motherboard layout for laptops depends on the laptop case.

A CPU socket (central processing unit) or slot is an electrical component that attaches to a Printed Circuit Board (PCB) and is designed to house a CPU (also called a microprocessor). It is a special type of integrated circuit socket designed for very high pin counts. A CPU socket provides many functions, including a physical structure to support the CPU, support for a heat sink, facilitating replacement (as well as reducing cost), and most importantly, forming an electrical interface both with the CPU and the PCB. CPU sockets on the motherboard can most often be found in most desktop and server computers (laptops typically use surface mount CPUs), particularly those based on the Intel x86 architecture. A CPU socket type and motherboard chipset must support the CPU series and speed.

With the steadily declining costs and size of integrated circuits, it is now possible to include support for many peripherals on the motherboard. By combining many functions on one PCB, the physical size and total cost of the system may be reduced; highly integrated motherboards are thus especially popular in small form factor and budget computers.

A typical motherboard will have a different number of connections depending on its standard and form factor.

A standard, modern ATX motherboard will typically have two or three PCI-Express 16x connection for a graphics card, one or two legacy PCI slots for various expansion cards, and one or two PCI-E 1x (which has superseded PCI). A standard EATX motherboard will have two to four PCI-E 16x connection for graphics cards, and a varying number of PCI and PCI-E 1x slots. It can sometimes also have a PCI-E 4x slot (will vary between brands and models).

Some motherboards have two or more PCI-E 16x slots, to allow more than 2 monitors without special hardware, or use a special graphics technology called SLI (for Nvidia) and Crossfire (for AMD). These allow 2 to 4 graphics cards to be linked together, to allow better performance in intensive graphical computing tasks, such as gaming, video editing, etc.

Motherboards are generally air cooled with heat sinks often mounted on larger chips, such as the Northbridge, in modern motherboards. Insufficient or improper cooling can cause damage to the internal components of the computer, or cause it to crash. Passive cooling, or a single fan mounted on the power supply, was sufficient for many desktop computer CPU's until the late 1990s; since then, most have required CPU fans mounted on their heat sinks, due to rising clock speeds and power consumption. Most motherboards have connectors for additional case fans and integrated temperature sensors to detect motherboard and CPU temperatures and controllable fan connectors which the BIOS or operating system can use to regulate fan speed. Alternatively computers can use a water cooling system instead of many fans.

Some small form factor computers and home theater PCs designed for quiet and energy-efficient operation boast fan-less designs. This typically requires the use of a low-power CPU, as well as careful layout of the motherboard and other components to allow for heat sink placement.

A 2003 study found that some spurious computer crashes and general reliability issues, ranging from screen image distortions to I/O read/write errors, can be attributed not to software or peripheral hardware but to aging capacitors on PC motherboards. Ultimately this was shown to be the result of a faulty electrolyte formulation, an issue termed capacitor plague.

Standard motherboards use electrolytic capacitors to filter the DC power distributed around the board. These capacitors age at a temperature-dependent rate, as their water based electrolytes slowly evaporate. This can lead to loss of capacitance and subsequent motherboard malfunctions due to voltage instabilities. While most capacitors are rated for 2000 hours of operation at , their expected design life roughly doubles for every below this. At a lifetime of 3 to 4 years can be expected. However, many manufacturers deliver substandard capacitors, which significantly reduce life expectancy. Inadequate case cooling and elevated temperatures around the CPU socket exacerbate this problem. With top blowers, the motherboard components can be kept under , effectively doubling the motherboard lifetime.

Mid-range and high-end motherboards on the other hand use solid capacitors exclusively. For every 10 °C less, their average lifespan is multiplied approximately by three, resulting in a 6-times higher lifetime expectancy at . These capacitors may be rated for 5000, 10000 or 12000 hours of operation at , extending the projected lifetime in comparison with standard solid capacitors.

High rates of motherboard failures in China and India appear to be due to "sulfurous air pollution produced by coal" that's burned to generate electricity. Air pollution corrodes the circuitry, according to Intel researchers.

Motherboards contain some non-volatile memory to initialize the system and load some startup software, usually an operating system, from some external peripheral device. Microcomputers such as the Apple II and IBM PC used ROM chips mounted in sockets on the motherboard. At power-up, the central processor would load its program counter with the address of the boot ROM and start executing instructions from the ROM. These instructions initialized and tested the system hardware, displayed system information on the screen, performed RAM checks, and then loaded an initial program from an external or peripheral device. If none was available, then the computer would perform tasks from other memory stores or display an error message, depending on the model and design of the computer and the ROM version. For example, both the Apple II and the original IBM PC had Microsoft Cassette BASIC in ROM and would start that if no program could be loaded from disk.

Most modern motherboard designs use a BIOS, stored in an EEPROM chip soldered to or socketed on the motherboard, to boot an operating system. Non-operating system boot programs are still supported on modern IBM PC-descended machines, but nowadays it is assumed that the boot program will be a complex operating system such as Microsoft Windows or Linux. When power is first supplied to the motherboard, the BIOS firmware tests and configures memory, circuitry, and peripherals. This Power-On Self Test (POST) may include testing some of the following things:

On recent motherboards the BIOS may also patch the central processor microcode if the BIOS detects that the installed CPU is one for which errata have been published.



</doc>
<doc id="19947" url="https://en.wikipedia.org/wiki?curid=19947" title="Mannerism">
Mannerism

Mannerism, also known as Late Renaissance, is a style in European art that emerged in the later years of the Italian High Renaissance around 1520 and lasted until about the end of the 16th century in Italy, when the Baroque style began to replace it. Northern Mannerism continued into the early 17th century.

Stylistically, Mannerism encompasses a variety of approaches influenced by, and reacting to, the harmonious ideals associated with artists such as Leonardo da Vinci, Raphael, and early Michelangelo. Where High Renaissance art emphasizes proportion, balance, and ideal beauty, Mannerism exaggerates such qualities, often resulting in compositions that are asymmetrical or unnaturally elegant. The style is notable for its intellectual sophistication as well as its artificial (as opposed to naturalistic) qualities. It favors compositional tension and instability rather than the balance and clarity of earlier Renaissance painting. Mannerism in literature and music is notable for its highly florid style and intellectual sophistication.

The definition of Mannerism and the phases within it continue to be a subject of debate among art historians. For example, some scholars have applied the label to certain early modern forms of literature (especially poetry) and music of the 16th and 17th centuries. The term is also used to refer to some late Gothic painters working in northern Europe from about 1500 to 1530, especially the Antwerp Mannerists—a group unrelated to the Italian movement. Mannerism also has been applied by analogy to the Silver Age of Latin literature.

The word "mannerism" derives from the Italian "maniera", meaning "style" or "manner". Like the English word "style", "maniera" can either indicate a specific type of style (a beautiful style, an abrasive style) or indicate an absolute that needs no qualification (someone "has style"). In the second edition of his "Lives of the Most Excellent Painters, Sculptors, and Architects" (1568), Giorgio Vasari used "maniera" in three different contexts: to discuss an artist's manner or method of working; to describe a personal or group style, such as the term "maniera greca" to refer to the Byzantine style or simply to the "maniera" of Michelangelo; and to affirm a positive judgment of artistic quality. Vasari was also a Mannerist artist, and he described the period in which he worked as "la maniera moderna", or the "modern style". James V. Mirollo describes how "bella maniera" poets attempted to surpass in virtuosity the sonnets of Petrarch. This notion of "bella maniera" suggests that artists who were thus inspired looked to copying and bettering their predecessors, rather than confronting nature directly. In essence, "bella maniera" utilized the best from a number of source materials, synthesizing it into something new.

As a stylistic label, "Mannerism" is not easily defined. It was used by Swiss historian Jacob Burckhardt and popularized by German art historians in the early 20th century to categorize the seemingly uncategorizable art of the Italian 16th century — art that was no longer found to exhibit the harmonious and rational approaches associated with the High Renaissance. “High Renaissance” connoted a period distinguished by harmony, grandeur and the revival of classical antiquity. The term Mannerist was redefined in 1967 by John Shearman following the exhibition of Mannerist paintings organised by Fritz Grossmann at Manchester City Art Gallery in 1965. The label “Mannerism” was used during the 16th century to comment on social behaviour and to convey a refined virtuoso quality or to signify a certain technique.
However, for later writers, such as the 17th-century Gian Pietro Bellori, "la maniera" was a derogatory term for the perceived decline of art after Raphael, especially in the 1530s and 1540s. From the late 19th century on, art historians have commonly used the term to describe art that follows Renaissance classicism and precedes the Baroque.

Yet historians differ as to whether Mannerism is a style, a movement, or a period; and while the term remains controversial it is still commonly used to identify European art and culture of the 16th century.

By the end of the High Renaissance, young artists experienced a crisis: it seemed that everything that could be achieved was already achieved. No more difficulties, technical or otherwise, remained to be solved. The detailed knowledge of anatomy, light, physiognomy and the way in which humans register emotion in expression and gesture, the innovative use of the human form in figurative composition, the use of the subtle gradation of tone, all had reached near perfection. The young artists needed to find a new goal, and they sought new approaches. At this point Mannerism started to emerge. The new style developed between 1510 and 1520 either in Florence, or in Rome, or in both cities simultaneously.

This period has been described as a "natural extension" of the art of Andrea del Sarto, Michelangelo, and Raphael. Michelangelo developed his own style at an early age, a deeply original one which was greatly admired at first, then often copied and imitated by other artists of the era. One of the qualities most admired by his contemporaries was his "terribilità", a sense of awe-inspiring grandeur, and subsequent artists attempted to imitate it. Other artists learned Michelangelo's impassioned and highly personal style by copying the works of the master, a standard way that students learned to paint and sculpt. His Sistine Chapel ceiling provided examples for them to follow, in particular his representation of collected figures often called "ignudi" and of the Libyan Sibyl, his vestibule to the Laurentian Library, the figures on his Medici tombs, and above all his "Last Judgment". The later Michelangelo was one of the great role models of Mannerism. Young artists broke in to his house and stole drawings from him. In his book "Lives of the Most Eminent Painters, Sculptors, and Architects", Giorgio Vasari noted that Michelangelo stated once: "Those who are followers can never pass by whom they follow".

The competitive spirit was cultivated by patrons who encouraged sponsored artists to emphasize virtuosic technique and to compete with one another for commissions. It drove artists to look for new approaches and dramatically illuminated scenes, elaborate clothes and compositions, elongated proportions, highly stylized poses, and a lack of clear perspective. Leonardo da Vinci and Michelangelo were each given a commission by Gonfaloniere Piero Soderini to decorate a wall in the Hall of Five Hundred in Florence. These two artists were set to paint side by side and compete against each other, fueling the incentive to be as innovative as possible.

The early Mannerists in Florence—especially the students of Andrea del Sarto such as Jacopo da Pontormo and Rosso Fiorentino who are notable for elongated forms, precariously balanced poses, a collapsed perspective, irrational settings, and theatrical lighting. Parmigianino (a student of Correggio) and Giulio Romano (Raphael’s head assistant) were moving in similarly stylized aesthetic directions in Rome. These artists had matured under the influence of the High Renaissance, and their style has been characterized as a reaction to or exaggerated extension of it. Instead of studying nature directly, younger artists began studying Hellenistic sculpture and paintings of masters past. Therefore, this style is often identified as "anti-classical”, yet at the time it was considered a natural progression from the High Renaissance. The earliest experimental phase of Mannerism, known for its "anti-classical" forms, lasted until about 1540 or 1550. Marcia B. Hall, professor of art history at Temple University, notes in her book "After Raphael" that Raphael's premature death marked the beginning of Mannerism in Rome.

In past analyses, it has been noted that mannerism arose in the early 16th century contemporaneously with a number of other social, scientific, religious and political movements such as the Copernican model, the Sack of Rome, and the Protestant Reformation's increasing challenge to the power of the Catholic Church. Because of this, the style's elongated forms and distorted forms were once interpreted as a reaction to the idealized compositions prevalent in High Renaissance art. This explanation for the radical stylistic shift c. 1520 has fallen out of scholarly favor, though early Mannerist art is still sharply contrasted with High Renaissance conventions; the accessibility and balance achieved by Raphael's "School of Athens" no longer seemed to interest young artists.

The second period of Mannerism is commonly differentiated from the earlier, so-called "anti-classical" phase.
Subsequent mannerists stressed intellectual conceits and artistic virtuosity, features that have led later critics to accuse them of working in an unnatural and affected "manner" ("maniera"). Maniera artists looked to their older contemporary Michelangelo as their principal model; theirs was an art imitating art, rather than an art imitating nature. Art historian Sydney Joseph Freedberg argues that the intellectualizing aspect of maniera art involves expecting its audience to notice and appreciate this visual reference—a familiar figure in an unfamiliar setting enclosed between "unseen, but felt, quotation marks". The height of artifice is the Maniera painter's penchant for deliberately misappropriating a quotation. Agnolo Bronzino and Giorgio Vasari exemplify this strain of Maniera that lasted from about 1530 to 1580. Based largely at courts and in intellectual circles around Europe, Maniera art couples exaggerated elegance with exquisite attention to surface and detail: porcelain-skinned figures recline in an even, tempered light, acknowledging the viewer with a cool glance, if they make eye contact at all. The Maniera subject rarely displays much emotion, and for this reason works exemplifying this trend are often called 'cold' or 'aloof.' This is typical of the so-called "stylish style" or "Maniera" in its maturity.

The cities Rome, Florence, and Mantua were Mannerist centers in Italy. Venetian painting pursued a different course, represented by Titian in his long career. A number of the earliest Mannerist artists who had been working in Rome during the 1520s fled the city after the Sack of Rome in 1527. As they spread out across the continent in search of employment, their style was disseminated throughout Italy and Northern Europe. The result was the first international artistic style since the Gothic. Other parts of Northern Europe did not have the advantage of such direct contact with Italian artists, but the Mannerist style made its presence felt through prints and illustrated books. European rulers, among others, purchased Italian works, while northern European artists continued to travel to Italy, helping to spread the Mannerist style. Individual Italian artists working in the North gave birth to a movement known as the Northern Mannerism. Francis I of France, for example, was presented with Bronzino's "Venus, Cupid, Folly and Time". The style waned in Italy after 1580, as a new generation of artists, including the Carracci brothers, Caravaggio and Cigoli, revived naturalism. Walter Friedlaender identified this period as "anti-mannerism", just as the early mannerists were "anti-classical" in their reaction away from the aesthetic values of the High Renaissance.

Outside of Italy, however, Mannerism continued into the 17th century. In France, where Rosso traveled to work for the court at Fontainebleau, it is known as the "Henry II style" and had a particular impact on architecture. Other important continental centers of Northern Mannerism include the court of Rudolf II in Prague, as well as Haarlem and Antwerp. Mannerism as a stylistic category is less frequently applied to English visual and decorative arts, where native labels such as "Elizabethan" and "Jacobean" are more commonly applied. Seventeenth-century Artisan Mannerism is one exception, applied to architecture that relies on pattern books rather than on existing precedents in Continental Europe.

Of particular note is the Flemish influence at Fontainebleau that combined the eroticism of the French style with an early version of the vanitas tradition that would dominate seventeenth-century Dutch and Flemish painting. Prevalent at this time was the "pittore vago," a description of painters from the north who entered the workshops in France and Italy to create a truly international style.

As in painting, early Italian Mannerist sculpture was very largely an attempt to find an original style that would top the achievement of the High Renaissance, which in sculpture essentially meant Michelangelo, and much of the struggle to achieve this was played out in commissions to fill other places in the Piazza della Signoria in Florence, next to Michelangelo's "David". Baccio Bandinelli took over the project of "Hercules and Cacus" from the master himself, but it was little more popular then than it is now, and maliciously compared by Benvenuto Cellini to "a sack of melons", though it had a long-lasting effect in apparently introducing relief panels on the pedestal of statues. Like other works of his and other Mannerists it removes far more of the original block than Michelangelo would have done. Cellini's bronze "Perseus with the head of Medusa" is certainly a masterpiece, designed with eight angles of view, another Mannerist characteristic, and artificially stylized in comparison with the "David"s of Michelangelo and Donatello. Originally a goldsmith, his famous gold and enamel Salt Cellar (1543) was his first sculpture, and shows his talent at its best.

Small bronze figures for collector's cabinets, often mythological subjects with nudes, were a popular Renaissance form at which Giambologna, originally Flemish but based in Florence, excelled in the later part of the century. He also created life-size sculptures, of which two entered the collection in the Piazza della Signoria. He and his followers devised elegant elongated examples of the "figura serpentinata", often of two intertwined figures, that were interesting from all angles.

Giorgio Vasari's opinions about the art of painting emerge in the praise he bestows on fellow artists in his multi-volume "Lives of the Artists": he believed that excellence in painting demanded refinement, richness of invention ("invenzione"), expressed through virtuoso technique ("maniera"), and wit and study that appeared in the finished work, all criteria that emphasized the artist's intellect and the patron's sensibility. The artist was now no longer just a trained member of a local Guild of St Luke. Now he took his place at court alongside scholars, poets, and humanists, in a climate that fostered an appreciation for elegance and complexity. The coat-of-arms of Vasari's Medici patrons appears at the top of his portrait, quite as if it were the artist's own. The framing of the woodcut image of Vasari's "Lives of the Artists" would be called "Jacobean" in an English-speaking milieu. In it, Michelangelo's Medici tombs inspire the anti-architectural "architectural" features at the top, the papery pierced frame, the satyr nudes at the base. As a mere frame it is extravagant: Mannerist, in short.

Another literary figure from the period is Gian Paolo Lomazzo, who produced two works—one practical and one metaphysical—that helped define the Mannerist artist's self-conscious relation to his art. His "Trattato dell'arte della pittura, scoltura et architettura" (Milan, 1584) is in part a guide to contemporary concepts of decorum, which the Renaissance inherited in part from Antiquity but Mannerism elaborated upon. Lomazzo's systematic codification of aesthetics, which typifies the more formalized and academic approaches typical of the later 16th century, emphasized a consonance between the functions of interiors and the kinds of painted and sculpted decors that would be suitable. Iconography, often convoluted and abstruse, is a more prominent element in the Mannerist styles. His less practical and more metaphysical "Idea del tempio della pittura" ("The ideal temple of painting", Milan, 1590) offers a description along the lines of the "four temperaments" theory of human nature and personality, defining the role of individuality in judgment and artistic invention.

Jacopo da Pontormo's "Joseph in Egypt" features what would in the Renaissance have been considered incongruous colors and an incoherent handling of time and space.

Rosso Fiorentino, who had been a fellow pupil of Pontormo in the studio of Andrea del Sarto, in 1530 brought Florentine mannerism to Fontainebleau, where he became one of the founders of French 16th-century Mannerism, popularly known as the "School of Fontainebleau".

The examples of a rich and hectic decorative style at Fontainebleau further disseminated the Italian style through the medium of engravings, to Antwerp and from there throughout Northern Europe from London to Poland. Mannerist design was extended to luxury goods like silver and carved furniture. A sense of tense, controlled emotion expressed in elaborate symbolism and allegory, and an ideal of female beauty characterized by elongated proportions are features of this style.

Mannerist portraits by Agnolo Bronzino are distinguished by a serene elegance and meticulous attention to detail. As a result, Bronzino's sitters have been said to project an aloofness and marked emotional distance from the viewer. There is also a virtuosic concentration on capturing the precise pattern and sheen of rich textiles.

Alessandro Allori's (1535–1607) "Susanna and the Elders" ("below") is distinguished by latent eroticism and consciously brilliant still life detail, in a crowded, contorted composition.

Tintoretto's "Last Supper" (below) focuses on light and motion, bringing the image to dramatic life. Unlike more traditional views of the Last Supper, Tintoretto depicts Heaven opening up into the room, and the angels looking on in awe, in line with the old Catholic maxim that "If the angels were capable of envy, they would envy the Eucharist."

El Greco attempted to express religious emotion with exaggerated traits. After the realistic depiction of the human form and the mastery of perspective achieved in high Renaissance Classicism, some artists started to deliberately distort proportions in disjointed, irrational space for emotional and artistic effect. El Greco still is a deeply original artist. El Greco has been characterized by modern scholars as an artist so individual that he belongs to no conventional school. Key aspects of Mannerism in El Greco include the jarring "acid" palette, elongated and tortured anatomy, irrational perspective and light, and obscure and troubling iconography.

Benvenuto Cellini created the Cellini Salt Cellar of gold and enamel in 1540 featuring Poseidon and Amphitrite (water and earth) placed in uncomfortable positions and with elongated proportions. It is considered a masterpiece of Mannerist sculpture.

Joachim Wtewael (1566–1638) continued to paint in a Northern Mannerist style until the end of his life, ignoring the arrival of the Baroque, and making him perhaps the last significant Mannerist artist still to be working. His subjects included large scenes with still life in the manner of Pieter Aertsen, and mythological scenes, many small cabinet paintings beautifully executed on copper, and most featuring nudity.

Giuseppe Arcimboldo (also spelled "Arcimboldi") is known for his portraits contrived from a still life composition

Mannerist architecture was characterized by visual trickery and unexpected elements that challenged the renaissance norms. Flemish artists, many of whom had traveled to Italy and were influenced by Mannerist developments there, were responsible for the spread of Mannerist trends into Europe north of the Alps, including into the realm of architecture. During the period, architects experimented with using architectural forms to emphasize solid and spatial relationships. The Renaissance ideal of harmony gave way to freer and more imaginative rhythms. The best known architect associated with the Mannerist style, and a pioneer at the Laurentian Library, was Michelangelo (1475–1564). He is credited with inventing the giant order, a large pilaster that stretches from the bottom to the top of a façade. He used this in his design for the Campidoglio in Rome.

Prior to the 20th century, the term "Mannerism" had negative connotations, but it is now used to describe the historical period in more general non-judgmental terms. Mannerist architecture has also been used to describe a trend in the 1960s and 1970s that involved breaking the norms of modernist architecture while at the same time recognizing their existence. Defining mannerist in this context, architect and author Robert Venturi wrote "Mannerism for architecture of our time that acknowledges conventional order rather than original expression but breaks the conventional order to accommodate complexity and contradiction and thereby engages ambiguity unambiguously." 

An example of mannerist architecture is the Villa Farnese at Caprarola. in the rugged country side outside of Rome. The proliferation of engravers during the 16th century spread Mannerist styles more quickly than any previous styles.

Dense with ornament of "Roman" detailing, the display doorway at Colditz Castle exemplifies this northern style, characteristically applied as an isolated "set piece" against unpretentious vernacular walling.

From the late 1560s onwards, many buildings in Valletta, the new capital city of Malta, were designed by the architect Girolamo Cassar in the Mannerist style. Such buildings include St. John's Co-Cathedral, the Grandmaster's Palace and the seven original auberges. Many of Cassar's buildings were modified over the years, especially in the Baroque period. However, a few buildings, such as Auberge d'Aragon and the exterior of St. John's Co-Cathedral, still retain most of Cassar's original Mannerist design.

In English literature, Mannerism is commonly identified with the qualities of the "Metaphysical" poets of whom the most famous is John Donne. The witty sally of a Baroque writer, John Dryden, against the verse of Donne in the previous generation, affords a concise contrast between Baroque and Mannerist aims in the arts:

The rich musical possibilities in the poetry of the late 16th and early 17th centuries provided an attractive basis for the madrigal, which quickly rose to prominence as the pre-eminent musical form in Italian musical culture, as discussed by Tim Carter:

The word Mannerism has also been used to describe the style of highly florid and contrapuntally complex polyphonic music made in France in the late 14th century. This period is now usually referred to as the "ars subtilior".

"The Early Commedia dell'Arte (1550–1621): The Mannerist Context" by Paul Castagno discusses Mannerism's effect on the contemporary professional theatre. Castagno's was the first study to define a theatrical form as Mannerist, employing the vocabulary of Mannerism and maniera to discuss the typification, exaggerated, and effetto meraviglioso of the comici dell'arte. See Part II of the above book for a full discussion of Mannerist characteristics in the commedia dell'arte. The study is largely iconographic, presenting a pictorial evidence that many of the artists who painted or printed commedia images were in fact, coming from the workshops of the day, heavily ensconced in the maniera tradition.

The preciosity in Jacques Callot's minute engravings seem to belie a much larger scale of action. Callot's "Balli di Sfessania" (literally, dance of the buttocks) celebrates the commedia's blatant eroticism, with protruding phalli, spears posed with the anticipation of a comic ream, and grossly exaggerated masks that mix the bestial with human. The eroticism of the innamorate (lovers) including the baring of breasts, or excessive veiling, was quite in vogue in the paintings and engravings from the second school at Fontainebleau, particularly those that detect a Franco-Flemish influence. Castagno demonstrates iconographic linkages between genre painting and the figures of the commedia dell'arte that demonstrate how this theatrical form was embedded within the cultural traditions of the late cinquecento.

Important corollaries exist between the "disegno interno", which substituted for the "disegno esterno" (external design) in mannerist painting. This notion of projecting a deeply subjective view as superseding nature or established principles (perspective, for example), in essence, the emphasis away from the object to its subject, now emphasizing execution, displays of virtuosity, or unique techniques. This inner vision is at the heart of commedia performance. For example, in the moment of improvisation the actor expresses his virtuosity without heed to formal boundaries, decorum, unity, or text. Arlecchino became emblematic of the mannerist "discordia concors" (the union of opposites), at one moment he would be gentle and kind, then, on a dime, become a thief violently acting out with his batte. Arlecchino could be graceful in movement, only in the next beat, to clumsily trip over his feet. Freed from the external rules, the actor celebrated the evanescence of the moment; much the way Cellini would dazzle his patrons by draping his sculptures, unveiling them with lighting effects and a sense of the marvelous. The presentation of the object became as important as the object itself.

According to art critic Jerry Saltz, "Neo-Mannerism" (new Mannerism) is among several clichés that are "squeezing the life out of the art world". Neo-Mannerism describes art of the 21st century that is turned out by students whose academic teachers "have scared [them] into being pleasingly meek, imitative, and ordinary".




</doc>
<doc id="19948" url="https://en.wikipedia.org/wiki?curid=19948" title="Monica Lewinsky">
Monica Lewinsky

Monica Samille Lewinsky (born July 23, 1973) is an American activist, television personality, fashion designer, and former White House intern.

President Bill Clinton admitted to having had what he called an "inappropriate relationship" with Lewinsky while she worked at the White House in 1995–1996. The affair and its repercussions (which included Clinton's impeachment) became known later as the Clinton–Lewinsky scandal.

As a result of the public coverage of the political scandal, Lewinsky gained international celebrity status; she subsequently engaged in a variety of ventures that included designing a line of handbags under her name, being an advertising spokesperson for a diet plan, and working as a television personality.

Lewinsky then decided to leave the public spotlight to pursue a master's degree in psychology in London. In 2014, she returned to public view as a social activist speaking out against cyberbullying, from which she personally suffered when publicly ridiculed on the Internet regarding the scandal.

Lewinsky was born in San Francisco, California, and grew up in an affluent family in Southern California in the Westside Brentwood area of Los Angeles and in Beverly Hills. Her father is Bernard Lewinsky, an oncologist, who is the son of German Jews who escaped from Nazi Germany and moved to El Salvador and then to the United States when he was 14. Her mother, born Marcia Kay Vilensky, is an author who uses the name Marcia Lewis. In 1996, she wrote her only book, the gossip biography, "The Private Lives of the Three Tenors". During the Lewinsky scandal, the press compared Lewis' unproven "hints" that she had an affair with opera star Plácido Domingo to her daughter's sexual relationship with Clinton. Monica's maternal grandfather, Samuel M. Vilensky, was a Lithuanian Jew, and Monica's maternal grandmother, Bronia Poleshuk, was born in the British Concession of Tianjin, China, to a Russian Jewish family. Monica's parents' acrimonious separation and divorce during 1987 and 1988 had a significant effect on her. Her father later married his current wife, Barbara; her mother later married R. Peter Straus, a media executive and former director of the Voice of America under President Jimmy Carter.

The family attended Sinai Temple in Los Angeles and Monica attended Sinai Akiba Academy, its religious school. For her primary education she attended the John Thomas Dye School in Bel-Air. She then attended Beverly Hills High School, but for her senior year transferred to, and graduated from, Bel Air Prep (later known as Pacific Hills School) in 1991.

Following high school graduation, Lewinsky attended Santa Monica College, a two-year community college, and worked for the drama department at Beverly Hills High School and at a tie shop. In 1992, she allegedly began a five-year affair with Andy Bleiler, her married former high school drama instructor. In 1993, she enrolled at Lewis & Clark College in Portland, Oregon, graduating with a bachelor's degree in psychology in 1995.

With the assistance of a family connection, Lewinsky got an unpaid summer White House internship in the office of White House Chief of Staff Leon Panetta. Lewinsky moved to Washington, D.C. and took up the position in July 1995. She moved to a paid position in the White House Office of Legislative Affairs in December 1995.

Lewinsky stated that between November 1995 and March 1997, she had nine sexual encounters in the Oval Office with then-President Bill Clinton. According to her testimony, these involved fellatio and other sexual acts, but not sexual intercourse.

Clinton had previously been confronted with allegations of sexual misconduct during his time as Governor of Arkansas. Former Arkansas state employee Paula Jones filed a civil lawsuit against him; she alleged that he had sexually harassed her. Lewinsky's name surfaced during the discovery phase of Jones' case, when Jones' lawyers sought to show a pattern of behavior by Clinton that involved inappropriate sexual relationships with other government employees.

In April 1996, Lewinsky's superiors transferred her from the White House to the Pentagon because they felt she was spending too much time around Clinton. At the Pentagon, she worked as an assistant to chief Pentagon spokesperson Kenneth Bacon. Lewinsky told co-worker Linda Tripp about her relationship with the President. Beginning in September 1997, Tripp began secretly recording their telephone conversations regarding the affair with Clinton. In December 1997, Lewinsky left the Pentagon position. In January 1998, after Lewinsky had submitted an affidavit in the Paula Jones case denying any physical relationship with Clinton, and had attempted to persuade Tripp to lie under oath in that case, Tripp gave the tapes to Independent Counsel Kenneth Starr, adding to his ongoing investigation into the Whitewater controversy. Starr then broadened his investigation beyond the Arkansas land use deal to include Lewinsky, Clinton, and others for possible perjury and subornation of perjury in the Jones case. Tripp reported the taped conversations to literary agent Lucianne Goldberg. She also convinced Lewinsky to save the gifts that Clinton had given her during their relationship, and not to dry clean what would later become known as "the blue dress". Under oath, Clinton denied having had "a sexual affair", "sexual relations", or "a sexual relationship" with Lewinsky.

News of the Clinton–Lewinsky relationship broke in January 1998. On January 26, 1998, Clinton stated, "I did not have sexual relations with that woman, Miss Lewinsky" in a nationally televised White House news conference. The matter instantly occupied the news media, and Lewinsky spent the next weeks hiding from public attention in her mother's residence at the Watergate complex. News of Lewinsky's affair with Bleiler also came to light, and he turned over to Starr various souvenirs, photographs, and documents that Lewinsky had sent him and his wife during the time she was in the White House.

Clinton had also said, "there is not a sexual relationship, an improper sexual relationship or any other kind of improper relationship" which he defended as truthful on August 17, 1998 because of his use of the present tense, famously arguing "it depends on what the meaning of the word 'is' is" (i.e., he was not, at the time he made that statement, still in a sexual relationship with Lewinsky). Under pressure from Starr, who had obtained from Lewinsky a blue dress with Clinton's semen stain, as well as testimony from Lewinsky that the President had inserted a cigar tube into her vagina, Clinton stated, "I did have a relationship with Miss Lewinsky that was not appropriate." Clinton denied having committed perjury because, according to Clinton, the legal definition of oral sex was not encompassed by "sex" "per se". In addition, relying upon the definition of "sexual relations" as proposed by the prosecution and agreed by the defense and by Judge Susan Webber Wright, who was hearing the Paula Jones case, Clinton claimed that because certain acts were performed on him, not by him, he did not engage in sexual relations. Lewinsky's testimony to the Starr Commission, however, contradicted Clinton's claim of being totally passive in their encounters.

Clinton and Lewinsky were both called before a grand jury; Clinton testified via closed-circuit television, Lewinsky in person. She was granted transactional immunity by the United States Office of the Independent Counsel, in exchange for her testimony.

The affair led to pop culture celebrity for Lewinsky, as she had become the focus of a political storm. Her immunity agreement restricted what she could talk about publicly, but she was able to cooperate with Andrew Morton in his writing of "Monica's Story", her biography which included her side of the Clinton affair. The book was published in March 1999; it was also excerpted as a cover story in "TIME" magazine. On March 3, 1999, Barbara Walters interviewed Lewinsky on ABC's "20/20". The program was watched by 70 million Americans, which ABC said was a record for a news show. Lewinsky made about $500,000 from her participation in the book and another $1 million from international rights to the Walters interview, but was still beset by high legal bills and living costs.

In June 1999, "Ms. Magazine" published a series of articles by writer Susan Jane Gilman, sexologist Susie Bright, and author-host Abiola Abrams arguing from three generations of women whether Lewinsky's behavior had any meaning for feminism. Also in 1999, Lewinsky declined to sign an autograph in an airport, saying, "I'm kind of known for something that's not so great to be known for." She made a cameo appearance as herself in two sketches during the May 8, 1999, episode of NBC's "Saturday Night Live", a program that had lampooned her relationship with Clinton over the prior 16 months.

By her own account, Lewinsky had survived the intense media attention during the scandal period by knitting. In September 1999, she took this interest further by beginning to sell a line of handbags bearing her name, under the company name The Real Monica, Inc. They were sold online as well as at Henri Bendel in New York, Fred Segal in California, and The Cross in London. Lewinsky designed the bags—described by "New York" magazine as "hippie-ish, reversible totes"—and traveled frequently to supervise their manufacture in Louisiana.

At the start of 2000, Lewinsky began appearing in television commercials for the diet company Jenny Craig, Inc. The $1 million endorsement deal, which required Lewinsky to lose 40 or more pounds in six months, gained considerable publicity at the time. Lewinsky said that despite her desire to return to a more private life, she needed the money to pay off legal fees, and she believed in the product. A Jenny Craig spokesperson said of Lewinsky, "She represents a busy active woman of today with a hectic lifestyle. And she has had weight issues and weight struggles for a long time. That represents a lot of women in America." The choice of Lewinsky as a role model proved controversial for Jenny Craig, and some of its private franchises switched to an older advertising campaign. The company stopped running the Lewinsky ads in February 2000, concluded her campaign entirely in April 2000, and paid her only $300,000 of the $1 million contracted for her involvement.

Also at the start of 2000, Lewinsky moved to New York City, lived in the West Village, and became an A-list guest in the Manhattan social scene. In February 2000, she appeared on MTV's "The Tom Green Show", in an episode in which the host took her to his parents' home in Ottawa in search of fabric for her new handbag business. Later in 2000, Lewinsky worked as a correspondent for Channel 5 in the UK, on the show "Monica's Postcards", reporting on U.S. culture and trends from a variety of locations.

In March 2002, Lewinsky, no longer bound by the terms of her immunity agreement, appeared in the HBO special, "Monica in Black and White", part of the "America Undercover" series. In it she answered a studio audience's questions about her life and the Clinton affair.

Lewinsky hosted the reality television dating program, "Mr. Personality", on Fox Television Network in 2003, where she advised young women contestants who were picking men hidden by masks. Some Americans tried to organize a boycott of advertisers on the show, to protest Lewinsky's capitalizing on her notoriety. Nevertheless, the show debuted to very high ratings, and Alessandra Stanley wrote in "The New York Times": "after years of trying to cash in on her fame by designing handbags and other self-marketing schemes, Ms. Lewinsky has finally found a fitting niche on television." The ratings, however, slid downward each successive week, and after the show completed its initial limited run, it did not reappear. The same year she appeared as a guest on the programs "V Graham Norton" in the UK, "High Chaparall" in Sweden, and "The View" and "Jimmy Kimmel Live!" in the U.S.

After Clinton's autobiography, "My Life", appeared in 2004, Lewinsky said in an interview with the British tabloid "Daily Mail":
By 2005, Lewinsky found that she could not escape the spotlight in the U.S., which made both her professional and personal life difficult. She stopped selling her handbag line and moved to London to study social psychology at the London School of Economics. In December 2006, Lewinsky graduated with a Master of Science degree. Her thesis was titled, "In Search of the Impartial Juror: An Exploration of the Third-Person Effect and Pre-Trial Publicity." For the next decade she tried to avoid publicity.

Lewinsky did correspond in 2009 with scholar Ken Gormley, who was writing an in-depth study of the Clinton scandals, maintaining that Clinton had lied under oath when asked detailed and specific questions about his relationship with her. In 2013, the items associated with Lewinsky that Bleiler had turned over to Starr were put up for auction by Bleiler's ex-wife, who had come into possession of them.

During her decade out of the public eye, Lewinsky lived in London, Los Angeles, New York, and Portland but, due to her notoriety, had trouble finding employment in the communications and marketing jobs for nonprofit organizations where she had been interviewed.

In May 2014, Lewinsky wrote an essay for "Vanity Fair" magazine titled "Shame and Survival", wherein she discussed her life and the scandal. She continued to maintain that the relationship was mutual and wrote that while Clinton took advantage of her, it was a consensual relationship. She added: "I, myself, deeply regret what happened between me and President Clinton. Let me say it again: I. Myself. Deeply. Regret. What. Happened." However, she said it was now time to "stick my head above the parapet so that I can take back my narrative and give a purpose to my past." The magazine later announced her as a "Vanity Fair" contributor, stating she would "contribute to their website on an ongoing basis, on the lookout for relevant topics of interest".
In July 2014, Lewinsky was interviewed in a three-part television special for the National Geographic Channel, titled "The 90s: The Last Great Decade". The series looked at various events of the 1990s, including the scandal that brought Lewinsky into the national spotlight. This was Lewinsky's first such interview in more than ten years.

In October 2014, she took a public stand against cyberbullying, calling herself "patient zero" of online harassment. Speaking at a "Forbes" magazine "30 Under 30" summit about her experiences in the aftermath of the scandal, she said, "Having survived myself, what I want to do now is help other victims of the shame game survive, too." She said she was influenced by reading about the suicide of Tyler Clementi, a Rutgers University freshman, involving cyberbullying and joined Twitter to facilitate her efforts. In March 2015, Lewinsky continued to speak out publicly against cyberbullying, delivering a TED talk calling for a more compassionate Internet. In June 2015, she became an ambassador and strategic advisor for anti-bullying organization Bystander Revolution. The same month, she gave an anti-cyberbullying speech at the Cannes Lions International Festival of Creativity. In September 2015, Lewinsky was interviewed by Amy Robach on "Good Morning America", about Bystander Revolution's Month of Action campaign for National Bullying Prevention Month. Lewinsky wrote the foreword to an October 2017 book by Sue Scheff and Melissa Schorr, "Shame Nation: The Global Epidemic of Online Hate".

In October 2017, Lewinsky tweeted the #MeToo hashtag to indicate that she was a victim of sexual harassment and/or sexual assault, but did not provide details. She wrote an essay in the March 2018 issue of "Vanity Fair" in which she did not directly explain why she used the #MeToo hashtag in October, but she did write that although her relationship with Bill Clinton was consensual, because he was 27 years older than she was and in a position with a lot more power than she had, in her opinion now the relationship constituted an "abuse of power" on Clinton's part. She added that she had been diagnosed with post-traumatic stress disorder due to the experiences involved after the relationship was disclosed. In May 2018, Lewinsky was uninvited from an event hosted by "Town & Country" when Bill Clinton accepted an invitation to the event.




</doc>
<doc id="19951" url="https://en.wikipedia.org/wiki?curid=19951" title="Pressure measurement">
Pressure measurement

Pressure measurement is the analysis of an applied force by a fluid (liquid or gas) on a surface. Pressure is typically measured in units of force per unit of surface area. Many techniques have been developed for the measurement of pressure and vacuum. Instruments used to measure and display pressure in an integral unit are called pressure gauges or vacuum gauges. A manometer is a good example, as it uses a column of liquid to both measure and indicate pressure. Likewise the widely used Bourdon gauge is a mechanical device, which both measures and indicates and is probably the best known type of gauge.

A vacuum gauge is a pressure gauge used to measure pressures lower than the ambient atmospheric pressure, which is set as the zero point, in negative values (e.g.: −15 psig or −760 mmHg equals total vacuum). Most gauges measure pressure relative to atmospheric pressure as the zero point, so this form of reading is simply referred to as "gauge pressure". However, anything greater than total vacuum is technically a form of pressure. For very accurate readings, especially at very low pressures, a gauge that uses total vacuum as the zero point may be used, giving pressure readings in an absolute scale.

Other methods of pressure measurement involve sensors that can transmit the pressure reading to a remote indicator or control system (telemetry).

Everyday pressure measurements, such as for vehicle tire pressure, are usually made relative to ambient air pressure. In other cases measurements are made relative to a vacuum or to some other specific reference. When distinguishing between these zero references, the following terms are used:

The zero reference in use is usually implied by context, and these words are added only when clarification is needed. Tire pressure and blood pressure are gauge pressures by convention, while atmospheric pressures, deep vacuum pressures, and altimeter pressures must be absolute.

For most working fluids where a fluid exists in a closed system, gauge pressure measurement prevails. Pressure instruments connected to the system will indicate pressures relative to the current atmospheric pressure. The situation changes when extreme vacuum pressures are measured, then absolute pressures are typically used instead.

Differential pressures are commonly used in industrial process systems. Differential pressure gauges have two inlet ports, each connected to one of the volumes whose pressure is to be monitored. In effect, such a gauge performs the mathematical operation of subtraction through mechanical means, obviating the need for an operator or control system to watch two separate gauges and determine the difference in readings.

Moderate vacuum pressure readings can be ambiguous without the proper context, as they may represent absolute pressure or gauge pressure without a negative sign. Thus a vacuum of 26 inHg gauge is equivalent to an absolute pressure of 30 inHg (typical atmospheric pressure) − 26 inHg = 4 inHg.

Atmospheric pressure is typically about 100 kPa at sea level, but is variable with altitude and weather. If the absolute pressure of a fluid stays constant, the gauge pressure of the same fluid will vary as atmospheric pressure changes. For example, when a car drives up a mountain, the (gauge) tire pressure goes up because atmospheric pressure goes down. The absolute pressure in the tire is essentially unchanged.

Using atmospheric pressure as reference is usually signified by a "g" for gauge after the pressure unit, e.g. 70 psig, which means that the pressure measured is the total pressure minus atmospheric pressure. There are two types of gauge reference pressure: vented gauge (vg) and sealed gauge (sg).

A vented-gauge pressure transmitter, for example, allows the outside air pressure to be exposed to the negative side of the pressure-sensing diaphragm, through a vented cable or a hole on the side of the device, so that it always measures the pressure referred to ambient barometric pressure. Thus a vented-gauge reference pressure sensor should always read zero pressure when the process pressure connection is held open to the air.

A sealed gauge reference is very similar, except that atmospheric pressure is sealed on the negative side of the diaphragm. This is usually adopted on high pressure ranges, such as hydraulics, where atmospheric pressure changes will have a negligible effect on the accuracy of the reading, so venting is not necessary. This also allows some manufacturers to provide secondary pressure containment as an extra precaution for pressure equipment safety if the burst pressure of the primary pressure sensing diaphragm is exceeded.

There is another way of creating a sealed gauge reference, and this is to seal a high vacuum on the reverse side of the sensing diaphragm. Then the output signal is offset, so the pressure sensor reads close to zero when measuring atmospheric pressure.

A sealed gauge reference pressure transducer will never read exactly zero because atmospheric pressure is always changing and the reference in this case is fixed at 1 bar.

To produce an absolute pressure sensor, the manufacturer seals a high vacuum behind the sensing diaphragm. If the process-pressure connection of an absolute-pressure transmitter is open to the air, it will read the actual barometric pressure.

The SI unit for pressure is the pascal (Pa), equal to one newton per square metre (N·m or kg·m·s). This special name for the unit was added in 1971; before that, pressure in SI was expressed in units such as N·m. When indicated, the zero reference is stated in parenthesis following the unit, for example 101 kPa (abs). The pound per square inch (psi) is still in widespread use in the US and Canada, for measuring, for instance, tire pressure. A letter is often appended to the psi unit to indicate the measurement's zero reference; psia for absolute, psig for gauge, psid for differential, although this practice is discouraged by the NIST.

Because pressure was once commonly measured by its ability to displace a column of liquid in a manometer, pressures are often expressed as a depth of a particular fluid ("e.g.," inches of water). Manometric measurement is the subject of pressure head calculations. The most common choices for a manometer's fluid are mercury (Hg) and water; water is nontoxic and readily available, while mercury's density allows for a shorter column (and so a smaller manometer) to measure a given pressure. The abbreviation "W.C." or the words "water column" are often printed on gauges and measurements that use water for the manometer.

Fluid density and local gravity can vary from one reading to another depending on local factors, so the height of a fluid column does not define pressure precisely. So measurements in "millimetres of mercury" or "inches of mercury" can be converted to SI units as long as attention is paid to the local factors of fluid density and gravity. Temperature fluctuations change the value of fluid density, while location can affect gravity.

Although no longer preferred, these manometric units are still encountered in many fields. Blood pressure is measured in millimetres of mercury (see torr) in most of the world, and lung pressures in centimeters of water are still common, as in settings for CPAP machines. Natural gas pipeline pressures are measured in inches of water, expressed as "inches W.C." Scuba divers often use a manometric rule of thumb: the pressure exerted by ten meters depth of sea water ("10 msw") is approximately equal to one atmosphere. In vacuum systems, the units torr (millimeter of mercury), micron (micrometer of mercury), and inch of mercury (inHg) are most commonly used. Torr and micron usually indicates an absolute pressure, while inHg usually indicates a gauge pressure.

Atmospheric pressures are usually stated using hectopascal (hPa), kilopascal (kPa), millibar (mbar) or atmospheres (atm). In American and Canadian engineering, stress is often measured in kip. Note that stress is not a true pressure since it is not scalar. In the cgs system the unit of pressure was the barye (ba), equal to 1 dyn·cm. In the mts system, the unit of pressure was the pieze, equal to 1 sthene per square metre.

Many other hybrid units are used such as mmHg/cm or grams-force/cm (sometimes as kg/cm without properly identifying the force units). Using the names kilogram, gram, kilogram-force, or gram-force (or their symbols) as a unit of force is prohibited in SI; the unit of force in SI is the newton (N).

Static pressure is uniform in all directions, so pressure measurements are independent of direction in an immovable (static) fluid. Flow, however, applies additional pressure on surfaces perpendicular to the flow direction, while having little impact on surfaces parallel to the flow direction. This directional component of pressure in a moving (dynamic) fluid is called dynamic pressure. An instrument facing the flow direction measures the sum of the static and dynamic pressures; this measurement is called the total pressure or stagnation pressure. Since dynamic pressure is referenced to static pressure, it is neither gauge nor absolute; it is a differential pressure.

While static gauge pressure is of primary importance to determining net loads on pipe walls, dynamic pressure is used to measure flow rates and airspeed. Dynamic pressure can be measured by taking the differential pressure between instruments parallel and perpendicular to the flow. Pitot-static tubes, for example perform this measurement on airplanes to determine airspeed. The presence of the measuring instrument inevitably acts to divert flow and create turbulence, so its shape is critical to accuracy and the calibration curves are often non-linear.


Many instruments have been invented to measure pressure, with different advantages and disadvantages. Pressure range, sensitivity, dynamic response and cost all vary by several orders of magnitude from one instrument design to the next. The oldest type is the liquid column (a vertical tube filled with mercury) manometer invented by Evangelista Torricelli in 1643. The U-Tube was invented by Christiaan Huygens in 1661.

Hydrostatic gauges (such as the mercury column manometer) compare pressure to the hydrostatic force per unit area at the base of a column of fluid. Hydrostatic gauge measurements are independent of the type of gas being measured, and can be designed to have a very linear calibration. They have poor dynamic response.

Piston-type gauges counterbalance the pressure of a fluid with a spring (for example tire-pressure gauges of comparatively low accuracy) or a solid weight, in which case it is known as a deadweight tester and may be used for calibration of other gauges.

Liquid-column gauges consist of a column of liquid in a tube whose ends are exposed to different pressures. The column will rise or fall until its weight (a force applied due to gravity) is in equilibrium with the pressure differential between the two ends of the tube (a force applied due to fluid pressure). A very simple version is a U-shaped tube half-full of liquid, one side of which is connected to the region of interest while the reference pressure (which might be the atmospheric pressure or a vacuum) is applied to the other. The difference in liquid levels represents the applied pressure. The pressure exerted by a column of fluid of height "h" and density "ρ" is given by the hydrostatic pressure equation, "P" = "hgρ". Therefore, the pressure difference between the applied pressure "P" and the reference pressure "P" in a U-tube manometer can be found by solving . In other words, the pressure on either end of the liquid (shown in blue in the figure) must be balanced (since the liquid is static), and so .

In most liquid-column measurements, the result of the measurement is the height "h", expressed typically in mm, cm, or inches. The "h" is also known as the pressure head. When expressed as a pressure head, pressure is specified in units of length and the measurement fluid must be specified. When accuracy is critical, the temperature of the measurement fluid must likewise be specified, because liquid density is a function of temperature. So, for example, pressure head might be written "742.2 mm" or "4.2 in at 59 °F" for measurements taken with mercury or water as the manometric fluid respectively. The word "gauge" or "vacuum" may be added to such a measurement to distinguish between a pressure above or below the atmospheric pressure. Both mm of mercury and inches of water are common pressure heads, which can be converted to S.I. units of pressure using unit conversion and the above formulas.

If the fluid being measured is significantly dense, hydrostatic corrections may have to be made for the height between the moving surface of the manometer working fluid and the location where the pressure measurement is desired, except when measuring differential pressure of a fluid (for example, across an orifice plate or venturi), in which case the density ρ should be corrected by subtracting the density of the fluid being measured.

Although any fluid can be used, mercury is preferred for its high density (13.534 g/cm) and low vapour pressure. For low pressure differences, light oil or water are commonly used (the latter giving rise to units of measurement such as inches water gauge and millimetres HO. Liquid-column pressure gauges have a highly linear calibration. They have poor dynamic response because the fluid in the column may react slowly to a pressure change.

When measuring vacuum, the working liquid may evaporate and contaminate the vacuum if its vapor pressure is too high. When measuring liquid pressure, a loop filled with gas or a light fluid can isolate the liquids to prevent them from mixing, but this can be unnecessary, for example, when mercury is used as the manometer fluid to measure differential pressure of a fluid such as water. Simple hydrostatic gauges can measure pressures ranging from a few torrs (a few 100 Pa) to a few atmospheres (approximately ).

A single-limb liquid-column manometer has a larger reservoir instead of one side of the U-tube and has a scale beside the narrower column. The column may be inclined to further amplify the liquid movement. Based on the use and structure, following types of manometers are used

A McLeod gauge isolates a sample of gas and compresses it in a modified mercury manometer until the pressure is a few millimetres of mercury. The technique is very slow and unsuited to continual monitoring, but is capable of good accuracy. Unlike other manometer gauges, the McLeod gauge reading is dependent on the composition of the gas, since the interpretation relies on the sample compressing as an ideal gas. Due to the compression process, the McLeod gauge completely ignores partial pressures from non-ideal vapors that condense, such as pump oils, mercury, and even water if compressed enough.

0.1 mPa is the lowest direct measurement of pressure that is possible with current technology. Other vacuum gauges can measure lower pressures, but only indirectly by measurement of other pressure-dependent properties. These indirect measurements must be calibrated to SI units by a direct measurement, most commonly a McLeod gauge.

Aneroid gauges are based on a metallic pressure-sensing element that flexes elastically under the effect of a pressure difference across the element. "Aneroid" means "without fluid", and the term originally distinguished these gauges from the hydrostatic gauges described above. However, aneroid gauges can be used to measure the pressure of a liquid as well as a gas, and they are not the only type of gauge that can operate without fluid. For this reason, they are often called mechanical gauges in modern language. Aneroid gauges are not dependent on the type of gas being measured, unlike thermal and ionization gauges, and are less likely to contaminate the system than hydrostatic gauges. The pressure sensing element may be a Bourdon tube, a diaphragm, a capsule, or a set of bellows, which will change shape in response to the pressure of the region in question. The deflection of the pressure sensing element may be read by a linkage connected to a needle, or it may be read by a secondary transducer. The most common secondary transducers in modern vacuum gauges measure a change in capacitance due to the mechanical deflection. Gauges that rely on a change in capacitance are often referred to as capacitance manometers.

The Bourdon pressure gauge uses the principle that a flattened tube tends to straighten or regain its circular form in cross-section when pressurized. This change in cross-section may be hardly noticeable, involving moderate stresses within the elastic range of easily workable materials. The strain of the material of the tube is magnified by forming the tube into a C shape or even a helix, such that the entire tube tends to straighten out or uncoil elastically as it is pressurized. Eugène Bourdon patented his gauge in France in 1849, and it was widely adopted because of its superior sensitivity, linearity, and accuracy; Edward Ashcroft purchased Bourdon's American patent rights in 1852 and became a major manufacturer of gauges. Also in 1849, Bernard Schaeffer in Magdeburg, Germany patented a successful diaphragm (see below) pressure gauge, which, together with the Bourdon gauge, revolutionized pressure measurement in industry. But in 1875 after Bourdon's patents expired, his company Schaeffer and Budenberg also manufactured Bourdon tube gauges.

In practice, a flattened thin-wall, closed-end tube is connected at the hollow end to a fixed pipe containing the fluid pressure to be measured. As the pressure increases, the closed end moves in an arc, and this motion is converted into the rotation of a (segment of a) gear by a connecting link that is usually adjustable. A small-diameter pinion gear is on the pointer shaft, so the motion is magnified further by the gear ratio. The positioning of the indicator card behind the pointer, the initial pointer shaft position, the linkage length and initial position, all provide means to calibrate the pointer to indicate the desired range of pressure for variations in the behavior of the Bourdon tube itself. Differential pressure can be measured by gauges containing two different Bourdon tubes, with connecting linkages.

Bourdon tubes measure gauge pressure, relative to ambient atmospheric pressure, as opposed to absolute pressure; vacuum is sensed as a reverse motion. Some aneroid barometers use Bourdon tubes closed at both ends (but most use diaphragms or capsules, see below). When the measured pressure is rapidly pulsing, such as when the gauge is near a reciprocating pump, an orifice restriction in the connecting pipe is frequently used to avoid unnecessary wear on the gears and provide an average reading; when the whole gauge is subject to mechanical vibration, the entire case including the pointer and indicator card can be filled with an oil or glycerin. Tapping on the face of the gauge is not recommended as it will tend to falsify actual readings initially presented by the gauge. The Bourdon tube is separate from the face of the gauge and thus has no effect on the actual reading of pressure. Typical high-quality modern gauges provide an accuracy of ±2% of span, and a special high-precision gauge can be as accurate as 0.1% of full scale.

In the following illustrations the transparent cover face of the pictured combination pressure and vacuum gauge has been removed and the mechanism removed from the case. This particular gauge is a combination vacuum and pressure gauge used for automotive diagnosis:

Stationary parts:

Moving Parts:

A second type of aneroid gauge uses deflection of a flexible membrane that separates regions of different pressure. The amount of deflection is repeatable for known pressures so the pressure can be determined by using calibration. The deformation of a thin diaphragm is dependent on the difference in pressure between its two faces. The reference face can be open to atmosphere to measure gauge pressure, open to a second port to measure differential pressure, or can be sealed against a vacuum or other fixed reference pressure to measure absolute pressure. The deformation can be measured using mechanical, optical or capacitive techniques. Ceramic and metallic diaphragms are used.
For absolute measurements, welded pressure capsules with diaphragms on either side are often used.

shape:

In gauges intended to sense small pressures or pressure differences, or require that an absolute pressure be measured, the gear train and needle may be driven by an enclosed and sealed bellows chamber, called an aneroid, which means "without liquid". (Early barometers used a column of liquid such as water or the liquid metal mercury suspended by a vacuum.) This bellows configuration is used in aneroid barometers (barometers with an indicating needle and dial card), altimeters, altitude recording barographs, and the altitude telemetry instruments used in weather balloon radiosondes. These devices use the sealed chamber as a reference pressure and are driven by the external pressure. Other sensitive aircraft instruments such as air speed indicators and rate of climb indicators (variometers) have connections both to the internal part of the aneroid chamber and to an external enclosing chamber.

These gauges use the attraction of two magnets to translate differential pressure into motion of a dial pointer. As differential pressure increases, a magnet attached to either a piston or rubber diaphragm moves. A rotary magnet that is attached to a pointer then moves in unison. To create different pressure ranges, the spring rate can be increased or decreased.

The spinning-rotor gauge works by measuring the amount a rotating ball is slowed by the viscosity of the gas being measured. The ball is made of steel and is magnetically levitated inside a steel tube closed at one end and exposed to the gas to be measured at the other. The ball is brought up to speed (about 2500 rad/s), and the speed measured after switching off the drive, by electromagnetic transducers. The range of the instrument is 10 to 10 Pa (10 Pa with less accuracy). It is accurate and stable enough to be used as a secondary standard. The instrument requires some skill and knowledge to use correctly. Various corrections must be applied and the ball must be spun at a pressure well below the intended measurement pressure for five hours before using. It is most useful in calibration and research laboratories where high accuracy is required and qualified technicians are available.


Generally, as a real gas increases in density -which may indicate an increase in pressure- its ability to conduct heat increases. In this type of gauge, a wire filament is heated by running current through it. A thermocouple or resistance thermometer (RTD) can then be used to measure the temperature of the filament. This temperature is dependent on the rate at which the filament loses heat to the surrounding gas, and therefore on the thermal conductivity. A common variant is the Pirani gauge, which uses a single platinum filament as both the heated element and RTD. These gauges are accurate from 10 Torr to 10 Torr, but their calibration is sensitive to the chemical composition of the gases being measured.

A Pirani gauge consist of a metal wire open to the pressure being measured. The wire is heated by a current flowing through it and cooled by the gas surrounding it. If the gas pressure is reduced, the cooling effect will decrease, hence the equilibrium temperature of the wire will increase. The resistance of the wire is a function of its temperature: by measuring the voltage across the wire and the current flowing through it, the resistance (and so the gas pressure) can be determined. This type of gauge was invented by Marcello Pirani.

In two-wire gauges, one wire coil is used as a heater, and the other is used to measure temperature due to convection. Thermocouple gauges and thermistor gauges work in this manner using thermocouple or thermistor, respectively, to measure the temperature of the heated wire.

Ionization gauges are the most sensitive gauges for very low pressures (also referred to as hard or high vacuum). They sense pressure indirectly by measuring the electrical ions produced when the gas is bombarded with electrons. Fewer ions will be produced by lower density gases. The calibration of an ion gauge is unstable and dependent on the nature of the gases being measured, which is not always known. They can be calibrated against a McLeod gauge which is much more stable and independent of gas chemistry.

Thermionic emission generate electrons, which collide with gas atoms and generate positive ions. The ions are attracted to a suitably biased electrode known as the collector. The current in the collector is proportional to the rate of ionization, which is a function of the pressure in the system. Hence, measuring the collector current gives the gas pressure. There are several sub-types of ionization gauge.

Most ion gauges come in two types: hot cathode and cold cathode. In the hot cathode version, an electrically heated filament produces an electron beam. The electrons travel through the gauge and ionize gas molecules around them. The resulting ions are collected at a negative electrode. The current depends on the number of ions, which depends on the pressure in the gauge. Hot cathode gauges are accurate from 10 Torr to 10 Torr. The principle behind cold cathode version is the same, except that electrons are produced in the discharge of a high voltage. Cold Cathode gauges are accurate from 10 Torr to 10 Torr. Ionization gauge calibration is very sensitive to construction geometry, chemical composition of gases being measured, corrosion and surface deposits. Their calibration can be invalidated by activation at atmospheric pressure or low vacuum. The composition of gases at high vacuums will usually be unpredictable, so a mass spectrometer must be used in conjunction with the ionization gauge for accurate measurement.

A hot-cathode ionization gauge is composed mainly of three electrodes acting together as a triode, wherein the cathode is the filament. The three electrodes are a collector or plate, a filament, and a grid. The collector current is measured in picoamperes by an electrometer. The filament voltage to ground is usually at a potential of 30 volts, while the grid voltage at 180–210 volts DC, unless there is an optional electron bombardment feature, by heating the grid, which may have a high potential of approximately 565 volts.

The most common ion gauge is the hot-cathode Bayard–Alpert gauge, with a small ion collector inside the grid. A glass envelope with an opening to the vacuum can surround the electrodes, but usually the nude gauge is inserted in the vacuum chamber directly, the pins being fed through a ceramic plate in the wall of the chamber. Hot-cathode gauges can be damaged or lose their calibration if they are exposed to atmospheric pressure or even low vacuum while hot. The measurements of a hot-cathode ionization gauge are always logarithmic.

Electrons emitted from the filament move several times in back-and-forth movements around the grid before finally entering the grid. During these movements, some electrons collide with a gaseous molecule to form a pair of an ion and an electron (electron ionization). The number of these ions is proportional to the gaseous molecule density multiplied by the electron current emitted from the filament, and these ions pour into the collector to form an ion current. Since the gaseous molecule density is proportional to the pressure, the pressure is estimated by measuring the ion current.

The low-pressure sensitivity of hot-cathode gauges is limited by the photoelectric effect. Electrons hitting the grid produce x-rays that produce photoelectric noise in the ion collector. This limits the range of older hot-cathode gauges to 10 Torr and the Bayard–Alpert to about 10 Torr. Additional wires at cathode potential in the line of sight between the ion collector and the grid prevent this effect. In the extraction type the ions are not attracted by a wire, but by an open cone. As the ions cannot decide which part of the cone to hit, they pass through the hole and form an ion beam. This ion beam can be passed on to a:

There are two subtypes of cold-cathode ionization gauges: the Penning gauge (invented by Frans Michel Penning), and the Inverted magnetron, also called a Redhead gauge. The major difference between the two is the position of the anode with respect to the cathode. Neither has a filament, and each may require a DC potential of about 4 kV for operation. Inverted magnetrons can measure down to 1  Torr.

Likewise, cold-cathode gauges may be reluctant to start at very low pressures, in that the near-absence of a gas makes it difficult to establish an electrode current - in particular in Penning gauges, which use an axially symmetric magnetic field to create path lengths for electrons that are of the order of metres. In ambient air, suitable ion-pairs are ubiquitously formed by cosmic radiation; in a Penning gauge, design features are used to ease the set-up of a discharge path. For example, the electrode of a Penning gauge is usually finely tapered to facilitate the field emission of electrons.

Maintenance cycles of cold cathode gauges are, in general, measured in years, depending on the gas type and pressure that they are operated in. Using a cold cathode gauge in gases with substantial organic components, such as pump oil fractions, can result in the growth of delicate carbon films and shards within the gauge that eventually either short-circuit the electrodes of the gauge or impede the generation of a discharge path.

When fluid flows are not in equilibrium, local pressures may be higher or lower than the average pressure in a medium. These disturbances propagate from their source as longitudinal pressure variations along the path of propagation. This is also called sound. Sound pressure is the instantaneous local pressure deviation from the average pressure caused by a sound wave. Sound pressure can be measured using a microphone in air and a hydrophone in water. The effective sound pressure is the root mean square of the instantaneous sound pressure over a given interval of time. Sound pressures are normally small and are often expressed in units of microbar.

The American Society of Mechanical Engineers (ASME) has developed two separate and distinct standards on pressure Measurement, B40.100 and PTC 19.2.
B40.100 provides guidelines on Pressure Indicated Dial Type and Pressure Digital Indicating Gauges, Diaphragm Seals, Snubbers, and Pressure Limiter Valves.
PTC 19.2 provides instructions and guidance for the accurate determination of pressure values in support of the ASME Performance Test Codes. The choice of method, instruments, required calculations, and corrections to be applied depends on the purpose of the measurement, the allowable uncertainty, and the characteristics of the equipment being tested.

The methods for pressure measurement and the protocols used for data transmission are also provided. Guidance is given for setting up the instrumentation and determining the uncertainty of the measurement. Information regarding the instrument type, design, applicable pressure range, accuracy, output, and relative cost is provided. Information is also provided on pressure-measuring devices that are used in field environments i.e., Piston Gauges, Manometers, and Low-Absolute-Pressure (Vacuum) Instruments.

These methods are designed to assist in the evaluation of measurement uncertainty based on current technology and engineering knowledge, taking into account published instrumentation specifications and measurement and application techniques. This Supplement provides guidance in the use of methods to establish the pressure-measurement uncertainty.





</doc>
<doc id="19953" url="https://en.wikipedia.org/wiki?curid=19953" title="Medieval dance">
Medieval dance

Sources for an understanding of dance in Europe in the Middle Ages are limited and fragmentary, being composed of some interesting depictions in paintings and illuminations, a few musical examples of what may be dances, and scattered allusions in literary texts. The first detailed descriptions of dancing only date from 1451 in Italy, which is after the start of the Renaissance in Western Europe.

The most documented form of dance during the Middle Ages is the carol also called the "carole" or "carola" and known from the 12th and 13th centuries in Western Europe in rural and court settings. It consisted of a group of dancers holding hands usually in a circle, with the dancers singing in a leader and refrain style while dancing. No surviving lyrics or music for the carol have been identified. In northern France, other terms for this type of dance included "ronde" and its diminutives "rondet", "rondel", and "rondelet" from which the more modern music term "rondeau" derives. In the German-speaking areas, this same type of choral dance was known as "reigen".

Some of the earliest mentions of the carol occur in the works of the French poet Chretien de Troyes in his series of Arthurian romances. In the wedding scene in Erec and Enide (about 1170)

In The Knight of the Cart, (probably late 1170s) at a meadow where there are knights and ladies, various games are played while:

In what is probably Chretien's last work, Perceval, the Story of the Grail, probably written 1181-1191, we find:

and later at a court setting:

Dante (1265-1321) has a few minor references to dance in his works but a more substantive description of the round dance with song from Bologna comes from Giovanni del Virgilio (floruit 1319-1327).

Later in the 14th century Giovanni Boccaccio (1313–1375) shows us the "carola" in Florence in the Decameron (about 1350-1353) which has several passages describing men and women dancing to their own singing or accompanied by musicians. Boccaccio also uses two other terms for contemporary dances, "ridda" and "ballonchio", both of which refer to round dances with singing.

Approximately contemporary with the "Decameron" are a series of frescos in Siena by Ambrogio Lorenzetti painted about 1338-40, one of which shows a group of women doing a "bridge" figure while accompanied by another woman playing the tambourine.

In a life of Saint Dunstan composed about 1000, the author tells how Dunstan, going into a church, found maidens dancing in a ring and singing a hymn. According to the Oxford English Dictionary (1933) the term "carol" was first used in England for this type of circle dance accompanied by singing in manuscripts dating to as early as 1300. The word was used as both a noun and a verb and the usage of carol for a dance form persisted well into the 16th century. One of the earliest references is in Robert of Brunne's early 14th century "Handlyng Synne" (Handling Sin) where it occurs as a verb.

Mullally in his book on the carole makes the case that the dance, at least in France, was done in a closed circle with the dancers, usually men and women interspersed, holding hands. He adduces evidence that the general progression of the dance was to the left (clockwise) and that the steps probably were very simple consisting of a step to the left with the left foot followed by a step on the right foot closing to the left foot.

Circle or line dances also existed in other parts of Europe outside England, France and Italy where the term carol was best known. These dances were of the same type with dancers hand-in-hand and a leader who sang the ballad.

In Denmark, old ballads mention a closed Ring dance which can open into a Chain dance. A fresco in Ørslev church in Zealand from about 1400 shows nine people, men and women, dancing in a line. The leader and some others in the chain carry bouquets of flowers. Dances could be for men and women, or for men alone, or women alone. In the case of women's dances, however, there may have been a man who acted as the leader. Two dances specifically named in the Danish ballads which appear to be line dances of this type are "The Beggar Dance", and "The Lucky Dance" which may have been a dance for women. A modern version of these medieval chains is seen in the Faroese chain dance, the earliest account of which goes back only to the 17th century.

In Sweden too, medieval songs often mentioned dancing. A long chain was formed, with the leader singing the verses and setting the time while the other dancers joined in the chorus. These "Long Dances" have lasted into modern times in Sweden. 
A similar type of song dance may have existed in Norway in the Middle Ages as well, but no historical accounts have been found.

The same dance in Germany was called "Reigen" and may have originated from devotional dances at early Christian festivals. Dancing around the church or a fire was frequently denounced by church authorities which only underscores how popular it was. There are records of church and civic officials in various German towns forbidding dancing and singing from the 8th to the 10th centuries. Once again, in singing processions, the leader provided the verse and the other dancers supplied the chorus. The minnesinger Neidhart von Reuental, who lived in the first half of the 13th century wrote several songs for dancing, some of which use the term "reigen".
In southern Tyrol, at Runkelstein Castle, a series of frescos was executed in the last years of the 14th century. One of the frescos depicts Elisabeth of Poland, Queen of Hungary leading a chain dance.

Circle dances were also found in the area that is today the Czech Republic. Descriptions and illustrations of dancing can be found in church registers, chronicles and the 15th century writings of Bohuslav Hasištejnský z Lobkovic. Dancing was primarily done around trees on the village green but special houses for dancing appear from the 14th century. In Poland as well the earliest village dances were in circles or lines accompanied by the singing or clapping of the participants.

The present day folk dances in the Balkans consist of dancers linked together in a hand or shoulder hold in an open or closed circle or a line. The basic round dance goes by many names in the various countries of the region: "kolo", "oro", "horo" or "hora". The modern couple dance so common in western and northern Europe has only made a few inroads into the Balkan dance repertory.
Chain dances of a similar type to these modern dance forms have been documented from the medieval Balkans. Tens of thousands of medieval tombstones called "Stećci" are found in Bosnia and Hercegovina and neighboring areas in Montenegro, Serbia and Croatia. They date from the end of the 12th century to the 16th century. Many of the stones bear inscription and figures, several of which have been interpreted as dancers in a ring or line dance. These mostly date to the 14th and 15th centuries. Usually men and women are portrayed dancing together holding hands at shoulder level but occasionally the groups consist of only one sex.

Further south in Macedonia, near the town of Zletovo, the monastery of Lesnovo (Lesnovo Manastir), originally built in the 11th century, was renovated in the middle of the 14th century and a series of murals were painted. One of these shows a group of young men linking arms in a round dance. They are accompanied by two musicians, one playing the kanun while the other beats on a long drum.

There is also some documentary evidence from the Dalmatian coast area of what is now Croatia. An anonymous chronicle from 1344 exhorts the people of the city of Zadar to sing and dance circle dances for a festival while in the 14th and 15th centuries, authorities in Dubrovnik forbid circle dances and secular songs on the cathedral grounds. Another early reference comes from the area of present-day Bulgaria in a manuscript of a 14th-century sermon which calls chain dances "devilish and damned."

At a later period there are the accounts of two western European travelers to Constantinople, the capital of the Ottoman Empire. Salomon Schweigger (1551-1622) was a German preacher who traveled in the entourage of Jochim von Sinzendorf, Ambassador to Constantinople for Rudolf II in 1577. He describes the events at a Greek wedding:

Another traveler, the German pharmacist Reinhold Lubenau, was in Constantinople in November 1588 and reports on a Greek wedding in these terms:

If the story is true that troubadour Raimbaut de Vaqueiras (about 1150-1207) wrote the famous Provençal song "Kalenda Maya" to fit the tune of an estampie that he heard two jongleurs play, then the history of the estampie extends back to the 12th century. The only musical examples actually identified as "estampie" or "istanpita" occur in two 14th-century manuscripts. The same manuscripts also contain other pieces named "danse real" or other dance names. These are similar in musical structure to the estampies but consensus is divided as to whether these should be considered the same.

In addition to these instrumental music compositions, there are also mentions of the estampie in various literary sources from the 13th and 14th centuries. One of these as "stampenie" is found in Gottfried von Strassburg's "Tristan" from 1210 in a catalog of Tristan's accomplishments:

Later, in a description of Isolde:

A century and a half later in the poem "La Prison amoreuse" (1372–73) by French chronicler and poet Jean Froissart (c. 1337-1405), we find:

Opinion is divided as to whether the Estampie was actually a dance or simply early instrumental music. Sachs believes the strong rhythm of the music, a derivation of the name from a term meaning "to stamp" and the quotation from the Froissart poem above definitely label the estampie as a dance. However, others stress the complex music in some examples as being uncharacteristic of dance melodies and interpret Froissart's poem to mean that the dancing begins with the carol. There is also debate on the derivation of the word "estampie". In any case, no description of dance steps or figures for the estampie are known.

According to German dance historian Aenne Goldschmidt, the oldest notice of a couple dance comes from the southern German Latin romance Ruodlieb probably composed in the early to mid-11th century. The dance is done at a wedding feast and is described in the translation by Edwin Zeydel as follows:





</doc>
<doc id="19955" url="https://en.wikipedia.org/wiki?curid=19955" title="Megatokyo">
Megatokyo

Set in a fictional version of Tokyo, "Megatokyo" portrays the adventures of Piro, a young fan of anime and manga, and his friend Largo, an American video game enthusiast. The comic often parodies and comments on the archetypes and clichés of anime, manga, dating sims, arcade and video games, occasionally making direct references to real-world works. "Megatokyo" originally emphasized humor, with continuity of the story a subsidiary concern. Over time, it focused more on developing a complex plot and the personalities of its characters. This transition was due primarily to Gallagher's increasing control over the comic, which led to Caston choosing to leave the project. "Megatokyo" has received praise from such sources as "The New York Times", while negative criticism of Gallagher's changes to the comic has been given by sources including Websnark.

"Megatokyo" began publication as a joint project between Fred Gallagher and Rodney Caston, along with a few internet acquaintances. Gallagher and Caston later became business partners, as well. According to Gallagher, the comic's first two strips were drawn in reaction to Caston being "convinced that he and I could do [a webcomic] ... [and] bothering me incessantly about it", without any planning or pre-determined storyline. The comic's title was derived from an Internet domain owned by Caston, which had hosted a short-lived gaming news site maintained by Caston before the comic's creation. With Caston co-writing the comic's scripts and Gallagher supplying its artwork, the comic's popularity quickly increased, eventually reaching levels comparable to those of such popular webcomics as "Penny Arcade" and "PvP". According to Gallagher, "Megatokyo"<nowiki>'</nowiki>s popularity was not intended, as the project was originally an experiment to help him improve his writing and illustrating skills for his future project, "Warmth".

In May 2002, Caston sold his ownership of the title to Gallagher, who has managed the comic on his own since then. In October of the same year, after Gallagher was laid off from his day job as an architect, he took up producing the comic as a full time profession. Caston's departure from "Megatokyo" was not fully explained at the time. Initially, Gallagher and Caston only briefly mentioned the split, with Gallagher publicly announcing Caston's departure on June 17, 2002. On January 15, 2005, Gallagher explained his view of the reasoning behind the split in response to a comment made by Scott Kurtz of "PvP", in which he suggested that Gallagher had stolen ownership of "Megatokyo" from Caston. Calling Kurtz's claim "mean spirited", Gallagher responded:
"While things were good at first, over time we found that we were not working well together creatively. There is no fault in this, it happens. I've never blamed Rodney for this creative 'falling out' nor do I blame myself. Not all creative relationships click, ours didn't in the long run."
Four days later, Caston posted his view of the development on his website:
"After this he approached me and said either I would sell him my ownership of MegaTokyo or he would simply stop doing it entirely, and we'd divide up the company's assets and end it all.
This was right before the MT was to go into print form, and I really wanted to see it make it into print, rather [than] die on the vine."
In May 2011, it was announced that "Endgames" (a gameworld existing within "Megatokyo") was being revamped in a light novel format, with a story written by webfiction author Thomas Knapp, with four light novels planned. A short story "Behind the Masque" was also announced, and released on Amazon's Kindle Store on June 10, 2011.

"Megatokyo" is usually hand-drawn in pencil by Fred Gallagher, without any digital or physical "inking". Inking was originally planned, but dropped as Gallagher decided it was unfeasible. "Megatokyo"<nowiki>'</nowiki>s first strips were created by roughly sketching on large sheets of paper, followed by tracing, scanning, digital clean-up of the traced comics with Adobe Photoshop, and final touches in Adobe Illustrator to achieve a finished product. Gallagher has stated that tracing was necessary because his sketches were not neat enough to use before tracing. Because of the tracing necessary, these comics regularly took six to eight hours to complete. As the comic progressed, Gallagher became able to draw "cleaner" comics without rough lines and tracing lines, and was able to abandon the tracing step. Gallagher believes "that this eventually led to better looking and more expressive comics".

"Megatokyo"<nowiki>'</nowiki>s early strips were laid out in four square panels per strip, in a two-by-two square array – a formatting choice made as a compromise between the horizontal layout of American comic strips and the vertical layout of Japanese comic strips. The limitations of this format became apparent during the first year of "Megatokyo"<nowiki>'</nowiki>s publication, and in the spring of 2001, the comic switched to a manga-style, free-form panel layout. This format allowed for both large, detailed drawings and small, abstract progressions, as based on the needs of the script. Gallagher has commented that his drawing speed had increased since the comic's beginning, and with four panel comics taking much less time to produce, it "made sense in some sort of twisted, masochistic way, that [he] could use that extra time to draw more for each comic".

"Megatokyo"<nowiki>'</nowiki>s earliest strips were drawn entirely on single sheets of paper. Following these, Gallagher began drawing the comic's panels separately and assembling them in Adobe Illustrator, allowing him to draw more detailed frames. This changed during "Megatokyo"<nowiki>'</nowiki>s eighth chapter, with Gallagher returning to drawing entire comics on single sheets of paper. Gallagher stated that this change allowed for more differentiated layouts, in addition to allowing him a better sense of momentum during comic creation.

The strip is currently drawn on inkjet paper in pencil, the text and speech being added later with Adobe Photoshop or Illustrator. In March 2009 he began Fredarting, a streaming live video feed of the comic being drawn.

Gallagher occasionally has guest artists participate in the production of the comic, including Mohammad F. Haque of "Applegeeks".

"Megatokyo" has had several sources of funding during its production. In its early years, it was largely funded by Gallagher and Caston's full time jobs, with the additional support of banner advertisements. A store connected to ThinkGeek was launched during October 2000 in order to sell "Megatokyo" merchandise, and, in turn, help fund the comic. On August 1, 2004, this store was replaced by "Megagear", an independent online store created by Fred Gallagher and his wife, Sarah, to be used solely by "Megatokyo", although it now also offers "Applegeeks" and "Angerdog" merchandise.

Gallagher has emphasized that "Megatokyo" will continue to remain on the Internet free of charge, and that releasing it in book form is simply another way for the comic to reach readers, as opposed to replacing its webcomic counterpart entirely. Additionally, he has stated that he is against micropayments, as he believes that word of mouth and public attention are powerful property builders, and that a "pay-per-click" system would only dampen their effectiveness. He has claimed that such systems are a "superior" option to direct monetary compensation, and that human nature is opposed to micropayments.

Much of "Megatokyo"<nowiki>'</nowiki>s early humor consists of jokes related to the video game subculture, as well as culture-clash issues. In these early strips, the comic progressed at a pace which Gallagher has called "haphazard", often interrupted by purely punchline-driven installments. As Gallagher gradually gained more control over "Megatokyo"<nowiki>'</nowiki>s production, the comic began to gain more similarities to the Japanese shōjo manga that Gallagher enjoys. Following Gallagher's complete takeover of "Megatokyo", the comic's thematic relation to Japanese manga continued to grow.

The comic features characteristics borrowed from anime and manga archetypes, often parodying the medium's clichés. Examples include Junpei, a ninja who becomes Largo's apprentice; Rent-a-zillas, giant monsters based on Godzilla; the Tokyo Police Cataclysm Division, which fights the monsters with giant robots and supervises the systematic destruction and reconstruction of predesignated areas of the city; fan service; a Japanese school girl, Yuki, who has also started being a magical girl in recent comics; and Ping, a robot girl. In addition, Dom and Ed, hitmen employed by Sega and Sony, respectively, are associated with a Japanese stereotype that all Americans are heavily armed.

Characters in "Megatokyo" usually speak Japanese, although some speak English, or English-based l33t. Typically, when a character is speaking Japanese, it is signified by enclosing English text between angle brackets (<>). Not every character speaks every language, so occasionally characters are unable to understand one another. In several scenes (such as this one), a character's speech is written entirely in rōmaji Japanese to emphasize this.

"Megatokyo" is divided into chapters. Chapter 0, which contains all of the comic's early phase, covers a time span in the comic of about six weeks. Each of the subsequent chapters chronicles the events of a single day. Chapter 0 was originally not given a title, although the book version retroactively dubbed it "Relax, we understand j00." Between the chapters, and occasionally referenced in the main comic, are a number of omake.

Piro, the protagonist, is an author surrogate of Fred Gallagher. Gallagher has stated that Piro is an idealized version of himself when he was in college. As a character, he is socially inept and frequently depressed. His design was originally conceived as a visual parody of the character Ruri Hoshino, from the "Martian Successor Nadesico" anime series. His name is derived from Gallagher's online nickname, which was in turn taken from Makoto Sawatari's cat in the Japanese visual novel "Kanon".

In the story, Piro has extreme difficulty understanding "Megatokyo"<nowiki>'</nowiki>s female characters, making him for the most part ignorant of the feelings that the character Nanasawa Kimiko has for him, though he has become much more aware of her attraction as the series progressed. Gallagher has commented that Piro is the focal point of emotional damage, while his friend, Largo, takes the physical damage in the comic.

Largo is the comic's secondary protagonist, and the comic version of co-creator Rodney Caston. An impulsive alcoholic whose speech is rendered in L33t frequently, he serves as one of the primary sources of comic relief. A technologically gifted character, he is obsessed with altering devices, often with hazardous results. Gallagher designed Largo to be the major recipient of the comic's physical damage. Largo's name comes from Caston's online nickname, which refers to the villain from "Bubblegum Crisis". For various reasons (including fire and battle damage) he often ends up wearing very little clothing. Largo seems to have awkwardly blundered into a relatively successful relationship with Hayasaka Erika at the current time in the comic.

 is a strong-willed, cynical, and sometimes violent character. At the time of the story, she is a former popular Japanese idol (singer) and voice actress who has been out of the spotlight for three years, though she still possesses a considerable fanbase. Erika's past relationship troubles, combined with exposure to swarms of fanboys, have caused her to adopt a negative outlook on life. Gallagher has implied that her personality was loosely based on the "tsundere" (tough girl) stereotype often seen in anime and manga.

 is a Japanese girl who previously worked as a waitress at an Anna Miller's restaurant, and is Piro's romantic interest. At the current point in the story, she is a voice actress for the possibly-failing Lockart game "Sight", playing the main heroine, Kannazuki Kotone. Kimiko is a kind and soft-spoken character, though she is prone to mood-swings, and often causes herself embarrassment by saying things she does not mean. Gallagher has commented that Kimiko was the only female character not based entirely on anime stereotypes.

 is an enigmatic and manipulative young goth girl. She is drawn to resemble a "Gothic Lolita", and is often described as "darkly cute," with Gallagher occasionally describing her as a "perkigoth." Miho often acts strangely compared to the comic's other characters, and regularly accomplishes abnormal feats, such as leaping inhuman distances or perching herself atop telephone poles. Despite these displays of ability, it is hinted at that Miho has problems with her health. Little is revealed in the comic about Miho's past or motivations, although Gallagher states that these will eventually be explained. Largo believes that she (Miho) is the queen of the undead, and is the cause of the zombie invasion of Tokyo. It has been hinted that she is a magical girl who may have some past connection with the zombies. She is apparently killed in a robotic beam attack by Ed, but nine days later is found in the hospital reading and eating with no obvious signs of physical damage. More possibilities exist that she is some type of game prototype or archetype.

"Megatokyo"<nowiki>'</nowiki>s story begins when Piro and Largo fly to Tokyo after an incident at the Electronic Entertainment Expo (E3). Piro has the proper paperwork; Largo must beat the ninja Junpei at a video game to enter. After a spending spree, the pair are stranded without enough money to buy plane tickets home, forcing them to live with Tsubasa, a Japanese friend of Piro's. When Tsubasa suddenly departs for America to seek his "first true love", the protagonists are forced out of the apartment. Tsubasa leaves Ping, a robot girl PlayStation 2 accessory, in their care. This leads to old friends of Piro and Largo showing up later. The two are shadow operatives for video game companies, Ed (Sony) and Dom (SEGA).

At one point, Piro, confronted with girl troubles, visits the local bookstore to "research"—look in the vast shelves of shoujo manga for a solution to his problem. A spunky schoolgirl, Sonoda Yuki, and her friends, Asako and Mami, see him sitting amidst piles of read manga, and ask him what he is doing. Piro, flustered, runs away, accidentally leaving behind his bookbag and sketchbook.

After their eviction, Piro begins work at "Megagamers", a store specializing in anime, manga, and video games. His employer allows him and Largo to live in the apartment above the store. Largo is mistaken for the new English teacher at a local school, where he takes on the alias "Great Teacher Largo" and instructs his students in L33t, video games, and about computers. Yuki's father, Inspector Sonada Masamichi of the "Tokyo Police Cataclysm Division" (TPCD) hires Largo after Largo manipulates Ping into stopping a rampaging monster, the drunken turtle Gameru.

As Largo is working at the local high school, Piro encounters Yuki again while working at Megagamers, when she returns his bookbag and sketchbook, scribbled all over with comments about his drawings. She then, to his consternation, asks if he would give her drawing lessons. Piro, flustered, agrees, and promptly forgets about them.

Earlier in the story, Piro had seen Nanasawa Kimiko at an Anna Miller's restaurant, where she is a waitress, after Tsubasa brought him and Largo there. Later on, Piro encounters Kimiko outside a train station, where she is worrying aloud that she will miss an audition because she has forgotten her money and railcard. Piro hands her his own railcard and walks off before she can refuse his offer. This event causes Kimiko to develop an idealized vision of her benefactor, an image which is shattered the next time they meet. Despite this, she gradually develops feelings for Piro, though she is too shy to admit them. Later on in the story, Kimiko's outburst on a radio talk show causes her to suddenly rise to idol status. Angered by the hosts' derisive comments about fanboys, she comes to the defense of her audience, immediately and unintentionally securing their obsessive adoration. Later, her new horde of fanboys find out where she works and flock to the restaurant, obsessively trying to get pictures up her skirt. Piro works undercover as a busboy to get rid of all cameras. The scene eventually builds to a climax, in which Kimiko shouts at the fanboys and lifts her skirt in defiance, and they take photographs. Piro, provoked by her outburst into actively defending her, threatens the fanboy crowd, and collects all of their memory cards with the photos. On the way back from the restaurant, Kimiko is suffering from the aftermath of the scene and lashes out at Piro on the subway, which causes him to walk off.

Meanwhile, Largo develops a relationship with Hayasaka Erika, Piro's coworker at Megagamers. She and Kimiko share a house. As with Piro and Kimiko, Largo and Erika meet by coincidence early in the story. Later, it is revealed that Erika is a former pop idol, who caused a big scene then disappeared from the public eye after her fiancé left her. When she is rediscovered by her fans, Largo helps thwart a fanboy horde, but not well enough to escape being dismissed by the TPCD for it. He then offers to help Erika to deal with her "vulnerabilities in the digital plane". Erika insists on protecting herself, so Largo instructs her in computer-building. This leads into a little more relationship than Largo can handle, partly because he insists all computer building be done in the nude or as close to it as possible, to avoid static electrical discharge ruining components, and partly because his behavior, crude though it may appear, impresses Erika in many ways.

The enigmatic Tohya Miho frequently meddles in the lives of the protagonists. Miho knows Piro and Largo from the "Endgames" MMORPG previous to "Megatokyo"<nowiki>'</nowiki>s plot. She abused a hidden statistic in the game to gain control of nearly all of the game's player characters, but was ultimately defeated by Piro and Largo. In the comic, Miho becomes close friends with Ping, influencing Ping's relationship with Piro and pitting Ping against Largo in video game battles. Miho is also involved in Erika's backstory; Miho manipulated Erika's fans after Erika's disappearance. This effort ended badly, leaving Miho hospitalized, and the TPCD cleaning up the aftermath. Most of the exact details of what happened are left to the readers' imagination, as are her current motivations and ultimate goal. Miho and many of the events surrounding her involve a club in Harajuku, the Cave of Evil (CoE).

After getting yelled at for retaining her waitress job, Kimiko quits her voice acting job and goes home to find Erika assembling a new computer in her undergarments. Not long after Erika tells Kimiko to strip, Piro comes by, who she tells to get undressed as well. While Erika and Piro talk about her, Kimiko, who hid when Piro showed up, runs out of the apartment. Kimiko runs into Ping, who wanted to talk to Piro about why, after an explosion at school, she had started to cry uncontrollably. They encounter Largo at the store, who explains what went wrong, although no one knows what he means until Piro comes in and translates. Ping is relieved to know that she won't shut down and Kimiko hugs Piro and apologizes for her actions. Largo leaves for Erika's apartment after she calls looking for help. That night, while Piro and Kimiko fall asleep watching TV, Erika, who finished the computer with Largo's help, tries to seduce Largo, but it freaks him out and he runs out for home. The next morning, after Kimiko departs, Piro finds out she quit her voice acting job and tries to find her.

Kimiko and Miho are in the same diner, to which Ed has sent an attack robot (Kill-Bot) against Miho, since she has disrupted his attempts to destroy Ping. Miho is in the diner trying to contact Piro, Kimiko is talking with Erika. Dom is also there to talk with Kimiko. After rescuing both herself and Kimiko from the Kill-Bot and chaos at the diner, the two talk about things. Miho talks to Piro on her phone, argues with him, and then Piro and Kimiko have a conversation about that as the two females are leaving the area. Dom follows and tries to coerce Kimiko into joining SEGA for protection from fans, but she refuses. Drained, she has Miho finish talking to Piro on the phone. Piro then encounters a group who found Kimiko's cell phone and other belongings after she and Miho escaped the diner. The group wants to help Piro get together with Kimiko, partially due to feeling bad for trying to snap a picture up Kimiko's skirt. Piro and the group set out for a press conference Kimiko is going to for the voice acting project, "Sight". Besides all of the other fans going to the event, a planned zombie outbreak occurs in the area. Miho, who helped Kimiko get ready for the event and accompanied her to it, later calls the zombies off for unexplained reasons through an unexplained mechanism.

Largo and Yuki, who has since been revealed along the way to be a magical girl like her mother Meimi (likewise revealed), steal a Rent-a-Zilla to fight the zombie outbreak. Largo leaves Yuki to help Piro get to Kimiko. Unfortunately, the Rent-a-Zilla gets bitten by zombies and turns into one itself, resulting in the TPCD capturing it. Yuki protects it from the TPCD, teleports it out of the area, and adopts it as a pet in a miniaturized form, all much to her father's chagrin.

After the event, Erika, Largo, Kimiko and Piro are reunited, and they talk a bit with Miho, who has shown up again after storming out following an argument with Kenji earlier. Miho declines an offer to eat with the group and wanders off thinking about games and Largo and Piro. She is shown walking amongst the zombies and then in Ed's gun-sights, and in the center of an attack by a number of Ed's Kill-Bots.

During the next nine days, Piro and Kimiko have made up and Kimiko returned to both of her jobs, with them seeing little of each other. Largo and Erika are shown to likewise be involved but more often, including going to dinner with the Sonoda family, as the inspector's brother was Erika's fiancé. Kimiko is attempting to get Piro working as an artist on "Sight", which unbeknownst to them is now being funded by Dom. Ping is concerned about the whereabouts of Miho, who hasn't been seen during the time, but Piro is still upset about all that has happened and somewhat evasively refuses direct assistance. Ping and Junko, another one of Largo's students, who used to be a friend of Miho, work towards finding Miho. Yuki and Kobayashi Yutaka then also become involved with the attempt because of this. That night, Piro and Kimiko discuss Miho and "Endgames", which Yuki overhears, they unaware she is there. This leads Yuki to appropriate Piro's powerless laptop and leave, believing him to still be in love with Miho and that the device might hold clues to finding her. Kimiko and Piro work on his portfolio for "Sight" and then they say goodnight and leave. He returns to his apartment, but Kimiko goes to the CoE club using a pass Miho gave her long ago in the beginning. Once at the club, Dom mockingly advises her, Yuki unknowingly whisps past her, and she unexpectedly meets up with an old friend Komugiko. During all this, Piro has left his apartment after looking at his sketchbook and a drawing of Miho. His current location is unknown.

Aside from Kimiko, concurrent overlapping events have led to almost every main character converging upon the club for various reasons involving Miho, or in support of others involved. Ed, attempting to destroy Ping, fights with Largo, as the staff of the club have maneuvered Ed and Ping into the protective radius of ex-Idol Erika. Yuki and Yutaka get Piro's laptop powered on, she reads the old chat logs between Piro and Miho, and follows instructions from her to him. Going to a "hidden-in-plain-sight" hospital room, she finds Miho alive and well, although seemingly in a weakened state. During a heated argument and Miho's goading, Yuki then forcibly moves Miho to the club. Shortly after the arrival of the two in the center of everyone, the bulk of the denizens go into trance-like states while others are fighting or confused about what to do next. Miho appears to be collapsing. Upon instructions from Erika, Largo finds then uses his Largo-Phone and the club's sound system to knock out power in the immediate area of the club. During this event, Piro has gone to visit Miho at the "hospital" room, where he discovers that she is missing. Following the blackout, Largo, Erika, and Miho board a train, where Miho decides to return home. However, a large crowd has blocked her path home, apparently waiting for someone's return.

The next morning, Piro has been brought to jail, where he has been interrogated by police about Miho's disappearance. He is able to leave jail by paying a suspiciously set low bail of about $100 US, which is obtained through a 10,000 yen bill that has been shaped into an origami 'zilla and left in the cell. Piro walks back home, where he finds Miho sleeping on a beanbag in the apartment. Piro and Miho then work out some of the confusion between them, which reveals several background events. She explains the Analogue Support Facility as a sort of safehouse, where she was able to come and go when she wanted. Since Ping in her extreme attempt to find Miho had posted tons of pictures, videos, and information on the internet, people are now using that to "build a 'real' me", as Miho explains it. During the process, at one point Kimiko calls from the studio, updating Piro on his artwork and telling him some of how last night she and others found Miho and how crazy it was. Largo and Erika, who are riding on the roof of a train in the Miyagi prefecture also call during the conversation. After a short conversation with both Largo and Erika on the phone, and a bit more conversation with Miho, Piro instructs her to stay in the apartment until they can figure out what to do. Junko and Ping are shown leaving for school, with Junko seeming taking Ed's shotguns from last night with her.

After receiving a phone call from Yutaka, whom Masamichi initially disapproves of, Yuki, who has not changed clothing from the events of the previous chapter, leaves her house, grabs him, and takes him to a rooftop, where they try to explain things after Yutaka was being questioned by Asako and Mami. She goes over everything, even why she referred to herself as a "monster", which Yuki's friends previously overheard and misunderstood. Realizing that Miho is the cause of this mess, Yutaka indirectly vows revenge, but Yuki stops him. Yutaka goes anyway and meets his brother in front of Megagamers, who has tracked Miho to the store since the previous night. Yutaka's brother is a member of a group of Nanasawa fans who plan to intervene and remind Piro who his true love is to get rid of Miho. However, Dom's van is blocking the store's entrance. Though Yuki protests against intervention to the group, Dom, who is unknown to them, performs his own method of intervention anyway and forces Piro to choose between Nanasawa and Miho. It is currently unknown if Dom knows who Miho is, but Miho, in a disguise, overhears the conversation and forces Piro to briefly wear a hat. At the same time, Yuki, deciding that she can wait no longer, steals Dom's van and guns, and rushes into the store with Yutaka in tow. Seeing this, Miho grabs Piro and rushes upstairs, discarding the hat in the process. Yuki subsequently collides with the hat and a presumed explosion occurs, stalling Yuki and Yutaka. Miho and Piro don cosplay outfits as a disguise, escape, and make their way to the local bath house. Just before Yuki grabs Yutaka again, Dom, now trapped under a pile of rubble, expresses his condolences to Yutaka, to which he does not understand. The pair quickly follow Miho and Piro and await for them to leave the bath house.

"Megatokyo" was first published in print by Studio Ironcat, a partnership announced in September 2002. Following this, the first book, a compilation of "Megatokyo" strips under the title ""Megatokyo Volume One: Chapter Zero"", was released by Studio Ironcat in January 2003. According to Gallagher, Studio Ironcat was unable to meet demand for the book, due to problems the company was facing at the time. On July 7, 2003, Gallagher announced that Ironcat would not continue to publish "Megatokyo" in book form. This was followed by an announcement on August 27, 2003 that Dark Horse Comics would publish "Megatokyo Volume 2" and future collected volumes, including a revised edition of "Megatokyo Volume 1". The comic once more changed publishers in February 2006, moving from Dark Horse Comics to the CMX Manga imprint of DC Comics. The comic then transferred to CMX's parent Wildstorm, with its last volume published in July 2010.
CMX, along with Wildstorm closed down in 2010. Former publisher Dark Horse regained the rights to the series and planned to release it in omnibus format in January 2013, but didn't.

, six volumes are available for purchase: volumes 1 through 3 from Dark Horse, volumes 4 and 5 by CMX/DC, and volume 6 by Wildstorm. The books have also been translated into German, Italian, French, and Polish. In July 2004, "Megatokyo" was the tenth best-selling manga property in the United States, and during the week ending February 20, 2005, volume 3 ranked third in the Nielsen BookScan figures, which was not only its highest ranking to date (), but also made it the highest monthly rank for an original English-language manga title.

In July 2007, Kodansha announced that in 2008 it intends to publish "Megatokyo" in a Japanese-language edition, (in a silver slipcased box as part of Kodansha Box editions, a new manga line started in November 2006). Depending on reader response, Kodansha hoped to subsequently publish the entire "Megatokyo" book series. The first volume was released in Japan on May 7, 2009.

The artwork and characterizations of "Megatokyo" have received praise from such publications as "The New York Times" and Comics Bulletin. Many critics praise "Megatokyo"s character designs and pencil work, rendered entirely in grayscale; conversely, it has been criticized for perceived uniformity and simplicity in the designs of its peripheral characters, which have been regarded as confusing and difficult to tell apart due to their similar appearances.

Some critics, such as Eric Burns of Websnark, have found the comic to suffer from "incredibly slow pacing" (, only about 2 months of in-universe time have elapsed), unclear direction or resolutions for plot threads, a lack of official character profiles and plot summaries for the uninitiated, and an erratic update schedule. Burns also harshly criticized the often uncanonical filler material Gallagher employs to prevent the comic's front page content from becoming stagnant, such as "Shirt Guy Dom", a punchline-driven stick figure comic strip written and illustrated by "Megatokyo" editor Dominic Nguyen. Following Gallagher taking on "Megatokyo" as a full-time occupation, some critics have complained that updates should be more frequent than when he worked on the comic part time. Update schedule issues prompted Gallagher to install an update progress bar for readers awaiting the next installment of the comic; however, it has since been removed as it itself often wasn't updated.

IGN called "Megatokyo"'s fans "some of the most patient and forgiving in the webcomic world." During an interview, Gallagher stated that "Megatokyo" fans "always [tell him] they are patient and find that the final comics are always worth the wait," but he feels as though he "[has] a commitment to [his] readers and to [himself] to deliver the best comics [he] can, and to do it on schedule," finally saying that nothing would make him happier than "[getting] a better handle on the time it takes to create each page." Upon missing deadlines, Gallagher often makes self-disparaging comments. Poking fun at this, Jerry "Tycho" Holkins of "Penny Arcade" has claimed to have "gotten on famously" with Gallagher, ever since he "figured out that [Gallagher] legitimately detests himself and is not hoisting some kind of "glamour"."

While "Megatokyo" was originally presented as a slapstick comedy, it began focusing more on the romantic relationships between its characters after Caston's departure from the project. As a result, some fans, preferring the comic's gag-a-day format, have claimed its quality was superior when Caston was writing it. Additionally, it has been said that, without Caston's input, Largo's antics appear contrived. Comics Bulletin regards "Megatokyo"'s characters as convincingly portrayed, commenting that "the reader truly feels connected to the characters, their romantic hijinks, and their wacky misadventures with the personal touches supplied by the author." Likewise, Anime News Network has praised the personal tone in which the comic is written, stating that much of its appeal is a result of the "friendly and casual feeling of a fan-made production."

Gallagher states early in "Megatokyo Volume 1" that he and Caston "didn't want the humor ... to rely too heavily on what might be considered 'obscure knowledge.'" An article in "The New York Times" insists that such scenarios were unavoidable, commenting that the comic "sits at the intersection of several streams of obscure knowledge," including "gaming and hacking; manga ... the boom in Web comics over the past few years; and comics themselves." The article also held that "Gallagher doesn't mean to be exclusive ... he graciously offers translation of the strip's later occasional lapses into l33t ... [and] explains why the characters are occasionally dressed in knickers or as rabbits." The newspaper went on to argue that "The pleasure of a story like "Megatokyo" comes not in its novelistic coherence, but in its loose ranginess."

"Megatokyo" was nominated in at least one category of the Web Cartoonist's Choice Awards every year from 2001 through 2007. It won Best Comic in 2002, as well as Best Writing, Best Serial Comic, and Best Dramatic Comic. The largest number of nominations it has received in one year is 14 in 2003, when it won Outstanding Environment Design. The series tied with Svetlana Chmakova's "Dramacon" for the 2007 Best Continuing OEL Manga.


 


</doc>
<doc id="19956" url="https://en.wikipedia.org/wiki?curid=19956" title="Medieval music">
Medieval music

Medieval music consists of songs, instrumental pieces, and liturgical music from about 500 A.D. to 1400. Medieval music was an era of Western music, including liturgical music (also known as sacred) used for the church, and secular music, non-religious music. Medieval music includes solely vocal music, such as Gregorian chant and choral music (music for a group of singers), solely instrumental music, and music that uses both voices and instruments (typically with the instruments accompanying the voices). Gregorian chant was sung by monks during Catholic Mass. The Mass is a reenactment of Christ's Last Supper, intended to provide a spiritual connection between man and God. Part of this connection was established through music.
This era begins with the fall of the Western Roman Empire in the fifth century and ends sometime in the early fifteenth century. Establishing the end of the medieval era and the beginning of the Renaissance music era is difficult, since the trends started at different times in different regions. The date range in this article is the one usually adopted by musicologists.

During the Medieval period the foundation was laid for the music notation and music theory practices that would shape Western music into the norms that developed during the common-practice era, a period of shared music writing practices which encompassed the Baroque music composers from 1600–1750, such as J.S. Bach and Classical music period composers from the 1700s such as W.A. Mozart and Romantic music era composers from the 1800s such as Wagner. The most obvious of these is the development of a comprehensive music notational system which enabled composers to write out their song melodies and instrumental pieces on parchment or paper. Prior to the development of musical notation, songs and pieces had to be learned "by ear", from one person who knew a song to another person. This greatly limited how many people could be taught new music and how wide music could spread to other regions or countries. The development of music notation made it easier to disseminate (spread) songs and musical pieces to a larger number of people and to a wider geographic area. However the theoretical advances, particularly in regard to rhythm—the timing of notes—and polyphony—using multiple, interweaving melodies at the same time—are equally important to the development of Western music.

Many instruments used to perform medieval music still exist in the 21st century, but in different and typically more technologically developed forms. The flute was made of wood in the medieval era rather than silver or other metal, and could be made as a side-blown or end-blown instrument. While modern orchestral flutes are usually made of metal and have complex key mechanisms and airtight pads, medieval flutes had holes that the performer had to cover with the fingers (as with the recorder). The recorder was made of wood during the Medieval era, and despite the fact that in the 2000s, it may be made of synthetic materials, it has more or less retained its past form. The gemshorn is similar to the recorder as it has finger holes on its front, though it is actually a member of the ocarina family. One of the flute's predecessors, the pan flute, was popular in medieval times, and is possibly of Hellenic origin. This instrument's pipes were made of wood, and were graduated in length to produce different pitches.

Medieval music used many plucked string instruments like the lute, a fretted instrument with a pear-shaped hollow body which is the predecessor to the modern guitar. Other plucked stringed instruments included the mandore, gittern, citole and psaltery. The dulcimers, similar in structure to the psaltery and zither, were originally plucked, but musicians began to strike the dulcimer with hammers in the 14th century after the arrival of new metal technology that made metal strings possible.

The bowed lyra of the Byzantine Empire was the first recorded European bowed string instrument. Like the modern violin, a performer produced sound by moving a bow with tensioned hair over tensioned strings. The Persian geographer Ibn Khurradadhbih of the 9th century (d. 911) cited the Byzantine lyra, in his lexicographical discussion of instruments as a bowed instrument equivalent to the Arab rabāb and typical instrument of the Byzantines along with the "urghun" (organ), "shilyani" (probably a type of harp or lyre) and the "salandj" (probably a bagpipe). The hurdy-gurdy was (and still is) a mechanical violin using a rosined wooden wheel attached to a crank to "bow" its strings. Instruments without sound boxes like the jaw harp were also popular. Early versions of the pipe organ, fiddle (or vielle), and a precursor to the modern trombone (called the sackbut) were used.

Medieval music was composed and, for some vocal and instrumental music, improvised for many different music genres (styles of music). Medieval music created for sacred (church use) and secular (non-religious use) was typically written by composers, except for some sacred vocal and secular instrumental music which was improvised (made up on-the-spot). During the earlier medieval period, the liturgical genre, predominantly Gregorian chant done by monks, was monophonic ("monophonic" means a single melodic line, without a harmony part or instrumental accompaniment). Polyphonic genres, in which multiple independent melodic lines are performed simultaneously, began to develop during the high medieval era, becoming prevalent by the later 13th and early 14th century. The development of polyphonic forms, with different voices interweaving, is often associated with the late Medieval Ars nova style which flourished in the 1300s. The Ars Nova, which means "new art" was an innovative style of writing music that served as a key transition from the medieval music style to the more expressive styles of the post-1400s Renaissance music era.

The earliest innovations upon monophonic plainchant were heterophonic. "Heterophony" is the performance of the same melody by two different performers at the same time, in which each performer slightly alters the ornaments she or he is using. Another simple form of heterophony is for singers to sing the same shape of melody, but with one person singing the melody and a second person singing the melody at a higher or lower pitch. Organum, for example, expanded upon plainchant melody using an accompanying line, sung at a fixed interval (often a perfect fifth or perfect fourth away from the main melody), with a resulting alternation between a simple form of polyphony and monophony. The principles of organum date back to an anonymous 9th century tract, the "Musica enchiriadis", which established the tradition of duplicating a preexisting plainchant in parallel motion at the interval of an octave, a fifth or a fourth.

Of greater sophistication was the motet, which developed from the clausula genre of medieval plainchant. The motet would become the most popular form of medieval polyphony. While early motets were liturgical or sacred (designed for use in a church service), by the end of the thirteenth century the genre had expanded to include secular topics, such as courtly love. Courtly love was the respectful veneration of a lady from afar by an amorous, noble man. Many popular motets had lyrics about a man's love and adoration of beautiful, noble and much-admired woman.

The Medieval motet developed during the Renaissance music era (after 1400). During the Renaissance, the Italian secular genre of the Madrigal became popular. Similar to the polyphonic character of the motet, madrigals featured greater fluidity and motion in the leading melody line. The madrigal form also gave rise to polyphonic canons (songs in which multiple singers sing the same melody, but starting at different times), especially in Italy where they were called "caccie." These were three-part secular pieces, which featured the two higher voices in canon, with an underlying instrumental long-note accompaniment.

Finally, purely instrumental music also developed during this period, both in the context of a growing theatrical tradition and for court performances for the aristocracy. Dance music, often improvised around familiar tropes, was the largest purely instrumental genre. The secular Ballata, which became very popular in Trecento Italy, had its origins, for instance, in medieval instrumental dance music.

During the Medieval period the foundation was laid for the notational and theoretical practices that would shape Western music into the norms that developed during the common practice era. The most obvious of these is the development of a comprehensive music notational system; however the theoretical advances, particularly in regard to rhythm and polyphony, are equally important to the development of Western music.

The earliest Medieval music did not have any kind of notational system. The tunes were primarily monophonic (a single melody without accompaniment) and transmitted by oral tradition. As Rome tried to centralize the various liturgies and establish the Roman rite as the primary church tradition the need to transmit these chant melodies across vast distances effectively was equally glaring. So long as music could only be taught to people "by ear," it limited the ability of the church to get different regions to sing the same melodies, since each new person would have to spend time with a person who already knew a song and learn it "by ear." The first step to fix this problem came with the introduction of various signs written above the chant texts to indicate direction of pitch movement, called "neumes".

The origin of "neumes" is unclear and subject to some debate; however, most scholars agree that their closest ancestors are the classic Greek and Roman grammatical signs that indicated important points of declamation by recording the rise and fall of the voice. The two basic signs of the classical grammarians were the "acutus", /, indicating a raising of the voice, and the "gravis", \, indicating a lowering of the voice. A singer reading a chant text with neume markings would be able to get a general sense of whether the melody line went up in pitch, stayed the same, or went down in pitch. For a singer who already knew a song, seeing the written neume markings above the text could help to jog his or her memory about how the melody went. However, a singer reading a chant text with neume markings would not be able to sight read a song which he or she had never heard sung before.

These neumes eventually evolved into the basic symbols for "neumatic" notation, the "virga" (or "rod") which indicates a higher note and still looked like the "acutus" from which it came; and the "punctum" (or "dot") which indicates a lower note and, as the name suggests, reduced the "gravis" symbol to a point. Thus the "acutus" and the "gravis" could be combined to represent graphical vocal inflections on the syllable. This kind of notation seems to have developed no earlier than the eighth century, but by the ninth it was firmly established as the primary method of musical notation. The basic notation of the "virga" and the "punctum" remained the symbols for individual notes, but other "neumes" soon developed which showed several notes joined together. These new "neumes"—called ligatures—are essentially combinations of the two original signs.

The first music notation was the use of dots over the lyrics to a chant, with some dots being higher or lower, giving the reader a general sense of the direction of the melody. However, this form of notation only served as a memory aid for a singer who already knew the melody. This basic "neumatic" notation could only specify the number of notes and whether they moved up or down. There was no way to indicate exact pitch, any rhythm, or even the starting note. These limitations are further indication that the "neumes" were developed as tools to support the practice of oral tradition, rather than to supplant it. However, even though it started as a mere memory aid, the worth of having more specific notation soon became evident.

The next development in musical notation was "heighted "neumes"", in which "neumes" were carefully placed at different heights in relation to each other. This allowed the "neumes" to give a rough indication of the size of a given interval as well as the direction. This quickly led to one or two lines, each representing a particular note, being placed on the music with all of the "neumes" relating back to them. At first, these lines had no particular meaning and instead had a letter placed at the beginning indicating which note was represented. However, the lines indicating middle C and the F a fifth below slowly became most common. Having been at first merely scratched on the parchment, the lines now were drawn in two different colored inks: usually red for F, and yellow or green for C. This was the beginning of the musical staff as we know it today. The completion of the four-line staff is usually credited to Guido d’ Arezzo (c. 1000–1050), one of the most important musical theorists of the Middle Ages. While older sources attribute the development of the staff to Guido, some modern scholars suggest that he acted more as a codifier of a system that was already being developed. Either way, this new notation allowed a singer to learn pieces completely unknown to him in a much shorter amount of time. However, even though chant notation had progressed in many ways, one fundamental problem remained: rhythm. The "neumatic" notational system, even in its fully developed state, did not clearly define any kind of rhythm for the singing of notes.

The music theory of the Medieval period saw several advances over previous practice both in regard to tonal material, texture, and rhythm.

Concerning rhythm, this period had several dramatic changes in both its conception and notation. During the early Medieval period there was no method to notate rhythm, and thus the rhythmical practice of this early music is subject to heated debate among scholars. The first kind of written rhythmic system developed during the 13th century and was based on a series of modes. This rhythmic plan was codified by the music theorist Johannes de Garlandia, author of the "De Mensurabili Musica" (c.1250), the treatise which defined and most completely elucidated these rhythmic modes. In his treatise Johannes de Garlandia describes six "species" of mode, or six different ways in which longs and breves can be arranged. Each mode establishes a rhythmic pattern in beats (or "tempora") within a common unit of three "tempora" (a "perfectio") that is repeated again and again. Furthermore, notation without text is based on chains of "ligature"s (the characteristic notations by which groups of notes are bound to one another).

The rhythmic mode can generally be determined by the patterns of ligatures used. Once a rhythmic mode had been assigned to a melodic line, there was generally little deviation from that mode, although rhythmic adjustments could be indicated by changes in the expected pattern of ligatures, even to the extent of changing to another rhythmic mode. The next step forward concerning rhythm came from the German theorist Franco of Cologne. In his treatise "Ars cantus mensurabilis" ("The Art of Mensurable Music"), written around 1280, he describes a system of notation in which differently shaped notes have entirely different rhythmic values. This is a striking change from the earlier system of de Garlandia. Whereas before the length of the individual note could only be gathered from the mode itself, this new inverted relationship made the mode dependent upon—and determined by—the individual notes or "figurae" that have incontrovertible durational values, an innovation which had a massive impact on the subsequent history of European music. Most of the surviving notated music of the 13th century uses the rhythmic modes as defined by Garlandia. The step in the evolution of rhythm came after the turn of the 13th century with the development of the "Ars Nova" style.

The theorist who is most well recognized in regard to this new style is Philippe de Vitry, famous for writing the "Ars Nova" ("New Art") treatise around 1320. This treatise on music gave its name to the style of this entire era. In some ways the modern system of rhythmic notation began with Vitry, who completely broke free from the older idea of the rhythmic modes. The notational predecessors of modern time meters also originate in the "Ars Nova". This new style was clearly built upon the work of Franco of Cologne. In Franco's system, the relationship between a breve and a semibreves (that is, half breves) was equivalent to that between a breve and a long: and, since for him "modus" was always perfect (grouped in threes), the "tempus" or beat was also inherently perfect and therefore contained three semibreves. Sometimes the context of the mode would require a group of only two semibreves, however, these two semibreves would always be one of normal length and one of double length, thereby taking the same space of time, and thus preserving the perfect subdivision of the "tempus". This ternary division held for all note values. In contrast, the "Ars Nova" period introduced two important changes: the first was an even smaller subdivision of notes (semibreves, could now be divided into "minim"), and the second was the development of "mensuration."

Mensurations could be combined in various manners to produce metrical groupings. These groupings of mensurations are the precursors of simple and compound meter. By the time of "Ars Nova", the perfect division of the "tempus" was not the only option as duple divisions became more accepted. For Vitry the breve could be divided, for an entire composition, or section of one, into groups of two or three smaller semibreves. This way, the "tempus" (the term that came to denote the division of the breve) could be either "perfect" ("tempus perfectum"), with ternary subdivision, or "imperfect" ("tempus imperfectum"), with binary subdivision. In a similar fashion, the semibreve's division (termed "prolation") could be divided into three "minima" ("prolatio perfectus" or major prolation) or two "minima" ("prolatio imperfectus" or minor prolation) and, at the higher level, the longs division (called "modus") could be three or two breves ("modus perfectus" or perfect mode, or "modus imperfectus" or imperfect mode respectively). Vitry took this a step further by indicating the proper division of a given piece at the beginning through the use of a "mensuration sign", equivalent to our modern "time signature".

"Tempus perfectum" was indicated by a circle, while "tempus imperfectum" was denoted by a half-circle (the current symbol , used as an alternative for the time signature, is actually a holdover of this symbol, not a letter "C" as an abbreviation for "common time", as popularly believed). While many of these innovations are ascribed to Vitry, and somewhat present in the "Ars Nova" treatise, it was a contemporary—and personal acquaintance—of de Vitry, named Johannes de Muris (Jehan des Mars) who offered the most comprehensive and systematic treatment of the new mensural innovations of the "Ars Nova" (for a brief explanation of the mensural notation in general, see the article Renaissance music). Many scholars, citing a lack of positive attributory evidence, now consider "Vitry's" treatise to be anonymous, but this does not diminish its importance for the history of rhythmic notation. However, this makes the first definitely identifiable scholar to accept and explain the mensural system to be de Muris, who can be said to have done for it what Garlandia did for the rhythmic modes.

For the duration of the medieval period, most music would be composed primarily in perfect tempus, with special effects created by sections of imperfect tempus; there is a great current controversy among musicologists as to whether such sections were performed with a breve of equal length or whether it changed, and if so, at what proportion. This "Ars Nova" style remained the primary rhythmical system until the highly syncopated works of the "Ars subtilior" at the end of the 14th century, characterized by extremes of notational and rhythmic complexity. This sub-genera pushed the rhythmic freedom provided by "Ars Nova" to its limits, with some compositions having different voices written in different mensurations simultaneously. The rhythmic complexity that was realized in this music is comparable to that in the 20th century.

Of equal importance to the overall history of western music theory were the textural changes that came with the advent of polyphony. This practice shaped western music into the harmonically dominated music that we know today. The first accounts of this textural development were found in two anonymous yet widely circulated treatises on music, the "Musica" and the "Scolica enchiriadis". These texts are dated to sometime within the last half of the ninth century. The treatises describe a technique that seemed already to be well established in practice. This early polyphony is based on three simple and three compound intervals. The first group comprises fourths, fifths, and octaves; while the second group has octave-plus-fourths, octave-plus-fifths, and double octaves. This new practice is given the name "organum" by the author of the treatises. "Organum" can further be classified depending on the time period in which it was written. The early "organum" as described in the "enchiriadis" can be termed "strict "organum"" Strict "organum" can, in turn, be subdivided into two types: "diapente" (organum at the interval of a fifth) and "diatesseron" (organum at the interval of a fourth). However, both of these kinds of strict "organum" had problems with the musical rules of the time. If either of them paralleled an original chant for too long (depending on the mode) a tritone would result.

This problem was somewhat overcome with the use of a second type of "organum". This second style of "organum" was called "free "organum"". Its distinguishing factor is that the parts did not have to move only in parallel motion, but could also move in oblique, or contrary motion. This made it much easier to avoid the dreaded tritone. The final style of "organum" that developed was known as "melismatic "organum"", which was a rather dramatic departure from the rest of the polyphonic music up to this point. This new style was not note against note, but was rather one sustained line accompanied by a florid melismatic line. This final kind of "organum" was also incorporated by the most famous polyphonic composer of this time—Léonin. He united this style with measured discant passages, which used the rhythmic modes to create the pinnacle of "organum" composition. This final stage of "organum" is sometimes referred to as Notre Dame school of polyphony, since that was where Léonin (and his student Pérotin) were stationed. Furthermore, this kind of polyphony influenced all subsequent styles, with the later polyphonic genera of motets starting as a trope of existing Notre Dame "organums".

Another important element of Medieval music theory was the system by which pitches were arranged and understood. During the Middle Ages, this systematic arrangement of a series of whole steps and half steps, what we now call a scale, was known as a mode. The modal system worked like the scales of today, insomuch that it provided the rules and material for melodic writing. The eight church modes are: "Dorian", "Hypodorian", "Phrygian", "Hypophrygian", "Lydian", "Hypolydian", "Mixolydian", and "Hypomixolydian". Much of the information concerning these modes, as well as the practical application of them, was codified in the 11th century by the theorist Johannes Afflighemensis. In his work he describes three defining elements to each mode: the final (or "finalis)", the reciting tone ("tenor" or "confinalis"), and the range (or "ambitus"). The "finalis" is the tone that serves as the focal point for the mode and, as the name suggests, is almost always used as the final tone. The reciting tone is the tone that serves as the primary focal point in the melody (particularly internally). It is generally also the tone most often repeated in the piece, and finally the range delimits the upper and lower tones for a given mode. The eight modes can be further divided into four categories based on their final ("finalis").

Medieval theorists called these pairs "maneriae" and labeled them according to the Greek ordinal numbers. Those modes that have d, e, f, and g as their final are put into the groups "protus", "deuterus", "tritus", and "tetrardus" respectively. These can then be divided further based on whether the mode is "authentic" or "plagal." These distinctions deal with the range of the mode in relation to the final. The authentic modes have a range that is about an octave (one tone above or below is allowed) and start on the final, whereas the plagal modes, while still covering about an octave, start a perfect fourth below the authentic. Another interesting aspect of the modal system is the universal allowance for altering B to B no matter what the mode. The inclusion of this tone has several uses, but one that seems particularly common is in order to avoid melodic difficulties caused, once again, by the tritone.

These ecclesiastical modes, although they have Greek names, have little relationship to the modes as set out by Greek theorists. Rather, most of the terminology seems to be a misappropriation on the part of the medieval theorists Although the church modes have no relation to the ancient Greek modes, the overabundance of Greek terminology does point to an interesting possible origin in the liturgical melodies of the Byzantine tradition. This system is called "octoechos" and is also divided into eight categories, called "echoi". 
For specific medieval music theorists, see also: Isidore of Seville, Aurelian of Réôme, Odo of Cluny, Guido of Arezzo, Hermannus Contractus, Johannes Cotto (Johannes Afflighemensis), Johannes de Muris, Franco of Cologne, Johannes de Garlandia (Johannes Gallicus), Anonymous IV, Marchetto da Padova (Marchettus of Padua), Jacques of Liège, Johannes de Grocheo, Petrus de Cruce (Pierre de la Croix), and Philippe de Vitry.

Chant (or plainsong) is a monophonic sacred (single, unaccompanied melody) form which represents the earliest known music of the Christian church. Chant developed separately in several European centres. Although the most important were Rome, Hispania, Gaul, Milan, and Ireland, there were others as well. These styles were all developed to support the regional liturgies used when celebrating the Mass there. Each area developed its own chant and rules for celebration. In Spain and Portugal, Mozarabic chant was used and shows the influence of North African music. The Mozarabic liturgy even survived through Muslim rule, though this was an isolated strand and this music was later suppressed in an attempt to enforce conformity on the entire liturgy. In Milan, Ambrosian chant, named after St. Ambrose, was the standard, while Beneventan chant developed around Benevento, another Italian liturgical center. Gallican chant was used in Gaul, and Celtic chant in Ireland and Great Britain.

Around AD 1011, the Roman Catholic Church wanted to standardize the Mass and chant across its empire. At this time, Rome was the religious centre of western Europe, and Paris was the political centre. The standardization effort consisted mainly of combining these two (Roman and Gallican) regional liturgies. Pope Gregory I and Charlemagne sent trained singers throughout the Holy Roman Empire to teach this new form of chant. This body of chant became known as Gregorian Chant, named after Pope Gregory I. By the 12th and 13th centuries, Gregorian chant had superseded all the other Western chant traditions, with the exception of the Ambrosian chant in Milan and the Mozarabic chant in a few specially designated Spanish chapels. Hildegard von Bingen (1098–1179) was the earliest known female composer. She wrote many monophonic works for the Catholic Church, almost all of them for female voices.

Around the end of the 9th century, singers in monasteries such as St. Gall in Switzerland began experimenting with adding another part to the chant, generally a voice in parallel motion, singing mostly in perfect fourths or fifths above the original tune (see interval). This development is called organum and represents the beginnings of counterpoint and, ultimately, harmony. Over the next several centuries, organum developed in several ways.

The most significant of these developments was the creation of "florid organum" around 1100, sometimes known as the school of St. Martial (named after a monastery in south-central France, which contains the best-preserved manuscript of this repertory). In "florid organum" the original tune would be sung in long notes while an accompanying voice would sing many notes to each one of the original, often in a highly elaborate fashion, all the while emphasizing the perfect consonances (fourths, fifths and octaves), as in the earlier organa. Later developments of organum occurred in England, where the interval of the third was particularly favoured, and where organa were likely improvised against an existing chant melody, and at Notre Dame in Paris, which was to be the centre of musical creative activity throughout the thirteenth century.

Much of the music from the early medieval period is anonymous. Some of the names may have been poets and lyric writers, and the tunes for which they wrote words may have been composed by others. Attribution of monophonic music of the medieval period is not always reliable. Surviving manuscripts from this period include the Musica Enchiriadis, Codex Calixtinus of Santiago de Compostela, the Magnus Liber, and the Winchester Troper. For information about specific composers or poets writing during the early medieval period, see Pope Gregory I, St. Godric, Hildegard of Bingen, Hucbald, Notker Balbulus, Odo of Arezzo, Odo of Cluny, and Tutilo.

Another musical tradition of Europe originating during the early Middle Ages was the liturgical drama. In its original form, it may represent a survival of Roman drama with Christian stories—mainly the Gospel, the Passion, and the lives of the saints—grafted on. Every part of Europe had some sort of tradition of musical or semi-musical drama in the Middle Ages, involving acting, speaking, singing and instrumental accompaniment in some combination. These dramas were probably performed by travelling actors and musicians. Many have been preserved sufficiently to allow modern reconstruction and performance (for example the "Play of Daniel", which has been recently recorded at least ten times).

The Goliards were itinerant poet-musicians of Europe from the tenth to the middle of the thirteenth century. Most were scholars or ecclesiastics, and they wrote and sang in Latin. Although many of the poems have survived, very little of the music has. They were possibly influential—even decisively so—on the troubadour-trouvère tradition which was to follow. Most of their poetry is secular and, while some of the songs celebrate religious ideals, others are frankly profane, dealing with drunkenness, debauchery and lechery. One of the most important extant sources of Goliards chansons is the Carmina Burana.

The flowering of the Notre Dame school of polyphony from around 1150 to 1250 corresponded to the equally impressive achievements in Gothic architecture: indeed the centre of activity was at the cathedral of Notre Dame itself. Sometimes the music of this period is called the Parisian school, or Parisian organum, and represents the beginning of what is conventionally known as "Ars antiqua". This was the period in which rhythmic notation first appeared in western music, mainly a context-based method of rhythmic notation known as the rhythmic modes.

This was also the period in which concepts of formal structure developed which were attentive to proportion, texture, and architectural effect. Composers of the period alternated florid and discant organum (more note-against-note, as opposed to the succession of many-note melismas against long-held notes found in the florid type), and created several new musical forms: clausulae, which were melismatic sections of organa extracted and fitted with new words and further musical elaboration; conductus, which was a song for one or more voices to be sung rhythmically, most likely in a procession of some sort; and tropes, which were additions of new words and sometimes new music to sections of older chant. All of these genres save one were based upon chant; that is, one of the voices, (usually three, though sometimes four) nearly always the lowest (the tenor at this point) sang a chant melody, though with freely composed note-lengths, over which the other voices sang organum. The exception to this method was the conductus, a two-voice composition that was freely composed in its entirety.

The motet, one of the most important musical forms of the high Middle Ages and Renaissance, developed initially during the Notre Dame period out of the clausula, especially the form using multiple voices as elaborated by Pérotin, who paved the way for this particularly by replacing many of his predecessor (as canon of the cathedral) Léonin's lengthy florid clausulae with substitutes in a discant style. Gradually, there came to be entire books of these substitutes, available to be fitted in and out of the various chants. Since, in fact, there were more than can possibly have been used in context, it is probable that the clausulae came to be performed independently, either in other parts of the mass, or in private devotions. The clausulae, thus practised, became the motet when troped with non-liturgical words, and were further developed into a form of great elaboration, sophistication and subtlety in the fourteenth century, the period of "Ars nova". Surviving manuscripts from this era include the Montpellier Codex, Bamberg Codex, and Las Huelgas Codex.

Composers of this time include Léonin, Pérotin, W. de Wycombe, Adam de St. Victor, and Petrus de Cruce (Pierre de la Croix). Petrus is credited with the innovation of writing more than three semibreves to fit the length of a breve. Coming before the innovation of imperfect tempus, this practice inaugurated the era of what are now called "Petronian" motets. These late 13th-century works are in three to four parts and have multiple texts sung simultaneously. Originally, the tenor line (from the Latin "tenere", "to hold") held a preexisting liturgical chant line in the original Latin, while the text of the one, two, or even three voices above, called the "voces organales", provided commentary on the liturgical subject either in Latin or in the vernacular French. The rhythmic values of the "voces organales" decreased as the parts multiplied, with the "duplum" (the part above the tenor) having smaller rhythmic values than the tenor, the "triplum" (the line above the "duplum") having smaller rhythmic values than the "duplum", and so on. As time went by, the texts of the "voces organales" became increasingly secular in nature and had less and less overt connection to the liturgical text in the tenor line.

The Petronian motet is a highly complex genre, given its mixture of several semibreve breves with rhythmic modes and sometimes (with increasing frequency) substitution of secular songs for chant in the tenor. Indeed, ever-increasing rhythmic complexity would be a fundamental characteristic of the 14th century, though music in France, Italy, and England would take quite different paths during that time.

The Cantigas de Santa Maria ("Canticles of Holy Mary"; , ) are 420 poems with musical notation, written in Galician-Portuguese during the reign of Alfonso X "El Sabio" (1221–1284) and often attributed to him. It is one of the largest collections of monophonic (solo) songs from the Middle Ages and is characterized by the mention of the Virgin Mary in every song, while every tenth song is a hymn. The manuscripts have survived in four codices: two at El Escorial, one at Madrid's National Library, and one in Florence, Italy. Some have colored miniatures showing pairs of musicians playing a wide variety of instruments.

The music of the troubadours and trouvères was a vernacular tradition of monophonic secular song, probably accompanied by instruments, sung by professional, occasionally itinerant, musicians who were as skilled as poets as they were singers and instrumentalists. The language of the troubadours was Occitan (also known as the langue d'oc, or Provençal); the language of the trouvères was Old French (also known as langue d'oil). The period of the troubadours corresponded to the flowering of cultural life in Provence which lasted through the twelfth century and into the first decade of the thirteenth. Typical subjects of troubadour song were war, chivalry and courtly love—the love of an idealized woman from afar. The period of the troubadours wound down after the Albigensian Crusade, the fierce campaign by Pope Innocent III to eliminate the Cathar heresy (and northern barons' desire to appropriate the wealth of the south). Surviving troubadours went either to Portugal, Spain, northern Italy or northern France (where the trouvère tradition lived on), where their skills and techniques contributed to the later developments of secular musical culture in those places.

The trouvères and troubadours shared similar musical styes, but the trouvères were generally noblemen. The music of the trouvères was similar to that of the troubadours, but was able to survive into the thirteenth century unaffected by the Albigensian Crusade. Most of the more than two thousand surviving trouvère songs include music, and show a sophistication as great as that of the poetry it accompanies.

The Minnesinger tradition was the Germanic counterpart to the activity of the troubadours and trouvères to the west. Unfortunately, few sources survive from the time; the sources of Minnesang are mostly from two or three centuries after the peak of the movement, leading to some controversy over the accuracy of these sources. Among the Minnesingers with surviving music are Wolfram von Eschenbach, Walther von der Vogelweide, and Niedhart von Reuenthal.

In the Middle Ages, Galician-Portuguese was the language used in nearly all of Iberia for lyric poetry. From this language derive both modern Galician and Portuguese. The Galician-Portuguese school, which was influenced to some extent (mainly in certain formal aspects) by the Occitan troubadours, is first documented at the end of the twelfth century and lasted until the middle of the fourteenth.

The earliest extant composition in this school is usually agreed to be Ora faz ost' o senhor de Navarra by the Portuguese João Soares de Paiva, usually dated just before or after 1200. The troubadours of the movement, not to be confused with the Occitan troubadours (who frequented courts in nearby León and Castile), wrote almost entirely cantigas. Beginning probably around the middle of the thirteenth century, these songs, known also as cantares or trovas, began to be compiled in collections known as cancioneiros (songbooks). Three such anthologies are known: the Cancioneiro da Ajuda, the Cancioneiro Colocci-Brancuti (or Cancioneiro da Biblioteca Nacional de Lisboa), and the Cancioneiro da Vaticana. In addition to these there is the priceless collection of over 400 Galician-Portugues cantigas in the Cantigas de Santa Maria, which tradition attributes to Alfonso X.

The Galician-Portuguese cantigas can be divided into three basic genres: male-voiced love poetry, called cantigas de amor (or cantigas d'amor) female-voiced love poetry, called cantigas de amigo (cantigas d'amigo); and poetry of insult and mockery called cantigas d'escarnho e de mal dizer. All three are lyric genres in the technical sense that they were strophic songs with either musical accompaniment or introduction on a stringed instrument. But all three genres also have dramatic elements, leading early scholars to characterize them as lyric-dramatic.

The origins of the cantigas d'amor are usually traced to Provençal and Old French lyric poetry, but formally and rhetorically they are quite different. The cantigas d'amigo are probably rooted in a native song tradition (; ), though this view has been contested. The cantigas d'escarnho e maldizer may also (according to Lang) have deep local roots. The latter two genres (totalling around 900 texts) make the Galician-Portuguese lyric unique in the entire panorama of medieval Romance poetry.


The beginning of the "Ars nova" is one of the few clear chronological divisions in medieval music, since it corresponds to the publication of the "Roman de Fauvel", a huge compilation of poetry and music, in 1310 and 1314. The "Roman de Fauvel" is a satire on abuses in the medieval church, and is filled with medieval motets, lais, rondeaux and other new secular forms. While most of the music is anonymous, it contains several pieces by Philippe de Vitry, one of the first composers of the isorhythmic motet, a development which distinguishes the fourteenth century. The isorhythmic motet was perfected by Guillaume de Machaut, the finest composer of the time.

During the "Ars nova" era, secular music acquired a polyphonic sophistication formerly found only in sacred music, a development not surprising considering the secular character of the early Renaissance (while this music is typically considered "medieval", the social forces that produced it were responsible for the beginning of the literary and artistic Renaissance in Italy—the distinction between Middle Ages and Renaissance is a blurry one, especially considering arts as different as music and painting). The term ""Ars nova"" (new art, or new technique) was coined by Philippe de Vitry in his treatise of that name (probably written in 1322), in order to distinguish the practice from the music of the immediately preceding age.

The dominant secular genre of the Ars Nova was the "chanson", as it would continue to be in France for another two centuries. These chansons were composed in musical forms corresponding to the poetry they set, which were in the so-called "formes fixes" of "rondeau", "ballade", and "virelai". These forms significantly affected the development of musical structure in ways that are felt even today; for example, the "ouvert-clos" rhyme-scheme shared by all three demanded a musical realization which contributed directly to the modern notion of antecedent and consequent phrases. It was in this period, too, in which began the long tradition of setting the mass ordinary. This tradition started around mid-century with isolated or paired settings of Kyries, Glorias, etc., but Machaut composed what is thought to be the first complete mass conceived as one composition. The sound world of Ars Nova music is very much one of linear primacy and rhythmic complexity. "Resting" intervals are the fifth and octave, with thirds and sixths considered dissonances. Leaps of more than a sixth in individual voices are not uncommon, leading to speculation of instrumental participation at least in secular performance. Surviving French manuscripts include the Ivrea Codex and the Apt Codex.

For information about specific French composers writing in late medieval era, see Jehan de Lescurel, Philippe de Vitry, Guillaume de Machaut, Borlet, Solage, and François Andrieu.

Most of the music of "Ars nova" was French in origin; however, the term is often loosely applied to all of the music of the fourteenth century, especially to include the secular music in Italy. There this period was often referred to as "Trecento". Italian music has alway been known for its lyrical or melodic character, and this goes back to the 14th century in many respects. Italian secular music of this time (what little surviving liturgical music there is, is similar to the French except for somewhat different notation) featured what has been called the "cantalina" style, with a florid top voice supported by two (or even one; a fair amount of Italian Trecento music is for only two voices) that are more regular and slower moving. This type of texture remained a feature of Italian music in the popular 15th and 16th century secular genres as well, and was an important influence on the eventual development of the trio texture that revolutionized music in the 17th.

There were three main forms for secular works in the Trecento. One was the madrigal, not the same as that of 150–250 years later, but with a verse/refrain-like form. Three-line stanzas, each with different words, alternated with a two-line "ritornello", with the same text at each appearance. Perhaps we can see the seeds of the subsequent late-Renaissance and Baroque ritornello in this device; it too returns again and again, recognizable each time, in contrast with its surrounding disparate sections. Another form, the "caccia" ("chase,") was written for two voices in a canon at the unison. Sometimes, this form also featured a ritornello, which was occasionally also in a canonic style. Usually, the name of this genre provided a double meaning, since the texts of caccia were primarily about hunts and related outdoor activities, or at least action-filled scenes. The third main form was the "ballata", which was roughly equivalent to the French "virelai".

Surviving Italian manuscripts include the Squarcialupi Codex and the Rossi Codex. For information about specific Italian composers writing in the late medieval era, see Francesco Landini, Gherardello da Firenze, Andrea da Firenze, Lorenzo da Firenze, Giovanni da Firenze (aka Giovanni da Cascia), Bartolino da Padova, Jacopo da Bologna, Donato da Cascia, Lorenzo Masini, Niccolò da Perugia, and Maestro Piero.

The Geisslerlieder were the songs of wandering bands of flagellants, who sought to appease the wrath of an angry God by penitential music accompanied by mortification of their bodies. There were two separate periods of activity of Geisslerlied: one around the middle of the thirteenth century, from which, unfortunately, no music survives (although numerous lyrics do); and another from 1349, for which both words and music survive intact due to the attention of a single priest who wrote about the movement and recorded its music. This second period corresponds to the spread of the Black Death in Europe, and documents one of the most terrible events in European history. Both periods of Geisslerlied activity were mainly in Germany.

As often seen at the end of any musical era, the end of the medieval era is marked by a highly manneristic style known as "Ars subtilior". In some ways, this was an attempt to meld the French and Italian styles. This music was highly stylized, with a rhythmic complexity that was not matched until the 20th century. In fact, not only was the rhythmic complexity of this repertoire largely unmatched for five and a half centuries, with extreme syncopations, mensural trickery, and even examples of "augenmusik" (such as a chanson by Baude Cordier written out in manuscript in the shape of a heart), but also its melodic material was quite complex as well, particularly in its interaction with the rhythmic structures. Already discussed under Ars Nova has been the practice of isorhythm, which continued to develop through late-century and in fact did not achieve its highest degree of sophistication until early in the 15th century. Instead of using isorhythmic techniques in one or two voices, or trading them among voices, some works came to feature a pervading isorhythmic texture which rivals the integral serialism of the 20th century in its systematic ordering of rhythmic and tonal elements. The term "mannerism" was applied by later scholars, as it often is, in response to an impression of sophistication being practised for its own sake, a malady which some authors have felt infected the "Ars subtilior".

One of the most important extant sources of Ars Subtilior chansons is the Chantilly Codex. For information about specific composers writing music in "Ars subtilior" style, see Anthonello de Caserta, Philippus de Caserta (aka Philipoctus de Caserta), Johannes Ciconia, Matteo da Perugia, Lorenzo da Firenze, Grimace, Jacob Senleches, and Baude Cordier.

Demarcating the end of the medieval era and the beginning of the Renaissance era, with regard to the composition of music, is difficult. While the music of the fourteenth century is fairly obviously medieval in conception, the music of the early fifteenth century is often conceived as belonging to a transitional period, not only retaining some of the ideals of the end of the Middle Ages (such as a type of polyphonic writing in which the parts differ widely from each other in character, as each has its specific textural function), but also showing some of the characteristic traits of the Renaissance (such as the increasingly international style developing through the diffusion of Franco-Flemish musicians throughout Europe, and in terms of texture an increasing equality of parts). Music historians do not agree on when the Renaissance era began, but most historians agree that England was still a medieval society in the early fifteenth century (see periodization issues of the Middle Ages). While there is no consensus, 1400 is a useful marker, because it was around that time that the Renaissance came into full swing in Italy.

The increasing reliance on the interval of the third as a consonance is one of the most pronounced features of transition into the Renaissance. Polyphony, in use since the 12th century, became increasingly elaborate with highly independent voices throughout the 14th century. With John Dunstaple and other English composers, partly through the local technique of faburden (an improvisatory process in which a chant melody and a written part predominantly in parallel sixths above it are ornamented by one sung in perfect fourths below the latter, and which later took hold on the continent as "fauxbordon"), the interval of the third emerges as an important musical development; because of this "Contenance Angloise" ("English countenance"), English composers' music is often regarded as the first to sound less truly bizarre to 2000s-era audiences who are not trained in music history.

English stylistic tendencies in this regard had come to fruition and began to influence continental composers as early as the 1420s, as can be seen in works of the young Dufay, among others. While the Hundred Years' War continued, English nobles, armies, their chapels and retinues, and therefore some of their composers, travelled in France and performed their music there; it must also of course be remembered that the English controlled portions of northern France at this time. English manuscripts include the Worcester Fragments, the Old St. Andrews Music Book, the Old Hall Manuscript, and Egerton Manuscript. For information about specific composers who are considered transitional between the medieval and the Renaissance, see Zacara da Teramo, Paolo da Firenze, Giovanni Mazzuoli, Antonio da Cividale, Antonius Romanus, Bartolomeo da Bologna, Roy Henry, Arnold de Lantins, Leonel Power, and John Dunstaple.

An early composer from the Franco-Flemish School of the Renaissance was Johannes Ockeghem (1410/1425 –1497). He was the most famous member of the Franco-Flemish School in the last half of the 15th century, and is often considered the most influential composer between Dufay and Josquin des Prez. Ockeghem probably studied with Gilles Binchois, and at least was closely associated with him at the Burgundian court. Antoine Busnois wrote a motet in honor of Ockeghem. Ockeghem is a direct link from the Burgundian style to the next generation of Netherlanders, such as Obrecht and Josquin. A strong influence on Josquin des Prez and the subsequent generation of Netherlanders, Ockeghem was famous throughout Europe Charles VII for his expressive music, although he was equally renowned for his technical prowess.

The Schola Cantorum Basiliensis, university for old music in Basel, Switzerland, provides a full-time practical study course for the music of the Middle Ages.

A two-year vocational training for musicians is offered at the academy Burg Fürsteneck in Germany.

Kees Boeke coordinates a new Master of Music- Musik des Mittelalters und des Renaissance for both singers and instrumentalists in the Staatliche Hochschule für Musik Trossingen, also in Germany.

The musical styles of Léonin and Pérotin influenced 20th century minimalist composers such as Steve Reich.






</doc>
<doc id="19957" url="https://en.wikipedia.org/wiki?curid=19957" title="Maser">
Maser

A maser (, an acronym for "microwave amplification by stimulated emission of radiation") is a device that produces coherent electromagnetic waves through amplification by stimulated emission. The first maser was built by Charles H. Townes, James P. Gordon, and H. J. Zeiger at Columbia University in 1953. Townes, Nikolay Basov and Alexander Prokhorov were awarded the 1964 Nobel Prize in Physics for theoretical work leading to the maser. Masers are used as the timekeeping device in atomic clocks, and as extremely low-noise microwave amplifiers in radio telescopes and deep space spacecraft communication ground stations.

Modern masers can be designed to generate electromagnetic waves at not only microwave frequencies but also radio and infrared frequencies. For this reason Charles Townes suggested replacing "microwave" with the word "molecular" as the first word in the acronym "maser".

The laser works by the same principle as the maser, but produces higher frequency coherent radiation at visible wavelengths. The maser was the forerunner of the laser, inspiring theoretical work by Townes and Arthur Leonard Schawlow that led to the invention of the laser in 1960. When the coherent optical oscillator was first imagined in 1957, it was originally called the "optical maser". This was ultimately changed to laser for "Light Amplification by Stimulated Emission of Radiation". Gordon Gould is credited with creating this acronym in 1957.

The theoretical principles governing the operation of a maser were first described by Joseph Weber of the University of Maryland at the Electron Tube Research Conference in 1952 in Ottawa, with a summary published in the June 1953 Transactions of the Institute of Radio Engineers Professional Group on Electron Devices, and simultaneously by Nikolay Basov and Alexander Prokhorov from Lebedev Institute of Physics at an "All-Union Conference on Radio-Spectroscopy" held by the USSR Academy of Sciences in May 1952, subsequently published in October 1954.

Independently, Charles Hard Townes, James P. Gordon, and H. J. Zeiger built the first ammonia maser at Columbia University in 1953. This device used stimulated emission in a stream of energized ammonia molecules to produce amplification of microwaves at a frequency of about 24.0 gigahertz. Townes later worked with Arthur L. Schawlow to describe the principle of the "optical maser", or "laser", of which Theodore H. Maiman created the first working model in 1960.

For their research in the field of stimulated emission, Townes, Basov and Prokhorov were awarded the Nobel Prize in Physics in 1964.

The maser is based on the principle of stimulated emission proposed by Albert Einstein in 1917. When atoms have been induced into an excited energy state, they can amplify radiation at a frequency particular to the element or molecule used as the masing medium (similar to what occurs in the lasing medium in a laser).

By putting such an amplifying medium in a resonant cavity, feedback is created that can produce coherent radiation.


In 2012, a research team from the National Physical Laboratory and Imperial College London developed a solid-state maser that operated at room temperature by using optically pumped, pentacene-doped p-Terphenyl as the amplifier medium. It produced pulses of maser emission lasting for a few hundred microseconds. 

In 2018, a research team from Imperial College London and University College London demonstrated continuous-wave maser oscillation using synthetic diamonds containing Nitrogen-Vacancy defects.

Masers serve as high precision frequency references. These "atomic frequency standards" are one of the many forms of atomic clocks. They are often used as low-noise microwave amplifiers in radio telescopes.

, the most important type of maser is the hydrogen maser which is currently used as an atomic frequency standard. Together with other kinds of atomic clocks, these help make up the International Atomic Time standard ("Temps Atomique International" or "TAI" in French). This is the international time scale coordinated by the International Bureau of Weights and Measures.

Norman Ramsey and his colleagues first conceived of the maser as a timing standard. More recent masers are practically identical to their original design. Maser oscillations rely on the stimulated emission between two hyperfine energy levels of atomic hydrogen. Here is a brief description of how they work:


Maser-like stimulated emission has also been observed in nature from interstellar space, and it is frequently called "superradiant emission" to distinguish it from laboratory masers. Such emission is observed from molecules such as water (HO), hydroxyl radicals (OH), methanol (CHOH), formaldehyde (CHO), and silicon monoxide (SiO). Water molecules in star-forming regions can undergo a population inversion and emit radiation at about 22.0 GHz, creating the brightest spectral line in the radio universe. Some water masers also emit radiation from a rotational transition at a frequency of 96 GHz.

Extremely powerful masers, associated with active galactic nuclei, are known as megamasers and are up to a million times more powerful than stellar masers.

The meaning of the term "maser" has changed slightly since its introduction. Initially the acronym was universally given as "microwave amplification by stimulated emission of radiation", which described devices which emitted in the microwave region of the electromagnetic spectrum.

The principle and concept of stimulated emission has since been extended to more devices and frequencies. Thus, the original acronym is sometimes modified, as suggested by Charles H. Townes, to ""molecular" amplification by stimulated emission of radiation." Some have asserted that Townes's efforts to extend the acronym in this way were primarily motivated by the desire to increase the importance of his invention, and his reputation in the scientific community. 

When the laser was developed, Townes and Schawlow and their colleagues at Bell Labs pushed the use of the term "optical maser", but this was largely abandoned in favor of "laser", coined by their rival Gordon Gould. In modern usage, devices that emit in the X-ray through infrared portions of the spectrum are typically called lasers, and devices that emit in the microwave region and below are commonly called "masers", regardless of whether they emit microwaves or other frequencies.

Gould originally proposed distinct names for devices that emit in each portion of the spectrum, including "grasers" (gamma ray lasers), "xasers" (x-ray lasers), "uvasers" (ultraviolet lasers), " lasers" (visible lasers), "irasers" (infrared lasers), "masers" (microwave masers), and "rasers" (RF masers). Most of these terms never caught on, however, and all have now become (apart from in science fiction) obsolete except for "maser" and "laser".

During the early 1960s, the Jet Propulsion Laboratory developed a maser to provide ultra-low-noise amplification of S-band microwave signals received from deep space probes. This maser used deeply refrigerated hydrogen to chill the amplifier down to a temperature of four kelvin. Amplification was achieved by exciting a ruby comb with a 12.0 gigahertz klystron. In the early years, it took days to chill and remove the impurities from the hydrogen lines. Refrigeration was a two-stage process with a large Linde unit on the ground, and a crosshead compressor within the antenna. The final injection was at through a micrometer-adjustable entry to the chamber. The whole system noise temperature looking at cold sky (2.7 kelvins in the microwave band) was 17 kelvins. This gave such a low noise figure that the Mariner IV space probe could send still pictures from Mars back to the Earth even though the output power of its radio transmitter was only 15 watts, and hence the total signal power received was only -169 decibels with respect to a milliwatt (dBm).





</doc>
<doc id="19958" url="https://en.wikipedia.org/wiki?curid=19958" title="Mario Botta">
Mario Botta

Mario Botta (born April 1, 1943) is a Swiss architect. He studied at the Liceo Artistico in Milan and the IUAV in Venice. His ideas were influenced by Le Corbusier, Carlo Scarpa, Louis Kahn. He opened his own practice in 1970 in Lugano.

Botta designed his first buildings at age 16, a two-family house at Morbio Superiore in Ticino. While the arrangements of spaces in this structure is inconsistent, its relationship to its site, separation of living from service spaces, and deep window recesses echo of what would become his stark, strong, towering style. His designs tend to include a strong sense of geometry, often being based on very simple shapes, yet creating unique volumes of space. His buildings are often made of brick, yet his use of material is wide, varied, and often unique.

His trademark style can be seen widely in Switzerland particularly the Ticino region and also in the Mediatheque in Villeurbanne (1988), a cathedral in Évry (1995), and the San Francisco Museum of Modern Art or SFMOMA (1994). He also designed the Europa-Park Dome, which houses many major events at the Europa-Park theme park resort in Germany. Religious works by Botta, including the Cymbalista Synagogue and Jewish Heritage Center were shown in London at the Royal Institute of British Architects in an exhibition entitled, "Architetture del Sacro: Prayers in Stone." “A church is the place, par excellence, of architecture,” he said in an interview with architectural historian Judith Dupré. “When you enter a church, you already are part of what has transpired and will transpire there. The church is a house that puts a believer in a dimension where he or she is the protagonist. The sacred directly lives in the collective. Man becomes a participant in a church, even if he never says anything.”

In 1998, he designed the new bus station for Vimercate (near Milan), a red brick building linked to many facilities, underlining the city's recent development.
He worked at La Scala's theatre renovation, which proved controversial as preservationists feared that historic details would be lost. 

In 2004, he designed Museum One of the Leeum, Samsung Museum of Art in Seoul, South Korea. On January 1, 2006 he received the Grand Officer award from President of the Italian Republic Carlo Azeglio Ciampi. In 2006 he designed his first ever spa, the Bergoase Spa in Arosa, Switzerland. The spa opened in December 2006 and cost an estimated CHF 35 million. Mario Botta participated in the Stock Exchange of Visions project in 2007. He was a member of the Jury of the Global Holcim Awards in 2012.




</doc>
