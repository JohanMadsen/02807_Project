<doc id="23476" url="https://en.wikipedia.org/wiki?curid=23476" title="Plea bargain">
Plea bargain

The plea bargain (also plea agreement, plea deal, copping a plea, or plea in mitigation) is any agreement in a criminal case between the prosecutor and defendant whereby the defendant agrees to plead guilty to a particular charge in return for some concession from the prosecutor. This may mean that the defendant will plead guilty to a less serious charge, or to one of the several charges, in return for the dismissal of other charges; or it may mean that the defendant will plead guilty to the original criminal charge in return for a more lenient sentence.

A plea bargain allows both parties to avoid a lengthy criminal trial and may allow criminal defendants to avoid the risk of conviction at trial on a more serious charge. For example, in the U.S. legal system, a criminal defendant charged with a felony theft charge, the conviction of which would require imprisonment in state prison, may be offered the opportunity to plead guilty to a misdemeanor theft charge, which may not carry a custodial sentence.

In cases such as an automobile collision when there is a potential for civil liability against the defendant, the defendant may agree to plead no contest or "guilty with a civil reservation", which essentially is a guilty plea without admitting civil liability.

Plea bargaining can present a dilemma to defense attorneys, in that they must choose between vigorously seeking a good deal for their present client, or maintaining a good relationship with the prosecutor for the sake of helping future clients. However, defense attorneys are required by the ethics of the bar to defend the present client's interests over the interests of others. Violation of this rule may result in disciplinary sanctions being imposed against the defense attorney by the appropriate state's bar association.

In charge bargaining, defendants plead guilty to a less serious crime than the original charge. In count bargaining, they plead guilty to a subset of multiple original charges. In sentence bargaining, they plead guilty agreeing in advance what sentence will be given; however, this sentence can still be denied by the judge. In fact bargaining, defendants plead guilty but the prosecutor agrees to stipulate (i.e., to affirm or concede) certain facts that will affect how the defendant is punished under the sentencing guidelines.

Plea bargaining has been defended as a voluntary exchange that leaves both parties better off, in that defendants have many procedural and substantive rights, but by pleading guilty, defendants "sell" these rights to the prosecutor. For a defendant who believes that conviction is almost certain, a discount to the sentence is more useful than an unlikely chance of acquittal. For the prosecutor, it means that a conviction is guaranteed. By allowing a quicker trial, it saves money and resources for the courts and prosecutors. It also means that victims and witnesses do not have to testify at the trial, which in some cases can be traumatic.

Plea bargaining is criticized, particularly outside the United States, on the grounds that its close relationship with rewards, threats and coercion potentially endanger the correct legal outcome.

Author Martin Yant discusses the use of coercion in plea bargaining:

Even when the charges are more serious, prosecutors often can still bluff defense attorneys and their clients into pleading guilty to a lesser offense. As a result, people who might have been acquitted because of lack of evidence, but also who are in fact truly innocent, will often plead guilty to the charge. Why? In a word, fear. And the more numerous and serious the charges, studies have shown, the greater the fear. That explains why prosecutors sometimes seem to file every charge imaginable against defendants.

This tactic is prohibited in some other countries—for example in the United Kingdom the prosecutor's code states:

Prosecutors should never go ahead with more charges than are necessary just to encourage a defendant to plead guilty to a few. In the same way, they should never go ahead with a more serious charge just to encourage a defendant to plead guilty to a less serious one.

although it adds that in some kinds of complex cases such as major fraud trials:

The over-riding duty of the prosecutor is ... to see that justice is done. The procedures must command public and judicial confidence. Many defendants in serious and complex fraud cases are represented by solicitors experienced in commercial litigation, including negotiation. This means that the defendant is usually protected from being put under improper pressure to plead. The main danger to be guarded against in these cases is that the prosecutor is persuaded to agree to a plea or a basis that is not in the public interest and interests of justice because it does not adequately reflect the seriousness of the offending ... Any plea agreement must reflect the seriousness and extent of the offending and give the court adequate sentencing powers. It must consider the impact of an agreement on victims and also the wider public, whilst respecting the rights of defendants.

John H. Langbein argues that the modern American system of plea bargaining is comparable to the medieval European system of torture:
There is, of course, a difference between having your limbs crushed if you refuse to confess, or suffering some extra years of imprisonment if you refuse to confess, but the difference is of degree, not kind. Plea bargaining, like torture, is coercive. Like the medieval Europeans, the Americans are now operating a procedural system that engages in condemnation without adjudication.

Theoretical work based on the prisoner's dilemma is one reason that, in many countries, plea bargaining is forbidden. Often, precisely the prisoner's dilemma scenario applies: it is in the interest of both suspects to confess and testify against the other suspect, irrespective of the innocence of the accused. Arguably, the worst case is when only one party is guilty: here, the innocent one has no incentive to confess, while the guilty one has a strong incentive to confess and give testimony (including "false" testimony) against the innocent.

A 2009 study by the European Association of Law and Economics observed that innocent defendants are consistently more likely than guilty defendants to reject otherwise-favorable pleas proposals, even when theoretically disadvantageous to do so, because of perceived unfairness, and would do so even if the expected sanction would be worse if they proceeded to trial. The study concluded that "[t]his somewhat counterintuitive 'cost of innocence', where the preferences of innocents lead them collectively to fare worse than their guilty counterparts, is further increased by the practice of imposing much harsher sentences at trial on defendants who contest the charges. This 'trial penalty' seeks to facilitate guilty pleas by guilty defendants [...and ironically...] disproportionately, collectively, penalizes innocents, who reject on fairness grounds some offers their guilty counterparts accept."

The extent to which innocent people will accept a plea bargain and plead guilty is contentious and has been subjected to considerable research. Much research has focused on the relatively few actual cases where innocence was subsequently proven, such as successful appeals for murder and rape based upon DNA evidence, which tend to be atypical of trials as a whole (being by their nature only the most serious kinds of crime). Other studies have focused on presenting hypothetical situations to subjects and asking what choice they would make. More recently some studies have attempted to examine actual reactions of innocent persons generally, when faced with actual plea bargain decisions. A study by Dervan and Edkins (2013) attempted to recreate a real-life controlled plea bargain situation, rather than merely asking theoretical responses to a theoretical situation—a common approach in previous research. It placed subjects in a situation where an accusation of academic fraud (cheating) could be made, of which some subjects were in fact by design actually guilty (and knew this), and some were innocent but faced seemingly strong evidence of guilt and no verifiable proof of innocence. Each subject was presented with the evidence of guilt and offered a choice between facing an academic ethics board and potentially a heavy penalty in terms of extra courses and other forfeits, or admitting guilt and accepting a lighter "sentence". The study found that as expected from court statistics, around 90% of accused subjects who were actually guilty chose to take the plea-bargain and plead guilty. It also found that around 56% of subjects who were actually innocent (and privately knew it) also to take the plea-bargain and plead guilty, for reasons including avoiding formal quasi-legal processes, uncertainty, possibility of greater harm to personal future plans, or deprivation of home environment due to remedial courses. The authors stated:

Previous research has argued that the innocence problem is minimal because defendants are risk-prone and willing to defend themselves before a tribunal. Our research, however, demonstrates that when study participants are placed in real, rather than hypothetical, bargaining situations and are presented with accurate information regarding their statistical probability of success, just as they might be so informed by their attorney or the government during a criminal plea negotiation, innocent defendants are highly risk-averse.

More pressure to plea bargain may be applied in weak cases (where there is less certainty of both guilt and jury conviction) than strong cases. Prosecutors tend to be strongly motivated by conviction rates, and "there are many indications that prosecutors are willing to go a long way to avoid losing cases, [and that] when prosecutors decide to proceed with such weak cases they are often willing to go a long way to assure that a plea bargain is struck". Prosecutors often have great power to procure a desired level of incentive, as they select the charges to be presented. For this reason,

[P]lea bargains are just as likely in strong and weak cases. Prosecutors only need to adjust the offer to the probability of conviction in order to reach an agreement. Thus, weaker cases result in more lenient plea bargains, and stronger ones in relative harshness, but both result in an agreement. [... W]hen the case is weak, the parties must rely on charge bargaining ... But [charge bargaining] is hardly an obstacle. Charge bargaining in weak cases is not the exception; it is the norm all around the country. Thus, even if the evidence against innocent defendants is, on average, weaker, the likelihood of plea bargains is not dependent on guilt.

Another situation in which an innocent defendant may plead guilty is in the case of a defendant who cannot raise bail, and who is being held in custody in a jail or detention facility. Because it may take months, or even years, for criminal cases to come to trial or even indictment in some jurisdictions, an innocent defendant who is offered a plea bargain that includes a sentence of less time than he would otherwise spend in jail awaiting an indictment or a trial may choose to accept the plea arrangement and plead guilty.

Agency problems sometimes arise in plea bargaining in that although the prosecutor represents the people and the defense attorney represents the defendant, these agents' goals may be far from congruent with those of their principals. Moreover, prosecutors and defense attorneys often view each other as colleagues and generally wish to maintain good relations with one another. A defense attorney often receives a flat fee or in any event will not receive enough additional money if he goes to trial to cover the costs of doing so; this can create an incentive to plea bargain, even at the expense of the defense attorney's client's interests.

On the other hand, the prosecutor may wish to maintain a high conviction rate and avoid losing high-profile trials; thus, settling a case by plea bargain may further his interests, even if the resulting sentence would not effectively deter crime. As many crimes have very narrow sentencing bands, a prosecutor often has scope to propose whatever degree of "discounted" charges, or substitution of misdemeanor rather than felony charges, to whatever extent they believe would incentivise a defendant to make a guilty plea and accept a speedy conviction, regardless of actual guilt.

Another argument against plea bargaining is that it may not actually reduce the costs of administering justice. For example, if a prosecutor has only a 25% chance of winning his case and sending the defendant away to prison for 10 years, he may make a plea agreement for a sentence of one year; but if plea bargaining is unavailable, a prosecutor may drop the case completely.

Plea bargaining is a significant part of the criminal justice system in the United States; the vast majority (roughly 90%) of criminal cases in the United States are settled by plea bargain rather than by a jury trial. Plea bargains are subject to the approval of the court, and different States and jurisdictions have different rules. The Federal Sentencing Guidelines are followed in federal cases and have been created to ensure a standard of uniformity in all cases decided in the federal courts. A two- or three-level offense level reduction is usually available for those who accept responsibility by not holding the prosecution to the burden of proving its case; this usually amounts to a complete sentence reduction had they gone to trial and lost.

The Federal Rules of Criminal Procedure provide for two main types of plea agreements. An 11(c)(1)(B) agreement does not bind the court; the prosecutor's recommendation is merely advisory, and the defendant cannot withdraw his plea if the court decides to impose a sentence other than what was stipulated in the agreement. An 11(c)(1)(C) agreement, however, binds the court once the court accepts the agreement. When such an agreement is proposed, the court can reject it if it disagrees with the proposed sentence, in which case the defendant has an opportunity to withdraw his plea.

Plea bargains are so common in the Superior Courts of California (the general trial courts) that the Judicial Council of California has published an optional seven-page form (containing all mandatory advisements required by federal and state law) to help prosecutors and defense attorneys reduce such bargains into written plea agreements.

Certain aspects of the American justice system serve to promote plea bargaining. For example, the adversarial nature of the U.S. criminal justice system puts judges in a passive role, in which they have no independent access to information with which to assess the strength of the case against the defendant. The prosecutor and defense may thus control the outcome of a case through plea bargaining. The court must approve a plea bargain as being within the interests of justice.

The lack of compulsory prosecution also gives prosecutors greater discretion as well as the inability of crime victims to mount a private prosecution and their limited ability to influence plea agreements. Defendants who are held in custody—who either do not have the right to bail or cannot afford bail, or who do not qualify for release on their own recognizance—may get out of jail immediately following the judge’s acceptance of a plea.

Generally, once a plea bargain is made and accepted by the courts, the matter is final and cannot be appealed. However, a defendant may withdraw his plea for certain legal reasons, and a defendant may agree to a "conditional" plea bargain, whereby s/he pleads guilty and accepts a sentence, but reserves the right to appeal a specific matter (such as violation of a constitutional right). If the defendant does not win on appeal the agreement is carried out; if the defendant is successful on appeal the bargain is terminated. The defendant in "Doggett v. United States" made such a bargain, reserving the right to appeal solely on the grounds that he was not given a speedy trial as required by the United States Constitution; Doggett's claim was upheld by the United States Supreme Court and he was freed.

In Canada, the courts always have the final say with regard to sentencing. Nevertheless, plea bargaining has become an accepted part of the criminal justice system although judges and Crown attorneys are often reluctant to refer to it as such. In most Canadian criminal proceedings, the Crown has the ability to recommend a lighter sentence than it would seek following a guilty verdict in exchange for a guilty plea.

Like other common law jurisdictions, the Crown can also agree to withdraw some charges against the defendant in exchange for a guilty plea. This has become standard procedure for certain offences such as impaired driving. Note that in the case of hybrid offences, the Crown must make a binding decision as to whether to proceed summarily or by indictment prior to the defendant making his or her plea. If the Crown elects to proceed summarily and the defendant then pleads not guilty, the Crown cannot change its election. Therefore, the Crown is not in a position to offer to proceed summarily in exchange for a guilty plea.

Canadian judges are not bound by the Crown's sentencing recommendations and could impose harsher (or more lenient) penalties. Therefore, the Crown and the defence will often make a "joint submission" with respect to sentencing. While a joint submission can entail both the Crown and defence recommending exactly the same disposition of a case, this is not common except in cases that are sufficiently minor that the Crown is willing to recommend a discharge. In more serious cases, a joint submission normally call for a sentence within relatively narrow range, with the Crown arguing for a sentence at the upper end of the range and the defence arguing for a sentence at the lower end, so as to maintain the visibility of the judge's ability to exercise discretion.

Judges are not bound to impose a sentence within the range of a joint submission, and a judge's disregard for a joint submission is not in itself grounds for the sentence to be altered on appeal. However, if a judge routinely disregards joint submissions, that judge would compromise the ability of the Crown to offer meaningful incentives for defendants to plead guilty. Defence lawyers would become reluctant to enter into joint submissions if they were thought to be of little value with a particular judge, which would thus result in otherwise avoidable trials. For these reasons, Canadian judges will normally impose a sentence within the range of any joint submission.

Following a Supreme Court of Canada ruling that imposes strict time limits on the resolution of criminal cases (eighteen months for cases in provincial court and thirty months for cases in Superior Court), several provinces have initiated and/or intensified measures intended to maximize the number of minor criminal cases resolved by a plea bargain.

Largely unique to the Canadian justice system is that further negotiations concerning the final disposition of a criminal case may also arise even after a sentence has been passed. This is because in Canada the Crown has (by common law standards) a very broad right to appeal acquittals, and also a right to appeal for harsher sentences except in cases where the sentence imposed was maximum allowed. Therefore, in Canada, after sentencing the defence sometimes has an incentive to try and persuade the Crown to not appeal a case, in exchange for the defence also declining to appeal. While, strictly speaking, this is not plea bargaining, it is done for largely the same reasons.

Plea bargaining is permitted in the legal system of England and Wales. The guidelines by the Sentencing Council require that the discount it gives to the sentence are determined by the timing of the plea and no other factors. The guidelines state that the earlier the guilty plea is entered, the greater the discount to the sentence. The maximum discount permitted is one third, for a plea entered at the earliest stage. There is no minimum discount; a guilty plea entered on the first proper day of the trial would be expected provide a discount of one tenth. The discount can sometimes involve changing the type of punishment, such as substituting a prison sentence for community service.

Plea bargaining in Magistrates' Court trials is permitted only to the extent that the prosecutors and the defence can agree that the defendant will plead guilty to some charges and the prosecutor will drop the remainder. However, although this is not conducting a plea bargain, in cases before the Crown Court, the defence can request an indication from the judge of the likely maximum sentence that would be imposed should the defendant decide to plead guilty.

In the case of hybrid offences in England and Wales, the decision whether to deal with a case in Magistrates Court or Crown Court is not made by magistrates until after a plea has been entered. A defendant is thus unable to plead guilty in exchange for having a case dealt with in Magistrates' Court (which has lesser sentencing powers).

Plea bargaining was introduced in India by "The Criminal Law (Amendment) Act, 2005", which amended the Code of Criminal Procedure and introduced a new chapter XXI(A) in the code, enforceable from July 5, 2006. It allows plea bargaining for cases in which the maximum punishment is imprisonment for 7 years; however, offenses affecting the socio-economic condition of the country and offenses committed against a woman or a child below 14 are excluded.

In 2007, Sakharam Bandekar case became the first such case in India where the accused Sakharam Bandekar requested lesser punishment in return for confessing to his crime (using plea bargaining). However, the court rejected his plea and accepted CBI's argument that the accused was facing serious charges of corruption. Finally, the court convicted Bandekar and sentenced him to 3 years imprisonment.

Plea bargain as a formal legal provision was introduced in Pakistan by the National Accountability Ordinance 1999, an anti-corruption law. A special feature of this plea bargain is that the accused applies for it, accepting guilt, and offers to return the proceeds of corruption as determined by investigators/prosecutors. After an endorsement by the Chairman National Accountability Bureau, the request is presented before the court, which decides whether it should be accepted or not. If the request for plea bargain is accepted by the court, the accused stands convicted but neither is sentenced if in trial nor undergoes any sentence previously pronounced by a lower court if in appeal. The accused is disqualified to take part in elections, hold any public office, or obtain a loan from any bank; the accused is also dismissed from service if a government official.

In other cases, formal plea bargains in Pakistan are limited, but the prosecutor has the authority to drop a case or a charge in a case and, in practice, often does so, in return for a defendant pleading guilty on some lesser charge. No bargaining takes place over the penalty, which is the court's sole privilege.

In some common law jurisdictions, such as Singapore and the Australian state of Victoria, plea bargaining is practiced only to the extent that the prosecution and the defense can agree that the defendant will plead guilty to some charges and/or to reduced charges in exchange for the prosecutor withdrawing the remaining and/or more serious charges. In New South Wales, a 10-25% discount on the sentence is customarily given in exchange for an early guilty plea, but this concession is expected to be granted by the judge as a way of recognizing the utilitarian value of an early guilty plea to the justice system - it is never negotiated with a prosecutor. The courts in these jurisdictions have made it plain that they will always decide what the appropriate penalty is to be. No bargaining takes place between the prosecution and the defence over criminal penalties.

Plea bargaining is extremely difficult in jurisdictions based on the civil law. This is because unlike common law systems, civil law systems have no concept of plea—if the defendant confesses; a confession is entered into evidence, but the prosecution is not absolved of the duty to present a full case. A court may decide that a defendant is innocent even though they presented a full confession. Also, unlike common law systems, prosecutors in civil law countries may have limited or no power to drop or reduce charges after a case has been filed, and in some countries their power to drop or reduce charges "before" a case has been filed is limited, making plea bargaining impossible. Since the 1980s, many civil law nations have adapted their systems to allow for plea bargaining.

In 2013 Brazil passed a law allowing plea bargains, which have been used in the political corruption trials taking place since then.

In the Central African Republic, witchcraft carries heavy penalties but those accused of it typically confess in exchange for a modest sentence.

In China, a plea bargaining pilot scheme has been introduced by the Standing Committee of the National People's Congress in 2016. For defendants that faces jail terms of three years or below, agrees to plea guilty voluntarily and agree with prosecutors' crime and sentencing proposals, will be given mitigated punishments.

In 2009, in a case about whether witness testimony originating from a plea deal in the United States was admissible in a Danish criminal trial "(297/2008 H)", the Supreme Court of Denmark (Danish: Højesteret) unanimously ruled that plea bargains are "prima facie" not legal under Danish law, but that the witnesses in the particular case would be allowed to testify regardless (with the caveat that the lower court consider the possibility that the testimony was untrue or at least influenced by the benefits of the plea bargain). The Supreme Court did however point out that Danish law contains mechanisms similar to plea bargains, such as §82.10 of the Danish Penal Code (Danish: Straffeloven) which states that a sentence may be reduced if the perpetrator of a crime provides information that helps solve a crime perpetrated by others, or §23.a of the Danish Competition Law (Danish: Konkurrenceloven) which states that someone can apply to avoid being fined or prosecuted for participating in a cartel if they provide information about the cartel that the authorities did not know at the time.

If a defendant admits to having committed a crime, the prosecution doesn't have to file charges against them, and the case can be heard as a so-called "admission case" (Danish: tilståelsessag) under §831 of the Law on the Administration of Justice (Danish: Retsplejeloven) provided that: the confession is supported by other pieces of evidence (meaning that a confession is not enough to convict someone on its own); both the defendant and the prosecutor consent to it; the court does not have any objections; §§ 68, 69, 70 and 73 of the Penal Code do not apply to the case.

In Estonia, plea bargaining was introduced in the 1990s: the penalty is reduced in exchange for confession and avoiding most of the court proceedings. Plea bargaining is permitted for the crimes punishable by no more than four years of imprisonment. Normally, a 25% reduction of the penalty is given.

The introduction of a limited form of plea bargaining ("comparution sur reconnaissance préalable de culpabilité" or CRPC, often summarized as "plaider coupable") in 2004 was highly controversial in France. In this system, the public prosecutor could propose to suspects of relatively minor crimes a penalty not exceeding one year in prison; the deal, if accepted, had to be accepted by a judge. Opponents, usually lawyers and leftist political parties, argued that plea bargaining would greatly infringe on the rights of defense, the long-standing constitutional right of presumption of innocence, the rights of suspects in police custody, and the right to a fair trial.

For instance, Robert Badinter argued that plea bargaining would give too much power to the public prosecutor and would encourage defendants to accept a sentence only to avoid the risk of a bigger sentence in a trial, even if they did not really deserve it. Only a minority of criminal cases are settled by that method: in 2009, 77,500 out of the 673,700 or 11.5% of the decisions by the correctional courts.

Plea bargaining (Georgian: საპროცესო შეთანხმება, literally "plea agreement") was introduced in Georgia in 2004. The substance of the Georgian plea bargaining is similar to the United States and other common law jurisdictions.

A plea bargaining, also called a plea agreement or negotiated plea, is an alternative and consensual way of criminal case settlement. A plea agreement means settlement of case without main hearing when the defendant agrees to plead guilty in exchange for a lesser charge or for a more lenient sentence and/or for dismissal of certain related charges. (Article 209 of the Criminal Procedure Code of Georgia)

The main principle of the plea bargaining is that it must be based on the free will of the defendant, equality of the parties and advanced protection of the rights of the defendant:
a) In order to avoid fraud of the defendant or insufficient consideration of his/her interests, legislation foresees obligatory participation of the defense council; (Article 210 of the Criminal Procedure Code of Georgia)<br>
b) The defendant has the right to reject the plea agreement on any stage of the criminal proceedings before the court renders the judgment. (Article 213 of the Criminal Procedure Code of Georgia)<br>
c) In case of refusal, it is prohibited to use information provided by the defendant under the plea agreement against him in the future. (Article 214 of the Criminal Procedure Code of Georgia)<br>
d) The defendant has the right to appeal the judgment rendered consequent to the plea agreement if the plea agreement was concluded by deception, coercion, violence, threat, or violence. (Article 215 of the Criminal Procedure Code of Georgia)

While concluding the plea agreement, the prosecutor is obliged to take into consideration public interest, severity of the penalty, and personal characteristics of the defendant. (Article 210 of the Criminal Procedure Code of Georgia)
To avoid abuse of powers, legislation foresees written consent of the supervisory prosecutor as necessary precondition to conclude plea agreement and to amend its provisions. (Article 210 of the Criminal Procedure Code of Georgia)

Plea agreement without the approval of the court doesn’t have the legal effect. 
The court must satisfy itself that the plea agreement is concluded on the basis of the free will of the defendant, that the defendant fully acknowledges the essence of the plea agreement and its consequences. (Article 212 of the Criminal Procedure Code of Georgia)

Guilty plea of the defendant is not enough to render guilty judgment. (Article 212 of the Criminal Procedure Code of Georgia) Consequently, court is obliged to discuss 2 important issues:

a) Whether irrefutable evidence is presented which proves the defendant’s guilt beyond reasonable doubt.<br>
b) Whether sentence provided for in the plea agreement is legitimate. (Article 212 of the Criminal Procedure Code of Georgia)
After both criteria are satisfied the court additionally checks whether formalities related to the legislative requirements are followed and only then makes decision.

If the court finds that presented evidence is not sufficient to support the charges or that a motion to render a judgment without substantial consideration of a case is submitted in violation of the requirements stipulated by the Criminal Procedure Code of Georgia, it shall return the case to the prosecution. The court before returning the case to the prosecutor offers the parties to change the terms of the agreement. If the changed terms do not satisfy the court, then it shall return the case to the prosecution. (Article 213 of the Criminal Procedure Code of Georgia)

If the court satisfies itself that the defendant fully acknowledges the consequences of the plea agreement, and he/she was represented by the defense council, his/her will is expressed in full compliance with the legislative requirements without deception and coercion, also if there is enough body of doubtless evidence for the conviction and the agreement is reached on legitimate sentence - the court approves the plea agreement and renders guilty judgment. If any of the abovementioned requirements are not satisfied, the court rejects to approve the plea agreement and returns the case to the prosecutor. (Article 213 of the Criminal Procedure Code of Georgia)

The plea agreement is concluded between the parties - the prosecutor and the defendant. Notwithstanding the fact that the victim is not party to the criminal case and the prosecutor is not a tool in the hands of the victim to obtain revenge against the offender, the attitude of the victim in relation to the plea agreement is still important.

Under Article 217 of the Criminal procedure Code of Georgia, the prosecutor is obliged to consult with the victim prior to concluding the plea agreement and inform him/her about this. In addition, under the Guidelines of the Prosecution Service of Georgia, the prosecutor is obliged to take into consideration the interests of the victim and as a rule conclude the plea agreement after the damage is compensated.

Plea agreements have made a limited appearance in Germany. However, there is no exact equivalent of a guilty plea in German criminal procedure.

Italy has a form of bargaining, popularly known as "patteggiamento" but that has a technical name of penalty application under request of the parts. In fact, the bargaining is not about the charges, but about the penalty applied in sentence, reduced up to one third.

When the defendant deems that the punishment that would, concretely, be handed down is less than a five-year imprisonment (or that it would just be a fine), the defendant may request to plea bargain with the prosecutor. The defendant is rewarded with a reduction on the sentence and has other advantages (such as that the defendant does not pay the fees on the proceeding). The defendant must accept the penalty for the charges (even if the plea-bargained sentence has some particular matters in further compensation proceedings), no matter how serious the charges are.

Sometimes, the prosecutor agrees to reduce a charge or to drop some of multiple charges in exchange for the defendant's acceptance of the penalty. Defendant, in the request, could argue with the penalty and aggravating and extenuating circumstancing with the prosecutor, that can accept or refuse. The request could also be made by the prosecutor. The plea bargaining could be granted if the penalty that could be concretely applied is, after the reduction of one third, inferior to five-year imprisonment (so called "patteggiamento allargato", wide bargaining); When the penalty applied, after the reduction of one third, is inferior of two years imprisonment or is only a fine (so called "patteggiamento ristretto" limited bargaining), the defendant can have other advantages, like sentence suspended and the effacement of the crime if in five year of the sentence, the defendant doesn't commit a similar crime.

In the request, when it could be applied the conditional suspension of the penalty according to the article 163 and following of Italian penal code, the defendant could subordinate the request to the grant of the suspension; if the judge rejects the suspension, the bargaining is refused. When both the prosecutor and the defendant have come to an agreement, the proposal is submitted to the judge, who can refuse or accept the plea bargaining.

According to Italian law, a bargain doesn't need a guilty plea (in Italy there is no plea declaration); for this reason, a bargaining sentence is only an acceptance of the penalty in exchange with the stop of investigation and trial and has no binding cogency in other trials, especially in civil trials in which parts argue of the same facts at the effects of civil liability and in other criminal trials in which are processed the accomplices of the defendant that had requested and got a bargaining sentence.

Poland also adopted a limited form of plea bargaining, which is applicable only to minor felonies (punishable by no more than 10 years of imprisonment). The procedure is called “voluntary submission to a penalty” and allows the court to pass an agreed sentence without reviewing the evidence, what significantly shortens the trial.
There are some specific conditions that have to be simultaneously met:
However, the court may object to the terms of proposed plea agreement (even if already agreed between the defendant, victim and prosecutor) and suggest changes (not specific but rather general). If the defendant accepts these suggestions and changes his penalty proposition, the court approves it and passes the verdict according to the plea agreement. In spite of the agreement, all the parties of the trial: prosecution, defendant and the victim as an auxiliary prosecutor (in Poland, the victim may declare that he wants to act as an "auxiliary prosecutor" and consequently gains the rights similar to official prosecutor) - have the right to appeal.

In Japan, plea bargaining is forbidden by law. Sources report that prosecutors illegally have offered defendants plea bargains in exchange for their confessions.



</doc>
<doc id="23477" url="https://en.wikipedia.org/wiki?curid=23477" title="Protest song">
Protest song

A protest song is a song that is associated with a movement for social change and hence part of the broader category of "topical" songs (or songs connected to current events). It may be folk, classical, or commercial in genre.

Among social movements that have an associated body of songs are the abolition movement, women's suffrage, the labour movement, the human rights movement, civil rights, the anti-war movement and 1960s counterculture, the feminist movement, the sexual revolution, the gay rights movement, animal rights movement, vegetarianism and veganism, gun control, and environmentalism.

Protest songs are often situational, having been associated with a social movement through context. "Goodnight Irene", for example, acquired the aura of a protest song because it was written by Lead Belly, a black convict and social outcast, although on its face it is a love song. Or they may be abstract, expressing, in more general terms, opposition to injustice and support for peace, or free thought, but audiences usually know what is being referred to. Beethoven's "Ode to Joy", a song in support of universal brotherhood, is a song of this kind. It is a setting of a poem by Friedrich Schiller celebrating the continuum of living beings (who are united in their capacity for feeling pain and pleasure and hence for empathy), to which Beethoven himself added the lines that all men are brothers. Songs which support the status quo do not qualify as protest songs.

Protest song texts may have significant cognitive content. The labour movement musical "Pins and Needles" summed up the definition of a protest song in a number called "Sing Me a Song of Social Significance." Phil Ochs once explained, "A protest song is a song that's so specific that you cannot mistake it for BS."

An 18th-century example of topical song intended as a feminist protest song is "Rights of Woman" (1795), sung to the tune of "God Save the King", written anonymously by "A Lady", and published in the "Philadelphia Minerva", October 17, 1795. There is no evidence that it was ever sung as a movement song, however. A more recent song advocating sexual liberation is "Sexo" (1985) by Los Prisioneros.

The sociologist R. Serge Denisoff saw protest songs rather narrowly in terms of their function, as forms of persuasion or propaganda. Denisoff saw the protest song tradition as originating in the "psalms" or songs of grassroots Protestant religious revival movements, terming these hymns "protest-propaganda", as well.

Denisoff subdivided protest songs as either "magnetic" or "rhetorical". "Magnetic" protest songs were aimed at attracting people to the movement and promoting group solidarity and commitment – for example, "Keep Your Eyes on the Prize" and "We Shall Overcome". "Rhetorical" protest songs, on the other hand, are often characterized by individual indignation and offer a straightforward political message designed to change political opinion. Denisoff argued that although "rhetorical" songs often are not overtly connected to building a larger movement, they should nevertheless be considered as "protest-propaganda". Examples include Bob Dylan's "Masters of War" (which contains the lines "I hope that you die / And your death'll come soon") and "What's Going On" by Marvin Gaye.

Ron Eyerman and Andrew Jamison, in "Music and Social Movements: Mobilizing Tradition in the Twentieth Century" (1998), take issue with what they consider Denisoff's reductive approach to the history and function of song (and particularly traditional song) in social movements. They point out that Denisoff had paid little attention to the song tunes of protest music, considered them strictly subordinate to the texts, a means to the message. It is true that in the highly text-oriented western European song tradition, tunes can be subordinate, interchangeable, and even limited in number (as in Portuguese "fado", which only has 64 tunes), nevertheless, Eyerman and Jamison point out that some of the most effective protest songs gain power through their appropriation of tunes that are bearers of strong cultural traditions. They also note that:There is more to music and movements than can be captured within a functional perspective, such as Denisoff's, which focuses on the use made of music within already-existing movements. Music, and song, we suggest, can maintain a movement even when it no longer has a visible presence in the form of organizations, leaders, and demonstrations, and can be a vital force in preparing the emergence of a new movement. Here the role and place of music needs to be interpreted through a broader framework in which tradition and ritual are understood as processes of identity and identification, as encoded and embodied forms of collective meaning and memory.

Martin Luther King Jr. described the freedom songs this way: "They invigorate the movement in a most significant way ... these freedom songs serve to give unity to a movement."

Raï () is a form of folk music, originated in Oran, Algeria from Bedouin shepherds, mixed with Spanish, French, African and Arabic musical forms, which dates back to the 1930s and has been primarily evolved by women in the culture. Raï has been forbidden music in Algeria, to the point of one popular singer being assassinated, although since the 1980s it has enjoyed some considerable success. The song "Parisien Du Nord" by Cheb Mami is a recent example of how the genre has been used as form of protest, as the song was written as a protest against the racial tensions that sparked the 2005 French riots. According to Memi: It is a song against racism, so I wanted to sing it with a North African who was born in France ... Because of that and because of his talent, I chose K-Mel. In the song, we say, 'In your eyes, I feel like foreigner.' It's like the kids who were born in France but they have Arab faces. They are French, and they should be considered French."

Indigenous issues feature prominently in politically inspired Australian music and include the topics of land rights, and aboriginal deaths in custody. One of the most prominent Australian bands to confront these issues is Yothu Yindi. Other Australian bands to have confronted indigenous issues include Tiddas, Kev Carmody, Archie Roach, Christine Anu, The Herd, Neil Murray, Blue King Brown, the John Butler Trio, Midnight Oil, Warumpi Band, Paul Kelly, Powderfinger and Xavier Rudd.

In addition to Indigenous issues, many Australian protest singers have sung about the futility of war. Notable anti-war songs include "And The Band Played Waltzing Matilda" (1972) by Eric Bogle, and "A Walk in the Light Green" (1983) by Redgum, most often remembered by its chorus "I was only nineteen".
The first famous Belorussian protest songs were created at the beginning of the 20th century during the rise of Belorussian People's Republic and war for independence from Russian Empire and Soviet Russia. This period includes such protest songs as "Advieku My Spali" ("We've slept enough", also known as Belorussian Marselliese) and "Vajaćki Marš" ("March of the Warriors"), which was an anthem of Belorussian People's Republic.
The next period of protest songs was in the 1990s, with many created by such bands as NRM, Novaje Nieba and others, which lead to unspoken prohibition of these musicians. As an example, Lavon Volski, frontman of NRM, Mroja and Krambambulia, had issues with officials at the majority of his concert due to the criticism of the Belorussian political system. One of the most famous bands of Belarus, Lyapis Trubetskoy, was forbidden from performing in the country due to being critical of Aleksandr Lukashenka in his lyrics. These prohibitions lead most "forbidden" bands to organize concerts in Vilnius, which, though situated in modern Lithuania, is considered to be a Belorussian historical capital because less than a hundred years ago most dwellers of Vilnius (Vilnia, as it was called before it was given to Lithuania) were Belorussians. But at the middle of the 2010s, the situation began to change a bit and many protest bands started to organize concerts in Belarus.

English folk songs from the late medieval and early modern period reflect the social upheavals of their day. In 1944 the Marxist scholar A. L. Lloyd claimed that "The Cutty Wren" song constituted a coded anthem against feudal oppression and actually dated back to the English peasants' revolt of 1381, making it the oldest extant European protest song. He offered no evidence for his assertion, however and no trace of the song has been found before the 18th century. Despite Lloyd's dubious claim about its origins, however, the "Cutty Wren" was revived and used as a protest song in the 1950s folk revival, an example of the importance of context in determining what may be considered a protest song. In contrast, the rhyme, "When Adam delved and Eve span, who was then the gentleman?", is attested as authentically originating in the 1381 Peasant Revolt, though no tune associated with it has survived. Ballads celebrating social bandits like Robin Hood, from the 14th century onwards, can be seen as expressions of a desire for social justice, though although social criticism is implied and there is no overt questioning of the status quo.

The era of civil and religious wars of the 17th century in Britain gave rise to the radical communist millenarian Levellers and Diggers' movements and their associated ballads and hymns, as, for example, the "Diggers' Song". with the incendiary verse:
<poem>
But the Gentry must come down,
and the poor shall wear the crown.
Stand up now, Diggers all!"</poem>

The Digger movement was violently crushed, and so it is not surprising if few overt protest songs associated with it have survived. From roughly the same period, however, songs protesting wars and the human suffering they inflict abound, though such song do not generally explicitly condemn the wars or the leaders who wage them. For example, "The Maunding Souldier" or "The Fruits of Warre is Beggery", framed as a begging appeal from a crippled soldier of the Thirty Years War. Such songs have been known, strictly speaking, as songs of complaint rather than of protest, since they offered no solution or hint of rebellion against the status quo.

The advent of industrialization in the 18th and early 19th centuries was accompanied by a series of protest movements and a corresponding increase in the number of topical social protest songs and ballads. An important example is "The Triumph of General Ludd", which built a fictional persona for the alleged leader of the early 19th century anti-technological Luddite movement in the cloth industry of the north midlands, and which made explicit reference to the Robin Hood tradition. A surprising English folk hero immortalized in song is Napoleon Bonaparte, the military figure most often the subject of popular ballads, many of them treating him as the champion of the common working man in songs such as the "Bonny Bunch of Roses" and "Napoleon's Dream". As labour became more organized songs were used as anthems and propaganda, for miners with songs such as "The Black Leg Miner", and for factory workers with songs such as "The Factory Bell".

These industrial protest songs were largely ignored during the first English folk revival of the later 19th and early 20th century, which had focused on songs that had been collected in rural areas where they were still being sung and on music education. They were revived in the 1960s and performed by figures such as A. L. Lloyd on his album "The Iron Muse" (1963). In the 1980s the anarchist rock band Chumbawamba recorded several versions of traditional English protest songs as "English Rebel Songs 1381–1914".


Colin Irwin, a journalist for "The Guardian", believes the modern British protest movement started in 1958 when the Campaign for Nuclear Disarmament organized a 53-mile march from Trafalgar Square to Aldermaston, to protest Britain's participation in the arms race and recent testing of the H-bomb. The protest "fired up young musicians to write campaigning new songs to argue the case against the bomb and whip up support along the way. Suddenly many of those in skiffle groups playing American songs were changing course and writing fierce topical songs to back direct action." A song composed for the march, "The H-Bomb's Thunder", set the words of a poem by novelist John Brunner to the tune of "Miner's Lifeguard":
<poem>
Men and women, stand together
Do not heed the men of war
Make your minds up now or never
Ban the bomb for evermore.</poem>

Folk singer Ewan MacColl was for some time one of the principal musical figures of the British nuclear disarmament movement. A former agitprop actor and playwright. MacColl, a prolific songwriter and committed leftist, some years earlier had penned "The Ballad of Ho Chi Minh" (1953), issued as single on Topic Records, and "The Ballad of Stalin" (1954), commemorating the death of that leader. Neither record has ever been reissued.
According to Irwin, MacColl, when interviewed in the "Daily Worker" in 1958, declared that:There are now more new songs being written than at any other time in the past eighty years—young people are finding out for themselves that folk songs are tailor-made for expressing their thoughts and comments on contemporary topics, dreams, and worries,

In 1965, folk-rock singer Donovan's cover of Buffy Sainte-Marie's "Universal Soldier" was a hit on the charts. His anti-Vietnam War song "The War Drags On" appeared that same year. This was a common trend in popular music of the 1960s and 1970s. The romantic lyrics of pop songs in the 1950s gave way to words of protest.
As their fame and prestige increased in the late 1960s, The Beatles—and John Lennon in particular—added their voices to the Anti-war. In the documentary "The US Versus John Lennon", Tariq Ali attributes the Beatles' activism to the fact that, in his opinion, "The whole culture had been radicalized: [Lennon] was engaged with the world, and the world was changing him." "Revolution", 1968, commemorated the worldwide student uprisings. In 1969, when Lennon and Yoko Ono were married, they staged a week-long "bed-in for peace" in the Amsterdam Hilton, attracting worldwide media coverage. At the second "Bed-in" in Montreal, in June 1969, they recorded "Give Peace a Chance" in their hotel room. The song was sung by over half a million demonstrators in Washington, DC, at the second Vietnam Moratorium Day, on 15 October 1969. In 1972 Lennon's most controversial protest song LP was released, "Some Time In New York City", the title of whose lead single "Woman Is the Nigger of the World", a phrase coined by Ono in the late 1960s to protest sexism, set off a storm of controversy, and in consequence received little airplay and much banning. The Lennons went to great lengths (including a press conference attended by staff from "Jet" and "Ebony" magazines) to explain that they had used the word "nigger" in a symbolic sense and not as an affront to African Americans. The album also included "Attica State", about the Attica Prison riots of September 9, 1971; "Sunday Bloody Sunday" and "The Luck Of The Irish", about the massacre of demonstrators in Northern Ireland and "Angela", in support of black activist Angela Davis. Lennon also performed at the "Free John Sinclair" benefit concert in Ann Arbor, Michigan, on December 10, 1971. on behalf of the imprisoned antiwar activist and poet who was serving 10 years in state prison for selling two joints of marijuana to an undercover cop. On this occasion Lennon and Ono appeared on stage with among others singers Phil Ochs and Stevie Wonder, plus antiwar activists Jerry Rubin and Bobby Seale of the Black Panthers party. Lennon's song "John Sinclair" (which can be heard on his "Some Time In New York City" album), calls on the authorities to "Let him be, set him free, let him be like you and me". The benefit was attended by some 20,000 people, and three days later the State of Michigan released Sinclair from prison.

The 1970s saw a number notable songs by British acts that protested against war, including "Peace Train" by Cat Stevens (1971), and "War Pigs" by Black Sabbath (1970). Sabbath also protested environmental destruction, describing people leaving a ruined Earth ("Into the Void" including, "Iron Man"). Renaissance added political repression as a protest theme with "Mother Russia" being based on "One Day in the Life of Ivan Denisovich" and being joined on the second side of their 1974 album "Turn of the Cards" by two other protest songs in "Cold Is Being" (about ecological destruction) and "Black Flame" (about the Vietnam War).
As the 1970s progressed, the louder, more aggressive Punk movement became the strongest voice of protest, particularly in the UK, featuring anti-war, anti-state, and anti-capitalist themes. The punk culture, in stark contrast with the 1960s' sense of power through union, concerned itself with individual freedom, often incorporating concepts of individualism, free thought and even anarchism. According to "Search and Destroy" founder V. Vale, "Punk was a total cultural revolt. It was a hardcore confrontation with the black side of history and culture, right-wing imagery, sexual taboos, a delving into it that had never been done before by any generation in such a thorough way." The most significant protest songs of the movement included "God Save the Queen" (1977) by the Sex Pistols, "If the Kids are United" by Sham 69, "Career Opportunities" (1977) (protesting the political and economic situation in England at the time, especially the lack of jobs available to the youth), and "White Riot" (1977) (about class economics and race issues) by The Clash, and "Right to Work" by Chelsea. See also Punk ideology.

War was still the prevalent theme of British protest songs of the 1980s – such as Kate Bush's "Army Dreamers" (1980), which deals with the traumas of a mother whose son dies while away at war. However, as the 1980s progressed, it was British prime minister Margaret Thatcher who came under the greatest degree of criticism from native protest singers, mostly for her strong stance against trade unions, and especially for her handling of the UK miners' strike (1984–1985). The leading voice of protest in Thatcherite Britain in the 1980s was Billy Bragg, whose style of protest song and grass-roots political activism was mostly reminiscent of those of Woody Guthrie, however with themes that were relevant to the contemporary Briton. He summarized his stance in "Between the Wars" (1985), in which he sings: "I'll give my consent to any government that does not deny a man a living wage."

Also in the 1980s the band Frankie Goes to Hollywood released a political pop protest song Two Tribes a relentless bass driven track depicting the futility and starkness of nuclear weapons and the Cold War. The video for the song depicted a wrestling match between then-President Ronald Reagan and then-Soviet leader Konstantin Chernenko for the benefit of group members and an eagerly belligerent assembly of representatives from the world's nations, the event ultimately degenerating into complete global destruction. This video was played several times at the 1984 Democratic National Convention. Due to some violent scenes ("Reagan" biting "Chernenko"'s ear, etc.), the unedited video could not be shown on MTV, and an edited version was substituted. The single quickly hit the number one spot in the United Kingdom.
Several mixes of the track features actor Patrick Allen, who recreated his narration from the Protect and Survive public information films for certain 12-inch mixes (the original Protect and Survive soundtracks were sampled for the 7-inch mixes).

Another type of protest song that appeared in the late 1980s came in the form of "I'd rather Jack" by The Reynolds Girls. This was a protest against musical snobbery – particularly that being exhibited by middle-aged DJ's who refused to play new higher selling tracks coming from labels such as PWL in favour of older more niche / self-important artists.

Irish rebel music is a subgenre of Irish folk music, played on typically Irish instruments (such as the Fiddle, tin whistle, Uilleann pipes, accordion, bodhrán etc.) and acoustic guitars. The lyrics deal with the fight for Irish freedom, people who were involved in liberation movements, the persecution and violence during Northern Ireland's Troubles and the history of Ireland's numerous rebellions.

Among the many examples of the genre, some of the most famous are "A Nation Once Again", "Come out Ye Black and Tans", "Erin go Bragh", "The Fields of Athenry", "The Men Behind the Wire" and the Republic of Ireland's national Anthem "Amhrán na bhFiann" ("The Soldier's Song"). Music of this genre has often courted controversy, and some of the more outwardly anti-British songs have been effectively banned from the airwaves in both England and the Republic of Ireland.

Paul McCartney also made a contribution to the genre with his 1972 single "Give Ireland Back to the Irish", which he wrote as a reaction to Bloody Sunday in Northern Ireland on January 30, 1972. The song also faced an all-out ban in the UK, and has never been re-released or appeared on any Paul McCartney or Wings best-ofs. The same year McCartney's former colleague John Lennon released two protest songs concerning the hardships of war-torn Northern Ireland: "Sunday Bloody Sunday", written shortly after the 1972 massacre of Irish civil rights activists (which differs from U2's 1983 song of the same title in that it directly supports the Irish Republican cause and does not call for peace), and "The Luck Of The Irish", both from his album "Some Time in New York City" (1972).

The Wolfe Tones have become legendary in Ireland for their contribution to the Irish rebel genre. The band has been recording since 1963 and has attracted worldwide fame and attention through their renditions of traditional Irish songs and originals, dealing with the former conflict in Northern Ireland. In 2002 the Wolfe Tones' version of "A Nation Once Again", a nationalist song from the 19th century, was voted the greatest song in the world in a poll conducted by the BBC World Service

An Irish alternative rock/post punk band from Dublin, U2 broke with the rebel musical tradition when in 1983 they wrote their song "Sunday Bloody Sunday". The song makes reference to two separate massacres in Irish history of civilians by British forces – Bloody Sunday (1920) and Bloody Sunday 1972 – however, unlike other songs dealing with those events, the lyrics call for peace as opposed to revenge.

The Cranberries' hit "Zombie", written during their English tour in 1993, is in memory of two boys, Jonathan Ball and Tim Parry, who were killed in an IRA bombing in Warrington.

Chinese-Korean Cui Jian's 1986 song "Nothing to My Name" was popular with protesters in Tiananmen Square.

Many of the songs performed at the Estonian Laulupidu are protest songs, particularly those written during the Singing Revolution. Due to the official position of the Soviet Union at the time, the lyrics are frequently allusive, rather than explicitly anti-Soviet, such as Tõnis Mägi's song "Koit". In contrast, "Eestlane olen ja eestlaseks jään", sung by Ivo Linna and the group In spe is explicitly in favour of an Estonian identity.

Finland has a long tradition of socialist and communist protest songs beginning in years before Finnish Civil War, most which were imported and translated from Soviet Russia. Notably right-wing protest songs are completely absent in contrast to Estonian tradition and widely considered socially unacceptable. In the 21st century the socialist protest song tradition is continued by rap artists and to lesser degree in more traditional Taistoist form by KOM-theatre choir.

"The Internationale" (""L'Internationale"" in French) is a socialist, anarchist, communist, and social-democratic anthem. 

"The Internationale" became the anthem of international socialism. Its original French refrain is "C'est la lutte finale/ Groupons-nous et demain/ L'Internationale/ Sera le genre humain." (Freely translated: "This is the final struggle/ Let us join together and tomorrow/ The Internationale/ Will be the human race.") The "Internationale" has been translated into most of the world's languages. Traditionally it is sung with the hand raised in a clenched fist salute. "The Internationale" is sung not only by communists but also (in many countries) by socialists or social democrats. The Chinese version was also a rallying song of the students and workers at the Tiananmen Square protests of 1989.

There is not so much a protest song trend in France, but rather of a permanent background of criticism and contestation, and individuals who personify it. World War II and its horrors forced French singers to think more critically about war in general, forcing them to question their governments and the powers who ruled their society.

Jazz trumpeter and singer Boris Vian's was one of the first to protest against the Algerian war with his anti-war song "Le déserteur" (The deserter), which was banned by the government.

Several French songwriters, such as Léo Ferré (1916–1993), Georges Brassens (1921–1981), Jacques Brel (1929–1978) (actually a Belgian singer), Maxime Le Forestier (born 1949) or interpreters (Yves Montand, Marcel Mouloudji, Serge Reggiani, Graeme Allwright...) often wrote or sang songs aligned against majority ideas and political powers. Because racial tensions did not rise to the same levels as those in the United States, criticism was focused more toward bourgeoisie, power, religion, and songs defending liberty of thought, speech and action. After 1945, immigration became a source of inspiration for some singers: Pierre Perret (born 1934), well known for his humorous songs, started writing several more "serious" and committed songs against racism ("Lily", 1977), which critically pointed out everyday racist behaviour in French society.

Brassens wrote several songs protesting war, hate, intolerance ("Les Deux Oncles" [""The Two Uncles""], "La Guerre de 14–18" [""14–18 War""], "Mourir pour des idées" [""To Die for Ideas""] "Les Patriotes" [""The Patriots""]...), against chauvinism ("La Ballade des gens qui sont nés quelque part" ["Ballad of People Who Are Born Somewhere"]), against bourgeoisie ("La Mauvaise Réputation" [""The bad reputation""], "Les Philistins" [""The Philistines""]...). He was often called "anarchist" because of his songs on representatives of law and order (and religion) ("Le Gorille" [""The gorilla""] "Hécatombe" [""Slaughter""] "Le Nombril des femmes d'agents" [""The navel of cops wives""], "Le Mécréant" [""The miscreant""]...).

Ferré was also called an "anarchist". He sang against consumerism ("Vitrines" [""Shop Fronts""], "Chanson mécanisée" [""Mechanized Song""], "Il n'y a plus rien" [""There is nothing left""]...), against French war ("Miss guéguerre" [""Miss Squabble""], "Pacific blues", "Regardez-les" [""Look at them""], "Mon général" [""My general""], "Les Temps difficiles" [""Hard Times""], "La Marseillaise"), death penalty ("Ni Dieu ni maître" [""No God no Master""], "La Mort des loups" [""The Death of the Wolves""]), Estate control ("La Gueuse", "La Complainte de la télé" [""Lament of TV""], "La Révolution" [""Revolution""], "Le Conditionnel de variétés" [""Middle of the road music conditional mood""]), illusion of representative democracy ("Ils ont voté" [""They voted""], "La Grève" [""Strike""]), dictatorships ("Franco la muerte", "Allende", "La Violence et l'Ennui" [""Words... Words... Words...""]), sexual hypocrisy and freedom ("Le Chien" [""The Dog""], "Le Mal" [""Evil""], "Ton style" [""Your style""], "La Damnation" [""Damnation""]...).

Brel's work is another ode to freedom ("Ces gens-là" [""These people""], "Les Bourgeois" [""The Bourgeois""], "Jaurès", "Les Bigotes" [""The bigots""], "Le Colonel" [""The colonel""], "Le Caporal Casse-Pompon" [""Corporal Break-Nots""]).

Ton Steine Scherben, one of the first and most influential German language rock bands of the 1970s and early 1980s, were well known for the highly political lyrics of vocalist Rio Reiser. The band became a musical mouthpiece of new left movements, such as the squatting movement, during that time in Germany and their hometown of West Berlin in particular. Their lyrics were, at the beginning, anti-capitalist and anarchist, and the band had connections to members of the German Red Army Faction movement before they became illegal. Later songs were about more complex issues such as unemployment ("Mole Hill Rockers") or homosexuality ("Mama war so"). They also contributed to two full-length concept album about homosexuality, which were issued under the name "Brühwarm" (literally: boiling warm) in cooperation with a gay-revue group.

A dissatisfied German youth in the late 1970s and early 1980s resulted in a strand of highly politicized German-language Punkrock ("Deutschpunk"), which mostly concerned itself with politically radical left-wing lyrics, mostly influenced by the Cold War. Probably the most important German-language punk band was Slime from Hamburg, who were the first band whose LP was banned because of political topics. Their songs "Deutschland" ("Germany"), "Bullenschweine", "Polizei SA/SS", and the anti-imperialist "Yankees raus" ("Yankees out") were banned, some of them are still banned today, because they propagated the use of violence against the police or compared the police to the SA and SS of Nazi Germany.

The Cologne-based rock group BAP is known for their committed and intelligently written lyrics, dealing with discrimination and the power games of Germany's political elites in many of their songs. The song "Kristallnaach" (1982) is a point in case. It analyses the corruptibility of the present-day masses for new forms of fascism, while referring to the "Night of Broken Glass" that took place in 1938.

In East Germany, protesting against the state was often prohibited. Despite this, the song Ermutigung by Wolf Biermann became a widely popular protest song against the SPU government.

Hong Kong rock band Beyond's "Boundless Oceans Vast Skies" (1993) and "Glory Days" (光輝歲月)(1990) have been considered as protest anthems in various social movements.

India provided many examples of protest songs throughout its struggle for freedom from Britain.

Israel's protest music has often become associated with different political factions.

During the 1967 war, Naomi Shemer added a third verse to her song "Jerusalem of Gold", sung by Shuli Natan, about the recapturing of Jerusalem after 2,000 years. Later on that year, a different point of view of the song was introduced by the folk singer Meir Ariel, who recorded an anti-war version and named it "Jerusalem of Iron".

Gush Emunim supporters have taken a repertoire of old religious songs and invested them with political meaning. An example is the song "Utsu Etsu VeTufar" (They gave counsel but their counsel was violated). The song signifies the ultimate rightness of those steadfast in their beliefs, suggesting the rightness of Gush Emunim's struggle against anti-settlement policy by the government.

Minutes before Prime Minister Yitzhak Rabin was murdered at a political rally in November 1995, Israeli folk singer Miri Aloni sang the Israeli pop song "Shir Lashalom" ("Song for Peace"). This song, originally written in 1969 and performed extensively at the time by an Israeli military performing group, has become one of the anthems of the Israeli peace camp.

During the Arab uprising known as the First Intifada, Israeli singer Si Heyman sang "Yorim VeBokhim" ("Shoot and Weep") to protest Israeli policy in the territories. Pink Floyd's "Another Brick in the Wall" is used as a protest song by some opponents of Israel's barrier in the West Bank. The lyrics were adapted to: "We don't need no occupation. We don't need no racist wall."

Since the onset of the Oslo Process and, more recently, Israel's unilateral disengagement plan, protest songs became a major avenue for opposition activists to express sentiments. Songs protesting these policies were written and performed by Israeli musicians such as Ariel Zilber, Aharon Razel, and others.

While the protest song was enjoying its Golden Age in America in the 1960s, it also saw many detractors overseas who saw it as having been commercialized. Chilean singer-songwriter Víctor Jara, who played a pivotal role in the folkloric renaissance that led to the "Nueva Canción Chilena" (New Chilean Song) movement, which created a revolution in the popular music of his country, criticized the "commercialized" American protest song phenomenon that had been imported into Chile. He criticized it thus:
The cultural invasion is like a leafy tree which prevents us from seeing our own sun, sky and stars. Therefore in order to be able to see the sky above our heads, our task is to cut this tree off at the roots. US imperialism understands very well the magic of communication through music and persists in filling our young people with all sorts of commercial tripe. With professional expertise they have taken certain measures: first, the commercialization of the so-called 'protest music'; second, the creation of 'idols' of protest music who obey the same rules and suffer from the same constraints as the other idols of the consumer music industry – they last a little while and then disappear. Meanwhile they are useful in neutralizing the innate spirit of rebellion of young people. The term 'protest song' is no longer valid because it is ambiguous and has been misused. I prefer the term 'revolutionary song'.

Nueva canción (literally "new song" in Spanish) was a type of protest/social song in Latin American music which took root in South America, especially Chile and other Andean countries, and gained extreme popularity throughout Latin America. It combined traditional Latin American folk music idioms (played on the quena, zampoña, charango or cajón with guitar accompaniment) with some popular (esp. British) rock music, and was characterized by its progressive and often politicized lyrics. It is sometimes considered a precursor to rock en español. The lyrics are typically in Spanish, with some indigenous or local words mixed in.

A type of Cuban and Puerto Rican protest music started in the mid-1960s when a movement in Cuban music emerged that combined traditional folk music idioms with progressive and often politicized lyrics. This movement of protest music came to be known as "Nueva trova", and was somewhat similar to that of Nueva canción, however with the advantage of support from the Cuban government, as it promoted the Cuban Revolution – and thus part of revolutionary song. Though originally and still largely Cuban, nueva trova has become popular across Latin America, especially in Puerto Rico and Venezuela. The movements biggest stars included Cubans Silvio Rodríguez, Noel Nicola and Pablo Milanés, as well as Puerto Ricans such as Roy Brown, Andrés Jiménez, Antonio Cabán Vale and the group Haciendo Punto en Otro Son.

In 1966 Boudewijn de Groot released "Welterusten meneer de president", a song about the Vietnam War. The song spent 12 weeks in the Dutch Top 40 and to this day it remains an important song in nederpop and among Dutch protest songs. Following "Welterusten meneer de president", Boudewijn de Groot and Lennaert Nijgh, a Dutch lyricist, made more protest songs. The couple inspired other Dutch musicians, namely Armand and Robert Long.

One of the earliest protest songs in New Zealand was John Hanlon's "Damn the Dam", recorded in 1973 in support of the Save Manapouri Campaign.

During the bitterly divisive 1981 Springbok Tour, Blam Blam Blam's "There Is No Depression in New Zealand" became a favourite among anti-tour protesters. Reggae band Herbs wrote and performed songs criticising French nuclear testing in the Pacific Ocean.

Palestinian music () deals with the conflict with Israel, the longing for peace, and the love of the Palestinians' land. A typical example of such a song is "Biladi, Biladi" (My Country, My Country), which has become the unofficial Palestinian national anthem. Palestinian music rarely focuses on internal divides (unlike most Israeli peace songs), and instead deals almost solely with Israel. Additionally, there are very few Palestinian peace songs that do not indict Israel, and outwardly militaristic. Certain commentators have compared this with the general unwillingness of Palestinians to speak about internal problems, as they tend to be taboo in Palestinian society, and dissent is outlawed in Gaza, under Hamas control.

Another example is the song "Al-Quds (Jerusalem) our Land", with words by Sharif Sabri. The song, sung by Amr Diab from Port Said, Egypt, won first prize in 2003 in a contest in Egypt for video clips produced in the West Bank and Gaza. DAM is an Arabic hip-hop group, rapping in Arabic and Hebrew about the problems faced by Palestinians under occupation and calling for change. Kamilya Joubran's song "Ghareeba", a setting of a poem by Khalil Gibran, deals with a sense of isolation and loneliness felt by the Palestinian woman.

From the revolutionary songs of the Katipunan to the songs being sung by the New Peoples Army, Filipino protest music deals with poverty, oppression as well as anti-imperialism and independence. A typical example was during the American era, as Jose Corazon de Jesus created a well-known protest song entitled "Bayan Ko", which calls for redeeming the nation against oppression, mainly colonialism, and also became popular as a song against the Marcos regime.

However, during the 1960s, Filipino protest music became aligned with the ideas of Communism as well as of revolution. The protest song ""Ang Linyang Masa"" came from Mao Zedong and his Mass Line and ""Papuri sa Pag-aaral"" was from Bertolt Brecht. These songs, although Filipinized, rose to become another part of Filipino protest music known as Revolutionary songs that became popular during protests and campaign struggles.

The protest songs in Portugal were mostly associated with the antifascist movement and developed chiefly among students and activists. The best known are songs by Paulo de Carvalho and Zeca Afonso, respectively "E Depois do Adeus" (And After the Goodbye) and "Grândola Vila Morena"(Grândola Swarthy Town). They were chosen as a code to start the Carnation Revolution that would successfully triumph against the dictatorial regime. The first was written out of letters that the author, then fighting to maintain the colonies (a war that the general public was against) sent to his wife. Hence the title that refers to his departure "goodbye" to the war. The other song was very explicit regarding his objective: ""O Povo é quem mais ordena / dentro de ti oh cidade"" (The people is the one who orders the most/ inside of you oh city). "E Depois do Adeus" was vague enough to elude the censorship and pass as a "end of love" song, which also accounts for the order of the broadcast.

Of the two, Zeca Afonso was more prolific and more identified with the movement, so much so that another of his songs was the first choice for the code "Venham mais 5" (Let 5 more come). Other artists also used some craft to hide their meanings in the song or went into exile. One example is Adriano Correia de Oliveira that masked the explicit lyrics with the vocal tone making it difficult to distinguish the critical verse, from the refrain or even other verses. In no other song is this more noted that the ballad "Trova do Vento que Passa" (Song/Poem of the Passing Wind), whose lyrics by the writer Manuel Alegre were a direct criticism of the state. The music was by António Portugal but Correia used a typical Fado rhythm to hide such provocative verses as "Mesmo na noite mais triste/em tempo de sevidão/há sempre alguém que resiste/há sempre alguém que diz não" (even in the saddest night/in time of servitude/there is always someone who stands up/there is always someone who says No).

Not only men but also women had an active participation, albeit in lesser numbers. Emerlinda Duarte, one of those women, wrote the song "Somos Livres", for a 1972 theatre play called "Lisboa 72", masking a deep meaning with catchy children's music. Although the version of her singing the tune is the best known it was only recorded "after" the carnation revolution.

Many other songwriters and singers, in order to generate awareness, used their talents to act in all of Portugal, sometimes without pay or transport. Fausto Bordalo Dias once sang into a mike so poorly made it needed a plastic cup to work. Other singers included the priest Francisco Fanhais, the writer Jose Jorge Letria; Fernando Tordo; Luís Cília; Amélia Muge; Janita Salomé; Manuel Freire; José Barata-Moura; the poet José Carlos Ary dos Santos; Jose Mario Branco and Sergio Godinho.

Protest songs in Poland were mostly associated with anti-communist movement and developed in the 1970s and 1980s. One of the most important artists was Jacek Kaczmarski, author of such famous songs as "Mury" ("The Walls"), "Przedszkole" ("The Kindergarten") and "Zbroja" ("The Armor"), criticizing both the totalitarian communist government and the opposition. Another famous Polish folk singer, Jan Pietrzak, wrote one of the best-known Polish patriotic protest songs, "Żeby Polska była Polską" ("Make Poland Polish"), in which he reminded the most heroic moments of Polish history, including Kościuszko Uprising, and called people to fight the communists as they fought other enemies of Poland before. He also recorded a musical version of the Jonasz Kofta's poem "Pamiętajcie o ogrodach" ("Remember the Gardens"), protesting against the industrialism of life promoted by the communist propaganda. Other Polish artists well known for writing protest songs include Stanisław Staszewski and Przemysław Gintrowski.

The most famous source of Russian protest music in the 20th century has been those known locally as bards. The term (бард in Russian) came to be used in the Soviet Union in the early 1960s, and continues to be used in Russia today, to refer to singer-songwriters who wrote songs outside the Soviet establishment. Many of the most famous bards wrote numerous songs about war, particularly The Great Patriotic War (World War II). Bards had various reasons for writing and singing songs about war. Bulat Okudzhava, who actually fought in the war, used his sad and emotional style to illustrate the futility of war in songs such as "The Paper Soldier" ("Бумажный Солдат").

Many political songs were written by bards under Soviet rule, and the genre varied from acutely political, "anti-Soviet" songs, to witty satire in the best traditions of Aesop. Some of Bulat Okudzhava's songs provide examples of political songs written on these themes. Vladimir Vysotsky was perceived as a political songwriter, but later he gradually made his way into more mainstream culture. It was not so with Alexander Galich, who was forced to emigrate—owning a tape with his songs could mean a prison term in the USSR. Before emigration, he suffered from KGB persecution, as did another bard, Yuliy Kim. Others, like Evgeny Kliachkin and Aleksander Dolsky, maintained a balance between outright anti-Soviet and plain romantic material.
Protest rhetoric can also be traced in the works of such rock bands as Grazhdanskaya Oborona, Naive, Tarakany!, Pilot, Noize MC and Louna.

The majority of South African protest music of the 20th century concerned itself with apartheid, a system of legalized racial segregation in which blacks were stripped of their citizenship and rights from 1948 to 1994. As the apartheid regime forced Africans into townships and industrial centres, people sang about leaving their homes, the horror of the coal mines and the degradation of working as domestic servants. Examples of which include Benedict Wallet Vilakazi's "Meadowlands", the "Toyi-toyi" chant and "Bring Him Back Home" (1987) by Hugh Masekela, which became an anthem for the movement to free Nelson Mandela. The Special AKA wrote a song on Nelson Mandela called "Free Nelson Mandela". The track is upbeat and celebratory, drawing on musical influence from South Africa, was immensely popular in Africa. Masekela's song "Soweto Blues", sung by his former wife, Miriam Makeba, is a blues/jazz piece that mourns the carnage of the Soweto riots in 1976. Basil Coetzee and Abdullah Ibrahim's "Mannenberg" became an unofficial soundtrack to the anti-apartheid resistance.

In Afrikaans, the Voëlvry movement led by Johannes Kerkorrel, Koos Kombuis and Bernoldus Niemand in 1989, provided a voice of opposition from within the white Afrikaner community. These musicians sought to redefine Afrikaner identity, and although met with opposition from the authorities, Voëlvry played to large crowds at Afrikaans university campuses and was quite popular among Afrikaner youth.

Following apartheid's demise, most Afrikaans writers and musicians followed public sentiments by embracing the new South Africa, but cracks soon emerged in the dream of the "rainbow nation" and criticism started to emerge, criticism that has grown in frequency and intensity in recent years. With violent crime putting South Africa in the top category of most dangerous country in the world, poverty, government corruption, and the AIDS pandemic, writers and musicians, some of them veterans of anti-apartheid movements, are once again protesting against what they consider to be a government failing to uphold the promise of 'peace, democracy and freedom for all' that Nelson Mandela made upon his release from prison. By 2000, Johannes Kerkorrel claimed in the song "Die stad bloei vanaand" [The city bleeds tonight]: "the dream was promised, but just another lie has been sold."

Two Afrikaans compilation albums of predominantly protest music were released recently: "Genoeg is genoeg" [Enough is enough] (2007) and "Vaderland" [Fatherland] (2008), and Koos Kombuis also released a CD called "Bloedrivier" [Blood River] (2008), which is primarily a protest album. One track, "Waar is Mandela" [Where is Mandela] asks, "Where is Mandela when the shadows descend ... Where is the rainbow, where is the glory?" and another, "Die fokkol song" [The fuck all song], tells tourists who visit South Africa for the 2010 Football World Cup that there is nothing in South Africa, no jobs, no petrol, no electric power, not even jokes. However, these compilations only represent the tip of the iceberg, as many prominent musicians have included protest songs on recent albums, including Bok van Blerk, Fokofpolisiekar, and KOBUS!.

The reality of the New South Africa is decidedly violent, and crime is a well-known theme in post-apartheid Afrikaans protest music. The punk group Fokofpolisiekar (which translates to "fuck off police car") sings in "Brand Suid-Afrika" [Burn South Africa]: "For you knives lie in wait, in the garden outside you house," and Radio Suid-Afrika sings in "Bid" [Pray]: "Pray that no-one will be waiting in the garden, pray for strength and for mercy in each dark day." Theirs is a country of "murder and child rape" where the only respite is alcohol abuse. In "Blaas hom" [Blow him away] by the industrial band Battery9, the narrator sings how he gleefully unloads his gun on a burglar after being robbed for the third time, and in "Siek bliksems" [Sick bastards] Kristoe Strauss asks God to help against the "sick bastards" responsible for hijackings. The metal band KOBUS! pleads for a reinstatement of the death penalty in "Doodstraf", because they feel the promise of peace has not been realized. In "Reconciliation Day", Koos Kombuis sings: "Our streets run with blood, every day a funeral procession, they steal all our goods, on Reconciliation Day." Elsewhere he states, "we're in a state of war." The video of this song features a lawless microcosm of theft, rape and abuse – a lawlessness reflected in Valiant Swart's "Sodom en Gomorra": "two cities in the north, without laws, without order, too wonderful for words." Hanru Niemand rewrites the traditional Afrikaans song Sarie Marais, turning it into a murder ballad speculating on where Sarie's body will be found. The new protest musicians also parody Voëlvry's music: Johannes Kerkorrel's "Sit dit af" [Switch it off] – a satire on P. W. Botha of the apartheid regime – is turned into "Sit dit aan" [Switch it on] by Koos Kombuis, now a song protesting mismanagement resulting in chronic power failures.

Much of the protest by Afrikaans musicians concerns the legacy of apartheid: In "Blameer dit op apartheid" [Blame it on apartheid] Koos Kombuis sings how "the whole country is evil," yet the situation is blamed on apartheid. Klopjag, in "Ek sal nie langer" [I will no longer] sings that they will no longer apologize for apartheid, a theme echoed by many others, including Koos Kombuis in "Hoe lank moet ons nog sorry sê" [For how long do we still have to say sorry]. Piet Paraat sings in "Toema Jacob Zuma" [Never mind Jacob Zuma]: "My whole life I'm punished for the sins of my father." There is also a distinct feeling that the Afrikaner is being marginalized by the ANC government: Fokofpolisiekar sings in "Antibiotika" [Antibiotics], "I'm just a tourist in the country of my birth," Bok van Blerk sings in "Die kleur van my vel" [The colour of my skin] that the country does not want him despite his willingness to work, because he is white, and in "Bloekomboom" Rian Malan uses the metaphor of a blue gum tree (an alien species) to plead that Afrikaners should not be regarded as settlers, but as part of the nation. Steve Hofmeyr has expressed concern about the statistically high murders of Afrikaner farmers, and has also appealed in several speeches to remember Afrikaner heritage. His songs "Ons Sal Dit Oorleef" (We will survive this)and "My Kreed" (My Cry) also echoes many Afrikaners' fears of losing their culture and rights. The appeals by these musicians, and several others, to be included follows a sense of exclusion manifested in the political, linguistic and economic realms, an exclusion depicted particularly vividly by Bok van Blerk's "Kaplyn" [Cut line], a song that laments that fallen South African soldiers have been omitted in one of the country's show-case memorials, the Freedom Park Memorial, despite official claims of it being a memorial for all who had fought for the country.

Commonly, protest songs in South Korea are known as "Minjung Gayo" (, literally "People's song"), and the genre of protest songs is called "Norae Undong", literally "Song movement". It was raised by people in the 1970s~1980s to be against the military governments of Presidents Park Jeong-hee and Jeon Doo-hwan.

The Minjung-Gayo (Hangul: 민중가요; Hanja: 民衆歌謠) is one of Korean modern singing culture, which has been used as musical means of pro-democracy movement. It was mainly enjoyed by the people who are critical of mainstream song culture in the process of democratization movement. The term of Minjung-Gayo was naturally coined by people in the mid-1980s. Since this was the period when protest songs were grown rapidly and the singing movement began, It was needed to take care of protest songs, a new term that could be used to differentiate them from popular songs was necessary. In a broad sense, The Minjung-Gayo includes the anti-Japanese song on Japanese colonial era which is continued to the early 1970s. But Generally, the Minjung-Gayo means the culture which is matured in the late 1970s and lasted in 1990.

Korean protest song called Minjung-Gayo reflects the will of crowd and voices of criticism of the day. Korean protest song has emerged on 1980s, especially before and after of the June Democracy Movement in 1987.

The starting point of Korean protest songs is the music culture of Korean students movements around 1970. With criticizing about pop music or overcoming, It’s started that their own unique music culture having certain coriander layer and own existing method distinguished with pop culture. a few songs called as ‘Demo-ga’ (demonstration songs) and others from 1960s was chosen as ‘Minjung-Gayo’ (Korean protest songs). There’re ‘Haebang-ga(Hangul; 해방가)’,‘ Tana-Tana’, ‘Barami-bunda'(Hangul; 바람이 분다), ‘Stenka Razin’ an so on. After 1975, another songs like ‘Hula-song’, ‘Jungui-ga’ was added in the list.

Through the era of an emergency measure, the atmosphere of Korean universities was getting stiffer. Students who participated in the students' movements had to be prepared to die and they were required to have much stronger faith and actions. Students who participated in students’ movements became to be critic against old social systems as well as pop culture which we the result of old social system so that they started to pursue progressive and political culture. Spreading the criticism against pop music, a series of certain music culture which had such unique criticism of university students was established and it's the base of Korean protest songs.

The short 'Spring of democracy' before May, 1980 coming after 10.26 situation in 1979 was such a big opportunity to show the protest songs hidden by a few students to many students in public demonstrations. the organizers of demonstrations was spreading papers that the lyrics and sheet music was written on in continued demonstrations and in this period, the most of demonstrations were started to make the atmosphere with learning the songs.

The main stream of Korean protest songs in 1980's could divided in 3 period. The first period is the establishment of the protest songs. It is the period that many songs composed as marching song with minor like 'The March For Her' (Hanguel : 임을 위한 행진곡) were being written and the number of the songs were increased massively from 1980 to 1984.

The second period started with young men fresh just out of college, who had engaged in music club. They perform a concert the story of song "Eggplant Flower(Hangul; 가지꽃)" in Aeogae little theater by lending the name of theater "Handurae(Hangul; 한두레)". In this period, music has taken a part of social movement.

The third period is after the Democratic uprising in June, 1987 and the first regular performing of 'People seeking music' held in Korean church 100th anniversary memorial in oct, 1987 after the great labor conflict in Jul, Aug, Sep, 1987. In this period, they were trying to figure out how could they overcome limits that 'the music movement in universities' had and find new ways that they should be on. After successive The great labor conflict in July to September, protest song reflects the joys and sorrows of workers'. After going through this period, protest song embraces not only the intellectuals but also the working-class population.

From the middle of 1990s, since the social voices of the students demonstrations and the labor demonstrations started getting decreased, Korean protest songs has lost their popularity in many other fields except the struggle scenes. it's the period that the music groups in universities and the professional cultural demonstration groups started trying to change the form of Korean protest songs and trying new things. but It was not easy to change such generalized form of the music into the new wave.

in 2000s, from the memorial candle demonstration for the middle school girls who were killed by U.S Army's tank to the demonstration against importing mad cow disease beef from U.S, such people participatory demonstration culture started being settled. In this period, the songs not having such solemn atmosphere like 'Fucking USA', 'The first Korean constitution' were made, but the influence still could not spread wide and only stayed in the field

Born in Iksan-si, Jeonlabuk-do, He moved to Seoul before he was in primary school. From He made a group named 'Dobidoo' when he was in Seoul Univ, he started writting music. At that time, He met Heeuen, Yang who was his primary school friend and gave her song named 'Morning dew'<아침 이슬>, it was released in 1970. In 1972, he was arrested for singing songs 'We will win'<우리 승리하리라>, 'Freedom song'<해방가>, 'The child blowing flowers' <꽃피우는 아이> and so on and all of his song prevented from broadcasting. After he got out from Korean army, he wrote Heeuen, Yang's song 'Like the pine needles in wild grassland' <거치른 들판의 푸르른 솔잎처럼> and also wrote the song named 'The light in the factory' <공장의 불빛>.

<nowiki>'People who're finding songs'[노래를 찾는 사람들] is the music group writing Korean protest songs in 1980~90s (known as 'Nochatsa'[노찾사]). There're many demonstrations against the Korean military dictatorship around Korean universties in 1980s, and since then, lots of protest songs has been written by the students in those universtities. Korean protest songs [hangul : 민중가요 Minjung-gayo] reflected the reality of the period different from typical love songs so they wouldn't expect comercial success from the songs. However, the group's albums were actually comercially successful and have left footprints in Korean pop music history. 'Meari' from Seoul univ, 'Norea-erl' from Korea univ, 'Hansori' from Ehwa women univ, 'Sori-sarang' from Sungkyunkwan univ and etc were particepated in the group</nowiki>

"Island's Sunrise" (Chinese: 島嶼天光) is the theme song of 2014 Sunflower Student Movement in Taiwan. Also, the theme song of Lan Ling Wang TV drama series "Into The Array Song" (Chinese: 入陣曲), sung by Mayday, expressed all the social and political controversies during Taiwan under the president Ma Ying-jeou administration.

In Thailand, protest songs are known as "Phleng phuea chiwit" (, ; lit. "songs for life"), a music genre that originated in the '70s, by famous artists such as Caravan, Carabao, Pongthep Kradonchamnan and Pongsit Kamphee.

Emel Mathlouthi composed songs since a young age which called for freedom and dignity in a Tunisia ruled by the dictator Zine El Abidine Ben Ali, earning her scrutiny from internal security forces and forcing her to retreat to Paris. Banned from the official airwaves, her protest songs found listeners on social media. In late 2010 and early 2011, Tunisian protesters referred to her song Kelmti Horra (my word is free) as an anthem of the Tunisian Revolution.

The roots of the rebellious/protest music in Anatolia goes back to the 16th century. Asiks who lived in that era, like Pir Sultan Abdal, Koroglu and Dadaloglu who lived in the 18th century are still the inspirations. The tradition of rebellion have gone for centuries and have given many song to this geography´s culture. The message in Turkish protest music has been against inequality, lack of freedom, poverty, and the freedom of expression. Milder elements in this style are referred to as progressive, while some die-hard protest musicians have been prosecuted, and sometimes persecuted, in the 20th century Turkey. More than a few Turkish singers have been forced to exile, most notably Cem Karaca, who later returned to Turkey during freer conditions and atmosphere. Typically, Protest Music bands are leftist bands with a huge following, especially in high schools and universities. The music is a crossover between folk and rock and the lyrics are about freedom, repression and uprising, capitalism and the oppressed, and the revolution that never comes. It’s customary to say anti-American slogans here and there. The male singers always have a what we call Davidian voice (meaning deep and husky a la Barry White) and the females usually sing nasally with a high pitch.

 was a former Yugoslavian protest singer-songwriter.





</doc>
<doc id="23478" url="https://en.wikipedia.org/wiki?curid=23478" title="Professor Griff">
Professor Griff

Richard Griffin (born August 1, 1960), better known by his stage name Professor Griff, is an American rapper, spoken word artist, and lecturer. He is a member of the hip hop group Public Enemy and head of the group Security of the First World.

Before the release of "It Takes a Nation of Millions to Hold Us Back", Professor Griff, in his role as Minister of Information, gave interviews to UK magazines on behalf of Public Enemy, during which he made homophobic and anti-Semitic remarks. However, there was little controversy until May 22, 1989, when Griffin was interviewed by the "Washington Times". At the time, Public Enemy enjoyed unprecedented mainstream attention with the single "Fight the Power" from the soundtrack of Spike Lee's "Do the Right Thing".

During the interview with David Mills, Griffin made numerous statements such as "Jews are responsible for the majority of the wickedness in the world". When the interview was published, a media firestorm emerged, and the band found itself under intense scrutiny.
In a series of press conferences, Griffin was either fired, quit, or never left. Def Jam co-founder Rick Rubin had already left the label by then; taking his place alongside Russell Simmons was Lyor Cohen, the son of Israeli immigrants who had run Rush Artists Management since 1985. Before the dust settled, Cohen claims to have arranged for a Holocaust Museum to give the band a private tour.

In an attempt to defuse the situation, Ridenhour first expressed an apology on his behalf, and fired Griffin soon thereafter. Griffin later rejoined the group, provoking more protests, causing Ridenhour to briefly disband the group. When Public Enemy reformed, due to increasing attention from the press and pressure from Def Jam hierarchy, Griffin was no longer with the band.

Griffin later publicly expressed remorse for his statements after a meeting with the National Holocaust Awareness Student Organization in 1990.

In his 2009 book, titled "Analytixz", Griff once again admitted the faults in his alleged 1989 statement: "To say the Jews are responsible for the majority of wickedness that went on around the globe, I would have to know about the majority of wickedness that went on around the globe, which is impossible...I'm not the best knower—God is. Then, not only knowing that, I would have to know who is at the crux of all of the problems in the world and then blame Jewish people, which is not correct." Griff also said that not only were his words taken out of context, but that the recording was never released to the public for an unbiased listen.

Griffin embraces a radical form of Afrocentrism. "Muslim, Christian, Jew, Here's a little somethin' I thought you knew/There is only one God and God is one, the rich praises none."

After his departure from Public Enemy, Griffin formed his own group, the Last Asiatic Disciples. Griffin's albums were of an Islamic and Afrocentric style, combined with increasingly spoken word lyrics.

He was a member of the Nation of Islam, which his lyrics and record titles as a solo artist referenced. Another general theme in his lyrics is New World Order conspiracy.


</doc>
<doc id="23479" url="https://en.wikipedia.org/wiki?curid=23479" title="Physicalism">
Physicalism

In philosophy, physicalism is the ontological thesis that "everything is physical", that there is "nothing over and above" the physical, or that everything supervenes on the physical. Physicalism is a form of ontological monism—a "one substance" view of the nature of reality as opposed to a "two-substance" (dualism) or "many-substance" (pluralism) view. Both the definition of "physical" and the meaning of physicalism have been debated.

Physicalism is closely related to materialism. Physicalism grew out of materialism with advancements of the physical sciences in explaining observed phenomena. The terms are often used interchangeably, although they are sometimes distinguished, for example on the basis of physics describing more than just matter (including energy and physical law). Common arguments against physicalism include both the philosophical zombie argument and the multiple observers argument, that the existence of a physical being may imply zero or more distinct conscious entities.

The word "physicalism" was introduced into philosophy in the 1930s by Otto Neurath and Rudolf Carnap.

The use of "physical" in physicalism is a philosophical concept and can be distinguished from alternative definitions found in the literature (e.g. Karl Popper defined a physical proposition to be one which can at least in theory be denied by observation). A "physical property", in this context, may be a metaphysical or logical combination of properties which are physical in the ordinary sense. It is common to express the notion of "metaphysical or logical combination of properties" using the notion of supervenience: A property "A" is said to supervene on a property "B" if any change in "A" necessarily implies a change in "B". Since any change in a combination of properties must consist of a change in at least one component property, we see that the combination does indeed supervene on the individual properties. The point of this extension is that physicalists usually suppose the existence of various abstract concepts which are non-physical in the ordinary sense of the word; so physicalism cannot be defined in a way that denies the existence of these abstractions. Also, physicalism defined in terms of supervenience does not entail that all properties in the actual world are type identical to physical properties. It is, therefore, compatible with multiple realizability.

From the notion of supervenience, we see that, assuming that mental, social, and biological properties supervene on physical properties, it follows that two hypothetical worlds cannot be identical in their physical properties but differ in their mental, social or biological properties.

Two common approaches to defining "physicalism" are the theory-based and object-based approaches. The theory-based conception of physicalism proposes that "a property is physical if and only if it either is the sort of property that physical theory tells us about or else is a property which metaphysically (or logically) supervenes on the sort of property that physical theory tells us about". Likewise, the object-based conception claims that "a property is physical if and only if: it either is the sort of property required by a complete account of the intrinsic nature of paradigmatic physical objects and their constituents or else is a property which metaphysically (or logically) supervenes on the sort of property required by a complete account of the intrinsic nature of paradigmatic physical objects and their constituents".

Physicalists have traditionally opted for a "theory-based" characterization of the physical either in terms of current physics, or a future (ideal) physics. These two theory-based conceptions of the physical represent both horns of Hempel's dilemma (named after the late philosopher of science and logical empiricist Carl Gustav Hempel): an argument against theory-based understandings of the physical. Very roughly, Hempel's dilemma is that if we define the physical by reference to current physics, then physicalism is very likely to be false, as it is very likely (by pessimistic meta-induction) that much of current physics is false. But if we instead define the physical in terms of a future (ideal) or completed physics, then physicalism is hopelessly vague or indeterminate.

While the force of Hempel's dilemma against theory-based conceptions of the physical remains contested, alternative "non-theory-based" conceptions of the physical have also been proposed. Frank Jackson (1998) for example, has argued in favour of the aforementioned "object-based" conception of the physical. An objection to this proposal, which Jackson himself noted in 1998, is that if it turns out that panpsychism or panprotopsychism is true, then such a non-materialist understanding of the physical gives the counterintuitive result that physicalism is, nevertheless, also true since such properties will figure in a complete account of paradigmatic examples of the physical.

David Papineau and Barbara Montero have advanced and subsequently defended a "via negativa" characterization of the physical. The gist of the via negativa strategy is to understand the physical in terms of what it is not: the mental. In other words, the via negativa strategy understands the physical as "the non-mental". An objection to the via negativa conception of the physical is that (like the object-based conception) it doesn't have the resources to distinguish neutral monism (or panprotopsychism) from physicalism.

Adopting a supervenience-based account of the physical, the definition of physicalism as "all properties are physical" can be unravelled to:

1) Physicalism is true at a possible world "w" if and only if any world that is a physical duplicate of "w" is also a duplicate of "w simpliciter".

Applied to the actual world (our world), statement 1 above is the claim that physicalism is true at the actual world if and only if at "every possible world" in which the physical properties and laws of the actual world are instantiated, the non-physical (in the ordinary sense of the word) properties of the actual world are instantiated as well. To borrow a metaphor from Saul Kripke (1972), the truth of physicalism at the actual world entails that once God has instantiated or "fixed" the physical properties and laws of our world, then God's work is done; the rest comes "automatically".

Unfortunately, statement 1 fails to capture even a necessary condition for physicalism to be true at a world "w". To see this, imagine a world in which there are "only" physical properties—if physicalism is true at any world it is true at this one. But one can conceive physical duplicates of such a world that are "not" also duplicates simpliciter of it: worlds that have the same physical properties as our imagined one, but with some additional property or properties. A world might contain "epiphenomenal ectoplasm", some additional pure experience that does not interact with the physical components of the world and is not necessitated by them (does not supervene on them). To handle the epiphenomenal ectoplasm problem, statement 1 can be modified to include a "that's-all" or "totality" clause or be restricted to "positive" properties. Adopting the former suggestion here, we can reformulate statement 1 as follows:

2) Physicalism is true at a possible world "w" if and only if any world that is a "minimal" physical duplicate of "w" is a duplicate of "w simpliciter".

Applied in the same way, statement 2 is the claim that physicalism is true at a possible world "w" if and only if any world that is a physical duplicate of "w" (without any further changes), is duplicate of "w" without qualification. This allows a world in which there are only physical properties to be counted as one at which physicalism is true, since worlds in which there is some extra stuff are "not" "minimal" physical duplicates of such a world, nor are they minimal physical duplicates of worlds that contain some non-physical properties that are metaphysically necessitated by the physical.

But while statement 2 overcomes the problem of worlds at which there is some extra stuff (sometimes referred to as the "epiphenomenal ectoplasm problem") it faces a different challenge: the so-called "blockers problem". Imagine a world where the relation between the physical and non-physical properties at this world (call the world "w") is slightly weaker than metaphysical necessitation, such that a certain kind of non-physical intervener—"a blocker"—could, were it to exist at "w," prevent the non-physical properties in "w" from being instantiated by the instantiation of the physical properties at "w." Since statement 2 rules out worlds which are physical duplicates of "w" that also contain non-physical interveners by virtue of the minimality, or that's-all clause, statement 2 gives the (allegedly) incorrect result that physicalism is true at "w." One response to this problem is to abandon statement 2 in favour of the alternative possibility mentioned earlier in which supervenience-based formulations of physicalism are restricted to what David Chalmers (1996) calls "positive properties". A positive property is one that "...if instantiated in a world W, is also instantiated by the corresponding individual in all worlds that contain W as a proper part." Following this suggestion, we can then formulate physicalism as follows:

3) Physicalism is true at a possible world "w" if and only if any world that is a physical duplicate of "w" is a positive duplicate of "w".

On the face of it, statement 3 seems able to handle both the epiphenomenal ectoplasm problem and the blockers problem. With regard to the former, statement 3 gives the correct result that a purely physical world is one at which physicalism is true, since worlds in which there is some extra stuff are positive duplicates of a purely physical world. With regard to the latter, statement 3 appears to have the consequence that worlds in which there are blockers are worlds where positive non-physical properties of "w" will be absent, hence "w" will not be counted as a world at which physicalim is true. Daniel Stoljar (2010) objects to this response to the blockers problem on the basis that since the non-physical properties of "w" aren't instantiated at a world in which there is a blocker, they are not positive properties in Chalmers' (1996) sense, and so statement 3 will count "w" as a world at which physicalism is true after all.

A further problem for supervenience-based formulations of physicalism is the so-called "necessary beings problem". A necessary being in this context is a non-physical being that exists in all possible worlds (for example what theists refer to as God). A necessary being is compatible with all the definitions provided, because it is supervenient on everything; yet it is usually taken to contradict the notion that everything is physical. So any supervenience-based formulation of physicalism will at best state a necessary but not sufficient condition for the truth of physicalism.

Additional objections have been raised to the above definitions provided for supervenience physicalism: one could imagine an alternate world that differs only by the presence of a single ammonium molecule (or physical property), and yet based on statement 1, such a world might be completely different in terms of its distribution of mental properties. Furthermore, there are differences expressed concerning the modal status of physicalism; whether it is a necessary truth, or is only true in a world which conforms to certain conditions (i.e. those of physicalism).

Closely related to supervenience physicalism, is realisation physicalism, the thesis that every instantiated property is either physical or is realised by a physical property.

Token physicalism is the proposition that "for every actual particular (object, event or process) x, there is some physical particular y such that x = y". It is intended to capture the idea of "physical mechanisms". Token physicalism is compatible with property dualism, in which all substances are "physical", but physical objects may have mental properties as well as physical properties. Token physicalism is not however equivalent to supervenience physicalism. Firstly, token physicalism does not imply supervenience physicalism because the former does not rule out the possibility of non-supervenient properties (provided that they are associated only with physical particulars). Secondarily, supervenience physicalism does not imply token physicalism, for the former allows supervenient objects (such as a "nation", or "soul") that are not equal to any physical object.

There are multiple versions of reductionism. In the context of physicalism, the reductions referred to are of a "linguistic" nature, allowing discussions of, say, mental phenomena to be translated into discussions of physics. In one formulation, every concept is analysed in terms of a physical concept. One counter-argument to this supposes there may be an additional class of expressions which is non-physical but which increases the expressive power of a theory. Another version of reductionism is based on the requirement that one theory (mental or physical) be logically derivable from a second.

The combination of reductionism and physicalism is usually called reductive physicalism in the philosophy of mind. The opposite view is non-reductive physicalism. Reductive physicalism is the view that mental states are both nothing over and above physical states and reducible to physical states. One version of reductive physicalism is type physicalism or mind-body identity theory. Type physicalism asserts that "for every actually instantiated property F, there is some physical property G such that F=G". Unlike token physicalism, type physicalism entails supervenience physicalism.

A common argument against reductive physicalism is multiple realizability, the possibility that a psychological process (say) could be instantiated by many different neurological processes (even non-neurological processes, in the case of machine or alien intelligence). For in this case, the neurological terms translating a psychological term must be disjunctions over the possible instantiations, and it is argued that no physical law can use these disjunctions as terms. Type physicalism was the original target of the multiple realizability argument.

There are two versions of emergentism, the strong version and the weak version. Supervenience physicalism has been seen as a strong version of emergentism, in which the subject's psychological experience is considered genuinely novel. Non-reductive physicalism, on the other side, is a weak version of emergentism because it does not need that the subject's psychological experience be novel. The strong version of emergentism is incompatible with physicalism. Since there are novel mental states, mental states are not nothing over and above physical states. However, the weak version of emergentism is compatible with physicalism. 

We can see that emergentism is actually a very broad view. Some forms of emergentism appear either incompatible with physicalism or equivalent to it (e.g. posteriori physicalism), others appear to merge both dualism and supervenience. Emergentism compatible with dualism claims that mental states and physical states are metaphysically distinct while maintaining the supervenience of mental states on physical states. This proposition however contradicts supervenience physicalism, which asserts a denial of dualism.

Physicalists hold that physicalism is true. A natural question for physicalists, then, is whether the truth of physicalism is deducible a priori from the nature of the physical world (i.e., the inference is justified independently of experience, even though the nature of the physical world can itself only be determined through experience) or can only be deduced a posteriori (i.e., the justification of the inference itself is dependent upon experience). So-called "a priori physicalists" hold that from knowledge of the conjunction of all physical truths, a totality or that's-all truth (to rule out non-physical epiphenomena, and enforce the closure of the physical world), and some primitive indexical truths such as "I am A" and "now is B", the truth of physicalism is knowable a priori. Let "P" stand for the conjunction of all physical truths and laws, "T" for a that's-all truth, "I" for the indexical "centering" truths, and "N" for any [presumably non-physical] truth at the actual world. We can then, using the material conditional "→", represent a priori physicalism as the thesis that PTI → N is knowable a priori. An important wrinkle here is that the concepts in N must be possessed non-deferentially in order for PTI → N to be knowable a priori. The suggestion, then, is that possession of the concepts in the consequent, plus the empirical information in the antecedent is sufficient for the consequent to be knowable a priori.

An "a posteriori physicalist", on the other hand, will reject the claim that PTI → N is knowable a priori. Rather, they would hold that the inference from PTI to N is justified by metaphysical considerations that in turn can be derived from experience. So the claim then is that "PTI and not N" is metaphysically impossible.

One commonly issued challenge to a priori physicalism and to physicalism in general is the "conceivability argument", or zombie argument. At a rough approximation, the conceivability argument runs as follows:

P1) PTI and not Q (where "Q" stands for the conjunction of all truths about consciousness, or some "generic" truth about someone being "phenomenally" conscious [i.e., there is "something it is like" to be a person x] ) is conceivable (i.e., it is not knowable a priori that PTI and not Q is false).

P2) If PTI and not Q is conceivable, then PTI and not Q is metaphysically possible.

P3) If PTI and not Q is metaphysically possible then physicalism is false.

C) Physicalism is false.

Here proposition P3 is a direct application of the supervenience of consciousness, and hence of any supervenience-based version of physicalism: If PTI and not Q is possible, there is some possible world where it is true. This world differs from [the relevant indexing on] our world, where PTIQ is true. But the other world is a minimal physical duplicate of our world, because PT is true there. So there is a possible world which is a minimal physical duplicate of our world, but not a full duplicate; this contradicts the definition of physicalism that we saw above.

Since a priori physicalists hold that PTI → N is a priori, they are committed to denying P1) of the conceivability argument. The a priori physicalist, then, must argue that PTI and not Q, on ideal rational reflection, is incoherent or contradictory.

A posteriori physicalists, on the other hand, generally accept P1) but deny P2)--the move from "conceivability to metaphysical possibility". Some a posteriori physicalists think that unlike the possession of most, if not all other empirical concepts, the possession of consciousness has the special property that the presence of PTI and the absence of consciousness will be conceivable—even though, according to them, it is knowable a posteriori that PTI and not Q is not metaphysically possible. These a posteriori physicalists endorse some version of what Daniel Stoljar (2005) has called "the phenomenal concept strategy". Roughly speaking, the phenomenal concept strategy is a label for those a posteriori physicalists who attempt to show that it is only the "concept" of consciousness—not the "property"—that is in some way "special" or sui generis. Other a posteriori physicalists eschew the phenomenal concept strategy, and argue that even ordinary macroscopic truths such as "water covers 60% of the earth's surface" are not knowable a priori from PTI and a non-deferential grasp of the concepts "water" and "earth" "et cetera". If this is correct, then we should (arguably) conclude that conceivability does not entail metaphysical possibility, and P2) of the conceivability argument against physicalism is false.

Galen Strawson's "realistic physicalism" (or "realistic monism") entails panpsychism – or at least micropsychism. Strawson argues that "many—perhaps most—of those who call themselves physicalists or materialists [are mistakenly] committed to the thesis that physical stuff is, in itself, in its fundamental nature, something wholly and utterly non-experiential... even when they are prepared to admit with Eddington that physical stuff has, in itself, 'a nature capable of manifesting itself as mental activity', i.e. as experience or consciousness". Because experiential phenomena allegedly cannot be emergent from wholly non-experiential phenomena, philosophers are driven to substance dualism, property dualism, eliminative materialism and "all other crazy attempts at wholesale mental-to-non-mental reduction".

Daniel Stoljar's SEP entry on Physicalism: http://plato.stanford.edu/entries/physicalism/


</doc>
<doc id="23482" url="https://en.wikipedia.org/wiki?curid=23482" title="Parallelism">
Parallelism

Parallelism may refer to:




</doc>
<doc id="23483" url="https://en.wikipedia.org/wiki?curid=23483" title="Philosophy of perception">
Philosophy of perception

The philosophy of perception is concerned with the nature of perceptual experience and the status of perceptual data, in particular how they relate to beliefs about, or knowledge of, the world. Any explicit account of perception requires a commitment to one of a variety of ontological or metaphysical views. Philosophers distinguish internalist accounts, which assume that perceptions of objects, and knowledge or beliefs about them, are aspects of an individual's mind, and externalist accounts, which state that they constitute real aspects of the world external to the individual. The position of naïve realism—the 'everyday' impression of physical objects constituting what is perceived—is to some extent contradicted by the occurrence of perceptual illusions and hallucinations and the relativity of perceptual experience as well as certain insights in science. Realist conceptions include phenomenalism and direct and indirect realism. Anti-realist conceptions include idealism and skepticism.

We may categorize perception as "internal" or "external".

The philosophy of perception is mainly concerned with exteroception.

An object at some distance from an observer will reflect light in all directions, some of which will fall upon the corneae of the eyes, where it will be focussed upon each retina, forming an image. The disparity between the electrical output of these two slightly different images is resolved either at the level of the lateral geniculate nucleus or in a part of the visual cortex called 'V1'. The resolved data is further processed in the visual cortex where some areas have specialised functions, for instance area V5 is involved in the modelling of motion and V4 in adding colour. The resulting single image that subjects report as their experience is called a 'percept'. Studies involving rapidly changing scenes show the percept derives from numerous processes that involve time delays. Recent fMRI studies show that dreams, imaginings and perceptions of things such as faces are accompanied by activity in many of the same areas of brain as are involved with physical sight. Imagery that originates from the senses and internally generated imagery may have a shared ontology at higher levels of cortical processing.

Sound is analyzed in term of pressure waves sensed by the cochlea in the ear. Data from the eyes and ears is combined to form a 'bound' percept. The problem of how this is produced, known as the binding problem.

Perception is analyzed as a cognitive process in which information processing is used to transfer information into the mind where it is related to other information. Some psychologists propose that this processing gives rise to particular mental states (cognitivism) whilst others envisage a direct path back into the external world in the form of action (radical behaviourism). Behaviourists such as John B. Watson and B.F. Skinner have proposed that perception acts largely as a process between a stimulus and a response but have noted that Gilbert Ryle's "ghost in the machine of the brain" still seems to exist. "The objection to inner states is not that they do not exist, but that they are not relevant in a functional analysis". This view, in which experience is thought to be an incidental by-product of information processing, is known as epiphenomenalism.

Contrary to the behaviouralist approach to understanding the elements of cognitive processes, gestalt psychology sought to understand their organization as a whole, studying perception as a process of figure and ground.

Important philosophical problems derive from the epistemology of perception—how we can gain knowledge via perception—such as the question of the nature of qualia. Within the biological study of perception naive realism is unusable. However, outside biology modified forms of naive realism are defended. Thomas Reid, the eighteenth-century founder of the Scottish School of Common Sense, formulated the idea that sensation was composed of a set of data transfers but also declared that there is still a direct connection between perception and the world. This idea, called direct realism, has again become popular in recent years with the rise of postmodernism.

The succession of data transfers involved in perception suggests that sense data are somehow available to a perceiving subject that is the substrate of the percept. Indirect realism, the view held by John Locke and Nicolas Malebranche, proposes that we can only be aware of mental representations of objects. however this may imply an infinite regress (a perceiver within a perceiver within a perceiver...), though a finite regress is perfectly possible. It also assumes that perception is entirely due to data transfer and information processing, an argument that can be avoided by proposing that the percept does not depend wholly upon the transfer and rearrangement of data. This still involves basic ontological issues of the sort raised by Leibniz Locke, Hume, Whitehead and others, which remain outstanding particularly in relation to the binding problem, the question of how different perceptions (e.g. color and contour in vision) are "bound" to the same object when they are processed by separate areas of the brain.

Indirect realism (representational views) provides an account of issues such as perceptual contents, qualia, dreams, imaginings, hallucinations, illusions, the resolution of binocular rivalry, the resolution of multistable perception, the modelling of motion that allows us to watch TV, the sensations that result from direct brain stimulation, the update of the mental image by saccades of the eyes and the referral of events backwards in time. Direct realists must either argue that these experiences do not occur or else refuse to define them as perceptions.

Idealism holds that reality is limited to mental qualities while skepticism challenges our ability to know anything outside our minds. One of the most influential proponents of idealism was George Berkeley who maintained that everything was mind or dependent upon mind. Berkeley's idealism has two main strands, phenomenalism in which physical events are viewed as a special kind of mental event and subjective idealism. David Hume is probably the most influential proponent of skepticism.

A fourth theory of perception in opposition to naive realism, enactivism, attempts to find a middle path between direct realist and indirect realist theories, positing that cognition arises as a result of the dynamic interplay between an organism's sensory-motor capabilities and its environment. Instead of seeing perception as a passive process determined entirely by the features of an independently existing world, enactivism suggests that organism and environment are structurally coupled and co-determining. The theory was first formalized by Francisco Varela, Evan Thompson, and Eleanor Rosch in "The Embodied Mind".

An aspect of perception that is common to both realists and anti-realists is the idea of mental or perceptual space. David Hume concluded that things appear extended because they have attributes of colour and solidity. A popular modern philosophical view is that the brain cannot contain images so our sense of space must be due to the actual space occupied by physical things. However, as René Descartes noticed, perceptual space has a projective geometry, things within it appear as if they are viewed from a point. The phenomenon of perspective was closely studied by artists and architects in the Renaissance, who relied mainly on the 11th century polymath, Alhazen (Ibn al-Haytham), who affirmed the visibility of perceptual space in geometric structuring projections. Mathematicians now know of many types of projective geometry such as complex Minkowski space that might describe the layout of things in perception (see Peters (2000)) and it has also emerged that parts of the brain contain patterns of electrical activity that correspond closely to the layout of the retinal image (this is known as retinotopy). How or whether these become conscious experience is still unknown (see McGinn (1995)).




</doc>
<doc id="23484" url="https://en.wikipedia.org/wiki?curid=23484" title="Proper name (philosophy)">
Proper name (philosophy)

In the philosophy of language a proper name, for example the names of persons or places, is a name which is ordinarily taken to uniquely identify its referent in the world. As such it presents particular challenges for theories of meaning and it has become a central problem in analytical philosophy. The common sense view was originally formulated by John Stuart Mill in "A System of Logic" where he defines it as "a word that answers the purpose of showing what thing it is that we are talking about but not of telling anything about it". This view was criticized when philosophers applied principles of formal logic to linguistic propositions. Gottlob Frege pointed out that proper names may apply to imaginary and inexistent entities without becoming meaningless, and he showed that sometimes more than one proper name may identify the same entity without having the same "sense", so that the phrase "Homer believed the morning star was the evening star" could be meaningful and not tautological in spite of the fact that the morning star and the evening star identifies the same referent. This example became known as Frege's Puzzle and is a central issue in the theory of proper names.

Bertrand Russell was the first to propose a Descriptivist theory of names, which held that a proper name refers not to a referent, but to a set of true propositions that uniquely describe a referent - for example "Aristotle" refers to "the teacher of Alexander the Great". Rejecting descriptivism Saul Kripke and Keith Donnellan instead advanced causal-historical theories of reference which hold that names come to be associated with individual referents because social groups who links the name to its reference in a naming event (e.g. a baptism) which henceforth fixes the value of the name to the specific referent within that community. Today a direct reference theory is common, which holds that proper names refer to their referents without attributing any additional information, connotative or of sense, about them.

The problem of proper names arise within a theory of meaning that is based on truth values and propositional logic, when trying to ascertain the criteria with which to determine if propositions that include proper names are true or false.

For example, in the proposition "Cicero is Roman" it is unclear what semantic content the proper name "Cicero" provides to the proposition. One may intuitively assume that the name refers to a person who may or may not be Roman, and that the truth value depends on whether that is the case or not. But from the point of view of a theory of meaning the question is "how" the word Cicero establishes its referent.

Another problem known as Frege's Puzzle, asks why it can be the case that the two names can refer to the same referent, yet not necessarily be considered entirely synonymous. His example is that the proposition "Hesperus is Hesperus" (Hesperus being the Greek name of the morning star) is tautological and vacuous while the proposition "Hesperus is Phosphorus" (Phosphorus being the Greek name of the evening star) conveys information. This puzzle suggests that there is something more to the meaning of the proper name than simply pointing out its referent.

Many theories have been proposed about proper names, each attempting to solve the problems of reference and identity inherent in the concept.

John Stuart Mill distinguished between connotative and denotative meaning, and argued that proper names included no other semantic content to a proposition than identifying the referent of the name and were hence purely denotative. Some contemporary proponents of a Millian theory of naming argue that the process through which something becomes a proper name is exactly the gradual loss of connotation for pure denotation - such as the process that turned the descriptive propositions "long island" into the proper name Long Island.

Frege argued that one had to distinguish between the sense ("Sinn") and the reference of the name. And that different names for the same entity might identify the same referent without being formally synonymous. For example, although the Morning star and the evening star is the same astronomical object, the proposition "the morning star is the evening star" is not a tautology but provides actual information to someone who did not know this. Hence to Frege the two names for the object must have a different sense. Philosophers such as John McDowell have elaborated on Frege's theory of proper names.

The "descriptive" theory of proper names is the view that the meaning of a given use of a proper name is a set of properties that can be expressed as a description that picks out an object that satisfies the description. 
Bertrand Russell espoused such a view arguing that the name refers to a description, and that description, like a definition, "picks out" the bearer of the name. The description then functions as an abbreviation or a truncated form of the description. The distinction between the embedded description and the bearer itself is similar to that between the "extension" and the "intension" (Frege's terms) of a general term, or between connotation and denotation (Mill's terms).

John Searle elaborated Russell's theory suggesting that the proper name refers to a cluster of propositions that in combination pick out a unique referent. This was meant to deal with the objection by some critics of Russell's theory that a descriptive theory of meaning would make the referent of a name dependent on the knowledge that the person saying the name has about the referent.

In 1973 Tyler Burge proposed a metalinguistic descriptivist theory of proper names which holds that names have the meaning that corresponds to the description of the individual entities to whom the name is applied. This however opens up for the possibility that names are not proper, when for example more than one person shares the same name. This leads Burge to argue that plural usages of names, such as "all the Alfreds I know have red hair", support this view.

The causal-historical theory originated by Saul Kripke in "Naming and Necessity", building on work by among others Keith Donnellan, combines the referential view with the idea that the name's referent is fixed by a baptismal act, whereupon the name becomes a rigid designator of the referent. Kripke did not emphasize causality, but rather the historical relation between the naming event and the community of speakers within which it circulates, but in spite of this the theory is often called "a causal theory of naming".

The pragmatic naming theory of Charles Sanders Peirce is sometimes considered a precursor of causal-historical naming theory. He described proper names in the following terms: "A proper name, when one meets with it for the first time, is existentially connected with some percept or other equivalent individual knowledge of the individual it names. It is then, and then only, a genuine Index. The next time one meets with it, one regards it as an Icon of that Index. The habitual acquaintance with it having been acquired, it becomes a Symbol whose Interpretant represents it as an Icon of an Index of the Individual named." Here he notes out that the baptismal event takes place for each person when a proper name is first associated with a referent (for example by pointing and saying "this is John", establishing an indexical relation between the name and the person) who is henceforth considered to be a conventional ("symbolic" in Peircean terms) references to the referent. [ "who is...a conventional...references to the referent" is grammatically incorrect, rendering the whole sentence incoherent]

Rejecting sense-based, descriptivist and causal-historical theories of naming, theories of direct reference hold that names together with demonstratives are a class of words that refer directly to their referent.

In the "Tractatus Logico Philosophicus" Ludwig Wittgenstein also held a direct reference position, arguing that names refer to a particular directly, and that this referent is its only meaning. In his later work however he has been attributed a cluster-descriptivist position based on the idea of family resemblances (for example by Kripke), although it has been argued that this misconstrues Wittgenstein's argument. Particularly his later view has been compared to that of Kripke's own view which recognizes names as stemming from a social convention and pragmatic principles of understanding others utterances.

Direct reference theory is similar to Mill's theory in that it proposes that the only meaning of a proper name is its referent. Modern proposals such as those by David Kaplan, which distinguish between Fregean and non-Fregean terms, the former which have both sense and reference and the latter which include proper names and have only reference.

Outside of the analytic tradition few continental philosophers have approached the proper name as a philosophical problem. In "Of Grammatology" Jacques Derrida specifically refutes the idea that proper names stand outside of the social construct of language as a binary relation between referent and sign. Rather he argues, the proper name as all words are caught up in a context of social, spatial and temporal differences that make it meaningful. He also notes that there are subjective elements of meaning in proper names, since they connect the bearer of a name with the sign of their own identity.




</doc>
<doc id="23485" url="https://en.wikipedia.org/wiki?curid=23485" title="Prolog">
Prolog

Prolog is a general-purpose logic programming language associated with artificial intelligence and computational linguistics.

Prolog has its roots in first-order logic, a formal logic, and unlike many other programming languages, Prolog is intended primarily as a declarative programming language: the program logic is expressed in terms of relations, represented as facts and rules. A computation is initiated by running a "query" over these relations.

The language was first conceived by a group around Alain Colmerauer in Marseille, France, in the early 1970s and the first Prolog system was developed in 1972 by Colmerauer with Philippe Roussel.

Prolog was one of the first logic programming languages, and remains the most popular among such languages today, with several free and commercial implementations available. The language has been used for theorem proving, expert systems, term rewriting, type inference, and automated planning, as well as its original intended field of use, natural language processing. Modern Prolog environments support the creation of graphical user interfaces, as well as administrative and networked applications.

Prolog is well-suited for specific tasks that benefit from rule-based logical queries such as searching databases, voice control systems, and filling templates.

In Prolog, program logic is expressed in terms of relations, and a computation is initiated by running a "query" over these relations. Relations and queries are constructed using Prolog's single data type, the "term". Relations are defined by "clauses". Given a query, the Prolog engine attempts to find a resolution refutation of the negated query. If the negated query can be refuted, i.e., an instantiation for all free variables is found that makes the union of clauses and the singleton set consisting of the negated query false, it follows that the original query, with the found instantiation applied, is a logical consequence of the program. This makes Prolog (and other logic programming languages) particularly useful for database, symbolic mathematics, and language parsing applications. Because Prolog allows impure predicates, checking the truth value of certain special predicates may have some deliberate side effect, such as printing a value to the screen. Because of this, the programmer is permitted to use some amount of conventional imperative programming when the logical paradigm is inconvenient. It has a purely logical subset, called "pure Prolog", as well as a number of extralogical features.

Prolog's single data type is the "term". Terms are either "atoms", "numbers", "variables" or "compound terms".


Special cases of compound terms:

ISO Prolog provides the codice_11, codice_12, codice_13, and codice_14 predicates for type-checking.

Prolog programs describe relations, defined by means of clauses. Pure Prolog is restricted to Horn clauses. There are two types of clauses: facts and rules. A rule is of the form

Head :- Body.

and is read as "Head is true if Body is true". A rule's body consists of calls to predicates, which are called the rule's goals. The built-in predicate codice_15 (meaning a 2-arity operator with name codice_16) denotes conjunction of goals, and codice_17 denotes disjunction. Conjunctions and disjunctions can only appear in the body, not in the head of a rule.

Clauses with empty bodies are called facts. An example of a fact is:

cat(tom).

which is equivalent to the rule:

cat(tom) :- true.

The built-in predicate codice_18 is always true.

Given the above fact, one can ask:

"is tom a cat?"
"what things are cats?"
Clauses with bodies are called rules. An example of a rule is:

animal(X) :- cat(X).

If we add that rule and ask "what things are animals?"
Due to the relational nature of many built-in predicates, they can typically be used in several directions. For example, codice_19 can be used to determine the length of a list (codice_20, given a list codice_21) as well as to generate a list skeleton of a given length (codice_22), and also to generate both list skeletons and their lengths together (codice_23). Similarly, codice_24 can be used both to append two lists (codice_25 given lists codice_26 and codice_27) as well as to split a given list into parts (codice_28, given a list codice_21). For this reason, a comparatively small set of library predicates suffices for many Prolog programs.

As a general purpose language, Prolog also provides various built-in predicates to perform routine activities like input/output, using graphics and otherwise communicating with the operating system. These predicates are not given a relational meaning and are only useful for the side-effects they exhibit on the system. For example, the predicate codice_30 displays a term on the screen.

Execution of a Prolog program is initiated by the user's posting of a single goal, called the query. Logically, the Prolog engine tries to find a resolution refutation of the negated query. The resolution method used by Prolog is called SLD resolution. If the negated query can be refuted, it follows that the query, with the appropriate variable bindings in place, is a logical consequence of the program. In that case, all generated variable bindings are reported to the user, and the query is said to have succeeded. Operationally, Prolog's execution strategy can be thought of as a generalization of function calls in other languages, one difference being that multiple clause heads can match a given call. In that case, the system creates a choice-point, unifies the goal with the clause head of the first alternative, and continues with the goals of that first alternative. If any goal fails in the course of executing the program, all variable bindings that were made since the most recent choice-point was created are undone, and execution continues with the next alternative of that choice-point. This execution strategy is called chronological backtracking. For example:
This results in the following query being evaluated as true:
This is obtained as follows: Initially, the only matching clause-head for the query codice_31 is the first one, so proving the query is equivalent to proving the body of that clause with the appropriate variable bindings in place, i.e., the conjunction codice_32. The next goal to be proved is the leftmost one of this conjunction, i.e., codice_33. Two clause heads match this goal. The system creates a choice-point and tries the first alternative, whose body is codice_34. This goal can be proved using the fact codice_35, so the binding codice_36 is generated, and the next goal to be proved is the second part of the above conjunction: codice_37. Again, this can be proved by the corresponding fact. Since all goals could be proved, the query succeeds. Since the query contained no variables, no bindings are reported to the user. A query with variables, like:

?- father_child(Father, Child).

enumerates all valid answers on backtracking.

Notice that with the code as stated above, the query codice_38 also succeeds. One would insert additional goals to describe the relevant restrictions, if desired.

Iterative algorithms can be implemented by means of recursive predicates.

The built-in Prolog predicate codice_39 provides negation as failure, which allows for non-monotonic reasoning. The goal codice_40 in the rule

legal(X) :- \+ illegal(X).

is evaluated as follows: Prolog attempts to prove codice_41. If a proof for that goal can be found, the original goal (i.e., codice_40) fails. If no proof can be found, the original goal succeeds. Therefore, the codice_39 prefix operator is called the "not provable" operator, since the query codice_44 succeeds if Goal is not provable. This kind of negation is sound if its argument is "ground" (i.e. contains no variables). Soundness is lost if the argument contains variables and the proof procedure is complete. In particular, the query codice_45 can now not be used to enumerate all things that are legal.

In Prolog, loading code is referred to as "consulting". Prolog can be used interactively by entering queries at the Prolog prompt codice_46. If there is no solution, Prolog writes codice_47. If a solution exists then it is printed. If there are multiple solutions to the query, then these can be requested by entering a semi-colon codice_48. There are guidelines on good programming practice to improve code efficiency, readability and maintainability.

Here follow some example programs written in Prolog.

An example of a query:
Any computation can be expressed declaratively as a sequence of state transitions. As an example, an optimizing compiler with three optimization passes could be implemented as a relation between an initial program and its optimized form:

or equivalently using DCG notation:

The quicksort sorting algorithm, relating a list to its sorted version:
A design pattern is a general reusable solution to a commonly occurring problem in software design. In Prolog, design patterns go under various names: skeletons and techniques, cliches, program schemata, and logic description schemata.
An alternative to design patterns is higher order programming.

A higher-order predicate is a predicate that takes one or more other predicates as arguments. Although support for higher-order programming takes Prolog outside the domain of first-order logic, which does not allow quantification over predicates, ISO Prolog now has some built-in higher-order predicates such as codice_49, codice_50, codice_51, codice_52, codice_53, and codice_54. Furthermore, since arbitrary Prolog goals can be constructed and evaluated at run-time, it is easy to write higher-order predicates like codice_55, which applies an arbitrary predicate to each member of a given list, and codice_56, which filters elements that satisfy a given predicate, also allowing for currying.

To convert solutions from temporal representation (answer substitutions on backtracking) to spatial representation (terms), Prolog has various all-solutions predicates that collect all answer substitutions of a given query in a list. This can be used for list comprehension. For example, perfect numbers equal the sum of their proper divisors:

This can be used to enumerate perfect numbers, and also to check whether a number is perfect.

As another example, the predicate codice_57 applies a predicate codice_58 to all corresponding positions in a pair of lists:

When codice_58 is a predicate that for all codice_60, codice_61 unifies codice_62 with a single unique value, codice_63 is equivalent to applying the map function in functional programming as codice_64.

Higher-order programming style in Prolog was pioneered in HiLog and λProlog.

For programming in the large, Prolog provides a module system. The module system is standardised by ISO. However, not all Prolog compilers support modules, and there are compatibility problems between the module systems of the major Prolog compilers. Consequently, modules written on one Prolog compiler will not necessarily work on others.

There is a special notation called definite clause grammars (DCGs). A rule defined via codice_65 instead of codice_66 is expanded by the preprocessor (codice_67, a facility analogous to macros in other languages) according to a few straightforward rewriting rules, resulting in ordinary Prolog clauses. Most notably, the rewriting equips the predicate with two additional arguments, which can be used to implicitly thread state around, analogous to monads in other languages. DCGs are often used to write parsers or list generators, as they also provide a convenient interface to difference lists.

Prolog is a homoiconic language and provides many facilities for reflection. Its implicit execution strategy makes it possible to write a concise meta-circular evaluator (also called "meta-interpreter") for pure Prolog code:
solve(true).
solve((Subgoal1,Subgoal2)) :- 
solve(Head) :- 

where codice_68 represents an empty conjunction, and codice_69 unifies with clauses in the database of the form codice_70.

Since Prolog programs are themselves sequences of Prolog terms (codice_66 is an infix operator) that are easily read and inspected using built-in mechanisms (like codice_72), it is possible to write customized interpreters that augment Prolog with domain-specific features. For example, Sterling and Shapiro present a meta-interpreter that performs reasoning with uncertainty, reproduced here with slight modifications:
solve(true, 1) :- !.
solve((Subgoal1,Subgoal2), Certainty) :-
solve(Goal, 1) :-
solve(Head, Certainty) :-
This interpreter uses a table of built-in Prolog predicates of the form
builtin(A is B).
builtin(read(X)).
% etc.
and clauses represented as codice_73. Given those, it can be called as codice_74 to execute codice_75 and obtain a measure of certainty about the result.

Pure Prolog is based on a subset of first-order predicate logic, Horn clauses, which is Turing-complete. Turing completeness of Prolog can be shown by using it to simulate a Turing machine:
A simple example Turing machine is specified by the facts:
This machine performs incrementation by one of a number in unary encoding: It loops over any number of "1" cells and appends an additional "1" at the end. Example query and result:
This illustrates how any computation can be expressed declaratively as a sequence of state transitions, implemented in Prolog as a relation between successive states of interest.

The ISO Prolog standard consists of two parts. ISO/IEC 13211-1, published in 1995, aims to standardize the existing practices of the many implementations of the core elements of Prolog. It has clarified aspects of the language that were previously ambiguous and leads to portable programs. There are three corrigenda: Cor.1:2007, Cor.2:2012, and Cor.3:2017. ISO/IEC 13211-2, published in 2000, adds support for modules to the standard. The standard is maintained by the ISO/IEC JTC1/SC22/WG17 working group. ANSI X3J17 is the US Technical Advisory Group for the standard.

For efficiency, Prolog code is typically compiled to abstract machine code, often influenced by the register-based Warren Abstract Machine (WAM) instruction set. Some implementations employ abstract interpretation to derive type and mode information of predicates at compile time, or compile to real machine code for high performance. Devising efficient implementation methods for Prolog code is a field of active research in the logic programming community, and various other execution methods are employed in some implementations. These include clause binarization and stack-based virtual machines.

Prolog systems typically implement a well-known optimization method called tail call optimization (TCO) for deterministic predicates exhibiting tail recursion or, more generally, tail calls: A clause's stack frame is discarded before performing a call in a tail position. Therefore, deterministic tail-recursive predicates are executed with constant stack space, like loops in other languages.

Finding clauses that are unifiable with a term in a query is linear in the number of clauses. Term indexing uses a data structure that enables sub-linear-time lookups. Indexing only affects program performance, it does not affect semantics. Most Prologs only use indexing on the first term, as indexing on all terms is expensive, but techniques based on "field-encoded words" or "superimposed codewords" provide fast indexing across the full query and head.

Some Prolog systems, such as WIN-PROLOG and SWI-Prolog, now implement hashing to help handle large datasets more efficiently. This tends to yield very large performance gains when working with large corpora such as WordNet.

Some Prolog systems, (B-Prolog, XSB, SWI-Prolog, YAP, and Ciao), implement a memoization method called "tabling", which frees the user from manually storing intermediate results.
Subgoals encountered in a query evaluation are maintained in a table, along with answers to these subgoals. If a subgoal is re-encountered, the evaluation reuses information from the table rather than re-performing resolution against program clauses.
Tabling is a space–time tradeoff; execution time can be reduced by using more memory to store intermediate results.

During the Fifth Generation Computer Systems project, there were attempts to implement Prolog in hardware with the aim of achieving faster execution with dedicated architectures. Furthermore, Prolog has a number of properties that may allow speed-up through parallel execution. A more recent approach has been to compile restricted Prolog programs to a field programmable gate array. However, rapid progress in general-purpose hardware has consistently overtaken more specialised architectures.

Although Prolog is widely used in research and education, Prolog and other logic programming languages have not had a significant impact on the computer industry in general. Most applications are small by industrial standards, with few exceeding 100,000 lines of code. Programming in the large is considered to be complicated because not all Prolog compilers support modules, and there are compatibility problems between the module systems of the major Prolog compilers. Portability of Prolog code across implementations has also been a problem, but developments since 2007 have meant: "the portability within the family of Edinburgh/Quintus derived Prolog implementations is good enough to allow for maintaining portable real-world applications."

Software developed in Prolog has been criticised for having a high performance penalty compared to conventional programming languages. In particular, Prolog's non-deterministic evaluation strategy can be problematic when programming deterministic computations, or when even using "don't care non-determinism" (where a single choice is made instead of backtracking over all possibilities). Cuts and other language constructs may have to be used to achieve desirable performance, destroying one of Prolog's main attractions, the ability to run programs "backwards and forwards".

Prolog is not purely declarative: because of constructs like the cut operator, a procedural reading of a Prolog program is needed to understand it. The order of clauses in a Prolog program is significant, as the execution strategy of the language depends on it. Other logic programming languages, such as Datalog, are truly declarative but restrict the language. As a result, many practical Prolog programs are written to conform to Prolog's depth-first search order, rather than as purely declarative logic programs.

Various implementations have been developed from Prolog to extend logic programming capabilities in numerous directions. These include types, modes, constraint logic programming (CLP), object-oriented logic programming (OOLP), concurrency, linear logic (LLP), functional and higher-order logic programming capabilities, plus interoperability with knowledge bases:

Prolog is an untyped language. Attempts to introduce types date back to the 1980s, and as of 2008 there are still attempts to extend Prolog with types. Type information is useful not only for type safety but also for reasoning about Prolog programs.<ref name="cite doi|10.1007/BF01213601"></ref>

The syntax of Prolog does not specify which arguments of a predicate are inputs and which are outputs. However, this information is significant and it is recommended that it be included in the comments. Modes provide valuable information when reasoning about Prolog programs and can also be used to accelerate execution.

Constraint logic programming extends Prolog to include concepts from constraint satisfaction. A constraint logic program allows constraints in the body of clauses, such as: codice_76 It is suited to large-scale combinatorial optimisation problems and is thus useful for applications in industrial settings, such as automated time-tabling and production scheduling. Most Prolog systems ship with at least one constraint solver for finite domains, and often also with solvers for other domains like rational numbers.

Flora-2 is an object-oriented knowledge representation and reasoning system based on F-logic and incorporates HiLog, Transaction logic, and defeasible reasoning.

Logtalk is an object-oriented logic programming language that can use most Prolog implementations as a back-end compiler. As a multi-paradigm language, it includes support for both prototypes and classes.

Oblog is a small, portable, object-oriented extension to Prolog by Margaret McDougall of EdCAAD, University of Edinburgh.

Objlog was a frame-based language combining objects and Prolog II from CNRS, Marseille, France.

Prolog++ was developed by Logic Programming Associates and first released in 1989 for MS-DOS PCs. Support for other platforms was added, and a second version was released in 1995. A book about Prolog++ by Chris Moss was published by Addison-Wesley in 1994.

Prolog systems that provide a graphics library are SWI-Prolog, Visual Prolog, WIN-PROLOG, and B-Prolog.

Prolog-MPI is an open-source SWI-Prolog extension for distributed computing over the Message Passing Interface. Also there are various concurrent Prolog programming languages.

Some Prolog implementations, notably SWI-Prolog and Ciao, support server-side web programming with support for web protocols, HTML and XML. There are also extensions to support semantic web formats such as RDF and OWL. Prolog has also been suggested as a client-side language.

Cedar is a free and basic Prolog interpreter. From version 4 and above Cedar has a FCA (Flash Cedar App) support. This provides a new platform to programming in Prolog through ActionScript.


Frameworks exist which can bridge between Prolog and other languages:

The name "Prolog" was chosen by Philippe Roussel as an abbreviation for "" (French for "programming in logic"). It was created around 1972 by Alain Colmerauer with Philippe Roussel, based on Robert Kowalski's procedural interpretation of Horn clauses. It was motivated in part by the desire to reconcile the use of logic as a declarative knowledge representation language with the procedural representation of knowledge that was popular in North America in the late 1960s and early 1970s. According to Robert Kowalski, the first Prolog system was developed in 1972 by Colmerauer and Phillipe Roussel. The first implementations of Prolog were interpreters. However, David H. D. Warren created the Warren Abstract Machine, an early and influential Prolog compiler which came to define the "Edinburgh Prolog" dialect which served as the basis for the syntax of most modern implementations.

European AI researchers favored Prolog while Americans favored Lisp, reportedly causing many nationalistic debates on the merits of the languages. Much of the modern development of Prolog came from the impetus of the Fifth Generation Computer Systems project (FGCS), which developed a variant of Prolog named "Kernel Language" for its first operating system.

Pure Prolog was originally restricted to the use of a resolution theorem prover with Horn clauses of the form:

The application of the theorem-prover treats such clauses as procedures:

Pure Prolog was soon extended, however, to include negation as failure, in which negative conditions of the form not(B) are shown by trying and failing to solve the corresponding positive conditions B.

Subsequent extensions of Prolog by the original team introduced constraint logic programming abilities into the implementations.

Prolog has been used in Watson. Watson uses IBM's DeepQA software and the Apache UIMA (Unstructured Information Management Architecture) framework. The system was written in various languages, including Java, C++, and Prolog, and runs on the SUSE Linux Enterprise Server 11 operating system using Apache Hadoop framework to provide distributed computing. Prolog is used for pattern matching over natural language parse trees. The developers have stated: "We required a language in which we could conveniently express pattern matching rules over the parse trees and other annotations (such as named entity recognition results), and a technology that could execute these rules very efficiently. We found that Prolog was the ideal choice for the language due to its simplicity and expressiveness."






</doc>
<doc id="23486" url="https://en.wikipedia.org/wiki?curid=23486" title="Phil Zimmermann">
Phil Zimmermann

Philip R. "Phil" Zimmermann, Jr. (born February 12, 1954) is the creator of Pretty Good Privacy (PGP), the most widely used email encryption software in the world. He is also known for his work in VoIP encryption protocols, notably ZRTP and Zfone. Zimmermann is co-founder and Chief Scientist of the global encrypted communications firm, Silent Circle.

He was born in Camden, New Jersey. His father was a concrete mixer truck driver. Zimmermann received a B.S. degree in computer science from Florida Atlantic University in Boca Raton, Florida in 1978, and thereafter moved to the San Francisco Bay Area. In the 1980s, Zimmermann worked in Boulder, Colorado as a software engineer and was a part of the Nuclear Weapons Freeze Campaign as a military policy analyst.

In 1991, he wrote the popular Pretty Good Privacy (PGP) program, and made it available (together with its source code) through public FTP for download, the first widely available program implementing public-key cryptography. Shortly thereafter, it became available overseas via the Internet, though Zimmermann has said he had no part in its distribution outside the United States.

The very first version of PGP included an encryption algorithm, BassOmatic, developed by Zimmermann.

After a report from RSA Security, who were in a licensing dispute with regard to the use of the RSA algorithm in PGP, the United States Customs Service started a criminal investigation of Zimmermann, for allegedly violating the Arms Export Control Act. The United States Government had long regarded cryptographic software as a munition, and thus subject to arms trafficking export controls. At that time, the boundary between what cryptography was permitted ("low-strength") and impermissible ("high-strength") for export from the United States was placed such that PGP fell on the too-strong-to-export side of the boundary. The boundary for legal export has since been raised and now allows PGP to be exported. The investigation lasted three years, but was finally dropped without filing charges.

After the government dropped its case without indictment in early 1996, Zimmermann founded PGP Inc. and released an updated version of PGP and some additional related products. That company was acquired by Network Associates (NAI) in December 1997, and Zimmermann stayed on for three years as a Senior Fellow. NAI decided to drop the product line and in 2002, PGP was acquired from NAI by a new company called PGP Corporation. Zimmermann served as a special advisor and consultant to that firm until Symantec acquired PGP Corporation in 2010. Zimmermann is also a fellow at the Stanford Law School's Center for Internet and Society. He was a principal designer of the cryptographic key agreement protocol (the "association model") for the Wireless USB standard.

Along with Mike Janke, in 2012 he created Silent Circle, a secure hardware and subscription based software security company.

In October 2013, Zimmermann, along with other key employees from Silent Circle, teamed up with Lavabit founder Ladar Levison to create the Dark Mail Alliance. The goal of the organization is to work on a new protocol to replace PGP that will encrypt metadata, among other things that PGP is not capable of.

In 2013, an article on "Zimmermann's Law" quoted Phil Zimmermann as saying "The natural flow of technology tends to move in the direction of making surveillance easier", and "the ability of computers to track us doubles every eighteen months," in reference to Moore's law.

Zimmermann has received numerous technical and humanitarian awards for his pioneering work in cryptography:

Simon Singh's "The Code Book" devotes an entire chapter to Zimmermann and PGP.





</doc>
<doc id="23490" url="https://en.wikipedia.org/wiki?curid=23490" title="Political spectrum">
Political spectrum

A political spectrum is a system of classifying different political positions upon one or more geometric axes that symbolize independent political dimensions.

Most long-standing spectra include a right wing and left wing, which originally referred to seating arrangements in the French parliament after the Revolution (1789–1799). According to the simplest left–right axis, communism and socialism are usually regarded internationally as being on the left, whereas conservatism and capitalism are on the right. Liberalism can mean different things in different contexts, sometimes on the left (social liberalism), sometimes within libertarianism (classical liberalism). Those with an intermediate outlook are classified as centrists or moderates. Politics that rejects the conventional left–right spectrum is known as syncretic politics.

Political scientists have frequently noted that a single left–right axis is insufficient for describing the existing variation in political beliefs and often include other axes. Though the descriptive words at polar opposites may vary, often in popular biaxial spectra the axes are split between sociocultural issues and economic issues, each scaling from some form of individualism (or government for the freedom of the individual) to some form of communitarianism (or government for the welfare of the community).

The terms "Right" and "Left" refer to political affiliations originating early in the French Revolutionary era of 1789–1799 and referred originally to the seating arrangements in the various legislative bodies of France. As seen from the Speaker's seat at the front of the Assembly, the aristocracy sat on the right (traditionally the seat of honor) and the commoners sat on the left, hence the terms right-wing politics and left-wing politics.

Originally, the defining point on the ideological spectrum was the "Ancien Régime" ("old order"). "The Right" thus implied support for aristocratic or royal interests and the church, while "The Left" implied support for republicanism, secularism and civil liberties. Because the political franchise at the start of the revolution was relatively narrow, the original "Left" represented mainly the interests of the bourgeoisie, the rising capitalist class (with notable exceptions such as the proto-communist Gracchus Babeuf). Support for "laissez-faire" commerce and free markets were expressed by politicians sitting on the left because these represented policies favorable to capitalists rather than to the aristocracy, but outside parliamentary politics these views are often characterized as being on the Right.

The reason for this apparent contradiction lies in the fact that those "to the left" of the parliamentary left, outside official parliamentary structures (such as the "sans-culottes" of the French Revolution), typically represent much of the working class, poor peasantry and the unemployed. Their political interests in the French Revolution lay with opposition to the aristocracy and so they found themselves allied with the early capitalists. However, this did not mean that their economic interests lay with the "laissez-faire" policies of those representing them politically.

As capitalist economies developed, the aristocracy became less relevant and were mostly replaced by capitalist representatives. The size of the working class increased as capitalism expanded and began to find expression partly through trade unionist, socialist, anarchist and communist politics rather than being confined to the capitalist policies expressed by the original "left". This evolution has often pulled parliamentary politicians away from laissez-faire economic policies, although this has happened to different degrees in different countries.

Thus the word "Left" in American political parlance may refer to "liberalism" and be identified with the Democratic Party, whereas in a country such as France these positions would be regarded as relatively more right-wing and "left" is more likely to refer to "socialist" positions rather than "liberal" ones.

For almost a century, social scientists have considered the problem of how best to describe political variation.

In 1950, Leonard W. Ferguson analyzed political values using ten scales measuring attitudes toward: birth control, capital punishment, censorship, communism, evolution, law, patriotism, theism, treatment of criminals and war. Submitting the results to factor analysis, he was able to identify three factors, which he named religionism, humanitarianism and nationalism. He defined religionism as belief in God and negative attitudes toward evolution and birth control; humanitarianism as being related to attitudes opposing war, capital punishment and harsh treatment of criminals; and nationalism as describing variation in opinions on censorship, law, patriotism and communism.

This system was derived empirically, as rather than devising a political model on purely theoretical grounds and testing it, Ferguson's research was exploratory. As a result of this method, care must be taken in the interpretation of Ferguson's three factors, as factor analysis will output an abstract factor whether an objectively real factor exists or not. Although replication of the nationalism factor was inconsistent, the finding of religionism and humanitarianism had a number of replications by Ferguson and others.

Shortly afterward, Hans Eysenck began researching political attitudes in Great Britain. He believed that there was something essentially similar about the National Socialists (Nazis) on the one hand and the communists on the other, despite their opposite positions on the left–right axis. As Hans Eysenck described in his 1956 book "Sense and Nonsense in Psychology", Eysenck compiled a list of political statements found in newspapers and political tracts and asked subjects to rate their agreement or disagreement with each. Submitting this value questionnaire to the same process of factor analysis used by Ferguson, Eysenck drew out two factors, which he named "Radicalism" (R-factor) and "Tender-Mindedess" (T-factor).

Such analysis produces a factor whether or not it corresponds to a real-world phenomenon and so caution must be exercised in its interpretation. While Eysenck's R-factor is easily identified as the classical "left–right" dimension, the T-factor (representing a factor drawn at right angles to the R-factor) is less intuitive, as high-scorers favored pacifism, racial equality, religious education and restrictions on abortion, while low-scorers had attitudes more friendly to militarism, harsh punishment, easier divorce laws and companionate marriage.

Despite the difference in methodology, location and theory, the results attained by Eysenck and Ferguson matched. Simply rotating Eysenck's two factors 45 degrees renders the same factors of religionism and humanitarianism identified by Ferguson in America.

Eysenck's dimensions of R and T were found by factor analyses of values in Germany and Sweden, France and Japan.

One interesting result Eysenck noted in his 1956 work was that in the United States and Great Britain, most of the political variance was subsumed by the left/right axis, while in France the T-axis was larger and in the Middle East the only dimension to be found was the T-axis: "Among mid-Eastern Arabs it has been found that while the tough-minded/tender-minded dimension is still clearly expressed in the relationships observed between different attitudes, there is nothing that corresponds to the radical-conservative continuum".

Eysenck's political views related to his research: Eysenck was an outspoken opponent of what he perceived as the authoritarian abuses of the left and right and accordingly he believed that with this T axis he had found the link between nazism and communism. According to Eysenck, members of both ideologies were tough-minded. Central to Eysenck's thesis was the claim that tender-minded ideologies were democratic and friendly to human freedoms, while tough-minded ideologies were aggressive and authoritarian, a claim that is open to political criticism. In this context, Eysenck carried out studies on nazism and communist groups, claiming to find members of both groups to be more "dominant" and more "aggressive" than control groups.

Eysenck left Nazi Germany to live in Britain and was not shy in attacking Stalinism, noting the anti-Semitic prejudices of the Russian government, the luxurious lifestyles of the Soviet Union leadership and the Orwellian "doublethink" of East Germany's naming itself the German Democratic Republic despite being "one of the most undemocratic regimes in the world today". While Eysenck was an opponent of Nazism, his relationship with fascist organizations was more complex. Eysenck himself lent theoretical support to the English National Party (which also opposed "Hitlerite" Nazism) and was interviewed in the first issue of their journal "The Beacon" in relation to his controversial views on relative intelligence between different races. At one point during the interview, Eysenck was asked whether or not he was of Jewish origin before the interviewer proceeded. His political allegiances were called into question by other researchers, notably Steven Rose, who alleged that his scientific research was used for political purposes.

Eysenck's conception of tough-mindedness has been criticized for a number of reasons.

Dissatisfied with Hans J. Eysenck's work, Milton Rokeach developed his own two-axis model of political values in 1973, basing this on the ideas of freedom and equality, which he described in his book, "The Nature of Human Values".

Milton Rokeach claimed that the defining difference between the left and right was that the left stressed the importance of equality more than the right. Despite his criticisms of Eysenck's tough-tender axis, Rokeach also postulated a basic similarity between communism and nazism, claiming that these groups would not value freedom as greatly as more conventional social democratics, democratic socialists and capitalists would and he wrote that "the two value model presented here most resembles Eysenck's hypothesis".

To test this model, Milton Rokeach and his colleagues used content analysis on works exemplifying nazism (written by Adolf Hitler), communism (written by Vladimir Lenin), capitalism (by Barry Goldwater) and socialism (written by various socialist authors). This method has been criticized for its reliance on the experimenter's familiarity with the content under analysis and its dependence on the researcher's particular political outlooks.

Multiple raters made frequency counts of sentences containing synonyms for a number of values identified by Rokeach—including freedom and equality—and Rokeach analyzed these results by comparing the relative frequency rankings of all the values for each of the four texts:

Later studies using samples of American ideologues and American presidential inaugural addresses attempted to apply this model.

In further research, Hans J. Eysenck refined his methodology to include more questions on economic issues. Doing this, he revealed a split in the left–right axis between social policy and economic policy, with a previously undiscovered dimension of socialism-capitalism (S-factor).

While factorially distinct from Eysenck's previous R factor, the S-factor did positively correlate with the R-factor, indicating that a basic left–right or right–left tendency underlies both social values and economic values, although S tapped more into items discussing economic inequality and big business, while R relates more to the treatment of criminals and to sexual issues and military issues.

Most research and political theory since this time has replicated the factors shown above.

Another replication came from Ronald Inglehart's research into national opinions based on the World Values Survey, although Inglehart's research described the values of countries rather than individuals or groups of individuals within nations. Inglehart's two-factor solution took the form of Ferguson's original religionism and humanitarianism dimensions; Inglehart labelled them "secularism–traditionalism", which covered issues of tradition and religion, like patriotism, abortion, euthanasia and the importance of obeying the law and authority figures, and "survivalism – self expression", which measured issues like everyday conduct and dress, acceptance of diversity (including foreigners) and innovation and attitudes towards people with specific controversial lifestyles such as homosexuality and vegetarianism, as well as willingness to engage in political activism. See for Inglehart's national chart.

The Nolan chart was created by libertarian David Nolan. This chart shows what he considers as "economic freedom" (issues like taxation, free trade and free enterprise) on the horizontal axis and what he considers as "personal freedom" (issues like drug legalization, abortion and the draft) on the vertical axis. This puts left-wingers in the left quadrant, libertarians in the top, right-wingers in the right and what Nolan originally named populists in the bottom.

The political compass has two axes. One represents economic issues as right-vs-left. The other represents issues of freedom, or social issues, as authoritarian-vs-libertarian. One can determine their position on the political compass through an online quiz by the same name.

In a 2003 "Psychological Bulletin" paper, Jeff Greenberg and Eva Jonas posit a model comprising the standard left–right axis and an axis representing ideological rigidity. For Greenberg and Jonas, ideological rigidity has "much in common with the related concepts of dogmatism and authoritarianism" and is characterized by "believing in strong leaders and submission, preferring one’s own in-group, ethnocentrism and nationalism, aggression against dissidents, and control with the help of police and military". Greenberg and Jonas posit that high ideological rigidity can be motivated by "particularly strong needs to reduce fear and uncertainty" and is a primary shared characteristic of "people who subscribe to any extreme government or ideology, whether it is right-wing or left-wing".

This very distinct two-axis model was created by Jerry Pournelle in 1963 for his doctoral dissertation in political science. The Pournelle chart has liberty on one axis, with those on the left seeking freedom from control or protections for social deviance and those on the right emphasizing state authority or protections for norm enforcement (farthest right being state worship, farthest left being the idea of a state as the "ultimate evil"). The other axis is rationalism, defined here as the belief in planned social progress, with those higher up believing that there are problems with society that can be rationally solved and those lower down skeptical of such approaches.

In its 4 January 2003 issue, "The Economist" discussed a chart, proposed by Dr. Ronald Inglehart and supported by the World Values Survey (associated with the University of Michigan), to plot cultural ideology onto two dimensions. On the y-axis it covered issues of tradition and religion, like patriotism, abortion, euthanasia and the importance of obeying the law and authority figures. At the bottom of the chart is the traditionalist position on issues like these (with loyalty to country and family and respect for life considered important), while at the top is the secular position. The x-axis deals with self-expression, issues like everyday conduct and dress, acceptance of diversity (including foreigners) and innovation, and attitudes towards people with specific controversial lifestyles such as vegetarianism, as well as willingness to engage in political activism. At the right of the chart is the open self-expressionist position, while at the left is its opposite position, which Dr. Inglehart calls survivalist. This chart not only has the power to map the values of individuals, but also to compare the values of people in different countries. Placed on this chart, European Union countries in continental Europe come out on the top right, Anglophone countries on the middle right, Latin American countries on the bottom right, African, Middle Eastern and South Asian countries on the bottom left and ex-Communist countries on the top left.

In 2006, Brian Patrick Mitchell identified four main political traditions in Anglo-American history based on their regard for "kratos" (defined as the use of force) and "archē" or "archy" (defined as the recognition of rank). Mitchell grounded the distinction of archy and kratos in the West's historical experience of church and state, crediting the collapse of the Christian consensus on church and state with the appearance of four main divergent traditions in Western political thought:

Mitchell charts these traditions graphically using a vertical axis as a scale of kratos/akrateia and a horizontal axis as a scale of archy/anarchy. He places democratic progressivism in the lower left, plutocratic nationalism in the lower right, republican constitutionalism in the upper right, and libertarian individualism in the upper left. The political left is therefore distinguished by its rejection of archy, while the political right is distinguished by its acceptance of archy. For Mitchell, anarchy is not the absence of government but the rejection of rank. Thus there can be both anti-government anarchists (Mitchell’s "libertarian individualists") and pro-government anarchists (Mitchell's "democratic progressives", who favor the use of government force against social hierarchies such as patriarchy). Mitchell also distinguishes between left-wing anarchists and right-wing anarchists, whom Mitchell renames "akratists" for their opposition to the government’s use of force.

From the four main political traditions, Mitchell identifies eight distinct political perspectives diverging from a populist center. Four of these perspectives (Progressive, Individualist, Paleoconservative, and Neoconservative) fit squarely within the four traditions; four others (Paleolibertarian, Theoconservative, Communitarian, and Radical) fit between the traditions, being defined by their singular focus on rank or force. Anthony Gregory of the Independent Institute credits Mitchell with "the best explanation of the political spectrum", saying he "makes sense of all the major mysteries".

The spatial model of voting plots voters and candidates in a multi-dimensional space where each dimension represents a single political issue (or sub-component of an issue). Voters are then modeled as voting for the nearest candidates in this ideological space. The dimensions of this model can also be assigned to non-political properties of the candidates, such as perceived corruption, health, etc.

Most of the other spectra in this article can then be considered projections of this multi-dimensional space onto a smaller number of dimensions. For example, a study of German voters found that at least four dimensions were required to adequately represent all political parties. 

One alternative spectrum offered by the conservative "American Federalist Journal" accounts for only the "degree of government control" without consideration for any other social or political variable and thus places "fascism" (totalitarianism) at one extreme and "anarchism" (no government at all) at the other extreme.

The Vosem Chart, or Vosem Cube, is based on the Nolan Chart and adds a third axis for government, depicted three dimensionally, with eight discrete categories representing eight different political ideologies. "Vosem" is the Russian word for "eight."

The Vikaas-Doolittle compass orients the political spectrum within three sociocultural axes: aesthetic vs linguistic, individualist vs collectivist, and low-context (stoic) vs high-context
(dramatic). The map predicts the social behavior of an individual from their cultural orientation; for instance, a Puritan colonist would be linguistic-individualist-stoic; an early 20th Century Italian immigrant aesthetic-collectivist-dramatic; and an early 21st Century Latin immigrant lingusitic-collectivist-dramatic.

Other proposed axes include:

As shown by Russian political scientist Stepan S. Sulakshin, political spectra can be used as a forecasting tool. Sulakshin offered mathematical evidence that stable development (positive dynamics of the vast number of statistic indices) depends on the width of the political spectrum: if it is too narrow or too wide, stagnation or political disasters will result. Sulakshin also showed that in the short run the political spectrum determines the statistic indices dynamic and not vice versa.




</doc>
<doc id="23496" url="https://en.wikipedia.org/wiki?curid=23496" title="Pregnancy (mammals)">
Pregnancy (mammals)

In mammals, pregnancy is the period of reproduction during which a female carries one or more live offspring from implantation in the uterus through gestation. It begins when a fertilized zygote implants in the female's uterus, and ends once it leaves the uterus.

During copulation, the male inseminates the female. The spermatozoon fertilizes an ovum or various ova in the uterus or fallopian tubes, and this results in one or multiple zygotes. Sometimes, a zygote can be created by humans outside of the animal's body in the artificial process of in-vitro fertilization. After fertilization, the newly formed zygote then begins to divide through mitosis, forming an embryo, which implants in the female's endometrium. At this time, the embryo usually consists of 50 cells.

A blastocoele is a small cavity on the center of the embryo, and the developing embryonary cells will grow around it. Then, a flat layer cell forms on the exterior of this cavity, and the zona pellucida, the blastocyst's barrier, remains the same size as before. Cells grow increasingly smaller to fit in. This new structure with a cavity in the center and the developing cells around it is known as a blastocyst.

The presence of the blastocyst means that two types of cells are forming, an inner-cell mass growing on the interior of the blastocele and cells growing on the exterior of it. In 24 to 48 hours, the zona pellucida breaches. The cells on the exterior of the blastocyst begin excreting an enzyme which erodes epithelial uterine lining and creates a site for implantation.

The cells surrounding the blastocyst now destroy cells in the uterine lining, forming small pools of blood, which in turn stimulate the production of capillaries. This is the first stage in the growth of the placenta. The inner cell mass of the blastocyst divides rapidly, forming two layers. The top layer becomes the embryo, and cells from there occupy the amniotic cavity. At the same time, the bottom layer forms a small sac (if the cells begin developing in an abnormal position, an ectopic gestation may also occur at this point).

Several days later, chorionic villi in the forming placenta anchor the implantation site to the uterus. A system of blood and blood vessels now develops at the point of the newly forming placenta, growing near the implantation site. The small sac inside the blastocyst begins producing red blood cells. For the next 24 hours, connective tissue develops between the developing placenta and the growing embryo. This later develops into the umbilical cord.

Following this, a narrow line of cells appears on the surface on the embryo. Its growth makes the embryo undergo gastrulation, in which the three primary tissue layers of the fetus, the ectoderm, mesoderm, and endoderm, develop. The narrow line of cells begin to form the endoderm and mesoderm. The ectoderm begins to grow rapidly as a result of chemicals being produced by the mesoderm. These three layers give rise to all the various types of tissue in the body.

The endoderm later forms the lining of the tongue, digestive tract, lungs, bladder and several glands. The mesoderm forms muscle, bone, and lymph tissue, as well as the interior of the lungs, heart, and reproductive and excretory systems. It also gives rise to the spleen, and produces blood cells. The ectoderm forms the skin, nails, hair, cornea, lining of the internal and external ear, nose, sinuses, mouth, anus, teeth, pituitary gland, mammary glands, eyes, and all parts of the nervous system.

Approximately 18 days after fertilization, the embryo has divided to form much of the tissue it will need. It is shaped like a pear, where the head region is larger than the tail. The embryo's nervous system is one of the first organic systems to grow. It begins growing in a concave area known as the neural groove.

The blood system continues to grow networks which allow the blood to flow around the embryo. Blood cells are already being produced and are flowing through these developing networks. Secondary blood vessels also begin to develop around the placenta, to supply it with more nutrients. Blood cells begin to form on the sac in the center of the embryo, as well as cells which begin to differentiate into blood vessels. Endocardial cells begin to form the myocardium.

At about 24 days past fertilization, there is a primitive S-shaped tubule heart which begins beating. The flow of fluids throughout the embryo begins at this stage.

For mammals the gestation period is the time in which a fetus develops, beginning with fertilization and ending at birth. The duration of this period varies between species.

For most species, the amount a fetus grows before birth determines the length of the gestation period. Smaller species normally have a shorter gestation period than larger animals. For example, a cat's gestation normally takes 58–65 days while an elephant's takes nearly 2 years (21 months). However, growth does not necessarily determine the length of gestation for all species, especially for those with a breeding season. Species that use a breeding season usually give birth during a specific time of year when food is available.

Various other factors can come into play in determining the duration of gestation. For humans, male fetuses normally gestate several days longer than females and multiple pregnancies gestate for a shorter period. Ethnicity may also lengthen or shorten gestation. In dogs there's a positive correlation between a longer gestation time and a small litter size.



</doc>
<doc id="23497" url="https://en.wikipedia.org/wiki?curid=23497" title="Paroxysmal attack">
Paroxysmal attack

Paroxysmal attacks or paroxysms (from Greek παροξυσμός) are a sudden recurrence or intensification of symptoms, such as a spasm or seizure. These short, frequent, symptoms can be observed in various clinical conditions. They are usually associated with multiple sclerosis or pertussis, but they may also be observed in other disorders such as encephalitis, head trauma, stroke, asthma, trigeminal neuralgia, breath-holding spells, epilepsy, malaria, tabes dorsalis, and Behçet's disease, paroxysmal nocturnal hemoglobinuria (PNH). It has also been noted as a symptom of gratification disorder in children.

The word paroxysm means "sudden attack, outburst", and comes from the Greek παροξυσμός ("paroxusmos"), "irritation, exasperation".

Paroxysmal attacks in various disorders have been reported extensively and ephaptic coupling of demyelinated nerves has been presumed as one of the underlying mechanisms of this phenomenon. This is supported by the presence of these attacks in multiple sclerosis and tabes dorsalis, which both involve demyelination of spinal cord neurons. Exercise, tactile stimuli, hot water, anxiety and neck flexion may provoke paroxysmal attacks. Most reported paroxysmal attacks are painful tonic spasms, dysarthria and ataxia, numbness and hemiparesis. They are typically different from other transient symptoms by their brevity (lasting no more than 2 minutes), frequency (from 1-2 times/day up to a few hundred times/day), stereotyped fashion and excellent response to drugs (usually carbamazepine). Withdrawal of symptoms without any residual neurological finding is another key feature in their recognition.



</doc>
<doc id="23501" url="https://en.wikipedia.org/wiki?curid=23501" title="Potato">
Potato

The potato is a starchy, tuberous crop from the perennial nightshade Solanum tuberosum. "Potato" may be applied to both the plant and the edible tuber. Potatoes have become a staple food in many parts of the world and an integral part of much of the world's food supply. Potatoes are the world's fourth-largest food crop, following maize (corn), wheat, and rice. Tubers produce glycoalkaloids in small amounts. If green sections (sprouts and skins) of the plant are exposed to light the tuber can produce a high enough concentration of glycoalkaloids to affect human health.
In the Andes region of South America, where the species is indigenous, some other closely related species are cultivated. Potatoes were introduced to Europe in the second half of the 16th century by the Spanish. Wild potato species can be found throughout the Americas from the United States to southern Chile. The potato was originally believed to have been domesticated independently in multiple locations, but later genetic testing of the wide variety of cultivars and wild species proved a single origin for potatoes in the area of present-day southern Peru and extreme northwestern Bolivia (from a species in the "Solanum brevicaule" complex), where they were domesticated approximately 7,000–10,000 years ago. Following millennia of selective breeding, there are now over a thousand different types of potatoes. Over 99% of the presently cultivated potatoes worldwide descended from varieties that originated in the lowlands of south-central Chile, which have displaced formerly popular varieties from the Andes.

However, the local importance of the potato is variable and changing rapidly. It remains an essential crop in Europe (especially eastern and central Europe), where per capita production is still the highest in the world, but the most rapid expansion over the past few decades has occurred in southern and eastern Asia. As of 2014, China led the world in potato production, and, together with India, produced 37% of the world's potatoes.

The English word "potato" comes from Spanish "patata" (the name used in Spain). The Spanish Royal Academy says the Spanish word is a hybrid of the Taíno "batata" (sweet potato) and the Quechua "papa" (potato). The name originally referred to the sweet potato although the two plants are not closely related. The 16th-century English herbalist John Gerard referred to sweet potatoes as "common potatoes", and used the terms "bastard potatoes" and "Virginia potatoes" for the species we now call "potato". In many of the chronicles detailing agriculture and plants, no distinction is made between the two. Potatoes are occasionally referred to as "Irish potatoes" or "white potatoes" in the United States, to distinguish them from sweet potatoes.

The name spud for a small potato comes from the digging of soil (or a hole) prior to the planting of potatoes. The word has an unknown origin and was originally (c. 1440) used as a term for a short knife or dagger, probably related to the Latin "spad-" a word root meaning "sword"; cf. Spanish "espada", English "spade" and "spadroon". It subsequently transferred over to a variety of digging tools. Around 1845, the name transferred to the tuber itself, the first record of this usage being in New Zealand English. The origin of the word "spud" has erroneously been attributed to an 18th-century activist group dedicated to keeping the potato out of Britain, calling itself The Society for the Prevention of Unwholesome Diet . It was Mario Pei's 1949 "The Story of Language" that can be blamed for the word's false origin. Pei writes, "the potato, for its part, was in disrepute some centuries ago. Some Englishmen who did not fancy potatoes formed a Society for the Prevention of Unwholesome Diet. The initials of the main words in this title gave rise to spud." Like most other pre-20th century acronymic origins, this is false, and there is no evidence that a Society for the Prevention of Unwholesome Diet ever existed.

Potato plants are herbaceous perennials that grow about high, depending on variety, with the leaves dying back after flowering, fruiting and tuber formation. They bear white, pink, red, blue, or purple flowers with yellow stamens. In general, the tubers of varieties with white flowers have white skins, while those of varieties with colored flowers tend to have pinkish skins. Potatoes are mostly cross-pollinated by insects such as bumblebees, which carry pollen from other potato plants, though a substantial amount of self-fertilizing occurs as well. Tubers form in response to decreasing day length, although this tendency has been minimized in commercial varieties.

After flowering, potato plants produce small green fruits that resemble green cherry tomatoes, each containing about 300 seeds. Like all parts of the plant except the tubers, the fruit contain the toxic alkaloid solanine and are therefore unsuitable for consumption. All new potato varieties are grown from seeds, also called "true potato seed", "TPS" or "botanical seed" to distinguish it from seed tubers. New varieties grown from seed can be propagated vegetatively by planting tubers, pieces of tubers cut to include at least one or two eyes, or cuttings, a practice used in greenhouses for the production of healthy seed tubers. Plants propagated from tubers are clones of the parent, whereas those propagated from seed produce a range of different varieties.

There are about 5,000 potato varieties worldwide. Three thousand of them are found in the Andes alone, mainly in Peru, Bolivia, Ecuador, Chile, and Colombia. They belong to eight or nine species, depending on the taxonomic school. Apart from the 5,000 cultivated varieties, there are about 200 wild species and subspecies, many of which can be cross-bred with cultivated varieties. Cross-breeding has been done repeatedly to transfer resistances to certain pests and diseases from the gene pool of wild species to the gene pool of cultivated potato species. Genetically modified varieties have met public resistance in the United States and in the European Union.

The major species grown worldwide is "Solanum tuberosum" (a tetraploid with 48 chromosomes), and modern varieties of this species are the most widely cultivated. There are also four diploid species (with 24 chromosomes): "S. stenotomum", "S. phureja", "S. goniocalyx", and "S. ajanhuiri". There are two triploid species (with 36 chromosomes): "S. chaucha" and "S. juzepczukii". There is one pentaploid cultivated species (with 60 chromosomes): "S. curtilobum". There are two major subspecies of "Solanum tuberosum": "andigena", or Andean; and "tuberosum", or Chilean. The Andean potato is adapted to the short-day conditions prevalent in the mountainous equatorial and tropical regions where it originated; the Chilean potato, however, native to the Chiloé Archipelago, is adapted to the long-day conditions prevalent in the higher latitude region of southern Chile.

The International Potato Center, based in Lima, Peru, holds an ISO-accredited collection of potato germplasm. The international Potato Genome Sequencing Consortium announced in 2009 that they had achieved a draft sequence of the potato genome. The potato genome contains 12 chromosomes and 860 million base pairs, making it a medium-sized plant genome. More than 99 percent of all current varieties of potatoes currently grown are direct descendants of a subspecies that once grew in the lowlands of south-central Chile. Nonetheless, genetic testing of the wide variety of cultivars and wild species affirms that all potato subspecies derive from a single origin in the area of present-day southern Peru and extreme Northwestern Bolivia (from a species in the "Solanum brevicaule" complex). The wild Crop Wild Relatives Prebreeding project encourages the use of wild relatives in breeding programs. Enriching and preserving the gene bank collection to make potatoes adaptive to diverse environmental conditions is seen as a pressing issue due to climate change.

Most modern potatoes grown in North America arrived through European settlement and not independently from the South American sources, although at least one wild potato species, "Solanum fendleri", naturally ranges from Peru into Texas, where it is used in breeding for resistance to a nematode species that attacks cultivated potatoes. A secondary center of genetic variability of the potato is Mexico, where important wild species that have been used extensively in modern breeding are found, such as the hexaploid "Solanum demissum", as a source of resistance to the devastating late blight disease. Another relative native to this region, "Solanum bulbocastanum", has been used to genetically engineer the potato to resist potato blight.

Potatoes yield abundantly with little effort, and adapt readily to diverse climates as long as the climate is cool and moist enough for the plants to gather sufficient water from the soil to form the starchy tubers. Potatoes do not keep very well in storage and are vulnerable to moulds that feed on the stored tubers and quickly turn them rotten, whereas crops such as grain can be stored for several years with a low risk of rot. The yield of Calories per acre (about 9.2 million) is higher than that of maize (7.5 million), rice (7.4 million), wheat (3 million), or soybean (2.8 million).

The potato was first domesticated in the region of modern-day southern Peru and extreme northwestern Bolivia between 8000 and 5000 BC. It has since spread around the world and become a staple crop in many countries.

The earliest archaeologically verified potato tuber remains have been found at the coastal site of Ancon (central Peru), dating to 2500 BC. The most widely cultivated variety, "Solanum tuberosum tuberosum", is indigenous to the Chiloé Archipelago, and has been cultivated by the local indigenous people since before the Spanish conquest.

According to conservative estimates, the introduction of the potato was responsible for a quarter of the growth in Old World population and urbanization between 1700 and 1900. Following the Spanish conquest of the Inca Empire, the Spanish introduced the potato to Europe in the second half of the 16th century, part of the Columbian exchange. The staple was subsequently conveyed by European mariners to territories and ports throughout the world. The potato was slow to be adopted by distrustful European farmers, but soon enough it became an important food staple and field crop that played a major role in the European 19th century population boom. However, lack of genetic diversity, due to the very limited number of varieties initially introduced, left the crop vulnerable to disease. In 1845, a plant disease known as late blight, caused by the fungus-like oomycete "Phytophthora infestans", spread rapidly through the poorer communities of western Ireland as well as parts of the Scottish Highlands, resulting in the crop failures that led to the Great Irish Famine. Thousands of varieties still persist in the Andes however, where over 100 cultivars might be found in a single valley, and a dozen or more might be maintained by a single agricultural household.

In 2014, world production of potatoes was 382 million tonnes, an increase of 4% over 2013 amounts and led by China with 25% of the world total (table). Other major producers were India, Russia, Ukraine and the United States. However, the local importance of potato is variable and rapidly changing. It remains an essential crop in Europe (especially eastern and central Europe), where per capita production is still the highest in the world, but the most rapid expansion over the past few decades has occurred in southern and eastern Asia.

Raw potato is 79% water, 17% carbohydrates (88% of which is starch), 2% protein, contains negligible fat (table). In a amount, raw potato provides and is a rich source of vitamin B6 and vitamin C (23% and 24% of the Daily Value, respectively), with no other nutrients in significant amount (table). When a potato is baked, contents of vitamin B6 and vitamin C decline with little significant change in other nutrients.

Potatoes are often broadly classified as high on the glycemic index (GI) and so are often excluded from the diets of individuals trying to follow a low-GI diet. The GI of potatoes can vary considerably depending on type (such as red, russet, white, or King Edward), origin, preparation methods (by cooking method, whether it is eaten hot or cold, whether it is mashed or cubed or consumed whole), and with what it is consumed (addition of various high-fat or high-protein toppings). Consuming reheated or cooled potatoes that were previously cooked may afford a lower GI effect.

In the UK, potatoes are not considered by the NHS as counting towards the recommended daily five portions of fruit and vegetables.

The following table shows the nutrient content of potato and other major staple foods, each in respective raw form. Staple foods are not commonly eaten raw and are usually sprouted or cooked before eating. In sprouted and cooked form, the relative nutritional and anti-nutritional contents of each of these grains may be different from the values reported in this table. 
Potatoes contain toxic compounds known as glycoalkaloids, of which the most prevalent are solanine and chaconine. Solanine is also found in other plants in the family Solanaceae, which includes such plants as the deadly nightshade ("Atropa belladonna"), henbane ("Hyoscyamus niger") and tobacco ("Nicotiana"), as well as eggplant and tomato. These compounds, which protect the plant from its predators, are, in general, concentrated in its leaves, stems, sprouts, and fruits (in contrast to the roots). In a summary of several studies, the glycoalkaloid content was highest in flowers and sprouts and lowest in the tuber flesh (in order from highest to lowest content, generally: flowers, sprouts, leaves, skin, roots, berries, peel [skin plus outer cortex of tuber flesh], stems, and tuber flesh).

Exposure to light, physical damage, and age increase glycoalkaloid content within the tuber. Cooking at high temperatures—over —partly destroys these compounds. The concentration of glycoalkaloid in wild potatoes suffices to produce toxic effects in humans. Glycoalkaloids may cause headaches, diarrhea, cramps, and in severe cases coma and death; however, poisoning from potatoes occurs very rarely. Light exposure causes greening from chlorophyll synthesis, thus giving a visual clue as to areas of the tuber that may have become more toxic; however, this does not provide a definitive guide, as greening and glycoalkaloid accumulation can occur independently of each other. Varieties contain different levels of glycoalkaloids. The Lenape variety was released in 1967 but was withdrawn in 1970 as it contained high levels of glycoalkaloids. Since then breeders developing new varieties test for this, and sometimes have to discard an otherwise promising cultivar.

Breeders try to keep glycoalkaloid levels below 200 mg/kg (200 ppmw). However, when these commercial varieties turn green, they can still approach concentrations of solanine of 1000 mg/kg (1000 ppmw). In normal potatoes, analysis has shown solanine levels may be as little as 3.5% of the breeders' maximum, with 7–187 mg/kg being found. While a normal potato has 12–20 mg/kg of glycoalkaloid content, a green tuber contains 250–280 mg/kg, and green skin 1500–2200 mg/kg.

Potatoes are generally grown from "seed potatoes," tubers specifically grown to be free from disease and to provide consistent and healthy plants. To be disease free, the areas where seed potatoes are grown are selected with care. In the US, this restricts production of seed potatoes to only 15 states out of all 50 states where potatoes are grown. These locations are selected for their cold, hard winters that kill pests and summers with long sunshine hours for optimum growth. In the UK, most seed potatoes originate in Scotland, in areas where westerly winds prevent aphid attack and thus prevent spread of potato virus pathogens.

Potato growth is divided into five phases. During the first phase, sprouts emerge from the seed potatoes and root growth begins. During the second, photosynthesis begins as the plant develops leaves and branches. In the third phase, stolons develop from lower leaf axils on the stem and grow downwards into the ground and on these stolons new tubers develop as swellings of the stolon. This phase is often, but not always, associated with flowering. Tuber formation halts when soil temperatures reach ; hence potatoes are considered a cool-season, or winter, crop. Tuber bulking occurs during the fourth phase, when the plant begins investing the majority of its resources in its newly formed tubers. At this phase, several factors are critical to a good yield: optimal soil moisture and temperature, soil nutrient availability and balance, and resistance to pest attacks. The fifth and final phase is the maturation of the tubers: the plant canopy dies back, the tuber skins harden, and the sugars in the tubers convert to starches.

New tubers may start growing at the surface of the soil. Since exposure to light leads to an undesirable greening of the skins and the development of solanine as a protection from the sun's rays, growers cover surface tubers. Commercial growers cover them by piling additional soil around the base of the plant as it grows (called "hilling" up, or in British English "earthing up"). An alternative method, used by home gardeners and smaller-scale growers, involves covering the growing area with organic mulches such as straw or plastic sheets.

Correct potato husbandry can be an arduous task in some circumstances. Good ground preparation, harrowing, plowing, and rolling are always needed, along with a little grace from the weather and a good source of water. Three successive plowings, with associated harrowing and rolling, are desirable before planting. Eliminating all root-weeds is desirable in potato cultivation. In general, the potatoes themselves are grown from the eyes of another potato and not from seed. Home gardeners often plant a piece of potato with two or three eyes in a hill of mounded soil. Commercial growers plant potatoes as a row crop using seed tubers, young plants or microtubers and may mound the entire row. Seed potato crops are in some countries to eliminate diseased plants or those of a different variety from the seed crop.

Potatoes are sensitive to heavy frosts, which damage them in the ground. Even cold weather makes potatoes more susceptible to bruising and possibly later rotting, which can quickly ruin a large stored crop.

At harvest time, gardeners usually dig up potatoes with a long-handled, three-prong "grape" (or graip), i.e., a spading fork, or a potato hook, which is similar to the graip but with tines at a 90° angle to the handle. In larger plots, the plow is the fastest implement for unearthing potatoes. Commercial harvesting is typically done with large potato harvesters, which scoop up the plant and surrounding earth. This is transported up an apron chain consisting of steel links several feet wide, which separates some of the dirt. The chain deposits into an area where further separation occurs. Different designs use different systems at this point. The most complex designs use vine choppers and shakers, along with a blower system to separate the potatoes from the plant. The result is then usually run past workers who continue to sort out plant material, stones, and rotten potatoes before the potatoes are continuously delivered to a wagon or truck. Further inspection and separation occurs when the potatoes are unloaded from the field vehicles and put into storage.

Immature potatoes may be sold as "creamer potatoes" and are particularly valued for taste. These are often harvested by the home gardener or farmer by "grabbling", i.e. pulling out the young tubers by hand while leaving the plant in place. A creamer potato is a variety of potato harvested before it matures to keep it small and tender. It is generally either a Yukon Gold potato or a Red potato, called gold creamers or red creamers respectively, and measures approximately one inch in diameter. The skin of creamer potatoes is waxy and high in moisture content, and the flesh contains a lower level of starch than other potatoes. Like potatoes in general, they can be prepared by boiling, baking, frying, and roasting. Slightly older than creamer potatoes are "new potatoes", which are also prized for their taste and texture and often come from the same varieties.

Potatoes are usually cured after harvest to improve skin-set. Skin-set is the process by which the skin of the potato becomes resistant to skinning damage. Potato tubers may be susceptible to skinning at harvest and suffer skinning damage during harvest and handling operations. Curing allows the skin to fully set and any wounds to heal. Wound-healing prevents infection and water-loss from the tubers during storage. Curing is normally done at relatively warm temperatures with high humidity and good gas-exchange if at all possible.

Storage facilities need to be carefully designed to keep the potatoes alive and slow the natural process of decomposition, which involves the breakdown of starch. It is crucial that the storage area is dark, well ventilated and for long-term storage maintained at temperatures near . For short-term storage before cooking, temperatures of about are preferred.

On the other hand, temperatures below convert potatoes' starch into sugar, which alters their taste and cooking qualities and leads to higher acrylamide levels in the cooked product, especially in deep-fried dishesthe discovery of acrylamides in starchy foods in 2002 has led to many international health concerns as they are believed to be probable carcinogens and their occurrence in cooked foods is currently under study as a possible influence in potential health problems.

Under optimum conditions possible in commercial warehouses, potatoes can be stored for up to ten to twelve months. When stored in homes, the shelf life is usually only a few weeks. If potatoes develop green areas or start to sprout, these areas should be trimmed before using. Trimming or peeling green areas are inadequate to remove copresent toxins, and such potatoes are no longer suitable as animal food.

Commercial storage of potatoes involves several phases: drying of surface moisture; a wound healing phase at 85% to 95% relative humidity and temperatures below ; a staged cooling phase; a holding phase; and a reconditioning phase, during which the tubers are slowly warmed. Mechanical ventilation is used at various points during the process to prevent condensation and accumulation of carbon dioxide.
The world dedicated 18.6 million hectares in 2010 for potato cultivation. The average world farm yield for potato was 17.4 tonnes per hectare, in 2010. Potato farms in the United States were the most productive in 2010, with a nationwide average of 44.3 tonnes per hectare. United Kingdom was a close second.

New Zealand farmers have demonstrated some of the best commercial yields in the world, ranging between 60 and 80 tonnes per hectare, some reporting yields of 88 tonnes potatoes per hectare.

There is a big gap among various countries between high and low yields, even with the same variety of potato. Average potato yields in developed economies ranges between 38–44 tonnes per hectare. China and India accounted for over a third of world's production in 2010, and had yields of 14.7 and 19.9 tonnes per hectare respectively. The yield gap between farms in developing economies and developed economies represents an opportunity loss of over 400 million tonnes of potato, or an amount greater than 2010 world potato production. Potato crop yields are determined by factors such as the crop breed, seed age and quality, crop management practices and the plant environment. Improvements in one or more of these yield determinants, and a closure of the yield gap, can be a major boost to food supply and farmer incomes in the developing world.

While there are close to 4,000 varieties of potato, it has been bred into many standard or well-known varieties, each of which has particular agricultural or culinary attributes. In general, varieties are categorized into a few main groups, such as russets, reds, whites, yellows (also called Yukons) and purples—based on common characteristics. Around 80 varieties are commercially available in the UK. For culinary purposes, varieties are often differentiated by their waxiness. Floury, or mealy (baking) potatoes have more starch (20–22%) than waxy (boiling) potatoes (16–18%). The distinction may also arise from variation in the comparative ratio of two potato starch compounds: amylose and amylopectin. Amylose, a long-chain molecule, diffuses from the starch granule when cooked in water, and lends itself to dishes where the potato is mashed. Varieties that contain a slightly higher amylopectin content, a highly branched molecule, help the potato retain its shape when boiled.

The European Cultivated Potato Database (ECPD) is an online collaborative database of potato variety descriptions, updated and maintained by the Scottish Agricultural Science Agency within the framework of the European Cooperative Programme for Crop Genetic Resources Networks (ECP/GR)—which is run by the International Plant Genetic Resources Institute (IPGRI).

Dozens of potato cultivars have been bred specifically for their colors, including gold, red, and blue varieties that contain varying amounts of phytochemicals, including carotenoids for gold/yellow or polyphenols for red or blue cultivars. Carotenoid compounds include provitamin A alpha-carotene and beta-carotene, which are converted to the essential nutrient, vitamin A, during digestion. Anthocyanins mainly responsible for red or blue pigmentation in potato cultivars do not have nutritional significance, but are used for color variety and consumer appeal. Potatoes have been bioengineered specifically for these pigmentation traits.

Genetic research has produced several genetically modified varieties. 'New Leaf', owned by Monsanto Company, incorporates genes from "Bacillus thuringiensis", which confers resistance to the Colorado potato beetle; 'New Leaf Plus' and 'New Leaf Y', approved by US regulatory agencies during the 1990s, also include resistance to viruses. McDonald's, Burger King, Frito-Lay, and Procter & Gamble announced they would not use genetically modified potatoes, and Monsanto published its intent to discontinue the line in March 2001.

Waxy potato varieties produce two main kinds of potato starch, amylose and amylopectin, the latter of which is most industrially useful. The German chemical company BASF created the Amflora potato, which has been modified to contain antisense against the enzyme that drives synthesis of amylose, namely granule bound starch synthase. This resulting potato almost exclusively produces amylopectin, and thus is more useful for the starch industry. In 2010, the European Commission cleared the way for 'Amflora' to be grown in the European Union for industrial purposes only—not for food. Nevertheless, under EU rules, individual countries have the right to decide whether they will allow this potato to be grown on their territory. Commercial planting of 'Amflora' was expected in the Czech Republic and Germany in the spring of 2010, and Sweden and the Netherlands in subsequent years. Another GM potato variety developed by BASF is 'Fortuna' which was made resistant to late blight by adding two resistance genes, blb1 and blb2, which originate from the Mexican wild potato Solanum bulbocastanum. In October 2011 BASF requested cultivation and marketing approval as a feed and food from the EFSA. In 2012, GMO development in Europe was stopped by BASF.

In November 2014, the USDA approved a genetically modified potato developed by J.R. Simplot Company, which contains genetic modifications that prevent bruising and produce less acrylamide when fried than conventional potatoes; the modifications do not cause new proteins to be made, but rather prevent proteins from being made via RNA interference.

The historically significant "Phytophthora infestans" (late blight) remains an ongoing problem in Europe and the United States. Other potato diseases include "Rhizoctonia", "Sclerotinia", black leg, powdery mildew, powdery scab and leafroll virus.

Insects that commonly transmit potato diseases or damage the plants include the Colorado potato beetle, the potato tuber moth, the green peach aphid ("Myzus persicae"), the potato aphid, beet leafhoppers, thrips, and mites. The potato cyst nematode is a microscopic worm that thrives on the roots, thus causing the potato plants to wilt. Since its eggs can survive in the soil for several years, crop rotation is recommended.

During the crop year 2008, many of the certified organic potatoes produced in the United Kingdom and certified by the Soil Association as organic were sprayed with a copper pesticide to control potato blight ("Phytophthora infestans"). According to the Soil Association, the total copper that can be applied to organic land is 6 kg/ha/year.

According to an Environmental Working Group analysis of USDA and FDA pesticide residue tests performed from 2000 through 2008, 84% of the 2,216 tested potato samples contained detectable traces of at least one pesticide. A total of 36 unique pesticides were detected on potatoes over the 2,216 samples, though no individual sample contained more than 6 unique pesticide traces, and the average was 1.29 detectable unique pesticide traces per sample. The average quantity of all pesticide traces found in the 2,216 samples was 1.602 ppm. While this was a very low value of pesticide residue, it was the highest amongst the 50 vegetables analyzed.

Potatoes are prepared in many ways: skin-on or peeled, whole or cut up, with seasonings or without. The only requirement involves cooking to swell the starch granules. Most potato dishes are served hot but some are first cooked, then served cold, notably potato salad and potato chips/crisps. Common dishes are: mashed potatoes, which are first boiled (usually peeled), and then mashed with milk or yogurt and butter; whole baked potatoes; boiled or steamed potatoes; French-fried potatoes or chips; cut into cubes and roasted; scalloped, diced, or sliced and fried (home fries); grated into small thin strips and fried (hash browns); grated and formed into dumplings, Rösti or potato pancakes. Unlike many foods, potatoes can also be easily cooked in a microwave oven and still retain nearly all of their nutritional value, provided they are covered in ventilated plastic wrap to prevent moisture from escaping; this method produces a meal very similar to a steamed potato, while retaining the appearance of a conventionally baked potato. Potato chunks also commonly appear as a stew ingredient. Potatoes are boiled between 10 and 25 minutes, depending on size and type, to become soft.

Potatoes are also used for purposes other than eating by humans, for example:

Peruvian cuisine naturally contains the potato as a primary ingredient in many dishes, as around 3,000 varieties of this tuber are grown there.
Some of the more notable dishes include boiled potato as a base for several dishes or with ají-based sauces like in Papa a la Huancaína or ocopa, diced potato for its use in soups like in cau cau, or in Carapulca with dried potato (papa seca). Smashed condimented potato is used in causa Limeña and papa rellena. French-fried potatoes are a typical ingredient in Peruvian stir-fries, including the classic dish lomo saltado.

Chuño is a freeze-dried potato product traditionally made by Quechua and Aymara communities of Peru and Bolivia, and is known in various countries of South America, including Peru, Bolivia, Argentina, and Chile. In Chile's Chiloé Archipelago, potatoes are the main ingredient of many dishes, including milcaos, chapaleles, curanto and chochoca. In Ecuador, the potato, as well as being a staple with most dishes, is featured in the hearty "locro de papas", a thick soup of potato, squash, and cheese.

In the UK, potatoes form part of the traditional staple fish and chips. Roast potatoes are commonly served with a Sunday roast, and mashed potatoes form a major component of several other traditional dishes such as shepherd's pie, bubble and squeak, and bangers and mash. New potatoes may be cooked with mint but always served with butter.

The Tattie scone is a popular Scottish dish containing potatoes. Colcannon is a traditional Irish food made with mashed potato, shredded kale or cabbage, and onion; champ is a similar dish. Boxty pancakes are eaten throughout Ireland, although associated especially with the North, and in Irish diaspora communities; they are traditionally made with grated potatoes, soaked to loosen the starch and mixed with flour, buttermilk and baking powder. A variant eaten and sold in Lancashire, especially Liverpool, is made with cooked and mashed potatoes.

"Bryndzové halušky" is the Slovakian national dish, made of a batter of flour and finely grated potatoes that is boiled to form dumplings. These are then mixed with regionally varying ingredients.

In Germany, Northern and Eastern Europe (especially in Scandinavian countries), Finland, Poland, Russia, Belarus and Ukraine, newly harvested, early ripening varieties are considered a special delicacy. Boiled whole and served un-peeled with dill, these "new potatoes" are traditionally consumed with Baltic herring. Puddings made from grated potatoes (kugel, kugelis, and potato babka) are popular items of Ashkenazi, Lithuanian, and Belarusian cuisine. German fries and various version of Potato salad are part of German cuisine. Bauernfrühstück(literally "Farmer's breakfast") is a warm German dish made from fried potatoes, eggs, ham and vegetables.

Cepelinai is Lithuanian national dish. They are a type of dumpling made from riced potatoes (see Potato ricer) and usually stuffed with minced meat, although sometimes dry cottage cheese (curd) or mushrooms are used instead.
In Western Europe, especially in Belgium, sliced potatoes are fried to create "frieten", the original French fried potatoes. "Stamppot", a traditional Dutch meal, is based on mashed potatoes mixed with vegetables.

In France, the most notable potato dish is the "Hachis Parmentier", named after Antoine-Augustin Parmentier, a French pharmacist, nutritionist, and agronomist who, in the late 18th century, was instrumental in the acceptance of the potato as an edible crop in the country. The "pâté aux pommes de terre" is a regional potato dish from the central Allier and Limousin regions.

In the north of Italy, in particular, in the Friuli region of the northeast, potatoes serve to make a type of pasta called gnocchi. Similarly, cooked and mashed potatoes or potato flour can be used in the Knödel or dumpling eaten with or added to meat dishes all over central and Eastern Europe, but especially in Bavaria and Luxembourg. Potatoes form one of the main ingredients in many soups such as the vichyssoise and Albanian potato and cabbage soup. In western Norway, komle is popular.

A traditional Canary Islands dish is Canarian wrinkly potatoes or "papas arrugadas". "Tortilla de patatas" (potato omelete) and "patatas bravas" (a dish of fried potatoes in a spicy tomato sauce) are near-universal constituent of Spanish tapas.

In the US, potatoes have become one of the most widely consumed crops and thus have a variety of preparation methods and condiments. French fries and often hash browns are commonly found in typical American fast-food burger 'joints' and cafeterias. One popular favourite involves a baked potato with cheddar cheese (or sour cream and chives) on top, and in New England "smashed potatoes" (a chunkier variation on mashed potatoes, retaining the peel) have great popularity. Potato flakes are popular as an instant variety of mashed potatoes, which reconstitute into mashed potatoes by adding water, with butter or oil and salt to taste. A regional dish of Central New York, salt potatoes are bite-size new potatoes boiled in water saturated with salt then served with melted butter. At more formal dinners, a common practice includes taking small red potatoes, slicing them, and roasting them in an iron skillet. Among American Jews, the practice of eating latkes (fried potato pancakes) is common during the festival of Hanukkah.

A traditional Acadian dish from New Brunswick is known as "poutine râpée". The Acadian poutine is a ball of grated and mashed potato, salted, sometimes filled with pork in the centre, and boiled. The result is a moist ball about the size of a baseball. It is commonly eaten with salt and pepper or brown sugar. It is believed to have originated from the German "Klöße", prepared by early German settlers who lived among the Acadians. "Poutine", by contrast, is a hearty serving of French fries, fresh cheese curds and hot gravy. Tracing its origins to Quebec in the 1950s, it has become a widespread and popular dish throughout Canada.

Potato grading for Idaho potatoes is performed in which No. 1 potatoes are the highest quality and No. 2 are rated as lower in quality due to their appearance (e.g. blemishes or bruises, pointy ends). Potato density assessment can be performed by floating them in brines. High-density potatoes are desirable in the production of dehydrated mashed potatoes, potato crisps and french fries.

In South Asia, the Potato is a very popular traditional staple. In India, the most popular potato dishes are "aloo ki sabzi", batata vada, and samosa, which is spicy mashed potato mixed with a small amount of vegetable stuffed in conical dough, and deep fried. Potatoes are also a major ingredient as fast food items, such as aloo chaat, where they are deep fried and served with chutney. In Northern India, alu dum and alu paratha are a favourite part of the diet; the first is a spicy curry of boiled potato, the second is a type of stuffed chapati.

A dish called masala dosa from South India is very notable all over India. It is a thin pancake of rice and pulse paste rolled over spicy smashed potato and eaten with sambhar and chutney. Poori in south India in particular in Tamil Nadu is almost always taken with smashed potato masal. Other favourite dishes are alu tikki and pakoda items.

Vada pav is a popular vegetarian fast food dish in Mumbai and other regions in the Maharashtra in India.

Aloo posto (a curry with potatoes and poppy seeds) is immensely popular in East India, especially Bengal. Although potatoes are not native to India, it has become a vital part of food all over the country especially North Indian food preparations. In Tamil Nadu this tuber acquired a name based on its appearance 'urulai-k-kizhangu' (உருளைக் கிழங்கு) meaning cylindrical tuber.

The Aloo gosht, Potato and meat curry, is one of the popular dishes in South Asia, especially in Pakistan.

In East Asia, particularly Southeast Asia, rice is by far the predominant starch crop, with potatoes a secondary crop, especially in China and Japan. However, it is used in northern China where rice is not easily grown, with a popular dish being 青椒土豆丝 (qīng jiāo tǔ dòu sī), made with green pepper, vinegar and thin slices of potato. In the winter, roadside sellers in northern China will also sell roasted potatoes. It is also occasionally seen in Korean and Thai cuisines.

During the late 19th century, numerous images of potato harvesting appeared in European art, including the works of Willem Witsen and Anton Mauve.

Van Gogh's 1885 painting "The Potato Eaters" portrays a family eating potatoes. Van Gogh said he wanted to depict peasants as they really were. He deliberately chose coarse and ugly models, thinking that they would be natural and unspoiled in his finished work.

Jean-François Millet's "The Potato Harvest" depicts peasants working in the plains between Barbizon and Chailly. It presents a theme representative of the peasants' struggle for survival. Millet's technique for this work incorporated paste-like pigments thickly applied over a coarsely textured canvas.

The potato has been an essential crop in the Andes since the pre-Columbian Era. The Moche culture from Northern Peru made ceramics from earth, water, and fire. This pottery was a sacred substance, formed in significant shapes and used to represent important themes. Potatoes are represented anthropomorphically as well as naturally.
Invented in 1949 and marketed and sold commercially by Hasbro in 1952, Mr. Potato Head is an American toy that consists of a plastic potato and attachable plastic parts such as ears and eyes to make a face. It was the first toy ever advertised on television.





</doc>
<doc id="23503" url="https://en.wikipedia.org/wiki?curid=23503" title="Portland, Oregon">
Portland, Oregon

Portland is the largest city in the U.S. state of Oregon and the seat of Multnomah County. It is a major port in the Willamette Valley region of the Pacific Northwest, at the confluence of the Willamette and Columbia rivers. The city covers and had an estimated population of 647,805 in 2017, making it the 26th most populous city in the United States, and the second-most populous in the Pacific Northwest. Approximately 2,424,955 people live in the Portland metropolitan statistical area (MSA), making it the 25th most populous MSA in the United States. Its Combined Statistical Area (CSA) ranks 18th with a population of 3,160,488. Roughly 60% of Oregon's population resides within the Portland metropolitan area.

Named after Portland, Maine, which in turn was named after the Isle of Portland in Dorset, the Oregon settlement began to be populated in the 1830s near the end of the Oregon Trail. Its water access provided convenient transportation of goods, and the timber industry was a major force in the city's early economy. At the turn of the 20th century, the city had a reputation as one of the most dangerous port cities in the world, a hub for organized crime and racketeering. After the city's economy experienced an industrial boom during World War II, its hard-edged reputation began to dissipate. Beginning in the 1960s, Portland became noted for its growing progressive political values, earning it a reputation as a bastion of counterculture.

The city operates with a commission-based government guided by a mayor and four commissioners as well as Metro, the only directly elected metropolitan planning organization in the United States. The city government is notable for its land-use planning and investment in public transportation. Portland is frequently recognized as one of the world's most environmentally conscious cities because of its high walkability, large community of bicyclists, farm-to-table dining, expansive network of public transportation options, and over of public parks. Its climate is marked by warm, dry summers and cool, rainy winters. This climate is ideal for growing roses, and Portland has been called the "City of Roses" for over a century.

During the prehistoric period, the land that would become Portland was flooded after the collapse of glacial dams from Lake Missoula, in what would later become Montana. These massive floods occurred during the last ice age and filled the Willamette Valley with of water.

Before American pioneers began arriving in the 1800s, the land that eventually became Portland and surrounding Multnomah County was inhabited for many centuries by two bands of indigenous Chinook people— the Multnomah and the Clackamas peoples. The Chinook people occupying the land which would become Portland were first documented by Meriwether Lewis and William Clark in 1805. Before its European settlement, the Portland Basin of the lower Columbia River and Willamette River valleys had been one of the most densely populated regions on the Pacific Coast.

Large numbers of pioneer settlers began arriving in the Willamette Valley in the 1830s via the Oregon Trail, though life was originally centered in nearby Oregon City. In the early 1840s a new settlement emerged ten miles from the mouth of the Willamette River, roughly halfway between Oregon City and Fort Vancouver. This community was initially referred to as "Stumptown" and "The Clearing" because of the many trees cut down to allow for its growth. In 1843 William Overton saw potential in the new settlement but lacked the funds to file an official land claim. For 25 cents Overton agreed to share half of the site with Asa Lovejoy of Boston.

In 1845 Overton sold his remaining half of the claim to Francis W. Pettygrove of Portland, Maine. Both Pettygrove and Lovejoy wished to rename "The Clearing" after their respective hometowns (Lovejoy's being Boston, and Pettygrove's, Portland). This controversy was settled with a coin toss which Pettygrove won in a series of two out of three tosses, thereby providing Portland with its namesake. The coin used for this decision, now known as the Portland Penny, is on display in the headquarters of the Oregon Historical Society. At the time of its incorporation on February 8, 1851, Portland had over 800 inhabitants, a steam sawmill, a log cabin hotel, and a newspaper, the "Weekly Oregonian". A major fire swept through downtown in August 1873, destroying twenty blocks on the west side of the Willamette along Yamhill and Morrison Streets, and causing $1.3 million in damage. By 1879, the population had grown to 17,500 and by 1890 it had grown to 46,385. In 1888, the city built the first steel bridge built on the West Coast.

Portland's access to the Pacific Ocean via the Willamette and the Columbia rivers, as well as its easy access to the agricultural Tualatin Valley via the "Great Plank Road" (the route of current-day U.S. Route 26), provided the pioneer city with an advantage over other nearby ports, and it grew very quickly. Portland remained the major port in the Pacific Northwest for much of the 19th century, until the 1890s, when Seattle's deepwater harbor was connected to the rest of the mainland by rail, affording an inland route without the treacherous navigation of the Columbia River. The lumber industry also became a prominent economical presence, due to the area's large population of Douglas Firs, Western Hemlocks, Red Cedars, and Big Leaf Maple trees.

Portland developed a reputation early in its history as a hard-edged and gritty port town. Some historians have described the city's early establishment as being a "scion of New England; an ends-of-the-earth home for the exiled spawn of the eastern established elite." In 1889, "The Oregonian" called Portland "the most filthy city in the Northern States", due to the unsanitary sewers and gutters, and, at the turn of the 20th century, it was considered one of the most dangerous port cities in the world. The city housed a large number of saloons, bordellos, gambling dens, and boardinghouses which were populated with miners after the California Gold Rush, as well as the multitude of sailors passing through the port. By the early 20th century, the city had lost its reputation as a "sober frontier city" and garnered a reputation for being violent and dangerous.

Between 1900 and 1930, the city's population tripled from nearly 100,000 to 301,815. During World War II, it housed an "assembly center" from which up to 3,676 people of Japanese descent were dispatched to internment camps in the heartland. The Pacific International Livestock Exposition operated from May through September 10, 1942 processing people from the city, northern Oregon, and central Washington.

At the same time, Portland became a notorious hub for underground criminal activity and organized crime between the 1940s and 1950s. In 1957, "LIFE" Magazine published an article detailing the city's history of government corruption and crime, specifically its gambling rackets and illegal nightclubs. The article, which focused on crime boss Jim Elkins, became the basis of a fictionalized film titled "Portland Exposé" (1957). In spite of the city's seedier undercurrent of criminal activity, Portland enjoyed an economic and industrial surge during World War II. Ship builder Henry J. Kaiser had been awarded contracts to build Liberty ships and aircraft carrier escorts, and chose sites in Portland and Vancouver, Washington, for work yards. During this time, Portland's population rose by over 150,000, largely attributed to recruited laborers.

During the 1960s, an influx of hippie subculture began to take root in the city in the wake of San Francisco's burgeoning countercultural scene. The city's Crystal Ballroom became a hub for the city's psychedelic culture, while food cooperatives and listener-funded media and radio stations were established. A large social activist presence evolved during this time as well, specifically concerning Native American rights, environmentalist causes, and gay rights. By the 1970s, Portland had well established itself as a progressive city, and experienced an economic boom for the majority of the decade; however, the slowing of the housing market in 1979 caused demand for the city and state timber industries to drop significantly.

In the 1990s, the technology industry began to emerge in Portland, specifically with the establishment of companies like Intel, which brought more than $10 billion in investments in 1995 alone. After the year 2000, Portland experienced significant growth, with a population rise of over 90,000 between the years 2000 and 2014. The city's increased presence within the cultural lexicon has established it as a popular city for young people, and it was second only to Louisville, Kentucky as one of the cities to attract and retain the highest number of college-educated people in the United States. Between 2001 and 2012, Portland's gross domestic product per person grew fifty percent, more than any other city in the country.

The city has acquired a diverse range of nicknames throughout its history, though it is most often called "Rose City" or "The City of Roses", the latter of which has been its unofficial nickname since 1888 and its official nickname since 2003. Another widely used nickname by local residents in everyday speech is "PDX", which is also the airport code for Portland International Airport. Other nicknames include Bridgetown, Stumptown, Rip City, Soccer City, P-Town, Portlandia, and the more antiquated Little Beirut.

Portland lies on top of an extinct volcanic field known as the Boring Lava Field, named after the nearby bedroom community of Boring. The Boring Lava Field has at least 32 cinder cones such as Mount Tabor, and its center lies in southeast Portland. Mount St. Helens, a highly active volcano northeast of the city in Washington state, is easily visible on clear days and is close enough to have dusted the city with volcanic ash after its eruption on May 18, 1980. The rocks of the Portland area range in age from late Eocene to more recent eras.

Multiple shallow, active fault lines traverse the Portland metropolitan area. Among them are the Portland Hills Fault on the city's west side, and the East Bank Fault on the east side. According to a 2017 survey, several of these faults were characterized as "probably more of a hazard" than the Cascadia subduction zone due to their proximities to population centers, with the potential of producing magnitude 7 earthquakes. Notable earthquakes that have impacted the Portland area in recent history include the 6.8-magnitude Nisqually earthquake in 2001, and a 5.6-magnitude earthquake that struck on March 25, 1993.

Per a 2014 report, over 7,000 locations within the Portland area are at high-risk for landslides and soil liquefaction in the event of a major earthquake, including much of the city's west side (such as Washington Park) and sections of Clackamas County.

Portland is east of the Pacific Ocean at the northern end of Oregon's most populated region, the Willamette Valley. Downtown Portland straddles the banks of the Willamette River, which flows north through the city center and separates the city's east and west neighborhoods. Less than from downtown, the Willamette River flows into the Columbia River, the fourth-largest river in the United States, which divides Oregon from Washington state. Portland is approximately upriver from the Pacific Ocean on the Columbia.

Though much of downtown Portland is relatively flat, the foothills of the Tualatin Mountains, more commonly referred to locally as the "West Hills", pierce through the northwest and southwest reaches of the city. Council Crest Park, commonly thought of as the highest point within city limits, is in the West Hills and rises to an elevation of The city's actual high point is a little-known and infrequently accessed point of near Forest Park. The highest point east of the river is Mt. Tabor, an extinct volcanic cinder cone, which rises to . Nearby Powell Butte and Rocky Butte rise to and , respectively. To the west of the Tualatin Mountains lies the Oregon Coast Range, and to the east lies the actively volcanic Cascade Range. On clear days, Mt. Hood and Mt. St. Helens dominate the horizon, while Mt. Adams and Mt. Rainier can also be seen in the distance.

According to the United States Census Bureau, the city has an area of , of which is land and is water. Although almost all of Portland is within Multnomah County, small portions of the city are within Clackamas and Washington Counties, with populations estimated at 785 and 1,455, respectively.

Portland's cityscape derives much of its character from the many bridges that span the Willamette River downtown, several of which are historic landmarks, and Portland has been nicknamed "Bridgetown" for many decades as a result. Three of downtown's most heavily used bridges are more than 100 years old and are designated historic landmarks: Hawthorne Bridge (1910), Steel Bridge (1912), and Broadway Bridge (1913). Portland's newest bridge in the downtown area, Tilikum Crossing, opened in 2015 and is the first new bridge to span the Willamette in Portland since the 1973 opening of the double-decker Fremont Bridge.

Other bridges that span the Willamette river in the downtown area include the Burnside Bridge, the Ross Island Bridge (both built 1926), and the double-decker Marquam Bridge (built 1966). Other bridges outside the downtown area include the Sellwood Bridge (built 2016) to the south; and the St. Johns Bridge, a Gothic revival suspension bridge built in 1931, to the north. The Glenn L. Jackson Memorial Bridge and the Interstate Bridge provide access from Portland across the Columbia River into Washington state.

The Willamette River, which flows north through downtown, serves as the natural boundary between east and west Portland. The denser and earlier-developed west side extends into the lap of the West Hills, while the flatter east side fans out for roughly 180 blocks until it meets the suburb of Gresham. In 1891 the cities of Portland, Albina, and East Portland were consolidated, creating inconsistent patterns of street names and addresses. The "great renumbering" on September 2, 1931 standardized street naming patterns, divided Portland into five official quadrants, and changed house numbers from 20 per block to 100 per block. 

The five current quintets (a.k.a. "quadrants") of Portland have developed distinctive identities, with mild cultural differences and friendly rivalries between their residents, especially between those who live east of the Willamette River versus west of the river. The official quintets of Portland are: North, Northwest, Northeast, Southwest, and Southeast, with downtown Portland in the SW quadrant. The Willamette River divides the east and west quadrants while Burnside Street, which traverses the entire city lengthwise, divides the north and south quadrants. All addresses within the city are denoted as belonging to one of these specific quadrants with the prefixes: N, NW, NE, SW or SE. 

A new "sixth sextant" called South Portland—which was officially approved by the Portland City Council on June 6, 2018—is roughly bounded by Naito Parkway and Barbur Boulevard to the west, Montgomery Street to the north and Nevada Street to the south. In 2018, the city's Bureau of Transportation finalized a plan to transition this part of Portland into South Portland, beginning in May 2020 and to be completed by May 2025, to reduce confusions by 9-1-1 dispatchers and delivery services. For example, the current address 0246 SW California St. will become 246 S. California St. effective May 2020.

The Pearl District in Northwest Portland, which was largely occupied by warehouses, light industry and railroad classification yards in the early to mid-20th century, now houses upscale art galleries, restaurants, and retail stores, and is one of the wealthiest neighborhoods in the city. Areas further west of the Pearl District include neighborhoods known as Uptown and Nob Hill, as well as the Alphabet District and NW 23rd Ave., a major shopping street lined with clothing boutiques and other upscale retail, mixed with cafes and restaurants.

Northeast Portland is home to the Lloyd District, Alberta Arts District, and the Hollywood District. The northernmost point of the city, known simply as North Portland, is also largely residential; it contains the St. Johns neighborhood, which is historically one of the most ethnically diverse and poorest neighborhoods in the city.

Old Town Chinatown is next to the Pearl District in Northwest Portland, while Southwest Portland consists largely of the downtown district, made up of commercial businesses, museums, skyscrapers, and public landmarks. Southeast Portland is largely residential, and consists of the Hawthorne District, Belmont, Brooklyn, and Mount Tabor.

Portland's South Waterfront area has developed into a dense neighborhood of shops, condominiums, and apartments. The area is served by the Portland Streetcar, the MAX Orange Line and four TriMet bus lines.

Portland experiences a temperate climate with both oceanic and Mediterranean features. This climate is characterized by warm, dry summers and cool, rainy winters. The precipitation pattern is distinctly Mediterranean, with little to no rainfall occurring during the summer months and more than half of annual precipitation falling between November and February. Of the three most populated cities within the Pacific Northwest (Seattle, Vancouver, British Columbia and Portland) Portland has the warmest average temperature, the highest number of sunshine hours, and the fewest inches of rainfall and snowfall. According to the Köppen climate classification, Portland falls within the dry-summer mild temperate zone ("Csb"), also referred to as a warm-summer Mediterranean climate with a USDA Plant Hardiness Zones between 8b and 9a. Other climate systems, such as the Trewartha climate classification, places it within the oceanic zone ("Do"), like much of the Pacific Northwest and Western Europe.

Summers in Portland are warm to hot, dry, and sunny. The months of June, July, August and September account for a combined of total rainfall only 12% of the of the precipitation that falls throughout the year. The warmest month is August, with an average high temperature of . Because of its inland location from the coast, as well as the protective nature of the Oregon Coast Range to its west, Portland summers are less susceptible to the moderating influence of the nearby Pacific Ocean. Consequently, Portland experiences heat waves with temperatures rising well above for days at a time, and sometimes above . On average, temperatures reach or exceed 56 days per year, of which 12 days will reach and 1.4 days will reach . The most 90-degree days ever recorded in one year is 29, which happened in 2015. The highest temperature ever recorded was , on July 30, 1965, as well as August 8 and 10, 1981. The warmest recorded overnight low was on July 28, 2009. A temperature of has been recorded in all five months from May through September.
Spring and fall can bring variable weather including warm fronts that send temperatures surging above and cold snaps that plunge daytime temperatures into the 40s °F (4–9 °C). However, consistently mild temperatures in the 50s and 60s °F (12–19 °C) are the norm with lengthy stretches of cloudy or partly cloudy days beginning in mid fall and continuing into mid spring. Rain often falls as a light drizzle for several consecutive days at a time, contributing to 155 days on average with measurable (≥) precipitation annually. Temperatures have reached as early as May 3 and as late as October 5, while has been reached as early as April 1 and as late as October 21. Severe weather, such as thunder and lightning, is uncommon and tornadoes are exceptionally rare.

Winters are cool, cloudy, and rainy. The coldest month is December with an average daily high of , although overnight lows usually remain above freezing. Evening temperatures fall to or below freezing 33 nights per year on average, but very rarely to or below . There are only 2.1 days per year where the daytime high temperature fails to rise above freezing. The lowest overnight temperature ever recorded was , on February 2, 1950, while the coldest daytime high temperature ever recorded was on December 30, 1968. The average window for freezing temperatures to potentially occur is between November 15 and March 19, allowing a growing season of 240 days.

Snowfall is uncommon with a normal yearly accumulation of , which usually falls during only two or three days per year. Portland has one of the warmest and least snowy winters of any non-Sun Belt city in the United States, with more than 25 percent of its winters receiving no snow whatsoever. The city of Portland avoids snow more frequently than its suburbs, due in part to its low elevation and urban heat island effect. Neighborhoods outside of the downtown core, especially in slightly higher elevations near the West Hills and Mount Tabor, can experience a dusting of snow while downtown receives no accumulation at all. The city has experienced a few major snow and ice storms in its past with extreme totals having reached at the airport in 1949–50 and at downtown in 1892–93.

The 2010 census reported the city as 76.1% White (444,254 people), 7.1% Asian (41,448), 6.3% Black or African American (36,778), 1.0% Native American (5,838), 0.5% Pacific Islander (2,919), 4.7% belonging to two or more racial groups (24,437) and 5.0% from other races (28,987). 9.4% were Hispanic or Latino, of any race (54,840). Whites not of Hispanic origin made up 72.2% of the total population.

In 1940, Portland's African-American population was approximately 2,000 and largely consisted of railroad employees and their families. During the war-time Liberty Ship construction boom, the need for workers drew many blacks to the city. The new influx of blacks settled in specific neighborhoods, such as the Albina district and Vanport. The May 1948 flood which destroyed Vanport eliminated the only integrated neighborhood, and an influx of blacks into the northeast quadrant of the city continued. Portland's longshoremen racial mix was described as being "lily-white" in the 1960s, when the local International Longshore and Warehouse Union declined to represent grain handlers since some were black.

At 6.3%, Portland's African American population is three times the state average. Over two thirds of Oregon's African-American residents live in Portland. As of the 2000 census, three of its high schools (Cleveland, Lincoln and Wilson) were over 70% white, reflecting the overall population, while Jefferson High School was 87% non-white. The remaining six schools have a higher number of non-whites, including blacks and Asians. Hispanic students average from 3.3% at Wilson to 31% at Roosevelt.
Portland residents identifying solely as Asian Americans account for 7.1% of the population; an additional 1.8% is partially of Asian heritage. Vietnamese Americans make up 2.2% of Portland's population, and make up the largest Asian ethnic group in the city, followed by Chinese (1.7%), Filipinos (0.6%), Japanese (0.5%), Koreans (0.4%), Laotians (0.4%), Hmong (0.2%), and Cambodians (0.1%). A small population of Yao people live in Portland. Portland has two Chinatowns, with New Chinatown along SE 82nd Avenue with Chinese supermarkets, Hong Kong style noodle houses, dim sum, and Vietnamese phở restaurants.

With about 12,000 Vietnamese residing in the city proper, Portland has one of the largest Vietnamese populations in America per capita. According to statistics there are 21,000 Pacific Islanders in Portland, making up 4% of the population.
Portland's population has been and remains predominantly white. In 1940, whites were over 98% of the city's population. In 2009, Portland had the fifth-highest percentage of white residents among the 40 largest U.S. metropolitan areas. A 2007 survey of the 40 largest cities in the U.S. concluded Portland's urban core has the highest percentage of white residents. Some scholars have noted the Pacific Northwest as a whole is "one of the last Caucasian bastions of the United States". While Portland's diversity was historically comparable to metro Seattle and Salt Lake City, those areas grew more diverse in the late 1990s and 2000s. Portland not only remains white, but migration to Portland is disproportionately white.

The Oregon Territory banned African American settlement in 1849. In the 19th century, certain laws allowed the immigration of Chinese laborers but prohibited them from owning property or bringing their families. The early 1920s saw the rapid growth of the Ku Klux Klan, which became very influential in Oregon politics, culminating in the election of Walter M. Pierce as governor.

The largest influxes of minority populations occurred during World War II, as the African American population grew by a factor of 10 for wartime work. After World War II, the Vanport flood in 1948 displaced many African Americans. As they resettled, redlining directed the displaced workers from the wartime settlement to neighboring Albina. There and elsewhere in Portland, they experienced police hostility, lack of employment, and mortgage discrimination, leading to half the black population leaving after the war.

In the 1980s and 1990s, radical skinhead groups flourished in Portland. In 1988, Mulugeta Seraw, an Ethiopian immigrant, was killed by three skinheads. The response to his murder involved a community-driven series of rallies, campaigns, nonprofits and events designed to address Portland's racial history, leading to a city considered significantly more tolerant than in 1988 at Seraw's death.

During the early 2000s, displacement of minorities occurred at a drastic rate. Out of 29 census tracts in north and northeast Portland, ten were majority nonwhite in 2000. By 2010, none of these tracts were majority nonwhite as gentrification drove the cost of living up. Today, Portland's African-American community is concentrated in the north and northeast section of the city, mainly in the King neighborhood. In 2017, the gentrification of Portland was named by Realtor.com to be among the fastest gentrification of cities in the United States.

As of the 2010 census, there are 583,776 people residing in the city, organized into 235,508 households. The population density is 4,375.2 people per square mile. There are 265,439 housing units at an average density of 1989.4 per square mile (1,236.3/km²). Population growth in Portland increased 10.3% between 2000 and 2010. Population growth in the Portland metropolitan area has outpaced the national average during the last decade, and this is expected to continue over the next 50 years.

Out of 223,737 households, 24.5% have children under the age of 18 living with them, 38.1% are married couples living together, 10.8% have a female householder with no husband present, and 47.1% are non-families. 34.6% of all households are made up of individuals and 9% have someone living alone who is 65 years of age or older. The average household size is 2.3 and the average family size is 3. The age distribution was 21.1% under the age of 18, 10.3% from 18 to 24, 34.7% from 25 to 44, 22.4% from 45 to 64, and 11.6% who are 65 years of age or older. The median age is 35 years. For every 100 females, there are 97.8 males. For every 100 females age 18 and over, there are 95.9 males.

The median income for a household in the city is $40,146, and the median income for a family is $50,271. Males have a reported median income of $35,279 versus $29,344 reported for females. The per capita income for the city is $22,643. 13.1% of the population and 8.5% of families are below the poverty line. Out of the total population, 15.7% of those under the age of 18 and 10.4% of those 65 and older are living below the poverty line. Figures delineating the income levels based on race are not available at this time. According to the Modern Language Association, in 2010 80.92% (539,885) percent of Multnomah County residents ages 5 and over spoke English as their primary language at home. 8.10% of the population spoke Spanish (54,036), with Vietnamese speakers making up 1.94%, and Russian 1.46%.

The Portland metropolitan area has historically had a significant LGBT population throughout the late 20th and 21st century. In 2015, the city metro had the second highest percentage of LGBT residents in the United States with 5.4% of residents identifying as gay, lesbian, bisexual, or transgender, second only to San Francisco. In 2006, it was reported to have the seventh highest LGBT population in the country, with 8.8% of residents identifying as gay, lesbian, or bisexual, and the metro ranking fourth in the nation at 6.1%. The city held its first pride festival in 1975 on the Portland State University campus.

Portland has been cited as the least religious city in the United States, with over 42% of residents identifying as religiously "unaffiliated", according to the nonpartisan and nonprofit Public Religion Research Institute's American Values Atlas. Of the 35.89% of the city's residents who do identify as religious, Roman Catholics make up the largest group, at 15.8%. The second highest religious group in the city are Evangelical Christians at 6.04%, with Baptists following behind at 2.5%. Latter Day Saints make up 2.3% of the city's religiously affiliated population, with Lutheran and Pentecostal following behind. 1.48% of religiously affiliated persons identified themselves as following Eastern religions, while 0.86% of the religiously affiliated population identified as Jewish, and 0.29% as Muslim.

Portland's location is beneficial for several industries. Relatively low energy cost, accessible resources, north–south and east–west Interstates, international air terminals, large marine shipping facilities, and both west coast intercontinental railroads are all economic advantages. The U.S. consulting firm Mercer, in a 2009 assessment "conducted to help governments and major companies place employees on international assignments", ranked Portland 42nd worldwide in quality of living; the survey factored in political stability, personal freedom, sanitation, crime, housing, the natural environment, recreation, banking facilities, availability of consumer goods, education, and public services including transportation. In 2012, the city was listed among the 10 best places to retire in the U.S. by CBS MoneyWatch.
The city's marine terminals alone handle over 13 million tons of cargo per year, and the port is home to one of the largest commercial dry docks in the country. The Port of Portland is the third-largest export tonnage port on the west coast of the U.S., and being about upriver, it is the largest fresh-water port. The city of Portland is largest shipper of wheat in the United States, and is the second-largest port for wheat in the world.

The steel industry's history in Portland predates World War II. By the 1950s, the steel industry became the city's number one industry for employment. The steel industry thrives in the region, with Schnitzer Steel Industries, a prominent steel company, shipping a record 1.15 billion tons of scrap metal to Asia during 2003. Other heavy industry companies include ESCO Corporation and Oregon Steel Mills.

Technology is a major component of the city's economy, with more than 1,200 technology companies existing within the metro. This high density of technology companies has led to the nickname Silicon Forest being used to describe the Portland area, a reference to the abundance of trees in the region and to the Silicon Valley region in Northern California. The area also hosts facilities for software companies and online startup companies, some supported by local seed funding organizations and business incubators. Computer components manufacturer Intel is the Portland area's largest employer, providing jobs for more than 15,000 people, with several campuses to the west of central Portland in the city of Hillsboro.
The Portland metro area has become a business cluster for athletic and footwear manufacturers. The area is home to the global, North American or U.S. headquarters of Nike, Adidas, Columbia Sportswear, LaCrosse Footwear, Dr. Martens, Li-Ning, Keen, and Hi-Tec Sports. While headquartered elsewhere, Merrell, Amer Sports and Under Armour have design studios and local offices in the Portland area. Portland-based Precision Castparts is one of two Fortune 500 companies headquartered in Oregon, the other being Nike. Other notable Portland-based companies include film animation studio Laika; commercial vehicle manufacturer Daimler Trucks North America; advertising firm Wieden+Kennedy; bankers Umpqua Holdings; and retailers Fred Meyer, New Seasons Market and Storables.

Breweries are another major industry in Portland, which is home to 85 breweries/microbreweries, the most of any city in the world. Additionally, the city boasts a robust coffee culture that now rivals Seattle and hosts over 20 coffee roasters.

In 2016, home prices in Portland grew faster than in any other city in the United States. Apartment rental costs in the Portland metro area are now equal to those in other major cities such as San Diego, Boston, Miami, Seattle, and Los Angeles with the average one bedroom costing between $1,300 and $1,950 per month. New sky rise apartment building and condo complexes have changed the skyline of the city, adding over 16,000 new units since 2010.

Portland is home to a range of classical performing arts institutions, including the Portland Opera, the Oregon Symphony, and the Portland Youth Philharmonic; the latter, established in 1924, was the first youth orchestra established in the United States. The city is also home to several theaters and performing arts institutions, including the Oregon Ballet Theatre, Northwest Children's Theatre, Portland Center Stage, Artists Repertory Theatre, Miracle Theatre, and Tears of Joy Theatre.

In 2013, the "Guardian" named the city's music scene as one of the "most vibrant" in the United States. Portland is home to famous bands such as the Kingsmen and Paul Revere & the Raiders, both famous for their association with the song "Louie Louie" (1963). Other widely known musical groups include the Dandy Warhols, Quarterflash, Everclear, Pink Martini, The Hugs, Sleater-Kinney, the Shins, Blitzen Trapper, the Decemberists, and the late Elliott Smith. In the 1980s, the city was home to a burgeoning punk scene, which included bands such as the Wipers and Dead Moon. The city's now-demolished Satyricon nightclub was a punk venue notorious for being the place where Nirvana frontman Kurt Cobain first encountered future wife and Hole frontwoman Courtney Love in 1990. Love was then a resident of Portland and started several bands there with Kat Bjelland, later of Babes in Toyland. Multi-Grammy award-winning jazz artist Esperanza Spalding is from Portland and performed with the Chamber Music Society of Oregon at a young age.

A wide range of films have been shot in Portland, from various independent features to major big-budget productions (see "List of films shot in Oregon" for a complete list). Director Gus Van Sant has notably set and shot many of his films in the city. The city has also been featured in various television programs, notably the IFC sketch comedy series "Portlandia". The series, which ran for eight seasons from 2011 to 2018, was shot on location in Portland, and satirized the city as a hub of liberal politics, organic food, alternative lifestyles, and anti-establishment attitudes. MTV's long-time running reality show "The Real World" was also shot in Portland for the show's 29th season: "" premiered on MTV in 2013. Other television series shot in the city include "Leverage", "The Librarians", "Under Suspicion", "Grimm", and "Nowhere Man".

An unusual feature of Portland entertainment is the large number of movie theaters serving beer, often with second-run or revival films. Notable examples of these "brew and view" theaters include the Bagdad Theater and Pub, a former vaudeville theater built in 1927 by Universal Studios; Cinema 21; and the Laurelhurst Theater, in operation since 1923. Portland hosts the world's longest-running H. P. Lovecraft Film Festival at the Hollywood Theatre.

Portland is home to numerous museums and educational institutions, ranging from art museums to institutions devoted to science and wildlife. Among the science-oriented institutions are the Oregon Museum of Science and Industry (OMSI), which consists of five main halls and other ticketed attractions, such as the submarine, the ultra-large-screen Empirical Theater (which replaced an OMNIMAX theater in 2013), and the Kendall Planetarium. The World Forestry Center Discovery Museum, located in the city's Washington Park area, offers educational exhibits on forests and forest-related subjects. Also located in Washington Park are the Hoyt Arboretum, the International Rose Test Garden, the Japanese Garden, and the Oregon Zoo.
The Portland Art Museum owns the city's largest art collection and presents a variety of touring exhibitions each year and, with the recent addition of the Modern and Contemporary Art wing, it became one of the United States' 25 largest museums. Other museums include the Portland Children's Museum, a museum specifically geared for early childhood development; and the Oregon Historical Society Museum, founded in 1898, which has a variety of books, film, pictures, artifacts, and maps dating back throughout Oregon's history. It houses permanent and temporary exhibits about Oregon history, and hosts traveling exhibits about the history of the United States.

Oaks Amusement Park, in the Sellwood district of Southeast Portland, is the city's only amusement park and is also one of the country's longest-running amusement parks. It has operated since 1905 and was known as the "Coney Island of the Northwest" upon its opening.

Portland has been named the best city in the world for street food by several publications and news outlets, including the "U.S. News & World Report" and CNN. Food carts are extremely popular within the city, with over 600 licensed carts, making Portland one of the most robust street food scenes in North America. In 2014, the "Washington Post" called Portland the fourth best city for food in the United States. "Travel + Leisure" ranked Portland's food and bar scene No. 5 in the nation in 2012. Portland is also known as a leader in specialty coffee. The city is home to Stumptown Coffee Roasters as well as dozens of other micro-roasteries and cafes.
Portland has the most breweries and independent microbreweries of any city in the world, with 58 active breweries within city limits and 70+ within the surrounding metro area. The city receives frequent acclaim as the best beer city in the United States and is consistently ranked as one of the top-five beer destinations in the world. Portland has played a prominent role in the microbrewery revolution in the U.S. and is nicknamed "Beertown" and "Beervana" as a result. The McMenamin brothers alone have over thirty brewpubs, distilleries, and wineries scattered throughout the metropolitan area, several in renovated cinemas and other historically significant buildings otherwise destined for demolition. Other notable Portland brewers include Widmer Brothers, BridgePort, Portland Brewing, Hair of the Dog, and Hopworks Urban Brewery.

Portland hosts a number of festivals throughout the year that celebrate beer and brewing, including the Oregon Brewers Festival, held in Tom McCall Waterfront Park. Held each summer during the last full weekend of July, it is the largest outdoor craft beer festival in North America, with over 70,000 attendees in 2008. Other major beer festivals throughout the calendar year include the Spring Beer and Wine Festival in April, the North American Organic Brewers Festival in June, the Portland International Beerfest in July, and the Holiday Ale Festival in December.

Portland is often awarded "Greenest City in America" and similar designations. "Popular Science" awarded Portland the title of the Greenest City in America in 2008, and "Grist" magazine listed it in 2007 as the second greenest city in the world. The city became a pioneer of state-directed metropolitan planning, a program which was instituted statewide in 1969 to compact the urban growth boundaries of the city.

Portland is home to two major league sports franchises: the Portland Trail Blazers of the NBA and the Portland Timbers of Major League Soccer. The Portland Thorns of the National Women's Soccer League also play in Portland. In 2015, the Timbers won the MLS Cup, which was the first male professional sports championship for a team from Portland since the Trail Blazers won the NBA championship in 1977. Despite being the 19th most populated metro area in the United States, Portland contains only one franchise from the NFL, NBA, NHL, or MLB, making it America's most populated metro area with that distinction. The city has been often rumored to receive an additional franchise, although efforts to acquire a team have failed due to stadium funding issues.

Portland sports fans are characterized by their passionate support. The Trail Blazers sold out every home game between 1977 and 1995, a span of 814 consecutive games, the second-longest streak in American sports history. The Timbers joined MLS in 2011 and have sold out every home match since joining the league, a streak that has now reached 70+ matches. The Timbers season ticket waiting list has reached 10,000+, the longest waiting list in MLS. In 2015, they became the first team in the Northwest to win the MLS Cup. Player Diego Valeri marked a new record for fastest goal in MLS Cup history at 27 seconds into the game.

Two rival universities exist within Portland city limits: the University of Portland Pilots and the Portland State University Vikings, both of whom field teams in popular spectator sports including soccer, baseball, and basketball. Portland State also has a football team. Additionally, the University of Oregon Ducks and the Oregon State University Beavers both receive substantial attention and support from many Portland residents, despite their campuses being 110 and 84 miles from the city, respectively.
Running is a popular activity in Portland and every year the city hosts the Portland Marathon as well as parts of the Hood to Coast Relay, the world's largest long-distance relay race (by number of participants). Portland serves as the center to an elite running group, the Nike Oregon Project, and is the residence of several elite runners including British 2012 Olympic 10,000m and 5,000m champion Mo Farah, American record holder at 10,000m Galen Rupp, and 2008 American Olympic bronze medalist at 10,000m Shalane Flanagan.

Portland also hosts numerous cycling events and has become an elite bicycle racing destination. The Oregon Bicycle Racing Association supports hundreds of official bicycling events every year. Weekly events at Alpenrose Velodrome and Portland International Raceway allow for racing nearly every night of the week from March through September. Cyclocross races, such as the Cross Crusade, can attract over 1,000 riders and spectators.

Parks and greenspace planning date back to John Charles Olmsted's 1903 "Report to the Portland Park Board". In 1995, voters in the Portland metropolitan region passed a regional bond measure to acquire valuable natural areas for fish, wildlife, and people. Ten years later, more than of ecologically valuable natural areas had been purchased and permanently protected from development.

Portland is one of only four cities in the U.S. with extinct volcanoes within its boundaries (along with Pilot Butte in Bend, Oregon, Jackson Volcano in Jackson, Mississippi, and Diamond Head in Honolulu, Hawaii). Mount Tabor Park is known for its scenic views and historic reservoirs.

Forest Park is the largest wilderness park within city limits in the United States, covering more than . Portland is also home to Mill Ends Park, the world's smallest park (a two-foot-diameter circle, the park's area is only about 0.3 m). Washington Park is just west of downtown and is home to the Oregon Zoo, Hoyt Arboretum, the Portland Japanese Garden, and the International Rose Test Garden. Portland is also home to Lan Su Chinese Garden (formerly the Portland Classical Chinese Garden), an authentic representation of a Suzhou-style walled garden. Portland's east side has several formal public gardens: the historic Peninsula Park Rose Garden, the rose gardens of Ladd's Addition, the Crystal Springs Rhododendron Garden, the Leach Botanical Garden, and The Grotto.

Portland's downtown features two groups of contiguous city blocks dedicated for park space: the North and South Park Blocks. The Tom McCall Waterfront Park was built in 1974 along the length of the downtown waterfront after Harbor Drive was removed; it now hosts large events throughout the year. The nearby historically significant Burnside Skatepark and five indoor skateparks give Portland a reputation as possibly "the most skateboard-friendly town in America."

Tryon Creek State Natural Area is one of three Oregon State Parks in Portland and the most popular; its creek has a run of steelhead. The other two State Parks are Willamette Stone State Heritage Site, in the West Hills, and the Government Island State Recreation Area in the Columbia River near Portland International Airport.

Portland's city park system has been proclaimed one of the best in America. In its 2013 ParkScore ranking, the Trust for Public Land reported Portland had the seventh best park system among the 50 most populous U.S. cities. ParkScore ranks city park systems by a formula that analyzes the city's median park size, park acres as percent of city area, the percent of city residents within a half-mile of a park, spending of park services per resident, and the number of playgrounds per 10,000 residents. The survey revealed that 80% of Portlanders live within a half-mile to a park, and over 16% of Portland's city area is parkland.

The city of Portland is governed by the Portland City Council, which includes the Mayor, four Commissioners, and an auditor. Each is elected citywide to serve a four-year term. The auditor provides checks and balances in the commission form of government and accountability for the use of public resources. In addition, the auditor provides access to information and reports on various matters of city government.
The city's Office of Neighborhood Involvement serves as a conduit between city government and Portland's 95 officially recognized neighborhoods. Each neighborhood is represented by a volunteer-based neighborhood association which serves as a liaison between residents of the neighborhood and the city government. The city provides funding to neighborhood associations through seven district coalitions, each of which is a geographical grouping of several neighborhood associations. Most (but not all) neighborhood associations belong to one of these district coalitions.

Portland and its surrounding metropolitan area are served by Metro, the United States' only directly elected metropolitan planning organization. Metro's charter gives it responsibility for land use and transportation planning, solid waste management, and map development. Metro also owns and operates the Oregon Convention Center, Oregon Zoo, Portland Center for the Performing Arts, and Portland Metropolitan Exposition Center.

The Multnomah County government provides many services to the Portland area, as do Washington and Clackamas counties to the west and south.

Law enforcement is provided by the Portland Police Bureau. Fire and emergency services are provided by Portland Fire & Rescue.

Portland is a territorial charter city, and strongly favors the Democratic Party. All city offices are technically non-partisan.

Portland's delegation to the Oregon Legislative Assembly is entirely Democratic. In the current 76th Oregon Legislative Assembly, which first convened in 2011, four state Senators represent Portland in the state Senate: Diane Rosenbaum (District 21), Chip Shields (District 22), Jackie Dingfelder (District 23), and Rod Monroe (District 24). Portland sends six Representatives to the state House of Representatives: Jules Bailey (District 42), Lew Frederick (District 43), Tina Kotek (District 44), Michael Dembrow (District 45), Alissa Keny-Guyer (District 46), and Jefferson Smith (District 47).

Portland is split among three U.S. congressional districts. Most of the city is in the 3rd District, represented by Earl Blumenauer, who served on the city council from 1986 until his election to Congress in 1996. Most of the city west of the Willamette River is part of the 1st District, represented by Suzanne Bonamici. A small portion of southwestern Portland is in the 5th District, represented by Kurt Schrader. All three are Democrats; a Republican has not represented a significant portion of Portland in the U.S. House of Representatives since 1975. Both of Oregon's senators, Ron Wyden and Jeff Merkley, are from Portland and are also both Democrats.

In the 2008 presidential election, Democratic candidate Barack Obama easily carried Portland, winning 245,464 votes from city residents to 50,614 for his Republican rival, John McCain. In the 2012 presidential election, Democratic candidate Barack Obama again easily carried Portland, winning 256,925 votes from Multnomah county residents to 70,958 for his Republican rival, Mitt Romney.

Sam Adams, the former mayor of Portland, became the city's first openly gay mayor in 2009. In 2004, 59.7 percent of Multnomah County voters cast ballots against Oregon Ballot Measure 36, which amended the Oregon Constitution to prohibit recognition of same-sex marriages. The measure passed with 56.6% of the statewide vote. Multnomah County is one of two counties where a majority voted against the initiative; the other is Benton County, which includes Corvallis, home of Oregon State University. On April 28, 2005, Portland became the only city in the nation to withdraw from a Joint Terrorism Task Force. As of February 19, 2015, the Portland city council approved permanently staffing the JTTF with two of its city's police officers.

The city consulted with urban planners as far back as 1904, resulting in the development of Washington Park and the 40-Mile Loop greenway, which interconnects many of the city's parks. Portland is often cited as an example of a city with strong land use planning controls. This is largely the result of statewide land conservation policies adopted in 1973 under Governor Tom McCall, in particular the requirement for an urban growth boundary (UGB) for every city and metropolitan area. The opposite extreme, a city with few or no controls, is typically illustrated by Houston.

Portland's urban growth boundary, adopted in 1979, separates urban areas (where high-density development is encouraged and focused) from traditional farm land (where restrictions on non-agricultural development are very strict). This was atypical in an era when automobile use led many areas to neglect their core cities in favor of development along interstate highways, in suburbs, and satellite cities. The original state rules included a provision for expanding urban growth boundaries, but critics felt this wasn't being accomplished. In 1995, the State passed a law requiring cities to expand UGBs to provide enough undeveloped land for a 20-year supply of future housing at projected growth levels.

Oregon's 1973 "urban growth boundary" law limits the boundaries for large-scale development in each metropolitan area in Oregon. This limits access to utilities such as sewage, water and telecommunications, as well as coverage by fire, police and schools. Originally this law mandated the city must maintain enough land within the boundary to provide an estimated 20 years of growth; however, in 2007 the legislature changed the law to require the maintenance of an estimated 50 years of growth within the boundary, as well as the protection of accompanying farm and rural lands. The growth boundary, along with efforts of the PDC to create economic development zones, has led to the development of a large portion of downtown, a large number of mid- and high-rise developments, and an overall increase in housing and business density.

The Portland Development Commission is a semi-public agency that plays a major role in downtown development; city voters created it in 1958 to serve as the city's urban renewal agency. It provides housing and economic development programs within the city, and works behind the scenes with major local developers to create large projects. In the early 1960s, the PDC led the razing of a large Italian-Jewish neighborhood downtown, bounded roughly by I-405, the Willamette River, 4th Avenue and Market street. Mayor Neil Goldschmidt took office in 1972 as a proponent of bringing housing and the associated vitality back to the downtown area, which was seen as emptying out after 5 pm. The effort has had dramatic effects in the 30 years since, with many thousands of new housing units clustered in three areas: north of Portland State University (between I-405, SW Broadway, and SW Taylor St.); the RiverPlace development along the waterfront under the Marquam (I-5) bridge; and most notably in the Pearl District (between I-405, Burnside St., NW Northrup St., and NW 9th Ave.).

Historically, environmental consciousness has weighed significantly in the city's planning and development efforts. Portland was one of the first cities in the United States to promote and integrate alternative forms of transportation, such as the MAX Light Rail and extensive bike paths.<ref name=topgreen/ The Urban Greenspaces Institute, housed in Portland State University Geography Department's Center for Mapping Research, promotes better integration of the built and natural environments. The institute works on urban park, trail, and natural areas planning issues, both at the local and regional levels. In October 2009, the Portland City Council unanimously adopted a climate action plan that will cut the city's greenhouse gas emissions to 80% below 1990 levels by 2050. The city's longstanding efforts were recognized in a 2010 Reuters report, which named Portland the second-most environmentally conscious or "green" city in the world after Reykjavik, Iceland.

As of 2012, Portland was the largest city in the United States that did not add fluoride to its public water supply, and fluoridation has historically been a subject of controversy in the city. Portland voters have four times voted against fluoridation, in 1956, 1962, 1980 (repealing a 1978 vote in favor), and 2013. In 2012 the city council, responding to advocacy from public health organizations and others, voted unanimously to begin fluoridation by 2014. Fluoridation opponents forced a public vote on the issue, and on May 21, 2013, city voters again rejected fluoridation.

Strong free speech protections of the Oregon Constitution upheld by the Oregon Supreme Court in "State v. Henry", specifically found that full nudity and lap dances in strip clubs are protected speech. Portland has the highest number of strip clubs per-capita in a city in the United States, and Oregon ranks as the highest state for per-capita strip clubs. In addition to its strip clubs and erotic massage parlors, the city also has a high rate of child sex trafficking.

In November 2008, a Multnomah County judge dismissed charges against a nude bicyclist arrested on June 26, 2008. The judge stated that the city's annual World Naked Bike Rideheld each year in June since 2004has created a "well-established tradition" in Portland where cyclists may ride naked as a form of protest against cars and fossil fuel dependence. The defendant was not riding in the official World Naked Bike Ride at the time of his arrest as it had occurred 12 days earlier that year, on June 14.

A state law prohibiting publicly insulting a person in a way likely to provoke a violent response was tested in Portland and struck down unanimously by the State Supreme Court as violating protected free speech and being overly broad.

According to the Federal Bureau of Investigation's Uniform Crime Report in 2009, Portland ranked 53rd in violent crime out of the top 75 U.S. cities with a population greater than 250,000. The murder rate in Portland in 2013 averaged 2.3 murders per 100,000 people per year, which was lower than the national average. In October 2009, "Forbes" magazine rated Portland as the third safest city in America.

Below is a sortable table containing violent crime data from each Portland neighborhood during the calendar year of 2014.

Six public school districts and many private schools serve Portland. Portland Public Schools is the largest school district, operating 85 public schools. David Douglas High School, in the Powellhurst neighborhood, has the largest enrollment of any public high school in the city. Other high schools include Benson Polytechnic High School, Cleveland High School, Grant High School, Jefferson High School, Madison High School and Roosevelt High School. Established in 1869, Lincoln High School is the city's oldest public education institution, and is one of two of the oldest high schools west of the Mississippi River (after San Francisco's Lowell High School).

Former public schools in the city included Washington High School, which operated from 1906 until 1981, as well as Jackson High School, which also closed the same year.

The area's private schools include The Northwest Academy, Portland Jewish Academy, Rosemary Anderson High School, Portland Adventist Academy, Portland Lutheran School, the Portland Waldorf School, and Trinity Academy.
The city and surrounding metropolitan area is also home to a large number of Roman Catholic-affiliated private schools, including St. Mary's Academy, an all-girls school; De La Salle North Catholic High School; the co-educational Jesuit High School; La Salle High School; and Central Catholic High School, the only archdiocesan high school in the Roman Catholic Archdiocese of Portland.

Portland State University has the second-largest enrollment rate of any university in the state (after Oregon State University), with a student body of nearly 30,000. It has been named among the top fifteen percentile of American universities by The Princeton Review for undergraduate education, and has been internationally recognized for its degrees in Masters of Business Administration and urban planning. The city is also home to the Oregon Health & Science University, as well as Portland Community College.

Notable private universities include the University of Portland, a Roman Catholic university affiliated with the Congregation of Holy Cross; Reed College, a rigorous liberal arts college, ranked by "Forbes" as the 52nd best college in the country; and Lewis & Clark College.

Other institutions of higher learning within the city are:
"The Oregonian" is the only daily general-interest newspaper serving Portland. It also circulates throughout the state and in Clark County, Washington.
Smaller local newspapers, distributed free of charge in newspaper boxes and at venues around the city, include the "Portland Tribune" (general-interest paper published on Tuesdays and Thursdays), "Willamette Week" (general-interest alternative weekly published on Wednesdays), "The Portland Mercury" (another alt-weekly, targeted at younger urban readers published on Thursdays), "The Asian Reporter" (a weekly covering Asian news, both international and local) and The Skanner (a weekly African-American newspaper covering both local and national news).

Portland Indymedia is one of the oldest and largest Independent Media Centers. The "Portland Alliance", a largely anti-authoritarian progressive monthly, is the largest radical print paper in the city. "Just Out", published in Portland twice monthly until the end of 2011, was the region's foremost LGBT publication. A biweekly paper, "Street Roots", is also sold within the city by members of the homeless community.

"The Portland Business Journal", a weekly, covers business-related news, as does "The Daily Journal of Commerce". "Portland Monthly" is a monthly news and culture magazine. "The Bee", over 105 years old, is another neighborhood newspaper serving the inner southeast neighborhoods.

Legacy Health, a non-profit healthcare system in Portland, operates multiple facilities in the city and surrounding suburbs. These include Legacy Emanuel, founded in 1912, in Northeast Portland; and Legacy Good Samaritan, founded in 1875, and in Northwest Portland. Randall's Children's Hospital operates at the Legacy Emanuel Campus. Good Samaritan has centers for breast health, cancer, and stroke, and is home to the Legacy Devers Eye Institute, the Legacy Obesity and Diabetes Institute, the Legacy Diabetes and Endocrinology Center, the Legacy Rehabilitation Clinic of Oregon, and the Linfield-Good Samaritan School of Nursing.

The Catholic-affiliated Providence Health & Services operates Providence Portland Medical Center in the North Tabor neighborhood of the city. Oregon Health & Science University is a university hospital formed in 1974. The Veterans Affairs Medical Center operates next to the Oregon Health & Science University main campus. Adventist Medical Center also serves the city. Shriners Hospital for Children is a small children's hospital established in 1923.

The Portland metropolitan area has transportation services common to major U.S. cities, though Oregon's emphasis on proactive land-use planning and transit-oriented development within the urban growth boundary means commuters have multiple well-developed options. In 2014, "Travel + Leisure" magazine rated Portland as the No. 1 most pedestrian and transit-friendly city in the United States. A 2011 study by Walk Score ranked Portland 12th most walkable of fifty largest U.S. cities.

In 2008, 12.6% of all commutes in Portland were on public transit. TriMet operates most of the region's buses and the MAX (short for Metropolitan Area Express) light rail system, which connects the city and suburbs. The 1986-opened MAX system has expanded to five lines, with the latest being the Orange Line to Milwaukie, in service as of September 2015. WES Commuter Rail opened in February 2009 in Portland's western suburbs, linking Beaverton and Wilsonville.

The city-owned Portland Streetcar serves two routes in the Central City – downtown and adjacent districts. The first line, which opened in 2001 and was extended in 2005–2007, operates from the South Waterfront District through Portland State University and north through the West End of downtown, to shopping areas and dense residential districts north and northwest of downtown. The second line that opened in 2012 added of tracks on the east side of the Willamette River and across the Broadway Bridge to a connection with the original line. The east-side line completed a loop to the tracks on the west side of the river upon completion of the new Tilikum Crossing in 2015, and, in anticipation of that, had been named the Central Loop line in 2012. However, it was renamed the Loop Service, with an A Loop (clockwise) and B Loop (counterclockwise), when it became a complete loop with the opening of the Tilikum Crossing bridge.

Fifth and Sixth avenues within downtown comprise the Portland Transit Mall, two streets devoted primarily to bus and light rail traffic with limited automobile access. Opened in 1977 for buses, the transit mall was renovated and rebuilt in 2007–09, with light rail added. Starting in 1975 and lasting nearly four decades, all transit service within downtown Portland was free, the area being known by TriMet as Fareless Square, but a need for minor budget cuts and funding needed for expansion prompted the agency to limit free rides to rail service only in 2010, and subsequently to discontinue the fare-free zone entirely in 2012.

TriMet provides real-time tracking of buses and trains with its TransitTracker, and makes the data available to software developers so they can create customized tools of their own.
I-5 connects Portland with the Willamette Valley, Southern Oregon, and California to the south and with Washington to the north. I-405 forms a loop with I-5 around the central downtown area of the city and I-205 is a loop freeway route on the east side which connects to the Portland International Airport. U.S. 26 supports commuting within the metro area and continues to the Pacific Ocean westward and Mount Hood and Central Oregon eastward. U.S. 30 has a main, bypass, and business route through the city extending to Astoria to the west; through Gresham, Oregon, and the eastern exurbs, and connects to I-84, traveling towards Boise, Idaho. Portland ranks 13th in traffic congestion of all American cities, and is 16th among all North American cities.

Portland's main airport is Portland International Airport, about 20 minutes by car (40 minutes by MAX) northeast of downtown. Portland is also home to Oregon's only public use heliport, the Portland Downtown Heliport.
Amtrak, the national passenger rail system, provides service to Portland at Union Station on three routes. Long-haul train routes include the "Coast Starlight" (with service from Los Angeles to Seattle) and the "Empire Builder" (with service from Seattle/Portland to Chicago.) The "Amtrak Cascades" state-supported trains operate between Vancouver and Eugene, Oregon, and serve Portland several times daily. The city is also served by Greyhound Lines intercity bus service which operates BoltBus an express bus service. The bus depot is about one block from the Portland Union Station. The city's first airport was the Swan Island Municipal Airport which was closed in the 1940s.
Portland is the only city in the United States that owns operating mainline steam locomotives, donated to the city in 1958 by the railroads that ran them. Spokane, Portland & Seattle 700 and the world-famous Southern Pacific 4449 can be seen several times a year pulling a special excursion train, either locally or on an extended trip. The "Holiday Express", pulled over the tracks of the Oregon Pacific Railroad on weekends in December, has become a Portland tradition over its several years running. These trains and others are operated by volunteers of the Oregon Rail Heritage Foundation, an amalgamation of rail preservation groups which collaborated on the finance and construction of the Oregon Rail Heritage Center, a permanent and publicly accessible home for the locomotives, which opened in 2012 adjacent to OMSI.

In Portland, cycling is a significant mode of transportation. As the city has been particularly supportive of urban bicycling it now ranks highly among the most bicycle-friendly cities in the world.
Approximately 8% of commuters bike to work, the highest proportion of any major U.S. city and about 10 times the national average. For its achievements in promoting cycling as an everyday means of transportation, Portland has been recognized by the League of American Bicyclists and other cycling organizations for its network of on-street bicycling facilities and other bicycle-friendly services, being one of only three U.S. cities to have earned a Platinum-level rating. A new bicycle-sharing system, Biketown, launched on July 19, 2016, with 100 stations in the city's central and eastside neighborhoods. The bikes were provided by Social Bicycles, and the system is operated by Motivate.

Car sharing through Zipcar, Car2Go, Getaround, and Uhaul Car Share is available to residents of the city and some inner suburbs. Portland has a commuter aerial cableway, the Portland Aerial Tram, which connects the South Waterfront district on the Willamette River to the Oregon Health & Science University campus on Marquam Hill above.

See List of people from Portland, Oregon

Portland has ten sister cities and one "friendship city" (Utrecht); each city is required to maintain long-term involvement and participation:



Portland websites that are also wikis


</doc>
<doc id="23506" url="https://en.wikipedia.org/wiki?curid=23506" title="Pan and scan">
Pan and scan

Pan and scan is a method of adjusting widescreen film images so that they can be shown in fullscreen proportions of a standard definition 4:3 aspect ratio television screen, often cropping off the sides of the original widescreen image to focus on the composition's most important aspects.

Some film directors and enthusiasts disapprove of pan and scan cropping, because it can remove up to 45% of the original image on 2.35:1 films or up to 53% on earlier 2.55:1 presentations, changing the director or cinematographer's original vision and intentions. The most extreme examples remove up to 75% of the original picture on such aspect ratios as 2.75:1 or even 3:1 in epics such as "Ben-Hur", "King of Kings" or "Lawrence of Arabia".

The vertical equivalent is known as "tilt and scan" or "reverse pan and scan". The method was most common in the days of VHS, before widescreen home media such as DVD and Blu-ray.

Center cut is similar with the difference as the name suggests that it is simply a direct cut of the material from the center of the image with no horizontal panning or vertical tilting involved. This method doesn't require the permission or availability of the film maker or director to identify the most important part of each frame. Most video displays have three options for 16:9 widescreen frame formatting, which are either center cut, letterbox or full frame. The first two options are reliant on the video stream's aspect ratio flag being set correctly.

For the first several decades of television broadcasting, sets displayed images with a 4:3 aspect ratio in which the width is 1.33 times the height—similar to most theatrical films prior to 1960. This was fine for pre-1953 films such as "The Wizard of Oz" or "Casablanca". Meanwhile, in order to compete with television and lure audiences away from their sets, producers of theatrical motion pictures began to use "widescreen" formats such as CinemaScope and Todd-AO in the early to mid-1950s, which enable more panoramic vistas and present other compositional opportunities. Films with these formats might be twice as wide as a TV screen when televised. To present a widescreen movie on such a television requires one of two techniques to accommodate this difference: One is "letterboxing", which preserves the original theatrical aspect ratio, but is not as tall as a standard television screen, leaving black bars at the top and bottom of the screen; the other technique is to "pan and scan", filling the full height of the screen, but cropping it horizontally. Pan and scan cuts out as much as half of the image.

In the 1990s (before Blu-ray Disc or HDTV), when so-called televisions offered a wider 16:9 aspect ratio (1.78 times the height instead of 1.33), they allowed films made at 1.66:1 and 1.85:1 to fill most or all of the screen, with only small letterboxing or cropping required. DVD packaging began to use the expression, "16:9 – Enhanced for Widescreen TVs."

However, films shot at aspect ratios of 2.20:1, 2.35:1, 2.39:1, 2.55:1, and especially 2.76:1 ("Ben-Hur" for example) might still be problematic when displayed on televisions of any type. But when the DVD is "anamorphically enhanced for widescreen", or the film is telecast on a high-definition channel seen on a widescreen TV, the black spaces are smaller, and the effect is still much like watching a film on a theatrical wide screen. Though 16:9 (and occasionally 16:10, mostly for computers and tablets) remain standard as of 2018, wider-screen consumer TVs in 21:9 have been released to the market by multiple brands.

During the "pan and scan" process, an editor selects the parts of the original filmed composition that seem to be the focus of the shot and makes sure that these are copied (i.e. "scanned"). When the important action shifts to a new position in the frame, the operator moves the scanner to follow it, creating the effect of a "pan" shot. In a scene in which the focus does not gradually shift from one horizontal position to another—such as actors at each extreme engaging in rapid conversation with each other—the editor may choose to "cut" from one to the other rather than rapidly panning back and forth. If the actors are closer together on the screen, the editor may pan slightly, alternately cropping one or the other partially. This method allows the maximum resolution of the image, since it uses all the available vertical video scan lines—which is especially important for NTSC televisions, having a rather low number of lines available. It also gives a full-screen image on a traditional television set; hence pan-and-scan versions of films on videotape or DVD are often known as "".

However, it also has several drawbacks. Some visual information is necessarily cropped out. It can also change a shot in which the camera was originally stationary to one in which it is frequently panning, or change a single continuous shot into one with frequent cuts. In a shot which was originally panned to show something new, or one in which something enters the shot from off-camera, it changes the timing of these appearances to the audience. As an example, in the film "Oliver!", made in Panavision, the criminal Bill Sikes commits a murder. The murder takes place mostly offscreen, behind a staircase wall, and Oliver is a witness to it. As Sikes steps back from behind the wall, we see Oliver from the back watching him in terror. In the pan-and-scan version of the film, we see Oliver's reaction as the murder is being committed, but not when Sikes steps backward from the wall having done it. Often in a pan and scan telecast, a character will seem to be speaking offscreen, when what has really happened is that the pan and scan technique has cut his image out of the screen.

As television screenings of feature films became more common and more financially important, cinematographers began to work for compositions that would keep the vital information within the "TV safe area" of the frame. For example, the BBC suggested programme makers who were recording in 16:9 frame their shots in a aspect ratio which was then broadcast on analogue services with small black bars at the top and bottom of the picture, while owners of widescreen TV sets receiving digital broadcasts would see the full 16:9 picture (this is known as Shoot and protect).

One modern alternative to pan and scan is to directly adjust the source material. This is very rare: the only known uses are computer-generated features, such as those produced by Pixar and video games such as "BioShock". They call their approach to full-screen versions "reframing": some shots are pan and scan, while others are transferred open matte (a full widescreen image extended with added image above and below). Another method is to keep the camera angle as tight as a pan shot, but move the location of characters, objects, or the camera, so that the subjects fit in the frame. The advent of DVDs and their use of anamorphic presentation, coupled with the increasing popularity of widescreen televisions and computer monitors, have rendered pan and scan less important. Fullscreen versions of films originally produced in widescreen are still available in the United States.

Film makers may also create an original image that includes visual information that extends above and below the widescreen theatrical image; this is called "open matte". This may still be pan-and-scanned, but gives the compositor the freedom to "zoom out" or "uncrop" the image to include not only the full width of the wide-format image, but additional visual content at the top and/or bottom of the screen, not included in the widescreen version. As a general rule (prior to the adoption of DVD), special effects would be done within the theatrical aspect ratio, but not the full-frame thereof; also the expanded image area can include extraneous objects—such as cables, microphone booms, jet vapor trails, or overhead telephone wires—not intended to be included in the frame.

A more unusual use of the technique is present in the 17 original Dragon Ball Z movies, released from 1986 to 1996. The films were displayed in 16:9 during their theatrical release, but this was in fact cut down from 4:3 animation- a choice made so that the VHS releases would be uncropped.

Changes in screen angle (panning) may be necessary to prevent closeups between two speakers where only one person is visible in the pan-and-scan version and both participants seem to speak alternately to persons off camera; this comes at the cost of losing the smoothness of scenes. Inversely, the cropping of a film originally shown in the standard ratio to fit widescreen televisions may cut off foreground or background, such as a tap-dance scene in which much attention is directed appropriately at a dancer's feet. This situation will commonly occur whenever a widescreen TV is set to display full images without stretching (often called the zoom setting) on images with an aspect ratio of 1.78:1 or less. The solution is to pillar box the image by adding black bars on either side of the image, which maintains the full picture height. In Europe, where the PAL TV format offers more resolution to begin with, "pan-and-scan" broadcasts and "pan-and-scan" DVDs of movies originally shown in widescreen are relatively rare, unless it is of programming broadcasts aimed for family viewing times like "A Bug's Life". However, on some channels in some countries (such as the United Kingdom), films with an aspect ratio of more than 1.85:1 are panned and scanned to fit the broadcast 1.78:1 ratio.

Some directors still balk at the use of "pan and scan" because they feel it compromises the directorial vision with which their movies were created. For instance, Sydney Pollack brought a lawsuit against Danish TV after a screening of his 1975 film "Three Days of the Condor" in pan-and-scan in 1991 (The court ruled that the pan scanning conducted by Danish television was a 'mutilation' of the film and a violation of Pollack's droit moral, his legal right as an artist to maintain his reputation by protecting the integrity of his work. Nonetheless, the court ruled in favor of the defendant on a technicality). Steven Spielberg initially refused to release a pan-and-scan version of "Raiders of the Lost Ark" but eventually gave in (although he successfully ordered the letterboxed format for the home video releases of "The Color Purple" and "Always"); Woody Allen refused altogether to release one of "Manhattan", the letterbox version is therefore the only version available on VHS and DVD even though one VHS release includes the typical pan-and-scan disclaimer on the cover. Even the "pan and scan" versions of the widescreen animated shorts from the 1950s were also criticized, as several details, such as the babysitter grabbing the baby out of Tom's hands near the end of "Tot Watchers" and the ant blowing his horn near the end of "Barbecue Brawl", are cropped out, which occasionally airs on TV channels, such as Cartoon Network and Boomerang.




</doc>
<doc id="23508" url="https://en.wikipedia.org/wiki?curid=23508" title="Plymouth">
Plymouth

Plymouth () is a city situated on the south coast of Devon, England, approximately south-west of Exeter and west-south-west of London. Enclosing the city are the mouths of the river Plym and river Tamar, which are naturally incorporated into Plymouth Sound to form a boundary with Cornwall.

Plymouth's early history extends to the Bronze Age, when a first settlement emerged at Mount Batten. This settlement continued as a trading post for the Roman Empire, until it was surpassed by the more prosperous village of Sutton founded in the ninth century, now called Plymouth. In 1620, the Pilgrim Fathers departed Plymouth for the New World and established Plymouth Colony, the second English settlement in what is now the United States of America. During the English Civil War, the town was held by the Parliamentarians and was besieged between 1642 and 1646.

Throughout the Industrial Revolution, Plymouth grew as a commercial shipping port, handling imports and passengers from the Americas, and exporting local minerals (tin, copper, lime, china clay and arsenic). The neighbouring town of Devonport became a strategic Royal Naval shipbuilding and dockyard town. In 1914 three neighbouring independent towns, viz., the county borough of Plymouth, the county borough of Devonport, and the urban district of East Stonehouse were merged to form a single County Borough. The combined town took the name of Plymouth which, in 1928, achieved city status. The city's naval importance later led to its being targeted by the German military and partially destroyed by bombing during World War II, an act known as the Plymouth Blitz. After the war the city centre was completely rebuilt and subsequent expansion led to the incorporation of Plympton and Plymstock along with other outlying suburbs in 1967.

The city is home to () people, making it the 30th-most populous built-up area in the United Kingdom and the second-largest city in the South West, after Bristol. It is governed locally by Plymouth City Council and is represented nationally by three MPs. Plymouth's economy remains strongly influenced by shipbuilding and seafaring including ferry links to Brittany (Roscoff and St Malo) and Spain (Santander), but has tended toward a service-based economy since the 1990s. It has the largest operational naval base in Western Europe, HMNB Devonport, and is home to the University of Plymouth.

Upper Palaeolithic deposits, including bones of Homo sapiens, have been found in local caves, and artefacts dating from the Bronze Age to the Middle Iron Age have been found at Mount Batten, showing that it was one of the main trading ports of the country at that time. An unidentified settlement named "TAMARI OSTIA" (mouth/estuaries of the Tamar) is listed in Ptolemy's "Geographia" and is presumed to be located in the area of the modern city. An ancient promontory fort was located at Rame Head at the mouth of Plymouth Sound with ancient hillforts located at Lyneham Warren to the east , Boringdon Camp and Maristow Camp to the north .

The settlement of Plympton, further up the River Plym than the current Plymouth, was also an early trading port. As the river silted up in the early 11th century, mariners and merchants were forced to settle downriver at the current day Barbican near the river mouth. At the time this village was called Sutton, meaning "south town" in Old English. The name "Plym Mouth", meaning "mouth of the River Plym" was first mentioned in a Pipe Roll of 1211.
The name "Plymouth" first officially replaced Sutton in a charter of King Henry VI in 1440. See Plympton for the derivation of the name "Plym".

During the Hundred Years' War a French attack (1340) burned a manor house and took some prisoners, but failed to get into the town. In 1403 the town was burned by Breton raiders. On 12 November 1439, the English Parliament made Plymouth the first town incorporated. In the late fifteenth century, Plymouth Castle, a "castle quadrate", was constructed close to the area now known as The Barbican; it included four round towers, one at each corner, as featured on the city coat of arms.

The castle served to protect Sutton Pool, which is where the fleet was based in Plymouth prior to the establishment of Plymouth Dockyard. In 1512 an Act of Parliament was passed for further fortifying Plymouth. A series of fortifications were built, including defensive walls at the entrance to Sutton Pool (across which a chain would be extended in time of danger). Defences on St Nicholas Island also date from this time, and a string of six artillery blockhouses were built, including one on Fishers Nose at the south-eastern corner of the Hoe. This location was further strengthened by the building of a fort (later known as Drake's Fort) in 1596; it was the site of the Citadel, established in the 1660s (see below).
During the 16th century, locally produced wool was the major export commodity. Plymouth was the home port for successful maritime traders, among them Sir John Hawkins, who led England's first foray into the Atlantic slave trade, as well as Sir Francis Drake, Mayor of Plymouth in 1581 and 1593. According to legend, Drake insisted on completing his game of bowls on the Hoe before engaging the Spanish Armada in 1588. In 1620 the Pilgrim Fathers set sail for the New World from Plymouth, establishing Plymouth Colony – the second English colony in what is now the United States of America.

During the English Civil War Plymouth sided with the Parliamentarians and was besieged for almost four years by the Royalists. The last major attack by the Royalists was by Sir Richard Grenville leading thousands of soldiers towards Plymouth, but they were defeated by the Plymothians at Freedom Fields Park. The civil war ended as a Parliamentary win, but monarchy was restored by King Charles II in 1660, who imprisoned many of the Parliamentary heroes on Drake's Island. Construction of the Royal Citadel began in 1665, after the Restoration; it was armed with cannon facing both out to sea and into the town, rumoured to be a reminder to residents not to oppose the Crown. Mount Batten tower also dates from around this time.

Throughout the 17th century Plymouth had gradually lost its pre-eminence as a trading port. By the mid-17th century, commodities manufactured elsewhere in England cost too much to transport to Plymouth, and the city had no means of processing sugar or tobacco imports, major products from the colonies. It played a part in the Atlantic slave trade during the early 18th century, although it was relatively small.

In the nearby parish of Stoke Damerel the first dockyard, HMNB Devonport, opened in 1690 on the eastern bank of the River Tamar. Further docks were built here in 1727, 1762 and 1793. The settlement that developed here was called "Dock" or "Plymouth Dock" at the time, and a new town, separate from Plymouth, grew up. In 1712 there were 318 men employed and by 1733 the population had grown to 3,000 people.

Before the latter half of the 18th century, grain, timber and then coal were Plymouth's main imports. During this time the real source of wealth was from the neighbouring town of Plymouth Dock (renamed in 1824 to Devonport) and the major employer in the entire region was the dockyard. The "Three Towns" conurbation of Plymouth, Stonehouse and Devonport enjoyed some prosperity during the late 18th and early 19th century and were enriched by a series of neo-classical urban developments designed by London architect John Foulston. Foulston was important for both Devonport and Plymouth and was responsible for several grand public buildings, many now destroyed, including the Athenaeum, the Theatre Royal and Royal Hotel, and much of Union Street.

Local chemist William Cookworthy established his short-lived Plymouth Porcelain venture in 1768 to exploit the deposits of china clay that he had discovered in Cornwall. He was acquainted with engineer John Smeaton, the builder of the third Eddystone Lighthouse.

The Breakwater in Plymouth Sound was designed by John Rennie in order to protect the fleet moving in and out of Devonport; work started in 1812. Numerous technical difficulties and repeated storm damage meant that it was not completed until 1841, twenty years after Rennie's death. In the 1860s, a ring of Palmerston forts was constructed around the outskirts of Devonport, to protect the dockyard from attack from any direction.

Some of the most significant imports to Plymouth from the Americas and Europe during the latter half of the 19th century included maize, wheat, barley, sugar cane, guano, sodium nitrate and phosphate. Aside from the dockyard in the town of Devonport, industries in Plymouth such as the gasworks, the railways and tramways, and a number of small chemical works had begun to develop in the 19th century, continuing into the 20th century.

During the First World War, Plymouth was the port of entry for many troops from around the Empire. It was developed as a facility for the manufacture of munitions. Although major units of the Royal Navy moved to the safety of Scapa Flow, Devonport was an important base for escort vessels and repairs. Flying boats operated from Mount Batten.

During the Second World War, Devonport was the headquarters of Western Approaches Command until 1941, and Sunderland flying boats were operated by the Royal Australian Air Force. It was an important embarkation point for US troops for D-Day. The city was heavily bombed by the Luftwaffe, in a series of 59 raids known as the Plymouth Blitz. Although the dockyards were the principal targets, much of the city centre and over 3,700 houses were completely destroyed and more than 1,000 civilians lost their lives. This was largely due to Plymouth's status as a major port. Charles Church was hit by incendiary bombs and partially destroyed in 1941 during the Blitz, but has not been demolished. It has been designated as an official permanent monument to the bombing of Plymouth during World War II.

The redevelopment of the city was planned by Sir Patrick Abercrombie in his 1943 "Plan for Plymouth" whilst simultaneously working on the reconstruction plan for London. Between 1951 and 1957 over 1000 homes were completed every year, mostly using innovative prefabricated systems of just three main types/

By 1964 over 20,000 new homes had been built, transforming the dense overcrowded and unsanitary slums of the pre-war city into a low density, dispersed suburbia. Most of the city centre shops had been destroyed and those that remained were cleared to enable a zoned reconstruction according to his plan. In 1962 the modernist high rise of the Civic Centre was constructed, an architecturally significant example of mid-twentieth century civic slab-and-tower set piece. The Plymouth City Council allowed it to fall into disrepair but it was grade II listed in 2010 by English Heritage to prevent its demolition.

Post-war, Devonport Dockyard was kept busy refitting aircraft carriers such as the and, later, nuclear submarines. New light industrial factories were constructed in the newly zoned industrial sector, attracting rapid growth of the urban population. The army had substantially left the city by 1971, after barracks were pulled down in the 1960s. But the city remains home to the 42 Commando of the Royal Marines.

The first record of the existence of a settlement at Plymouth was in the Domesday Book in 1086 as "Sudtone", Saxon for south farm, located at the present-day Barbican. From Saxon times, it was in the hundred of Roborough. In 1254 it gained status as a town and in 1439, became the first town in England to be granted a Charter by Parliament. Between 1439 and 1934, Plymouth had a Mayor. In 1914 the county boroughs of Plymouth and Devonport, and the urban district of East Stonehouse merged to form a single county borough of Plymouth. Collectively they were referred to as "The Three Towns".

In 1919 Nancy Astor was elected the first ever female member of parliament to take office in the British Houses of Parliament for the constituency of Plymouth Sutton. Taking over office from her husband Waldorf Astor, Lady Astor was a vibrantly active campaigner for her resident constituents. Plymouth was granted city status on 18 October 1928. The city's first Lord Mayor was appointed in 1935 and its boundaries further expanded in 1967 to include the town of Plympton and the parish of Plymstock.

In 1945, Plymouth-born Michael Foot was elected Labour MP for the war-torn constituency of Plymouth Devonport and after serving as Secretary of State for Education and responsible for the 1974 Health and Safety at Work Act, went on to become leader of the Labour party (1980-1983).

The 1971 Local Government White Paper proposed abolishing county boroughs, which would have left Plymouth, a town of 250,000 people, being administered from a council based at the smaller Exeter, on the other side of the county. This led to Plymouth lobbying for the creation of a Tamarside county, to include Plymouth, Torpoint, Saltash, and the rural hinterland. The campaign was not successful, and Plymouth ceased to be a county borough on 1 April 1974 with responsibility for education, social services, highways and libraries transferred to Devon County Council. All powers returned when the city become a unitary authority on 1 April 1998 under recommendations of the Banham Commission.

In the Parliament of the United Kingdom, Plymouth is represented by the three constituencies of Plymouth Moor View, Plymouth Sutton and Devonport and South West Devon and within the European Parliament as South West England. In the 2015 general election all three constituencies returned Conservative MPs, who were Oliver Colvile (for Sutton and Devonport), Gary Streeter (for South West Devon) and Johnny Mercer for Moor View.

The City of Plymouth is divided into 20 wards, 17 of which elect three councillors and the other three electing two councillors, making up a total council of 57. Each year a third of the council is up for election for three consecutive years – there are no elections on the following "fourth" year, which is when County Council elections take place. The total for Plymouth was 188,924 in April 2015. The local election of 7 May 2015 resulted in a political composition of 28 Labour councillors, 26 Conservative and 3 UKIP resulting in a Labour administration. Plymouth City Council is formally twinned with: Brest, France (1963), Gdynia, Poland (1976), Novorossiysk, Russia (1990) San Sebastián, Spain (1990) and Plymouth, United States (2001).

Plymouth was granted the dignity of Lord Mayor by King George V in 1935. The position is elected each year by a group of six councillors. It is traditional that the position of the Lord Mayor alternates between the Conservative Party and the Labour Party annually and that the Lord Mayor chooses the Deputy Lord Mayor. Conservative councillor Dr John Mahony is the incumbent for 2015–16.
The Lord Mayor's official residence is 3 Elliot Terrace, located on the Hoe. Once a home of Waldorf and Nancy Astor, it was given by Lady Astor to the City of Plymouth as an official residence for future Lord Mayors and is also used today for civic hospitality, as lodgings for visiting dignitaries and High Court judges and it is also available to hire for private events. The Civic Centre municipal office building in Armada Way became a listed building in June 2007 because of its quality and period features, but has become the centre of a controversy as the council planned for its demolition estimating that it could cost £40m to refurbish it, resulting in possible job losses.

Plymouth lies between the River Plym to the east and the River Tamar to the west; both rivers flow into the natural harbour of Plymouth Sound. Since 1967, the unitary authority of Plymouth has included the, once independent, towns of Plympton and Plymstock which lie along the east of the River Plym. The River Tamar forms the county boundary between Devon and Cornwall and its estuary forms the Hamoaze on which is sited Devonport Dockyard.

The River Plym, which flows off Dartmoor to the north-east, forms a smaller estuary to the east of the city called Cattewater. Plymouth Sound is protected from the sea by the Plymouth Breakwater, in use since 1814. In the Sound is Drake's Island which is seen from Plymouth Hoe, a flat public area on top of limestone cliffs. The Unitary Authority of Plymouth is . The topography rises from sea level to a height, at Roborough, of about above Ordnance Datum (AOD).

Geologically, Plymouth has a mixture of limestone, Devonian slate, granite and Middle Devonian limestone. Plymouth Sound, Shores and Cliffs is a Site of Special Scientific Interest, because of its geology. The bulk of the city is built upon Upper Devonian slates and shales and the headlands at the entrance to Plymouth Sound are formed of Lower Devonian slates, which can withstand the power of the sea.

A band of Middle Devonian limestone runs west to east from Cremyll to Plymstock including the Hoe. Local limestone may be seen in numerous buildings, walls and pavements throughout Plymouth. To the north and north east of the city is the granite mass of Dartmoor; the granite was mined and exported via Plymouth. Rocks brought down the Tamar from Dartmoor include ores containing tin, copper, tungsten, lead and other minerals. There is evidence that the middle Devonian limestone belt at the south edge of Plymouth and in Plymstock was quarried at West Hoe, Cattedown and Radford.

On 27 April 1944 Sir Patrick Abercrombie's "Plan for Plymouth" to rebuild the bomb-damaged city was published; it called for demolition of the few remaining pre-War buildings in the city centre to make way for their replacement with wide, parallel, modern boulevards aligned east–west linked by a north–south avenue (Armada Way) linking the railway station with the vista of Plymouth Hoe. A peripheral road system connecting the historic Barbican on the east and Union Street to the west determines the principal form of the city centre, even following pedestrianisation of the shopping centre in the late 1980s, and continues to inform the present 'Vision for Plymouth' developed by a team led by Barcelona-based architect David MacKay in 2003 which calls for revivification of the city centre with mixed-use and residential. In suburban areas, post-War prefabs had already begun to appear by 1946, and over 1,000 permanent council houses were built each year from 1951–57 according to the Modernist zoned low-density garden city model advocated by Abercrombie. By 1964 over 20,000 new homes had been built, more than 13,500 of them permanent council homes and 853 built by the Admiralty. Plymouth is home to 28 parks with an average size of . Its largest park is Central Park, with other sizeable green spaces including Victoria Park, Freedom Fields Park, Alexandra Park, Devonport Park and the Hoe.

Along with the rest of South West England, Plymouth has a temperate oceanic climate (Köppen "Cfb") which is generally wetter and milder than the rest of England. This means a wide range of exotic plants can be grown. The annual mean temperature is approximately . Due to the modifying effect of the sea the seasonal range is less than in most other parts of the UK. As a result of this summer highs are lower than points further north in the UK; however, the coldest month of February has mean minimum temperatures as mild as between . Snow is rare, not usually equating to more than a few flakes, but there have been exclusions, namely the European winter storms of 2009-10 which, in early January, covered Plymouth in at least of snow; more on higher ground. Another period of notable snow occurred from 17–19 December 2010 when up to of snow fell through the period – though only would lie at any one time due to melt. Over the 1961–1990 period, annual snowfall accumulation averaged less than per year. July and August are the warmest months with mean daily maxima over .

South West England has a favoured location when the Azores High pressure area extends north-eastwards towards the UK, particularly in summer. Coastal areas have average annual sunshine totals over 1,600 hours.

Rainfall tends to be associated with Atlantic depressions or with convection. The Atlantic depressions are more vigorous in autumn and winter and most of the rain which falls in those seasons in the south-west is from this source. Average annual rainfall is around . November to March have the highest mean wind speeds, with June to August having the lightest winds. The predominant wind direction is from the south-west.

Typically, the warmest day of the year (1971–2000) will achieve a temperature of , although in June 1976 the temperature reached , the site record. On average, 4.25 days of the year will report a maximum temperature of or above. During the winter half of the year, the coldest night will typically fall to although in January 1979 the temperature fell to . Typically, 18.6 nights of the year will register an air frost.

The University of Plymouth enrolls total students as of (largest in the UK out of ). It also employs 3,000 staff with an annual income of around £160 million. It was founded in 1992 from Polytechnic South West (formerly Plymouth Polytechnic) following the Further and Higher Education Act 1992. It has a wide range of courses including those in marine focused business, marine engineering, marine biology and Earth, ocean and environmental sciences, surf science, shipping and logistics. The university formed a joint venture with the fellow Devonian University of Exeter in 2000, establishing the Peninsula College of Medicine and Dentistry. The college is ranked 8th out of 30 universities in the UK in 2011 for medicine. Its dental school was established in 2006, which also provides free dental care in an attempt to improve access to dental care in the South West.

The University of St Mark & St John (known as "Marjon" or "Marjons") specialises in teacher training, and offers training across the country and abroad.

The city is also home to two large colleges. The City College Plymouth provides courses from the most basic to Foundation degrees for approximately 26,000 students. Plymouth College of Art offers a selection of courses including media. It was started 153 years ago and is now one of only four independent colleges of art and design in the UK.

Plymouth also has 71 state primary phase schools, 13 state secondary schools, eight special schools and three selective state grammar schools, Devonport High School for Girls, Devonport High School for Boys and Plymouth High School for Girls. There is also an independent school Plymouth College.

The city was also home to the Royal Naval Engineering College; opened in 1880 in Keyham, it trained engineering students for five years before they completed the remaining two years of the course at Greenwich. The college closed in 1910, but in 1940 a new college opened at Manadon. This was renamed "Dockyard Technical College" in 1959 before finally closing in 1994; training was transferred to the University of Southampton.

Plymouth is home to the Marine Biological Association of the United Kingdom (MBA; founded 1884) which conducts research in all areas of the marine sciences. The Plymouth Marine Laboratory (PML; founded 1988) was formed in part from components of the MBA. Together with the National Marine Aquarium, the Sir Alister Hardy Foundation for Ocean Sciences, Plymouth University's Marine Institute and the Diving Diseases Research Centre, these marine-related organisations form the Plymouth Marine Sciences Partnership. The Plymouth Marine Laboratory, which focuses on global issues of climate change and sustainability. It monitors the effects of ocean acidity on corals and shellfish and reports the results to the UK government. It also cultivates algae that could be used to make biofuels or in the treatment of waste water by using technology such as photo-bioreactors. It works alongside the Boots Group to investigate the use of algae in skin care protects, taking advantage of the chemicals they contain that adapt to protect themselves from the sun.

From the 2011 Census, the Office for National Statistics published that Plymouth's unitary authority area population was 256,384; 15,664 more people than that of the last census from 2001, which indicated that Plymouth had a population of 240,720. The Plymouth urban area had a population of 260,203 in 2011 (the urban sprawl which extends outside the authority's boundaries). The city's average household size was 2.3 persons. At the time of the 2011 UK census, the ethnic composition of Plymouth's population was 96.2% White (of 92.9% was White British), with the largest minority ethnic group being Chinese at 0.5%. The white Irish ethnic group saw the largest decline in its share of the population since the 2001 Census (-24%), while the "Other Asian" and Black African had the largest increases (360% and 351% respectively). This excludes the two new ethnic groups added to the 2011 census of Gypsy or Irish Traveller and Arab. The population rose rapidly during the second half of the 19th century, but declined by over 1.6% from 1931 to 1951.

Plymouth's gross value added (a measure of the size of its economy) was 5,169 million GBP in 2013 making up 25% of Devon's GVA. Its GVA per person was £19,943 and compared to the national average of £23,755, was £3,812 lower. Plymouth's unemployment rate was 7.0% in 2014 which was 2.0 points higher than the South West average and 0.8 points higher than the average for Great Britain (England, Wales and Scotland).

A 2014 profile by the National Health Service showed Plymouth had higher than average levels of poverty and deprivation (26.2% of population among the poorest 20.4% nationally). Life expectancy, at 78.3 years for men and 82.1 for women, was the lowest of any region in the South West of England.

Because of its coastal location, the economy of Plymouth has traditionally been , in particular the defence sector with over 12,000 people employed and approximately 7,500 in the armed forces. The Plymouth Gin Distillery has been producing Plymouth Gin since 1793, which was exported around the world by the Royal Navy. During the 1930s, it was the most widely distributed gin and has a controlled term of origin. Since the 1980s, employment in the defence sector has decreased substantially and the public sector is now prominent particularly in administration, health, education, medicine and engineering.

Devonport Dockyard is the UK's only naval base that refits nuclear submarines and the Navy estimates that the Dockyard generates about 10% of Plymouth's income. Plymouth has the largest cluster of marine and maritime businesses in the south west with 270 firms operating within the sector. Other substantial employers include the university with almost 3,000 staff, the national retail chain The Range at their Estover headquarters, as well as the Plymouth Science Park employing 500 people in 50 companies.

Plymouth has a post-war shopping area in the city centre with substantial pedestrianisation. At the west end of the zone inside a grade II listed building is the Pannier Market that was completed in 1959 – "pannier" meaning "basket" from French, so it translates as "basket market". In terms of retail floorspace, Plymouth is ranked in the top five in the South West, and 29th nationally. Plymouth was one of the first ten British cities to trial the new Business Improvement District initiative. The Tinside Pool is situated at the foot of the Hoe and became a grade II listed building in 1998 before being restored to its 1930s look for £3.4 million.

Since 2003, Plymouth Council has been undertaking a project of urban redevelopment called the "Vision for Plymouth" launched by the architect David Mackay and backed by both Plymouth City Council and the Plymouth Chamber of Commerce (PCC). Its projects range from shopping centres, a cruise terminal, a boulevard and to increase the population to 300,000 and build 33,000 dwellings.
In 2004 the old Drake Circus shopping centre and Charles Cross car park were demolished and replaced by the latest Drake Circus Shopping Centre, which opened in October 2006. It received negative feedback before opening when David Mackay said it was already "ten years out of date". In contrast, the Theatre Royal's production and education centre, TR2, which was built on wasteland at Cattedown, was a runner-up for the RIBA Stirling Prize for Architecture in 2003.

There is a project involving the future relocation of Plymouth City Council's headquarters, the civic centre, to the current location of the Bretonside bus station; it would involve both the bus station and civic centre being demolished and a rebuilt together at the location with the land from the civic centre being sold off. Other suggestions include the demolition of the Plymouth Pavilions entertainment arena to create a canal "boulevard" linking Millbay to the city centre. Millbay is being regenerated with mixed residential, retail and office space alongside the ferry port.

The A38 dual-carriageway runs from east to west across the north of the city. Within the city it is designated as 'The Parkway' and represents the boundary between the urban parts of the city and the generally more recent suburban areas. Heading east, it connects Plymouth to the M5 motorway about away near Exeter; and heading west it connects Cornwall and Devon via the Tamar Bridge. Regular bus services are provided by Plymouth Citybus, Stagecoach South West and Target Travel. There are three Park and ride services located at Milehouse, Coypool (Plympton) and George Junction (Plymouth City Airport), which are operated by Stagecoach South West.
A regular international ferry service provided by Brittany Ferries operates from Millbay taking cars and foot passengers directly to France (Roscoff) and Spain (Santander) on the three ferries, "MV Armorique", "MV Bretagne" and "MV Pont-Aven". The Cremyll Ferry is a passenger ferry between Stonehouse and the Cornish hamlet of Cremyll, which is believed to have operated continuously since 1204. There is also a pedestrian ferry from the Mayflower Steps to Mount Batten, and an alternative to using the Tamar Bridge via the Torpoint Ferry (vehicle and pedestrian) across the River Tamar.

The city's airport was Plymouth City Airport about north of the city centre.
The airport was home to the local airline Air Southwest,
which operated flights across the United Kingdom and Ireland. In June 2003, a report by the South West RDA was published looking at the future of aviation in the south-west and the possible closure of airports. It concluded that the best option for the south-west was to close Plymouth City Airport and expand Exeter International Airport and Newquay Cornwall Airport, although it did conclude that this was not the best option for Plymouth. In April 2011, it was announced that the airport would close, which it did on 23 December. FlyPlymouth has put forward plans to reopen the city airport by 2018, which would provide daily services to various destinations including London.

Plymouth railway station, which opened in 1877, is managed by Great Western Railway and also sees trains on the CrossCountry network. Smaller stations are served by local trains on the Tamar Valley Line and Cornish Main Line. First Great Western have come under fire recently, due to widespread rail service cuts across the south-west, which affect Plymouth greatly. Three MPs from the three main political parties in the region have lobbied that the train services are vital to its economy.

There is a proposal to reopen the Exeter to Plymouth railway of the LSWR which would connect Cornwall and Plymouth to the rest of the UK railway system on an all weather basis. There are proposals to reopen the line from Tavistock to Bere Alston for a through service to Plymouth. On the night of 4 February 2014, amid high winds and extremely rough seas, part of the sea wall at Dawlish was breached washing away around of the wall and the ballast under the railway immediately behind. The line was closed. Network Rail began repair work and the line reopened on 4 April 2014. In the wake of widespread disruption caused by damage to the mainline track at Dawlish by coastal storms in February 2014, Network Rail are considering reopening the Tavistock to Okehampton and Exeter section of the line as an alternative to the coastal route.

Plymouth is at the southern end of the long Devon Coast to Coast Cycle Route (National Cycle Route 27). The route runs mostly traffic free on off-road sections between Ilfracombe and Plymouth. The route uses former railway lines, though there are some stretches on public roads.

Plymouth has about 150 churches and its Roman Catholic cathedral (1858) is in Stonehouse. The city's oldest church is Plymouth Minster, also known as St Andrew's Church, (Anglican) located at the top of Royal Parade—it is the largest parish church in Devon and has been a site of gathering since AD 800. The city also includes five Baptist churches, over twenty Methodist chapels, and thirteen Roman Catholic churches. In 1831 the first Brethren assembly in England, a movement of conservative non-denominational Evangelical Christians, was established in the city, so that Brethren are often called Plymouth Brethren, although the movement did not begin locally.

Plymouth has the first known reference to Jews in the South West from Sir Francis Drake's voyages in 1577 to 1580, as his log mentioned "Moses the Jew" – a man from Plymouth. The Plymouth Synagogue is a Listed Grade II* building, built in 1762 and is the oldest Ashkenazi Synagogue in the English speaking world. There are also places of worship for Islam, Bahá'í, Buddhism, Unitarianism, Chinese beliefs and Humanism.

58.1% of the population described themselves in the 2011 census return as being at least nominally Christian and 0.8% as Muslim with all other religions represented by less than 0.5% each. The portion of people without a religion is 32.9%; above the national average of 24.7%. 7.1% did not state their religious belief. Since the 2001 Census, the number of Christians and Jews has decreased (-16% and -7% respectively), while all other religions have increased and non-religious people have almost doubled in number.

Built in 1815, Union Street was at the heart of Plymouth's historical culture. It became known as "the servicemen's playground", as it was where sailors from the Royal Navy would seek entertainment of all kinds. During the 1930s, there were 30 pubs and it attracted such performers as Charlie Chaplin to the New Palace Theatre. It is now the late-night hub of Plymouth's entertainment strip, but has a reputation for trouble at closing hours.

Outdoor events and festivals are held including the annual British Firework Championships in August, which attracts tens of thousands of people across the waterfront. In August 2006 the world record for the most amount of simultaneous fireworks was surpassed, by Roy Lowry of the University of Plymouth, over Plymouth Sound. From 2014 MTV Crashes Plymouth has taken place every July on Plymouth Hoe, hosting big-name acts such as The 1975, Little Mix, Tinie Tempah and Busted. Between 1992 and 2012 the Music of the Night celebration was performed in the Royal Citadel by the 29 Commando Regiment and local performers to raise money for local and military charities. A number of other smaller cultural events taken place annually, including Plymouth Art Weekender, Plymouth Fringe Festival and Illuminate Festival.

The city's main theatre is Theatre Royal Plymouth, presenting large-scale West End shows and smaller works as well as an extensive education and outreach programme. The main building is locatedin the city centre and contains three performance spaces - The Lyric (1,315 capacity), Drum Theatre (200 capacity), and The Lab (60 capacity) - and they also run their own specialised production and creative learning centre called TR2, based in Cattedown. Plymouth Pavilions has multiple uses for the city staging music concerts, basketball matches and stand-up comedy. There are also three cinemas: Reel Cinema at Derrys Cross, Plymouth Arts Centre at Looe Street and a Vue cinema at the Barbican Leisure Park. Barbican Theatre, Plymouth delivers a theatre and dance programme of performances and workshops focused on young people and emerging artists contains a main auditorium (110 - 140 capacity) and rehearsal studio; they also host the B-Bar (80 capacity), which offers a programme of music, comedy and spoken word performance. The Plymouth Athenaeum, which includes a local interest library, is a society dedicated to the promotion of learning in the fields of science, technology, literature and art. In 2017 its auditorium (340 capacity) returned to use as a theatre, having been out of service since 2009. The Plymouth City Museum and Art Gallery is operated by Plymouth City Council allowing free admission – it has six galleries.

Plymouth is the regional television centre of BBC South West. A team of journalists are headquartered at Plymouth for the ITV West Country regional station, after a merger with ITV West forced ITV Westcountry to close on 16 February 2009. The main local newspapers serving Plymouth are "The Herald" and "Western Morning News" with Radio Plymouth, BBC Radio Devon, Heart South West, and Pirate FM being the local radio stations with the most listeners.

Plymouth is home to Plymouth Argyle F.C., who play in the third tier of English football league known as Football League One. The team's home ground is called Home Park and is located in Central Park. It links itself with the group of English non-conformists that left Plymouth for the New World in 1620: its nickname is "The Pilgrims". The city also has three Non-League football clubs; Plymouth Parkway who play at Bolitho Park, Elburton Villa who play at Haye Road and Plymstock United who play at Dean Cross. Plymouth Parkway were recently promoted to the Western League from the South West Peninsula League, whilst Elburton Villa and Plymstock United continue to compete in the South West Peninsula League.

Other sports clubs include Plymouth Albion R.F.C. and the Plymouth Raiders basketball club. Plymouth Albion Rugby Football Club is a rugby union club that was founded in 1875 and are currently competing in the third tier of Professional English Rugby. They play at the Brickfields. Plymouth Raiders play in the British Basketball League – the top tier of British basketball. They play at the Plymouth Pavilions entertainment arena and were founded in 1983. Plymouth cricket club was formed in 1843, the current 1st XI play in the Devon Premier League. Plymouth Devils are a speedway team in the British National League. Plymouth was home to an American football club, the Plymouth Admirals until 2010. Plymouth is also home to Plymouth Marjons Hockey Club, with their 1st XI playing in the National League last season.

Plymouth is an important centre for watersports, especially scuba diving and sailing. The Port of Plymouth Regatta is one of the oldest regattas in the world, and has been held regularly since 1823. In September 2011, Plymouth hosted the America's Cup World Series for nine days.

Since 1973 Plymouth has been supplied water by South West Water. Prior to the 1973 take over it was supplied by Plymouth County Borough Corporation. Before the 19th century two leats were built in order to provide drinking water for the town. They carried water from Dartmoor to Plymouth. A watercourse, known as Plymouth or Drake's Leat, was opened on 24 April 1591 to tap the River Meavy. The Devonport Leat was constructed to carry fresh drinking water to the expanding town of Devonport and its ever-growing dockyard. It was fed by three Dartmoor rivers: The West Dart, Cowsic and Blackabrook. It seems to have been carrying water since 1797, but it was officially completed in 1801. It was originally designed to carry water to Devonport town, but has since been shortened and now carries water to Burrator Reservoir, which feeds most of the water supply of Plymouth. Burrator Reservoir is located about north of the city and was constructed in 1898 and expanded in 1928.
Plymouth City Council is responsible for waste management throughout the city and South West Water is responsible for sewerage. Plymouth's electricity is supplied from the National Grid and distributed to Plymouth via Western Power Distribution. On the outskirts of Plympton a combined cycle gas-powered station, the Langage Power Station, which started to produce electricity for Plymouth at the end of 2009.

Her Majesty's Courts Service provide a Magistrates' Court and a Combined Crown and County Court in the city. The Plymouth Borough Police, formed in 1836, eventually became part of Devon and Cornwall Constabulary. There are police stations at Charles Cross and Crownhill (the Divisional HQ) and smaller stations at Plympton and Plymstock. The city has one of the Devon and Cornwall Area Crown Prosecution Service Divisional offices. Plymouth has five fire stations located in Camel's Head, Crownhill, Greenbank, Plympton and Plymstock which is part of Devon and Somerset Fire and Rescue Service. The Royal National Lifeboat Institution have an Atlantic 85 class lifeboat and Severn class lifeboat stationed at Millbay Docks.

Plymouth is served by Plymouth Hospitals NHS Trust and the city's NHS hospital is Derriford Hospital north of the city centre. The Royal Eye Infirmary is located at Derriford Hospital. South Western Ambulance Service NHS Foundation Trust operates in Plymouth and the rest of the south west; its headquarters are in Exeter.

The mid-19th century burial ground at Ford Park Cemetery was reopened in 2007 by a successful trust and the City council operate two large early 20th century cemeteries at Weston Mill and Efford both with crematoria and chapels. There is also a privately owned cemetery on the outskirts of the city, Drake Memorial Park which does not allow headstones to mark graves, but a brass plaque set into the ground.

After the English Civil War the Royal Citadel was erected in 1666 towards the eastern section of Plymouth Hoe, to defend the port from naval attacks, suppress Plymothian Parliamentary leanings and to train the armed forces. Currently, guided tours are available in the summer months. Further west is Smeaton's Tower, which is a standard lighthouse that was constructed in 1759. Furthermore, Smeaton’s Tower was dismantled in 1877 and the top two thirds were reassembled on Plymouth Hoe. It is open to the public and has views over the Plymouth Sound and the city from the lantern room. Plymouth has 20 war memorials of which nine are on The Hoe including: Plymouth Naval Memorial, to remember those killed in World Wars I and II, and the Armada Memorial, to commemorate the defeat of the Spanish Armada.

The early port settlement of Plymouth, called "Sutton", approximates to the area now referred to as the Barbican and has 100 listed buildings and the largest concentration of cobbled streets in Britain. The Pilgrim Fathers left for the New World in 1620 near the commemorative Mayflower Steps in Sutton Pool. Also on Sutton Pool is the National Marine Aquarium which displays 400 marine species and includes Britain's deepest aquarium tank.

On the northern outskirts of the city, Crownhill Fort is a well restored example of a "Palmerston's Folly". It is owned by the Landmark Trust and is open to the public.

To the west of the city is Devonport, one of Plymouth's historic quarters. As part of Devonport's millennium regeneration project, the "Devonport Heritage Trail" has been introduced, complete with over 70 waymarkers outlining the route.

Plymouth is often used as a base by visitors to Dartmoor, the Tamar Valley and the beaches of south-east Cornwall. Kingsand, Cawsand and Whitsand Bay are popular.

The Roland Levinsky building, the landmark building of the University of Plymouth, is located in the city's central quarter. Designed by leading architect Henning Larsen, the building was opened in 2008 and houses the University's Arts faculty. It has been consistently considered one of the UK's most beautiful university buildings.

People from Plymouth are known as Plymothians or less formally as Janners. Its meaning is described as a person from Devon, deriving from Cousin Jan (the Devon form of John), but more particularly in naval circles anyone from the Plymouth area.

The Elizabethan navigator, Sir Francis Drake was born in the nearby town of Tavistock and was the mayor of Plymouth. He was the first Englishman to circumnavigate the world and was known by the Spanish as "El Draco" meaning "The Dragon" after he raided many of their ships. He died of dysentery in 1596 off the coast of Puerto Rico. In 2002 a mission to recover his body and bring it to Plymouth was allowed by the Ministry of Defence. His cousin and contemporary John Hawkins was a Plymouth man. Painter Sir Joshua Reynolds, founder and first president of the Royal Academy was born and educated in nearby Plympton, now part of Plymouth. William Cookworthy born in Kingsbridge set up his successful porcelain business in the city and was a close friend of John Smeaton designer of the Eddystone Lighthouse. On 26 January 1786, Benjamin Robert Haydon, an English painter who specialised in grand historical pictures, was born here. The naturalist Dr William Elford Leach FRS, who did much to pave the way in Britain for Charles Darwin, was born at Hoe Gate in 1791.

Antarctic explorers Robert Falcon Scott and Frank Bickerton both lived in the city. Artists include Beryl Cook whose paintings depict the culture of Plymouth and Robert Lenkiewicz, whose paintings investigated themes of vagrancy, sexual behaviour and suicide, lived in the city from the 1960s until his death in 2002. Illustrator and creator of children's series Mr Benn and King Rollo, David McKee, was born and brought up in South Devon and trained at Plymouth College of Art. Jazz musician John Surman, born in nearby Tavistock, has close connections to the area, evidenced by his 2012 album Saltash Bells. The avant garde prepared guitarist Keith Rowe was born in the city before establishing the jazz free improvisation band AMM in London in 1965 and MIMEO in 1997. The musician and film director Cosmo Jarvis has lived in several towns in South Devon and has filmed videos in and around Plymouth. In addition, actors Sir Donald Sinden and Judi Trott. George Passmore of Turner Prize winning duo Gilbert and George was born in the city, as was Labour politician Michael Foot whose family reside at nearby Trematon Castle.

Notable athletes include swimmer Sharron Davies, diver Tom Daley, dancer Wayne Sleep, and footballer Trevor Francis. Other past residents include composer journalist and newspaper editor William Henry Wills, Ron Goodwin, and journalist Angela Rippon and comedian Dawn French. Canadian politician and legal scholar Chris Axworthy hails from Plymouth. America based actor Donald Moffat, whose roles include American Vice President Lyndon B. Johnson in the film "The Right Stuff", and fictional President Bennett in "Clear and Present Danger", was born in Plymouth.

Cambridge spy Guy Burgess was born at 2 Albemarle Villas, Stoke whilst his father was a serving Royal Navy officer.





</doc>
<doc id="23511" url="https://en.wikipedia.org/wiki?curid=23511" title="Point-to-Point Protocol">
Point-to-Point Protocol

In computer networking, Point-to-Point Protocol (PPP) is a data link layer (layer 2) communications protocol used to establish a direct connection between two nodes. It connects two routers directly without any host or any other networking device in between. It can provide connection authentication, transmission encryption, and compression.

PPP is used over many types of physical networks including serial cable, phone line, trunk line, cellular telephone, specialized radio links, and fiber optic links such as SONET. Internet service providers (ISPs) have used PPP for customer dial-up access to the Internet, since IP packets cannot be transmitted over a modem line on their own, without some data link protocol.

Two derivatives of PPP, Point-to-Point Protocol over Ethernet (PPPoE) and Point-to-Point Protocol over ATM (PPPoA), are used most commonly by ISPs to establish a Digital Subscriber Line (DSL) Internet service connection with customers.

PPP is commonly used as a data link layer protocol for connection over synchronous and asynchronous circuits, where it has largely superseded the older Serial Line Internet Protocol (SLIP) and telephone company mandated standards (such as Link Access Protocol, Balanced (LAPB) in the X.25 protocol suite). The only requirement for PPP is that the circuit provided be duplex. PPP was designed to work with numerous network layer protocols, including Internet Protocol (IP), TRILL, Novell's Internetwork Packet Exchange (IPX), NBF, DECnet and AppleTalk. Like SLIP, this is a full Internet connection over telephone lines via modem. It is more reliable than SLIP because it double checks to make sure that Internet packets arrive intact. It resends any damaged packets.

PPP was designed somewhat after the original HDLC specifications. The designers of PPP included many additional features that had been seen only in proprietary data-link protocols up to that time. PPP is specified in RFC 1661.

RFC 2516 describes Point-to-Point Protocol over Ethernet (PPPoE) as a method for transmitting PPP over Ethernet that is sometimes used with DSL. RFC 2364 describes Point-to-Point Protocol over ATM (PPPoA) as a method for transmitting PPP over ATM Adaptation Layer 5 (AAL5), which is also a common alternative to PPPoE used with DSL.

PPP is a layered protocol that has three components:

LCP initiates and terminates connections gracefully, allowing hosts to negotiate connection options. It is an integral part of PPP, and is defined in the same standard specification. LCP provides automatic configuration of the interfaces at each end (such as setting datagram size, escaped characters, and magic numbers) and for selecting optional authentication. The LCP protocol runs on top of PPP (with PPP protocol number 0xC021) and therefore a basic PPP connection has to be established before LCP is able to configure it.

RFC 1994 describes Challenge-Handshake Authentication Protocol (CHAP), which is preferred for establishing dial-up connections with ISPs.
Although deprecated, Password Authentication Protocol (PAP) is still sometimes used.

Another option for authentication over PPP is Extensible Authentication Protocol (EAP) described in RFC 2284.

After the link has been established, additional network (layer 3) configuration may take place. Most commonly, the Internet Protocol Control Protocol (IPCP) is used, although Internetwork Packet Exchange Control Protocol (IPXCP) and AppleTalk Control Protocol (ATCP) were once popular. Internet Protocol Version 6 Control Protocol (IPv6CP) will see extended use in the future, when IPv6 replaces IPv4 as the dominant layer-3 protocol.

PPP permits multiple network layer protocols to operate on the same communication link. For every network layer protocol used, a separate Network Control Protocol (NCP) is provided in order to encapsulate and negotiate options for the multiple network layer protocols. It negotiates network-layer information, e.g. network address or compression options, after the connection has been established.

For example, Internet Protocol (IP) uses the IP Control Protocol (IPCP), and Internetwork Packet Exchange (IPX) uses the Novell IPX Control Protocol (IPX/SPX). NCPs include fields containing standardized codes to indicate the network layer protocol type that the PPP connection encapsulates.

The following NCPs may be used with PPP:

PPP detects looped links using a feature involving magic numbers. When the node sends PPP LCP messages, these messages may include a magic number. If a line is looped, the node receives an LCP message with its own magic number, instead of getting a message with the peer's magic number.

The previous section introduced the use of LCP options to meet specific WAN connection requirements. PPP may include the following LCP options:

PPP frames are variants of HDLC frames:

If both peers agree to Address field and Control field compression during LCP, then those fields are omitted. Likewise if both peers agree to Protocol field compression, then the 0x00 byte can be omitted.

The Protocol field indicates the type of payload packet: 0xC021 for LCP, 0x80xy for various NCPs, 0x0021 for IP, 0x0029 AppleTalk, 0x002B for IPX, 0x003D for Multilink, 0x003F for NetBIOS, 0x00FD for MPPC and MPPE, etc. PPP is limited, and cannot contain general Layer 3 data, unlike EtherType.

The Information field contains the PPP payload; it has a variable length with a negotiated maximum called the Maximum Transmission Unit. By default, the maximum is 1500 octets. It might be padded on transmission; if the information for a particular protocol can be padded, that protocol must allow information to be distinguished from padding.

PPP frames are encapsulated in a lower-layer protocol that provides framing and may provide other functions such as a checksum to detect transmission errors. PPP on serial links is usually encapsulated in a framing similar to HDLC, described by IETF RFC 1662.
The Flag field is present when PPP with HDLC-like framing is used.

The Address and Control fields always have the value hex FF (for "all stations") and hex 03 (for "unnumbered information"), and can be omitted whenever PPP LCP Address-and-Control-Field-Compression (ACFC) is negotiated.

The frame check sequence (FCS) field is used for determining whether an individual frame has an error. It contains a checksum computed over the frame to provide basic protection against errors in transmission. This is a CRC code similar to the one used for other layer two protocol error protection schemes such as the one used in Ethernet. According to RFC 1662, it can be either 16 bits (2 bytes) or 32 bits (4 bytes) in size (default is 16 bits - Polynomial "x" + "x" + "x" + 1).

The FCS is calculated over the Address, Control, Protocol, Information and Padding fields after the message has been encapsulated.


Multilink PPP (also referred to as MLPPP, MP, MPPP, MLP, or Multilink) provides a method for spreading traffic across multiple distinct PPP connections. It is defined in RFC 1990. It can be used, for example, to connect a home computer to an Internet Service Provider using two traditional 56k modems, or to connect a company through two leased lines.

On a single PPP line frames cannot arrive out of order, but this is possible when the frames are divided among multiple PPP connections. Therefore, Multilink PPP must number the fragments so they can be put in the right order again when they arrive.

Multilink PPP is an example of a link aggregation technology. Cisco IOS Release 11.1 and later supports Multilink PPP. 

With PPP, one cannot establish several simultaneous distinct PPP connections over a single link.

That's not possible with Multilink PPP either. Multilink PPP uses contiguous numbers for all the fragments of a packet, and as a consequence it is not possible to suspend the sending of a sequence of fragments of one packet in order to send another packet. This prevents from running Multilink PPP multiple times on the same links.

Multiclass PPP is a kind of Multilink PPP where each "class" of traffic uses a separate sequence number space and reassembly buffer. Multiclass PPP is defined in RFC 2686

PPTP (Point-to-Point Tunneling Protocol) is a form of PPP between two hosts via GRE using encryption (MPPE) and compression (MPPC).

Many protocols can be used to tunnel data over IP networks. Some of them, like SSL, SSH, or L2TP create virtual network interfaces and give the impression of a direct physical connections between the tunnel endpoints. On a Linux host for example, these interfaces would be called tun0.

As there are only two endpoints on a tunnel, the tunnel is a point-to-point connection and PPP is a natural choice as a data link layer protocol between the virtual network interfaces. PPP can assign IP addresses to these virtual interfaces, and these IP addresses can be used, for example, to route between the networks on both sides of the tunnel.

IPsec in tunneling mode does not create virtual physical interfaces at the end of the tunnel, since the tunnel is handled directly by the TCP/IP stack. L2TP can be used to provide these interfaces, this technique is called L2TP/IPsec. In this case too, PPP provides IP addresses to the extremities of the tunnel.


PPP is defined in RFC 1661 (The Point-to-Point Protocol, July 1994). RFC 1547 (Requirements for an Internet Standard Point-to-Point Protocol, December 1993) provides historical information about the need for PPP and its development. A series of related RFCs have been written to define how a variety of network control protocols-including TCP/IP, DECnet, AppleTalk, IPX, and others-work with PPP.



</doc>
<doc id="23512" url="https://en.wikipedia.org/wiki?curid=23512" title="Patterson–Gimlin film">
Patterson–Gimlin film

The Patterson–Gimlin film (also known as the Patterson film or the PGF) is an American short motion picture of an unidentified subject which the filmmakers have said was a Bigfoot. The footage was shot in 1967 in Northern California, and has since been subjected to many attempts to authenticate or debunk it.

The footage was filmed alongside Bluff Creek, a tributary of the Klamath River, about 25 logging-road miles northwest of Orleans, California, in Humboldt County. The film site is roughly 38 miles south of Oregon and 18 miles east of the Pacific Ocean. For decades, the exact location of the site was lost, primarily because of re-growth of foliage in the streambed after the flood of 1964. It was rediscovered in 2011. It is just south of a north-running segment of the creek informally known as "the bowling alley".

The filmmakers were Roger Patterson (February 14, 1933 – January 15, 1972) and Robert "'Bob" Gimlin (born October 18, 1931). Patterson died of cancer in 1972 and "maintained right to the end that the creature on the film was real". Patterson's friend, Gimlin, has always denied being involved in any part of a hoax with Patterson. Gimlin mostly avoided publicly discussing the subject from at least the early 1970s until about 2005 (except for three appearances), when he began giving interviews and appearing at Bigfoot conferences.

The film is 23.85 feet long (preceded by 76.15 feet of "horseback" footage), has 954 frames, and runs for 59.5 seconds at 16 frames per second. If the film was shot at 18 fps, as Grover Krantz believed, the event lasted 53 seconds. The date was October 20, 1967, according to the filmmakers, although some critics believe it was shot earlier.

Patterson said he became interested in Bigfoot after reading an article about the creature by Ivan T. Sanderson in "True" magazine in December 1959. In 1961 Sanderson published his encyclopedic "Abominable Snowmen: Legend Come to Life," a worldwide survey of accounts of Bigfoot-type creatures, including recent track finds, etc. in the Bluff Creek area, which heightened his interest. Thereafter, Marian Place wrote:

Patterson's book, "Do Abominable Snowmen of America Really Exist?", was self-published in 1966. The book has been characterized as "little more than a collection of newspaper clippings laced together with Patterson's circus-poster style prose". The book, however, contains 20 pages of previously unpublished interviews and letters, 17 drawings by Patterson of the encounters described in the text, 5 hand-drawn maps (rare in subsequent Bigfoot books), and almost 20 photos and illustrations from other sources. It was first reprinted in 1996 by Chris Murphy, and then again re-issued by Murphy in 2005 under the title "The Bigfoot Film Controversy," with 81 pages of additional material by Murphy.

In May/June 1967 Patterson began filming a docudrama or pseudo-documentary about cowboys being led by an old miner and a wise Indian tracker on a hunt for Bigfoot. The storyline called for Patterson, his Indian guide (Gimlin in a wig), and the cowboys to recall in flashbacks the stories of Fred Beck (of the 1924 Ape Canyon incident) and others as they tracked the beast on horseback. For actors and cameraman, Patterson used at least nine volunteer acquaintances, including Gimlin and Bob Heironimus, for three days of shooting, perhaps over the Memorial Day weekend. Lacking a cooperative Bigfoot, Patterson would have needed a costume to represent one, if the time came to shoot such climactic scenes.

Prior to the October 1967 filming, Patterson apparently visited Los Angeles on these occasions:
Merritt soon moved back to Yakima and became Patterson's neighbor, and later his collaborator on his Bigfoot documentary. 

Both Patterson and Gimlin had been rodeo riders and amateur boxers — and local champions in their weight classes. Patterson had played high school football.

In October 1967, Patterson and his friend Gimlin set out for the Six Rivers National Forest in far Northern California. They drove in Gimlin's truck, carrying his provisions and three horses, positioned sideways. Patterson chose the area because of intermittent reports of the creatures in the past, and of their enormous footprints since 1958. (His familiarity with the area and its residents from prior visits may also have been a factor.)

The most recent of these reports was the nearby Blue Creek Mountain track find, which was investigated by journalist John Green, Bigfoot hunter René Dahinden, and archaeologist Don Abbott on and after August 28, 1967. This find was reported to Patterson (via his wife) soon thereafter by Al Hodgson, owner of the Willow Creek Variety Store, a five and dime at the time.

Though Gimlin says he doubted the existence of Sasquatch-like creatures, he agreed to Patterson's insistence that they should not attempt to shoot one.

As their stories went, in the early afternoon of Friday, October 20, 1967, Patterson and Gimlin were riding generally northeast (upstream) on horseback along the east bank of Bluff Creek. At sometime between 1:15 and 1:40 PM they "came to an overturned tree with a large root system at a turn in the creek, almost as high as a room". When they rounded it, "there was a logjam—a 'crow's nest'—left over from the flood of '64," and then they spotted the figure behind it nearly simultaneously. It was either "crouching beside the creek to their left" or "standing" there, on the opposite bank. Gimlin later described himself as in a mild state of shock after first seeing the figure.

Patterson initially estimated its height at six and one-half to seven feet, and later raised his estimate to about seven and one-half feet. Some later analysts, anthropologist Grover Krantz among them, have suggested Patterson's later estimate was about one foot too tall. Gimlin's estimate was six feet even.

The film shows what Patterson and Gimlin claimed was a large, hairy, bipedal, apelike figure with short, "silvery brown" or "dark reddish-brown" or "black" hair covering most of its body, including its prominent breasts. The figure in the Patterson–Gimlin film generally matches the descriptions of Bigfoot offered by others who claim to have seen one.

Patterson estimated he was about 25 ft (7.6 m) away from the creature at his closest. Patterson said that his horse reared upon sensing the figure, and he spent about 20 seconds extricating himself from the saddle, controlling his horse, getting around to its other side, and getting his camera from a saddlebag before he could run toward the figure while operating his camera. He yelled "Cover me" to Gimlin, "meaning to get the gun out". Gimlin crossed the creek on horseback after Patterson had run well beyond it, riding on a path somewhat to the left of Patterson's and somewhat beyond his position. Perez estimates he came within 60–90 feet of "Patty". Then, rifle in hand, he dismounted, but did not point his rifle at the creature.

The figure had walked away from them to a distance of about 120 ft (36.5 m) before Patterson began to run after it. The resulting film (about 59.5 seconds long at 16 fps) is initially quite shaky until Patterson got about 80 ft (24.4 m) from the figure. At that point, the figure glanced over its right shoulder at the men and Patterson fell to his knees; on Krantz's map this corresponds to frame 264. To researcher John Green, Patterson would later characterize the creature's expression as one of "contempt and disgust...you know how it is when the umpire tells you 'one more word and you're out of the game.' That's the way it felt."

Shortly after this point the steady, middle portion of the film begins, containing the famous look-back frame 352. Patterson said, "it turned a total of I think three times," the other times therefore being before the filming began and/or while he was running with his finger off the trigger. Shortly after glancing over its shoulder on film, the creature disappeared behind a grove of trees for 14 seconds, then reappeared in the film's final 15 seconds after Patterson moved ten feet to a better vantage point, fading into the trees again and being lost to view at a distance of 265 feet as the reel of film ran out.

Gimlin remounted and followed it on horseback, keeping his distance, until it disappeared around a bend in the road three hundred yards away. Patterson called him back at that point, feeling vulnerable on foot without a rifle, because he feared the creature's mate might approach. The entire encounter had lasted less than two minutes.

Next, Gimlin and Patterson rounded up Patterson's horses, which had run off in the opposite direction, downstream, before the filming began. Patterson got his second roll of film from his saddlebag and filmed the tracks. Then the men tracked "Patty" for either one mile or three miles (5 km), but "lost it in the heavy undergrowth". They went to their campsite three miles south, picked up plaster, returned to the initial site, measured the creature's step-length, and made two plaster casts, one each of the best-quality right and left prints.

According to Patterson and Gimlin, they were the only witnesses to their brief encounter with what they claimed was a Sasquatch. Their statements agree in general, but author Greg Long notes a number of inconsistencies. They offered somewhat different sequences in describing how they and the horses reacted upon seeing the creature. Patterson in particular increased his estimates of the creature's size in subsequent retellings of the encounter. In a different context, Long argues, these discrepancies would probably be considered minor, but given the extraordinary claims made by Patterson and Gimlin, any apparent disagreements in perception or memory are worth noting.

The film's defenders have responded by saying that commercially motivated hoaxers would have "got their stories straight" beforehand so they wouldn't have disagreed immediately upon being interviewed, and on so many points, and so they wouldn't have created a suit and a creature with foreseeably objectionable features and behaviors.

A more serious objection concerns the film's "timeline". This is important because Kodachrome II movie film, as far as is known, could only be developed by a lab containing a $60,000+ machine, and the few West Coast labs known to possess one did not do developing over weekends. Patterson's brother-in-law Al DeAtley claims not to remember where he took the film for development—or even where he picked it up.

Another timeline problem is that critics claim that too much happened between the filming (at 1:15 at the earliest) and the filmmakers' arrival in Willow Creek (at 6:30 at the latest). Daegling wrote, "All of the problems with the timeline disappear if the film is shot a few days or hours beforehand. If that is the case, one has to wonder what other details of this story are wrong." The film's defenders retort that although the time window was tight, it was do-able.

Chris Murphy wrote, "I have confirmed with Bob Gimlin that Patterson definitely rode a small quarter horse (which he owned), not his Welsh pony 'Peanuts'. Also, that Patterson had arranged to borrow a horse by the name of 'Chico' from Bob Heironimus for Gimlin to use... Gimlin did not have a horse that was suitable (old enough) for the expedition." Heironimus stated that Chico (a middle-aged gelding) "wouldn't jump or buck..."

At approximately 6:30 PM, Patterson and Gimlin met up with Al Hodgson at his variety store in Willow Creek, approximately 54.3 miles south by road, about 28.8 miles by Bluff Creek Road from their camp to the 1967 roadhead by Bluff Creek, and 25.5 miles down California State Route 96 to Willow Creek. Patterson intended to drive on to Eureka to ship his film. Either at that time, or when he arrived in the Eureka/Arcata area, he called Al DeAtley (his brother-in-law in Yakima) and told him to expect the film he was shipping. He requested Hodgson to call Donald Abbott, whom Grover Krantz described as "the only scientist of any stature to have demonstrated any serious interest in the [Bigfoot] subject," hoping he would help them search for the creature by bringing a tracking dog. Hodgson called, but Abbott declined. Krantz argued that this call the same day of the encounter is evidence against a hoax, at least on Patterson's part.

After shipping the film, they headed back toward their camp, where they had left their horses. On their way they "stopped at the Lower Trinity Ranger Station, as planned, arriving about 9:00 p.m. Here they met with Syl McCoy [another friend] and Al Hodgson." At this point Patterson called the daily "Times-Standard" newspaper in Eureka and related his story. They arrived back at their campsite at about midnight. At either 5 or 5:30 the next morning, after it started to rain heavily, Gimlin returned to the filmsite from the camp and covered the other prints with bark to protect them. The cardboard boxes he had been given by Al Hodgson for this purpose and had left outside were so soggy they were useless, so he left them.

When he returned to the camp he and Patterson aborted their plan to remain looking for more evidence and departed for home, fearing the rain would wash out their exit. After attempting to go out along "the low road"—Bluff Creek Road—and finding it blocked by a mudslide, they went instead up the steep Onion Mountain Road, off whose shoulder their truck slipped; extracting it required the (unauthorized) borrowing of a nearby front-end loader. The drive home from their campsite covered about 580 miles, the initial 28.8 miles on a low-speed logging road, and then about 110 miles on twisty Route 96. Driving a truck with three horses, and allowing for occasional stops, it would have taken 13 hours to get home Saturday evening, at an average speed of 45 mph; it would have taken 14.5 hours at a 40 mph average speed.

US Forest Service "Timber Management Assistant" Lyle Laverty said, "I [and his team of three, in a Jeep] passed the site on either Thursday the 19th or Friday the 20th" and noticed no tracks. After reading the news of Patterson's encounter on their weekend break, Laverty and his team returned to the site on Monday, the 23rd, and made six photos of the tracks. (Laverty later served as an Assistant Secretary of the Interior under George W. Bush.) Taxidermist and outdoorsman Robert Titmus went to the site with his sister and brother-in-law nine days later. Titmus made plaster casts of ten successive prints of the creature and, as best he could, plotted Patterson's and the creature's movements on a map.

Grover Krantz writes that "Patterson had the film developed as soon as possible. At first he thought he had brought in proof of Bigfoot's existence and really expected the scientists to accept it. But only a few scientists were willing to even look at the film," usually at showings at scientific organizations. These were usually arranged at the behest of zoologist, author, and media figure Ivan Sanderson, a supporter of Patterson's film. Seven showings occurred, in Vancouver, Manhattan, The Bronx, Washington, D.C., Atlanta, and Washington, D.C. again (all by the end of 1968); then, later, in Beaverton, Oregon. Of those who were quoted, most expressed various reservations, although some were willing to say they were intrigued by it.

Christopher Murphy wrote, "Dahinden traveled to Europe [with the film] in 1971. He visited England, Finland, Sweden, Switzerland and Russia. Although scientists in these countries were somewhat more open-minded than those in North America, their findings were basically the same ... A real glimmer of hope, however, emerged [in Russia, where he met Bayanov, Bourtsev, and their associates]."

Though there was little scientific interest in the film, Patterson was still able to capitalize on it. He made a deal with the BBC, allowing the use of his footage in a docudrama made in return for letting him tour with their docudrama, into which he melded material from his own documentary and additional material he and Al DeAtley filmed. This film was shown in local movie houses around the Pacific Northwest and Midwest. A technique commonly used for nature films called "four-walling" was employed, involving heavy local advertising, mostly on TV, of a few days of showings. It was a modest financial success. Al DeAtley estimated that his 50% of the film's profits amounted to $75,000.

The film generated a fair amount of national publicity. Patterson appeared on a few popular TV talk shows to promote the film and belief in Bigfoot by showing excerpts from it: for instance, on the "Joe Pyne Show" in Los Angeles, in 1967, which covered most of the western US; on Merv Griffin's program, with Krantz offering his analysis of the film; on Joey Bishop's talk show, and also on Johnny Carson's "Tonight Show". Articles on the film appeared in "Argosy", "National Wildlife Magazine", and "Reader's Digest".

One radio interview, with Gimlin, by Vancouver-based Jack Webster in November 1967, was partly recorded by John Green and reprinted in Loren Coleman's "Bigfoot!" Patterson also appeared on broadcast interviews on local stations near where his film would be shown during his four-walling tour in 1968.

Patterson subsequently sold overlapping distribution rights for the film to several parties, which resulted in costly legal entanglements.

After Patterson's death, Michael McLeod wrote, "With the consent of Al DeAtley and Patricia Patterson, the film distributor Ron Olson took over the operation of Northwest Research . . . and changed its name to the North American Wildlife Research Association. . . . He worked full-time compiling reports, soliciting volunteers to join the hunt, and organizing several small expeditions. A Bigfoot trap Olson and his crew built still survives . . . . Olson . . . continued to lobby the company [American National Enterprises] to produce a Bigfoot film. . . . In 1974 . . . ANE finally agreed. . . . [It was released in 1975,] titled "Bigfoot: Man or Beast". [H]e devised a storyline involving members of a Bigfoot research party . . . . The film comes to a frightful end when a Bigfoot terrorized the expedition at night. Olson spent several years exhibiting the film around the country. He planned to make millions with the film, but says it lost money." Olson is profiled in Barbara Wasson's "Sasquatch Apparitions".

Joshua Buhs wrote, "During the Thanksgiving holiday of 1974, CBS aired "Mysterious Monsters", a documentary about the Loch Ness Monster and Bigfoot. (It was co-produced by the Smithsonian Institution...) The show attracted sixty million viewers, making it the highest-rated program of the week. Sunn [Classic Films] took the documentary on a four-wall tour ..." This show included footage from the Patterson–Gimlin film. John Green wrote of this show's popularity, "Almost everyone is interested in monsters, only most people don't like to admit it... But let some official organization show an interest in a monster, and the situation reverses. When it has somehow been made respectable, a monster story attracts a tremendous public response."

Patterson's expensive ($369) 16mm camera had been rented on May 13, but he had kept it longer than the contract had stipulated, and an arrest warrant had been issued for him on October 17; he was actually arrested within weeks of his return from Bluff Creek. After Patterson returned the camera in working order, this charge was ultimately dismissed, in 1969.

While Patterson sought publicity, Gimlin was conspicuous by his absence. He only briefly helped to promote the film and avoided discussing his Bigfoot encounter publicly for many subsequent years; he turned down requests for interviews. He later reported that he had avoided publicity after Patterson and promoter Al DeAtley had broken their agreement to pay him a one-third share of any profits generated by the film. Another factor was that his wife objected to publicity.

Daegling wrote, "Bigfoot advocates emphasize that Patterson remained an active Bigfoot hunter up until his death." For instance, in 1969, he hired a pair of brothers to travel around in a truck chasing down leads to Bigfoot witnesses and interviewing them. Later, in December of that year, he was one of those present in Bossburg, Washington, in the aftermath of the cripplefoot tracks found there. Krantz reports that "[a] few years after the film was made, Patterson received a letter from a man ["a US airman stationed in Thailand"] who assured him a Sasquatch was being held in a Buddhist monastery. Patterson spent most of his remaining money preparing an expedition to retrieve this creature" only to learn it was a hoax. He learned this only after having sent Dennis Jenson fruitlessly to Thailand (where he concluded that the airman was "mentally unbalanced") and then, after receiving a second untrue letter from the man, going himself to Thailand with Jenson.

To obtain money to travel to Thailand, "Patterson called Ron, who had returned to ANE, and sold the company the theatrical rights to the clip for what Olson described as a pretty good sum of money."

Patterson died of Hodgkin's lymphoma in 1972. According to Michael McLeod, Greg Long, and Bill Munns, "A few days before Roger died, he told [Bigfoot-book author Peter] Byrne that in retrospect, . . . he [wished he] would have shot the thing and brought out a body instead of a reel of film." According to Grover Krantz and Robert Pyle, years later, Patterson and Gimlin both agreed they should have tried to shoot the creature, both for financial gain and to silence naysayers.

In 1995, almost three decades after the Patterson–Gimlin filming, Greg Long, a technical writer for a technology firm who had a hobby of investigating and writing about Northwest mysteries, started years of interviewing people who knew Patterson, some of whom described him as a liar and a conman. 

Greg Long reports that a 1978 legal "settlement gave Dahinden controlling rights—51 percent of the film footage, 51 percent of video cassette rights, and 100 percent of all 952 frames of the footage. Patty Patterson had 100 percent of all TV rights and 49 percent rights in the film footage. Dahinden had ... bought out Gimlin, who himself had received nothing from Patterson; and Mason and Radford, promised part of the profits by Patterson, had nothing to show for their investment or efforts."

Frame 352, the well-known look-back image, is in the public domain, having long been reprinted by others without protest by the copyright holder.

The whereabouts of the original is unknown, although there are several speculations, mostly online, as to what happened to it. 

At least seven copies were made of the original film

Bill Munns listed four other missing reels of derivative works that would be helpful to film analysts.

The second reel, showing Patterson and Gimlin making and displaying plaster casts of some footprints, was not shown in conjunction with the first reel at Al DeAtley's house, according to those who were there. Chris Murphy wrote, "I believe the screening of this roll at the University of British Columbia on October 26, 1967, was the first and last major screening." It has subsequently been lost. 
A ten-foot strip from that reel, or from a copy of that reel, from which still images were taken by Chris Murphy, still exists, but it too has gone missing.

One factor that complicates discussion of the Patterson film is that Patterson said he normally filmed at 24 frames per second, but in his haste to capture the Bigfoot on film, he did not note the camera's setting. His Cine-Kodak K-100 camera had markings on its continuously variable dial at 16, 24, 32, 48, and 64 frames per second, but no click-stops, and was capable of filming at any frame speed within this range. Grover Krantz wrote, "Patterson clearly told John Green that he found, after the filming, that the camera was set on 18 frames per second (fps) . . . ." It has been suggested that Patterson simply misread "16" as "18".


The Patterson–Gimlin film has seen relatively little interest from mainstream scientists. Statements of scientists who viewed the film at a screening, or who conducted a study, are reprinted in Chris Murphy's "Bigfoot Film Journal". Typical objections include: Neither humans nor chimpanzees have hairy breasts as does the figure in the film, and Napier has noted that a sagittal crest is "only very occasionally seen, to an insignificant extent, in chimpanzees females". Critics have argued these features are evidence against authenticity. Krantz countered the latter point, saying "a sagittal crest ... is a consequence of absolute size alone."

As anthropologist David Daegling writes, "[t]he skeptics have not felt compelled to offer much of a detailed argument against the film; the burden of proof, rightly enough, should lie with the advocates." Yet, without a detailed argument against authenticity, Daegling notes that "the film has not gone away." Similarly, Krantz argues that of the many opinions offered about the Patterson film, "[o]nly a few of these opinions are based on technical expertise and careful study of the film itself."

Regarding the quality of the film, second-generation copies or copies from TV and DVD productions are inferior to first-generation copies. Many early frames are blurry due to camera shake, and the quality of subsequent frames varies for the same reason. Stabilization of the film (e.g., by M.K. Davis) to counter the effect of camera shake has improved viewers' ability to analyze it. Regarding "graininess," Bill Munns writes, "Based on transparencies taken off the camera original, . . . the PGF original is as fine grain as any color 16mm film can achieve." He adds that graininess increases as images are magnified.

Dimitri Bayanov, Igor Bourtsev, and René Dahinden authored "Analysis of the Patterson–Gimlin Film, Why We Find It Authentic". It is a study with sections examining the technical characteristics of the footage, the filming speed, the morphology of the creature, and the specimen's movements. It ended with an assessment and a conclusion favorable to the film subject's reality. The most notable sentences are these: "[Sculptor Nikita Lavinsky argues that] the better a costume from the anatomical point of view, the worse it would be from the viewpoint of biomechanics. A clever costume on a moving hoaxer would "expose, not conceal" a fraud." Later, Bayanov "felt the North American monster enthusiasts did not pursue the [PGF] issues with enough vigor" and more funding from the ISC.

A formal academic study of the Patterson film was conducted by Dmitri Donskoy, Chief of the Dept. of Biomechanics at the USSR Central Institute of Physical Culture, and later associated with Moscow's Darwin Museum.

Donskoy concluded the creature was non-human on the basis of its weight, and especially its gait, which Donskoy judged would be difficult, if not impossible, for a human to replicate. He inferred the film's subject was weighty from the ponderous momentum he observed in the movements of its arms and legs, in the sagging of the knee as weight came onto it, and in the flatness of the foot. Its gait he considered non-artificial because it was confident and unwavering, "neatly expressive," and well-coordinated—and yet non-human because its arm motion and glide resembled a cross-country skier's. Krantz describes Donskoy's conclusion as being that the film depicts "a very massive animal that is definitely not a human being".

Jeff Meldrum wrote, "Animator and computer-generated effects expert Reuben Steindorf, of Vision Realm, created a computer model of 'Patty,' as the film subject has been nicknamed. ... Steindorf reconstructed Patty's skeletal anatomy from the ground up, using 'reverse kinematics.'" Among other findings, "Steindorf confirmed ... that the upper extremity was rather long compared to the lower. This ratio can be expressed as an intermembral index (IM). ... The intermembral index for the film subject was approximately 88. ... An average human IM is 71."

Gordon Strasenburgh authored "The Crested Australopithecus Robustus and the Patterson–Gimlin Film". After an introduction, it reviews four other studies and opinions by scientists on the film, then goes on with the following sections: Testing Hypotheses, Anthropological Attitudes, Alternatives to "A. robustus", The Basic Problem, and Conclusion. The last section begins, "The Patterson–Gimlin film and its analytical results to date are the best data."

Glickman is a Certified Forensic Examiner who "performed intensive computer analysis on the Patterson/Gimlin film over a period of three years". His 43-page study, written in a scientific format, contains 13 pages about the film. He gave estimated measurements of the creature, including a very high weight estimate that few have accepted. He was unable to find evidence of fakery, but noted several indications of authenticity. His conclusions are summed up on one page in two of Christopher Murphy's books. Background information on Glickman's project, sponsored by the North American Science Institute (NASI), can be found in another of Murphy's books.

Anthropologist Grover Krantz was originally skeptical of the Patterson film, based on the still photos in Argosy Magazine, but changed his mind in 1969 after seeing the film because "the realism of the creature's locomotion impressed him." He later offered an in-depth examination of the Patterson film. He concluded that the film depicts a genuine unknown creature. Primarily, Krantz's argument is based on a detailed analysis of the figure's stride, center of gravity, and biomechanics. Krantz argues that the creature's leg and foot motions are quite different from a human's and could not have been duplicated by a person wearing a gorilla suit. Krantz wrote, "the knee is regularly bent more than 90°, while the human leg bends less than 70°." Daniel Perez brought out the implication of this, writing, "The subject['s] ... toes lift off the soil at least ten inches in every walking cycle. ... René Dahinden ... filmed and studied how modern man walks, finding ... a maximum of 2–3 inches of distance between toes and the surface it is walking over . . . ." No human has yet replicated this 10"-high lower leg lift while maintaining the smoothness, posture, and stride length (41") of the creature.

Krantz pointed out the tremendous width of the creature's shoulders, which (after deducting 1" for hair) he estimated at 28.2 inches, or 35.1% of its full standing height of 78", or a higher percentage of its 72" "walking height," which was a bit stooped, crouched, and sunk into the sand. The creature's shoulders are almost 50% wider than the human mean. (For comparison, André the Giant had a typical human ratio of 24%. Wide-shouldered Bob Heironimus (see below) has 27.4%. Only very rarely do humans have a shoulder breadth of 30%.) Krantz argued that a suited person could not mimic this breadth and still have the naturalistic hand and arm motions present on the film.

Krantz and others have noted natural-looking musculature visible as the creature moved, arguing this would be highly difficult or impossible to fake. Hunter and Dahinden also note that "the bottom of the figure's head seems to become part of the heavy back and shoulder muscles... [and] the muscles of the buttocks were distinct."

Jeffrey Meldrum of Idaho State University cites efforts by John Green as important in his own studies of the Patterson film. "It has been obvious to even the casual viewer that the film subject possesses arms that are disproportionately long for its stature." Meldrum writes that "Anthropologists typically express limb proportions as an intermembral index (IM)" and notes that humans have an average IM index of 72, gorillas an average IM index of 117 and chimpanzees an average IM index of 106.

In determining an IM index for the figure in the Patterson film, Meldrum concludes the figure has "an IM index somewhere between 80 and 90, intermediate between humans and African apes. In spite of the imprecision of this preliminary estimate, it is well beyond the mean for humans and effectively rules out a man-in-a-suit explanation for the Patterson–Gimlin film without invoking an elaborate, if not inconceivable, prosthetic contrivance to account for the appropriate positions and actions of wrist and elbow and finger flexion visible on the film. This point deserves further examination and may well rule out the probability of hoaxing."

In his book, Meldrum says, "[Reuben] Steindorf tracked the joint centers through 116 frames of the film, yielding a reliable estimate of the film subject's limb proportions. ... The combination of these proportions with the exceptional breadth dimensions argue[s] compellingly against the simplistic hypothesis of an average man, even one wearing shoulder pads ... or using artificial arm extensions."

However, scientist Esteban Sarmiento (see below) disagrees that the subject has a non-human IMI.

Dr. Scott Lynn, Associate Professor of Kinesiology, California State University, was another scientist who reached a favorable conclusion.

Bernard Heuvelmans—a zoologist and the so-called "father of cryptozoology"—thought the creature in the Patterson film was a suited human. He objected to the film subject's hair-flow pattern as being too uniform; to the hair on the breasts as not being like a primate; to its buttocks as being insufficiently separated; and to its too-calm retreat from the pursuing men. However, Brian Regal writes, "The father of cryptozoology, who believed the Patterson film a hoax, hesitated in his original assessment of the film because of Krantz's [favorable] analysis," but nevertheless remained a disbeliever in it.

Anatomist D.W. Grieve of the Royal Free Hospital School of Medicine studied a copy of the film in 1971, and wrote a detailed analysis. He notes, "The possibility of a very clever fake cannot be ruled out on the evidence of the film" but also writes that his analysis hinges largely on the question of filming speed.

Grieve concluded that "the possibility of fakery is ruled out if the speed of the film was 16 or 18 frames per second. In these conditions a normal human being could not duplicate the observed pattern, which would suggest that the Sasquatch must possess a very different locomotor system to that of man." If filmed at the higher speed, Grieve concluded that the creature "walked with a gait pattern very similar in most respects to a man walking at high speed".

Grieve stated, "I can see the muscle masses in the appropriate places... If it is a fake, it is an extremely clever one." Like Krantz, Grieve thought the figure's shoulders were quite broad. Also like Krantz, Grieve thought Patterson's estimate of the figure's height was inaccurate. Grieve concluded the figure in the Patterson film revealed "an estimated standing height for the subject of not more than ". He notes that a tall human is consistent with the figure's height but also notes that for a tall human "[t]he shoulder breadth however would be difficult to achieve without giving an unnatural appearance to the arm swing and shoulder contours."

Grieve notes that his "subjective impressions have oscillated between total acceptance of the Sasquatch based on the grounds that the film would be difficult to fake, to one of irrational rejection based on an emotional response to the possibility that the Sasquatch actually exists. This seems worth stating because others have reacted similarly to the film."

Krantz claimed Grieve made errors in his measurements and reference points. Canadian Bigfoot research John Green also criticized Grieve's measurements and his reasoning.

Prominent primate expert John Napier (one-time director of the Smithsonian's Primate Biology Program) was one of the few mainstream scientists not only to critique the Patterson–Gimlin film but also to study then-available Bigfoot evidence in a generally sympathetic manner, in his 1973 book, "Bigfoot: The Sasquatch and Yeti in Myth and Reality".

Napier conceded the likelihood of Bigfoot as a real creature, stating, "I am convinced that Sasquatch exists." But he argued against the film being genuine: "There is little doubt that the scientific evidence taken collectively points to a hoax of some kind. The creature shown in the film does not stand up well to functional analysis." Napier gives several reasons for his and other's skepticism that are commonly raised, but apparently his main reasons are original with him. First, the length of "the footprints are totally at variance with its calculated height". Second, the footprints are of the "hourglass" type, which he is suspicious of. (In response, Barbara Wasson criticized Napier's logic at length.)

He adds, "I could not see the zipper; and I still can't. There I think we must leave the matter. Perhaps it was a man dressed up in a monkey-skin; if so it was a brilliantly executed hoax and the unknown perpetrator will take his place with the great hoaxers of the world. Perhaps it was the first film of a new type of hominid, quite unknown to science, in which case Roger Patterson deserves to rank with Dubois, the discoverer of "Pithecanthropus erectus", or Raymond Dart of Johannesburg, the man who introduced the world to its immediate human ancestor, "Australopithecus africanus"."

The skeptical views of Grieve and Napier are summarized favorably by Kenneth Wylie (and those of Bayanov and Donskoy negatively) in Appendix A of his 1980 book, "Bigfoot: A Personal Inquiry into a Phenomenon".

Esteban Sarmiento is a specialist in physical anthropology at the American Museum of Natural History. He has 25 years of experience with great apes in the wild. He writes, "I did find some inconsistencies in appearance and behavior that might suggest a fake ... but nothing that conclusively shows that this is the case." His most original criticism is this: "The plantar surface of the feet is decidedly pale, but the palm of the hand seems to be dark. There is no mammal I know of in which the plantar sole differs so drastically in color from the palm." (But see Meldrum, 170–71.) His most controversial statements are these: "The gluteals, although large, fail to show a humanlike cleft (or crack)." "Body proportions: ... In all of the above relative values, bigfoot is well within the human range and differs markedly from any living ape and from the 'australopithecine' fossils." (E.g., the IM index is in the normal human range.) And: "I estimate bigfoot's weight to be between 190 and 240 lbs."

When anthropologists David J. Daegling of the University of Florida and Daniel O. Schmitt examined the film, they concluded it was impossible to conclusively determine if the subject in the film is nonhuman, and additionally argued that flaws in the studies by Krantz and others invalidated their claims. Daegling and Schmitt noted problems of uncertainties in the subject and camera positions, camera movement, poor image quality, and artifacts of the subject. They concluded: "Based on our analysis of gait and problems inherent in estimating subject dimensions, it is our opinion that it is not possible to evaluate the identity of the film subject with any confidence."

Daegling has asserted that the creature's odd walk could be replicated: "Supposed peculiarities of subject speed, stride length, and posture are all reproducible by a human being employing this type of locomotion [a "compliant gait"]."

Daegling notes that in 1967, movie and television special effects were primitive compared to the more sophisticated effects in later decades, and allows that if the Patterson film depicts a man in a suit that "it is not unreasonable to suggest that it is better than some of the tackier monster outfits that got thrown together for television at that time."

Jessica Rose and James Gamble are authors of "the definitive text on human gait", "Human Walking". They operate the Motion and Gait Analysis Lab at Stanford University. They conducted a high-tech human-replication attempt of "Patty's" gait, in cooperation with Jeff Meldrum. Rose was certain their subject had matched Patty's gait, while Gamble was not quite as sure. Meldrum was impressed and acknowledged that "some aspects" of the creature's walk had been replicated, but not all. The narrator said, "even the experts can see the gait test could not replicate all parameters of the gait." It was shown in an episode of the Discovery Channel's "Best Evidence" series.

A computerized visual analysis of the video conducted by Cliff Crook, who once devoted rooms to sasquatch memorabilia in his home in Bothell, Washington, and Chris Murphy, a Canadian Bigfoot buff from Vancouver, British Columbia, was released in January 1999 and exposed an object which appeared to be the suit's zip-fastener. Zooming in on four magnified frames of the 16 mm footage video exposed what appeared to be tracings of a bell-shaped fastener on the creature's waist area, presumably used to hold a person's suit together. Since both Crook and Murphy were previously staunch supporters of the video's authenticity, Associated Press journalist John W. Humbell noted "Longtime enthusiasts smell a deserter."

Developments in computer technology permitted enhancements of the Patterson–Gimlin films to be made. Bigfoot enthusiast M.K. Davis created a version that removes the shakiness of the camera, permitting the creature to be seen from a more stable perspective. Davis has produced a second stabilized version incorporating enlargements of specific elements that he believes are significant.

Krantz also showed the film to Gordon Valient, a researcher for Nike shoes, who he says "made some rather useful observations about some rather unhuman movements he could see".

A first-season episode of "MonsterQuest" focuses on the Bigfoot phenomenon. One pair of scientists, Jurgen Konczak (Director, Human Sensorimotor Control Laboratory, University of Minnesota) and Esteban Sarmiento, attempts and fails to get a mime outfitted with LEDs on his joints to mimic the Patterson Bigfoot's gait. A second pair, Daris Swindler and Owen Caddy, employs digital enhancement and observes facial movements, such as moving eyelids, lips that compress like an upset chimp's, and a mouth that is lower than it appears, due to a false-lip anomaly like that of a chimp's. (Unfortunately, the show's narrator falsely claims, three times, that the original film shot by Patterson was used.) The episode concludes, "the new findings are intriguing but inconclusive, until a body is found."


Bill Munns, retired, was a special effects and make-up artist, cameraman, and film editor. He argues that Universal and Disney were not the most knowledgeable studios to consult with. He says that Fox, MGM, and special effects artist Stuart Freeborn in England, "who had just completed his groundbreaking ape suits for ""," would have been preferable.

Munns started posting his online analysis of the film in 2009 and summarizing it in the online Munns Report. In 2013 he and Jeff Meldrum co-authored three papers in Meldrum's online magazine, "Relict Hominoid Inquiry". In 2014, Munns self-published "When Roger Met Patty", a 488-page book incorporating material from those articles that analyses the film and film subject from various perspectives.

He argues the film depicts a non-human animal, not a man in a fur suit. He proposes a new diagnostic test of authenticity, at the armpit: natural concave skin fold vs. artificial vertical crease. Munns' analysis has been featured in an episode of the History Channel series "MonsterQuest".


The major hoax allegations are summarized and criticized in:


In 2002, Philip Morris, owner of Morris Costumes (a North Carolina-based company offering costumes, props and stage products) claimed that he made a gorilla costume that was used in the Patterson film. Morris says he discussed his role in the hoax "at costume conventions, lectures, [and] magician conventions" in the 1980s, but first addressed the public at large on August 16, 2002, on Charlotte, North Carolina, radio station WBT-AM. His story was also printed in "The Charlotte Observer". Morris claims he was reluctant to expose the hoax earlier for fear of harming his business: giving away a performer's secrets, he said, would be widely regarded as disreputable.

Morris said that he sold an ape suit to Patterson via mail order in 1967, thinking it was going to be used in what Patterson described as a "prank". (Ordinarily the gorilla suits he sold were used for a popular sideshow routine that depicted an attractive woman changing into a gorilla.) After the initial sale, Morris said that Patterson telephoned him asking how to make the "shoulders more massive" and the "arms longer". Morris says he suggested that whoever wore the suit should wear football shoulder pads and hold sticks in his hands within the suit.

As for the creature's walk, Morris said:
The Bigfoot researchers say that no human can walk that way in the film. Oh, yes they can! When you're wearing long clown's feet, you can't place the ball of your foot down first. You have to put your foot down flat. Otherwise, you'll stumble. Another thing, when you put on the gorilla head, you can only turn your head maybe a quarter of the way. And to look behind you, you've got to turn your head and your shoulders and your hips. Plus, the shoulder pads in the suit are in the way of the jaw. That's why the Bigfoot turns and looks the way he does in the film. He has to twist his entire upper body.
Morris' wife and business partner Amy had vouched for her husband and claims to have helped frame the suit. Morris offered no evidence apart from his own testimony to support his account, the most conspicuous shortcoming being the absence of a gorilla suit or documentation that would match the detail evidenced in the film and could have been produced in 1967.

A re-creation of the PGF was undertaken on October 6, 2004, at "Cow Camp," near Rimrock Lake, a location 41 miles west of Yakima. This was six months after the publication of Long's book and 11 months after Long had first contacted Morris. Bigfooter Daniel Perez wrote, ""National Geographic's" [producer] Noel Dockster . . . noted the suit used in the re-creation ... was in no way similar to what was depicted in the P–G film."

Morris wouldn't consent to release the video to National Geographic, the re-creation's sponsor, claiming he hadn't had adequate time to prepare and that the month was in the middle of his busy season. However, he has not attempted to create a suit more to his liking since that time.

Bob Heironimus claims to have been the figure depicted in the Patterson film. Heironimus says he had not previously publicly discussed his role in the hoax because he hoped to be paid eventually and was afraid of being convicted of fraud had he confessed. After speaking with his lawyer he was told that since he had not been paid for his involvement in the hoax, he could not be held accountable.

A month after watching the December 28, 1998, Fox-television special "World's Greatest Hoaxes: Secrets Finally Revealed?", he went public, via a January 30 press release by his lawyer, Barry Woodard, in a Yakima newspaper story. He stated, "I'm telling the truth. I'm tired after thirty-seven years." Five days later, a second newspaper story reported that his "lawyer's office has been inundated with calls from media outlets . . . . 'We're just sort of waiting for the dust to settle,' he said, explaining he and his client are evaluating offers." He also said, "We anticipate that we will be telling the full story to somebody rather quickly."

Heironimus's name was first publicly revealed, and his allegations first publicly detailed, five years later, in Greg Long's book, "The Making of Bigfoot", which includes testimony that corroborates Heironimus' claims: 

Long argues that the suit Morris says he sold to Patterson was the same suit Heironimus claims to have worn in the Patterson film. However, Long quotes Heironimus and Morris describing different ape suits in many respects. Among the notable differences are:



Long speculates that Patterson modified the costume, but only by attaching Morris's loose hands and feet to the costume, and by replacing Morris's mask. However, there's nothing he wrote on "suit" modification. There's no evidence or testimony that Patterson changed the Morris suit to horsehide, or dyed it a darker color, or cut it in half at the waist to agree with Heironimus's description.

Some film proponents say that Heironimus' arms are too short to match that of a Bigfoot and that he was a few inches shorter than the creature on the film (up to 14 inches shorter).

It has also been said that Heironimus was not as bulky as the creature, but film critics claim that a suit could correct for that (and for height). However, Heironimus did not mention there being padding in the torso, either when questioned by Long about the suit or when specifically asked about padding by Rob McConnell in his 2nd "XZone" radio interview, on August 6, 2007.

Polygraph tests regarding their claims have been passed by both Heironimus and Patterson.

After the death of Ray Wallace in 2002, following a request by Loren Coleman to "The Seattle Times" reporter Bob Young to investigate, the family of Wallace went public with claims that he had started the Bigfoot phenomenon with fake footprints (made from a wooden foot-shaped cutout) left in Californian sites in 1958.











</doc>
<doc id="23513" url="https://en.wikipedia.org/wiki?curid=23513" title="Producer">
Producer

Producer or producers may refer to:





</doc>
<doc id="23517" url="https://en.wikipedia.org/wiki?curid=23517" title="List of Polish-language poets">
List of Polish-language poets

List of poets who have written much of their poetry in the Polish language. See also Discussion Page for additional poets not listed here.

There have been four Polish Nobel Prize laureates in literature: Henryk Sienkiewicz, Władysław Reymont, Czesław Miłosz, Wisława Szymborska. The last two have been poets.










</doc>
<doc id="23519" url="https://en.wikipedia.org/wiki?curid=23519" title="Paul Valéry">
Paul Valéry

Ambroise Paul Toussaint Jules Valéry (; 30 October 1871 – 20 July 1945) was a French poet, essayist, and philosopher. In addition to his poetry and fiction (drama and dialogues), his interests included aphorisms on art, history, letters, music, and current events. Valéry was nominated for the Nobel Prize in Literature in 12 different years.

Valéry was born to a Corsican father and Genoese-Istrian mother in Sète, a town on the Mediterranean coast of the Hérault, but he was raised in Montpellier, a larger urban center close by. After a traditional Roman Catholic education, he studied law at university and then resided in Paris for most of the remainder of his life, where he was, for a while, part of the circle of Stéphane Mallarmé.

In 1900, he married Jeannie Gobillard, a friend of Stéphane Mallarmé's family, who was also a niece of the painter Berthe Morisot. The wedding was a double ceremony in which the bride's cousin, Morisot's daughter, Julie Manet, married the painter Ernest Rouart. Valéry and Gobillard had three children: Claude, Agathe and François.

Valéry served as a juror with Florence Meyer Blumenthal in awarding the Prix Blumenthal, a grant given between 1919 and 1954 to young French painters, sculptors, decorators, engravers, writers, and musicians.

Though his earliest publications date from his mid-twenties, Valéry did not become a full-time writer until 1920, when the man for whom he worked as private secretary, a former chief executive of the Havas news agency, Edouard Lebey, died of Parkinson's disease. Until then, Valéry had, briefly, earned his living at the Ministry of War before assuming the relatively flexible post as assistant to the increasingly impaired Lebey, a job he held for some twenty years.

After his election to the Académie française in 1925, Valéry became a tireless public speaker and intellectual figure in French society, touring Europe and giving lectures on cultural and social issues as well as assuming a number of official positions eagerly offered to him by an admiring French nation. He represented France on cultural matters at the League of Nations, and he served on several of its committees, including the sub-committee on Arts and Letters of the Committee on Intellectual Cooperation. The English-language collection "The Outlook for Intelligence" (1989) contains translations of a dozen essays related to these activities. 

In 1931, he founded the Collège International de Cannes, a private institution teaching French language and civilization. The Collège is still operating today, offering professional courses for native speakers (for educational certification, law and business) as well as courses for foreign students.

He gave the keynote address at the 1932 German national celebration of the 100th anniversary of the death of Johann Wolfgang Goethe. This was a fitting choice, as Valéry shared Goethe's fascination with science (specifically, biology and optics).

In addition to his activities as a member of the Académie française, he was also a member of the Academy of Sciences of Lisbon, and of the "Front national des Ecrivains". In 1937, he was appointed chief executive of what later became the University of Nice. He was the inaugural holder of the Chair of Poetics at the Collège de France.

During World War II, the Vichy regime stripped him of some of these jobs and distinctions because of his quiet refusal to collaborate with Vichy and the German occupation, but Valéry continued, throughout these troubled years, to publish and to be active in French cultural life, especially as a member of the Académie française.

Valéry died in Paris in 1945. He is buried in the cemetery of his native town, Sète, the same cemetery celebrated in his famous poem "Le Cimetière marin".

Valéry is best known as a poet, and he is sometimes considered to be the last of the French symbolists. However, he published fewer than a hundred poems, and none of them drew much attention. On the night of 4 October 1892, during a heavy storm, Paul Valéry underwent an existential crisis, an event that made a huge impact on his writing career. Eventually, around 1898, he quit writing altogether, publishing not a word for nearly twenty years. This hiatus was in part due to the death of his mentor, Stéphane Mallarmé. When, in 1917, he finally broke his 'great silence' with the publication of "La Jeune Parque"; he was forty-six years of age.

This obscure, but sublimely musical, masterpiece, of 512 alexandrine lines in rhyming couplets, had taken him four years to complete, and it immediately secured his fame. With "Le Cimetière marin" and "L'Ébauche d'un serpent," it is often considered one of the greatest French poems of the twentieth century.

The title was chosen late in the poem's gestation; it refers to the youngest of the three "Parcae" (the minor Roman deities also called "The Fates"), though for some readers the connection with that mythological figure is tenuous and problematic.

The poem is written in the first person, and is the soliloquy of a young woman contemplating life and death, engagement and withdrawal, love and estrangement, in a setting dominated by the sea, the sky, stars, rocky cliffs, and the rising sun. However, it is also possible to read the poem as an allegory on the way fate moves human affairs or as an attempt to comprehend the horrific violence in Europe at the time of the poem's composition. The poem is not about World War I, but it does try to address the relationships between destruction and beauty, and, in this sense, it resonates with ancient Greek meditations on these matters, especially in the plays of Sophocles and Aeschylus. There are, therefore, evident links with "le Cimetière marin", which is also a seaside meditation on comparably large themes.

Before "la Jeune Parque", Valéry's only publications of note were dialogues, articles, some poems, and a study of Leonardo da Vinci. In 1920 and 1922, he published two slim collections of verses. The first, "Album des vers anciens" (Album of old verses), was a revision of early but beautifully wrought smaller poems, some of which had been published individually before 1900. The second, "Charmes" (from the Latin "carmina", meaning "songs" and also "incantations"), further confirmed his reputation as a major French poet. The collection includes "le Cimetière marin", and many smaller poems with diverse structures. 'Le Cimetière marin' is mentioned or indirectly implied or referred to in at least four of Iris Murdoch's novels, The Unicorn, The Time of the Angels, The Nice and the Good and The Sea, The Sea.

Valéry's technique is quite orthodox in its essentials. His verse rhymes and scans in conventional ways, and it has much in common with the work of Mallarmé. His poem, "Palme", inspired James Merrill's celebrated 1974 poem "Lost in Translation", and his cerebral lyricism also influenced the American poet, Edgar Bowers.

His far more ample prose writings, peppered with many aphorisms and "bons mots", reveal a conservative and skeptical outlook on human nature, verging on the cynical. However, he never said or wrote anything giving aid or comfort to any form of totalitarianism popular during his lifetime.

Raymond Poincaré, Louis de Broglie, André Gide, Henri Bergson, and Albert Einstein all respected Valéry's thinking and became friendly correspondents. Valéry was often asked to write articles on topics not of his choosing; the resulting intellectual journalism was collected in five volumes titled "Variétés".

Valéry's most striking achievement is perhaps his monumental intellectual diary, called the "Cahiers" (Notebooks). Early every morning of his adult life, he contributed something to the "Cahiers", prompting him to write: "Having dedicated those hours to the life of the mind, I thereby earn the right to be stupid for the rest of the day."

The subjects of his "Cahiers" entries often were, surprisingly, reflections on science and mathematics. In fact, arcane topics in these domains appear to have commanded far more of his considered attention than his celebrated poetry. The "Cahiers" also contain the first drafts of many aphorisms he later included in his books. To date, the "Cahiers" have been published in their entirety only as photostatic reproductions, and only since 1980 have they begun to receive scholarly scrutiny. The "Cahiers" have been translated into English in five volumes published by Peter Lang with the title "Cahiers/Notebooks".

In recent decades Valéry's thought has been considered a touchstone in the field of constructivist epistemology, as noted, for instance, by Jean-Louis Le Moigne in his description of constructivist history.

One of three epigraphs in Cormac McCarthy's novel Blood Meridian is from Valéry's Writing at the Yalu River (1895):

"Your ideas are terrifying and your hearts are faint. Your acts of pity and cruelty are absurd, committed with no calm, as if they were irresistible. Finally, you fear blood more and more. Blood and time."

Oscar-winning Japanese director Hayao Miyazaki's 2013 film "The Wind Rises" and the Japanese novel of the same name (on which the film was partially based) take their title from Valéry's verse "Le vent se lève... il faut tenter de vivre !" ("The wind rises… We must try to live!") in the poem "Le Cimetière marin" ("The Graveyard by the Sea"). The same quote is used in the closing sentences of Anthony Burgess's 1962 novel The Wanting Seed.


In English translation:





</doc>
<doc id="23528" url="https://en.wikipedia.org/wiki?curid=23528" title="Pianist">
Pianist

A pianist ( , ) is an individual musician who plays the piano. Since most forms of Western music can make use of the piano, pianists have a wide repertoire and a wide variery of styles to choose from, among them traditional classical music, jazz, blues, and all sorts of popular music, including rock and roll. Most pianists can, to an extent, easily play other keyboard-related instruments such as the synthesizer, harpsichord, celesta, and the organ.

Modern classical pianists dedicate their careers to performing, recording, teaching, researching, and learning new works to expand their repertoire. They generally do not write or transcribe music as pianists did in the 19th century. Some classical pianists might specialize in accompaniment and chamber music, while others (though comparatively few) will perform as full-time soloists.

Mozart could be considered the first "concert pianist" as he performed widely on the piano. Composers Beethoven and Clementi from the classical era were also famed for their playing, as were, from the romantic era, Liszt, Brahms, Chopin, Mendelssohn and Rachmaninoff. From that era, leading performers less known as composers were Clara Schumann and Hans von Bülow. However, as we do not have modern audio recordings of most of these pianists, we rely mainly on written commentary to give us an account of their technique and style.

Jazz pianists almost always perform with other musicians. Their playing is more free than that of classical pianists and they create an air of spontaneity in their performances. They generally do not write down their compositions; improvisation is a significant part of their work. Well known jazz pianists include Art Tatum, Duke Ellington, Thelonious Monk, Oscar Peterson and Bud Powell.

Popular pianists might work as live performers (concert, theatre, etc.), session musicians, arrangers most likely feel at home with synthesizers and other electronic keyboard instruments. Notable popular pianists include Victor Borge who performed as a comedian; Richard Clayderman, who is known for his covers of popular tunes; and singer and entertainer Liberace, who at the height of his fame, was one of the highest paid entertainers in the world.
A single listing of pianists in all genres would be impractical, given the multitude of musicians noted for their performances on the instrument. Below are links to lists of well-known or influential pianists divided by genres:







Many important composers were also virtuoso pianists. The following is an incomplete list of such musicians.




Some people, having received a solid piano training in their youth, decide not to continue their musical careers but choose nonmusical ones. As a result, there are prominent communities of "amateur pianists" all over the world that play at quite a high level and give concerts not to earn money but just for the love of music. The International Piano Competition for Outstanding Amateurs, held annually in Paris, attracts about one thousand listeners each year and is broadcast on French radio.

It is notable that Jon Nakamatsu, the Gold Medal winner of the prestigious Van Cliburn International Piano Competition for professional pianists in Fort Worth, Texas (1997) was at the moment of his victory technically an amateur: he never attended a music conservatory or majored in music, and worked as a high school German teacher at the time; it was only after the competition that he started pursuing a career as a classical pianist.

The German pianist Davide Martello is known for traveling around conflict zones to play his moving piano. Martello has previously been recognised by the European parliament for his “outstanding contribution to European cooperation and the promotion of common values”.



</doc>
<doc id="23529" url="https://en.wikipedia.org/wiki?curid=23529" title="Proverb">
Proverb

A proverb (from ) is a simple and concrete saying, popularly told and repeated, that expresses a truth based on common sense or experience. They are often metaphorical. Proverbs fall into the category of formulaic language and form a folklore genre

Proverbs are often borrowed from similar languages and cultures, and sometimes come down to the present through more than one language. Both the Bible (including, but not limited to the Book of Proverbs) and medieval Latin (aided by the work of Erasmus) have played a considerable role in distributing proverbs across Europe. Mieder has concluded that cultures that treat the Bible as their "major spiritual book contain between three hundred and five hundred proverbs that stem from the Bible". In his list of the 106 most common and widespread proverbs across Europe, Paczolay listed 11 that are from the Bible. However, almost every culture has examples of its own unique proverbs.

Defining a "proverb" is a difficult task. Proverb scholars often quote Archer Taylor's classic "The definition of a proverb is too difficult to repay the undertaking... An incommunicable quality tells us this sentence is proverbial and that one is not. Hence no definition will enable us to identify positively a sentence as proverbial". Another common definition is from Lord John Russell (c. 1850) "A proverb is the wit of one, and the wisdom of many."

More constructively, Mieder has proposed the following definition, "A proverb is a short, generally known sentence of the folk which contains wisdom, truth, morals, and traditional views in a metaphorical, fixed, and memorizable form and which is handed down from generation to generation". Norrick created a table of distinctive features to distinguish proverbs from idioms, cliches, etc. Prahlad distinguishes proverbs from some other, closely related types of sayings, "True proverbs must further be distinguished from other types of proverbial speech, e.g. proverbial phrases, Wellerisms, maxims, quotations, and proverbial comparisons." Based on Persian proverbs, Zolfaghari and Ameri propose the following definition: "A proverb is a short sentence, which is well-known and at times rhythmic, including advice, sage themes and ethnic experiences, comprising simile, metaphor or irony which is well-known among people for its fluent wording, clarity of expression, simplicity, expansiveness and generality and is used either with or without change".

There are many sayings in English that are commonly referred to as "proverbs", such as weather sayings. Alan Dundes, however, rejects including such sayings among truly proverbs: "Are weather proverbs proverbs? I would say emphatically 'No!'" The definition of "proverb" has also changed over the years. For example, the following was labeled "A Yorkshire proverb" in 1883, but would not be categorized as a proverb by most today, "as throng as Throp's wife when she hanged herself with a dish-cloth". The changing of the definition of "proverb" is also noted in Turkish.

In other languages and cultures, the definition of "proverb" also differs from English. In the Chumburung language of Ghana, ""aŋase" are literal proverbs and "akpare" are metaphoric ones". Among the Bini of Nigeria, there are three words that are used to translate "proverb": "ere, ivbe", and "itan". The first relates to historical events, the second relates to current events, and the third was "linguistic ornamentation in formal discourse". Among the Balochi of Pakistan and Afghanistan, there is a word "batal" for ordinary proverbs and "bassīttuks" for "proverbs with background stories".

There are also language communities that combine proverbs and riddles in some sayings, leading some scholars to create the label "proverb riddles".


Proverbs come from a variety of sources. Some are, indeed, the result of people pondering and crafting language, such as some by Confucius, Plato, Baltasar Gracián, etc. Others are taken from such diverse sources as poetry, stories, songs, commercials, advertisements, movies, literature, etc. A number of the well known sayings of Jesus, Shakespeare, and others have become proverbs, though they were original at the time of their creation, and many of these sayings were not seen as proverbs when they were first coined. Many proverbs are also based on stories, often the end of a story. For example, the proverb "Who will bell the cat?" is from the end of a story about the mice planning how to be safe from the cat.

Some authors have created proverbs in their writings, such a J.R.R. Tolkien, and some of these proverbs have made their way into broader society, such as the bumper sticker pictured below. Similarly, C.S. Lewis' created proverb about a lobster in a pot, from the "Chronicles of Narnia", has also gained currency. In cases like this, deliberately created proverbs for fictional societies have become proverbs in real societies. In a fictional story set in a real society, the movie "Forrest Gump" introduced "Life is like a box of chocolates" into broad society. In at least one case, at appears that a proverb deliberately created by one writer has been naively picked up and used by another who assumed it to be an established Chinese proverb, Ford Madox Ford having picked up a proverb from Ernest Bramah, "It would be hypocrisy to seek for the person of the Sacred Emperor in a Low Tea House."

The proverb with "a longer history than any other recorded proverb in the world", going back to "around 1800 BC" is in a Sumerian clay tablet, "The bitch by her acting too hastily brought forth the blind". Though many proverbs are ancient, they were all newly created at some point by somebody. Sometimes it is easy to detect that a proverb is newly coined by a reference to something recent, such as the Haitian proverb "The fish that is being microwaved doesn't fear the lightning". Similarly, there is a recent Maltese proverb, "wil-muturi, ferh u duluri" "Women and motorcycles are joys and griefs"; the proverb is clearly new, but still formed as a traditional style couplet with rhyme. Also, there is a proverb in the Kafa language of Ethiopia that refers to the forced military conscription of the 1980s, "...the one who hid himself lived to have children." A Mongolian proverb also shows evidence of recent origin, "A beggar who sits on gold; Foam rubber piled on edge." A political candidate in Kenya popularised a new proverb in his 1995 campaign, "Chuth ber" "Immediacy is best". "The proverb has since been used in other contexts to prompt quick action." Over 1,400 new English proverbs are said to have been coined and gained currency in the 20th century. This process of creating proverbs is always ongoing, so that possible new proverbs are being created constantly. Those sayings that are adopted and used by an adequate number of people become proverbs in that society.

Interpreting proverbs is often complex, but is best done in a context. Interpreting proverbs from other cultures is much more difficult than interpreting proverbs in one's own culture. Even within English-speaking cultures, there is difference of opinion on how to interpret the proverb "A rolling stone gathers no moss." Some see it as condemning a person that keeps moving, seeing moss as a positive thing, such as profit; others see the proverb as praising people that keep moving and developing, seeing moss as a negative thing, such as negative habits.

Similarly, among Tajik speakers, the proverb "One hand cannot clap" has two significantly different interpretations. Most see the proverb as promoting teamwork. Others understand it to mean that an argument requires two people. In an extreme example, one researcher working in Ghana found that for a single Akan proverb, twelve different interpretations were given. Children will sometimes interpret proverbs in a literal sense, not yet knowing how to understand the conventionalized metaphor. Interpretation of proverbs is also affected by injuries and diseases of the brain, "A hallmark of schizophrenia is impaired proverb interpretation."

Proverbs in various languages are found with a wide variety of grammatical structures. In English, for example, we find the following structures (in addition to others):

However, people will often quote only a fraction of a proverb to invoke an entire proverb, e.g. "All is fair" instead of "All is fair in love and war", and "A rolling stone" for "A rolling stone gathers no moss."

The grammar of proverbs is not always the typical grammar of the spoken language, often elements are moved around, to achieve rhyme or focus.

Another type of grammatical structure in proverbs is a short dialogue:

Because many proverbs are both poetic and traditional, they are often passed down in fixed forms. Though spoken language may change, many proverbs are often preserved in conservative, even archaic, form. In English, for example, "betwixt" is not used by many, but a form of it is still heard (or read) in the proverb "There is many a slip 'twixt the cup and the lip." The conservative form preserves the meter and the rhyme. This conservative nature of proverbs can result in archaic words and grammatical structures being preserved in individual proverbs, as has been documented in Amharic, Greek, Nsenga, and Polish.

In addition, proverbs may still be used in languages which were once more widely known in a society, but are now no longer so widely known. For example, English speakers use some non-English proverbs that are drawn from languages that used to be widely understood by the educated class, e.g. "C'est la vie" from French and "Carpe diem" from Latin. 

Proverbs are often handed down through generations. Therefore, "many proverbs refer to old measurements, obscure professions, outdated weapons, unknown plants, animals, names, and various other traditional matters."
Therefore, it is common that they preserve words that become less common and archaic in broader society. Proverbs in solid form -- such as murals, carvings, and glass -- can be viewed even after the language of their form is no longer widely understood, such as an Anglo-French proverb in a stained glass window in York.

Proverbs are often and easily translated and transferred from one language into another. "There is nothing so uncertain as the derivation of proverbs, the same proverb being often found in all nations, and it is impossible to assign its paternity."

Proverbs are often borrowed across lines of language, religion, and even time. For example, a proverb of the approximate form "No flies enter a mouth that is shut" is currently found in Spain, France, Ethiopia, and many countries in between. It is embraced as a true local proverb in many places and should not be excluded in any collection of proverbs because it is shared by the neighbors. However, though it has gone through multiple languages and millennia, the proverb can be traced back to an ancient Babylonian proverb (Pritchard 1958:146). Another example of a widely spread proverb is "A drowning person clutches at [frogs] foam", found in Peshai of Afghanistan and Orma of Kenya, and presumably places in between.

Proverbs about one hand clapping are common across Asia, from Dari in Afghanistan to Japan. Some studies have been done devoted to the spread of proverbs in certain regions, such as India and her neighbors and Europe. An extreme example of the borrowing and spread of proverbs was the work done to create a corpus of proverbs for Esperanto, where all the proverbs were translated from other languages.

It is often not possible to trace the direction of borrowing a proverb between languages. This is complicated by the fact that the borrowing may have been through plural languages. In some cases, it is possible to make a strong case for discerning the direction of the borrowing based on an artistic form of the proverb in one language, but a prosaic form in another language. For example, in Ethiopia there is a proverb "Of mothers and water, there is none evil." It is found in Amharic, Alaaba language, and Oromo, three languages of Ethiopia:
The Oromo version uses poetic features, such as the initial "ha" in both clauses with the final "-aa" in the same word, and both clauses ending with "-an". Also, both clauses are built with the vowel "a" in the first and last words, but the vowel "i" in the one syllable central word. In contrast, the Amharic and Alaaba versions of the proverb show little evidence of sound-based art.

However, not all languages have proverbs. Proverbs are (nearly) universal across Europe, Asia, and Africa. Some languages in the Pacific have them, such as Maori. Other Pacific languages do not, e.g. "there are no proverbs in Kilivila" of the Trobriand Islands. However, in the New World, there are almost no proverbs: "While proverbs abound in the thousands in most cultures of the world, it remains a riddle why the Native Americans have hardly any proverb tradition at all." Hakamies has examined the matter of whether proverbs are found universally, a universal genre, concluding that they are not. 

Proverbs are used in conversation by adults more than children, partially because adults have learned more proverbs than children. Also, using proverbs well is a skill that is developed over years. Additionally, children have not mastered the patterns of metaphorical expression that are invoked in proverb use. Proverbs, because they are indirect, allow a speaker to disagree or give advice in a way that may be less offensive. Studying actual proverb use in conversation, however, is difficult since the researcher must wait for proverbs to happen. An Ethiopian researcher, Tadesse Jaleta Jirata, made headway in such research by attending and taking notes at events where he knew proverbs were expected to be part of the conversations.

Many authors have used proverbs in their writings, for a very wide variety of literary genres: epics, novels, poems, short stories.

Probably the most famous user of proverbs in novels is J. R. R. Tolkien in his "The Hobbit" and "The Lord of the Rings" series. Herman Melville is noted for creating proverbs in Moby Dick and in his poetry. Also, C. S. Lewis created a dozen proverbs in "The Horse and His Boy", and Mercedes Lackey created dozens for her invented Shin'a'in and Tale'edras cultures; Lackey's proverbs are notable in that they are reminiscent to those of Ancient Asia - e.g. "Just because you feel certain an enemy is lurking behind every bush, it doesn't follow that you are wrong" is like to "Before telling secrets on the road, look in the bushes." These authors are notable for not only using proverbs as integral to the development of the characters and the story line, but also for creating proverbs.

Among medieval literary texts, Geoffrey Chaucer's Troilus and Criseyde plays a special role because Chaucer's usage seems to challenge the truth value of proverbs by exposing their epistemological unreliability. Rabelais used proverbs to write an entire chapter of Gargantua.

The patterns of using proverbs in literature can change over time. A study of "classical Chinese novels" found proverb use as frequently as one proverb every 3,500 words in "Water Margin" ("Sui-hu chuan") and one proverb every 4,000 words in "Wen Jou-hsiang". But modern Chinese novels have fewer proverbs by far.
Proverbs (or portions of them) have been the inspiration for titles of books: "The Bigger they Come" by Erle Stanley Gardner, and "Birds of a Feather" (several books with this title), "Devil in the Details" (multiple books with this title). Sometimes a title alludes to a proverb, but does not actually quote much of it, such as "The Gift Horse's Mouth" by Robert Campbell. Some books or stories have titles that are twisted proverbs, anti-proverbs, such as "No use dying over spilled milk", "When life gives you lululemons," and two books titled "Blessed are the Cheesemakers". The twisted proveb of last title was also used in the Monty Python movie Life of Brian, where a person mishears one of Jesus Christ's beatitudes, "I think it was 'Blessed are the cheesemakers.'"

Some books and stories are built around a proverb. Some of Tolkien's books have been analyzed as having "governing proverbs" where "the acton of a book turns on or fulfills a proverbial saying." Some stories have been written with a proverb overtly as an opening, such as "A stitch in time saves nine" at the beginning of "Kitty's Class Day", one of Louisa May Alcott's "Proverb Stories". Other times, a proverb appears at the end of a story, summing up a moral to the story, frequently found in Aesop's Fables, such as "Heaven helps those who help themselves" from "Hercules and the Wagoner".

Proverbs have also been used strategically by poets. Sometimes proverbs (or portions of them or anti-proverbs) are used for titles, such as "A bird in the bush" by Lord Kennet and his stepson Peter Scott and "The blind leading the blind" by Lisa Mueller. Sometimes, multiple proverbs are important parts of poems, such as Paul Muldoon's "Symposium", which begins "You can lead a horse to water but you can't make it hold its nose to the grindstone and hunt with the hounds. Every dog has a stitch in time..." The Turkish poet Refiki wrote an entire poem by stringing proverbs together, which has been translated into English poetically yielding such verses as "Be watchful and be wary, / But seldom grant a boon; / The man who calls the piper / Will also call the tune."

Because proverbs are familiar and often pointed, they have been used by a number of hip-hop poets. This has been true not only in the USA, birthplace of hip-hop, but also in Nigeria. Since Nigeria is so multilingual, hip-hop poets there use proverbs from various languages, mixing them in as it fits their need, sometimes translating the original. For example,
"They forget say ogbon ju agbaralo
They forget that wisdom is greater than power"

Some authors have bent and twisted proverbs, creating anti-proverbs, for a variety of literary effects. For example, in the Harry Potter novels, J. K. Rowling reshapes a standard English proverb into "It's no good crying over spilt potion" and Dumbledore
advises Harry not to "count your owls before they are delivered". In a slightly different use of reshaping proverbs, in the Aubrey–Maturin series of historical naval novels by Patrick O'Brian, Capt. Jack Aubrey humorously mangles and mis-splices proverbs, such as "Never count the bear's skin before it is hatched" and "There's a good deal to be said for making hay while the iron is hot." Earlier than O'Brian's Aubrey, Beatrice Grimshaw also used repeated splicings of proverbs in the mouth of an eccentric marquis to create a memorable character in "The Sorcerer's Stone", such as "The proof of the pudding sweeps clean" (p. 109) and "A stitch in time is as good as a mile" (p. 97).

Because proverbs are so much a part of the language and culture, authors have sometimes used proverbs in historical fiction effectively, but anachronistically, before the proverb was actually known. For example, the novel "Ramage and the Rebels", by Dudley Pope is set in approximately 1800. Captain Ramage reminds his adversary "You are supposed to know that it is dangerous to change horses in midstream" (p. 259), with another allusion to the same proverb three pages later. However, the proverb about changing horses in midstream is reliably dated to 1864, so the proverb could not have been known or used by a character from that period.

Some authors have used so many proverbs that there have been entire books written cataloging their proverb usage, such as Charles Dickens, Agatha Christie, George Bernard Shaw, Cervantes, and Friedrich Nietzsche.

On the non-fiction side, proverbs have also been used by authors for articles that have no connection to the study of proverbs. Some have been used as the basis for book titles, e.g. "I Shop, Therefore I Am: Compulsive Buying and the Search for Self" by April Lane Benson. Some proverbs been used as the basis for article titles, though often in altered form: "All our eggs in a broken basket: How the Human Terrain System is undermining sustainable military cultural competence" and "Should Rolling Stones Worry About Gathering Moss?", "Between a Rock and a Soft Place". Proverbs have been noted as common in subtitles of articles such as "Discontinued intergenerational transmission of Czech in Texas: 'Hindsight is better than foresight'." Also, the reverse is found with a proverb (complete or partial) as the title, then an explanatory subtitle, "To Change or Not to Change Horses: The World War II Elections". Many authors have cited proverbs as epigrams at the beginning of their articles, e.g. "'If you want to dismantle a hedge, remove one thorn at a time' Somali proverb" in an article on peacemaking in Somalia. An article about research among the Māori used a Māori proverb as a title, then began the article with the Māori form of the proverb as an epigram "Set the overgrown bush alight and the new flax shoots will spring up", followed by three paragraphs about how the proverb served as a metaphor for the research and the present context. A British proverb has even been used as the title for a doctoral dissertation: "Where there is muck there is brass".

Similarly to other forms of literature, proverbs have also been used as important units of language in drama and films. This is true from the days of classical Greek works to old French to Shakespeare, to 19th Century Spanish, to today. The use of proverbs in drama and film today is still found in languages around the world, such as Yorùbá.

A film that makes rich use of proverbs is "Forrest Gump", known for both using and creating proverbs. Other studies of the use of proverbs in film include work by Kevin McKenna on the Russian film "Aleksandr Nevsky", Haase's study of an adaptation of Little Red Riding Hood, Elias Dominguez Barajas on the film "Viva Zapata!", and Aboneh Ashagrie on "The Athlete" (a movie in Amharic about Abebe Bikila).

In the case of "Forrest Gump", the screenplay by Eric Roth had more proverbs than the novel by Winston Groom, but for "The Harder They Come", the reverse is true, where the novel derived from the movie by Michael Thelwell has many more proverbs than the movie.

Éric Rohmer, the French film director, directed a series of films, the "Comedies and Proverbs", where each film was based on a proverb: "The Aviator's Wife", "The Perfect Marriage", "Pauline at the Beach", "Full Moon in Paris" (the film's proverb was invented by Rohmer himself: "The one who has two wives loses his soul, the one who has two houses loses his mind."), "The Green Ray", "Boyfriends and Girlfriends".

Movie titles based on proverbs include "Murder Will Out (1939 film)", "Try, Try Again", and "The Harder They Fall". A twisted anti-proverb was the title for a Three Stooges film, "A Bird in the Head". The title of an award-winning Turkish film, Three Monkeys, also invokes a proverb, though the title does not fully quote it.

They have also been used as the titles of plays: "Baby with the Bathwater" by Christopher Durang, "Dog Eat Dog" by Mary Gallagher, and "The Dog in the Manger" by Charles Hale Hoyt. The use of proverbs as titles for plays is not, of course, limited to English plays: "Il faut qu'une porte soit ouverte ou fermée" (A door must be open or closed) by Paul de Musset. Proverbs have also been used in musical dramas, such as "The Full Monty", which has been shown to use proverbs in clever ways. In "Beauty and the Beast", Gaston plays with three proverbs in sequence, "All roads lead to.../The best things in life are.../All's well that ends with me."

Proverbs are often poetic in and of themselves, making them ideally suited for adapting into songs. Proverbs have been used in music from opera to country to hip-hop. Proverbs have also been used in music in other languages, such as the Akan language the Igede language, and Spanish. 

In English the proverb (or rather the beginning of the proverb, If the shoe fits has been used as a title for three albums and five songs. Other English examples of using proverbs in music include Elvis Presley's "Easy come, easy go", Harold Robe's "Never swap horses when you're crossing a stream", Arthur Gillespie's "Absence makes the heart grow fonder", Bob Dylan's "Like a rolling stone", Cher's "Apples don't fall far from the tree". Lynn Anderson made famous a song full of proverbs, "I never promised you a rose garden" (written by Joe South). In choral music, we find Michael Torke's "Proverbs" for female voice and ensemble. A number of Blues musicians have also used proverbs extensively. The frequent use of proverbs in Country music has led to published studies of proverbs in this genre. The Reggae artist Jahdan Blakkamoore has recorded a piece titled "Proverbs Remix". The opera "Maldobrìe" contains careful use of proverbs. An extreme example of many proverbs used in composing songs is a song consisting almost entirely of proverbs performed by Bruce Springsteen, "My best was never good enough". The Mighty Diamonds recorded a song called simply "Proverbs".

The band Fleet Foxes used the proverb painting Netherlandish Proverbs for the cover of their eponymous album Fleet Foxes.

In addition to proverbs being used in songs themselves, some rock bands have used parts of proverbs as their names, such as the Rolling Stones, Bad Company, The Mothers of Invention, Feast or Famine, Of Mice and Men. There have been at least two groups that called themselves "The Proverbs", and there is a hip-hop performer in South Africa known as "Proverb". In addition, many albums have been named with allusions to proverbs, such as "Spilt milk" (a title used by Jellyfish and also Kristina Train), "The more things change" by Machine Head, "Silk purse" by Linda Ronstadt, "Another day, another dollar" by DJ Scream Roccett, "The blind leading the naked" by Violent Femmes, "What's good for the goose is good for the gander" by Bobby Rush, "Resistance is Futile" by Steve Coleman, "Murder will out" by Fan the Fury. The proverb "Feast or famine" has been used as an album title by Chuck Ragan, Reef the Lost Cauze, Indiginus, and DaVinci. Whitehorse mixed two proverbs for the name of their album "Leave no bridge unburned". The band Splinter Group released an album titled "When in Rome, Eat Lions". The band Downcount used a proverb for the name of their tour, "Come and take it".

From ancient times, people around the world have recorded proverbs in visual form. This has been done in two ways. First, proverbs have been "written" to be displayed, often in a decorative manner, such as on pottery, cross-stitch, murals, kangas (East African women's wraps), quilts, a stained glass window, and graffiti.

Secondly, proverbs have often been visually depicted in a variety of media, including paintings, etchings, and sculpture. Jakob Jordaens painted a plaque with a proverb about drunkenness above a drunk man wearing a crown, titled "The King Drinks". Probably the most famous examples of depicting proverbs are the different versions of the paintings "Netherlandish Proverbs" by the father and son Pieter Bruegel the Elder and Pieter Brueghel the Younger, the proverbial meanings of these paintings being the subject of a 2004 conference, which led to a published volume of studies (Mieder 2004a). The same father and son also painted versions of The Blind Leading the Blind, a Biblical proverb. These and similar paintings inspired another famous painting depicting some proverbs and also idioms (leading to a series of additional paintings), such as "Proverbidioms" by T. E. Breitenbach. Another painting inspired by Bruegel's work is by the Chinese artist, Ah To, who created a painting illustrating 81 Cantonese sayings. Corey Barksdale has produced a book of paintings with specific proverbs and pithy quotations. The British artist Chris Gollon has painted a major work entitled "Big Fish Eat Little Fish", a title echoing Bruegel's painting Big Fishes Eat Little Fishes.

Sometimes well-known proverbs are pictured on objects, without a text actually quoting the proverb, such as the three wise monkeys who remind us "Hear no evil, see no evil, speak no evil". When the proverb is well known, viewers are able to recognize the proverb and understand the image appropriately, but if viewers do not recognize the proverb, much of the effect of the image is lost. For example, there is a Japanese painting in the Bonsai museum in Saitama city that depicted flowers on a dead tree, but only when the curator learned the ancient (and no longer current) proverb "Flowers on a dead tree" did the curator understand the deeper meaning of the painting.

A study of school students found that students remembered proverbs better when there were visual representations of proverbs along with the verbal form of the proverbs.

A bibliography on proverbs in visual form has been prepared by Mieder and Sobieski (1999). Interpreting visual images of proverbs is subjective, but familiarity with the depicted proverb helps.

Some artists have used proverbs and anti-proverbs for titles of their paintings, alluding to a proverb rather than picturing it. For example, Vivienne LeWitt painted a piece titled "If the shoe doesn't fit, must we change the foot?", which shows neither foot nor shoe, but a woman counting her money as she contemplates different options when buying vegetables.

Cartoonists, both editorial and pure humorists, have often used proverbs, sometimes primarily building on the text, sometimes primarily on the situation visually, the best cartoons combining both. Not surprisingly, cartoonists often twist proverbs, such as visually depicting a proverb literally or twisting the text as an anti-proverb. An example with all of these traits is a cartoon showing a waitress delivering two plates with worms on them, telling the customers, "Two early bird specials... here ya go."

The traditional Three wise monkeys were depicted in Bizarro with different labels. Instead of the negative imperatives, the one with ears covered bore the sign "See and speak evil", the one with eyes covered bore the sign "See and hear evil", etc. The caption at the bottom read "The power of positive thinking." Another cartoon showed a customer in a pharmacy telling a pharmacist, "I'll have an ounce of prevention." The comic strip The Argyle Sweater showed an Egyptian archeologist loading a mummy on the roof of a vehicle, refusing the offer of a rope to tie it on, with the caption "A fool and his mummy are soon parted." The comic One Big Happy showed a conversation where one person repeatedly posed part of various proverb and the other tried to complete each one, resulting in such humorous results as "Don't change horses... unless you can lift those heavy diapers."

Editorial cartoons can use proverbs to make their points with extra force as they can invoke the wisdom of society, not just the opinion of the editors. In an example that invoked a proverb only visually, when a US government agency (GSA) was caught spending money extravagantly, a cartoon showed a black pot labeled "Congress" telling a black kettle labeled "GSA", "Stop wasting the taxpayers' money!" It may have taken some readers a moment of pondering to understand it, but the impact of the message was the stronger for it.

Cartoons with proverbs are so common that Wolfgang Mieder has published a collected volume of them, many of them editorial cartoons. For example, a German editorial cartoon linked a current politician to the Nazis, showing him with a bottle of swastika-labeled wine and the caption "In vino veritas".

One cartoonist very self-consciously drew and wrote cartoons based on proverbs for the University of Vermont student newspaper "The Water Tower", under the title "Proverb place".

Proverbs are frequently used in advertising, often in slightly modified form.
Ford once advertised its Thunderbird with, "One drive is worth a thousand words" (Mieder 2004b: 84). This is doubly interesting since the underlying proverb behind this, "One picture is worth a thousand words," was originally introduced into the English proverb repertoire in an ad for televisions (Mieder 2004b: 83).

A few of the many proverbs adapted and used in advertising include:

The GEICO company has created a series of television ads that are built around proverbs, such as "A bird in the hand is worth two in the bush", and "The pen is mightier than the sword", "Pigs may fly/When pigs fly", "If a tree falls in the forest...", and "Words can never hurt you". Doritos made a commercial based on the proverb, "When pigs fly." Many advertisements that use proverbs shorten or amend them, such as, "Think outside the shoebox." 
Use of proverbs in advertising is not limited to the English language. Seda Başer Çoban has studied the use of proverbs in Turkish advertising. Tatira has given a number of examples of proverbs used in advertising in Zimbabwe. However, unlike the examples given above in English, all of which are anti-proverbs, Tatira's examples are standard proverbs. Where the English proverbs above are meant to make a potential customer smile, in one of the Zimbabwean examples "both the content of the proverb and the fact that it is phrased as a proverb secure the idea of a secure time-honored relationship between the company and the individuals". When newer buses were imported, owners of older buses compensated by painting a traditional proverb on the sides of their buses, "Going fast does not assure safe arrival".

There are often proverbs that contradict each other, such as "Look before you leap" and "He who hesitates is lost", or "Many hands make light work" and "Too many cooks spoil the broth". These have been labeled "counter proverbs" or "antonymous proverbs". When there are such counter proverbs, each can be used in its own appropriate situation, and neither is intended to be a universal truth.

The concept of "counter proverb" is more about pairs of contradictory proverbs than about the use of proverbs to counter each other in an argument. For example, from the Tafi language of Ghana, the following pair of proverbs are counter to each other but are each used in appropriate contexts, "A co-wife who is too powerful for you, you address her as your mother" and "Do not call your mother's co-wife your mother..." In Nepali, there is a set of totally contradictory proverbs: "Religion is victorious and sin erodes" and "Religion erodes and sin is victorious".
Also, the following pair are counter proverbs from the Kasena of Ghana: "It is the patient person who will milk a barren cow" and "The person who would milk a barren cow must prepare for a kick on the forehead". The two contradict each other, whether they are used in an argument or not (though indeed they were used in an argument). But the same work contains an appendix with many examples of proverbs used in arguing for contrary positions, but proverbs that are not inherently contradictory, such as "One is better off with hope of a cow's return than news of its death" countered by "If you don't know a goat [before its death] you mock at its skin". Though this pair was used in a contradictory way in a conversation, they are not a set of "counter proverbs".

Discussing counter proverbs in the Badaga language, Hockings explained that in his large collection "a few proverbs are mutually contradictory... we can be sure that the Badagas do not see the matter that way, and would explain such apparent contradictions by reasoning that proverb "x" is used in one context, while "y" is used in quite another." Comparing Korean proverbs, "when you compare two proverbs, often they will be contradictory." They are used for "a particular situation".

"Counter proverbs" are not the same as a "paradoxical proverb", a proverb that contains a seeming paradox.

In many cultures, proverbs are so important and so prominent that there are proverbs about proverbs, that is, "metaproverbs". The most famous one is from Yoruba of Nigeria, "Proverbs are the horses of speech, if communication is lost we use proverbs to find it," used by Wole Soyinka in "Death and the King's Horsemen". In Mieder's bibliography of proverb studies, there are twelve publications listed as describing metaproverbs. Other metaproverbs include:

There is a growing interest in deliberately using proverbs to achieve goals, usually to support and promote changes in society. On the negative side, this was deliberately done by the Nazis. On the more positive side, proverbs have also been used for constructive purposes. For example, proverbs have been used for teaching foreign languages at various levels. In addition, proverbs have been used for public health promotion, such as promoting breast feeding with a shawl bearing a Swahili proverb "Mother's milk is sweet". Proverbs have also been applied for helping people manage diabetes, to combat prostitution, and for community development., to resolve conflicts, and to slow the transmission of HIV.

The most active field deliberately using proverbs is Christian ministry, where Joseph G. Healey and others have deliberately worked to catalyze the collection of proverbs from smaller languages and the application of them in a wide variety of church-related ministries, resulting in publications of collections and applications. This attention to proverbs by those in Christian ministries is not new, many pioneering proverb collections having been collected and published by Christian workers.

U.S. Navy Captain Edward Zellem pioneered the use of Afghan proverbs as a positive relationship-building tool during the war in Afghanistan, and in 2012 he published two bilingual collections of Afghan proverbs in Dari and English, part of an effort of nationbuilding, followed by a volume of Pashto proverbs in 2014.

There is a longstanding debate among proverb scholars as to whether the cultural values of specific language communities are reflected (to varying degree) in their proverbs. Many claim that the proverbs of a particular culture reflect the values of that specific culture, at least to some degree. Many writers have asserted that the proverbs of their cultures reflect their culture and values; this can be seen in such titles as the following: "An introduction to Kasena society and culture through their proverbs", Prejudice, power, and poverty in Haiti: a study of a nation's culture as seen through its proverbs, Proverbiality and worldview in Maltese and Arabic proverbs, Fatalistic traits in Finnish proverbs, "Vietnamese cultural patterns and values as expressed in proverbs", "The Wisdom and Philosophy of the Gikuyu proverbs: The Kihooto worldview", "Spanish Grammar and Culture through Proverbs," and "How Russian Proverbs Present the Russian National Character". Kohistani has written a thesis to show how understanding Afghan Dari proverbs will help Europeans understand Afghan culture.

However, a number of scholars argue that such claims are not valid. They have used a variety of arguments. Grauberg argues that since many proverbs are so widely circulated they are reflections of broad human experience, not any one culture's unique viewpoint. Related to this line of argument, from a collection of 199 American proverbs, Jente showed that only 10 were coined in the USA, so that most of these proverbs would not reflect uniquely American values. Giving another line of reasoning that proverbs should not be trusted as a simplistic guide to cultural values, Mieder once observed "proverbs come and go, that is, antiquated proverbs with messages and images we no longer relate to are dropped from our proverb repertoire, while new proverbs are created to reflect the mores and values of our time", so old proverbs still in circulation might reflect past values of a culture more than its current values. Also, within any language's proverb repertoire, there may be "counter proverbs", proverbs that contradict each other on the surface (see section above). When examining such counter proverbs, it is difficult to discern an underlying cultural value. With so many barriers to a simple calculation of values directly from proverbs, some feel "one cannot draw conclusions about values of speakers simply from the texts of proverbs".

Many outsiders have studied proverbs to discern and understand cultural values and world view of cultural communities. These outsider scholars are confident that they have gained insights into the local cultures by studying proverbs, but this is not universally accepted. 
Seeking empirical evidence to evaluate the question of whether proverbs reflect a culture's values, some have counted the proverbs that support various values. For example, Moon lists what he sees as the top ten core cultural values of the Builsa society of Ghana, as exemplified by proverbs. He found that 18% of the proverbs he analyzed supported the value of being a member of the community, rather than being independent. This was corroboration to other evidence that collective community membership is an important value among the Builsa. In studying Tajik proverbs, Bell notes that the proverbs in his corpus "Consistently illustrate Tajik values" and "The most often observed proverbs reflect the focal and specific values" discerned in the thesis.

A study of English proverbs created since 1900 showed in the 1960s a sudden and significant increase in proverbs that reflected more casual attitudes toward sex. Since the 1960s was also the decade of the Sexual revolution, this shows a strong statistical link between the changed values of the decades and a change in the proverbs coined and used. Another study mining the same volume counted Anglo-American proverbs about religion to show that proverbs indicate attitudes toward religion are going downhill.

There are many examples where cultural values have been explained and illustrated by proverbs. For example, from India, the concept that birth determines one's nature "is illustrated in the oft-repeated proverb: there can be no friendship between grass-eaters and meat-eaters, between a food and its eater". Proverbs have been used to explain and illustrate the Fulani cultural value of "pulaaku". But using proverbs to "illustrate" a cultural value is not the same as using a collection of proverbs to "discern" cultural values. In a comparative study between Spanish and Jordanian proverbs it is defined the social imagination for the mother as an archetype in the context of role transformation and in contrast with the roles of husband, son and brother, in two societies which might be occasionally associated with sexist and /or rural ideologies.

Some scholars have adopted a cautious approach, acknowledging at least a genuine, though limited, link between cultural values and proverbs: "The cultural portrait painted by proverbs may be fragmented, contradictory, or otherwise at variance with reality... but must be regarded not as accurate renderings but rather as tantalizing shadows of the culture which spawned them." There is not yet agreement on the issue of whether, and how much, cultural values are reflected in a culture's proverbs.

It is clear that the Soviet Union believed that proverbs had a direct link to the values of a culture, as they used them to try to create changes in the values of cultures within their sphere of domination. Sometimes they took old Russian proverbs and altered them into socialist forms. These new proverbs promoted Socialism and its attendant values, such as atheism and collectivism, e.g. "Bread is given to us not by Christ, but by machines and collective farms" and "A good harvest is had only by a collective farm." They did not limit their efforts to Russian, but also produced "newly coined proverbs that conformed to socialist thought" in Tajik and other languages of the USSR.
Many proverbs from around the world address matters of ethics and expected of behavior. Therefore, it is not surprising that proverbs are often important texts in religions. The most obvious example is the Book of Proverbs in the Bible. Additional proverbs have also been coined to support religious values, such as the following from Dari of Afghanistan: "In childhood you're playful, In youth you're lustful, In old age you're feeble, So when will you before God be worshipful?"

Clearly proverbs in religion are not limited to monotheists; among the Badaga of India (Sahivite Hindus), there is a traditional proverb "Catch hold of and join with the man who has placed sacred ash [on himself]." Proverbs are widely associated with large religions that draw from sacred books, but they are also used for religious purposes among groups with their own traditional religions, such as the Guji Oromo. The broadest comparative study of proverbs across religions is "The eleven religions and their proverbial lore, a comparative study. A reference book to the eleven surviving major religions of the world" by Selwyn Gurney Champion, from 1945. Some sayings from sacred books also become proverbs, even if they were not obviously proverbs in the original passage of the sacred book. For example, many quote "Be sure your sin will find you out" as a proverb from the Bible, but there is no evidence it was proverbial in its original usage (Numbers 32:23).

Not all religious references in proverbs are positive, some are cynical, such as the Tajik, "Do as the mullah says, not as he does." Also, note the Italian proverb, "One barrel of wine can work more miracles than a church full of saints". An Indian proverb is cynical about devotees of Hinduism, "[Only] When in distress, a man calls on Rama". In the context of Tibetan Buddhism, some Ladakhi proverbs mock the lamas, e.g. "If the lama's own head does not come out cleanly, how will he do the drawing upwards of the dead?... used for deriding the immoral life of the lamas." Proverbs do not have to explicitly mention religion or religious figures to be used to mock a religion, seen in the fact that in a collection of 555 proverbs from the Lur, a Muslim group in Iran, the explanations for 15 of them use illustrations that mock Muslim clerics.

Dammann thought "The influence of Islam manifests itself in African proverbs... Christian influences, on the contrary, are rare." If widely true in Africa, this is likely due to the longer presence of Islam in many parts of Africa. Reflection of Christian values is common in Amharic proverbs of Ethiopia, an area that has had a presence of Christianity for well over 1,000 years. The Islamic proverbial reproduction may also be shown in the image of some animals such as the dog. Although dog is portrayed in many European proverbs as the most faithful friend of man, it is represented in some Islamic countries as impure, dirty, vile, cowardly, ungrateful and treacherous, in addition to links to negative human superstitions such as loneliness, indifference and bad luck.

Though much proverb scholarship is done by literary scholars, those studying the human mind have used proverbs in a variety of studies. One of the earliest studies in this field is the "Proverbs Test" by Gorham, developed in 1956. A similar test is being prepared in German. Proverbs have been used to evaluate dementia, study the cognitive development of children, measure the results of brain injuries, and study how the mind processes figurative language.

The study of proverbs is called paremiology which has a variety of uses in the study of such topics as philosophy, linguistics, and folklore. There are several types and styles of proverbs which are analyzed within Paremiology as is the use and misuse of familiar expressions which are not strictly 'proverbial' in the dictionary definition of being fixed sentences

Grigorii Permjakov developed the concept of the core set of proverbs that full members of society know, what he called the "paremiological minimum" (1979). For example, an adult American is expected to be familiar with "Birds of a feather flock together", part of the American paremiological minimum. However, an average adult American is not expected to know "Fair in the cradle, foul in the saddle", an old English proverb that is not part of the current American paremiological minimum. Thinking more widely than merely proverbs, Permjakov observed "every adult Russian language speaker (over 20 years of age) knows no fewer than 800 proverbs, proverbial expressions, popular literary quotations and other forms of cliches". Studies of the paremiological minimum have been done for a limited number of languages, including Russian, Hungarian, Czech, Somali, Nepali, Gujarati, Spanish, Esperanto, Polish, Ukrainian, Two noted examples of attempts to establish a paremiological minimum in America are by Haas (2008) and Hirsch, Kett, and Trefil (1988), the latter more prescriptive than descriptive. There is not yet a recognized standard method for calculating the paremiological minimum, as seen by comparing the various efforts to establish the paremiological minimum in a number of languages.

A seminal work in the study of proverbs is Archer Taylor's "The Proverb" (1931), later republished by Wolfgang Mieder with Taylor's Index included (1985/1934). A good introduction to the study of proverbs is Mieder's 2004 volume, "Proverbs: A Handbook". Mieder has also published a series of bibliography volumes on proverb research, as well as a large number of articles and other books in the field. Stan Nussbaum has edited a large collection on proverbs of Africa, published on a CD, including reprints of out-of-print collections, original collections, and works on analysis, bibliography, and application of proverbs to Christian ministry (1998). Paczolay has compared proverbs across Europe and published a collection of similar proverbs in 55 languages (1997). Mieder edits an academic journal of proverb study, "Proverbium" (), many back issues of which are available online. A volume containing articles on a wide variety of topics touching on proverbs was edited by Mieder and Alan Dundes (1994/1981). "Paremia" is a Spanish-language journal on proverbs, with articles available online. There are also papers on proverbs published in conference proceedings volumes from the annual Interdisciplinary Colloquium on Proverbs in Tavira, Portugal. Mieder has published a two-volume "International Bibliography of Paremiology and Phraseology", with a topical, language, and author index. Mieder has published a bibliography of collections of proverbs from around the world. A broad introduction to proverb study, "Introduction to Paremiology", edited by Hrisztalina Hrisztova-Gotthardt and Melita Aleksa Varga has been published in both hardcover and free open access, with articles by a dozen different authors.

The study of proverbs has been built by a number of notable scholars and contributors. Earlier scholars were more concerned with collecting than analyzing. Desiderius Erasmus was a Latin scholar (1466 – 1536), whose collection of Latin proverbs, known as "Adagia", spread Latin proverbs across Europe. Juan de Mal Lara was a 16th century Spanish scholar, one of his books being 1568 "Philosophia vulgar", the first part of which contains one thousand and one sayings.

From the 20th century onwards, proverb scholars were involved in not only collecting proverbs, but also analyzing and comparing proverbs. Alan Dundes was a 20th century American folklorist whose scholarly output on proverbs led Wolfgang Mieder to refer to him as a “pioneering paremiologist”. Matti Kuusi was a 20th century Finnish paremiologist, the creator of the Matti Kuusi international type system of proverbs. With encouragement from Archer Taylor, he founded the journal "Proverbium: Bulletin d'Information sur les Recherches Parémiologiques", published from 1965 to 1975 by the Society for Finnish Literature, which was later restarted as "Proverbium: International Yearbook of Proverb Scholarship". Archer Taylor was a 20th century American scholar, best known for his "magisterial" book "The Proverb". Dimitrios Loukatos was a 20th century Greek proverb scholar, author of such works as "Aetiological Tales of Modern Greek Proverbs". Arvo Krikmann (1939 – 2017) was an Estonian proverb scholar, whom Wolfgang Mieder called “one of the leading paremiologists in the world” and “master folklorist and paremiologist”.

Current proverb scholars have continued the trend to be involved in analysis as well as collection of proverbs. Claude Buridant is a century French scholar whose work has concentrated on Romance languages. Galit Hasan-Rokem is an Israeli scholar, associate editor of "Proverbium: The yearbook of international proverb scholarship", since 1984. She has written on proverbs in Jewish traditions. Joseph G. Healey is an American Catholic missionary in Kenya who has led a movement to sponsor African proverb scholars to collect proverbs from their own language communities. This led Wolfgang Mieder to dedicate the "International Bibliography of New and Reprinted Proverb Collections" section of "Proverbium" 32 to Healey. Barbara Kirshenblatt-Gimblett is a scholar of Jewish history and folklore, including proverbs. Wolfgang Mieder is a German-born proverb scholar who has worked his entire academic career in the USA. He is the editor of ‘’Proverbium’’ and the author of the two volume "International Bibliography of Paremiology and Phraseology". He has been honored by three festschrift publications. He has also been recognized by biographical publications that focused on his scholarship. Elisabeth Piirainen is a German scholar with 50 proverb-related publications. Dora Sakayan is a scholar who has written about German and Armenian studies, including "Armenian Proverbs: A Paremiological Study with an Anthology of 2,500 Armenian Folk Sayings Selected and Translated into English". An extensive introduction addresses the language and structure, as well as the origin of Armenian proverbs (international, borrowed and specifically Armenian proverbs). Mineke Schipper is a Dutch scholar, best known for her book "Never Marry a Woman with Big Feet - Women in Proverbs from Around the World".. Edward Zellem is an American proverb scholar who has edited books of Afghan proverbs, developed a method of collecting proverbs via the Web.



Serious websites related to the study of proverbs, and some that list regional proverbs:


</doc>
<doc id="23531" url="https://en.wikipedia.org/wiki?curid=23531" title="Portability (social security)">
Portability (social security)

The portability of social security benefits is the ability of workers to preserve, maintain, and transfer acquired social security rights and social security rights in the process of being acquired from one private, occupational, or public social security scheme to another. Social security rights refer to rights stemming from pension schemes (old age, survivor, disability), unemployment insurance, health insurance, workers' compensation, and sickness benefits. 

Hence, if social security benefits are portable, contributors to, for example, old-age pension schemes do not experience any disadvantage such as the loss of contributions and benefits associated with these contributions when moving from one job to another, from one occupation to another, or from the public to the private sector or vice versa.

International portability of social security rights allows international migrants, who have contributed to a social security scheme for some time in a particular country, to maintain acquired benefits or benefits in the process of being acquired when moving to another country. International portability of social security benefits is therefore understood as the migrant's ability to preserve, maintain, and transfer acquired social security rights independent of nationality and country of residence.

International portability of social security benefits is achieved through bilateral or multilateral social security agreements between countries. These agreements guarantee the totalization of periods of contribution to the social security systems of both countries and the extraterritorial payment of benefits. Currently it is estimated that approximately 23 per cent of migrants worldwide are covered by bilateral social security agreements.


</doc>
<doc id="23534" url="https://en.wikipedia.org/wiki?curid=23534" title="Percopsiformes">
Percopsiformes

The Percopsiformes are a small order of ray-finned fishes, comprising the trout-perch and its allies. It contains just ten extant species, grouped into seven genera and three families. Five of these genera are monotypic

They are generally small fish, ranging from in adult body length. They inhabit freshwater habitats in North America. They are grouped together because of technical characteristics of their internal anatomy, and the different species may appear quite different externally.



</doc>
<doc id="23535" url="https://en.wikipedia.org/wiki?curid=23535" title="Photon">
Photon

The photon is a type of elementary particle, the quantum of the electromagnetic field including electromagnetic radiation such as light, and the force carrier for the electromagnetic force (even when static via virtual particles). The photon has zero rest mass and always moves at the speed of light within a vacuum.

Like all elementary particles, photons are currently best explained by quantum mechanics and exhibit wave–particle duality, exhibiting properties of both waves and particles. For example, a single photon may be refracted by a lens and exhibit wave interference with itself, and it can behave as a particle with definite and finite measurable position or momentum, though not both at the same time. The photon's wave and quantum qualities are two observable aspects of a single phenomenon – they cannot be described by any mechanical model; a representation of this dual property of light that assumes certain points on the wavefront to be the seat of the energy is not possible. The quanta in a light wave are not spatially localized. 

The modern concept of the photon was developed gradually by Albert Einstein in the early 20th century to explain experimental observations that did not fit the classical wave model of light. The benefit of the photon model was that it accounted for the frequency dependence of light's energy, and explained the ability of matter and electromagnetic radiation to be in thermal equilibrium. The photon model accounted for anomalous observations, including the properties of black-body radiation, that others (notably Max Planck) had tried to explain using "semiclassical models". In that model, light was described by Maxwell's equations, but material objects emitted and absorbed light in "quantized" amounts (i.e., they change energy only by certain particular discrete amounts). Although these semiclassical models contributed to the development of quantum mechanics, many further experiments beginning with the phenomenon of Compton scattering of single photons by electrons, validated Einstein's hypothesis that "light itself" is quantized. In 1926 the optical physicist Frithiof Wolfers and the chemist Gilbert N. Lewis coined the name "photon" for these particles. After Arthur H. Compton won the Nobel Prize in 1927 for his scattering studies, most scientists accepted that light quanta have an independent existence, and the term "photon" was accepted.

In the Standard Model of particle physics, photons and other elementary particles are described as a necessary consequence of physical laws having a certain symmetry at every point in spacetime. The intrinsic properties of particles, such as charge, mass, and spin, are determined by this gauge symmetry. The photon concept has led to momentous advances in experimental and theoretical physics, including lasers, Bose–Einstein condensation, quantum field theory, and the probabilistic interpretation of quantum mechanics. It has been applied to photochemistry, high-resolution microscopy, and measurements of molecular distances. Recently, photons have been studied as elements of quantum computers, and for applications in optical imaging and optical communication such as quantum cryptography.

The word "quanta" (singular "quantum," Latin for "how much") was used before 1900 to mean particles or amounts of different quantities, including electricity. In 1900, the German physicist Max Planck was studying black-body radiation: he suggested that the experimental observations would be explained if the energy carried by electromagnetic waves could only be released in "packets" of energy. In his 1901 article in "Annalen der Physik" he called these packets "energy elements". In 1905, Albert Einstein published a paper in which he proposed that many light-related phenomena—including black-body radiation and the photoelectric effect—would be better explained by modelling electromagnetic waves as consisting of spatially localized, discrete wave-packets. He called such a wave-packet "the light quantum" (German: "das Lichtquant"). The name "photon" derives from the Greek word for light, "" (transliterated "phôs"). Arthur Compton used "photon" in 1928, referring to Gilbert N. Lewis. The same name was used earlier, by the American physicist and psychologist Leonard T. Troland, who coined the word in 1916, in 1921 by the Irish physicist John Joly, in 1924 by the French physiologist René Wurmser (1890–1993) and in 1926 by the French physicist Frithiof Wolfers (1891–1971). The name was suggested initially as a unit related to the illumination of the eye and the resulting sensation of light and was used later in a physiological context. Although Wolfers's and Lewis's theories were contradicted by many experiments and never accepted, the new name was adopted very soon by most physicists after Compton used it.

In physics, a photon is usually denoted by the symbol "γ" (the Greek letter gamma). This symbol for the photon probably derives from gamma rays, which were discovered in 1900 by Paul Villard, named by Ernest Rutherford in 1903, and shown to be a form of electromagnetic radiation in 1914 by Rutherford and Edward Andrade. In chemistry and optical engineering, photons are usually symbolized by "hν", which is the photon energy, where "h" is Planck constant and the Greek letter "ν" (nu) is the photon's frequency. Much less commonly, the photon can be symbolized by "hf", where its frequency is denoted by "f".

A photon is massless, has no electric charge, and is a stable particle. A photon has two possible polarization states. In the momentum representation of the photon, which is preferred in quantum field theory, a photon is described by its wave vector, which determines its wavelength "λ" and its direction of propagation. A photon's wave vector may not be zero and can be represented either as a spatial 3-vector or as a (relativistic) four-vector; in the latter case it belongs to the light cone (pictured). Different signs of the four-vector denote different circular polarizations, but in the 3-vector representation one should account for the polarization state separately; it actually is a spin quantum number. In both cases the space of possible wave vectors is three-dimensional.

The photon is the gauge boson for electromagnetism, and therefore all other quantum numbers of the photon (such as lepton number, baryon number, and flavour quantum numbers) are zero. Also, the photon does not obey the Pauli exclusion principle.

Photons are emitted in many natural processes. For example, when a charge is accelerated it emits synchrotron radiation. During a molecular, atomic or nuclear transition to a lower energy level, photons of various energy will be emitted, ranging from radio waves to gamma rays. Photons can also be emitted when a particle and its corresponding antiparticle are annihilated (for example, electron–positron annihilation).

In empty space, the photon moves at "c" (the speed of light) and its energy and momentum are related by , where "p" is the magnitude of the momentum vector p. This derives from the following relativistic relation, with :

The energy and momentum of a photon depend only on its frequency ("ν") or inversely, its wavelength ("λ"):

where k is the wave vector (where the wave number ), is the angular frequency, and is the reduced Planck constant.

Since p points in the direction of the photon's propagation, the magnitude of the momentum is

The photon also carries a quantity called spin angular momentum that does not depend on its frequency. The magnitude of its spin is "ħ" and the component measured along its direction of motion, its helicity, must be ±"ħ". These two possible helicities, called right-handed and left-handed, correspond to the two possible circular polarization states of the photon.

To illustrate the significance of these formulae, the annihilation of a particle with its antiparticle in free space must result in the creation of at least "two" photons for the following reason. In the center of momentum frame, the colliding antiparticles have no net momentum, whereas a single photon always has momentum (since, as we have seen, it is determined by the photon's frequency or wavelength, which cannot be zero). Hence, conservation of momentum (or equivalently, translational invariance) requires that at least two photons are created, with zero net momentum. (However, it is possible if the system interacts with another particle or field for the annihilation to produce one photon, as when a positron annihilates with a bound atomic electron, it is possible for only one photon to be emitted, as the nuclear Coulomb field breaks translational symmetry.) The energy of the two photons, or, equivalently, their frequency, may be determined from conservation of four-momentum. Seen another way, the photon can be considered as its own antiparticle. The reverse process, pair production, is the dominant mechanism by which high-energy photons such as gamma rays lose energy while passing through matter. That process is the reverse of "annihilation to one photon" allowed in the electric field of an atomic nucleus.

The classical formulae for the energy and momentum of electromagnetic radiation can be re-expressed in terms of photon events. For example, the pressure of electromagnetic radiation on an object derives from the transfer of photon momentum per unit time and unit area to that object, since pressure is force per unit area and force is the change in momentum per unit time.

Each photon carries two distinct and independent forms of angular momentum of light. The spin angular momentum of light of a particular photon is always either +"ħ" or −"ħ".
The light orbital angular momentum of a particular photon can be any integer "N", including zero.

Current commonly accepted physical theories imply or assume the photon to be strictly massless. If the photon is not a strictly massless particle, it would not move at the exact speed of light, "c", in vacuum. Its speed would be lower and depend on its frequency. Relativity would be unaffected by this; the so-called speed of light, "c", would then not be the actual speed at which light moves, but a constant of nature which is the upper bound on speed that any object could theoretically attain in spacetime. Thus, it would still be the speed of spacetime ripples (gravitational waves and gravitons), but it would not be the speed of photons.

If a photon did have non-zero mass, there would be other effects as well. Coulomb's law would be modified and the electromagnetic field would have an extra physical degree of freedom. These effects yield more sensitive experimental probes of the photon mass than the frequency dependence of the speed of light. If Coulomb's law is not exactly valid, then that would allow the presence of an electric field to exist within a hollow conductor when it is subjected to an external electric field. This thus allows one to test Coulomb's law to very high precision. A null result of such an experiment has set a limit of .

Sharper upper limits on the speed of light have been obtained in experiments designed to detect effects caused by the galactic vector potential. Although the galactic vector potential is very large because the galactic magnetic field exists on very great length scales, only the magnetic field would be observable if the photon is massless. In the case that the photon has mass, the mass term "m'A'A" would affect the galactic plasma. The fact that no such effects are seen implies an upper bound on the photon mass of . The galactic vector potential can also be probed directly by measuring the torque exerted on a magnetized ring. Such methods were used to obtain the sharper upper limit of (the equivalent of ) given by the Particle Data Group.

These sharp limits from the non-observation of the effects caused by the galactic vector potential have been shown to be model-dependent. If the photon mass is generated via the Higgs mechanism then the upper limit of from the test of Coulomb's law is valid.

Photons inside superconductors do develop a nonzero effective rest mass; as a result, electromagnetic forces become short-range inside superconductors.

In most theories up to the eighteenth century, light was pictured as being made up of particles. Since particle models cannot easily account for the refraction, diffraction and birefringence of light, wave theories of light were proposed by René Descartes (1637), Robert Hooke (1665), and Christiaan Huygens (1678); however, particle models remained dominant, chiefly due to the influence of Isaac Newton. In the early nineteenth century, Thomas Young and August Fresnel clearly demonstrated the interference and diffraction of light and by 1850 wave models were generally accepted. In 1865, James Clerk Maxwell's prediction that light was an electromagnetic wave—which was confirmed experimentally in 1888 by Heinrich Hertz's detection of radio waves—seemed to be the final blow to particle models of light.
The Maxwell wave theory, however, does not account for "all" properties of light. The Maxwell theory predicts that the energy of a light wave depends only on its intensity, not on its frequency; nevertheless, several independent types of experiments show that the energy imparted by light to atoms depends only on the light's frequency, not on its intensity. For example, some chemical reactions are provoked only by light of frequency higher than a certain threshold; light of frequency lower than the threshold, no matter how intense, does not initiate the reaction. Similarly, electrons can be ejected from a metal plate by shining light of sufficiently high frequency on it (the photoelectric effect); the energy of the ejected electron is related only to the light's frequency, not to its intensity.

At the same time, investigations of blackbody radiation carried out over four decades (1860–1900) by various researchers culminated in Max Planck's hypothesis that the energy of "any" system that absorbs or emits electromagnetic radiation of frequency "ν" is an integer multiple of an energy quantum . As shown by Albert Einstein, some form of energy quantization "must" be assumed to account for the thermal equilibrium observed between matter and electromagnetic radiation; for this explanation of the photoelectric effect, Einstein received the 1921 Nobel Prize in physics.

Since the Maxwell theory of light allows for all possible energies of electromagnetic radiation, most physicists assumed initially that the energy quantization resulted from some unknown constraint on the matter that absorbs or emits the radiation. In 1905, Einstein was the first to propose that energy quantization was a property of electromagnetic radiation itself. Although he accepted the validity of Maxwell's theory, Einstein pointed out that many anomalous experiments could be explained if the "energy" of a Maxwellian light wave were localized into point-like quanta that move independently of one another, even if the wave itself is spread continuously over space. In 1909 and 1916, Einstein showed that, if Planck's law of black-body radiation is accepted, the energy quanta must also carry momentum , making them full-fledged particles. This photon momentum was observed experimentally by Arthur Compton, for which he received the Nobel Prize in 1927. The pivotal question was then: how to unify Maxwell's wave theory of light with its experimentally observed particle nature? The answer to this question occupied Albert Einstein for the rest of his life, and was solved in quantum electrodynamics and its successor, the Standard Model (see ' and ', below).

Unlike Planck, Einstein entertained the possibility that there might be actual physical quanta of light—what we now call photons. He noticed that a light quantum with energy proportional to its frequency would explain a number of troubling puzzles and paradoxes, including an unpublished law by Stokes, the ultraviolet catastrophe, and the photoelectric effect. Stokes's law said simply that the frequency of fluorescent light cannot be greater than the frequency of the light (usually ultraviolet) inducing it. Einstein eliminated the ultraviolet catastrophe by imagining a gas of photons behaving like a gas of electrons that he had previously considered. He was advised by a colleague to be careful how he wrote up this paper, in order to not challenge Planck, a powerful figure in physics, too directly, and indeed the warning was justified, as Planck never forgave him for writing it.

Einstein's 1905 predictions were verified experimentally in several ways in the first two decades of the 20th century, as recounted in Robert Millikan's Nobel lecture. However, before Compton's experiment showed that photons carried momentum proportional to their wave number (1922), most physicists were reluctant to believe that electromagnetic radiation itself might be particulate. (See, for example, the Nobel lectures of Wien, Planck and Millikan.) Instead, there was a widespread belief that energy quantization resulted from some unknown constraint on the matter that absorbed or emitted radiation. Attitudes changed over time. In part, the change can be traced to experiments such as Compton scattering, where it was much more difficult not to ascribe quantization to light itself to explain the observed results.

Even after Compton's experiment, Niels Bohr, Hendrik Kramers and John Slater made one last attempt to preserve the Maxwellian continuous electromagnetic field model of light, the so-called BKS model. To account for the data then available, two drastic hypotheses had to be made:


However, refined Compton experiments showed that energy–momentum is conserved extraordinarily well in elementary processes; and also that the jolting of the electron and the generation of a new photon in Compton scattering obey causality to within 10 ps. Accordingly, Bohr and his co-workers gave their model "as honorable a funeral as possible". Nevertheless, the failures of the BKS model inspired Werner Heisenberg in his development of matrix mechanics.

A few physicists persisted in developing semiclassical models in which electromagnetic radiation is not quantized, but matter appears to obey the laws of quantum mechanics. Although the evidence from chemical and physical experiments for the existence of photons was overwhelming by the 1970s, this evidence could not be considered as "absolutely" definitive; since it relied on the interaction of light with matter, and a sufficiently complete theory of matter could in principle account for the evidence. Nevertheless, "all" semiclassical theories were refuted definitively in the 1970s and 1980s by photon-correlation experiments. Hence, Einstein's hypothesis that quantization is a property of light itself is considered to be proven.

Photons, like all quantum objects, exhibit wave-like and particle-like properties. Their dual wave–particle nature can be difficult to visualize. The photon displays clearly wave-like phenomena such as diffraction and interference on the length scale of its wavelength. For example, a single photon passing through a double-slit experiment exhibits interference phenomena but only if no measure was made at the slit. A single photon passing through a double-slit experiment lands on the screen with a probability distribution given by its interference pattern determined by Maxwell's equations. However, experiments confirm that the photon is "not" a short pulse of electromagnetic radiation; it does not spread out as it propagates, nor does it divide when it encounters a beam splitter. Rather, the photon seems to be a point-like particle since it is absorbed or emitted "as a whole" by arbitrarily small systems, systems much smaller than its wavelength, such as an atomic nucleus (≈10 m across) or even the point-like electron. Nevertheless, the photon is "not" a point-like particle whose trajectory is shaped probabilistically by the electromagnetic field, as conceived by Einstein and others; that hypothesis was also refuted by the photon-correlation experiments cited above. According to our present understanding, the electromagnetic field itself is produced by photons, which in turn result from a local gauge symmetry and the laws of quantum field theory (see ' and ' below).

A key element of quantum mechanics is Heisenberg's uncertainty principle, which forbids the simultaneous measurement of the position and momentum of a particle along the same direction. Remarkably, the uncertainty principle for charged, material particles "requires" the quantization of light into photons, and even the frequency dependence of the photon's energy and momentum.

An elegant illustration of the uncertainty principle is Heisenberg's thought experiment for locating an electron with an ideal microscope. The position of the electron can be determined to within the resolving power of the microscope, which is given by a formula from classical optics

where θ is the aperture angle of the microscope and λ is the wavelength of the light used to observe the electron. Thus, the position uncertainty formula_6 can be made arbitrarily small by reducing the wavelength λ. Even if the momentum of the electron is initially known, the light impinging on the electron will give it a momentum "kick" formula_7 of some unknown amount, rendering the momentum of the electron uncertain. If light were "not" quantized into photons, the uncertainty formula_7 could be made arbitrarily small by reducing the light's intensity. In that case, since the wavelength and intensity of light can be varied independently, one could simultaneously determine the position and momentum to arbitrarily high accuracy, violating the uncertainty principle. By contrast, Einstein's formula for photon momentum preserves the uncertainty principle; since the photon is scattered anywhere within the aperture, the uncertainty of momentum transferred equals

giving the product formula_10, which is Heisenberg's uncertainty principle. Thus, the entire world is quantized; both matter and fields must obey a consistent set of quantum laws, if either one is to be quantized.

The analogous uncertainty principle for photons forbids the simultaneous measurement of the number formula_11 of photons (see Fock state and the Second quantization section below) in an electromagnetic wave and the phase formula_12 of that wave

See coherent state and squeezed coherent state for more details.

Both photons and electrons create analogous interference patterns when passed through a double-slit experiment. For photons, this corresponds to the interference of a Maxwell light wave whereas, for material particles (electron), this corresponds to the interference of the Schrödinger wave equation. Although this similarity might suggest that Maxwell's equations describing the photon's electromagnetic wave are simply Schrödinger's equation for photons, most physicists do not agree. For one thing, they are mathematically different; most obviously, Schrödinger's one equation for the electron solves for a complex field, whereas Maxwell's four equations solve for real fields. More generally, the normal concept of a Schrödinger probability wave function cannot be applied to photons. As photons are massless, they cannot be localized without being destroyed; technically, photons cannot have a position eigenstate formula_14, and, thus, the normal Heisenberg uncertainty principle formula_15 does not pertain to photons. A few substitute wave functions have been suggested for the photon, but they have not come into general use. Instead, physicists generally accept the second-quantized theory of photons described below, quantum electrodynamics, in which photons are quantized excitations of electromagnetic modes.

Another interpretation, that avoids duality, is the De Broglie–Bohm theory: known also as the "pilot-wave model". In that theory, the photon is both, wave and particle. ""This idea seems to me so natural and simple, to resolve the wave-particle dilemma in such a clear and ordinary way, that it is a great mystery to me that it was so generally ignored"", J.S.Bell.

In 1924, Satyendra Nath Bose derived Planck's law of black-body radiation without using any electromagnetism, but rather by using a modification of coarse-grained counting of phase space. Einstein showed that this modification is equivalent to assuming that photons are rigorously identical and that it implied a "mysterious non-local interaction", now understood as the requirement for a symmetric quantum mechanical state. This work led to the concept of coherent states and the development of the laser. In the same papers, Einstein extended Bose's formalism to material particles (bosons) and predicted that they would condense into their lowest quantum state at low enough temperatures; this Bose–Einstein condensation was observed experimentally in 1995. It was later used by Lene Hau to slow, and then completely stop, light in 1999 and 2001.

The modern view on this is that photons are, by virtue of their integer spin, bosons (as opposed to fermions with half-integer spin). By the spin-statistics theorem, all bosons obey Bose–Einstein statistics (whereas all fermions obey Fermi–Dirac statistics).

In 1916, Albert Einstein showed that Planck's radiation law could be derived from a semi-classical, statistical treatment of photons and atoms, which implies a link between the rates at which atoms emit and absorb photons. The condition follows from the assumption that functions of the emission and absorption of radiation by the atoms are independent of each other, and that thermal equilibrium is made by way of the radiation's interaction with the atoms. Consider a cavity in thermal equilibrium with all parts of itself and filled with electromagnetic radiation and that the atoms can emit and absorb that radiation. Thermal equilibrium requires that the energy density formula_16 of photons with frequency formula_17 (which is proportional to their number density) is, on average, constant in time; hence, the rate at which photons of any particular frequency are "emitted" must equal the rate at which they "absorb" them.

Einstein began by postulating simple proportionality relations for the different reaction rates involved. In his model, the rate formula_18 for a system to "absorb" a photon of frequency formula_17 and transition from a lower energy formula_20 to a higher energy formula_21 is proportional to the number formula_22 of atoms with energy formula_20 and to the energy density formula_16 of ambient photons of that frequency,

where formula_26 is the rate constant for absorption. For the reverse process, there are two possibilities: spontaneous emission of a photon, or the emission of a photon initiated by the interaction of the atom with a passing photon and the return of the atom to the lower-energy state. Following Einstein's approach, the corresponding rate formula_27 for the emission of photons of frequency formula_17 and transition from a higher energy formula_21 to a lower energy formula_20 is

where formula_32 is the rate constant for emitting a photon spontaneously, and formula_33 is the rate constant for emissions in response to ambient photons (induced or stimulated emission). In thermodynamic equilibrium, the number of atoms in state i and those in state j must, on average, be constant; hence, the rates formula_18 and formula_27 must be equal. Also, by arguments analogous to the derivation of Boltzmann statistics, the ratio of formula_36 and formula_22 is formula_38 where formula_39 are the degeneracy of the state i and that of j, respectively, formula_40 their energies, k the Boltzmann constant and T the system's temperature. From this, it is readily derived that
formula_41 and
The A and Bs are collectively known as the "Einstein coefficients".

Einstein could not fully justify his rate equations, but claimed that it should be possible to calculate the coefficients formula_32, formula_26 and formula_33 once physicists had obtained "mechanics and electrodynamics modified to accommodate the quantum hypothesis". In fact, in 1926, Paul Dirac derived the formula_33 rate constants by using a semiclassical approach, and, in 1927, succeeded in deriving "all" the rate constants from first principles within the framework of quantum theory. Dirac's work was the foundation of quantum electrodynamics, i.e., the quantization of the electromagnetic field itself. Dirac's approach is also called "second quantization" or quantum field theory; earlier quantum mechanical treatments only treat material particles as quantum mechanical, not the electromagnetic field.

Einstein was troubled by the fact that his theory seemed incomplete, since it did not determine the "direction" of a spontaneously emitted photon. A probabilistic nature of light-particle motion was first considered by Newton in his treatment of birefringence and, more generally, of the splitting of light beams at interfaces into a transmitted beam and a reflected beam. Newton hypothesized that hidden variables in the light particle determined which of the two paths a single photon would take. Similarly, Einstein hoped for a more complete theory that would leave nothing to chance, beginning his separation from quantum mechanics. Ironically, Max Born's probabilistic interpretation of the wave function was inspired by Einstein's later work searching for a more complete theory.

In 1910, Peter Debye derived Planck's law of black-body radiation from a relatively simple assumption. He correctly decomposed the electromagnetic field in a cavity into its Fourier modes, and assumed that the energy in any mode was an integer multiple of formula_47, where formula_17 is the frequency of the electromagnetic mode. Planck's law of black-body radiation follows immediately as a geometric sum. However, Debye's approach failed to give the correct formula for the energy fluctuations of blackbody radiation, which were derived by Einstein in 1909.

In 1925, Born, Heisenberg and Jordan reinterpreted Debye's concept in a key way. As may be shown classically, the Fourier modes of the electromagnetic field—a complete set of electromagnetic plane waves indexed by their wave vector k and polarization state—are equivalent to a set of uncoupled simple harmonic oscillators. Treated quantum mechanically, the energy levels of such oscillators are known to be formula_49, where formula_17 is the oscillator frequency. The key new step was to identify an electromagnetic mode with energy formula_49 as a state with formula_11 photons, each of energy formula_47. This approach gives the correct energy fluctuation formula.
Dirac took this one step further. He treated the interaction between a charge and an electromagnetic field as a small perturbation that induces transitions in the photon states, changing the numbers of photons in the modes, while conserving energy and momentum overall. Dirac was able to derive Einstein's formula_32 and formula_33 coefficients from first principles, and showed that the Bose–Einstein statistics of photons is a natural consequence of quantizing the electromagnetic field correctly (Bose's reasoning went in the opposite direction; he derived Planck's law of black-body radiation by "assuming" B–E statistics). In Dirac's time, it was not yet known that all bosons, including photons, must obey Bose–Einstein statistics.

Dirac's second-order perturbation theory can involve virtual photons, transient intermediate states of the electromagnetic field; the static electric and magnetic interactions are mediated by such virtual photons. In such quantum field theories, the probability amplitude of observable events is calculated by summing over "all" possible intermediate steps, even ones that are unphysical; hence, virtual photons are not constrained to satisfy formula_56, and may have extra polarization states; depending on the gauge used, virtual photons may have three or four polarization states, instead of the two states of real photons. Although these transient virtual photons can never be observed, they contribute measurably to the probabilities of observable events. Indeed, such second-order and higher-order perturbation calculations can give apparently infinite contributions to the sum. Such unphysical results are corrected for using the technique of renormalization.

Other virtual particles may contribute to the summation as well; for example, two photons may interact indirectly through virtual electron–positron pairs. In fact, such photon–photon scattering (see two-photon physics), as well as electron–photon scattering, is meant to be one of the modes of operations of the planned particle accelerator, the International Linear Collider.

In modern physics notation, the quantum state of the electromagnetic field is written as a Fock state, a tensor product of the states for each electromagnetic mode

where formula_58 represents the state in which formula_59 photons are in the mode formula_60. In this notation, the creation of a new photon in mode formula_60 (e.g., emitted from an atomic transition) is written as formula_62. This notation merely expresses the concept of Born, Heisenberg and Jordan described above, and does not add any physics.

Measurements of the interaction between energetic photons and hadrons show that the interaction is much more intense than expected by the interaction of merely photons with the hadron's electric charge. Furthermore, the interaction of energetic photons with protons is similar to the interaction of photons with neutrons in spite of the fact that the electric charge structures of protons and neutrons are substantially different. A theory called Vector Meson Dominance (VMD) was developed to explain this effect. According to VMD, the photon is a superposition of the pure electromagnetic photon which interacts only with electric charges and vector mesons. However, if experimentally probed at very short distances, the intrinsic structure of the photon is recognized as a flux of quark and gluon components, quasi-free according to asymptotic freedom in QCD and described by the photon structure function. A comprehensive comparison of data with theoretical predictions was presented in a review in 2000.

The electromagnetic field can be understood as a gauge field, i.e., as a field that results from requiring that a gauge symmetry holds independently at every position in spacetime. For the electromagnetic field, this gauge symmetry is the Abelian U(1) symmetry of complex numbers of absolute value 1, which reflects the ability to vary the phase of a complex field without affecting observables or real valued functions made from it, such as the energy or the Lagrangian.

The quanta of an Abelian gauge field must be massless, uncharged bosons, as long as the symmetry is not broken; hence, the photon is predicted to be massless, and to have zero electric charge and integer spin. The particular form of the electromagnetic interaction specifies that the photon must have spin ±1; thus, its helicity must be formula_63. These two spin components correspond to the classical concepts of right-handed and left-handed circularly polarized light. However, the transient virtual photons of quantum electrodynamics may also adopt unphysical polarization states.

In the prevailing Standard Model of physics, the photon is one of four gauge bosons in the electroweak interaction; the other three are denoted W, W and Z and are responsible for the weak interaction. Unlike the photon, these gauge bosons have mass, owing to a mechanism that breaks their SU(2) gauge symmetry. The unification of the photon with W and Z gauge bosons in the electroweak interaction was accomplished by Sheldon Glashow, Abdus Salam and Steven Weinberg, for which they were awarded the 1979 Nobel Prize in physics. Physicists continue to hypothesize grand unified theories that connect these four gauge bosons with the eight gluon gauge bosons of quantum chromodynamics; however, key predictions of these theories, such as proton decay, have not been observed experimentally.

The energy of a system that emits a photon is "decreased" by the energy formula_64 of the photon as measured in the rest frame of the emitting system, which may result in a reduction in mass in the amount formula_65. Similarly, the mass of a system that absorbs a photon is "increased" by a corresponding amount. As an application, the energy balance of nuclear reactions involving photons is commonly written in terms of the masses of the nuclei involved, and terms of the form formula_65 for the gamma photons (and for other relevant energies, such as the recoil energy of nuclei).

This concept is applied in key predictions of quantum electrodynamics (QED, see above). In that theory, the mass of electrons (or, more generally, leptons) is modified by including the mass contributions of virtual photons, in a technique known as renormalization. Such "radiative corrections" contribute to a number of predictions of QED, such as the magnetic dipole moment of leptons, the Lamb shift, and the hyperfine structure of bound lepton pairs, such as muonium and positronium.

Since photons contribute to the stress–energy tensor, they exert a gravitational attraction on other objects, according to the theory of general relativity. Conversely, photons are themselves affected by gravity; their normally straight trajectories may be bent by warped spacetime, as in gravitational lensing, and their frequencies may be lowered by moving to a higher gravitational potential, as in the Pound–Rebka experiment. However, these effects are not specific to photons; exactly the same effects would be predicted for classical electromagnetic waves.

Light that travels through transparent matter does so at a lower speed than "c", the speed of light in a vacuum. For example, photons engage in so many collisions on the way from the core of the sun that radiant energy can take about a million years to reach the surface; however, once in open space, a photon takes only 8.3 minutes to reach Earth. The factor by which the speed is decreased is called the refractive index of the material. In a classical wave picture, the slowing can be explained by the light inducing electric polarization in the matter, the polarized matter radiating new light, and that new light interfering with the original light wave to form a delayed wave. In a particle picture, the slowing can instead be described as a blending of the photon with quantum excitations of the matter to produce quasi-particles known as polariton (other quasi-particles are phonons and excitons); this polariton has a nonzero effective mass, which means that it cannot travel at "c". Light of different frequencies may travel through matter at different speeds; this is called dispersion (not to be confused with scattering). In some cases, it can result in extremely slow speeds of light in matter. The effects of photon interactions with other quasi-particles may be observed directly in Raman scattering and Brillouin scattering.

Photons can also be absorbed by nuclei, atoms or molecules, provoking transitions between their energy levels. A classic example is the molecular transition of retinal (CHO), which is responsible for vision, as discovered in 1958 by Nobel laureate biochemist George Wald and co-workers. The absorption provokes a cis-trans isomerization that, in combination with other such transitions, is transduced into nerve impulses. The absorption of photons can even break chemical bonds, as in the photodissociation of chlorine; this is the subject of photochemistry.

Photons have many applications in technology. These examples are chosen to illustrate applications of photons "per se", rather than general optical devices such as lenses, etc. that could operate under a classical theory of light. The laser is an extremely important application and is discussed above under stimulated emission.

Individual photons can be detected by several methods. The classic photomultiplier tube exploits the photoelectric effect: a photon of sufficient energy strikes a metal plate and knocks free an electron, initiating an ever-amplifying avalanche of electrons. Semiconductor charge-coupled device chips use a similar effect: an incident photon generates a charge on a microscopic capacitor that can be detected. Other detectors such as Geiger counters use the ability of photons to ionize gas molecules contained in the device, causing a detectable change of conductivity of the gas.

Planck's energy formula formula_67 is often used by engineers and chemists in design, both to compute the change in energy resulting from a photon absorption and to determine the frequency of the light emitted from a given photon emission. For example, the emission spectrum of a gas-discharge lamp can be altered by filling it with (mixtures of) gases with different electronic energy level configurations.

Under some conditions, an energy transition can be excited by "two" photons that individually would be insufficient. This allows for higher resolution microscopy, because the sample absorbs energy only in the spectrum where two beams of different colors overlap significantly, which can be made much smaller than the excitation volume of a single beam (see two-photon excitation microscopy). Moreover, these photons cause less damage to the sample, since they are of lower energy.

In some cases, two energy transitions can be coupled so that, as one system absorbs a photon, another nearby system "steals" its energy and re-emits a photon of a different frequency. This is the basis of fluorescence resonance energy transfer, a technique that is used in molecular biology to study the interaction of suitable proteins.

Several different kinds of hardware random number generators involve the detection of single photons. In one example, for each bit in the random sequence that is to be produced, a photon is sent to a beam-splitter. In such a situation, there are two possible outcomes of equal probability. The actual outcome is used to determine whether the next bit in the sequence is "0" or "1".

Much research has been devoted to applications of photons in the field of quantum optics. Photons seem well-suited to be elements of an extremely fast quantum computer, and the quantum entanglement of photons is a focus of research. Nonlinear optical processes are another active research area, with topics such as two-photon absorption, self-phase modulation, modulational instability and optical parametric oscillators. However, such processes generally do not require the assumption of photons "per se"; they may often be modeled by treating atoms as nonlinear oscillators. The nonlinear process of spontaneous parametric down conversion is often used to produce single-photon states. Finally, photons are essential in some aspects of optical communication, especially for quantum cryptography.

Two-photon physics studies interactions between photons, which are rare. In 2018, MIT researchers announced the discovery of bound photon triplets, which may involve polaritons.

By date of publication:
Education with single photons:



</doc>
<doc id="23537" url="https://en.wikipedia.org/wiki?curid=23537" title="Philipp Franz von Siebold">
Philipp Franz von Siebold

Philipp Franz Balthasar von Siebold (17 February 1796 – 18 October 1866) was a German physician, botanist, and traveler. He achieved prominence by his studies of Japanese flora and fauna and the introduction of Western medicine in Japan. He was the father of the first female Japanese doctor, Kusumoto Ine.

Born into a family of doctors and professors of medicine in Würzburg (then in the Bishopric of Würzburg, later part of Bavaria), Siebold initially studied medicine at University of Würzburg from November 1815, where he became a member of the Corps Moenania Würzburg. One of his professors was Franz Xaver Heller (1775–1840), author of the " ("Flora of the Grand Duchy of Würzburg", 1810–1811). Ignaz Döllinger (1770–1841), his professor of anatomy and physiology, however, most influenced him. Döllinger was one of the first professors to understand and treat medicine as a natural science. Siebold stayed with Döllinger, where he came in regular contact with other scientists. He read the books of Humboldt, a famous naturalist and explorer, which probably raised his desire to travel to distant lands. Philipp Franz von Siebold became a physician by earning his M.D. degree in 1820. He initially practiced medicine in Heidingsfeld, in the Kingdom of Bavaria, now part of Würzburg.

Invited to Holland by an acquaintance of his family, Siebold applied for a position as a military physician, which would enable him to travel to the Dutch colonies. He entered the Dutch military service on June 19, 1822, and was appointed as ship's surgeon on the frigate "Adriana", sailing from Rotterdam to Batavia (present-day Jakarta) in the Dutch East Indies (now called Indonesia). On his trip to Batavia on the frigate "Adriana", Siebold practiced his knowledge of the Dutch language and also rapidly learned Malay, and during the long voyage he began a collection of marine fauna. He arrived in Batavia on February 18, 1823.

As an army medical officer, Siebold was posted to an artillery unit. However, he was given a room for a few weeks at the residence of the Governor-General of the Dutch East Indies, Baron Godert van der Capellen, to recover from an illness. With his erudition, he impressed the Governor-General, and also the director of the botanical garden at Buitenzorg (now Bogor), Caspar Georg Carl Reinwardt. These men sensed in Siebold a worthy successor to Engelbert Kaempfer and Carl Peter Thunberg, two former resident physicians at Dejima, a Dutch trading post in Japan, the latter of whom was the author of "". The Batavian Academy of Arts and Sciences soon elected Siebold as a member.

On 28 June 1823, after only a few months in the Dutch East Indies, Siebold was posted as resident physician and scientist to Dejima, a small artificial island and trading post at Nagasaki, and arrived there on 11 August 1823. During an eventful voyage to Japan he only just escaped drowning during a typhoon in the East China Sea. As only a very small number of Dutch personnel were allowed to live on this island, the posts of physician and scientist had to be combined. Dejima had been in the possession of the Dutch East India Company (known as the VOC) since the 17th century, but the Company had gone bankrupt in 1798, after which a trading post was operated there by the Dutch state for political considerations, with notable benefits to the Japanese.

The European tradition of sending doctors with botanical training to Japan was a long one. Sent on a mission by the Dutch East India Company, Engelbert Kaempfer (1651–1716), a German physician and botanist who lived in Japan from 1690 until 1692, ushered in this tradition of a combination of physician and botanist. The Dutch East India Company did not, however, actually employ the Swedish botanist and physician Carl Peter Thunberg (1743–1828), who had arrived in Japan in 1775.

Japanese scientists invited Siebold to show them the marvels of western science, and he learned in return through them much about the Japanese and their customs. After curing an influential local officer, Siebold gained the permission to leave the trade post. He used this opportunity to treat Japanese patients in the greater area around the trade post. Siebold is credited with the introduction of vaccination and pathological anatomy for the first time in Japan.

In 1824, Siebold started a medical school in Nagasaki, the "Narutaki-juku", that grew into a meeting place for around fifty "students". They helped him in his botanical and naturalistic studies. The Dutch language became the "lingua franca" (common spoken language) for these academic and scholarly contacts for a generation, until the Meiji Restoration.

His patients paid him in kind with a variety of objects and artifacts that would later gain historical significance. These everyday objects later became the basis of his large ethnographic collection, which consisted of everyday household goods, woodblock prints, tools and hand-crafted objects used by the Japanese people.

During his stay in Japan, Siebold "lived together" with Kusumoto Taki (楠本滝), who gave birth to their daughter Kusumoto (O-)Ine in 1827. Siebold used to call his wife "Otakusa" (probably derived from O-Taki-san) and named a "Hydrangea" after her. Kusumoto Ine eventually became the first Japanese woman known to have received a physician's training and became a highly regarded practicing physician and court physician to the Empress in 1882. She died at court in 1903.

His main interest, however, focused on the study of Japanese fauna and flora. He collected as much material as he could. Starting a small botanical garden behind his home (there was not much room on the small island) Siebold amassed over 1,000 native plants. In a specially built glasshouse he cultivated the Japanese plants to endure the Dutch climate. Local Japanese artists like Kawahara Keiga drew and painted images of these plants, creating botanical illustrations but also images of the daily life in Japan, which complemented his ethnographic collection. He hired Japanese hunters to track rare animals and collect specimens. Many specimens were collected with the help of his Japanese collaborators Keisuke Ito (1803–1901), Mizutani Sugeroku (1779–1833), Ōkochi Zonshin (1796–1882) and Katsuragawa Hoken (1797–1844), a physician to the "shōgun". As well, Siebold's assistant and later successor, Heinrich Bürger (1806–1858), proved to be indispensable in carrying on Siebold's work in Japan.

Siebold first introduced to Europe such familiar garden-plants as the "Hosta" and the "Hydrangea otaksa". Unknown to the Japanese, he was also able to smuggle out germinative seeds of tea plants to the botanical garden "" in Batavia. Through this single act, he started the tea culture in Java, a Dutch colony at the time. Until then Japan had strictly guarded the trade in tea plants. Remarkably, in 1833, Java already could boast a half million tea plants.

He also introduced Japanese knotweed ("Fallopia japonica"), which has become a highly invasive weed in Europe and North America. All derive from a single female plant collected by Siebold.

During his stay at Dejima, Siebold sent three shipments with an unknown number of herbarium specimens to Leiden, Ghent, Brussels and Antwerp. The shipment to Leiden contained the first specimens of the Japanese giant salamander ("Andrias japonicus") to be sent to Europe.

In 1825 the government of the Dutch-Indies provided him with two assistants: apothecary and mineralogist Heinrich Bürger (his later successor) and the painter Carl Hubert de Villeneuve. Each would prove to be useful to Siebold's efforts that ranged from ethnographical to botanical to horticultural, when attempting to document the exotic Eastern Japanese experience. De Villeneuve taught Kawahara the techniques of Western painting.

Reportedly, Siebold was not the easiest man to deal with. He was in continuous conflict with his Dutch superiors who felt he was arrogant. This threat of conflict resulted in his recall in July 1827 back to Batavia. But the ship, the "Cornelis Houtman", sent to carry him back to Batavia, was thrown ashore by a typhoon in Nagasaki bay. The same storm badly damaged Dejima and destroyed Siebold's botanical garden. Repaired, the "Cornelis Houtman" was refloated. It left for Batavia with 89 crates of Siebold's salvaged botanical collection, but Siebold himself remained behind in Dejima.

In 1826 Siebold made the court journey to Edo. During this long trip he collected many plants and animals. But he also obtained from the court astronomer Takahashi Kageyasu several detailed maps of Japan and Korea (written by Inō Tadataka), an act strictly forbidden by the Japanese government. When the Japanese discovered, by accident, that Siebold had a map of the northern parts of Japan, the government accused him of high treason and of being a spy for Russia.

The Japanese placed Siebold under house arrest and expelled him from Japan on 22 October 1829. Satisfied that his Japanese collaborators would continue his work, he journeyed back on the frigate "Java" to his former residence, Batavia, in possession of his enormous collection of thousands of animals and plants, his books and his maps. The botanical garden of "" would soon house Siebold's surviving, living flora collection of 2,000 plants. He arrived in the Netherlands on 7 July 1830. His stay in Japan and Batavia had lasted for a period of eight years.

Philipp Franz von Siebold arrived in the Netherlands in 1830, just at a time when political troubles erupted in Brussels, leading soon to Belgian independence. Hastily he salvaged his ethnographic collections in Antwerp and his herbarium specimens in Brussels and took them to Leiden, helped by Johann Baptist Fischer. He left behind his botanical collections of living plants that were sent to the University of Ghent. The consequent expansion of this collection of rare and exotic plants led to the horticultural fame of Ghent. In gratitude the University of Ghent presented him in 1841 with specimens of every plant from his original collection.

Siebold settled in Leiden, taking with him the major part of his collection. The "Philipp Franz von Siebold collection", containing many type specimens, was the earliest botanical collection from Japan. Even today, it still remains a subject of ongoing research, a testimony to the depth of work undertaken by Siebold. It contained about 12,000 specimens, from which he could describe only about 2,300 species. The whole collection was purchased for a handsome amount by the Dutch government. Siebold was also granted a substantial annual allowance by the Dutch King William II and was appointed "Advisor to the King for Japanese Affairs". In 1842, the King even raised Siebold to the nobility as an esquire.

The "Siebold collection" opened to the public in 1831. He founded a museum in his home in 1837. This small, private museum would eventually evolve into the National Museum of Ethnology in Leiden. Siebold's successor in Japan, Heinrich Bürger, sent Siebold three more shipments of herbarium specimens collected in Japan. This flora collection formed the basis of the Japanese collections of the National Herbarium of the Netherlands in Leiden, while the zoological specimens Siebold collected were kept by the Rijksmuseum van Natuurlijke Historie ("National Museum of Natural History") in Leiden, which later became Naturalis. Both institutions merged into Naturalis Biodiversity Center in 2010, which now maintains the entire natural history collection that Siebold brought back to Leiden.

In 1845 Siebold married Helene von Gagern (1820–1877), they had three sons and two daughters.

During his stay in Leiden, Siebold wrote "Nippon" in 1832, the first part of a volume of a richly illustrated ethnographical and geographical work on Japan. The 'Archiv zur Beschreibung Nippons' also contained a report of his journey to the Shogunate Court at Edo. He wrote six further parts, the last ones published posthumously in 1882; his sons published an edited and lower-priced reprint in 1887.

The " appeared between 1833 and 1841. This work was co-authored by Joseph Hoffmann and Kuo Cheng-Chang, a Javanese of Chinese extraction, who had journeyed along with Siebold from Batavia. It contained a survey of Japanese literature and a Chinese, Japanese and Korean dictionary.

The zoologists Coenraad Temminck (1777–1858), Hermann Schlegel (1804–1884), and Wilhem de Haan (1801–1855) scientifically described and documented Siebold's collection of Japanese animals. The ', a series of monographs published between 1833 and 1850, was mainly based on Siebold's collection, making the Japanese fauna the best-described non-European fauna – "a remarkable feat". A significant part of the ' was also based on the collections of Siebold's successor on Dejima, Heinrich Bürger.

Siebold wrote his "" in collaboration with the German botanist Joseph Gerhard Zuccarini (1797–1848). It first appeared in 1835, but the work was not completed until after his death, finished in 1870 by F.A.W. Miquel (1811–1871), director of the Rijksherbarium in Leiden. This work expanded Siebold's scientific fame from Japan to Europe.

From the Hortus Botanicus Leiden – the botanical garden of Leiden – many of Siebold's plants spread to Europe and from there to other countries. "Hosta" and "Hortensia", "Azalea", and the Japanese butterbur and the coltsfoot as well as the Japanese larch began to inhabit gardens across the world.

After his return to Europe, Siebold tried to exploit his knowledge of Japan. Whilst living in Boppard, from 1852 he corresponded with Russian diplomats such as Baron von Budberg-Bönninghausen, the Russian ambassador to Prussia, which resulted in an invitation to go to St Petersburg to advise the Russian government how to open trade relations with Japan. Though still employed by the Dutch government he did not inform the Dutch of this voyage until after his return. 

American Naval Commodore Matthew C. Perry consulted Siebold in advance of his voyage to Japan in 1854.

In 1858, the Japanese government lifted the banishment of Siebold. He returned to Japan in 1859 as an adviser to the Agent of the Dutch Trading Society (Nederlandsche Handel-Maatschappij) in Nagasaki, Albert Bauduin. After two years the connection with the Trading Society was severed as the advice of Siebold was considered to be of no value. In Nagasaki he fathered another child with one of his female servants. 

In 1861 Siebold organised his appointment as an adviser to the Japanese government and went in that function to Edo. There he tried to obtain a position between the foreign representatives and the Japanese government. As he had been specially admonished by the Dutch authorities before going to Japan that he was to abstain from all interference in politics, the Dutch Consul General in Japan, J.K. de Wit, was ordered to ask Siebold's removal. Siebold was ordered to return to Batavia and from there he returned to Europe. 

After his return he asked the Dutch government to employ him as Consul General in Japan but the Dutch government severed all relations with Siebold who had a huge debt because of loans given to him, except for the payment of his pension.

Siebold kept trying to organise another voyage to Japan. After he did not succeed in gaining employment with the Russian government, he went to Paris in 1865 to try to interest the French government in funding another expedition to Japan, but failed. He died in Munich on 18 October 1866.

The botanical and horticultural spheres of influence have honored Philipp Franz von Siebold by naming some of the very garden-worthy plants that he studied after him. Examples include:



Though he is well known in Japan, where he is called "Shiboruto-san", and although mentioned in the relevant schoolbooks, Siebold is almost unknown elsewhere, except among gardeners who admire the many plants whose names incorporate "sieboldii" and "sieboldiana". The Hortus Botanicus in Leiden has recently laid out the "Von Siebold Memorial Garden", a Japanese garden with plants sent by Siebold. The garden was laid out under a 150-year-old "Zelkova serrata" tree dating from Siebold's lifetime. Japanese visitors come and visit this garden, to pay their respect for him.

Although he was disillusioned by what he perceived as a lack of appreciation for Japan and his contributions to its understanding, a testimony of the remarkable character of Siebold is found in museums that honor him.

His collections laid the foundation for the ethnographic museums of Munich and Leiden. Alexander von Siebold, his son by his European wife, donated much of the material left behind after Siebold's death in Würzburg to the British Museum in London. The Royal Scientific Academy of St. Petersburg purchased 600 colored plates of the "".

Another son, Heinrich (or Henry) von Siebold (1852–1908), continued part of his father's research. He is recognized, together with Edward S. Morse, as one of the founders of modern archaeological efforts in Japan.


The standard author abbreviation Siebold is used to indicate Philipp Franz von Siebold as the author when citing a botanical name.




</doc>
<doc id="23538" url="https://en.wikipedia.org/wiki?curid=23538" title="Probability interpretations">
Probability interpretations

The word probability has been used in a variety of ways since it was first applied to the mathematical study of games of chance. Does probability measure the real, physical tendency of something to occur or is it a measure of how strongly one believes it will occur, or does it draw on both these elements? In answering such questions, mathematicians interpret the probability values of probability theory.

There are two broad categories of probability interpretations which can be called "physical" and "evidential" probabilities. Physical probabilities, which are also called objective or frequency probabilities, are associated with random physical systems such as roulette wheels, rolling dice and radioactive atoms. In such systems, a given type of event (such as a die yielding a six) tends to occur at a persistent rate, or "relative frequency", in a long run of trials. Physical probabilities either explain, or are invoked to explain, these stable frequencies. The two main kinds of theory of physical probability are frequentist accounts (such as those of Venn, Reichenbach and von Mises) and propensity accounts (such as those of Popper, Miller, Giere and Fetzer).

Evidential probability, also called Bayesian probability, can be assigned to any statement whatsoever, even when no random process is involved, as a way to represent its subjective plausibility, or the degree to which the statement is supported by the available evidence. On most accounts, evidential probabilities are considered to be degrees of belief, defined in terms of dispositions to gamble at certain odds. The four main evidential interpretations are the classical (e.g. Laplace's) interpretation, the subjective interpretation (de Finetti and Savage), the epistemic or inductive interpretation (Ramsey, Cox) and the logical interpretation (Keynes and Carnap). There are also evidential interpretations of probability covering groups, which are often labelled as 'intersubjective' (proposed by Gillies and Rowbottom).

Some interpretations of probability are associated with approaches to statistical inference, including theories of estimation and hypothesis testing. The physical interpretation, for example, is taken by followers of "frequentist" statistical methods, such as Ronald Fisher, Jerzy Neyman and Egon Pearson. Statisticians of the opposing Bayesian school typically accept the existence and importance of physical probabilities, but also consider the calculation of evidential probabilities to be both valid and necessary in statistics. This article, however, focuses on the interpretations of probability rather than theories of statistical inference.

The terminology of this topic is rather confusing, in part because probabilities are studied within a variety of academic fields. The word "frequentist" is especially tricky. To philosophers it refers to a particular theory of physical probability, one that has more or less been abandoned. To scientists, on the other hand, "frequentist probability" is just another name for physical (or objective) probability. Those who promote Bayesian inference view "frequentist statistics" as an approach to statistical inference that recognises only physical probabilities. Also the word "objective", as applied to probability, sometimes means exactly what "physical" means here, but is also used of evidential probabilities that are fixed by rational constraints, such as logical and epistemic probabilities.

The philosophy of probability presents problems chiefly in matters of epistemology and the uneasy interface between mathematical concepts and ordinary language as it is used by non-mathematicians.
Probability theory is an established field of study in mathematics. It has its origins in correspondence discussing the mathematics of games of chance between Blaise Pascal and Pierre de Fermat in the seventeenth century, and was formalized and rendered axiomatic as a distinct branch of mathematics by Andrey Kolmogorov in the twentieth century. In axiomatic form, mathematical statements about probability theory carry the same sort of epistemological confidence within the philosophy of mathematics as are shared by other mathematical statements.

The mathematical analysis originated in observations of the behaviour of game equipment such as playing cards and dice, which are designed specifically to introduce random and equalized elements; in mathematical terms, they are subjects of indifference. This is not the only way probabilistic statements are used in ordinary human language: when people say that ""it will probably rain"", they typically do not mean that the outcome of rain versus not-rain is a random factor that the odds currently favor; instead, such statements are perhaps better understood as qualifying their expectation of rain with a degree of confidence. Likewise, when it is written that "the most probable explanation" of the name of Ludlow, Massachusetts "is that it was named after Roger Ludlow", what is meant here is not that Roger Ludlow is favored by a random factor, but rather that this is the most plausible explanation of the evidence, which admits other, less likely explanations.

Thomas Bayes attempted to provide a logic that could handle varying degrees of confidence; as such, Bayesian probability is an attempt to recast the representation of probabilistic statements as an expression of the degree of confidence by which the beliefs they express are held.

Though probability initially had somewhat mundane motivations, its modern influence and use is widespread ranging from evidence-based medicine, through Six sigma, all the way to the Probabilistically checkable proof and the String theory landscape.

The first attempt at mathematical rigour in the field of probability, championed by Pierre-Simon Laplace, is now known as the classical definition. Developed from studies of games of chance (such as rolling dice) it states that probability is shared equally between all the possible outcomes, provided these outcomes can be deemed equally likely. (3.1)

This can be represented mathematically as follows:
If a random experiment can result in N mutually exclusive and equally likely outcomes and if N of these outcomes result in the occurrence of the event A, the probability of A is defined by

There are two clear limitations to the classical definition. Firstly, it is applicable only to situations in which there is only a 'finite' number of possible outcomes. But some important random experiments, such as tossing a coin until it rises heads, give rise to an infinite set of outcomes. And secondly, you need to determine in advance that all the possible outcomes are equally likely without relying on the notion of probability to avoid circularity—for instance, by symmetry considerations.

Frequentists posit that the probability of an event is its relative frequency over time, (3.4) i.e., its relative frequency of occurrence after repeating a process a large number of times under similar conditions. This is also known as aleatory probability. The events are assumed to be governed by some random physical phenomena, which are either phenomena that are predictable, in principle, with sufficient information (see determinism); or phenomena which are essentially unpredictable. Examples of the first kind include tossing dice or spinning a roulette wheel; an example of the second kind is radioactive decay. In the case of tossing a fair coin, frequentists say that the probability of getting a heads is 1/2, not because there are two equally likely outcomes but because repeated series of large numbers of trials demonstrate that the empirical frequency converges to the limit 1/2 as the number of trials goes to infinity.

If we denote by formula_2 the number of occurrences of an event formula_3 in formula_4 trials, then if formula_5 we say that "formula_6.

The frequentist view has its own problems. It is of course impossible to actually perform an infinity of repetitions of a random experiment to determine the probability of an event. But if only a finite number of repetitions of the process are performed, different relative frequencies will appear in different series of trials. If these relative frequencies are to define the probability, the probability will be slightly different every time it is measured. But the real probability should be the same every time. If we acknowledge the fact that we only can measure a probability with some error of measurement attached, we still get into problems as the error of measurement can only be expressed as a probability, the very concept we are trying to define. This renders even the frequency definition circular; see for example “What is the Chance of an Earthquake?” 

Subjectivists, also known as Bayesians or followers of epistemic probability, give the notion of probability a subjective status by regarding it as a measure of the 'degree of belief' of the individual assessing the uncertainty of a particular situation. Epistemic or subjective probability is sometimes called credence, as opposed to the term chance for a propensity probability.

Some examples of epistemic probability are to assign a probability to the proposition that a proposed law of physics is true, and to determine how probable it is that a suspect committed a crime, based on the evidence presented.

Gambling odds don't reflect the bookies' belief in a likely winner, so much as the other bettors' belief, because the bettors are actually betting against one another. The odds are set based on how many people have bet on a possible winner, so that even if the high odds players always win, the bookies will always make their percentages anyway.

The use of Bayesian probability raises the philosophical debate as to whether it can contribute valid justifications of belief.

Bayesians point to the work of Ramsey (p 182) and de Finetti (p 103) as proving that subjective beliefs must follow the laws of probability if they are to be coherent. Evidence casts doubt that humans will have coherent beliefs.

The use of Bayesian probability involves specifying a prior probability. This may be obtained from consideration of whether the required prior probability is greater or lesser than a reference probability associated with an urn model or a thought experiment. The issue is that for a given problem, multiple thought experiments could apply, and choosing one is a matter of judgement: different people may assign different prior probabilities, known as the reference class problem.
The "sunrise problem" provides an example.

Propensity theorists think of probability as a physical propensity, or disposition, or tendency of a given type of physical situation to yield an outcome of a certain kind or to yield a long run relative frequency of such an outcome. This kind of objective probability is sometimes called 'chance'.

Propensities, or chances, are not relative frequencies, but purported causes of the observed stable relative frequencies. Propensities are invoked to explain why repeating a certain kind of experiment will generate given outcome types at persistent rates, which are known as propensities or chances. Frequentists are unable to take this approach, since relative frequencies do not exist for single tosses of a coin, but only for large ensembles or collectives (see "single case possible" in the table above). In contrast, a propensitist is able to use the law of large numbers to explain the behaviour of long-run frequencies. This law, which is a consequence of the axioms of probability, says that if (for example) a coin is tossed repeatedly many times, in such a way that its probability of landing heads is the same on each toss, and the outcomes are probabilistically independent, then the relative frequency of heads will be close to the probability of heads on each single toss. This law allows that stable long-run frequencies are a manifestation of invariant "single-case" probabilities. In addition to explaining the emergence of stable relative frequencies, the idea of propensity is motivated by the desire to make sense of single-case probability attributions in quantum mechanics, such as the probability of decay of a particular atom at a particular time.

The main challenge facing propensity theories is to say exactly what propensity means. (And then, of course, to show that propensity thus defined has the required properties.) At present, unfortunately, none of the well-recognised accounts of propensity comes close to meeting this challenge.

A propensity theory of probability was given by Charles Sanders Peirce. A later propensity theory was proposed by philosopher Karl Popper, who had only slight acquaintance with the writings of C. S. Peirce, however. Popper noted that the outcome of a physical experiment is produced by a certain set of "generating conditions". When we repeat an experiment, as the saying goes, we really perform another experiment with a (more or less) similar set of generating conditions. To say that a set of generating conditions has propensity "p" of producing the outcome "E" means that those exact conditions, if repeated indefinitely, would produce an outcome sequence in which "E" occurred with limiting relative frequency "p". For Popper then, a deterministic experiment would have propensity 0 or 1 for each outcome, since those generating conditions would have same outcome on each trial. In other words, non-trivial propensities (those that differ from 0 and 1) only exist for genuinely indeterministic experiments.

A number of other philosophers, including David Miller and Donald A. Gillies, have proposed propensity theories somewhat similar to Popper's.

Other propensity theorists (e.g. Ronald Giere) do not explicitly define propensities at all, but rather see propensity as defined by the theoretical role it plays in science. They argued, for example, that physical magnitudes such as electrical charge cannot be explicitly defined either, in terms of more basic things, but only in terms of what they do (such as attracting and repelling other electrical charges). In a similar way, propensity is whatever fills the various roles that physical probability plays in science.

What roles does physical probability play in science? What are its properties? One central property of chance is that, when known, it constrains rational belief to take the same numerical value. David Lewis called this the "Principal Principle", (3.3 & 3.5) a term that philosophers have mostly adopted. For example, suppose you are certain that a particular biased coin has propensity 0.32 to land heads every time it is tossed. What is then the correct price for a gamble that pays $1 if the coin lands heads, and nothing otherwise? According to the Principal Principle, the fair price is 32 cents.

It is widely recognized that the term "probability" is sometimes used in contexts where it has nothing to do with physical randomness. Consider, for example, the claim that the extinction of the dinosaurs was probably caused by a large meteorite hitting the earth. Statements such as "Hypothesis H is probably true" have been interpreted to mean that the (presently available) empirical evidence (E, say) supports H to a high degree. This degree of support of H by E has been called the logical probability of H given E, or the epistemic probability of H given E, or the inductive probability of H given E.

The differences between these interpretations are rather small, and may seem inconsequential. One of the main points of disagreement lies in the relation between probability and belief. Logical probabilities are conceived (for example in Keynes' Treatise on Probability) to be objective, logical relations between propositions (or sentences), and hence not to depend in any way upon belief. They are degrees of (partial) entailment, or degrees of logical consequence, not degrees of belief. (They do, nevertheless, dictate proper degrees of belief, as is discussed below.) Frank P. Ramsey, on the other hand, was skeptical about the existence of such objective logical relations and argued that (evidential) probability is "the logic of partial belief". (p 157) In other words, Ramsey held that epistemic probabilities simply "are" degrees of rational belief, rather than being logical relations that merely "constrain" degrees of rational belief.

Another point of disagreement concerns the "uniqueness" of evidential probability, relative to a given state of knowledge. Rudolf Carnap held, for example, that logical principles always determine a unique logical probability for any statement, relative to any body of evidence. Ramsey, by contrast, thought that while degrees of belief are subject to some rational constraints (such as, but not limited to, the axioms of probability) these constraints usually do not determine a unique value. Rational people, in other words, may differ somewhat in their degrees of belief, even if they all have the same information.

An alternative account of probability emphasizes the role of "prediction" – predicting future observations on the basis of past observations, not on unobservable parameters. In its modern form, it is mainly in the Bayesian vein. This was the main function of probability before the 20th century,
but fell out of favor compared to the parametric approach, which modeled phenomena as a physical system that was observed with error, such as in celestial mechanics.

The modern predictive approach was pioneered by Bruno de Finetti, with the central idea of exchangeability – that future observations should behave like past observations. This view came to the attention of the Anglophone world with the 1974 translation of de Finetti's book, and has
since been propounded by such statisticians as Seymour Geisser.

The mathematics of probability can be developed on an entirely axiomatic basis that is independent of any interpretation: see the articles on probability theory and probability axioms for a detailed treatment.





</doc>
<doc id="23539" url="https://en.wikipedia.org/wiki?curid=23539" title="Probability axioms">
Probability axioms

In Kolmogorov's probability theory, the probability "P" of some event "E", denoted formula_1, is usually defined such that "P" satisfies the Kolmogorov axioms, named after the Russian mathematician Andrey Kolmogorov, which are described below.

These assumptions can be summarised as follows: Let (Ω, "F", "P") be a measure space with "P"(Ω) = 1. Then (Ω, "F", "P") is a probability space, with sample space Ω, event space "F" and probability measure "P".

An alternative approach to formalising probability, favoured by some Bayesians, is given by Cox's theorem.

The probability of an event is a non-negative real number:

where formula_3 is the event space. In particular, formula_1 is always finite, in contrast with more general measure theory. Theories which assign negative probability relax the first axiom.

This is the assumption of unit measure: that the probability that at least one of the elementary events in the entire sample space will occur is 1.

This is the assumption of σ-additivity:
Some authors consider merely finitely additive probability spaces, in which case one just needs an algebra of sets, rather than a σ-algebra. Quasiprobability distributions in general relax the third axiom.

From the Kolmogorov axioms, one can deduce other useful rules for calculating probabilities.

In some cases, formula_9 is not the only event with probability 0.

If A is a subset of, or equal to B, then the probability of A is less than, or equal to the probability of B.

It immediately follows from the monotonicity property that

The proofs of these properties are both interesting and insightful. They illustrate the power of the third axiom, and its interaction with the remaining two axioms. When studying axiomatic probability theory, many deep consequences follow from merely these three axioms.
In order to verify the monotonicity property, we set formula_12 and formula_13, where formula_14 and formula_15 for formula_16. It is easy to see that the sets formula_17 are pairwise disjoint and formula_18. Hence, we obtain from the third axiom that
Since the left-hand side of this equation is a series of non-negative numbers, and since it converges to formula_20 which is finite, we obtain both formula_21 and formula_22.
The second part of the statement is seen by contradiction: if formula_23 then the left hand side is not less than infinity
If formula_25 then we obtain a contradiction, because the sum does not exceed formula_20 which is finite. Thus, formula_27. We have shown as a byproduct of the proof of monotonicity that formula_22.

Another important property is:

This is called the addition law of probability, or the sum rule.
That is, the probability that "A" "or" "B" will happen is the sum of the probabilities that "A" will happen and that "B" will happen, minus the probability that both "A" "and" "B" will happen. The proof of this is as follows:

Firstly,

So,

Also, 

and eliminating formula_34 from both equations gives us the desired result.

An extension of the addition law to any number of sets is the inclusion–exclusion principle.

Setting "B" to the complement "A" of "A" in the addition law gives

That is, the probability that any event will "not" happen (or the event's complement) is 1 minus the probability that it will.

Consider a single coin-toss, and assume that the coin will either land heads (H) or tails (T) (but not both). No assumption is made as to whether the coin is fair.

We may define:

Kolmogorov's axioms imply that:

The probability of "neither" heads "nor" tails, is 0.

The probability of "either" heads "or" tails, is 1.

The sum of the probability of heads and the probability of tails, is 1.





</doc>
<doc id="23542" url="https://en.wikipedia.org/wiki?curid=23542" title="Probability theory">
Probability theory

Probability theory is the branch of mathematics concerned with probability. Although there are several different probability interpretations, probability theory treats the concept in a rigorous mathematical manner by expressing it through a set of axioms. Typically these axioms formalise probability in terms of a probability space, which assigns a measure taking values between 0 and 1, termed the probability measure, to a set of outcomes called the sample space. Any specified subset of these outcomes is called an event.

Central subjects in probability theory include discrete and continuous random variables, probability distributions, and stochastic processes, which provide mathematical abstractions of non-deterministic or uncertain processes or measured quantities that may either be single occurrences or evolve over time in a random fashion.

Although it is not possible to perfectly predict random events, much can be said about their behavior. Two major results in probability theory describing such behaviour are the law of large numbers and the central limit theorem.

As a mathematical foundation for statistics, probability theory is essential to many human activities that involve quantitative analysis of data. Methods of probability theory also apply to descriptions of complex systems given only partial knowledge of their state, as in statistical mechanics. A great discovery of twentieth-century physics was the probabilistic nature of physical phenomena at atomic scales, described in quantum mechanics.

The mathematical theory of probability has its roots in attempts to analyze games of chance by Gerolamo Cardano in the sixteenth century, and by Pierre de Fermat and Blaise Pascal in the seventeenth century (for example the "problem of points"). Christiaan Huygens published a book on the subject in 1657 and in the 19th century, Pierre Laplace completed what is today considered the classic interpretation.

Initially, probability theory mainly considered discrete events, and its methods were mainly combinatorial. Eventually, analytical considerations compelled the incorporation of continuous variables into the theory.

This culminated in modern probability theory, on foundations laid by Andrey Nikolaevich Kolmogorov. Kolmogorov combined the notion of sample space, introduced by Richard von Mises, and measure theory and presented his axiom system for probability theory in 1933. This became the mostly undisputed axiomatic basis for modern probability theory; but, alternatives exist, such as the adoption of finite rather than countable additivity by Bruno de Finetti.

Most introductions to probability theory treat discrete probability distributions and continuous probability distributions separately. The more mathematically advanced measure theory-based treatment of probability covers the discrete, continuous, a mix of the two, and more.

Consider an experiment that can produce a number of outcomes. The set of all outcomes is called the "sample space" of the experiment. The "power set" of the sample space (or equivalently, the event space) is formed by considering all different collections of possible results. For example, rolling an honest die produces one of six possible results. One collection of possible results corresponds to getting an odd number. Thus, the subset {1,3,5} is an element of the power set of the sample space of die rolls. These collections are called "events". In this case, {1,3,5} is the event that the die falls on some odd number. If the results that actually occur fall in a given event, that event is said to have occurred.

Probability is a way of assigning every "event" a value between zero and one, with the requirement that the event made up of all possible results (in our example, the event {1,2,3,4,5,6}) be assigned a value of one. To qualify as a probability distribution, the assignment of values must satisfy the requirement that if you look at a collection of mutually exclusive events (events that contain no common results, e.g., the events {1,6}, {3}, and {2,4} are all mutually exclusive), the probability that any of these events occurs is given by the sum of the probabilities of the events.

The probability that any one of the events {1,6}, {3}, or {2,4} will occur is 5/6. This is the same as saying that the probability of event {1,2,3,4,6} is 5/6. This event encompasses the possibility of any number except five being rolled. The mutually exclusive event {5} has a probability of 1/6, and the event {1,2,3,4,5,6} has a probability of 1, that is, absolute certainty.

When doing calculations using the outcomes of an experiment, it is necessary that all those elementary events have a number assigned to them. This is done using a random variable. A random variable is a function that assigns to each elementary event in the sample space a real number. This function is usually denoted by a capital letter. In the case of a die, the assignment of a number to a certain elementary events is obvious, namely 1 for 1, 2 for 2, etc. This is not always the case. For example, when flipping a coin the two possible outcomes are "heads" and "tails". In this example, the random variable "X" could assign to the outcome "heads" the number "0" (formula_1) and to the outcome "tails" the number "1" (formula_2).

Discrete probability theory deals with events that occur in countable sample spaces.

Examples: Throwing dice, experiments with decks of cards, random walk, and tossing coins

Classical definition:
Initially the probability of an event to occur was defined as the number of cases favorable for the event, over the number of total outcomes possible in an equiprobable sample space: see Classical definition of probability.

For example, if the event is "occurrence of an even number when a die is rolled", the probability is given by formula_3, since 3 faces out of the 6 have even numbers and each face has the same probability of appearing.

Modern definition:
The modern definition starts with a finite or countable set called the sample space, which relates to the set of all "possible outcomes" in classical sense, denoted by formula_4. It is then assumed that for each element formula_5, an intrinsic "probability" value formula_6 is attached, which satisfies the following properties:

That is, the probability function "f"("x") lies between zero and one for every value of "x" in the sample space "Ω", and the sum of "f"("x") over all values "x" in the sample space "Ω" is equal to 1. An event is defined as any subset formula_9 of the sample space formula_10. The probability of the event formula_9 is defined as

So, the probability of the entire sample space is 1, and the probability of the null event is 0.

The function formula_6 mapping a point in the sample space to the "probability" value is called a probability mass function abbreviated as pmf. The modern definition does not try to answer how probability mass functions are obtained; instead, it builds a theory that assumes their existence.

Continuous probability theory deals with events that occur in a continuous sample space.

Classical definition:
The classical definition breaks down when confronted with the continuous case. See Bertrand's paradox.

Modern definition:
If the outcome space of a random variable "X" is the set of real numbers (formula_14) or a subset thereof, then a function called the cumulative distribution function (or cdf) formula_15 exists, defined by formula_16. That is, "F"("x") returns the probability that "X" will be less than or equal to "x".

The cdf necessarily satisfies the following properties.

If formula_15 is absolutely continuous, i.e., its derivative exists and integrating the derivative gives us the cdf back again, then the random variable "X" is said to have a probability density function or pdf or simply density formula_21

For a set formula_22, the probability of the random variable "X" being in formula_9 is

In case the probability density function exists, this can be written as

Whereas the "pdf" exists only for continuous random variables, the "cdf" exists for all random variables (including discrete random variables) that take values in formula_26

These concepts can be generalized for multidimensional cases on formula_27 and other continuous sample spaces.

The "raison d'être" of the measure-theoretic treatment of probability is that it unifies the discrete and the continuous cases, and makes the difference a question of which measure is used. Furthermore, it covers distributions that are neither discrete nor continuous nor mixtures of the two.

An example of such distributions could be a mix of discrete and continuous distributions—for example, a random variable that is 0 with probability 1/2, and takes a random value from a normal distribution with probability 1/2. It can still be studied to some extent by considering it to have a pdf of formula_28, where formula_29 is the Dirac delta function.

Other distributions may not even be a mix, for example, the Cantor distribution has no positive probability for any single point, neither does it have a density. The modern approach to probability theory solves these problems using measure theory to define the probability space:

Given any set formula_10 (also called sample space) and a σ-algebra formula_31 on it, a measure formula_32 defined on formula_31 is called a probability measure if formula_34

If formula_31 is the Borel σ-algebra on the set of real numbers, then there is a unique probability measure on formula_31 for any cdf, and vice versa. The measure corresponding to a cdf is said to be induced by the cdf. This measure coincides with the pmf for discrete variables and pdf for continuous variables, making the measure-theoretic approach free of fallacies.

The "probability" of a set formula_9 in the σ-algebra formula_31 is defined as

where the integration is with respect to the measure formula_40 induced by formula_41

Along with providing better understanding and unification of discrete and continuous probabilities, measure-theoretic treatment also allows us to work on probabilities outside formula_27, as in the theory of stochastic processes. For example, to study Brownian motion, probability is defined on a space of functions.

When it's convenient to work with a dominating measure, the Radon-Nikodym theorem is used to define a density as the Radon-Nikodym derivative of the probability distribution of interest with respect to this dominating measure. Discrete densities are usually defined as this derivative with respect to a counting measure over the set of all possible outcomes. Densities for absolutely continuous distributions are usually defined as this derivative with respect to the Lebesgue measure. If a theorem can be proved in this general setting, it holds for both discrete and continuous distributions as well as others; separate proofs are not required for discrete and continuous distributions.

Certain random variables occur very often in probability theory because they well describe many natural or physical processes. Their distributions, therefore, have gained "special importance" in probability theory. Some fundamental "discrete distributions" are the discrete uniform, Bernoulli, binomial, negative binomial, Poisson and geometric distributions. Important "continuous distributions" include the continuous uniform, normal, exponential, gamma and beta distributions.

In probability theory, there are several notions of convergence for random variables. They are listed below in the order of strength, i.e., any subsequent notion of convergence in the list implies convergence according to all of the preceding notions.




As the names indicate, weak convergence is weaker than strong convergence. In fact, strong convergence implies convergence in probability, and convergence in probability implies weak convergence. The reverse statements are not always true.

Common intuition suggests that if a fair coin is tossed many times, then "roughly" half of the time it will turn up "heads", and the other half it will turn up "tails". Furthermore, the more often the coin is tossed, the more likely it should be that the ratio of the number of "heads" to the number of "tails" will approach unity. Modern probability theory provides a formal version of this intuitive idea, known as the law of large numbers. This law is remarkable because it is not assumed in the foundations of probability theory, but instead emerges from these foundations as a theorem. Since it links theoretically derived probabilities to their actual frequency of occurrence in the real world, the law of large numbers is considered as a pillar in the history of statistical theory and has had widespread influence.
The law of large numbers (LLN) states that the sample average
of a sequence of independent and
identically distributed random variables formula_59 converges towards their common expectation formula_60, provided that the expectation of formula_61 is finite.

It is in the different forms of convergence of random variables that separates the "weak" and the "strong" law of large numbers

It follows from the LLN that if an event of probability "p" is observed repeatedly during independent experiments, the ratio of the observed frequency of that event to the total number of repetitions converges towards "p".

For example, if formula_66 are independent Bernoulli random variables taking values 1 with probability "p" and 0 with probability 1-"p", then formula_67 for all "i", so that formula_68 converges to "p" almost surely.

"The central limit theorem (CLT) is one of the great results of mathematics." (Chapter 18 in)
It explains the ubiquitous occurrence of the normal distribution in nature.

The theorem states that the average of many independent and identically distributed random variables with finite variance tends towards a normal distribution "irrespective" of the distribution followed by the original random variables. Formally, let formula_50 be independent random variables with mean formula_60 and variance formula_71 Then the sequence of random variables
converges in distribution to a standard normal random variable.

For some classes of random variables the classic central limit theorem works rather fast (see Berry–Esseen theorem), for example the distributions with finite first, second, and third moment from the exponential family; on the other hand, for some random variables of the heavy tail and fat tail variety, it works very slowly or may not work at all: in such cases one may use the Generalized Central Limit Theorem (GCLT).




</doc>
<doc id="23543" url="https://en.wikipedia.org/wiki?curid=23543" title="Probability distribution">
Probability distribution

In probability theory and statistics, a probability distribution is a mathematical function that provides the probabilities of occurrence of different possible outcomes in an experiment. In more technical terms, the probability distribution is a description of a random phenomenon in terms of the probabilities of events. For instance, if the random variable is used to denote the outcome of a coin toss ("the experiment"), then the probability distribution of would take the value 0.5 for , and 0.5 for (assuming the coin is fair). Examples of random phenomena can include the results of an experiment or survey.

A probability distribution is defined in terms of an underlying sample space, which is the set of all possible outcomes of the random phenomenon being observed. The sample space may be the set of real numbers or a higher-dimensional vector space, or it may be a list of non-numerical values; for example, the sample space of a coin flip would be .

Probability distributions are generally divided into two classes. A discrete probability distribution (applicable to the scenarios where the set of possible outcomes is discrete, such as a coin toss or a roll of dice) can be encoded by a discrete list of the probabilities of the outcomes, known as a probability mass function. On the other hand, a continuous probability distribution (applicable to the scenarios where the set of possible outcomes can take on values in a continuous range (e.g. real numbers), such as the temperature on a given day) is typically described by probability density functions (with the probability of any individual outcome actually being 0). The normal distribution is a commonly encountered continuous probability distribution. More complex experiments, such as those involving stochastic processes defined in continuous time, may demand the use of more general probability measures.

A probability distribution whose sample space is the set of real numbers is called univariate, while a distribution whose sample space is a vector space is called multivariate. A univariate distribution gives the probabilities of a single random variable taking on various alternative values; a multivariate distribution (a joint probability distribution) gives the probabilities of a random vector – a list of two or more random variables – taking on various combinations of values. Important and commonly encountered univariate probability distributions include the binomial distribution, the hypergeometric distribution, and the normal distribution. The multivariate normal distribution is a commonly encountered multivariate distribution.

To define probability distributions for the simplest cases, one needs to distinguish between discrete and continuous random variables. In the discrete case, it is sufficient to specify a probability mass function formula_1 assigning a probability to each possible outcome: for example, when throwing a fair dice, each of the six values 1 to 6 has the probability 1/6. The probability of an event is then defined to be the sum of the probabilities of the outcomes that satisfy the event; for example, the probability of the event "the dice rolls an even value" is 

In contrast, when a random variable takes values from a continuum then typically, any individual outcome has probability zero and only events that include infinitely many outcomes, such as intervals, can have positive probability. For example, the probability that a given object weighs "exactly" 500 g is zero, because the probability of measuring exactly 500 g tends to zero as the accuracy of our measuring instruments increases. Nevertheless, in quality control one might demand that the probability of a "500 g" package containing between 490 g and 510 g should be no less than 98%, and this demand is less sensitive to the accuracy of measurement instruments.

Continuous probability distributions can be described in several ways. The probability density function describes the infinitesimal probability of any given value, and the probability that the outcome lies in a given interval can be computed by integrating the probability density function over that interval. On the other hand, the cumulative distribution function describes the probability that the random variable is no larger than a given value; the probability that the outcome lies in a given interval can be computed by taking the difference between the values of the cumulative distribution function at the endpoints of the interval. The cumulative distribution function is the antiderivative of the probability density function provided that the latter function exists.

As probability theory is used in quite diverse applications, terminology is not uniform and sometimes confusing. The following terms are used for non-cumulative probability distribution functions:


The following terms are somewhat ambiguous as they can refer to non-cumulative or cumulative distributions, depending on authors' preferences:


Because a probability distribution "P" on the real line is determined by the probability of a scalar random variable "X" being in a half-open interval <nowiki>(</nowiki>−∞, "x"<nowiki>]</nowiki>, the probability distribution is completely characterized by its cumulative distribution function:

A discrete probability distribution is a probability distribution characterized by a probability mass function. Thus, the distribution of a random variable "X" is discrete, and "X" is called a discrete random variable, if

as "u" runs through the set of all possible values of "X". A discrete random variable can assume only a finite or countably infinite number of values. For the number of potential values to be countably infinite, even though their probabilities sum to 1, the probabilities have to decline to zero fast enough. For example, if formula_5 for "n" = 1, 2, ..., we have the sum of probabilities 1/2 + 1/4 + 1/8 + ... = 1.

Well-known discrete probability distributions used in statistical modeling include the Poisson distribution, the Bernoulli distribution, the binomial distribution, the geometric distribution, and the negative binomial distribution. Additionally, the discrete uniform distribution is commonly used in computer programs that make equal-probability random selections between a number of choices.

When a sample (a set of observations) is drawn from a larger population, the sample points have an empirical distribution that is discrete and that provides information about the population distribution.

A measurable function formula_6 between a probability space formula_7 and a measurable space formula_8 is
called a discrete random variable provided its image is a countable set and the pre-image of singleton sets are measurable, i.e., formula_9 for all formula_10.
The latter requirement induces a probability mass function formula_11 via formula_12. Since the pre-images of disjoint sets
are disjoint
This recovers the definition given above.

Equivalently to the above, a discrete random variable can be defined as a random variable whose cumulative distribution function (cdf) increases only by jump discontinuities—that is, its cdf increases only where it "jumps" to a higher value, and is constant between those jumps. The points where jumps occur are precisely the values which the random variable may take.

Consequently, a discrete probability distribution is often represented as a generalized probability density function involving Dirac delta functions, which substantially unifies the treatment of continuous and discrete distributions. This is especially useful when dealing with probability distributions involving both a continuous and a discrete part.

For a discrete random variable "X", let "u", "u", ... be the values it can take with non-zero probability. Denote

These are disjoint sets, and for such sets

It follows that the probability that "X" takes any value except for "u", "u", ... is zero, and thus one can write "X" as

except on a set of probability zero, where formula_17 is the indicator function of "A". This may serve as an alternative definition of discrete random variables.

A continuous probability distribution is a probability distribution that has a cumulative distribution function that is continuous. Most often they are generated by having a probability density function. Mathematicians call distributions with probability density functions absolutely continuous, since their cumulative distribution function is absolutely continuous with respect to the Lebesgue measure "λ". If the distribution of "X" is continuous, then "X" is called a continuous random variable. There are many examples of continuous probability distributions: normal, uniform, chi-squared, and others.

Intuitively, a continuous random variable is the one which can take a continuous range of values—as opposed to a discrete distribution, where the set of possible values for the random variable is at most countable. While for a discrete distribution an event with probability zero is impossible (e.g., rolling on a standard die has probability zero and is impossible), this is not so in the case of a continuous random variable. For example, if one measures the width of an oak leaf, the result of 3½ cm is possible; however, it has probability zero because uncountably many other potential values exist even between 3 cm and 4 cm. Each of these individual outcomes has probability zero, yet the probability that the outcome will fall into the interval is nonzero. This apparent paradox is resolved by the fact that the probability that "X" attains some value within an infinite set, such as an interval, cannot be found by naively adding the probabilities for individual values. Formally, each value has an infinitesimally small probability, which statistically is equivalent to zero.

Formally, if "X" is a continuous random variable, then it has a probability density function "ƒ"("x"), and therefore its probability of falling into a given interval, say is given by the integral
In particular, the probability for "X" to take any single value "a" (that is ) is zero, because an integral with coinciding upper and lower limits is always equal to zero.

The definition states that a continuous probability distribution must possess a density, or equivalently, its cumulative distribution function be absolutely continuous. This requirement is stronger than simple continuity of the cumulative distribution function, and there is a special class of distributions, singular distributions, which are neither continuous nor discrete nor a mixture of those. An example is given by the Cantor distribution. Such singular distributions however are never encountered in practice.

Note on terminology: some authors use the term "continuous distribution" to denote the distribution with continuous cumulative distribution function. Thus, their definition includes both the (absolutely) continuous and singular distributions.

By one convention, a probability distribution formula_19 is called "continuous" if its cumulative distribution function formula_20 is continuous and, therefore, the probability measure of singletons formula_21 for all formula_22.

Another convention reserves the term "continuous probability distribution" for absolutely continuous distributions. These distributions can be characterized by a probability density function: a non-negative Lebesgue integrable function formula_23 defined on the real numbers such that

Discrete distributions and some continuous distributions (like the Cantor distribution) do not admit such a density.


In the measure-theoretic formalization of probability theory, a random variable is defined as a measurable function "X" from a probability space formula_25 to measurable space formula_26. A probability distribution of "X" is the pushforward measure "X"P  of "X" , which is a probability measure on formula_26 satisfying "X"P = P"X".

A frequent problem in statistical simulations (the Monte Carlo method) is the generation of pseudo-random numbers that are distributed in a given way. Most algorithms are based on a pseudorandom number generator that produces numbers "X" that are uniformly distributed in the half-open interval [0,1). These random variates "X" are then transformed via some algorithm to create a new random variate having the required probability distribution.

The concept of the probability distribution and the random variables which they describe underlies the mathematical discipline of probability theory, and the science of statistics. There is spread or variability in almost any value that can be measured in a population (e.g. height of people, durability of a metal, sales growth, traffic flow, etc.); almost all measurements are made with some intrinsic error; in physics many processes are described probabilistically, from the kinetic properties of gases to the quantum mechanical description of fundamental particles. For these and many other reasons, simple numbers are often inadequate for describing a quantity, while probability distributions are often more appropriate.

As a more specific example of an application, the cache language models and other statistical language models used in natural language processing to assign probabilities to the occurrence of particular words and word sequences do so by means of probability distributions.

The following is a list of some of the most common probability distributions, grouped by the type of process that they are related to. For a more complete list, see list of probability distributions, which groups by the nature of the outcome being considered (discrete, continuous, multivariate, etc.)

Note also that all of the univariate distributions below are singly peaked; that is, it is assumed that the values cluster around a single point. In practice, actually observed quantities may cluster around multiple values. Such quantities can be modeled using a mixture distribution.














</doc>
<doc id="23545" url="https://en.wikipedia.org/wiki?curid=23545" title="Psychological statistics">
Psychological statistics

Psychological statistics is application of formulas, theorems, numbers and laws to psychology. 
Statistical Methods for psychology include development and application statistical theory and methods for modeling psychological data. 
These methods include psychometrics, Factor analysis, Experimental Designs, Multivariate Behavioral Research. The article also discusses journals in the same field Wilcox, R. (2012).

Psychometrics deals with measurement of psychological attributes. It involved developing and applying statistical models for mental measurements (Lord and Novik, ; etc.) The measurement theories are divided into two major areas: (1) Classical test theory; (2) Item Response Theory (Nunnally, J. & Bernstein, I. (1994)).

The classical test theory or true score theory or reliability theory in statistics is a set of statistical procedures useful for development of psychological tests and scales. It is based on fundamental equation 
X = T + E
where, X is total score, T is a true score and E is error of measurement. For each participant, it assumes that there exist a true score and it need to be obtained score (X) has to be as close to it as possible (Lord, F. M. , and Novick, M. R. ( 1 968), Raykov, T. & Marcoulides, G.A. (2010) ). The closeness of X has with T is expressed in terms of ratability of the obtained score. The reliability in terms of classical test procedure is correlation between true score and obtained score. The typical test construction procedures has following steps:

(1) Determine the construct 
(2) Outline the behavioral domain of the construct
(3) Write 3 to 5 times more items than desired test length
(4) Get item content analyzed by experts and cull items
(5) Obtain data on initial version of the test 
(8) After the second cull, make final version
(9) Use it for research

The reliability is computed in specific ways. 
(A) Inter-Rater reliability: Inter-Rater reliability is estimate of agreement between independent raters. This is most useful for subjective responses. Cohen’s Kappa, Krippendorff’s Alpha, Intra-Class correlation coefficients, Correlation coefficients, Kendal’s concordance coefficient, etc. are useful statistical tools. 
(B) Test-Retest Reliability: Test-Retest Procedure is estimation of temporal consistency of the test. A test is administered twice to the same sample with a time interval. Correlation between two sets of scores is used as an estimate of reliability. Testing conditions are assumed to be identical. 
(C) Internal Consistency Reliability: Internal consistency reliability estimates consistency of items with each other. Split-half reliability (Spearman- Brown Prophecy) and Cronbach Alpha are popular estimates of this reliability . (Cronbach LJ (1951)). 
(D) Parallel Form Reliability: It is an estimate of consistency between two different instruments of measurement. The inter-correlation between two parallel forms of a test or scale is used as an estimate of parallel form reliability.

Validity of a scale or test is ability of the instrument to measure what it purports to measure (Nunnally, J. & Bernstein, I. (1994)). Construct validity, Content Validity, Criterion Validity are types of validity. 
Construct validity is estimated by convergent and discriminant validity and factor analysis. Convergent and discriminant validity are ascertained by correlation between similar of different constructs. 
Content Validity: Subject matter experts evaluate content validity. 
Criterion Validity is correlation between the test and a criterion variable (or variables) of the construct. Regression analysis, Multiple regression analysis, Logistic regression is used as an estimate of criterion validity. 
Software applications: The R software has ‘psych’ package that is useful for classical test theory analysis.

The modern test theory is based on latent trait model. Every item estimates the ability of the test taker. The ability parameter is called as theta (θ). The difficulty parameter is called b. the two important assumptions are local independence and unidimensionality. 
The Item Response Theory has three models. They are one parameter logistic model, two parameter logistic model and three parameter logistic model. In addition, Polychromous IRT Model are also useful (Hambleton & Swaminathan, 1985).

The R Software has ‘ltm’, packages useful for IRT analysis.

Factor analysis is at the core of psychological statistics. It has two schools: (1) Exploratory Factor analysis (2) Confirmatory Factor analysis

The exploratory factor analysis begins without a theory or with a very tentative theory. It is a dimension reduction technique. It is useful in psychometrics, multivariate analysis of data and data analytics. 
Typically a k-dimensional correlation matrix or covariance matrix of variables is reduced to k X r factor pattern matrix where r < k. Principal Component analysis and common factor analysis are two ways of extracting data. Principal axis factoring, ML factor analysis, alpha factor analysis and image factor analysis is most useful ways of EFA. 
It employees various factor rotation methods which can be classified into orthogonal (resulting in uncorrelated factors) and oblique (resulting correlated factors).

The ‘psych’ package in R is useful for EFA.

Confirmatory Factor Analysis (CFA) is factor analytic technique that begins with theory and test the theory by carrying out factor analysis. 
The CFA is also called as latent structure analysis, which considers factor as latent variables causing actual observable variables. The basic equation of the CFA is

X = Λξ + δ

where, X is observed variables, Λ are structural coefficients, ξ are latent variables (factors) and δ are errors. 
The parameters are estimated using ML methods however; other methods of estimation are also available. The chi-square test is very sensitive and hence various fit measures are used (Bollen,1989, Loehlin, 1992).
R package ‘sem’, ‘lavaan’ are useful for the same.

Experimental Methods are very popular in psychology. It has more than 100 years tradition. Experimental psychology has a status of sub-discipline in psychology .
The statistical methods are applied for designing and analyzing experimental data. They involve, t-test, ANOVA, ANCOVA, MANOVA, MANCOVA, binomial test, chi-square etc. are used for the analysis if the experimental data.

Multivariate behavioral research is becoming very popular in psychology. These methods include Multiple Regression and Prediction; Moderated and Mediated Regression Analysis; Logistics Regression; Canonical Correlations; Cluster analysis; Multi-level modeling; Survival-Failure analysis; Structural Equations Modeling; hierarchical linear modelling etc. are very useful for psychological statistics (Hayes, 2013; Agresti, 1990; Loehlin, 1992; Menard, 2001; Tabachnick, & Fidell, 2007).

There are many specialized journals that publish advances in statistical analysis for psychology. Psychometrika is at the forefront. Educational and Psychological Measurement, Assessment, American Journal of Evaluation, Applied Psychological Measurement, Behavior Research Methods, British Journal of Mathematical and Statistical Psychology, Journal of Educational and Behavioral Statistics, Journal of Mathematical Psychology, Multivariate Behavioral Research, Psychological Assessment, Structural Equation Modeling are other useful journals.

Various software packages are available for statistical methods for psychological research. They can be classified as commercial software (e.g., JMP and SPSS) and Open-Source (e.g., R). Among the free-wares, the R software is most popular one. There are many online references for R and specialised books on R for Psychologist are also being written (e.g., Belhekar, 2016 ). The "psych" package of R is very useful for psychologists. Among others, "lavaan", "sem", "ltm", "ggplot2" are some of the popular packages. PSPP and KNIME are other free packages. Among the commercial packages include JMP, SPSS and SAS. JMP and SPSS are commonly reported in books.





</doc>
<doc id="23547" url="https://en.wikipedia.org/wiki?curid=23547" title="Peter Cook">
Peter Cook

Peter Edward Cook (17 November 1937 – 9 January 1995) was an English actor, satirist, writer and comedian. Cook is widely regarded as the leading light of the British satire boom of the 1960s. He was closely associated with the anti-establishment comedy that emerged in the United Kingdom and United States in the late 1950s.

Called "the father of modern satire" by "The Guardian", in 2005, Cook was ranked number one in the "Comedians' Comedian", a poll of over 300 comics, comedy writers, producers, and directors throughout the English-speaking world.

Cook was born at his parents' house, "Shearbridge", in Middle Warberry Road, Torquay, Devon. He was the only son and eldest of the three children of Alexander Edward "Alec" Cook (1906–1984), a colonial civil servant (serving as political officer and later district officer in Nigeria, then as financial secretary to the colony of Gibraltar, followed by a return to Nigeria as Permanent Secretary of the Eastern Region, based at Enugu), and his wife Ethel Catherine Margaret (1908–1994), daughter of solicitor Charles Mayo. Cook's grandfather, Edward Arthur Cook (1869-1914), had also been a colonial civil servant, traffic manager for the Federated Malay States Railway in Kuala Lumpur, Malaya; stress leading up to an interview regarding promotion led him to commit suicide. His wife, Minnie Jane (1869-1957; daughter of Thomas Wreford, of Thelbridge and Witheridge, Devon, and of Stratford-upon-Avon, of a prominent Devonshire family traced back to 1440), kept this fact secret; Peter Cook only discovered the truth when later researching his family.

Cook was educated at Radley College and Pembroke College, Cambridge, where he studied French and German. As a student, Cook initially intended to become a career diplomat like his father, but Britain "had run out of colonies", as he put it. Although politically largely apathetic, particularly in later life when he displayed a deep distrust of politicians of all hues, he did join the Cambridge University Liberal Club. At Pembroke Cook performed and wrote comedy sketches as a member of the Cambridge Footlights Club, of which he became president in 1960. His hero was fellow Footlights writer and Cambridge magazine writer David Nobbs.

Whilst still at university, Cook wrote for Kenneth Williams, providing several sketches for Williams' hit West End comedy revue "Pieces of Eight" and much of the follow-up, "One Over the Eight", before finding prominence in his own right in a four-man group satirical stage show, "Beyond the Fringe", with Jonathan Miller, Alan Bennett and Dudley Moore.

"Beyond the Fringe" became a great success in London after being first performed at the Edinburgh Festival and included Cook impersonating the prime minister, Harold Macmillan. This was one of the first occasions satirical political mimicry had been attempted in live theatre and it shocked audiences. During one performance, Macmillan was in the theatre and Cook departed from his script and attacked him verbally.

In 1961, Cook opened The Establishment, a club at 18 Greek Street in Soho in central London, presenting fellow comedians in a nightclub setting, including American Lenny Bruce. Cook said it was a satirical venue modelled on "those wonderful Berlin cabarets ... which did so much to stop the rise of Hitler and prevent the outbreak of the Second World War"; as a members-only venue it was outside the censorship restrictions. 

Cook befriended and supported Australian comedian and actor Barry Humphries, who began his British solo career at the club. Humphries said in his autobiography, "My Life As Me", that he found Cook's lack of interest in art and literature off-putting. Dudley Moore's jazz trio played in the basement of the club during the early 1960s.

In 1962, the BBC commissioned a pilot for a television series of satirical sketches based on the Establishment Club, but it was not immediately picked up and Cook went to New York City for a year to perform "Beyond The Fringe" on Broadway. When he returned, the pilot had been refashioned as "That Was the Week That Was" and had made a star of David Frost, something Cook resented. 

The 1960s satire boom was coming to an end and Cook said: "England was about to sink giggling into the sea". He complained that Frost's success was based on copying Cook's own stage persona and Cook dubbed him "the bubonic plagiarist", and said that his only regret in life, according to Alan Bennett, had been saving Frost from drowning. This incident occurred in the summer of 1963, when the rivalry between the two men was at its height. Cook had realised that Frost's potential drowning would have looked deliberate if he had not been rescued.

Around this time, Cook provided financial backing for the satirical magazine "Private Eye", supporting it through difficult periods, particularly in libel trials. Cook invested his own money and solicited investment from his friends. For a time, the magazine was produced from the premises of the Establishment Club. In 1963, Cook married Wendy Snowden; the couple had two daughters, Lucy and Daisy, but the marriage ended in 1970.

Cook expanded television comedy with Eleanor Bron, John Bird and John Fortune. His first regular television spot was on Granada Television's "Braden Beat" with Bernard Braden, where he featured his most enduring character: the static, dour and monotonal E. L. Wisty, whom Cook had conceived for Radley College's Marionette Society.

Cook's comedy partnership with Dudley Moore led to "Not Only... But Also". This was originally intended by the BBC as a vehicle for Moore's music, but Moore invited Cook to write sketches and appear with him. Using few props, they created dry, absurd television that proved hugely popular and lasted for three series between 1965 and 1970. Cook played characters such as Sir Arthur Streeb-Greebling and the two men created their Pete and Dud alter egos. Other sketches included "Superthunderstingcar", a parody of the Gerry Anderson marionette TV shows, and Cook's pastiche of 1960s trendy arts documentaries – satirised in a parodic segment on Greta Garbo.

When Cook learned a few years later that the videotapes of the series were to be wiped, a common practice at the time, he offered to buy the recordings from the BBC but was refused because of copyright issues. He suggested he could purchase new tapes so that the BBC would have no need to erase the originals, but this was also turned down. Of the original 22 programmes, only eight still survive complete. A compilation of six half-hour programmes, "The Best of What's Left of Not Only...But Also" was shown on television and has been released on both VHS and DVD.

With "The Wrong Box" (1966) and "Bedazzled" (1967) Cook and Moore began to act in films together. Directed by Stanley Donen, the underlying story of "Bedazzled" is credited to Cook and Moore and its screenplay to Cook. A comic parody of Faust, it stars Cook as George Spigott (the Devil) who tempts Stanley Moon (Moore), a frustrated, short-order chef, with the promise of gaining his heart's desire – the unattainable beauty and waitress at his cafe, Margaret Spencer (Eleanor Bron) – in exchange for his soul, but repeatedly tricks him. The film features cameo appearances by Barry Humphries as Envy and Raquel Welch as Lust. Moore composed the soundtrack music and co-wrote (with Cook) the songs performed in the film. His jazz trio backed Cook on the theme, a parodic anti-love song, which Cook delivered in a deadpan monotone and included his familiar put-down, "you fill me with inertia."

In 1968, Cook and Moore briefly switched to ATV for four one-hour programmes titled "Goodbye Again", based on the Pete and Dud characters. Cook's increasing alcoholism led him to become reliant on cue cards and the show was not a popular success, owing in part to the publication of the ITV listings magazine, "TV Times", being suspended because of a strike. John Cleese was a cast member.

In 1970, Cook took over a project initiated by David Frost for a satirical film about an opinion pollster who rises to become President of Great Britain. Under Cook's guidance, the character became modelled on Frost. The film, "The Rise and Rise of Michael Rimmer", was not a success, although the cast contained notable names (including appearances from Monty Python's John Cleese and Graham Chapman, who co-wrote the film).

Cook became a favourite of the chat show circuit but his own effort at hosting one for the BBC in 1971, "Where Do I Sit?", was said by the critics to have been a disappointment. He was replaced after only two episodes by Michael Parkinson, the start of Parkinson's career as a chat show host. Parkinson later asked Cook what his ambitions were, Cook replied jocularly "[...] in fact, my ambition is to shut you up altogether you see!"

Cook and Moore fashioned sketches from "Not Only...But Also" and "Goodbye Again" with new material into the stage revue called "Behind the Fridge". This show toured Australia in 1972 before transferring to New York City in 1973, re-titled as "Good Evening". Cook frequently appeared on and off stage the worse for drink. Nonetheless, the show proved very popular and it won Tony and Grammy Awards. When it finished, Moore stayed in the United States to pursue his film acting ambitions in Hollywood. Cook returned to Britain and in 1973 married the actress and model Judy Huxtable.

Later, the more risqué humour of Pete and Dud went farther on long-playing records as "Derek and Clive". The first recording was initiated by Cook to alleviate boredom during the Broadway run of "Good Evening" and used material conceived years before for the two characters but considered too outrageous. One of these audio recordings was also filmed and tensions between the duo are seen to rise. Chris Blackwell circulated bootleg copies to friends in the music business. The popularity of the recording convinced Cook to release it commercially, although Moore was initially reluctant, fearing that his rising fame as a Hollywood star would be undermined. Two further "Derek and Clive" albums were released, the last accompanied by a film.

Cook and Moore hosted "Saturday Night Live" on 24 January 1976 during the show's first season. They did a number of their classic stage routines, including "One Leg Too Few" and "Frog and Peach" among others, in addition to participating in some skits with the show's ensemble cast.

In 1978, Cook appeared on the British music series "Revolver" as the manager of a ballroom where emerging punk and new wave acts played. For some groups, these were their first appearances on television. Cook's acerbic commentary was a distinctive aspect of the programme.

In 1979, Cook recorded comedy-segments as B-sides to the Sparks 12-inch singles "Number One in Heaven" and "Tryouts for the Human Race". The main songwriter Ron Mael often began with a banal situation in his lyrics, and then went at surreal tangents in the style of Cook and S. J. Perelman.

Cook played multiple roles on the 1977 concept album "Consequences", written and produced by former 10cc members Kevin Godley and Lol Creme. A mixture of spoken comedy and progressive rock with an environmental subtext, "Consequences" started as a single that Godley and Creme planned to make to demonstrate their invention, an electric guitar effect called the Gizmo, which they developed in 10cc. The project grew into a triple LP boxed set. The comedy sections were originally intended to be performed by a cast including Spike Milligan and Peter Ustinov, but Godley and Creme eventually settled on Cook once they realised he could perform most parts himself.

The storyline centres on the impending divorce of ineffectual Englishman Walter Stapleton (Cook) and his French wife Lulu (Judy Huxtable). While meeting their lawyers – the bibulous Mr. Haig and overbearing Mr. Pepperman (both played by Cook) – the encroaching global catastrophe interrupts proceedings with bizarre and mysterious happenings, which seem to centre on Mr. Blint (Cook), a musician and composer living in the flat below Haig's office, to which it is connected by a large hole in the floor.

Although it has since developed a cult following due to Cook's presence, "Consequences" was released as punk was sweeping the UK and proved a resounding commercial failure, savaged by critics who found the music self-indulgent. The script and story have evident connections to Cook's own life – his then wife Judy Huxtable plays Walter's wife. Cook's struggles with alcohol are mirrored in Haig's drinking, and there is a parallel between the fictional divorce of Walter and Lulu and Cook's own divorce from his first wife. The voice and accent Cook used for the character of Stapleton are similar to those of Cook's "Beyond the Fringe" colleague, Alan Bennett, and a book on Cook's comedy, "How Very Interesting", speculates that the characters Cook plays in "Consequences" are caricatures of the four "Beyond The Fringe" cast members – the alcoholic Haig represents Cook, the tremulous Stapleton is Bennett, the parodically Jewish Pepperman is Miller, and the pianist Blint represents Moore.

Cook appeared at the first three fund-raising galas staged by humourists John Cleese and Martin Lewis on behalf of Amnesty International. The benefits were dubbed "The Secret Policeman's Balls" though it wasn't until the third show in 1979 that the title was used. He performed on all three nights of the first show in April 1976, "A Poke in the Eye (With a Sharp Stick)", as an individual performer and as a member of the cast of "Beyond the Fringe", which reunited for the first time since the 1960s. He also appeared in a Monty Python sketch, taking the place of Eric Idle. Cook was on the cast album of the show and in the film, "Pleasure at Her Majesty's". He was in the second Amnesty gala in May 1977, "An Evening Without Sir Bernard Miles". It was retitled "The Mermaid Frolics" for the cast album and TV special. Cook performed monologues and skits with Terry Jones.

In June 1979, Cook performed all four nights of "The Secret Policeman's Ball" – teaming with John Cleese. Cook performed a couple of solo pieces and a sketch with Eleanor Bron. He also led the ensemble in the finale – the "End of the World" sketch from "Beyond The Fringe".

In response to a barb in "The Daily Telegraph" that the show was recycled material, Cook wrote a satire of the summing-up by Mr Justice Cantley in the trial of former Liberal Party leader Jeremy Thorpe, a summary now widely thought to show bias in favour of Thorpe. Cook performed it that same night (Friday 29 June – the third of the four nights) and the following night. The nine-minute opus, "Entirely a Matter for You", is considered by many fans and critics to be one of the finest works of Cook's career. Cook and show producer Martin Lewis brought out an album on Virgin Records entitled "Here Comes the Judge: Live" of the live performance together with three studio tracks that further lampooned the Thorpe trial.

Although unable to take part in the 1981 gala, Cook supplied the narration over the animated opening title sequence of the 1982 film of the show. With Lewis, he wrote and voiced radio commercials to advertise the film in the UK. He also hosted a spoof film awards ceremony that was part of the world première of the film in London in March 1982.

Following Cook's 1987 stage reunion with Moore for the annual American benefit for the homeless, "Comic Relief" (not related to the UK "Comic Relief" benefits), Cook repeated the reunion for a British audience by performing with Moore at the 1989 Amnesty benefit "The Secret Policeman's Biggest Ball".

In 1980, partly spurred by Moore's growing film star status, Cook moved to Hollywood and appeared as an uptight English butler to a wealthy American woman in a short-lived United States television sitcom, "The Two of Us", also making cameo appearances in a couple of undistinguished films. In 1980, Cook starred in the LWT special "Peter Cook & Co." The show included comedy sketches, including a "Tales of the Unexpected" parody "Tales of the Much As We Expected." This involved Cook as Roald Dahl, explaining his name had been Ronald before he dropped the "n." The cast included John Cleese, Rowan Atkinson, Beryl Reid, Paula Wilcox and Terry Jones.

In 1983 Cook played the role of Richard III in the first episode of "Blackadder", "The Foretelling," which parodies Laurence Olivier's portrayal. He narrated the short film "Diplomatix" by Norwegian comedy trio Kirkvaag, Lystad and Mjøen, which won the "Special Prize of the City of Montreux" at the Montreux Comedy Festival in 1985. In 1986 he partnered Joan Rivers on her UK talk show. He appeared as Mr Jolly in 1987 in "The Comic Strip Presents"' episode "Mr. Jolly Lives Next Door," playing an assassin who covers the sound of his murders by playing Tom Jones records. That same year, Cook made a big splash on American shores when he appeared in "The Princess Bride" as the "Impressive Clergyman" who officiates the wedding ceremony between Buttercup and Prince Humperdinck, uttering the now famous line "Mawage!" Also that year he spent time working with Martin Lewis on a political satire about the 1988 US presidential elections for HBO, but the script went unproduced. Lewis suggested Cook team with Moore for the US "Comic Relief" telethon for the homeless. The duo reunited and performed their "One Leg Too Few" sketch.

In 1988, Cook appeared as a contestant on the improvisation comedy show "Whose Line Is It Anyway?" Cook was declared the winner, his prize being to read the credits in the style of a New York cab driver – a character he had portrayed in "Peter Cook & Co."

Cook occasionally called in to Clive Bull's night-time phone-in radio show on LBC in London. Using the name "Sven from Swiss Cottage," he mused on love, loneliness and herrings in a mock Norwegian accent. Jokes included Sven's attempts to find his estranged wife, in which he often claimed to be telephoning the show from all over the world, and his hatred of the Norwegian obsession with fish. While Bull was clearly aware that Sven was fictional he did not learn of his real identity until later.

In late 1989, Cook married for the third time, to Malaysian-born property developer Chiew Lin Chong (1945–2016) in Torbay, Devon. She provided him with some stability in his personal life and he reduced his drinking, to the extent that for a time he was teetotal. He lived alone in a small 18th-century house in Perrins Walk, Hampstead, while his wife kept her own property only 100 yards away.

Cook returned to the BBC as Sir Arthur Streeb-Greebling for an appearance with Ludovic Kennedy in "A Life in Pieces". The 12 interviews saw Sir Arthur recount his life based on the Twelve Days of Christmas. Unscripted interviews with Cook as Streeb-Greebling and satirist Chris Morris were recorded in late 1993 and broadcast as "Why Bother?" on BBC Radio 3. Morris described them:

On 17 December 1993, Cook appeared on "Clive Anderson Talks Back" as four characters – biscuit tester and alien abductee Norman House, football manager and motivational speaker Alan Latchley, judge Sir James Beauchamp and rock legend Eric Daley. The following day he appeared on BBC2 performing links for "Arena"'s "Radio Night". He also appeared, on 26 December, in the 1993 Christmas special of "One Foot in the Grave" ("One Foot in the Algarve"), playing a muckraking tabloid photographer. Before the end of the next year his mother died, and a grief-stricken Cook returned to heavy drinking. He made his last TV appearance on the show "Pebble Mill at One" in November 1994.

Cook died from a gastrointestinal hemorrhage on 9 January 1995, aged 57. His body was cremated at Golders Green Crematorium and his ashes were buried in an unmarked plot behind St John-at-Hampstead, not far from his home in Perrins Walk.

Dudley Moore attended Cook's memorial service at St John-at-Hampstead on 1 May 1995. He and Martin Lewis presented a two-night memorial for Cook at The Improv in Los Angeles, on 15 and 16 November 1995, to mark what would have been Cook's 58th birthday.

Cook is widely acknowledged as a strong influence on the many British comedians who followed him from the amateur dramatic clubs of British universities to the Edinburgh Festival Fringe, and then to radio and television. On his death some critics choose to see Cook's life as tragic, insofar as the brilliance of his youth had not been sustained in his later years. However, Cook himself always maintained he had no ambitions at all for sustained success. He assessed happiness by his friendships and his enjoyment of life. Eric Idle and Stephen Fry said Cook had not wasted his talent but rather that the newspapers had tried to waste him.

Several friends honoured him with a dedication in the closing credits of "Fierce Creatures" (1997), a comedy film written by John Cleese about a zoo in peril of being closed. It starred Cleese, Jamie Lee Curtis, Kevin Kline and Michael Palin. The dedication displays photos and the lifespan dates of Cook and of British naturalist and humourist Gerald Durrell.

In 1999 the minor planet 20468 Petercook, in the main asteroid belt, was named after Cook.

Channel 4 broadcast "Not Only But Always", a television film dramatising the relationship between Cook and Moore, with Rhys Ifans portraying Cook. At the 2005 Edinburgh Festival Fringe a play, "" written by Chris Bartlett and Nick Awde, examined the relationship from Moore's view. The play was transferred to London's West End at The Venue in 2006 and toured the UK the following year. Tom Goodman-Hill starred as Cook and Kevin Bishop as Moore in the West End.

A green plaque was unveiled by the Westminster City Council and the Heritage Foundation at the site of the Establishment Club on 15 February 2009 after an online campaign by satirist / event Organiser Mark Biddiss, who also organised "The World's 1st Peter Cook is dead Birthday Party/Long overdue Public Wake" at the site of the Establishment Club to promote the plaque, which featured a live reworking of 'Derek & Clive' material titled "Derek & Clive are Alive again".

A historic blue plaque was unveiled by the Torbay Civic Society on 17 November 2014 at Cook's place of birth, "Shearbridge", Middle Warberry Road, Torquay, with his widow Lin and other members of the family in attendance. A further blue plaque was commissioned and erected at the home of Torquay United, Plainmoor, Torquay, in 2015.



"Amnesty International Performances:"


UK chart singles:

Albums:




</doc>
<doc id="23549" url="https://en.wikipedia.org/wiki?curid=23549" title="Psychedelic rock">
Psychedelic rock

Psychedelic rock is a diverse style of rock music inspired, influenced, or representative of psychedelic culture, which is centred around perception-altering hallucinogenic drugs. Psychedelic rock is intended to replicate and enhance the mind-altering experiences of psychedelic drugs, most notably LSD. Many psychedelic groups differ in style, and the label is often used indiscriminately.

Originating in the mid-1960s among British and American musicians, the sounds of psychedelic rock invokes three core effects of LSD: depersonalization, dechronicization, and dynamization; all of which detach the user from reality. Musically, the effects may be represented via novelty studio tricks, electronic or non-Western instrumentation, disjunctive song structures, and extended instrumental segments. Some of the earlier 1960s psychedelic rock musicians were based in folk, jazz, and the blues, while others showcased an explicit Indian classical influence called "raga rock". In the 1960s, there existed two main variants of the genre: the whimsical British pop-psychedelia and the harder American West Coast acid rock. While "acid rock" is sometimes deployed interchangeably with the term "psychedelic rock", it also refers more specifically to the heavier and more extreme ends of the genre.

The peak years of psychedelic rock were between 1966 and 1969, with milestone events including the 1967 Summer of Love and the 1969 Woodstock Rock Festival, becoming an international musical movement associated with a widespread counterculture before beginning a decline as changing attitudes, the loss of some key individuals and a back-to-basics movement, led surviving performers to move into new musical areas. The genre bridged the transition from early blues and folk-based rock to progressive rock and hard rock, and as a result contributed to the development of sub-genres such as heavy metal. Since the late 1970s it has been revived in various forms of neo-psychedelia.

As a musical style, psychedelic rock attempted to replicate the effects of and enhance the mind-altering experiences of hallucinogenic drugs, incorporating new electronic sound effects and recording effects, extended solos, and improvisation. Common features include:

The term "psychedelic" was first coined in 1956 by psychiatrist Humphry Osmond as an alternative descriptor for hallucinogenic drugs in the context of psychedelic psychotherapy. As the countercultural scene developed in San Francisco, the terms acid rock and psychedelic rock were used in 1966 to describe the new drug-influenced music and were being widely used by 1967. The terms psychedelic rock and acid rock are often used interchangeably, but acid rock may be distinguished as a more extreme variation that was heavier, louder, relied on long jams, focused more directly on LSD, and made greater use of distortion.

In the popular music of the early 1960s, it was common for producers, songwriters, and engineers to freely experiment with musical form, arrangements, unnatural reverb, and other sound effects. Some of the best known examples are Phil Spector's Wall of Sound production formula and Joe Meek's use of homemade electronics for acts like the Tornados. XTC's Andy Partridge interprets the music of psychedelic groups as a "grown-up" version of children's novelty records, believing that many acts were trying to emulate those records that they grew up with; "They use exactly the same techniques—sped-up bits, slowed-down bits, too much echo, too much reverb, that bit goes backwards. ... There was no transition to be made. You go from things like 'Flying Purple People Eater' to 'I Am the Walrus'. They go hand-in-hand." Music critic Richie Unterberger says that attempts to "pin down" the first psychedelic record are therefore "nearly as elusive as trying to name the first rock & roll record". Some of the "far-fetched claims" include the instrumental "Telstar" (produced by Meek for the Tornados in 1962) and the Dave Clark Five's "massively reverb-laden" "Any Way You Want It" (1964). The first mention of LSD on a rock record was the Gamblers' 1960 surf instrumental "LSD 25". A 1962 single by The Ventures, "The 2000 Pound Bee", issued forth the buzz of a distorted, "fuzztone" guitar, and the quest into "the possibilities of heavy, transistorised distortion" and other effects, like improved reverb and echo began in earnest on London's fertile rock 'n' roll scene. By 1964 fuzztone could be heard on singles by P.J. Proby, and the Beatles had employed feedback in "I Feel Fine", their 6th consecutive No. 1 hit in the UK.

American folk singer Bob Dylan was a massive influence on mid 1960s rock music. He led directly to the creation of folk rock and the psychedelic rock musicians that followed, and his lyrics were a touchstone for the psychedelic songwriters of the late 1960s. Virtuoso sitarist Ravi Shankar had begun in 1956 a mission to bring Indian classical music to the West, inspiring jazz, classical and folk musicians; and by the mid-1960s, a generation of young rock musicians who would make raga rock part of the psychedelic rock aesthetic and one of the many intersecting cultural motifs of the era. Meanwhile, in British folk, blues, drugs, jazz and eastern influences blended in the early 1960s work of Davy Graham, who adopted modal guitar tunings to transpose Indian ragas and Celtic reels. Graham was a "profound influence" on Scottish folk virtuoso Bert Jansch and other pioneering guitarists across a spectrum of styles and genres in the mid-1960s. Jazz saxophonist and composer John Coltrane had a similar impact, as the exotic sounds on his albums "My Favorite Things" (1960) and "A Love Supreme" (1964), the latter influenced by the ragas of Shankar, were source material for guitar players and others looking to improvise or "jam".

According to music journalist Barry Miles: "Hippies didn't just pop up overnight, but 1965 was the first year in which a discernible youth movement began to emerge. Many of the key "psychedelic" rock bands formed this year." On the West Coast, underground chemist Augustus Owsley Stanley III and Ken Kesey (along with his followers known as the "Merry Pranksters") helped thousands of people take uncontrolled trips at Kesey's "Acid Tests" and in the new psychedelic dance halls. In Britain, Michael Hollingshead opened the World Psychedelic Centre and Beat Generation poets Allen Ginsberg, Lawrence Ferlinghetti and Gregory Corso read at the Royal Albert Hall. Miles adds: "The readings acted as a catalyst for underground activity in London, as people suddenly realized just how many like-minded people there were around. This was also the year that London began to blossom into colour with the opening of the Granny Takes a Trip and Hung On You clothes shops." Thanks to media coverage, use of LSD became widespread.

Molly Longman of mic.com writes that, in terms of bridging the relationship between music and hallucinogens, the Beatles and the Beach Boys were the era's most pivotal acts. In 1965, the Beach Boys' leader Brian Wilson started exploring song composition while under the influence of psychedelic drugs, and after being introduced to cannabis in 1964 by Dylan, members of the Beatles also began using LSD. The considerable success enjoyed by these two bands allowed them the freedom to experiment with new technology over entire albums. Producer George Martin, who was initially known as a specialist in comedy and novelty records, responded to the Beatles' requests by providing a range of studio tricks that ensured the band played a key role in the development of psychedelic effects, including the drug-inspired drone on "Ticket to Ride" (1965).

In Unterberger's opinion, the Byrds, emerging from the Los Angeles folk rock scene, and the Yardbirds, from England's blues scene, were more responsible than the Beatles for "sounding the psychedelic siren". Drug use and attempts at psychedelic music moved out of acoustic folk-based music towards rock soon after the Byrds "plugged in" to electric guitars to produce a chart topping version of Dylan's "Mr. Tambourine Man" in the summer of 1965, which became a folk rock standard.

On the Yardbirds, Unterberger identifies lead guitarist Jeff Beck as having "laid the blueprint for psychedelic guitar", and the band for defining psychedelic rock's "manic eclecticism ... With their ominous minor key melodies, hyperactive instrumental breaks (called rave-ups), and use of Gregorian chants." All were present on "Having a Rave-Up" the Yardbirds U.S.-only album on which Beck "emerged as a full-fledged guitar hero", in the view of "Guitar Player" magazine. "Heart Full of Soul" (June 1965) was a hit single driven by a distorted fuzz guitar riff by Beck made to simulate the drone of a sitar, which "carried the energy of a new scene" and herald the arrival of new Eastern sounds.

The Kinks would also incorporate guitars to mimic the drones of Indian music on "See My Friends", another Top 10 hit just a few weeks later. The Beatles' "Norwegian Wood" from the December 1965 album "Rubber Soul" marked the first released recording on which a member of a Western rock group played the sitar. The song is generally credited for sparking the sitar craze of the mid-1960s – a trend which fueled the growth raga rock as the India exotic became part of the essence of psychedelic rock. Rock author George Case recognises "Rubber Soul" as one of two Beatles albums that "marked the authentic beginning of the psychedelic era".

A number of Californian-based folk acts followed the Byrds into folk-rock, bringing their psychedelic influences with them, to produce the "San Francisco Sound". The San Francisco music scene developed in the city's Haight-Asbury neighborhood in 1965 at basement shows organised by Chet Helms of the Family Dog; and as Jefferson Airplane founder Marty Balin and investors opened The Matrix nightclub that summer and began booking his and other local bands, such as the Grateful Dead, The Steve Miller Band and Country Joe & the Fish. Helms and San Francisco Mime Troupe manager Bill Graham in fall of 1965 organised larger scale multi-media community events/benefits featuring the Airplane, the Diggers and poet Alan Ginsberg. By early 1966 Graham had secured booking at The Fillmore, and Helms at the Avalon Ballroom, where in-house psychedelic-themed light shows replicated the visual effects of the psychedelic experience. Graham would become a major figure in the growth of psychedelic rock, attracting most of the major psychedelic rock bands of the day to The Fillmore.

According to Kevin T. McEneaney, the Grateful Dead "invented" acid rock in front of a crowd of concertgoers in San Jose, California on December 4, 1965, the date of the second Acid Test held by novelist Ken Kesey and The Merry Pranksters. Their stage performance involved the use of strobe lights to reproduce LSD's "surrealistic fragmenting" or "vivid isolating of caught moments". The Acid Test experiments subsequently launched the entire psychedelic subculture.

Musicologist William Echard writes that in 1966, "the psychedelic implications" advanced by recent rock experiments "became fully explicit and much more widely distributed," and by the end of the year, "most of the key elements of psychedelic topicality had been at least broached." Author Jim DeRogatis says the birth date of psychedelic (or acid) rock is "best listed at 1966". Music journalists Pete Prown and Harvey P. Newquist locate the "peak years" of psychedelic rock between 1966 and 1969. 1966 saw the media coverage of rock music change considerably as the music became reevaluated as a new form of art in tandem with the growing psychedelic community.

In February, the Yardbirds released "Shapes of Things", which is frequently considered the first psychedelic rock song. Reaching No. 3 in the UK and 11 in the US, the work continued the Yardbirds' exploration of guitar effects, Eastern-sounding scales, and shifting rhythms that began with their 1965 singles. By overdubbing guitar parts, Beck layered multiple takes for his solo, which included extensive use of fuzz tone and harmonic feedback. The Yardbirds' lyrics, described as "stream-of-consciousness", have been interpreted as pro-environmental or anti-war. Another record often considered the first psychedelic rock song is the Byrds' "Eight Miles High" (March 1966). For their new single, the Byrds moved away from their earlier folk rock with Roger McGuinn's 12-string Rickenbacker guitar interpretation of free jazz (Coltrane) and Indian raga-sounding scales (Shankar). The Byrds' lyrics were widely taken to refer to drug use, although the group denied it at the time. "Eight Miles High" peaked at No. 14 in the US. and No. 24 in the UK. According to author David Simonelli, despite being released a month apart from each other, both songs "achieved the same status" as the first "psychedelic" hit, and the Yardbirds became the first British band to have the term applied to one of its songs.

Contributing to psychedelia's emergence into the pop mainstream was the release of Beach Boys' "Pet Sounds" (May 1966) and the Beatles' "Revolver" (August 1966). Often considered one of the earliest albums in the canon of psychedelic rock, "Pet Sounds" contained many elements that would be incorporated into psychedelia, with its artful experiments, psychedelic lyrics based on emotional longings and self-doubts, elaborate sound effects and new sounds on both conventional and unconventional instruments. The album track "I Just Wasn't Made for These Times" contained the first use of theremin sounds on a rock record. Scholar Philip Auslander says that even though psychedelic music is not normally associated with the Beach Boys, the "odd directions" and experiments in "Pet Sounds" "put it all on the map. ... basically that sort of opened the door — not for groups to be formed or to start to make music, but certainly to become as visible as say Jefferson Airplane or somebody like that." Like "Pet Sounds", "Revolver" explored musical soundscapes that could not be replicated in concert, even with the addition of an orchestra. The Beatles' May 1966 B-side "Rain", recorded during the "Revolver" sessions, was the first pop recording to include reversed sounds. It makes full use of an assortment of studio tricks such as varispeed and backwards taping, combining them with a droning melody that further highlights a growing interest in non-Western musical form. Author Simon Philo believes the song to be "the birth of British psychedelic rock". Author Steve Turner recognises the Beatles' success in conveying an LSD-inspired worldview on "Revolver", particularly on "Tomorrow Never Knows", as having "opened the doors to psychedelic rock (or acid rock)".

In October 1966, the Texas band 13th Floor Elevators debuted with "The Psychedelic Sounds of the 13th Floor Elevators". They were the first group to advertise themselves as psychedelic rock, having done so since the end of 1965. The Beach Boys' October 1966 single "Good Vibrations" was another early pop song to incorporate psychedelic lyrics and sounds. Upon release, the single prompted an unexpected revival in theremins and increased the awareness of analog synthesizers. As psychedelia gained prominence, Beach Boys-style harmonies would be ingrained into the newer psychedelic pop.

1967 was when psychedelic rock received widespread media attention and a larger audience beyond local psychedelic communities. From 1967 to 1968, psychedelic rock was the prevailing sound of rock music, either in the whimsical British variant, or the harder American West Coast acid rock. Since most of the US acts had yet to release records in the UK, most of the British groups based their sound on what they'd simply read or heard about psychedelic music. Compared with American psychedelia, British psychedelic music was often more arty in its experimentation, and it tended to stick within pop song structures. Pink Floyd's "Arnold Layne" (March 1967) and "See Emily Play" (June 1967), both written by Syd Barrett, helped set the pattern for British pop-psychedelia.

Jefferson Airplane's "Surrealistic Pillow" (February 1967) was the first album to come out of San Francisco during this era, which sold well enough to bring the city's music scene to the attention of the record industry: from it they took two of the earliest psychedelic hit singles: "White Rabbit" and "Somebody to Love". That same month, the Beatles released the double A-side "Strawberry Fields Forever" and "Penny Lane", which Ian MacDonald says opened a strain of "British pop-pastoral" music explored by late 1960s groups like Pink Floyd, Traffic, Family, and Fairport Convention. Soon, British clubs like the UFO Club, Middle Earth Club, The Roundhouse, the Country Club and the Art Lab were drawing capacity audiences with psychedelic rock and ground-breaking liquid light shows. A major figure in the development of British psychedelia was the American promoter and record producer Joe Boyd, who moved to London in 1966. He co-founded venues including the UFO Club, produced Pink Floyd's first single, "Arnold Layne", and went on to manage folk and folk rock acts including Nick Drake, the Incredible String Band and Fairport Convention.

Psychedelic rock's popularity accelerated following the success of the Monterey Pop Festival and the release of the Beatles' album "Sgt. Pepper's Lonely Hearts Club Band" in the same week of June. The album was the first commercially successful work that critics heralded as a landmark aspect of psychedelia, and the Beatles' mass appeal meant that the album would be played virtually everywhere. The Summer of Love of 1967 saw a huge number of young people from across America and the world travel to the Haight-Ashbury district of San Francisco, boosting the population from 15,000 to around 100,000. It was prefaced by the Human Be-In event in March and reached its peak at the Monterey Pop Festival in June, the latter helping to make major American stars of Janis Joplin, lead singer of Big Brother and the Holding Company, Jimi Hendrix, and the Who. Existing "British Invasion" acts now joined the psychedelic revolution, including Eric Burdon (previously of The Animals) and The Who, whose "The Who Sell Out" (December 1967) included psychedelic influenced tracks "I Can See for Miles" and "Armenia City in the Sky". The Incredible String Band's "The 5000 Spirits or the Layers of the Onion" (July 1967) developed their folk music into full blown psychedelia, which would be a major influence on psychedelic rock.

According to author Edward Macan, there ultimately existed three distinct wings of British psychedelic music. The first was based on a heavy, electric reinterpretation of the blues played by the Rolling Stones, adding guitarist Pete Townshend of the Who's pioneering power chord style to the mix. Groups of this nature were dominated by Cream, the Yardbirds, and Hendrix. The second drew strongly from jazz sources and was represented early on by Traffic, Colosseum, If, and the Canterbury scene spearheaded by Soft Machine and Caravan. Their music was considerably more complex than the Cream/Hendrix/Yardbirds approach. The third wing was represented by the Moody Blues, Pink Floyd, and the Nice, who were influenced by the later music of the Beatles, unlike the other two wings. Several of the English psychedelic bands who followed in the wake of the Beatles' psychedelic "Sgt. Pepper's" developed characteristics of the Beatles' music (specifically their classical influence) further than either the Beatles or contemporaneous West Coast psychedelic bands.

The US and UK were the major centres of psychedelic music, but in the late 1960s scenes began to develop across the world, including continental Europe, Australasia, Asia and south and Central America. In the later 1960s psychedelic scenes developed in a large number of countries in continental Europe, including the Netherlands with bands like The Outsiders, Denmark where it was pioneered by Steppeulvene, and Germany, where musicians began to fuse music of psychedelia and the electronic avant-garde. 1968 saw the first major German rock festival in , and the foundation of the Zodiak Free Arts Lab in Berlin by Hans-Joachim Roedelius, and Conrad Schnitzler, which helped bands like Tangerine Dream and Amon Düül achieve cult status. 

A thriving psychedelic music scene in Cambodia, influenced by psychedelic rock and soul broadcast by US forces radio in Vietnam, was pioneered by artists such as Sinn Sisamouth and Ros Sereysothea. In South Korea, Shin Jung-Hyeon, often considered the godfather of Korean rock, played psychedelic-influenced music for the American soldiers stationed in the country. Following Shin Jung-Hyeon, the band San Ul Lim (Mountain Echo) often combined psychedelic rock with a more folk sound. In Turkey, Anatolian rock artist Erkin Koray blended classic Turkish music and Middle Eastern themes into his psychedelic-driven rock, helping to found the Turkish rock scene with artists such as Cem Karaca, Mogollar and Baris Manco. In Brasil the Tropicalia movement merged Brazilian and African rhythms with psychedelic rock. Musicians who were part of the movement include Caetano Veloso, Gilberto Gil, Os Mutantes, Gal Costa, Tom Zé, and the poet/lyricist Torquato Neto, all of whom participated in the 1968 album "", which served as a musical manifesto.

Psychedelic trends climaxed in the 1969 Woodstock festival, which saw performances by most of the major psychedelic acts, including Jimi Hendrix, Jefferson Airplane, and the Grateful Dead. By the end of the 1960s, psychedelic rock was in retreat. In 1966, LSD had been made illegal in the US and UK. In 1969, the murders of Sharon Tate and Leno and Rosemary LaBianca by Charles Manson and his cult of followers, claiming to have been inspired by Beatles' songs such as "Helter Skelter", has been seen as contributing to an anti-hippie backlash. At the end of the same year, the Altamont Free Concert in California, headlined by the Rolling Stones, became notorious for the fatal stabbing of black teenager Meredith Hunter by Hells Angel security guards.

Brian Wilson of the Beach Boys, Brian Jones of the Rolling Stones, Peter Green of Fleetwood Mac and Syd Barrett of Pink Floyd were early "acid casualties", helping to shift the focus of the respective bands of which they had been leading figures. Some groups, such as the Jimi Hendrix Experience and Cream, broke up. Hendrix died in London in September 1970, shortly after recording "Band of Gypsys" (1970), Janis Joplin died of a heroin overdose in October 1970 and they were closely followed by Jim Morrison of the Doors, who died in Paris in July 1971. Many surviving acts moved away from psychedelia into either more back-to-basics "roots rock", traditional-based, pastoral or whimsical folk, the wider experimentation of progressive rock, or riff-based heavy rock. 

Following the lead of Hendrix in rock, psychedelia began to influence African American musicians, particularly the stars of the Motown label. This psychedelic soul was influenced by the civil rights movement, giving it a darker and more political edge than much psychedelic rock. Building on the funk sound of James Brown, it was pioneered from about 1968 by Sly and the Family Stone and The Temptations. Acts that followed them into this territory included Edwin Starr and the Undisputed Truth. George Clinton's interdependent Funkadelic and Parliament ensembles and their various spin-offs took the genre to its most extreme lengths making funk almost a religion in the 1970s, producing over forty singles, including three in the US top ten, and three platinum albums.

While psychedelic rock began to waver at the end of the 1960s, psychedelic soul continued into the 1970s, peaking in popularity in the early years of the decade, and only disappearing in the late 1970s as tastes began to change. Acts like Earth, Wind and Fire, Kool and the Gang and Ohio Players, who began as psychedelic soul artists, incorporated its sounds into funk music and eventually the disco which partly replaced it.

Many of the British musicians and bands that had embraced psychedelia went on to create progressive rock in the 1970s, including Pink Floyd, Soft Machine and members of Yes. King Crimson's album "In the Court of the Crimson King" (1969) has been seen as an important link between psychedelia and progressive rock. While bands such as Hawkwind maintained an explicitly psychedelic course into the 1970s, most dropped the psychedelic elements in favour of wider experimentation. The incorporation of jazz into the music of bands like Soft Machine and Can also contributed to the development of the jazz rock of bands like Colosseum. As they moved away from their psychedelic roots and placed increasing emphasis on electronic experimentation, German bands like Kraftwerk, Tangerine Dream, Can and Faust developed a distinctive brand of electronic rock, known as kosmische musik, or in the British press as "Kraut rock". The adoption of electronic synthesisers, pioneered by Popol Vuh from 1970, together with the work of figures like Brian Eno (for a time the keyboard player with Roxy Music), would be a major influence on subsequent electronic rock.

Psychedelic rock, with its distorted guitar sound, extended solos and adventurous compositions, has been seen as an important bridge between blues-oriented rock and later heavy metal. American bands whose loud, repetitive psychedelic rock emerged as early heavy metal included the Amboy Dukes and Steppenwolf. From England, two former guitarists with the Yardbirds, Jeff Beck and Jimmy Page, moved on to form key acts in the genre, The Jeff Beck Group and Led Zeppelin respectively. Other major pioneers of the genre had begun as blues-based psychedelic bands, including Black Sabbath, Deep Purple, Judas Priest and UFO. Psychedelic music also contributed to the origins of glam rock, with Marc Bolan changing his psychedelic folk duo into rock band T. Rex and becoming the first glam rock star from 1970. From 1971 David Bowie moved on from his early psychedelic work to develop his Ziggy Stardust persona, incorporating elements of professional make up, mime and performance into his act.

There were occasional mainstream acts that dabbled in neo-psychedelia, a style of music which emerged in late 1970s post-punk circles. Although it has mainly been an influence on alternative and indie rock bands, neo-psychedelia sometimes updated the approach of 1960s psychedelic rock. In the US in the early 1980s it was joined by the Paisley Underground movement, based in Los Angeles and fronted by acts such as Dream Syndicate, The Bangles and Rain Parade. Emerging in the 1990s, stoner rock combined elements of psychedelic rock and doom metal. Typically using a slow-to-mid tempo and featuring low-tuned guitars in a bass-heavy sound, with melodic vocals, and 'retro' production, it was pioneered by the Californian bands Kyuss and Sleep. Modern festivals focusing on psychedelic music include Austin Psych Fest in Texas, founded in 2008 and Liverpool Psych Fest.




</doc>
<doc id="23550" url="https://en.wikipedia.org/wiki?curid=23550" title="Philips">
Philips

Koninklijke Philips N.V. (Philips, stylized as PHILIPS) is a Dutch multinational technology company headquartered in Amsterdam currently focused in the area of healthcare. It was founded in Eindhoven in 1891, by Gerard Philips and his father Frederik. It was once one of the largest electronic conglomerates in the world and currently employs around 105,000 people across 60 countries.

Philips is organized into three main divisions: Philips Consumer Lifestyle (formerly Philips Consumer Electronics and Philips Domestic Appliances and Personal Care), Philips Healthcare (formerly Philips Medical Systems) and Signify N.V. (known as Philips Lighting prior to 2018). , Philips was the largest manufacturer of lighting in the world measured by applicable revenues. In 2013, the company announced the sale of the bulk of its remaining consumer electronics to Japan's Funai Electric Co, but in October 2013, the deal to Funai Electric Co was broken off and the consumer electronics operations remain under Philips. Philips said it would seek damages for breach of contract in the US$200-million sale. In April 2016, the International Court of Arbitration ruled in favour of Philips, awarding compensation of €135 million in the process.

Philips has a primary listing on the Euronext Amsterdam stock exchange and is a component of the Euro Stoxx 50 stock market index. It has a secondary listing on the New York Stock Exchange.

The Philips Company was founded in 1891, by Gerard Philips and his father Frederik Philips. Frederik, a banker based in Zaltbommel, financed the purchase and setup of an empty factory building in Eindhoven, where the company started the production of carbon-filament lamps and other electro-technical products in 1892. This first factory has been adapted and is used as a museum.

In 1895, after a difficult first few years and near bankruptcy, the Philipses brought in Anton, Gerard's younger brother by sixteen years. Though he had earned a degree in engineering, Anton started work as a sales representative; soon, however, he began to contribute many important business ideas. With Anton's arrival, the family business began to expand rapidly, resulting in the founding of Philips Metaalgloeilampfabriek N.V. (Philips Metal Filament Lamp Factory Ltd.) in Eindhoven in 1908, followed in 1912, by the foundation of Philips Gloeilampenfabrieken N.V. (Philips Lightbulb Factories Ltd.). After Gerard and Anton Philips changed their family business by founding the Philips corporation, they laid the foundations for the later electronics multinational.

In the 1920s, the company started to manufacture other products, such as vacuum tubes. In 1939, they introduced their electric razor, the "Philishave" (marketed in the US using the Norelco brand name). The "Chapel" is a radio with built-in loudspeaker, which was designed during the early 1930s.

On 11 March 1927, Philips went on the air with shortwave radio station PCJJ (later PCJ) which was joined in 1929 by sister station PHOHI (Philips Omroep Holland-Indië). PHOHI broadcast in Dutch to the Dutch East Indies (now Indonesia) while PCJJ broadcast in English, Spanish and German to the rest of the world.

The international program on Sundays commenced in 1928, with host Eddie Startz hosting the "Happy Station" show, which became the world's longest-running shortwave program. Broadcasts from the Netherlands were interrupted by the German invasion in May 1940. The Germans commandeered the transmitters in Huizen to use for pro-Nazi broadcasts, some originating from Germany, others concerts from Dutch broadcasters under German control.

Philips Radio was absorbed shortly after liberation when its two shortwave stations were nationalised in 1947 and renamed Radio Netherlands Worldwide, the Dutch International Service. Some PCJ programs, such as "Happy Station", continued on the new station.

Philips was instrumental in the revival of the Stirling engine when, in the early 1930s, the management decided that offering a low-power portable generator would assist in expanding sales of its radios into parts of the world where mains electricity was unavailable and the supply of batteries uncertain. Engineers at the company's research lab carried out a systematic comparison of various power sources and determined that the almost forgotten Stirling engine would be most suitable, citing its quiet operation (both audibly and in terms of radio interference) and ability to run on a variety of heat sources (common lamp oil – "cheap and available everywhere" – was favored). They were also aware that, unlike steam and internal combustion engines, virtually no serious development work had been carried out on the Stirling engine for many years and asserted that modern materials and know-how should enable great improvements.

Encouraged by their first experimental engine, which produced 16 W of shaft power from a bore and stroke of , various development models were produced in a program which continued throughout World War II. By the late 1940s, the 'Type 10' was ready to be handed over to Philips' subsidiary Johan de Witt in Dordrecht to be produced and incorporated into a generator set as originally planned. The result, rated at 180/200 W electrical output from a bore and stroke of , was designated MP1002CA (known as the "Bungalow set"). Production of an initial batch of 250 began in 1951, but it became clear that they could not be made at a competitive price, besides with the advent of transistor radios with their much lower power requirements meant that the original rationale for the set was disappearing. Approximately 150 of these sets were eventually produced.

In parallel with the generator set Philips developed experimental Stirling engines for a wide variety of applications and continued to work in the field until the late 1970s, though the only commercial success was the 'reversed Stirling engine' cryocooler. However, they filed a large number of patents and amassed a wealth of information, which they later licensed to other companies.

The first Philips shaver was introduced in the 1930s, and was simply called Philishave. In the US, it was called Norelco. The Philishave remains part of the Philips product line until the present.

On 9 May 1940, the Philips directors learned that the German invasion of the Netherlands was to take place the following day. Having prepared for this, Anton Philips and his son in law Frans Otten, as well as other Philips family members, fled to the United States, taking a large amount of the company capital with them. Operating from the US as the North American Philips Company, they managed to run the company throughout the war. At the same time, the company was moved (on paper) to the Netherlands Antilles to keep it out of German hands.

On 6 December 1942, the British No. 2 Group RAF undertook Operation Oyster, which heavily damaged the Philips Radio factory in Eindhoven with few casualties among the Dutch workers and civilians. The Philips works in Eindhoven was bombed again by the RAF on 30 March 1943.

Frits Philips, the son of Anton, was the only Philips family member to stay in the Netherlands. He saved the lives of 382 Jews by convincing the Nazis that they were indispensable for the production process at Philips. In 1943 he was held at the internment camp for political prisoners at Vught for several months because a strike at his factory reduced production. For his actions in saving the hundreds of Jews, he was recognized by Yad Vashem in 1995 as a "Righteous Among the Nations".

After the war the company was moved back to the Netherlands, with their headquarters in Eindhoven.
In 1949, the company began selling television sets. In 1950, it formed Philips Records, which eventually formed part of PolyGram.

Philips introduced the audio Compact Audio Cassette tape in 1963, and it was wildly successful. Compact cassettes were initially used for dictation machines for office typing stenographers and professional journalists. As their sound quality improved, cassettes would also be used to record sound and became the second mass media alongside vinyl records used to sell recorded music.

Philips introduced the first combination portable radio and cassette recorder, which was marketed as the "radiorecorder", and is now better known as the boom box. Later, the cassette was used in telephone answering machines, including a special form of cassette where the tape was wound on an endless loop. The C-cassette was used as the first mass storage device for early personal computers in the 1970s and 1980s. Philips reduced the cassette size for the professional needs with the Mini-Cassette, although it would not be as successful as the Olympus Microcassette. This became the predominant dictation medium up to the advent of fully digital dictation machines. Philips continued with computers through the early 1990s (see separate article: Philips Computers).

In 1972, Philips launched the world's first home video cassette recorder, in the UK, the N1500. Its relatively bulky video cassettes could record 30 minutes or 45 minutes. Later one-hour tapes were also offered. As competition came from Sony's Betamax and the VHS group of manufacturers, Philips introduced the N1700 system which allowed double-length recording. For the first time, a 2-hour movie could fit onto one video cassette. In 1977, the company unveiled a special promotional film for this system in the UK, featuring comedian Denis Norden. The concept was quickly copied by the Japanese makers, whose tapes were significantly cheaper. Philips made one last attempt at a new standard for video recorders with the Video 2000 system, with tapes that could be used on both sides and had 8 hours of total recording time. As Philips only sold its systems on the PAL standard and in Europe, and the Japanese makers sold globally, the scale advantages of the Japanese proved insurmountable and Philips withdrew the V2000 system and joined the VHS Coalition.

Philips had developed a LaserDisc early on for selling movies, but delayed its commercial launch for fear of cannibalizing its video recorder sales. Later Philips joined with MCA to launch the first commercial LaserDisc standard and players. In 1982, Philips teamed with Sony to launch the Compact Disc; this format evolved into the CD-R, CD-RW, DVD and later Blu-ray, which Philips launched with Sony in 1997 and 2006 respectively.

In 1984, the Dutch Philips Group bought out nearly a one-third share and took over the management of German company Grundig.

In 1984, Philips split off its activities on the field of photolithographic integrated circuit production equipment, the so-called wafer steppers, into a joint venture with ASM International, located in Veldhoven under the name ASML. Over the years, this new company has evolved into the world's leading manufacturer of chip production machines at the expense of competitors like Nikon and Canon.

In 1991, the company's name was changed from N.V. Philips Gloeilampenfabrieken to Philips Electronics N.V. At the same time, North American Philips was formally dissolved, and a new corporate division was formed in the US with the name Philips Electronics North America Corp.

In 1991-1992, Philips along with their subsidiary Magnavox, released the Philips CD-i, a combined CD player and home video game console. It sold one million units and was discontinued in 1998 after being heavily criticized amongst the gaming community.

In 1997, the company officers decided to move the headquarters from Eindhoven to Amsterdam along with the corporate name change to Koninklijke Philips Electronics N.V.

The move of the headquarter to Amsterdam was completed in 2001. Initially, the company was housed in the Rembrandt Tower. In 2002 it moved again, this time to the Breitner Tower. Philips Lighting, Philips Research, Philips Semiconductors (spun off as NXP in September 2006) and Philips Design, are still based in Eindhoven. Philips Healthcare is headquartered in both Best, Netherlands (near Eindhoven) and Andover, Massachusetts, United States (near Boston).

In 2000, Philips bought Optiva Corporation, the maker of Sonicare electric toothbrushes. The company was renamed Philips Oral Healthcare and made a subsidiary of Philips DAP. In 2001, Philips acquired Agilent Technologies' Healthcare Solutions Group (HSG) for EUR 2 billion.

In 2004, Philips abandoned the slogan "Let's make things better" in favour of a new one: "Sense and simplicity".

In December 2005 Philips announced its intention to sell or demerge its semiconductor division. On 1 September 2006, it was announced in Berlin that the name of the new company formed by the division would be NXP Semiconductors. On 2 August 2006, Philips completed an agreement to sell a controlling 80.1% stake in NXP Semiconductors to a consortium of private equity investors consisting of Kohlberg Kravis Roberts & Co. (KKR), Silver Lake Partners and AlpInvest Partners. On 21 August 2006, Bain Capital and Apax Partners announced that they had signed definitive commitments to join the acquiring consortium, a process which was completed on 1 October 2006.

In 2006 Philips bought out the company Lifeline Systems headquartered in Framingham, Massachusetts in a deal valued at $750 million, its biggest move yet to expand its consumer-health business (M). In August 2007, Philips acquired the company Ximis, Inc. headquartered in El Paso, Texas for their Medical Informatics Division. In October 2007, it purchased a Moore Microprocessor Patent (MPP) Portfolio license from The TPL Group.

On 21 December 2007, Philips and Respironics, Inc. announced a definitive agreement pursuant to which Philips acquired all of the outstanding shares of Respironics for US$66 per share, or a total purchase price of approximately €3.6 billion (US$5.1 billion) in cash.

On 21 February 2008, Philips completed the acquisition of VISICU Baltimore, Maryland through the merger of its indirect wholly owned subsidiary into VISICU. As a result of that merger, VISICU has become an indirect wholly owned subsidiary of Philips. VISICU was the creator of the eICU concept of the use of Telemedicine from a centralized facility to monitor and care for ICU patients.

The Philips physics laboratory was scaled down in the early 21st century, as the company ceased trying to be innovative in consumer electronics through fundamental research.

In January 2011, Philips agreed to acquire the assets of Preethi, a leading India-based kitchen appliances company. On 27 June 2011, Philips acquired Sectra Mamea AB, the mammography division of Sectra AB, together with the MicroDose brand.

Because net profit slumped 85 percent in Q3 2011, Philips announced a cut of 4,500 jobs to match part of an €800 million ($1.1 billion) cost-cutting scheme to boost profits and meet its financial target. In 2011, the company posted a loss of €1.3 billion, but earned a net profit in Q1 and Q2 2012, however the management wanted €1.1 billion cost-cutting which was an increase from €800 million and may cut another 2,200 jobs until end of 2014.
In March 2012, Philips announced its intention to sell, or demerge its television manufacturing operations to TPV Technology.

On 5 December 2012, the antitrust regulators of the European Union fined Philips and several other major companies for fixing prices of TV cathode-ray tubes in two cartels lasting nearly a decade.

On 29 January 2013, it was announced that Philips had agreed to sell its audio and video operations to the Japan-based Funai Electric for €150 million, with the audio business planned to transfer to Funai in the latter half of 2013, and the video business in 2017. As part of the transaction, Funai was to pay a regular licensing fee to Philips for the use of the Philips brand. The purchase agreement was terminated by Philips in October because of breach of contract. In April 2013, Philips announced a collaboration with Paradox Engineering for the realization and implementation of a "pilot project" on network-connected street-lighting management solutions. This project was endorsed by the San Francisco Public Utilities Commission (SFPUC).

In 2013, Philips omitted the word "Electronics" from its name, which is now Royal Philips N.V. On 13 November 2013, Philips unveiled its new brand line "Innovation and You" and a new design of its shield mark. The new brand positioning is cited by Philips to signify company's evolution and emphasize that innovation is only meaningful if it is based on an understanding of people's needs and desires.

On 28 April 2014, Philips agreed to sell their Woox Innovations subsidiary (consumer electronics) to Gibson Brands for $US135 million. On 23 September 2014, Philips announced a plan to split the company into two, separating the lighting business from the healthcare and consumer lifestyle divisions. it moved to complete this in March 2015 to an investment group for $3.3 billion

On February 2015, Philips acquired Volcano Corporation to strengthen its position in non-invasive surgery and imaging. In June 2016, Philips spun off its lighting division to focus on the healthcare division. In June 2017, Philips announced it would acquire US-based Spectranetics Corp, a manufacturer of devices to treat heart disease, for €1.9 billion (£1.68 billion) expanding its current image-guided therapy business.

In 2018, the lighting products division known as Philips Lighting N.V. was renamed Signify N.V. It continues to produce and market Philips-branded products such as Philips Hue color-changing LED light bulbs.

Past and present CEOs:

CEOs lighting


Past and Present CFOs (Chief Financial Officer)

Companies acquired by Philips through the years include ADAC Laboratories, Agilent Healthcare Solutions Group, Amperex, ATL Ultrasound, EKCO, Lifeline Systems, Magnavox, Marconi Medical Systems, Mullard, Optiva, Preethi, Pye, Respironics, Inc., Sectra Mamea AB, Signetics, VISICU, Volcano, VLSI, Ximis, portions of Westinghouse and the consumer electronics operations of Philco and Sylvania. Philips abandoned the Sylvania trademark which is now owned by Havells Sylvania except in Australia, Canada, Mexico, New Zealand, Puerto Rico and the USA where it is owned by Osram. Formed in November 1999 as an equal joint venture between Philips and Agilent Technologies, the light-emitting diode manufacturer Lumileds became a subsidiary of Phillips Lighting in August 2005 and a fully owned subsidiary in December 2006. An 80.1 percent stake in Lumileds was sold to Apollo Global Management in 2017.

Philips is registered in the Netherlands as a naamloze vennootschap and has its global headquarters in Amsterdam. At the end of 2013 Philips had 111 manufacturing facilities, 59 R&D Facilities across 26 countries and sales and service operations in around 100 countries.

Philips is organized into three main divisions: Philips Consumer Lifestyle (formerly Philips Consumer Electronics and Philips Domestic Appliances and Personal Care), Philips Healthcare (formerly Philips Medical Systems) and Philips Lighting. Philips achieved total revenues of €22.579 billion in 2011, of which €8.852 billion were generated by Philips Healthcare, €7.638 billion by Philips Lighting, €5.823 billion by Philips Consumer Lifestyle and €266 million from group activities. At the end of 2011 Philips had a total of 121,888 employees, of whom around 44% were employed in Philips Lighting, 31% in Philips Healthcare and 15% in Philips Consumer Lifestyle.

Philips invested a total of €1.61 billion in research and development in 2011, equivalent to 7.1% of sales. Philips Intellectual Property and Standards is the group-wide division responsible for licensing, trademark protection and patenting. Philips currently holds around 54,000 patent rights, 39,000 trademarks, 70,000 design rights and 4,400 domain name registrations.

Philips Thailand was established in 1952. It is a subsidiary which produces healthcare, lifestyle and lighting products. Philips started manufacturing in Thailand in 1960 with an incandescent lamp factory. Philips has diversified its production facilities to include a fluorescent lamp factory and a luminaries factory, serving Thai and worldwide markets.

Philips Hong Kong began operation in 1948. Philips Hong Kong houses the global headquarters of Philips' Audio Business Unit. It also house Philips' Asia Pacific regional office and headquarters for its Design Division, Domestic Appliances & Personal Care Products Division, Lighting Products Division and Medical System Products Division.

In 1974, Philips opened a lamp factory in Hong Kong. This has a capacity of 200 million pieces a year and is certified with ISO 9001:2000 and ISO 14001. Its product portfolio includes prefocus, lensend and E10 miniature light bulbs.

Philips established in Zhuhai, Guangdong in 1990. The site mainly manufactures Philishaves and healthcare products. In early 2008, Philips Lighting, a division of Royal Philips Electronics, opened a small engineering center in Shanghai to adapt the company's products to vehicles in Asia.

Philips began operations in India in 1930, with the establishment of Philips Electrical Co. (India) Pvt Ltd in Kolkata as a sales outlet for imported Philips lamps. In 1938, Philips established its first Indian lamp-manufacturing factory in Kolkata. In 1948, Philips started manufacturing radios in Kolkata. In 1959, a second radio factory was established near Pune. This was closed and sold around 2006. In 1957, the company converted into a public limited company, renamed "Philips India Ltd". In 1970 a new consumer electronics factory began operations in Pimpri near Pune. This is now called the 'Philips Healthcare Innovation Centre'. Also, a manufacturing facility 'Philips Centre for Manufacturing Excellence' was set up in Chakan, Pune in 2012. In 1996, the Philips Software Centre was established in Bangalore, later renamed the Philips Innovation Campus. In 2008, Philips India entered the water purifier market. In 2014, Philip's was ranked 12th among India's most trusted brands according to the Brand Trust Report, a study conducted by Trust Research Advisory.

Philips has been active in Israel since 1948 and in 1998, set up a wholly owned subsidiary, Philips Electronics (Israel) Ltd. The company has over 700 employees in Israel and generated sales of over $300 million in 2007.

Philips Medical Systems Technologies Ltd. (Haifa) is a developer and manufacturer of Computerized Tomography (CT), diagnostic and Medical Imaging systems. The company was founded in 1969 as Elscint by Elron Electronic Industries and was acquired by Marconi Medical Systems in 1998, which was itself acquired by Philips in 2001.

Philips Semiconductors formerly had major operations in Israel; these now form part of NXP Semiconductors.

Philips has been active in Pakistan since 1948 and has a wholly owned subsidiary, Philips Pakistan Limited (Formerly Philips Electrical Industries of Pakistan Limited).

The head office is in Karachi with regional sales offices in Lahore and Rawalpindi.

Philips France has its headquarters in Suresnes. The company employs over 3600 people nationwide.

Philips Lighting has manufacturing facilities in Chalon-sur-Saône (fluorescent lamps), Chartres (automotive lighting), Lamotte-Beuvron (architectural lighting by LEDs and professional indoor lighting), Longvic (lamps), Miribel (outdoor lighting), Nevers (professional indoor lighting).

Philips Germany was founded in 1926 in Berlin. Now its headquarters is located in Hamburg. Over 4900 people are employed in Germany.


Philips' Greece is headquartered in Halandri, Attica. As of 2012 Philips has no manufacturing plants in Greece, although there have been in the past.

Philips founded its Italian headquarter in 1918, basing it in Monza (Milan) where it still operates, for commercial activities only.

Philips' operations in Poland include: a European financial and accounting centre in Łódź; Philips Lighting facilities in Bielsko-Biała, Pabianice, Piła, and Kętrzyn; and a Philips Domestic Appliances facility in Białystok.

Philips started business in Portugal in 1927, as "Philips Portuguesa S.A.R.L.". Currently, Philips Portuguesa S.A. is headquartered in Oeiras near Lisbon. There were three Philips factories in Portugal: the FAPAE lamp factory in Lisbon; the Carnaxide magnetic-core memory factory near Lisbon, where the Philips Service organization was also based; and the Ovar factory in northern Portugal making camera components and remote control devices. The company still operates in Portugal with divisions for commercial lighting, medical systems and domestic appliances.

Philips Sweden has two main sites, Kista, Stockholm County, with regional sales, marketing and a customer support organization and Solna, Stockholm County, with the main office of the mammography division.

Philips UK has its headquarters in Guildford. The company employs over 2500 people nationwide.


In the past, Philips UK also included:

Philips Canada was founded in 1934. It is well known in medical systems for diagnosis and therapy, lighting technologies, shavers, and consumer electronics.

The Canadian headquarters are located in Markham, Ontario.

For several years, Philips manufactured lighting products in two Canadian factories. The London, Ontario, plant opened in 1971. It produced A19 lamps (including the "Royale" long life bulbs), PAR38 lamps and T19 lamps (originally a Westinghouse lamp shape). Philips closed the factory in May 2003. The Trois-Rivières, Quebec plant was a Westinghouse facility which Philips continued to run it after buying Westinghouse's lamp division in 1983. Philips closed this factory a few years later, in the late 1980s.

Philips Mexicana SA de CV is headquartered in Mexico City. Philips Lighting has manufacturing facilities in: Monterrey, Nuevo León; Ciudad Juárez, Chihuahua; and Tijuana, Baja California. Philips Consumer Electronics has a manufacturing facility in Ciudad Juárez, Chihuahua. Philips Domestic Appliances formerly operated a large factory in the Industrial Vallejo sector of Mexico City but this was closed in 2004.

Philips' Electronics North American headquarters is in Andover, Massachusetts. In early 2018, it was announced that the US headquarters would move to Cambridge, Massachusetts by 2020. Philips Lighting has its corporate office in Somerset, New Jersey, with manufacturing plants in Danville, Kentucky, Dallas, Salina, Kansas and Paris, Texas and distribution centers in Mountain Top, Pennsylvania El Paso, Texas, Ontario, California and Memphis, Tennessee. Philips Healthcare is headquartered in Cambridge, Massachusetts. The North American sales organization is based in Bothell, Washington. There are also manufacturing facilities in Andover, Massachusetts, Bothell, Washington, Baltimore, Maryland, Cleveland, Ohio, Foster City, California, Gainesville, Florida, Milpitas, California and Reedsville, Pennsylvania. Philips Healthcare also formerly had a factory in Knoxville, Tennessee. Philips Consumer Lifestyle has its corporate office in Stamford, Connecticut. Philips Lighting has a Color Kinetics office in Burlington, Massachusetts. Philips Research North American headquarters is in Cambridge, Massachusetts.

In 2007, Philips entered into a definitive merger agreement with North American luminaires company Genlyte Group Incorporated, which provides the company with a leading position in the North American luminaires (also known as ˜lighting fixtures"), controls and related products for a wide variety of applications, including solid state lighting. The company also acquired Respironics, which was a significant gain for its healthcare sector. On 21 February 2008 Philips completed the acquisition of VISICU Baltimore, Maryland. VISICU was the creator of the eICU concept of the use of Telemedicine from a centralized facility to monitor and care for ICU patients.

Philips Australia was founded in 1927 and is headquartered in North Ryde, New South Wales and also manages the New Zealand operation from there. The company currently employs around 800 people. Regional sales and support offices are located in Melbourne, Brisbane, Adelaide, Perth and Auckland.

Current activities include: Philips Healthcare (also responsible for New Zealand operations); Philips Lighting (also responsible for New Zealand operations); Phillips Oral Healthcare, Phillips Professional Dictation Solutions, Phillips Professional Display Solutions, Phillips AVENT Professional, Philips Consumer Lifestyle (also responsible for New Zealand operations); Philips Sleep & Respiratory Care (formerly Respironics), with its ever-increasing national network of Sleepeasy Centres ; Philips Dynalite (Lighting Control systems, acquired in 2009, global design and manufacturing centre) and Philips Selecon NZ (Lighting Entertainment product design and manufacture).

Philips do Brasil () was founded in 1924 in Rio de Janeiro. In 1929, Philips started to sell radio receivers. In the 1930s, Philips was making its light bulbs and radio receivers in Brazil. From 1939 to 1945, World War II forced Brazilian branch of Philips to sell bicycles, refrigerators and insecticides. After the war, Philips had a great industrial expansion in Brazil, and was among the first groups to establish in Manaus Free Zone. In the 1970s, Philips Records was a major player in Brazil recording industry. Nowadays, Philips do Brasil is one of the largest foreign-owned companies in Brazil. Philips uses the brand Walita for domestic appliances in Brazil.

Philips subsidiary Philips-Duphar(nl) manufactured pharmaceuticals for human and veterinary use and products for crop protection. Duphar was sold to Solvay in 1990. In subsequent years Solvay sold off all divisions to other companies (crop protection to UniRoyal, now Chemtura, the veterinary division to Fort Dodge, a division of Wyeth, and the pharmaceutical division to Abbott Laboratories).

PolyGram, Philips' music television and movies division, was sold to Seagram in 1998; merged into Universal Music Group. Philips Records continues to operate as record label of UMG, its name licensed from its former parent.

Origin, now part of Atos Origin, is a former division of Philips.

ASM Lithography is a spin-off from a division of Philips.

Hollandse Signaalapparaten was a manufacturer of military electronics. The business was sold to Thomson-CSF in 1990 and is now Thales Nederland.

NXP Semiconductors, formerly known as Philips Semiconductors, was sold a consortium of private equity investors in 2006. On 6 August 2010, NXP completed its IPO, with shares trading on NASDAQ.

Philips used to sell major household appliances (whitegoods) under the name Philips. After selling the Major Domestic Appliances division to Whirlpool Corporation it changed from Philips Whirlpool to Whirlpool Philips and finally to just Whirlpool. Whirlpool bought a 53% stake in Philips' major appliance operations to form Whirlpool International. Whirlpool bought Philips' remaining interest in Whirlpool International in 1991.

Philips Cryogenics was split off in 1990 to form the Stirling Cryogenics BV, Netherlands. This company is still active in the development and manufacturing of Stirling cryocoolers and cryogenic cooling systems.

North American Philips distributed AKG Acoustics products under the AKG of America, Philips Audio/Video, Norelco and AKG Acoustics Inc. branding until AKG set up its North American division in San Leandro, California in 1985. (AKG's North American division has since moved to Northridge, California.)

Polymer Vision was a Philips spin-off that manufactured a flexible e-ink display screen. The company closed in 2009.

Philips' core products are consumer electronics and electrical products (including small domestic appliances, shavers, beauty appliances, mother and childcare appliances, electric toothbrushes and coffee makers (products like Smart Phones, audio equipment, Blu-ray players, computer accessories and televisions are sold under license)); and healthcare products (including CT scanners, ECG equipment, mammography equipment, monitoring equipment, MRI scanners, radiography equipment, resuscitation equipment, ultrasound equipment and X-ray equipment);



Philips healthcare products include:







In 1913, in celebration of the 100th anniversary of the liberation of the Netherlands, Philips founded "Philips Sport Vereniging" (Philips Sports Club, now commonly known as PSV). The club is active in numerous sports, but is now best known for its football team, PSV Eindhoven, and swimming team. Philips owns the naming rights to Philips Stadion in Eindhoven, which is the home ground of PSV Eindhoven.

Outside of the Netherlands, Philips sponsors and has sponsored numerous sport clubs, sport facilities and events. In November 2008 Philips renewed and extended its F1 partnership with AT&T Williams. Philips owns the naming rights to the Philips Arena in Atlanta, Georgia and to the "Philips Championship", the premier basketball league in Australia, traditionally known as the National Basketball League. From 1988 to 1993 Philips was the principal sponsor of the Australian rugby league team The Balmain Tigers.And Indonesian football club side Persiba Balikpapan From 1998 to 2000, Philips sponsored the Winston Cup #7 entry for Geoff Bodine Racing, later Ultra Motorsports, for drivers Geoff Bodine and Michael Waltrip.

Outside of sports Philips sponsors the international "Philips Monsters of Rock festival".

Philips is running the EcoVision4 initiative in which it committed to a number of environmentally positive improvements by 2012.

Also Philips marks its "green" products with the Philips Green Logo, identifying them as products that have a significantly better environmental performance than their competitors or predecessors.

In 2011, Philips won a $10 million cash prize from the US Department of Energy for winning its L-Prize competition, to produce a high-efficiency, long operating life replacement for a standard 60-W incandescent lightbulb. The winning LED lightbulb, which was made available to consumers in April 2012, produces slightly more than 900 lumens at an input power of only 10 W.

In Greenpeace's 2012 Guide to Greener Electronics, that ranks electronics manufacturers on sustainability, climate and energy and how green their products are, Philips ranks 10th place with a score of 3.8/10. The company was the top scorer in the Energy section due to its energy advocacy work calling upon the EU to adopt a 30% reduction for greenhouse gas emissions by 2020. It is also praised for its new products which are free from PVC plastic and BFRs. However, the guide criticizes Phillips' sourcing of fibres for paper, arguing it must develop a paper procurement policy which excludes suppliers involved in deforestation and illegal logging.

Philips have made some considerable progress since 2007 (when it was first ranked in this guide), in particular by supporting the Individual Producer Responsibility principle, which means that the company is accepting the responsibility for the toxic impacts of its products on e-waste dumps around the world.




</doc>
<doc id="23551" url="https://en.wikipedia.org/wiki?curid=23551" title="Perciformes">
Perciformes

Perciformes, also called the Percomorpha or Acanthopteri, are the most numerous order of vertebrates, containing about 41% of all bony fish. Perciformes means "perch-like". They belong to the class of ray-finned fish, and comprise over 10,000 species found in almost all aquatic ecosystems.

The order contains about 160 families, which is the most of any order within the vertebrates. It is also the most variably sized order of vertebrates, ranging from the 7-mm (1/4-in) "Schindleria brevipinguis" to the 5-m (16.4 ft) marlin in the genus "Makaira". They first appeared and diversified in the Late Cretaceous.

Among the well-known members of this group are perch and darters (Percidae), sea bass and groupers (Serranidae), mackerel and tuna (Scombridae), billfish (Xiphiidae and Istiophoridae), and icefish (Nototheniidae).

The dorsal and anal fins are divided into anterior spiny and posterior soft-rayed portions, which may be partially or completely separated. The pelvic fins usually have one spine and up to five soft rays, positioned unusually far forward under the chin or under the belly. Scales are usually ctenoid, although sometimes they are cycloid or otherwise modified.

Classification is controversial. As traditionally defined before the introduction of cladistics, the Perciformes are almost certainly paraphyletic. Other orders that should possibly be included as suborders are the Scorpaeniformes, Tetraodontiformes, and Pleuronectiformes.
Of the presently recognized suborders, several may be paraphyletic, as well. These are grouped by suborder/superfamily, generally following the text "Fishes of the World".


</doc>
<doc id="23553" url="https://en.wikipedia.org/wiki?curid=23553" title="Asimina">
Asimina

Asimina is a genus of small trees or shrubs described as a genus in 1763.

"Asimina" has large simple leaves and large fruit. It is native to eastern North America and collectively referred to as pawpaw. The genus includes the widespread common pawpaw "Asimina triloba," which bears the largest edible fruit indigenous to the continent. Pawpaws are native to 26 states of the U.S. and to Ontario in Canada. The common pawpaw is a patch-forming (clonal) understory tree found in well-drained, deep, fertile bottomland and hilly upland habitat. Pawpaws are in the same plant family (Annonaceae) as the custard-apple, cherimoya, sweetsop, ylang-ylang and soursop; the genus is the only member of that family not confined to the tropics.

The genus name "Asimina" was first described and named by Michel Adanson, a French naturalist of Scottish descent. The name is adapted from the Native American name "assimin" through the French colonial "asiminier."

The common name pawpaw, also spelled paw paw, paw-paw, and papaw, probably derives from the Spanish "papaya", perhaps because of the superficial similarity of their fruits.

Pawpaws are shrubs or small trees to tall. The northern, cold-tolerant common pawpaw ("Asimina triloba") is deciduous, while the southern species are often evergreen.

The leaves are alternate, obovate, entire, long and broad.

The flowers of pawpaws are produced singly or in clusters of up to eight together; they are large, 4–6 cm across, perfect, with six sepals and petals (three large outer petals, three smaller inner petals). The petal color varies from white to purple or red-brown.

The fruit of the common pawpaw is a large edible berry, long and broad, weighing from , with numerous seeds; it is green when unripe, maturing to yellow or brown. It has a flavor somewhat similar to both banana and mango, varying significantly by cultivar, and has more protein than most fruits.


The common pawpaw is native to shady, rich bottom lands, where it often forms a dense undergrowth in the forest, often appearing as a patch or thicket of individual small slender trees.

Pawpaw flowers are insect-pollinated, but fruit production is limited since few if any pollinators are attracted to the flower's faint, or sometimes non-existent scent. The flowers produce an odor similar to that of rotting meat to attract blowflies or carrion beetles for cross pollination. Other insects that are attracted to pawpaw plants include scavenging fruit flies, carrion flies and beetles. Because of difficult pollination, some believe the flowers are self-incompatible.

Pawpaw fruit may be eaten by foxes, opossums, squirrels and raccoons. However, pawpaw leaves and twigs are seldom consumed by rabbits or deer.

The leaves, twigs, and bark of the common pawpaw tree contain natural insecticides known as acetogenins.

Larvae of the zebra swallowtail butterfly feed exclusively on young leaves of the various pawpaw species, but never occur in great numbers on the plants.

Wild-collected fruits of the common pawpaw ("Asimina triloba") have long been a favorite treat throughout the tree's extensive native range in eastern North America. Fresh pawpaw fruits are commonly eaten raw; however, they do not store or ship well unless frozen. The fruit pulp is also often used locally in baked dessert recipes, with pawpaw often substituted in many banana-based recipes.

Pawpaws have never been cultivated for fruit on the scale of apples and peaches, but interest in pawpaw cultivation has increased in recent decades. However, only frozen fruit will store or ship well. Other methods of preservation include dehydration, production of jams or jellies, and pressure canning.

The pawpaw is also gaining in popularity among backyard gardeners because of the tree's distinctive growth habit, the appeal of its fresh fruit, and its relatively low maintenance needs once established. The common pawpaw is also of interest in ecological restoration plantings since this tree grows well in wet soil and has a strong tendency to form well-rooted clonal thickets.

The several other species of "Asimina" have few economic uses.

The earliest documentation of pawpaws is in the 1541 report of the Spanish de Soto expedition, who found Native Americans cultivating it east of the Mississippi River. Chilled pawpaw fruit was a favorite dessert of George Washington, and Thomas Jefferson planted it at his home in Virginia, Monticello. The Lewis and Clark Expedition sometimes subsisted on pawpaws during their travels. The common pawpaw was designated as the Ohio state native fruit in 2009.


 


</doc>
<doc id="23555" url="https://en.wikipedia.org/wiki?curid=23555" title="Pentecostalism">
Pentecostalism

Pentecostalism or Classical Pentecostalism is a renewal movement within Protestant Christianity that places special emphasis on a direct personal experience of God through the baptism with the Holy Spirit. The term "Pentecostal" is derived from Pentecost, the Greek name for the Jewish Feast of Weeks. For Christians, this event commemorates the descent of the Holy Spirit upon the followers of Jesus Christ, as described in the second chapter of the Acts of the Apostles.

Like other forms of evangelical Protestantism, Pentecostalism adheres to the inerrancy of the Bible and the necessity of accepting Jesus Christ as personal Lord and Savior. It is distinguished by belief in the baptism in the Holy Spirit that enables a Christian to live a Spirit-filled and empowered life. This empowerment includes the use of spiritual gifts such as speaking in tongues and divine healing—two other defining characteristics of Pentecostalism. Because of their commitment to biblical authority, spiritual gifts, and the miraculous, Pentecostals tend to see their movement as reflecting the same kind of spiritual power and teachings that were found in the Apostolic Age of the early church. For this reason, some Pentecostals also use the term "Apostolic" or "Full Gospel" to describe their movement.

Pentecostalism emerged in the early 20th century among radical adherents of the Holiness movement who were energized by revivalism and expectation for the imminent Second Coming of Christ. Believing that they were living in the end times, they expected God to spiritually renew the Christian Church thereby bringing to pass the restoration of spiritual gifts and the evangelization of the world. In 1900, Charles Parham, an American evangelist and faith healer, began teaching that speaking in tongues was the Bible evidence of Spirit baptism and along with William J. Seymour, a Wesleyan-Holiness preacher, he taught that this was the third work of grace. The three-year-long Azusa Street Revival, founded and led by Seymour in Los Angeles, California, resulted in the spread of Pentecostalism throughout the United States and the rest of the world as visitors carried the Pentecostal experience back to their home churches or felt called to the mission field. While virtually all Pentecostal denominations trace their origins to Azusa Street, the movement has experienced a variety of divisions and controversies. An early dispute centered on challenges to the doctrine of the Trinity. As a result, the Pentecostal movement is divided between trinitarian and non-trinitarian branches, resulting in the emergence of Oneness Pentecostals.

Comprising over 700 denominations and a large number of independent churches, there is no central authority governing Pentecostalism; however, many denominations are affiliated with the Pentecostal World Fellowship. There are over 279 million Pentecostals worldwide, and the movement is growing in many parts of the world, especially the global South. Since the 1960s, Pentecostalism has increasingly gained acceptance from other Christian traditions, and Pentecostal beliefs concerning Spirit baptism and spiritual gifts have been embraced by non-Pentecostal Christians in Protestant and Catholic churches through the Charismatic Movement. Together, Pentecostal and Charismatic Christianity numbers over 500 million adherents.

Pentecostalism is an evangelical faith, emphasizing the reliability of the Bible and the need for the transformation of an individual's life through faith in Jesus. Like other evangelicals, Pentecostals generally adhere to the Bible's divine inspiration and inerrancy—the belief that the Bible, in the original manuscripts in which it was written, is infallible. Pentecostals emphasize the teaching of the "full gospel" or "foursquare gospel". The term "foursquare" refers to the four fundamental beliefs of Pentecostalism: Jesus saves according to ; baptizes with the Holy Spirit according to Acts 2:4; heals bodily according to James 5:15; and is coming again to receive those who are saved according to 1 Thessalonians 4:16–17.

The central belief of classical Pentecostalism is that through the death, burial, and resurrection of Jesus Christ, sins can be forgiven and humanity reconciled with God. This is the Gospel or "good news". The fundamental requirement of Pentecostalism is that one be born again. The new birth is received by the grace of God through faith in Christ as Lord and Savior. In being born again, the believer is regenerated, justified, adopted into the family of God, and the Holy Spirit's work of sanctification is initiated.

Classical Pentecostal soteriology is generally Arminian rather than Calvinist. The security of the believer is a doctrine held within Pentecostalism; nevertheless, this security is conditional upon continual faith and repentance. Pentecostals believe in both a literal heaven and hell, the former for those who have accepted God's gift of salvation and the latter for those who have rejected it.

For most Pentecostals there is no other requirement to receive salvation. Baptism with the Holy Spirit and speaking in tongues are not generally required, though Pentecostal converts are usually encouraged to seek these experiences. A notable exception is Jesus' Name Pentecostalism, most adherents of which believe both water baptism and Spirit baptism are integral components of salvation.

Pentecostals identify three distinct uses of the word "baptism" in the New Testament:

While the figure of Jesus Christ and his redemptive work are at the center of Pentecostal theology, that redemptive work is believed to provide for a fullness of the Holy Spirit of which believers in Christ may take advantage. The majority of Pentecostals believe that at the moment a person is born again, the new believer has the presence (indwelling) of the Holy Spirit. While the Spirit "dwells" in every Christian, Pentecostals believe that all Christians should seek to be "filled" with him. The Spirit's "filling", "falling upon", "coming upon", or being "poured out upon" believers is called the baptism with the Holy Spirit. Pentecostals define it as a definite experience occurring after salvation whereby the Holy Spirit comes upon the believer to anoint and empower him or her for special service. It has also been described as "a baptism into the love of God".

The main purpose of the experience is to grant power for Christian service. Other purposes include power for spiritual warfare (the Christian struggles against spiritual enemies and thus requires spiritual power), power for overflow (the believer's experience of the presence and power of God in his or her life flows out into the lives of others), and power for ability (to follow divine direction, to face persecution, to exercise spiritual gifts for the edification of the church, etc.).

Pentecostals believe that the baptism with the Holy Spirit is available to all Christians. Repentance from sin and being born again are fundamental requirements to receive it. There must also be in the believer a deep conviction of needing more of God in his or her life, and a measure of consecration by which the believer yields himself or herself to the will of God. Citing instances in the Book of Acts where believers were Spirit baptized before they were baptized with water, most Pentecostals believe a Christian need not have been baptized in water to receive Spirit baptism. However, Pentecostals do believe that the biblical pattern is "repentance, regeneration, water baptism, and then the baptism with the Holy Ghost". There are Pentecostal believers who have claimed to receive their baptism with the Holy Spirit while being water baptized.

It is received by having faith in God's promise to fill the believer and in yielding the entire being to Christ. Certain conditions, if present in a believer's life, could cause delay in receiving Spirit baptism, such as "weak faith, unholy living, imperfect consecration, and egocentric motives". In the absence of these, Pentecostals teach that seekers should maintain a persistent faith in the knowledge that God will fulfill his promise. For Pentecostals, there is no prescribed manner in which a believer will be filled with the Spirit. It could be expected or unexpected, during public or private prayer.

Pentecostals expect certain results following baptism with the Holy Spirit. Some of these are immediate while others are enduring or permanent. Most Pentecostal denominations teach that speaking in tongues is an immediate or initial physical evidence that one has received the experience. Some teach that any of the gifts of the Spirit can be evidence of having received Spirit baptism. Other immediate evidences include giving God praise, having joy, and desiring to testify about Jesus. Enduring or permanent results in the believer's life include Christ glorified and revealed in a greater way, a "deeper passion for souls", greater power to witness to nonbelievers, a more effective prayer life, greater love for and insight into the Bible, and the manifestation of the gifts of the Spirit.

Pentecostals, with their background in the Holiness movement, historically teach that baptism with the Holy Spirit, as evidenced by glossolalia, is the third work of grace, which follows the new birth (first work of grace) and entire sanctification (second work of grace).

While the baptism with the Holy Spirit is a definite experience in a believer's life, Pentecostals view it as just the beginning of living a Spirit-filled life. Pentecostal teaching stresses the importance of continually being filled with the Spirit. There is only one baptism with the Spirit, but there should be many infillings with the Spirit throughout the believer's life.

Pentecostalism is a holistic faith, and the belief that Jesus is Healer is one quarter of the full gospel. Pentecostals cite four major reasons for believing in divine healing: 1) it is reported in the Bible, 2) Jesus' healing ministry is included in his atonement (thus divine healing is part of salvation), 3) "the whole gospel is for the whole person"—spirit, soul, and body, 4) sickness is a consequence of the Fall of Man and salvation is ultimately the restoration of the fallen world. In the words of Pentecostal scholar Vernon L. Purdy, "Because sin leads to human suffering, it was only natural for the Early Church to understand the ministry of Christ as the alleviation of human suffering, since he was God's answer to sin ... The restoration of fellowship with God is the most important thing, but this restoration not only results in spiritual healing but many times in physical healing as well." In the book "In Pursuit of Wholeness: Experiencing God's Salvation for the Total Person", Pentecostal writer and Church historian Wilfred Graves, Jr. describes the healing of the body as a physical expression of salvation.

For Pentecostals, spiritual and physical healing serves as a reminder and testimony to Christ's future return when his people will be completely delivered from all the consequences of the fall. However, not everyone receives healing when they pray. It is God in his sovereign wisdom who either grants or withholds healing. Common reasons that are given in answer to the question as to why all are not healed include: God teaches through suffering, healing is not always immediate, lack of faith on the part of the person needing healing, and personal sin in one's life (however, this does not mean that all illness is caused by personal sin). Regarding healing and prayer Purdy states:

Pentecostals believe that prayer is central in receiving healing. Pentecostals look to scriptures such as James 5:13–16 for direction regarding healing prayer. One can pray for one's own healing (verse 13) and for the healing of others (verse 16); no special gift or clerical status is necessary. Verses 14–16 supply the framework for congregational healing prayer. The sick person expresses his or her faith by calling for the elders of the church who pray over and anoint the sick with olive oil. The oil is a symbol of the Holy Spirit.

Besides prayer, there are other ways in which Pentecostals believe healing can be received. One way is based on Mark 16:17–18 and involves believers laying hands on the sick. This is done in imitation of Jesus who often healed in this manner. Another method that is found in some Pentecostal churches is based on the account in Acts 19:11–12 where people were healed when given handkerchiefs or aprons worn by the Apostle Paul. This practice is described by Duffield and Van Cleave in "Foundations of Pentecostal Theology":

During the initial decades of the movement, Pentecostals thought it was sinful to take medicine or receive care from doctors. Over time, Pentecostals moderated their views concerning medicine and doctor visits; however, a minority of Pentecostal churches continues to rely exclusively on prayer and divine healing. For example, doctors in the United Kingdom reported that a minority of Pentecostal HIV patients was encouraged to stop taking their medicines and parents were told to stop giving medicine to their children, trends that placed lives at risk.

The last element of the gospel is that Jesus is the "Soon Coming King". For Pentecostals, "every moment is eschatological" since at any time Christ may return. This "personal and imminent" Second Coming is for Pentecostals the motivation for practical Christian living including: personal holiness, meeting together for worship, faithful Christian service, and evangelism (both personal and worldwide). Many, if not the majority, of Pentecostals are premillennial dispensationalists believing in a pretribulation rapture.

Dispensationalism, Futurism. Pre-tribulation rapture theology was popularized extensively in the 1830s by John Nelson Darby, and further popularized in the United States in the early 20th century by the wide circulation of the Scofield Reference Bible.

Pentecostals are continuationists, meaning they believe that all of the spiritual gifts, including the miraculous or "sign gifts", found in 1 Corinthians 12:4–11, 12:27–31, Romans 12:3–8, and Ephesians 4:7–16 continue to operate within the Church in the present time. Pentecostals place the gifts of the Spirit in context with the fruit of the Spirit. The fruit of the Spirit is the result of the new birth and continuing to abide in Christ. It is by the fruit exhibited that spiritual character is assessed. Spiritual gifts are received as a result of the baptism with the Holy Spirit. As gifts freely given by the Holy Spirit, they cannot be earned or merited, and they are not appropriate criteria with which to evaluate one's spiritual life or maturity. Pentecostals see in the biblical writings of Paul an emphasis on having both character and power, exercising the gifts in love.

Just as fruit should be evident in the life of every Christian, Pentecostals believe that every Spirit-filled believer is given some capacity for the manifestation of the Spirit. It is important to note that the exercise of a gift is a manifestation of the Spirit, not of the gifted person, and though the gifts operate through people, they are primarily gifts given to the Church. They are valuable only when they minister spiritual profit and edification to the body of Christ. Pentecostal writers point out that the lists of spiritual gifts in the New Testament do not seem to be exhaustive. It is generally believed that there are as many gifts as there are useful ministries and functions in the Church. A spiritual gift is often exercised in partnership with another gift. For example, in a Pentecostal church service, the gift of tongues might be exercised followed by the operation of the gift of interpretation.

According to Pentecostals, all manifestations of the Spirit are to be judged by the church. This is made possible, in part, by the gift of discerning of spirits, which is the capacity for discerning the source of a spiritual manifestation—whether from the Holy Spirit, an evil spirit, or from the human spirit. While Pentecostals believe in the current operation of all the spiritual gifts within the church, their teaching on some of these gifts has generated more controversy and interest than others. There are different ways in which the gifts have been grouped. W. R. Jones suggests three categories, illumination (Word of Wisdom, word of knowledge, discerning of spirits), action (Faith, working of miracles and gifts of healings) and communication (Prophecy, tongues and interpretation of tongues). Duffield and Van Cleave use two categories: the vocal and the power gifts.

The gifts of prophecy, tongues, interpretation of tongues, and words of wisdom and knowledge are called the vocal gifts. Pentecostals look to 1 Corinthians 14 for instructions on the proper use of the spiritual gifts, especially the vocal ones. Pentecostals believe that prophecy is the vocal gift of preference, a view derived from 1 Corinthians 14. Some teach that the gift of tongues is equal to the gift of prophecy when tongues are interpreted. Prophetic and glossolalic utterances are not to replace the preaching of the Word of God nor to be considered as equal to or superseding the written Word of God, which is the final authority for determining teaching and doctrine.

Pentecostals understand the word of wisdom and the word of knowledge to be supernatural revelations of wisdom and knowledge by the Holy Spirit. The word of wisdom is defined as a revelation of the Holy Spirit that applies scriptural wisdom to a specific situation that a Christian community faces. The word of knowledge is often defined as the ability of one person to know what God is currently doing or intends to do in the life of another person.

Pentecostals agree with the Protestant principle of "sola Scriptura". The Bible is the "all sufficient rule for faith and practice"; it is "fixed, finished, and objective revelation". Alongside this high regard for the authority of scripture is a belief that the gift of prophecy continues to operate within the Church. Pentecostal theologians Duffield and van Cleave described the gift of prophecy in the following manner: "Normally, in the operation of the gift of prophecy, the Spirit heavily anoints the believer to speak forth to the body not premeditated words, but words the Spirit supplies spontaneously in order to uplift and encourage, incite to faithful obedience and service, and to bring comfort and consolation."

Any Spirit-filled Christian, according to Pentecostal theology, has the potential, as with all the gifts, to prophesy. Sometimes, prophecy can overlap with preaching "where great unpremeditated truth or application is provided by the Spirit, or where special revelation is given beforehand in prayer and is empowered in the delivery".

While a prophetic utterance at times might foretell future events, this is not the primary purpose of Pentecostal prophecy and is never to be used for personal guidance. For Pentecostals, prophetic utterances are fallible, i.e. subject to error. Pentecostals teach that believers must discern whether the utterance has edifying value for themselves and the local church. Because prophecies are subject to the judgement and discernment of other Christians, most Pentecostals teach that prophetic utterances should never be spoken in the first person (e.g. "I, the Lord") but always in the third person (e.g. "Thus saith the Lord" or "The Lord would have...").

A Pentecostal believer in a spiritual experience may vocalize fluent, unintelligible utterances (glossolalia) or articulate a natural language previously unknown to them (xenoglossy). Commonly termed "speaking in tongues", this vocal phenomenon is believed by Pentecostals to include an endless variety of languages. According to Pentecostal theology, the language spoken (1) may be an unlearned human language, such as the Bible claims happened on the Day of Pentecost, or (2) it might be of heavenly (angelic) origin. In the first case, tongues could work as a sign by which witness is given to the unsaved. In the second case, tongues are used for praise and prayer when the mind is superseded and "the speaker in tongues speaks to God, speaks mysteries, and ... no one understands him".

Within Pentecostalism, there is a belief that speaking in tongues serves two functions. Tongues as the "initial evidence" of the third work of grace, baptism with the Holy Spirit, and in individual prayer serves a different purpose than tongues as a spiritual gift. All Spirit-filled believers, according to initial evidence proponents, will speak in tongues when baptized in the Spirit and, thereafter, will be able to express prayer and praise to God in an unknown tongue. This type of tongue speaking forms an important part of many Pentecostals' personal daily devotions. When used in this way, it is referred to as a "prayer language" as the believer is speaking unknown languages not for the purpose of communicating with others but for "communication between the soul and God". Its purpose is for the spiritual edification of the individual. Pentecostals believe the private use of tongues in prayer (i.e. "prayer in the Spirit") "promotes a deepening of the prayer life and the spiritual development of the personality". From Romans 8:26–27, Pentecostals believe that the Spirit intercedes for believers through tongues; in other words, when a believer prays in an unknown tongue, the Holy Spirit is supernaturally directing the believer's prayer.

Besides acting as a prayer language, tongues also function as the "gift of tongues". Not all Spirit-filled believers possess the gift of tongues. Its purpose is for gifted persons to publicly "speak with God in praise, to pray or sing in the Spirit, or to speak forth in the congregation". There is a division among Pentecostals on the relationship between the gifts of tongues and prophecy. One school of thought believes that the gift of tongues is always directed from man to God, in which case it is always prayer or praise spoken to God but in the hearing of the entire congregation for encouragement and consolation. Another school of thought believes that the gift of tongues can be prophetic, in which case the believer delivers a "message in tongues"—a prophetic utterance given under the influence of the Holy Spirit—to a congregation.

Whether prophetic or not, however, Pentecostals are agreed that all public utterances in an unknown tongue must be interpreted in the language of the gathered Christians. This is accomplished by the gift of interpretation, and this gift can be exercised by the same individual who first delivered the message (if he or she possesses the gift of interpretation) or by another individual who possesses the required gift. If a person with the gift of tongues is not sure that a person with the gift of interpretation is present and is unable to interpret the utterance him or herself, then the person should not speak. Pentecostals teach that those with the gift of tongues should pray for the gift of interpretation. Pentecostals do not require that an interpretation be a literal word-for-word translation of a glossolalic utterance. Rather, as the word "interpretation" implies, Pentecostals expect only an accurate explanation of the utterance's meaning.

Besides the gift of tongues, Pentecostals may also use glossolalia as a form of praise and worship in corporate settings. Pentecostals in a church service may pray aloud in tongues while others pray simultaneously in the common language of the gathered Christians. This use of glossolalia is seen as an acceptable form of prayer and therefore requires no interpretation. Congregations may also corporately sing in tongues, a phenomenon known as singing in the Spirit.

Speaking in tongues is not universal among Pentecostal Christians. In 2006, a ten-country survey by the Pew Forum on Religion and Public Life found that 49 percent of Pentecostals in the US, 50 percent in Brazil, 41 percent in South Africa, and 54 percent in India said they "never" speak or pray in tongues.

The gifts of power are distinct from the vocal gifts in that they do not involve utterance. Included in this category are the gift of faith, gifts of healing, and the gift of miracles. The gift of faith (sometimes called "special" faith) is different from "saving faith" and normal Christian faith in its degree and application. This type of faith is a manifestation of the Spirit granted only to certain individuals "in times of special crisis or opportunity" and endues them with "a divine certainty ... that triumphs over everything". It is sometimes called the "faith of miracles" and is fundamental to the operation of the other two power gifts.

Pentecostals are divided over the nature of the Godhead. The majority of Pentecostal denominations believe in the doctrine of the Trinity, which is considered to be Christian orthodoxy. Oneness Pentecostals (self-identifying as "Apostolic Pentecostals") are nontrinitarian Christians, believing in a "Oneness" theology about God. The Oneness doctrine may be considered a form of Modalism, an ancient teaching considered heresy by most Christians.

In Oneness theology, the Godhead is not three persons united by one substance, but one person who reveals himself as three different modes. Thus, God manifests himself as Father within creation, he becomes Son by virtue of his incarnation as Jesus Christ, and he becomes the Holy Spirit by way of his activity in the life of the believer.

In stark contrast to Oneness Pentecostals, Trinitarian Pentecostals hold to the traditional doctrine of the Trinity, that is, the Godhead is not seen as simply three modes or titles of God manifest at different points in history, but is composed of three completely distinct persons who are co-eternal with each other and united as one substance. Thus the Son is from all eternity who became incarnate as Jesus, and likewise the Holy Spirit is from all eternity, and both are with the eternal Father from all eternity. Trinitarian Pentecostals, and most other mainstream Christian groups, may consider Oneness Pentecostals heretical. On the flip side, Oneness Pentecostals may view the doctrine of the Trinity as polytheistic.

Traditional Pentecostal worship has been described as a "gestalt made up of prayer, singing, sermon, the operation of the gifts of the Spirit, altar intercession, offering, announcements, testimonies, musical specials, Scripture reading, and occasionally the Lord's supper". Russell P. Spittler identified five values that govern Pentecostal spirituality. The first was individual experience, which emphasizes the Holy Spirit's personal work in the life of the believer. Second was orality, a feature that might explain Pentecostalism's success in evangelizing nonliterate cultures. The third was spontaneity; members of Pentecostal congregations are expected to follow the leading of the Holy Spirit, sometimes resulting in unpredictable services. The fourth value governing Pentecostal spirituality was "otherworldliness" or asceticism, which was partly informed by Pentecostal eschatology. The final and fifth value was a commitment to biblical authority, and many of the distinctive practices of Pentecostals are derived from a literal reading of scripture.

Spontaneity is a characteristic element of Pentecostal worship. This was especially true in the movement's earlier history, when anyone could initiate a song, chorus, or spiritual gift. Even as Pentecostalism has become more organized and formal, with more control exerted over services, the concept of spontaneity has retained an important place within the movement and continues to inform stereotypical imagery, such as the derogatory "holy roller". The phrase "Quench not the Spirit", derived from 1 Thessalonians 5:19, is used commonly and captures the thought behind Pentecostal spontaneity.

Prayer plays an important role in Pentecostal worship. Collective oral prayer, whether glossolalic or in the vernacular or a mix of both, is common. While praying, individuals may lay hands on a person in need of prayer, or they may raise their hands in response to biblical commands (1 Timothy 2:8). The raising of hands (which itself is a revival of the ancient orans posture) is an example of some Pentecostal worship practices that have been widely adopted by the larger Christian world. Pentecostal musical and liturgical practice have also played an influential role in shaping contemporary worship trends, with Pentecostal churches such as Hillsong Church being the leading producers of congregational music.

Several spontaneous practices have become characteristic of Pentecostal worship. Being "slain in the Spirit" or "falling under the power" is a form of prostration in which a person falls backwards, as if fainting, while being prayed over. It is at times accompanied by glossolalic prayer; at other times, the person is silent. It is believed by Pentecostals to be caused by "an overwhelming experience of the presence of God", and Pentecostals sometimes receive the baptism in the Holy Spirit in this posture. Another spontaneous practice is "dancing in the Spirit". This is when a person leaves their seat "spontaneously 'dancing' with eyes closed without bumping into nearby persons or objects". It is explained as the worshipper becoming "so enraptured with God's presence that the Spirit takes control of physical motions as well as the spiritual and emotional being". Pentecostals derive biblical precedent for dancing in worship from 2 Samuel 6, where David danced before the Lord. A similar occurrence is often called "running the aisles". The "Jericho march" (inspired by Book of Joshua 6:1–27) is a celebratory practice occurring at times of high enthusiasm. Members of a congregation began to spontaneously leave their seats and walk in the aisles inviting other members as they go. Eventually, a full column is formed around the perimeter of the meeting space as worshipers march with singing and loud shouts of praise and jubilation. Another spontaneous manifestation found in some Pentecostal churches is holy laughter, in which worshippers uncontrollably laugh. In some Pentecostal churches, these spontaneous expressions are primarily found in revival meetings or special prayer meetings, being rare or non-existent in the main services.

Like other Christian churches, Pentecostals believe that certain rituals or ceremonies were instituted as a pattern and command by Jesus in the New Testament. Pentecostals commonly call these ceremonies ordinances. Many Christians call these sacraments, but this term is not generally used by Pentecostals and certain other Protestants as they do not see ordinances as imparting grace. Instead the term sacerdotal ordinance is used to denote the distinctive belief that grace is received directly from God by the congregant with the officiant serving only to facilitate rather than acting as a conduit or vicar.

The ordinance of water baptism is an outward symbol of an inner conversion that has already taken place. Therefore, most Pentecostal groups practice believer's baptism by immersion. The majority of Pentecostals do not view baptism as essential for salvation, and likewise, most Pentecostals are Trinitarian and use the traditional Trinitarian baptismal formula. However, Oneness Pentecostals view baptism as an essential and necessary part of the salvation experience and, as non-Trinitarians, reject the use of the traditional baptismal formula. For more information on Oneness Pentecostal baptismal beliefs, see the following section on Statistics and denominations.

The ordinance of Holy Communion, or the Lord's Supper, is seen as a direct command given by Jesus at the Last Supper, to be done in remembrance of him. Pentecostal denominations reject the use of wine as part of communion, using grape juice instead.

Foot washing is also held as an ordinance by some Pentecostals. It is considered an "ordinance of humility" because Jesus showed humility when washing his disciples' feet in John 13:14–17. Other Pentecostals do not consider it an ordinance; however, they may still recognize spiritual value in the practice.

In 1995, David Barrett estimated there were 217 million "Denominational Pentecostals" throughout the world. In 2011, a Pew Forum study of global Christianity found that there were an estimated 279 million classical Pentecostals, making 4 percent of the total world population and 12.8 percent of the world's Christian population Pentecostal. The study found "Historically pentecostal denominations" (a category that did not include independent Pentecostal churches) to be the largest Protestant denominational family.

The largest percentage of Pentecostals are found in Sub-Saharan Africa (44 percent), followed by the Americas (37 percent) and Asia and the Pacific (16 percent). The movement is enjoying its greatest surge today in the global South, which includes Africa, Latin America, and most of Asia. There are 740 recognized Pentecostal denominations, but the movement also has a significant number of independent churches that are not organized into denominations.

Among the over 700 Pentecostal denominations, 240 are classified as part of Wesleyan, Holiness, or "Methodistic" Pentecostalism. Until 1910, Pentecostalism was universally Wesleyan in doctrine, and Holiness Pentecostalism continues to predominate in the Southern United States. Wesleyan Pentecostals teach that there are three crisis experiences within a Christian's life: conversion, sanctification, and Spirit baptism. They inherited the holiness movement's belief in entire sanctification. According to Wesleyan Pentecostals, entire sanctification is a definite event that occurs after salvation but before Spirit baptism. This inward experience cleanses and enables the believer to live a life of outward holiness. This personal cleansing prepares the believer to receive the baptism in the Holy Spirit. Holiness Pentecostal denominations include the Church of God in Christ, Church of God (Cleveland, Tennessee), and the Pentecostal Holiness Church.

After William H. Durham began preaching his Finished Work doctrine in 1910, many Pentecostals rejected the Wesleyan doctrine of entire sanctification and began to teach that there were only two definite crisis experiences in the life of a Christian: conversion and Spirit baptism. These Finished Work Pentecostals (also known as "Baptistic" or "Reformed" Pentecostals because many converts were originally drawn from Baptist and Presbyterian backgrounds) teach that a person is initially sanctified at the moment of conversion. After conversion, the believer grows in grace through a lifelong process of progressive sanctification. There are 390 denominations that adhere to the finished work position. They include the Assemblies of God, the Foursquare Gospel Church, and the Open Bible Churches.

The 1904–1905 Welsh Revival laid the foundation for British Pentecostalism and especially for a distinct family of denominations known as Apostolic Pentecostalism (not to be confused with Oneness Pentecostalism). These Pentecostals are led by a hierarchy of living apostles, prophets, and other charismatic offices. Apostolic Pentecostals are found worldwide in 30 denominations, including the Apostolic Church based in the United Kingdom.

There are 80 Pentecostal denominations that are classified as Jesus' Name or Oneness Pentecostalism (often self identifying as "Apostolic Pentecostals"). These differ from the rest of Pentecostalism in several significant ways. Oneness Pentecostals reject the doctrine of the Trinity. They do not describe God as three persons but rather as three manifestations of the one living God. Oneness Pentecostals practice Jesus' Name Baptism—water baptisms performed in the name of Jesus Christ, rather than that of the Trinity. Oneness Pentecostal adherents believe repentance, baptism in Jesus' name, and Spirit baptism are all essential elements of the conversion experience. Oneness Pentecostals hold that repentance is necessary before baptism to make the ordinance valid, and receipt of the Holy Spirit manifested by speaking in other tongues is necessary afterwards, to complete the work of baptism. This differs from other Pentecostals, along with evangelical Christians in general, who see only repentance and faith in Christ as essential to salvation. This has resulted in Oneness believers being accused by some (including other Pentecostals) of a "works-salvation" soteriology, a charge they vehemently deny. Oneness Pentecostals insist that salvation comes by grace through faith in Christ, coupled with obedience to his command to be "born of water and of the Spirit"; hence, no good works or obedience to laws or rules can save anyone. For them, baptism is not seen as a "work" but rather the indispensable means that Jesus himself provided to come into his kingdom. The major Oneness churches include the United Pentecostal Church International and the Pentecostal Assemblies of the World.

In addition to the denominational Pentecostal churches, there are many Pentecostal churches that choose to exist independently of denominational oversight. Some of these churches may be doctrinally identical to the various Pentecostal denominations, while others may adopt beliefs and practices that differ considerably from classical Pentecostalism, such as Word of Faith teachings or Kingdom Now theology. Some of these groups have been successful in utilizing the mass media, especially television and radio, to spread their message.


The charismatic experiences found in Pentecostalism have precedents in earlier movements in Christianity. Church historian Dr. Curtis Ward proposes the existence of an unbroken Pentecostal lineage from the early church to the present, with glossolalia and gifts following. However, early Pentecostals considered the movement a latter-day restoration of the church's apostolic power, and historians such as Cecil M. Robeck, Jr. and Edith Blumhofer write that the movement emerged from late 19th-century radical evangelical revival movements in America and in Great Britain.

Within this radical evangelicalism, expressed most strongly in the Wesleyan—holiness and Higher Life movements, themes of restorationism, premillennialism, faith healing, and greater attention on the person and work of the Holy Spirit were central to emerging Pentecostalism. Believing that the second coming of Christ was imminent, these Christians expected an endtime revival of apostolic power, spiritual gifts, and miracle—working. Figures such as Dwight L. Moody and R. A. Torrey began to speak of an experience available to all Christians which would empower believers to evangelize the world, often termed "baptism with the Holy Spirit".

Certain Christian leaders and movements had important influences on early Pentecostals. The essentially universal belief in the continuation of all the spiritual gifts in the Keswick and Higher Life movements constituted a crucial historical background for the rise of Pentecostalism. Albert Benjamin Simpson (1843–1919) and his Christian and Missionary Alliance (founded in 1887) was very influential in the early years of Pentecostalism, especially on the development of the Assemblies of God. Another early influence on Pentecostals was John Alexander Dowie (1847–1907) and his Christian Catholic Apostolic Church (founded in 1896). Pentecostals embraced the teachings of Simpson, Dowie, Adoniram Judson Gordon (1836–1895) and Maria Woodworth-Etter (1844–1924; she later joined the Pentecostal movement) on healing. Edward Irving's Catholic Apostolic Church (founded c. 1831) also displayed many characteristics later found in the Pentecostal revival.

No one person or group founded Pentecostalism. Instead, isolated Christian groups were experiencing charismatic phenomena such as divine healing and speaking in tongues. The holiness movement provided a theological explanation for what was happening to these Christians, and they adapted Wesleyan soteriology to accommodate their new understanding.

Charles Fox Parham, an independent holiness evangelist who believed strongly in divine healing, was an important figure to the emergence of Pentecostalism as a distinct Christian movement. In 1900, he started a school near Topeka, Kansas, which he named Bethel Bible School. There he taught that speaking in tongues was the scriptural evidence for the reception of the baptism with the Holy Spirit. On January 1, 1901, after a watch night service, the students prayed for and received the baptism with the Holy Spirit with the evidence of speaking in tongues. Parham received this same experience sometime later and began preaching it in all his services. Parham believed this was xenoglossia and that missionaries would no longer need to study foreign languages. After 1901, Parham closed his Topeka school and began a four-year revival tour throughout Kansas and Missouri. He taught that the baptism with the Holy Spirit was a third experience, subsequent to conversion and sanctification. Sanctification cleansed the believer, but Spirit baptism empowered for service.

At about the same time that Parham was spreading his doctrine of initial evidence in the Midwestern United States, news of the Welsh Revival of 1904–05 ignited intense speculation among radical evangelicals around the world and particularly in the US of a coming move of the Spirit which would renew the entire Christian Church. This revival saw thousands of conversions and also exhibited speaking in tongues.

In 1905, Parham moved to Houston, Texas, where he started a Bible training school. One of his students was William J. Seymour, a one-eyed black preacher. Seymour traveled to Los Angeles where his preaching sparked the three-year-long Azusa Street Revival in 1906. The revival first broke out on Monday April 9, 1906 at 214 Bonnie Brae Street and then moved to 312 Azusa Street on Friday, April 14, 1906. Worship at the racially integrated Azusa Mission featured an absence of any order of service. People preached and testified as moved by the Spirit, spoke and sung in tongues, and fell in the Spirit. The revival attracted both religious and secular media attention, and thousands of visitors flocked to the mission, carrying the "fire" back to their home churches. Despite the work of various Wesleyan groups such as Parham's and D. L. Moody's revivals, the beginning of the widespread Pentecostal movement in the US is generally considered to have begun with Seymour's Azusa Street Revival.
The crowds of African-Americans and whites worshiping together at William Seymour's Azusa Street Mission set the tone for much of the early Pentecostal movement. During the period of 1906–24, Pentecostals defied social, cultural and political norms of the time that called for racial segregation and the enactment of Jim Crow laws. The Church of God in Christ, the Church of God (Cleveland), the Pentecostal Holiness Church, and the Pentecostal Assemblies of the World were all interracial denominations before the 1920s. These groups, especially in the Jim Crow South were under great pressure to conform to segregation. Ultimately, North American Pentecostalism would divide into white and African-American branches. Though it never entirely disappeared, interracial worship within Pentecostalism would not reemerge as a widespread practice until after the civil rights movement.

Women were vital to the early Pentecostal movement. Believing that whoever received the Pentecostal experience had the responsibility to use it towards the preparation for Christ's second coming, Pentecostal women held that the baptism in the Holy Spirit gave them empowerment and justification to engage in activities traditionally denied to them. The first person at Parham's Bible college to receive Spirit baptism with the evidence of speaking in tongues was a woman, Agnes Ozman. Women such as Florence Crawford, Ida Robinson, and Aimee Semple McPherson founded new denominations, and many women served as pastors, co-pastors, and missionaries. Women wrote religious songs, edited Pentecostal papers, and taught and ran Bible schools. The unconventionally intense and emotional environment generated in Pentecostal meetings dually promoted, and was itself created by, other forms of participation such as personal testimony and spontaneous prayer and singing. Women did not shy away from engaging in this forum, and in the early movement the majority of converts and church-goers were female. Nevertheless, there was considerable ambiguity surrounding the role of women in the church. The subsiding of the early Pentecostal movement allowed a socially more conservative approach to women to settle in, and, as a result, female participation was channeled into more supportive and traditionally accepted roles. Auxiliary women's organizations were created to focus women's talents on more traditional activities. Women also became much more likely to be evangelists and missionaries than pastors. When they were pastors, they often co-pastored with their husbands.

The majority of early Pentecostal denominations taught pacifism and adopted military service articles that advocated conscientious objection.

Azusa participants returned to their homes carrying their new experience with them. In many cases, whole churches were converted to the Pentecostal faith, but many times Pentecostals were forced to establish new religious communities when their experience was rejected by the established churches. One of the first areas of involvement was the African continent, where, by 1907, American missionaries were established in Liberia, as well as in South Africa by 1908. Because speaking in tongues was initially believed to always be actual foreign languages, it was believed that missionaries would no longer have to learn the languages of the peoples they evangelized because the Holy Spirit would provide whatever foreign language was required. (When the majority of missionaries, to their disappointment, learned that tongues speech was unintelligible on the mission field, Pentecostal leaders were forced to modify their understanding of tongues.) Thus, as the experience of speaking in tongues spread, a sense of the immediacy of Christ's return took hold and that energy would be directed into missionary and evangelistic activity. Early Pentecostals saw themselves as outsiders from mainstream society, dedicated solely to preparing the way for Christ's return.

An associate of Seymour's, Florence Crawford, brought the message to the Northwest, forming what would become the Apostolic Faith Church by 1908. After 1907, Azusa participant William Howard Durham, pastor of the North Avenue Mission in Chicago, returned to the Midwest to lay the groundwork for the movement in that region. It was from Durham's church that future leaders of the Pentecostal Assemblies of Canada would hear the Pentecostal message. One of the most well known Pentecostal pioneers was Gaston B. Cashwell (the "Apostle of Pentecost" to the South), whose evangelistic work led three Southeastern holiness denominations into the new movement.

The Pentecostal movement, especially in its early stages, was typically associated with the impoverished and marginalized of America, especially African Americans and Southern Whites. With the help of many healing evangelists such as Oral Roberts, Pentecostalism spread across America by the 1950s.
International visitors and Pentecostal missionaries would eventually export the revival to other nations. The first foreign Pentecostal missionaries were A. G. Garr and his wife, who were Spirit baptized at Azusa and traveled to India and later Hong Kong. The Norwegian Methodist pastor T. B. Barratt was influenced by Seymour during a tour of the United States. By December 1906, he had returned to Europe and is credited with beginning the Pentecostal movement in Sweden, Norway, Denmark, Germany, France and England. A notable convert of Barratt was Alexander Boddy, the Anglican vicar of All Saints' in Sunderland, England, who became a founder of British Pentecostalism. Other important converts of Barratt were German minister Jonathan Paul who founded the first German Pentecostal denomination (the Mülheim Association) and Lewi Pethrus, the Swedish Baptist minister who founded the Swedish Pentecostal movement.

Through Durham's ministry, Italian immigrant Luigi Francescon received the Pentecostal experience in 1907 and established Italian Pentecostal congregations in the US, Argentina (Christian Assembly in Argentina), and Brazil (Christian Congregation of Brazil). In 1908, Giacomo Lombardi led the first Pentecostal services in Italy. In November 1910, two Swedish Pentecostal missionaries arrived in Belem, Brazil and established what would become the Assembleias de Deus (Assemblies of God of Brazil). In 1908, John G. Lake, a follower of Alexander Dowie who had experienced Pentecostal Spirit baptism, traveled to South Africa and founded what would become the Apostolic Faith Mission of South Africa and the Zion Christian Church. As a result of this missionary zeal, practically all Pentecostal denominations today trace their historical roots to the Azusa Street Revival.

The first generation of Pentecostal believers faced immense criticism and ostracism from other Christians, most vehemently from the Holiness movement from which they originated. Alma White, leader of the Pillar of Fire Church, wrote a book against the movement titled "Demons and Tongues" in 1910. She called Pentecostal tongues "satanic gibberish" and Pentecostal services "the climax of demon worship". Famous holiness preacher W. B. Godbey characterized those at Azusa Street as "Satan's preachers, jugglers, necromancers, enchanters, magicians, and all sorts of mendicants". To Dr. G. Campbell Morgan, Pentecostalism was "the last vomit of Satan", while Dr. R. A. Torrey thought it was "emphatically not of God, and founded by a Sodomite". The Pentecostal Church of the Nazarene, one of the largest holiness groups, was strongly opposed to the new Pentecostal movement. To avoid confusion, the church changed its name in 1919 to the Church of the Nazarene. A. B. Simpson's Christian and Missionary Alliance negotiated a compromise position unique for the time. Simpson believed that Pentecostal tongues speaking was a legitimate manifestation of the Holy Spirit, but he did not believe it was a necessary evidence of Spirit baptism. This view on speaking in tongues ultimately led to what became known as the "Alliance position" articulated by A. W. Tozer as "seek not—forbid not".

Zora Neal Hurston performed anthropological, sociological studies examining the spread of Pentecostalism. According to scholar of religion, Ashon Crawley, Hurston's analysis is important because she understood the class struggle that this seemingly new religiocultural movement articulated: "The Sanctified Church is a protest against the high-brow tendency in Negro Protestant congregations as the Negroes gain more education and wealth." She stated that this sect was "a revitalizing element in Negro music and religion" and that this collection of groups was "putting back int Negro religion those elements which were brought over from Africa and grafted onto Christianity." Crawley would go on to argue that the shouting Hurston documented evince what Martinique psychoanalyst Frantz Fanon called the refusal of positionality wherein "no strategic position is given preference" as the creation of, the grounds for, social form.

The first Pentecostal converts were mainly derived from the Holiness movement and adhered to a Wesleyan understanding of sanctification as a definite, instantaneous experience and second work of grace. Problems with this view arose when large numbers of converts entered the movement from non-Wesleyan backgrounds, especially from Baptist churches. In 1910, William Durham of Chicago first articulated the Finished Work, a doctrine which located sanctification at the moment of salvation and held that after conversion the Christian would progressively grow in grace in a lifelong process. This teaching polarized the Pentecostal movement into two factions. The Wesleyan doctrine was strongest in the Southern denominations, such as the Church of God (Cleveland), Church of God in Christ, and the Pentecostal Holiness Church. The Finished Work, however, would ultimately gain ascendancy among Pentecostals. After 1911, most new Pentecostal denominations would adhere to Finished Work sanctification.

In 1914, a group of predominately 300 white Pentecostal ministers and laymen from all regions of the United States gathered in Hot Springs, Arkansas, to create a new, national Pentecostal fellowship—the General Council of the Assemblies of God. By 1911, many of these white ministers were distancing themselves from an existing arrangement under an African-American leader. Many of these white ministers were licensed by the African-American, C. H. Mason under the auspices of the Church of God in Christ, one of the few legally chartered Pentecostal organizations at the time credentialing and licensing ordained Pentecostal clergy. To further such distance, Bishop Mason and other African-American Pentecostal leaders were not invited to the initial 1914 fellowship of Pentecostal ministers. These predominately white ministers adopted a congregational polity (whereas the COGIC and other Southern groups remained largely episcopal) and rejected a Finished Work understanding of Sanctification. Thus, the creation of the Assemblies of God marked an official end of Pentecostal doctrinal unity and racial integration.

The new Assemblies of God would soon face a "new issue" which first emerged at a 1913 camp meeting. During a baptism service, the speaker, R. E. McAlister, mentioned that the Apostles baptized converts once in the name of Jesus Christ, and the words "Father, Son, and Holy Ghost" were never used in baptism. This inspired Frank Ewart who claimed to have received as a divine prophecy revealing a nontrinitarian conception of God. Ewart believed that there was only one personality in the Godhead—Jesus Christ. The terms "Father" and "Holy Ghost" were titles designating different aspects of Christ. Those who had been baptized in the Trinitarian fashion needed to submit to rebaptism in Jesus' name. Furthermore, Ewart believed that Jesus' name baptism and the gift of tongues were essential for salvation. Ewart and those who adopted his belief called themselves "oneness" or "Jesus' Name" Pentecostals, but their opponents called them "Jesus Only".

Amid great controversy, the Assemblies of God rejected the Oneness teaching, and a large number of its churches and pastors were forced to withdraw from the denomination in 1916. They organized their own Oneness groups. Most of these joined Garfield T. Haywood, an African-American preacher from Indianapolis, to form the Pentecostal Assemblies of the World. This church maintained an interracial identity until 1924 when the white ministers withdrew to form the Pentecostal Church, Incorporated. This church later merged with another group forming the United Pentecostal Church International.

While Pentecostals shared many basic assumptions with conservative Protestants, the earliest Pentecostals were rejected by Fundamentalist Christians who adhered to cessationism. In 1928, the World Christian Fundamentals Association labeled Pentecostalism "fanatical" and "unscriptural". By the early 1940s, this rejection of Pentecostals was giving way to a new cooperation between them and leaders of the "new evangelicalism", and American Pentecostals were involved in the founding of the 1942 National Association of Evangelicals. Pentecostal denominations also began to interact with each other both on national levels and international levels through the Pentecostal World Fellowship, which was founded in 1947.

Though Pentecostals began to find acceptance among evangelicals in the 1940s, the previous decade was widely viewed as a time of spiritual dryness, when healings and other miraculous phenomena were perceived as being less prevalent than in earlier decades of the movement. It was in this environment that the Latter Rain Movement, the most important controversy to affect Pentecostalism since World War II, began in North America and spread around the world in the late 1940s. Latter Rain leaders taught the restoration of the fivefold ministry led by apostles. These apostles were believed capable of imparting spiritual gifts through the laying on of hands. There were prominent participants of the early Pentecostal revivals, such as Stanley Frodsham and Lewi Pethrus, who endorsed the movement citing similarities to early Pentecostalism. However, Pentecostal denominations were critical of the movement and condemned many of its practices as unscriptural. One reason for the conflict with the denominations was the sectarianism of Latter Rain adherents. Many autonomous churches were birthed out of the revival.

A simultaneous development within Pentecostalism was the postwar Healing Revival. Led by healing evangelists William Branham, Oral Roberts, Gordon Lindsay, and T. L. Osborn, the Healing Revival developed a following among non-Pentecostals as well as Pentecostals. Many of these non-Pentecostals were baptized in the Holy Spirit through these ministries. The Latter Rain and the Healing Revival influenced many leaders of the charismatic movement of the 1960s and 1970s.

Before the 1960s, most non-Pentecostal Christians who experienced the Pentecostal baptism in the Holy Spirit typically kept their experience a private matter or joined a Pentecostal church afterward. The 1960s saw a new pattern develop where large numbers of Spirit baptized Christians from mainline churches in the US, Europe, and other parts of the world chose to remain and work for spiritual renewal within their traditional churches. This initially became known as New or Neo-Pentecostalism (in contrast to the older classical Pentecostalism) but eventually became known as the Charismatic Movement. While cautiously supportive of the Charismatic Movement, the failure of Charismatics to embrace traditional Pentecostal taboos on dancing, drinking alcohol, smoking, and restrictions on dress and appearance initiated an identity crisis for classical Pentecostals, who were forced to reexamine long held assumptions about what it meant to be Spirit filled. The liberalizing influence of the Charismatic Movement on classical Pentecostalism can be seen in the disappearance of many of these taboos since the 1960s. Because of this, the cultural differences between classical Pentecostals and charismatics have lessened over time. The global renewal movements manifest many of these tensions as inherent characteristics of Pentecostalism and as representative of the character of global Christianity.







</doc>
<doc id="23558" url="https://en.wikipedia.org/wiki?curid=23558" title="Pangenesis">
Pangenesis

Pangenesis was Charles Darwin's hypothetical mechanism for heredity, in which he proposed that each part of the body continually emitted its own type of small organic particles called gemmules that aggregated in the gonads, contributing heritable information to the gametes. He presented this 'provisional hypothesis' in his 1868 work "The Variation of Animals and Plants under Domestication", intending it to fill what he perceived as a major gap in evolutionary theory at the time. The etymology of the word comes from the Greek words "pan" (a prefix meaning "whole", "encompassing") and "genesis" ("birth") or "genos" ("origin"). Pangenesis mirrored ideas orignally formulated by Hippocrates and other pre-Darwinian scientists, but built off of new concepts such as cell theory, explaining cell development as beginning with gemmules which were specified to be necessary for the occurrence of new growths in an organism, both in initial development and regeneration. It also accounted for regeneration and the Lamarckian concept of the inheritance of acquired characteristics, as a body part altered by the environment would produce altered gemmules. This made Pangenesis popular among the neo-Lamarckian school of evolutionary thought. This hypothesis was made effectively obsolete after the 1900 rediscovery among biologists of Gregor Mendel's theory of the particulate nature of inheritance.

Pangenesis was similar to ideas put forth by Hippocrates, Democritus and other pre-Darwinian scientists in proposing that the whole of parental organisms participate in heredity (thus the prefix "pan"). Darwin wrote that Hippocrates' pangenesis was "almost identical with mine—merely a change of terms—and an application of them to classes of facts necessarily unknown to the old philosopher."

Science historian Conway Zirkle wrote that:

Zirkle demonstrated that the idea of inheritance of acquired characteristics had become fully accepted by the 16th century and remained immensely popular through to the time of Lamarck's work, at which point it began to draw more criticism due to lack of hard evidence. He also stated that pangenesis was the only scientific explanation ever offered for this concept, developing from Hippocrates' belief that "the semen was derived from the whole body." In the 13th century, pangenesis was commonly accepted on the principle that semen was a refined version of food unused by the body, which eventually translated to 15th and 16th century widespread use of pangenetic principles in medical literature, especially in gynecology. Later pre-Darwinian important applications of the idea included hypotheses about the origin of the differentiation of races.

A theory put forth by Pierre Louis Maupertuis in 1745 called for particles from both parents governing the attributes of the child, although some historians have called his remarks on the subject cursory and vague.

In 1749, French naturalist Georges-Louis Leclerc, Comte de Buffon developed a hypothetical system of heredity much like Darwin's pangenesis, wherein 'organic molecules' were transferred to offspring during reproduction and stored in the body during development. Commenting on Buffon's views, Darwin stated, "If Buffon had assumed that his organic molecules had been formed by each separate unit throughout the body, his view and mine would have been very closely similar."

In 1801, Erasmus Darwin advocated a hypothesis of pangenesis in the third edition of his book "Zoonomia". In 1809, Jean-Baptiste Lamarck in his "Philosophie Zoologique" put forth evidence for the idea that characteristics acquired during the lifetime of an organism, either from effects of the environment or may be passed on to the offspring. Charles Darwin first had significant contact with Lamarckism during his time at the University of Edinburgh Medical School in the late 1820s, both through Robert Edmond Grant, whom he assisted in research, and in Erasmus's journals. Darwin's first known writings on the topic of Lamarckian ideas as they related to inheritance are found in a notebook he opened in 1837, also entitled "Zoonomia". Historian Johnathan Hodge states that the theory of pangenesis itself first appeared in Darwin's notebooks in 1841.

In 1861, Irish physician Henry Freke developed a variant of pangenesis in his book "Origin of Species by Means of Organic Affinity". Freke proposed that all life was developed from microscopic organic agents which he named "granules", which existed as 'distinct species of organizing matter' and would develop into different biological structures.

In 1864, four years before the publication of "Variation", Herbert Spencer in his book "Principles of Biology" proposed a theory of "physiological units" similar to Darwin's gemmules, which likewise were said to be related to specific body parts and responsible for the transmission of characteristics of those body parts to offspring. He also supported the Lamarckian idea of transmission of acquired characteristics.

Darwin had debated whether to publish a theory of heredity for an extended period of time due to its highly speculative nature. He decided to include pangenesis in "Variation" after sending a 30 page manuscript to his close friend and supporter Thomas Huxley in May 1865, which was met by significant criticism from Huxley that made Darwin even more hesitant. However, Huxley eventually advised Darwin to publish, writing: "Somebody rummaging among your papers half a century hence will find Pangenesis & say 'See this wonderful anticipation of our modern Theories—and that stupid ass, Huxley, prevented his publishing them'" Darwin's initial version of pangenesis appeared in the first edition of "Variation" in 1868, and was later reworked for the publication of a second edition in 1875.

Darwin's pangenesis theory attempted to explain the process of sexual reproduction, inheritance of traits, and complex developmental phenomena such as cellular regeneration in a unified mechanistic structure. Yongshen Liu wrote that in modern terms, pangenesis deals with issues of "dominance inheritance, graft hybridization, reversion, xenia, telegony, the inheritance of acquired characters, regeneration and many groups of facts pertaining to variation, inheritance and development." Mechanistically, Darwin proposed pangenesis to occur through the transfer of organic particles which he named 'gemmules.' Gemmules, which he also sometimes referred to as "plastitudes," pangenes, granules, or germs, were supposed to be shed by the organs of the body and carried in the bloodstream to the reproductive organs where they accumulated in the germ cells or gametes. Their accumulation was thought to occur by some sort of a 'mutual affinity.' Each gemmule was said to be specifically related to a certain body part- as described, they did not contain information about the entire organism. The different types were assumed to be dispersed through the whole body, and capable of self-replication given ‘proper nutriment'. When passed on to offspring via the reproductive process, gemmules were thought to be responsible for developing into each part of an organism and expressing characteristics inherited from both parents. Darwin thought this to occur in a literal sense: he explained cell proliferation to progress as gemmules to bind to more developed cells of their same character and mature. In this sense, the uniqueness of each individual would be due to their unique mixture of their parents’ gemmules, and therefore characters. Similarity to one parent over the other could be explained by a quantitative superiority of one parent's gemmules. Yongshen Lu points out that Darwin knew of cells' ability to multiply by self-division, so it is unclear how Darwin supposed the two proliferation mechanisms to relate to each other. He did clarify in a later statement that he had always supposed gemmules to only bind to and proliferate from developing cells, not mature ones. Darwin hypothesized that gemmules might be able to survive and multiply outside of the body in a letter to J. D. Hooker in 1870.
Some gemmules were thought to remain dormant for generations, whereas others were routinely expressed by all offspring. Every child was built up from selective expression of the mixture of the parents and grandparents' gemmules coming from either side. Darwin likened this to gardening: a flowerbed could be sprinkled with seeds "most of which soon germinate, some lie for a period dormant, whilst others perish." He did not claim gemmules were in the blood, although his theory was often interpreted in this way. Responding to Fleming Jenkin's review of "On the Origin of Species", he argued that pangenesis would permit the preservation of some favourable variations in a population so that they wouldn't die out through blending.

Darwin thought that environmental effects that caused altered characteristics would lead to altered gemmules for the affected body part. The altered gemmules would then have a chance of being transferred to offspring, since they were assumed to be produced throughout an organisms life. Thus, pangenesis theory allowed for the Lamarckian idea of transmission of characteristics acquired through use and disuse. Accidental gemmule development in incorrect parts of the body could explain deformations and the 'monstrosities' Darwin cited in "Variation".

Hugo de Vries characterized his own version of pangenesis theory in his 1889 book "Intracellular Pangenesis" with two propositions, of which he only accepted the first:

De Vries also coined the term 'pangene' which 20 years later was shortened by Wilhelm Johannsen to gene.

Science historian Janet Browne points out that while Herbert Spencer and Carl von Nägeli also put forth ideas for systems of inheritance involving gemmules, their version of gemmules differed in that it contained "a complete microscopic blueprint for an entire creature." Spencer published his theory of "physiological units" three years prior to Darwin's publication of "Variation".

She goes on to say that Darwin believed specifically in gemmules for each body part because they might explain how environmental effects could be passed on as characteristics to offspring.

Interpretations and applications of pangenesis continued to appear frequently in medical literature up until Weismann's experiments and subsequent publication on germ-plasm theory in 1892. For instance, an address by Huxley spurred on substantial work by Dr. James Ross in linking ideas found in Darwin's pangenesis to the germ theory of disease. Ross cites the work of both Darwin and Spencer as key to his application of pangenetic theory.

Darwin's half-cousin Francis Galton conducted wide-ranging inquiries into heredity which led him to refute Charles Darwin's hypothetical theory of pangenesis. In consultation with Darwin, he set out to see if gemmules were transported in the blood. In a long series of experiments from 1869 to 1871, he transfused the blood between dissimilar breeds of rabbits, and examined the features of their offspring. He found no evidence of characters transmitted in the transfused blood.

Galton was troubled because he began the work in good faith, intending to prove Darwin right, and having praised pangenesis in "Hereditary Genius" in 1869. Cautiously, he criticized his cousin’s theory, although qualifying his remarks by saying that Darwin's gemmules, which he called "pangenes," might be temporary inhabitants of the blood that his experiments had failed to pick up.

Darwin challenged the validity of Galton's experiment, giving his reasons in an article published in "Nature" where he wrote:

After the circulation of Galton's results, the perception of pangenesis quickly changed to severe skepticism if not outright disbelief.

August Weismann's idea, set out in his 1892 book "Das Keimplasma: eine Theorie der Vererbung" (The Germ Plasm: a Theory of Inheritance), was that the hereditary material, which he called the germ plasm, and the rest of the body (the soma) had a one-way relationship: the germ-plasm formed the body, but the body did not influence the germ-plasm, except indirectly in its participation in a population subject to natural selection. This distinction is commonly referred to as the Weismann Barrier. If correct, this made Darwin's pangenesis wrong and Lamarckian inheritance impossible. His experiment on mice, cutting off their tails and showing that their offspring had normal tails across multiple generations, was proposed as a proof of the non-existence of Lamarckian inheritance, although Peter Gauthier has argued that Weismann's experiment showed only that injury did not affect the germ plasm and neglected to test the effect of Lamarckian use and disuse. Weismann argued strongly and dogmatically for Darwinism and against neo-Lamarckism, polarising opinions among other scientists. This increased anti-Darwinian feeling, contributing to its eclipse.

Darwin's pangenesis theory was widely criticised, in part for its Lamarckian premise that parents could pass on traits acquired in their lifetime. Conversely, the neo-Lamarckians of the time seized upon pangenesis as evidence to support their case. Italian Botanist Federico Delpino's objection that gemmules' ability to self-divide is contrary to their supposedly innate nature gained considerable traction; however, Darwin was dismissive of this criticism, remarking that the particulate agents of small pox and scarlet fever seem to have such characteristics. Lamarckism fell from favour after August Weismann's research in the 1880s indicated that changes from use (such as lifting weights to increase muscle mass) and disuse (such as being lazy and becoming weak) were not heritable. However, some scientists continued to voice their support in spite of Galton's and Weismann's results: notably, in 1900 Karl Pearson wrote that pangenesis "is no more disproved by the statement that ‘gemmules have not been found in the blood,’ than the atomic theory is disproved by the fact that no atoms have been found in the air." Finally, the rediscovery of Mendel's Laws of Inheritance in 1900 led to pangenesis being fully set aside. Julian Huxley has observed that the later discovery of chromosomes and the research of T. H. Morgan also made pangenesis untenable.

Some of Darwin's pangenesis principles do relate to heritable aspects of phenotypic plasticity, although the status of gemmules as a distinct class of organic particles has been firmly rejected. However, starting in the 1950s, many research groups in revisiting Galton's experiments found that heritable characteristics could indeed arise in rabbits and chickens following DNA injection or blood transfusion. This type of research originated in the Soviet Union in the late 1940's in the work of Sopikov and others, and was later corroborated by researchers in Switzerland as it was being further developed by the Soviet scientists. Notably, this work was supported in the USSR in part due to its conformation with the ideas of Trofim Lysenko, who espoused a version of neo-Lamarckism as part of Lysenkoism. Further research of this heritability of acquired characteristics developed into, in part, the modern field of epigenetics. Darwin himself had noted that "the existence of free gemmules is a gratuitous assumption"; by some accounts in modern interpretation, gemmules may be considered a prescient mix of DNA, RNA, proteins, prions, and other mobile elements that are heritable in a non-Mendelian manner at the molecular level. Liu points out that Darwin's ideas about gemmules replicating outside of the body are predictive of "in vitro" gene replication used, for instance, in PCR. It is worth noting, however, that this reinterpretation of pangenesis's viability in modern terms is the work of a niche group of scholars and does not necessarily reflect a renewal of interest by related fields as a whole.





</doc>
<doc id="23560" url="https://en.wikipedia.org/wiki?curid=23560" title="Proboscidea">
Proboscidea

The Proboscidea (from the Greek and the Latin "proboscis") are a taxonomic order of afrotherian mammals containing one living family, Elephantidae, and several extinct families. This order, first described by J. Illiger in 1811, encompasses the trunked mammals. In addition to their enormous size, later proboscideans are distinguished by tusks and long, muscular trunks; these features were less developed or absent in the smaller early proboscideans. Beginning in the mid Miocene, most members of this order were very large animals. The largest land mammal today is the african elephant weighting up to 10.4 tonnes with a shoulder height of up to . The largest land mammal of all time may have also been a proboscidean: "Palaeoloxodon namadicus", which may have weighed up to with a shoulder height of up to , surpassing several sauropod dinosaurs (in height).

The earliest known proboscidean is "Eritherium", followed by "Phosphatherium", a small animal about the size of a fox. These both date from late Paleocene deposits of Morocco.

Proboscideans diversified during the Eocene and early Oligocene. Several primitive families from these epochs have been described, including Numidotheriidae, Moeritheriidae, and Barytheriidae in Africa. (Anthracobunidae from the Indian subcontinent has also been included, but was excluded from Proboscidea by Shoshani & Tassy (2005) and has more recently been assigned to Perissodactyla.) These were followed by the earliest Deinotheriidae, or "hoe tuskers", which thrived during the Miocene and into the early Quaternary. Proboscideans from the Miocene also included "Stegolophodon", an early genus of the disputed family Stegodontidae; the diverse family of Gomphotheriidae, or "shovel tuskers", such as "Platybelodon" and "Amebelodon"; and the Mammutidae, or mastodons.

Most families of Proboscidea are now extinct, many since the end of the last glacial period. Recently extinct species include the last examples of gomphotheres in Central and South America, the American mastodon of family Mammutidae in North America, numerous stegodonts once found in Asia, the last of the mammoths, and several island species of dwarf elephants.

Below is the current taxonomy of the proboscidean genera as of 2017.



</doc>
<doc id="23561" url="https://en.wikipedia.org/wiki?curid=23561" title="Paranthropus">
Paranthropus

Paranthropus (from Greek παρα, "para" "beside"; άνθρωπος, "ánthropos" "human") is a genus of extinct hominins that lived between 2.6 and 1.1 million years ago. Also known as robust australopithecines, they were bipedal hominids probably descended from the gracile australopithecine hominids ("Australopithecus") 2.7 million years ago. 

The genus is characterised by robust craniodental anatomy, including gorilla-like sagittal cranial crests which suggest strong muscles of mastication, and broad, grinding herbivorous teeth. However, "Paranthropus" skulls lack the transverse cranial crests 
of modern gorillas.

A partial cranium and mandible of "Paranthropus robustus" was discovered in 1938 by a schoolboy, Gert Terblanche, at Kromdraai B (70 km south west of Pretoria) in South Africa. It was described as a new genus and species by Robert Broom of the Transvaal Museum. The site has been excavated since 1993 by Francis Thackeray of the Transvaal Museum. A date of at least 1.95 million years has been obtained for Kromdraai B.
"Paranthropus boisei" was discovered by Mary Leakey on July 17, 1959, at the FLK Bed I site of Olduvai Gorge in Tanzania (specimen OH 5). Mary was working alone, as Louis Leakey was ill in camp. She rushed back to camp and, at the news, Louis made a remarkable recovery. They refrained from excavating until Des Bartlett had photographed the site. In Louis recorded a first name, "Titanohomo mirabilis", reflecting an initial impression of close human affinity. Louis and Mary began to call it "Dear Boy". Recovery was halted on August 7. "Dear Boy" was found in context with Oldowan tools and animal bones.

The fossil was published in "Nature" dated August 15, 1959, but due to a strike of the printers the issue was not released until September. In it Louis placed the fossil in Broom's subfamily Australopithecinae, creating a new genus for it, "Zinjanthropus", species "boisei", which is no longer used. "Zinj" is an ancient Arabic word for the coast of East Africa and "boisei" referred to Charles Watson Boise, an anthropological benefactor of the Leakeys. Louis based his classification on twenty differences from "Australopithecus".

At that time palaeoanthropology was in an overall mood to lump species. Consequently, the presentation of Zinj during the Fourth Pan-African Congress of Prehistorians in July in the then Belgian Congo, at which Louis was forced to read the delayed "Nature" article, nearly came to grief for Louis over the creation of a new genus. Dart rescued him with the now famous joke, "... what would have happened if Mrs. Ples had met Dear Boy one dark night."

The battle of the name went on for many years and drove a wedge between Louis and Sir Wilfrid LeGros Clark, from 1955, who took the "Paranthropus" view. On the other hand, it brought the Leakeys and Dr. Melville Bell Grosvenor of the National Geographic Society together. The Leakeys became international figures and had no trouble finding funds from then on. The Zinj question ultimately became part of the "Australopithecus"/"Paranthropus" question (which only applied to the robust Australopithecines).

All species of "Paranthropus" were bipedal, and many lived during a time when species of the genus "Homo" (which were possibly descended from "Australopithecus"), were prevalent. "Paranthropus" first appeared roughly 2.7 million years ago. Most species of "Paranthropus" had a brain about 40 percent the size of that of a modern human. There was some size variation between the different species of "Paranthropus", but most stood roughly 1.3-1.4 m (4 ft 3 in to 4 ft 7 in) tall and were quite well muscled. "Paranthropus" is thought to have lived in wooded areas rather than the grasslands of "Australopithecus".

"Paranthropus" is thought to be bipedal based on its anatomical structure in its hips, legs, and feet that resemble both its ancestor, "Australopithecus afarensis", and modern humans. The pelvis is similar to "A. afarensis" but the hip joint, including the femoral head and acetabulum are smaller in "Paranthropus". The similar hip structure between "A. afarensis" and "Paranthropus" implies that they had a similar walking gait, and that "Paranthropus" moved like the "gracile australopiths". They show anatomical similarity to modern humans in the big toe of their foot and their well developed plantar aponeurosis. The hallux metatarsal shows increased base for more internal support, and more distal articular surface which causes more connection and support to the other bones in the foot. The extra support in the big toe and extensive plantar aponeurosis shows that "Paranthropus" had hyperextension of their toes for a "toe-off" gait cycle, characteristic of modern bipedalism in humans.

The behavior of "Paranthropus" was quite different from that of the genus "Homo", in that it was not as adaptable to its environment or as resourceful. Evidence exists in its anatomy, which was specifically tailored to a diet of grubs and plants. This would have made it more reliant on favorable environmental conditions than members of the genus "Homo", which consumed a much wider variety of foods. Therefore, because it was a specialist species, it had more difficulty adapting to a changing climate, leading to its extinction.

Evolutionary biologist Richard Dawkins notes "perhaps several different species" of robust hominids, and "as usual their affinities, and the exact number of species, are hotly disputed. Names that have been attached to various of these creatures...are "Australopithecus" (or "Paranthropus") "robustus", "Australopithecus" (or "Paranthropus" or "Zinjanthropus") "boisei", and "Australopithecus" (or "Paranthropus") "aethiopicus"."

Opinions differ whether the species "P. aethiopicus, P. boisei" and "P. robustus" should be included within the genus "Australopithecus". The emergence of the robusts could be either a display of divergent or convergent evolution. There is currently no consensus in the scientific community whether "P. aethiopicus, P. boisei" and "P. robustus" should be placed into a distinct genus, "Paranthropus", which is believed to have evolved from the ancestral "Australopithecus" line. Up the late 20th century the majority of the scientific community included all the species of both "Australopithecus" and "Paranthropus" in a single genus. Currently, both taxonomic systems are used and accepted in the scientific community. However, although "Australopithecus robustus" and "Paranthropus robustus" are used interchangeably for the same specimens, some researchers, beginning with Robert Broom, and continuing with people such as Bernard A. Wood, think that there is a difference between "Australopithecus" and "Paranthropus", and that there should be two genera.

For the most part the "Australopithecus" species "A. afarensis", "A. africanus", and "A. anamensis" either disappeared from the fossil record before the appearance of early humans or seem to have been the ancestors of "Homo habilis", yet "P. boisei" and "P. aethiopicus" continued to evolve along a separate path distinct and unrelated to early humans. "Paranthropus" shared the earth with some early examples of the genus "Homo", such as "H. habilis", "H. ergaster", and possibly even "H. erectus".

"Australopithecus afarensis" and "A. anamensis" had mostly disappeared by this time. There were significant morphological differences between "Australopithecus" and "Paranthropus", although the differences were found on the cranial remains. The postcranial remains were still very similar. "Paranthropus" was more massively built craniodentally and tended to contain gorilla-like sagittal crests on the cranium which anchored massive temporalis muscles of mastication.

Species of "Paranthropus" had smaller braincases than "Homo", yet they had significantly larger braincases than "Australopithecus". "Paranthropus" is associated with stone tools both in southern and eastern Africa, although there is considerable debate whether they were made and utilized by these robust australopithecines or contemporaneous "Homo". Most believe that early "Homo" was the tool maker, but hand fossils from Swartkrans, South Africa, indicate that the hand of "Paranthropus robustus" was also adapted for precision grasping and tool use. 
Most "Paranthropus" species seem almost certainly not to have used language nor to have controlled fire, although they are directly associated with the latter at Swartkrans.

In 2011 Thure E. Cerling of the University of Utah and colleagues, published a study in the "Proceedings of the National Academy of Sciences" of their work with the carbon isotopes in the enamel of 24 teeth from 22 "Paranthropus" individuals who lived in East Africa between 1.4 million and 1.9 million years ago. Their results suggest that "Paranthropus boisei" dined more heavily on C4 plants, possibly as a part-time graminivore (as many grass species are C4 plants), than any other human ancestor or human relative studied to date.




</doc>
<doc id="23562" url="https://en.wikipedia.org/wiki?curid=23562" title="Odd-toed ungulate">
Odd-toed ungulate

Members of the order Perissodactyla, also known as odd-toed ungulates, are mammals characterized by an odd number of toes and by hindgut fermentation with somewhat simple stomachs. Perissodactyla comes from the Ancient Greek περισσός ("perissós", “uneven”) + δάκτυλος ("dáktulos", “a finger, toe”). Unlike the even-toed ungulates, they digest plant cellulose in their intestines rather than in one or more stomach chambers. The order includes three extant families: Equidae (horses, asses, and zebras), Rhinocerotidae (rhinoceroses), and Tapiridae (tapirs), with a total of about 17 species. Despite their very different appearances, they were recognized as related families in the 19th century by the zoologist Richard Owen, who also coined the order name.

The largest odd-toed ungulates are rhinoceroses, and the extinct "Paraceratherium", a hornless rhino from the Oligocene, is considered one of the largest land mammals of all time. At the other extreme, an early member of the order, the prehistoric horse "Hyracotherium", had a withers height of only . Apart from dwarf varieties of the domestic horse and donkey, perissodactyls reach a body length of and a weight of . While rhinos have only sparse hair and exhibit a thick epidermis, tapirs and horses have dense, short coats. Most species are grey or brown, although zebras and young tapirs are striped.

The main axes of both the front and rear feet pass through the third toe, which is always the largest. The remaining toes have been reduced in size to varying degrees. Tapirs, which are adapted to walking on soft ground, have four toes on their fore feet and three on their hind feet. Living rhinos have three toes on both the front and hind feet. Modern equines possess only a single toe; however, their feet are equipped with hooves, which almost completely cover the toe. Rhinos and tapirs, by contrast, have hooves covering only the leading edge of the toes, with the bottom being soft.

The ulnae and fibulae are reduced in horses. A common feature that clearly distinguishes this group from other mammals is the saddle-shaped ankle between the astragalus and the scaphoid, which greatly restricts the mobility of the foot. The thigh is relatively short, and the clavicle is absent.

Odd-toed ungulates have a long upper jaw with an extended diastema between the front and cheek teeth, giving them an elongated head. The various forms of snout between families are due to differences in the form of the premaxilla. The lacrimal bone has projecting cusps in the eye sockets and a wide contact with the nasal bone. The temporomandibular joint is high and the mandible is enlarged.

Rhinos have one or two horns made of agglutinated keratin, unlike the horns of even-toed ungulates, which have a bony core.

The number and form of the teeth vary according to diet. The incisors and canines can be very small or completely absent, as in the two African species of rhinoceros. In the horses, usually only the males possess canines. The surface shape and height of the molars is heavily dependent on whether soft leaves or hard grass makes up the main component of their diets. Three or four cheek teeth are present on each jaw half, so the dental formula of odd-toed ungulates is: 
All perissodactyls are hindgut fermenters. In contrast to ruminants, hindgut fermenters store digested food that has left the stomach in an enlarged cecum, where the food is digested by bacteria. No gallbladder is present. The stomach of perissodactyls is simply built, while the cecum accommodates up to in horses. The intestine is very long, reaching up to in horses. Extraction of nutrients from food is relatively inefficient, which probably explains why no odd-toed ungulates are small; for large animals, nutritional requirements per unit of body weight are lower and the surface-to-volume ratio is smaller.

The present distribution of most perissodactyl species is only a small fraction of their original range. Members of this group are now found only in Central and South America, eastern and southern Africa, and central, southern, and southeastern Asia. During the peak of odd-toed ungulate existence, from the Eocene to the Oligocene, perissodactyls were distributed over much of the globe, the only exceptions being Australia and Antarctica. Horses and tapirs arrived in South America after the formation of the Isthmus of Panama in the Pliocene, around 3 million years ago. In North America, they died out around 10,000 years ago, while in Europe, the tarpans disappeared in the 19th century. Hunting and habitat restriction have reduced the present-day species to fragmented relict populations. In contrast, domesticated horses and donkeys have gained a worldwide distribution, and feral animals of both species are now also found in regions outside of their original range, such as in Australia.

Perissodactyls inhabit a number of different habitats, leading to different lifestyles. Tapirs are solitary and inhabit mainly tropical rainforests. Rhinos tend to live alone in rather dry savannas, and in Asia, wet marsh or forest areas. Horses inhabit open areas such as grasslands, steppes, or semideserts, and live together in groups. Odd-toed ungulates are exclusively herbivores that feed, to varying degrees, on grasses, leaves, and other plant parts. A distinction is often made between primarily grass feeders (white rhinos, equines) and leaf feeders (tapirs, other rhinos).

Odd-toed ungulates are characterized by a long gestation period and a small litter size, usually delivering a single young. The gestation period is 330–500 days, being longest in the rhinos. Newborn perissodactyls are precocial; young horses and rhinos can follow the mother after a few hours. The young are nursed for a relatively long time, often into their second year, reaching sexual maturity around eight or ten years old. Perissodactyls are long-lived, with several species reaching an age of almost 50 years in captivity.

Traditionally, the odd-toed ungulates were classified with other mammals such as artiodactyls, hyraxes, mammals with a proboscis, and other "ungulates". A close family relationship with hyraxes was suspected based on similarities in the construction of the ear and the course of the carotid artery.

Recent molecular genetic studies, however, have shown the ungulates to be polyphyletic, meaning that in some cases the similarities are the result of convergent evolution rather than common ancestry. Elephants and hyraxes are now considered to belong to Afrotheria, so are not closely related to the perissodactyls. These, in turn, are in the Laurasiatheria, a superorder that had its origin in the former supercontinent Laurasia. Molecular genetic findings suggest that the cloven Artiodactyla (containing the cetaceans as a deeply nested subclade) are the sister taxon of the Perissodactyla; together, the two groups form the Euungulata. More distant are the bats (Chiroptera) and Ferae (a common taxon of carnivorans, Carnivora, and pangolins, Pholidota). In a discredited alternative scenario, a close relationship exists between perissodactyls, carnivores, and bats, this assembly comprising the Pegasoferae.

According to studies published in March 2015, odd-toed ungulates are in a close family relationship with at least some of the so-called Meridiungulata, a very diverse group of mammals living from the Paleocene to the Pleistocene in South America, whose systematic unity is largely unexplained. Some of these were classified on the basis of their paleogeographic distribution. However, a close relationship can be worked out to perissodactyls by means of protein sequencing and comparison with fossil collagen from remnants of phylogenetically young members of the Meridiungulata (specifically "Macrauchenia" from the Litopterna and "Toxodon" from the Notoungulata). Both kinship groups, the odd-toed ungulates and the Litopterna-Notoungulata, are now in the higher-level taxon of Panperissodactyla. This kinship group is included among the Euungulata which also contains the even-toed ungulates and whales (Artiodactyla). The separation of the Litopterna-Notoungulata group from the perissodactyls probably took place before the Cretaceous-Paleogene extinction event. "Condylarths" can probably be considered the starting point for the development of the two groups, as they represent a heterogeneous group of primitive ungulates that mainly inhabited the northern hemisphere in the Paleogene.

Odd-toed ungulates (Perissodactyla) comprise three living families with around 17 species—in the horse the exact count is still controversial. Rhinos and tapirs are more closely related to each other than to the horses. The separation of horses from other perissodactyls took place according to molecular genetic analysis in the Paleocene some 56 million years ago, while the rhinos and tapirs split off in the lower middle Eocene, about 47 million years ago. 

There are many perissodactyl fossils of multivariant form. The major lines of development include the following groups:


Relationships within the large group of odd-toed ungulates are not fully understood. Initially, after the establishment of "Perissodactyla" by Richard Owen in 1848, the present-day representatives were considered equal in rank. In the first half of the 20th century, a more systematic differentiation of odd-toed ungulates began, based on a consideration of fossil forms, and they were placed in two major suborders: Hippomorpha and Ceratomorpha. The Hippomorpha comprises today's horses and their extinct members (Equoidea); the Ceratomorpha consist of tapirs and rhinos plus their extinct members (Tapiroidea and Rhinocerotoidea). The names Hippomorpha and Ceratomorpha were introduced in 1937 by Horace Elmer Wood, in response to criticism of the name "Solidungula" that he proposed three years previously. It had been based on the grouping of horses and Tridactyla and on the rhinoceros/tapir complex. The extinct brontotheriidae were also classified under Hippomorpha and therefore possess a close relationship to horses. Some researchers accept this assignment because of similar dental features, but there is also the view that a very basal position within the odd-toed ungulates places them rather in the group of "Titanotheriomorpha".

Originally, the Chalicotheriidae were seen as members of Hippomorpha, and presented as such in 1941. William Berryman Scott thought that, as claw-bearing perissodactyls, they belong in the new suborder Ancylopoda (where Ceratomorpha and Hippomorpha as odd-toed ungulates were combined in the group of Chelopoda). The term Ancylopoda, coined by Edward Drinker Cope in 1889, had been established for chalicotheres. However, further morphological studies from the 1960s showed a middle position of Ancylopoda between Hippomorpha and Ceratomorpha. Leonard Burton Radinsky saw all three major groups of odd-toed ungulates as peers, based on the extremely long and independent phylogenetic development of the three lines. In the 1980s, Jeremy J. Hooker saw a general similarity of Ancylopoda and "Ceratomorpha" based on dentition, especially in the earliest members, leading to the unification in 1984 of the two submissions in the interim order, "Tapiromorpha". At the same time he expanded the Ancylopoda to include the "Lophiodontidae". The name "Tapiromorpha" goes back to Ernst Haeckel, who coined it in 1873, but it was long considered synonymous to Ceratomorpha because Wood had not considered it in 1937 when Ceratomorpha were named, since the term had been used quite differently in the past. Also in 1984, Robert M. Schoch used the conceptually similar term Moropomorpha, which today applies synonymously to Tapiromorpha. Included within the Tapiromorpha are the now extinct Isectolophidae, a sister group of the Ancylopoda-Ceratomorpha group and thus the most primitive members of this relationship complex.

The evolutionary development of Perissodactyla is well documented in the fossil record. Numerous finds are evidence of the adaptive radiation of this group, which was once much more varied and widely dispersed. "Radinskya" from the late Paleocene of East Asia is often considered to be one of the oldest close relatives of the ungulates. Its only 8 cm skull must have belonged to a very small and primitive animal with a π-shaped crown pattern on the enamel of its rear molars similar to that of perissodactyls and their relatives, especially the rhinos. Finds of "Cambaytherium" and "Kalitherium" in the Cambay shale of western India indicate an origin in Asia dating to the Lower Eocene roughly 54.5 million years ago. Their teeth also show similarities to "Radinskya" as well as to the Tethytheria clade. The saddle-shaped configuration of the navicular joints and the mesaxonic construction of the front and hind feet also indicates a close relationship to Tethytheria. However, this construction deviates from that of "Cambaytherium", indicating that it is actually a member of a sister group. Ancestors of Perissodactyla may have arrived via an island bridge from the Afro-Arab landmass onto the Indian subcontinent as it drifted north towards Asia.

The alignment of hyopsodontids and phenacodontids to Perissodactyla in general suggests an older Laurasian origin and distribution for the clade, dispersed across the northern continents already in the early Paleocene. These forms already show a fairly well-developed molar morphology, with no intermediary forms as evidence of the course of its development. The close relationship between meridiungulate mammals and perissoodactyls in particular is of interest since the latter appear in South America soon after the KT event, implying rapid ecological radiation and dispersal after the mass extinction.

The Perissodactyla appear relatively abruptly at the beginning of the Lower Paleocene before about 63 million years ago, both in North America and Asia, in the form of phenacodontids and hyopsodontids. The oldest finds from an extant group originate among other sources from "Sifrhippus", an ancestor of the horses from the Willswood lineup in northwestern Wyoming. The distant ancestors of tapirs appeared not too long after that in the Ghazij lineup in Balochistan, such as "Ganderalophus", as well as "Litolophus" from the Chalicotheriidae line, or "Eotitanops" from the group of brontotheriidae. Initially, the members of the different lineages looked quite similar with an arched back and generally four toes on the front and three on the hind feet. "Hyracotherium", which is considered a member of the horse family, outwardly resembled "Hyrachyus", the first representative of the rhino and tapir line. All were small compared to later forms and lived as fruit and foliage eaters in forests. The first of the mega-fauna to emerge were the brontotheres, in the Middle and Upper Eocene. "Megacerops", known from North America, reached a withers height of and could have weighed just over . The decline of brontotheres at the end of the Eocene is associated with competition arising from the advent of more successful herbivores.

More successful lines of odd-toed ungulates emerged at the end of the Eocene when dense jungles gave way to steppe, such as the chalicotheriid rhinos, and their immediate relatives; their development also began with very small forms. "Paraceratherium", one of the largest mammals ever to walk the earth, evolved during this era. They weighed up to and lived throughout the Oligocene in Eurasia. About 20 million years ago at the onset of the Miocene the perissodactyls first reached Africa when it became connected to Eurasia because of the closing of the Tethys Ocean. For the same reason, however, new animals such as the mammoths also entered the ancient settlement areas of odd-toed ungulates, creating competition that led to the extinction of some of their lines. The rise of ruminants, which occupied similar ecological niches and had a much more efficient digestive system, is also associated with the decline in diversity of odd-toed ungulates. A significant cause for the decline of perissodactyls was climate change during the Miocene, leading to a cooler and drier climate accompanied by the spread of open landscapes. However, some lines flourished, such as the horses and rhinos; anatomical adaptations made it possible for them to consume tougher grass food. This led to open land forms that dominated the newly created landscapes. With the emergence of the Isthmus of Panama in the Pliocene, perissodactyls and other megafauna were given access to one of their last habitable continents: South America. However, many perissodactyls became extinct at the end of the ice ages, including American horses and the "Elasmotherium". Whether over-hunting by humans (overkill hypothesis), climatic change, or a combination of both factors was responsible for the extinction of ice age mega-fauna, remains controversial.

In 1758, in his seminal work "Systema Naturae", Linnaeus (1707–1778) classified horses ("Equus") together with hippos ("Hippopotamus"). At that time, this category also included the tapirs ("Tapirus"), more precisely the lowland or South American tapir ("Tapirus terrestus"), the only tapir then known in Europe. Linnaeus classified this tapir as "Hippopotamus terrestris" and put both genera in the group of the "Belluae" ("beasts"). He combined the rhinos with the Glires, a group now consisting of the lagomorphs and rodents. Mathurin Jacques Brisson (1723–1806) first separated the tapirs and hippos in 1762 with the introduction of the concept "le tapir". He also separated the rhinos from the rodents, but did not combine the three families now known as the odd-toed ungulates. In the transition to the 19th century, the individual perissodactyl genera were associated with various other groups, such as the proboscidean and even-toed ungulates. In 1795, Étienne Geoffroy Saint-Hilaire (1772- 1844) and Georges Cuvier (1769–1832) introduced the term "pachyderm" (Pachydermata), including in it not only the rhinos and elephants, but also the hippos, pigs, peccaries, tapirs and hyrax . The horses were still generally regarded as a group separate from other mammals and were often classified under the name "Solidungula" or "Solipèdes", meaning "one-hoof animal".

In 1861, Henri Marie Ducrotay de Blainville (1777–1850) classified ungulates by the structure of their feet, differentiating those with an even number of toes from those with an odd number. He moved the horses as "solidungulate" over to the tapirs and rhinos as "multungulate" animals and referred to all of them together as "onguligrades à doigts impairs", coming close to the concept of the odd-toed ungulate as a systematic unit. Richard Owen (1804–1892) quoted Blainville in his study on fossil mammals of the Isle of Wight and introduced the name "Perissodactyla".

In 1884, Othniel Charles Marsh (1831–1899) came up with the concept "Mesaxonia", which he used for what are today called the odd-toed ungulates, including their extinct relatives, but explicitly excluding the hyrax. "Mesaxonia" is now considered a synonym of "Perissodactyla", but it was sometimes also used for the true odd-toed ungulates as a subcategory (rhinos, horses, tapirs), while "Perissodactyla" stood for the entire order, including the hyrax. The assumption that hyraxes were "Perissodactyla" was held well into the 20th century. Only with the advent of molecular genetic research methods had it been recognized that the hyrax is not closely related to perissodactyls but rather to elephants and manatees.

The domestic horse and the donkey play an important role in human history particularly as transport, work and pack animals. The domestication of both species began several millennia B.C. Due to the motorisation of agriculture and the spread of automobile traffic, such use has declined sharply in Western industrial countries; riding is usually undertaken more as a hobby or sport. In less developed regions of the world, the traditional uses for these animals are, however, still widespread. To a lesser extent, horses and donkeys are also kept for their meat and their milk.

In contrast, the existence in the wild of almost all other odd-toed ungulates species has declined dramatically because of hunting and habitat destruction. The quagga is extinct and Przewalski's horse has been eradicated in the wild.

Present threat levels, according to the International Union for Conservation of Nature (2012):




</doc>
<doc id="23565" url="https://en.wikipedia.org/wiki?curid=23565" title="Pai gow">
Pai gow

Pai gow () is a Chinese gambling game, played with a set of 32 Chinese dominoes. It is played in major casinos in China (including Macau); the United States (including Las Vegas, Nevada; Reno, Nevada; Connecticut; Atlantic City, New Jersey; Pennsylvania; and cardrooms in California); Canada (including Edmonton, Alberta and Calgary, Alberta); Australia; and, New Zealand.

The name "pai gow" is sometimes used to refer to a card game called pai gow poker (or “double-hand poker”), which is loosely based on pai gow.

Tiles are shuffled on the table and are arranged into eight face-down stacks of four tiles each in an assembly known as the "woodpile". Individual stacks or tiles may then be moved in specific ways to rearrange the woodpile, after which the players place their bets.

Next, each player (including the dealer) is given one stack of tiles and must use them to form two hands of two tiles each. The hand with the lower value is called the "front hand", and the hand with the higher value is called the "rear hand". If a player's front hand beats the dealer's front hand, and the player's rear hand beats the dealer's rear hand, then that player wins the bet. If a player's front and rear hands both lose to the dealer's respective hands, the player loses the bet. If one hand wins and the other loses, the player is said to "push", and gets back only the money he or she bet. Generally seven players will play, and each player's hands are compared only against the dealer's hands.

There are 35,960 possible ways to select 4 of the 32 tiles when the 32 tiles are considered distinguishable. However, there are 3620 distinct sets of 4 tiles when the tiles of a pair are considered indistinguishable. There are 496 ways to select 2 of the 32 tiles when the 32 tiles are considered distinguishable. There are 136 distinct hands (pairs of tiles) when the tiles of a pair are considered indistinguishable.

The name "pai gow" is loosely translated as "make nine" or "card nine". This reflects the fact that, with a few high-scoring exceptions, the maximum score for a hand is nine. If a hand consists of two tiles that do not form a pair, its value is determined by adding up the total number of pips on the tiles and dropping the tens digit (if any). Examples:


There are special ways in which a hand can score more than nine points. The double-one tiles and double-six tiles are known as the "Day" and "Teen" tiles, respectively. The combination of a Day or Teen with an eight results in a "Gong", worth 10 points, while putting either of them with a nine creates a "Wong", worth 11. However, when a Day or Teen is paired with any other tile, the standard scoring rules apply.

The 1-2 and the 2-4 tiles are called "Gee Joon" tiles and act as limited wild cards. When used as part of a hand, these tiles may be scored as either 3 or 6, whichever results in a higher hand value. For example, a hand of 1-2 and 5-6 scores as seven rather than four.

The 32 tiles in a Chinese dominoes set can be arranged into 16 pairs, as shown in the picture at the top of this article. Eleven of these pairs have identical tiles, and five of these pairs are made up of two tiles that score the same, but look different. (The latter group includes the Gee Joon tiles, which can score the same, whether as three or six.) If a hand is made up of a pair, it always scores higher than a non-pair, no matter what the value of the pips are. (Pairs are often thought of as being worth 12 points each.)

When the player and dealer both have a pair, the higher-ranked pair wins. Ranking is determined not by the sum of the tiles' pips, but rather by aesthetics; the order must be memorized. The highest pairs are the Gee Joon tiles, the Teens, the Days, and the red eights. The lowest pairs are the mismatched nines, eights, sevens, and fives.

When the player and dealer display hands with the same score, the one with the highest-valued tile (based on the pair rankings described above) is the winner. For example, a player's hand of 3-4 and 2-2 and a dealer's hand of 5-6 and 5-5 would each score one point. However, since the dealer's 5-5 outranks the other three tiles, he would win the hand.

If the scores are tied, and if the player and dealer each have an identical highest-ranking tile, the hand is ruled a "copy" and the dealer wins. For example, if the player held 2-2 and 1-6, and the dealer held 2-2 and 3-4, the dealer would win since the scores (1 each) and the higher tiles (2-2) are the same. The lower-ranked tile in each hand is never used to break a tie.

There are two exceptions to the method described above. First, although the Gee Joon tiles form the highest-ranking pair, they are considered to have no value when evaluating ties. Second, any zero-zero tie is won by the dealer, regardless of the tiles in the two hands.

The key element of pai gow strategy is to present the optimal front and rear hands based on the tiles dealt to the player. There are three ways to arrange four tiles into two hands when no two of them form a pair. However, if there is at least one pair among the tiles, there are only two distinct ways to form two hands.

Using the tiles shown at right, the following hands and scores are possible:


The player must decide which combination is most likely to give a set of front/rear hands that can beat the dealer, or at least break a tie in the player's favor. In some cases, a player with weaker tiles may deliberately attempt to attain a push so as to avoid losing the bet outright. Many players rely on superstition or tradition to choose tile pairings.




</doc>
<doc id="23572" url="https://en.wikipedia.org/wiki?curid=23572" title="Partially ordered set">
Partially ordered set

In mathematics, especially order theory, a partially ordered set (also poset) formalizes and generalizes the intuitive concept of an ordering, sequencing, or arrangement of the elements of a set. A poset consists of a set together with a binary relation indicating that, for certain pairs of elements in the set, one of the elements precedes the other in the ordering. The word "partial" in the names "partial order" or "partially ordered set" is used as an indication that not every pair of elements need be comparable. That is, there may be pairs of elements for which neither element precedes the other in the poset. Partial orders thus generalize total orders, in which every pair is comparable. 

To be a partial order, a binary relation must be reflexive (each element is comparable to itself), antisymmetric (no two different elements precede each other), and transitive (the start of a chain of precedence relations must precede the end of the chain).

One familiar example of a partially ordered set is a collection of people ordered by genealogical descendancy. Some pairs of people bear the descendant-ancestor relationship, but other pairs of people are incomparable, with neither being a descendent of the other. 

A poset can be visualized through its Hasse diagram, which depicts the ordering relation.

A (non-strict) partial order is a binary relation ≤ over a set "P" satisfying particular axioms which are discussed below. When "a" ≤ "b", we say that "a" is related to "b". (This does not imply that "b" is also related to "a", because the relation need not be symmetric.) 

The axioms for a non-strict partial order state that the relation ≤ is reflexive, antisymmetric, and transitive. That is, for all "a", "b", and "c" in "P", it must satisfy:


In other words, a partial order is an antisymmetric preorder.

A set with a partial order is called a partially ordered set (also called a poset). The term "ordered set" is sometimes also used, as long as it is clear from the context that no other kind of order is meant. In particular, totally ordered sets can also be referred to as "ordered sets", especially in areas where these structures are more common than posets.

For "a, b", elements of a partially ordered set "P", if "a" ≤ "b" or "b" ≤ "a", then "a" and "b" are comparable. Otherwise they are incomparable. In the figure on top-right, e.g. {x} and {x,y,z} are comparable, while {x} and {y} are not. A partial order under which every pair of elements is comparable is called a total order or linear order; a totally ordered set is also called a chain (e.g., the natural numbers with their standard order). A subset of a poset in which no two distinct elements are comparable is called an antichain (e.g. the set of singletons in the top-right figure). An element "a" is said to be covered by another element "b", written "a"<:"b", if "a" is strictly less than "b" and no third element "c" fits between them; formally: if both "a"≤"b" and "a"≠"b" are true, and "a"≤"c"≤"b" is false for each "c" with "a"≠"c"≠"b". A more concise definition will be given below using the strict order corresponding to "≤". For example, {x} is covered by {x,z} in the top-right figure, but not by {x,y,z}.

Standard examples of posets arising in mathematics include:


There are several notions of "greatest" and "least" element in a poset "P", notably:

For example, consider the positive integers, ordered by divisibility: 1 is a least element, as it divides all other elements; on the other hand this poset does not have a greatest element (although if one would include 0 in the poset, which is a multiple of any integer, that would be a greatest element; see figure). This partially ordered set does not even have any maximal elements, since any "g" divides for instance 2"g", which is distinct from it, so "g" is not maximal. If the number 1 is excluded, while keeping divisibility as ordering on the elements greater than 1, then the resulting poset does not have a least element, but any prime number is a minimal element for it. In this poset, 60 is an upper bound (though not a least upper bound) of the subset {2,3,5,10}, which does not have any lower bound (since 1 is not in the poset); on the other hand 2 is a lower bound of the subset of powers of 2, which does not have any upper bound.

In order of increasing strength, i.e., decreasing sets of pairs, three of the possible partial orders on the Cartesian product of two partially ordered sets are (see figures):

All three can similarly be defined for the Cartesian product of more than two sets.

Applied to ordered vector spaces over the same field, the result is in each case also an ordered vector space.

See also orders on the Cartesian product of totally ordered sets.

Another way to combine two posets is the ordinal sum (or linear sum), "Z" = "X" ⊕ "Y", defined on the union of the underlying sets "X" and "Y" by the order "a" ≤ "b" if and only if:

If two posets are well-ordered, then so is their ordinal sum.
The ordinal sum operation is one of two operations used to form series-parallel partial orders, and in this context is called series composition. The other operation used to form these orders, the disjoint union of two partially ordered sets (with no order relation between elements of one set and elements of the other set) is called in this context parallel composition.

In some contexts, the partial order defined above is called a non-strict (or reflexive, or weak) partial order. In these contexts, a strict (or irreflexive) partial order "<" is a binary relation that is irreflexive, transitive and asymmetric, i.e. which satisfies for all "a", "b", and "c" in "P":


Strict and non-strict partial orders are closely related. A non-strict partial order may be converted to a strict partial order by removing all relationships of the form "a" ≤ "a". Conversely, a strict partial order may be converted to a non-strict partial order by adjoining all relationships of that form. Thus, if "≤" is a non-strict partial order, then the corresponding strict partial order "<" is the irreflexive kernel given by:

Conversely, if "<" is a strict partial order, then the corresponding non-strict partial order "≤" is the reflexive closure given by:

This is the reason for using the notation "≤".

Using the strict order "<", the relation ""a" is covered by "b"" can be equivalently rephrased as ""a"<"b", but not "a"<"c"<"b" for any "c"".
Strict partial orders are useful because they correspond more directly to directed acyclic graphs (dags): every strict partial order is a dag, and the transitive closure of a dag is both a strict partial order and also a dag itself.

The inverse (or converse) of a partial order relation ≤ is the converse of ≤. Typically denoted ≥, it is the relation that satisfies "x" ≥ "y" if and only if "y" ≤ "x". The inverse of a partial order relation is reflexive, transitive, and antisymmetric, and hence itself a partial order relation. The order dual of a partially ordered set is the same set with the partial order relation replaced by its inverse. The irreflexive relation > is to ≥ as < is to ≤.

Any one of the four relations ≤, <, ≥, and > on a given set uniquely determines the other three.

In general two elements "x" and "y" of a partial order may stand in any of four mutually exclusive relationships to each other: either "x" < "y", or "x" = "y", or "x" > "y", or "x" and "y" are "incomparable" (none of the other three). A totally ordered set is one that rules out this fourth possibility: all pairs of elements are comparable and we then say that trichotomy holds. The natural numbers, the integers, the rationals, and the reals are all totally ordered by their algebraic (signed) magnitude whereas the complex numbers are not. This is not to say that the complex numbers cannot be totally ordered; we could for example order them lexicographically via "x"+iy" < "u"+iv" if and only if "x" < "u" or ("x" = "u" and "y" < "v"), but this is not ordering by magnitude in any reasonable sense as it makes 1 greater than 100i. Ordering them by absolute magnitude yields a preorder in which all pairs are comparable, but this is not a partial order since 1 and i have the same absolute magnitude but are not equal, violating antisymmetry.

Given two partially ordered sets ("S",≤) and ("T",≤), a function "f": "S" → "T" is called order-preserving, or monotone, or isotone, if for all "x" and "y" in "S", "x"≤"y" implies "f"("x") ≤ "f"("y").
If ("U",≤) is also a partially ordered set, and both "f": "S" → "T" and "g": "T" → "U" are order-preserving, their composition ("g"∘"f"): "S" → "U" is order-preserving, too.
A function "f": "S" → "T" is called order-reflecting if for all "x" and "y" in "S", "f"("x") ≤ "f"("y") implies "x"≤"y".
If "f" is both order-preserving and order-reflecting, then it is called an order-embedding of ("S",≤) into ("T",≤).
In the latter case, "f" is necessarily injective, since "f"("x") = "f"("y") implies "x" ≤ "y" and "y" ≤ "x". If an order-embedding between two posets "S" and "T" exists, one says that "S" can be embedded into "T". If an order-embedding "f": "S" → "T" is bijective, it is called an order isomorphism, and the partial orders ("S",≤) and ("T",≤) are said to be isomorphic. Isomorphic orders have structurally similar Hasse diagrams (cf. right picture). It can be shown that if order-preserving maps "f": "S" → "T" and "g": "T" → "S" exist such that "g"∘"f" and "f"∘"g" yields the identity function on "S" and "T", respectively, then "S" and "T" are order-isomorphic.
For example, a mapping "f": ℕ → ℙ(ℕ) from the set of natural numbers (ordered by divisibility) to the power set of natural numbers (ordered by set inclusion) can be defined by taking each number to the set of its prime divisors. It is order-preserving: if "x" divides "y", then each prime divisor of "x" is also a prime divisor of "y". However, it is neither injective (since it maps both 12 and 6 to {2,3}) nor order-reflecting (since besides 12 doesn't divide 6). Taking instead each number to the set of its prime power divisors defines a map "g": ℕ → ℙ(ℕ) that is order-preserving, order-reflecting, and hence an order-embedding. It is not an order-isomorphism (since it e.g. doesn't map any number to the set {4}), but it can be made one by restricting its codomain to "g"(ℕ). The right picture shows a subset of ℕ and its isomorphic image under "g". The construction of such an order-isomorphism into a power set can be generalized to a wide class of partial orders, called distributive lattices, see "Birkhoff's representation theorem".

Sequence [ A001035] in OEIS gives the number of partial orders on a set of "n" labeled elements:

The number of strict partial orders is the same as that of partial orders.

If the count is made only up to isomorphism, the sequence 1, 1, 2, 5, 16, 63, 318, … is obtained.

A partial order ≤ on a set "X" is an extension of another partial order ≤ on "X" provided that for all elements "x" and "y" of "X", whenever "x" ≤ "y", it is also the case that "x" ≤ "y". A linear extension is an extension that is also a linear (i.e., total) order. Every partial order can be extended to a total order (order-extension principle).

In computer science, algorithms for finding linear extensions of partial orders (represented as the reachability orders of directed acyclic graphs) are called topological sorting.

Every poset (and every preorder) may be considered as a category in which every hom-set has at most one element. More explicitly, let hom("x", "y") = {("x", "y")} if "x" ≤ "y" (and otherwise the empty set) and ("y", "z")∘("x", "y") = ("x", "z"). Such categories are sometimes called "posetal".

Posets are equivalent to one another if and only if they are isomorphic. In a poset, the smallest element, if it exists, is an initial object, and the largest element, if it exists, is a terminal object. Also, every preordered set is equivalent to a poset. Finally, every subcategory of a poset is isomorphism-closed.

If "P" is a partially ordered set that has also been given the structure of a topological space, then it is customary to assume that is a closed subset of the topological product space formula_1. Under this assumption partial order relations are well behaved at limits in the sense that if formula_2, formula_3 and "a" ≤ "b" for all "i", then "a" ≤ "b".

For "a" ≤ "b", the closed interval is the set of elements "x" satisfying "a" ≤ "x" ≤ "b" (i.e. "a" ≤ "x" and "x" ≤ "b"). It contains at least the elements "a" and "b".

Using the corresponding strict relation "<", the open interval is the set of elements "x" satisfying "a" < "x" < "b" (i.e. "a" < "x" and "x" < "b"). An open interval may be empty even if "a" < "b". For example, the open interval on the integers is empty since there are no integers "i" such that 1 < "i" < 2.

Sometimes the definitions are extended to allow "a" > "b", in which case the interval is empty.

The "half-open intervals" and are defined similarly.

A poset is locally finite if every interval is finite. For example, the integers are locally finite under their natural ordering. The lexicographical order on the cartesian product ℕ×ℕ is not locally finite, since e.g. (1,2)≤(1,3)≤(1,4)≤(1,5)≤...≤(2,1).
Using the interval notation, the property ""a" is covered by "b"" can be rephrased equivalently as ["a","b"] = {"a","b"}.

This concept of an interval in a partial order should not be confused with the particular class of partial orders known as the interval orders.




</doc>
<doc id="23574" url="https://en.wikipedia.org/wiki?curid=23574" title="Psyche">
Psyche

Psyche (Psyché in French) is the Greek term for "soul" or "spirit" (ψυχή).

It may also refer to:









</doc>
<doc id="23575" url="https://en.wikipedia.org/wiki?curid=23575" title="Parmenides">
Parmenides

Parmenides of Elea (; ; ) was a pre-Socratic Greek philosopher from Elea in Magna Graecia (Greater Greece, included Southern Italy). He was the founder of the Eleatic school of philosophy. The single known work of Parmenides is a poem, "On Nature", which has survived only in fragmentary form. In this poem, Parmenides prescribes two views of reality. In "the way of truth" (a part of the poem), he explains how reality (coined as "what-is") is one, change is impossible, and existence is timeless, uniform, necessary, and unchanging. In "the way of opinion", he explains the world of appearances, in which one's sensory faculties lead to conceptions which are false and deceitful. He has been considered to be the founder of metaphysics or ontology.

Parmenides was born in the Greek colony of Elea (now Ascea), which, according to Herodotus, had been founded shortly before 535 BC. He was descended from a wealthy and illustrious family.

His dates are uncertain; according to Diogenes Laërtius, he flourished just before 500 BC, which would put his year of birth near 540 BC, but Plato has him visiting Athens at the age of 65, when Socrates was a young man, c. 450 BC, which, if true, suggests a year of birth of c. 515 BC. He was said to have been a pupil of Xenophanes, and regardless of whether they actually knew each other, Xenophanes' philosophy is the most obvious influence on Parmenides. Diogenes Laërtius also describes Parmenides as a disciple of "Ameinias, son of Diochaites, the Pythagorean"; but there are no obvious Pythagorean elements in his thought.

However, according to Sir William Smith, in "Dictionary of Greek and Roman Biography and Mythology" (1870):Others content themselves with reckoning Parmenides as well as Zeno as belonging to the Pythagorean school, or with speaking of a "Parmenidean life", in the same way as a "Pythagorean life" is spoken of; and even the censorious Timon allows Parmenides to have been a high-minded man; while Plato speaks of him with veneration, and Aristotle and others give him an unqualified preference over the rest of the Eleatics.

The first hero cult of a philosopher we know of was Parmenides' dedication of a heroon to his teacher Ameinias in Elea. Parmenides was the founder of the School of Elea, which also included Zeno of Elea and Melissus of Samos. Of his life in Elea, it was said that he had written the laws of the city. His most important pupil was Zeno, who according to Plato was 25 years his junior, and was regarded as his "eromenos". Parmenides had a large influence on Plato, who not only named a dialogue, "Parmenides", after him, but always wrote about him with veneration.

William Smith also wrote in "Dictionary of Greek and Roman Biography and Mythology":On the former reason is our guide; on the latter the eye that does not catch the object and re-echoing hearing. On the former path we convince ourselves that the existent neither has come into being, nor is perishable, and is entirely of one sort, without change and limit, neither past nor future, entirely included in the present. For it is as impossible that it can become and grow out of the existent, as that it could do so out of the non-existent; since the latter, non-existence, is absolutely inconceivable, and the former cannot precede itself; and every coming into existence presupposes a non-existence. By similar arguments divisibility, motion or change, as also infinity, are shut out from the absolutely existent, and the latter is represented as shut up in itself, so that it may be compared to a well-rounded ball; while thought is appropriated to it as its only positive definition. Thought and that which is thought of (Object) coinciding; the corresponding passages of Plato, Aristotle, Theophrastus, and others, which authenticate this view of his theory.

Cosmology originally comprised the greater part of his poem, him explaining the world’s origins and operations. John Palmer notes "Parmenides’ distinction among the principal modes of being and his derivation of the attributes that must belong to what must be, simply as such, qualify him to be seen as the founder of metaphysics or ontology as a domain of inquiry distinct from theology." Some idea of the sphericity of the Earth seems to have been known to both Parmenides and Empedocles.

Parmenides also outlined the phases of the moon, highlighted in a rhymed translation by Karl Popper:
Smith stated:Of the cosmogony of Parmenides, which was carried out very much in detail, we possess only a few fragments and notices, which are difficult to understand, according to which, with an approach to the doctrines of the "Pythagoreans", he conceived the spherical mundane system, surrounded by a circle of the pure light (Olympus, Uranus); in the centre of this mundane system the solid earth, and between the two the circle of the milkyway, of the morning or evening star, of the sun, the planets, and the moon; which circle he regarded as a mixture of the two primordial elements.

The fragments read:
Parmenides is one of the most significant of the pre-Socratic philosophers. His single known work, a poem conventionally titled "On Nature", has survived only in fragments. Approximately 160 verses remain today from an original total that was probably near 800. The poem was originally divided into three parts:

The proem is a narrative sequence in which the narrator travels "beyond the beaten paths of mortal men" to receive a revelation from an unnamed goddess (generally thought to be Persephone or Dikē) on the nature of reality. "Aletheia", an estimated 90% of which has survived, and "doxa", most of which no longer exists, are then presented as the spoken revelation of the goddess without any accompanying narrative.

Parmenides attempted to distinguish between the unity of nature and its variety, insisting in the "Way of Truth" upon the reality of its unity, which is therefore the object of knowledge, and upon the unreality of its variety, which is therefore the object, not of knowledge, but of opinion. In the "Way of Opinion" he propounded a theory of the world of seeming and its development, pointing out, however, that, in accordance with the principles already laid down, these cosmological speculations do not pretend to anything more than mere appearance.

In the proem, Parmenides describes the journey of the poet, escorted by maidens ("the daughters of the Sun made haste to escort me, having left the halls of Night for the light"), from the ordinary daytime world to a strange destination, outside our human paths. Carried in a whirling chariot, and attended by the daughters of Helios the Sun, the man reaches a temple sacred to an unnamed goddess (variously identified by the commentators as Nature, Wisdom, Necessity or Themis), by whom the rest of the poem is spoken. The goddess resides in a well-known mythological space: where Night and Day have their meeting place. Its essential character is that here all opposites are undivided, or one. He must learn all things, she tells him – both truth, which is certain, and human opinions, which are uncertain – for though one cannot rely on human opinions, they represent an aspect of the whole truth.

The section known as "the way of truth" discusses that which is real and contrasts with the argument in the section called "the way of opinion," which discusses that which is illusory. Under the "way of truth," Parmenides stated that there are two ways of inquiry: that it "is", on the one side, and that it "is not". on the other side. He said that the latter argument is never feasible because there is no thing that can "not be": "For never shall this prevail, that things that are not are." (B 7.1)

There are extremely delicate issues here. In the original Greek the two ways are simply named "that Is" (ὅπως ἐστίν) and "that Not-Is" (ὡς οὐκ ἐστίν) (B 2.3 and 2.5) without the "it" inserted in our English translation. In ancient Greek, which, like many languages in the world, does not always require the presence of a subject for a verb, "is" functions as a grammatically complete sentence. Much debate has been focused on where and what the subject is. The simplest explanation as to why there is no subject here is that Parmenides wishes to express the simple, bare fact of existence in his mystical experience without the ordinary distinctions, just as the Latin "pluit" and the Greek "huei" (ὕει "rains") mean "it rains"; there is no subject for these impersonal verbs because they express the simple fact of raining without specifying what is doing the raining. This is, for instance, Hermann Fränkel's thesis. Many scholars still reject this explanation and have produced more complex metaphysical explanations. Since existence is an immediately intuited fact, non-existence is the wrong path because a thing cannot disappear, just as something cannot originate from nothing. In such mystical experience ("unio mystica"), however, the distinction between subject and object disappears along with the distinctions between objects, in addition to the fact that if nothing cannot be, it cannot be the object of thought either:Thinking and the thought that it is are the same; for you will not find thinking apart from what is, in relation to which it is uttered. (B 8.34–36)For to be aware and to be are the same. (B 3)It is necessary to speak and to think what is; for being is, but nothing is not. (B 6.1–2)Helplessness guides the wandering thought in their breasts; they are carried along deaf and blind alike, dazed, beasts without judgment, convinced that to be and not to be are the same and not the same, and that the road of all things is a backward-turning one. (B 6.5–9)Thus, he concluded that "Is" could not have "come into being" because "nothing comes from nothing". Existence is necessarily eternal. That which truly is [x], has always been [x], and was never becoming [x]; that which is becoming [x] was never nothing (Not-[x]), but will never actually be. Parmenides was not struggling to formulate the laws of conservation of mass and conservation of energy; he was struggling with the metaphysics of change, which is still a relevant philosophical topic today.

Moreover, he argued that movement was impossible because it requires moving into "the void", and Parmenides identified "the void" with nothing, and therefore (by definition) it does not exist. That which does exist is "The Parmenidean One", which is timeless, uniform, and unchanging:How could what is perish? How could it have come to be? For if it came into being, it is not; nor is it if ever it is going to be. Thus coming into being is extinguished, and destruction unknown. (B 8.20–22)Nor was [it] once, nor will [it] be, since [it] is, now, all together, / One, continuous; for what coming-to-be of it will you seek? / In what way, whence, did [it] grow? Neither from what-is-not shall I allow / You to say or think; for it is not to be said or thought / That [it] is not. And what need could have impelled it to grow / Later or sooner, if it began from nothing? Thus [it] must either be completely or not at all. (B 8.5–11)[What exists] is now, all at once, one and continuous... Nor is it divisible, since it is all alike; nor is there any more or less of it in one place which might prevent it from holding together, but all is full of what is. (B 8.5–6, 8.22–24)And it is all one to me / Where I am to begin; for I shall return there again. (B 5)

Parmenides claimed that there is no truth in the opinions of the mortals. Genesis-and-destruction, as Parmenides emphasizes, is a false opinion, because to be means to be completely, once and for all. What exists can in no way not exist. For this view, that That Which Is Not exists, can never predominate. You must debar your thought from this way of search, nor let ordinary experience in its variety force you along this way, (namely, that of allowing) the eye, sightless as it is, and the ear, full of sound, and the tongue, to rule; but (you must) judge by means of the Reason (Logos) the much-contested proof which is expounded by me. (B 7.1–8.2)

After the exposition of the "arche" (ἀρχή), i.e. the origin, the necessary part of reality that is understood through reason or logos ("that [it] Is"), in the next section, "the Way of Appearance/Opinion/Seeming", Parmenides proceeds to explain the structure of the becoming cosmos (which is an illusion, of course) that comes from this origin.
The structure of the cosmos is a fundamental binary principle that governs the manifestations of all the particulars: "the aether fire of flame" (B 8.56), which is gentle, mild, soft, thin and clear, and self-identical, and the other is "ignorant night", body thick and heavy.The mortals lay down and decided well to name two forms (i.e. the flaming light and obscure darkness of night), out of which it is necessary not to make one, and in this they are led astray. (B 8.53–4)The structure of the cosmos then generated is recollected by Aetius (II, 7, 1):
For Parmenides says that there are circular bands wound round one upon the other, one made of the rare, the other of the dense; and others between these mixed of light and darkness. What surrounds them all is solid like a wall. Beneath it is a fiery band, and what is in the very middle of them all is solid, around which again is a fiery band. The most central of the mixed bands is for them all the origin and cause of motion and becoming, which he also calls steering goddess and keyholder and Justice and Necessity. The air has been separated off from the earth, vapourized by its more violent condensation, and the sun and the circle of the Milky Way are exhalations of fire. The moon is a mixture of both earth and fire. The "aether" lies around above all else, and beneath it is ranged that fiery part which we call heaven, beneath which are the regions around the earth.

The traditional interpretation of Parmenides' work is that he argued that the every-day perception of reality of the physical world (as described in "doxa") is mistaken, and that the reality of the world is 'One Being' (as described in "aletheia"): an unchanging, ungenerated, indestructible whole. Under the "Way of Opinion", Parmenides set out a contrasting but more conventional view of the world, thereby becoming an early exponent of the duality of appearance and reality. For him and his pupils, the phenomena of movement and change are simply appearances of a changeless, eternal reality. This interpretation could settle because of various wrong translations of the fragments. For example, it is not at all clear that Parmenides refuted that which we call perception. The verb "noein", used frequently by Parmenides, could better be translated as 'to be aware of' than as 'to think'. Furthermore, it is hard to believe that 'being' is only within our heads, according to Parmenides.

Parmenides' philosophy is presented in the form of poetry. The philosophy he argued was, he says, given to him by a goddess, though the "mythological" details in Parmenides' poem do not bear any close correspondence to anything known from traditional Greek mythology:Welcome, youth, who come attended by immortal charioteers and mares which bear you on your journey to our dwelling. For it is no evil fate that has set you to travel on this road, far from the beaten paths of men, but right and justice. It is meet that you learn all things — both the unshakable heart of well-rounded truth and the opinions of mortals in which there is not true belief. (B 1.24–30)It is with respect to this religious/mystical context that recent generations of scholars such as Alexander P. Mourelatos, Charles H. Kahn, and the controversial Peter Kingsley have begun to call parts of the traditional, rational logical/philosophical interpretation of Parmenides into question (Kingsley in particular stating that Parmenides practiced iatromancy). It has been claimed that previous scholars placed too little emphasis on the apocalyptic context in which Parmenides frames his revelation. As a result, traditional interpretations have put Parmenidean philosophy into a more modern, metaphysical context to which it is not necessarily well suited, which has led to misunderstanding of the true meaning and intention of Parmenides' message. The obscurity and fragmentary state of the text, however, renders almost every claim that can be made about Parmenides extremely contentious, and the traditional interpretation has by no means been abandoned.

Parmenides' considerable influence on the thinking of Plato is undeniable, and in this respect Parmenides has influenced the whole history of Western philosophy, and is often seen as its grandfather. Even Plato himself, in the "Sophist", refers to the work of "our Father Parmenides" as something to be taken very seriously and treated with respect. In the "Parmenides", the Eleatic philosopher, which may well be Parmenides himself, and Socrates argue about dialectic. In the "Theaetetus", Socrates says that Parmenides alone among the wise (Protagoras, Heraclitus, Empedocles, Epicharmus, and Homer) denied that everything is change and motion.

Parmenides is credited with a great deal of influence as the author of an "Eleatic challenge" that determined the course of subsequent philosophers' enquiries. For example, the ideas of Empedocles, Anaxagoras, Leucippus, and Democritus have been seen as in response to Parmenides' arguments and conclusions.

Parmenides' influence on philosophy reaches up till present times. The Italian philosopher Emanuele Severino has founded his extended philosophical investigations on the words of Parmenides. His philosophy is sometimes called Neo Parmenideism, and can be understood as an attempt to build a bridge between the poem on truth and the poem on opinion.

Parmenides made the ontological argument against nothingness, "essentially denying the possible existence of a void". According to Aristotle, this led Democritus and Leucippus, and many other physicists, to propose the atomic theory, which supposes that everything in the universe is either atoms or voids, specifically to contradict Parmenides' argument. Aristotle himself reasoned, in opposition to atomism, that in a complete vacuum, motion would encounter no resistance, and "no one could say why a thing once set in motion should stop anywhere; for why should it stop here rather than here? So that a thing will either be at rest or must be moved ad infinitum, unless something more powerful get in its way." See also "horror vacui."

Erwin Schrödinger identified Parmenides' monad of the "Way of Truth" as being the conscious self in "Nature and the Greeks". The scientific implications of this view have been discussed by scientist Anthony Hyman.

A shadow of Parmenides' ideas can be seen in the physical concept of Block time, which considers existence to consist of past, present, and future, and the flow of time to be illusory. In his critique of this idea, Karl Popper called Einstein "Parmenides". However, Popper did write:
So what was really new in Parmenides was his axiomatic-deductive method, which Leucippus and Democritus turned into a hypothetical-deductive method, and thus made part of scientific methodology.




</doc>
<doc id="23576" url="https://en.wikipedia.org/wiki?curid=23576" title="Tetraodontidae">
Tetraodontidae

The Tetraodontidae are a family of primarily marine and estuarine fish of the order Tetraodontiformes. The family includes many familiar species which are variously called pufferfish, puffers, balloonfish, blowfish, blowies, bubblefish, globefish, swellfish, toadfish, toadies, honey toads, sugar toads, and sea squab. They are morphologically similar to the closely related porcupinefish, which have large external spines (unlike the thinner, hidden spines of the Tetraodontidae, which are only visible when the fish has puffed up). The scientific name refers to the four large teeth, fused into an upper and lower plate, which are used for crushing the hard shells of crustaceans and mollusks, their natural prey.

The majority of pufferfish species are toxic and some are among the most poisonous vertebrates in the world. In certain species, the internal organs, such as liver, and sometimes their skin, contain tetrodotoxin and are highly toxic to most animals when eaten; nevertheless, the meat of some species is considered a delicacy in Japan (as 河豚, pronounced as "fugu"), Korea (as 복 "bok" or 복어 "bogeo"), and China (as 河豚 "hétún") when prepared by specially trained chefs who know which part is safe to eat and in what quantity. Other pufferfish species with nontoxic flesh, such as the northern puffer, "Sphoeroides maculatus", of Chesapeake Bay, are considered a delicacy elsewhere.

The species "Torquigener albomaculosus" was called by David Attenborough "the greatest artist of the animal kingdom" due to the males<nowiki>'</nowiki> unique habit of wooing females by creating nests in sand composed of complex geometric designs.

The Tetraodontidae contain at least 191 species of puffers in 29 genera:



They are typically small to medium in size, although a few species can reach lengths of greater than .

They are most diverse in the tropics, relatively uncommon in the temperate zone, and completely absent from cold waters.

Most pufferfish species live in marine or brackish waters, but some can enter fresh water. About 35 species spend their entire lifecycles in fresh water. These fresh water species are found in disjunct tropical regions of South America ("Colomesus asellus"), Africa (six "Tetraodon" species) and Southeast Asia ("Auriglobus", "Carinotetraodon", "Dichotomyctere", "Leiodon" and "Pao").

The puffer's unique and distinctive natural defenses help compensate for its slow locomotion. It moves by combining pectoral, dorsal, anal, and caudal fins. This makes it highly maneuverable, but very slow, and therefore a comparatively easy predation target. Its tail fin is mainly used as a rudder, but it can be used for a sudden evasive burst of speed that shows none of the care and precision of its usual movements. The puffer's excellent eyesight, combined with this speed burst, is the first and most important defense against predators.

The pufferfish's secondary defense mechanism, used if successfully pursued, is to fill its extremely elastic stomach with water (or air when outside the water) until it is much larger and almost spherical in shape. Even if they are not visible when the puffer is not inflated, all puffers have pointed spines, so a hungry predator may suddenly find itself facing an unpalatable, pointy ball rather than a slow, tasty fish. Predators which do not heed this warning (or which are "lucky" enough to catch the puffer suddenly, before or during inflation) may die from choking, and predators that do manage to swallow the puffer may find their stomachs full of tetrodotoxin, making puffers an unpleasant, possibly lethal, choice of prey. This neurotoxin is found primarily in the ovaries and liver, although smaller amounts exist in the intestines and skin, as well as trace amounts in muscle. It does not always have a lethal effect on large predators, such as sharks, but it can kill humans.

Not all puffers are necessarily poisonous; the flesh of the northern puffer is not toxic (a level of poison can be found in its viscera) and it is considered a delicacy in North America. "Takifugu oblongus", for example, is a "fugu" puffer that is not poisonous, and toxin level varies wildly even in fish that are. A puffer's neurotoxin is not necessarily as toxic to other animals as it is to humans, and puffers are eaten routinely by some species of fish, such as lizardfish and tiger sharks. Also, Japanese fish farmers have grown nonpoisonous puffers by controlling their diets.

Puffers are able to move their eyes independently, and many species can change the color or intensity of their patterns in response to environmental changes. In these respects, they are somewhat similar to the terrestrial chameleon. Although most puffers are drab, many have bright colors and distinctive markings, and make no attempt to hide from predators. This is likely an example of honestly signaled aposematism.

Many marine puffers have a pelagic, or open-ocean, life stage. Spawning occurs after males slowly push females to the water surface or join females already present. The eggs are spherical and buoyant. Hatching occurs after roughly four days. The fry are tiny, but under magnification have a shape usually reminiscent of a pufferfish. They have a functional mouth and eyes, and must eat within a few days. Brackish-water puffers may breed in bays in a similar manner to marine species, or may breed more similarly to the freshwater species, in cases where they have moved far enough upriver.

Reproduction in freshwater species varies quite a bit. The dwarf puffers court with males following females, possibly displaying the crests and keels unique to this subgroup of species. After the female accepts his advances, she will lead the male into plants or another form of cover, where she can release eggs for fertilization. The male may help her by rubbing against her side. This has been observed in captivity, and they are the only commonly captive-spawned puffer species.

Target-group puffers have also been spawned in aquariums, and follow a similar courting behavior, minus the crest/keel display. However, eggs are laid on a flat piece of slate or other smooth, hard material, to which they adhere. The male will guard them until they hatch, carefully blowing water over them regularly to keep the eggs healthy. His parenting is finished when the young hatch, and the fry are on their own.

Information on breeding of specific species is very limited. "T. nigroviridis", the green-spotted puffer, has recently been artificially spawned under captive conditions. It is believed to spawn in bays in a similar manner to saltwater species, as their sperm was found to be motile only at full marine salinities, but actual wild breeding has never been observed. "Xenopterus naritus" has been reported to be first breed artificially in Sarawak, Northwestern Borneo in June 2016, which the main purpose is for development in aquaculture of the species.

In 2012, males of the species "Torquigener albomaculosus" were documented carving large geometric, circular structures in the seabed sand in Amami Ōshima, Japan. The structures serve to attract females and provide a safe place for them to lay their eggs.

A pufferfish's diet can vary depending on its environment. Traditionally, their diet consists mostly of algae and small invertebrates. They can survive on a completely vegetarian diet if their environment is lacking resources, but prefer an omnivorous food selection. Larger species of pufferfish are able to use their beak-like front teeth to break open clams, mussels, as well as other shellfish. Some species of pufferfish have also been known to enact various hunting techniques ranging from ambush to open water hunting.

The tetraodontids have been estimated to diverge from diodontids between 89 and 138 million years ago. The four major clades diverged during the Cretaceous between 80 and 101 million years ago. The oldest known pufferfish genus is "Eotetraodon", from the Lutetian epoch of Middle Eocene Europe, with fossils found in Monte Bolca and the Caucasus Mountains. The Monte Bolca species, "E. pygmaeus", coexisted with several other tetraodontiforms, including an extinct species of diodontid, primitive boxfish ("Proaracana" and "Eolactoria"), and other, totally extinct forms, such as "Zignoichthys" and the spinacanthids. The extinct genus, "Archaeotetraodon" is known from Miocene-aged fossils from Europe.

Pufferfish can be lethal if not served properly. Puffer poisoning usually results from consumption of incorrectly prepared puffer soup, "fugu chiri", or occasionally from raw puffer meat, "sashimi fugu". While "chiri" is much more likely to cause death, "sashimi fugu" often causes intoxication, light-headedness, and numbness of the lips, and is often eaten for this reason. Pufferfish tetrodotoxin deadens the tongue and lips, and induces dizziness and vomiting, followed by numbness and prickling over the body, rapid heart rate, decreased blood pressure, and muscle paralysis. The toxin paralyzes diaphragm muscle and stops the person who has ingested it from breathing. People who live longer than 24 hours typically survive, although possibly after a coma lasting several days.

The source of tetrodotoxin in puffers has been a matter of debate, but it is increasingly accepted that bacteria in the fish's intestinal tract are the source.

Saxitoxin, the cause of paralytic shellfish poisoning and red tide, can also be found in certain puffers.

The Bureau of Fisheries and Aquatic Resources issued a warning not to eat puffer fish, locally known as "butete", after local fishermen died upon consuming puffer fish for dinner. The warning indicated that puffer fish toxin is 100 times more potent than cyanide.

Pufferfish, called "pakpao" in Thailand, are usually consumed by mistake. They are often cheaper than other fish, and because they contain inconsistent levels of toxins between fish and season, there is little awareness or monitoring of the danger. Consumers are regularly hospitalized and some even die from the poisoning.

Cases of neurological symptoms, including numbness and tingling of the lips and mouth, have been reported to rise after the consumption of puffers caught in the area of Titusville, Florida, U.S. The symptoms generally resolve within hours to days, although one affected individual required intubation for 72 hours. As a result, Florida banned the harvesting of puffers from certain bodies of water.

Treatment consists of intestinal decontamination with gastric lavage and activated charcoal, and life-support until the toxin is metabolized. Case reports suggest anticholinesterases such as edrophonium may be effective.





</doc>
<doc id="23577" url="https://en.wikipedia.org/wiki?curid=23577" title="Partial function">
Partial function

In mathematics, a partial function from "X" to "Y" (sometimes written as or ) is a function , for some proper subset "X" ′ of "X". It generalizes the concept of a function by not forcing "f" to map "every" element of "X" to an element of "Y" (only some proper subset "X" ′ of "X"). If , then "f" is called a total function and is equivalent to a function. Partial functions are often used when the exact domain, "X", is not known (e.g. many functions in computability theory).

Specifically, we will say that for any , either:

For example, we can consider the square root function restricted to the integers

Thus "g"("n") is only defined for "n" that are perfect squares (). So, , but "g"(26) is undefined.

There are two distinct meanings in current mathematical usage for the notion of the domain of a partial function. Most mathematicians, including recursion theorists, use the term "domain of "f"" for the set of all values "x" such that "f"("x") is defined ("X<nowiki>'</nowiki>" above). But some, particularly category theorists, consider the domain of a partial function "f":"X" → "Y" to be "X", and refer to "X<nowiki>'</nowiki>" as the domain of definition. Similarly, the term range can refer to either the codomain or the "image" of a function.

A partial function is said to be injective or surjective when the total function given by the restriction of the partial function to its domain of definition is injective or surjective respectively. A partial function may be both injective and surjective (and thus bijective).

Because a function is trivially surjective when restricted to its image, the term partial bijection denotes a partial function which is injective.

An injective partial function may be inverted to an injective partial function, and a partial function which is both injective and surjective has an injective function as inverse. Furthermore, a total function which is injective may be inverted to an injective partial function.

The notion of transformation can be generalized to partial functions as well. A partial transformation is a function , where both "A" and "B" are subsets of some set "X".

Total function is a synonym for function. The use of the adjective "total" is to suggest that it is a special case of a partial function (specifically, a total function with domain "X" is a special case of a partial function over "X"). The adjective will typically be used for clarity in contexts where partial functions are common, for example in computability theory.

The set of all partial functions from a set "X" to a set "Y", denoted by , is the union of all total functions defined on subsets of "X" with same codomain "Y":
the latter also written as formula_5. In finite case, its cardinality is
because any partial function can be extended to a total function by any fixed value "c" not contained in "Y", so that the codomain is }, an operation which is injective (unique and invertible by restriction).

The first diagram above represents a partial function that is "not" a total function since the element 1 in the left-hand set is not associated with anything in the right-hand set. Whereas, the second diagram represents a total function since every element on the left-hand set is associated with exactly one element in the right hand set.

Consider the natural logarithm function mapping the real numbers to themselves. The logarithm of a non-positive real is not a real number, so the natural logarithm function doesn't associate any real number in the codomain with any non-positive real number in the domain. Therefore, the natural logarithm function is not a total function when viewed as a function from the reals to themselves, but it is a partial function. If the domain is restricted to only include the positive reals (that is, if the natural logarithm function is viewed as a function from the positive reals to the reals), then the natural logarithm is a total function.

Subtraction of natural numbers (non-negative integers) can be viewed as a partial function:

It is defined only when formula_10.

In denotational semantics a partial function is considered as returning the bottom element when it is undefined.

In computer science a partial function corresponds to a subroutine that raises an exception or loops forever. The IEEE floating point standard defines a not-a-number value which is returned when a floating point operation is undefined and exceptions are suppressed, e.g. when the square root of a negative number is requested.

In a programming language where function parameters are statically typed, a function may be defined as a partial function because the language's type system cannot express the exact domain of the function, so the programmer instead gives it the smallest domain which is expressible as a type and contains the true domain.

In category theory, when considering the operation of morphism composition in concrete categories, the composition operation formula_11 is a total function if and only if formula_12 has one element. The reason for this is that two morphisms formula_13 and formula_14 can only be composed as formula_15 if formula_16, that is, the codomain of formula_17 must equal the domain of formula_18.

The category of sets and partial functions is equivalent to but not isomorphic with the category of pointed sets and point-preserving maps. One textbook notes that "This formal completion of sets and partial maps by adding “improper,” “infinite” elements was reinvented many times, in particular, in topology (one-point compactification) and in theoretical computer science."

The category of sets and partial bijections is equivalent to its dual. It is the prototypical inverse category.

Partial algebra generalizes the notion of universal algebra to partial operations. An example would be a field, in which the multiplicative inversion is the only proper partial operation (because division by zero is not defined).

The set of all partial functions (partial transformations) on a given base set, "X", forms a regular semigroup called the semigroup of all partial transformations (or the partial transformation semigroup on "X"), typically denoted by formula_19. The set of all partial bijections on "X" forms the symmetric inverse semigroup.

Charts in the atlases which specify the structure of manifolds and fiber bundles are partial functions. In the case of manifolds, the domain is the point set of the manifold. In the case of fiber bundles, the domain is the total space of the fiber bundle. In these applications, the most important construction is the transition map, which is the composite of one chart with the inverse of another. The initial classification of manifolds and fiber bundles is largely expressed in terms of constraints on these transition maps.

The reason for the use of partial functions instead of total functions is to permit general global topologies to be represented by stitching together local patches to describe the global structure. The "patches" are the domains where the charts are defined.




</doc>
<doc id="23579" url="https://en.wikipedia.org/wiki?curid=23579" title="Photoelectric effect">
Photoelectric effect

The photoelectric effect is the emission of electrons or other free carriers when light shines on a material. Electrons emitted in this manner can be called "photo electrons". This phenomenon is commonly studied in electronic physics, as well as in fields of chemistry, such as quantum chemistry or electrochemistry.

According to classical electromagnetic theory, this effect can be attributed to the transfer of energy from the light to an electron. From this perspective, an alteration in the intensity of light would induce changes in the kinetic energy of the electrons emitted from the metal. Furthermore, according to this theory, a sufficiently dim light would be expected to show a time lag between the initial shining of its light and the subsequent emission of an electron. However, the experimental results did not correlate with either of the two predictions made by classical theory.

Instead, electrons are dislodged only by the impingement of photons when those photons reach or exceed a threshold frequency (energy). Below that threshold, no electrons are emitted from the material regardless of the light intensity or the length of time of exposure to the light. (Rarely, an electron will escape by absorbing two or more quanta. However, this is extremely rare because by the time it absorbs enough quanta to escape, the electron will probably have emitted the rest of the quanta.) To make sense of the fact that light can eject electrons even if its intensity is low, Albert Einstein proposed that a beam of light is not a wave propagating through space, but rather a collection of discrete wave packets (photons), each with energy "hν". This shed light on Max Planck's previous discovery of the Planck relation () linking energy ("E") and frequency ("ν") as arising from quantization of energy. The factor "h" is known as the Planck constant.

In 1887, Heinrich Hertz discovered that electrodes illuminated with ultraviolet light create electric sparks more easily. In 1900, while studying black-body radiation, the German physicist Max Planck suggested that the energy carried by electromagnetic waves could only be released in "packets" of energy. In 1905, Albert Einstein published a paper advancing the hypothesis that light energy is carried in discrete quantized packets to explain experimental data from the photoelectric effect. This model contributed to the development of quantum mechanics. In 1914, Millikan's Experiment supported Einstein's model of the photoelectric effect. Einstein was awarded the Nobel Prize in 1921 for "his discovery of the law of the photoelectric effect", and Robert Millikan was awarded the Nobel Prize in 1923 for "his work on the elementary charge of electricity and on the photoelectric effect".

The photoelectric effect requires photons with energies approaching zero (in the case of negative electron affinity) to over 1 MeV for core electrons in elements with a high atomic number. Emission of conduction electrons from typical metals usually requires a few electron-volts, corresponding to short-wavelength visible or ultraviolet light. Study of the photoelectric effect led to important steps in understanding the quantum nature of light and electrons and influenced the formation of the concept of wave–particle duality. Other phenomena where light affects the movement of electric charges include the photoconductive effect (also known as photoconductivity or photoresistivity), the photovoltaic effect, and the photoelectrochemical effect.

Photoemission can occur from any material, but it is most easily observable from metals or other conductors because the process produces a charge imbalance, and if this charge imbalance is not neutralized by current flow (enabled by conductivity), the potential barrier to emission increases until the emission current ceases. It is also usual to have the emitting surface in a vacuum, since gases impede the flow of photoelectrons and make them difficult to observe. Additionally, the energy barrier to photoemission is usually increased by thin oxide layers on metal surfaces if the metal has been exposed to oxygen, so most practical experiments and devices based on the photoelectric effect use clean metal surfaces in a vacuum.

When the photoelectron is emitted into a solid rather than into a vacuum, the term "internal photoemission" is often used, and emission into a vacuum distinguished as "external photoemission".
The photons of a light beam have a characteristic energy proportional to the frequency of the light. In the photoemission process, if an electron within some material absorbs the energy of one photon and acquires more energy than the work function (the electron binding energy) of the material, it is ejected. If the photon energy is too low, the electron is unable to escape the material. Since an increase in the intensity of low-frequency light will only increase the number of low-energy photons sent over a given interval of time, this change in intensity will not create any single photon with enough energy to dislodge an electron. Thus, the energy of the emitted electrons does not depend on the intensity of the incoming light, but only on the energy (equivalent frequency) of the individual photons. It is an interaction between the incident photon and the outermost electrons.

Electrons can absorb energy from photons when irradiated, but they usually follow an "all or nothing" principle. All of the energy from one photon must be absorbed and used to liberate one electron from atomic binding, or else the energy is re-emitted. If the photon energy is absorbed, some of the energy liberates the electron from the atom, and the rest contributes to the electron's kinetic energy as a free particle.

The theory of the photoelectric effect must explain the experimental observations of the emission of electrons from an illuminated metal surface.

For a given metal, there exists a certain minimum frequency of incident radiation below which no photoelectrons are emitted. This frequency is called the "threshold frequency". Increasing the frequency of the incident beam, keeping the number of incident photons fixed (this would result in a proportionate increase in energy) increases the maximum kinetic energy of the photoelectrons emitted. Thus the stopping voltage increases. The number of electrons also changes because of the probability that each photon results in an emitted electron are a function of photon energy. If the intensity of the incident radiation of a given frequency is increased, there is no effect on the kinetic energy of each photoelectron.

Above the threshold frequency, the maximum kinetic energy of the emitted photoelectron depends on the frequency of the incident light, but is independent of the intensity of the incident light so long as the latter is not too high.

For a given metal and frequency of incident radiation, the rate at which photoelectrons are ejected is directly proportional to the intensity of the incident light. An increase in the intensity of the incident beam (keeping the frequency fixed) increases the magnitude of the photoelectric current, although the stopping voltage remains the same.

The time lag between the incidence of radiation and the emission of a photoelectron is very small, less than 10 second.

The direction of distribution of emitted electrons peaks in the direction of polarization (the direction of the electric field) of the incident light, if it is linearly polarized.

In 1905, Einstein proposed an explanation of the photoelectric effect using a concept first put forward by Max Planck that light waves consist of tiny bundles or packets of energy known as photons or quanta. 
The maximum kinetic energy formula_1 of an ejected electron is given by

where formula_3 is the Planck constant and formula_4 is the frequency of the incident photon. The term formula_5 is the work function (sometimes denoted formula_6, or formula_7), which gives the minimum energy required to remove a delocalised electron from the surface of the metal. The work function satisfies

where formula_9 is the threshold frequency for the metal. The maximum kinetic energy of an ejected electron is then

Kinetic energy is positive, so we must have formula_11 for the photoelectric effect to occur.

The relation between current and applied voltage illustrates the nature of the photoelectric effect. For discussion, a light source illuminates a plate P, and another plate electrode Q collects any emitted electrons. We vary the potential between P and Q and measure the current flowing in the external circuit between the two plates.

If the frequency and the intensity of the incident radiation are fixed, the photoelectric current increases gradually with an increase in the positive potential on the collector electrode until all the photoelectrons emitted are collected. The photoelectric current attains a saturation value and does not increase further for any increase in the positive potential. The saturation current increases with the increase of the light intensity. It also increases with greater frequencies due to a greater probability of electron emission when collisions happen with higher energy photons.

If we apply a negative potential to the collector plate Q with respect to the plate P and gradually increase it, the photoelectric current decreases, becoming zero at a certain negative potential. The negative potential on the collector at which the photoelectric current becomes zero is called the "stopping potential" or "cut off" potential

i. For a given frequency of incident radiation, the stopping potential is independent of its intensity.

ii. For a given frequency of incident radiation, the stopping potential is determined by the maximum kinetic energy formula_1 of the photoelectrons that are emitted. If "q" is the charge on the electron and formula_13 is the stopping potential, then the work done by the retarding potential in stopping the electron is formula_14, so we have

Recalling

we see that the stopping voltage varies linearly with frequency of light, but depends on the type of material. For any particular material, there is a threshold frequency that must be exceeded, independent of light intensity, to observe any electron emission.

In the X-ray regime, the photoelectric effect in crystalline material is often decomposed into three steps:

In the three-step model, an electron can take multiple paths through these three steps. All paths can interfere in the sense of the path integral formulation.
For surface states and molecules the three-step model does still make some sense as even most atoms have multiple electrons which can scatter the one electron leaving.

When a surface is exposed to electromagnetic radiation above a certain threshold frequency (typically visible light for alkali metals, near ultraviolet for other metals, and extreme ultraviolet for non-metals), the radiation is absorbed and electrons are emitted.
Light, and especially ultra-violet light, discharges negatively electrified bodies with the production of rays of the same nature as cathode rays. Under certain circumstances it can directly ionize gases. The first of these phenomena was discovered by Hertz and Hallwachs in 1887. The second was announced first by Philipp Lenard in 1900.

The ultra-violet light to produce these effects may be obtained from an arc lamp, or by burning magnesium, or by sparking with an induction coil between zinc or cadmium terminals, the light from which is very rich in ultra-violet rays. Sunlight is not rich in ultra-violet rays, as these have been absorbed by the atmosphere, and it does not produce nearly so large an effect as the arc-light. Many substances besides metals discharge negative electricity under the action of ultraviolet light: lists of these substances will be found in papers by G. C. Schmidt and O. Knoblauch.

In 1839, Alexandre Edmond Becquerel discovered the photovoltaic effect while studying the effect of light on electrolytic cells. Though not equivalent to the photoelectric effect, his work on photovoltaics was instrumental in showing a strong relationship between light and electronic properties of materials. In 1873, Willoughby Smith discovered photoconductivity in selenium while testing the metal for its high resistance properties in conjunction with his work involving submarine telegraph cables.

Johann Elster (1854–1920) and Hans Geitel (1855–1923), students in Heidelberg, developed the first practical photoelectric cells that could be used to measure the intensity of light. Elster and Geitel had investigated with great success the effects produced by light on electrified bodies.

In 1887, Heinrich Hertz observed the photoelectric effect and the production and reception of electromagnetic waves. He published these observations in the journal Annalen der Physik. His receiver consisted of a coil with a spark gap, where a spark would be seen upon detection of electromagnetic waves. He placed the apparatus in a darkened box to see the spark better. However, he noticed that the maximum spark length was reduced when in the box. A glass panel placed between the source of electromagnetic waves and the receiver absorbed ultraviolet radiation that assisted the electrons in jumping across the gap. When removed, the spark length would increase. He observed no decrease in spark length when he replaced the glass with quartz, as quartz does not absorb UV radiation. Hertz concluded his months of investigation and reported the results obtained. He did not further pursue the investigation of this effect.

The discovery by Hertz in 1887 that the incidence of ultra-violet light on a spark gap facilitated the passage of the spark, led immediately to a series of investigations by Hallwachs, Hoor, Righi and Stoletow on the effect of light, and especially of ultra-violet light, on charged bodies. It was proved by these investigations that a newly cleaned surface of zinc, if charged with negative electricity, rapidly loses this charge however small it may be when ultra-violet light falls upon the surface; while if the surface is uncharged to begin with, it acquires a positive charge when exposed to the light, the negative electrification going out into the gas by which the metal is surrounded; this positive electrification can be much increased by directing a strong airblast against the surface. If however the zinc surface is positively electrified it suffers no loss of charge when exposed to the light: this result has been questioned, but a very careful examination of the phenomenon by Elster and Geitel has shown that the loss observed under certain circumstances is due to the discharge by the light reflected from the zinc surface of negative electrification on neighbouring conductors induced by the positive charge, the negative electricity under the influence of the electric field moving up to the positively electrified surface.

With regard to the "Hertz effect", the researchers from the start showed a great complexity of the phenomenon of photoelectric fatigue — that is, the progressive diminution of the effect observed upon fresh metallic surfaces. According to an important research by Wilhelm Hallwachs, ozone played an important part in the phenomenon. However, other elements enter such as oxidation, the humidity, the mode of polish of the surface, etc. It was at the time not even sure that the fatigue is absent in a vacuum.

In the period from February 1888 and until 1891, a detailed analysis of photoeffect was performed by Aleksandr Stoletov with results published in 6 works; four of them in "Comptes Rendus", one review in "Physikalische Revue" (translated from Russian), and the last work in "Journal de Physique". First, in these works Stoletov invented a new experimental setup which was more suitable for a quantitative analysis of photoeffect. Using this setup, he discovered the direct proportionality between the intensity of light and the induced photo electric current (the first law of photoeffect or Stoletov's law). One of his other findings resulted from measurements of the dependence of the intensity of the electric photo current on the gas pressure, where he found the existence of an optimal gas pressure P corresponding to a maximum photocurrent; this property was used for a creation of solar cells.

In 1899, J. J. Thomson investigated ultraviolet light in Crookes tubes. Thomson deduced that the ejected particles were the same as those previously found in the cathode ray, later called electrons, which he called "corpuscles". In the research, Thomson enclosed a metal plate (a cathode) in a vacuum tube, and exposed it to high-frequency radiation. It was thought that the oscillating electromagnetic fields caused the atoms' field to resonate and, after reaching a certain amplitude, caused a subatomic "corpuscle" to be emitted, and current to be detected. The amount of this current varied with the intensity and color of the radiation. Larger radiation intensity or frequency would produce more current.

The discovery of the ionization of gases by ultra-violet light was made by Philipp Lenard in 1900. As the effect was produced across several centimeters of air and made very great positive and small negative ions, it was natural to interpret the phenomenon, as did J. J. Thomson, as a "Hertz effect" upon the solid or liquid particles present in the gas.

In 1902, Lenard observed that the energy of individual emitted electrons increased with the frequency (which is related to the color) of the light.

This appeared to be at odds with Maxwell's wave theory of light, which predicted that the electron energy would be proportional to the intensity of the radiation.

Lenard observed the variation in electron energy with light frequency using a powerful electric arc lamp which enabled him to investigate large changes in intensity, and that had sufficient power to enable him to investigate the variation of potential with light frequency. His experiment directly measured potentials, not electron kinetic energy: he found the electron energy by relating it to the maximum stopping potential (voltage) in a phototube. He found that the calculated maximum electron kinetic energy is determined by the frequency of the light. For example, an increase in frequency results in an increase in the maximum kinetic energy calculated for an electron upon liberation – ultraviolet radiation would require a higher applied stopping potential to stop current in a phototube than blue light. However, Lenard's results were qualitative rather than quantitative because of the difficulty in performing the experiments: the experiments needed to be done on freshly cut metal so that the pure metal was observed, but it oxidized in a matter of minutes even in the partial vacuums he used. The current emitted by the surface was determined by the light's intensity, or brightness: doubling the intensity of the light doubled the number of electrons emitted from the surface.

The researches of Langevin and those of Eugene Bloch have shown that the greater part of the Lenard effect is certainly due to this 'Hertz effect'. The Lenard effect upon the gas itself nevertheless does exist. Refound by J. J. Thomson and then more decisively by Frederic Palmer, Jr., it was studied and showed very different characteristics than those at first attributed to it by Lenard.

In 1905, Albert Einstein solved this apparent paradox by describing light as composed of discrete quanta, now called photons, rather than continuous waves. Based upon Max Planck's theory of black-body radiation, Einstein theorized that the energy in each quantum of light was equal to the frequency multiplied by a constant, later called Planck's constant. A photon above a threshold frequency has the required energy to eject a single electron, creating the observed effect. This discovery led to the quantum revolution in physics and earned Einstein the Nobel Prize in Physics in 1921. By wave-particle duality the effect can be analyzed purely in terms of waves though not as conveniently.

Albert Einstein's mathematical description of how the photoelectric effect was caused by absorption of quanta of light was in one of his 1905 papers, named ""On a Heuristic Viewpoint Concerning the Production and Transformation of Light"". This paper proposed the simple description of "light quanta", or photons, and showed how they explained such phenomena as the photoelectric effect. His simple explanation in terms of absorption of discrete quanta of light explained the features of the phenomenon and the characteristic frequency.

The idea of light quanta began with Max Planck's published law of black-body radiation (""On the Law of Distribution of Energy in the Normal Spectrum"") by assuming that Hertzian oscillators could only exist at energies "E" proportional to the frequency "f" of the oscillator by "E" = "hf", where "h" is Planck's constant. By assuming that light actually consisted of discrete energy packets, Einstein wrote an equation for the photoelectric effect that agreed with experimental results. It explained why the energy of photoelectrons was dependent only on the "frequency" of the incident light and not on its "intensity": a low-intensity, the high-frequency source could supply a few high energy photons, whereas a high-intensity, the low-frequency source would supply no photons of sufficient individual energy to dislodge any electrons. This was an enormous theoretical leap, but the concept was strongly resisted at first because it contradicted the wave theory of light that followed naturally from James Clerk Maxwell's equations for electromagnetic behavior, and more generally, the assumption of infinite divisibility of energy in physical systems. Even after experiments showed that Einstein's equations for the photoelectric effect were accurate, resistance to the idea of photons continued since it appeared to contradict Maxwell's equations, which were well understood and verified.

Einstein's work predicted that the energy of individual ejected electrons increases linearly with the frequency of the light. Perhaps surprisingly, the precise relationship had not at that time been tested. By 1905 it was known that the energy of photoelectrons increases with increasing "frequency" of incident light and is independent of the "intensity" of the light. However, the manner of the increase was not experimentally determined until 1914 when Robert Andrews Millikan showed that Einstein's prediction was correct.

The photoelectric effect helped to propel the then-emerging concept of wave–particle duality in the nature of light. Light simultaneously possesses the characteristics of both waves and particles, each being manifested according to the circumstances. The effect was impossible to understand in terms of the classical wave description of light, as the energy of the emitted electrons did not depend on the intensity of the incident radiation. Classical theory predicted that the electrons would 'gather up' energy over a period of time, and then be emitted.

These are extremely light-sensitive vacuum tubes with a photocathode coated onto part (an end or side) of the inside of the envelope. The photocathode contains combinations of materials such as cesium, rubidium, and antimony specially selected to provide a low work function, so when illuminated even by very low levels of light, the photocathode readily releases electrons. By means of a series of electrodes (dynodes) at ever-higher potentials, these electrons are accelerated and substantially increased in number through secondary emission to provide a readily detectable output current. Photomultipliers are still commonly used wherever low levels of light must be detected.

Video camera tubes in the early days of television used the photoelectric effect, for example, Philo Farnsworth's "Image dissector" used a screen charged by the photoelectric effect to transform an optical image into a scanned electronic signal.

Gold-leaf electroscopes are designed to detect static electricity. Charge placed on the metal cap spreads to the stem and the gold leaf of the electroscope. Because they then have the same charge, the stem and leaf repel each other. This will cause the leaf to bend away from the stem.

An electroscope is an important tool in illustrating the photoelectric effect. For example, if the electroscope is negatively charged throughout, there is an excess of electrons and the leaf is separated from the stem. If high-frequency light shines on the cap, the electroscope discharges, and the leaf will fall limp. This is because the frequency of the light shining on the cap is above the cap's threshold frequency. The photons in the light have enough energy to liberate electrons from the cap, reducing its negative charge. This will discharge a negatively charged electroscope and further charge a positive electroscope. However, if the electromagnetic radiation hitting the metal cap does not have a high enough frequency (its frequency is below the threshold value for the cap), then the leaf will never discharge, no matter how long one shines the low-frequency light at the cap.

Since the energy of the photoelectrons emitted is exactly the energy of the incident photon minus the material's work function or binding energy, the work function of a sample can be determined by bombarding it with a monochromatic X-ray source or UV source, and measuring the kinetic energy distribution of the electrons emitted.

Photoelectron spectroscopy is usually done in a high-vacuum environment, since the electrons would be scattered by gas molecules if they were present. However, some companies are now selling products that allow photoemission in air. The light source can be a laser, a discharge tube, or a synchrotron radiation source.

The concentric hemispherical analyzer is a typical electron energy analyzer and uses an electric field to change the directions of incident electrons, depending on their kinetic energies. For every element and core (atomic orbital) there will be a different binding energy. The many electrons created from each of these combinations will show up as spikes in the analyzer output, and these can be used to determine the elemental composition of the sample.

The photoelectric effect will cause spacecraft exposed to sunlight to develop a positive charge. This can be a major problem, as other parts of the spacecraft are in shadow which will result in the spacecraft developing a negative charge from nearby plasmas. The imbalance can discharge through delicate electrical components. The static charge created by the photoelectric effect is self-limiting, because a higher charged object doesn't give up its electrons as easily as a lower charged object does.

Light from the sun hitting lunar dust causes it to become charged with the photoelectric effect. The charged dust then repels itself and lifts off the surface of the Moon by electrostatic levitation. This manifests itself almost like an "atmosphere of dust", visible as a thin haze and blurring of distant features, and visible as a dim glow after the sun has set. This was first photographed by the Surveyor program probes in the 1960s. It is thought that the smallest particles are repelled kilometers from the surface and that the particles move in "fountains" as they charge and discharge.

Photons hitting a thin film of alkali metal or semiconductor material such as gallium arsenide in an image intensifier tube cause the ejection of photoelectrons due to the photoelectric effect. These are accelerated by an electrostatic field where they strike a phosphor coated screen, converting the electrons back into photons. Intensification of the signal is achieved either through acceleration of the electrons or by increasing the number of electrons through secondary emissions, such as with a micro-channel plate. Sometimes a combination of both methods is used. Additional kinetic energy is required to move an electron out of the conduction band and into the vacuum level. This is known as the electron affinity of the photocathode and is another barrier to photoemission other than the forbidden band, explained by the band gap model. Some materials such as Gallium Arsenide have an effective electron affinity that is below the level of the conduction band. In these materials, electrons that move to the conduction band are all of the sufficient energy to be emitted from the material and as such, the film that absorbs photons can be quite thick. These materials are known as negative electron affinity materials.

The photoelectric effect is one interaction mechanism between photons and atoms. It is one of 12 theoretically possible interactions.

At the high photon energies comparable to the electron rest energy of , Compton scattering, another process, may take place. Above twice this () pair production may take place. Compton scattering and pair production are examples of two other competing mechanisms.

Indeed, even if the photoelectric effect is the favoured reaction for a particular single-photon bound-electron interaction, the result is also subject to statistical processes and is not guaranteed, albeit the photon has certainly disappeared and a bound electron has been excited (usually K or L shell electrons at gamma ray energies). The probability of the photoelectric effect occurring is measured by the cross-section of interaction, σ. This has been found to be a function of the atomic number of the target atom and photon energy. A crude approximation, for photon energies above the highest atomic binding energy, is given by:

Here "Z" is atomic number and "n" is a number which varies between 4 and 5. (At lower photon energies a characteristic structure with edges appears, K edge, L edges, M edges, etc.) The obvious interpretation follows that the photoelectric effect rapidly decreases insignificance, in the gamma-ray region of the spectrum, with increasing photon energy, and that photoelectric effect increases steeply with atomic number. The corollary is that high-"Z" materials make good gamma-ray shields, which is the principal reason that lead ("Z" = 82) is a preferred and ubiquitous gamma radiation shield.



"Applets"


</doc>
<doc id="23580" url="https://en.wikipedia.org/wiki?curid=23580" title="Paleogene">
Paleogene

The Paleogene (; also spelled Palaeogene or Palæogene; informally Lower Tertiary or Early Tertiary) is a geologic period and system that spans 43 million years from the end of the Cretaceous Period million years ago (Mya) to the beginning of the Neogene Period Mya. It is the beginning of the Cenozoic Era of the present Phanerozoic Eon. The Paleogene is most notable for being the time during which mammals diversified from relatively small, simple forms into a large group of diverse animals in the wake of the Cretaceous–Paleogene extinction event that ended the preceding Cretaceous Period. 

This period consists of the Paleocene, Eocene, and Oligocene epochs. The end of the Paleocene (55.5/54.8 Mya) was marked by the Paleocene–Eocene Thermal Maximum, one of the most significant periods of global change during the Cenozoic, which upset oceanic and atmospheric circulation and led to the extinction of numerous deep-sea benthic foraminifera and on land, a major turnover in mammals. The terms 'Paleogene System' (formal) and 'lower Tertiary System' (informal) are applied to the rocks deposited during the 'Paleogene Period'. The somewhat confusing terminology seems to be due to attempts to deal with the comparatively fine subdivisions of time possible in the relatively recent geologic past, for which more details are preserved. By dividing the Tertiary Period into two periods instead of directly into five epochs, the periods are more closely comparable to the duration of 'periods' of the preceding Mesozoic and Paleozoic Eras.

The global climate during the Paleogene departed from the hot and humid conditions of the late Mesozoic era and began a cooling and drying trend which, despite having been periodically disrupted by warm periods such as the Paleocene–Eocene Thermal Maximum, persists today. The trend was partly caused by the formation of the Antarctic Circumpolar Current, which significantly lowered oceanic water temperatures.

During the Paleogene, the continents continued to drift closer to their current positions. India was in the process of colliding with Asia, subsequently forming the Himalayas. The Atlantic Ocean continued to widen by a few centimeters each year. Africa was moving north to meet with Europe and form the Mediterranean, while South America was moving closer to North America (they would later connect via the Isthmus of Panama). Inland seas retreated from North America early in the period. Australia had also separated from Antarctica and was drifting toward Southeast Asia.

Mammals began a rapid diversification during this period. After the Cretaceous–Paleogene extinction event, which saw the demise of the non-avian dinosaurs, mammals transformed from a few small and generalized forms that began to evolve into most of the modern varieties we see today. Some of these mammals would evolve into large forms that would dominate the land, while others would become capable of living in marine, specialized terrestrial, and airborne environments. Those that took to the oceans became modern cetaceans, while those that took to the trees became primates, the group to which humans belong. Birds, which were already well established by the end of the Cretaceous, also experienced an adaptive radiation as they took over the skies left empty by the now extinct Pterosaurs. In comparison to birds and mammals, most other branches of life remained relatively unchanged during this period.

As the Earth cooled, tropical plants became less numerous and were now restricted to equatorial regions. Deciduous plants, which could survive through the seasonal climates the world was now experiencing, became more common.

The Paleogene is notable in the context of offshore oil drilling, and especially in Gulf of Mexico oil exploration, where it is commonly referred to as the "Lower Tertiary". These rock formations represent the current cutting edge of deep-water oil discovery.

Lower Tertiary rock formations encountered in the Gulf of Mexico oil industry usually tend to be comparatively high temperature and high pressure reservoirs, often with high sand content (70%+) or under very thick evaporite sediment layers.

Lower Tertiary explorations to date include (partial list):



</doc>
<doc id="23582" url="https://en.wikipedia.org/wiki?curid=23582" title="Preorder">
Preorder

In mathematics, especially in order theory, a preorder or quasiorder is a binary relation that is reflexive and transitive. Preorders are more general than equivalence relations and (non-strict) partial orders, both of which are special cases of a preorder. An antisymmetric preorder is a partial order, and a symmetric preorder is an equivalence relation.

The name 'preorder' comes from the idea that preorders (that are not partial orders) are 'almost' (partial) orders, but not quite; they are neither necessarily anti-symmetric nor asymmetric. Because a preorder is a binary relation, the symbol ≤ can be used as the notational device for the relation. However, because they are not necessarily anti-symmetric, some of the ordinary intuition associated to the symbol ≤ may not apply. On the other hand, a preorder can be used, in a straightforward fashion, to define a partial order and an equivalence relation. Doing so, however, is not always useful or worthwhile, depending on the problem domain being studied.

In words, when "a" ≤ "b", one may say that "b" "covers" "a" or that "a" "precedes" "b", or that "b" "reduces" to "a". Occasionally, the notation ← or formula_1 is used instead of ≤.

To every preorder, there corresponds a directed graph, with elements of the set corresponding to vertices, and the order relation between pairs of elements corresponding to the directed edges between vertices. The converse is not true: most directed graphs are neither reflexive nor transitive. In general, the corresponding graphs may contain cycles. A preorder that is antisymmetric no longer has cycles; it is a partial order, and corresponds to a directed acyclic graph. A preorder that is symmetric is an equivalence relation; it can be thought of as having lost the direction markers on the edges of the graph. In general, a preorder's corresponding directed graph may have many disconnected components.

Consider some set "P" and a binary relation ≤ on "P". Then ≤ is a preorder, or quasiorder, if it is reflexive and transitive, i.e., for all "a", "b" and "c" in "P", we have that:

A set that is equipped with a preorder is called a preordered set (or proset).

If a preorder is also antisymmetric, that is, "a" ≤ "b" and "b" ≤ "a" implies "a" = "b", then it is a partial order.

On the other hand, if it is symmetric, that is, if "a" ≤ "b" implies "b" ≤ "a", then it is an equivalence relation.

Equivalently, the notion of a preordered set "P" can be formulated in a categorical framework as a thin category, i.e. as a category with at most one morphism from an object to another. Here the objects correspond to the elements of "P", and there is one morphism for objects which are related, zero otherwise. Alternately, a preordered set can be understood as an enriched category, enriched over the category 2 = (0→1).

A preordered class is a class equipped with a preorder. Every set is a class and so every preordered set is a preordered class.


In computer science, one can find examples of the following preorders.

Example of a total preorder:

Preorders play a pivotal role in several situations:

Every binary relation R on a set S can be extended to a preorder on S by taking the transitive closure and reflexive closure, R. The transitive closure indicates path connection in R: "x" R "y" if and only if there is an R-path from "x" to y.

Given a preorder formula_7 on S one may define an equivalence relation ~ on S such that "a" ~ "b" if and only if "a" formula_7 "b" and "b" formula_7 "a". (The resulting relation is reflexive since a preorder is reflexive, transitive by applying transitivity of the preorder twice, and symmetric by definition.)

Using this relation, it is possible to construct a partial order on the quotient set of the equivalence, S / ~, the set of all equivalence classes of ~. Note that if the preorder is R, S / ~ is the set of R-cycle equivalence classes: "x" ∈ ["y"] if and only if "x" = "y" or "x" is in an R-cycle with y. In any case, on S / ~ we can define ["x"] ≤ ["y"] if and only if "x" formula_7 "y". By the construction of ~, this definition is independent of the chosen representatives and the corresponding relation is indeed well-defined. It is readily verified that this yields a partially ordered set.

Conversely, from a partial order on a partition of a set S one can construct a preorder on S. There is a 1-to-1 correspondence between preorders and pairs (partition, partial order).

For a preorder "formula_7", a relation "<" can be defined as "a" < "b" if and only if ("a" formula_7 "b" and not "b" formula_7 "a"), or equivalently, using the equivalence relation introduced above, ("a" formula_7 "b" and not "a" ~ "b"). It is a strict partial order; every strict partial order can be the result of such a construction. If the preorder is anti-symmetric, hence a partial order "≤", the equivalence is equality, so the relation "<" can also be defined as "a" < "b" if and only if ("a" ≤ "b" and "a" ≠ "b").

Conversely we have "a" formula_7 "b" if and only if "a" < "b" or "a" ~ "b". This is the reason for using the notation "formula_7"; "≤" can be confusing for a preorder that is not anti-symmetric, it may suggest that "a" ≤ "b" implies that "a" < "b" or "a" = "b".

Note that with this construction multiple preorders "formula_7" can give the same relation "<", so without more information, such as the equivalence relation, "formula_7" cannot be reconstructed from "<". Possible preorders include the following:

As explained above, there is a 1-to-1 correspondence between preorders and pairs (partition, partial order). Thus the number of preorders is the sum of the number of partial orders on every partition. For example:

For "a" formula_7 "b", the interval ["a","b"] is the set of points "x" satisfying "a" formula_7 "x" and "x" formula_7 "b", also written "a" formula_7 "x" formula_7 "b". It contains at least the points "a" and "b". One may choose to extend the definition to all pairs ("a","b"). The extra intervals are all empty.

Using the corresponding strict relation "<", one can also define the interval ("a","b") as the set of points "x" satisfying "a" < "x" and "x" < "b", also written "a" < "x" < "b". An open interval may be empty even if "a" < "b".

Also ["a","b") and ("a","b"] can be defined similarly.




</doc>
<doc id="23585" url="https://en.wikipedia.org/wiki?curid=23585" title="Psychoanalysis">
Psychoanalysis

Psychoanalysis is a set of theories and therapeutic techniques related to the study of the unconscious mind, which together form a method of treatment for mental-health disorders. The discipline was established in the early 1890s by Austrian neurologist Sigmund Freud and stemmed partly from the clinical work of Josef Breuer and others.

Freud first used the term "psychoanalysis" (in French) in 1896. "Die Traumdeutung" ("The Interpretation of Dreams"), which Freud saw as his "most significant work", appeared in November 1899. Psychoanalysis was later developed in different directions, mostly by students of Freud such as Alfred Adler and Carl Gustav Jung, and by neo-Freudians such as Erich Fromm, Karen Horney and Harry Stack Sullivan. Freud retained the term "psychoanalysis" for his own school of thought. The basic tenets of psychoanalysis include:


During psychoanalytic sessions, which typically last 50 minutes and ideally take place 4–5 times a week, the patient (the "analysand") may lie on a couch, with the analyst often sitting just behind and out of sight. The patient expresses his or her thoughts, including free associations, fantasies and dreams, from which the analyst infers the unconscious conflicts causing the patient's symptoms and character problems. Through the analysis of these conflicts, which includes interpreting the transference and countertransference (the analyst's feelings for the patient), the analyst confronts the patient's pathological defenses to help the patient gain insight.

Psychoanalysis is a controversial discipline and its validity as a science is contested. Nonetheless, it remains a strong influence within psychiatry, more so in some quarters than others. Psychoanalytic concepts are also widely used outside the therapeutic arena, in areas such as psychoanalytic literary criticism, as well as in the analysis of film, fairy tales and other cultural phenomena.

The idea of psychoanalysis () first started to receive serious attention under Sigmund Freud, who formulated his own theory of psychoanalysis in Vienna in the 1890s. Freud was a neurologist trying to find an effective treatment for patients with neurotic or hysterical symptoms. Freud realised that there were mental processes that were not conscious, whilst he was employed as a neurological consultant at the Children's Hospital, where he noticed that many aphasic children had no apparent organic cause for their symptoms. He then wrote a monograph about this subject. In 1885, Freud obtained a grant to study with Jean-Martin Charcot, a famed neurologist, at the Salpêtrière in Paris, where Freud followed the clinical presentations of Charcot, particularly in the areas of hysteria, paralyses and the anaesthesias. Charcot had introduced hypnotism as an experimental research tool and developed the photographic representation of clinical symptoms.

Freud's first theory to explain hysterical symptoms was presented in "Studies on Hysteria" (1895), co-authored with his mentor the distinguished physician Josef Breuer, which was generally seen as the birth of psychoanalysis. The work was based on Breuer's treatment of Bertha Pappenheim, referred to in case studies by the pseudonym "Anna O.", treatment which Pappenheim herself had dubbed the "talking cure". Breuer wrote that many factors that could result in such symptoms, including various types of emotional trauma, and he also credited work by others such as Pierre Janet; while Freud contended that at the root of hysterical symptoms were repressed memories of distressing occurrences, almost always having direct or indirect sexual associations.

Around the same time Freud attempted to develop a neuro-physiological theory of unconscious mental mechanisms, which he soon gave up. It remained unpublished in his lifetime.

The first occurrence of the term "psychoanalysis" (written "psychoanalyse") was in Freud's essay "L'hérédité et l’étiologie des névroses" which was written and published in French in 1896.

In 1896 Freud also published his so-called seduction theory which proposed that the preconditions for hysterical symptoms are sexual excitations in infancy, and he claimed to have uncovered repressed memories of incidents of sexual abuse for all his current patients. However, by 1898 he had privately acknowledged to his friend and colleague Wilhelm Fliess that he no longer believed in his theory, though he did not state this publicly until 1906. Though in 1896 he had reported that his patients "had no feeling of remembering the [infantile sexual] scenes", and assured him "emphatically of their unbelief", in later accounts he claimed that they had told him that they had been sexually abused in infancy. This became the received historical account until challenged by several Freud scholars in the latter part of the 20th century who argued that he had imposed his preconceived notions on his patients. However, building on his claims that the patients reported infantile sexual abuse experiences, Freud subsequently contended that his clinical findings in the mid-1890s provided evidence of the occurrence of unconscious fantasies, supposedly to cover up memories of infantile masturbation. Only much later did he claim the same findings as evidence for Oedipal desires.

By 1899, Freud had theorised that dreams had symbolic significance, and generally were specific to the dreamer. Freud formulated his second psychological theory— which hypothesises that the unconscious has or is a "primary process" consisting of symbolic and condensed thoughts, and a "secondary process" of logical, conscious thoughts. This theory was published in his 1899 book, "The Interpretation of Dreams". Chapter VII was a re-working of the earlier "Project" and Freud outlined his "Topographic Theory". In this theory, which was mostly later supplanted by the Structural Theory, unacceptable sexual wishes were repressed into the "System Unconscious", unconscious due to society's condemnation of premarital sexual activity, and this repression created anxiety. This "topographic theory" is still popular in much of Europe, although it has fallen out of favour in much of North America. 

In 1905, Freud published "Three Essays on the Theory of Sexuality" in which he laid out his discovery of so-called psychosexual phases: oral (ages 0–2), anal (2–4), phallic-oedipal (today called 1st genital ) (3–6), latency (6-puberty), and mature genital (puberty-onward). His early formulation included the idea that because of societal restrictions, sexual wishes were repressed into an unconscious state, and that the energy of these unconscious wishes could be turned into anxiety or physical symptoms. Therefore, the early treatment techniques, including hypnotism and abreaction, were designed to make the unconscious conscious in order to relieve the pressure and the apparently resulting symptoms. This method would later on be left aside by Freud, giving free association a bigger role.

In "On Narcissism" (1915) Freud turned his attention to the subject of narcissism. Still using an energic system, Freud characterized the difference between energy directed at the self versus energy directed at others, called cathexis. By 1917, in "Mourning and Melancholia", he suggested that certain depressions were caused by turning guilt-ridden anger on the self. In 1919 in "A Child is Being Beaten" he began to address the problems of self-destructive behavior (moral masochism) and frank sexual masochism. Based on his experience with depressed and self-destructive patients, and pondering the carnage of World War I, Freud became dissatisfied with considering only oral and sexual motivations for behavior. By 1920, Freud addressed the power of identification (with the leader and with other members) in groups as a motivation for behavior ("Group Psychology and the Analysis of the Ego"). In that same year (1920) Freud suggested his "dual drive" theory of sexuality and aggression in "Beyond the Pleasure Principle", to try to begin to explain human destructiveness. Also, it was the first appearance of his "structural theory" consisting three new concepts id, ego, and superego.

Three years later, he summarised the ideas of id, ego, and superego in "The Ego and the Id". In the book, he revised the whole theory of mental functioning, now considering that repression was only one of many defense mechanisms, and that it occurred to reduce anxiety. Hence, Freud characterised repression as both a cause and a result of anxiety. In 1926, in "Inhibitions, Symptoms and Anxiety," Freud characterised how intrapsychic conflict among drive and superego (wishes and guilt) caused anxiety, and how that anxiety could lead to an inhibition of mental functions, such as intellect and speech. "Inhibitions, Symptoms and Anxiety" was written in response to Otto Rank, who, in 1924, published "Das Trauma der Geburt" (translated into English in 1929 as "The Trauma of Birth"), analysing how art, myth, religion, philosophy and therapy were illuminated by separation anxiety in the "phase before the development of the Oedipus complex". Freud's theories, however, characterized no such phase. According to Freud, the Oedipus complex, was at the centre of neurosis, and was the foundational source of all art, myth, religion, philosophy, therapy—indeed of all human culture and civilization. It was the first time that anyone in the inner circle had characterised something other than the Oedipus complex as contributing to intrapsychic development, a notion that was rejected by Freud and his followers at the time.

By 1936 the "Principle of Multiple Function" was clarified by Robert Waelder. He widened the formulation that psychological symptoms were caused by and relieved conflict simultaneously. Moreover, symptoms (such as phobias and compulsions) each represented elements of some drive wish (sexual and/or aggressive), superego, anxiety, reality, and defenses. Also in 1936, Anna Freud, Sigmund's daughter, published her seminal book, "The Ego and the Mechanisms of Defense", outlining numerous ways the mind could shut upsetting things out of consciousness.

When Hitler's power grew, the Freud family and many of their colleagues fled to London. Within a year Sigmund Freud died. In the United States, also following the death of Freud, a new group of psychoanalysts began to explore the function of the ego. Led by Heinz Hartmann, Kris, Rappaport and Lowenstein, the group built upon understandings of the synthetic function of the ego as a mediator in psychic functioning . Hartmann in particular distinguished between autonomous ego functions (such as memory and intellect which could be secondarily affected by conflict) and synthetic functions which were a result of compromise formation . These "Ego Psychologists" of the 1950s paved a way to focus analytic work by attending to the defenses (mediated by the ego) before exploring the deeper roots to the unconscious conflicts. In addition there was burgeoning interest in child psychoanalysis. Although criticized since its inception, psychoanalysis has been used as a research tool into childhood development, and is still used to treat certain mental disturbances. In the 1960s, Freud's early thoughts on the childhood development of female sexuality were challenged; this challenge led to the development of a variety of understandings of female sexual development , many of which modified the timing and normality of several of Freud's theories (which had been gleaned from the treatment of women with mental disturbances). Several researchers followed Karen Horney's studies of societal pressures that influence the development of women. The psychoanalyst Mark J. Blechner argued that dreams reveal how the mind works when it is not concerned with communicability.

In the first decade of the 21st century, there were approximately 35 training institutes for psychoanalysis in the United States accredited by the American Psychoanalytic Association (APsaA), which is a component organization of the International Psychoanalytical Association (IPA), and there are over 3000 graduated psychoanalysts practicing in the United States. The IPA accredits psychoanalytic training centers through such "component organisations" throughout the rest of the world, including countries such as Serbia, France, Germany, Austria, Italy, Switzerland, and many others, as well as about six institutes directly in the United States.

The predominant psychoanalytic theories can be organised into several theoretical schools. Although these theoretical schools differ, most of them emphasize the influence of unconscious elements on the conscious. There has also been considerable work done on consolidating elements of conflicting theories (cf. the work of Theodore Dorpat, B. Killingmo, and S. Akhtar). As in all fields of medicine, there are some persistent conflicts regarding specific causes of certain syndromes, and disputes regarding the ideal treatment techniques. In the 21st century, psychoanalytic ideas are embedded in Western culture, especially in fields such as childcare, education, literary criticism, cultural studies, mental health, and particularly psychotherapy. Though there is a mainstream of evolved analytic ideas, there are groups who follow the precepts of one or more of the later theoreticians. Psychoanalytic ideas also play roles in some types of literary analysis such as Archetypal literary criticism.

Topographic theory was named and first described by Sigmund Freud in "The Interpretation of Dreams" (1900). The theory hypothesizes that the mental apparatus can be divided into the systems Conscious, Preconscious, and Unconscious. These systems are not anatomical structures of the brain but, rather, mental processes. Although Freud retained this theory throughout his life he largely replaced it with the Structural theory. The Topographic theory remains as one of the meta-psychological points of view for describing how the mind functions in classical psychoanalytic theory.

Structural theory divides the psyche into the id, the ego, and the super-ego. The id is present at birth as the repository of basic instincts, which Freud called ""Triebe"" ("drives"): unorganized and unconscious, it operates merely on the 'pleasure principle', without realism or foresight. The ego develops slowly and gradually, being concerned with mediating between the urging of the id and the realities of the external world; it thus operates on the 'reality principle'. The super-ego is held to be the part of the ego in which self-observation, self-criticism and other reflective and judgmental faculties develop. The ego and the super-ego are both partly conscious and partly unconscious.

During the twentieth century, many different clinical and theoretical models of psychoanalysis emerged. 

Ego psychology was initially suggested by Freud in "Inhibitions, Symptoms and Anxiety" (1926). A major step forward was Anna Freud's work on defense mechanisms, first published in her book "The Ego and the Mechanisms of Defence" (1936).

The theory was refined by Hartmann, Loewenstein, and Kris in a series of papers and books from 1939 through the late 1960s. Leo Bellak was a later contributor. This series of constructs, paralleling some of the later developments of cognitive theory, includes the notions of autonomous ego functions: mental functions not dependent, at least in origin, on intrapsychic conflict. Such functions include: sensory perception, motor control, symbolic thought, logical thought, speech, abstraction, integration (synthesis), orientation, concentration, judgment about danger, reality testing, adaptive ability, executive decision-making, hygiene, and self-preservation. Freud noted that inhibition is one method that the mind may utilize to interfere with any of these functions in order to avoid painful emotions. Hartmann (1950s) pointed out that there may be delays or deficits in such functions.

Frosch (1964) described differences in those people who demonstrated damage to their relationship to reality, but who seemed able to test it. Deficits in the capacity to organize thought are sometimes referred to as blocking or loose associations (Bleuler), and are characteristic of schizophrenia. Deficits in abstraction ability and self-preservation also suggest psychosis in adults. Deficits in orientation and sensorium are often indicative of a medical illness affecting the brain (and therefore, autonomous ego functions). Deficits in certain ego functions are routinely found in severely sexually or physically abused children, where powerful effects generated throughout childhood seem to have eroded some functional development.

According to ego psychology, ego strengths, later described by Otto F. Kernberg (1975), include the capacities to control oral, sexual, and destructive impulses; to tolerate painful affects without falling apart; and to prevent the eruption into consciousness of bizarre symbolic fantasy. Synthetic functions, in contrast to autonomous functions, arise from the development of the ego and serve the purpose of managing conflict processes. Defenses are synthetic functions that protect the conscious mind from awareness of forbidden impulses and thoughts. One purpose of ego psychology has been to emphasize that some mental functions can be considered to be basic, rather than derivatives of wishes, affects, or defenses. However, autonomous ego functions can be secondarily affected because of unconscious conflict. For example, a patient may have an hysterical amnesia (memory being an autonomous function) because of intrapsychic conflict (wishing not to remember because it is too painful).

Taken together, the above theories present a group of metapsychological assumptions. Therefore, the inclusive group of the different classical theories provides a cross-sectional view of human mentation. There are six "points of view", five described by Freud and a sixth added by Hartmann. Unconscious processes can therefore be evaluated from each of these six points of view. The "points of view" are: 1. Topographic 2. Dynamic (the theory of conflict) 3. Economic (the theory of energy flow) 4. Structural 5. Genetic (propositions concerning origin and development of psychological functions) and 6. Adaptational (psychological phenomena as it relates to the external world).

Modern conflict theory, a variation of ego psychology, is a revised version of structural theory, most notably different by altering concepts related to where repressed thoughts were stored(Freud, 1923, 1926). Modern conflict theory addresses emotional symptoms and character traits as complex solutions to mental conflict. It dispenses with the concepts of a fixed id, ego and superego, and instead posits conscious and unconscious conflict among wishes (dependent, controlling, sexual, and aggressive), guilt and shame, emotions (especially anxiety and depressive affect), and defensive operations that shut off from consciousness some aspect of the others. Moreover, healthy functioning (adaptive) is also determined, to a great extent, by resolutions of conflict.

A major objective of modern conflict-theory psychoanalysis is to change the balance of conflict in a patient by making aspects of the less adaptive solutions (also called "compromise formations") conscious so that they can be rethought, and more adaptive solutions found. Current theoreticians following Brenner's many suggestions (see especially Brenner's 1982 book, "The Mind in Conflict") include Sandor Abend, MD (Abend, Porder, & Willick, (1983), "Borderline Patients: Clinical Perspectives"), Jacob Arlow (Arlow and Brenner (1964), "Psychoanalytic Concepts and the Structural Theory"), and Jerome Blackman (2003), "101 Defenses: How the Mind Shields Itself".

Object relations theory attempts to explain the ups and downs of human relationships through a study of how internal representations of the self and others are organized. The clinical symptoms that suggest object relations problems (typically developmental delays throughout life) include disturbances in an individual's capacity to feel warmth, empathy, trust, sense of security, identity stability, consistent emotional closeness, and stability in relationships with significant others. (It is not suggested that one should trust everyone, for example.) Concepts regarding internal representations (also sometimes termed, "introspects", "self and object representations", or "internalization of self and other") although often attributed to Melanie Klein, were actually first mentioned by Sigmund Freud in his early concepts of drive theory ("Three Essays on the Theory of Sexuality", 1905). Freud's 1917 paper "Mourning and Melancholia", for example, hypothesized that unresolved grief was caused by the survivor's internalized image of the deceased becoming fused with that of the survivor, and then the survivor shifting unacceptable anger toward the deceased onto the now complex self-image.

Vamik Volkan, in "Linking Objects and Linking Phenomena", expanded on Freud's thoughts on this, describing the syndromes of "Established pathological mourning" vs. "reactive depression" based on similar dynamics. Melanie Klein's hypotheses regarding internalization during the first year of life, leading to paranoid and depressive positions, were later challenged by René Spitz (e.g., "The First Year of Life", 1965), who divided the first year of life into a coenesthetic phase of the first six months, and then a diacritic phase for the second six months. Margaret Mahler (Mahler, Fine, and Bergman, "The Psychological Birth of the Human Infant", 1975) and her group, first in New York, then in Philadelphia, described distinct phases and subphases of child development leading to "separation-individuation" during the first three years of life, stressing the importance of constancy of parental figures, in the face of the child's destructive aggression, to the child's internalizations, stability of affect management, and ability to develop healthy autonomy.

John Frosch, Otto Kernberg, Salman Akhtar and Sheldon Bach have developed the theory of self and object constancy as it affects adult psychiatric problems such as psychosis and borderline states. Peter Blos described (in a book called "On Adolescence", 1960) how similar separation-individuation struggles occur during adolescence, of course with a different outcome from the first three years of life: the teen usually, eventually, leaves the parents' house (this varies with the culture). During adolescence, Erik Erikson (1950–1960s) described the "identity crisis", that involves identity-diffusion anxiety. In order for an adult to be able to experience "Warm-ETHICS" (warmth, empathy, trust, holding environment (Winnicott), identity, closeness, and stability) in relationships (see Blackman, "101 Defenses: How the Mind Shields Itself", 2001), the teenager must resolve the problems with identity and redevelop self and object constancy.

Self psychology emphasizes the development of a stable and integrated sense of self through empathic contacts with other humans, primary significant others conceived of as "selfobjects". Selfobjects meet the developing self's needs for mirroring, idealization, and twinship, and thereby strengthen the developing self. The process of treatment proceeds through "transmuting internalizations" in which the patient gradually internalizes the selfobject functions provided by the therapist.
Self psychology was proposed originally by Heinz Kohut, and has been further developed by Arnold Goldberg, Frank Lachmann, Paul and Anna Ornstein, Marian Tolpin, and others.

Lacanian psychoanalysis, which integrates psychoanalysis with structural linguistics and Hegelian philosophy, is especially popular in France and parts of Latin America. Lacanian psychoanalysis is a departure from the traditional British and American psychoanalysis, which is predominantly Ego psychology. Jacques Lacan frequently used the phrase "retourner à Freud" ("return to Freud") in his seminars and writings, as he claimed that his theories were an extension of Freud's own, contrary to those of Anna Freud, the Ego Psychology, object relations and "self" theories and also claims the necessity of reading Freud's complete works, not only a part of them. Lacan's concepts concern the "mirror stage", the "Real", the "Imaginary", and the "Symbolic", and the claim that "the unconscious is structured as a language".

Though a major influence on psychoanalysis in France and parts of Latin America, Lacan and his ideas have taken longer to be translated into English and he has thus had a lesser impact on psychoanalysis and psychotherapy in the English-speaking world. In the United Kingdom and the United States, his ideas are most widely used to analyze texts in literary theory. Due to his increasingly critical stance towards the deviation from Freud's thought, often singling out particular texts and readings from his colleagues, Lacan was excluded from acting as a training analyst in the IPA, thus leading him to create his own school in order to maintain an institutional structure for the many candidates who desired to continue their analysis with him.

Interpersonal psychoanalysis accents the nuances of interpersonal interactions, particularly how individuals protect themselves from anxiety by establishing collusive interactions with others, and the relevance of actual experiences with other persons developmentally (e.g. family and peers) as well as in the present. This is contrasted with the primacy of intrapsychic forces, as in classical psychoanalysis. Interpersonal theory was first introduced by Harry Stack Sullivan, MD, and developed further by Frieda Fromm-Reichmann, Clara Thompson, Erich Fromm, and others who contributed to the founding of the William Alanson White Institute and Interpersonal Psychoanalysis in general.

Some psychoanalysts have been labeled "culturalist", because of the prominence they attributed culture in the genesis of behavior. Among others, Erich Fromm, Karen Horney, Harry Stack Sullivan, have been called culturalist psychoanalysts. They were famously in conflict with orthodox psychoanalysts.

Feminist theories of psychoanalysis emerged towards the second half of the 20th century, in an effort to articulate the feminine, the maternal and sexual difference and development from the point of view of female subjects. For Freud, male is subject and female is object. For Freud, Winnicott and the object relations theories, the mother is structured as the object of the infant's rejection (Freud) and destruction (Winnicott). For Lacan, the "woman" can either accept the phallic symbolic as an object or incarnate a lack in the symbolic dimension that informs the structure of the human subject. Feminist psychoanalysis is mainly post-Freudian and post-Lacanian with theorists like Toril Moi, Joan Copjec, Juliet Mitchell, Teresa Brennan and Griselda Pollock that rethinks Art and Mythology following French feminist psychoanalysis, the gaze and sexual difference in, of and from the feminine. French theorists like Luce Irigaray challenge phallogocentrism. Bracha Ettinger offers a "matrixial" subject's dimension that brings into account the prenatal stage (matrixial connectivity) and suggests a feminine-maternal Eros, matrixial gaze and Primal mother-phantasies. Jessica Benjamin addresses the question of the feminine and love. Feminist psychoanalysis informs and includes gender, queer and post-feminist theories.

The "adaptive paradigm of psychotherapy" develops out of the work of Robert Langs. The adaptive paradigm interprets psychic conflict primarily in terms of conscious and unconscious adaptation to reality. Langs’ recent work in some measure returns to the earlier Freud, in that Langs prefers a modified version of the topographic model of the mind (conscious, preconscious, and unconscious) over the structural model (id, ego, and super-ego), including the former’s emphasis on trauma (though Langs looks to death-related traumas rather than sexual traumas). At the same time, Langs’ model of the mind differs from Freud’s in that it understands the mind in terms of evolutionary biological principles.

Relational psychoanalysis combines interpersonal psychoanalysis with object-relations theory and with inter-subjective theory as critical for mental health. It was introduced by Stephen Mitchell. Relational psychoanalysis stresses how the individual's personality is shaped by both real and imagined relationships with others, and how these relationship patterns are re-enacted in the interactions between analyst and patient. In New York, key proponents of relational psychoanalysis include Lew Aron, Jessica Benjamin, and Adrienne Harris. Fonagy and Target, in London, have propounded their view of the necessity of helping certain detached, isolated patients, develop the capacity for "mentalization" associated with thinking about relationships and themselves. Arietta Slade, Susan Coates, and Daniel Schechter in New York have additionally contributed to the application of relational psychoanalysis to treatment of the adult patient-as-parent, the clinical study of mentalization in parent-infant relationships, and the intergenerational transmission of attachment and trauma.

The term interpersonal-relational psychoanalysis is often used as a professional identification. Psychoanalysts under this broader umbrella debate about what precisely are the differences between the two schools, without any current clear consensus.

The term "intersubjectivity" was introduced in psychoanalysis by George E. Atwood and Robert Stolorow (1984). Intersubjective approaches emphasize how both personality development and the therapeutic process are influenced by the interrelationship between the patient's subjective perspective and that of others. The authors of the interpersonal-relational and intersubjective approaches: Otto Rank, Heinz Kohut, Stephen A. Mitchell, Jessica Benjamin, Bernard Brandchaft, J. Fosshage, Donna M.Orange, Arnold "Arnie" Mindell, Thomas Ogden, Owen Renik, Irwin Z. Hoffman, Harold Searles, Colwyn Trevarthen, Edgar A. Levenson, Jay Greenberg, Edward R. Ritvo, Beatrice Beebe, Frank M. Lachmann, Herbert Rosenfeld and Daniel Stern.

"Modern psychoanalysis" is a term coined by Hyman Spotnitz and his colleagues to describe a body of theoretical and clinical approaches that aim to extend Freud's theories so as to make them applicable to the full spectrum of emotional disorders and broaden the potential for treatment to pathologies thought to be untreatable by classical methods . Interventions based on this approach are primarily intended to provide an emotional-maturational communication to the patient, rather than to promote intellectual insight. These interventions, beyond insight directed aims, are used to resolve resistances that are presented in the clinical setting. This school of psychoanalysis has fostered training opportunities for students in the United States and from countries worldwide. Its journal Modern Psychoanalysis has been published since 1976.

The various psychoses involve deficits in the autonomous ego functions (see above) of integration (organization) of thought, in abstraction ability, in relationship to reality and in reality testing. In depressions with psychotic features, the self-preservation function may also be damaged (sometimes by overwhelming depressive affect). Because of the integrative deficits (often causing what general psychiatrists call "loose associations", "blocking", "flight of ideas", "verbigeration", and "thought withdrawal"), the development of self and object representations is also impaired. Clinically, therefore, psychotic individuals manifest limitations in warmth, empathy, trust, identity, closeness and/or stability in relationships (due to problems with self-object fusion anxiety) as well.

In patients whose autonomous ego functions are more intact, but who still show problems with object relations, the diagnosis often falls into the category known as "borderline". Borderline patients also show deficits, often in controlling impulses, affects, or fantasies – but their ability to test reality remains more or less intact. Adults who do not experience guilt and shame, and who indulge in criminal behavior, are usually diagnosed as psychopaths, or, using DSM-IV-TR, antisocial personality disorder.

Panic, phobias, conversions, obsessions, compulsions and depressions (analysts call these "neurotic symptoms") are not usually caused by deficits in functions. Instead, they are caused by intrapsychic conflicts. The conflicts are generally among sexual and hostile-aggressive wishes, guilt and shame, and reality factors. The conflicts may be conscious or unconscious, but create anxiety, depressive affect, and anger. Finally, the various elements are managed by defensive operations – essentially shut-off brain mechanisms that make people unaware of that element of conflict. "Repression" is the term given to the mechanism that shuts thoughts out of consciousness. "Isolation of affect" is the term used for the mechanism that shuts sensations out of consciousness. Neurotic symptoms may occur with or without deficits in ego functions, object relations, and ego strengths. Therefore, it is not uncommon to encounter obsessive-compulsive schizophrenics, panic patients who also suffer with borderline personality disorder, etc.

This section above is partial to ego psychoanalytic theory "autonomous ego functions". As the "autonomous ego functions" theory is only a theory, it may yet be proven incorrect.

Freudian theories hold that adult problems can be traced to unresolved conflicts from certain phases of childhood and adolescence, caused by fantasy, stemming from their own drives. Freud, based on the data gathered from his patients early in his career, suspected that neurotic disturbances occurred when children were sexually abused in childhood (the so-called "seduction theory"). Later, Freud came to believe that, although child abuse occurs, neurotic symptoms were not associated with this. He believed that neurotic people often had unconscious conflicts that involved incestuous fantasies deriving from different stages of development. He found the stage from about three to six years of age (preschool years, today called the "first genital stage") to be filled with fantasies of having romantic relationships with both parents. Arguments were quickly generated in early 20th-century Vienna about whether adult seduction of children, i.e. child sexual abuse, was the basis of neurotic illness. There still is no complete agreement, although nowadays professionals recognize the negative effects of child sexual abuse on mental health.

Many psychoanalysts who work with children have studied the actual effects of child abuse, which include ego and object relations deficits and severe neurotic conflicts. Much research has been done on these types of trauma in childhood, and the adult sequelae of those. In studying the childhood factors that start neurotic symptom development, Freud found a constellation of factors that, for literary reasons, he termed the Oedipus complex (based on the play by Sophocles, "Oedipus Rex", where the protagonist unwittingly kills his father Laius and marries his mother Jocasta). The validity of the Oedipus complex is now widely disputed and rejected. The shorthand term, "oedipal" — later explicated by Joseph J. Sandler in "On the Concept Superego" (1960) and modified by Charles Brenner in "The Mind in Conflict" (1982) — refers to the powerful attachments that children make to their parents in the preschool years. These attachments involve fantasies of sexual relationships with either (or both) parent, and, therefore, competitive fantasies toward either (or both) parents. Humberto Nagera (1975) has been particularly helpful in clarifying many of the complexities of the child through these years.

"Positive" and "negative" oedipal conflicts have been attached to the heterosexual and homosexual aspects, respectively. Both seem to occur in development of most children. Eventually, the developing child's concessions to reality (that they will neither marry one parent nor eliminate the other) lead to identifications with parental values. These identifications generally create a new set of mental operations regarding values and guilt, subsumed under the term "superego". Besides superego development, children "resolve" their preschool oedipal conflicts through channeling wishes into something their parents approve of ("sublimation") and the development, during the school-age years ("latency") of age-appropriate obsessive-compulsive defensive maneuvers (rules, repetitive games).

Using the various analytic and psychological techniques to assess mental problems, some believe that there are particular constellations of problems that are especially suited for analytic treatment (see below) whereas other problems might respond better to medicines and other interpersonal interventions. To be treated with psychoanalysis, whatever the presenting problem, the person requesting help must demonstrate a desire to start an analysis. The person wishing to start an analysis must have some capacity for speech and communication. As well, they need to be able to have or develop trust and insight within the psychoanalytic session. Potential patients must undergo a preliminary stage of treatment to assess their amenability to psychoanalysis at that time, and also to enable the analyst to form a working psychological model, which the analyst will use to direct the treatment. Psychoanalysts mainly work with neurosis and hysteria in particular; however, adapted forms of psychoanalysis are used in working with schizophrenia and other forms of psychosis or mental disorder. Finally, if a prospective patient is severely suicidal a longer preliminary stage may be employed, sometimes with sessions which have a twenty-minute break in the middle. There are numerous modifications in technique under the heading of psychoanalysis due to the individualistic nature of personality in both analyst and patient.

The most common problems treatable with psychoanalysis include: phobias, conversions, compulsions, obsessions, anxiety attacks, depressions, sexual dysfunctions, a wide variety of relationship problems (such as dating and marital strife), and a wide variety of character problems (for example, painful shyness, meanness, obnoxiousness, workaholism, hyperseductiveness, hyperemotionality, hyperfastidiousness). The fact that many of such patients also demonstrate deficits above makes diagnosis and treatment selection difficult.

Analytical organizations such as the IPA, APsaA and the European Federation for Psychoanalytic Psychotherapy have established procedures and models for the indication and practice of psychoanalytical therapy for trainees in analysis. The match between the analyst and the patient can be viewed as another contributing factor for the indication and contraindication for psychoanalytic treatment. The analyst decides whether the patient is suitable for psychoanalysis. This decision made by the analyst, besides made on the usual indications and pathology, is also based to a certain degree by the "fit" between analyst and patient. A person's suitability for analysis at any particular time is based on their desire to know something about where their illness has come from. Someone who is not suitable for analysis expresses no desire to know more about the root causes of their illness.

An evaluation may include one or more other analysts' independent opinions and will include discussion of the patient's financial situation and insurances.

The basic method of psychoanalysis is interpretation of the patient's unconscious conflicts that are interfering with current-day functioning – conflicts that are causing painful symptoms such as phobias, anxiety, depression, and compulsions. Strachey (1936) stressed that figuring out ways the patient distorted perceptions about the analyst led to understanding what may have been forgotten (also see Freud's paper "Repeating, Remembering, and Working Through"). In particular, unconscious hostile feelings toward the analyst could be found in symbolic, negative reactions to what Robert Langs later called the "frame" of the therapy – the setup that included times of the sessions, payment of fees, and necessity of talking. In patients who made mistakes, forgot, or showed other peculiarities regarding time, fees, and talking, the analyst can usually find various unconscious "resistances" to the flow of thoughts (sometimes called free association).

When the patient reclines on a couch with the analyst out of view, the patient tends to remember more experiences, more resistance and transference, and is able to reorganize thoughts after the development of insight – through the interpretive work of the analyst. Although fantasy life can be understood through the examination of dreams, masturbation fantasies (cf. Marcus, I. and Francis, J. (1975), "Masturbation from Infancy to Senescence") are also important. The analyst is interested in how the patient reacts to and avoids such fantasies (cf. Paul Gray (1994), "The Ego and the Analysis of Defense"). Various memories of early life are generally distorted – Freud called them "screen memories" – and in any case, very early experiences (before age two) – cannot be remembered (See the child studies of Eleanor Galenson on "evocative memory").

There is what is known among psychoanalysts as "classical technique", although Freud throughout his writings deviated from this considerably, depending on the problems of any given patient. Classical technique was summarized by Allan Compton, MD, as comprising instructions (telling the patient to try to say what's on their mind, including interferences); exploration (asking questions); and clarification (rephrasing and summarizing what the patient has been describing). As well, the analyst can also use confrontation to bringing an aspect of functioning, usually a defense, to the patient's attention. The analyst then uses a variety of interpretation methods, such as dynamic interpretation (explaining how being too nice guards against guilt, e.g. – defense vs. affect); genetic interpretation (explaining how a past event is influencing the present); resistance interpretation (showing the patient how they are avoiding their problems); transference interpretation (showing the patient ways old conflicts arise in current relationships, including that with the analyst); or dream interpretation (obtaining the patient's thoughts about their dreams and connecting this with their current problems). Analysts can also use reconstruction to estimate what may have happened in the past that created some current issue.

These techniques are primarily based on conflict theory (see above). As object relations theory evolved, supplemented by the work of John Bowlby and Mary Ainsworth, techniques with patients who had more severe problems with basic trust (Erikson, 1950) and a history of maternal deprivation (see the works of Augusta Alpert) led to new techniques with adults. These have sometimes been called interpersonal, intersubjective (cf. Stolorow), relational, or corrective object relations techniques. These techniques include expressing an empathic attunement to the patient or warmth; exposing a bit of the analyst's personal life or attitudes to the patient; allowing the patient autonomy in the form of disagreement with the analyst (cf. I.H. Paul, "Letters to Simon"); and explaining the motivations of others which the patient misperceives. Ego psychological concepts of deficit in functioning led to refinements in supportive therapy. These techniques are particularly applicable to psychotic and near-psychotic (cf., Eric Marcus, "Psychosis and Near-psychosis") patients. These supportive therapy techniques include discussions of reality; encouragement to stay alive (including hospitalization); psychotropic medicines to relieve overwhelming depressive affect or overwhelming fantasies (hallucinations and delusions); and advice about the meanings of things (to counter abstraction failures).

The notion of the "silent analyst" has been criticized. Actually, the analyst listens using Arlow's approach as set out in "The Genesis of Interpretation", using active intervention to interpret resistances, defenses creating pathology, and fantasies. Silence is not a technique of psychoanalysis (also see the studies and opinion papers of Owen Renik, MD). "Analytic neutrality" is a concept that does not mean the analyst is silent. It refers to the analyst's position of not taking sides in the internal struggles of the patient. For example, if a patient feels guilty, the analyst might explore what the patient has been doing or thinking that causes the guilt, but not reassure the patient not to feel guilty. The analyst might also explore the identifications with parents and others that led to the guilt.

Interpersonal–relational psychoanalysts emphasize the notion that it is impossible to be neutral. Sullivan introduced the term "participant-observer" to indicate the analyst inevitably interacts with the analysand, and suggested the detailed inquiry as an alternative to interpretation. The detailed inquiry involves noting where the analysand is leaving out important elements of an account and noting when the story is obfuscated, and asking careful questions to open up the dialogue.

Although single-client sessions remain the norm, psychoanalytic theory has been used to develop other types of psychological treatment. Psychoanalytic group therapy was pioneered by Trigant Burrow, Joseph Pratt, Paul F. Schilder, Samuel R. Slavson, Harry Stack Sullivan, and Wolfe. Child-centered counseling for parents was instituted early in analytic history by Freud, and was later further developed by Irwin Marcus, Edith Schulhofer, and Gilbert Kliman. Psychoanalytically based couples therapy has been promulgated and explicated by Fred Sander, MD. Techniques and tools developed in the first decade of the 21st century have made psychoanalysis available to patients who were not treatable by earlier techniques. This meant that the analytic situation was modified so that it would be more suitable and more likely to be helpful for these patients. M.N. Eagle (2007) believes that psychoanalysis cannot be a self-contained discipline but instead must be open to influence from and integration with findings and theory from other disciplines.

Psychoanalytic constructs have been adapted for use with children with treatments such as play therapy, art therapy, and storytelling. Throughout her career, from the 1920s through the 1970s, Anna Freud adapted psychoanalysis for children through play. This is still used today for children, especially those who are preadolescent (see Leon Hoffman, New York Psychoanalytic Institute Center for Children). Using toys and games, children are able to demonstrate, symbolically, their fears, fantasies, and defenses; although not identical, this technique, in children, is analogous to the aim of free association in adults. Psychoanalytic play therapy allows the child and analyst to understand children's conflicts, particularly defenses such as disobedience and withdrawal, that have been guarding against various unpleasant feelings and hostile wishes. In art therapy, the counselor may have a child draw a portrait and then tell a story about the portrait. The counselor watches for recurring themes—regardless of whether it is with art or toys.

Psychoanalysis can be adapted to different cultures, as long as the therapist or counselor understands the client's culture. For example, Tori and Blimes found that defense mechanisms were valid in a normative sample of 2,624 Thais. The use of certain defense mechanisms was related to cultural values. For example, Thais value calmness and collectiveness (because of Buddhist beliefs), so they were low on regressive emotionality. Psychoanalysis also applies because Freud used techniques that allowed him to get the subjective perceptions of his patients. He takes an objective approach by not facing his clients during his talk therapy sessions. He met with his patients wherever they were, such as when he used free association — where clients would say whatever came to mind without self-censorship. His treatments had little to no structure for most cultures, especially Asian cultures. Therefore, it is more likely that Freudian constructs will be used in structured therapy (Thompson, et al., 2004). In addition, Corey postulates that it will be necessary for a therapist to help clients develop a cultural identity as well as an ego identity.

The cost to the patient of psychoanalytic treatment ranges widely from place to place and between practitioners. Low-fee analysis is often available in a psychoanalytic training clinic and graduate schools. Otherwise, the fee set by each analyst varies with the analyst's training and experience. Since, in most locations in the United States, unlike in Ontario and Germany, classical analysis (which usually requires sessions three to five times per week) is not covered by health insurance, many analysts may negotiate their fees with patients whom they feel they can help, but who have financial difficulties. The modifications of analysis, which include psychodynamic therapy, brief therapies, and certain types of group therapy (cf. Slavson, S. R., "A Textbook in Analytic Group Therapy"), are carried out on a less frequent basis – usually once, twice, or three times a week – and usually the patient sits facing the therapist. As a result of the defense mechanisms and the lack of access to the unfathomable elements of the unconscious, psychoanalysis can be an expansive process that involves 2 to 5 sessions per week for several years. This type of therapy relies on the belief that reducing the symptoms will not actually help with the root causes or irrational drives. The analyst typically is a 'blank screen', disclosing very little about themselves in order that the client can use the space in the relationship to work on their unconscious without interference from outside.

The psychoanalyst uses various methods to help the patient to become more self-aware and to develop insights into their behavior and into the meanings of symptoms. First and foremost, the psychoanalyst attempts to develop a confidential atmosphere in which the patient can feel safe reporting his feelings, thoughts and fantasies. Analysands (as people in analysis are called) are asked to report whatever comes to mind without fear of reprisal. Freud called this the "fundamental rule". Analysands are asked to talk about their lives, including their early life, current life and hopes and aspirations for the future. They are encouraged to report their fantasies, "flash thoughts" and dreams. In fact, Freud believed that dreams were, "the royal road to the unconscious"; he devoted an entire volume to the interpretation of dreams. Also, psychoanalysts encourage their patients to recline on a couch. Typically, the psychoanalyst sits, out of sight, behind the patient.

The psychoanalyst's task, in collaboration with the analysand, is to help deepen the analysand's understanding of those factors, outside of his awareness, that drive his behaviors. In the safe environment of the psychoanalytic setting, the analysand becomes attached to the analyst and pretty soon he begins to experience the same conflicts with his analyst that he experiences with key figures in his life such as his parents, his boss, his significant other, etc. It is the psychoanalyst's role to point out these conflicts and to interpret them. The transferring of these internal conflicts onto the analyst is called "transference".

Many studies have also been done on briefer "dynamic" treatments; these are more expedient to measure, and shed light on the therapeutic process to some extent. Brief Relational Therapy (BRT), Brief Psychodynamic Therapy (BPT), and Time-Limited Dynamic Therapy (TLDP) limit treatment to 20–30 sessions. On average, classical analysis may last 5.7 years, but for phobias and depressions uncomplicated by ego deficits or object relations deficits, analysis may run for a shorter period of time. Longer analyses are indicated for those with more serious disturbances in object relations, more symptoms, and more ingrained character pathology.

Psychoanalytic training in the United States involves a personal psychoanalysis for the trainee, approximately 600 hours of class instruction, with a standard curriculum, over a four or five-year period.

Typically, this psychoanalysis must be conducted by a Supervising and Training Analyst. Most institutes (but not all) within the American Psychoanalytic Association, require that Supervising and Training Analysts become certified by the American Board of Psychoanalysts. Certification entails a blind review in which the psychoanalysts work is vetted by psychoanalysts outside of their local community. After earning certification, these psychoanalysts undergo another hurdle in which they are specially vetted by senior members of their own institute. Supervising and Training analysts are held to the highest clinical and ethical standards. Moreover, they are required to have extensive experience conducting psychoanalyses.

Similarly, class instruction for psychoanalytic candidates is rigorous. Typically classes meet several hours a week, or for a full day or two every other weekend during the academic year; this varies with the institute.

Candidates generally have an hour of supervision each week, with a Supervising and Training Analyst, on each psychoanalytic case. The minimum number of cases varies between institutes, often two to four cases. Male and female cases are required. Supervision must go on for at least a few years on one or more cases. Supervision is done in the supervisor's office, where the trainee presents material from the psychoanalytic work that week. In supervision, the patient's unconscious conflicts are explored, also, transference-countertransference constellations are examined. Also, clinical technique is taught.

Many psychoanalytic training centers in the United States have been accredited by special committees of the APsaA or the IPA. Because of theoretical differences, there are independent institutes, usually founded by psychologists, who until 1987 were not permitted access to psychoanalytic training institutes of the APsaA. Currently there are between 75 and 100 independent institutes in the United States. As well, other institutes are affiliated to other organizations such as the American Academy of Psychoanalysis and Dynamic Psychiatry, and the National Association for the Advancement of Psychoanalysis. At most psychoanalytic institutes in the United States, qualifications for entry include a terminal degree in a mental health field, such as Ph.D., Psy.D., M.S.W., or M.D. A few institutes restrict applicants to those already holding an M.D. or Ph.D., and most institutes in Southern California confer a Ph.D. or Psy.D. in psychoanalysis upon graduation, which involves completion of the necessary requirements for the state boards that confer that doctoral degree. The first training institute in America to educate non-medical psychoanalysts was The National Psychological Association for Psychoanalysis (1978) in New York City. It was founded by the analyst Theodor Reik. The Contemporary Freudian (originally the New York Freudian Society) an offshoot of the National Psychological Association has a branch in Washington, DC. It is a component society/institute or the IPA.

Some psychoanalytic training has been set up as a post-doctoral fellowship in university settings, such as at Duke University, Yale University, New York University, Adelphi University and Columbia University. Other psychoanalytic institutes may not be directly associated with universities, but the faculty at those institutes usually hold contemporaneous faculty positions with psychology Ph.D. programs and/or with medical school psychiatry residency programs.

The IPA is the world's primary accrediting and regulatory body for psychoanalysis. Their mission is to assure the continued vigor and development of psychoanalysis for the benefit of psychoanalytic patients. It works in partnership with its 70 constituent organizations in 33 countries to support 11,500 members. In the US, there are 77 psychoanalytical organizations, institutes associations in the United States, which are spread across the states of America. APSaA has 38 affiliated societies which have 10 or more active members who practice in a given geographical area. The aims of APSaA and other psychoanalytical organizations are: provide ongoing educational opportunities for its members, stimulate the development and research of psychoanalysis, provide training and organize conferences. There are eight affiliated study groups in the United States. A study group is the first level of integration of a psychoanalytical body within the IPA, followed by a provisional society and finally a member society.

The Division of Psychoanalysis (39) of the American Psychological Association (APA) was established in the early 1980s by several psychologists. Until the establishment of the Division of Psychoanalysis, psychologists who had trained in independent institutes had no national organization. The Division of Psychoanalysis now has approximately 4,000 members and approximately 30 local chapters in the United States. The Division of Psychoanalysis holds two annual meetings or conferences and offers continuing education in theory, research and clinical technique, as do their affiliated local chapters. The European Psychoanalytical Federation (EPF) is the organization which consolidates all European psychoanalytic societies. This organization is affiliated with the IPA. In 2002 there were approximately 3,900 individual members in 22 countries, speaking 18 different languages. There are also 25 psychoanalytic societies.

The American Association of Psychoanalysis in Clinical Social Work (AAPCSW) was established by Crayton Rowe in 1980 as a division of the Federation of Clinical Societies of Social Work and became an independent entity in 1990. Until 2007 it was known as the National Membership Committee on Psychoanalysis. The organization was founded because although social workers represented the larger number of people who were training to be psychoanalysts, they were underrepresented as supervisors and teachers at the institutes they attended. AAPCSW now has over 1000 members and has over 20 chapters. It holds a bi-annual national conference and numerous annual local conferences.

Experiences of psychoanalysts and psychoanalytic psychotherapists and research into infant and child development have led to new insights. Theories have been further developed and the results of empirical research are now more integrated in the psychoanalytic theory.

The London Psychoanalytical Society was founded by Ernest Jones on 30 October 1913. With the expansion of psychoanalysis in the United Kingdom the Society was renamed the British Psychoanalytical Society in 1919. Soon after, the Institute of Psychoanalysis was established to administer the Society’s activities. These include: the training of psychoanalysts, the development of the theory and practice of psychoanalysis, the provision of treatment through The London Clinic of Psychoanalysis, the publication of books in The New Library of Psychoanalysis and Psychoanalytic Ideas. The Institute of Psychoanalysis also publishes "The International Journal of Psychoanalysis", maintains a library, furthers research, and holds public lectures. The society has a Code of Ethics and an Ethical Committee. The society, the institute and the clinic are all located at Byron House.

The society is a component of the IPA, a body with members on all five continents that safeguards professional and ethical practice. The society is a member of the British Psychoanalytic Council (BPC); the BPC publishes a register of British psychoanalysts and psychoanalytical psychotherapists. All members of the British Psychoanalytical Society are required to undertake continuing professional development.

Members of the Society have included Michael Balint, Wilfred Bion, John Bowlby, Anna Freud, Melanie Klein, Joseph J. Sandler, and Donald Winnicott.

The Institute of Psychoanalysis is the foremost publisher of psychoanalytic literature. The 24-volume "Standard Edition of the Complete Psychological Works of Sigmund Freud" was conceived, translated, and produced under the direction of the British Psychoanalytical Society. The Society, in conjunction with Random House, will soon publish a new, revised and expanded Standard Edition. With the New Library of Psychoanalysis the Institute continues to publish the books of leading theorists and practitioners. "The International Journal of Psychoanalysis" is published by the Institute of Psychoanalysis. Now in its 84th year, it has one of the largest circulations of any psychoanalytic journal.

Over a hundred years of case reports and studies in the journal "Modern Psychoanalysis", the "Psychoanalytic Quarterly", the "International Journal of Psychoanalysis" and the "Journal of the American Psychoanalytic Association" have analyzed the efficacy of analysis in cases of neurosis and character or problems. Psychoanalysis modified by object relations techniques has been shown to be effective in many cases of ingrained problems of intimacy and relationship (cf. the many books of Otto Kernberg). As a therapeutic treatment, psychoanalytic techniques may be useful in a one-session consultation. Psychoanalytic treatment, in other situations, may run from about a year to many years, depending on the severity and complexity of the pathology.

Psychoanalytic theory has, from its inception, been the subject of criticism and controversy. Freud remarked on this early in his career, when other physicians in Vienna ostracized him for his findings that hysterical conversion symptoms were not limited to women. Challenges to analytic theory began with Otto Rank and Alfred Adler (turn of the 20th century), continued with behaviorists (e.g. Wolpe) into the 1940s and '50s, and have persisted (e.g. Miller). Criticisms come from those who object to the notion that there are mechanisms, thoughts or feelings in the mind that could be unconscious. Criticisms also have been leveled against the idea of "infantile sexuality" (the recognition that children between ages two and six imagine things about procreation). Criticisms of theory have led to variations in analytic theories, such as the work of Ronald Fairbairn, Michael Balint, and John Bowlby. In the past 30 years or so, the criticisms have centered on the issue of empirical verification, in spite of many empirical, prospective research studies that have been empirically validated (e.g., See the studies of Barbara Milrod, at Cornell University Medical School, et al.). Research supports some of Freud's ideas, such as repression.

Psychoanalysis has been used as a research tool into childhood development (cf. the journal "The Psychoanalytic Study of the Child"), and has developed into a flexible, effective treatment for certain mental disturbances. In the 1960s, Freud's early (1905) thoughts on the childhood development of female sexuality were challenged; this challenge led to major research in the 1970s and 80s, and then to a reformulation of female sexual development that corrected some of Freud's concepts. Also see the various works of Eleanor Galenson, Nancy Chodorow, Karen Horney, Françoise Dolto, Melanie Klein, Selma Fraiberg, and others. Most recently, psychoanalytic researchers who have integrated attachment theory into their work, including Alicia Lieberman, Susan Coates, and Daniel Schechter have explored the role of parental traumatization in the development of young children's mental representations of self and others.

There are different forms of psychoanalysis and psychotherapies in which psychoanalytic thinking is practiced. Besides classical psychoanalysis there is for example psychoanalytic psychotherapy, a therapeutic approach which widens "the accessibility of psychoanalytic theory and clinical practices that had evolved over 100 plus years to a larger number of individuals." Other examples of well known therapies which also use insights of psychoanalysis are mentalization-based treatment (MBT), and transference focused psychotherapy (TFP). There is also a continuing influence of psychoanalytic thinking in mental health care.

The effectiveness of strict psychoanalysis is difficult to gauge; therapy as Freud intended it relies too much on the interpretation of the therapist which cannot be proven. The effectiveness of more modern, developed techniques can be gauged. Meta-analyses in 2012 and 2013 come to the conclusion that there is support or evidence for the efficacy of psychoanalytic therapy, thus further research is needed. Other meta-analyses published in the recent years showed psychoanalysis and psychodynamic therapy to be effective, with outcomes comparable or greater than other kinds of psychotherapy or antidepressant drugs, but these arguments have also been subjected to various criticisms.

In 2011, the American Psychological Association made 103 comparisons between psychodynamic treatment and a non-dynamic competitor and found that 6 were superior, 5 were inferior, 28 had no difference and 63 were adequate. The study found that this could be used as a basis "to make psychodynamic psychotherapy an 'empirically validated' treatment."

Meta-analyses of Short Term Psychodynamic Psychotherapy (STPP) have found effect sizes ranging from .34–.71 compared to no treatment and was found to be slightly better than other therapies in follow up. Other reviews have found an effect size of .78–.91 for somatic disorders compared to no treatment and .69 for treating depression. A 2012 meta-analysis by the "Harvard Review of Psychiatry" of Intensive Short-Term Dynamic Psychotherapy (ISTDP) found effect sizes ranging from .84 for interpersonal problems to 1.51 for depression. Overall ISTDP had an effect size of 1.18 compared to no treatment.

A system review of Long Term Psychodynamic Psychotherapy in 2009 found an overall effect size of .33. Others have found effect sizes of .44–.68.

According to a 2004 French review conducted by INSERM, psychoanalysis was presumed or proven effective at treating panic disorder, post-traumatic stress and personality disorders.

The world's largest randomized controlled trial on therapy with anorexia nervosa outpatients, the ANTOP-Study, published 2013 in "The Lancet", found evidence that modified psychodynamic therapy is effective in increasing body mass index after a 10-month treatment and that the effect is persistent until at least a year after concluding the treatment. Relative to other treatments assigned, it was found to be as effective in increasing body mass index as cognitive behavioral therapy and as a standard treatment protocol (which consisted of referral to a list of psychotherapists with experience in treating eating-disorders in addition to close monitoring and treatment by a family doctor). Furthermore, considering the outcome to be the recovery rate one year after the treatment, measured by the proportion of patients who no longer met the diagnostic criteria for anorexia nervosa, modified psychodynamic therapy was found to be more effective than the standard treatment protocol and as effective as cognitive behavioral therapy.

A 2001 systematic review of the medical literature by the Cochrane Collaboration concluded that no data exist demonstrating that psychodynamic psychotherapy is effective in treating schizophrenia and severe mental illness, and cautioned that medication should always be used alongside any type of talk therapy in schizophrenia cases. A French review from 2004 found the same. The Schizophrenia Patient Outcomes Research Team advises against the use of psychodynamic therapy in cases of schizophrenia, arguing that more trials are necessary to verify its effectiveness.

Both Freud and psychoanalysis have been criticized in very extreme terms. Exchanges between critics and defenders of psychoanalysis have often been so heated that they have come to be characterized as the "Freud Wars".

Early critics of psychoanalysis believed that its theories were based too little on quantitative and experimental research, and too much on the clinical case study method. Some have accused Freud of fabrication, most famously in the case of Anna O. Frank Cioffi, author of "Freud and the Question of Pseudoscience", cites false claims of a sound scientific verification of the theory and its elements as the strongest basis for classifying the work of Freud and his school as pseudoscience. Others have speculated that patients suffered from now easily identifiable conditions unrelated to psychoanalysis; for instance, Anna O. is thought to have suffered from an organic impairment such as tuberculous meningitis or temporal lobe epilepsy and not hysteria (see modern interpretations).

Karl Popper argued that psychoanalysis is a pseudoscience because its claims are not testable and cannot be refuted; that is, they are not falsifiable. Imre Lakatos later wrote that, "Freudians have been nonplussed by Popper's basic challenge concerning scientific honesty. Indeed, they have refused to specify experimental conditions under which they would give up their basic assumptions." The philosopher Roger Scruton, writing in "Sexual Desire" (1986), rejected Popper's arguments, pointing to the theory of repression as an example of a Freudian theory that does have testable consequences. Scruton nevertheless concluded that psychoanalysis is not genuinely scientific, on the grounds that it involves an unacceptable dependence on metaphor.

Cognitive scientists, in particular, have also weighed in. Martin Seligman, a prominent academic in positive psychology wrote, "Thirty years ago, the cognitive revolution in psychology overthrew both Freud and the behaviorists, at least in academia. ... [T]hinking ... is not just a [result] of emotion or behavior. ... [E]motion is always generated by cognition, not the other way around." Linguist Noam Chomsky has criticized psychoanalysis for lacking a scientific basis. Steven Pinker considers Freudian theory unscientific for understanding the mind. Evolutionary biologist Steven Jay Gould considered psychoanalysis influenced by pseudoscientific theories such as recapitulation theory. Psychologists Hans Eysenck and John F. Kihlstrom have also criticized the field as pseudoscience.

Adolf Grünbaum argues in "Validation in the Clinical Theory of Psychoanalysis" (1993) that psychoanalytic based theories are falsifiable, but that the causal claims of psychoanalysis are unsupported by the available clinical evidence.

Richard Feynman wrote off psychoanalysts as mere "witch doctors":

The psychiatrist E. Fuller Torrey, in "Witchdoctors and Psychiatrists" (1986), agreed that psychoanalytic theories have no more scientific basis than the theories of traditional native healers, "witchdoctors" or modern "cult" alternatives such as est. Psychologist Alice Miller charged psychoanalysis with being similar to the poisonous pedagogies, which she described in her book "For Your Own Good". She scrutinized and rejected the validity of Freud's drive theory, including the Oedipus complex, which, according to her and Jeffrey Masson, blames the child for the abusive sexual behavior of adults. Psychologist Joel Kupfersmid investigated the validity of the Oedipus complex, examining its nature and origins. He concluded that there is little evidence to support the existence of the Oedipus complex.

Michel Foucault and Gilles Deleuze claimed that the institution of psychoanalysis has become a center of power and that its confessional techniques resemble the Christian tradition. Jacques Lacan criticized the emphasis of some American and British psychoanalytical traditions on what he has viewed as the suggestion of imaginary "causes" for symptoms, and recommended the return to Freud. Together with Deleuze, Félix Guattari criticised the Oedipal structure. Luce Irigaray criticised psychoanalysis, employing Jacques Derrida's concept of phallogocentrism to describe the exclusion of the woman from Freudian and Lacanian psychoanalytical theories. Deleuze and Guattari, in their 1972 work "Anti-Œdipus", take the cases of Gérard Mendel, Bela Grunberger and Janine Chasseguet-Smirgel, prominent members of the most respected associations (IPa), to suggest that, traditionally, psychoanalysis enthusiastically embraces a police state.

Psychoanalysis continues to be practiced by psychiatrists, social workers, and other mental health professionals; however, its practice is less common today than in years past. "I think most people would agree that psychoanalysis as a form of treatment is on its last legs", says Bradley Peterson, a psychoanalyst, child psychiatrist and the director of the Institute for the Developing Mind at Children's Hospital Los Angeles. The theoretical foundations of psychoanalysis lie in the same philosophical currents that lead to interpretive phenomenology rather than in those that lead to scientific positivism, making the theory largely incompatible with positivist approaches to the study of the mind.

A French 2004 report from INSERM concluded that psychoanalytic therapy is less effective than other psychotherapies (including cognitive behavioral therapy) for certain diseases. It used a meta-analysis of numerous other studies to find whether the treatment was "proven" or "presumed" to be effective on different diseases. Numerous studies have shown that its efficacy is related to the quality of the therapist, rather than the psychoanalytic school or technique or training.

An increasing amount of empirical research from academic psychologists and psychiatrists has begun to address this criticism. A survey of scientific research suggested that while personality traits corresponding to Freud's oral, anal, Oedipal, and genital phases can be observed, they do not necessarily manifest as stages in the development of children. These studies also have not confirmed that such traits in adults result from childhood experiences (Fisher & Greenberg, 1977, 399). However, these stages should not be viewed as crucial to modern psychoanalysis. What is crucial to modern psychoanalytic theory and practice is the power of the unconscious and the transference phenomenon.

The idea of "unconscious" is contested because human behavior can be observed while human mental activity has to be inferred. However, the unconscious is now a popular topic of study in the fields of experimental and social psychology (e.g., implicit attitude measures, fMRI, and PET scans, and other indirect tests). The idea of unconscious, and the transference phenomenon, have been widely researched and, it is claimed, validated in the fields of cognitive psychology and social psychology (Westen & Gabbard 2002), though a Freudian interpretation of unconscious mental activity is not held by the majority of cognitive psychologists. Recent developments in neuroscience have resulted in one side arguing that it has provided a biological basis for unconscious emotional processing in line with psychoanalytic theory i.e., neuropsychoanalysis (Westen & Gabbard 2002), while the other side argues that such findings make psychoanalytic theory obsolete and irrelevant.

Shlomo Kalo explains that the scientific materialism that flourished in the 19th century severely harmed religion and rejected whatever called spiritual. The institution of the confession priest in particular was badly damaged. The empty void that this institution left behind was swiftly occupied by the newborn psychoanalysis. In his writings Kalo claims that psychoanalysis basic approach is erroneous. It represents the mainline wrong assumptions that happiness is unreachable and that the natural desire of a human being is to exploit his fellow men for his own pleasure and benefit.

Jacques Derrida incorporated aspects of psychoanalytic theory into his theory of deconstruction in order to question what he called the 'metaphysics of presence'. Derrida also turns some of these ideas against Freud, to reveal tensions and contradictions in his work. For example, although Freud defines religion and metaphysics as displacements of the identification with the father in the resolution of the Oedipal complex, Derrida insists in "The Postcard: From Socrates to Freud and Beyond" that the prominence of the father in Freud's own analysis is itself indebted to the prominence given to the father in Western metaphysics and theology since Plato.





</doc>
<doc id="23587" url="https://en.wikipedia.org/wiki?curid=23587" title="Peking (disambiguation)">
Peking (disambiguation)

Peking usually refers to Beijing, the capital city of the People's Republic of China. It may also refer to:




</doc>
<doc id="23588" url="https://en.wikipedia.org/wiki?curid=23588" title="Pinyin">
Pinyin

Hanyu Pinyin Romanization (), often abbreviated to pinyin, is the official romanization system for Standard Chinese in mainland China and to some extent in Taiwan. It is often used to teach Standard Mandarin Chinese, which is normally written using Chinese characters. The system includes four diacritics denoting tones. Pinyin without tone marks is used to spell Chinese names and words in languages written with the Latin alphabet, and also in certain computer input methods to enter Chinese characters.

The pinyin system was developed in the 1950s by many linguists, including Zhou Youguang, based on earlier form romanizations of Chinese. It was published by the Chinese government in 1958 and revised several times.
The International Organization for Standardization (ISO) adopted pinyin as an international standard in 1982, followed by the United Nations in 1986. The system was adopted as the official standard in Taiwan in 2009, where it is used for international events rather than for educational or computer-input purposes. But "some cities, businesses, and organizations, notably in the south of Taiwan, did not accept this", so it remains one of several rival romanization systems in use.

The word ' () means "The spoken language of the Han people." ' () literally means "spelled sounds."

In 1605, the Jesuit missionary Matteo Ricci published ' () in Beijing. This was the first book to use the Roman alphabet to write the Chinese language. Twenty years later, another Jesuit in China, Nicolas Trigault, issued his ' () at Hangzhou. Neither book had much immediate impact on the way in which Chinese thought about their writing system, and the romanizations they described were intended more for Westerners than for the Chinese.

One of the earliest Chinese thinkers to relate Western alphabets to Chinese was late Ming to early Qing dynasty scholar-official, Fang Yizhi (; 1611–1671).

The first late Qing reformer to propose that China adopt a system of spelling was Song Shu (1862–1910). A student of the great scholars Yu Yue and Zhang Taiyan, Song had been to Japan and observed the stunning effect of the "kana" syllabaries and Western learning there. This galvanized him into activity on a number of fronts, one of the most important being reform of the script. While Song did not himself actually create a system for spelling Sinitic languages, his discussion proved fertile and led to a proliferation of schemes for phonetic scripts.

The Wade–Giles system was produced by Thomas Wade in 1859, and further improved by Herbert Giles in the Chinese–English Dictionary of 1892. It was popular and used in English-language publications outside China until 1979.

In the early 1930s, Communist Party of China leaders trained in Moscow introduced a phonetic alphabet using Roman letters which had been developed in the Soviet Oriental Institute of Leningrad and was originally intended to improve literacy in the Russian Far East. This Sin Wenz or "New Writing" was much more linguistically sophisticated than earlier alphabets, with the major exception that it did not indicate tones.

In 1940, several thousand members attended a Border Region Sin Wenz Society convention. Mao Zedong and Zhu De, head of the army, both contributed their calligraphy (in characters) for the masthead of the Sin Wenz Society's new journal. Outside the CCP, other prominent supporters included Sun Yat-sen's son, Sun Fo; Cai Yuanpei, the country's most prestigious educator; Tao Xingzhi, a leading educational reformer; and Lu Xun. Over thirty journals soon appeared written in Sin Wenz, plus large numbers of translations, biographies (including Lincoln, Franklin, Edison, Ford, and Charlie Chaplin), some contemporary Chinese literature, and a spectrum of textbooks. In 1940, the movement reached an apex when Mao's Border Region Government declared that the Sin Wenz had the same legal status as traditional characters in government and public documents. Many educators and political leaders looked forward to the day when they would be universally accepted and completely replace characters. Opposition arose, however, because the system was less well adapted to writing regional languages, and therefore would require learning Mandarin. Sin Wenz fell into relative disuse during the following years.

In 1943, the U.S. military engaged Yale University to develop a romanization of Mandarin Chinese for its pilots flying over China. The resulting system is very close to "pinyin", but does not use English letters in unfamiliar ways; for example, "pinyin" x is written as sy. Medial semivowels are written with y and w (instead of "pinyin" i and u), and apical vowels (syllabic consonants) with r or z. Accent marks are used to indicate tone.

Pinyin was created by Chinese linguists, including Zhou Youguang, as part of a Chinese government project in the 1950s. Zhou is often called "the father of pinyin," Zhou worked as a banker in New York when he decided to return to China to help rebuild the country after the establishment of the People's Republic of China in 1949. He became an economics professor in Shanghai, and in 1955, when China's Ministry of Education created a Committee for the Reform of the Chinese Written Language, Premier Zhou Enlai assigned Zhou Youguang the task of developing a new romanization system, despite the fact that he was not a professional linguist.

"Hanyu Pinyin" was based on several existing systems: "Gwoyeu Romatzyh" of 1928, "Latinxua Sin Wenz" of 1931, and the diacritic markings from "zhuyin". "I'm not the father of pinyin," Zhou said years later; "I'm the son of pinyin. It's [the result of] a long tradition from the later years of the Qing dynasty down to today. But we restudied the problem and revisited it and made it more perfect."

A draft was published on February 12, 1956. The first edition of "Hanyu Pinyin" was approved and adopted at the Fifth Session of the 1st National People's Congress on February 11, 1958. It was then introduced to primary schools as a way to teach Standard Chinese pronunciation and used to improve the literacy rate among adults.

Beginning in the early 1980s, Western publications addressing Mainland China began using the Hanyu Pinyin romanization system instead of earlier romanization systems; this change followed the normalization of diplomatic relations between the United States and the PRC in 1979. In 2001, the PRC Government issued the "National Common Language Law", providing a legal basis for applying pinyin. The current specification of the orthographic rules is laid down in the National Standard GB/T 16159-2012.

Pinyin superseded older romanization systems such as Wade–Giles (1859; modified 1892) and postal romanization, and replaced zhuyin as the method of Chinese phonetic instruction in mainland China. The ISO adopted pinyin as the standard romanization for modern Chinese in 1982 (ISO 7098:1982, superseded by ISO 7098:2015); the United Nations followed suit in 1986. It has also been accepted by the government of Singapore, the United States's Library of Congress, the American Library Association, and many other international institutions.

The spelling of Chinese geographical or personal names in pinyin has become the most common way to transcribe them in English. Pinyin has also become the dominant method for entering Chinese text into computers in Mainland China, in contrast to Taiwan where Bopomofo is most commonly used.
Families outside of Taiwan who speak Mandarin as a mother tongue use pinyin to help children associate characters with spoken words which they already know. Chinese families outside of Taiwan who speak some other language as their mother tongue use the system to teach children Mandarin pronunciation when they learn vocabulary in elementary school.

Since 1958, pinyin has been actively used in adult education as well, making it easier for formerly illiterate people to continue with self-study after a short period of pinyin literacy instruction.

Pinyin has become a tool for many foreigners to learn Mandarin pronunciation, and is used to explain both the grammar and spoken Mandarin coupled with Chinese characters (). Books containing both Chinese characters and pinyin are often used by foreign learners of Chinese; pinyin's role in teaching pronunciation to foreigners and children is similar in some respects to furigana-based books (with hiragana letters written above or next to kanji, directly analogous to zhuyin) in Japanese or fully vocalised texts in Arabic ("vocalised Arabic").

The tone-marking diacritics are commonly omitted in popular news stories and even in scholarly works. This results in some degree of ambiguity as to which words are being represented.

When a foreign writing system with one set of coding/decoding system is taken to write a language, certain compromises may have to be made. The result is that the decoding systems used in some foreign languages will enable non-native speakers to produce sounds more closely resembling the target language than will the coding/decoding system used by other foreign languages. Native speakers of English will decode pinyin spellings to fairly close approximations of Mandarin except in the case of certain speech sounds that are not ordinarily produced by most native speakers of English: "j, q, x, z, c, s, zh, ch, sh", and "r" exhibiting the greatest discrepancies.

In this system, the correspondence between the Roman letter and the sound is sometimes idiosyncratic, though not necessarily more so than the way the Latin script is employed in other languages. For example, the aspiration distinction between "b, d, g" and "p, t, k" is similar to that of English (in which the two sets are however also differentiated by voicing), but not to that of French. Letters "z" and "c" also have that distinction, pronounced as and (whilst reminiscent of both of them being used for the phoneme in the German language and Latin script-using Slavic languages respectively). From "s, z, c" come the digraphs "sh, zh, ch" by analogy with English "sh, ch". Although this introduces the novel combination "zh", it is internally consistent in how the two series are related, and reminds the trained reader that many Chinese pronounce "sh, zh, ch" as "s, z, c" (and English-speakers use "zh" to represent in foreign languages such as Russian anyway). In the "x, j, q" series, the pinyin use of "x" is similar to its use in Portuguese, Galician, Catalan, Basque, and Maltese; and the pinyin "q" is akin to its value in Albanian; both pinyin and Albanian pronunciations may sound similar to the "ch" to the untrained ear. Pinyin vowels are pronounced in a similar way to vowels in Romance languages.

The pronunciation and spelling of Chinese words are generally given in terms of initials and finals, which represent the "segmental phonemic" portion of the language, rather than letter by letter. Initials are initial consonants, while finals are all possible combinations of medials (semivowels coming before the vowel), the nucleus vowel, and coda (final vowel or consonant).

Unlike European languages, clusters of letters – initials () and finals () – and not consonant and vowel letters, form the fundamental elements in pinyin (and most other phonetic systems used to describe the Han language). Every Mandarin syllable can be spelled with exactly one initial followed by one final, except for the special syllable "er" or when a trailing "-r" is considered part of a syllable (see below). The latter case, though a common practice in some sub-dialects, is rarely used in official publications. One exception is the city Harbin (), whose name comes from the Manchu language.

Even though most initials contain a consonant, finals are not always simple vowels, especially in compound finals (), i.e. when a "medial" is placed in front of the final. For example, the medials and are pronounced with such tight openings at the beginning of a final that some native Chinese speakers (especially when singing) pronounce "yī" (, clothes, officially pronounced ) as and "wéi" (, to enclose, officially pronounced ) as or . Often these medials are treated as separate from the finals rather than as part of them; this convention is followed in the chart of finals below.

In each cell below, the bold letters indicate pinyin and the brackets enclose the symbol in the International Phonetic Alphabet.

The conventional order (excluding "w" and "y"), derived from the zhuyin system, is:

In each cell below, the first line indicates IPA, the second indicates pinyin for a standalone (no-initial) form, and the third indicates pinyin for a combination with an initial. Other than finals modified by an "-r", which are omitted, the following is an exhaustive table of all possible finals.

The only syllable-final consonants in Standard Chinese are "-n" and "-ng", and "-r", which is attached as a grammatical suffix. A Chinese syllable ending with any other consonant either is from a non-Mandarin language (a southern Chinese language such as Cantonese, or a minority language of China), or indicates the use of a non-pinyin romanization system (where final consonants may be used to indicate tones).

Technically, "i, u, ü" without a following vowel are finals, not medials, and therefore take the tone marks, but they are more concisely displayed as above. In addition, "ê" () and syllabic nasals "m" (, ), "n" (, ), "ng" (, ) are used as interjections.

Most rules given here in terms of English pronunciation are approximations, as several of these sounds do not correspond directly to sounds in English.

"Y" and "w" are equivalent to the semivowel medials "i, u", and "ü" (see below). They are spelled differently when there is no initial consonant in order to mark a new syllable: "fanguan" is "fan-guan", while "fangwan" is "fang-wan" (and equivalent to "*fang-uan)". With this convention, an apostrophe only needs to be used to mark an initial "a, e", or "o: Xi'an" (two syllables: ) vs. "xian" (one syllable: ). In addition, "y" and "w" are added to fully vocalic "i, u", and "ü" when these occur without an initial consonant, so that they are written "yi, wu", and "yu". Some Mandarin speakers do pronounce a or sound at the beginning of such words—that is, "yi" or , "wu" or , "yu" or ,—so this is an intuitive convention. See below for a few finals which are abbreviated after a consonant plus "w/u" or "y/i" medial: "wen" → C+"un", "wei" → C+"ui", "weng" → C+"ong", and "you" → C+"iu".

The apostrophe (') () is used before a syllable starting with a vowel (, , or ) in a multiple-syllable word when the syllable does not start the word (which is most commonly realized as ), unless the syllable immediately follows a hyphen or other dash. This usage is done to remove ambiguity that could arise, as in "Xi'an", which consists of the two syllables ("") (""), compared to such words as (""). (This ambiguity does not occur when tone marks are used: the two tone marks in unambiguously show that the word consists of two syllables. However, even with tone marks, the city is usually spelled with an apostrophe as .)

The following is a list of finals in Standard Chinese, excepting most of those ending with "r".

To find a given final:

Pinyin differs from other romanizations in several aspects, such as the following:


Most of the above are used to avoid ambiguity when writing words of more than one syllable in pinyin. For example, "uenian" is written as "wenyan" because it is not clear which syllables make up "uenian"; "uen-ian", "uen-i-an", and "u-en-i-an" are all possible combinations whereas "wenyan" is unambiguous because "we", "nya", etc. do not exist in pinyin. See the pinyin table article for a summary of possible pinyin syllables (not including tones).

Although Chinese characters represent single syllables, Mandarin Chinese is a polysyllabic language. Spacing in pinyin is based on whole words, not single syllables. However, there are often ambiguities in partitioning a word. "The Basic Rules of the Chinese Phonetic Alphabet Orthography" () were put into effect in 1988 by the National Educational Commission () and the National Language Commission (). These rules became a Guobiao standard in 1996 and were updated in 2012.


The pinyin system also uses diacritics to mark the four tones of Mandarin. The diacritic is placed over the letter that represents the syllable nucleus, unless that letter is missing (see below). Many books printed in China use a mix of fonts, with vowels and tone marks rendered in a different font from the surrounding text, tending to give such pinyin texts a typographically ungainly appearance. This style, most likely rooted in early technical limitations, has led many to believe that pinyin's rules call for this practice and also for the use of a Latin alpha ("ɑ") rather than the standard style of the letter ("a") found in most fonts. (The same problem happens to "g"—often written as "ɡ", or U+0261). The official rules of "Hanyu Pinyin", however, specify no such practice.


These tone marks normally are only used in Mandarin textbooks or in foreign learning texts, but they are essential for correct pronunciation of Mandarin syllables, as exemplified by the following classic example of five characters whose pronunciations differ only in their tones:

The words are "mother", "hemp", "horse", "scold", and a question particle, respectively.

Before the advent of computers, many typewriter fonts did not contain vowels with macron or caron diacritics. Tones were thus represented by placing a tone number at the end of individual syllables. For example, "tóng" is written "tong2".
The number used for each tone is as the order listed above, except the neutral tone, which is either not numbered, or given the number 0 or 5, e.g. "ma5" for 吗/嗎, an interrogative marker.
Briefly, the tone mark should always be placed by the order—"a, o, e, i, u, ü", with the only exception being "iu", where the tone mark is placed on the "u" instead. Pinyin tone marks appear primarily above the nucleus of the syllable, for example as in "kuài", where "k" is the initial, "u" the medial, "a" the nucleus, and "i" the coda. The exception is syllabic nasals like /m/, where the nucleus of the syllable is a consonant, the diacritic will be carried by a written dummy vowel.

When the nucleus is /ə/ (written "e" or "o"), and there is both a medial and a coda, the nucleus may be dropped from writing. In this case, when the coda is a consonant "n" or "ng", the only vowel left is the medial "i, u", or "ü", and so this takes the diacritic. However, when the coda is a vowel, it is the coda rather than the medial which takes the diacritic in the absence of a written nucleus. This occurs with syllables ending in "-ui" (from "wei": (wèi → -uì) and in "-iu" (from "you: yòu → -iù".) That is, in the absence of a written nucleus the finals have priority for receiving the tone marker, as long as they are vowels: if not, the medial takes the diacritic.

An algorithm to find the correct vowel letter (when there is more than one) is as follows:


Worded differently,

If the tone is written over an "i", the tittle above the "i" is omitted, as in "yī".

The placement of the tone marker, when more than one of the written letters "a, e, i, o", and "u" appears, can also be inferred from the nature of the vowel sound in the medial and final. The rule is that the tone marker goes on the spelled vowel that is not a (near-)semi-vowel. The exception is that, for triphthongs that are spelled with only two vowel letters, both of which are the semi-vowels, the tone marker goes on the second spelled vowel.

Specifically, if the spelling of a diphthong begins with "i" (as in "ia") or "u" (as in "ua"), which serves as a near-semi-vowel, this letter does not take the tone marker. Likewise, if the spelling of a diphthong ends with "o" or "u" representing a near-semi-vowel (as in "ao" or "ou"), this letter does not receive a tone marker. In a triphthong spelled with three of "a, e, i, o", and "u" (with "i" or "u" replaced by "y" or "w" at the start of a syllable), the first and third letters coincide with near-semi-vowels and hence do not receive the tone marker (as in "iao" or "uai" or "iou"). But if no letter is written to represent a triphthong's middle (non-semi-vowel) sound (as in "ui" or "iu"), then the tone marker goes on the final (second) vowel letter.

In addition to tone number and mark, tone color has been suggested as a visual aid for learning. Although there are no formal standards, there are a number of different color schemes in use.

In spoken Chinese, the third tone is often pronounced as a "half third tone", in which the pitch does not rise. Additionally, when two third tones appear consecutively, such as in 你好 (nǐhǎo, hello), the first syllable is pronounced with the second tone. In pinyin, words like "hello" are still written with two third tones (nǐhǎo).

An umlaut is placed over the letter "u" when it occurs after the initials "l" and "n" when necessary in order to represent the sound [y]. This is necessary in order to distinguish the front high rounded vowel in "lü" (e.g. ) from the back high rounded vowel in "lu" (e.g. ). Tonal markers are added on top of the umlaut, as in "lǘ".

However, the "ü" is "not" used in the other contexts where it could represent a front high rounded vowel, namely after the letters "j", "q", "x", and "y". For example, the sound of the word / (fish) is transcribed in pinyin simply as "yú", not as "yǘ". This practice is opposed to Wade–Giles, which always uses "ü", and "Tongyong Pinyin", which always uses "yu". Whereas Wade–Giles needs of using the umlaut to distinguish between "chü" (pinyin "ju") and "chu" (pinyin "zhu"), this ambiguity does not arise with pinyin, so the more convenient form "ju" is used instead of "jü". Genuine ambiguities only happen with "nu"/"nü" and "lu"/"lü", which are then distinguished by an umlaut.

Many fonts or output methods do not support an umlaut for "ü" or cannot place tone marks on top of "ü". Likewise, using "ü" in input methods is difficult because it is not present as a simple key on many keyboard layouts. For these reasons "v" is sometimes used instead by convention. For example, it is common for cellphones to use "v" instead of "ü". Additionally, some stores in China use "v" instead of "ü" in the transliteration of their names. The drawback is that there are no tone marks for the letter "v".

This also presents a problem in transcribing names for use on passports, affecting people with names that consist of the sound "lü" or "nü", particularly people with the surname ("Lǚ"), a fairly common surname, particularly compared to the surnames (Lù), (Lǔ), (Lú) and (Lù). Previously, the practice varied among different passport issuing offices, with some transcribing as "LV" and "NV" while others used "LU" and "NU". On 10 July 2012, the Ministry of Public Security standardized the practice to use "LYU" and "NYU" in passports.

Although "nüe" written as "nue", and "lüe" written as "lue" are not ambiguous, "nue" or "lue" are not correct according to the rules; "nüe" and "lüe" should be used instead. However, some Chinese input methods (e.g. Microsoft Pinyin IME) support both "nve"/"lve" (typing "v" for "ü") and "nue"/"lue".

Taiwan (Republic of China) adopted "Tongyong Pinyin", a modification of "Hanyu Pinyin", as the official romanization system on the national level between October 2002 and January 2009, when it switched to "Hanyu Pinyin". "Tongyong Pinyin" ("common phonetic"), a variant of pinyin developed in Taiwan, was designed to romanize languages and dialects spoken on the island in addition to Mandarin Chinese. The Kuomintang (KMT) party resisted its adoption, preferring the "Hanyu Pinyin" system used in Mainland China and in general use internationally. Romanization preferences quickly became associated with issues of national identity. Preferences split along party lines: the KMT and its affiliated parties in the pan-blue coalition supported the use of Hanyu Pinyin while the Democratic Progressive Party and its affiliated parties in the pan-green coalition favored the use of Tongyong Pinyin.

"Tongyong Pinyin" was made the official system in an administrative order that allowed its adoption by local governments to be voluntary. A few localities with governments controlled by the KMT, most notably Taipei, Hsinchu, and Kinmen County, overrode the order and converted to "Hanyu Pinyin" before the January 1, 2009 national-level switch, though with a slightly different capitalization convention than mainland China. Most areas of Taiwan adopted Tongyong Pinyin, consistent with the national policy. After 2009 switch, many street signs in Taiwan today still display "Tongyong Pinyin" but some, especially in northern Taiwan, display "Hanyu Pinyin". It is still not unusual to see spellings on street signs and buildings derived from the older Wade–Giles, MPS2 and other systems.

The adoption of "Hanyu Pinyin" as the official romanization system in Taiwan does not preclude the official retention of earlier spellings. International familiarity has led to the retention of the spelling "Taipei" ("Taibei" in pinyin systems) and even to its continuation in the name of New Taipei, a municipality created in 2010. Personal names on Taiwanese passports honor the choices of Taiwanese citizens, who often prefer the Wade–Giles romanization of their personal names, though the official online conversion tool lists pinyin before other systems. Transition to Hanyu Pinyin in official use is also necessarily gradual. Universities and other government entities retain earlier spellings in long-established names, and budget restraints preclude widespread replacement of signage and stationery in every area. Primary education in Taiwan continues to teach pronunciation using "zhuyin" (MPS or Mandarin Phonetic Symbols).

Pinyin is now used by foreign students learning Chinese as a second language.

Pinyin assigns some Latin letters sound values which are quite different from that of most languages. This has drawn some criticism as it may lead to confusion when uninformed speakers apply either native or English assumed pronunciations to words. However, this problem is not limited only to pinyin, since many languages that use the Latin alphabet natively also assign different values to the same letters. A recent study on Chinese writing and literacy concluded, "By and large, pinyin represents the Chinese sounds better than the Wade–Giles system, and does so with fewer extra marks."

Because Pinyin is purely a representation of the sounds of Mandarin, it completely lacks the semantic cues and contexts inherent in Chinese characters. Pinyin is also unsuitable for transcribing some Chinese spoken languages other than Mandarin, languages which by contrast have traditionally been written with Han characters allowing for written communication which, by its unified semanto-phonetic orthography, could theoretically be readable in any of the various vernaculars of Chinese where a phonetic script would have only localized utility.

Simple computer systems, able to display only 7-bit ASCII text (essentially the 26 Latin letters, 10 digits, and punctuation marks), long provided a convincing argument for using unaccented pinyin instead of Chinese characters. Today, however, most computer systems are able to display characters from Chinese and many other writing systems as well, and have them entered with a Latin keyboard using an input method editor. Alternatively, some PDAs, tablet computers, and digitizing tablets allow users to input characters graphically by writing with a stylus, with concurrent online handwriting recognition.

Pinyin with accents can be entered with the use of special keyboard layouts or various character map utilities. X keyboard extension includes a "Hanyu Pinyin (altgr)" layout for AltGr-triggered dead key input of accented characters.

Pinyin-like systems have been devised for other variants of Chinese. Guangdong Romanization is a set of romanizations devised by the government of Guangdong province for Cantonese, Teochew, Hakka (Moiyen dialect), and Hainanese. All of these are designed to use Latin letters in a similar way to pinyin.

In addition, in accordance to the "Regulation of Phonetic Transcription in Hanyu Pinyin Letters of Place Names in Minority Nationality Languages" () promulgated in 1976, place names in non-Han languages like Mongolian, Uyghur, and Tibetan are also officially transcribed using pinyin in a system adopted by the State Administration of Surveying and Mapping and Geographical Names Committee known as SASM/GNC romanization. The pinyin letters (26 Roman letters, plus ü and ê) are used to approximate the non-Han language in question as closely as possible. This results in spellings that are different from both the customary spelling of the place name, and the pinyin spelling of the name in Chinese:

"Tongyong Pinyin" was developed in Taiwan for use in rendering not only Mandarin Chinese, but other languages and dialects spoken on the island such as Taiwanese, Hakka, and aboriginal languages.





</doc>
<doc id="23589" url="https://en.wikipedia.org/wiki?curid=23589" title="Parable of the Pearl">
Parable of the Pearl

The Parable of the Pearl (also called the Pearl of Great Price) is one of the parables of Jesus. It appears in and illustrates the great value of the Kingdom of Heaven. It is the penultimate parable in Matthew 13, just before the Parable of the Dragnet.

It immediately follows the Parable of the Hidden Treasure, which has a similar theme. It does not appear in the other synoptic gospels but a version of this parable does appear in the non-canonical Gospel of Thomas, Saying 76. The parable has been depicted by artists such as Domenico Fetti.

The parable reads as follows:

This parable is generally interpreted as illustrating the great value of the Kingdom of Heaven. Anglican bishop Charles Ellicott notes that:
"the caprices of luxury in the Roman empire had given a prominence to pearls, as an article of commerce, which they had never had before, and have probably never had since. They, rather than emeralds and sapphires, were the typical instance of all costliest adornments (; ). The story of Cleopatra and the fact that the opening of a new pearl market was one of the alleged motives which led the Emperor Claudius to invade Britain, are indications of the value that was then set on the “goodly pearls” of the parable", 
and theologian John Nolland likewise notes that pearls at that time had a greater value than they do today, and it thus has a similar theme to its partner, the parable of the Hidden Treasure. Nolland comments that it shares with that parable the notions of "good fortune and demanding action in attaining the kingdom of heaven", but adds in this case the notion of "diligent seeking".

The valuable pearl is the "deal of a lifetime" for the merchant in the story. However, those who do not believe in the kingdom of heaven enough to stake their whole future on it are unworthy of the kingdom.

This interpretation of the parable is the inspiration for a number of hymns, including the anonymous Swedish hymn "Den Kostliga Pärlan" ("O That Pearl of Great Price!"), which begins:

<poem>
O that Pearl of great price! have you found it?
Is the Savior supreme in your love?
O consider it well, ere you answer,
As you hope for a welcome above.
Have you given up all for this Treasure?
Have you counted past gains as but loss?
Has your trust in yourself and your merits
Come to naught before Christ and His cross?
</poem>

A less common interpretation of the parable is that the merchant represents Jesus, and the pearl represents the Christian Church. This interpretation would give the parable a similar theme to that of the Parable of the Lost Sheep, the Lost Coin, and the Prodigal Son.

The phrase "Pearl of Great Price" has also been interpreted more widely to apply to things of great value in a number of religious contexts. For example, it is the title of a selection of Mormon writings. Pope Pius XII used the phrase to describe virginity.

The pearl itself is a beautiful, single entity, formed through suffering in the heart of the oyster (in the same way that believers endure lack of wealth or comfort) and like the Church, will be put on display in a coming day. Unlike precious stones which must be cut and polished to reveal their clarity and beauty, the pearl is perfect as it comes from the oyster.

A version of the parable also appears in the Gnostic Gospel of Thomas (Saying 76):

This work's version of the parable of the Hidden Treasure appears later (Saying 109), rather than immediately preceding, as in Matthew. However, the mention of a treasure in Saying 76 may reflect a source for the Gospel of Thomas in which the parables were adjacent, so that the original pair of parables has been "broken apart, placed in separate contexts, and expanded in a manner characteristic of folklore." In Gnostic thought the pearl may represent Christ or the true self. In the Gnostic Acts of Peter and the Twelve, found with the Gospel of Thomas in the Nag Hammadi library, the travelling pearl merchant Lithargoel is eventually revealed to be Jesus.

There have been several depictions of the New Testament parable in art, including works by Domenico Fetti, John Everett Millais, and Jan Luyken.

The Parable is Referenced in Nathaniel Hawthorne's Novel "The Scarlet Letter" on page 82: "But she named the infant 'Pearl,' as being of great price- purchased with all see had,- her mothers only treasure!"



</doc>
<doc id="23590" url="https://en.wikipedia.org/wiki?curid=23590" title="Pantheism">
Pantheism

Pantheism is the belief that reality is identical with divinity, or that all-things compose an all-encompassing, immanent god. Pantheist belief does not recognize a distinct personal anthropomorphic god and instead characterizes a broad range of doctrines differing in forms of relationships between reality and divinity.

Pantheism was popularized in Western culture as a theology and philosophy based on the work of the 17th-century philosopher Baruch Spinoza, particularly his book "Ethics", published in 1677. The term "pantheism" was coined by mathematician Joseph Raphson in 1697 and has since been used to describe the beliefs of a variety of people and organizations.

Pantheistic concepts date back thousands of years, and pantheistic elements have been identified in various religious traditions.

"Pantheism" derives from the Greek πᾶν "pan" (meaning "all, of everything") and θεός "theos" (meaning "god, divine"). The first known combination of these roots appears in Latin, in Joseph Raphson's 1697 book "De Spatio Reali seu Ente Infinito", where he refers to the "pantheismus" of Spinoza and others.
It was subsequently translated into English as "pantheism" in 1702.

There are a variety of definitions of pantheism. Some consider it a theological and philosophical position concerning God.

Pantheism is the view that everything is part of an all-encompassing, immanent God. All forms of reality may then be considered either modes of that Being, or identical with it. Some hold that pantheism is a non-religious philosophical position. To them, pantheism is the view that the Universe (in the sense of the totality of all existence) and God are identical (implying a denial of the personality and transcendence of God).

Pantheistic tendencies existed in a number of early Gnostic groups, with pantheistic thought appearing throughout the Middle Ages. These included a section of Johannes Scotus Eriugena's 9th-century work De divisione naturae and the beliefs of mystics such as Amalric of Bena (11th12th centuries) and Eckhart (12th13th).

The Roman Catholic Church has long regarded pantheistic ideas as heresy. Giordano Bruno, an Italian monk who evangelized about an immanent and infinite God, was burned at the stake in 1600 by the Roman Inquisition. He has since become known as a celebrated pantheist and martyr of science, and an influence on many later thinkers.

In the West, pantheism was formalized as a separate theology and philosophy based on the work of the 17th-century philosopher Baruch Spinoza. Spinoza was a Dutch philosopher of Portuguese descent raised in the Sephardi Jewish community in Amsterdam. He developed highly controversial ideas regarding the authenticity of the Hebrew Bible and the nature of the Divine, and was effectively excluded from Jewish society at age 23, when the local synagogue issued a "herem" against him. A number of his books were published posthumously, and shortly thereafter included in the Catholic Church's "Index of Forbidden Books". The breadth and importance of Spinoza's work would not be realized for many years - as the groundwork for the 18th-century Enlightenment and modern biblical criticism, including modern conceptions of the self and the universe.

In the posthumous "Ethics", "Spinoza wrote the last indisputable Latin masterpiece, and one in which the refined conceptions of medieval philosophy are finally turned against themselves and destroyed entirely.". In particular, he opposed René Descartes' famous mind–body dualism, the theory that the body and spirit are separate. Spinoza held the monist view that the two are the same, and monism is a fundamental part of his philosophy. He was described as a "God-intoxicated man," and used the word God to describe the unity of all substance. This view influenced philosophers such as Georg Wilhelm Friedrich Hegel, who said, "You are either a Spinozist or not a philosopher at all." 
Spinoza earned praise as one of the great rationalists of 17th-century philosophy and one of Western philosophy's most important thinkers. Although the term "pantheism" was not coined until after his death, he is regarded as the most celebrated advocate of the concept. "Ethics" was the major source from which Western pantheism spread.

The first known use of the term "pantheism" was in Latin ("pantheismus" ) by the English mathematician Joseph Raphson in his work "De Spatio Reali seu Ente Infinito", published in 1697. Raphson begins with a distinction between atheistic "panhylists" (from the Greek roots "pan", "all", and "hyle", "matter"), who believe everything is matter, and Spinozan "pantheists" who believe in "a certain universal substance, material as well as intelligence, that fashions all things that exist out of its own essence." Raphson thought that the universe was immeasurable in respect to a human's capacity of understanding, and believed that humans would never be able to comprehend it. He referred to the pantheism of the Ancient Egyptians, Persians, Syrians, Assyrians, Greek, Indians, and Jewish Kabbalists, specifically referring to Spinoza.

The term was first used in English by a translation of Raphson's work in 1702. It was later used and popularized by Irish writer John Toland in his work of 1705 "Socinianism Truly Stated, by a pantheist". Toland was influenced by both Spinoza and Bruno, and had read Joseph Raphson's "De Spatio Reali", referring to it as "the ingenious Mr. Ralphson's (sic) Book of Real Space". Like Raphson, he used the terms "pantheist" and "Spinozist" interchangeably. In 1720 he wrote the "Pantheisticon: or The Form of Celebrating the Socratic-Society" in Latin, envisioning a pantheist society that believed, "All things in the world are one, and one is all in all things ... what is all in all things is God, eternal and immense, neither born nor ever to perish." He clarified his idea of pantheism in a letter to Gottfried Leibniz in 1710 when he referred to "the pantheistic opinion of those who believe in no other eternal being but the universe".

In the mid-eighteenth century, the English theologian Daniel Waterland defined pantheism this way: "It supposes God and nature, or God and the whole universe, to be one and the same substance—one universal being; insomuch that men's souls are only modifications of the divine substance." In the early nineteenth century, the German theologian Julius Wegscheider defined pantheism as the belief that God and the world established by God are one and the same.

Between 1785–89, a major controversy about Spinoza's philosophy arose between the German philosophers Friedrich Heinrich Jacobi (a critic) and Moses Mendelssohn (a defender). Known in German as the "Pantheismusstreit" (pantheism controversy), it helped spread pantheism to many German thinkers.
A 1780 conversation with the German dramatist Gotthold Ephraim Lessing led Jacobi to a protracted study of Spinoza's works. Lessing stated that he knew no other philosophy than Spinozism.
Jacobi's "Über die Lehre des Spinozas" (1st ed. 1785, 2nd ed. 1789) expressed his strenuous objection to a dogmatic system in philosophy, and drew upon him the enmity of the Berlin group, led by Mendelssohn. Jacobi claimed that Spinoza's doctrine was pure materialism, because all Nature and God are said to be nothing but extended substance. This, for Jacobi, was the result of Enlightenment rationalism and it would finally end in absolute atheism. Mendelssohn disagreed with Jacobi, saying that pantheism shares more characteristics of theism than of atheism. The entire issue became a major intellectual and religious concern for European civilization at the time.

Willi Goetschel argues that Jacobi's publication significantly shaped Spinoza's wide reception for centuries following its publication, obscuring the nuance of Spinoza's philosophic work.

During the beginning of the 19th century, pantheism was the viewpoint of many leading writers and philosophers, attracting figures such as William Wordsworth and Samuel Coleridge in Britain; Johann Gottlieb Fichte, Schelling and Hegel in Germany; Knut Hamsun in Norway; and Walt Whitman, Ralph Waldo Emerson and Henry David Thoreau in the United States. Seen as a growing threat by the Vatican, in 1864 it was formally condemned by Pope Pius IX in the "Syllabus of Errors".

A letter written by William Herndon, Abraham Lincoln's law partner in 1886, was sold at auction for US$30,000 in 2011. In it, Herndon writes of the U.S. President's evolving religious views, which included pantheism.
The subject is understandably controversial, but the content of the letter is consistent with Lincoln's fairly lukewarm approach to organized religion.

Some 19th-century theologians thought that various pre-Christian religions and philosophies were pantheistic. They thought Pantheism was similar to the ancient Hindu philosophy of Advaita (non-dualism) to the extent that the 19th-century German Sanskritist Theodore Goldstücker remarked that Spinoza's thought was "... a western system of philosophy which occupies a foremost rank amongst the philosophies of all nations and ages, and which is so exact a representation of the ideas of the Vedanta, that we might have suspected its founder to have borrowed the fundamental principles of his system from the Hindus."

19th-century European theologians also considered Ancient Egyptian religion to contain pantheistic elements and pointed to Egyptian philosophy as a source of Greek Pantheism. The latter included some of the Presocratics, such as Heraclitus and Anaximander. The Stoics were pantheists, beginning with Zeno of Citium and culminating in the emperor-philosopher Marcus Aurelius. During the pre-Christian Roman Empire, Stoicism was one of the three dominant schools of philosophy, along with Epicureanism and Neoplatonism. The early Taoism of Laozi and Zhuangzi is also sometimes considered pantheistic, althought it could be more similiar to Panentheism.

Cheondoism and Won Buddhism which arose in the Joseon Dynasty of Korea is also considered pantheistic.

In 2007, Dorion Sagan, the son of famous scientist and science communicator, Carl Sagan, published a book entitled "Dazzle Gradually: Reflections on the Nature of Nature" co-written with his mother, Lynn Margulis. In a chapter entitled, "Truth of My Father", he declares: "My father believed in the God of Spinoza and Einstein, God not behind nature, but as nature, equivalent to it."

In a letter written to Eduard Büsching (25 October 1929), after Büsching sent Albert Einstein a copy of his book "Es gibt keinen Gott" ("There is no God"), Einstein wrote, "We followers of Spinoza see our God in the wonderful order and lawfulness of all that exists and in its soul ["Beseeltheit"] as it reveals itself in man and animal." According to Einstein, the book only dealt with the concept of a personal god and not the impersonal God of pantheism. In a letter written in 1954 to philosopher Eric Gutkind, Einstein wrote "the word God is for me nothing more than the expression and product of human weaknesses." In another letter written in 1954 he wrote "I do not believe in a personal God and I have never denied this but have expressed it clearly.".

In the late 20th century, some declared that pantheism was an underlying theology of Neopaganism, and pantheists began forming organizations devoted specifically to pantheism and treating it as a separate religion.
Pantheism is mentioned in a Papal encyclical in 2009 and a statement on New Year's Day in 2010, criticizing pantheism for denying the superiority of humans over nature and seeing the source of man salvation in nature. In a review of the 2009 film "Avatar", Ross Douthat, an author, described pantheism as "Hollywood's religion of choice for a generation now".

In 2015, Los Angeles muralist Levi Ponce was commissioned to paint "Luminaries of Pantheism" for an area in Venice, California that receives over a million onlookers per year. The organization that commissioned the work, The Paradise Project, is "dedicated to celebrating and spreading awareness about pantheism." The mural painting depicts Albert Einstein, Alan Watts, Baruch Spinoza, Terence McKenna, Carl Jung, Carl Sagan, Emily Dickinson, Nikola Tesla, Friedrich Nietzsche, Ralph Waldo Emerson, W.E.B. Du Bois, Henry David Thoreau, Elizabeth Cady Stanton, Rumi, Adi Shankara, and Laozi.

There are multiple varieties of pantheism and various systems of classifying them relying upon one or more spectra or in discrete categories.

The philosopher Charles Hartshorne used the term Classical Pantheism to describe the deterministic philosophies of Baruch Spinoza, the Stoics, and other like-minded figures. Pantheism (All-is-God) is often associated with monism (All-is-One) and some have suggested that it logically implies determinism (All-is-Now). Albert Einstein explained theological determinism by stating, "the past, present, and future are an 'illusion'". This form of pantheism has been referred to as "extreme monism", in which in the words of one commentator "God decides or determines everything, including our supposed decisions." Other examples of determinism-inclined pantheisms include those of Ralph Waldo Emerson, and Hegel.

However, some have argued against treating every meaning of "unity" as an aspect of pantheism, and there exist versions of pantheism that regard determinism as an inaccurate or incomplete view of nature. Examples include the beliefs of Friedrich Wilhelm Joseph Schelling and William James.

It may also be possible to distinguish two types of pantheism, one being more religious and the other being more philosophical. The Columbia Encyclopedia writes of the distinction:

Philosophers and theologians have often suggested that pantheism implies monism. Different types of monism include:


Views contrasting with monism are:

Monism in modern philosophy of mind can be divided into three broad categories:

Certain positions do not fit easily into the above categories, such as functionalism, anomalous monism, and reflexive monism. Moreover, they do not define the meaning of "real".

In 1896, J. H. Worman, a theologian, identified seven categories of pantheism: Mechanical or materialistic (God the mechanical unity of existence); Ontological (fundamental unity, Spinoza); Dynamic; Psychical (God is the soul of the world); Ethical (God is the universal moral order, Fichte; Logical (Hegel); and Pure (absorption of God into nature, which Worman equates with atheism).

More recently, Paul D. Feinberg, professor of biblical and systematic theology at Trinity Evangelical Divinity School, also identified seven: Hylozoistic; Immanentistic; Absolutistic monistic; Relativistic monistic; Acosmic; Identity of opposites; and Neoplatonic or emanationistic.

Nature worship or nature mysticism is often conflated and confused with pantheism. It is pointed out by at least one expert in pantheist philosophy that Spinoza's identification of God with nature is very different from a recent idea of a self identifying pantheist with environmental ethical concerns, Harold Wood, founder of the Universal Pantheist Society. His use of the word nature to describe his worldview may be vastly different from the "nature" of modern sciences. He and other nature mystics who also identify as pantheists use "nature" to refer to the limited natural environment (as opposed to man-made built environment). This use of "nature" is different from the broader use from Spinoza and other pantheists describing natural laws and the overall phenomena of the physical world. Nature mysticism may be compatible with pantheism but it may also be compatible with theism and other views.

Nontheism is an umbrella term which has been used to refer to a variety of religions not fitting traditional theism, and under which pantheism has been included.

Panentheism (from Greek πᾶν (pân) "all"; ἐν (en) "in"; and θεός (theós) "God"; "all-in-God") was formally coined in Germany in the 19th century in an attempt to offer a philosophical synthesis between traditional theism and pantheism, stating that God is substantially omnipresent in the physical universe but also exists "apart from" or "beyond" it as its Creator and Sustainer. Thus panentheism separates itself from pantheism, positing the extra claim that God exists above and beyond the world as we know it. The line between pantheism and panentheism can be blurred depending on varying definitions of God, so there have been disagreements when assigning particular notable figures to pantheism or panentheism.

Pandeism is another word derived from pantheism, and is characterized as a combination of reconcilable elements of pantheism and deism. It assumes a Creator-deity that is at some point distinct from the universe and then transforms into it, resulting in a universe similar to the pantheistic one in present essence, but differing in origin.

Panpsychism is the philosophical view held by many pantheists that consciousness, mind, or soul is a universal feature of all things. Some pantheists also subscribe to the distinct philosophical views hylozoism (or panvitalism), the view that everything is alive, and its close neighbor animism, the view that everything has a soul or spirit.

Many traditional and folk religions including African traditional religions and Native American religions can be seen as pantheistic, or a mixture of pantheism and other doctrines such as polytheism and animism. According to pantheists, there are elements of pantheism in some forms of Christianity.

Ideas resembling pantheism existed in East/South Asian religions before the 18th century (notably Sikhism, Hinduism, Confucianism, and Taoism). Although there is no evidence that these influenced Spinoza's work, there is such evidence regarding other contemporary philosophers, such as Leibniz, and later Voltaire. In the case of Hinduism, pantheistic views exist alongside panentheistic, polytheistic, monotheistic, and atheistic ones. In the case of Sikhism, stories attributed to Guru Nanak suggest that he believed God was everywhere in the physical world, and the Sikh tradition typically describes God as the preservative force within the physical world, present in all material forms, each created as a manifestation of God. However, Sikhs view God as the transcendent creator, "immanent in the phenomenal reality of the world in the same way in which an artist can be said to be present in his art". This implies a more panentheistic position.

Pantheism is popular in modern spirituality and new religious movements, such as Neopaganism and Theosophy. Two organizations that specify the word pantheism in their title formed in the last quarter of the 20th century. The Universal Pantheist Society, open to all varieties of pantheists and supportive of environmental causes, was founded in 1975. The World Pantheist Movement is headed by Paul Harrison, an environmentalist, writer and a former vice president of the Universal Pantheist Society, from which he resigned in 1996. The World Pantheist Movement was incorporated in 1999 to focus exclusively on promoting naturalistic pantheism - a strict metaphysical naturalistic version of pantheism, considered by some a form of religious naturalism. It has been described as an example of "dark green religion" with a focus on environmental ethics.






</doc>
