<doc id="22131" url="https://en.wikipedia.org/wiki?curid=22131" title="Natural gas">
Natural gas

Natural gas is a naturally occurring hydrocarbon gas mixture consisting primarily of methane, but commonly including varying amounts of other higher alkanes, and sometimes a small percentage of carbon dioxide, nitrogen, hydrogen sulfide, or helium. It is formed when layers of decomposing plant and animal matter are exposed to intense heat and pressure under the surface of the Earth over millions of years. The energy that the plants originally obtained from the sun is stored in the form of chemical bonds in the gas.

Natural gas is a fossil fuel used as a source of energy for heating, cooking, and electricity generation. It is also used as a fuel for vehicles and as a chemical feedstock in the manufacture of plastics and other commercially important organic chemicals. Fossil fuel based natural gas is a non-renewable resource.

Natural gas is found in deep underground rock formations or associated with other hydrocarbon reservoirs in coal beds and as methane clathrates. Petroleum is another resource and fossil fuel found in close proximity to and with natural gas. Most natural gas was created over time by two mechanisms: biogenic and thermogenic. Biogenic gas is created by methanogenic organisms in marshes, bogs, landfills, and shallow sediments. Deeper in the earth, at greater temperature and pressure, thermogenic gas is created from buried organic material.

In petroleum production gas is often burnt as flare gas. The World Bank estimates that over 150 cubic kilometers of natural gas are flared or vented annually. Before natural gas can be used as a fuel, most, but not all, must be processed to remove impurities, including water, to meet the specifications of marketable natural gas. The by-products of this processing include: ethane, propane, butanes, pentanes, and higher molecular weight hydrocarbons, hydrogen sulfide (which may be converted into pure sulfur), carbon dioxide, water vapor, and sometimes helium and nitrogen.

Natural gas is often informally referred to simply as "gas", especially when compared to other energy sources such as oil or coal. However, it is not to be confused with gasoline, especially in North America, where the term gasoline is often shortened in colloquial usage to "gas".

Natural gas was discovered accidentally in ancient China, as it resulted from the drilling for brines. Natural gas was first used by the Chinese in about 500 BC (possibly even 1000 BC). They discovered a way to transport gas seeping from the ground in crude pipelines of bamboo to where it was used to boil salt water to extract the salt, in the Ziliujing District of Sichuan. The world's first industrial extraction of natural gas started at Fredonia, New York, United States, in 1825. By 2009, 66 000 km³ (or 8%) had been used out of the total 850 000 km³ of estimated remaining recoverable reserves of natural gas. Based on an estimated 2015 world consumption rate of about 3400 km³ of gas per year, the total estimated remaining economically recoverable reserves of natural gas would last 250 years at current consumption rates. An annual increase in usage of 2–3% could result in currently recoverable reserves lasting significantly less, perhaps as few as 80 to 100 years.

In the 19th century, natural gas was usually obtained as a by-product of producing oil, since the small, light gas carbon chains came out of solution as the extracted fluids underwent pressure reduction from the reservoir to the surface, similar to uncapping a soft drink bottle where the carbon dioxide effervesces. Unwanted natural gas was a disposal problem in the active oil fields. If there was not a market for natural gas near the wellhead it was prohibitively expensive to pipe to the end user.

In the 19th century and early 20th century, unwanted gas was usually burned off at oil fields. Today, unwanted gas (or stranded gas without a market) associated with oil extraction often is returned to the reservoir with 'injection' wells while awaiting a possible future market or to repressurize the formation, which can enhance extraction rates from other wells. In regions with a high natural gas demand (such as the US), pipelines are constructed when it is economically feasible to transport gas from a wellsite to an end consumer.

In addition to transporting gas via pipelines for use in power generation, other end uses for natural gas include export as liquefied natural gas (LNG) or conversion of natural gas into other liquid products via gas to liquids (GTL) technologies. GTL technologies can convert natural gas into liquids products such as gasoline, diesel or jet fuel. A variety of GTL technologies have been developed, including Fischer–Tropsch (F–T), methanol to gasoline (MTG) and syngas to gasoline plus (STG+). F–T produces a synthetic crude that can be further refined into finished products, while MTG can produce synthetic gasoline from natural gas. STG+ can produce drop-in gasoline, diesel, jet fuel and aromatic chemicals directly from natural gas via a single-loop process. In 2011, Royal Dutch Shell's per day F–T plant went into operation in Qatar.

Natural gas can be "associated" (found in oil fields), or "non-associated" (isolated in natural gas fields), and is also found in coal beds (as coalbed methane). It sometimes contains a significant amount of ethane, propane, butane, and pentane—heavier hydrocarbons removed for commercial use prior to the methane being sold as a consumer fuel or chemical plant feedstock. Non-hydrocarbons such as carbon dioxide, nitrogen, helium (rarely), and hydrogen sulfide must also be removed before the natural gas can be transported.

Natural gas extracted from oil wells is called casinghead gas (whether or not truly produced up the annulus and through a casinghead outlet) or associated gas. The natural gas industry is extracting an increasing quantity of gas from challenging resource types: sour gas, tight gas, shale gas, and coalbed methane.

There is some disagreement on which country has the largest proven gas reserves. Sources that consider that Russia has by far the largest proven reserves include the US CIA (47 600 km³), the US Energy Information Administration (47 800 km³), and OPEC (48 700 km³). However, BP credits Russia with only 32 900 km³, which would place it in second place, slightly behind Iran (33 100 to 33 800 km³, depending on the source). With Gazprom, Russia is frequently the world's largest natural gas extractor. Major proven resources (in cubic kilometers) are world 187 300 (2013), Iran 33 600 (2013), Russia 32 900 (2013), Qatar 25 100 (2013), Turkmenistan 17 500 (2013) and the United States 8500 (2013).

It is estimated that there are about 900 000 km³ of "unconventional" gas such as shale gas, of which 180 000 km³ may be recoverable. In turn, many studies from MIT, Black & Veatch and the DOE predict that natural gas will account for a larger portion of electricity generation and heat in the future.

The world's largest gas field is the offshore South Pars / North Dome Gas-Condensate field, shared between Iran and Qatar. It is estimated to have of natural gas and of natural gas condensates.

Because natural gas is not a pure product, as the reservoir pressure drops when non-associated gas is extracted from a field under supercritical (pressure/temperature) conditions, the higher molecular weight components may partially condense upon isothermic depressurizing—an effect called retrograde condensation. The liquid thus formed may get trapped as the pores of the gas reservoir get depleted. One method to deal with this problem is to re-inject dried gas free of condensate to maintain the underground pressure and to allow re-evaporation and extraction of condensates. More frequently, the liquid condenses at the surface, and one of the tasks of the gas plant is to collect this condensate. The resulting liquid is called natural gas liquid (NGL) and has commercial value.

Shale gas is natural gas produced from shale. Because shale has matrix permeability too low to allow gas to flow in economical quantities, shale gas wells depend on fractures to allow the gas to flow. Early shale gas wells depended on natural fractures through which gas flowed; almost all shale gas wells today require fractures artificially created by hydraulic fracturing. Since 2000, shale gas has become a major source of natural gas in the United States and Canada. Because of increased shale gas production, the United States is now the number one natural gas producer in the world. Following the success in the United States, shale gas exploration is beginning in countries such as Poland, China, and South Africa.

Town gas is a flammable gaseous fuel made by the destructive distillation of coal. It contains a variety of calorific gases including hydrogen, carbon monoxide, methane, and other volatile hydrocarbons, together with small quantities of non-calorific gases such as carbon dioxide and nitrogen, and is used in a similar way to natural gas. This is a historical technology and is not usually economically competitive with other sources of fuel gas today.

Most town "gashouses" located in the eastern US in the late 19th and early 20th centuries were simple by-product coke ovens that heated bituminous coal in air-tight chambers. The gas driven off from the coal was collected and distributed through networks of pipes to residences and other buildings where it was used for cooking and lighting. (Gas heating did not come into widespread use until the last half of the 20th century.) The coal tar (or asphalt) that collected in the bottoms of the gashouse ovens was often used for roofing and other waterproofing purposes, and when mixed with sand and gravel was used for paving streets.

Methanogenic archaea are responsible for all biological sources of methane. Some live in symbiotic relationships with other life forms, including termites, ruminants, and cultivated crops. Other sources of methane, the principal component of natural gas, include landfill gas, biogas, and methane hydrate. When methane-rich gases are produced by the anaerobic decay of non-fossil organic matter (biomass), these are referred to as biogas (or natural biogas). Sources of biogas include swamps, marshes, and landfills, as well as agricultural waste materials such as sewage sludge and manure by way of anaerobic digesters, in addition to enteric fermentation, particularly in cattle. Landfill gas is created by decomposition of waste in landfill sites. Excluding water vapor, about half of landfill gas is methane and most of the rest is carbon dioxide, with small amounts of nitrogen, oxygen, and hydrogen, and variable trace amounts of hydrogen sulfide and siloxanes. If the gas is not removed, the pressure may get so high that it works its way to the surface, causing damage to the landfill structure, unpleasant odor, vegetation die-off, and an explosion hazard. The gas can be vented to the atmosphere, flared or burned to produce electricity or heat. Biogas can also be produced by separating organic materials from waste that otherwise goes to landfills. This method is more efficient than just capturing the landfill gas it produces. Anaerobic lagoons produce biogas from manure, while biogas reactors can be used for manure or plant parts. Like landfill gas, biogas is mostly methane and carbon dioxide, with small amounts of nitrogen, oxygen and hydrogen. However, with the exception of pesticides, there are usually lower levels of contaminants.

Landfill gas cannot be distributed through utility natural gas pipelines unless it is cleaned up to less than 3% , and a few parts per million , because and corrode the pipelines. The presence of will lower the energy level of the gas below requirements for the pipeline. Siloxanes in the gas will form deposits in gas burners and need to be removed prior to entry into any gas distribution or transmission system. Consequently, it may be more economical to burn the gas on site or within a short distance of the landfill using a dedicated pipeline. Water vapor is often removed, even if the gas is burned on site. If low temperatures condense water out of the gas, siloxanes can be lowered as well because they tend to condense out with the water vapor. Other non-methane components may also be removed to meet emission standards, to prevent fouling of the equipment or for environmental considerations. Co-firing landfill gas with natural gas improves combustion, which lowers emissions.

Biogas, and especially landfill gas, are already used in some areas, but their use could be greatly expanded. Experimental systems were being proposed for use in parts of Hertfordshire, UK, and Lyon in France. Using materials that would otherwise generate no income, or even cost money to get rid of, improves the profitability and energy balance of biogas production. Gas generated in sewage treatment plants is commonly used to generate electricity. For example, the Hyperion sewage plant in Los Angeles burns of gas per day to generate power New York City utilizes gas to run equipment in the sewage plants, to generate electricity, and in boilers. Using sewage gas to make electricity is not limited to large cities. The city of Bakersfield, California, uses cogeneration at its sewer plants. California has 242 sewage wastewater treatment plants, 74 of which have installed anaerobic digesters. The total biopower generation from the 74 plants is about 66 MW.

Huge quantities of natural gas (primarily methane) exist in the form of hydrates under sediment on offshore continental shelves and on land in arctic regions that experience permafrost, such as those in Siberia. Hydrates require a combination of high pressure and low temperature to form.

In 2010, the cost of extracting natural gas from crystallized natural gas was estimated to be as much as twice the cost of extracting natural gas from conventional sources, and even higher from offshore deposits.

In 2013, Japan Oil, Gas and Metals National Corporation (JOGMEC) announced that they had recovered commercially relevant quantities of natural gas from methane hydrate.

The image below is a schematic block flow diagram of a typical natural gas processing plant. It shows the various unit processes used to convert raw natural gas into sales gas pipelined to the end user markets.

The block flow diagram also shows how processing of the raw natural gas yields byproduct sulfur, byproduct ethane, and natural gas liquids (NGL) propane, butanes and natural gasoline (denoted as pentanes +).

Natural gas production in the US reached a peak in 1973, and went over a second lower peak in 2001, but recently has peaked again and is continuing to rise.

Because of its low density, it is not easy to store natural gas or to transport it by vehicle. Natural gas pipelines are impractical across oceans, since the gas needs to be cooled down and compressed, as the friction in the pipeline causes the gas to heat up. Many existing pipelines in America are close to reaching their capacity, prompting some politicians representing northern states to speak of potential shortages. The large trade cost implies that natural gas markets are globally much less integrated, causing significant price differences across countries. In Western Europe, the gas pipeline network is already dense. New pipelines are planned or under construction in Eastern Europe and between gas fields in Russia, Near East and Northern Africa and Western Europe. See also List of natural gas pipelines.

Whenever gas is bought or sold at custody transfer points, rules and agreements are made regarding the gas quality. These may include the maximum allowable concentration of , and . Usually sales quality gas that has been treated to remove contamination is traded on a "dry gas" basis and is required to be commercially free from objectionable odours, materials, and dust or other solid or liquid matter, waxes, gums and gum forming constituents, which might damage or adversely affect operation of equipment downstream of the custody transfer point.

LNG carriers transport liquefied natural gas (LNG) across oceans, while tank trucks can carry liquefied or compressed natural gas (CNG) over shorter distances. Sea transport using CNG carrier ships that are now under development may be competitive with LNG transport in specific conditions.

Gas is turned into liquid at a liquefaction plant, and is returned to gas form at regasification plant at the terminal. Shipborne regasification equipment is also used. LNG is the preferred form for long distance, high volume transportation of natural gas, whereas pipeline is preferred for transport for distances up to over land and approximately half that distance offshore.

CNG is transported at high pressure, typically above . Compressors and decompression equipment are less capital intensive and may be economical in smaller unit sizes than liquefaction/regasification plants. Natural gas trucks and carriers may transport natural gas directly to end-users, or to distribution points such as pipelines.

In the past, the natural gas which was recovered in the course of recovering petroleum could not be profitably sold, and was simply burned at the oil field in a process known as flaring. Flaring is now illegal in many countries. Additionally, higher demand in the last 20–30 years has made production of gas associated with oil economically viable. As a further option, the gas is now sometimes re-ed into the formation for enhanced oil recovery by pressure maintenance as well as miscible or immiscible flooding. Conservation, re-injection, or flaring of natural gas associated with oil is primarily dependent on proximity to markets (pipelines), and regulatory restrictions.

Natural gas can be indirectly exported through the absorption in other physical output. A recent study suggests that the expansion of shale gas production in the US has caused prices to drop relative to other countries. This has caused a boom in energy intensive manufacturing sector exports, whereby the average dollar unit of US manufacturing exports has almost tripled its energy content between 1996 and 2012.

A "master gas system" was invented in Saudi Arabia in the late 1970s, ending any necessity for flaring. Satellite observation, however, shows that flaring and venting are still practiced in some gas-extracting countries.

Natural gas is used to generate electricity and heat for desalination. Similarly, some landfills that also discharge methane gases have been set up to capture the methane and generate electricity.

Natural gas is often stored underground inside depleted gas reservoirs from previous gas wells, salt domes, or in tanks as liquefied natural gas. The gas is injected in a time of low demand and extracted when demand picks up. Storage nearby end users helps to meet volatile demands, but such storage may not always be practicable.

With 15 countries accounting for 84% of the worldwide extraction, access to natural gas has become an important issue in international politics, and countries vie for control of pipelines. In the first decade of the 21st century, Gazprom, the state-owned energy company in Russia, engaged in disputes with Ukraine and Belarus over the price of natural gas, which have created concerns that gas deliveries to parts of Europe could be cut off for political reasons. The United States is preparing to export natural gas.

Floating liquefied natural gas (FLNG) is an innovative technology designed to enable the development of offshore gas resources that would otherwise remain untapped due to environmental or economic factors it is nonviable to develop them via a land-based LNG operation. FLNG technology also provides a number of environmental and economic advantages:


Many gas and oil companies are considering the economic and environmental benefits of floating liquefied natural gas (FLNG). There are currently projects underway to construct five FLNG facilities. Petronas is close to completion on their FLNG-1 at Daewoo Shipbuilding and Marine Engineering and are underway on their FLNG-2 project at Samsung Heavy Industries. Shell Prelude is due to start production 2017. The Browse LNG project will commence FEED in 2019.

Natural gas is primarily used in the northern hemisphere. North America and Europe are major consumers.

Often well head gases require removal of various hydrocarbon molecules contained within the gas. Some of these gases include heptane, pentane, propane and other hydrocarbons with molecular weights above methane (). The natural gas transmission lines extend to the natural gas processing plant or unit which removes the higher molecular weighted hydrocarbons to produce natural gas with energy content between . The processed natural gas may then be used for residential, commercial and industrial uses.

Natural gas flowing in the distribution lines is called mid-stream natural gas and is often used to power engines which rotate compressors. These compressors are required in the transmission line to pressurize and re-pressurize the mid-stream natural gas as the gas travels. Typically, natural gas powered engines require natural gas to operate at the rotational name plate specifications. Several methods are used to remove these higher molecular weighted gases for use by the natural gas engine. A few technologies are as follows:


Natural gas is a major source of electricity generation through the use of cogeneration, gas turbines and steam turbines. Natural gas is also well suited for a combined use in association with renewable energy sources such as wind or solar and for alimenting peak-load power stations functioning in tandem with hydroelectric plants. Most grid peaking power plants and some off-grid engine-generators use natural gas. Particularly high efficiencies can be achieved through combining gas turbines with a steam turbine in combined cycle mode. Natural gas burns more cleanly than other fuels, such as oil and coal. Because burning natural gas produces both water and carbon dioxide, it produces less carbon dioxide per unit of energy released than coal, which produces mostly carbon dioxide. Burning natural gas produces only about half the carbon dioxide per kilowatt-hour (kWh) that coal does. For transportation, burning natural gas produces about 30% less carbon dioxide than burning petroleum. The US Energy Information Administration reports the following emissions in million metric tons of carbon dioxide in the world for 2012:


Coal-fired electric power generation emits around of carbon dioxide for every megawatt-hour (MWh) generated, which is almost double the carbon dioxide released by natural gas-fired generation. Because of this higher carbon efficiency of natural gas generation, as the fuel mix in the United States has changed to reduce coal and increase natural gas generation, carbon dioxide emissions have unexpectedly fallen. Those measured in the first quarter of 2012 were the lowest of any recorded for the first quarter of any year since 1992.

Combined cycle power generation using natural gas is currently the cleanest available source of power using hydrocarbon fuels, and this technology is widely and increasingly used as natural gas can be obtained at increasingly reasonable costs. Fuel cell technology may eventually provide cleaner options for converting natural gas into electricity, but as yet it is not price-competitive. Locally produced electricity and heat using natural gas powered Combined Heat and Power plant (CHP or Cogeneration plant) is considered energy efficient and a rapid way to cut carbon emissions.

Natural gas generated power has increased from 740 TWh in 1973 to 5140 TWh in 2014, generating 22% of the worlds total electricity. Approximately half as much as generated with coal. Efforts around the world to reduce the use of coal has led some regions to switch to natural gas.

Natural gas dispensed in a residential setting can generate temperatures in excess of making it a powerful domestic cooking and heating fuel. In much of the developed world it is supplied through pipes to homes, where it is used for many purposes including ranges and ovens, gas-heated clothes dryers, heating/cooling, and central heating. Heaters in homes and other buildings may include boilers, furnaces, and water heaters. Both North America and Europe are major consumers of natural gas.

Domestic appliances, furnaces, and boilers use low pressure, usually 6 to 7 inches of water (6" to 7" WC), which is about 0.25 psig. The pressures in the supply lines vary, either utilization pressure (UP, the aforementioned 6" to 7" WC) or elevated pressure (EP), which may be anywhere from 1 psig to 120 psig. Systems using EP have a regulator at the service entrance to step down the pressure to UP.

In the US compressed natural gas (CNG) is used in rural homes without connections to piped-in public utility services, or with portable grills. Natural gas is also supplied by independent natural gas suppliers through Natural Gas Choice programs throughout the United States. However, as CNG costs more than LPG (liquefied petroleum gas), LPG is the dominant source of rural gas.

CNG is a cleaner and also cheaper alternative to other automobile fuels such as gasoline (petrol) and diesel. By the end of 2014 there were over 20 million natural gas vehicles worldwide, led by Iran (3.5 million), China (3.3 million), Pakistan (2.8 million), Argentina (2.5 million), India (1.8 million), and Brazil (1.8 million). The energy efficiency is generally equal to that of gasoline engines, but lower compared with modern diesel engines. Gasoline/petrol vehicles converted to run on natural gas suffer because of the low compression ratio of their engines, resulting in a cropping of delivered power while running on natural gas (10%–15%). CNG-specific engines, however, use a higher compression ratio due to this fuel's higher octane number of 120–130.

Besides use in road vehicles, CNG can also be used in aircraft. Compressed natural gas has been used in some aircraft like the Aviat Aircraft Husky 200 CNG and the Chromarat VX-1 KittyHawk

LNG is also being used in aircraft. Russian aircraft manufacturer Tupolev for instance is running a development program to produce LNG- and hydrogen-powered aircraft. The program has been running since the mid-1970s, and seeks to develop LNG and hydrogen variants of the Tu-204 and Tu-334 passenger aircraft, and also the Tu-330 cargo aircraft. Depending on the current market price for jet fuel and LNG, fuel for an LNG-powered aircraft could cost 5,000 rubles (US$100) less per tonne, roughly 60%, with considerable reductions to carbon monoxide, hydrocarbon and nitrogen oxide emissions.

The advantages of liquid methane as a jet engine fuel are that it has more specific energy than the standard kerosene mixes do and that its low temperature can help cool the air which the engine compresses for greater volumetric efficiency, in effect replacing an intercooler. Alternatively, it can be used to lower the temperature of the exhaust.

Natural gas is a major feedstock for the production of ammonia, via the Haber process, for use in fertilizer production.

Natural gas can be used to produce hydrogen, with one common method being the hydrogen reformer. Hydrogen has many applications: it is a primary feedstock for the chemical industry, a hydrogenating agent, an important commodity for oil refineries, and the fuel source in hydrogen vehicles.

Protein rich animal and fish feed is produced by feeding natural gas to Methylococcus capsulatus bacteria on commercial scale.

Natural gas is also used in the manufacture of fabrics, glass, steel, plastics, paint, and other products.

Natural gas is mainly composed of methane. After release to the atmosphere it is removed by gradual oxidation to carbon dioxide and water by hydroxyl radicals () formed in the troposphere or stratosphere, giving the overall chemical reaction + 2 → + 2. While the lifetime of atmospheric methane is relatively short when compared to carbon dioxide, with a half-life of about 7 years, it is more efficient at trapping heat in the atmosphere, so that a given quantity of methane has 84 times the global-warming potential of carbon dioxide over a 20-year period and 28 times over a 100-year period. Natural gas is thus a more potent greenhouse gas than carbon dioxide due to the greater global-warming potential of methane. 2009 estimates by the EPA place global emissions of methane at annually, or 3% of global production, (2009 est). Direct emissions of methane represented 14.3% by volume of all global anthropogenic greenhouse gas emissions in 2004.

During extraction, storage, transportation, and distribution, natural gas is known to leak into the atmosphere, particularly during the extraction process. A Cornell University study in 2011 demonstrated that the leak rate of methane may be high enough to jeopardize its global warming advantage over coal. This study was criticized later for its over-estimation of methane leakage values. Preliminary results of some air sampling from airplanes done by the National Oceanic and Atmospheric Administration indicated higher-than-estimated methane releases by gas wells in some areas, but the overall results showed methane emissions in line with previous EPA estimates

Natural gas is often described as the cleanest fossil fuel. It produces 25%–30% and 40%–45% less carbon dioxide per joule delivered than oil and coal respectively, and potentially fewer pollutants than other hydrocarbon fuels. However, in absolute terms, it comprises a substantial percentage of human carbon emissions, and this contribution is projected to grow. According to the IPCC Fourth Assessment Report, in 2004, natural gas produced about 5.3 billion tons a year of emissions, while coal and oil produced 10.6 and 10.2 billion tons respectively. According to an updated version of the Special Report on Emissions Scenario by 2030, natural gas would be the source of 11 billion tons a year, with coal and oil now 8.4 and 17.2 billion respectively because demand is increasing 1.9% a year.

Natural gas produces far lower amounts of sulfur dioxide and nitrous oxides than other fossil fuels. The pollutants due to natural gas combustion are listed below:
Natural gas extraction also produces radioactive isotopes of polonium (Po-210), lead (Pb-210) and radon (Rn-220). Radon is a gas with initial activity from 5 to 200,000 becquerels per cubic meter of gas. It decays rapidly to Pb-210 which can build up as a thin film in gas extraction equipment.

Some gas fields yield sour gas containing hydrogen sulfide (). This untreated gas is toxic. Amine gas treating, an industrial scale process which removes acidic gaseous components, is often used to remove hydrogen sulfide from natural gas.

Extraction of natural gas (or oil) leads to decrease in pressure in the reservoir. Such decrease in pressure in turn may result in subsidence, sinking of the ground above. Subsidence may affect ecosystems, waterways, sewer and water supply systems, foundations, and so on.

Releasing natural gas from subsurface porous rock formations may be accomplished by a process called hydraulic fracturing or "fracking". It's estimated that hydraulic fracturing will eventually account for nearly 70% of natural gas development in North America. Since the first commercial hydraulic fracturing operation in 1949, approximately one million wells have been hydraulically fractured in the United States. The production of natural gas from hydraulically fractured wells has utilized the technological developments of directional and horizontal drilling, which improved access to natural gas in tight rock formations. Strong growth in the production of unconventional gas from hydraulically fractured wells occurred between 2000-2012.

In hydraulic fracturing, well operators force water mixed with a variety of chemicals through the wellbore casing into the rock. The high pressure water breaks up or "fracks" the rock, which releases gas from the rock formation. Sand and other particles are added to the water as a proppant to keep the fractures in the rock open, thus enabling the gas to flow into the casing and then to the surface. Chemicals are added to the fluid to perform such functions as reducing friction and inhibiting corrosion. After the "frack," oil or gas is extracted and 30–70% of the frack fluid, i.e. the mixture of water, chemicals, sand, etc., flows back to the surface. Many gas-bearing formations also contain water, which will flow up the wellbore to the surface along with the gas, in both hydraulically fractured and non-hydraulically fractured wells. This produced water often has a high content of salt and other dissolved minerals that occur in the formation.

The volume of water used to hydraulically fracture wells varies according to the hydraulic fracturing technique. In the United States, the average volume of water used per hydraulic fracture has been reported as nearly 7,375 gallons for vertical oil and gas wells prior to 1953, nearly 197,000 gallons for vertical oil and gas wells between 2000-2010, and nearly 3 million gallons for horizontal gas wells between 2000-2010.

Determining which fracking technique is appropriate for well productivity depends largely on the properties of the reservoir rock from which to extract oil or gas. If the rock is characterized by low-permeability — which refers to its ability to let substances, i.e. gas, pass through it, then the rock may be considered a source of tight gas. Fracking for shale gas, which is currently also known as a source of unconventional gas, involves drilling a borehole vertically until it reaches a lateral shale rock formation, at which point the drill turns to follow the rock for hundreds or thousands of feet horizontally. In contrast, conventional oil and gas sources are characterized by higher rock permeability, which naturally enables the flow of oil or gas into the wellbore with less intensive hydraulic fracturing techniques than the production of tight gas has required. The decades in development of drilling technology for conventional and unconventional oil and gas production has not only improved access to natural gas in low-permeability reservoir rocks, but also posed significant adverse impacts on environmental and public health.

The US EPA has acknowledged that toxic, carcinogenic chemicals, i.e. benzene and ethylbenzene, have been used as gelling agents in water and chemical mixtures for high volume horizontal fracturing (HVHF). Following the hydraulic fracture in HVHF, the water, chemicals, and frack fluid that return to the well's surface, called flowback or produced water, may contain radioactive materials, heavy metals, natural salts, and hydrocarbons which exist naturally in shale rock formations. Fracking chemicals, radioactive materials, heavy metals, and salts that are removed from the HVHF well by well operators are so difficult to remove from the water they're mixed with, and would so heavily pollute the water cycle, that most of the flowback is either recycled into other fracking operations or injected into deep underground wells, eliminating the water that HVHF required from the hydrologic cycle.

In order to assist in detecting leaks, an odorizer is added to the otherwise colorless and almost odorless gas used by consumers. The odor has been compared to the smell of rotten eggs, due to the added tert-Butylthiol (t-butyl mercaptan). Sometimes a related compound, thiophane, may be used in the mixture. Situations in which an odorant that is added to natural gas can be detected by analytical instrumentation, but cannot be properly detected by an observer with a normal sense of smell, have occurred in the natural gas industry. This is caused by odor masking, when one odorant overpowers the sensation of another. As of 2011, the industry is conducting research on the causes of odor masking.

Explosions caused by natural gas leaks occur a few times each year. Individual homes, small businesses and other structures are most frequently affected when an internal leak builds up gas inside the structure. Frequently, the blast is powerful enough to significantly damage a building but leave it standing. In these cases, the people inside tend to have minor to moderate injuries. Occasionally, the gas can collect in high enough quantities to cause a deadly explosion, disintegrating one or more buildings in the process. The gas usually dissipates readily outdoors, but can sometimes collect in dangerous quantities if flow rates are high enough. However, considering the tens of millions of structures that use the fuel, the individual risk of using natural gas is very low.

Natural gas heating systems may cause carbon monoxide poisoning if unvented or poorly vented. In 2011, natural gas furnaces, space heaters, water heaters and stoves were blamed for 11 carbon monoxide deaths in the US. Another 22 deaths were attributed to appliances running on liquified petroleum gas, and 17 deaths on gas of unspecified type. Improvements in natural gas furnace designs have greatly reduced CO poisoning concerns. Detectors are also available that warn of carbon monoxide and/or explosive gas (methane, propane, etc.).

Quantities of natural gas are measured in normal cubic meters (cubic meter of gas at "normal" temperature and pressure ) or standard cubic feet (cubic foot of gas at "standard" temperature and pressure ), . The gross heat of combustion of commercial quality natural gas is around , but this can vary by several percent. This is about (assuming a density of , an approximate value).

Gas prices for end users vary greatly across the EU. A single European energy market, one of the key objectives of the EU, should level the prices of gas in all EU member states. Moreover, it would help to resolve supply and global warming issues, as well as strengthen relations with other Mediterranean countries and foster investments in the region.

In US units, of natural gas produces around . The actual heating value when the water formed does not condense is the net heat of combustion and can be as much as 10% less.

In the United States, retail sales are often in units of therms (th); 1 therm = 100,000 BTU. Gas sales to domestic consumers are often in units of 100 standard cubic feet (scf). Gas meters measure the volume of gas used, and this is converted to therms by multiplying the volume by the energy content of the gas used during that period, which varies slightly over time. The typical annual consumption of a single family residence is 1,000 therms or one Residential Customer Equivalent (RCE). Wholesale transactions are generally done in decatherms (Dth), thousand decatherms (MDth), or million decatherms (MMDth). A million decatherms is a trillion BTU, roughly a billion cubic feet of natural gas.

The price of natural gas varies greatly depending on location and type of consumer. In 2007, a price of $7 per 1000 cubic feet () was typical in the United States. The typical caloric value of natural gas is roughly 1,000 BTU per cubic foot, depending on gas composition. This corresponds to around $7 per million BTU or around $7 per gigajoule (GJ). In April 2008, the wholesale price was $10 per 1000 cubic feet ($10/MMBTU). The residential price varies from 50% to 300% more than the wholesale price. At the end of 2007, this was $12–$16 per 1000 cubic feet (). Natural gas in the United States is traded as a futures contract on the New York Mercantile Exchange. Each contract is for 10,000 MMBTU or . Thus, if the price of gas is $10/MMBTU on the NYMEX, the contract is worth $100,000.

Canada uses metric measure for internal trade of petrochemical products. Consequently, natural gas is sold by the gigajoule (GJ), cubic meter (m) or thousand cubic meters (E3m3). Distribution infrastructure and meters almost always meter volume (cubic foot or cubic meter). Some jurisdictions, such as Saskatchewan, sell gas by volume only. Other jurisdictions, such as Alberta, gas is sold by the energy content (GJ). In these areas, almost all meters for residential and small commercial customers measure volume (m or ft), and billing statements include a multiplier to convert the volume to energy content of the local gas supply.

A gigajoule (GJ) is a measure approximately equal to half a barrel (250 lbs) of oil, or 1 million BTUs, or of gas. The energy content of gas supply in Canada can vary from depending on gas supply and processing between the wellhead and the customer.

In the rest of the world, natural gas is sold in gigajoule retail units. LNG (liquefied natural gas) and LPG (liquefied petroleum gas) are traded in metric tonnes (1,000 kg) or MMBTU as spot deliveries. Long term natural gas distribution contracts are signed in cubic meters, and LNG contracts are in metric tonnes. The LNG and LPG is transported by specialized transport ships, as the gas is liquified at cryogenic temperatures. The specification of each LNG/LPG cargo will usually contain the energy content, but this information is in general not available to the public.

In the Russian Federation, Gazprom sold approximately of natural gas in 2008. In 2013 they produced of natural and associated gas. Gazprom supplied Europe with of gas in 2013.

In August 2015, possibly the largest natural gas discovery in history was made and notified by an Italian gas company ENI. The energy company indicated that it has unearthed a "supergiant" gas field in the Mediterranean Sea covering about . It was also reported that the gas field could hold a potential of natural gas. ENI said that the energy is about. The field was found in the deep waters off the northern coast of Egypt and ENI claims that it will be the largest ever in the Mediterranean and even the world.

Research conducted by the suggests that large US and Canadian pension funds and Asian and MENA area SWF investors have become particularly active in the fields of natural gas and natural gas infrastructure, a trend started in 2005 by the formation of Scotia Gas Networks in the UK by OMERS and Ontario Teachers' Pension Plan.

Another way to store natural gas is adsorbing it to the porous solids called sorbents. The best condition for methane storage is at room temperature and atmospheric pressure. The used pressure can be up to 4 MPa (about 40 times atmospheric pressure) for having more storage capacity. The most common sorbent used for ANG is activated carbon (AC). Three main types of activated carbons for ANG are: Activated Carbon Fiber (ACF), Powdered Activated Carbon (PAC), activated carbon monolith.


General:



</doc>
<doc id="22133" url="https://en.wikipedia.org/wiki?curid=22133" title="Nuclear chain reaction">
Nuclear chain reaction

A nuclear chain reaction occurs when one single nuclear reaction causes an average of one or more subsequent nuclear reactions, thus leading to the possibility of a self-propagating series of these reactions. The specific nuclear reaction may be the fission of heavy isotopes (e.g., uranium-235, U). The nuclear chain reaction releases several million times more energy per reaction than any chemical reaction.

Chemical chain reactions were first proposed by German chemist Max Bodenstein in 1913, and were reasonably well understood before nuclear chain reactions were proposed. It was understood that chemical chain reactions were responsible for exponentially increasing rates in reactions, such as produced in chemical explosions.

The concept of a nuclear chain reaction was reportedly first hypothesized by Hungarian scientist Leó Szilárd on September 12, 1933. The neutron had been discovered in 1932, shortly before. Szilárd realized that if a nuclear reaction produced neutrons, which then caused further nuclear reactions, the process might be self-perpetuating. Szilárd, however, did not propose fission as the mechanism for his chain reaction, since the fission reaction was not yet discovered or even suspected. Instead, Szilárd proposed using mixtures of lighter known isotopes which produced neutrons in copious amounts. He filed a patent for his idea of a simple nuclear reactor the following year.

In 1936, Szilárd attempted to create a chain reaction using beryllium and indium, but was unsuccessful. Nuclear fission was discovered and proved by Otto Hahn and Fritz Strassmann in December 1938. A few months later, Frédéric Joliot, H. Von Halban and L. Kowarski in Paris searched for, and discovered, neutron multiplication in uranium, proving that a nuclear chain reaction by this mechanism was indeed possible.

On May 4, 1939 Joliot, Halban et Kowarski filed three patents. The first two described power production from a nuclear chain reaction, the last one called ""Perfectionnement aux charges explosives"" was the first patent for the atomic bomb and is filed as patent n°445686 by the Caisse nationale de Recherche Scientifique.

In parallel, Szilárd and Enrico Fermi in New York made the same analysis. This discovery prompted the letter from Szilárd and signed by Albert Einstein to President Franklin D. Roosevelt, warning of the possibility that Nazi Germany might be attempting to build an atomic bomb.

On December 2, 1942, a team led by Enrico Fermi produced the first artificial self-sustaining nuclear chain reaction with the Chicago Pile-1 (CP-1) experimental reactor in a racquets court below the bleachers of Stagg Field at the University of Chicago. Fermi's experiments at the University of Chicago were part of Arthur H. Compton's Metallurgical Laboratory of the Manhattan Project; the lab was later renamed Argonne National Laboratory, and tasked with conducting research in harnessing fission for nuclear energy.

In 1956, Paul Kuroda of the University of Arkansas postulated that a natural fission reactor may have once existed. Since nuclear chain reactions only require natural materials (such as water and uranium), it is possible to have these chain reactions occur where there is the right combination of materials within the Earth's crust. Kuroda's prediction was verified with the discovery of evidence of natural self-sustaining nuclear chain reactions in the past at Oklo in Gabon, Africa, in September 1972.

Fission chain reactions occur because of interactions between neutrons and fissile isotopes (such as U). The chain reaction requires both the release of neutrons from fissile isotopes undergoing nuclear fission and the subsequent absorption of some of these neutrons in fissile isotopes. When an atom undergoes nuclear fission, a few neutrons (the exact number depends on several factors) are ejected from the reaction. These free neutrons will then interact with the surrounding medium, and if more fissile fuel is present, some may be absorbed and cause more fissions. Thus, the cycle repeats to give a reaction that is self-sustaining.

Nuclear power plants operate by precisely controlling the rate at which nuclear reactions occur, and that control is maintained through the use of several redundant layers of safety measures. Moreover, the materials in a nuclear reactor core and the uranium enrichment level make a nuclear explosion impossible, even if all safety measures failed. On the other hand, nuclear weapons are specifically engineered to produce a reaction that is so fast and intense it cannot be controlled after it has started. When properly designed, this uncontrolled reaction can lead to an explosive energy release.

Nuclear weapons employ high quality, highly enriched fuel exceeding the critical size and geometry (critical mass) necessary in order to obtain an explosive chain reaction. The fuel for energy purposes, such as in a nuclear fission reactor, is very different, usually consisting of a low-enriched oxide material (e.g. UO).

When a heavy atom undergoes nuclear fission, it breaks into two or more fission fragments. Also, several free neutrons, gamma rays, and neutrinos are emitted, and a large amount of energy is released. The sum of the rest masses of the fission fragments and ejected neutrons is less than the sum of the rest masses of the original atom and incident neutron (of course the fission fragments are not at rest). The mass difference is accounted for in the release of energy according to the equation "E"=Δ"mc":

Due to the extremely large value of the speed of light, "c", a small decrease in mass is associated with a tremendous release of active energy (for example, the kinetic energy of the fission fragments). This energy (in the form of radiation and heat) carries the missing mass, when it leaves the reaction system (total mass, like total energy, is always conserved). While typical chemical reactions release energies on the order of a few eVs (e.g. the binding energy of the electron to hydrogen is 13.6 eV), nuclear fission reactions typically release energies on the order of hundreds of millions of eVs.

Two typical fission reactions are shown below with average values of energy released and number of neutrons ejected:

Note that these equations are for fissions caused by slow-moving (thermal) neutrons. The average energy released and number of neutrons ejected is a function of the incident neutron speed. Also, note that these equations exclude energy from neutrinos since these subatomic particles are extremely non-reactive and, therefore, rarely deposit their energy in the system.

The prompt neutron lifetime, "l", is the average time between the emission of neutrons and either their absorption in the system or their escape from the system. The neutrons that occur directly from fission are called "prompt neutrons," and the ones that are a result of radioactive decay of fission fragments are called "delayed neutrons." The term lifetime is used because the emission of a neutron is often considered its "birth," and the subsequent absorption is considered its "death." For thermal (slow-neutron) fission reactors, the typical prompt neutron lifetime is on the order of 10 seconds, and for fast fission reactors, the prompt neutron lifetime is on the order of 10 seconds. These extremely short lifetimes mean that in 1 second, 10,000 to 10,000,000 neutron lifetimes can pass. The "average" (also referred to as the "adjoint unweighted") prompt neutron lifetime takes into account all prompt neutrons regardless of their importance in the reactor core; the "effective" prompt neutron lifetime (referred to as the "adjoint weighted" over space, energy, and angle) refers to a neutron with average importance.

The mean generation time, Λ, is the average time from a neutron emission to a capture that results in fission. The mean generation time is different from the prompt neutron lifetime because the mean generation time only includes neutron absorptions that lead to fission reactions (not other absorption reactions). The two times are related by the following formula:

In this formula, k is the effective neutron multiplication factor, described below.

The effective neutron multiplication factor, "k", is the average number of neutrons from one fission that cause another fission. The remaining neutrons either are absorbed in non-fission reactions or leave the system without being absorbed. The value of "k" determines how a nuclear chain reaction proceeds:
When describing kinetics and dynamics of nuclear reactors, and also in the practice of reactor operation, the concept of reactivity is used, which characterizes the deflection of reactor from the critical state. ρ=(k-1)/k. InHour is a unit of reactivity of a nuclear reactor.

In a nuclear reactor, "k" will actually oscillate from slightly less than 1 to slightly more than 1, due primarily to thermal effects (as more power is produced, the fuel rods warm and thus expand, lowering their capture ratio, and thus driving "k" lower). This leaves the average value of "k" at exactly 1. Delayed neutrons play an important role in the timing of these oscillations.

In an infinite medium, the multiplication factor may be described by the four factor formula; in a non-infinite medium, the multiplication factor may be described by the six factor formula.

Not all neutrons are emitted as a direct product of fission; some are instead due to the radioactive decay of some of the fission fragments. The neutrons that occur directly from fission are called "prompt neutrons," and the ones that are a result of radioactive decay of fission fragments are called "delayed neutrons." The fraction of neutrons that are delayed is called β, and this fraction is typically less than 1% of all the neutrons in the chain reaction.

The delayed neutrons allow a nuclear reactor to respond several orders of magnitude more slowly than just prompt neutrons would alone. Without delayed neutrons, changes in reaction rates in nuclear reactors would occur at speeds that are too fast for humans to control.

The region of supercriticality between k = 1 and k = 1/(1-β) is known as delayed supercriticality (or delayed criticality). It is in this region that all nuclear power reactors operate. The region of supercriticality for k > 1/(1-β) is known as prompt supercriticality (or prompt criticality), which is the region in which nuclear weapons operate.

The change in k needed to go from critical to prompt critical is defined as a dollar.

Nuclear fission weapons require a mass of fissile fuel that is prompt supercritical.

For a given mass of fissile material the value of k can be increased by increasing the density. Since the probability per distance traveled for a neutron to collide with a nucleus is proportional to the material density, increasing the density of a fissile material can increase k. This concept is utilized in the implosion method for nuclear weapons. In these devices, the nuclear chain reaction begins after increasing the density of the fissile material with a conventional explosive.

In the gun-type fission weapon two subcritical pieces of fuel are rapidly brought together. The value of k for a combination of two masses is always greater than that of its components. The magnitude of the difference depends on distance, as well as the physical orientation.

The value of k can also be increased by using a neutron reflector surrounding the fissile material

Once the mass of fuel is prompt supercritical, the power increases exponentially. However, the exponential power increase cannot continue for long since k decreases when the amount of fission material that is left decreases (i.e. it is consumed by fissions). Also, the geometry and density are expected to change during detonation since the remaining fission material is torn apart from the explosion.

Detonation of a nuclear weapon involves bringing fissile material into its optimal supercritical state very rapidly. During part of this process, the assembly is supercritical, but not yet in an optimal state for a chain reaction. Free neutrons, in particular from spontaneous fissions, can cause the device to undergo a preliminary chain reaction that destroys the fissile material before it is ready to produce a large explosion, which is known as predetonation. To keep the probability of predetonation low, the duration of the non-optimal assembly period is minimized and fissile and other materials are used which have low spontaneous fission rates. In fact, the combination of materials has to be such that it is unlikely that there is even a single spontaneous fission during the period of supercritical assembly. In particular, the gun method cannot be used with plutonium (see nuclear weapon design).

Chain reactions naturally give rise to reaction rates that grow (or shrink) exponentially, whereas a nuclear power reactor needs to be able to hold the reaction rate reasonably constant. To maintain this control, the chain reaction criticality must have a slow enough time-scale to permit intervention by additional effects (e.g., mechanical control rods or thermal expansion). Consequently, all nuclear power reactors (even fast-neutron reactors) rely on delayed neutrons for their criticality. An operating nuclear power reactor fluctuates between being slightly subcritical and slightly delayed-supercritical, but must always remain below prompt-critical.

It is impossible for a nuclear power plant to undergo a nuclear chain reaction that results in an explosion of power comparable with a nuclear weapon, but even low-powered explosions due to uncontrolled chain reactions, that would be considered "fizzles" in a bomb, may still cause considerable damage and meltdown in a reactor. For example, the Chernobyl disaster involved a runaway chain reaction but the result was a low-powered steam explosion from the relatively small release of heat, as compared with a bomb. However, the reactor complex was destroyed by the heat, as well as by ordinary burning of the graphite exposed to air. Such steam explosions would be typical of the very diffuse assembly of materials in a nuclear reactor, even under the worst conditions.

In addition, other steps can be taken for safety. For example, power plants licensed in the United States require a negative void coefficient of reactivity (this means that if water is removed from the reactor core, the nuclear reaction will tend to shut down, not increase). This eliminates the possibility of the type of accident that occurred at Chernobyl (which was due to a positive void coefficient). However, nuclear reactors are still capable of causing smaller explosions even after complete shutdown, such as was the case of the Fukushima Daiichi nuclear disaster. In such cases, residual decay heat from the core may cause high temperatures if there is loss of coolant flow, even a day after the chain reaction has been shut down (see SCRAM). This may cause a chemical reaction between water and fuel that produces hydrogen gas which can explode after mixing with air, with severe contamination consequences, since fuel rod material may still be exposed to the atmosphere from this process. However, such explosions do not happen during a chain reaction, but rather as a result of energy from radioactive beta decay, after the fission chain reaction has been stopped.




</doc>
<doc id="22135" url="https://en.wikipedia.org/wiki?curid=22135" title="Nichiren">
Nichiren

Nichiren (日蓮; 16 February 1222 – 13 October 1282), born as , was a Japanese Buddhist priest who lived during the Kamakura period (1185–1333).

Nichiren is known for his sole devotion to the "Lotus Sutra", asserting that it was Shakyamuni Buddha's ultimate teachings and was the exclusive method to attain enlightenment. He believed that the Lotus Sutra contained the essence of all of Shakyamuni Buddha's teachings related to the laws of causality, karma, without any distinction to enlightenment. His interpretation of the Lotus Sutra centers on the emphasis of its 16th chapter, "The Life Span of the Thus Come One", where he asserts his revelation that the chanting of Nam Myōhō Renge Kyō is the superior practice of today's age of "Mappō".

Nichiren strongly proposed the chanting of Nam Myōhō Renge Kyō by attributing the natural and social calamities of his time to his claim that the Pure Land, Zen, Shingon, Ritsu, and Tendai schools were unable to supernaturally protect Japan. Ultimately, Nichiren drew the anger of Japan's ruling Hōjō clan when his two Lotus Sutra-based predictions of foreign invasion and political strife were seemingly actualized by the Mongol invasions of Japan and an attempted coup within the Hōjō clan. The religious remonstration in which he made the prediction "Risshō Ankoku Ron" () ("On Establishing the Correct Teaching for the Security of the Land") is considered by Japanese historians to be a literary classic illustrating the apprehensions of that period, while in 1358 get awarded as "Risshō Daishi" () ("Great Teacher of Rectification") by Nichiren's disciples.

While all Nichiren Buddhist schools regard him as a reincarnation of the Visistacaritra or "Jōgyō" (), the lineage of disciples had proclaim Nichiren as the "Original Buddha" (本仏: Hombutsu) from infinite aeons ago, addressing him as the title of "True Buddha", "Latter Day of the Law" as taught the Three Ages of Buddhism.

Today, Nichiren Buddhism includes traditional schools such as the Nichiren Shū confederation of schools and Nichiren Shōshū, and modern lay movements such Kenshokai, Shoshinkai, Risshō Kōsei Kai, Honmon Butsuryū Shū, Kempon Hokke, and Soka Gakkai various others each claiming their own interpretations of Nichiren's teachings.

According to the Chinese lunar calendar, Nichiren was born on 27th of 1st month in year 1222 which is translated to 16 February on Gregorian solar calendar. A mistaken date sometimes used on 6 April or 30 March, when Tiantai time then was born on lunar calendar date 16th of 2st month in the Chinese 24th solar terms to calculate and conversion the Gregorian calendar.

Nichiren was born in the village of Kominato (today part of the city of Kamogawa), Nagase District, Awa Province (within present-day Chiba Prefecture). Nichiren's father, a fisherman, was Mikuni-no-Tayu Shigetada, also known as Nukina Shigetada Jiro (d. 1258) and his mother was Umegiku-nyo (d. 1267). On his birth, his parents named him which has variously been translated into English as "Splendid Sun" and "Virtuous Sun Boy" among others. The exact site of Nichiren's birth is believed to be submerged off the shore from present-day Kominato-zan Tanjō-ji (小湊山　誕生寺), a temple in Kominato that commemorates Nichiren's birth.

Nichiren stated that he was "the son of a chandala family who lived near the sea in Tojo in Awa Province, in the remote countryside of the eastern part of Japan".

In a letter dated the 6th day of the 9th month of the Kōan Era (1271), Nichiren writes to a disciple, looking back on his life:

Nichiren began his Buddhist study at a nearby temple of the Tendai school, Seichō-ji (清澄寺, also called Kiyosumi-dera), at twelve years old. He was formally ordained at sixteen years old and took the Buddhist name where "Renchō" means "Lotus Growth". He left Seichō-ji shortly thereafter to study in Kamakura and several years later traveled to western Japan for more in-depth study in the Kyoto and Nara area, where Japan's major centers of Buddhist learning were located. In 1233 he went to Kamakura, where he studied Pure Land Buddhism, a pious school that stressed salvation through the invocation of Amitābha (Japanese "Amida"), the Buddha of infinite compassion, under the guidance of a renowned master.

After having persuaded himself that devotion to Amitabha Buddha was not the true Buddhist doctrine, he passed to the study of Zen, which had become popular in Kamakura and Kyōto. He then went to Mount Hiei, the cradle of Tendai, where he felt the original purity of the Tendai doctrine corrupted by the introduction and acceptance of other doctrines, especially Amidism and esoteric Buddhism. To eliminate any possible doubts, Nichiren decided to spend some time at Mount Kōya, the centre of Shingon Buddhism, and also in Nara, Japan's ancient capital, where he studied the Risshū, which emphasized strict adherence to the Vinaya, the code of monastic discipline and ordination. During this time, he became convinced of the pre-eminence of the "Lotus Sutra" and in 1253, returned to Seichō-ji.

On 28 April 1253, he expounded the public declaration of Nam Myōhō Renge Kyō for the first time. With this, he proclaimed that Buddhist devotion as the correct form of Buddhism for the current time. At the same time he changed his name to own Buddhist name to "Nichiren", a portmanteau of "Nichi" (日) English: "Sun" and "Ren" (蓮) meaning "Lotus". He later explained this choice was rooted in passages from the "Lotus Sutra".

This declaration marked by all schools of Nichiren Buddhism to their cornerstone of foundation (立宗: "Risshū"). Nichiren began propagating his teachings in Kamakura, Kanagawa, the capital of Japan at the time due to the Shikken or regent and the "shōgun" himself lived and the government was established. He gained followers there consisting of both priests and laity, which several were from among the samurai class.

Devotees claim that in 1253, Nichiren predicted the Mongol invasions of Japan: a prediction which was validated in 1274. Nichiren viewed his teachings as a method of efficaciously preventing this and other disasters: that the best countermeasure to these disasters were the rejection of all Buddhist practices and singularly practice the chanting of Nam Myōhō Renge Kyō as he prescribed.

Nichiren then engaged in writing his various works including his : "Treatise On Establishing the Correct Teaching for the Peace of the Land", his first major treatise and the first of three remonstrations with government authorities. He felt that it was imperative for:

Nichiren claims that this is the "true and correct form of Buddhism", with regarding the Lotus Sutra as the fullest expression of the Shakyamuni Buddha's teachings and putting them into practice. Nichiren thought this could be achieved in Japan by withdrawing lay support so that the other disciples which he viewed as corrupt would be forced to change their ways or revert to laymen to prevent starving.

Based on apocalyptic prophecies cited in several Buddhist sutras, Nichiren attributed the occurrence of the famines, disease, and natural disasters (especially drought, typhoons, and earthquakes) of his day to claims that the expired teachings of Buddhism were no longer appropriate for the time.

Nichiren submitted his treatise in 16 July 1260 to "Hojo Tokiyori", the acting regent of the Kamakura shogunate. Though it drew no official response, it prompted a severe backlash from the Buddhist priests of other schools. As a result, Nichiren was frequently harassed causing him to constantly change dwellings.

As punishment, Nichiren was exiled to the Izu Peninsula in 1261, and pardoned in 1263. He was ambushed and nearly killed at Komatsubara in Awa Province in November 1264 by military forces led by Lord Tōjō Kagenobu.

After one exchange with the influential Shingon priest, Ninshō Ryōkan (良観), Nichiren was summoned for questioning by the Japanese authorities in September 1271. He used this as an opportunity to make his second government remonstration, this time to the police officer, Hei no Saemon (平の左衛門, also called 平頼綱: Taira no Yoritsuna) who summoned him to the court.

Two days later, on September 12, Hei no Saemon and a group of soldiers abducted Nichiren from his hut at Matsubagayatsu, Kamakura with the intent to arrest and behead him. He was brought to the Tatsunukuchi beach for execution. According to Nichiren's account, an astronomical phenomenon — "a brilliant orb as bright as the moon" — over the seaside Tatsunokuchi execution grounds terrified Nichiren's executioners into inaction. The incident is known as the Tatsunokuchi Persecution and regarded as a turning point in Nichiren's lifetime called "Hosshaku kenpon" (発迹顕本), translated as "casting off the transient and revealing the true", or "Outgrowing the provisional and revealing the essential".

Unsure of what to do with Nichiren, Hei no Saemon decided to banish him to Sado, Niigata island in the Sea of Japan known for its particularly severe winters where exilers do not survive.

This second exile lasted for three years caused him poor health, which later represented one of the most important and productive segments of his life. While on Sado, he won many devoted converts and wrote two of his most important doctrinal treatises, the "Kaimoku Shō" (開目抄: "On the Opening of the Eyes") and the "Kanjin no Honzon Shō" (観心本尊抄: "The Object of Devotion for Observing the Mind") as well as numerous letters and minor treatises whose content containing critical components of his teaching.

During his 1272 exile on Sado island, Nichiren inscribed the first "Gohonzon" (). He inscribed several during the course of many years. In addition, more than a hundred Gohonzon images preserved today are attributed to Nichiren, of which several are prominently retained by the Mount Minobu Sect in Yamanashi Prefecture also known as Nichiren Shu.

Hokkeko believers claim that on 12 October 1279 he inscribed the "Dai Gohonzon" for all humanity after the execution of the three "Atsuhara" farmers. The Dai-Gohonzon is enshrined currently at the "Tahō Fuji Dai-Nichirenge-Zan Taiseki-ji", informally known as the "Head Temple Taiseki-ji" of the Nichiren Shōshū Order of Buddhism, located at the foot of Mount Fuji in Fujinomiya, Shizuoka Prefecture, Japan.

Nichiren was pardoned in February 1274 and returned to Kamakura city in late March. He was again interviewed by Hei no Saemon, who became interested in Nichiren's prediction of an invasion by the Mongols. Mongol messengers demanding Japan's fealty had frightened the authorities into believing that Nichiren's prophecy of foreign invasion would materialize (which it later did in October of that year; see Mongol invasions of Japan). Nichiren, however, used the audience as yet another opportunity to remonstrate with the government.

With the exception of a few short journeys, Nichiren spent the rest of his life at Minobu, where he and his disciples completed the Myō-hōkke-in Kuon-ji Temple (久遠寺) in 1281, and he continued writing and training his disciples. Two of his works from this period are the "Senji Shō" (撰時抄: "The Selection of the Time") and the "Hōon Shō" (報恩抄: "On Repaying Debts of Gratitude"), which, along with his "Risshō Ankoku Ron" (立正安国論: "On Establishing the Correct Teaching for the Peace of the Land"), "Kaimoku Shō" ("The Opening of the Eyes"), and "Kanjin no Honzon Shō" ("The Object of Devotion for Observing the Mind"), constitute his Five Major Writings. He also inscribed numerous Gohonzon for bestowal upon specific disciples and lay believers.

Many of these survive today in the repositories of Nichiren temples such as Taiseki-ji (大石寺) in Fujinomiya, Shizuoka, which has a particularly large collection of scrolls that is publicly aired once a year, along with the dusting of the Dai-Gohonzon ("O-mushibarai ceremony") by the High Priest of Nichiren Shoshu in April, as well as the public exposure of the statue of the master in both Mieido and Hoando buildings in November.

Nichiren spent his final years writing, inscribing Gohonzon for his disciples and believers, and delivering sermons. In failing health, he was encouraged to travel to hot springs for their medicinal benefits. He left Minobu in the company of several disciples on September 8, 1282.

On 13 October 1282, Nichiren died in the presence of many disciples and lay believers. His funeral and cremation took place the following day. His disciples left Ikegami with Nichiren's ashes on October 21, reaching Minobu on October 25. Nichiren's original tomb is sited, as per his request, at Kuon-ji on Mount Minobu while Nichiren Shoshu claims that his disciples, the Chief Priest of Kuon-Ji temple consequently brought his ashes along with his other articles to Mount Fuji, where they are now enshrined on the left side next to the Dai Gohonzon within the "Hoando" storage house. 

Nichiren attributed the turmoils and disasters in society to his personal claim that the Buddhist teachings his time, including the Tendai sect in which he was ordained:

Accordingly, the Kamakura period of 13th century Japan in which Nichiren was born was characterised by natural disasters, internal strife and political conflict that he attributed to the third age of Buddhism.

At age 32, Nichiren began to denounce all Mahayana Buddhist schools of his time and by declaring the correct teaching as the Universal Dharma (Nam-Myōhō-Renge-Kyō) and chanting its words as the only path for both personal and social salvation.

At the age of 51, Nichiren ultimately inscribed his own gohonzon, the object of veneration or worship in his own Buddhism, the Gohonzon,""never before known"" as he described it.

Other contributions of Nichiren to Buddhism were the teaching of "The Five Guides of Propagation", The doctrine of the Three Great Secret Dharmas and the teaching of The Three Proofs for verification of the validity of Buddhist doctrines. There is a difference between Nichiren teachings and almost all schools of Mahayana Buddhism regarding the understanding of the Latter day of the Law, Mappō. Nichiren believed that the teachings of the Lotus Sutra will flourish for all eternity, and the disciples on Earth will propagate Buddhism in the future.

Nichiren criticized other Buddhist schools for what he viewed as manipulations of the populace for both political and religious control. Citing various Buddhist sutras and commentaries, Nichiren claimed and argued that these Buddhist schools were distorting the religious teachings for their own gain. Furthermore, he stated in his : "Treatise On Establishing the Correct Teaching for the Peace of the Land", his first major treatise and the first of three remonstrations with government authorities.

After Nichiren's death, his teachings were interpreted in different ways. As a result, Nichiren Buddhism encompasses several major branches and schools, each with its own doctrine and set of interpretations of Nichiren's teachings.

Many of Nichiren's writings still exist in his original handwriting, both some as complete writings and some as remaining fragments. Other documents survive as copies made by his immediate disciples. Nichiren's existing works number over 700 manuscripts in total, including transcriptions of orally delivered lectures, letters of remonstration and illustrations.

Today's Nichiren schools widely disagree which of his writings can be deemed authentic and which are apocryphal. Nichiren declared that women could attain enlightenment, therefore a great number of letters were addressed to female believers. Some schools within Nichiren Buddhism consider this to be a unique feature of Nichiren's teachings and have published separate volumes of those writings.

In addition to treatises written in formal "kanbun" (漢文) Classical Chinese, Nichiren also wrote expositories and letters to disciples and lay followers in mixed-kanji–kana vernacular as well as letters in simple kana for believers who could not read the more-formal styles, particularly children.

Some of Nichiren's "kanbun" works, especially the "Risshō Ankoku Ron", are considered exemplary of the "kanbun" style, while many of his letters show unusual empathy and understanding for the down-trodden of his day. Many of his most famous letters were to female believers, whom he often complimented for their in-depth questions about Buddhism while encouraging them in their efforts to attain enlightenment in this lifetime.

The five major writings that are common to all Nichiren Buddhism are:


Accordingly, the Taisekiji temple of Nichiren Shōshū revere an additional set of ten major writings. Other Nichiren sects either dispute them as secondary of importance, apocryphal, or forgery:


In his writings, Nichiren refers to his identity in a variety of ways, nevertheless always related to the "Lotus Sutra". For example: "I, Nichiren, am the foremost votary of the Lotus Sutra".





</doc>
<doc id="22137" url="https://en.wikipedia.org/wiki?curid=22137" title="Nichiren Buddhism">
Nichiren Buddhism

Nichiren Buddhism is a branch of Mahayana Buddhism based on the teachings of the 13th century Japanese Buddhist priest Nichiren (1222–1282) and is one of the "Kamakura Buddhism" schools. Its teachings derive from some 300–400 extant letters and treatises attributed to Nichiren.

Within Nichiren Buddhism there are two major divisions which fundamentally differ over whether Nichiren should be regarded as a bodhisattva of the earth, a saint, great teacher—or the actual Buddha of the third age of Buddhism. Several of Japan's New Religious Movements are Nichiren-inspired lay groups. It is practiced worldwide, with practitioners throughout the United States, Brazil and Europe, as well as in South Korea and southeast Asia. The largest sects are the Soka Gakkai/(Soka Gakkai International), Nichiren Shu, and Nichiren Shoshu.

Nichiren Buddhism focuses on the Lotus Sutra doctrine that all people have an innate Buddha-nature and are therefore inherently capable of attaining enlightenment in their current form and present lifetime. Nichiren proposed a classification system that ranks the quality of religions and various Nichiren schools can be either accommodating or vigorously opposed to any other forms of Buddhism or religious beliefs.

There are three essential aspects to Nichiren Buddhism:


The Nichiren Gohonzon is a calligraphic image which is prominently displayed in the home or temple buildings of its believers. The Gohonzon used in Nichiren Buddhism is composed of the names of key bodhisattvas and Buddhas in the Lotus Sutra as well as Namu-Myoho-Renge-Kyo written in large characters down the center.

After his death, Nichiren left to his followers the mandate to widely propagate the Gohonzon and Daimoku in order to secure the peace and prosperity of society.

Traditional Nichiren Buddhist temple groups are commonly associated with Nichiren Shoshu and varying Nichiren Shu schools. There are also modern 21st century lay groups not affiliated with temples such as Soka Gakkai, Kenshokai, Shoshinkai, Risshō Kōsei Kai, and Honmon Butsuryū-shū.

The basic practice of Nichiren Buddhism is chanting the invocation Nam-myoho-renge-kyo to a mandala inscribed by Nichiren, called Gohonzon. Embracing Nam-myoho-renge-kyo entails both chanting and having the mind of faith ("shinjin"). Both the invocation and the Gohonzon, as taught by Nichiren, embody the title and essence of the Lotus Sutra, which he taught as the only valid scripture for The Latter Day of the Law, as well as the life state of Buddhahood inherent in all life.

Nichiren considered that in the Latter Day of the Law – a time of human strife and confusion, when Buddhism would be in decline – Buddhism had to be more than the theoretical or meditative practice it had become, but was meant to be practiced "with the body", that is, in one’s actions and the consequent results that are manifested. More important than the formality of ritual, he claimed, was the substance of the practitioner's life in which the spiritual and material aspects are interrelated. He considered conditions in the world to be a reflection of the conditions of the inner lives of people; the premise of his first major remonstrance, Rissho Ankoku Ron (Establishing The Correct Teaching for the Peace of The Land), is that if a nation abandons heretical forms of Buddhism and adopts faith in the Lotus Sutra, the nation will know peace and security. He considered his disciples the "Bodhisattvas of the Earth" who appeared in the Lotus Sutra with the vow to spread the correct teaching and thereby establish a peaceful and just society.

The specific task to be pursued by Nichiren's disciples was the widespread propagation of his teachings (the invocation and the Gohonzon) in a way that would effect actual change in the world's societies so that the sanctuary, or seat, of Buddhism could be built. Nichiren saw this sanctuary as a specific seat of his Buddhism, but there is thought that he also meant it in a more general sense, that is, wherever his Buddhism would be practiced. This sanctuary, along with the invocation and Gohonzon, comprise "the three great secret laws (or dharmas)" found in the Lotus Sutra.

Nichiren Buddhism originated in 13th-century feudal Japan. It is one of six new forms of "Shin Bukkyo" (English: "New Buddhism") of "Kamakura Buddhism." The arrival of these new schools was a response to the social and political upheaval in Japan during this time as power passed from the nobility to a shogunate military dictatorship led by the Minamoto clan and later to the Hōjō clan. A prevailing pessimism existed associated with the perceived arrival of the Age of the Latter Day of the Law. The era was marked by an intertwining relationship between Buddhist schools and the state which included clerical corruption.

By Nichiren's time the Lotus Sūtra was firmly established in Japan. From the ninth century, Japanese rulers decreed that the Lotus Sūtra be recited in temples for its "nation-saving" qualities. It was the most frequently read and recited sutra by the literate lay class and its message was disseminated widely through art, folk tales, music, and theater. It was commonly held that it had powers to bestow spiritual and worldly benefits to individuals. However, even Mount Hiei, the seat of Tiantai Lotus Sutra devotion, had come to adopt an eclectic assortment of esoteric rituals and Pure Land practices as "expedient means" to understand the sutra itself.

Nichiren developed his thinking in this midst of confusing Lotus Sutra practices and a competing array of other "Old Buddhism" and "New Buddhism" schools. The biographical development of his thinking is sourced almost entirely from his extant writings as there is no documentation about him in the public records of his times. Modern scholarship on Nichiren's life tries to provide sophisticated textual and sociohistorical analyses to cull longstanding myths about Nichiren that accrued over time from what is actually concretized.

It is clear that from an early point in his studies Nichiren came to focus on the Lotus Sutra as the culmination and central message of Shakyamuni. As his life unfolded he engaged in a "circular hermeneutic" in which the interplay of the Lotus Sutra text and his personal experiences verified and enriched each other in his mind. As a result, there are significant turning points as his teachings reach full maturity. Scholar Yoshirō Tamura categorizes the development of Nichiren's thinking into three periods: 

For more than 20 years Nichiren examined Buddhist texts and commentaries at Mount Hiei's Enryaku-ji temple and other major centers of Buddhist study in Japan. In later writings he claimed he was motivated by four primary questions: (1) What were the essentials of the competing Buddhist sects so they could be ranked according to their merits and flaws? (2) Which of the many Buddhist scriptures that had reached Japan represented the essence of Shakyamuni's teaching? (3) How could he be assured of the certainty of his own enlightenment? (4) Why was the Imperial house defeated by the Kamakura regime in 1221 despite the prayers and rituals of Tendai and Shingon priests? He eventually concluded that the highest teachings of Shakyamuni Buddha ( – ) were to be found in the Lotus Sutra. Throughout his career Nichiren carried his personal copy of the Lotus Sutra which he continually annotated. The mantra he expounded on 28 April 1253, known as the "Daimoku" or "Odaimoku", Namu Myōhō Renge Kyō, expresses his devotion to the Lotus Sutra.

From this early stage of his career, Nichiren started to engage in fierce polemics criticizing the teachings of Buddhism taught by the other sects of his day, a practice that continued and expanded throughout his life. Although Nichiren accepted the Tendai theoretical constructs of "original enlightenment" ("hongaku shisō") and "attaining Buddhahood in one's present form" ("sokushin jobutsu") he drew a distinction, insisting both concepts should be seen as practical and realizable amidst the concrete realities of daily life. He took issue with other Buddhist schools of his time that stressed transcendence over immanence. Nichiren's emphasis on "self-power" (Jpn. "ji-riki") led him to harshly criticize Honen and his Pure Land Buddhism school because of its exclusive reliance on Amida Buddha for salvation which resulted in "other-dependence." (Jpn. "ta-riki") In addition to his critique of Pure Land Buddhism, he later expanded his polemics to criticisms of the Zen, Shingon, and Ritsu sects. These four critiques were later collectively referred to as his "four dictums." Later in his writings, Nichiren referred to his early exegeses of the Pure Land teachings as just the starting point for his polemics against the esoteric teachings, which he had deemed as a far more significant matter of concern. Adding to his criticisms of esoteric Shingon, Nichiren wrote detailed condemnations about the Tendai school which had abandoned its Lotus Sutra-exclusiveness and incorporated esoteric doctrines and rituals as well as faith in the soteriological power of Amida Buddha.

The target of his tactics expanded during the early part of his career. Between 1253 and 1259 he proselytized and converted individuals, mainly attracting mid- to lower-ranking samurai and local landholders and debated resident priests in Pure Land temples. In 1260, however, he attempted to directly reform society as a whole by submitting a treatise entitled ""Risshō Ankoku Ron"" (""Establishment of the Legitimate Teaching for the Protection of the Country"") to Hōjō Tokiyori, the "de facto" leader of the nation.

In it he cites passages from the Ninnō, Yakushi, Daijuku, and Konkōmyō sutras. Drawing on Tendai thinking about the nonduality of person and land, Nichiren argued that the truth and efficacy of the people's religious practice will be expressed in the outer conditions of their land and society. He thereby associated the natural disasters of his age with the nation's attachment to inferior teachings, predicted foreign invasion and internal rebellion, and called for the return to legitimate dharma to protect the country. Although the role of Buddhism in "nation-protection" ("chingo kokka") was well-established in Japan at this time, in this thesis Nichiren explicitly held the leadership of the country directly responsible for the safety of the land.

During the middle stage of his career, in refuting other religious schools publicly and vociferously, Nichiren provoked the ire of the country's rulers and of the priests of the sects he criticized. As a result, he was subjected to persecution which included two assassination attempts, an attempted beheading and two exiles. His first exile, to Izu Peninsula (1261–1263), convinced Nichiren that he was "bodily reading the Lotus Sutra ("Jpn. Hokke shikidoku")," fulfilling the predictions on the 13th chapter ("Fortitude") that votaries would be persecuted by ignorant lay people, influential priests, and their friends in high places.

Nichiren began to argue that through "bodily reading the Lotus Sutra," rather than just studying its text for literal meaning, a country and its people could be protected. According to Habito, Nichiren argued that bodily reading the Lotus Sutra entails four aspects:

His three-year exile to Sado Island proved to be another key turning point in Nichiren's thinking. Here he began inscribing the Gohonzon and wrote several major theses in which he claimed that he was functioning, at first, in the role of Bodhisattva Never Disparaging of the 20th chapter of the Lotus Sutra and, later, as Bodhisattva Superior Practices, the leader of the Bodhisattvas of the Earth. In his work "The True Object of Worship", he identified himself as functioning as the primordial Buddha, one and the same as the eternal Law represented by the mantra Nam-myoho-renge-kyo which he physically embodied as the Gohonzon mandala. This has been described as embodying the same condition or state he attained in a physical object of devotion worship so that others could attain that equivalent condition of enlightenment. During this time the "daimoku" becomes the means to directly access the Buddha's enlightenment.

He concludes his work "The Opening of the Eyes" with the declaration "I will be the pillar of Japan; I will be they eyes of Japan; I will be the vessel of Japan. Inviolable shall remain these vows!" His thinking now went beyond theories of karmic retribution or guarantees of the Lotus Sutra as a protective force. Rather, he expressed a resolve to fulfill his mission despite the consequences. All of his disciples, he asserted, should emulate his spirit and work just like him in helping all people open their innate Buddha lives even though this means entails encountering enormous challenges.

Nichiren’s teachings reached their full maturity between the years 1274 and 1282 while he resided in primitive settings at Mount Minobu located in today's Yamanashi Prefecture. During this time he devoted himself to training disciples, produced most of the Gohonzon which he sent to followers, and authored works constituting half of his extant writings including six treatises that were categorized by his follower Nikkō as among his ten most important.

In 1278 the “Atsuhara Affair” (“Atsuhara Persecution”) occurred, culminating three years later. In the prior stage of his career, between 1261 and 1273, Nichiren endured and overcame numerous trials that were directed at him personally including assassination attempts, an attempted execution, and two exiles, thereby “bodily reading the Lotus Sutra” ("shikidoku" 色読). In so doing, according to him, he validated the 13th ("Fortitude") chapter of the Lotus Sutra in which a host of bodhisattvas promise to face numerous trials that follow in the wake of upholding and spreading the sutra in the evil age following the death of the Buddha: slander and abuse; attack by swords and staves; enmity from kings, ministers, and respected monks; and repeated banishment.

On two occasions, however, the persecution was aimed at his followers. First, in 1271, in conjunction with the arrest and attempted execution of Nichiren and his subsequent exile to Sado, many of his disciples were arrested, banished, or had lands confiscated by the government. At that time, Nichiren stated, most recanted their faith in order to escape the government’s actions. In contrast, during the Atsuhara episode twenty lay peasant-farmer followers were arrested on questionable charges and tortured; three were ultimately executed. This time none recanted their faith. Some of his prominent followers in other parts of the country were also being persecuted but maintained their faith as well.

Although Nichiren was situated in Minobu, far from the scene of the persecution, the Fuji district of present-day Shizuoka Prefecture, Nichiren held his community together in the face of significant oppression through a sophisticated display of legal and rhetorical responses. He also drew on a wide array of support from the network of leading monks and lay disciples he had raised, some of whom were also experiencing persecution at the hands of the government.

Throughout the events he wrote many letters to his disciples in which he gave context to the unfolding events by asserting that severe trials have deep significance. According to Stone, “By standing firm under interrogation, the Atsuhara peasants had proved their faith in Nichiren’s eyes, graduating in his estimation from ‘ignorant people’ to devotees meriting equally with himself the name of ‘practitioners of the Lotus Sutra.’” During this time Nichiren inscribed 114 mandalas that are extant today, 49 of which have been identified as being inscribed for individual lay followers and which may have served to deepen the bond between teacher and disciple. In addition, a few very large mandalas were inscribed, apparently intended for use at gathering places, suggesting the existence of some type of conventicle structure.

The Atsuhara Affair also gave Nichiren the opportunity to better define what was to become Nichiren Buddhism. He stressed that meeting great trials was a part of the practice of the Lotus Sutra; the great persecutions of Atsuhara were not results of karmic retribution but were the historical unfolding of the Buddhist Dharma. The vague “single good of the true vehicle” which he advocated in the "Risshō ankoku ron" now took final form as chanting the Lotus Sutra’s "daimoku" or title which he described as the heart of the “origin teaching” ("honmon" 本門) of the Lotus Sutra. This, he now claimed, lay hidden in the depths of the 16th (“The Life Span of the Tathāgata”) chapter, never before being revealed, but intended by the Buddha solely for the beginning of the Final Dharma Age.

A prolific writer, Nichiren's personal communiques among his followers as well as numerous treatises detail his view of the correct form of practice for the "Latter Day of the Law" ("mappō"); lay out his views on other Buddhist schools, particularly those of influence during his lifetime; and elucidate his interpretations of Buddhist teachings that preceded his. These writings are collectively known as "Gosho" (御書) or "Nichiren ibun" (日蓮遺文).

Out of 162 historically identified followers of Nichiren, 47 were women. Many of his writings were to women followers in which he displays strong empathy for their struggles, and continually stressed the Lotus Sutra's teaching that all people, men and women equally, can become enlightened just as they are. His voice is sensitive and kind which differs from the strident picture painted about him by critics.

Which of these writings, including the "Ongi Kuden" (orally transmitted teachings), are deemed authentic or apocryphal is a matter of debate within the various schools of today's Nichiren Buddhism. One of his most important writings the "Rissho Ankoku Ron", preserved at Shochuzan Hokekyo-ji, is one of the National Treasures of Japan.

After Nichiren’s death in 1282 the Kamakura shogunate weakened largely due to financial and political stresses resulting from defending the country from the Mongols. It was replaced by the Ashikaga (Muromachi) shogunate (足利幕府 or 室町幕府, 1336–1573), which in turn was succeeded by the Azuchi–Momoyama period (安土桃山時代, 1573–1600), and finally the Tokugawa shogunate (江戸幕府, 1600–1868). During these time periods, collectively comprising the Japan's medieval history, Nichiren Buddhism experienced considerable fracturing, growth, turbulence and decline. A prevailing characteristic of the movement in medieval Japan was its lack of understanding of Nichiren's own spiritual realization. Serious commentaries about Nichiren's theology did not appear for almost two hundred years. This contributed to divisive doctrinal confrontations that were often superficial and dogmatic.

The long history of foundings, divisions, and mergers have led to today's 37 legally incorporated Nichiren Buddhist groups. After the era, in the modern period, Nichiren Buddhism experienced a revival, largely initiated by lay people and movements.

Several denominations comprise the umbrella term "Nichiren Buddhism" which was known at the time as the "Hokkeshū" (Lotus School) or "Nichirenshū" (Nichiren School). The splintering of Nichiren's teachings into different schools began several years after Nichiren's passing. Despite their differences, however, the Nichiren groups shared commonalities: asserting the primacy of the Lotus Sutra, tracing Nichiren as their founder, centering religious practice on chanting Namu-myoho-renge-kyo, using the Gohonzon in meditative practice, insisting on the need for propagation, and participating in remonstrations with the authorities.

The movement was supported financially by local warlords or stewards ("jitõ") who often founded tightly-organized clan temples ("ujidera") that were frequently led by sons who became priests. Most Nichiren schools point to the founding date of their respective head or main temple (for example, Nichiren Shū the year 1281, Nichiren Shōshū the year 1288, and Kempon Hokke Shu the year 1384) although they did not legally incorporate as religious bodies until the late 19th and early 20th century. A last wave of temple mergers took place in the 1950s.

The roots of this splintering can be traced to the organization of the Nichiren community during his life. In 1282, one year before his death, Nichiren named "six senior priests" ("rokurōsō") disciple to lead his community: Nikkō Shonin (日興), Nisshō (日昭), Nichirō (日朗), Nikō (日向), Nitchō (日頂), and Nichiji (日持). Each had led communities of followers in different parts of the Kanto region of Japan and these groups, after Nichiren's death, ultimately morphed into lineages of schools.

Nikkō Shonin, Nichirō, and Nisshō were the core of the Minobu (also known as the Nikō or Kuon-ji) "monryu" or school. Nikō became the second chief abbot of Minobu (Nichiren is considered by this school to be the first). Nichirō's direct lineage was called the Nichirō or Hikigayatsu "monryu". Nisshō's lineage became the Nisshō or Hama "monryu". Nitchō formed the Nakayama lineage but later returned to become a follower of Nikkō. Nichiji, originally another follower of Nikkō, eventually traveled to the Asian continent (ca. 1295) on a missionary journey and some scholarship suggests he reached northern China, Manchuria, and possibly Mongolia. Kuon-ji Temple in Mount Minobu eventually became the head temple of today's Nichiren Shū, the largest branch among traditional schools, encompassing the schools and temples tracing their origins to Nikō, Nichirō, Nisshō, Nitchō, and Nichiji. The lay and/or new religious movements Reiyūkai, Risshō Kōsei Kai, and Nipponzan-Myōhōji-Daisanga stem from this lineage.

Nikkō left Kuon-ji in 1289 and became the founder of what was to be called the Nikkō "monryu" or lineage. He founded a center at the foot of Mount Fuji which would later be known as the Taisekiji temple of Nichiren Shōshū. The Soka Gakkai is the largest independent lay organization that shares roots with lineage.

Fault lines between the various Nichiren groups crystallized over several issues:

The cleavage between Nichiren groups has also been classified by the so-called "Itchi" (meaning unity or harmony) and "Shoretsu" (a contraction of two words meaning superior/inferior) lineages.

Although there were rivalries and unique interpretations among the early Hokkeshũ lineages, none were as deep and distinct as the divide between the Nikkō or Fuji school and the rest of the tradition. Animosity and discord among the six senior disciples started after the second death anniversary of Nichiren's 100th Day Memorial ceremony (23 January 1283) when the rotation system as agreed upon the ""Shuso Gosenge Kiroku"" (English: Record document of founder's demise) and "Rimbo Cho" (English: Rotation Wheel System) to clean and maintain Nichiren's grave. By the third anniversary of Nichiren's passing (13 October 1284), these arrangements seemed to have broken down. Nikkō claimed that the other five senior priests no longer returned to Nichiren's tomb in Mount Minobu, citing signs of neglect at the gravesite. He took up residency and overall responsibility for Kuonji temple while Nikō served as its doctrinal instructor. Before long tensions grew between the two concerning the behavior of Hakii Nanbu Rokurō Sanenaga, the steward of the Minobu district and the temple's patron.

Nikkō accused Sanenaga of unorthodox practices deemed to be heretical such crafting a standing statue of Shakyamuni Buddha as an object of worship, providing funding for the construction of a Pure Land stupa in Fuji, and visiting and worshiping at the Mishima Taisha Shinto shrine which was an honorary shrine of the Hōjō clan shogunate. Nikkō regarded the latter as a violation of Nichiren's "Rissho ankoku ron".

In addition, Nikkō made accusatory charges that after Nichiren's death, other disciples slowly began to gradually deviate from what Nikkō viewed as Nichiren's orthodox teachings. Chief among these complaints was the syncretic practices of some of the disciples to worship images of Shakyamuni Buddha. Nikkō admonished other disciple priests for signing their names "Tendai Shamon" (of the Tendai Buddhist school) in documents they sent to the Kamakura government. Furthermore, Nikkō alleged that the other disciples disregarded some of Nichiren's writings written in Katakana rather than in Classical Chinese syllabary.

Sanenaga defended his actions claiming that it was customary for his political family to provide monetary donations and make homage to the Shinto shrine of the Kamakura shogunate. Nikō tolerated Sanenaga's acts, claiming that similar incidents occurred previously with the knowledge of Nichiren. Sanenaga sided with Nikō and Nikkō departed in 1289 from Minobu. He returned to his home in Suruga Province and established two temples: Taiseki-ji in the Fuji district and Honmonji in Omosu district. He spent most of his life at the latter where he trained his followers.

According to Stone, it is not absolutely clear that Nikkō intended to completely break from the other senior disciples and start his own school. However, his followers claimed that he was the only one of the six senior disciples who maintained the purity of Nichiren's legacy. Two documents appeared, first mentioned and discovered by Taiseki-ji High Priest Nikkyo Shonin in 1488, claiming Nichiren transferred his teaching exclusively to Nikkō but their authenticity has been questioned. Taiseki-ji does not dispute that the original documents are missing but holds that certified copies are preserved in their repositories. In contrast, other Nichiren sects vehemently claim them as forgeries since they are not in the original handwriting of Nichiren or Nikkō, holding they were copied down by Nikkō’s disciples after his death."

In addition to using the letters to defend its claim to othodoxy, the documents may have served to justify Taiseki-ji's claimed superiority over other Nikkō temples, especially Ikegami Honmon-ji, the site of Nichiren's tomb. Even though there had been efforts by temples of the Nikkō lineage in the late 19th century to unify into one single separate Nichiren school the "Kommon-ha", today's Nichiren Shōshū comprises only the Taiseki-ji temple and its dependent temples. It is not identical to the historical Nikkō or Fuji lineage. Parts of the "Kommon-ha", the "Honmon-Shu", eventually became part of Nichiren Shu in the 1950s. New religious movements like Sōka Gakkai, Shōshinkai, and Kenshōkai trace their origins to the Nichiren Shōshū school.

In the early 14th century Hokkeshū followers spread the teachings westward and established congregations (Jpn. "shū") into the imperial capital of Kyoto and as far as Bizen and Bitchu. During this time there is documentation of face-to-face public debates between Hokkeshū and Nembutsu adherents. By the end of the century Hokkeshū temples had been founded all over Kyoto, only being outnumbered by Zen temples. The demographic base of support in Kyoto were members of the merchant class (Jpn. "machishū"), some of whom had acquired great wealth. Tanabe hypothesizes they were drawn to this faith because of Nichiren's emphasis on the "third realm" (Jpn. "daisan hōmon") of the Lotus Sutra, staked out in chapters 10-22, which emphasize practice in the mundane world.

In the 15th century, the political and social order began to collapse and Hokkeshū followers armed themselves. The "Hokke-ikki" was an uprising in 1532 of Hokke followers against the followers of the Pure Land school in 1532. Initially successful it became the most powerful religious group in Kyoto but its fortunes were reversed in 1536 when Mt. Hiei armed forces destroyed twenty-one Hokkeshū temples and killed some 58,000 of its followers. In 1542 permission was granted by the government to rebuild the destroyed temples and the Hokke "machishū" played a crucial role in rebuilding the commerce, industry, and arts in Kyoto. Their influence in the arts and literature continued through the Momoyama (1568–1615) and Edo (1615–1868) periods and many of the most famous artists and literati were drawn from their ranks.

Although the various sects of Nichiren Buddhism were administratively independent, there is evidence of cooperation between them. For example, in 1466 the major Hokke temples in Kyoto signed the Kanshō-era accord (Kanshō "meiyaku") to protect themselves against threats from Mt. Hiei. Despite strong sectarian differences, there is also evidence of interactions between Hokkeshū and Tendai scholar-monks.

During the Edo period, with the consolidation of power by the Tokugawa shogunate, increased pressure was placed major Buddhist schools and Nichiren temples to conform to governmental policies. Some Hokkeshū adherents, the followers of the so-called Fuju-fuse lineage, adamantly bucked this policy based on their readings of Nichiren's teachings to neither take ("fuju") nor give ("fuse") offerings from non-believers. Suppressed, adherents often held their meetings clandestinely which led to the Fuju-fuse persecution and numerous executions of believers in 1668. During this time of persecution, most likely to prevent young priests from adopting a passion for propagation, Nichiren seminaries emphasized Tendai studies with only a few top-ranking students permitted to study some of Nichiren's writings.

During the Edo period the majority of Hokkeshū temples were subsumed into the shogunate's Danka system, an imposed nationwide parish system designed to ensure religious peace and root out Christianity. In this system Buddhist temples, in addition to their ceremonial duties, were forced to carry out state administrative functions. Thereby they became agents of the government and were prohibited to engage in any missionary activities. Hokkeshū temples were now obligated, just like those of other Buddhist schools, to focus on funeral and memorial services ("Sōshiki bukkyō") as their main activity. Stagnation was often the price for the protected status.

Nichiren Buddhism was deeply influenced by the transition from the Tokugawa (1600–1868) to Meiji (1868–1912) periods in nineteenth-century Japan. The changeover from early modern ("kinsei") to modern ("kindai") was marked by the transformation of late-feudal institutions into modern ones as well as the political transition from shogunal to imperial rule and the economic shift from national isolation to integration in the world economy. This entailed creating a centralized state, stitching together some 260 feudal domains ruled by hereditary leaders ("daimyo"), and moving from a caste social system to a meritocracy based on educational achievement. Although commonly perceived as a singular event called the Meiji Restoration, the transition was full of twists and turns that began in the later Tokugawa years and continued decades after the 1867–1868 demise of the shogunate and launch of imperial rule.

By this time Japanese Buddhism was often characterized by syncretism in which local nativistic worship was incorporated into Buddhist practice. For example, Tendai, Shingon, Jodō, and Nichiren temples often had chapels within them dedicated to Inari Shinto worship. Within Nichiren Buddhism there was a phenomenon of "Hokke Shintō" (Lotus Shinto), closely influenced by Yoshida Shintō.

Anti-Buddhist sentiment had been building throughout the latter part of the Tokugawa period (1603–1868). Scholars such as Tominaga Nakamoto and Hirata Atsutane attacked the theoretical roots of Buddhism. Critics included promoters of Confucianism, nativism, Shinto-inspired Restorationists, and modernizers. Buddhism was critiqued as a needless drain on public resources and also as an insidious foreign influence that had obscured the indigenous Japanese spirit.

Under attack by two policies of the day, "shinbutsu bunri" (Separation of Shinto Deities and Buddhas) and "haibutsu kishaku" 
(Eradication of Buddhism), Japanese Buddhism during the Tokugawa-to-Meiji transition proved to be a crisis of survival. The new government promoted policies that reduced the material resources available to Buddhist temples and downgraded their role in the religious, political, and social life of the nation.

The policies of "shibutsu bunri" were implemented at the local level throughout Japan but were particularly intense in three domains that were the most active in the Restoration: Satsuma, Choshii, and Tosa. In Satsuma, for example, by 1872 all of its 1000+ Buddhist temples had been abolished, their monks laicized, and their landholdings confiscated. Throughout the country thousands of Buddhist temples and, at a minimum, tens of thousands of Buddhist sutras, paintings, statues, temple bells and other ritual objects were destroyed, stolen, lost, or sold during the early years of the restoration.

Starting in the second decade of the restoration, pushback against these policies came from Western powers interested in providing a safe harbor for Christianity and Buddhist leaders who proposed an alliance of Shinto and Buddhism to resist Christianity. As part of this accommodation, Buddhist priests were forced to promote key teachings of Shinto and provide support for national policies.

Nichiren Buddhism, like the other Buddhist schools, struggled between accommodation and confrontation. The Nichiren scholar Udana-in Nichiki (1800–1859) argued for a policy of co-existence with other schools of Buddhism, Confucianism, Nativism, and European religions. His disciple Arai Nissatsu (1830–1888) forged an alliance of several Nichiren branches and became the first superintendent of the present Nichiren Shū which was incorporated in 1876. Nissatsu was active in Buddhist intersect cooperation to resist the government's hostile policies, adopted the government's "Great Teaching" policy that was Shinto-derived, and promoted intersectarian understanding. In the process, however, he reinterpreted some of Nichiren's important teachings. Among those arguing against accommodation were Nichiren scholar and lay believer Ogawa Taidō (1814–1878) and the cleric Honda Nisshō (1867–1931) of the Kempon Hokke denomination.

After the above events and centuries of splintering based on dogma and institutional histories, the following major Nichiren temple schools, according to Matsunaga, were officially recognized in the Meiji era:


Nichiren Buddhism went through many reforms in the Meiji Period during a time of persecution, Haibutsu kishaku (廃仏毀釈), when the government attempted to eradicate mainstream Japanese Buddhism. As a part of the Meiji Restoration, the interdependent Danka system between the state and Buddhist temples was dismantled which left the latter without its funding. Buddhist institutions had to align themselves to the new nationalistic agenda or perish. Many of these reform efforts were led by lay people.

The trend toward lay centrality was prominent in Nichiren Buddhism as well, predating the Meiji period. Some Nichiren reformers in the Meiji period attempted to inject a nationalistic interpretation of Nichiren's teachings; others called for globalist perspectives. According to Japanese researcher "Yoshiro Tamura", the term "Nichirenism" applies broadly to the following three categories:


 
Both Nichiren and his followers have been associated with fervent Japanese nationalism specifically identified as Nichirenism between the Meiji period and the conclusion of World War II. The nationalistic interpretation of Nichiren's teachings were inspired by lay Buddhist movements like Kokuchūkai or Kenshōkai and resulted in violent historical events such as the May 15 Incident and the League of Blood Incident. Among the key proponents of this interpretation are Chigaku Tanaka who founded the Kokuchūkai (English: Nation's Pillar Society). Tanaka was charismatic and through his writings and lecturers attracted many followers such as Kanji Ishiwara. Nisshō Honda advocated the unification Japanese Buddhists to support the imperial state. Other ultra-nationalist activists who based their ideas on Nichiren were Ikki Kita and Nisshō Inoue.

Nichirenism also includes several intellectuals and activists who reacted against the prewar ultranationalistic interpretations and argued for an egalitarian and socialist vision of society based on Nichiren's teachings and the Lotus Sutra. These figures ran against the growing tide of Japanese militarism and were subjected to political harassment and persecution. A leading figure in this group was Girō Seno who formed the New Buddhist Youth League ("Shinkō Bukkyō Seinen Dōmei").

Originally influenced by the ideals of Tanaka and Honda, Giro Seno came to reject ultra-nationalism and argued for humanism, socialism, pacifism, and democracy as a new interpretation of Nichiren's beliefs. He was imprisoned for two years under the National Security Act. The same fate was also endured by Tsunesaburo Makiguchi, who at the time supported the Japanese war effort of Emperor Showa during World War II but refused the religious dictum of Shinto display towards his religion, Nichiren Shoshu. Makiguchi would found the "Soka Kyoiku Gakkai", a lay organization composed of primarily secretaries and teachers until it grew to become Soka Gakkai after World War II.

Several Nichiren-inspired religious movements arose and appealed primarily to this segment of society with a message of alleviating suffering salvation for many poor urban workers. Honmon Butsuryū-shū, an early example of lay-based religious movements of the modern
period inspired by Nichiren, was founded several years before the Meiji Restoration. Reiyukai, Rissho Koseikai stemming from Nichiren Shu while Kenshokai and Soka Gakkai stemming from Nichiren Shoshu are more recent examples of lay-inspired movements drawing from Nichiren's teachings and life.

Accordingly, Nichiren Buddhism has had a major impact on Japan's literary and cultural life. Japanese literary figure Takayama Chogyū and children's author Kenji Miyazawa praised Nichiren's teachings. Another prominent researcher, Masaharu Anesaki was encouraged to study Nichiren which led to the latter's work "Nichiren: The Buddhist Prophet" which introduced Nichiren to the West. Non-Buddhist Japanese individuals such as Uchimura Kanzō listed Nichiren as one of five historical figures who best represented Japan while Tadao Yanaihara described Nichiren as one of the four historical figures he most admired.

While various sects and organizations have had a presence in nations outside Japan for over a century, the ongoing expansion of Nichiren Buddhism overseas started in 1960 when Soka Gakkai president Daisaku Ikeda initiated his group's worldwide propagation efforts growing from a few hundred transplanted Japanese to over 3500 families just by 1962.

Nichiren Buddhism is now practiced in many countries outside of Japan. In the United States Prebish coined the typology of "two Buddhisms" to delineate the divide between forms of Buddhism that appealed either primarily to people of the Asian diaspora or to Euro-American converts. Nattier, on the other hand, proposes a three-way typology. "Import" or "elite" Buddhism refers to a class of people who have the time and means to seek Buddhist teachers to appropriate certain Buddhist techniques such as meditation. "Export or evangelical" Buddhism refers to groups that actively proselytize for new members in their local organizations. "Baggage" or "ethnic" Buddhism refers to diaspora Buddhists, usually of a single ethnic group, who have relocated more for social and economic advancement than for evangelical purposes. Another taxonomy divides Western Buddhist groups into three different categories: evangelical, church-like, and meditational.

Nichiren Shu has been classified into the church-like category. One of several Japanese Buddhist schools that followed in the wake of Japanese military conquest and colonization, Nichiren Shu opened a temple in Pusan, Korea in 1881. Its fortunes rose and diminished with the political tides but eventually failed. It also established missions in Sakhalin, Manchuria, and Taiwan. A Nichiren Shu mission was established in Hawaii in 1900. By 1920 it established temples at Pahala, Honolulu, Wailuku and Maui. In 1955 it officially started a mission in Brazil. In 1991 it established the Nichiren Buddhist International Center in 1991 and in 2002 built a center in Hayward, California, to help overseas missions. However, Nichiren Shu does not widely propagate in the West.

Some have characterized the Soka Gakkai as evangelical but others claim that it broke out of the "Two Buddhisms" paradigm. It is quite multi-ethnic and it has taken hold among native populations in locations including Korea, Malaysia, Brazil, Europe, parts of Africa, India, and North America. The growth of the Soka Gakkai was sparked by repeated missionary trips beginning in the early 1960s by Daisaku Ikeda, its third president. In 1975 the Soka Gakkai International was launched in Guam. In the United States it has attracted a diverse membership including a significant demographic of African Americans. Since the 1970s it has created institutions, publications and exhibitions to support its overall theme of "peace, culture, and education." There is academic research on various national organizations affiliated with this movement: the United States, the United Kingdom, Italy, Canada, Brazil, Scotland, Southeast Asia, Germany, and Thailand.

The Rissho Kosei Kai focuses on using its teachings to promote a culture of religiosity through inter-religious dialogue. In 1967, it launched the "Faith to All Men Movement" to awaken a globalized religiosity. It has over 2 million members and 300 Dharma centers in 20 countries throughout the world including Frankfurt and Moorslede. It is active in interfaith organizations, including the International Association for Religious Freedom (IARF) and Religions for Peace (WCRP). It has consultative states with the United Nations and since 1983 issues an annual Peace Prize to individuals or organizations worldwide that work for peace and development and promote interreligious cooperation.

The Reiyukai conducts more typical missionary activities in the West. It has a membership of between five hundred and one thousand members in Europe, concentrated in Italy, Spain, England and France. The approximately 1,500 members of the Nihonzan Myohoji have built peace pagodas, conducted parades beating the drum while chanting the daimoku, and encouraged themselves and others to create world peace.

Nichiren Shoshu has six temples in the United States led by Japanese priests and supported by lay Asians and non-Asians. There is one temple in Brazil and the residing priest serves as a "circuit rider" to attend to other locations.

The following lists are based on English-language Wikipedia articles and the Japanese Wikipedia article on .

In alphabetical order (Japanese characters preceded by "ja:" link to articles in the Japanese Wikipedia). 
In alphabetical order (Japanese characters preceded by "ja:" link to articles in the Japanese Wikipedia):








</doc>
<doc id="22141" url="https://en.wikipedia.org/wiki?curid=22141" title="Newport News Shipbuilding">
Newport News Shipbuilding

Newport News Shipbuilding (NNS), a division of Huntington Ingalls Industries, is the largest industrial employer in Virginia, and sole designer, builder and refueler of U.S. Navy aircraft carriers and one of two providers of U.S. Navy submarines. Founded as the Chesapeake Dry Dock and Construction Co. in 1886, Newport News Shipbuilding has built more than 800 ships, including both naval and commercial ships. Located in the city of Newport News, their facilities span more than , strategically positioned in one of the great harbors of the East Coast.

The shipyard is a major employer not only for the lower Virginia Peninsula, but also portions of Hampton Roads south of the James River and the harbor, portions of the Middle Peninsula region, and even some northeastern counties of North Carolina.

The shipyard is building the aircraft carriers and .

In 2013, Newport News Shipbuilding began the deactivation of the first nuclear-powered aircraft carrier, , which it also built.

Newport News Shipbuilding also performs refueling and complex overhaul (RCOH) work on s. This is a four-year vessel renewal program that not only involves refueling of the vessel's nuclear reactors but also includes modernization work. The yard has completed RCOH for four "Nimitz"-class carriers (, , and ). As of May 2016 this work was underway for the fifth "Nimitz"-class vessel, . As of November 2017 this work was underway for the sixth "Nimitz"-class vessel, .

Industrialist Collis P. Huntington (1821–1900) provided crucial funding to complete the Chesapeake and Ohio Railroad (C&O) from Richmond, Virginia to the Ohio River in the early 1870s. Although originally built for general commerce, this C&O rail link to the midwest was soon also being used to transport bituminous coal from the previously isolated coalfields, adjacent to the New River and the Kanawha River in West Virginia. In 1881, the Peninsula Extension of the C&O was built from Richmond down the Virginia Peninsula to reach a new coal pier on Hampton Roads in Warwick County near the small unincorporated community of Newport News Point. However, building the railroad and coal pier was only the first part of Huntington's dreams for Newport News.

In 1886, Huntington built a shipyard to repair ships servicing this transportation hub. In 1891 Newport News Shipbuilding and Drydock Company delivered its first ship, the tugboat "Dorothy". By 1897 NNS had built three warships for the US Navy: , and .

When Collis died in 1900, his nephew Henry E. Huntington inherited much of his uncle's fortune. He also married Collis' widow Arabella Huntington, and assumed Collis's leadership role with Newport News Shipbuilding and Drydock Company. Under Henry Huntington's leadership, growth continued. 

In 1906 the revolutionary launched a great naval race worldwide. Between 1907 and 1923, Newport News built six of the US Navy's total of 22 dreadnoughts – , , , , and . All but the first were in active service in World War II. In 1907 President Theodore Roosevelt sent the Great White Fleet on its round-the-world voyage. NNS had built seven of its 16 battleships.

In 1914 NNS built SS "Medina" for the Mallory Steamship Company; as she was until 2009 the world's oldest active ocean-faring passenger ship.

In the early years, leaders of the Newport News community and those of the shipyard were virtually interchangeable. Shipyard president Walter A. Post served from March 9, 1911 to February 12, 1912, when he died. Earlier, he had come to the area as one of the builders of the C&O Railway's terminals, and had served as the first mayor of Newport News after it became an independent city in 1896. It was on March 14, 1914 that Albert Lloyd Hopkins, a young New Yorker trained in engineering, succeeded Post as president of the company. In May 1915 while traveling to England on shipyard business aboard , Albert L. Hopkins tenure and life ended prematurely when that ship was torpedoed and sunk by a German U-boat off Queenstown on the Irish coast. His assistant, Frederic Gauntlett, was also on board, but was able to swim to safety. Homer Lenoir Ferguson was company vice president when Hopkins died, and assumed the presidency the following August. He saw the company through both world wars, became a noted community leader, and was a co-founder of the Mariners' Museum with Archer Huntington. He served until July 31, 1946, after World War II had ended on both the European and Pacific fronts.
Just northwest of the shipyard, Hilton Village, one of the first planned communities in the country, was built by the federal government to house shipyard workers in 1918. The planners met with the wives of shipyard workers. Based on their input 14 house plans were designed for the projected 500 English-village-style homes. After the war, in 1922, Henry Huntington acquired it from the government, and helped facilitate the sale of the homes to shipyard employees and other local residents. Three streets there were named after Post, Hopkins, and Ferguson.

The "Lusitania" incident was among the events that brought the United States into World War I. Between 1918 and 1920 NNS delivered 25 destroyers, and after the war it began building aircraft carriers. was delivered in 1934, and NNS went on to build and .

After World War I NNS completed a major reconditioning and refurbishment of the ocean liner . Before the war she had been the German liner "Vaterland", but the start of hostilities found her laid up in New York Harbor and she had been seized by the US Government in 1917 and converted into a troopship. War duty and age meant that all wiring, plumbing, and interior layouts were stripped and redesigned while her hull was strengthened and her boilers converted from coal to oil while being refurbished. Virtually a new ship emerged from NNS in 1923, and SS "Leviathan" became the flagship of United States Lines.

In 1927 NNS launched the world's first significant turbo-electric ocean liner: Panama Pacific Line's . At the time she was also the largest merchant ship yet built in the United States, although she was a modest size compared with the biggest European liners of her era. NNS launched "California"s sister ships "Virginia" in 1928 and "Pennsylvania" in 1929. NNS followed them by launching two even larger turbo-electric liners for Dollar Steamship Company: the in 1930, followed by her sister in 1931. was launched in 1939 and entered service with United States lines shortly before World War II but soon returned to the shipyard for conversion to a troopship, USS "West Point".

By 1940 the Navy had ordered a battleship, seven more aircraft carriers and four cruisers. During World War II, NNS built ships as part of the U.S. Government's Emergency Shipbuilding Program, and swiftly filled requests for "Liberty ships" that were needed during the war. It founded the North Carolina Shipbuilding Company, an emergency yard on the banks of the Cape Fear River and launched its first Liberty ship before the end of 1941, building 243 ships in all, including 186 Libertys. For its contributions during the war, the Navy awarded the company its "E" pennant for excellence in shipbuilding. NNS ranked 23rd among United States corporations in the value of wartime production contracts.

In the post-war years NNS built the famous passenger liner , which set a transatlantic speed record that still stands today. In 1954 NNS, Westinghouse and the Navy developed and built a prototype nuclear reactor for a carrier propulsion system. NNS designed the in 1960. In 1959 NNS launched its first nuclear-powered submarine, as well as the ballistic missile submarine .

In the 1970s, NNS launched two of the largest tankers ever built in the western hemisphere and also constructed three liquefied natural gas carriers – at over 390,000 deadweight tons, the largest ever built in the United States. NNS and Westinghouse Electric Company jointly form Offshore Power Systems to build floating nuclear power plants for Public Service Electric and Gas Company. 
In the 1980s, NNS produced a variety of Navy products, including nuclear aircraft carriers and nuclear attack submarines. Since 1999 the shipyard has produced only warships for the Navy.

In 2007, the US Navy found that workers had used incorrect metal to fuse together pipes and joints on submarines under construction and this could have led to cracking and leaks. In 2009 it was found that bolts and fasteners in weapons-handling systems on four Navy submarines, including , , , and , were installed incorrectly, delaying the launching of the boats while the problems were corrected.

In 1968, Newport News merged with Tenneco Corporation. In 1996, Tenneco initiated a spinoff of Newport News into an independent company (Newport News Shipbuilding).

On 7 November 2001, Northrop Grumman entered an agreement to purchase Newport News Shipbuilding for a total of $2.6 billion. This acquisition created a $4 billion shipyard called Northrop Grumman Newport News.

On 28 January 2008, Northrop Grumman Corporation realigned its two shipbuilding sectors, Northrop Grumman Newport News and Northrop Grumman Ship Systems, into a single sector called "Northrop Grumman Shipbuilding".

On March 15, 2011 Northrop Grumman announced the spin-off of this sector into a separate company, Huntington Ingalls Industries, Inc., and on March 31, began operating as a separate company and publicly trading under the symbol HII on the New York Stock Exchange.

In 2016, Newport News Shipbuilding perform works on deactivation and the nuclear fuel removing of USS Enterprise's reactor removed by Huntington Ingalls Industries under a $745 million contract with US Navy.

Ships built at the Newport News yard include:





</doc>
<doc id="22145" url="https://en.wikipedia.org/wiki?curid=22145" title="Newton's method">
Newton's method

In numerical analysis, Newton's method (also known as the Newton–Raphson method), named after Isaac Newton and Joseph Raphson, is a method for finding successively better approximations to the roots (or zeroes) of a real-valued function. It is one example of a root-finding algorithm.

The Newton–Raphson method in one variable is implemented as follows:

The method starts with a function defined over the real numbers , the function's derivative , and an initial guess for a root of the function . If the function satisfies the assumptions made in the derivation of the formula and the initial guess is close, then a better approximation is

Geometrically, is the intersection of the -axis and the tangent of the graph of at .

The process is repeated as

until a sufficiently accurate value is reached.

This algorithm is first in the class of Householder's methods, succeeded by Halley's method. The method can also be extended to complex functions and to systems of equations.

The idea of the method is as follows: one starts with an initial guess which is reasonably close to the true root, then the function is approximated by its tangent line (which can be computed using the tools of calculus), and one computes the -intercept of this tangent line (which is easily done with elementary algebra). This -intercept will typically be a better approximation to the function's root than the original guess, and the method can be iterated.

Suppose is a differentiable function defined on the interval with values in the real numbers . The formula for converging on the root can be easily derived. Suppose we have some current approximation . Then we can derive the formula for a better approximation, by referring to the diagram on the right. The equation of the tangent line to the curve at the point is

where denotes the derivative of the function .

The -intercept of this line (the value of such that ) is then used as the next approximation to the root, . In other words, setting to zero and to gives

Solving for gives

We start the process off with some arbitrary initial value . (The closer to the zero, the better. But, in the absence of any intuition about where the zero might lie, a "guess and check" method might narrow the possibilities to a reasonably small interval by appealing to the intermediate value theorem.) The method will usually converge, provided this initial guess is close enough to the unknown zero, and that . Furthermore, for a zero of multiplicity 1, the convergence is at least quadratic (see rate of convergence) in a neighbourhood of the zero, which intuitively means that the number of correct digits roughly at least doubles in every step. More details can be found in the analysis section below.

The Householder's methods are similar but have higher order for even faster convergence. However, the extra computations required for each step can slow down the overall performance relative to Newton's method, particularly if or its derivatives are computationally expensive to evaluate.

The name "Newton's method" is derived from Isaac Newton's description of a special case of the method in "De analysi per aequationes numero terminorum infinitas" (written in 1669, published in 1711 by William Jones) and in "De metodis fluxionum et serierum infinitarum" (written in 1671, translated and published as "Method of Fluxions" in 1736 by John Colson). However, his method differs substantially from the modern method given above: Newton applies the method only to polynomials. He does not compute the successive approximations , but computes a sequence of polynomials, and only at the end arrives at an approximation for the root . Finally, Newton views the method as purely algebraic and makes no mention of the connection with calculus. Newton may have derived his method from a similar but less precise method by Vieta. The essence of Vieta's method can be found in the work of the Persian mathematician Sharaf al-Din al-Tusi, while his successor Jamshīd al-Kāshī used a form of Newton's method to solve to find roots of (Ypma 1995). A special case of Newton's method for calculating square roots was known much earlier and is often called the Babylonian method.

Newton's method was used by 17th-century Japanese mathematician Seki Kōwa to solve single-variable equations, though the connection with calculus was missing.

Newton's method was first published in 1685 in "A Treatise of Algebra both Historical and Practical" by John Wallis. In 1690, Joseph Raphson published a simplified description in "Analysis aequationum universalis". Raphson again viewed Newton's method purely as an algebraic method and restricted its use to polynomials, but he describes the method in terms of the successive approximations instead of the more complicated sequence of polynomials used by Newton. Finally, in 1740, Thomas Simpson described Newton's method as an iterative method for solving general nonlinear equations using calculus, essentially giving the description above. In the same publication, Simpson also gives the generalization to systems of two equations and notes that Newton's method can be used for solving optimization problems by setting the gradient to zero.

Arthur Cayley in 1879 in "The Newton-Fourier imaginary problem" was the first to notice the difficulties in generalizing Newton's method to complex roots of polynomials with degree greater than 2 and complex initial values. This opened the way to the study of the theory of iterations of rational functions.

Newton's method is an extremely powerful technique—in general the convergence is quadratic: as the method converges on the root, the difference between the root and the approximation is squared (the number of accurate digits roughly doubles) at each step. However, there are some difficulties with the method.

Newton's method requires that the derivative be calculated directly. An analytical expression for the derivative may not be easily obtainable and could be expensive to evaluate. In these situations, it may be appropriate to approximate the derivative by using the slope of a line through two nearby points on the function. Using this approximation would result in something like the secant method whose convergence is slower than that of Newton's method.

It is important to review the proof of quadratic convergence of Newton's Method before implementing it. Specifically, one should review the assumptions made in the proof. For situations where the method fails to converge, it is because the assumptions made in this proof are not met.

If the first derivative is not well behaved in the neighborhood of a particular root, the method may overshoot, and diverge from that root. An example of a function with one root, for which the derivative is not well behaved in the neighborhood of the root, is

for which the root will be overshot and the sequence of will diverge. For , the root will still be overshot, but the sequence will oscillate between two values. For , the root will still be overshot but the sequence will converge, and for the root will not be overshot at all.

In some cases, Newton's method can be stabilized by using successive over-relaxation, or the speed of convergence can be increased by using the same method.

If a stationary point of the function is encountered, the derivative is zero and the method will terminate due to division by zero.

A large error in the initial estimate can contribute to non-convergence of the algorithm. To overcome this problem one can often linearise the function that is being optimized using calculus, logs, differentials, or even using evolutionary algorithms, such as the Stochastic Funnel Algorithm. Good initial estimates lie close to the final globally optimal parameter estimate. In nonlinear regression, the sum of squared errors (SSE) is only "close to" parabolic in the region of the final parameter estimates. Initial estimates found here will allow the Newton-Raphson method to quickly converge. It is only here that the Hessian matrix of the SSE is positive and the first derivative of the SSE is close to zero.

In a robust implementation of Newton's method, it is common to place limits on the number of iterations, bound the solution to an interval known to contain the root, and combine the method with a more robust root finding method.

If the root being sought has multiplicity greater than one, the convergence rate is merely linear (errors reduced by a constant factor at each step) unless special steps are taken. When there are two or more roots that are close together then it may take many iterations before the iterates get close enough to one of them for the quadratic convergence to be apparent. However, if the multiplicity formula_8 of the root is known, the following modified algorithm preserves the quadratic convergence rate:

This is equivalent to using successive over-relaxation. On the other hand, if the multiplicity of the root is not known, it is possible to estimate formula_8 after carrying out one or two iterations, and then use that value to increase the rate of convergence.

Suppose that the function has a zero at , i.e., , and is differentiable in a neighborhood of .

If is continuously differentiable and its derivative is nonzero at , then there exists a neighborhood of such that for all starting values in that neighborhood, the sequence will converge to .

If the function is continuously differentiable and its derivative is not 0 at and it has a second derivative at then the convergence is quadratic or faster. If the second derivative is not 0 at then the convergence is merely quadratic. If the third derivative exists and is bounded in a neighborhood of , then:

where

If the derivative is 0 at , then the convergence is usually only linear. Specifically, if is twice continuously differentiable, and , then there exists a neighborhood of such that for all starting values in that neighborhood, the sequence of iterates converges linearly, with rate 1/2 Alternatively if and for ,  in a neighborhood of , being a zero of multiplicity , and if then there exists a neighborhood of such that for all starting values in that neighborhood, the sequence of iterates converges linearly.

However, even linear convergence is not guaranteed in pathological situations.

In practice these results are local, and the neighborhood of convergence is not known in advance. But there are also some results on global convergence: for instance, given a right neighborhood of , if is twice differentiable in and if , in , then, for each in the sequence is monotonically decreasing to .

According to Taylor's theorem, any function which has a continuous second derivative can be represented by an expansion about a point that is close to a root of . Suppose this root is . Then the expansion of about is:
where the Lagrange form of the Taylor series expansion remainder is

where is in between and .

Since is the root, () becomes:
Dividing equation () by and rearranging gives
Remembering that is defined by
one finds that

That is,
Taking absolute value of both sides gives

Equation () shows that the rate of convergence is quadratic if the following conditions are satisfied:


The term "sufficiently" close in this context means the following:
\right |<C\left |{\frac {f"(\alpha)}{f'(\alpha)}}\right |,</math> for some ;

Finally, () can be expressed in the following way:
where is the supremum of the variable coefficient of on the interval defined in condition 1, that is:

The initial point has to be chosen such that conditions 1 to 3 are satisfied, where the third condition requires that .

The disjoint subsets of the basins of attraction—the regions of the real number line such that within each region iteration from any point leads to one particular root—can be infinite in number and arbitrarily small. For example, for the function , the following initial conditions are in successive basins of attraction:

Newton's method is only guaranteed to converge if certain conditions are satisfied. If the assumptions made in the proof of quadratic convergence are met, the method will converge. For the following subsections, failure of the method to converge indicates that the assumptions made in the proof were not met.

In some cases the conditions on the function that are necessary for convergence are satisfied, but the point chosen as the initial point is not in the interval where the method converges. This can happen, for example, if the function whose root is sought approaches zero asymptotically as goes to or . In such cases a different method, such as bisection, should be used to obtain a better estimate for the zero to use as an initial point.

Consider the function:

It has a maximum at and solutions of at . If we start iterating from the stationary point (where the derivative is zero), will be undefined, since the tangent at (0,1) is parallel to the -axis:

The same issue occurs if, instead of the starting point, any iteration point is stationary. Even if the derivative is small but not zero, the next iteration will be a far worse approximation.

For some functions, some starting points may enter an infinite cycle, preventing convergence. Let

and take 0 as the starting point. The first iteration produces 1 and the second iteration returns to 0 so the sequence will alternate between the two without converging to a root. In fact, this 2-cycle is stable: there are neighborhoods around 0 and around 1 from which all points iterate asymptotically to the 2-cycle (and hence not to the root of the function). In general, the behavior of the sequence can be very complex (see Newton fractal). The real solution of this equation is ….

If the function is not continuously differentiable in a neighborhood of the root then it is possible that Newton's method will always diverge and fail, unless the solution is guessed on the first try.

A simple example of a function where Newton's method diverges is trying to find the cube root of zero. The cube root is continuous and infinitely differentiable, except for , where its derivative is undefined:

For any iteration point , the next iteration point will be:

The algorithm overshoots the solution and lands on the other side of the -axis, farther away than it initially was; applying Newton's method actually doubles the distances from the solution at each iteration.

In fact, the iterations diverge to infinity for every , where . In the limiting case of (square root), the iterations will alternate indefinitely between points and , so they do not converge in this case either.

If the derivative is not continuous at the root, then convergence may fail to occur in any neighborhood of the root. Consider the function

Its derivative is:

Within any neighborhood of the root, this derivative keeps changing sign as approaches 0 from the right (or from the left) while for .

So is unbounded near the root, and Newton's method will diverge almost everywhere in any neighborhood of it, even though:

In some cases the iterates converge but do not converge as quickly as promised. In these cases simpler methods converge just as quickly as Newton's method.

If the first derivative is zero at the root, then convergence will not be quadratic. Let

then and consequently

So convergence is not quadratic, even though the function is infinitely differentiable everywhere.

Similar problems occur even when the root is only "nearly" double. For example, let

Then the first few iterations starting at are
it takes six iterations to reach a point where the convergence appears to be quadratic.

If there is no second derivative at the root, then convergence may fail to be quadratic. Let
Then
And
except when where it is undefined. Given ,

which has approximately times as many bits of precision as has. This is less than the 2 times as many which would be required for quadratic convergence. So the convergence of Newton's method (in this case) is not quadratic, even though: the function is continuously differentiable everywhere; the derivative is not zero at the root; and is infinitely differentiable except at the desired root.

When dealing with complex functions, Newton's method can be directly applied to find their zeroes. Each zero has a basin of attraction in the complex plane, the set of all starting values that cause the method to converge to that particular zero. These sets can be mapped as in the image shown. For many complex functions, the boundaries of the basins of attraction are fractals.

In some cases there are regions in the complex plane which are not in any of these basins of attraction, meaning the iterates do not converge. For example, if one uses a real initial condition to seek a root of , all subsequent iterates will be real numbers and so the iterations cannot converge to either root, since both roots are non-real. In this case almost all real initial conditions lead to chaotic behavior, while some initial conditions iterate either to infinity or to repeating cycles of any finite length.

Curt McMullen has shown that for any possible purely iterative algorithm similar to Newton's Method, the algorithm will diverge on some open regions of the complex plane when applied to some polynomial of degree 4 or higher. However, McMullen gave a generally convergent algorithm for polynomials of degree 3.

One may also use Newton's method to solve systems of (nonlinear) equations, which amounts to finding the zeroes of continuously differentiable functions . In the formulation given above, one then has to left multiply with the inverse of the Jacobian matrix instead of dividing by :

Rather than actually computing the inverse of the Jacobian matrix, one can save time by solving the system of linear equations

for the unknown .

The -dimensional variant of Newton's method can be used to solve systems of greater than (nonlinear) equations as well if the algorithm uses the generalized inverse of the non-square Jacobian matrix instead of the inverse of . If the nonlinear system has no solution, the method attempts to find a solution in the non-linear least squares sense. See Gauss–Newton algorithm for more information.

Another generalization is Newton's method to find a root of a functional defined in a Banach space. In this case the formulation is

where is the Fréchet derivative computed at . One needs the Fréchet derivative to be boundedly invertible at each in order for the method to be applicable. A condition for existence of and convergence to a root is given by the Newton–Kantorovich theorem.

In -adic analysis, the standard method to show a polynomial equation in one variable has a -adic root is Hensel's lemma, which uses the recursion from Newton's method on the -adic numbers. Because of the more stable behavior of addition and multiplication in the -adic numbers compared to the real numbers (specifically, the unit ball in the -adics is a ring), convergence in Hensel's lemma can be guaranteed under much simpler hypotheses than in the classical Newton's method on the real line.

The Newton–Fourier method is Joseph Fourier's extension of Newton's method to provide bounds on the absolute error of the root approximation, while still providing quadratic convergence.

Assume that is twice continuously differentiable on and that contains a root in this interval. Assume that on this interval (this is the case for instance if , , and , and on this interval). This guarantees that there is a unique root on this interval, call it . If it is concave down instead of concave up then replace by since they have the same roots.

Let be the right endpoint of the interval and let be the left endpoint of the interval. Given , define

which is just Newton's method as before. Then define

where the denominator is and not . The iterations will be strictly decreasing to the root while the iterations will be strictly increasing to the root. Also,

so that distance between and decreases quadratically.

When the Jacobian is unavailable or too expensive to compute at every iteration, a quasi-Newton method can be used.

Newton's method can be generalized with the q-analog of the usual derivative. Its convergence is discussed in .

A nonlinear equation has multiple solutions in general. But if the initial value is not appropriate, Newton's method may not converge to the desired solution or may converge to the same solution found earlier. When we have already found N solutions of formula_38, then the next root can be found by applying Newton's method to the next equation (, ):
This method is applied to obtain zeros of the Bessel function of the second kind ().

Hirano's modified Newton method is a modification conserving the convergence of Newton method and avoiding unstableness (). It is developed to solve complex polynomials.

Newton's method can be used to find a minimum or maximum of a function formula_40. The derivative is zero at a minimum or maximum, so local minima and maxima can be found by applying Newton's method to the derivative. The iteration becomes:

An important application is Newton–Raphson division, which can be used to quickly find the reciprocal of a number, using only multiplication and subtraction.

Finding the reciprocal of amounts to finding the root of the function
Newton's iteration is
Therefore, Newton's iteration needs only two multiplications and one subtraction.

This method is also very efficient to compute the multiplicative inverse of a power series.

Many transcendental equations can be solved using Newton's method. Given the equation
with and/or a transcendental function, one writes
The values of that solve the original equation are then the roots of , which may be found via Newton's method.

Newton's method is applied to the ratio of Bessel functions in order to obtain its root.

A numerical verification for solutions of nonlinear equations has been established by using Newton's method multiple times and forming a set of solution candidates.

Consider the problem of finding the square root of a number. Newton's method is one of many methods of computing square roots.

For example, if one wishes to find the square root of 612, this is equivalent to finding the solution to

The function to use in Newton's method is then

with derivative

With an initial guess of 10, the sequence given by Newton's method is

where the correct digits are underlined. With only a few iterations one can obtain a solution accurate to many decimal places.

Consider the problem of finding the positive number with . We can rephrase that as finding the zero of . We have . Since for all and for , we know that our solution lies between 0 and 1. We try a starting value of . (Note that a starting value of 0 will lead to an undefined result, showing the importance of using a starting point that is close to the solution.)

The correct digits are underlined in the above example. In particular, is correct to 12 decimal places. We see that the number of correct digits after the decimal point increases from 2 (for ) to 5 and 10, illustrating the quadratic convergence.

The following is an example of an implementation of the Newton's Method for finding a root of a function codice_1 which has derivative codice_2.

The initial guess will be and the function will be so that .

Each new iterative of Newton's method will be denoted by codice_3. We will check during the computation whether the denominator (codice_4) becomes too small (smaller than codice_5), which would be the case if , since otherwise a large amount of error could be introduced.





</doc>
<doc id="22146" url="https://en.wikipedia.org/wiki?curid=22146" title="New Order (band)">
New Order (band)

New Order are an English rock band formed in 1980 by vocalist and guitarist Bernard Sumner, bassist Peter Hook and drummer Stephen Morris. New Order were formed after the demise of their previous band Joy Division, following the suicide of vocalist Ian Curtis. They were joined by Gillian Gilbert on keyboards later that year. Their integration of post-punk with electronic and dance music made them one of the most critically acclaimed and influential bands of the 1980s. They were the flagship band for Manchester-based independent record label Factory Records and its nightclub The Haçienda. They worked in long-term collaboration with graphic designer Peter Saville.

While the band's early years were shadowed by the legacy of Joy Division, their experience of the early 1980s New York club scene saw New Order increasingly incorporate dance rhythms and electronic instrumentation into their work. The band's 1983 hit "Blue Monday" became the best-selling 12-inch single of all time and a popular club track. In the 1980s, they released successful albums such as "Power, Corruption & Lies" (1983), "Technique" (1989) and the singles compilation "Substance" (1987). They disbanded in 1993 to work on individual projects, and reunited in 1998. In the years since, the band has gone through various hiatuses and personnel changes, most prominently the departure of Hook in 2007. They released their tenth studio album "Music Complete" in 2015.

Between 1977 and 1980, Ian Curtis, Peter Hook, Stephen Morris, and Bernard Sumner were members of the post-punk band Joy Division, often featuring heavy production input from producer Martin Hannett. Curtis committed suicide on 18 May 1980, the day before Joy Division were scheduled to depart for their first American tour, and prior to release of the band's second album, "Closer". The rest of the band decided soon after Curtis's death that they would carry on. Prior to his death, the members of Joy Division had agreed not to continue under the Joy Division name should any one member leave. On 29 July 1980, the still unnamed trio debuted live at Manchester's Beach Club. Rob Gretton, the band's manager for over twenty years, is credited for having found the name "New Order" in an article in "The Guardian" entitled "The People's New Order of Kampuchea". The band adopted this name, despite its previous use for former Stooge Ron Asheton's band The New Order. The group states that the name New Order (as was also the case with "Joy Division") does not draw a direct line to National Socialism or Fascism.

The band rehearsed with each member taking turns on vocals. Sumner ultimately took the role, as he could sing when he wasn't playing his guitar. They wanted to complete the line-up with someone they knew well and whose musical skill and style was compatible with their own. Gretton suggested Morris's girlfriend Gillian Gilbert, and she was invited to join the band in early October 1980, as keyboardist and guitarist. Her first live performance with the band occurred at The Squat in Manchester on 25 October 1980.

The initial release as New Order was the single "Ceremony", backed with "In a Lonely Place". These two songs were written in the weeks before Curtis took his own life. With the release of "Movement" in November 1981, New Order initially started on a similar route as their previous incarnation, performing dark, melodic songs, albeit with an increased use of synthesisers. The band viewed the period as a low point, as they were still reeling from Curtis' death. Hook commented that the only positive thing to come out of the "Movement" sessions was that producer Martin Hannett had showed the band how to use a mixing board, which allowed them to produce records by themselves from then on. More recently, Hook indicated a change of heart: "I think "Movement" gets a raw deal in general really – for me, when you consider the circumstances in which it was written, it is a fantastic record."

New Order visited New York City again in 1981, where the band were introduced to post-disco, freestyle and electro. The band had taken to listening to Italian disco to cheer themselves up, while Morris taught himself drum programming. The singles that followed, "Everything's Gone Green" and "Temptation", saw a change in direction toward dance music.

The Haçienda, Factory Records' own nightclub (largely funded by New Order) opened in May 1982 in Manchester and was even issued a Factory catalogue number: FAC51. The opening of UK's first ever superclub was marked by a nearly 23-minute instrumental piece originally entitled "Prime 5 8 6", but released 15 years later as "Video 5 8 6". Composed primarily by Sumner and Morris, "Prime 5 8 6"/"Video 5 8 6" was an early version of "5 8 6" that contained rhythm elements that would later surface on "Blue Monday" and "Ultraviolence".

"Power, Corruption & Lies", released in May 1983, was a synthesiser-based outing and a dramatic change in sound from Joy Division and the preceding album, although the band had been hinting at the increased use of technology during the music-making process for a number of years then, including their work as Joy Division. Starting from what earlier singles had hinted, this was where the band had found their footing, mixing early techno music with their earlier guitar-based sound and showing the strong influence of acts like Kraftwerk and Giorgio Moroder. Even further in this direction was the electronically sequenced, four-on-the-floor single "Blue Monday". Inspired by Klein & MBO's "Dirty Talk" and Sylvester's disco classic, "You Make Me Feel (Mighty Real)", "Blue Monday" became the best-selling independent 12" single of all time in the UK; however, (much to the chagrin of the buying public) it was not on the track list of "Power, Corruption & Lies". This resulted in a sticker being applied to unsold copies of "Power, Corruption & Lies" album saying, "DOES NOT CONTAIN BLUE MONDAY". The song was included however on the cassette format in some countries, such as Australia and New Zealand, and on the original North American CD release of the album, alongside its B-side, "The Beach". "Blue Monday" was also included on the 2008 collector's edition of "Power, Corruption & Lies".

The band were in fact, resistant to albums. Peter and Bernard — repeatedly — protested the very idea of albums. In their view, a band should be making each individual song the best it can be, forget the concept of albums and their “filler” material. This is why “Blue Monday” was not included on Power Corruption and Lies, precisely because it was the power, corruption and lies of the music business that forced them to compromise into making albums in the first place. 

The 1983 single "Confusion" firmly established the group as a dance music force, inspiring many musicians in subsequent years. In 1984 they followed the largely synthesised single "Thieves Like Us" with the heavy guitar-drum-bass rumble of "Murder", a not-too-distant cousin of "Ecstasy" from the "Power, Corruption & Lies" album. KROQ Los Angeles DJ Jed The Fish claims New Order had more to do with the emergence of house music than the Warehouse music of Chicago and “Frankie Knuckles and the whole so-called House music scene. Unless you were actually from regional Chicago, did you ever hear of House music until New Order? Be real, now.”

1985's "Low-Life" refined and sometimes mixed the two styles, brandishing "The Perfect Kiss"—the video for which was filmed by Jonathan Demme—and "Sub-culture". In February 1986, the soundtrack album to "Pretty in Pink" featuring "Shellshock" was released on A&M Records. An instrumental version of "Thieves Like Us" and the instrumental "Elegia" appeared in the film but were not on the soundtrack album. Later that summer, New Order headlined a line-up that included the Smiths, the Fall, and A Certain Ratio during the Festival of the Tenth Summer at Manchester's G-Mex.

"Brotherhood" (1986) divided the two approaches onto separate album sides. The album notably featured "Bizarre Love Triangle" and "Angel Dust" (of which a remixed instrumental version is available on the UK "True Faith" CD video single, under the title "Evil Dust"), a track which marries a synth break beat with "Low-Life"-era guitar effects. While New Order toured North America with friends Echo & the Bunnymen, the summer of 1987 saw the release of the compilation "Substance", which featured the new single "True Faith". "Substance" was an important album in collecting the group's 12-inch singles onto CD for the first time and featured new versions of "Temptation" and "Confusion"—referred to as "Temptation '87" and "Confusion '87". A second disc featured several of the B-sides from the singles on the first disc, as well as additional A-sides "Procession" and "Murder". The single, "True Faith", with its surreal video, became a hit on MTV and the band's first American top 40 hit. The single's B-side, "1963"—originally planned on being the A-side until the group's label convinced them to release "True Faith" instead—would later be released as a single in its own right several years later, with two new versions.

In December 1987, the band released a further single, "Touched by the Hand of God", with a Kathryn Bigelow-directed video parodying glam-metal. The single reached number 20 on the UK Singles Chart and number 1 in the UK Independent Singles chart, but would not appear on an album until the 1994 compilation "The Best of New Order".

By this time, the group was heavily influenced by the Balearic sounds of Ibiza, which were making their way into the Haçienda. Partly recorded at Mediterranean Sound studios on Ibiza, "Technique" was released in February 1989. The album entered the charts at number one in the UK and contained a mix of acid house influence (as on opening track "Fine Time") and a more traditional rock sound (as on the single "Run 2"). The album is a blend of upbeat, accessible music coupled with blunt, poignant lyrics. During the summer of 1989, New Order supported "Technique" by touring with Public Image Ltd, Throwing Muses and The Sugarcubes across the United States and Canada in what the press dubbed the "Monsters of Alternative Rock" tour. Around this time, band members also began side projects including Electronic (Sumner with Johnny Marr) and Revenge (Hook with Davyth Hicks). Morris and Gilbert began to work together on outside TV theme production work. Run 2's guitar break sampled part of John Denver's song Leaving on a Jet Plane which was performed by Peter, Paul and Mary. The case was settled out of court and the song has since been credited to both New Order and John Denver.

In 1990, New Order recorded the official song of the England national football team's 1990 World Cup campaign, "World in Motion", under the ad-hoc band name EnglandNewOrder. The song, co-written with comedian Keith Allen, was the band's sole number one UK hit. The song was originally planned to be titled "E for England", however the Football Association vetoed the title upon realising that this was a reference to ecstasy; a drug heavily associated with the Haçienda. (Allen claimed that his original draft lyrics included "E is for England, England starts with E / We'll all be smiling when we're in Italy.") The song also featured chanting from members of the England team and Allen, and a guest rap from left winger John Barnes. It was again produced by Stephen Hague, who the band chose to produce their next album.

The band's next album "Republic" was shadowed by the collapse of their longtime label Factory Records. The label had been ailing due to financial difficulties, and was forced to declare bankruptcy in 1992. New Order never had a formal contract with Factory. Although unusual for a major group, this was Factory's standard practice until the mid-1980s. Because of this, the band, rather than Factory Records, legally owned all of their recordings. This has been cited by Wilson himself as the main reason London Records' 1992 offer to buy the ailing label fell through. Following Factory's collapse, New Order signed with London, as did Morris and Gilbert separately for their side project The Other Two, whose debut album was originally intended for release on Factory. "Republic", released around the world in 1993, spawned the singles "Regret"—New Order's highest-charting single in the US—"Ruined in a Day", "World", and "Spooky".

Following the release and promotion of "Republic", the band put New Order on hold while focusing on side projects; with The Other Two's debut album released in 1993. In 1994, a second singles collection was released, entitled "The Best of New Order". It featured all of the band's singles since "Substance" as well as a few extra tracks: "Vanishing Point" (from 1989's "Technique"), "The Perfect Kiss", "Thieves Like Us", "Shellshock", and new recordings of "True Faith", "Bizarre Love Triangle", "1963", and "Round & Round". The new versions of "True Faith" and "1963" (the latter as a more guitar-oriented version produced by Arthur Baker) were released as singles to promote the album. In the US, the track listing was altered to set it apart from "Substance" as well as the UK release of "The Best of New Order" which had been available months prior. This collection was followed by a remix album, "The Rest of New Order", featuring a selection of existing and newly commissioned mixes of classic New Order tracks. Some versions contained an extra disc or cassette composed entirely of remixes of "Blue Monday". "Blue Monday" was released as a single for a third time to promote the collection.

The group reconvened in 1998 at the suggestion of Rob Gretton. Nearly five years had passed since they had last seen each other. Sumner said, "We decided before we agreed to doing any gig, to have a meeting, and if anyone had any grudges to bear, to iron them out." By the second meeting everyone agreed to continue playing, scheduling their reunion gig for the Phoenix Festival that same year. In addition to rarer songs, New Order also decided to begin playing Joy Division songs again. When the Phoenix Festival was cancelled due to low ticket sales, New Order instead played the last night of that year's Reading Festival.

Their 2001 release "Get Ready" largely departed from their more electronic style and focused on more guitar oriented music. According to Sumner, ""Get Ready" was guitar-heavy simply because we felt that we'd left that instrument alone for a long time." Longtime fan Billy Corgan of The Smashing Pumpkins played guitar and sang back-up on the track "Turn My Way," and in 2001 toured with the band on dates in the UK, US, and Japan for a short period of time. Phil Cunningham (formerly of Marion) joined the band in a live capacity, deputising for Gilbert who declined to tour in favour of caring for her and Morris' children. Primal Scream's Bobby Gillespie provided vocals on the track "Rock the Shack". Singles from the album included "Crystal", "60 Miles an Hour" and "Someone Like You".

In 2002, "Q" featured New Order on their list of the "50 Bands to See Before You Die", although this was as part of a sub-list of "5 Bands That Could Go Either Way". Both New Order and Joy Division were portrayed in the Michael Winterbottom film "24 Hour Party People", depicting the rise and fall of Factory Records as seen through the eyes of label founder Tony Wilson. Cameos by Wilson himself, along with Mark E. Smith of The Fall and former members of Happy Mondays and Inspiral Carpets, lent a degree of legitimacy to the proceedings. The film touched on some of Factory's other artists, including Happy Mondays and The Durutti Column. The soundtrack featured the new track "Here to Stay", produced by the Chemical Brothers, which was released as a single. The single's music video highlighted scenes taken from the film.

The band released a new album on 27 March 2005, titled "Waiting for the Sirens' Call", their first with new member Phil Cunningham. Cunningham replaced Gilbert (now married to Morris) so she could look after their children. Singles from this album were "Krafty", "Jetstream" (which features guest vocals by Ana Matronic from Scissor Sisters), and the title track. At the 2005 NME Awards, New Order and Joy Division received the award for "Godlike Geniuses" (for lifetime achievement). Previous winners include Ozzy Osbourne, The Clash, and Happy Mondays. In 2006 the album track "Guilt Is a Useless Emotion" was nominated for a Grammy Award in the category of Best Dance Recording.

In the autumn of 2005, the group released another greatest hits compilation, in the form of "Singles". The two-disc release was an updated version of the "Substance" collection and contained every single released from their 1981 debut all the way through to "Waiting for the Sirens' Call". However, unlike "Substance", which focused almost exclusively on the 12" versions of the group's singles, "Singles" collected the 7" versions, many of which (like "Ceremony", "Temptation" and "Confusion") had never been released on CD. The album was accompanied by a two-disc DVD set, titled "Item", that collected the extended UK version of "NewOrderStory" with a DVD of all New Order music videos as well as two newly commissioned videos for "Temptation '87" and "Ceremony".

The "New Order: Live in Glasgow" DVD was recorded at the Glasgow Academy in 2006 and features 18 tracks, including 4 Joy Division songs. Next to that, the release also contains a bonus disc of footage from the band's personal archive including 1980s footage from Glastonbury, Rome, Cork, Rotterdam and Toronto.

In 2006, the band played several one-off live dates as well as short tours in the UK, Brazil and Argentina. After their Buenos Aires show in November 2006, Peter Hook suggested that the band should stop touring. In early May 2007, Hook was interviewed by British radio station XFM – originally to talk about his contribution to the debut album of Jane's Addiction singer Perry Farrell's new band Satellite Party – and stated that "Me and Bernard aren't working together." Further complicating the news, NewOrderOnline, a website with support from New Order management, reported that according to "a source close to the band", "The news about the split is false... New Order still exists despite what [Hook] said … Peter Hook can leave the band, but this doesn't mean the end of New Order." However, Sumner revealed in 2009 that he no longer wished to make music as New Order.

In September 2011, the band announced that they would perform for the first time since 2006, at the Ancienne Belgique, Brussels on 17 October and at the Bataclan, Paris on 18 October. The band's line-up included keyboardist Gillian Gilbert, who returned to the band after a ten-year break, and Bad Lieutenant bassist Tom Chapman in place of Peter Hook. They played subsequent shows in London and South America in December.

In December 2011, New Order released "Live at the London Troxy", a live album from their performance of 10 December 2011 at The Troxy in London. This release featured the new lineup and their first show in London in over five years.
They continued to tour throughout 2012, including a short tour of New Zealand and Australia in February/March. They played at the 'T in the Park' festival in Scotland on 3 and 4 July 2012 and at the EXIT Festival in Novi Sad Serbia on 13 July 2012. New Order performed at Hyde Park with Blur and The Specials to celebrate the 2012 Summer Olympics closing ceremony.

In December 2012 it was announced that "Lost Sirens" would be released in the United Kingdom on 14 January 2013. "Lost Sirens" is an eight-track album of tracks left out of "Waiting for the Sirens' Call". The album was discussed by Gillian Gilbert in a Brazilian interview to promote the band’s appearance in São Paulo. She acknowledged issues with former member Peter Hook, and stated there was "a lot going on behind the scenes on the copyright" delaying the release.

The band debuted their first newly-written song since the "Waiting for the Sirens' Call" sessions, titled "Singularity", during Lollapalooza Chile in March 2014. In July, the group toured North America, where they debuted the song "Plastic". On 2 September it was announced that the band decided to release their new album through Mute Records. The New Order catalogue remains with Warner Music.

On 22 September 2015, the band released a new album, "Music Complete", their first without Peter Hook. The album was produced mostly by the band themselves, except "Singularity" and "Unlearn This Hatred", both produced by Tom Rowlands, while "Superheated" features additional production by Stuart Price.

In November 2015, Peter Hook sued Bernard Sumner, Stephen Morris and Gillian Gilbert. In an objection, he claimed that they set up a new company behind his back and it has generated an income of £7.8 million in four years while he received only a fraction of that. The three members insisted they had treated Mr. Hook fairly and that his stake in the band's royalties was reasonable. The judge ruled that there was "at least a reasonable prospect" of Mr. Hook proving that he was not getting a fair share of royalties and other income. He was willing to hear the case but urged the parties to come to an agreement rather than suffer legal costs of around £900,000.

On 13 July 2017, New Order played a concert at Manchester International Festival with Liam Gillick.

On 20 September 2017, a posting on New Order's official website announced that a full and final settlement had been reached in the long running disputes with their former bassist Peter Hook.

In 1988, Bernard Sumner teamed up with former Smiths guitarist Johnny Marr to form the group Electronic, also enlisting the help of Neil Tennant and Chris Lowe of the Pet Shop Boys. Electronic regrouped in 1996 for "Raise the Pressure", which also featured Karl Bartos (formerly of Kraftwerk). The project's third album "Twisted Tenderness" was released in 1999 after which the band dissolved.

In June 2009, Bernard Sumner formed a new band called Bad Lieutenant with Phil Cunningham (guitar) and Jake Evans (guitar and vocals). Their album "Never Cry Another Tear" was released on 5 October 2009. In addition to Cunningham and Evans the album also features appearances by Stephen Morris (drums), Jack Mitchell (drums), Tom Chapman (bass) and Alex James (bass). The live band included Morris on drums and Tom Chapman on bass.

Hook has been involved with several other projects. In the 1990s, Hook recorded with Killing Joke with a view to joining the band. However, original bassist Martin 'Youth' Glover instead returned to the band. In 1995 he toured with The Durutti Column. He has recorded one album with the band Revenge with Davyth Hicks and Chris Jones and two with Monaco (both as bassist, keyboardist and lead vocalist) with David Potts. Monaco scored a club and alternative radio hit with "What Do You Want From Me?" in 1997. Hook also formed a band called Freebass with fellow bass players Mani (The Stone Roses) and Andy Rourke (The Smiths) and vocalist Gary Briggs, which was active from 2007 to 2010. He also contributed to Perry Farrell's Satellite Party. Hook's current band Peter Hook and The Light is touring Joy Division and New Order albums in their entirety.

In 1990 Gilbert and Morris formed their own band, The Other Two. The Other Two released its first single "Tasty Fish" in 1991 and released two albums, "The Other Two & You" in 1993 and "Super Highways" in 1999. They have also been involved in scoring television soundtracks. In 2007, Gilbert and Morris remixed two tracks for the Nine Inch Nails remixes album "Year Zero Remixed".

"BeMusic" was a name the band used for their publishing company (the LP label for "Movement" says "B Music" in large letters, though using an italic ß for the letter B). All four members of the band used the name for production work for other artists' recordings between 1982 and 1985.

The first BeMusic credit was for Peter Hook producing Stockholm Monsters in 1982. Other artists with producer or musician credit for "BeMusic" were 52nd Street, Section 25, Marcel King, Quando Quango, Paul Haig, Thick Pigeon, Nyam Nyam and Life.

Their production work as BeMusic was collected on two LTM Recordings compilation CDs, "Cool As Ice: The BeMusic Productions" and "Twice As Nice" (which also included production work by Donald Johnson, of A Certain Ratio, and Arthur Baker).

New Order's music mixes rock with dance music, as can be seen on signature tracks such as 1982's "Temptation", 1983's "Blue Monday" and 1987's "True Faith". Founding member Hook stated that the band's shift from playing cold dark tracks from 1981 to producing electro/rock tracks from 1982 was inspired by the music of German electronic group Kraftwerk, US rock band Sparks who had produced disco/electro-rock music with producer Giorgio Moroder on their "No. 1 in Heaven" album, and also the Moroder/Donna Summer collaboration on "I Feel Love". New Order's collaboration with New York DJ Arthur Baker was inspired by the records' sounds of Grandmaster Flash and the Furious Five and Afrika Bambaataa & the Soulsonic Force. This synthesis laid down the groundwork for dance-rock groups of today. The group's album art earned them the status of icons in the alternative community, and has shown considerable longevity. According to a unsigned "Allmusic" text, the band are also regarded as "the first alternative dance" music group with their fusion of "used icy, gloomy post-punk with Kraftwerk-style synth-pop" and were also labeled as synth-pop, post-punk, new wave, dance-rock and electronica.

They have heavily influenced techno, rock, and pop musicians including the Pet Shop Boys, 808 State, The Chemical Brothers, The Killers, Arcade Fire and Moby, and were themselves influenced by the likes of David Bowie, Neu!, Kraftwerk, Cabaret Voltaire and Giorgio Moroder. They have also significantly influenced electro, freestyle and house. New Order's Kraftwerk influence was acknowledged by their single "Krafty", which had cover art referencing "Autobahn".

Bassist Peter Hook contributed to New Order's sound by developing an idiosyncratic bass guitar technique. He often used the bass as a lead instrument, playing melodies on the high strings with a signature heavy chorus effect, leaving the actual basslines to keyboards or sequencers. This has often been cited as a defining characteristic of the New Order sound. 

Drummer Stephen Morris plays a mixture of acoustic and electronic drums, and in many cases plays along seamlessly with sequenced parts. All the band members could and did switch instruments throughout gigs, as evidenced on Jonathan Demme's video for "The Perfect Kiss" and the concert videos "Taras Shevchenko" (recorded in New York, November 1981) and "Pumped Full of Drugs" (Tokyo, May 1985). During such live gigs, Sumner alternated between guitar, keyboards, melodica and (on the track "Confusion") bass; Gilbert switched between keyboards and guitar, Morris between drums and keyboards, and Hook played both bass and electronic drums. "Taras Shevchenko" is also notable for the fact all four members of the group have left the stage before the final song, "Temptation", comes to a complete end.

Both New Order and Joy Division were among the most successful artists on the Factory Records label, run by Granada television personality Tony Wilson, and partnered with Factory in the financing of the Manchester club The Haçienda. The band rarely gave interviews in the 1980s, later ascribing this to not wanting to discuss Ian Curtis. This, along with the Peter Saville sleeve designs and the tendency to give short performances with no encores, gave New Order a reputation as standoffish. The band became more open in the '90s; for example, the aforementioned "NewOrderStory" (and in particular the longer UK version) featured extensive personal interviews. Speaking in 2009, fellow synthpop musician Phil Oakey described New Order's slow-burn career as cult musicians as being unusually prolonged and effective: "If you want to make a lot of money out of pop, be number 3 a lot. Like New Order did. Or The Cure. Because when you're number 1 you're everybody's; nobody really cares about you any more." Despite this, the band have commented on the unplanned nature of their career and the considerable expense lost in supporting the Haçienda.

Almost all New Order recordings bear minimalist packaging, art directed by Peter Saville. The group's record sleeves bucked the 1980s trend by rarely showing the band members (with the exception of the "Low-Life" album) or even providing basic information such as the band name or title of the release. Song names were often hidden within the shrink wrapped package, either on the disc itself (such as the "Blue Monday" single), on an inconspicuous part of an inner sleeve ("The Perfect Kiss" single), or written in a cryptic colour code invented by Saville ("Power, Corruption & Lies"). Saville said his intention was to sell the band as a "mass-produced secret" of sorts, and that the minimalist style was enough to allow fans to identify the band's products without explicit labelling. Saville frequently sent the artwork straight to the printer, unreviewed by either the band or the label.

! Year !! Awards !! Work !! Category !! Result


Former members





</doc>
<doc id="22148" url="https://en.wikipedia.org/wiki?curid=22148" title="Niccolò Fontana Tartaglia">
Niccolò Fontana Tartaglia

Niccolò Fontana Tartaglia (; 1499/1500, Brescia – 13 December 1557, Venice) was a Venetian mathematician, engineer (designing fortifications), a surveyor (of topography, seeking the best means of defense or offense) and a bookkeeper from the then-Republic of Venice (now part of Italy). He published many books, including the first Italian translations of Archimedes and Euclid, and an acclaimed compilation of mathematics. Tartaglia was the first to apply mathematics to the investigation of the paths of cannonballs, known as ballistics, in his "Nova Scientia" ("A New Science"); his work was later partially validated and partially superseded by Galileo's studies on falling bodies. He also published a treatise on retrieving sunken ships.

Niccolò Fontana was the son of Michele Fontana, a dispatch rider who travelled to neighboring towns to deliver mail. But in 1506, Michele was murdered by robbers, and Niccolo, his two siblings, and his mother were left impoverished. Niccolò experienced further tragedy in 1512 when the King Louis XII's troops invaded Brescia during the War of the League of Cambrai against Venice. The militia of Brescia defended their city for seven days. When the French finally broke through, they took their revenge by massacring the inhabitants of Brescia. By the end of battle, over 45,000 residents were killed. During the massacre, Niccolò and his family sought sanctuary in the local cathedral. But the French entered and a soldier sliced Niccolò's jaw and palate with a saber and left him for dead. His mother nursed him back to health but the young boy was left with a speech impediment, prompting the nickname "Tartaglia" ("stammerer"). After this he would never shave, and grew a beard to camouflage his scars.

There is a story that Tartaglia learned only half the alphabet from a private tutor before funds ran out, and he had to learn the rest by himself. Be that as it may, he was essentially self-taught. He and his contemporaries, working outside the academies, were responsible for the spread of classical works in modern languages among the educated middle class.

His edition of Euclid in 1543, the first translation of the "Elements" into any modern European language, was especially significant. For two centuries Euclid had been taught from two Latin translations taken from an Arabic source; these contained errors in Book V, the Eudoxian theory of proportion, which rendered it unusable. Tartaglia's edition was based on Zamberti's Latin translation of an uncorrupted Greek text, and rendered Book V correctly. He also wrote the first modern and useful commentary on the theory. Later, the theory was an essential tool for Galileo, just as it had been for Archimedes.

However, his best known work is his treatise " General Trattato di Numeri et Misure" published in Venice 1556–1560. This has been called the "best" treatise on arithmetic that appeared in the sixteenth century. Not only does Tartaglia have complete discussions of numerical operations and the commercial rules used by Italian arithmeticians in this work, but he also discusses the life of the people, the customs of merchants and the efforts made to improve arithmetic in the 16th century.

Tartaglia is perhaps best known today for his conflicts with Gerolamo Cardano. Cardano cajoled Tartaglia into revealing his solution to the cubic equations by promising not to publish them. Tartaglia divulged the secrets of the solutions of three different forms of the cubic equation in verse. Several years later, Cardano happened to see unpublished work by Scipione del Ferro who independently came up with the same solution as Tartaglia. As the unpublished work was dated before Tartaglia's, Cardano decided his promise could be broken and included Tartaglia's solution in his next publication. Even though Cardano credited his discovery, Tartaglia was extremely upset and a famous public challenge match resulted between himself and Cardano's student, Ludovico Ferrari. Widespread stories that Tartaglia devoted the rest of his life to ruining Cardano, however, appear to be completely fabricated. Mathematical historians now credit both Cardano and Tartaglia with the formula to solve cubic equations, referring to it as the "Cardano–Tartaglia formula".

Tartaglia is also known for having given an expression (Tartaglia's formula) for the volume of a tetrahedron (including any irregular tetrahedra) as the Cayley–Menger determinant of the distance values measured pairwise between its four corners:

where "d" is the distance between vertices "i" and "j". This is a generalization of Heron's formula for the area of a triangle.




</doc>
<doc id="22149" url="https://en.wikipedia.org/wiki?curid=22149" title="Nagarjuna">
Nagarjuna

Nāgārjuna (c. 150 – c. 250 CE) is widely considered one of the most important Buddhist philosophers. Along with his disciple Āryadeva, he is considered to be the founder of the Madhyamaka school of Mahāyāna Buddhism. Nāgārjuna is also credited with developing the philosophy of the Prajñāpāramitā sūtras and, in some sources, with having revealed these scriptures in the world, having recovered them from the nāgas (water spirits often depicted in the form of serpent-like humans). Furthermore, he is traditionally supposed to have written several treatises on rasayana as well as serving a term as the head of Nālandā.

Very little is reliably known of the life of Nāgārjuna, since the surviving accounts were written in Chinese and Tibetan centuries after his death. According to some accounts, Nāgārjuna was originally from South India. Some scholars believe that Nāgārjuna was an advisor to a king of the Satavahana dynasty. Archaeological evidence at Amarāvatī indicates that if this is true, the king may have been Yajña Śrī Śātakarṇi, who ruled between 167 and 196 CE. On the basis of this association, Nāgārjuna is conventionally placed at around 150–250 CE.

According to a 4th/5th-century biography translated by Kumārajīva, Nāgārjuna was born into a Brahmin family in Vidarbha (a region of Maharashtra) and later became a Buddhist.

Some sources claim that in his later years, Nāgārjuna lived on the mountain of Śrīparvata near the city that would later be called Nāgārjunakoṇḍa ("Hill of Nāgārjuna"). The ruins of Nāgārjunakoṇḍa are located in Guntur district, Andhra Pradesh. The Caitika and Bahuśrutīya nikāyas are known to have had monasteries in Nāgārjunakoṇḍa. The archaeological finds at Nagarjunakonda have not resulted in any evidence that the site was associated with Nagarjuna. The name "Nagarjunakonda" dates from the medieval period, and the 3rd-4th century inscriptions found at the site make it clear that it was known as "Vijayapuri" in the ancient period.

There exist a number of influential texts attributed to Nāgārjuna though, as there are many pseudepigrapha attributed to him, lively controversy exists over which are his authentic works. 

The "Mūlamadhyamakakārikā" is Nāgārjuna's best-known work. It is "not only a grand commentary on the Buddha's discourse to Kaccayana, the only discourse cited by name, but also a detailed and careful analysis of most of the important discourses included in the Nikayas and the agamas, especially those of the "Atthakavagga" of the "Sutta-nipata".

In the "Mūlamadhyamakakārikā", "[A]ll experienced phenomena are empty ("sunya"). This did not mean that they are not experienced and, therefore, non-existent; only that they are devoid of a permanent and eternal substance ("svabhava") because, like a dream, they are mere projections of human consciousness. Since these imaginary fictions are experienced, they are not mere names ("prajnapti")."

According to one view, that of Christian Lindtner, the works definitely written by Nāgārjuna are:

Buston considers the first six to be the main treatises of Nāgārjuna, while according to Taaranaatha only the first five are the works of Nāgārjuna. TRV Murti considers Ratnaavali, Pratitya Samutpaada Hridaya and Sutra Samuccaya to be works of Nāgārjuna as the first two are quoted profusely by Chandrakirti and the third by Shantideva.

In addition to works mentioned above, several others are attributed to
Nāgārjuna. There is an ongoing, lively controversy over which of those
works are authentic. Contemporary research suggest that these works belong
to a significantly later period, either to late 8th or early 9th century CE,
and hence can not be authentic works of Nāgārjuna.

However, several works considered important in esoteric Buddhism are
attributed to Nāgārjuna and his disciples by traditional historians
like Tāranātha from 17th century Tibet. These historians try to account
for chronological difficulties with various theories. For example, a
propagation of later writings via mystical revelation. For a useful
summary of this tradition, see Wedemeyer 2007.

Lindtner considers that the "Mahāprajñāpāramitāupadeśa" "Commentary on the Great Perfection of Wisdom" is not a genuine work of Nāgārjuna. This work is only attested in a Chinese translation by Kumārajīva.There is much discussion as to whether this is a work of Nāgārjuna, or someone else. Étienne Lamotte, who translated one third of the work into French, felt that it was the work of a North Indian bhikṣu of the Sarvāstivāda school who later became a convert to the Mahayana. The Chinese scholar-monk Yin Shun felt that it was the work of a South Indian and that Nāgārjuna was quite possibly the author. These two views are not necessarily in opposition and a South Indian Nāgārjuna could well have studied the northern Sarvāstivāda. Neither of the two felt that it was composed by Kumārajīva, which others have suggested.

From studying his writings, it is clear that Nāgārjuna was conversant with many of the Śrāvaka philosophies and with the Mahāyāna tradition. However, determining Nāgārjuna's affiliation with a specific nikāya is difficult, considering much of this material has been lost. If the most commonly accepted attribution of texts (that of Christian Lindtner) holds, then he was clearly a Māhayānist, but his philosophy holds assiduously to the Śrāvaka "Tripiṭaka", and while he does make explicit references to Mahāyāna texts, he is always careful to stay within the parameters set out by the Śrāvaka canon.

Nāgārjuna may have arrived at his positions from a desire to achieve a consistent exegesis of the Buddha's doctrine as recorded in the āgamas. In the eyes of Nāgārjuna, the Buddha was not merely a forerunner, but the very founder of the Madhyamaka system. David Kalupahana sees Nāgārjuna as a successor to Moggaliputta-Tissa in being a champion of the middle-way and a reviver of the original philosophical ideals of the Buddha.

Nāgārjuna assumes a knowledge of the definitions of the sixteen categories as given in the Nyaya Sutras, the chief text of the Hindu Nyaya school, and wrote a treatise on the pramanas where he reduced the syllogism of five members into one of three. In the Vigrahavyavartani Karika, Nāgārjuna criticizes the Nyaya theory of pramanas (means of knowledge) 

Nāgārjuna was fully acquainted with the classical Hindu philosophies of Samkhya and even the Vaiseshika.

Because of the high degree of similarity between Nāgārjuna's philosophy and Pyrrhonism, particularly the surviving works of Sextus Empiricus Thomas McEvilley suspects that Nāgārjuna was influenced by Greek Pyrrhonists texts imported into India. Pyrrho of Elis (c. 360-c. 270 BCE), who is usually credited with founding this school of skeptical philosophy, was himself influenced by Indian philosophy, when he traveled to India with Alexander the Great's army and studied with the gymnosophists.

Nāgārjuna's major thematic focus is the concept of śūnyatā (translated into English as "emptiness") which brings together other key Buddhist doctrines, particularly anātman "not-self" and pratītyasamutpāda "dependent origination", to refute the metaphysics of some of his contemporaries. For Nāgārjuna, as for the Buddha in the early texts, it is not merely sentient beings that are "selfless" or non-substantial; all phenomena (dhammas) are without any svabhāva, literally "own-being", "self-nature", or "inherent existence" and thus without any underlying essence. They are "empty" of being independently existent; thus the heterodox theories of svabhāva circulating at the time were refuted on the basis of the doctrines of early Buddhism. This is so because all things arise always dependently: not by their own power, but by depending on conditions leading to their coming into existence, as opposed to being.

Nāgārjuna means by real any entity which has a nature of its own (svabhāva), which is not produced by causes (akrtaka), which is not dependent on anything else (paratra nirapeksha).

Chapter 24 verse 14 of the Mūlamadhyamakakārikā provides one of Nāgārjuna's most famous quotations on emptiness and co-arising:

As part of his analysis of the emptiness of phenomena in the Mūlamadhyamakakārikā, Nāgārjuna critiques svabhāva in several different concepts. He discusses the problems of positing any sort of inherent essence to causation, movement, change and personal identity. Nāgārjuna makes use of the Indian logical tool of the tetralemma to attack any essentialist conceptions. Nāgārjuna’s logical analysis is based on four basic propositions:

To say that all things are 'empty' is to deny any kind of ontological foundation, therefore Nāgārjuna's view is often seen as a kind of ontological anti-foundationalism or a metaphysical anti-realism.

Understanding the nature of the emptiness of phenomena is simply a means to an end, which is nirvana. Thus Nāgārjuna's philosophical project is ultimately a soteriological one meant to correct our everyday cognitive processes which mistakenly posits svabhāva on the flow of experience.

Some scholars such as Fyodor Shcherbatskoy and T.R.V. Murti held that Nāgārjuna was the inventor of the Shunyata doctrine, however, more recent work by scholars such as Choong Mun-keat, Yin Shun and Dhammajothi Thero has argued that Nāgārjuna was not an innovator by putting forth this theory, but that, in the words of Shi Huifeng, "the connection between emptiness and dependent origination is not an innovation or creation of Nāgārjuna."

Nāgārjuna was also instrumental in the development of the two truths doctrine, which claims that there are two levels of truth in Buddhist teaching, the ultimate truth ("paramārtha satya") and the conventional or superficial truth ("saṃvṛtisatya"). The ultimate truth to Nāgārjuna is the truth that everything is empty of essence, this includes emptiness itself ('the emptiness of emptiness'). While some (Murti, 1955) have interpreted this by positing Nāgārjuna as a Neo-Kantian and thus making ultimate truth a metaphysical noumenon or an "ineffable ultimate that transcends the capacities of discursive reason", others such as Mark Siderits and Jay L. Garfield have argued that Nāgārjuna's view is that "the ultimate truth is that there is no ultimate truth" (Siderits) and that Nāgārjuna is a "semantic anti-dualist" who posits that there are only conventional truths. Hence according to Garfield:

Suppose that we take a conventional entity, such as a table. We analyze it to demonstrate its emptiness, finding that there is no table apart from its parts […]. So we conclude that it is empty. But now let us analyze that emptiness […]. What do we find? Nothing at all but the table’s lack of inherent existence. […]. To see the table as empty […] is to see the table as conventional, as dependent.

In articulating this notion in the "Mūlamadhyamakakārikā", Nāgārjuna drew on an early source in the "Kaccānagotta Sutta", which distinguishes definitive meaning ("nītārtha") from interpretable meaning ("neyārtha"):

The version linked to is the one found in the nikayas, and is slightly different from the one found in the "Samyuktagama". Both contain the concept of teaching via the middle between the extremes of existence and non-existence. Nagarjuna does not make reference to "everything" when he quotes the agamic text in his "Mūlamadhyamakakārikā".

Jay L. Garfield describes that Nāgārjuna approached causality from the four noble truths and dependent origination. Nāgārjuna distinguished two dependent origination views in a causal process, that which causes effects and that which causes conditions. This is predicated in the two truth doctrine, as conventional truth and ultimate truth held together, in which both are empty in existence. The distinction between effects and conditions is controversial. In Nāgārjuna's approach, cause means an event or state that has power to bring an effect. Conditions, refer to proliferating causes that bring a further event, state or process; without a metaphysical commitment to an occult connection between explaining and explanans. He argues nonexistent causes and various existing conditions. The argument draws from unreal causal power. Things conventional exist and are ultimately nonexistent to rest in the middle way in both causal existence and nonexistence as casual emptiness within the Mūlamadhyamakakārikā doctrine. Although seeming strange to Westerners, this is seen as an attack on a reified view of causality.

Nāgārjuna also taught the idea of relativity; in the Ratnāvalī, he gives the example that shortness exists only in relation to the idea of length. The determination of a thing or object is only possible in relation to other things or objects, especially by way of contrast. He held that the relationship between the ideas of "short" and "long" is not due to intrinsic nature (svabhāva). This idea is also found in the Pali Nikāyas and Chinese Āgamas, in which the idea of relativity is expressed similarly: "That which is the element of light ... is seen to exist on account of [in relation to] darkness; that which is the element of good is seen to exist on account of bad; that which is the element of space is seen to exist on account of form."

Nāgārjuna is often depicted in composite form comprising human and nāga characteristics. Often the nāga-aspect forms a canopy crowning and shielding his human head. The notion of the naga is found throughout Indian religious culture, and typically signifies an intelligent serpent or dragon, who is responsible for the rains, lakes and other bodies of water. In Buddhism, it is a synonym for a realised arhat, or wise person in general.





</doc>
<doc id="22151" url="https://en.wikipedia.org/wiki?curid=22151" title="Nuclear reactor">
Nuclear reactor

A nuclear reactor, formerly known as an atomic pile, is a device used to initiate and control a self-sustained nuclear chain reaction. Nuclear reactors are used at nuclear power plants for electricity generation and in propulsion of ships. Heat from nuclear fission is passed to a working fluid (water or gas), which in turn runs through steam turbines. These either drive a ship's propellers or turn electrical generators' shafts. Nuclear generated steam in principle can be used for industrial process heat or for district heating. Some reactors are used to produce isotopes for medical and industrial use, or for production of weapons-grade plutonium. Some are run only for research. As of April 2014, the IAEA reports there are 435 nuclear power reactors in operation, in 31 countries around the world.
By 2017, this increased to 447 operable reactors according to the World Nuclear Association.

Just as conventional power-stations generate electricity by harnessing the thermal energy released from burning fossil fuels, nuclear reactors convert the energy released by controlled nuclear fission into thermal energy for further conversion to mechanical or electrical forms.

When a large fissile atomic nucleus such as uranium-235 or plutonium-239 absorbs a neutron, it may undergo nuclear fission. The heavy nucleus splits into two or more lighter nuclei, (the fission products), releasing kinetic energy, gamma radiation, and free neutrons. A portion of these neutrons may later be absorbed by other fissile atoms and trigger further fission events, which release more neutrons, and so on. This is known as a nuclear chain reaction.

To control such a nuclear chain reaction, neutron poisons and neutron moderators can change the portion of neutrons that will go on to cause more fission. Nuclear reactors generally have automatic and manual systems to shut the fission reaction down if monitoring detects unsafe conditions.

Commonly used moderators include regular (light) water (in 74.8% of the world's reactors), solid graphite (20% of reactors) and heavy water (5% of reactors). Some experimental types of reactor have used beryllium, and hydrocarbons have been suggested as another possibility.

The reactor core generates heat in a number of ways:

A kilogram of uranium-235 (U-235) converted via nuclear processes releases approximately three million times more energy than a kilogram of coal burned conventionally (7.2 × 10 joules per kilogram of uranium-235 versus 2.4 × 10 joules per kilogram of coal).

A nuclear reactor coolant — usually water but sometimes a gas or a liquid metal (like liquid sodium) or molten salt — is circulated past the reactor core to absorb the heat that it generates. The heat is carried away from the reactor and is then used to generate steam. Most reactor systems employ a cooling system that is physically separated from the water that will be boiled to produce pressurized steam for the turbines, like the pressurized water reactor. However, in some reactors the water for the steam turbines is boiled directly by the reactor core; for example the boiling water reactor.

The rate of fission reactions within a reactor core can be adjusted by controlling the quantity of neutrons that are able to induce further fission events. Nuclear reactors typically employ several methods of neutron control to adjust the reactor's power output. Some of these methods arising naturally from the physics of radioactive decay and are simply accounted for during the reactor's operation, while others are mechanisms engineered into the reactor design for a distinct purpose.

The fastest method for adjusting levels of fission-inducing neutrons in a reactor is via movement of the control rods. Control rods are made of neutron poisons and therefore tend to absorb neutrons. When a control rod is inserted deeper into the reactor, it absorbs more neutrons than the material it displaces—often the moderator. This action results in fewer neutrons available to cause fission and reduces the reactor's power output. Conversely, extracting the control rod will result in an increase in the rate of fission events and an increase in power.

The physics of radioactive decay also affects neutron populations in a reactor. One such process is delayed neutron emission by a number of neutron-rich fission isotopes. These delayed neutrons account for about 0.65% of the total neutrons produced in fission, with the remainder (termed "prompt neutrons") released immediately upon fission. The fission products which produce delayed neutrons have half lives for their decay by neutron emission that range from milliseconds to as long as several minutes, and so considerable time is required to determine exactly when a reactor reaches the critical point. Keeping the reactor in the zone of chain-reactivity where delayed neutrons are "necessary" to achieve a critical mass state allows mechanical devices or human operators to control a chain reaction in "real time"; otherwise the time between achievement of criticality and nuclear meltdown as a result of an exponential power surge from the normal nuclear chain reaction, would be too short to allow for intervention. This last stage, where delayed neutrons are no longer required to maintain criticality, is known as the prompt critical point. There is a scale for describing criticality in numerical form, in which bare criticality is known as "zero dollars" and the prompt critical point is "one dollar", and other points in the process interpolated in cents.

In some reactors, the coolant also acts as a neutron moderator. A moderator increases the power of the reactor by causing the fast neutrons that are released from fission to lose energy and become thermal neutrons. Thermal neutrons are more likely than fast neutrons to cause fission. If the coolant is a moderator, then temperature changes can affect the density of the coolant/moderator and therefore change power output. A higher temperature coolant would be less dense, and therefore a less effective moderator.

In other reactors the coolant acts as a poison by absorbing neutrons in the same way that the control rods do. In these reactors power output can be increased by heating the coolant, which makes it a less dense poison. Nuclear reactors generally have automatic and manual systems to scram the reactor in an emergency shut down. These systems insert large amounts of poison (often boron in the form of boric acid) into the reactor to shut the fission reaction down if unsafe conditions are detected or anticipated.

Most types of reactors are sensitive to a process variously known as xenon poisoning, or the iodine pit. The common fission product Xenon-135 produced in the fission process acts as a neutron poison that absorbs neutrons and therefore tends to shut the reactor down. Xenon-135 accumulation can be controlled by keeping power levels high enough to destroy it by neutron absorption as fast as it is produced. Fission also produces iodine-135, which in turn decays (with a half-life of 6.57 hours) to new xenon-135. When the reactor is shut down, iodine-135 continues to decay to xenon-135, making restarting the reactor more difficult for a day or two, as the xenon-135 decays into cesium-135, which is not nearly as poisonous as xenon-135, with a half-life of 9.2 hours. This temporary state is the "iodine pit." If the reactor has sufficient extra reactivity capacity, it can be restarted. As the extra xenon-135 is transmuted to xenon-136, which is much less a neutron poison, within a few hours the reactor experiences a "xenon burnoff (power) transient". Control rods must be further inserted to replace the neutron absorption of the lost xenon-135. Failure to properly follow such a procedure was a key step in the Chernobyl disaster.

Reactors used in nuclear marine propulsion (especially nuclear submarines) often cannot be run at continuous power around the clock in the same way that land-based power reactors are normally run, and in addition often need to have a very long core life without refueling. For this reason many designs use highly enriched uranium but incorporate burnable neutron poison in the fuel rods. This allows the reactor to be constructed with an excess of fissionable material, which is nevertheless made relatively safe early in the reactor's fuel burn-cycle by the presence of the neutron-absorbing material which is later replaced by normally produced long-lived neutron poisons (far longer-lived than xenon-135) which gradually accumulate over the fuel load's operating life.

The energy released in the fission process generates heat, some of which can be converted into usable energy. A common method of harnessing this thermal energy is to use it to boil water to produce pressurized steam which will then drive a steam turbine that turns an alternator and generates electricity.

The neutron was discovered in 1932 by British physicist James Chadwick. The concept of a nuclear chain reaction brought about by nuclear reactions mediated by neutrons was first realized shortly thereafter, by Hungarian scientist Leó Szilárd, in 1933. He filed a patent for his idea of a simple reactor the following year while working at the Admiralty in London. However, Szilárd's idea did not incorporate the idea of nuclear fission as a neutron source, since that process was not yet discovered. Szilárd's ideas for nuclear reactors using neutron-mediated nuclear chain reactions in light elements proved unworkable.

Inspiration for a new type of reactor using uranium came from the discovery by Lise Meitner, Fritz Strassmann and Otto Hahn in 1938 that bombardment of uranium with neutrons (provided by an alpha-on-beryllium fusion reaction, a "neutron howitzer") produced a barium residue, which they reasoned was created by the fissioning of the uranium nuclei. Subsequent studies in early 1939 (one of them by Szilárd and Fermi) revealed that several neutrons were also released during the fissioning, making available the opportunity for the nuclear chain reaction that Szilárd had envisioned six years previously.

On 2 August 1939 Albert Einstein signed a letter to President Franklin D. Roosevelt (written by Szilárd) suggesting that the discovery of uranium's fission could lead to the development of "extremely powerful bombs of a new type", giving impetus to the study of reactors and fission. Szilárd and Einstein knew each other well and had worked together years previously, but Einstein had never thought about this possibility for nuclear energy until Szilard reported it to him, at the beginning of his quest to produce the Einstein-Szilárd letter to alert the U.S. government.

Shortly after, Hitler's Germany invaded Poland in 1939, starting World War II in Europe. The U.S. was not yet officially at war, but in October, when the Einstein-Szilárd letter was delivered to him, Roosevelt commented that the purpose of doing the research was to make sure "the Nazis don't blow us up." The U.S. nuclear project followed, although with some delay as there remained skepticism (some of it from Fermi) and also little action from the small number of officials in the government who were initially charged with moving the project forward.

The following year the U.S. Government received the Frisch–Peierls memorandum from the UK, which stated that the amount of uranium needed for a chain reaction was far lower than had previously been thought. The memorandum was a product of the MAUD Committee, which was working on the UK atomic bomb project, known as Tube Alloys, later to be subsumed within the Manhattan Project.
Eventually, the first artificial nuclear reactor, Chicago Pile-1, was constructed at the University of Chicago, by a team led by Enrico Fermi, in late 1942. By this time, the program had been pressured for a year by U.S. entry into the war. The Chicago Pile achieved criticality on 2 December 1942 at 3:25 PM. The reactor support structure was made of wood, which supported a pile (hence the name) of graphite blocks, embedded in which was natural uranium-oxide 'pseudospheres' or 'briquettes'.

Soon after the Chicago Pile, the U.S. military developed a number of nuclear reactors for the Manhattan Project starting in 1943. The primary purpose for the largest reactors (located at the Hanford Site in Washington state), was the mass production of plutonium for nuclear weapons. Fermi and Szilard applied for a patent on reactors on 19 December 1944. Its issuance was delayed for 10 years because of wartime secrecy.

"World's first nuclear power plant" is the claim made by signs at the site of the EBR-I, which is now a museum near Arco, Idaho. Originally called "Chicago Pile-4", it was carried out under the direction of Walter Zinn for Argonne National Laboratory. This experimental LMFBR operated by the U.S. Atomic Energy Commission produced 0.8 kW in a test on 20 December 1951 and 100 kW (electrical) the following day, having a design output of 200 kW (electrical).

Besides the military uses of nuclear reactors, there were political reasons to pursue civilian use of atomic energy. U.S. President Dwight Eisenhower made his famous Atoms for Peace speech to the UN General Assembly on 8 December 1953. This diplomacy led to the dissemination of reactor technology to U.S. institutions and worldwide.

The first nuclear power plant built for civil purposes was the AM-1 Obninsk Nuclear Power Plant, launched on 27 June 1954 in the Soviet Union. It produced around 5 MW (electrical).

After World War II, the U.S. military sought other uses for nuclear reactor technology. Research by the Army and the Air Force never came to fruition; however, the U.S. Navy succeeded when they steamed the USS "Nautilus" (SSN-571) on nuclear power 17 January 1955.

The first commercial nuclear power station, Calder Hall in Sellafield, England was opened in 1956 with an initial capacity of 50 MW (later 200 MW).

The first portable nuclear reactor "Alco PM-2A" used to generate electrical power (2 MW) for Camp Century from 1960.

Nuclear Reactors are classified by several methods; a brief outline of these classification methods is provided.

All commercial power reactors are based on nuclear fission. They generally use uranium and its product plutonium as nuclear fuel, though a thorium fuel cycle is also possible. Fission reactors can be divided roughly into two classes, depending on the energy of the neutrons that sustain the fission chain reaction:

Used by thermal reactors:



In 2003, the French Commissariat à l'Énergie Atomique (CEA) was the first to refer to "Gen II" types in Nucleonics Week.

The first mentioning of "Gen III" was in 2000, in conjunction with the launch of the Generation IV International Forum (GIF) plans.

"Gen IV" was named in 2000, by the United States Department of Energy (DOE) for developing new plant types.






More than a dozen advanced reactor designs are in various stages of development. Some are evolutionary from the PWR, BWR and PHWR designs above, some are more radical departures. The former include the advanced boiling water reactor (ABWR), two of which are now operating with others under construction, and the planned passively safe Economic Simplified Boiling Water Reactor (ESBWR) and AP1000 units (see Nuclear Power 2010 Program).

Generation IV reactors are a set of theoretical nuclear reactor designs currently being researched. These designs are generally not expected to be available for commercial construction before 2030. Current reactors in operation around the world are generally considered second- or third-generation systems, with the first-generation systems having been retired some time ago. Research into these reactor types was officially started by the Generation IV International Forum (GIF) based on eight technology goals. The primary goals being to improve nuclear safety, improve proliferation resistance, minimize waste and natural resource utilization, and to decrease the cost to build and run such plants.

Generation V reactors are designs which are theoretically possible, but which are not being actively considered or researched at present. Though such reactors could be built with current or near term technology, they trigger little interest for reasons of economics, practicality, or safety.

Controlled nuclear fusion could in principle be used in fusion power plants to produce power without the complexities of handling actinides, but significant scientific and technical obstacles remain. Several fusion reactors have been built, but only recently reactors have been able to release more energy than the amount of energy used in the process. Despite research having started in the 1950s, no commercial fusion reactor is expected before 2050. The ITER project is currently leading the effort to harness fusion power.

Thermal reactors generally depend on refined and enriched uranium. Some nuclear reactors can operate with a mixture of plutonium and uranium (see MOX). The process by which uranium ore is mined, processed, enriched, used, possibly reprocessed and disposed of is known as the nuclear fuel cycle.

Under 1% of the uranium found in nature is the easily fissionable U-235 isotope and as a result most reactor designs require enriched fuel.
Enrichment involves increasing the percentage of U-235 and is usually done by means of gaseous diffusion or gas centrifuge. The enriched result is then converted into uranium dioxide powder, which is pressed and fired into pellet form. These pellets are stacked into tubes which are then sealed and called fuel rods. Many of these fuel rods are used in each nuclear reactor.

Most BWR and PWR commercial reactors use uranium enriched to about 4% U-235, and some commercial reactors with a high neutron economy do not require the fuel to be enriched at all (that is, they can use natural uranium). According to the International Atomic Energy Agency there are at least 100 research reactors in the world fueled by highly enriched (weapons-grade/90% enrichment uranium). Theft risk of this fuel (potentially used in the production of a nuclear weapon) has led to campaigns advocating conversion of this type of reactor to low-enrichment uranium (which poses less threat of proliferation).

Fissile U-235 and non-fissile but fissionable and fertile U-238 are both used in the fission process. U-235 is fissionable by thermal (i.e. slow-moving) neutrons. A thermal neutron is one which is moving about the same speed as the atoms around it. Since all atoms vibrate proportionally to their absolute temperature, a thermal neutron has the best opportunity to fission U-235 when it is moving at this same vibrational speed. On the other hand, U-238 is more likely to capture a neutron when the neutron is moving very fast. This U-239 atom will soon decay into plutonium-239, which is another fuel. Pu-239 is a viable fuel and must be accounted for even when a highly enriched uranium fuel is used. Plutonium fissions will dominate the U-235 fissions in some reactors, especially after the initial loading of U-235 is spent. Plutonium is fissionable with both fast and thermal neutrons, which make it ideal for either nuclear reactors or nuclear bombs.

Most reactor designs in existence are thermal reactors and typically use water as a neutron moderator (moderator means that it slows down the neutron to a thermal speed) and as a coolant. But in a fast breeder reactor, some other kind of coolant is used which will not moderate or slow the neutrons down much. This enables fast neutrons to dominate, which can effectively be used to constantly replenish the fuel supply. By merely placing cheap unenriched uranium into such a core, the non-fissionable U-238 will be turned into Pu-239, "breeding" fuel.

In thorium fuel cycle thorium-232 absorbs a neutron in either a fast or thermal reactor. The thorium-233 beta decays to protactinium-233 and then to uranium-233, which in turn is used as fuel. Hence, like uranium-238, thorium-232 is a fertile material.

The amount of energy in the reservoir of nuclear fuel is frequently expressed in terms of "full-power days," which is the number of 24-hour periods (days) a reactor is scheduled for operation at full power output for the generation of heat energy. The number of full-power days in a reactor's operating cycle (between refueling outage times) is related to the amount of fissile uranium-235 (U-235) contained in the fuel assemblies at the beginning of the cycle. A higher percentage of U-235 in the core at the beginning of a cycle will permit the reactor to be run for a greater number of full-power days.

At the end of the operating cycle, the fuel in some of the assemblies is "spent" and is discharged and replaced with new (fresh) fuel assemblies, although in practice it is the buildup of reaction poisons in nuclear fuel that determines the lifetime of nuclear fuel in a reactor. Long before all possible fission has taken place, the buildup of long-lived neutron absorbing fission byproducts impedes the chain reaction. The fraction of the reactor's fuel core replaced during refueling is typically one-fourth for a boiling-water reactor and one-third for a pressurized-water reactor. The disposition and storage of this spent fuel is one of the most challenging aspects of the operation of a commercial nuclear power plant. This nuclear waste is highly radioactive and its toxicity presents a danger for thousands of years.

Not all reactors need to be shut down for refueling; for example, pebble bed reactors, RBMK reactors, molten salt reactors, Magnox, AGR and CANDU reactors allow fuel to be shifted through the reactor while it is running. In a CANDU reactor, this also allows individual fuel elements to be situated within the reactor core that are best suited to the amount of U-235 in the fuel element.

The amount of energy extracted from nuclear fuel is called its burnup, which is expressed in terms of the heat energy produced per initial unit of fuel weight. Burn up is commonly expressed as megawatt days thermal per metric ton of initial heavy metal.

Nuclear safety covers the actions taken to prevent nuclear and radiation accidents and incidents or to limit their consequences. The nuclear power industry has improved the safety and performance of reactors, and has proposed new safer (but generally untested) reactor designs but there is no guarantee that the reactors will be designed, built and operated correctly. Mistakes do occur and the designers of reactors at Fukushima in Japan did not anticipate that a tsunami generated by an earthquake would disable the backup systems that were supposed to stabilize the reactor after the earthquake, despite multiple warnings by the NRG and the Japanese nuclear safety administration. According to UBS AG, the Fukushima I nuclear accidents have cast doubt on whether even an advanced economy like Japan can master nuclear safety. Catastrophic scenarios involving terrorist attacks are also conceivable. An interdisciplinary team from MIT has estimated that given the expected growth of nuclear power from 2005–2055, at least four serious nuclear accidents would be expected in that period.

Some serious nuclear and radiation accidents have occurred. Nuclear power plant accidents include the SL-1 accident (1961), the Three Mile Island accident (1979), Chernobyl disaster (1986), and the Fukushima Daiichi nuclear disaster (2011). Nuclear-powered submarine mishaps include the K-19 reactor accident (1961), the K-27 reactor accident (1968), and the K-431 reactor accident (1985).

Nuclear reactors have been launched into Earth orbit at least 34 times. A number of incidents connected with the unmanned nuclear-reactor-powered Soviet RORSAT radar satellite program resulted in spent nuclear fuel re-entering the Earth's atmosphere from orbit.

Although nuclear fission reactors are often thought of as being solely a product of modern technology, the first nuclear fission reactors were in fact naturally occurring. A natural nuclear fission reactor can occur under certain circumstances that mimic the conditions in a constructed reactor. Fifteen natural fission reactors have so far been found in three separate ore deposits at the Oklo uranium mine in Gabon, West Africa. First discovered in 1972 by French physicist Francis Perrin, they are collectively known as the Oklo Fossil Reactors. Self-sustaining nuclear fission reactions took place in these reactors approximately 1.5 billion years ago, and ran for a few hundred thousand years, averaging 100 kW of power output during that time. The concept of a natural nuclear reactor was theorized as early as 1956 by Paul Kuroda at the University of Arkansas.

Such reactors can no longer form on Earth in its present geologic period. Radioactive decay of formerly abundant uranium-235 over the time span of hundreds of millions of years has reduced the proportion of this naturally occurring fissile isotope to below the amount required to sustain a chain reaction.

The natural nuclear reactors formed when a uranium-rich mineral deposit became inundated with groundwater that acted as a neutron moderator, and a strong chain reaction took place. The water moderator would boil away as the reaction increased, slowing it back down again and preventing a meltdown. The fission reaction was sustained for hundreds of thousands of years.

These natural reactors are extensively studied by scientists interested in geologic radioactive waste disposal. They offer a case study of how radioactive isotopes migrate through the Earth's crust. This is a significant area of controversy as opponents of geologic waste disposal fear that isotopes from stored waste could end up in water supplies or be carried into the environment.

Nuclear reactors produce tritium as part of normal operations, which is eventually released into the environment in trace quantities.

As an isotope of hydrogen, tritium (T) frequently binds to oxygen and forms TO. This molecule is chemically identical to HO and so is both colorless and odorless, however the additional neutrons in the hydrogen nuclei cause the tritium to undergo beta decay with a half-life of 12.3 years. Despite being measurable, the tritium released by nuclear power plants is minimal. The United States NRC estimates that a person drinking water for one year out of a well contaminated by what they would consider to be a significant tritiated water spill would receive a radiation dose of 0.3 millirem. For comparison, this is an order of magnitude less than the 4 millirem a person receives on a round trip flight from Washington, D.C. to Los Angeles, a consequence of less atmospheric protection against highly energetic cosmic rays at high altitudes.

The amounts of Strontium-90 released from nuclear power plants under normal operations is so low as to be undetectable above natural background radiation. Detectable Strontium-90 in ground water and the general environment can be traced to weapons testing and the Chernobyl accident that occurred during the mid-20th century.




</doc>
<doc id="22153" url="https://en.wikipedia.org/wiki?curid=22153" title="Nuclear power">
Nuclear power

Nuclear power is the use of nuclear reactions that release nuclear energy to generate heat, which most frequently is then used in steam turbines to produce electricity in a nuclear power plant. 
Nuclear power can be obtained from nuclear fission, nuclear decay and nuclear fusion. 
Presently, the vast majority of electricity from nuclear power is produced by nuclear fission of elements in the actinide series of the periodic table.
Nuclear decay processes are used in niche applications such as radioisotope thermoelectric generators.
The possibility of generating electricity from nuclear fusion is still at a research phase with no commercial applications.
This article mostly deals with nuclear fission power for electricity generation.

Nuclear power is one of the leading low carbon power generation methods of producing electricity.
In terms of total life-cycle greenhouse gas emissions per unit of energy generated, nuclear power has emission values comparable or lower than renewable energy.
From the beginning of its commercialization in the 1970s, nuclear power prevented about 1.84 million air pollution-related deaths and the emission of about 64 billion tonnes of carbon dioxide equivalent that would have otherwise resulted from the burning of fossil fuels in thermal power stations.

As of April 2018, there are 449 operable fission reactors in the world, with a combined electrical capacity of 394 gigawatt (GW). 
Additionally, there are 58 reactors under construction and 154 reactors planned, with a combined capacity of 63 GW and 157 GW, respectively.
Most of reactors under construction are of generation III reactor design, with the majority in Asia. 
Over 300 more reactors are proposed.

There is a social debate about nuclear power.
Proponents, such as the World Nuclear Association and Environmentalists for Nuclear Energy, contend that nuclear power is a safe, sustainable energy source that reduces carbon emissions. 
Opponents, such as Greenpeace International and NIRS, contend that nuclear power poses many threats to people and the environment.

Far-reaching fission power reactor accidents, or accidents that resulted in medium to long-lived fission product contamination of inhabited areas, have occurred in Generation I and II reactor designs. 
These include the Chernobyl disaster in 1986, the Fukushima Daiichi nuclear disaster in 2011, and the more contained Three Mile Island accident in 1979. 
There have also been some nuclear submarine accidents. 
In terms of lives lost per unit of energy generated, analysis has determined that fission-electric reactors have caused fewer fatalities per unit of energy generated than the other major sources of energy generation. 
Energy production from coal, petroleum, natural gas and hydroelectricity has caused a greater number of fatalities per unit of energy generated due to air pollution and energy accident effects.

Collaboration on research & developments towards greater passive nuclear safety, efficiency and recycling of spent fuel in future Generation IV reactors presently includes Euratom and the co-operation of more than 10 permanent countries globally.

In 1932 physicist Ernest Rutherford discovered that when lithium atoms were "split" by protons from a proton accelerator, immense amounts of energy were released in accordance with the principle of mass–energy equivalence. However, he and other nuclear physics pioneers Niels Bohr and Albert Einstein believed harnessing the power of the atom for practical purposes anytime in the near future was unlikely, with Rutherford labeling such expectations "moonshine."

The same year, his doctoral student James Chadwick discovered the neutron, which was immediately recognized as a potential tool for nuclear experimentation because of its lack of an electric charge. Experimentation with bombardment of materials with neutrons led Frédéric and Irène Joliot-Curie to discover induced radioactivity in 1934, which allowed the creation of radium-like elements at much less the price of natural radium. Further work by Enrico Fermi in the 1930s focused on using slow neutrons to increase the effectiveness of induced radioactivity. Experiments bombarding uranium with neutrons led Fermi to believe he had created a new, transuranic element, which was dubbed hesperium.
But in 1938, German chemists Otto Hahn and Fritz Strassmann, along with Austrian physicist Lise Meitner and Meitner's nephew, Otto Robert Frisch, conducted experiments with the products of neutron-bombarded uranium, as a means of further investigating Fermi's claims. They determined that the relatively tiny neutron split the nucleus of the massive uranium atoms into two roughly equal pieces, contradicting Fermi. This was an extremely surprising result: all other forms of nuclear decay involved only small changes to the mass of the nucleus, whereas this process—dubbed "fission" as a reference to biology—involved a complete rupture of the nucleus. Numerous scientists, including Leó Szilárd, who was one of the first, recognized that if fission reactions released additional neutrons, a self-sustaining nuclear chain reaction could result. Once this was experimentally confirmed and announced by Frédéric Joliot-Curie in 1939, scientists in many countries (including the United States, the United Kingdom, France, Germany, and the Soviet Union) petitioned their governments for support of nuclear fission research, just on the cusp of World War II, for the development of a nuclear weapon.

In the United States, where Fermi and Szilárd had both emigrated, this led to the creation of the first man-made reactor, known as Chicago Pile-1, which achieved criticality on December 2, 1942. This work became part of the Manhattan Project, a massive secret U.S. government military project to make enriched uranium by building large reactors to breed plutonium for use in the first nuclear weapons. The United States tested atom bombs and eventually these weapons were used to attack the cities of Hiroshima and Nagasaki.

Unlike other applications of fission energy, in commercial nuclear fission reactors, the system is designed and operated in an otherwise self-extinguishing state. The reactor specific physical phenomena, that is depended upon to continue the constant heat output, is the predictably delayed and therefore comparatively easily controlled, transformations or movements of a vital class of fission product, or reaction ember, as they decay. Operating in this delayed critical state, with the dependence on the inherently delayed transformation or movement of fission products/embers to maintain the reaction from self-extinguishing, the process occurs slow enough to permit human feedback on the temperature control. In a similar manner to fire dampers varying the opening to control the movement of wood embers towards new fuel, control rods are comparatively varied up or down, as the nuclear fuel burns up over time.

In 1945, the first widely distributed account of nuclear energy, in the form of the pocketbook "The Atomic Age", discussed the peaceful future uses of nuclear energy and depicted a future where fossil fuels would go unused. Nobel laurette Glenn Seaborg, who later chaired the Atomic Energy Commission, is quoted as saying "there will be nuclear powered earth-to-moon shuttles, nuclear powered artificial hearts, plutonium heated swimming pools for SCUBA divers, and much more".

The United Kingdom, Canada, and the USSR proceeded to research and develop nuclear industries over the course of the late 1940s and early 1950s. Electricity was generated for the first time by a nuclear reactor on December 20, 1951, at the EBR-I experimental station near Arco, Idaho, which initially produced about 100 kW. Work was also strongly researched in the United States on nuclear marine propulsion, with a test reactor being developed by 1953 (eventually, the USS Nautilus, the first nuclear-powered submarine, would launch in 1955). In 1953, American President Dwight Eisenhower gave his "Atoms for Peace" speech at the United Nations, emphasizing the need to develop "peaceful" uses of nuclear power quickly. This was followed by the 1954 Amendments to the Atomic Energy Act which allowed rapid declassification of U.S. reactor technology and encouraged development by the private sector.

On June 27, 1954, the USSR's Obninsk Nuclear Power Plant became the world's first nuclear power plant to generate electricity for a power grid, and produced around 5 megawatts of electric power.

Later in 1954, Lewis Strauss, then chairman of the United States Atomic Energy Commission (U.S. AEC, forerunner of the U.S. Nuclear Regulatory Commission and the United States Department of Energy) spoke of electricity in the future being "too cheap to meter". Strauss was very likely referring to hydrogen fusion —which was secretly being developed as part of Project Sherwood at the time—but Strauss's statement was interpreted as a promise of very cheap energy from nuclear fission. The U.S. AEC itself had issued far more realistic testimony regarding nuclear fission to the U.S. Congress only months before, projecting that "costs can be brought down... [to]... about the same as the cost of electricity from conventional sources..."

In 1955 the United Nations' "First Geneva Conference", then the world's largest gathering of scientists and engineers, met to explore the technology. In 1957 EURATOM was launched alongside the European Economic Community (the latter is now the European Union). The same year also saw the launch of the International Atomic Energy Agency (IAEA).

The world's first commercial nuclear power station, Calder Hall at Windscale, England, was opened in 1956 with an initial capacity of 50 MW (later 200 MW). The first commercial nuclear generator to become operational in the United States was the Shippingport Reactor (Pennsylvania, December 1957).

One of the first organizations to develop nuclear power was the U.S. Navy, for the purpose of propelling submarines and aircraft carriers. The first nuclear-powered submarine, , was put to sea in December 1954. As of 2016, the U.S. Navy submarine fleet is made up entirely of nuclear-powered vessels, with 75 submarines in service. Two U.S. nuclear submarines, and , have been lost at sea. The Russian Navy is currently (2016) estimated to have 61 nuclear submarines in service; eight Soviet and Russian nuclear submarines have been lost at sea. This includes the reactor accident in 1961 which resulted in 8 deaths and more than 30 other people were over-exposed to radiation. The reactor accident in 1968 resulted in 9 fatalities and 83 other injuries. Moreover, sank twice, but was raised after each incident. Several serious nuclear and radiation accidents have involved nuclear submarine mishaps.

The U.S. Army also had a nuclear power program, beginning in 1954. The SM-1 Nuclear Power Plant, at Fort Belvoir, Virginia, was the first power reactor in the United States to supply electrical energy to a commercial grid (VEPCO), in April 1957, before Shippingport. The SL-1 was a U.S. Army experimental nuclear power reactor at the National Reactor Testing Station in eastern Idaho. It underwent a steam explosion and meltdown in January 1961, which killed its three operators. In the Soviet Union at The Mayak Production Association facility there were a number of accidents, including an explosion, that released 50–100 tonnes of high-level radioactive waste, contaminating a huge territory in the eastern Urals and causing numerous deaths and injuries. The Soviet government kept this accident secret for about 30 years. The event was eventually rated at 6 on the seven-level INES scale (third in severity only to the disasters at Chernobyl and Fukushima).

Installed nuclear capacity initially rose relatively quickly, rising from less than 1 gigawatt (GW) in 1960 to 100 GW in the late 1970s, and 300 GW in the late 1980s. Since the late 1980s worldwide capacity has risen much more slowly, reaching 366 GW in 2005. Between around 1970 and 1990, more than 50 GW of capacity was under construction (peaking at over 150 GW in the late 1970s and early 1980s) — in 2005, around 25 GW of new capacity was planned. More than two-thirds of all nuclear plants ordered after January 1970 were eventually cancelled. A total of 63 nuclear units were canceled in the United States between 1975 and 1980.

During the 1970s and 1980s rising economic costs (related to extended construction times largely due to regulatory changes and pressure-group litigation) and falling fossil fuel prices made nuclear power plants then under construction less attractive. In the 1980s (U.S.) and 1990s (Europe), flat load growth and electricity liberalization also made the addition of large new baseload capacity unattractive.

The 1973 oil crisis had a significant effect on countries, such as France and Japan, which had relied more heavily on oil for electric generation (39% and 73% respectively) to invest in nuclear power.

Some local opposition to nuclear power emerged in the early 1960s, and in the late 1960s some members of the scientific community began to express their concerns. These concerns related to nuclear accidents, nuclear proliferation, high cost of nuclear power plants, nuclear terrorism and radioactive waste disposal. In the early 1970s, there were large protests about a proposed nuclear power plant in Wyhl, Germany. The project was cancelled in 1975 and anti-nuclear success at Wyhl inspired opposition to nuclear power in other parts of Europe and North America. By the mid-1970s anti-nuclear activism had moved beyond local protests and politics to gain a wider appeal and influence, and nuclear power became an issue of major public protest. Although it lacked a single co-ordinating organization, and did not have uniform goals, the movement's efforts gained a great deal of attention. In some countries, the nuclear power conflict "reached an intensity unprecedented in the history of technology controversies". 
In France, between 1975 and 1977, some 175,000 people protested against nuclear power in ten demonstrations. In West Germany, between February 1975 and April 1979, some 280,000 people were involved in seven demonstrations at nuclear sites. Several site occupations were also attempted. In the aftermath of the Three Mile Island accident in 1979, some 120,000 people attended a demonstration against nuclear power in Bonn. In May 1979, an estimated 70,000 people, including then governor of California Jerry Brown, attended a march and rally against nuclear power in Washington, D.C. Anti-nuclear power groups emerged in every country that has had a nuclear power programme.

Health and safety concerns, the 1979 accident at Three Mile Island, and the 1986 Chernobyl disaster played a part in stopping new plant construction in many countries, although the public policy organization, the Brookings Institution states that new nuclear units, at the time of publishing in 2006, had not been built in the United States because of soft demand for electricity, and cost overruns on nuclear plants due to regulatory issues and construction delays. By the end of the 1970s it became clear that nuclear power would not grow nearly as dramatically as once believed. Eventually, more than 120 reactor orders in the United States were ultimately cancelled and the construction of new reactors ground to a halt. A cover story in the February 11, 1985, issue of "Forbes" magazine commented on the overall failure of the U.S. nuclear power program, saying it "ranks as the largest managerial disaster in business history".

Unlike the Three Mile Island accident, the much more serious Chernobyl accident did not increase regulations affecting Western reactors since the Chernobyl reactors were of the problematic RBMK design only used in the Soviet Union, for example lacking "robust" containment buildings. Many of these RBMK reactors are still in use today. However, changes were made in both the reactors themselves (use of a safer enrichment of uranium) and in the control system (prevention of disabling safety systems), amongst other things, to reduce the possibility of a duplicate accident.

An international organization to promote safety awareness and professional development on operators in nuclear facilities was created: World Association of Nuclear Operators (WANO).

Opposition in Ireland and Poland prevented nuclear programs there, while Austria (1978), Sweden (1980) and Italy (1987) (influenced by Chernobyl) voted in referendums to oppose or phase out nuclear power. In July 2009, the Italian Parliament passed a law that cancelled the results of an earlier referendum and allowed the immediate start of the Italian nuclear program. 
After the Fukushima Daiichi nuclear disaster a one-year moratorium was placed on nuclear power development, followed by a referendum in which over 94% of voters (turnout 57%) rejected plans for new nuclear power.

Since about 2001 the term "nuclear renaissance" has been used to refer to a possible nuclear power industry revival, driven by rising fossil fuel prices and new concerns about meeting greenhouse gas emission limits. 
Since commercial nuclear energy began in the mid-1950s, 2008 was the first year that no new nuclear power plant was connected to the grid, although two were connected in 2009.

Japan's 2011 Fukushima Daiichi nuclear accident prompted a re-examination of nuclear safety and nuclear energy policy in many countries and raised questions among some commentators over the future of the renaissance.
Germany plans to close all its reactors by 2022, and Italy has re-affirmed its ban on electric utilities generating, but not importing, fission derived electricity. 
China, Switzerland, Israel, Malaysia, Thailand, United Kingdom, and the Philippines have also reviewed their nuclear power programs, while Indonesia and Vietnam still plan to build nuclear power plants.

In 2011 the International Energy Agency halved its prior estimate of new generating capacity to be built by 2035. 
In 2013 Japan signed a deal worth $22 billion, in which Mitsubishi Heavy Industries would build four modern "Atmea" reactors for Turkey. 
In August 2015, following 4 years of near zero fission-electricity generation, Japan began restarting its nuclear reactors, after safety upgrades were completed, beginning with Sendai Nuclear Power Plant.

The World Nuclear Association has said that "nuclear power generation suffered its biggest ever one-year fall through 2012 as the bulk of the Japanese fleet remained offline for a full calendar year". Data from the International Atomic Energy Agency showed that nuclear power plants globally produced 2346 TWh of electricity in 2012 – seven per cent less than in 2011. The figures illustrate the effects of a full year of 48 Japanese power reactors producing no power during the year. 
The permanent closure of eight reactor units in Germany was also a factor. Problems at Crystal River, Fort Calhoun and the two San Onofre units in the United States meant they produced no power for the full year, while in Belgium Doel 3 and Tihange 2 were out of action for six months. Compared to 2010, the nuclear industry produced 11% less electricity in 2012.

The Fukushima Daiichi nuclear accident sparked controversy about the importance of the accident and its effect on nuclear's future. 
IAEA Director General Yukiya Amano said the Japanese nuclear accident "caused deep public anxiety throughout the world and damaged confidence in nuclear power", and the International Energy Agency halved its estimate of additional nuclear generating capacity to be built by 2035.

Though Platts reported in 2011 that "the crisis at Japan's Fukushima nuclear plants has prompted leading energy-consuming countries to review the safety of their existing reactors and cast doubt on the speed and scale of planned expansions around the world", Progress Energy Chairman/CEO Bill Johnson made the observation that "Today there’s an even more compelling case that greater use of nuclear power is a vital part of a balanced energy strategy". 
In 2011, "The Economist" opined that nuclear power "looks dangerous, unpopular, expensive and risky", and that "it is replaceable with relative ease and could be forgone with no huge structural shifts in the way the world works". 
Earth Institute Director Jeffrey Sachs disagreed, claiming combating climate change would require an expansion of nuclear power. "We won't meet the carbon targets if nuclear is taken off the table," he said. "We need to understand the scale of the challenge."

Investment banks were critical of nuclear soon after the accident. 
Deutsche Bank advised that "the global impact of the Fukushima accident is a fundamental shift in public perception with regard to how a nation prioritizes and values its populations health, safety, security, and natural environment when determining its current and future energy pathways...renewable energy will be a clear long-term winner in most energy systems, a conclusion supported by many voter surveys conducted over the past few weeks.

In September 2011, German engineering giant Siemens announced it will withdraw entirely from the nuclear industry, as a response to the Fukushima nuclear accident in Japan, and said that it would no longer build nuclear power plants anywhere in the world. 
The company’s chairman, Peter Löscher, said that "Siemens was ending plans to cooperate with Rosatom, the Russian state-controlled nuclear power company, in the construction of dozens of nuclear plants throughout Russia over the coming two decades".

In February 2012, the United States Nuclear Regulatory Commission approved the construction of two additional reactors at the Vogtle Electric Generating Plant, the first reactors to be approved in over 30 years since the Three Mile Island accident, but NRC Chairman Gregory Jaczko cast a dissenting vote citing safety concerns stemming from Japan's 2011 Fukushima nuclear disaster, and saying "I cannot support issuing this license as if Fukushima never happened". 
Jaczko resigned in April 2012. 
One week after Southern received the license to begin major construction on the two new reactors, a dozen environmental and anti-nuclear groups sued to stop the Plant Vogtle expansion project, saying "public safety and environmental problems since Japan's Fukushima Daiichi nuclear reactor accident have not been taken into account". 
In July 2012, the suit was rejected by the Washington, D.C. Circuit Court of Appeals.
In 2013, four aging uncompetitive reactors in the United States were closed. 
In the United States, four new Generation III reactors were under construction at Vogtle and Summer station, while a fifth was nearing completion at Watts Bar station, all five were expected to become operational before 2020.

In 2012, the World Nuclear Association reported that nuclear electricity generation was at its lowest level since 1999. 
According to the World Nuclear Association, the global trend is for new nuclear power stations coming online to be balanced by the number of old plants being retired.

Countries such as Australia, Austria, Denmark, Greece, Ireland, Italy, Latvia, Liechtenstein, Luxembourg, Malta, Portugal, Israel, Malaysia, New Zealand, and Norway have no nuclear power reactors and remain opposed to nuclear power.

By 2015, the IAEA's outlook for nuclear energy had become more promising. 
"Nuclear power is a critical element in limiting greenhouse gas emissions," the agency noted, and "the prospects for nuclear energy remain positive in the medium to long term despite a negative impact in some countries in the aftermath of the [Fukushima-Daiichi] accident...it is still the second-largest source worldwide of low-carbon electricity. 
And the 72 reactors under construction at the start of last year were the most in 25 years."

As of 2015, 441 reactors had a worldwide net electric capacity of 382,9 GW, with 67 new nuclear reactors under construction.
Over half of the 67 total being built were in Asia, with 28 in China, where there is an urgent need to control pollution from coal plants.
Eight new grid connections were completed by China in 2015 and the most recently completed reactor to be connected to the electrical grid, as of January 2016, was at the Kori Nuclear Power Plant in the Republic of Korea. 
In October 2016, Watts Bar 2 became the first new United States reactor to enter commercial operation since 1996.

As of January 2016, there are over 150 nuclear reactors planned, equivalent to nearly half of capacity at that time. 
However actual investment in new nuclear is declining, in 2017 reaching the lowest level for five years. Investment on upgrades of existing plant and life-time extensions continues.

The future of nuclear power varies greatly between countries, depending on government policies. 
Some countries, many of them in Europe, such as Germany, Belgium, and Lithuania, have adopted policies of nuclear power phase-out. 
At the same time, some Asian countries, such as China and India, have committed to rapid expansion of nuclear power. 
Many other countries, such as the United Kingdom and the United States, have policies in between. 
Japan was a major generator of nuclear power before the Fukushima accident, but the extent to which it will resume its nuclear program after the accident is uncertain. 
While South Korea has a large nuclear power industry, in 2017 responding to widespread public concerns after the Fukushima Daiichi nuclear disaster, the high earthquake risk in South Korea, and a 2013 nuclear scandal involving the use of counterfeit parts, the new government decided to gradually phase out nuclear power as reactors that are now operating or under construction close after 40 years of operations.

In 2015, the International Energy Agency reported that the Fukushima accident had a strongly negative effect on nuclear power, yet “the prospects for nuclear energy remain positive in the medium to long term despite a negative impact in some countries in the aftermath of the accident.” The IEA noted that at the start of 2014, there were 72 nuclear reactors under construction worldwide, the largest number in 25 years, and that China planned to increase nuclear power capacity from 17 gigawatts (GW) in 2014, to 58 GW in 2020.

In 2016, the U.S. Energy Information Administration projected for its “base case” that world nuclear power generation would increase from 2,344 terawatt-hour (TWh) in 2012 to 4,501 TWh in 2040. 
Most of the predicted increase was expected to be in Asia.

The nuclear power industry in western nations has a history of construction delays, cost overruns, plant cancellations, and nuclear safety issues despite significant government subsidies and support. 
In December 2013, "Forbes" magazine cited a report which concluded that, in western countries, "reactors are not a viable source of new power". 
Even where they make economic sense, they are not feasible because nuclear’s "enormous costs, political and popular opposition, and regulatory uncertainty". 
This view echoes the statement of former Exelon CEO John Rowe, who said in 2012 that new nuclear plants in the United States "don’t make any sense right now" and won’t be economically viable in the foreseeable future. 
John Quiggin, economics professor, also says the main problem with the nuclear option is that it is not economically-viable. Quiggin says that we need more efficient energy use and more renewable energy commercialization. Former NRC member Peter Bradford and Professor Ian Lowe made similar statements in 2011. However, some "nuclear cheerleaders" and lobbyists in the West continue to champion reactors, often with proposed new but largely untested designs, as a source of new power.

Much more new build activity is occurring in Asian countries like South Korea, India and China. 
In March 2016, China had 30 reactors in operation, 24 under construction and plans to build more, However, according to a government research unit, China must not build "too many nuclear power reactors too quickly", in order to avoid a shortfall of fuel, equipment and qualified plant workers.

In the United States, licenses of almost half its reactors have been extended to 60 years, Two new Generation III reactors are under construction at Vogtle, a dual construction project which marks the end of a 34-year period of stagnation in construction of civil nuclear power reactors in the United States. The station operator licenses of almost half the present 104 power reactors in the United States, as of 2008, have been given extensions to 60 years. As of 2012, U.S. nuclear industry officials expect five new reactors to enter service by 2020, all at existing plants. In 2013, four aging, uncompetitive, reactors were permanently closed. Relevant state legislatures are trying to close Vermont Yankee and Indian Point Nuclear Power Plant.

The U.S. NRC and the U.S. Department of Energy have initiated research into Light water reactor sustainability which is hoped will lead to allowing extensions of reactor licenses beyond 60 years, provided that safety can be maintained, as the loss in non-CO-emitting generation capacity by retiring reactors "may serve to challenge U.S. energy security, potentially resulting in increased greenhouse gas emissions, and contributing to an imbalance between electric supply and demand." Research into nuclear reactors that can last 100 years, known as Centurion Reactors, is already being conducted.

There is a possible impediment to production of nuclear power plants as only a few companies worldwide have the capacity to forge single-piece reactor pressure vessels, which are necessary in the most common reactor designs. Utilities across the world are submitting orders years in advance of any actual need for these vessels. Other manufacturers are examining various options, including making the component themselves, or finding ways to make a similar item using alternate methods.

According to the World Nuclear Association, globally during the 1980s one new nuclear reactor started up every 17 days on average, and in the year 2015 it was estimated that this rate could in theory eventually increase to one every 5 days, although no plans exist for that. As of 2007, Watts Bar 1 in Tennessee, which came on-line on February 7, 1996, was the last U.S. commercial nuclear reactor to go on-line. This is often quoted as evidence of a successful worldwide campaign for nuclear power phase-out. Electricity shortages, fossil fuel price increases, global warming, and heavy metal emissions from fossil fuel use, new technology such as passively safe plants, and national energy security may renew the demand for nuclear power plants.

Following Westinghouse filing for Chapter 11 bankruptcy protection in March 2017 because of US$9 billion of losses from nuclear construction projects in the United States, the future of new nuclear plant construction has largely moved to Asia and the Middle East. China has 21 reactors under construction and 40 planned, Russia has 7 under construction and 25 planned, and South Korea has 3 under construction plus 4 it is building in the United Arab Emirates.

Just as many conventional thermal power stations generate electricity by harnessing the thermal energy released from burning fossil fuels, nuclear power plants convert the energy released from the nucleus of an atom via nuclear fission that takes place in a nuclear reactor. The heat is removed from the reactor core by a cooling system that uses the heat to generate steam, which drives a steam turbine connected to a generator producing electricity.

A fission nuclear power plant is generally composed of a nuclear reactor, in which the nuclear reactions generating heat take place; a cooling system, which removes the heat from inside the reactor; a steam turbine, which transforms the heat in mechanical energy; an electric generator, which transform the mechanical energy into electrical energy.

Nuclear fission power stations, excluding the contribution from naval nuclear fission reactors, provided 11% of the world's electricity in 2012, somewhat less than that generated by hydro-electric stations at 16%. 
Since electricity accounts for about 25% of humanity's energy usage with the majority of the rest coming from fossil fuel reliant sectors such as transport, manufacture and home heating, nuclear fission's contribution to the global final energy consumption was about 2.5%. 
This is a little more than the combined global electricity production from wind, solar, biomass and geothermal power, which together provided 2% of global final energy consumption in 2014.

In 2013, the IAEA reported that there were 437 operational civil fission-electric reactors in 31 countries, although not every reactor was producing electricity. 
In addition, there were approximately 140 naval vessels using nuclear propulsion in operation, powered by about 180 reactors.

Regional differences in the use of nuclear power are large.
The United States produces the most nuclear energy in the world, with nuclear power providing 19% of the electricity it consumes, while France produces the highest percentage of its electrical energy from nuclear reactors—80% as of 2006. 
In the European Union as a whole nuclear power provides 30% of the electricity. 
Nuclear power is the single largest low-carbon electricity source in the United States, and accounts for two-thirds of the European Union's low-carbon electricity. 
Nuclear energy policy differs among European Union countries, and some, such as Austria, Estonia, Ireland and Italy, have no active nuclear power stations. 
In comparison, France has a large number of these plants, with 16 multi-unit stations in current use.

Many military and some civilian (such as some icebreakers) ships use nuclear marine propulsion. 
A few space vehicles have been launched using nuclear reactors: 33 reactors belong to the Soviet RORSAT series and one was the American SNAP-10A.

International research is continuing into additional uses of process heat such as hydrogen production (in support of a hydrogen economy), for desalinating sea water, and for use in district heating systems.

The nuclear industry comprises of a number of companies, organizations, governmental and international bodies.
The main fields of the industry include nuclear reactor building and operation; uranium mining and nuclear fuel production; nuclear waste storage and processing; research and development.
Other components of the nuclear industry include nuclear regulators and nuclear industry national and international associations.

Nuclear power plants typically have high capital costs for building the plant, but low fuel costs. 
Although nuclear power plants can vary their output the electricity is generally less favorably priced when doing so. 
Nuclear power plants are therefore typically run as much as possible to keep the cost of the generated electrical energy as low as possible, supplying mostly base-load electricity.

Internationally the price of nuclear plants rose 15% annually in 1970–1990. 
Yet, nuclear power has total costs in 2012 of about $96 per megawatt hour (MWh), most of which involves capital construction costs, compared with solar power at $130 per MWh, and natural gas at the low end at $64 per MWh.

In 2015, the "Bulletin of the Atomic Scientists" unveiled the Nuclear Fuel Cycle Cost Calculator, an online tool that estimates the full cost of electricity produced by three configurations of the nuclear fuel cycle. 
Two years in the making, this interactive calculator is the first generally accessible model to provide a nuanced look at the economic costs of nuclear power; it lets users test how sensitive the price of electricity is to a full range of components—more than 60 parameters that can be adjusted for the three configurations of the nuclear fuel cycle considered by this tool (once-through, limited-recycle, full-recycle). Users can select the fuel cycle they would like to examine, change cost estimates for each component of that cycle, and even choose uncertainty ranges for the cost of particular components. This approach allows users around the world to compare the cost of different nuclear power approaches in a sophisticated way, while taking account of prices relevant to their own countries or regions.

In recent years there has been a slowdown of electricity demand growth. 
In Eastern Europe, a number of long-established projects are struggling to find finance, notably Belene in Bulgaria and the additional reactors at Cernavoda in Romania, and some potential backers have pulled out. Where the electricity market is competitive, cheap natural gas is available, and its future supply relatively secure, this also poses a major problem for nuclear projects and existing plants.

Analysis of the economics of nuclear power must take into account who bears the risks of future uncertainties. To date all operating nuclear power plants were developed by state-owned or regulated utility monopolies where many of the risks associated with construction costs, operating performance, fuel price, accident liability and other factors were borne by consumers rather than suppliers. In addition, because the potential liability from a nuclear accident is so great, the full cost of liability insurance is generally limited/capped by the government, which the U.S. Nuclear Regulatory Commission concluded constituted a significant subsidy. Many countries have now liberalized the electricity market where these risks, and the risk of cheaper competitors emerging before capital costs are recovered, are borne by plant suppliers and operators rather than consumers, which leads to a significantly different evaluation of the economics of new nuclear power plants.

Following the 2011 Fukushima Daiichi nuclear disaster, costs are expected to increase for currently operating and new nuclear power plants, due to increased requirements for on-site spent fuel management and elevated design basis threats.

The economics of new nuclear power plants is a controversial subject, since there are diverging views on this topic, and multibillion-dollar investments ride on the choice of an energy source. Comparison with other power generation methods is strongly dependent on assumptions about construction timescales and capital financing for nuclear plants as well as the future costs of fossil fuels and renewables as well as for energy storage solutions for intermittent power sources. Cost estimates also need to take into account plant decommissioning and nuclear waste storage costs. On the other hand, measures to mitigate global warming, such as a carbon tax or carbon emissions trading, may favor the economics of nuclear power.

A nuclear reactor is only part of the life-cycle for nuclear power. The process starts with mining (see "Uranium mining"). Uranium mines are underground, open-pit, or in-situ leach mines. In any case, the uranium ore is extracted, usually converted into a stable and compact form such as yellowcake, and then transported to a processing facility. Here, the yellowcake is converted to uranium hexafluoride, which is then enriched using various techniques. At this point, the enriched uranium, containing more than the natural 0.7% U-235, is used to make rods of the proper composition and geometry for the particular reactor that the fuel is destined for. The fuel rods will spend about 3 operational cycles (typically 6 years total now) inside the reactor, generally until about 3% of their uranium has been fissioned, then they will be moved to a spent fuel pool where the short lived isotopes generated by fission can decay away. After about 5 years in a spent fuel pool the spent fuel is radioactively and thermally cool enough to handle, and it can be moved to dry storage casks or reprocessed.

Uranium is a fairly common element in the Earth's crust: it is approximately as common as tin or germanium, and is about 40 times more common than silver. Uranium is present in trace concentrations in most rocks, dirt, and ocean water, but can be economically extracted currently only where it is present in high concentrations. Still, the world's present measured resources of uranium, economically recoverable at the arbitrary price ceiling of 130 USD/kg, are enough to last for between 70 and 100 years.

According to the OECD in 2006, there was an expected 85 years worth of uranium in already identified resources, when that uranium is used in present reactor technology, in the OECD's red book of 2011, due to increased exploration, known uranium resources have grown by 12.5% since 2008, with this increase translating into greater than a century of uranium available if the metals usage rate were to continue at the 2011 level. The OECD also estimate 670 years of economically recoverable uranium in total conventional resources and phosphate ores, while also using present reactor technology, a resource that is recoverable from between 60–100 US$/kg of Uranium. In a similar manner to every other natural metal resource, for every tenfold increase in the cost per kilogram of uranium, there is a three-hundredfold increase in available lower quality ores that would then become economical. As the OECD note: For example, the OECD have determined that with a pure fast reactor fuel cycle with a burn up of, and recycling of, all the Uranium and actinides, actinides which presently make up the most hazardous substances in nuclear waste, there is 160,000 years worth of Uranium in total conventional resources and phosphate ore, at the price of 60–100 US$/kg of Uranium.

Current light water reactors make relatively inefficient use of nuclear fuel, mostly fissioning only the very rare uranium-235 isotope. Nuclear reprocessing can make this waste reusable, and more efficient reactor designs, such as the currently under construction Generation III reactors achieve a higher efficiency burn up of the available resources, than the current vintage generation II reactors, which make up the vast majority of reactors worldwide.

As opposed to current light water reactors which use uranium-235 (0.7% of all natural uranium), fast breeder reactors use uranium-238 (99.3% of all natural uranium). It has been estimated that there is up to five billion years' worth of uranium-238 for use in these power plants.

Breeder technology has been used in several reactors, but the high cost of reprocessing fuel safely, at 2006 technological levels, requires uranium prices of more than 200 USD/kg before becoming justified economically. 
Breeder reactors are however being pursued as they have the potential to burn up all of the actinides in the present inventory of nuclear waste while also producing power and creating additional quantities of fuel for more reactors via the breeding process.

As of 2017, there are only two breeder reactors producing commercial power: the BN-600 reactor and the BN-800 reactor, both in Russia. 
The BN-600, with a capacity of 600 MW, was built in 1980 in Beloyarsk and is planned to produce power until 2025. 
The BN-800 is an updated version of the BN-600, and started operation in 2016 with a net electrical capacity of 789 MW.
The technical design of a yet larger breeder, the BN-1200 reactor was originally scheduled to be finalized in 2013, with construction slated for 2015 but has since been delayed. 
The Phénix breeder reactor in France was powered down in 2009 after 36 years of operation.
Japan's Monju breeder reactor restarted (having been shut down in 1995) in 2010 for 3 months, but shut down again after equipment fell into the reactor during reactor checkups and it is now planned to be decommissioned.
Both China and India are building breeder reactors. 
The Indian 500 MWe Prototype Fast Breeder Reactor is under construction, with plans to build five more by 2020. 
The China Experimental Fast Reactor began producing power in 2011.

Another alternative to fast breeders is thermal breeder reactors that use uranium-233 bred from thorium as fission fuel in the thorium fuel cycle. 
Thorium is about 3.5 times more common than uranium in the Earth's crust, and has different geographic characteristics. This would extend the total practical fissionable resource base by 450%. India's three-stage nuclear power programme features the use of a thorium fuel cycle in the third stage, as it has abundant thorium reserves but little uranium.

The most important waste stream from nuclear power plants is spent nuclear fuel. It is primarily composed of unconverted uranium as well as significant quantities of transuranic actinides (plutonium and curium, mostly). In addition, about 3% of it is fission products from nuclear reactions. The actinides (uranium, plutonium, and curium) are responsible for the bulk of the long-term radioactivity, whereas the fission products are responsible for the bulk of the short-term radioactivity.

High-level radioactive waste management concerns management and disposal of highly radioactive materials created during production of nuclear power. The technical issues in accomplishing this are daunting, due to the extremely long periods radioactive wastes remain deadly to living organisms. Of particular concern are two long-lived fission products, Technetium-99 (half-life 220,000 years) and Iodine-129 (half-life 15.7 million years), which dominate spent nuclear fuel radioactivity after a few thousand years. The most troublesome transuranic elements in spent fuel are Neptunium-237 (half-life two million years) and Plutonium-239 (half-life 24,000 years). Consequently, high-level radioactive waste requires sophisticated treatment and management to successfully isolate it from the biosphere. This usually necessitates treatment, followed by a long-term management strategy involving permanent storage, disposal or transformation of the waste into a non-toxic form.

Governments around the world are considering a range of waste management and disposal options, usually involving deep-geologic placement, although there has been limited progress toward implementing long-term waste management solutions. This is partly because the timeframes in question when dealing with radioactive waste range from 10,000 to millions of years, according to studies based on the effect of estimated radiation doses.

Some proposed nuclear reactor designs however such as the American Integral Fast Reactor and the Molten salt reactor can use the nuclear waste from light water reactors as a fuel, transmutating it to isotopes that would be safe after hundreds, instead of tens of thousands of years. This offers a potentially more attractive alternative to deep geological disposal.

Another possibility is the use of thorium in a reactor especially designed for thorium (rather than mixing in thorium with uranium and plutonium (i.e. in existing reactors). Used thorium fuel remains only a few hundreds of years radioactive, instead of tens of thousands of years.

Since the fraction of a radioisotope's atoms decaying per unit of time is inversely proportional to its half-life, the relative radioactivity of a quantity of buried human radioactive waste would diminish over time compared to natural radioisotopes (such as the decay chains of 120 trillion tons of thorium and 40 trillion tons of uranium which are at relatively trace concentrations of parts per million each over the crust's 3 * 10 ton mass). For instance, over a timeframe of thousands of years, after the most active short half-life radioisotopes decayed, burying U.S. nuclear waste would increase the radioactivity in the top 2000 feet of rock and soil in the United States (10 million km) by ≈ 1 part in 10 million over the cumulative amount of natural radioisotopes in such a volume, although the vicinity of the site would have a far higher concentration of artificial radioisotopes underground than such an average.

The nuclear industry also produces a large volume of low-level radioactive waste in the form of contaminated items like clothing, hand tools, water purifier resins, and (upon decommissioning) the materials of which the reactor itself is built. In the United States, the Nuclear Regulatory Commission has repeatedly attempted to allow low-level materials to be handled as normal waste: landfilled, recycled into consumer items, etcetera.

In countries with nuclear power, radioactive wastes comprise less than 1% of total industrial toxic wastes, much of which remains hazardous for long periods. Overall, nuclear power produces far less waste material by volume than fossil-fuel based power plants. Coal-burning plants are particularly noted for producing large amounts of toxic and mildly radioactive ash due to concentrating naturally occurring metals and mildly radioactive material from the coal. A 2008 report from Oak Ridge National Laboratory concluded that coal power actually results in more radioactivity being released into the environment than nuclear power operation, and that the population effective dose equivalent, or dose to the public from radiation from coal plants is 100 times as much as from the operation of nuclear plants. Indeed, coal ash is much less radioactive than spent nuclear fuel on a weight per weight basis, but coal ash is produced in much higher quantities per unit of energy generated, and this is released directly into the environment as fly ash, whereas nuclear plants use shielding to protect the environment from radioactive materials, for example, in dry cask storage vessels.

Disposal of nuclear waste is often said to be the Achilles' heel of the industry. Presently, waste is mainly stored at individual reactor sites and there are over 430 locations around the world where radioactive material continues to accumulate. Some experts suggest that centralized underground repositories which are well-managed, guarded, and monitored, would be a vast improvement. There is an "international consensus on the advisability of storing nuclear waste in deep geological repositories", with the lack of movement of nuclear waste in the 2 billion year old natural nuclear fission reactors in Oklo, Gabon being cited as "a source of essential information today."

There are no commercial scale purpose built underground repositories in operation. The Waste Isolation Pilot Plant (WIPP) in New Mexico has been taking nuclear waste since 1999 from production reactors, but as the name suggests is a research and development facility. A radiation leak at WIPP in 2014 brought renewed attention to the need for R&D on disposal of radioactive waste and spent fuel.

Reprocessing can potentially recover up to 95% of the remaining uranium and plutonium in spent nuclear fuel, putting it into new mixed oxide fuel. This produces a reduction in long term radioactivity within the remaining waste, since this is largely short-lived fission products, and reduces its volume by over 90%. Reprocessing of civilian fuel from power reactors is currently done in Europe, Russia, Japan, and India. The full potential of reprocessing has not been achieved because it requires breeder reactors, which are not commercially available.

Nuclear reprocessing reduces the volume of high-level waste, but by itself does not reduce radioactivity or heat generation and therefore does not eliminate the need for a geological waste repository. Reprocessing has been politically controversial because of the potential to contribute to nuclear proliferation, the potential vulnerability to nuclear terrorism, the political challenges of repository siting (a problem that applies equally to direct disposal of spent fuel), and because of its high cost compared to the once-through fuel cycle. Several different methods for reprocessing been tried, but many have had safety and practicality problems which have led to their discontinuation.

In the United States, the Obama administration stepped back from President Bush's plans for commercial-scale reprocessing and reverted to a program focused on reprocessing-related scientific research. Reprocessing is not allowed in the U.S. In the United States, spent nuclear fuel is currently all treated as waste. A major recommendation of the Blue Ribbon Commission on America's Nuclear Future was that "the United States should undertake an integrated nuclear waste management program that leads to the timely development of one or more permanent deep geological facilities for the safe disposal of spent fuel and high-level nuclear waste".

Uranium enrichment produces many tons of depleted uranium (DU) which consists of U-238 with most of the easily fissile U-235 isotope removed. U-238 is a tough metal with several commercial uses—for example, aircraft production, radiation shielding, and armor—as it has a higher density than lead. Depleted uranium is also controversially used in munitions; DU penetrators (bullets or APFSDS tips) "self sharpen", due to uranium's tendency to fracture along shear bands.

Some serious nuclear and radiation accidents have occurred. Benjamin K. Sovacool has reported that worldwide there have been 99 accidents at nuclear power plants. Fifty-seven accidents have occurred since the Chernobyl disaster, and 57% (56 out of 99) of all nuclear-related accidents have occurred in the United States.

Nuclear power plant accidents include the Chernobyl accident (1986) with approximately 60 deaths so far attributed to the accident and a predicted, eventual total death toll, of from 4000 to 25,000 latent cancers deaths. The Fukushima Daiichi nuclear disaster (2011), has not caused any radiation related deaths, with a predicted, eventual total death toll, of from 0 to 1000, and the Three Mile Island accident (1979), no causal deaths, cancer or otherwise, have been found in follow up studies of this accident. Nuclear-powered submarine mishaps include the K-19 reactor accident (1961), the K-27 reactor accident (1968), and the K-431 reactor accident (1985). International research is continuing into safety improvements such as passively safe plants, and the possible future use of nuclear fusion.

In terms of lives lost per unit of energy generated, nuclear power has caused fewer accidental deaths per unit of energy generated than all other major sources of energy generation. Energy produced by coal, petroleum, natural gas and hydropower has caused more deaths per unit of energy generated, from air pollution and energy accidents. This is found in the following comparisons, when the immediate nuclear related deaths from accidents are compared to the immediate deaths from these other energy sources, when the latent, or predicted, indirect cancer deaths from nuclear energy accidents are compared to the immediate deaths from the above energy sources, and when the combined immediate and indirect fatalities from nuclear power and all fossil fuels are compared, fatalities resulting from the mining of the necessary natural resources to power generation and to air pollution. With these data, the use of nuclear power has been calculated to have prevented in the region of 1.8 million deaths between 1971 and 2009, by reducing the proportion of energy that would otherwise have been generated by fossil fuels, and is projected to continue to do so.

Although according to Benjamin K. Sovacool, fission energy accidents ranked first in terms of their total economic cost, accounting for 41 percent of all property damage attributed to energy accidents. Analysis presented in the international journal, "Human and Ecological Risk Assessment" found that coal, oil, Liquid petroleum gas and hydroelectric accidents(primarily due to the Banqiao dam burst) have resulted in greater economic impacts than nuclear power accidents.

Following the 2011 Japanese Fukushima nuclear disaster, authorities shut down the nation's 54 nuclear power plants, but it has been estimated that if Japan had never adopted nuclear power, accidents and pollution from coal or gas plants would have caused more lost years of life. As of 2013, the Fukushima site remains highly radioactive, with some 160,000 evacuees still living in temporary housing, and some land will be unfarmable for centuries. The difficult Fukushima disaster cleanup will take 40 or more years, and cost tens of billions of dollars.

Forced evacuation from a nuclear accident may lead to social isolation, anxiety, depression, psychosomatic medical problems, reckless behavior, even suicide. Such was the outcome of the 1986 Chernobyl nuclear disaster in Ukraine. A comprehensive 2005 study concluded that "the mental health impact of Chernobyl is the largest public health problem unleashed by the accident to date". Frank N. von Hippel, an American scientist, commented on the 2011 Fukushima nuclear disaster, saying that "fear of ionizing radiation could have long-term psychological effects on a large portion of the population in the contaminated areas". A 2015 report in "Lancet" explained that serious impacts of nuclear accidents were often not directly attributable to radiation exposure, but rather social and psychological effects. Evacuation and long-term displacement of affected populations created problems for many people, especially the elderly and hospital patients.

Terrorists could target nuclear power plants in an attempt to release radioactive contamination into the community. The United States 9/11 Commission has said that nuclear power plants were potential targets originally considered for the September 11, 2001 attacks. An attack on a reactor’s spent fuel pool could also be serious, as these pools are less protected than the reactor core. The release of radioactivity could lead to thousands of near-term deaths and greater numbers of long-term fatalities.

If nuclear power use is to expand significantly, nuclear facilities will have to be made extremely safe from attacks that could release massive quantities of radioactivity into the community. New reactor designs have features of passive safety, such as the flooding of the reactor core without active intervention by reactor operators. But these safety measures have generally been developed and studied with respect to accidents, not to the deliberate reactor attack by a terrorist group. However, the U.S. Nuclear Regulatory Commission does now also require new reactor license applications to consider security during the design stage. In the United States, the NRC carries out "Force on Force" (FOF) exercises at all Nuclear Power Plant (NPP) sites at least once every three years. In the United States, plants are surrounded by a double row of tall fences which are electronically monitored. The plant grounds are patrolled by a sizeable force of armed guards.

Insider sabotage regularly occurs, because insiders can observe and work around security measures. Successful insider crimes depended on the perpetrators' observation and knowledge of security vulnerabilities. 
A fire caused 5–10 million dollars worth of damage to New York's Indian Point Energy Center in 1971. 
The arsonist turned out to be a plant maintenance worker. 
Sabotage by workers has been reported at many other reactors in the United States: at Zion Nuclear Power Station (1974), Quad Cities Nuclear Generating Station, Peach Bottom Nuclear Generating Station, Fort St. Vrain Generating Station, Trojan Nuclear Power Plant (1974), Browns Ferry Nuclear Power Plant (1980), and Beaver Valley Nuclear Generating Station (1981). Many reactors overseas have also reported sabotage by workers.

Many technologies and materials associated with the creation of a nuclear power program have a dual-use capability, in that they can be used to make nuclear weapons if a country chooses to do so. When this happens a nuclear power program can become a route leading to a nuclear weapon or a public annex to a "secret" weapons program. The concern over Iran's nuclear activities is a case in point.

A fundamental goal for American and global security is to minimize the nuclear proliferation risks associated with the expansion of nuclear power. If this development is "poorly managed or efforts to contain risks are unsuccessful, the nuclear future will be dangerous". The Global Nuclear Energy Partnership is one such international effort to create a distribution network in which developing countries in need of energy, would receive nuclear fuel at a discounted rate, in exchange for that nation agreeing to forgo their own indigenous develop of a uranium enrichment program. The France-based Eurodif/"European Gaseous Diffusion Uranium Enrichment Consortium" was/is one such program that successfully implemented this concept, with Spain and other countries without enrichment facilities buying a share of the fuel produced at the French controlled enrichment facility, but without a transfer of technology. Iran was an early participant from 1974, and remains a shareholder of Eurodif via Sofidif.

According to Benjamin K. Sovacool, a "number of high-ranking officials, even within the United Nations, have argued that they can do little to stop states using nuclear reactors to produce nuclear weapons". A 2009 United Nations report said that:
the revival of interest in nuclear power could result in the worldwide dissemination of uranium enrichment and spent fuel reprocessing technologies, which present obvious risks of proliferation as these technologies can produce fissile materials that are directly usable in nuclear weapons.

On the other hand, one factor influencing the support of power reactors is due to the appeal that these reactors have at reducing nuclear weapons arsenals through the Megatons to Megawatts Program, a program which eliminated 425 metric tons of highly enriched uranium(HEU), the equivalent of 17,000 nuclear warheads, by diluting it with natural uranium making it equivalent to low enriched uranium(LEU), and thus suitable as nuclear fuel for commercial fission reactors. This is the single most successful non-proliferation program to date.

The Megatons to Megawatts Program, the brainchild of Thomas Neff of MIT, was hailed as a major success by anti-nuclear weapon advocates as it has largely been the driving force behind the sharp reduction in the quantity of nuclear weapons worldwide since the cold war ended. However without an increase in nuclear reactors and greater demand for fissile fuel, the cost of dismantling and down blending has dissuaded Russia from continuing their disarmament.

Currently, according to Harvard professor Matthew Bunn: "The Russians are not remotely interested in extending the program beyond 2013. We've managed to set it up in a way that costs them more and profits them less than them just making new low-enriched uranium for reactors from scratch. But there are other ways to set it up that would be very profitable for them and would also serve some of their strategic interests in boosting their nuclear exports."

Up to 2005, the Megatons to Megawatts Program had processed $8 billion of HEU/weapons grade uranium into LEU/reactor grade uranium, with that corresponding to the elimination of 10,000 nuclear weapons.

For approximately two decades, this material generated nearly 10 percent of all the electricity consumed in the United States (about half of all U.S. nuclear electricity generated) with a total of around 7 trillion kilowatt-hours of electricity produced. Enough energy to energize the entire United States electric grid for about two years. In total it is estimated to have cost $17 billion, a "bargain for US ratepayers", with Russia profiting $12 billion from the deal. Much needed profit for the Russian nuclear oversight industry, which after the collapse of the Soviet economy, had difficulties paying for the maintenance and security of the Russian Federations highly enriched uranium and warheads.

In April 2012 there were thirty one countries that have civil nuclear power plants, of which nine have nuclear weapons, with the vast majority of these nuclear weapons states having first produced weapons, before commercial fission electricity stations. Moreover, the re-purposing of civilian nuclear industries for military purposes would be a breach of the Non-proliferation treaty, of which 190 countries adhere to.

Nuclear power is one of the leading low carbon power generation methods of producing electricity, and in terms of total life-cycle greenhouse gas emissions per unit of energy generated, has emission values comparable to or lower than renewable energy.
A 2014 analysis of the carbon footprint literature by the Intergovernmental Panel on Climate Change (IPCC) reported that the embodied total life-cycle emission intensity of fission electricity has a median value of 12 g eq/kWh which is the lowest out of all commercial baseload energy sources.
This is contrasted with coal and fossil gas at 820 and 490 g eq/kWh. 
From the beginning of fission-electric power station commercialization in the 1970s, nuclear power prevented the emission of about 64 billion tonnes of carbon dioxide equivalent that would have otherwise resulted from the burning of fossil fuels in thermal power stations.

According to the United Nations (UNSCEAR), regular nuclear power plant operation including the nuclear fuel cycle causes radioisotope releases into the environment amounting to 0.0002 millisieverts (mSv) per year of public exposure as a global average. 
This is small compared to variation in natural background radiation, which averages 2.4 mSv/a globally but frequently varies between 1 mSv/a and 13 mSv/a depending on a person's location as determined by UNSCEAR. 
As of a 2008 report, the remaining legacy of the worst nuclear power plant accident (Chernobyl) is 0.002 mSv/a in global average exposure (a figure which was 0.04 mSv per person averaged over the entire populace of the Northern Hemisphere in the year of the accident in 1986, although far higher among the most affected local populations and recovery workers).

Climate change causing weather extremes such as heat waves, reduced precipitation levels and droughts can have a significant impact on all thermal power station infrastructure, including large biomass-electric and fission-electric stations alike, if cooling in these power stations, namely in the steam condenser is provided by certain freshwater sources. While many thermal stations use indirect seawater cooling or cooling towers that in comparison use little to no freshwater, those that were designed to heat exchange with rivers and lakes, can run into economic problems.

This presently infrequent generic problem may become increasingly significant over time. This can force nuclear reactors to be shut down, as happened in France during the 2003 and 2006 heat waves. Nuclear power supply was severely diminished by low river flow rates and droughts, which meant rivers had reached the maximum temperatures for cooling reactors. During the heat waves, 17 reactors had to limit output or shut down. 77% of French electricity is produced by nuclear power and in 2009 a similar situation created a 8GW shortage and forced the French government to import electricity. Other cases have been reported from Germany, where extreme temperatures have reduced nuclear power production only 9 times due to high temperatures between 1979 and 2007. In particular:

Similar events have happened elsewhere in Europe during those same hot summers. 
If global warming continues, this disruption is likely to increase or alternatively, station operators could instead retro-fit other means of cooling, like cooling towers, despite these frequently being large structures and therefore sometimes unpopular with the public.

There is an ongoing debate on the relative benefits of nuclear power compared to renewable energy sources for the generation of low-carbon electricity.
Proponents of renewable energy argue that wind power and solar power are already cheaper and safer than nuclear power.
Nuclear power proponents argue that renewable energy sources such as wind and solar do not offer the scalability necessary for a large scale decarbonization of the electric grid, mainly due to their intermittency.
Although the majority of installed renewable energy across the world is currently in the form of hydro power, solar and wind power are growing at a much higher pace, especially in developed countries.

Several studies report that it is in principle possible to cover most of energy generation with renewable sources.
The Intergovernmental Panel on Climate Change (IPCC) has said that if governments were supportive, and the full complement of renewable energy technologies were deployed, renewable energy supply could account for almost 80% of the world's energy use within forty years. 
Rajendra Pachauri, chairman of the IPCC, said the necessary investment in renewables would cost only about 1% of global GDP annually. 
This approach could contain greenhouse gas levels to less than 450 parts per million, the safe level beyond which climate change becomes catastrophic and irreversible.

However, other studies suggest that solar and wind energy are not cost-effective compared to nuclear power.
The Brookings Institution published "The Net Benefits of Low and No-Carbon Electricity Technologies" in 2014 which states, after performing an energy and emissions cost analysis, that "The net benefits of new nuclear, hydro, and natural gas combined cycle plants far outweigh the net benefits of new wind or solar plants", with the most cost effective low carbon power technology being determined to be nuclear power.

Nuclear power is also proposed as a tested and practical way to implement a low-carbon energy infrastructure, as opposed to renewable sources.
Analysis in 2015 by Professor and Chair of Environmental Sustainability Barry W. Brook and his colleagues on the topic of replacing fossil fuels entirely, from the electric grid of the world, has determined that at the historically modest and proven-rate at which nuclear energy was added to and replaced fossil fuels in France and Sweden during each nation's building programs in the 1980s, nuclear energy could displace or remove fossil fuels from the electric grid completely within 10 years, "allow[ing] the world to meet the most stringent greenhouse-gas mitigation targets.". 
In a similar analysis, Brook had earlier determined that 50% of all global energy, that is not solely electricity, but transportation synfuels etc. could be generated within approximately 30 years, if the global nuclear fission build rate was identical to each of these nation's already proven installation rates in units of installed nameplate capacity, GW per year, per unit of global GDP (GW/year/$).
This is in contrast to the conceptual studies for a "100% renewable energy" world, which would require an orders of magnitude more costly global investment per year, which has no historical precedent, along with far greater land that would have to be devoted to the wind, wave and solar projects, and the inherent assumption that humanity will use less, and not more, energy in the future.
As Brook notes, the "principal limitations on nuclear fission are not technical, economic or fuel-related, but are instead linked to complex issues of societal acceptance, fiscal and political inertia, and inadequate critical evaluation of the real-world constraints facing [the other] low-carbon alternatives."

Several studies conclude that wind and solar power have costs that are comparable or lower than nuclear power, when considering price per kWh.
The cost of constructing established nuclear power reactor designs has followed an increasing trend due to regulations and court cases whereas the levelized cost of electricity (LCOE) is declining for wind and solar power. 
In 2010 a report from Solar researchers at Duke University suggested that solar power is already cheaper than nuclear power. 
However they state that if subsidies were removed for solar power, the crossover point would be delayed by years.
Data from the EIA in 2011 estimated that in 2016, solar will have a levelized cost of electricity almost twice as expensive as nuclear (21¢/kWh for solar, 11.39¢/kWh for nuclear), and wind somewhat less expensive than nuclear (9.7¢/kWh).
However, the U.S. EIA has also cautioned that levelized costs of intermittent sources such as wind and solar are not directly comparable to costs of "dispatchable" sources (those that can be adjusted to meet demand), as intermittent sources need costly large-scale back-up power supplies for when the weather changes.

A 2010 study by the Global Subsidies Initiative compared global relative energy subsidies, or government financial aid for the deployment of different energy sources.
Results show that fossil fuels receive about 1 U.S. cents per kWh of energy they produce, nuclear energy receives 1.7 cents / kWh, renewable energy (excluding hydroelectricity) receives 5.0 cents / kWh and biofuels receive 5.1 cents / kWh in subsidies.

Nuclear power is comparable to, and in some cases lower, than many renewable energy sources in terms of lives lost per unit of electricity delivered.
However, as opposed to renewable energy, conventional designs for nuclear reactors produce intensely radioactive spent fuel that needs to be stored or reprocessed.
A nuclear plant also needs to be disassembled and removed and much of the disassembled nuclear plant needs to be stored as low level nuclear waste for a few decades.

The financial costs of every nuclear power plant continues for some time after the facility has finished generating its last useful electricity. Once no longer economically viable, nuclear reactors and uranium enrichment facilities are generally decommissioned, returning the facility and its parts to a safe enough level to be entrusted for other uses, such as greenfield status. 
After a cooling-off period that may last decades, reactor core materials are dismantled and cut into small pieces to be packed in containers for interim storage or transmutation experiments. The consensus on how to approach the task is one that is relatively inexpensive, but it has the potential to be hazardous to the natural environment as it presents opportunities for human error, accidents or sabotage.

In the United States a Nuclear Waste Policy Act and Nuclear Decommissioning Trust Fund is legally required, with utilities banking 0.1 to 0.2 cents/kWh during operations to fund future decommissioning. They must report regularly to the Nuclear Regulatory Commission (NRC) on the status of their decommissioning funds. About 70% of the total estimated cost of decommissioning all U.S. nuclear power reactors has already been collected (on the basis of the average cost of $320 million per reactor-steam turbine unit).

In the United States in 2011, there are 13 reactors that had permanently shut down and are in some phase of decommissioning. With Connecticut Yankee Nuclear Power Plant and Yankee Rowe Nuclear Power Station having completed the process in 2006–2007, after ceasing commercial electricity production circa 1992. 
The majority of the 15 years, was used to allow the station to naturally cool-down on its own, which makes the manual disassembly process both safer and cheaper.
Decommissioning at nuclear sites which have experienced a serious accident are the most expensive and time-consuming.

Working under an insurance framework that limits or structures accident liabilities in accordance with the Paris convention on nuclear third-party liability, the Brussels supplementary convention, and the Vienna convention on civil liability for nuclear damage and in the United States the Price-Anderson Act. 
It is often argued that this potential shortfall in liability represents an external cost not included in the cost of nuclear electricity; but the cost is small, amounting to about 0.1% of the levelized cost of electricity, according to a CBO study.

These beyond-regular-insurance costs for worst-case scenarios are not unique to nuclear power, as hydroelectric power plants are similarly not fully insured against a catastrophic event such as the Banqiao Dam disaster, where 11 million people lost their homes and from 30,000 to 200,000 people died, or large dam failures in general. As private insurers base dam insurance premiums on limited scenarios, major disaster insurance in this sector is likewise provided by the state.

The nuclear power debate concerns the controversy which has surrounded the deployment and use of nuclear fission reactors to generate electricity from nuclear fuel for civilian purposes. The debate about nuclear power peaked during the 1970s and 1980s, when it "reached an intensity unprecedented in the history of technology controversies", in some countries.

Proponents of nuclear energy contend that nuclear power is a sustainable energy source that reduces carbon emissions and increases energy security by decreasing dependence on imported energy sources. 
Proponents claim that nuclear power produces virtually no conventional air pollution, such as greenhouse gases and smog, in contrast to the main alternative of fossil-fuel power stations. Nuclear power can produce base-load power unlike many renewables which are intermittent energy sources lacking large-scale and cheap ways of storing energy. M. King Hubbert saw oil as a resource that would run out, and proposed nuclear energy as a replacement energy source. 
Proponents claim that the risks of storing waste are small and can be further reduced by using the latest technology in newer reactors, and the operational safety record in the Western world is excellent when compared to the other major kinds of power plants.

Opponents believe that nuclear power poses many threats to people and the environment. 
These threats include the problems of processing, transport and storage of radioactive nuclear waste, the risk of nuclear weapons proliferation and terrorism, as well as health risks and environmental damage from uranium mining. They also contend that reactors themselves are enormously complex machines where many things can and do go wrong; and there have been serious nuclear accidents. Critics do not believe that the risks of using nuclear fission as a power source can be fully offset through the development of new technology. In years past, they also argued that when all the energy-intensive stages of the nuclear fuel chain are considered, from uranium mining to nuclear decommissioning, nuclear power is neither a low-carbon nor an economical electricity source.

Arguments of economics and safety are used by both sides of the debate.

Both fission and fusion appear promising for space propulsion applications, generating higher mission velocities with less reaction mass. This is due to the much higher energy density of nuclear reactions: some 7 orders of magnitude (10,000,000 times) more energetic than the chemical reactions which power the current generation of rockets.

Radioactive decay has been used on a relatively small scale (few kW), mostly to power space missions and experiments by using radioisotope thermoelectric generators such as those developed at Idaho National Laboratory.

Current fission reactors in operation around the world are second or third generation systems, with most of the first-generation systems having been retired some time ago. Research into advanced generation IV reactor types was officially started by the Generation IV International Forum (GIF) based on eight technology goals, including to improve nuclear safety, improve proliferation resistance, minimize waste, improve natural resource utilization, the ability to consume existing nuclear waste in the production of electricity, and decrease the cost to build and run such plants. Most of these reactors differ significantly from current operating light water reactors, and are generally not expected to be available for commercial construction before 2030.

The nuclear reactors to be built at Vogtle are new AP1000 third generation reactors, which are said to have safety improvements over older power reactors. However, John Ma, a senior structural engineer at the NRC, is concerned that some parts of the AP1000 steel skin are so brittle that the "impact energy" from a plane strike or storm driven projectile could shatter the wall. Edwin Lyman, a senior staff scientist at the Union of Concerned Scientists, is concerned about the strength of the steel containment vessel and the concrete shield building around the AP1000.

The Union of Concerned Scientists has referred to the EPR (nuclear reactor), currently under construction in China, Finland and France, as the only new reactor design under consideration in the United States that "...appears to have the potential to be significantly safer and more secure against attack than today's reactors."

One disadvantage of any new reactor technology is that safety risks may be greater initially as reactor operators have little experience with the new design. Nuclear engineer David Lochbaum has explained that almost all serious nuclear accidents have occurred with what was at the time the most recent technology. He argues that "the problem with new reactors and accidents is twofold: scenarios arise that are impossible to plan for in simulations; and humans make mistakes". As one director of a U.S. research laboratory put it, "fabrication, construction, operation, and maintenance of new reactors will face a steep learning curve: advanced technologies will have a heightened risk of accidents and mistakes. The technology may be proven, but people are not".

Hybrid nuclear power is a proposed means of generating power by use of a combination of nuclear fusion and fission processes. The concept dates to the 1950s, and was briefly advocated by Hans Bethe during the 1970s, but largely remained unexplored until a revival of interest in 2009, due to delays in the realization of pure fusion. When a sustained nuclear fusion power plant is built, it has the potential to be capable of extracting all the fission energy that remains in spent fission fuel, reducing the volume of nuclear waste by orders of magnitude, and more importantly, eliminating all actinides present in the spent fuel, substances which cause security concerns.

Nuclear fusion reactions have the potential to be safer and generate less radioactive waste than fission. 
These reactions appear potentially viable, though technically quite difficult and have yet to be created on a scale that could be used in a functional power plant. 
Fusion power has been under theoretical and experimental investigation since the 1950s.

Several experimental nuclear fusion reactors and facilities exist. 
The largest and most ambitious international nuclear fusion project currently in progress is ITER, a large tokamak under construction in France.
ITER is planned to pave the way for commercial fusion power by demonstrating self-sustained nuclear fusion reactions with positive energy gain. 
Construction of the ITER facility began in 2007, but the project has run into many delays and budget overruns. 
The facility is now not expected to begin operations until the year 2027 – 11 years after initially anticipated. A follow on commercial nuclear fusion power station, DEMO, has been proposed. There are also suggestions for a power plant based upon a different fusion approach, that of an inertial fusion power plant.

Fusion powered electricity generation was initially believed to be readily achievable, as fission-electric power had been. However, the extreme requirements for continuous reactions and plasma containment led to projections being extended by several decades. In 2010, more than 60 years after the first attempts, commercial power production was still believed to be unlikely before 2050.





</doc>
<doc id="22156" url="https://en.wikipedia.org/wiki?curid=22156" title="BI Norwegian Business School">
BI Norwegian Business School

BI Norwegian Business School () is the largest business school in Norway and the second largest in all of Europe. BI has in total four campuses with the main one located in Oslo. The university has 845 employees consisting of an academic staff of 404 people and 441 administrative staff. In 2015, BI Norwegian Business School had 18,728 students. BI is the largest supplier of economic and administrative competence and skills in Norway with more than 200 000 graduates since 1983. BI Norwegian Business School is a private foundation and is accredited by NOKUT as a specialised university institution. BI organised its academic activities in nine separate research departments covering all of the disciplines that can be expected at a modern European business school.

BI Norwegian Business School was founded in 1943 by Finn Øien as "Bedriftøkonomisk Institutt" (), hence the abbreviation "BI".

BI offers a full set of programs for bachelor, master, and doctoral degrees, as well as executive education and tailor-made programs for businesses. The teaching languages are English (BBA and graduate programs) and Norwegian (majority of undergraduate programs and custom programs for local businesses). The school currently participates in exchange programs with 200 foreign institutions in 45 countries.

The internationally award-winning main campus in Nydalen (Oslo) was designed by Niels Torp, who also designed Gardermoen Airport.

Norsk Kundebarometer (NKB) () is a research program run by BI, with a focus on relations between customers and businesses. Based on an annual survey of Norwegian households, it collects data that may be used for comparison between businesses, comparisons between various industries, and comparisons over time.

BI has educated roughly 1700 students in China through its close relationship with Fudan University in Shanghai, and is also the majority shareholder of the ISM University of Management and Economics (previously known as International School of Management) with around 1800 students located in Vilnius and Kaunas in Lithuania.
Undergraduate (All taught in Norwegian except Business Administration), 
"Bachelor in":
Graduate (Only available in Oslo; all taught in English except MSc in Professional Accountancy)
Executive MBA (EMBA general management in cooperation with Nanyang Business School (Nanyang Technological University), Singapore and Instituto de Empresa in Madrid, Spain and Haas School of Business (University of California at Berkeley), USA)

The school has two student organizations, one for the main campus in Oslo and one for the other campuses. The Oslo student organization is called "" (SBIO) (). This union was formed in 2005 after the relocation of the three locations in Oslo into one—Nydalen Campus. The three previous unions were called Bedriftøkonomisk Studentersamfund (BS), BISON and MØSS. BS was the oldest union, formed in 1964. The union for the other campuses is "BI Studentsamfunn" (BIS) (). This union was founded on 7 February 1987 and is today the largest student union of a private school in Norway.

The student newspaper is named "INSIDE", and its circulation is 11,000.

The all-male student choir is named UFDA The Choir Boys and was established in 1986.

BI is currently ranked 35th in the Financial Times ranking of European Business Schools.

In 2009, BI was ranked by Eduniversal as the 35th most influential business school in the world.

BI is accredited as a specialised university institution by the Norwegian Agency for Quality Assurance in Education (NOKUT).

BI has also received the following recognitions from private institutions:




 

</doc>
<doc id="22158" url="https://en.wikipedia.org/wiki?curid=22158" title="Nuclear proliferation">
Nuclear proliferation

Nuclear proliferation is the spread of nuclear weapons, fissionable material, and weapons-applicable nuclear technology and information to nations not recognized as "Nuclear Weapon States" by the Treaty on the Non-Proliferation of Nuclear Weapons, commonly known as the Non-Proliferation Treaty or NPT. Proliferation has been opposed by many nations with and without nuclear weapons, as governments fear that more countries with nuclear weapons will increase the possibility of nuclear warfare (up to and including the so-called "countervalue" targeting of civilians with nuclear weapons), de-stabilize international or regional relations, or infringe upon the national sovereignty of states.

Four countries besides the five recognized Nuclear Weapons States have acquired, or are presumed to have acquired, nuclear weapons: India, Pakistan, North Korea, and Israel. None of these four is a party to the NPT, although North Korea acceded to the NPT in 1985, then withdrew in 2003 and conducted announced nuclear tests in 2006, 2009, 2013, 2016, and 2017. One critique of the NPT is that it is discriminatory in the sense that only those countries that tested nuclear weapons before 1968 are recognized as nuclear weapon states and require all other states are treated as non-nuclear-weapon states and can only join the treaty if they forswear nuclear weapons.

Research into the development of nuclear weapons was undertaken during World War II by the United States (in cooperation with the United Kingdom and Canada), Germany, Japan, and the USSR. The United States was the first and is the only country to have used a nuclear weapon in war, when it used two bombs against Japan in August 1945. With their loss during the war, Germany and Japan ceased to be involved in any nuclear weapon research. In August 1949, the USSR tested a nuclear weapon. The United Kingdom tested a nuclear weapon in October 1952. France developed a nuclear weapon in 1960. The People's Republic of China detonated a nuclear weapon in 1964. India exploded a nuclear device in 1974, and Pakistan conducted a series of nuclear weapon tests in May 1998, following tests by India earlier that month. In 2006, North Korea conducted its first nuclear test.

Early efforts to prevent nuclear proliferation involved intense government secrecy, the wartime acquisition of known uranium stores (the Combined Development Trust), and at times even outright sabotage—such as the bombing of a heavy-water facility thought to be used for a German nuclear program. These efforts began immediately after the discovery of nuclear fission and its military potential. None of these efforts were explicitly public, because the weapon developments themselves were kept secret until the bombing of Hiroshima.

Earnest international efforts to promote nuclear non-proliferation began soon after World War II, when the Truman Administration proposed the Baruch Plan of 1946, named after Bernard Baruch, America's first representative to the United Nations Atomic Energy Commission. The Baruch Plan, which drew heavily from the Acheson–Lilienthal Report of 1946, proposed the verifiable dismantlement and destruction of the U.S. nuclear arsenal (which, at that time, was the only nuclear arsenal in the world) after all governments had cooperated successfully to accomplish two things: (1) the establishment of an "international atomic development authority," which would actually own and control all military-applicable nuclear materials and activities, and (2) the creation of a system of automatic sanctions, which not even the U.N. Security Council could veto, and which would proportionately punish states attempting to acquire the capability to make nuclear weapons or fissile material.

Baruch's plea for the destruction of nuclear weapons invoked basic moral and religious intuitions. In one part of his address to the UN, Baruch said, "Behind the black portent of the new atomic age lies a hope which, seized upon with faith, can work out our salvation. If we fail, then we have damned every man to be the slave of Fear. Let us not deceive ourselves. We must elect World Peace or World Destruction... We must answer the world's longing for peace and security." With this remark, Baruch helped launch the field of nuclear ethics, to which many policy experts and scholars have contributed.

Although the Baruch Plan enjoyed wide international support, it failed to emerge from the UNAEC because the Soviet Union planned to veto it in the Security Council. Still, it remained official American policy until 1953, when President Eisenhower made his "Atoms for Peace" proposal before the U.N. General Assembly. Eisenhower's proposal led eventually to the creation of the International Atomic Energy Agency (IAEA) in 1957. Under the "Atoms for Peace" program thousands of scientists from around the world were educated in nuclear science and then dispatched home, where many later pursued secret weapons programs in their home country.

Efforts to conclude an international agreement to limit the spread of nuclear weapons did not begin until the early 1960s, after four nations (the United States, the Soviet Union, the United Kingdom and France) had acquired nuclear weapons (see List of states with nuclear weapons for more information). Although these efforts stalled in the early 1960s, they renewed once again in 1964, after China detonated a nuclear weapon. In 1968, governments represented at the Eighteen Nation Disarmament Committee (ENDC) finished negotiations on the text of the NPT. In June 1968, the U.N. General Assembly endorsed the NPT with General Assembly Resolution 2373 (XXII), and in July 1968, the NPT opened for signature in Washington, DC, London and Moscow. The NPT entered into force in March 1970.

Since the mid-1970s, the primary focus of non-proliferation efforts has been to maintain, and even increase, international control over the fissile material and specialized technologies necessary to build such devices because these are the most difficult and expensive parts of a nuclear weapons program. The main materials whose generation and distribution is controlled are highly enriched uranium and plutonium. Other than the acquisition of these special materials, the scientific and technical means for weapons construction to develop rudimentary, but working, nuclear explosive devices are considered to be within the reach of industrialized nations.

Since its founding by the United Nations in 1957, the International Atomic Energy Agency (IAEA) has promoted two, sometimes contradictory, missions: on the one hand, the Agency seeks to promote and spread internationally the use of civilian nuclear energy; on the other hand, it seeks to prevent, or at least detect, the diversion of civilian nuclear energy to nuclear weapons, nuclear explosive devices or purposes unknown. The IAEA now operates a safeguards system as specified under Article III of the Nuclear Non-Proliferation Treaty (NPT) of 1968, which aims to ensure that civil stocks of uranium and plutonium, as well as facilities and technologies associated with these nuclear materials, are used only for peaceful purposes and do not contribute in any way to proliferation or nuclear weapons programs. It is often argued that proliferation of nuclear weapons to many other states has been prevented by the extension of assurances and mutual defence treaties to these states by nuclear powers, but other factors, such as national prestige, or specific historical experiences, also play a part in hastening or stopping nuclear proliferation.

Dual-use technology refers to the possibility of military use of civilian nuclear power technology. Many technologies and materials associated with the creation of a nuclear power program have a dual-use capability, in that several stages of the nuclear fuel cycle allow diversion of nuclear materials for nuclear weapons. When this happens a nuclear power program can become a route leading to the atomic bomb or a public annex to a secret bomb program. The crisis over Iran’s nuclear activities is a case in point.

Many UN and US agencies warn that building more nuclear reactors unavoidably increases nuclear proliferation risks. A fundamental goal for American and global security is to minimize the proliferation risks associated with the
expansion of nuclear power. If this development is "poorly managed or efforts to contain risks are unsuccessful, the nuclear future will be dangerous". For nuclear power programs to be developed and managed safely and securely, it is important that countries have domestic “good governance” characteristics that will encourage proper nuclear operations and management:

These characteristics include low degrees of corruption (to avoid officials selling materials and technology for their own personal gain as occurred with the A.Q. Khan smuggling network in Pakistan), high degrees of political stability (defined by the World Bank as “likelihood that the government will be destabilized or overthrown by unconstitutional or violent means, including motivated violence and terrorism”), high governmental effectiveness scores (a World Bank aggregate measure of “the quality of the civil service and the degree of its independence from political pressures [and] the quality of policy formulation and implementation”), and a strong degree of regulatory competence.

At present, 189 countries are States Parties to the "Treaty on the Nonproliferation of Nuclear Weapons", more commonly known as the Nuclear Non-Proliferation Treaty or NPT. These include the five Nuclear Weapons States (NWS) recognized by the NPT: the People's Republic of China, France, Russian Federation, the UK, and the United States.

Notable non-signatories to the NPT are Israel, Pakistan, and India (the latter two have since tested nuclear weapons, while Israel is considered by most to be an unacknowledged nuclear weapons state). North Korea was once a signatory but withdrew in January 2003. The legality of North Korea's withdrawal is debatable but as of 9 October 2006, North Korea clearly possesses the capability to make a nuclear explosive device.

The IAEA was established on 29 July 1957 to help nations develop nuclear energy for peaceful purposes. Allied to this role is the administration of safeguards arrangements to provide assurance to the international community that individual countries are honoring their commitments under the treaty. Though established under its own international treaty, the IAEA reports to both the United Nations General Assembly and the Security Council.

The IAEA regularly inspects civil nuclear facilities to verify the accuracy of documentation supplied to it. The agency checks inventories, and samples and analyzes materials. Safeguards are designed to deter diversion of nuclear material by increasing the risk of early detection. They are complemented by controls on the export of sensitive technology from countries such as UK and United States through voluntary bodies such as the Nuclear Suppliers Group. The main concern of the IAEA is that uranium not be enriched beyond what is necessary for commercial civil plants, and that plutonium which is produced by nuclear reactors not be refined into a form that would be suitable for bomb production.

Traditional safeguards are arrangements to account for and control the use of nuclear materials. This verification is a key element in the international system which ensures that uranium in particular is used only for peaceful purposes.

Parties to the NPT agree to accept technical safeguard measures applied by the IAEA. These require that operators of nuclear facilities maintain and declare detailed accounting records of all movements and transactions involving nuclear material. Over 550 facilities and several hundred other locations are subject to regular inspection, and their records and the nuclear material being audited. Inspections by the IAEA are complemented by other measures such as surveillance cameras and instrumentation.

The inspections act as an alert system providing a warning of the possible diversion of nuclear material from peaceful activities. The system relies on;

All NPT non-weapons states must accept these full-scope safeguards. In the five weapons states plus the non-NPT states (India, Pakistan and Israel), facility-specific safeguards apply. IAEA inspectors regularly visit these facilities to verify completeness and accuracy of records.

The terms of the NPT cannot be enforced by the IAEA itself, nor can nations be forced to sign the treaty. In reality, as shown in Iraq and North Korea, safeguards can be backed up by diplomatic, political and economic measures.

While traditional safeguards easily verified the correctness of formal declarations by suspect states, in the 1990s attention turned to what might not have been declared. While accepting safeguards at declared facilities, Iraq had set up elaborate equipment elsewhere in an attempt to enrich uranium to weapons grade. North Korea attempted to use research reactors (not commercial electricity-generating reactors) and a reprocessing plant to produce some weapons-grade plutonium.

The weakness of the NPT regime lay in the fact that no obvious diversion of material was involved. The uranium used as fuel probably came from indigenous sources, and the nuclear facilities were built by the countries themselves without being declared or placed under safeguards. Iraq, as an NPT party, was obliged to declare all facilities but did not do so. Nevertheless, the activities were detected and brought under control using international diplomacy. In Iraq, a military defeat assisted this process.

In North Korea, the activities concerned took place before the conclusion of its NPT safeguards agreement. With North Korea, the promised provision of commercial power reactors appeared to resolve the situation for a time, but it later withdrew from the NPT and declared it had nuclear weapons.

In 1993 a program was initiated to strengthen and extend the classical safeguards system, and a model protocol was agreed by the IAEA Board of Governors 1997. The measures boosted the IAEA's ability to detect undeclared nuclear activities, including those with no connection to the civil fuel cycle.

Innovations were of two kinds. Some could be implemented on the basis of IAEA's existing legal authority through safeguards agreements and inspections. Others required further legal authority to be conferred through an Additional Protocol. This must be agreed by each non-weapons state with IAEA, as a supplement to any existing comprehensive safeguards agreement. Weapons states have agreed to accept the principles of the model additional protocol.

Key elements of the model Additional Protocol:

As of 3 July 2015, 146 countries have signed Additional Protocols and 126 have brought them into force. The IAEA is also applying the measures of the Additional Protocol in Taiwan. Under the Joint Comprehensive Plan of Action, Iran has agreed to implement its protocol provisionally. Among the leading countries that have not signed the Additional Protocol are Egypt, which says it will not sign until Israel accepts comprehensive IAEA safeguards, and Brazil, which opposes making the protocol a requirement for international cooperation on enrichment and reprocessing, but has not ruled out signing.

The greatest risk from nuclear weapons proliferation comes from countries which have not joined the NPT and which have significant unsafeguarded nuclear activities; India, Pakistan, and Israel fall within this category. While safeguards apply to some of their activities, others remain beyond scrutiny.

A further concern is that countries may develop various sensitive nuclear fuel cycle facilities and research reactors under full safeguards and then subsequently opt out of the NPT. Bilateral agreements, such as insisted upon by Australia and Canada for sale of uranium, address this by including fallback provisions, but many countries are outside the scope of these agreements. If a nuclear-capable country does leave the NPT, it is likely to be reported by the IAEA to the UN Security Council, just as if it were in breach of its safeguards agreement. Trade sanctions would then be likely.

IAEA safeguards can help ensure that uranium supplied as nuclear fuel and other nuclear supplies do not contribute to nuclear weapons proliferation. In fact, the worldwide application of those safeguards and the substantial world trade in uranium for nuclear electricity make the proliferation of nuclear weapons much less likely.

The Additional Protocol, once it is widely in force, will provide credible assurance that there are no undeclared nuclear materials or activities in the states concerned. This will be a major step forward in preventing nuclear proliferation.

The Nuclear Suppliers Group communicated its guidelines, essentially a set of export rules, to the IAEA in 1978. These were to ensure that transfers of nuclear material or equipment would not be diverted to unsafeguarded nuclear fuel cycle or nuclear explosive activities, and formal government assurances to this effect were required from recipients. The Guidelines also recognised the need for physical protection measures in the transfer of sensitive facilities, technology and weapons-usable materials, and strengthened retransfer provisions. The group began with seven membersthe United States, the former USSR, the UK, France, Germany, Canada and Japanbut now includes 46 countries including all five nuclear weapons states.

The International Framework for Nuclear Energy Cooperation is an international project involving 25 partner countries, 28 observer and candidate partner countries, and the International Atomic Energy Agency, the Generation IV International Forum, and the European Commission. Its goal is to "[..] provide competitive, commercially-based services as an alternative to a state’s development of costly, proliferation-sensitive facilities, and address other issues associated with the safe and secure management of used fuel and radioactive waste."

According to Kenneth D. Bergeron's "Tritium on Ice: The Dangerous New Alliance of Nuclear Weapons and Nuclear Power", tritium is not classified as a "special nuclear material" but rather as a by-product. It is seen as an important litmus test on the seriousness of the United States' intention to nuclear disarm. This radioactive super-heavy hydrogen isotope is used to boost the efficiency of fissile materials in nuclear weapons. The United States resumed tritium production in 2003 for the first time in 15 years. This could indicate that there is a potential nuclear arm stockpile replacement since the isotope naturally decays.

In May 1995, NPT parties reaffirmed their commitment to a Fissile Materials Cut-off Treaty to prohibit the production of any further fissile material for weapons. This aims to complement the Comprehensive Nuclear-Test-Ban Treaty of 1996 (not entered into force as of 2011) and to codify commitments made by the United States, the UK, France and Russia to cease production of weapons material, as well as putting a similar ban on China. This treaty will also put more pressure on Israel, India and Pakistan to agree to international verification.

On 9 August 2005, Ayatollah Ali Khamenei issued a fatwa forbidding the production, stockpiling and use of nuclear weapons. Khamenei's official statement was made at the meeting of the International Atomic Energy Agency (IAEA) in Vienna. As of February 2006 Iran formally announced that uranium enrichment within their borders has continued. Iran claims it is for peaceful purposes but the United Kingdom, France, Germany, and the United States claim the purpose is for nuclear weapons research and construction.

India, Pakistan and Israel have been "threshold" countries in terms of the international non-proliferation regime. They possess or are quickly capable of assembling one or more nuclear weapons. They have remained outside the 1970 NPT. They are thus largely excluded from trade in nuclear plant or materials, except for safety-related devices for a few safeguarded facilities.

In May 1998 India and Pakistan each exploded several nuclear devices underground. This heightened concerns regarding an arms race between them, with Pakistan involving the People's Republic of China, an acknowledged nuclear weapons state. Both countries are opposed to the NPT as it stands, and India has consistently attacked the Treaty since its inception in 1970 labeling it as a lopsided treaty in favor of the nuclear powers.

Relations between the two countries are tense and hostile, and the risks of nuclear conflict between them have long been considered quite high. Kashmir is a prime cause of bilateral tension, its sovereignty being in dispute since 1948. There is persistent low level bilateral military conflict due to alleged backing of insurgency by Pakistan in India and infiltration of Pakistani state backed militants in the Indian state of Jammu and Kashmir, along with the disputed status of Kashmir.

Both engaged in a conventional arms race in the 1980s, including sophisticated technology and equipment capable of delivering nuclear weapons. In the 1990s the arms race quickened. In 1994 India reversed a four-year trend of reduced allocations for defence, and despite its much smaller economy, Pakistan was expected to push its own expenditures yet higher. Both have lost their patrons: India, the former USSR, and Pakistan, the United States.

But it is the growth and modernization of China's nuclear arsenal and its assistance with Pakistan's nuclear power programme and, reportedly, with missile technology, which exacerbate Indian concerns. In particular, as viewed by Indian strategists, Pakistan is aided by China's People's Liberation Army.

Nuclear power for civil use is well established in India. Its civil nuclear strategy has been directed towards complete independence in the nuclear fuel cycle, necessary because of its outspoken rejection of the NPT. This self-sufficiency extends from uranium exploration and mining through fuel fabrication, heavy water production, reactor design and construction, to reprocessing and waste management. It has a small fast breeder reactor and is planning a much larger one. It is also developing technology to utilise its abundant resources of thorium as a nuclear fuel.

India has 14 small nuclear power reactors in commercial operation, two larger ones under construction, and ten more planned. The 14 operating ones (2548 MWe total) comprise:

The two under construction and two of the planned ones are 450 MWe versions of these 200 MWe domestic products. Construction has been seriously delayed by financial and technical problems. In 2001 a final agreement was signed with Russia for the country's first large nuclear power plant, comprising two VVER-1000 reactors, under a Russian-financed US$3 billion contract. The first unit is due to be commissioned in 2007. A further two Russian units are under consideration for the site. Nuclear power supplied 3.1% of India's electricity in 2000.

Its weapons material appears to come from a Canadian-designed 40MW "research" reactor which started up in 1960, well before the NPT, and a 100MW indigenous unit in operation since 1985. Both use local uranium, as India does not import any nuclear fuel. It is estimated that India may have built up enough weapons-grade plutonium for a hundred nuclear warheads.

It is widely believed that the nuclear programs of India and Pakistan used CANDU reactors to produce fissionable materials for their weapons; however, this is not accurate. Both Canada (by supplying the 40 MW research reactor) and the United States (by supplying 21 tons of heavy water) supplied India with the technology necessary to create a nuclear weapons program, dubbed CIRUS (Canada-India Reactor, United States). Canada sold India the reactor on the condition that the reactor and any by-products would be "employed for peaceful purposes only.". Similarly, the United States sold India heavy water for use in the reactor "only... in connection with research into and the use of atomic energy for peaceful purposes". India, in violation of these agreements, used the Canadian-supplied reactor and American-supplied heavy water to produce plutonium for their first nuclear explosion, Smiling Buddha. The Indian government controversially justified this, however, by claiming that Smiling Buddha was a "peaceful nuclear explosion."

The country has at least three other research reactors including the tiny one which is exploring the use of thorium as a nuclear fuel, by breeding fissile U-233. In addition, an advanced heavy-water thorium cycle is under development.

India exploded a nuclear device in 1974, the so-called Smiling Buddha test, which it has consistently claimed was for peaceful purposes. Others saw it as a response to China's nuclear weapons capability. It was then universally perceived, notwithstanding official denials, to possess, or to be able to quickly assemble, nuclear weapons. In 1999 it deployed its own medium-range missile and has developed an intermediate-range missile capable of reaching targets in China's industrial heartland.

In 1995 the United States quietly intervened to head off a proposed nuclear test. However, in 1998 there were five more tests in Operation Shakti. These were unambiguously military, including one claimed to be of a sophisticated thermonuclear device, and their declared purpose was "to help in the design of nuclear weapons of different yields and different delivery systems".

Indian security policies are driven by:

It perceives nuclear weapons as a cost-effective political counter to China's nuclear and conventional weaponry, and the effects of its nuclear weapons policy in provoking Pakistan is, by some accounts, considered incidental.
India has had an unhappy relationship with China. After an uneasy ceasefire ended the 1962 war, relations between the two nations were frozen until 1998. Since then a degree of high-level contact has been established and a few elementary confidence-building measures put in place. China still occupies some territory which it captured during the aforementioned war, claimed by India, and India still occupies some territory claimed by China. Its nuclear weapon and missile support for Pakistan is a major bone of contention.

American President George W. Bush met with India Prime Minister Manmohan Singh to discuss India's involvement with nuclear weapons. The two countries agreed that the United States would give nuclear power assistance to India.

Over the several years, the Nuclear power infrastructure has been well established by Pakistan which is dedicated for the industrial and economic development of the country. Its current nuclear policy is directed and aimed to promote the socio-economic development of the people as a "foremost priority"; and to fulfill the energy, economic, and industrial needs from the nuclear sources. Currently, there are three operational mega-commercial nuclear power plants while three larger ones are under construction. The nuclear power supplies 787MW (roughly ~3.6%) of electricity as of 2012, and the country has projected to produce 8800MW electricity by 2030. Infrastructure established by the IAEA and the U.S. in the 1950s–1960s were based on peaceful research and development and economic prosperity of the country.

Although the civil-sector nuclear power was established in the 1950s, the country has an active nuclear weapons program which was started in the 1970s. The bomb program has its roots after East-Pakistan gained its independence as Bangladesh after India's successful intervention led to a decisive victory on Pakistan in 1971. This large-scale but clandestine atomic bomb project was directed towards the development of ingenious development of reactor and military-grade plutonium. In 1974, when India surprised the outer world with its successful detonation of its own bomb, codename "Smiling Buddha", it became "imperative for Pakistan" to pursue the weapons research. According to leading scientist in the program, it became clear once India detonated the bomb, "Newton's third law" came into "operation", from then on it was a classic case of "action and reaction". Earlier efforts were directed towards mastering the plutonium technology from France, but plutonium route was partially slowed down when the plan was failed after the U.S. intervention to cancel the project. Contrary to popular perception, Pakistan did not forego the "plutonium" route and covertly continued its indegenious research under Munir Khan and it succeeded with plutonium route in the early 1980s. Reacting on India's nuclear test (Smiling Buddha), Bhutto and the country's elite political and military science circle sensed this test as final and dangerous anticipation to Pakistan's "moral and physical existence." With Aziz Ahmed on his side, Bhutto launched a serious diplomatic offense and aggressively maintained at the session of the United Nations Security Council:

After 1974, Bhutto's government redoubled its effort, this time equally focused on uranium and plutonium. Pakistan had established science directorates in almost all of her embassies in the important countries of the world, with theoretical physicist S.A. Butt being the director. Abdul Qadeer Khan then established a network through Dubai to smuggle URENCO technology to Engineering Research Laboratories. Earlier, he worked with "Physics Dynamics Research Laboratories" (FDO), a subsidiary of the Dutch firm VMF-Stork based in Amsterdam. Later after joining, the Urenco, he had access through photographs and documents of the technology. Against the popular perception, the technology that A.Q. Khan had brought from Urenco was based on first generation civil rector technology, filled with many serious technical errors, though it was authentic and vital link for centrifuge project of the country. After the British Government stopped the British subsidiary of the American Emerson Electric Co. from shipping the components to Pakistan, he describes his frustration with a supplier from Germany as: "That man from the German team was unethical. When he did not get the order from us, he wrote a letter to a Labour Party member and questions were asked in [British] Parliament." By 1978, his efforts were paid off and made him into a national hero. In 1981, as a tribute, President General Muhammad Zia-ul-Haq, renamed the research institute after his name.

In early 1996, Prime minister Benazir Bhutto made it clear that "if India conducts a nuclear test, Pakistan could be forced to "follow suit". In 1997, her statement was echoed by Prime minister Nawaz Sharif who maintained to the fact that "since 1972, [P]akistan had progressed significantly, and we have left that stage (developmental) far behind. Pakistan will not be made a "hostage" to India by signing the CTBT, before (India).!" In May 1998, within weeks of India's nuclear tests, Pakistan announced that it had conducted six underground tests in the Chagai Hills, five on the 28th and one on the 30th of that month. Seismic events consistent with these claims were recorded.

In 2004, the revelation of A.Q. Khan's efforts led to the exposure of many defunct European consortiums which had defied export restrictions in the 1970s, and of many defunct Dutch companies that exported thousands of centrifuges to Pakistan as early as 1976. Many centrifuge components were apparently manufactured in Malaysian Scomi Precision Engineering with the assistance of South Asian and German companies, and used a UAE-based computer company as a false front.

It was widely believed to have direct involvement of the government of Pakistan. This claim could not be verified due to the refusal of the government of Pakistan to allow IAEA to interview the alleged head of the nuclear black market, who happened to be no other than A.Q. Khan. Confessing his crimes later a month on national television, he bailed out the government by taking full responsibility. Independent investigation conducted by IISS confirmed that he had control over the import-export deals, and his acquisition activities were largely unsupervised by Pakistan governmental authorities. All of his activities went undetected for several years. He duly confessed of running the atomic proliferation ring from Pakistan to Iran and North Korea. He was immediately given presidential immunity. Exact nature of the involvement at the governmental level is still unclear, but the manner in which the government acted cast doubt on the sincerity of Pakistan.

The Democratic Peoples Republic of Korea (or better known as North Korea), joined the NPT in 1985 and had subsequently signed a safeguards agreement with the IAEA. However, it was believed that North Korea was diverting plutonium extracted from the fuel of its reactor at Yongbyon, for use in nuclear weapons. The subsequent confrontation with IAEA on the issue of inspections and suspected violations, resulted in North Korea threatening to withdraw from the NPT in 1993. This eventually led to negotiations with the United States resulting in the Agreed Framework of 1994, which provided for IAEA safeguards being applied to its reactors and spent fuel rods. These spent fuel rods were sealed in canisters by the United States to prevent North Korea from extracting plutonium from them. North Korea had to therefore freeze its plutonium programme.

During this period, Pakistan-North Korea cooperation in missile technology transfer was being established. A high level delegation of Pakistan military visited North Korea in August–September 1992, reportedly to discuss the supply of missile technology to Pakistan. In 1993, PM Benazir Bhutto repeatedly traveled to China, and the paid state visit to North Korea. The visits are believed to be related to the subsequent acquisition technology to developed its Ghauri system by Pakistan. During the period 1992–1994, A.Q. Khan was reported to have visited North Korea thirteen times. The missile cooperation program with North Korea was under Dr. A. Q. Khan Research Laboratories. At this time China was under U.S. pressure not to supply the M Dongfeng series of missiles to Pakistan. It is believed by experts that possibly with Chinese connivance and facilitation, the latter was forced to approach North Korea for missile transfers. Reports indicate that North Korea was willing to supply missile sub-systems including rocket motors, inertial guidance systems, control and testing equipment for US$50 million.

It is not clear what North Korea got in return. Joseph S. Bermudez Jr. in "Jane's Defence Weekly" (27 November 2002) reports that Western analysts had begun to question what North Korea received in payment for the missiles; many suspected it was the nuclear technology. The KRL was in charge of both uranium program and also of the missile program with North Korea. It is therefore likely during this period that cooperation in nuclear technology between Pakistan and North Korea was initiated. Western intelligence agencies began to notice exchange of personnel, technology and components between KRL and entities of the North Korean 2nd Economic Committee (responsible for weapons production).

A "New York Times" report on 18 October 2002 quoted U.S. intelligence officials having stated that Pakistan was a major supplier of critical equipment to North Korea. The report added that equipment such as gas centrifuges appeared to have been "part of a barter deal" in which North Korea supplied Pakistan with missiles. Separate reports indicate ("The Washington Times", 22 November 2002) that U.S. intelligence had as early as 1999 picked up signs that North Korea was continuing to develop nuclear arms. Other reports also indicate that North Korea had been working covertly to develop an enrichment capability for nuclear weapons for at least five years and had used technology obtained from Pakistan ("The Washington Times", 18 October 2002).

Israel is also thought to possess an arsenal of potentially up to several hundred nuclear warheads based on estimates of the amount of fissile material produced by Israel. This has never been openly confirmed or denied however, due to Israel's policy of deliberate ambiguity.

An Israeli nuclear installation is located about ten kilometers to the south of Dimona, the Negev Nuclear Research Center. Its construction commenced in 1958, with French assistance. The official reason given by the Israeli and French governments was to build a nuclear reactor to power a "desalination plant", in order to "green the Negev". The purpose of the Dimona plant is widely assumed to be the manufacturing of nuclear weapons, and the majority of defense experts have concluded that it does in fact do that. However, the Israeli government refuses to confirm or deny this publicly, a policy it refers to as "ambiguity".

Norway sold 20 tonnes of heavy water needed for the reactor to Israel in 1959 and 1960 in a secret deal. There were no "safeguards" required in this deal to prevent usage of the heavy water for non-peaceful purposes. The British newspaper "Daily Express" accused Israel of working on a bomb in 1960.
When the United States intelligence community discovered the purpose of the Dimona plant in the early 1960s, it demanded that Israel agree to international inspections. Israel agreed, but on a condition that U.S., rather than IAEA, inspectors were used, and that Israel would receive advanced notice of all inspections.
Some claim that because Israel knew the schedule of the inspectors' visits, it was able to hide the alleged purpose of the site from the inspectors by installing temporary false walls and other devices before each inspection. The inspectors eventually informed the U.S. government that their inspections were useless due to Israeli restrictions on what areas of the facility they could inspect. In 1969, the United States terminated the inspections.

In 1986, Mordechai Vanunu, a former technician at the Dimona plant, revealed to the media some evidence of Israel's nuclear program. Israeli agents arrested him from Italy, drugged him and transported him to Israel, and an Israeli court then tried him in secret on charges of treason and espionage, and sentenced him to eighteen years imprisonment. He was freed on 21 April 2004, but was severely limited by the Israeli government. He was arrested again on 11 November 2004, though formal charges were not immediately filed.

Comments on photographs taken by Mordechai Vanunu inside the Negev Nuclear Research Center have been made by prominent scientists. British nuclear weapons scientist Frank Barnaby, who questioned Vanunu over several days, estimated Israel had enough plutonium for about 150 weapons.

According to Lieutenant Colonel Warner D. Farr in a report to the USAF Counterproliferation Center while France was previously a leader in nuclear research "Israel and France were at a similar level of expertise after WWII, and Israeli scientists could make significant contributions to the French effort." In 1986 Francis Perrin, French high-commissioner for atomic energy from 1951 to 1970 stated that in 1949 Israeli scientists were invited to the Saclay nuclear research facility, this cooperation leading to a joint effort including sharing of knowledge between French and Israeli scientists especially those with knowledge from the Manhattan Project.

The public stance of the two states on non-proliferation differs markedly. Pakistan has initiated a series of regional security proposals. It has repeatedly proposed a nuclear free zone in South Asia and has proclaimed its willingness to engage in nuclear disarmament and to sign the Non-Proliferation Treaty if India would do so. It has endorsed a United States proposal for a regional five power conference to consider non-proliferation in South Asia.

India has taken the view that solutions to regional security issues should be found at the international rather than the regional level, since its chief concern is with China. It therefore rejects Pakistan's proposals.

Instead, the 'Gandhi Plan', put forward in 1988, proposed the revision of the Non-Proliferation Treaty, which it regards as inherently discriminatory in favor of the nuclear-weapon States, and a timetable for complete nuclear weapons disarmament. It endorsed early proposals for a Comprehensive Test Ban Treaty and for an international convention to ban the production of highly enriched uranium and plutonium for weapons purposes, known as the 'cut-off' convention.

The United States for some years, especially under the Clinton administration, pursued a variety of initiatives to persuade India and Pakistan to abandon their nuclear weapons programs and to accept comprehensive international safeguards on all their nuclear activities. To this end, the Clinton administration proposed a conference of the five nuclear-weapon states, Japan, Germany, India and Pakistan.

India refused this and similar previous proposals, and countered with demands that other potential weapons states, such as Iran and North Korea, should be invited, and that regional limitations would only be acceptable if they were accepted equally by China. The United States would not accept the participation of Iran and North Korea and these initiatives have lapsed.

Another, more recent approach, centers on 'capping' the production of fissile material for weapons purposes, which would hopefully be followed by 'roll back'. To this end, India and the United States jointly sponsored a UN General Assembly resolution in 1993 calling for negotiations for a 'cut-off' convention. Should India and Pakistan join such a convention, they would have to agree to halt the production of fissile materials for weapons and to accept international verification on their relevant nuclear facilities (enrichment and reprocessing plants). It appears that India is now prepared to join negotiations regarding such a Cut-off Treaty, under the UN Conference on Disarmament.

Bilateral confidence-building measures between India and Pakistan to reduce the prospects of confrontation have been limited. In 1990 each side ratified a treaty not to attack the other's nuclear installations, and at the end of 1991 they provided one another with a list showing the location of all their nuclear plants, even though the respective lists were regarded as not being wholly accurate. Early in 1994 India proposed a bilateral agreement for a 'no first use' of nuclear weapons and an extension of the 'no attack' treaty to cover civilian and industrial targets as well as nuclear installations.

Having promoted the Comprehensive Test Ban Treaty since 1954, India dropped its support in 1995 and in 1996 attempted to block the Treaty. Following the 1998 tests the question has been reopened and both Pakistan and India have indicated their intention to sign the CTBT. Indian ratification may be conditional upon the five weapons states agreeing to specific reductions in nuclear arsenals. The UN Conference on Disarmament has also called upon both countries "to accede without delay to the Non-Proliferation Treaty", presumably as non-weapons states.

In 2004 and 2005, Egypt disclosed past undeclared nuclear activities and material to the IAEA. In 2007 and 2008, high enriched and low enriched uranium particles were found in environmental samples taken in Egypt. In 2008, the IAEA states Egypt's statements were consistent with its own findings. In May 2009, "Reuters" reported that the IAEA was conducting further investigation in Egypt.

In 2003, the IAEA reported that Iran had been in breach of its obligations to comply with provisions of its safeguard agreement. In 2005, the IAEA Board of Governors voted in a rare non-consensus decision to find Iran in non-compliance with its NPT Safeguards Agreement and to report that non-compliance to the UN Security Council. In response, the UN Security Council passed a series of resolutions citing concerns about the program. Iran's representative to the UN argues sanctions compel Iran to abandon its rights under the Nuclear Nonproliferation Treaty to peaceful nuclear technology. Iran says its uranium enrichment program is exclusively for peaceful purposes and has enriched uranium to "less than 5 percent," consistent with fuel for a nuclear power plant and significantly below the purity of WEU (around 90%) typically used in a weapons program. The director general of the International Atomic Energy Agency, Yukiya Amano, said in 2009 he had not seen any evidence in IAEA official documents that Iran was developing nuclear weapons.

Up to the late 1980s it was generally assumed that any undeclared nuclear activities would have to be based on the diversion of nuclear material from safeguards. States acknowledged the possibility of nuclear activities entirely separate from those covered by safeguards, but it was assumed they would be detected by national intelligence activities. There was no particular effort by IAEA to attempt to detect them.

Iraq had been making efforts to secure a nuclear potential since the 1960s. In the late 1970s a specialised plant, Osiraq, was constructed near Baghdad. The plant was attacked during the Iran–Iraq War and was destroyed by Israeli bombers in June 1981.

Not until the 1990 NPT Review Conference did some states raise the possibility of making more use of (for example) provisions for "special inspections" in existing NPT Safeguards Agreements. Special inspections can be undertaken at locations other than those where safeguards routinely apply, if there is reason to believe there may be undeclared material or activities.

After inspections in Iraq following the UN Gulf War cease-fire resolution showed the extent of Iraq's clandestine nuclear weapons program, it became clear that the IAEA would have to broaden the scope of its activities. Iraq was an NPT Party, and had thus agreed to place all its nuclear material under IAEA safeguards. But the inspections revealed that it had been pursuing an extensive clandestine uranium enrichment programme, as well as a nuclear weapons design programme.

The main thrust of Iraq's uranium enrichment program was the development of technology for electromagnetic isotope separation (EMIS) of indigenous uranium. This uses the same principles as a mass spectrometer (albeit on a much larger scale). Ions of uranium-238 and uranium-235 are separated because they describe arcs of different radii when they move through a magnetic field. This process was used in the Manhattan Project to make the highly enriched uranium used in the Hiroshima bomb, but was abandoned soon afterwards.

The Iraqis did the basic research work at their nuclear research establishment at Tuwaitha, near Baghdad, and were building two full-scale facilities at Tarmiya and Ash Sharqat, north of Baghdad. However, when the war broke out, only a few separators had been installed at Tarmiya, and none at Ash Sharqat.

The Iraqis were also very interested in centrifuge enrichment, and had been able to acquire some components including some carbon-fibre rotors, which they were at an early stage of testing. In May 1998, "Newsweek" reported that Abdul Qadeer Khan had sent Iraq centrifuge designs, which were apparently confiscated by the UNMOVIC officials. Iraqi officials said "the documents were authentic but that they had not agreed to work with A. Q. Khan, fearing an ISI sting operation, due to strained relations between two countries. The Government of Pakistan and A. Q. Khan strongly denied this allegation whilst the government declared the evidence to be "fraudulent".

They were clearly in violation of their NPT and safeguards obligations, and the IAEA Board of Governors ruled to that effect. The UN Security Council then ordered the IAEA to remove, destroy or render harmless Iraq's nuclear weapons capability. This was done by mid-1998, but Iraq then ceased all cooperation with the UN, so the IAEA withdrew from this work.

The revelations from Iraq provided the impetus for a very far-reaching reconsideration of what safeguards are intended to achieve.

Libya possesses ballistic missiles and previously pursued nuclear weapons under the leadership of Muammar Gaddafi. On 19 December 2003, Gaddafi announced that Libya would voluntarily eliminate all materials, equipment and programs that could lead to internationally proscribed weapons, including weapons of mass destruction and long-range ballistic missiles. Libya signed the Nuclear Non-Proliferation Treaty (NPT) in 1968 and ratified it in 1975, and concluded a safeguards agreement with the International Atomic Energy Agency (IAEA) in 1980. In March 2004, the IAEA Board of Governors welcomed Libya's decision to eliminate its formerly undeclared nuclear program, which it found had violated Libya's safeguards agreement, and approved Libya's Additional Protocol. The United States and the United Kingdom assisted Libya in removing equipment and material from its nuclear weapons program, with independent verification by the IAEA.

A report in the "Sydney Morning Herald" and "Searchina", a Japanese newspaper, report that two Myanma defectors saying that the Myanmar junta was secretly building a nuclear reactor and plutonium extraction facility with North Korea's help, with the aim of acquiring its first nuclear bomb in five years. According to the report, "The secret complex, much of it in caves tunnelled into a mountain at Naung Laing in northern Burma, runs parallel to a civilian reactor being built at another site by Russia that both the Russians and Burmese say will be put under international safeguards." In 2002, Myanmar had notified IAEA of its intention to pursue a civilian nuclear programme. Later, Russia announced that it would build a nuclear reactor in Myanmar. There have also been reports that two Pakistani scientists, from the AQ Khan stable, had been dispatched to Myanmar where they had settled down, to help Myanmar's project. Recently, the David Albright-led Institute for Science and International Security (ISIS) rang alarm bells about Myanmar attempting a nuclear project with North Korean help. If true, the full weight of international pressure will be brought against Myanmar, said officials familiar with developments. But equally, the information that has been peddled by the defectors is also "preliminary" and could be used by the west to turn the screws on Myanmar—on democracy and human rights issues—in the run-up to the elections in the country in 2010. During an ASEAN meeting in Thailand in July 2009, US secretary of state Hillary Clinton highlighted concerns of the North Korean link. "We know there are also growing concerns about military cooperation between North Korea and Burma which we take very seriously," Clinton said. However, in 2012, after contact with the American president, Barack Obama, the Burmese leader, Thein Sein, renounced military ties with DPRK (North Korea).

The Democratic People's Republic of Korea (DPRK) acceded to the NPT in 1985 as a condition for the supply of a nuclear power station by the USSR. However, it delayed concluding its NPT Safeguards Agreement with the IAEA, a process which should take only 18 months, until April 1992.

During that period, it brought into operation a small gas-cooled, graphite-moderated, natural-uranium (metal) fuelled "Experimental Power Reactor" of about 25 MWt (5 MWe), based on the UK Magnox design. While this was a well-suited design to start a wholly indigenous nuclear reactor development, it also exhibited all the features of a small plutonium production reactor for weapons purposes. North Korea also made substantial progress in the construction of two larger reactors designed on the same principles, a prototype of about 200 MWt (50 MWe), and a full-scale version of about 800 MWt (200 MWe). They made only slow progress; construction halted on both in 1994 and has not resumed. Both reactors have degraded considerably since that time and would take significant efforts to refurbish.

In addition it completed and commissioned a reprocessing plant that makes the Magnox spent nuclear fuel safe, recovering uranium and plutonium. That plutonium, if the fuel was only irradiated to a very low burn-up, would have been in a form very suitable for weapons. Although all these facilities at Yongbyon were to be under safeguards, there was always the risk that at some stage, the DPRK would withdraw from the NPT and use the plutonium for weapons.

One of the first steps in applying NPT safeguards is for the IAEA to verify the initial stocks of uranium and plutonium to ensure that all the nuclear materials in the country have been declared for safeguards purposes. While undertaking this work in 1992, IAEA inspectors found discrepancies which indicated that the reprocessing plant had been used more often than the DPRK had declared, which suggested that the DPRK could have weapons-grade plutonium which it had not declared to the IAEA. Information passed to the IAEA by a Member State (as required by the IAEA) supported that suggestion by indicating that the DPRK had two undeclared waste or other storage sites.

In February 1993 the IAEA called on the DPRK to allow special inspections of the two sites so that the initial stocks of nuclear material could be verified. The DPRK refused, and on 12 March announced its intention to withdraw from the NPT (three months' notice is required). In April 1993 the IAEA Board concluded that the DPRK was in non-compliance with its safeguards obligations and reported the matter to the UN Security Council. In June 1993 the DPRK announced that it had "suspended" its withdrawal from the NPT, but subsequently claimed a "special status" with respect to its safeguards obligations. This was rejected by IAEA.

Once the DPRK's non-compliance had been reported to the UN Security Council, the essential part of the IAEA's mission had been completed. Inspections in the DPRK continued, although inspectors were increasingly hampered in what they were permitted to do by the DPRK's claim of a "special status". However, some 8,000 corroding fuel rods associated with the experimental reactor have remained under close surveillance.

Following bilateral negotiations between the United States and the DPRK, and the conclusion of the Agreed Framework in October 1994, the IAEA has been given additional responsibilities. The agreement requires a freeze on the operation and construction of the DPRK's plutonium production reactors and their related facilities, and the IAEA is responsible for monitoring the freeze until the facilities are eventually dismantled. The DPRK remains uncooperative with the IAEA verification work and has yet to comply with its safeguards agreement.

While Iraq was defeated in a war, allowing the UN the opportunity to seek out and destroy its nuclear weapons programme as part of the cease-fire conditions, the DPRK was not defeated, nor was it vulnerable to other measures, such as trade sanctions. It can scarcely afford to import anything, and sanctions on vital commodities, such as oil, would either be ineffective or risk provoking war.

Ultimately, the DPRK was persuaded to stop what appeared to be its nuclear weapons programme in exchange, under the agreed framework, for about US$5 billion in energy-related assistance. This included two 1000 MWe light water nuclear power reactors based on an advanced U.S. System-80 design.

In January 2003 the DPRK withdrew from the NPT. In response, a series of discussions among the DPRK, the United States, and China, a series of six-party talks (the parties being the DPRK, the ROK, China, Japan, the United States and Russia) were held in Beijing; the first beginning in April 2004 concerning North Korea's weapons program.

On 10 January 2005, North Korea declared that it was in the possession of nuclear weapons. On 19 September 2005, the fourth round of the Six-Party Talks ended with a joint statement in which North Korea agreed to end its nuclear programs and return to the NPT in exchange for diplomatic, energy and economic assistance. However, by the end of 2005 the DPRK had halted all six-party talks because the United States froze certain DPRK international financial assets such as those in a bank in Macau.

On 9 October 2006, North Korea announced that it has performed its first-ever nuclear weapon test. On 18 December 2006, the six-party talks finally resumed. On 13 February 2007, the parties announced "Initial Actions" to implement the 2005 joint statement including shutdown and disablement of North Korean nuclear facilities in exchange for energy assistance. Reacting to UN sanctions imposed after missile tests in April 2009, North Korea withdrew from the six-party talks, restarted its nuclear facilities and conducted a second nuclear test on 25 May 2009.

On 12 February 2013, North Korea conducted an underground nuclear explosion with an estimated yield of 6 to 7 kilotonnes. The detonation registered a magnitude 4.9 disturbance in the area around the epicenter.

"See also: North Korea and weapons of mass destruction and Six-party talks"

Security of nuclear weapons in Russia remains a matter of concern. According to high-ranking Russian SVR defector Tretyakov, he had a meeting with two Russian businessman representing a state-created "C-W" corporation in 1991. They came up with a project of destroying large quantities of chemical wastes collected from Western countries at the island of Novaya Zemlya (a test place for Soviet nuclear weapons) using an underground nuclear blast. The project was rejected by Canadian representatives, but one of the businessmen told Tretyakov that he keeps his own nuclear bomb at his dacha outside Moscow. Tretyakov thought that man was insane, but the "businessmen" (Vladimir K. Dmitriev) replied: "Do not be so naive. With economic conditions the way they are in Russia today, anyone with enough money can buy a nuclear bomb. It's no big deal really".

In 1991, South Africa acceded to the NPT, concluded a comprehensive safeguards agreement with the IAEA, and submitted a report on its nuclear material subject to safeguards. At the time, the state had a nuclear power programme producing nearly 10% of the country's electricity, whereas Iraq and North Korea only had research reactors.

The IAEA's initial verification task was complicated by South Africa's announcement that between 1979 and 1989 it built and then dismantled a number of nuclear weapons. South Africa asked the IAEA to verify the conclusion of its weapons programme. In 1995 the IAEA declared that it was satisfied all materials were accounted for and the weapons programme had been terminated and dismantled.

South Africa has signed the NPT, and now holds the distinction of being the only known state to have indigenously produced nuclear weapons, and then verifiably dismantled them.

On 6 September 2007, Israel bombed an officially unidentified site in Syria which it later asserted was a nuclear reactor under construction ("see Operation Outside the Box"). The alleged reactor was not asserted to be operational and it was not asserted that nuclear material had been introduced into it. Syria said the site was a military site and was not involved in any nuclear activities. The IAEA requested Syria to provide further access to the site and any other locations where the debris and equipment from the building had been stored. Syria denounced what it called the Western "fabrication and forging of facts" in regards to the incident. IAEA Director General Mohamed ElBaradei criticized the strikes and deplored that information regarding the matter had not been shared with his agency earlier.

For a state that does not possess nuclear weapons, the capability to produce one or more weapons quickly and with little warning is called a breakout capability.


There has been much debate in the academic study of International Security as to the advisability of proliferation. In the late 1950s and early 1960s, Gen. Pierre Marie Gallois of France, an adviser to Charles DeGaulle, argued in books like "The Balance of Terror: Strategy for the Nuclear Age" (1961) that mere possession of a nuclear arsenal, what the French called the "force de frappe", was enough to ensure deterrence, and thus concluded that the spread of nuclear weapons could increase international stability.

Some very prominent neo-realist scholars, such as Kenneth Waltz, Emeritus Professor of Political Science at UC Berkeley and Adjunct Senior Research Scholar at Columbia University, and John Mearsheimer, R. Wendell Harrison Distinguished Service Professor of Political Science at the University of Chicago, continue to argue along the lines of Gallois in a separate development. Specifically, these scholars advocate some forms of nuclear proliferation, arguing that it will decrease the likelihood of war, especially in troubled regions of the world. Aside from the majority opinion which opposes proliferation in any form, there are two schools of thought on the matter: those, like Mearsheimer, who favor selective proliferation, and those such as Waltz, who advocate a laissez-faire attitude to programs like North Korea's.

In embryo, Waltz argues that the logic of mutually assured destruction (MAD) should work in all security environments, regardless of historical tensions or recent hostility. He sees the Cold War as the ultimate proof of MAD logicthe only occasion when enmity between two Great Powers did not result in military conflict. This was, he argues, because nuclear weapons promote caution in decision-makers. Neither Washington nor Moscow would risk a nuclear apocalypse to advance territorial or power goals, hence a peaceful stalemate ensued (Waltz and Sagan (2003), p. 24). Waltz believes there to be no reason why this effect would not occur in all circumstances.

John Mearsheimer would not support Waltz's optimism in the majority of potential instances; however, he has argued for nuclear proliferation as policy in certain places, such as post–Cold War Europe. In two famous articles, Professor Mearsheimer opines that Europe is bound to return to its pre–Cold War environment of regular conflagration and suspicion at some point in the future. He advocates arming both Germany and Ukraine with nuclear weaponry in order to achieve a balance of power between these states in the east and France/UK in the west. If this does not occur, he is certain that war will eventually break out on the European continent.

Another separate argument against Waltz's open proliferation and in favor of Mearsheimer's selective distribution is the possibility of nuclear terrorism. Some countries included in the aforementioned laissez-faire distribution could predispose the transfer of nuclear materials or a bomb falling into the hands of groups not affiliated with any governments. Such countries would not have the political will or ability to safeguard attempts at devices being transferred to a third party. Not being deterred by self-annihilation, terrorism groups could push forth their own nuclear agendas or be used as shadow fronts to carry out the attack plans by mentioned unstable governments.

There are numerous arguments presented against both selective and total proliferation, generally targeting the very neorealist assumptions (such as the primacy of military security in state agendas, the weakness of international institutions, and the long-run unimportance of economic integration and globalization to state strategy) its proponents tend to make. With respect to Mearsheimer's specific example of Europe, many economists and neoliberals argue that the economic integration of Europe through the development of the European Union has made war in most of the European continent so disastrous economically so as to serve as an effective deterrent. Constructivists take this one step further, frequently arguing that the development of EU political institutions has led or will lead to the development of a nascent European identity, which most states on the European continent wish to partake in to some degree or another, and which makes all states within or aspiring to be within the EU regard war between them as unthinkable.

As for Waltz, the general opinion is that most states are not in a position to safely guard against nuclear use, that he underestimates the long-standing antipathy in many regions, and that weak states will be unable to prevent – or will actively provide for – the disastrous possibility of nuclear terrorism. Waltz has dealt with all of these objections at some point in his work; though to many, he has not adequately responded (Betts (2000)).

The Learning Channel documentary Doomsday: "On The Brink" illustrated 40 years of U.S. and Soviet nuclear weapons accidents. Even the 1995 Norwegian rocket incident demonstrated a potential scenario in which Russian democratization and military downsizing at the end of the Cold War did not eliminate the danger of accidental nuclear war through command and control errors. After asking: might a future Russian ruler or renegade Russian general be tempted to use nuclear weapons to make foreign policy? The documentary writers revealed a greater danger of Russian security over its nuclear stocks, but especially the ultimate danger of human nature to want the ultimate weapon of mass destruction to exercise political and military power. Future world leaders might not understand how close the Soviets, Russians, and Americans were to doomsday, how easy it all seemed because apocalypse was avoided for a mere 40 years between rivals, politicians not terrorists, who loved their children and did not want to die, against 30,000 years of human prehistory. History and military experts agree that proliferation can be slowed, but never stopped (technology cannot be uninvented).

Proliferation begets proliferation is a concept described by Scott Sagan in his article, "Why Do States Build Nuclear Weapons?". This concept can be described as a strategic chain reaction. If one state produces a nuclear weapon it creates almost a domino effect within the region. States in the region will seek to acquire nuclear weapons to balance or eliminate the security threat. Sagan describes this reaction best in his article when he states, “Every time one state develops nuclear weapons to balance against its main rival, it also creates a nuclear threat to another region, which then has to initiate its own nuclear weapons program to maintain its national security”. Going back through history we can see how this has taken place. When the United States demonstrated that it had nuclear power capabilities after the bombing of Hiroshima and Nagasaki, the Russians started to develop their program in preparation for the Cold War. With the Russian military buildup, France and the United Kingdom perceived this as a security threat and therefore they pursued nuclear weapons (Sagan, pg 71). Even though proliferation causes proliferation, this does not guarantee that other states will successfully develop nuclear weapons because the economic stability of a state plays an important role on whether the state will successfully be able to acquire nuclear weapons. The article written by Dong-Jong Joo and Erik Gartzke discusses how the economy of a country determines whether they will successfully acquire nuclear weapons.

Former Iranian President Mahmoud Ahmadinejad has been a frequent critic of the concept of "nuclear apartheid" as it has been put into practice by several countries, particularly the United States. In an interview with CNN's Christiane Amanpour, Ahmadinejad said that Iran was "against 'nuclear apartheid,' which means some have the right to possess it, use the fuel, and then sell it to another country for 10 times its value. We're against that. We say clean energy is the right of all countries. But also it is the duty and the responsibility of all countries, including ours, to set up frameworks to stop the proliferation of it." Hours after that interview, he spoke passionately in favor of Iran's right to develop nuclear technology, claiming the nation should have the same liberties.

Iran is a signatory of the Nuclear Non-Proliferation Treaty and claims that any work done in regards to nuclear technology is related only to civilian uses, which is acceptable under the treaty. Iran violated its safeguards obligations under the treaty by performing uranium-enrichment in secret, after which the United Nations Security Council ordered Iran to suspend all uranium-enrichment until July 2015.

India has also been discussed in the context of "nuclear apartheid". India has consistently attempted to pass measures that would call for full international disarmament, however they have not succeeded due to protests from those states that already have nuclear weapons. In light of this, India viewed nuclear weapons as a necessary right for all nations as long as certain states were still in possession of nuclear weapons. India stated that nuclear issues were directly related to national security.

Years before India's first underground nuclear test in 1998, the Comprehensive Nuclear-Test-Ban Treaty was passed. Some have argued that coercive language was used in an attempt to persuade India to sign the treaty, which was pushed for heavily by neighboring China. India viewed the treaty as a means for countries that already had nuclear weapons, primarily the five nations of the United Nations Security Council, to keep their weapons while ensuring that no other nations could develop them.

In their article, "The Correlates of Nuclear Proliferation," Sonali Singh and Christopher R. Way argue that states protected by a security guarantee from a great power, particularly if backed by the "nuclear umbrella" of extended deterrence, have less of an incentive to acquire their own nuclear weapons. States that lack such guarantees are more likely to feel their security threatened and so have greater incentives to bolster or assemble nuclear arsenals. As a result, it is then argued that bipolarity may prevent proliferation where as multipolarity may actually influence proliferation.



</doc>
<doc id="22159" url="https://en.wikipedia.org/wiki?curid=22159" title="NPT">
NPT

NPT may refer to:








</doc>
<doc id="22161" url="https://en.wikipedia.org/wiki?curid=22161" title="Nuclear energy">
Nuclear energy

Nuclear energy may refer to:


</doc>
<doc id="22164" url="https://en.wikipedia.org/wiki?curid=22164" title="Netlist">
Netlist

In electronic design, a netlist is a description of the connectivity of an electronic circuit. In its simplest form, a netlist consists of a list of the electronic components in a circuit and a list of the nodes they are connected to. A network (net) is a collection of two or more interconnected components. 

The structure, complexity and representation of netlists can vary considerably, but the fundamental purpose of every netlist is to convey connectivity information. Netlists usually provide nothing more than instances, nodes, and perhaps some attributes of the components involved. If they express much more than this, they are usually considered to be a hardware description language such as Verilog or VHDL, or one of several languages specifically designed for input to simulators.

Netlists can be "physical" or "logical", "instance-based" or "net-based", and "flat" or "hierarchical". The latter can be either "folded" or "unfolded".

Most netlists either contain or refer to descriptions of the parts or devices used.
Each time a part is used in a netlist, this is called an "instance".

These descriptions will usually list the connections that are made to that kind of device, and some basic properties of that device.
These connection points are called "terminals" or "pins", among several other names.

An "instance" could be anything from a MOSFET transistor or a bipolar transistor, to a resistor, capacitor, or integrated circuit chip.

Instances have "terminals". In the case of a vacuum cleaner, these terminals would be the three metal prongs in the plug. Each terminal has a name, and in continuing the vacuum cleaner example, they might be "Neutral", "Live" and "Ground". Usually, each instance will have a unique name, so that if you have two instances of vacuum cleaners, one might be "vac1" and the other "vac2". Besides their names, they might otherwise be identical.

Networks (nets) are the "wires" that connect things together in the circuit. There may or may not be any special attributes associated with the nets in a design, depending on the particular language the netlist is written in, and that language's features.

Instance based netlists usually provide a list of the instances used in a design.
Along with each instance, either an ordered list of net names is provided, or a list of pairs provided, of an instance port name, along with the net name to which that port is connected.
In this kind of description, the list of nets can be gathered from the connection lists, and there is no place to associate particular attributes with the nets themselves.
SPICE is an example of instance-based netlists.

Net-based netlists usually describe all the instances and their attributes, then describe each net, and say which port they are connected on each instance.
This allows for attributes to be associated with nets.
EDIF is probably the most famous of the net-based netlists.

In large designs, it is a common practice to split the design into pieces, each piece becoming a "definition" which can be used as instances in the design. In the vacuum cleaner analogy, one might have a vacuum cleaner definition with its ports, but now this definition would also include a full description of the machine's internal components and how they connect (motors, switches, etc.), like a wiring diagram does. 

A definition which includes no instances is called a "primitive" (or a "leaf", or other names); whereas a definition which includes instances is "hierarchical".

A "folded" hierarchy allows a single definition to be represented several times by instances. An "unfolded" hierarchy does not allow a definition to be used more than once in the hierarchy. 

Folded hierarchies can be extremely compact. A small netlist of just a few instances can describe designs with a very large number of instances. For example, suppose definition A is a simple primitive, like a memory cell. Then suppose definition B contains 32 instances of A; C contains 32 instances of B; D contains 32 instances of C; and E contains 32 instances of D. The design now contains 5 definitions (A through E) and 128 instances. Yet, E describes a circuit that contains over a million memory cells.

In a "flat" design, only primitives are instanced. Hierarchical designs can be recursively "exploded" ("flattened") by creating a new copy (with a new name) of each definition each time it is used. If the design is highly folded, expanding it like this will result in a much larger netlist database, but preserves the hierarchy dependencies. Given a hierarchical netlist, the list of instance names in a path from the root definition to a primitive instance specifies the single unique path to that primitive. The paths to every primitive, taken together, comprise a large but flat netlist that is exactly equivalent to the compact hierarchical version.

Backannotation is data that could be added to a hierarchical netlist. Usually they are kept separate from the netlist, because several such alternate sets of data could be applied to a single netlist. These data may have been extracted from a physical design, and might provide extra information for more accurate simulations. Usually the data are composed of a hierarchical path and a piece of data for that primitive or finding the values of RC delay due to interconnection.

Another concept often used in netlists is that of inheritance. Suppose a definition of a capacitor has an associated attribute called "Capacitance", corresponding to the physical property of the same name, with a default value of "100 pF" (100 picofarads). Each instance of this capacitor might also have such an attribute, only with a different value of capacitance. And other instances might not associate any capacitance at all. In the case where no capacitance is specified for an instance, the instance will "inherit" the 100 pF value from its definition. A value specified will "override" the value on the definition. If a great number of attributes end up being the same as on the definition, a great amount of information can be "inherited", and not have to be redundantly specified in the netlist, saving space, and making the design easier to read by both machines and people.


</doc>
<doc id="22165" url="https://en.wikipedia.org/wiki?curid=22165" title="Nuclear disarmament">
Nuclear disarmament

Nuclear disarmament is the act of reducing or eliminating nuclear weapons. It can also be the end state of a nuclear-weapons-free world, in which nuclear weapons are completely eliminated. The term denuclearization is also used to describe the process leading to complete nuclear disarmament.

Nuclear disarmament groups include the Campaign for Nuclear Disarmament, Peace Action, Greenpeace, Soka Gakkai International, International Physicians for the Prevention of Nuclear War, Mayors for Peace, Global Zero, the International Campaign to Abolish Nuclear Weapons, and the Nuclear Age Peace Foundation. There have been many large anti-nuclear demonstrations and protests. On June 12, 1982, one million people demonstrated in New York City's Central Park against nuclear weapons and for an end to the cold war arms race. It was the largest anti-nuclear protest and the largest political demonstration in American history.

In recent years, some U.S. elder statesmen have also advocated nuclear disarmament. Sam Nunn, William Perry, Henry Kissinger, and George Shultz have called upon governments to embrace the vision of a world free of nuclear weapons, and in various op-ed columns have proposed an ambitious program of urgent steps to that end. The four have created the Nuclear Security Project to advance this agenda. Organisations such as Global Zero, an international non-partisan group of 300 world leaders dedicated to achieving nuclear disarmament, have also been established.

Proponents of nuclear disarmament say that it would lessen the probability of nuclear war occurring, especially accidentally. Critics of nuclear disarmament say that it would undermine deterrence.

In 1945 in the New Mexico desert, American scientists conducted "Trinity," the first nuclear weapons test, marking the beginning of the atomic age. Even before the Trinity test, national leaders debated the impact of nuclear weapons on domestic and foreign policy. Also involved in the debate about nuclear weapons policy was the scientific community, through professional associations such as the Federation of Atomic Scientists and the Pugwash Conference on Science and World Affairs.

On August 6, 1945, towards the end of World War II, the "Little Boy" device was detonated over the Japanese city of Hiroshima. Exploding with a yield equivalent to 12,500 tonnes of TNT, the blast and thermal wave of the bomb destroyed nearly 50,000 buildings (including the headquarters of the 2nd General Army and Fifth Division) and killed 70,000–80,000 people outright, with total deaths being around 90,000–146,000. Detonation of the "Fat Man" device exploded over the Japanese city of Nagasaki three days later on 9 August 1945, destroying 60% of the city and killing 35,000–40,000 people outright, though up to 40,000 additional deaths may have occurred over some time after that. Subsequently, the world’s nuclear weapons stockpiles grew.

Operation Crossroads was a series of nuclear weapon tests conducted by the United States at Bikini Atoll in the Pacific Ocean in the summer of 1946. Its purpose was to test the effect of nuclear weapons on naval ships. Pressure to cancel Operation Crossroads came from scientists and diplomats. Manhattan Project scientists argued that further nuclear testing was unnecessary and environmentally dangerous. A Los Alamos study warned "the water near a recent surface explosion will be a 'witch's brew' of radioactivity". To prepare the atoll for the nuclear tests, Bikini's native residents were evicted from their homes and resettled on smaller, uninhabited islands where they were unable to sustain themselves.

Radioactive fallout from nuclear weapons testing was first drawn to public attention in 1954 when a hydrogen bomb test in the Pacific contaminated the crew of the Japanese fishing boat "Lucky Dragon". One of the fishermen died in Japan seven months later. The incident caused widespread concern around the world and "provided a decisive impetus for the emergence of the anti-nuclear weapons movement in many countries". The anti-nuclear weapons movement grew rapidly because for many people the atomic bomb "encapsulated the very worst direction in which society was moving".

Peace movements emerged in Japan and in 1954 they converged to form a unified "Japanese Council Against Atomic and Hydrogen Bombs". Japanese opposition to the Pacific nuclear weapons tests was widespread, and "an estimated 35 million signatures were collected on petitions calling for bans on nuclear weapons". In the United Kingdom, the first Aldermaston March organised by the Direct Action Committee and supported by the Campaign for Nuclear Disarmament took place on Easter 1958, when several thousand people marched for four days from Trafalgar Square, London, to the Atomic Weapons Research Establishment close to Aldermaston in Berkshire, England, to demonstrate their opposition to nuclear weapons. CND organised Aldermaston marches into the late 1960s when tens of thousands of people took part in the four-day events.

On November 1, 1961, at the height of the Cold War, about 50,000 women brought together by Women Strike for Peace marched in 60 cities in the United States to demonstrate against nuclear weapons. It was the largest national women's peace protest of the 20th century.

In 1958, Linus Pauling and his wife presented the United Nations with the petition signed by more than 11,000 scientists calling for an end to nuclear-weapon testing. The "Baby Tooth Survey," headed by Dr Louise Reiss, demonstrated conclusively in 1961 that above-ground nuclear testing posed significant public health risks in the form of radioactive fallout spread primarily via milk from cows that had ingested contaminated grass. Public pressure and the research results subsequently led to a moratorium on above-ground nuclear weapons testing, followed by the Partial Test Ban Treaty, signed in 1963 by John F. Kennedy and Nikita Khrushchev. On the day that the treaty went into force, the Nobel Prize Committee awarded Pauling the Nobel Peace Prize, describing him as "Linus Carl Pauling, who ever since 1946 has campaigned ceaselessly, not only against nuclear weapons tests, not only against the spread of these armaments, not only against their very use, but against all warfare as a means of solving international conflicts." Pauling started the International League of Humanists in 1974. He was president of the scientific advisory board of the World Union for Protection of Life and also one of the signatories of the Dubrovnik-Philadelphia Statement.

In the 1980s, a movement for nuclear disarmament again gained strength in the light of the weapons build-up and statements of US President Ronald Reagan. Reagan had "a world free of nuclear weapons" as his personal mission, and was largely scorned for this in Europe. Reagan was able to start discussions on nuclear disarmament with Soviet Union. He changed the name "SALT" (Strategic Arms Limitation Talks) to "START" (Strategic Arms Reduction Talks).

On June 3, 1981, William Thomas launched the White House Peace Vigil in Washington, D.C.. He was later joined on the vigil by anti-nuclear activists Concepcion Picciotto and Ellen Benjamin.

On June 12, 1982, one million people demonstrated in New York City's Central Park against nuclear weapons and for an end to the cold war arms race. It was the largest anti-nuclear protest and the largest political demonstration in American history. International Day of Nuclear Disarmament protests were held on June 20, 1983 at 50 sites across the United States. In 1986, hundreds of people walked from Los Angeles to Washington, D.C. in the Great Peace March for Global Nuclear Disarmament. There were many Nevada Desert Experience protests and peace camps at the Nevada Test Site during the 1980s and 1990s.

On May 1, 2005, 40,000 anti-nuclear/anti-war protesters marched past the United Nations in New York, 60 years after the atomic bombings of Hiroshima and Nagasaki. In 2008, 2009, and 2010, there have been protests about, and campaigns against, several new nuclear reactor proposals in the United States.

There is an annual protest against U.S. nuclear weapons research at Lawrence Livermore National Laboratory in California and in the 2007 protest, 64 people were arrested. There have been a series of protests at the Nevada Test Site and in the April 2007 Nevada Desert Experience protest, 39 people were cited by police. There have been anti-nuclear protests at Naval Base Kitsap for many years, and several in 2008.

In 2017, the International Campaign to Abolish Nuclear Weapons was awarded the Nobel Peace Prize "for its work to draw attention to the catastrophic humanitarian consequences of any use of nuclear weapons and for its ground-breaking efforts to achieve a treaty-based prohibition of such weapons".

One of the earliest peace organisations to emerge after the Second World War was the World Peace Council, which was directed by the Communist Party of the Soviet Union through the Soviet Peace Committee. Its origins lay in the Communist Information Bureau's (Cominform) doctrine, put forward 1947, that the world was divided between peace-loving progressive forces led by the Soviet Union and warmongering capitalist countries led by the United States. In 1949, Cominform directed that peace "should now become the pivot of the entire activity of the Communist Parties", and most western Communist parties followed this policy. Lawrence Wittner, a historian of the post-war peace movement, argues that the Soviet Union devoted great efforts to the promotion of the WPC in the early post-war years because it feared an American attack and American superiority of arms at a time when the USA possessed the atom bomb but the Soviet Union had not yet developed it.

In 1950, the WPC launched its Stockholm Appeal calling for the absolute prohibition of nuclear weapons. The campaign won support, collecting, it is said, 560 million signatures in Europe, most from socialist countries, including 10 million in France (including that of the young Jacques Chirac), and 155 million signatures in the Soviet Union – the entire adult population. Several non-aligned peace groups who had distanced themselves from the WPC advised their supporters not to sign the Appeal.

The WPC had uneasy relations with the non-aligned peace movement and has been described as being caught in contradictions as "it sought to become a broad world movement while being instrumentalized increasingly to serve foreign policy in the Soviet Union and nominally socialist countries." From the 1950s until the late 1980s it tried to use non-aligned peace organizations to spread the Soviet point of view. At first there was limited co-operation between such groups and the WPC, but western delegates who tried to criticize the Soviet Union or the WPC's silence about Russian armaments were often shouted down at WPC conferences and by the early 1960s they had dissociated themselves from the WPC.

After the 1986 Reykjavik Summit between U.S. President Ronald Reagan and the new Soviet General Secretary Mikhail Gorbachev, the United States and the Soviet Union concluded two important nuclear arms reduction treaties: the INF Treaty (1987) and START I (1991). After the end of the Cold War, the United States and the Russian Federation concluded the Strategic Offensive Reductions Treaty (2003) and the New START Treaty (2010).

When the extreme danger intrinsic to nuclear war and the possession of nuclear weapons became apparent to all sides during the Cold War, a series of disarmament and nonproliferation treaties were agreed upon between the United States, the Soviet Union, and several other states throughout the world. Many of these treaties involved years of negotiations, and seemed to result in important steps in arms reductions and reducing the risk of nuclear war.

Key treaties
Only one country has been known to ever dismantle their nuclear arsenal completely—the apartheid government of South Africa apparently developed half a dozen crude fission weapons during the 1980s, but they were dismantled in the early 1990s.

In its landmark resolution 1653 of 1961, "Declaration on the prohibition of the use of nuclear and thermo-nuclear weapons," the UN General Assembly stated that use of nuclear weaponry “would exceed even the scope of war and cause indiscriminate suffering and destruction to mankind and civilization and, as such, is contrary to the rules of international law and to the laws of humanity”.

The UN Office for Disarmament Affairs (UNODA) is a department of the United Nations Secretariat established in January 1998 as part of the United Nations Secretary-General Kofi Annan's plan to reform the UN as presented in his report to the General Assembly in July 1997.

Its goal is to promote nuclear disarmament and non-proliferation and the strengthening of the disarmament regimes in respect to other weapons of mass destruction, chemical and biological weapons. It also promotes disarmament efforts in the area of conventional weapons, especially land mines and small arms, which are often the weapons of choice in contemporary conflicts.

Following the retirement of Sergio Duarte in February 2012, Angela Kane was appointed as the new High Representative for Disarmament Affairs.

On 7 July 2017, a UN conference adopted the Treaty on the Prohibition of Nuclear Weapons with the backing of 122 states. It opened for signature on 20 September 2017.

Despite a general trend toward disarmament in the early 2000s, the George W. Bush administration repeatedly pushed to fund policies that would allegedly make nuclear weapons more usable in the post–Cold War environment. To date the U.S. Congress has refused to fund many of these policies. However, some feel that even considering such programs harms the credibility of the United States as a proponent of nonproliferation.


Former U.S. officials Henry Kissinger, George Shultz, Bill Perry, and Sam Nunn (aka 'The Gang of Four' on Nuclear Deterrence)." proposed in January 2007 that the United States rededicate itself to the goal of eliminating nuclear weapons, concluding: "We endorse setting the goal of a world free of nuclear weapons and working energetically on the actions required to achieve that goal." Arguing a year later that "with nuclear weapons more widely available, deterrence is decreasingly effective and increasingly hazardous," the authors concluded that although "it is tempting and easy to say we can't get there from here, [...] we must chart a course” toward that goal." During his presidential campaign, U.S. President-Elect Barack Obama pledged to "set a goal of a world without nuclear weapons, and pursue it."

The United States has taken the lead in ensuring that nuclear materials globally are properly safeguarded. A popular program that has received bipartisan domestic support for over a decade is the Cooperative Threat Reduction Program (CTR). While this program has been deemed a success, many believe that its funding levels need to be increased so as to ensure that all dangerous nuclear materials are secured in the most expeditious manner possible. The CTR program has led to several other innovative and important nonproliferation programs that need to continue to be a budget priority in order to ensure that nuclear weapons do not spread to actors hostile to the United States.

Key programs:

While the vast majority of states have adhered to the stipulations of the Nuclear Nonproliferation Treaty, a few states have either refused to sign the treaty or have pursued nuclear weapons programs while not being members of the treaty. Many view the pursuit of nuclear weapons by these states as a threat to nonproliferation and world peace.







Eliminating nuclear weapons has long been an aim of the pacifist left. But now many mainstream politicians, academic analysts, and retired military leaders also advocate nuclear disarmament. Sam Nunn, William Perry, Henry Kissinger, and George Shultz have called upon governments to embrace the vision of a world free of nuclear weapons, and in three "Wall Street Journal" opeds proposed an ambitious program of urgent steps to that end. The four have created the Nuclear Security Project to advance this agenda. Nunn reinforced that agenda during a speech at the Harvard Kennedy School on October 21, 2008, saying, "I’m much more concerned about a terrorist without a return address that cannot be deterred than I am about deliberate war between nuclear powers. You can’t deter a group who is willing to commit suicide. We are in a different era. You have to understand the world has changed." In 2010, the four were featured in a documentary film entitled "Nuclear Tipping Point". The film is a visual and historical depiction of the ideas laid forth in the Wall Street Journal op-eds and reinforces their commitment to a world without nuclear weapons and the steps that can be taken to reach that goal.

Global Zero is an international non-partisan group of 300 world leaders dedicated to achieving nuclear disarmament. The initiative, launched in December 2008, promotes a phased withdrawal and verification for the destruction of all devices held by official and unofficial members of the nuclear club. The Global Zero campaign works toward building an international consensus and a sustained global movement of leaders and citizens for the elimination of nuclear weapons. Goals include the initiation of United States-Russia bilateral negotiations for reductions to 1,000 total warheads each and commitments from the other key nuclear weapons countries to participate in multilateral negotiations for phased reductions of nuclear arsenals. Global Zero works to expand the diplomatic dialogue with key governments and continue to develop policy proposals on the critical issues related to the elimination of nuclear weapons.

The International Conference on Nuclear Disarmament took place in Oslo in February, 2008, and was organized by The Government of Norway, the Nuclear Threat Initiative and the Hoover Institute. The Conference was entitled "Achieving the Vision of a World Free of Nuclear Weapons" and had the purpose of building consensus between nuclear weapon states and non-nuclear weapon states in relation to the Nuclear Non-proliferation Treaty.

The Tehran International Conference on Disarmament and Non-Proliferation took place in Tehran in April 2010. The conference was held shortly after the signing of the New START, and resulted in a call of action toward eliminating all nuclear weapons. Representatives from 60 countries were invited to the conference. Non-governmental organizations were also present.

Among the prominent figures who have called for the abolition of nuclear weapons are "the philosopher Bertrand Russell, the entertainer Steve Allen, CNN’s Ted Turner, former Senator Claiborne Pell, Notre Dame president Theodore Hesburgh, South African Bishop Desmond Tutu and the Dalai Lama".

Others have argued that nuclear weapons have made the world relatively safer, with peace through deterrence and through the stability–instability paradox, including in south Asia. Kenneth Waltz has argued that nuclear weapons have created a nuclear peace, and further nuclear weapon proliferation might even help avoid the large scale conventional wars that were so common prior to their invention at the end of World War II. In the July 2012 issue of Foreign Affairs Waltz took issue with the view of most U.S., European, and Israeli, commentators and policymakers that a nuclear-armed Iran would be unacceptable. Instead Waltz argues that it would probably be the best possible outcome, as it would restore stability to the Middle East by balancing Israel's regional monopoly on nuclear weapons. Professor John Mueller of Ohio State University, the author of "Atomic Obsession", has also dismissed the need to interfere with Iran's nuclear program and expressed that arms control measures are counterproductive. During a 2010 lecture at the University of Missouri, which was broadcast by C-SPAN, Dr. Mueller has also argued that the threat from nuclear weapons, especially nuclear terrorism, has been exaggerated, both in the popular media and by officials.

Former Secretary Kissinger says there is a new danger, which cannot be addressed by deterrence: "The classical notion of deterrence was that there was some consequences before which aggressors and evildoers would recoil. In a world of suicide bombers, that calculation doesn’t operate in any comparable way". George Shultz has said, "If you think of the people who are doing suicide attacks, and people like that get a nuclear weapon, they are almost by definition not deterrable".

Andrew Bacevich wrote that there is no feasible scenario under which the US could sensibly use nuclear weapons. "For the United States, they are becoming unnecessary, even as a deterrent. Certainly, they are unlikely to dissuade the adversaries most likely to employ such weapons against us -- Islamic extremists intent on acquiring their own nuclear capability. If anything, the opposite is true. By retaining a strategic arsenal in readiness (and by insisting without qualification that the dropping of atomic bombs on two Japanese cities in 1945 was justified), the United States continues tacitly to sustain the view that nuclear weapons play a legitimate role in international politics ... ."

In "The Limits of Safety", Scott Sagan documented numerous incidents in US military history that could have produced a nuclear war by accident. He concluded, "while the military organizations controlling U.S. nuclear forces during the Cold War performed this task with less success than we know, they performed with more success than we "should" have reasonably predicted. The problems identified in this book were not the product of incompetent organizations. They reflect the inherent limits of organizational safety. Recognizing that simple truth is the first and most important step toward a safer future."



</doc>
<doc id="22170" url="https://en.wikipedia.org/wiki?curid=22170" title="Net (mathematics)">
Net (mathematics)

In mathematics, more specifically in general topology and related branches, a net or Moore–Smith sequence is a generalization of the notion of a sequence. In essence, a sequence is a function with domain the natural numbers, and in the context of topology, the codomain of this function is usually any topological space. However, in the context of topology, sequences do not fully encode all information about a function between topological spaces. In particular, the following two conditions are not equivalent in general for a map "f" between topological spaces "X" and "Y":


It is true, however, that condition 1 implies condition 2. The difficulty encountered when attempting to prove that condition 2 implies condition 1 lies in the fact that topological spaces are, in general, not first-countable.
If the first-countability axiom were imposed on the topological spaces in question, the two above conditions would be equivalent. In particular, the two conditions are equivalent for metric spaces.

The purpose of the concept of a net, first introduced by E. H. Moore and H. L. Smith in 1922, is to generalize the notion of a sequence so as to confirm the equivalence of the conditions (with "sequence" being replaced by "net" in condition 2). In particular, rather than being defined on a countable linearly ordered set, a net is defined on an arbitrary directed set. In particular, this allows theorems similar to that asserting the equivalence of condition 1 and condition 2, to hold in the context of topological spaces that do not necessarily have a countable or linearly ordered neighbourhood basis around a point. Therefore, while sequences do not encode sufficient information about functions between topological spaces, nets do because collections of open sets in topological spaces are much like directed sets in behaviour. The term "net" was coined by Kelley.

Nets are one of the many tools used in topology to generalize certain concepts that may only be general enough in the context of metric spaces. A related notion, that of the filter, was developed in 1937 by Henri Cartan.

Let A be a directed set with order relation "≥" and "X" be a topological space with topology "T". A function "f: A → X" is said to be a "net".

If "A" is a directed set, we often write a net from "A" to "X" in the form ("x"), which expresses the fact that the element α in "A" is mapped to the element "x" in "X".

Every non-empty totally ordered set is directed. Therefore, every function on such a set is a net. In particular, the natural numbers with the usual order form such a set, and a sequence is a function on the natural numbers, so every sequence is a net.

Another important example is as follows. Given a point "x" in a topological space, let "N" denote the set of all neighbourhoods containing "x". Then "N" is a directed set, where the direction is given by reverse inclusion, so that "S" ≥ "T" if and only if "S" is contained in "T". For "S" in "N", let "x" be a point in "S". Then ("x") is a net. As "S" increases with respect to ≥, the points "x" in the net are constrained to lie in decreasing neighbourhoods of "x", so intuitively speaking, we are led to the idea that "x" must tend towards "x" in some sense. We can make this limiting concept precise.

If ("x") is a net from a directed set "A" into "X", and if "Y" is a subset of "X", then we say that ("x") is eventually in "Y (or residually in "Y) if there exists an α in "A" so that for every β in "A" with β ≥ α, the point "x" lies in "Y".

If ("x") is a net in the topological space "X", and "x" is an element of "X", we say that the net converges towards "x or has limit "x and write
if and only if
Intuitively, this means that the values "x" come and stay as close as we want to "x" for large enough α.

The example net given above on the neighborhood system of a point "x" does indeed converge to "x" according to this definition.

Given a base for the topology, in order to prove convergence of a net it is necessary and sufficient to prove that there exists some point "x", such that ("x") is eventually in all members of the base containing this putative limit.


Let φ be a net on "X" based on the directed set "D" and let "A" be a subset of "X", then φ is said to be frequently in (or cofinally in) "A" if for every α in "D" there exists some β ≥ α, β in "D", so that φ(β) is in "A".

A point "x" in "X" is said to be an accumulation point or cluster point of a net if (and only if) for every neighborhood "U" of "x", the net is frequently in "U".

A net φ on set "X" is called universal, or an ultranet if for every subset "A" of "X", either φ is eventually in "A" or φ is eventually in "X" − "A".

Sequence in a topological space:

A sequence ("a", "a", ...) in a topological space "V" can be considered a net in "V" defined on N.

The net is eventually in a subset "Y" of "V" if there exists an N in N such that for every "n" ≥ "N", the point "a" is in "Y".

We have lim "a" = "L" if and only if for every neighborhood "Y" of "L", the net is eventually in "Y".

The net is frequently in a subset "Y" of "V" if and only if for every "N" in N there exists some "n" ≥ "N" such that "a" is in "Y", that is, if and only if infinitely many elements of the sequence are in "Y". Thus a point "y" in "V" is a cluster point of the net if and only if every neighborhood "Y" of "y" contains infinitely many elements of the sequence.

Function from a metric space to a topological space:

Consider a function from a metric space "M" to a topological space "V", and a point "c" of "M". We direct the set "M"\{"c"} reversely according to distance from "c", that is, the relation is "has at least the same distance to "c" as", so that "large enough" with respect to the relation means "close enough to "c"". The function ƒ is a net in "V" defined on "M"\{"c"}.

The net ƒ is eventually in a subset "Y" of "V" if there exists an "a" in "M" \ {"c"} such that for every "x" in "M" \ {"c"} with d("x","c") ≤ d("a","c"), the point f("x") is in "Y".

We have lim ƒ("x") = "L" if and only if for every neighborhood "Y" of "L", ƒ is eventually in "Y".

The net ƒ is frequently in a subset "Y" of "V" if and only if for every "a" in "M" \ {"c"} there exists some "x" in "M" \ {"c"} with "d"("x","c") ≤ d("a","c") such that "f(x)" is in "Y".

A point "y" in "V" is a cluster point of the net ƒ if and only if for every neighborhood "Y" of "y", the net is frequently in "Y".

Function from a well-ordered set to a topological space:

Consider a well-ordered set [0, "c"] with limit point "c", and a function ƒ from [0, "c") to a topological space "V". This function is a net on [0, "c").

It is eventually in a subset "Y" of "V" if there exists an "a" in [0, "c") such that for every "x" ≥ "a", the point "f"("x") is in "Y".

We have lim ƒ("x") = "L" if and only if for every neighborhood "Y" of "L", ƒ is eventually in "Y".

The net ƒ is frequently in a subset "Y" of "V" if and only if for every "a" in [0, "c") there exists some "x" in ["a", "c") such that "f"("x") is in "Y".

A point "y" in "V" is a cluster point of the net ƒ if and only if for every neighborhood "Y" of "y", the net is frequently in "Y".

The first example is a special case of this with "c" = ω.

See also ordinal-indexed sequence.

Virtually all concepts of topology can be rephrased in the language of nets and limits. This may be useful to guide the intuition since the notion of limit of a net is very similar to that of limit of a sequence. The following set of theorems and lemmas help cement that similarity:




In mathematics, a Cauchy net generalizes the notion of Cauchy sequence to nets defined on uniform spaces.

A net ("x") is a Cauchy net if for every entourage "V" there exists γ such that for all α, β ≥ γ, ("x", "x") is a member of "V". More generally, in a Cauchy space, a net ("x") is Cauchy if the filter generated by the net is a Cauchy filter.

A filter is another idea in topology that allows for a general definition for convergence in general topological spaces. The two ideas are equivalent in the sense that they give the same concept of convergence. More specifically, for every filter base an "associated net" can be constructed, and convergence of the filter base implies convergence of the associated net—and the other way around (for every net there is a filter base, and convergence of the net implies convergence of the filter base). For instance, any net formula_2 in formula_3 induces a filter base of tails formula_4 where the filter in formula_3 generated by this filter base is called the net's "eventuality filter." This correspondence allows for any theorem that can be proven with one concept to be proven with the other. For instance, continuity of a function from one topological space to the other can be characterized either by the convergence of a net in the domain implying the convergence of the corresponding net in the codomain, or by the same statement with filter bases.

Robert G. Bartle argues that despite their equivalence, it is useful to have both concepts. He argues that nets are enough like sequences to make natural proofs and definitions in analogy to sequences, especially ones using sequential elements, such as is common in analysis, while filters are most useful in algebraic topology. In any case, he shows how the two can be used in combination to prove various theorems in general topology.

Limit superior and limit inferior of a net of real numbers can be defined in a similar manner as for sequences. Some authors work even with more general structures than the real line, like complete lattices.

For a net formula_6 we put

Limit superior of a net of real numbers has many properties analogous to the case of sequences, e.g.
where equality holds whenever one of the nets is convergent.



</doc>
<doc id="22171" url="https://en.wikipedia.org/wiki?curid=22171" title="Nuclear winter">
Nuclear winter

Nuclear winter is the severe and prolonged global climatic cooling effect hypothesized to occur after widespread firestorms following a nuclear war. The hypothesis is based on the fact that such fires can inject soot into the stratosphere, where it can block some direct sunlight from reaching the surface of the Earth. It is speculated that the resulting cooling would lead to widespread crop failure and famine. In developing computer models of nuclear-winter scenarios, researchers use the conventional bombing of Hamburg, and the Hiroshima firestorm in World War II as example cases where soot might have been injected into the stratosphere, alongside modern observations of natural, large-area wildfire-firestorms.

"Nuclear winter," or as it was initially termed, "nuclear twilight," began to be considered as a scientific concept in the 1980s, after it became clear that an earlier hypothesis, that fireball generated NOx emissions would devastate the ozone layer, was losing credibility. It was within this context that the climatic effects of soot from fires was "chanced upon" and soon became the new focus of the climatic effects of nuclear war. In these model scenarios, various soot clouds containing uncertain quantities of soot were assumed to form over cities, oil refineries, and more rural missile silos. Once the quantity of soot is decided upon by the researchers, the climate effects of these soot clouds are then modeled. The term "nuclear winter" was a neologism coined in 1983 by Richard P. Turco in reference to a 1-dimensional computer model created to examine the "nuclear twilight" idea, this 1-D model output the finding that massive quantities of soot and smoke would remain aloft in the air for on the order of years, causing a severe planet-wide drop in temperature. Turco would later distance himself from these extreme 1-D conclusions.

After the failure of the predictions on the effects of the 1991 Kuwait oil fires, that were made by the primary team of climatologists that advocate the hypothesis, over a decade passed without any new published papers on the topic. More recently, the same team of prominent modellers from the 1980s have begun again to publish the outputs of computer models, these newer models produce the same general findings as their old ones, that the ignition of 100 firestorms, each comparable in intensity to that observed in Hiroshima in 1945, could produce a "small" nuclear winter. These firestorms would result in the injection of soot (specifically black carbon) into the Earth's stratosphere, producing an anti-greenhouse effect that would lower the Earth's surface temperature. The severity of this cooling in Alan Robock's model suggests that the cumulative products of 100 of these firestorms could cool the global climate by approximately 1 °C (1.8 °F), largely eliminating the magnitude of anthropogenic global warming for two to three years. Robock has not modeled this, but has speculated that it would have global agricultural losses as a consequence.

As nuclear devices need not be detonated to ignite a firestorm, the term "nuclear winter" is something of a misnomer. The majority of papers published on the subject state that without qualitative justification, nuclear explosions are the cause of the modeled firestorm effects. The only phenomenon that is modeled by computer in the nuclear winter papers is the climate forcing agent of firestorm-soot, a product which can be ignited and formed by a myriad of means. Although rarely discussed, the proponents of the hypothesis state that the same "nuclear winter" effect would occur if 100 conventional firestorms were ignited.

A much larger number of firestorms, in the thousands, was the initial assumption of the computer modelers who coined the term in the 1980s. These were speculated to be a possible result of any large scale employment of counter-value airbursting nuclear weapon use during an American-Soviet total war. This larger number of firestorms, which are not in themselves modeled, are presented as causing nuclear winter conditions as a result of the smoke inputted into various climate models, with the depths of severe cooling lasting for as long as a decade. During this period, summer drops in average temperature could be up to 20 °C (36 °F) in core agricultural regions of the US, Europe, and China, and as much as 35 °C (63 °F) in Russia. This cooling would be produced due to a 99% reduction in the natural solar radiation reaching the surface of the planet in the first few years, gradually clearing over the course of several decades.

On the fundamental level, since the advent of photographic evidence of tall clouds were captured, it was known that firestorms could inject soot smoke/aerosols into the stratosphere but the longevity of this slew of aerosols was a major unknown. Independent of the team that continue to publish theoretical models on nuclear winter, in 2006, Mike Fromm of the Naval Research Laboratory, experimentally found that each natural occurrence of a massive wildfire firestorm, much larger than that observed at Hiroshima, can produce minor "nuclear winter" effects, with short-lived, approximately 1 month of a nearly immeasurable drop in surface temperatures, confined to the hemisphere that they burned in. This is somewhat analogous to the frequent volcanic eruptions that inject sulfates into the stratosphere and thereby produce minor, even negligible, volcanic winter effects.

A suite of satellite and aircraft-based firestorm-soot-monitoring instruments are at the forefront of attempts to accurately determine the lifespan, quantity, injection height, and optical properties of this smoke. Information regarding all of these properties is necessary to truly ascertain the length and severity of the cooling effect of firestorms, independent of the nuclear winter computer model projections.

Presently, from satellite tracking data, stratospheric smoke aerosols dissipate in a time span under approximately two months. The existence of any hint of a tipping point into a new stratospheric condition where the aerosols would not be removed within this time frame remains to be determined.

The nuclear winter scenario assumes that 100 or more city firestorms are ignited by nuclear explosions, and that the firestorms lifts large amounts of sooty smoke into the upper troposphere and lower stratosphere by the movement offered by the pyrocumulonimbus clouds that form during a firestorm. At above the Earth's surface, the absorption of sunlight could further heat the soot in the smoke, lifting some or all of it into the stratosphere, where the smoke could persist for years if there is no rain to wash it out. This aerosol of particles could heat the stratosphere and prevent a portion of the sun's light from reaching the surface, causing surface temperatures to drop drastically. In this scenario it is predicted that surface air temperatures would be the same as, or colder than, a given region's winter for months to years on end.

The modeled stable inversion layer of hot soot between the troposphere and high stratosphere that produces the anti-greenhouse effect was dubbed the "Smokeosphere" by Stephen Schneider et al. in their 1988 paper.

Although it is common in the climate models to consider city firestorms, these need not be ignited by nuclear devices; more conventional ignition sources can instead be the spark of the firestorms. Prior to the previously mentioned solar heating effect, the soot's injection height is controlled by the rate of energy release from the firestorm's fuel, not the size of an initial nuclear explosion. For example, the mushroom cloud from the bomb dropped on Hiroshima reached a height of six kilometers (middle troposphere) within a few minutes and then dissipated due to winds, while the individual fires within the city took almost three hours to form into a firestorm and produce a pyrocumulus cloud, a cloud that is assumed to have reached upper tropospheric heights, as over its multiple hours of burning, the firestorm released an estimated 1000 times the energy of the bomb.

As the incendiary effects of a nuclear explosion do not present any especially characteristic features, it is estimated by those with Strategic bombing experience that as the city was a firestorm hazard, the same fire ferocity and building damage produced at Hiroshima by one 16-kiloton nuclear bomb from a single B-29 bomber could have been produced instead by the conventional use of about 1.2 kilotons of incendiary bombs from 220 B-29s distributed over the city.

While the firestorms of Dresden and Hiroshima and the mass fires of Tokyo and Nagasaki occurred within mere months in 1945, the more intense and conventionally lit Hamburg firestorm occurred in 1943. Despite the separation in time, ferocity and area burned, leading modelers of the hypothesis state that these five fires potentially placed five percent as much smoke into the stratosphere as the hypothetical 100 nuclear-ignited fires discussed in modern models. While it is believed that the modeled climate-cooling-effects from the mass of soot injected into the stratosphere by 100 firestorms (one to five teragrams) would have been detectable with technical instruments in WWII, five percent of that would not have been possible to observe at that time.

The exact timescale for how long this smoke remains, and thus how severely this smoke affects the climate once it reaches the stratosphere, is dependent on both chemical and physical removal processes.

The most important physical removal mechanism is "rainout", both during the "fire-driven convective column" phase, which produces "black rain" near the fire site, and rainout after the convective plume's dispersal, where the smoke is no longer concentrated and thus "wet removal" is believed to be very efficient. However, these efficient removal mechanisms in the troposphere are avoided in the Robock 2007 study, where solar heating is modeled to quickly loft the soot into the stratosphere, "detraining" or separating the darker soot particles from the fire clouds' whiter water condensation.

Once in the stratosphere, the physical removal mechanisms affecting the timescale of the soot particles' residence are how quickly the aerosol of soot collides and coagulates with other particles via Brownian motion, and falls out of the atmosphere via gravity-driven dry deposition, and the time it takes for the "phoretic effect" to move coagulated particles to a lower level in the atmosphere. Whether by coagulation or the phoretic effect, once the aerosol of smoke particles are at this lower atmospheric level, cloud seeding can begin, permitting precipitation to wash the smoke aerosol out of the atmosphere by the wet deposition mechanism.

The chemical processes that affect the removal are dependent on the ability of atmospheric chemistry to oxidize the carbonaceous component of the smoke, via reactions with oxidative species such as ozone and nitrogen oxides, both of which are found at all levels of the atmosphere, and which also occur at greater concentrations when air is heated to high temperatures.

Historical data on residence times of aerosols, albeit a different mixture of aerosols, in this case stratospheric sulfur aerosols and volcanic ash from megavolcano eruptions, appear to be in the one-to-two-year time scale, however aerosol–atmosphere interactions are still poorly understood.

Sooty aerosols can have a wide range of properties, as well as complex shapes, making it difficult to determine their evolving atmospheric Optical depth value. The conditions present during the creation of the soot are believed to be considerably important as to their final properties, with soot generated on the more efficient spectrum of burning efficiency considered almost "elemental carbon black," while on the more inefficient end of the burning spectrum, greater quantities of partially burnt/oxidized fuel are present. These partially burnt "organics" as they are known, often form tar balls and brown carbon during common lower-intensity wildfires, and can also coat the purer black carbon particles. However, as the soot of greatest importance is that which is injected to the highest altitudes by the pyroconvection of the firestorm – a fire being fed with storm-force winds of air – it is estimated that the majority of the soot under these conditions is the more oxidized black carbon.

A study presented at the annual meeting of the American Geophysical Union in December 2006 found that even a small-scale, regional nuclear war could disrupt the global climate for a decade or more. In a regional nuclear conflict scenario where two opposing nations in the subtropics would each use 50 Hiroshima-sized nuclear weapons (about 15 kiloton each) on major population centers, the researchers estimated as much as five million tons of soot would be released, which would produce a cooling of several degrees over large areas of North America and Eurasia, including most of the grain-growing regions. The cooling would last for years, and, according to the research, could be "catastrophic".

A 2008 study by Michael J. Mills et al., published in the Proceedings of the National Academy of Sciences, found that a nuclear weapons exchange between Pakistan and India using their current arsenals could create a near-global ozone hole, triggering human health problems and causing environmental damage for at least a decade. The computer-modeled study looked at a nuclear war between the two countries involving 50 Hiroshima-sized nuclear devices on each side, producing massive urban fires and lofting as much as five million metric tons of soot about into the mesosphere. The soot would absorb enough solar radiation to heat surrounding gases, causing a series of surface chemistry reactions that would break down the stratospheric ozone layer protecting Earth from harmful ultraviolet radiation.

A "nuclear summer" is a hypothesized scenario in which, after a nuclear winter has abated, a greenhouse effect then occurs due to CO released by combustion and methane released from the decay of the organic matter that froze during the nuclear winter. The risk of this happening is far less scientifically supported than nuclear winter.

In 1952, a few weeks prior to the Ivy Mike (10.4 Mt) bomb test on Elugelab island, there were concerns that the aerosols lifted by the explosion might cool the Earth. Major Norair Lulejian, USAF, and astronomer Natarajan Visvanathan, studied this possibility, reporting their findings in
"Effects of Superweapons Upon the Climate of the World". According to a document by the Defense Threat Reduction Agency", this report was the initial study of the "nuclear winter" concept that was popularized by others decades later. It indicated no appreciable chance of explosion-induced climate change.

Following numerous surface bursts of high yield Hydrogen bomb explosions on Pacific Proving Ground islands such as those of Ivy Mike in 1952 and Castle Bravo (15 Mt) in 1954, "The Effects of Nuclear Weapons" by Samuel Glasstone was published in 1957, containing a section entitled "Nuclear Bombs and the Weather", which states: "The dust raised in severe volcanic eruptions, such as that at Krakatoa in 1883, is known to cause a noticeable reduction in the sunlight reaching the earth … The amount of [soil or other surface] debris remaining in the atmosphere after the explosion of even the largest nuclear weapons is probably not more than about 1 percent or so of that raised by the Krakatoa eruption. Further, solar radiation records reveal that none of the nuclear explosions to date has resulted in any detectable change in the direct sunlight recorded on the ground." The US Weather Bureau in 1956 regarded it as conceivable that a large enough nuclear war with megaton-range surface detonations could lift enough soil to cause a new ice age.

In the 1966 RAND corporation memorandum "The Effects of Nuclear War on the Weather and Climate" by E. S. Batten, while primarily analysing potential dust effects from surface bursts, it notes that "in addition to the effects of the debris, extensive fires ignited by nuclear detonations might change the surface characteristics of the area and modify local weather patterns ... however, a more thorough knowledge of the atmosphere is necessary to determine their exact nature, extent, and magnitude."

In the 1985 report "The Effects on the Atmosphere of a Major Nuclear Exchange", the Committee on the Atmospheric Effects of Nuclear Explosions argues that a "plausible" estimate on the amount of stratospheric dust injected following a surface burst of 1 Mt is 0.3 teragrams, of which 8 percent would be in the micrometer range. The potential cooling from soil dust was again looked at in 1992, in a US National Academy of Sciences (NAS) report on geoengineering, which estimated that about 10kg (100 teragrams) of stratospheric injected soil dust with particulate grain dimensions of 0.1 to 1 micrometer would be required to mitigate the warming from a doubling of atmospheric , that is, to produce ~2 ˚C of cooling.

In 1969, Paul Crutzen discovered that oxides of nitrogen (NOx) could be an efficient
catalyst for the destruction of the ozone layer/stratospheric ozone. Following studies on the potential effects of NOx generated by engine heat in stratosphere flying Supersonic Transport (SST) airplanes in the 1970s,< in 1974, John Hampson suggested in the journal "Nature" that due to the creation of atmospheric NOx by nuclear fireballs, a full-scale nuclear exchange could result in depletion of the ozone shield, possibly subjecting the earth to ultraviolet radiation for a year or more. In 1975, Hampson's hypothesis "led directly" to the United States National Research Council (NRC) reporting on the models of ozone depletion following nuclear war in the book "Long-Term Worldwide Effects of Multiple Nuclear-Weapons Detonations".

More recent accounts on the specific ozone layer destruction potential of NOx species are much less than earlier assumed from simplistic calculations, as "about 1.2 million tons" of natural and anthropogenic generated stratospheric NOx is believed to be formed each year according to Robert P. Parson in the 1990s.

The first published suggestion that a cooling of climate could be an effect of a nuclear war, appears to have been originally put forth by Poul Anderson and F.N. Waldrop in their post-war story "Tomorrow's Children", in the March 1947 issue of the "Astounding Science Fiction" magazine. The story, primarily about a team of scientists hunting down mutants, warns of a "Fimbulwinter" caused by dust that blocked sunlight after a recent nuclear war and speculated that it may even trigger a new Ice Age. Anderson went on to publish a novel based partly on this story in 1961 titling it "Twilight World". Similarly in 1985 it was noted by T. G. Parsons that the story "Torch" by C. Anvil, which also appeared in "Astounding Science Fiction" magazine, but in the April 1957 edition, contains the essence of the "Twilight at Noon"/"nuclear winter" hypothesis. In the story a nuclear warhead ignites an oil field, and the soot produced "screens out part of the sun's radiation", resulting in Arctic temperatures for much of the population of North America and the Soviet Union.

The 1988 Air Force Geophysics Laboratory publication "An assessment of global atmospheric effects of a major nuclear war" by H. S. Muench et al. contains a chronology and review of the major reports on the nuclear winter hypothesis from 1983–86. In general these reports arrive at similar conclusions as they are based on "the same assumptions, the same basic data", with only minor model-code differences. They skip the modeling steps of assessing the possibility of fire and the initial fire plumes and instead start the modeling process with a "spatially uniform soot cloud" which has found its way into the atmosphere.

Although never openly acknowledged by the multi-disciplinary team who authored the most popular 1980s TTAPS model, in 2011 the American Institute of Physics states that the TTAPS team (named for its participants, who had all previously worked on the phenomenon of dust storms on Mars, or in the area of asteroid impact events: Richard P. Turco, Owen Toon, Thomas P. Ackerman, James B. Pollack and Carl Sagan) announcement of their results in 1983 "was with the explicit aim of promoting international arms control". However, "the computer models were so simplified, and the data on smoke and other aerosols were still so poor, that the scientists could say nothing for certain."

In 1981, William J. Moran began discussions and research in the National Research Council (NRC) on the airborne soil/dust effects of a large exchange of nuclear warheads, having seen a possible parallel in the dust effects of a war with that of the asteroid-created K-T boundary and its popular analysis a year earlier by Luis Alvarez in 1980. An NRC study panel on the topic met in December 1981 and April 1982 in preparation for the release of the NRC's "The Effects on the Atmosphere of a Major Nuclear Exchange", published in 1985.

As part of a study on the creation of oxidizing species such as NOx and ozone in the troposphere after a nuclear war, launched in 1980 by "AMBIO", a journal of the Royal Swedish Academy of Sciences, Paul J. Crutzen and John Birks began preparing for the 1982 publication of a calculation on the effects of nuclear war on stratospheric ozone, using the latest models of the time. However they found that in part as a result of the trend towards more numerous but less energetic, sub-megaton range nuclear warheads (made possible by the ceaseless march to increase ICBM warhead accuracy/Circular Error Probable), the ozone layer danger was "not very significant".

It was after being confronted with these results that they "chanced" upon the notion, as "an afterthought" of nuclear detonations igniting massive fires everywhere and, crucially, the smoke from these conventional fires then going on to absorb sunlight, causing surface temperatures to plummet. In early 1982, the two circulated a draft paper with the first suggestions of alterations in short-term climate from fires presumed to occur following a nuclear war. Later in the same year, the special issue of "Ambio" devoted to the possible environmental consequences of nuclear war by Crutzen and Birks was titled "Twilight at Noon", and largely anticipated the nuclear winter hypothesis. The paper looked into fires and their climatic effect and discussed particulate matter from large fires, nitrogen oxide, ozone depletion and the effect of nuclear twilight on agriculture. Crutzen and Birks' calculations suggested that smoke particulates injected into the atmosphere by fires in cities, forests and petroleum reserves could prevent up to 99% of sunlight from reaching the Earth's surface. This darkness, they said, could exist "for as long as the fires burned", which was assumed to be many weeks, with effects such as: "The normal dynamic and temperature structure of the atmosphere would ... change considerably over a large fraction of the Northern Hemisphere, which will probably lead to important changes in land surface temperatures and wind systems." An implication of their work was that a successful nuclear decapitation strike could have severe climatic consequences for the perpetrator.

After reading a paper by N. P. Bochkov and E. I. Chazov, published in the same edition of "Ambio" that carried Crutzen and Birks's paper "Twilight at Noon", Soviet atmospheric scientist Georgy Golitsyn applied his research on Mars dust storms to soot in the Earth's atmosphere. The use of these influential Martian dust storm models in nuclear winter research began in 1971, when the Soviet spacecraft Mars 2 arrived at the red planet and observed a global dust cloud. The orbiting instruments together with the 1971 Mars 3 lander determined that temperatures on the surface of the red-planet were considerably colder than temperatures at the top of the dust cloud. Following these observations, Golitsyn received two telegrams from astronomer Carl Sagan, in which Sagan asked Golitsyn to "explore the understanding and assessment of this phenomenon." Golitsyn recounts that it was around this time that he had "proposed a theory to explain how Martian dust may be formed and how it may reach global proportions."

In the same year Alexander Ginzburg, an employee in Golitsyn's institute, developed a model of dust storms to describe the cooling phenomenon on Mars. Golitsyn felt that his model would be applicable to soot after he read a 1982 Swedish magazine dedicated to the effects of a hypothetical nuclear war between the USSR and the US. Golitsyn would use Ginzburg's largely unmodified dust-cloud model with soot assumed as the aerosol in the model instead of soil dust and in an identical fashion to the results returned, when computing dust-cloud cooling in the Martian atmosphere, the cloud high above the planet would be heated while the planet below would cool drastically. Golitsyn presented his intent to publish this Martian derived Earth-analog model to the Andropov instigated "Committee of Soviet Scientists in Defence of Peace Against the Nuclear Threat" in May 1983, an organization that Golitsyn would later be appointed a position of vice-chairman of. The establishment of this committee was done with the expressed approval of the Soviet leadership with the intent "to expand controlled contacts with Western "nuclear freeze" activists". Having gained this committees approval, in September 1983, Golitsyn published the first computer model on the nascent "nuclear winter" effect in the widely read "Herald of the Russian Academy of Sciences".

On 31 October 1982, Golitsyn and Ginsburg's model and results were presented at the conference on "The World after Nuclear War", hosted in Washington, D.C.

Both Golitsyn and Sagan had been interested in the cooling on the dust storms on the planet Mars in the years preceding their focus on "nuclear winter". Sagan had also worked on Project A119 in the 1950s–60s, in which he attempted to model the movement and longevity of a plume of lunar soil.

After the publication of "Twilight at Noon" in 1982, the TTAPS team have said that they began the process of doing a 1-dimensional computational modeling study of the atmospheric consequences of nuclear war/soot in the stratosphere, though they would not publish a paper in "Science" magazine until late December 1983. The phrase "nuclear winter" had been coined by Turco just prior to publication. In this early paper, TTAPS used assumption based estimates on the total smoke and dust emissions that would result from a major nuclear exchange, and with that, began analyzing the subsequent effects on the atmospheric radiation balance and temperature structure as a result of this quantity of assumed smoke. To compute dust and smoke effects, they employed a one-dimensional microphysics/radiative-transfer model of the Earth's lower atmosphere (up to the mesopause), which defined only the vertical characteristics of the global climate perturbation.

Interest in the environmental effects of nuclear war, however, had continued in the Soviet Union after Golitsyn's September paper, with Vladimir Alexandrov and G. I. Stenchikov also publishing a paper in December 1983 on the climatic consequences, although in contrast to the contemporary TTAPS paper, this paper was based on simulations with a three-dimensional global circulation model. (Two years later Alexandrov disappeared under mysterious circumstances). Richard Turco and Starley L. Thompson were both critical of the Soviet research. Turco called it "primitive" and Thompson said it used obsolete US computer models. Later they were to rescind these criticisms and instead applauded Alexandrov's pioneering work, saying that the Soviet model shared the weaknesses of all the others.

In 1984, the World Meteorological Organization (WMO) commissioned Golitsyn and N. A. Phillips to review the state of the science. They found that studies generally assumed a scenario where half of the world's nuclear weapons would be used, ~5000 Mt, destroying approximately 1,000 cities, and creating large quantities of carbonaceous smoke – 1– being most likely, with a range of 0.2– (NAS; TTAPS assumed ). The smoke resulting would be largely opaque to solar radiation but transparent to infra-red, thus cooling the Earth by blocking sunlight, but not creating warming by enhancing the greenhouse effect. The optical depth of the smoke can be much greater than unity. Forest fires resulting from non-urban targets could increase aerosol production further. Dust from near-surface explosions against hardened targets also contributes; each megaton-equivalent explosion could release up to 5 million tons of dust, but most would quickly fall out; high altitude dust is estimated at 0.1–1 million tons per megaton-equivalent of explosion. Burning of crude oil could also contribute substantially.

The 1-D radiative-convective models used in these studies produced a range of results, with coolings up to 15–42 °C between 14 and 35 days after the war, with a "baseline" of about 20 °C. Somewhat more sophisticated calculations using 3-D GCMs produced similar results: temperature drops of about 20 °C, though with regional variations.

All calculations show large heating (up to 80 °C) at the top of the smoke layer at about 10 km; this implies a substantial modification of the circulation there and the possibility of advection of the cloud into low latitudes and the southern hemisphere.

In a 1990 paper entitled "Climate and Smoke: An Appraisal of Nuclear Winter", TTAPS gave a more detailed description of the short- and long-term atmospheric effects of a nuclear war using a three-dimensional model:

First 1 to 3 months:

Following 1 to 3 years:

One of the major results of TTAPS' 1990 paper was the re-iteration of the team's 1983 model that 100 oil refinery fires would be sufficient to bring about a small scale, but still globally deleterious nuclear winter.

Following Iraq's invasion of Kuwait and Iraqi threats of igniting the country's approximately 800 oil wells, speculation on the cumulative climatic effect of this, presented at the World Climate Conference in Geneva that November in 1990, ranged from a nuclear winter type scenario, to heavy acid rain and even short term immediate global warming.

In articles printed in the "Wilmington Morning Star" and the "Baltimore Sun" newspapers in January 1991, prominent authors of nuclear winter papers – Richard P. Turco, John W. Birks, Carl Sagan, Alan Robock and Paul Crutzen – collectively stated that they expected catastrophic nuclear winter like effects with continental-sized effects of sub-freezing temperatures as a result of the Iraqis going through with their threats of igniting 300 to 500 pressurized oil wells that could subsequently burn for several months.

As threatened, the wells were set on fire by the retreating Iraqis in March 1991, and the 600 or so burning oil wells were not fully extinguished until November 6, 1991, eight months after the end of the war, and they consumed an estimated six million barrels of oil per day at their peak intensity.

When Operation Desert Storm begun in January 1991, coinciding with the first few oil fires being lit, Dr. S. Fred Singer and Carl Sagan discussed the possible environmental effects of the Kuwaiti petroleum fires on the ABC News program "Nightline". Sagan again argued that some of the effects of the smoke could be similar to the effects of a nuclear winter, with smoke lofting into the stratosphere, beginning around above sea level in Kuwait, resulting in global effects. He also argued that he believed the net effects would be very similar to the explosion of the Indonesian volcano Tambora in 1815, which resulted in the year 1816 being known as the "Year Without a Summer".

Sagan listed modeling outcomes that forecast effects extending to South Asia, and perhaps to the Northern Hemisphere as well. Sagan stressed this outcome was so likely that "It should affect the war plans." Singer, on the other hand, anticipated that the smoke would go to an altitude of about and then be rained out after about three to five days, thus limiting the lifetime of the smoke. Both height estimates made by Singer and Sagan turned out to be wrong, albeit with Singer's narrative being closer to what transpired, with the comparatively minimal atmospheric effects remaining limited to the Persian Gulf region, with smoke plumes, in general, lofting to about and a few as high as .

Sagan and his colleagues expected that a "self-lofting" of the sooty smoke would occur when it absorbed the sun's heat radiation, with little to no scavenging occurring, whereby the black particles of soot would be heated by the sun and lifted/lofted higher and higher into the air, thereby injecting the soot into the stratosphere, a position where they argued it would take years for the sun blocking effect of this aerosol of soot to fall out of the air, and with that, catastrophic ground level cooling and agricultural effects in Asia and possibly the Northern Hemisphere as a whole. In a 1992 follow-up, Peter Hobbs and others had observed no appreciable evidence for the nuclear winter team's predicted massive "self-lofting" effect and the oil-fire smoke clouds contained less soot than the nuclear winter modelling team had assumed.

The atmospheric scientist tasked with studying the atmospheric effect of the Kuwaiti fires by the National Science Foundation, Peter Hobbs, stated that the fires' modest impact suggested that "some numbers [used to support the Nuclear Winter hypothesis]... were probably a little overblown."

Hobbs found that at the peak of the fires, the smoke absorbed 75 to 80% of the sun's radiation. The particles rose to a maximum of , and when combined with scavenging by clouds the smoke had a short residency time of a maximum of a few days in the atmosphere.

Pre-War claims of wide scale, long-lasting, and significant global environmental effects were thus not borne out, and found to be significantly exaggerated by the media and speculators, with climate models by those not supporting the nuclear winter hypothesis at the time of the fires predicting only more localized effects such as a daytime temperature drop of ~10 °C within 200 km of the source.

Sagan later conceded in his book "The Demon-Haunted World" that his predictions obviously did not turn out to be correct: "it "was" pitch black at noon and temperatures dropped 4–6 °C over the Persian Gulf, but not much smoke reached stratospheric altitudes and Asia was spared."

The idea of oil well and oil reserve smoke pluming into the stratosphere serving as a main contributor to the soot of a nuclear winter was a central idea of the early climatology papers on the hypothesis; they were considered more of a possible contributor than smoke from cities, as the smoke from oil has a higher ratio of black soot, thus absorbing more sunlight. Hobbs compared the papers' assumed "emission factor" or soot generating efficiency from ignited oil pools and found, upon comparing to measured values from oil pools at Kuwait, which were the greatest soot producers, the emissions of soot assumed in the nuclear winter calculations were still "too high". Following the results of the Kuwaiti oil fires being in disagreement with the core nuclear winter promoting scientists, 1990s nuclear winter papers generally attempted to distance themselves from suggesting oil well and reserve smoke will reach the stratosphere.

In 2007, a nuclear winter study, noted that modern computer models have been applied to the Kuwait oil fires, finding that individual smoke plumes are not able to loft smoke into the stratosphere, but that smoke from fires covering a large area like some forest fires can lift smoke into the stratosphere, and recent evidence suggests that this occurs far more often than previously thought. The study also suggested that the burning of the comparably smaller cities, which would be expected to follow a nuclear strike, would also loft significant amounts of smoke into the stratosphere:

However the above simulation notably contained the assumption that no dry or wet deposition would occur.

Between 1990 and 2003, commentators noted that no peer-reviewed papers on "nuclear winter" were published.

Based on new work published in 2007 and 2008 by some of the authors of the original studies, several new hypotheses have been put forth, primarily the assessment that as few as 100 firestorms would result in a nuclear winter. However far from the hypothesis being "new", it drew the same conclusion as earlier 1980s models, which similarly regarded 100 or so city firestorms as a threat.

A minor nuclear war with each country using 50 Hiroshima-sized atom bombs as air-bursts on urban areas could produce climate change unprecedented in recorded human history. A nuclear war between the United States and Russia today could produce nuclear winter, with temperatures plunging below freezing in the summer in major agricultural regions, threatening the food supply for most of the planet. The climatic effects of the smoke from burning cities and industrial areas would last for several years, much longer than previously thought. New climate model simulations, which are said to have the capability of including the entire atmosphere and oceans, show that the smoke would be lofted by solar heating to the upper stratosphere, where it would remain for years.

Compared to climate change for the past millennium, even the smallest exchange modeled would plunge the planet into temperatures colder than the Little Ice Age (the period of history between approximately AD 1600 and AD 1850). This would take effect instantly, and agriculture would be severely threatened. Larger amounts of smoke would produce larger climate changes, and for the 150 teragrams (Tg) producing a true nuclear winter (1 Tg is 10 grams), making agriculture impossible for years. In both cases, new climate model simulations show that the effects would last for more than a decade.

A study published in the "Journal of Geophysical Research" in July 2007, titled "Nuclear winter revisited with a modern climate model and current nuclear arsenals: Still catastrophic consequences", used current climate models to look at the consequences of a global nuclear war involving most or all of the world's current nuclear arsenals (which the authors judged to be one similar to the size of the world's arsenals twenty years earlier). The authors used a global circulation model, ModelE from the NASA Goddard Institute for Space Studies, which they noted "has been tested extensively in global warming experiments and to examine the effects of volcanic eruptions on climate." The model was used to investigate the effects of a war involving the entire current global nuclear arsenal, projected to release about 150 Tg of smoke into the atmosphere, as well as a war involving about one third of the current nuclear arsenal, projected to release about 50 Tg of smoke. In the 150 Tg case they found that:

In addition, they found that this cooling caused a weakening of the global hydrological cycle, reducing global precipitation by about 45%. As for the 50 Tg case involving one third of current nuclear arsenals, they said that the simulation "produced climate responses very similar to those for the 150 Tg case, but with about half the amplitude," but that "the time scale of response is about the same." They did not discuss the implications for agriculture in depth, but noted that a 1986 study which assumed no food production for a year projected that "most of the people on the planet would run out of food and starve to death by then" and commented that their own results show that, "This period of no food production needs to be extended by many years, making the impacts of nuclear winter even worse than previously thought."

In 2014, Michael J. Mills (at the US National Center for Atmospheric Research, NCAR) et al. published "Multi-decadal global cooling and unprecedented ozone loss following a regional nuclear conflict" in the journal "Earth's Future". The authors used computational models developed by NCAR to simulate the climatic effects of a regional nuclear war in which 100 "small" (15 Kt) weapons are detonated over cities. They concluded that:

global ozone losses of 20–50% over populated areas, levels unprecedented in human history, would accompany the coldest average surface temperatures in the last 1000 years. We calculate summer enhancements in UV indices of 30–80% over Mid-Latitudes, suggesting widespread damage to human health, agriculture, and terrestrial and aquatic ecosystems. Killing frosts would reduce growing seasons by 10–40 days per year for 5 years. Surface temperatures would be reduced for more than 25 years, due to thermal inertia and albedo effects in the ocean and expanded sea ice. The combined cooling and enhanced UV would put significant pressures on global food supplies and could trigger a global nuclear famine.

The four major, largely independent underpinnings that the nuclear winter concept has and continues to receive criticism over, are regarded as: firstly, would cities readily firestorm, and if so how much soot would be generated. Secondly, "atmospheric" longevity; would the quantities of soot assumed in the models remain in the atmosphere for as long as projected or would far more soot precipitate as black rain much sooner. Third, "timing" of events; how realistic is it to start the firestorms or war modelling in late spring or summer, which almost all US-Soviet winter papers assume, so as to depict the maximum possible cooling results. Lastly, the issue of "darkness or opacity"; how much light-blocking effect the assumed quality of the soot reaching the atmosphere would have.

While the highly popularized initial 1983 TTAPS 1-dimensional model forecasts were widely reported and criticized in the media, in part because every later model predicts far less of its "apocalyptic" level of cooling, most models continue to suggest that some deleterious global cooling would still result, under the assumption that a large number of fires occurred in the spring or summer. Starley L. Thompson's less primitive mid-1980s 3-Dimensional model, which notably contained the very same general assumptions, led him to coin the term "nuclear autumn" to more accurately describe the climate results of the soot in this model, in an on camera interview in which he dismisses the earlier "apocalyptic" models.

A major criticism of the assumptions that continue to make these model results possible appeared in the 1987 book "Nuclear War Survival Skills" ("NWSS"), a civil defense manual by Cresson Kearny for the Oak Ridge National Laboratory. According to the 1988 publication "An assessment of global atmospheric effects of a major nuclear war", Kearny's criticisms were directed at the excessive amount of soot that the modelers assumed would reach the stratosphere. Kearny cited a Soviet study that modern cities would not burn as firestorms, as most flammable city items would be buried under non-combustible rubble and that the TTAPS study included a massive overestimate on the size and extent of non-urban wildfires that would result from a nuclear war. The TTAPS authors responded that, amongst other things, they did not believe target planners would intentionally blast cities into rubble, but instead argued fires would begin in relatively undamaged suburbs when nearby sites were hit, and partially conceded his point about non-urban wildfires. Dr. Richard D. Small, director of thermal sciences at the Pacific-Sierra Research Corporation similarly disagreed strongly with the model assumptions, in particular the 1990 update by TTAPS that argues that some 5,075 Tg of material would burn in a total US-Soviet nuclear war, as analysis by Small of blueprints and real buildings returned a maximum of 1,475 Tg of material that could be burned, "assuming that all the available combustible material was actually ignited".

Although Kearny was of the opinion that future more accurate models would "indicate there will be even smaller reductions in temperature", including future potential models that did not so readily accept that firestorms would occur as dependably as nuclear winter modellers assume, in "NWSS" Kearny did summarize the comparatively moderate cooling estimate of no more than a few days, from the 1986 "Nuclear Winter Reappraised" model by Starley Thompson and Stephen Schneider. This was done in an effort to convey to his readers that contrary to the popular opinion at the time, in the conclusion of these two climate scientists, "on scientific grounds the global apocalyptic conclusions of the initial nuclear winter hypothesis can now be relegated to a vanishing low level of probability."

However while a 1988 article by Brian Martin in "Science and Public Policy" states that although "Nuclear Winter Reappraised" concluded the US-Soviet "nuclear winter" would be much less severe than originally thought, with the authors describing the effects more as a "nuclear autumn", other statements by Thompson and Schneider show that they "resisted the interpretation that this means a rejection of the basic points made about nuclear winter". In the Alan Robock et al. 2007 paper they write that "because of the use of the term 'nuclear autumn' by Thompson and Schneider [1986], even though the authors made clear that the climatic consequences would be large, in policy circles the theory of nuclear winter is considered by some to have been exaggerated and disproved [e.g., Martin, 1988]." In 2007 Schneider expressed his tentative support for the cooling results of the limited nuclear war (Pakistan and India) analyzed in the 2006 model, saying "The sun is much stronger in the tropics than it is in mid-latitudes. Therefore, a much more limited war [there] could have a much larger effect, because you are putting the smoke in the worst possible place", and "anything that you can do to discourage people from thinking that there is any way to win anything with a nuclear exchange is a good idea."

The contribution of smoke from the ignition of live non-desert vegetation, living forests, grasses and so on, nearby to many missile silos is a source of smoke originally assumed to be very large in the initial "Twilight at Noon" paper, and also found in the popular TTAPS publication. However, this assumption was examined by Bush and Small in 1987 and they found that the burning of live vegetation could only conceivably contribute very slightly to the estimated total "nonurban smoke production". With the vegetation's potential to sustain burning only probable if it is within a radius or two from the surface of the nuclear fireball, which is at a distance that would also experience extreme blast winds that would influence any such fires. This reduction in the estimate of the non-urban smoke hazard is supported by the earlier preliminary "Estimating Nuclear Forest Fires" publication of 1984, and by the 1950–60s in-field examination of surface-scorched, mangled but never burnt-down tropical forests on the surrounding islands from the shot points in the Operation Castle, and Operation Redwing test series.

A paper by the United States Department of Homeland Security, finalized in 2010, states that after a nuclear detonation targeting a city "If fires are able to grow and coalesce, a firestorm could develop that would be beyond the abilities of firefighters to control. However experts suggest in the nature of modern US city design and construction may make a raging firestorm unlikely". The nuclear bombing of Nagasaki for example, did not produce a firestorm. This was similarly noted as early as 1986–88, when the assumed quantity of fuel "mass loading" (the amount of fuel per square meter) in cities underpinning the winter models was found to be too high and intentionally creates heat fluxes that loft smoke into the lower stratosphere, yet assessments "more characteristic of conditions" to be found in real-world modern cities, had found that the fuel loading, and hence the heat flux that would result from efficient burning, would rarely loft smoke much higher than 4 km.

Russell Seitz, Associate of the Harvard University Center for International Affairs, argues that the winter models' assumptions give results which the researchers want to achieve and is a case of "worst-case analysis run amok". In September 1986 Seitz published "Siberian fire as 'nuclear winter' guide" in the journal "Nature" in which he investigated the 1915 Siberian fire which started in the early summer months and was caused by the worst drought in the region's recorded history. The fire ultimately devastated the region burning the world's largest boreal forest, the size of Germany. While approximately 8 ˚C of daytime summer cooling occurred under the smoke clouds during the weeks of burning, no increase in potentially devastating agricultural night frosts occurred. Following his investigation into the Siberian fire of 1915, Seitz criticized the "nuclear winter" model results for being based on successive worst-case events: “The improbability of a string of 40 such coin tosses coming up heads approaches that of a pat royal flush. Yet it was represented as a "sophisticated one-dimensional model" – a usage that is oxymoronic, unless applied to [the British model Lesley Lawson] Twiggy.”

Seitz cited Carl Sagan, adding an emphasis: ""In almost any realistic case" involving nuclear exchanges between the superpowers, global environmental changes sufficient to cause an extinction event equal to or more severe than that of the close of the Cretaceous when the dinosaurs and many other species died out are likely.” Seitz comments: “The ominous rhetoric italicized in this passage puts even the 100 megaton [the original 100 city firestorm] scenario … on a par with the 100 million megaton blast of an asteroid striking the Earth. This [is] astronomical mega-hype …” Seitz concludes:
Seitz's opposition caused the proponents of nuclear winter to issue responses in the media. The proponents believed it was simply necessary to show only the possibility of climatic catastrophe, often a worst-case scenario, while opponents insisted that to be taken seriously, nuclear winter should be shown as likely under "reasonable" scenarios. One of these areas of contention, as elucidated by Lynn R. Anspaugh, is upon the question of which season should be used as the backdrop for the US-USSR war models, as most models choose the summer in the Northern Hemisphere as the start point to produce the maximum soot lofting and therefore eventual winter effect, whereas it has been pointed out that if the firestorms occurred in the autumn or winter months, when there is much less intense sunlight to loft soot into a stable region of the stratosphere, the magnitude of the cooling effect from the same number of firestorms as ignited in the summer models, would be negligible according to a January model run by Covey et al. Schneider conceded the issue in 1990, saying "a war in late fall or winter would have no appreciable [cooling] effect".

Anspaugh also expressed frustration that although a managed forest fire in Canada on 3 August 1985 is said to have been lit by proponents of nuclear winter, with the fire potentially serving as an opportunity to do some basic measurements of the optical properties of the smoke and smoke-to-fuel ratio, which would have helped refine the estimates of these critical model inputs, the proponents did not indicate that any such measurements were made. Peter V. Hobbs, who would later successfully attain funding to fly into and sample the smoke clouds from the Kuwait oil fires in 1991, also expressed frustration that he was denied funding to sample the Canadian, and other forest fires in this way. Turco wrote a 10-page memorandum with information derived from his notes and some satellite images, claiming that the smoke plume reached 6 km in altitude.

In 1986, atmospheric scientist Joyce Penner from the Lawrence Livermore National Laboratory published an article in "Nature" in which she focused on the specific variables of the smoke's optical properties and the quantity of smoke remaining airborne after the city fires and found that the published estimates of these variables varied so widely that depending on which estimates were chosen the climate effect could be negligible, minor or massive.
The assumed optical properties for black carbon in more recent nuclear winter papers in 2006 are still "based on those assumed in earlier nuclear winter simulations".

John Maddox, editor of the journal "Nature", issued a series of skeptical comments about nuclear winter studies during his tenure. Similarly S. Fred Singer was a long term vocal critic of the hypothesis in the journal and in televised debates with Carl Sagan.

In a 2011 response to the more modern papers on the hypothesis, Russell Seitz published a comment in "Nature" challenging Alan Robock's claim that there has been no real scientific debate about the 'nuclear winter' concept. In 1986 Seitz also contends that many others are reluctant to speak out for fear of being stigmatized as "closet Dr. Strangeloves", physicist Freeman Dyson of Princeton for example stated "It's an absolutely atrocious piece of science, but I quite despair of setting the public record straight." According to the Rocky Mountain News, Stephen Schneider had been called a fascist by some disarmament supporters for having written his 1986 article "Nuclear Winter Reappraised." As MIT meteorologist Kerry Emanuel similarly wrote a review in "Nature" that the winter concept is “notorious for its lack of scientific integrity” due to the unrealistic estimates selected for the quantity of fuel likely to burn, the imprecise global circulation models used, and ends by stating that the evidence of other models, point to substantial scavenging of the smoke by rain. Emanuel also made an "interesting point" about questioning proponent's objectivity when it came to strong emotional or political issues that they hold.

William R. Cotton, Professor of Atmospheric Science at Colorado State University, specialist in cloud physics modeling and co-creator of the highly influential, and previously mentioned RAMS atmosphere model, had in the 1980s worked on soot rain-out models and supported the predictions made by his own and other nuclear winter models, but has since reversed this position according to a book co-authored by him in 2007, stating that, amongst other systematically examined assumptions, far more rain out/wet deposition of soot will occur than is assumed in modern papers on the subject: "We must wait for a new generation of GCMs to be implemented to examine potential consequences quantitatively" and revealing that in his experience, "nuclear winter was largely politically motivated from the beginning".

During the Cuban Missile Crisis, Fidel Castro and Che Guevara called on the USSR to launch a nuclear first strike against the US in the event of a US invasion of Cuba. In the 1980s Castro was pressuring the Kremlin to adopt a harder line against the US under President Ronald Reagan, even arguing for the potential use of nuclear weapons. As a direct result of this a Soviet official was dispatched to Cuba in 1985 with an entourage of "experts", who detailed the ecological effect on Cuba in the event of nuclear strikes on the United States. Soon after, the Soviet official recounts, Castro lost his prior "nuclear fever". In 2010 Alan Robock was summoned to Cuba to help Castro promote his new view that nuclear war would bring about Armageddon. Robock's 90 minute lecture was later aired on the nationwide state-controlled television station in the country.

However, according to Robock, insofar as getting US government attention and affecting nuclear policy, he has failed. In 2009, together with Owen Toon, he gave a talk to the United States Congress but nothing transpired from it and the then presidential science adviser, John Holdren, did not respond to their requests in 2009 or at the time of writing in 2011.
In a 2012 "Bulletin of the Atomic Scientists" feature, Robock and Toon, who had routinely mixed their disarmament advocacy into the conclusions of their "nuclear winter" papers, argue in the political realm that the hypothetical effects of nuclear winter necessitates that the doctrine they assume is active in Russia and US, "mutually assured destruction" (MAD) should instead be replaced with their own "self-assured destruction" (SAD) concept, because, regardless of whose cities burned, the effects of the resultant nuclear winter that they advocate, would be, in their view, catastrophic. In a similar vein, in 1989 Carl Sagan and Richard Turco wrote a policy implications paper that appeared in "AMBIO" that suggested that as nuclear winter is a "well-established prospect", both superpowers should jointly reduce their nuclear arsenals to "Canonical Deterrent Force" levels of 100–300 individual warheads each, such that in "the event of nuclear war [this] would minimize the likelihood of [extreme] nuclear winter."

An originally classified 1984 US interagency intelligence assessment states that in both the preceding 1970s and 80s, the Soviet and US military were already following the ""existing trends"" in warhead miniaturization, of higher accuracy and lower yield nuclear warheads, this is seen when assessing the most numerous physics packages in the US arsenal, which in the 1960s were the B28 and W31, however both quickly became less prominent with the 1970s mass production runs of the 50 Kt W68, the 100 Kt W76 and in the 1980s, with the B61. This trend towards miniaturization, enabled by advances in inertial guidance and accurate GPS navigation etc., was motivated by a multitude of factors, namely the desire to leverage the physics of equivalent megatonnage that miniaturization offered; of freeing up space to fit more MIRV warheads and decoys on each missile. Alongside the desire to still destroy hardened targets but while reducing the severity of fallout collateral damage depositing on neighboring, and potentially friendly, countries. As it relates to the likelihood of nuclear winter, the range of potential thermal radiation ignited fires was already reduced with miniaturization. For example, the most popular nuclear winter paper, the 1983 TTAPS paper, had described a 3000 Mt counterforce attack on ICBM sites with each individual warhead having approximately one Mt of energy; however not long after publication, Michael Altfeld of Michigan State University and political scientist Stephen Cimbala of Pennsylvania State University argued that the then already developed and deployed smaller, more accurate warheads (e.g. W76), together with lower detonation heights, could produce the same counterforce strike with a total of only 3 Mt of energy being expended. They continue that, "if" the nuclear winter models prove to be representative of reality, then far less climatic-cooling would occur, even if firestorm prone areas existed in the target list, as lower fusing heights such as surface bursts, would also limit the range of the burning thermal rays due to terrain masking and shadows cast by buildings, while also temporarily lofting far more localized fallout when compared to airburst fuzing – the standard mode of employment against un-hardened targets. This logic is similarly reflected in the originally classified 1984 "Interagency Intelligence assessment", which suggests that targeting planners would simply have to consider target combustibility along with yield, height of burst, timing and other factors to reduce the amount of smoke to safeguard against the potentiality of a nuclear winter. Therefore, as a consequence of attempting to limit the target fire hazard by reducing the range of thermal radiation with fuzing for surface and sub-surface bursts, this will result in a scenario where the far more concentrated, and therefore deadlier, "local" fallout that is generated following a surface burst forms, as opposed to the comparatively dilute "global" fallout created when nuclear weapons are fuzed in air burst mode.

Altfeld and Cimbala also argued that belief in the possibility of nuclear winter would actually make nuclear war more likely, contrary to the views of Sagan and others, because it would serve yet further motivation to follow the "existing trends", towards the development of more accurate, and even lower explosive yield, nuclear weapons. As the winter hypothesis suggests that the replacement of the then Cold War viewed strategic nuclear weapons in the multi-megaton yield range, with weapons of explosive yields closer to tactical nuclear weapons, such as the Robust Nuclear Earth Penetrator (RNEP), would safeguard against the nuclear winter potential. With the latter capabilities of the then, largely still conceptual RNEP, specifically cited by the influential nuclear warfare analyst Albert Wohlstetter. Tactical nuclear weapons, on the low end of the scale have yields that overlap with large conventional weapons, and are therefore often viewed "as blurring the distinction between conventional and nuclear weapons", making the prospect of using them "easier" in a conflict.

In an interview in 2000 with Mikhail Gorbachev (the leader of the Soviet Union from 1985–91), the following statement was posed to him: "In the 1980s, you warned about the unprecedented dangers of nuclear weapons and took very daring steps to reverse the arms race", with Gorbachev replying "Models made by Russian and American scientists showed that a nuclear war would result in a nuclear winter that would be extremely destructive to all life on Earth; the knowledge of that was a great stimulus to us, to people of honor and morality, to act in that situation."

However, a 1984 US Interagency Intelligence Assessment expresses a far more skeptical and cautious approach, stating that the hypothesis is not scientifically convincing. The report predicted that Soviet nuclear policy would be to maintain their strategic nuclear posture, such as their fielding of the high throw-weight SS-18 missile and they would merely attempt to exploit the hypothesis for propaganda purposes, such as directing scrutiny on the US portion of the nuclear arms race. Moreover, it goes on to express the belief that if Soviet officials did begin to take nuclear winter seriously, it would probably make them demand exceptionally high standards of scientific proof for the hypothesis, as the implications of it would undermine their military doctrine – a level of scientific proof which perhaps could not be met without field experimentation. The un-redacted portion of the document ends with the suggestion that substantial increases in Soviet Civil defense food stockpiles might be an early indicator that Nuclear Winter was beginning to influence Soviet upper echelon thinking.

In 1985 "Time" magazine noted "the suspicions of some Western scientists that the nuclear winter hypothesis was promoted by Moscow to give anti-nuclear groups in the U.S. and Europe some fresh ammunition against America's arms buildup."
In 1985, the United States Senate met to discuss the science and politics of nuclear winter. During the congressional hearing, the influential analyst Leon Gouré presented evidence that perhaps the Soviets have simply echoed Western reports rather than producing unique findings. Gouré hypothesized that Soviet research and discussions of nuclear war may serve only Soviet political agendas, rather than to reflect actual opinions of Soviet leadership.

In 1986, the Defense Nuclear Agency document "An update of Soviet research on and exploitation of Nuclear winter 1984–1986" charted the minimal [public domain] research contribution on, and Soviet propaganda usage of, the nuclear winter phenomenon.

There is some doubt as to when the Soviet Union began modelling fires and the atmospheric effects of nuclear war. Former Soviet intelligence officer Sergei Tretyakov claimed that, under the directions of Yuri Andropov, the KGB invented the concept of "nuclear winter" in order to stop the deployment of NATO Pershing II missiles. They are said to have distributed to peace groups, the environmental movement and the journal "Ambio" disinformation based on a faked "doomsday report" by the Soviet Academy of Sciences by Georgii Golitsyn, Nikita Moiseyev and Vladimir Alexandrov concerning the climatic effects of nuclear war. Although it is accepted that the Soviet Union exploited the nuclear winter hypothesis for propaganda purposes, Tretyakov's inherent claim that the KGB funnelled disinformation to "AMBIO", the journal in which Paul Crutzen and John Birks published the 1982 paper "Twilight at Noon", has not been corroborated . In an interview in 2009, conducted by the National Security Archive, Vitalii Nikolaevich Tsygichko; a Senior Analyst at the Soviet Academy of Sciences and military mathematical modeler, stated that Soviet military analysts were discussing the idea of "nuclear winter" years before U.S. scientists, although they did not use that exact term.

A number of solutions have been proposed to mitigate the potential harm of a nuclear winter if one appears inevitable; with the problem being attacked at both ends, from those focusing on preventing the growth of fires and therefore limiting the amount of smoke that reaches the stratosphere in the first place, and those focusing on food production with reduced sunlight, with the assumption that the very worst-case analysis results of the nuclear winter models prove accurate and no other mitigation strategies are fielded.

In a report from 1967, techniques included various methods of applying liquid nitrogen, dry ice, and water to nuclear-caused fires. The report considered attempting to stop the spread of fires by creating firebreaks by blasting combustible material out of an area, possibly even using nuclear weapons, along with the use of preventative Hazard Reduction Burns. According to the report, one of the most promising techniques investigated was initiation of rain from seeding of mass-fire thunderheads and other clouds passing over the developing, and then stable, firestorm.

Possibilities include natural-gas-digesting bacteria or mushrooms that can grow directly on wood without sunlight. Another example is that cellulosic biofuel production typically already creates sugar as an intermediate product.

The minimum annual global wheat storage is approximately 2 months. To feed everyone despite nuclear winter, years of food storage prior to the event has been proposed. While the suggested masses of preserved food would likely never get used as a nuclear winter is comparatively unlikely to occur, the stockpiling of food would have the positive result of ameliorating the effect of the far more frequent disruptions to regional food supplies caused by lower-level conflicts and droughts. There is however the danger that if a sudden rush to food stockpiling occurs without the buffering effect offered by Victory gardens etc., it may exacerbate current food security problems by elevating present food prices.

Despite the name "nuclear winter", nuclear events are not necessary to produce the modeled climatic effect. In an effort to find a quick and cheap solution to the global warming projection of at least 2 ˚C of surface warming as a result of the doubling in CO levels within the atmosphere, through solar radiation management (a form of climate engineering) the underlying nuclear winter effect has been looked at as perhaps holding potential. Besides the more common suggestion to inject sulfur compounds into the stratosphere to approximate the effects of a volcanic winter, the injection of other chemical species such as the release of a particular type of soot particle to create minor "nuclear winter" conditions, has been proposed by Paul Crutzen and others. According to the threshold "nuclear winter" computer models, if one to five teragrams of firestorm-generated soot is injected into the low stratosphere, it is modeled, through the anti-greenhouse effect, to heat the stratosphere but cool the lower troposphere and produce 1.25 °C cooling for two to three years; and after 10 years, average global temperatures would still be 0.5 °C lower than before the soot injection.

Similar climatic effects to "nuclear winter" followed historical supervolcano eruptions, which plumed sulfate aerosols high into the stratosphere, with this being known as a volcanic winter.

Similarly, extinction-level comet and asteroid impacts are also believed to have generated impact winters by the pulverization of massive amounts of fine rock dust. This pulverized rock can also produce "volcanic winter" effects, if sulfate-bearing rock is hit in the impact and lofted high into the air, and "nuclear winter" effects, with the heat of the heavier rock ejecta igniting regional and possibly even global forest firestorms.

This global "impact firestorms" hypothesis, initially supported by Wolbach, H. Jay Melosh and Owen Toon, suggests that as a result of massive impact events, the small sand-grain-sized ejecta fragments created can meteorically re-enter the atmosphere forming a hot blanket of global debris high in the air, potentially turning the entire sky red-hot for minutes to hours, and with that, burning the complete global inventory of above-ground carbonaceous material, including rain forests. This hypothesis is suggested as a means to explain the severity of the Cretaceous–Paleogene extinction event, as the earth impact of an asteroid about 10 km wide which precipitated the extinction is not regarded as sufficiently energetic to have caused the level of extinction from the initial impact's energy release alone.

The global firestorm winter, however, has been questioned in more recent years (2003–2013) by Claire Belcher, Tamara Goldin and Melosh, who had initially supported the hypothesis, with this re-evaluation being dubbed the "Cretaceous-Palaeogene firestorm debate" by Belcher. The issues raised by these scientists in the debate are the perceived low quantity of soot in the sediment beside the fine-grained iridium-rich asteroid dust layer, if the quantity of re-entering ejecta was perfectly global in blanketing the atmosphere, and if so, the duration and profile of the re-entry heating, whether it was a high thermal pulse of heat or the more prolonged and therefore more incendiary "oven" heating, and finally, how much the "self-shielding effect" from the first wave of now-cooled meteors in dark flight contributed to diminishing the total heat experienced on the ground from later waves of meteors.

In part due to the Cretaceous period being a high-atmospheric-oxygen era, with concentrations above that of the present day. Owen Toon et al. in 2013 were critical of the re-evaluations the hypothesis is undergoing.

It is difficult to successfully ascertain the percentage contribution of the soot in this period's geological sediment record from living plants and fossil fuels present at the time, in much the same manner that the fraction of the material ignited directly by the meteor impact is difficult to determine.






</doc>
<doc id="22172" url="https://en.wikipedia.org/wiki?curid=22172" title="Ode">
Ode

An ode (from ) is a type of lyrical stanza. It is an elaborately structured poem praising or glorifying an event or individual, describing nature intellectually as well as emotionally. A classic ode is structured in three major parts: the "strophe", the "antistrophe", and the "epode". Different forms such as the "homostrophic ode" and the "irregular ode" also exist.

Greek odes were originally poetic pieces performed with musical accompaniment. As time passed on, they gradually became known as personal lyrical compositions whether sung (with or without musical instruments) or merely recited (always with accompaniment). The primary instruments used were the aulos and the lyre (the latter was the most revered instrument to the ancient Greeks).

There are three typical forms of odes: the Pindaric, Horatian, and irregular. Pindaric odes follow the form and style of Pindar. Horatian odes follow conventions of Horace; the odes of Horace deliberately imitated the Greek lyricists such as Alcaeus and Anacreon. Irregular odes use rhyme, but not the three-part form of the Pindaric ode, nor the two- or four-line stanza of the Horatian ode. The ode is a lyric poem. It conveys exalted and inspired emotions. It is a lyric in an elaborate form, expressed in a language that is imaginative, dignified and sincere. Like the lyric, it is of Greek origin.

An English ode is a lyrical stanza in praise of, or dedicated to someone or something that captures the poet's interest or serves as an inspiration for the ode. The lyrics can be on various themes. The earliest odes in the English language, using the word in its strict form, were the "Epithalamium" and "Prothalamium" of Edmund Spenser.

In the 17th century, the most important original odes in English are by Abraham Cowley. These were iambic, but had irregular line length patterns and rhyme schemes. Cowley based the principle of his Pindariques on an apparent misunderstanding of Pindar's metrical practice but, nonetheless, others widely imitated his style, with notable success by John Dryden.

With Pindar's metre being better understood in the 18th century, the fashion for Pindaric odes faded, though there are notable actual Pindaric odes by Thomas Gray, "The Progress of Poesy" and "The Bard".

<poem>
There was a time when meadow, grove, and stream,
The earth, and every common sight,
To me did seem
Apparelled in celestial light,
The glory and the freshness of a dream.
It is not now as it hath been of yore;—
Turn wheresoe'er I may,
By night or day,
The things which I have seen I now can see no more...
Our birth is but a sleep and a forgetting:
The Soul that rises with us, our life's Star,
Hath had elsewhere its setting,
And cometh from afar:
Not in entire forgetfulness,
And not in utter nakedness,
But trailing clouds of glory do we come
From God, who is our home...
</poem>

Around 1800, William Wordsworth revived Cowley's Pindarick for one of his finest poems, the "" ode. Others also wrote odes: Samuel Taylor Coleridge, John Keats, and Percy Bysshe Shelley who wrote odes with regular stanza patterns. Shelley's "Ode to the West Wind", written in fourteen line terza rima stanzas, is a major poem in the form. Perhaps the greatest odes of the 19th century, however, were Keats's "Five Great Odes of 1819", which included "Ode to a Nightingale", "Ode on Melancholy", "Ode on a Grecian Urn", "Ode to Psyche", and "To Autumn". After Keats, there have been comparatively few major odes in English. One major exception is the fourth verse of the poem "For the Fallen" by Laurence Binyon, which is often known as "The Ode to the Fallen", or simply as "The Ode".

W.H. Auden also wrote "Ode", one of the most popular poems from his earlier career when he lived in London, in opposition to people's ignorance over the reality of war. In an interview, Auden once stated that he had intended to title the poem "My Silver Age" in mockery of the supposedly imperial Golden age, however chose "Ode" as it seemed to provide a more sensitive exploration of warfare.

"Ode on a Grecian Urn", while an ekphrasis, also functions as an ode to the artistic beauty the narrator observes. The English ode's most common rhyme scheme is ABABCDECDE.




</doc>
<doc id="22189" url="https://en.wikipedia.org/wiki?curid=22189" title="Temple of Olympian Zeus, Athens">
Temple of Olympian Zeus, Athens

The Temple of Olympian Zeus (, "Naós tou Olympíou Diós"), also known as the Olympieion or Columns of the Olympian Zeus, is a former colossal temple at the centre of the Greek capital Athens. It was dedicated to "Olympian" Zeus, a name originating from his position as head of the Olympian gods. Construction began in the 6th century BC during the rule of the Athenian tyrants, who envisaged building the greatest temple in the ancient world, but it was not completed until the reign of the Roman Emperor Hadrian in the 2nd century AD, some 638 years after the project had begun. During the Roman period the temple -that included 104 colossal columns- was renowned as the largest temple in Greece and housed one of the largest cult statues in the ancient world.

The temple's glory was short-lived, as it fell into disuse after being pillaged during a barbarian invasion in the 3rd century AD, just about a century after its completion. It was probably never repaired and was reduced to ruins thereafter. In the centuries after the fall of the Roman Empire, it was extensively quarried for building materials to supply building projects elsewhere in the city. Despite this, a substantial part of the temple remains today, notably sixteen of the original gigantic columns, and it continues to be part of a very important archaeological site of Greece

The temple is located approximately 500 m (1640 feet) south-east of the Acropolis, and about 700 m (2,300 feet) south of the center of Athens, Syntagma Square. Its foundations were laid on the site of an ancient outdoor sanctuary dedicated to Zeus. An earlier temple had stood there, constructed by the tyrant Peisistratus around 550 BC. The building was demolished after the death of Peisistratos and the construction of a colossal new Temple of Olympian Zeus was begun around 520 BC by his sons, Hippias and Hipparchos. 
They sought to surpass two famous contemporary temples, the Heraion of Samos and the Temple of Artemis at Ephesus, which was one of the Seven Wonders of the Ancient World. Designed by the architects Antistates, Callaeschrus, Antimachides and Pornius, the Temple of Olympian Zeus was intended to be built of local limestone in the Doric style on a colossal platform measuring 41 m (134.5 feet) by 108 m (353.5 feet). It was to be flanked by a double colonnade of eight columns across the front and back and twenty-one on the flanks, surrounding the cella. 

The work was abandoned when the tyranny was overthrown and Hippias was expelled in 510 BC. Only the platform and some elements of the columns had been completed by this point, and the temple remained in this state for 336 years. The temple was left unfinished during the years of Athenian democracy, apparently because the Greeks thought it was hubris to build on such a scale. In the treatise "Politics", Aristotle cited the temple as an example of how tyrannies engaged the populace in great works for the state (like a white elephant) and left them no time, energy or means to rebel.

It was not until 174 BC that the Seleucid king Antiochus IV Epiphanes, who presented himself as the earthly embodiment of Zeus, revived the project and placed the Roman architect Decimus Cossutius in charge. The design was changed to have three rows of eight columns across the front and back of the temple and a double row of twenty on the flanks, for a total of 104 columns. The columns would stand 17 m (55.5 feet) high and 2 m (6.5 ft) in diameter. The building material was changed to the expensive but high-quality Pentelic marble and the order was changed from Doric to Corinthian, marking the first time that this order had been used on the exterior of a major temple. However, the project ground to a halt again in 164 BC with the death of Antiochus. The temple was still only half-finished by this stage.
Serious damage was inflicted on the partly built temple by Lucius Cornelius Sulla's sack of Athens in 86 BC. While looting the city, Sulla seized some of the incomplete columns and transported them back to Rome, where they were re-used in the Temple of Jupiter on the Capitoline Hill. A half-hearted attempt was made to complete the temple during Augustus' reign as the first Roman emperor, but it was not until the accession of Hadrian in the 2nd century AD that the project was finally completed around 638 years after it had begun. 

In 124-125 AD, when the strongly Philhellene Hadrian visited Athens, a massive building programme was begun that included the completion of the Temple of Olympian Zeus. A walled marble-paved precinct was constructed around the temple, making it a central focus of the ancient city. Cossutius's design was used with few changes and the temple was formally dedicated by Hadrian in 132, who took the title of "Panhellenios" in commemoration of the occasion. The temple and the surrounding precinct were adorned with numerous statues depicting Hadrian, the gods and personifications of the Roman provinces. A colossal statue of Hadrian was raised behind the building by the people of Athens in honour of the emperor's generosity. An equally colossal chryselephantine statue of Zeus occupied the cella of the temple. The statue's form of construction was unusual, as the use of chryselephantine was by this time regarded as archaic. It has been suggested that Hadrian was deliberately imitating Phidias' famous statue of Athena Parthenos in the Parthenon, seeking to draw attention to the temple and himself by doing so.

The Temple of Olympian Zeus was badly damaged during the Herulian sack of Athens in 267. It is unlikely to have been repaired, given the extent of the damage to the rest of the city. Assuming that it was not abandoned it would certainly have been closed down in 425 by the Christian emperor Theodosius II when he prohibited the worship of the old Roman and Greek gods during the persecution of pagans in the late Roman Empire. Material from the (presumably now ruined) building was incorporated into a basilica constructed nearby during the 5th or 6th century.

Over the following centuries, the temple was systematically quarried to provide building materials and material for the houses and churches of medieval Athens. By the end of the Byzantine period, it had been almost totally destroyed; when Ciriaco de' Pizzicolli (Cyriacus of Ancona) visited Athens in 1436 he found only 21 of the original 104 columns still standing. The fate of one of the columns is recorded by a Greek inscription on one of the surviving columns, which states that "on 27 April 1759 he pulled down the column". This refers to the Turkish governor of Athens, Tzisdarakis, who is recorded by a chronicler as having "destroyed one of Hadrian's columns with gunpowder" in order to re-use the marble to make plaster for the mosque that he was building in the Monastiraki district of the city. During the Ottoman period the temple was known to the Greeks as the Palace of Hadrian, while the Turks called it the Palace of Belkis, from a Turkish legend that the temple had been the residence of Solomon's wife.

Fifteen columns remain standing today and a sixteenth column lies on the ground where it fell during a storm in 1852. Nothing remains of the cella or the great statue that it once housed.

The temple was excavated in 1889-1896 by Francis Penrose of the British School in Athens (who also played a leading role in the restoration of the Parthenon), in 1922 by the German archaeologist Gabriel Welter and in the 1960s by Greek archaeologists led by Ioannes Travlos. The temple, along with the surrounding ruins of other ancient structures, is a historical precinct administered by Ephorate of Antiquites of the Greek Interior Ministry.

On 21 January 2007, a group of Greek pagans held a ceremony honoring Zeus on the grounds of the temple. The event was organized by Ellinais, an organization which won a court battle to obtain recognition for Ancient Greek religious practices in the fall of 2006.





</doc>
<doc id="22190" url="https://en.wikipedia.org/wiki?curid=22190" title="Organic electronics">
Organic electronics

Organic electronics is a field of materials science concerning the design, synthesis, characterization, and application of organic small molecules or polymers that show desirable electronic properties such as conductivity. Unlike conventional inorganic conductors and semiconductors, organic electronic materials are constructed from organic (carbon-based) small molecules or polymers using synthetic strategies developed in the context of organic and polymer chemistry. One of the promised benefits of organic electronics is their potential low cost compared to traditional inorganic electronics. Attractive properties of polymeric conductors include their electrical conductivity that can be varied by the concentrations of dopants. Relative to metals, they have mechanical flexibility. Some have high thermal stability.

One class of materials of interest in organic electronics are electrical conductive, i.e. substances that can transmit electrical charges with low resistivity. Traditionally, conductive materials are inorganic. Classical (and still technologically dominant) conductive materials are metals such as copper and aluminum as well as many alloys.

The earliest reported organic conductive material, polyaniline, was described by Henry Letheby in 1862. Work on other polymeric organic materials began in earnest in the 1960s, A high conductivity of 1 S/cm (S = Siemens) was reported in 1963 for a derivative of tetraiodopyrrole. In 1977, it was discovered that polyacetylene can be oxidized with halogens to produce conducting materials from either insulating or semiconducting materials. The 2000 Nobel Prize in Chemistry was awarded to Alan J. Heeger, Alan G. MacDiarmid, and Hideki Shirakawa jointly for their work on conductive polymers. These and many other workers identified large families of electrically conducting polymers including polythiophene, polyphenylene sulfide, and others.

In the 1950s, a second class of electric conductors were discovered based on charge-transfer salts. Early examples were derivatives of polycyclic aromatic compounds. For example, pyrene was shown to form semiconducting charge-transfer complex salts with halogens. In 1972, researchers found metallic conductivity(conductivity comparable to a metal) in the charge-transfer complex TTF-TCNQ.

Conductive plastics have undergone development for applications in industry. In 1987, the first organic diode was produced at Eastman Kodak by Ching W. Tang and Steven Van Slyke.

The initial characterization of the basic properties of polymer light emitting diodes, demonstrating that the light emission phenomenon was injection electroluminescence and that the frequency response was sufficiently fast to permit video display applications, was reported by Bradley, Burroughes, Friend, et al. in a 1990 Nature paper. Moving from molecular to macromolecular materials solved the problems previously encountered with the long-term stability of the organic films and enabled high-quality films to be easily made. Subsequent research developed multilayer polymers and the new field of plastic electronics and organic light-emitting diodes (OLED) research and device production grew rapidly.

Organic conductive materials can be grouped into two main classes: conductive polymers and conductive molecular solids and salts.

Semiconducting small molecules include polycyclic aromatic compounds such as pentacene and rubrene.

Conductive polymers are often typically intrinsically conductive or at least semiconductors. They sometimes show mechanical properties comparable to those of conventional organic polymers. Both organic synthesis and advanced dispersion techniques can be used to tune the electrical properties of conductive polymers, unlike typical inorganic conductors. The most well-studied class of conductive polymers include polyacetylene, polypyrrole, polyaniline, and their copolymers. Poly(p-phenylene vinylene) and its derivatives are used for electroluminescent semiconducting polymers. Poly(3-alkythiophenes) are also a typical material for use in solar cells and transistors.

An OLED (organic light-emitting diode) consists of a thin film of organic material that emits light under stimulation by an electric current. A typical OLED consists of an anode, a cathode, OLED organic material and a conductive layer.

André Bernanose was the first person to observe electroluminescence in organic materials, and Ching W. Tang, reported fabrication of an OLED device in 1987. The OLED device incorporated a double-layer structure motif consisting of separate hole transporting and electron-transporting layers, with light emission taking place in between the two layers. Their discovery opened a new era of current OLED research and device design.

OLED organic materials can be divided into two major families: small-molecule-based and polymer-based. Small molecule OLEDs (SM-OLEDs) include organometallic chelates(Alq3), fluorescent and phosphorescent dyes, and conjugated dendrimers. Fluorescent dyes can be selected according to the desired range of emission wavelengths; compounds like perylene and rubrene are often used. Very recently, Dr. Kim J. et al. at University of Michigan reported a pure organic light emitting crystal, Br6A, by modifying its halogen bonding, they succeeded in tuning the phosphorescence to different wavelengths including green, blue and red. By modifying the structure of Br6A, scientists are attempting to achieve a next generation organic light emitting diode. Devices based on small molecules are usually fabricated by thermal evaporation under vacuum. While this method enables the formation of well-controlled homogeneous film; is hampered by high cost and limited scalability.
Polymer light-emitting diodes (PLEDs), similar to SM-OLED, emit light under an applied electric current. Polymer-based OLEDs are generally more efficient than SM-OLEDs requiring a comparatively lower amount of energy to produce the same luminescence. Common polymers used in PLEDs include derivatives of poly(p-phenylene vinylene) and polyfluorene. The emitted color can be tuned by substitution of different side chains onto the polymer backbone or modifying the stability of the polymer. In contrast to SM-OLEDs, polymer-based OLEDs cannot be fabricated through vacuum evaporation, and must instead be processed using solution-based techniques. Compared to thermal evaporation, solution based methods are more suited to creating films with large dimensions. Zhenan Bao. et al. at Stanford University reported a novel way to construct large-area organic semiconductor thin films using aligned single crystalline domains.

An Organic field-effect transistor is a field-effect transistor utilizing organic molecules or polymers as the active semiconducting layer. A field-effect transistor (FET) is any semiconductor material that utilizes electric field to control the shape of a channel of one type of charge carrier, thereby changing its conductivity. Two major classes of FET are n-type and p-type semiconductor, classified according to the charge type carried. In the case of organic FETs (OFETs), p-type OFET compounds are generally more stable than n-type due to the susceptibility of the latter to oxidative damage.

J.E. Lilienfeld first proposed the field-effect transistor in 1930, but the first OFET was not reported until 1987, when Koezuka et al. constructed one using Polythiophene which shows extremely high conductivity. Other conductive polymers have been shown to act as semiconductors, and newly synthesized and characterized compounds are reported weekly in prominent research journals. Many review articles exist documenting the development of these materials.

Like OLEDs, OFETs can be classified into small-molecule and polymer-based system. Charge transport in OFETs can be quantified using a measure called carrier mobility; currently, rubrene-based OFETs show the highest carrier mobility of 20–40 cm/(V·s). Another popular OFET material is Pentacene. Due to its low solubility in most organic solvents, it's difficult to fabricate thin film transistors (TFTs) from pentacene itself using conventional spin-cast or, dip coating methods, but this obstacle can be overcome by using the derivative TIPS-pentacene. Current research focuses more on thin-film transistor (TFT) model, which eliminates the usage of conductive materials. Very recently, two studies conducted by Dr. Bao Z. et al. and Dr. Kim J. et al. demonstrated control over the formation of designed thin-film transistors. By controlling the formation of crystalline TFT, it is possible to create an aligned (as opposed to randomly ordered) charge transport pathway, resulting in enhanced charge mobility.

Organic solar cells could cut the cost of solar power by making use of inexpensive organic polymers rather than the expensive crystalline silicon used in most solar cells. What's more, the polymers can be processed using low-cost equipment such as ink-jet printers or coating equipment employed to make photographic film, which reduces both capital and operating costs compared with conventional solar-cell manufacturing.

Silicon thin-film solar cells on flexible substrates allow a significant cost reduction of large-area photovoltaics for several reasons:


Inexpensive polymeric substrates like polyethylene terephthalate (PET) or polycarbonate (PC) have the potential for further cost reduction in photovoltaics. Protomorphous solar cells prove to be a promising concept for efficient and low-cost photovoltaics on cheap and flexible substrates for large-area production as well as small and mobile applications.

One advantage of printed electronics is that different electrical and electronic components can be printed on top of each other, saving space and increasing reliability and sometimes they are all transparent. One ink must not damage another, and low temperature annealing is vital if low-cost flexible materials such as paper and plastic film are to be used. There is much sophisticated engineering and chemistry involved here, with iTi, Pixdro, Asahi Kasei, Merck & Co.|Merck, BASF, HC Starck, Hitachi Chemical and Frontier Carbon Corporation among the leaders.
Electronic devices based on organic compounds are now widely used, with many new products under development. Sony reported the first full-color, video-rate, flexible, plastic display made purely of organic materials; television screen based on OLED materials; biodegradable electronics based on organic compound and low-cost organic solar cell are also available.

There are important differences between the processing of small molecule organic semiconductors and semiconducting polymers. Small molecule semiconductors are quite often insoluble and typically require deposition via vacuum sublimation. While usually thin films of soluble conjugated polymers. Devices based on conductive polymers can be prepared by solution processing methods. Both solution processing and vacuum based methods produce amorphous and polycrystalline films with variable degree of disorder. "Wet" coating techniques require polymers to be dissolved in a volatile solvent, filtered and deposited onto a substrate. Common examples of solvent-based coating techniques include drop casting, spin-coating, doctor-blading, inkjet printing and screen printing. Spin-coating is a widely used technique for small area thin film production. It may result in a high degree of material loss. The doctor-blade technique results in a minimal material loss and was primarily developed for large area thin film production. Vacuum based thermal deposition of small molecules requires evaporation of molecules from a hot source. The molecules are then transported through vacuum onto a substrate. The process of condensing these molecules on the substrate surface results in thin film formation. Wet coating techniques can in some cases be applied to small molecules depending on their solubility.

Compared to conventional inorganic solar cell, organic solar cells have the advantage of lower fabrication cost. An organic solar cell is a device that uses organic electronics to convert light into electricity. Organic solar cells utilize organic photovoltaic materials, organic semiconductor diodes that convert light into electricity. Figure to the right shows five commonly used organic photovoltaic materials. Electrons in these organic molecules can be delocalized in a delocalized π orbital with a corresponding π* antibonding orbital. The difference in energy between the π orbital, or highest occupied molecular orbital(HOMO), and π* orbital, or lowest unoccupied molecular orbital(LUMO) is called the band gap of organic photovoltaic materials. Typically, the band gap lies in the range of 1-4eV.

The difference in the band gap of organic photovoltaic materials leads to different chemical structures and forms of organic solar cells. Different forms of solar cells includes single-layer organic photovoltaic cells, bilayer organic photovoltaic cells and heterojunction photovoltaic cells. However, all three of these types of solar cells share the approach of sandwiching the organic electronic layer between two metallic conductors, typically indium tin oxide.
An organic field-effect transistor device consists of three major components: the source, the drain and the gate. Generally, a field-effect transistor has two plates, source in contact with drain and the gate respectively, working as conducting channel. The electrons move from source to the drain, and the gate serves to control the electrons’ movement from source to drain. Different types of FETs are designed based on carrier properties. Thin film transistor (TFT), among them, is an easy fabricating one. In a thin film transistor, the source and drain are made by directly depositing a thin layer of semiconductor followed by a thin film of insulator between semiconductor and the metal gate contact. Such a thin film is made by either thermal evaporation, or simply spins coating. In a TFT device, there is no carrier movement between the source and drain. After applying a positive charge, accumulation of electrons on the interface cause bending of the semiconductor and ultimately lowers the conduction band with regards to the Fermi-level of the semiconductor. Finally, a highly conductive channel is formed at the interface.

Conductive polymers are lighter, more flexible, and less expensive than inorganic conductors. This makes them a desirable alternative in many applications. It also creates the possibility of new applications that would be impossible using copper or silicon.

Organic electronics not only includes organic semiconductors, but also organic dielectrics, conductors and light emitters.

New applications include smart windows and electronic paper. Conductive polymers are expected to play an important role in the emerging science of molecular computers.




</doc>
<doc id="22194" url="https://en.wikipedia.org/wiki?curid=22194" title="Operating system">
Operating system

An operating system (OS) is system software that manages computer hardware and software resources and provides common services for computer programs.

Time-sharing operating systems schedule tasks for efficient use of the system and may also include accounting software for cost allocation of processor time, mass storage, printing, and other resources.

For hardware functions such as input and output and memory allocation, the operating system acts as an intermediary between programs and the computer hardware, although the application code is usually executed directly by the hardware and frequently makes system calls to an OS function or is interrupted by it. Operating systems are found on many devices that contain a computer from cellular phones and video game consoles to web servers and supercomputers.

The dominant desktop operating system is Microsoft Windows with a market share of around 82.74%. macOS by Apple Inc. is in second place (13.23%), and the varieties of Linux are collectively in third place (1.57%). In the mobile (smartphone and tablet combined) sector, use in 2017 is up to 70% of Google's Android and according to third quarter 2016 data, Android on smartphones is dominant with 87.5 percent and a growth rate 10.3 percent per year, followed by Apple's iOS with 12.1 percent and a per year decrease in market share of 5.2 percent, while other operating systems amount to just 0.3 percent. Linux distributions are dominant in the server and supercomputing sectors. Other specialized classes of operating systems, such as embedded and real-time systems, exist for many applications.

A single-tasking system can only run one program at a time, while a multi-tasking operating system allows more than one program to be running in concurrency. This is achieved by time-sharing, where the available processor time is divided between multiple processes. These processes are each interrupted repeatedly in time slices by a task-scheduling subsystem of the operating system. Multi-tasking may be characterized in preemptive and co-operative types. In preemptive multitasking, the operating system slices the CPU time and dedicates a slot to each of the programs. Unix-like operating systems, such as Solaris and Linux—as well as non-Unix-like, such as AmigaOS—support preemptive multitasking. Cooperative multitasking is achieved by relying on each process to provide time to the other processes in a defined manner. 16-bit versions of Microsoft Windows used cooperative multi-tasking. 32-bit versions of both Windows NT and Win9x, used preemptive multi-tasking.

Single-user operating systems have no facilities to distinguish users, but may allow multiple programs to run in tandem. A multi-user operating system extends the basic concept of multi-tasking with facilities that identify processes and resources, such as disk space, belonging to multiple users, and the system permits multiple users to interact with the system at the same time. Time-sharing operating systems schedule tasks for efficient use of the system and may also include accounting software for cost allocation of processor time, mass storage, printing, and other resources to multiple users.

A distributed operating system manages a group of distinct computers and makes them appear to be a single computer. The development of networked computers that could be linked and communicate with each other gave rise to distributed computing. Distributed computations are carried out on more than one machine. When computers in a group work in cooperation, they form a distributed system.

In an OS, distributed and cloud computing context, templating refers to creating a single virtual machine image as a guest operating system, then saving it as a tool for multiple running virtual machines. The technique is used both in virtualization and cloud computing management, and is common in large server warehouses.

Embedded operating systems are designed to be used in embedded computer systems. They are designed to operate on small machines like PDAs with less autonomy. They are able to operate with a limited number of resources. They are very compact and extremely efficient by design. Windows CE and Minix 3 are some examples of embedded operating systems.

A real-time operating system is an operating system that guarantees to process events or data by a specific moment in time. A real-time operating system may be single- or multi-tasking, but when multitasking, it uses specialized scheduling algorithms so that a deterministic nature of behavior is achieved. An event-driven system switches between tasks based on their priorities or external events while time-sharing operating systems switch tasks based on clock interrupts

A library operating system is one in which the services that a typical operating system provides, such as networking, are provided in the form of libraries and composed with the application and configuration code to construct a unikernel: a specialized, single address space, machine image that can be deployed to cloud or embedded environments.

Early computers were built to perform a series of single tasks, like a calculator. Basic operating system features were developed in the 1950s, such as resident monitor functions that could automatically run different programs in succession to speed up processing. Operating systems did not exist in their modern and more complex forms until the early 1960s. Hardware features were added, that enabled use of runtime libraries, interrupts, and parallel processing. When personal computers became popular in the 1980s, operating systems were made for them similar in concept to those used on larger computers.

In the 1940s, the earliest electronic digital systems had no operating systems. Electronic systems of this time were programmed on rows of mechanical switches or by jumper wires on plug boards. These were special-purpose systems that, for example, generated ballistics tables for the military or controlled the printing of payroll checks from data on punched paper cards. After programmable general purpose computers were invented, machine languages (consisting of strings of the binary digits 0 and 1 on punched paper tape) were introduced that sped up the programming process (Stern, 1981).
In the early 1950s, a computer could execute only one program at a time. Each user had sole use of the computer for a limited period of time and would arrive at a scheduled time with program and data on punched paper cards or punched tape. The program would be loaded into the machine, and the machine would be set to work until the program completed or crashed. Programs could generally be debugged via a front panel using toggle switches and panel lights. It is said that Alan Turing was a master of this on the early Manchester Mark 1 machine, and he was already deriving the primitive conception of an operating system from the principles of the universal Turing machine.

Later machines came with libraries of programs, which would be linked to a user's program to assist in operations such as input and output and generating computer code from human-readable symbolic code. This was the genesis of the modern-day operating system. However, machines still ran a single job at a time. At Cambridge University in England the job queue was at one time a washing line (clothes line) from which tapes were hung with different colored clothes-pegs to indicate job-priority.

An improvement was the Atlas Supervisor introduced with the Manchester Atlas commissioned in 1962, "considered by many to be the first recognisable modern operating system". Brinch Hansen described it as "the most significant breakthrough in the history of operating systems."

Through the 1950s, many major features were pioneered in the field of operating systems on mainframe computers, including batch processing, input/output interrupt, buffering, multitasking, spooling, runtime libraries, link-loading, and programs for sorting records in files. These features were included or not included in application software at the option of application programmers, rather than in a separate operating system used by all applications. In 1959, the SHARE Operating System was released as an integrated utility for the IBM 704, and later in the 709 and 7090 mainframes, although it was quickly supplanted by IBSYS/IBJOB on the 709, 7090 and 7094.

During the 1960s, IBM's OS/360 introduced the concept of a single OS spanning an entire product line, which was crucial for the success of the System/360 machines. IBM's current mainframe operating systems are distant descendants of this original system and applications written for OS/360 can still be run on modern machines.

OS/360 also pioneered the concept that the operating system keeps track of all of the system resources that are used, including program and data space allocation in main memory and file space in secondary storage, and file locking during update. When the process is terminated for any reason, all of these resources are re-claimed by the operating system.

The alternative CP-67 system for the S/360-67 started a whole line of IBM operating systems focused on the concept of virtual machines. Other operating systems used on IBM S/360 series mainframes included systems developed by IBM: COS/360 (Compatibility Operating System), DOS/360 (Disk Operating System), TSS/360 (Time Sharing System), TOS/360 (Tape Operating System), BOS/360 (Basic Operating System), and ACP (Airline Control Program), as well as a few non-IBM systems: MTS (Michigan Terminal System), MUSIC (Multi-User System for Interactive Computing), and ORVYL (Stanford Timesharing System).

Control Data Corporation developed the SCOPE operating system in the 1960s, for batch processing. In cooperation with the University of Minnesota, the Kronos and later the NOS operating systems were developed during the 1970s, which supported simultaneous batch and timesharing use. Like many commercial timesharing systems, its interface was an extension of the Dartmouth BASIC operating systems, one of the pioneering efforts in timesharing and programming languages. In the late 1970s, Control Data and the University of Illinois developed the PLATO operating system, which used plasma panel displays and long-distance time sharing networks. Plato was remarkably innovative for its time, featuring real-time chat, and multi-user graphical games.

In 1961, Burroughs Corporation introduced the B5000 with the MCP, (Master Control Program) operating system. The B5000 was a stack machine designed to exclusively support high-level languages with no machine language or assembler, and indeed the MCP was the first OS to be written exclusively in a high-level language ESPOL, a dialect of ALGOL. MCP also introduced many other ground-breaking innovations, such as being the first commercial implementation of virtual memory. During development of the AS/400, IBM made an approach to Burroughs to license MCP to run on the AS/400 hardware. This proposal was declined by Burroughs management to protect its existing hardware production. MCP is still in use today in the Unisys ClearPath/MCP line of computers.

UNIVAC, the first commercial computer manufacturer, produced a series of EXEC operating systems. Like all early main-frame systems, this batch-oriented system managed magnetic drums, disks, card readers and line printers. In the 1970s, UNIVAC produced the Real-Time Basic (RTB) system to support large-scale time sharing, also patterned after the Dartmouth BC system.

General Electric and MIT developed General Electric Comprehensive Operating Supervisor (GECOS), which introduced the concept of ringed security privilege levels. After acquisition by Honeywell it was renamed General Comprehensive Operating System (GCOS).

Digital Equipment Corporation developed many operating systems for its various computer lines, including TOPS-10 and TOPS-20 time sharing systems for the 36-bit PDP-10 class systems. Before the widespread use of UNIX, TOPS-10 was a particularly popular system in universities, and in the early ARPANET community. RT-11 was a single-user real-time OS for the PDP-11 class minicomputer, and RSX-11 was the corresponding multi-user OS. 

From the late 1960s through the late 1970s, several hardware capabilities evolved that allowed similar or ported software to run on more than one system. Early systems had utilized microprogramming to implement features on their systems in order to permit different underlying computer architectures to appear to be the same as others in a series. In fact, most 360s after the 360/40 (except the 360/165 and 360/168) were microprogrammed implementations.

The enormous investment in software for these systems made since the 1960s caused most of the original computer manufacturers to continue to develop compatible operating systems along with the hardware. Notable supported mainframe operating systems include:


The first microcomputers did not have the capacity or need for the elaborate operating systems that had been developed for mainframes and minis; minimalistic operating systems were developed, often loaded from ROM and known as "monitors". One notable early disk operating system was CP/M, which was supported on many early microcomputers and was closely imitated by Microsoft's MS-DOS, which became widely popular as the operating system chosen for the IBM PC (IBM's version of it was called IBM DOS or PC DOS). In the 1980s, Apple Computer Inc. (now Apple Inc.) abandoned its popular Apple II series of microcomputers to introduce the Apple Macintosh computer with an innovative graphical user interface (GUI) to the Mac OS.

The introduction of the Intel 80386 CPU chip in October 1985, with 32-bit architecture and paging capabilities, provided personal computers with the ability to run multitasking operating systems like those of earlier minicomputers and mainframes. Microsoft responded to this progress by hiring Dave Cutler, who had developed the VMS operating system for Digital Equipment Corporation. He would lead the development of the Windows NT operating system, which continues to serve as the basis for Microsoft's operating systems line. Steve Jobs, a co-founder of Apple Inc., started NeXT Computer Inc., which developed the NEXTSTEP operating system. NEXTSTEP would later be acquired by Apple Inc. and used, along with code from FreeBSD as the core of Mac OS X (macOS after latest name change).

The GNU Project was started by activist and programmer Richard Stallman with the goal of creating a complete free software replacement to the proprietary UNIX operating system. While the project was highly successful in duplicating the functionality of various parts of UNIX, development of the GNU Hurd kernel proved to be unproductive. In 1991, Finnish computer science student Linus Torvalds, with cooperation from volunteers collaborating over the Internet, released the first version of the Linux kernel. It was soon merged with the GNU user space components and system software to form a complete operating system. Since then, the combination of the two major components has usually been referred to as simply "Linux" by the software industry, a naming convention that Stallman and the Free Software Foundation remain opposed to, preferring the name GNU/Linux. The Berkeley Software Distribution, known as BSD, is the UNIX derivative distributed by the University of California, Berkeley, starting in the 1970s. Freely distributed and ported to many minicomputers, it eventually also gained a following for use on PCs, mainly as FreeBSD, NetBSD and OpenBSD.

Unix was originally written in assembly language. Ken Thompson wrote B, mainly based on BCPL, based on his experience in the MULTICS project. B was replaced by C, and Unix, rewritten in C, developed into a large, complex family of inter-related operating systems which have been influential in every modern operating system (see History).

The "Unix-like" family is a diverse group of operating systems, with several major sub-categories including System V, BSD, and Linux. The name "UNIX" is a trademark of The Open Group which licenses it for use with any operating system that has been shown to conform to their definitions. "UNIX-like" is commonly used to refer to the large set of operating systems which resemble the original UNIX.

Unix-like systems run on a wide variety of computer architectures. They are used heavily for servers in business, as well as workstations in academic and engineering environments. Free UNIX variants, such as Linux and BSD, are popular in these areas.

Four operating systems are certified by The Open Group (holder of the Unix trademark) as Unix. HP's HP-UX and IBM's AIX are both descendants of the original System V Unix and are designed to run only on their respective vendor's hardware. In contrast, Sun Microsystems's Solaris can run on multiple types of hardware, including x86 and Sparc servers, and PCs. Apple's macOS, a replacement for Apple's earlier (non-Unix) Mac OS, is a hybrid kernel-based BSD variant derived from NeXTSTEP, Mach, and FreeBSD.

Unix interoperability was sought by establishing the POSIX standard. The POSIX standard can be applied to any operating system, although it was originally created for various Unix variants.

A subgroup of the Unix family is the Berkeley Software Distribution family, which includes FreeBSD, NetBSD, and OpenBSD. These operating systems are most commonly found on webservers, although they can also function as a personal computer OS. The Internet owes much of its existence to BSD, as many of the protocols now commonly used by computers to connect, send and receive data over a network were widely implemented and refined in BSD. The World Wide Web was also first demonstrated on a number of computers running an OS based on BSD called NeXTSTEP.

In 1974, University of California, Berkeley installed its first Unix system. Over time, students and staff in the computer science department there began adding new programs to make things easier, such as text editors. When Berkeley received new VAX computers in 1978 with Unix installed, the school's undergraduates modified Unix even more in order to take advantage of the computer's hardware possibilities. The Defense Advanced Research Projects Agency of the US Department of Defense took interest, and decided to fund the project. Many schools, corporations, and government organizations took notice and started to use Berkeley's version of Unix instead of the official one distributed by AT&T.

Steve Jobs, upon leaving Apple Inc. in 1985, formed NeXT Inc., a company that manufactured high-end computers running on a variation of BSD called NeXTSTEP. One of these computers was used by Tim Berners-Lee as the first webserver to create the World Wide Web.

Developers like Keith Bostic encouraged the project to replace any non-free code that originated with Bell Labs. Once this was done, however, AT&T sued. After two years of legal disputes, the BSD project spawned a number of free derivatives, such as NetBSD and FreeBSD (both in 1993), and OpenBSD (from NetBSD in 1995).

macOS (formerly "Mac OS X" and later "OS X") is a line of open core graphical operating systems developed, marketed, and sold by Apple Inc., the latest of which is pre-loaded on all currently shipping Macintosh computers. macOS is the successor to the original classic Mac OS, which had been Apple's primary operating system since 1984. Unlike its predecessor, macOS is a UNIX operating system built on technology that had been developed at NeXT through the second half of the 1980s and up until Apple purchased the company in early 1997.
The operating system was first released in 1999 as Mac OS X Server 1.0, followed in March 2001 by a client version (Mac OS X v10.0 "Cheetah"). Since then, six more distinct "client" and "server" editions of macOS have been released, until the two were merged in OS X 10.7 "Lion".

Prior to its merging with macOS, the server edition macOS Server was architecturally identical to its desktop counterpart and usually ran on Apple's line of Macintosh server hardware. macOS Server included work group management and administration software tools that provide simplified access to key network services, including a mail transfer agent, a Samba server, an LDAP server, a domain name server, and others. With Mac OS X v10.7 Lion, all server aspects of Mac OS X Server have been integrated into the client version and the product re-branded as "OS X" (dropping "Mac" from the name). The server tools are now offered as an application.

The Linux kernel originated in 1991, as a project of Linus Torvalds, while a university student in Finland. He posted information about his project on a newsgroup for computer students and programmers, and received support and assistance from volunteers who succeeded in creating a complete and functional kernel.

Linux is Unix-like, but was developed without any Unix code, unlike BSD and its variants. Because of its open license model, the Linux kernel code is available for study and modification, which resulted in its use on a wide range of computing machinery from supercomputers to smart-watches. Although estimates suggest that Linux is used on only 1.82% of all "desktop" (or laptop) PCs, it has been widely adopted for use in servers and embedded systems such as cell phones. Linux has superseded Unix on many platforms and is used on most supercomputers including the top 385. Many of the same computers are also on Green500 (but in different order), and Linux runs on the top 10. Linux is also commonly used on other small energy-efficient computers, such as smartphones and smartwatches. The Linux kernel is used in some popular distributions, such as Red Hat, Debian, Ubuntu, Linux Mint and Google's Android, Chrome OS, and Chromium OS.

Microsoft Windows is a family of proprietary operating systems designed by Microsoft Corporation and primarily targeted to Intel architecture based computers, with an estimated 88.9 percent total usage share on Web connected computers. The latest version is Windows 10.

In 2011, Windows 7 overtook Windows XP as most common version in use.

Microsoft Windows was first released in 1985, as an operating environment running on top of MS-DOS, which was the standard operating system shipped on most Intel architecture personal computers at the time. In 1995, Windows 95 was released which only used MS-DOS as a bootstrap. For backwards compatibility, Win9x could run real-mode MS-DOS and 16-bit Windows 3.x drivers. Windows ME, released in 2000, was the last version in the Win9x family. Later versions have all been based on the Windows NT kernel. Current client versions of Windows run on IA-32, x86-64 and 32-bit ARM microprocessors. In addition Itanium is still supported in older server version Windows Server 2008 R2. In the past, Windows NT supported additional architectures.

Server editions of Windows are widely used. In recent years, Microsoft has expended significant capital in an effort to promote the use of Windows as a server operating system. However, Windows' usage on servers is not as widespread as on personal computers as Windows competes against Linux and BSD for server market share.

ReactOS is a Windows-alternative operating system, which is being developed on the principles of Windows without using any of Microsoft's code.

There have been many operating systems that were significant in their day but are no longer so, such as AmigaOS; OS/2 from IBM and Microsoft; classic Mac OS, the non-Unix precursor to Apple's macOS; BeOS; XTS-300; RISC OS; MorphOS; Haiku; BareMetal and FreeMint. Some are still used in niche markets and continue to be developed as minority platforms for enthusiast communities and specialist applications. OpenVMS, formerly from DEC, is still under active development by Hewlett-Packard. Yet other operating systems are used almost exclusively in academia, for operating systems education or to do research on operating system concepts. A typical example of a system that fulfills both roles is MINIX, while for example Singularity is used purely for research. Another example is the Oberon System designed at ETH Zürich by Niklaus Wirth, Jürg Gutknecht and a group of students at the former Computer Systems Institute in the 1980s. It was used mainly for research, teaching, and daily work in Wirth's group.

Other operating systems have failed to win significant market share, but have introduced innovations that have influenced mainstream operating systems, not least Bell Labs' Plan 9.

The components of an operating system all exist in order to make the different parts of a computer work together. All user software needs to go through the operating system in order to use any of the hardware, whether it be as simple as a mouse or keyboard or as complex as an Internet component.

With the aid of the firmware and device drivers, the kernel provides the most basic level of control over all of the computer's hardware devices. It manages memory access for programs in the RAM, it determines which programs get access to which hardware resources, it sets up or resets the CPU's operating states for optimal operation at all times, and it organizes the data for long-term non-volatile storage with file systems on such media as disks, tapes, flash memory, etc.

The operating system provides an interface between an application program and the computer hardware, so that an application program can interact with the hardware only by obeying rules and procedures programmed into the operating system. The operating system is also a set of services which simplify development and execution of application programs. Executing an application program involves the creation of a process by the operating system kernel which assigns memory space and other resources, establishes a priority for the process in multi-tasking systems, loads program binary code into memory, and initiates execution of the application program which then interacts with the user and with hardware devices.

Interrupts are central to operating systems, as they provide an efficient way for the operating system to interact with and react to its environment. The alternative having the operating system "watch" the various sources of input for events (polling) that require action can be found in older systems with very small stacks (50 or 60 bytes) but is unusual in modern systems with large stacks. Interrupt-based programming is directly supported by most modern CPUs. Interrupts provide a computer with a way of automatically saving local register contexts, and running specific code in response to events. Even very basic computers support hardware interrupts, and allow the programmer to specify code which may be run when that event takes place.

When an interrupt is received, the computer's hardware automatically suspends whatever program is currently running, saves its status, and runs computer code previously associated with the interrupt; this is analogous to placing a bookmark in a book in response to a phone call. In modern operating systems, interrupts are handled by the operating system's kernel. Interrupts may come from either the computer's hardware or the running program.

When a hardware device triggers an interrupt, the operating system's kernel decides how to deal with this event, generally by running some processing code. The amount of code being run depends on the priority of the interrupt (for example: a person usually responds to a smoke detector alarm before answering the phone). The processing of hardware interrupts is a task that is usually delegated to software called a device driver, which may be part of the operating system's kernel, part of another program, or both. Device drivers may then relay information to a running program by various means.

A program may also trigger an interrupt to the operating system. If a program wishes to access hardware, for example, it may interrupt the operating system's kernel, which causes control to be passed back to the kernel. The kernel then processes the request. If a program wishes additional resources (or wishes to shed resources) such as memory, it triggers an interrupt to get the kernel's attention.

Modern microprocessors (CPU or MPU) support multiple modes of operation. CPUs with this capability offer at least two modes: user mode and supervisor mode. In general terms, supervisor mode operation allows unrestricted access to all machine resources, including all MPU instructions. User mode operation sets limits on instruction use and typically disallows direct access to machine resources. CPUs might have other modes similar to user mode as well, such as the virtual modes in order to emulate older processor types, such as 16-bit processors on a 32-bit one, or 32-bit processors on a 64-bit one.

At power-on or reset, the system begins in supervisor mode. Once an operating system kernel has been loaded and started, the boundary between user mode and supervisor mode (also known as kernel mode) can be established.

Supervisor mode is used by the kernel for low level tasks that need unrestricted access to hardware, such as controlling how memory is accessed, and communicating with devices such as disk drives and video display devices. User mode, in contrast, is used for almost everything else. Application programs, such as word processors and database managers, operate within user mode, and can only access machine resources by turning control over to the kernel, a process which causes a switch to supervisor mode. Typically, the transfer of control to the kernel is achieved by executing a software interrupt instruction, such as the Motorola 68000 codice_1 instruction. The software interrupt causes the microprocessor to switch from user mode to supervisor mode and begin executing code that allows the kernel to take control.

In user mode, programs usually have access to a restricted set of microprocessor instructions, and generally cannot execute any instructions that could potentially cause disruption to the system's operation. In supervisor mode, instruction execution restrictions are typically removed, allowing the kernel unrestricted access to all machine resources.

The term "user mode resource" generally refers to one or more CPU registers, which contain information that the running program isn't allowed to alter. Attempts to alter these resources generally causes a switch to supervisor mode, where the operating system can deal with the illegal operation the program was attempting, for example, by forcibly terminating ("killing") the program).

Among other things, a multiprogramming operating system kernel must be responsible for managing all system memory which is currently in use by programs. This ensures that a program does not interfere with memory already in use by another program. Since programs time share, each program must have independent access to memory.

Cooperative memory management, used by many early operating systems, assumes that all programs make voluntary use of the kernel's memory manager, and do not exceed their allocated memory. This system of memory management is almost never seen any more, since programs often contain bugs which can cause them to exceed their allocated memory. If a program fails, it may cause memory used by one or more other programs to be affected or overwritten. Malicious programs or viruses may purposefully alter another program's memory, or may affect the operation of the operating system itself. With cooperative memory management, it takes only one misbehaved program to crash the system.

Memory protection enables the kernel to limit a process' access to the computer's memory. Various methods of memory protection exist, including memory segmentation and paging. All methods require some level of hardware support (such as the 80286 MMU), which doesn't exist in all computers.

In both segmentation and paging, certain protected mode registers specify to the CPU what memory address it should allow a running program to access. Attempts to access other addresses trigger an interrupt which cause the CPU to re-enter supervisor mode, placing the kernel in charge. This is called a segmentation violation or Seg-V for short, and since it is both difficult to assign a meaningful result to such an operation, and because it is usually a sign of a misbehaving program, the kernel generally resorts to terminating the offending program, and reports the error.

Windows versions 3.1 through ME had some level of memory protection, but programs could easily circumvent the need to use it. A general protection fault would be produced, indicating a segmentation violation had occurred; however, the system would often crash anyway.

The use of virtual memory addressing (such as paging or segmentation) means that the kernel can choose what memory each program may use at any given time, allowing the operating system to use the same memory locations for multiple tasks.

If a program tries to access memory that isn't in its current range of accessible memory, but nonetheless has been allocated to it, the kernel is interrupted in the same way as it would if the program were to exceed its allocated memory. (See section on memory management.) Under UNIX this kind of interrupt is referred to as a page fault.

When the kernel detects a page fault it generally adjusts the virtual memory range of the program which triggered it, granting it access to the memory requested. This gives the kernel discretionary power over where a particular application's memory is stored, or even whether or not it has actually been allocated yet.

In modern operating systems, memory which is accessed less frequently can be temporarily stored on disk or other media to make that space available for use by other programs. This is called swapping, as an area of memory can be used by multiple programs, and what that memory area contains can be swapped or exchanged on demand.

"Virtual memory" provides the programmer or the user with the perception that there is a much larger amount of RAM in the computer than is really there.

Multitasking refers to the running of multiple independent computer programs on the same computer; giving the appearance that it is performing the tasks at the same time. Since most computers can do at most one or two things at one time, this is generally done via time-sharing, which means that each program uses a share of the computer's time to execute.

An operating system kernel contains a scheduling program which determines how much time each process spends executing, and in which order execution control should be passed to programs. Control is passed to a process by the kernel, which allows the program access to the CPU and memory. Later, control is returned to the kernel through some mechanism, so that another program may be allowed to use the CPU. This so-called passing of control between the kernel and applications is called a context switch.

An early model which governed the allocation of time to programs was called cooperative multitasking. In this model, when control is passed to a program by the kernel, it may execute for as long as it wants before explicitly returning control to the kernel. This means that a malicious or malfunctioning program may not only prevent any other programs from using the CPU, but it can hang the entire system if it enters an infinite loop.

Modern operating systems extend the concepts of application preemption to device drivers and kernel code, so that the operating system has preemptive control over internal run-times as well.

The philosophy governing preemptive multitasking is that of ensuring that all programs are given regular time on the CPU. This implies that all programs must be limited in how much time they are allowed to spend on the CPU without being interrupted. To accomplish this, modern operating system kernels make use of a timed interrupt. A protected mode timer is set by the kernel which triggers a return to supervisor mode after the specified time has elapsed. (See above sections on Interrupts and Dual Mode Operation.)

On many single user operating systems cooperative multitasking is perfectly adequate, as home computers generally run a small number of well tested programs. The AmigaOS is an exception, having preemptive multitasking from its very first version. Windows NT was the first version of Microsoft Windows which enforced preemptive multitasking, but it didn't reach the home user market until Windows XP (since Windows NT was targeted at professionals).

Access to data stored on disks is a central feature of all operating systems. Computers store data on disks using files, which are structured in specific ways in order to allow for faster access, higher reliability, and to make better use of the drive's available space. The specific way in which files are stored on a disk is called a file system, and enables files to have names and attributes. It also allows them to be stored in a hierarchy of directories or folders arranged in a directory tree.

Early operating systems generally supported a single type of disk drive and only one kind of file system. Early file systems were limited in their capacity, speed, and in the kinds of file names and directory structures they could use. These limitations often reflected limitations in the operating systems they were designed for, making it very difficult for an operating system to support more than one file system.

While many simpler operating systems support a limited range of options for accessing storage systems, operating systems like UNIX and Linux support a technology known as a virtual file system or VFS. An operating system such as UNIX supports a wide array of storage devices, regardless of their design or file systems, allowing them to be accessed through a common application programming interface (API). This makes it unnecessary for programs to have any knowledge about the device they are accessing. A VFS allows the operating system to provide programs with access to an unlimited number of devices with an infinite variety of file systems installed on them, through the use of specific device drivers and file system drivers.

A connected storage device, such as a hard drive, is accessed through a device driver. The device driver understands the specific language of the drive and is able to translate that language into a standard language used by the operating system to access all disk drives. On UNIX, this is the language of block devices.

When the kernel has an appropriate device driver in place, it can then access the contents of the disk drive in raw format, which may contain one or more file systems. A file system driver is used to translate the commands used to access each specific file system into a standard set of commands that the operating system can use to talk to all file systems. Programs can then deal with these file systems on the basis of filenames, and directories/folders, contained within a hierarchical structure. They can create, delete, open, and close files, as well as gather various information about them, including access permissions, size, free space, and creation and modification dates.

Various differences between file systems make supporting all file systems difficult. Allowed characters in file names, case sensitivity, and the presence of various kinds of file attributes makes the implementation of a single interface for every file system a daunting task. Operating systems tend to recommend using (and so support natively) file systems specifically designed for them; for example, NTFS in Windows and ext3 and ReiserFS in Linux. However, in practice, third party drivers are usually available to give support for the most widely used file systems in most general-purpose operating systems (for example, NTFS is available in Linux through NTFS-3g, and ext2/3 and ReiserFS are available in Windows through third-party software).

Support for file systems is highly varied among modern operating systems, although there are several common file systems which almost all operating systems include support and drivers for. Operating systems vary on file system support and on the disk formats they may be installed on. Under Windows, each file system is usually limited in application to certain media; for example, CDs must use ISO 9660 or UDF, and as of Windows Vista, NTFS is the only file system which the operating system can be installed on. It is possible to install Linux onto many types of file systems. Unlike other operating systems, Linux and UNIX allow any file system to be used regardless of the media it is stored in, whether it is a hard drive, a disc (CD, DVD...), a USB flash drive, or even contained within a file located on another file system.

A device driver is a specific type of computer software developed to allow interaction with hardware devices. Typically this constitutes an interface for communicating with the device, through the specific computer bus or communications subsystem that the hardware is connected to, providing commands to and/or receiving data from the device, and on the other end, the requisite interfaces to the operating system and software applications. It is a specialized hardware-dependent computer program which is also operating system specific that enables another program, typically an operating system or applications software package or computer program running under the operating system kernel, to interact transparently with a hardware device, and usually provides the requisite interrupt handling necessary for any necessary asynchronous time-dependent hardware interfacing needs.

The key design goal of device drivers is abstraction. Every model of hardware (even within the same class of device) is different. Newer models also are released by manufacturers that provide more reliable or better performance and these newer models are often controlled differently. Computers and their operating systems cannot be expected to know how to control every device, both now and in the future. To solve this problem, operating systems essentially dictate how every type of device should be controlled. The function of the device driver is then to translate these operating system mandated function calls into device specific calls. In theory a new device, which is controlled in a new manner, should function correctly if a suitable driver is available. This new driver ensures that the device appears to operate as usual from the operating system's point of view.

Under versions of Windows before Vista and versions of Linux before 2.6, all driver execution was co-operative, meaning that if a driver entered an infinite loop it would freeze the system. More recent revisions of these operating systems incorporate kernel preemption, where the kernel interrupts the driver to give it tasks, and then separates itself from the process until it receives a response from the device driver, or gives it more tasks to do.

Currently most operating systems support a variety of networking protocols, hardware, and applications for using them. This means that computers running dissimilar operating systems can participate in a common network for sharing resources such as computing, files, printers, and scanners using either wired or wireless connections. Networks can essentially allow a computer's operating system to access the resources of a remote computer to support the same functions as it could if those resources were connected directly to the local computer. This includes everything from simple communication, to using networked file systems or even sharing another computer's graphics or sound hardware. Some network services allow the resources of a computer to be accessed transparently, such as SSH which allows networked users direct access to a computer's command line interface.

Client/server networking allows a program on a computer, called a client, to connect via a network to another computer, called a server. Servers offer (or host) various services to other network computers and users. These services are usually provided through ports or numbered access points beyond the server's IP address. Each port number is usually associated with a maximum of one running program, which is responsible for handling requests to that port. A daemon, being a user program, can in turn access the local hardware resources of that computer by passing requests to the operating system kernel.

Many operating systems support one or more vendor-specific or open networking protocols as well, for example, SNA on IBM systems, DECnet on systems from Digital Equipment Corporation, and Microsoft-specific protocols (SMB) on Windows. Specific protocols for specific tasks may also be supported such as NFS for file access. Protocols like ESound, or esd can be easily extended over the network to provide sound from local applications, on a remote system's sound hardware.

A computer being secure depends on a number of technologies working properly. A modern operating system provides access to a number of resources, which are available to software running on the system, and to external devices like networks via the kernel.

The operating system must be capable of distinguishing between requests which should be allowed to be processed, and others which should not be processed. While some systems may simply distinguish between "privileged" and "non-privileged", systems commonly have a form of requester "identity", such as a user name. To establish identity there may be a process of "authentication". Often a username must be quoted, and each username may have a password. Other methods of authentication, such as magnetic cards or biometric data, might be used instead. In some cases, especially connections from the network, resources may be accessed with no authentication at all (such as reading files over a network share). Also covered by the concept of requester identity is "authorization"; the particular services and resources accessible by the requester once logged into a system are tied to either the requester's user account or to the variously configured groups of users to which the requester belongs.

In addition to the allow or disallow model of security, a system with a high level of security also offers auditing options. These would allow tracking of requests for access to resources (such as, "who has been reading this file?"). Internal security, or security from an already running program is only possible if all possibly harmful requests must be carried out through interrupts to the operating system kernel. If programs can directly access hardware and resources, they cannot be secured.

External security involves a request from outside the computer, such as a login at a connected console or some kind of network connection. External requests are often passed through device drivers to the operating system's kernel, where they can be passed onto applications, or carried out directly. Security of operating systems has long been a concern because of highly sensitive data held on computers, both of a commercial and military nature. The United States Government Department of Defense (DoD) created the "Trusted Computer System Evaluation Criteria" (TCSEC) which is a standard that sets basic requirements for assessing the effectiveness of security. This became of vital importance to operating system makers, because the TCSEC was used to evaluate, classify and select trusted operating systems being considered for the processing, storage and retrieval of sensitive or classified information.

Network services include offerings such as file sharing, print services, email, web sites, and file transfer protocols (FTP), most of which can have compromised security. At the front line of security are hardware devices known as firewalls or intrusion detection/prevention systems. At the operating system level, there are a number of software firewalls available, as well as intrusion detection/prevention systems. Most modern operating systems include a software firewall, which is enabled by default. A software firewall can be configured to allow or deny network traffic to or from a service or application running on the operating system. Therefore, one can install and be running an insecure service, such as Telnet or FTP, and not have to be threatened by a security breach because the firewall would deny all traffic trying to connect to the service on that port.

An alternative strategy, and the only sandbox strategy available in systems that do not meet the Popek and Goldberg virtualization requirements, is where the operating system is not running user programs as native code, but instead either emulates a processor or provides a host for a p-code based system such as Java.

Internal security is especially relevant for multi-user systems; it allows each user of the system to have private files that the other users cannot tamper with or read. Internal security is also vital if auditing is to be of any use, since a program can potentially bypass the operating system, inclusive of bypassing auditing.

Every computer that is to be operated by an individual requires a user interface. The user interface is usually referred to as a shell and is essential if human interaction is to be supported. The user interface views the directory structure and requests services from the operating system that will acquire data from input hardware devices, such as a keyboard, mouse or credit card reader, and requests operating system services to display prompts, status messages and such on output hardware devices, such as a video monitor or printer. The two most common forms of a user interface have historically been the command-line interface, where computer commands are typed out line-by-line, and the graphical user interface, where a visual environment (most commonly a WIMP) is present.

Most of the modern computer systems support graphical user interfaces (GUI), and often include them. In some computer systems, such as the original implementation of the classic Mac OS, the GUI is integrated into the kernel.

While technically a graphical user interface is not an operating system service, incorporating support for one into the operating system kernel can allow the GUI to be more responsive by reducing the number of context switches required for the GUI to perform its output functions. Other operating systems are modular, separating the graphics subsystem from the kernel and the Operating System. In the 1980s UNIX, VMS and many others had operating systems that were built this way. Linux and macOS are also built this way. Modern releases of Microsoft Windows such as Windows Vista implement a graphics subsystem that is mostly in user-space; however the graphics drawing routines of versions between Windows NT 4.0 and Windows Server 2003 exist mostly in kernel space. Windows 9x had very little distinction between the interface and the kernel.

Many computer operating systems allow the user to install or create any user interface they desire. The X Window System in conjunction with GNOME or KDE Plasma 5 is a commonly found setup on most Unix and Unix-like (BSD, Linux, Solaris) systems. A number of Windows shell replacements have been released for Microsoft Windows, which offer alternatives to the included Windows shell, but the shell itself cannot be separated from Windows.

Numerous Unix-based GUIs have existed over time, most derived from X11. Competition among the various vendors of Unix (HP, IBM, Sun) led to much fragmentation, though an effort to standardize in the 1990s to COSE and CDE failed for various reasons, and were eventually eclipsed by the widespread adoption of GNOME and K Desktop Environment. Prior to free software-based toolkits and desktop environments, Motif was the prevalent toolkit/desktop combination (and was the basis upon which CDE was developed).

Graphical user interfaces evolve over time. For example, Windows has modified its user interface almost every time a new major version of Windows is released, and the Mac OS GUI changed dramatically with the introduction of Mac OS X in 1999.

A real-time operating system (RTOS) is an operating system intended for applications with fixed deadlines (real-time computing). Such applications include some small embedded systems, automobile engine controllers, industrial robots, spacecraft, industrial control, and some large-scale computing systems.

An early example of a large-scale real-time operating system was Transaction Processing Facility developed by American Airlines and IBM for the Sabre Airline Reservations System.

Embedded systems that have fixed deadlines use a real-time operating system such as VxWorks, PikeOS, eCos, QNX, MontaVista Linux and RTLinux. Windows CE is a real-time operating system that shares similar APIs to desktop Windows but shares none of desktop Windows' codebase. Symbian OS also has an RTOS kernel (EKA2) starting with version 8.0b.

Some embedded systems use operating systems such as Palm OS, BSD, and Linux, although such operating systems do not support real-time computing.

Operating system development is one of the most complicated activities in which a computing hobbyist may engage. A hobby operating system may be classified as one whose code has not been directly derived from an existing operating system, and has few users and active developers.

In some cases, hobby development is in support of a "homebrew" computing device, for example, a simple single-board computer powered by a 6502 microprocessor. Or, development may be for an architecture already in widespread use. Operating system development may come from entirely new concepts, or may commence by modeling an existing operating system. In either case, the hobbyist is his/her own developer, or may interact with a small and sometimes unstructured group of individuals who have like interests.

Examples of a hobby operating system include Syllable.

Application software is generally written for use on a specific operating system, and sometimes even for specific hardware. When porting the application to run on another OS, the functionality required by that application may be implemented differently by that OS (the names of functions, meaning of arguments, etc.) requiring the application to be adapted, changed, or otherwise maintained.

Unix was the first operating system not written in assembly language, making it very portable to systems different from its native PDP-11.

This cost in supporting operating systems diversity can be avoided by instead writing applications against software platforms like Java or Qt. These abstractions have already borne the cost of adaptation to specific operating systems and their system libraries.

Another approach is for operating system vendors to adopt standards. For example, POSIX and OS abstraction layers provide commonalities that reduce porting costs.

In 2014, Android was first (currently not replicated by others, in a single year) operating system ever to ship on a billion devices, becoming the most popular operating system by installed base.



</doc>
<doc id="22196" url="https://en.wikipedia.org/wiki?curid=22196" title="Orson Welles">
Orson Welles

George Orson Welles (; May 6, 1915 – October 10, 1985) was an American actor, director, writer, and producer who worked in theatre, radio, and film. He is remembered for his innovative work in all three: in theatre, most notably "Caesar" (1937), a Broadway adaptation of William Shakespeare's "Julius Caesar"; in radio, the legendary 1938 broadcast "The War of the Worlds"; and in film, "Citizen Kane" (1941), consistently ranked as one of the greatest films ever made.

In his 20s, Welles directed a number of high-profile stage productions for the Federal Theatre Project, including an adaptation of "Macbeth" with an entirely African American cast, and the political musical "The Cradle Will Rock". In 1937 he and John Houseman founded the Mercury Theatre, an independent repertory theatre company that presented a series of productions on Broadway through 1941. Welles found national and international fame as the director and narrator of a 1938 radio adaptation of H. G. Wells' novel "The War of the Worlds" performed for his radio anthology series "The Mercury Theatre on the Air". It reportedly caused widespread panic when listeners thought that an invasion by extraterrestrial beings was actually occurring. Although some contemporary sources say these reports of panic were mostly false and overstated, they rocketed Welles to notoriety.

His first film was "Citizen Kane" (1941), which he co-wrote, produced, directed, and starred in as Charles Foster Kane. Welles was an outsider to the studio system and directed only 13 full-length films in his career. He struggled for creative control on his projects early on with the major film studios and later in life with a variety of independent financiers, and his films were either heavily edited or remained unreleased. His distinctive directorial style featured layered and nonlinear narrative forms, uses of lighting such as chiaroscuro, unusual camera angles, sound techniques borrowed from radio, deep focus shots, and long takes. He has been praised as "the ultimate auteur".

Welles followed up "Citizen Kane" with 12 other feature films, the most acclaimed of which include "The Magnificent Ambersons" (1942), "Touch of Evil" (1958), and "Chimes at Midnight" (1966). Other works of his, such as "The Lady from Shanghai" (1947) and "F for Fake" (1973), are also well-regarded.

In 2002, Welles was voted the greatest film director of all time in two British Film Institute polls among directors and critics. Known for his baritone voice, Welles was an actor in radio and film, a Shakespearean stage actor, and a magician noted for presenting troop variety shows in the war years.

George Orson Welles was born May 6, 1915, in Kenosha, Wisconsin, son of Richard Head Welles (b. Richard Hodgdon Wells, November 12, 1872, near St. Joseph, Missouri; d. December 28, 1930, Chicago, Illinois) and Beatrice Ives Welles (b. Beatrice Lucy Ives, September 1, 1883, Springfield, Illinois; d. May 10, 1924, Chicago). He was named after his paternal great-grandfather, influential Kenosha attorney Orson S. Head, and his brother George Head. An alternative story of the source of his first and middle names was told by George Ade, who met Welles's parents on a West Indies cruise toward the end of 1914. Ade was traveling with a friend, Orson Wells (no relation), and the two of them sat at the same table as Mr. and Mrs. Richard Welles. Mrs. Welles was pregnant at the time, and when they said good-by, she told them that she had enjoyed their company so much that if the child were a boy, she intended to name it for them: George Orson. Welles's birth announcement and a picture of him as a young boy are among George Ade's papers at Purdue University.

Despite his family's affluence, Welles encountered hardship in childhood. His parents separated and moved to Chicago in 1919. His father, who made a fortune as the inventor of a popular bicycle lamp, became an alcoholic and stopped working. Welles's mother, a pianist, played during lectures by Dudley Crafts Watson at the Art Institute of Chicago to support her son and herself; the oldest Welles boy, "Dickie", was institutionalized at an early age because he had learning difficulties. Beatrice died of hepatitis in a Chicago hospital May 10, 1924, just after Welles's ninth birthday. The Gordon String Quartet, which had made its first appearance at her home in 1921, played at Beatrice's funeral.

After his mother's death, Welles ceased pursuing music. It was decided that he would spend the summer with the Watson family at a private art colony in Wyoming, New York, established by Lydia Avery Coonley Ward. There he played and became friends with the children of the Aga Khan, including the 12-year-old Prince Aly Khan. Then, in what Welles later described as "a hectic period" in his life, he lived in a Chicago apartment with both his father and Dr. Maurice Bernstein, a Chicago physician who had been a close friend of both his parents. Welles briefly attended public school before his alcoholic father left business altogether and took him along on his travels to Jamaica and the Far East. When they returned they settled in a hotel in Grand Detour, Illinois, that was owned by his father. When the hotel burned down, Welles and his father took to the road again.

"During the three years that Orson lived with his father, some observers wondered who took care of whom", wrote biographer Frank Brady.

"In some ways, he was never really a young boy, you know," said Roger Hill, who became Welles's teacher and lifelong friend.

Welles briefly attended public school in Madison, Wisconsin, enrolled in the fourth grade. On September 15, 1926, he entered the Todd Seminary for Boys, an expensive independent school in Woodstock, Illinois, that his older brother, Richard Ives Welles, had attended ten years before but was expelled for misbehavior. At Todd School, Welles came under the influence of Roger Hill, a teacher who was later Todd's headmaster. Hill provided Welles with an "ad hoc" educational environment that proved invaluable to his creative experience, allowing Welles to concentrate on subjects that interested him. Welles performed and staged theatrical experiments and productions there.

"Todd provided Welles with many valuable experiences", wrote critic Richard France. "He was able to explore and experiment in an atmosphere of acceptance and encouragement. In addition to a theater the school's own radio station was at his disposal." Welles' first radio experience was on the Todd station, he performed an adaptation of "Sherlock Holmes" that was written by him.

On December 28, 1930, when Welles was 15, his father died of heart and kidney failure at the age of 58, alone in a hotel in Chicago. Shortly before this, Welles had announced to his father that he would stop seeing him, believing it would prompt his father to refrain from drinking. As a result, Orson felt guilty because he believed his father had drunk himself to death because of him. His father's will left it to Orson to name his guardian. When Roger Hill declined, Welles chose Maurice Bernstein.

Following graduation from Todd in May 1931, Welles was awarded a scholarship to Harvard University, while his mentor Roger Hill advocated he attend Cornell College in Iowa. Rather than enrolling, he chose travel. He studied for a few weeks at the Art Institute of Chicago with Boris Anisfeld, who encouraged him to pursue painting.

Welles would occasionally return to Woodstock, the place he eventually named when he was asked in a 1960 interview, "Where is home?" Welles replied, "I suppose it's Woodstock, Illinois, if it's anywhere. I went to school there for four years. If I try to think of a home, it's that."

After his father's death, Welles traveled to Europe using a small portion of his inheritance. Welles said that while on a walking and painting trip through Ireland, he strode into the Gate Theatre in Dublin and claimed he was a Broadway star. The manager of the Gate, Hilton Edwards, later said he had not believed him but was impressed by his brashness and an impassioned audition he gave. Welles made his stage debut at the Gate Theatre on October 13, 1931, appearing in Ashley Dukes's adaptation of "Jew Suss" as Duke Karl Alexander of Württemberg. He performed small supporting roles in subsequent Gate productions, and he produced and designed productions of his own in Dublin. In March 1932 Welles performed in W. Somerset Maugham's "The Circle" at Dublin's Abbey Theatre and travelled to London to find additional work in the theatre. Unable to obtain a work permit, he returned to the U.S.

Welles found his fame ephemeral and turned to a writing project at Todd School that would become the immensely successful, first entitled "Everybody's Shakespeare" and subsequently, "The Mercury Shakespeare". Welles traveled to North Africa while working on thousands of illustrations for the "Everybody's Shakespeare" series of educational books, a series that remained in print for decades.

In 1933, Roger and Hortense Hill invited Welles to a party in Chicago, where Welles met Thornton Wilder. Wilder arranged for Welles to meet Alexander Woollcott in New York, in order that he be introduced to Katharine Cornell, who was assembling a repertory theatre company. Cornell's husband, director Guthrie McClintic, immediately put Welles under contract and cast him in three plays. "Romeo and Juliet", "The Barretts of Wimpole Street" and "Candida" toured in repertory for 36 weeks beginning in November 1933, with the first of more than 200 performances taking place in Buffalo, New York.

In 1934, Welles got his first job on radio—on "The American School of the Air"—through actor-director Paul Stewart, who introduced him to director Knowles Entrikin. That summer Welles staged a drama festival with the Todd School in Woodstock, Illinois, inviting Micheál Mac Liammóir and Hilton Edwards from Dublin's Gate Theatre to appear along with New York stage luminaries in productions including "Trilby", "Hamlet", "The Drunkard" and "Tsar Paul". At the old firehouse in Woodstock he also shot his first film, an eight-minute short titled "The Hearts of Age".

On November 14, 1934, Welles married Chicago socialite and actress Virginia Nicolson (often misspelled "Nicholson") in a civil ceremony in New York. To appease the Nicolsons, who were furious at the couple's elopement, a formal ceremony took place December 23, 1934, at the New Jersey mansion of the bride's godmother. Welles wore a cutaway borrowed from his friend George Macready.

A revised production of Katharine Cornell's "Romeo and Juliet" opened December 20, 1934, at the Martin Beck Theatre in New York. The Broadway production brought the 19-year-old Welles (now playing Tybalt) to the notice of John Houseman, a theatrical producer who was casting the lead role in the debut production of Archibald MacLeish's verse play, "Panic". On March 22, 1935, Welles made his debut on the CBS Radio series "The March of Time", performing a scene from "Panic" for a news report on the stage production

By 1935 Welles was supplementing his earnings in the theater as a radio actor in Manhattan, working with many actors who would later form the core of his Mercury Theatre on programs including "America's Hour", "Cavalcade of America", "Columbia Workshop" and "The March of Time". "Within a year of his debut Welles could claim membership in that elite band of radio actors who commanded salaries second only to the highest paid movie stars," wrote critic Richard France.

Part of the Works Progress Administration, the Federal Theatre Project (1935–39) was a New Deal program to fund theatre and other live artistic performances and entertainment programs in the United States during the Great Depression. It was created as a relief measure to employ artists, writers, directors and theater workers. Under national director Hallie Flanagan it was shaped into a true national theatre that created relevant art, encouraged experimentation and innovation, and made it possible for millions of Americans to see live theatre for the first time.
John Houseman, director of the Negro Theatre Unit in New York, invited Welles to join the Federal Theatre Project in 1935. Far from unemployed — "I was so employed I forgot how to sleep" — Welles put a large share of his $1,500-a-week radio earnings into his stage productions, bypassing administrative red tape and mounting the projects more quickly and professionally. "Roosevelt once said that I was the only operator in history who ever illegally siphoned money "into" a Washington project," Welles said.

The Federal Theatre Project was the ideal environment in which Welles could develop his art. Its purpose was employment, so he was able to hire any number of artists, craftsmen and technicians, and he filled the stage with performers. The company for the first production, an adaptation of William Shakespeare's "Macbeth" with an entirely African-American cast, numbered 150. The production became known as the "Voodoo Macbeth" because Welles changed the setting to a mythical island suggesting the Haitian court of King Henri Christophe, with Haitian "vodou" fulfilling the rôle of Scottish witchcraft. The play opened April 14, 1936, at the Lafayette Theatre in Harlem and was received rapturously. At 20, Welles was hailed as a prodigy. The production then made a 4,000-mile national tour that included two weeks at the Texas Centennial Exposition in Dallas.

Next mounted was the farce "Horse Eats Hat", an adaptation by Welles and Edwin Denby of "The Italian Straw Hat", an 1851 five-act farce by Eugène Marin Labiche and Marc-Michel. The play was presented September 26 – December 5, 1936, at Maxine Elliott's Theatre, New York, and featured Joseph Cotten in his first starring role. It was followed by an adaptation of "Dr. Faustus" that used light as a prime unifying scenic element in a nearly black stage, presented January 8 – May 9, 1937, at Maxine Elliott's Theatre.

Outside the scope of the Federal Theatre Project, American composer Aaron Copland chose Welles to direct "The Second Hurricane" (1937), an operetta with a libretto by Edwin Denby. Presented at the Henry Street Settlement Music School in New York for the benefit of high school students, the production opened April 21, 1937, and ran its scheduled three performances.

In 1937, Welles rehearsed Marc Blitzstein's political operetta, "The Cradle Will Rock". It was originally scheduled to open June 16, 1937, in its first public preview. Because of severe federal cutbacks in the Works Progress projects, the show's premiere at the Maxine Elliott Theatre was canceled. The theater was locked and guarded to prevent any government-purchased materials from being used for a commercial production of the work. In a last-minute move, Welles announced to waiting ticket-holders that the show was being transferred to the Venice, 20 blocks away. Some cast, and some crew and audience, walked the distance on foot. The union musicians refused to perform in a commercial theater for lower non-union government wages. The actors' union stated that the production belonged to the Federal Theater Project and could not be performed outside that context without permission. Lacking the participation of the union members, "The Cradle Will Rock" began with Blitzstein introducing the show and playing the piano accompaniment on stage with some cast members performing from the audience. This impromptu performance was well received by its audience.

Breaking with the Federal Theatre Project in 1937, Welles and Houseman founded their own repertory company, which they called the Mercury Theatre. The name was inspired by the title of the iconoclastic magazine, "The American Mercury". Welles was executive producer, and the original company included such actors as Joseph Cotten, George Coulouris, Geraldine Fitzgerald, Arlene Francis, Martin Gabel, John Hoyt, Norman Lloyd, Vincent Price, Stefan Schnabel and Hiram Sherman.

"I think he was the greatest directorial talent we've ever had in the [American] theater," Lloyd said of Welles in a 2014 interview. "When you saw a Welles production, you saw the text had been affected, the staging was remarkable, the sets were unusual, music, sound, lighting, a totality of everything. We had not had such a man in our theater. He was the first and remains the greatest."

The Mercury Theatre opened November 11, 1937, with "Caesar", Welles's modern-dress adaptation of Shakespeare's tragedy "Julius Caesar" — streamlined into an anti-fascist tour de force that Joseph Cotten later described as "so vigorous, so contemporary that it set Broadway on its ear." The set was completely open with no curtain, and the brick stage wall was painted dark red. Scene changes were achieved by lighting alone. On the stage was a series of risers; squares were cut into one at intervals and lights were set beneath it, pointing straight up to evoke the "cathedral of light" at the Nuremberg Rallies. "He staged it like a political melodrama that happened the night before," said Lloyd.

Beginning January 1, 1938, "Caesar" was performed in repertory with "The Shoemaker's Holiday"; both productions moved to the larger National Theatre. They were followed by "Heartbreak House" (April 29, 1938) and "Danton's Death" (November 5, 1938). As well as being presented in a pared-down oratorio version at the Mercury Theatre on Sunday nights in December 1937, "The Cradle Will Rock" was at the Windsor Theatre for 13 weeks (January 4–April 2, 1938). Such was the success of the Mercury Theatre that Welles appeared on the cover of "Time" magazine, in full makeup as Captain Shotover in "Heartbreak House", in the issue dated May 9, 1938—three days after his 23rd birthday.

Simultaneously with his work in the theatre, Welles worked extensively in radio as an actor, writer, director and producer, often without credit. Between 1935 and 1937 he was earning as much as $2,000 a week, shuttling between radio studios at such a pace that he would arrive barely in time for a quick scan of his lines before he was on the air. While he was directing the "Voodoo Macbeth" Welles was dashing between Harlem and midtown Manhattan three times a day to meet his radio commitments.

In addition to continuing as a repertory player on "The March of Time", in the fall of 1936 Welles adapted and performed "Hamlet" in an early two-part episode of CBS Radio's "Columbia Workshop". His performance as the announcer in the series' April 1937 presentation of Archibald MacLeish's verse drama "The Fall of the City" was an important development in his radio career and made the 21-year-old Welles an overnight star.

In July 1937, the Mutual Network gave Welles a seven-week series to adapt "Les Misérables". It was his first job as a writer-director for radio, the radio debut of the Mercury Theatre, and one of Welles's earliest and finest achievements. He invented the use of narration in radio.

"By making himself the center of the storytelling process, Welles fostered the impression of self-adulation that was to haunt his career to his dying day," wrote critic Andrew Sarris. "For the most part, however, Welles was singularly generous to the other members of his cast and inspired loyalty from them above and beyond the call of professionalism."

That September, Mutual chose Welles to play Lamont Cranston, also known as "The Shadow". He performed the role anonymously through mid-September 1938.

After the theatrical successes of the Mercury Theatre, CBS Radio invited Orson Welles to create a summer show for 13 weeks. The series began July 11, 1938, initially titled "First Person Singular", with the formula that Welles would play the lead in each show. Some months later the show was called "The Mercury Theatre on the Air". The weekly hour-long show presented radio plays based on classic literary works, with original music composed and conducted by Bernard Herrmann.

The Mercury Theatre's radio adaptation of "The War of the Worlds" by H. G. Wells October 30, 1938, brought Welles instant fame. The combination of the news bulletin form of the performance with the between-breaks dial spinning habits of listeners was later reported to have created widespread confusion among listeners who failed to hear the introduction, although the extent of this confusion has come into question. Panic was reportedly spread among listeners who believed the fictional news reports of a Martian invasion. The myth of the result created by the combination was reported as fact around the world and disparagingly mentioned by Adolf Hitler in a public speech.

Welles's growing fame drew Hollywood offers, lures that the independent-minded Welles resisted at first. "The Mercury Theatre on the Air," which had been a sustaining show (without sponsorship) was picked up by Campbell Soup and renamed "The Campbell Playhouse." "The Mercury Theatre on the Air" made its last broadcast on December 4, 1938, and "The Campbell Playhouse" began five days later.

Welles began commuting from California to New York for the two Sunday broadcasts of "The Campbell Playhouse" after signing a film contract with RKO Pictures in August 1939. In November 1939, production of the show moved from New York to Los Angeles.

After 20 shows, Campbell began to exercise more creative control and had complete control over story selection. As his contract with Campbell came to an end, Welles chose not to sign on for another season. After the broadcast of March 31, 1940, Welles and Campbell parted amicably.

RKO Radio Pictures president George Schaefer eventually offered Welles what generally is considered the greatest contract offered to a filmmaker, much less to one who was untried. Engaging him to write, produce, direct and perform in two motion pictures, the contract subordinated the studio's financial interests to Welles's creative control, and broke all precedent by granting Welles the right of final cut. After signing a summary agreement with RKO on July 22, Welles signed a full-length 63-page contract August 21, 1939. The agreement was bitterly resented by the Hollywood studios and persistently mocked in the trade press.

RKO rejected Welles's first two movie proposals, but agreed on the third offer—"Citizen Kane". Welles co-wrote, produced and directed the film, and performed the lead role. Welles conceived the project with screenwriter Herman J. Mankiewicz, who was writing radio plays for "The Campbell Playhouse". Mankiewicz based the original outline on the life of William Randolph Hearst, whom he knew socially and came to hate after being exiled from Hearst's circle.

After agreeing on the storyline and character, Welles supplied Mankiewicz with 300 pages of notes and put him under contract to write the first draft screenplay under the supervision of John Houseman. Welles wrote his own draft, then drastically condensed and rearranged both versions and added scenes of his own. The industry accused Welles of underplaying Mankiewicz's contribution to the script, but Welles countered the attacks by saying, "At the end, naturally, I was the one making the picture, after all—who had to make the decisions. I used what I wanted of Mank's and, rightly or wrongly, kept what I liked of my own."

Welles's project attracted some of Hollywood's best technicians, including cinematographer Gregg Toland. For the cast, Welles primarily used actors from his Mercury Theatre. Filming "Citizen Kane" took ten weeks.

Hearst's newspapers barred all reference to "Citizen Kane" and exerted enormous pressure on the Hollywood film community to force RKO to shelve the film. RKO chief George Schaefer received a cash offer from MGM's Louis B. Mayer and other major studio executives if he would destroy the negative and existing prints of the film.

While waiting for "Citizen Kane" to be released, Welles produced and directed the original Broadway production of "Native Son", a drama written by Paul Green and Richard Wright based on Wright's novel. Starring Canada Lee, the show ran March 24 – June 28, 1941, at the St. James Theatre. The Mercury Production was the last time Welles and Houseman worked together.

"Citizen Kane" was given a limited release and the film received overwhelming critical praise. It was voted the best picture of 1941 by the National Board of Review and the New York Film Critics Circle. The film garnered nine Academy Award nominations but won only for Best Original Screenplay, shared by Mankiewicz and Welles. "Variety" reported that block voting by screen extras deprived "Citizen Kane" of Oscars for Best Picture and Best Actor (Welles), and similar prejudices were likely to have been responsible for the film receiving no technical awards.

The delay in the film's release and uneven distribution contributed to mediocre results at the box office. After it ran its course theatrically, "Citizen Kane" was retired to the vault in 1942. In postwar France, however, the film's reputation grew after it was seen for the first time in 1946. In the United States, it began to be re-evaluated after it began to appear on television in 1956. That year it was also re-released theatrically, and film critic Andrew Sarris described it as "the great American film" and "the work that influenced the cinema more profoundly than any American film since "Birth of a Nation"." "Citizen Kane" is now hailed as one of the greatest films ever made.

Welles's second film for RKO was "The Magnificent Ambersons", adapted by Welles from the Pulitzer Prize-winning novel by Booth Tarkington. Toland was not available, so Stanley Cortez was named cinematographer. The meticulous Cortez worked slowly and the film lagged behind schedule and over budget. Prior to production, Welles's contract was renegotiated, revoking his right to control the final cut. "The Magnificent Ambersons" was in production October 28, 1941 – January 22, 1942.

Throughout the shooting of the film Welles was also producing a weekly half-hour radio series, "The Orson Welles Show". Many of the "Ambersons" cast participated in the CBS Radio series, which ran September 15, 1941 – February 2, 1942.

At RKO's request, Welles worked on an adaptation of Eric Ambler's spy thriller, "Journey into Fear", co-written with Joseph Cotten. In addition to acting in the film, Welles was the producer. Direction was credited to Norman Foster. Welles later said that they were in such a rush that the director of each scene was determined by whoever was closest to the camera.

"Journey into Fear" was in production January 6–March 12, 1942.

In late November 1941, Welles was appointed as a goodwill ambassador to Latin America by Nelson Rockefeller, U.S. Coordinator of Inter-American Affairs and a principal stockholder in RKO Radio Pictures. The mission of the OCIAA was cultural diplomacy, promoting hemispheric solidarity and countering the growing influence of the Axis powers in Latin America. John Hay Whitney, head of the agency's Motion Picture Division, was asked by the Brazilian government to produce a documentary of the annual Rio Carnival celebration taking place in early February 1942. In a telegram December 20, 1941, Whitney wrote Welles, "Personally believe you would make great contribution to hemisphere solidarity with this project."

The OCIAA sponsored cultural tours to Latin America and appointed goodwill ambassadors including George Balanchine and the American Ballet, Bing Crosby, Aaron Copland, Walt Disney, John Ford and Rita Hayworth. Welles was thoroughly briefed in Washington, D.C., immediately before his departure for Brazil, and film scholar Catherine L. Benamou, a specialist in Latin American affairs, finds it "not unlikely" that he was among the goodwill ambassadors who were asked to gather intelligence for the U.S. government in addition to their cultural duties. She concludes that Welles's acceptance of Whitney's request was "a logical and patently patriotic choice".

In addition to working on his ill-fated film project, "It's All True", Welles was responsible for radio programs, lectures, interviews and informal talks as part of his OCIAA-sponsored cultural mission, which was regarded as a success. He spoke on topics ranging from Shakespeare to visual art at gatherings of Brazil's elite, and his two intercontinental radio broadcasts in April 1942 were particularly intended to tell U.S. audiences that President Vargas was a partner with the Allies. Welles's ambassadorial mission was extended to permit his travel to other nations including Argentina, Bolivia, Chile, Colombia, Ecuador, Guatemala, Mexico, Peru and Uruguay. Welles worked for more than half a year with no compensation.

Welles's own expectations for the film were modest. ""It's All True" was not going to make any cinematic history, nor was it intended to," he later said. "It was intended to be a perfectly honorable execution of my job as a goodwill ambassador, bringing entertainment to the Northern Hemisphere that showed them something about the Southern one."

In July 1941, Welles conceived "It's All True" as an omnibus film mixing documentary and docufiction in a project that emphasized the dignity of labor and celebrated the cultural and ethnic diversity of North America. It was to have been his third film for RKO, following "Citizen Kane" (1941) and "The Magnificent Ambersons" (1942). Duke Ellington was put under contract to score a segment with the working title, "The Story of Jazz", drawn from Louis Armstrong's 1936 autobiography, "Swing That Music". Armstrong was cast to play himself in the brief dramatization of the history of jazz performance, from its roots to its place in American culture in the 1940s. "The Story of Jazz" was to go into production in December 1941.

Mercury Productions purchased the stories for two other segments—"My Friend Bonito" and "The Captain's Chair"—from documentary filmmaker Robert J. Flaherty. Adapted by Norman Foster and John Fante, "My Friend Bonito" was the only segment of the original "It's All True" to go into production. Filming took place in Mexico September–December 1941, with Norman Foster directing under Welles's supervision.

In December 1941, the Office of the Coordinator of Inter-American Affairs asked Welles to make a film in Brazil that would showcase the Carnaval in Rio de Janeiro. With filming of "My Friend Bonito" about two-thirds complete, Welles decided he could shift the geography of "It's All True" and incorporate Flaherty's story into an omnibus film about Latin America—supporting the Roosevelt administration's Good Neighbor policy, which Welles strongly advocated. In this revised concept, "The Story of Jazz" was replaced by the story of samba, a musical form with a comparable history and one that came to fascinate Welles. He also decided to do a ripped-from-the-headlines episode about the epic voyage of four poor Brazilian fishermen, the jangadeiros, who had become national heroes. Welles later said this was the most valuable story.

Required to film the Carnaval in Rio de Janeiro in early February 1942, Welles rushed to edit "The Magnificent Ambersons" and finish his acting scenes in "Journey into Fear". He ended his lucrative CBS radio show February 2, flew to Washington, D.C., for a briefing, and then lashed together a rough cut of "Ambersons" in Miami with editor Robert Wise. Welles recorded the film's narration the night before he left for South America: "I went to the projection room at about four in the morning, did the whole thing, and then got on the plane and off to Rio—and the end of civilization as we know it."

Welles left for Brazil on February 4 and began filming in Rio February 8, 1942. At the time it did not seem that Welles's other film projects would be disrupted, but as film historian Catherine L. Benamou wrote, "the ambassadorial appointment would be the first in a series of turning points leading—in 'zigs' and 'zags,' rather than in a straight line—to Welles's loss of complete directorial control over both "The Magnificent Ambersons" and "It's All True", the cancellation of his contract at RKO Radio Studio, the expulsion of his company Mercury Productions from the RKO lot, and, ultimately, the total suspension of "It's All True".

In 1942 RKO Pictures underwent major changes under new management. Nelson Rockefeller, the primary backer of the Brazil project, left its board of directors, and Welles's principal sponsor at RKO, studio president George Schaefer, resigned. RKO took control of "Ambersons" and edited the film into what the studio considered a commercial format. Welles's attempts to protect his version ultimately failed. In South America, Welles requested resources to finish "It's All True". Given a limited amount of black-and-white film stock and a silent camera, he was able to finish shooting the episode about the jangadeiros, but RKO refused to support further production on the film.

"So I was fired from RKO," Welles later recalled. "And they made a great publicity point of the fact that I had gone to South America without a script and thrown all this money away. I never recovered from that attack." Later in 1942, when RKO Pictures began promoting its new corporate motto, "Showmanship In Place of Genius: A New Deal at RKO", Welles understood it as a reference to him.

Welles returned to the United States August 22, 1942, after more than six months in South America. A week after his return he produced and emceed the first two hours of a seven-hour coast-to-coast War Bond drive broadcast titled "I Pledge America". Airing August 29, 1942, on the Blue Network, the program was presented in cooperation with the United States Department of the Treasury, Western Union (which wired bond subscriptions free of charge) and the American Women's Voluntary Services. Featuring 21 dance bands and a score of stage and screen and radio stars, the broadcast raised more than $10 million—more than $146 million today—for the war effort.

On October 12, 1942, "Cavalcade of America" presented Welles's radio play, "Admiral of the Ocean Sea", an entertaining and factual look at the legend of Christopher Columbus.

"It belongs to a period when hemispheric unity was a crucial matter and many programs were being devoted to the common heritage of the Americas," wrote broadcasting historian Erik Barnouw. "Many such programs were being translated into Spanish and Portuguese and broadcast to Latin America, to counteract many years of successful Axis propaganda to that area. The Axis, trying to stir Latin America against Anglo-America, had constantly emphasized the differences between the two. It became the job of American radio to emphasize their common experience and essential unity."

"Admiral of the Ocean Sea", also known as "Columbus Day", begins with the words, "Hello Americans"—the title Welles would choose for his own series five weeks later.

"Hello Americans", a CBS Radio series broadcast November 15, 1942 – January 31, 1943, was produced, directed and hosted by Welles under the auspices of the Office of the Coordinator for Inter-American Affairs. The 30-minute weekly program promoted inter-American understanding and friendship, drawing upon the research amassed for the ill-fated film, "It's All True". The series was produced concurrently with Welles's other CBS series, "Ceiling Unlimited" (November 9, 1942 – February 1, 1943), sponsored by the Lockheed-Vega Corporation. The program was conceived to glorify the aviation industry and dramatize its role in World War II. Welles's shows were regarded as significant contributions to the war effort.

Throughout the war Welles worked on patriotic radio programs including "Command Performance", "G.I. Journal", "Mail Call", "Nazi Eyes on Canada", "Stage Door Canteen" and "Treasury Star Parade".

In early 1943, the two concurrent radio series ("Ceiling Unlimited", "Hello Americans") that Orson Welles created for CBS to support the war effort had ended. Filming also had wrapped on the 1943 film adaptation of "Jane Eyre" and that fee, in addition to the income from his regular guest-star roles in radio, made it possible for Welles to fulfill a lifelong dream. He approached the War Assistance League of Southern California and proposed a show that evolved into a big-top spectacle, part circus and part magic show. He offered his services as magician and director, and invested some $40,000 of his own money in an extravaganza he co-produced with his friend Joseph Cotten: "The Mercury Wonder Show for Service Men". Members of the U.S. armed forces were admitted free of charge, while the general public had to pay. The show entertained more than 1,000 service members each night, and proceeds went to the War Assistance League, a charity for military service personnel.

The development of the show coincided with the resolution of Welles's oft-changing draft status in May 1943, when he was finally declared 4-F—unfit for military service—for a variety of medical reasons. "I felt guilty about the war," Welles told biographer Barbara Leaming. "I was guilt-ridden about my civilian status." He had been publicly hounded about his patriotism since "Citizen Kane", when the Hearst press began persistent inquiries about why Welles had not been drafted.

"The Mercury Wonder Show" ran August 3 – September 9, 1943, in an 80-by-120-foot tent located at 9000 Cahuenga Boulevard, in the heart of Hollywood.

At intermission September 7, 1943, KMPC radio interviewed audience and cast members of "The Mercury Wonder Show"—including Welles and Rita Hayworth, who were married earlier that day. Welles remarked that "The Mercury Wonder Show" had been performed for approximately 48,000 members of the U.S. armed forces.

The idea of doing a radio variety show occurred to Welles after his success as substitute host of four consecutive episodes (March 14 – April 4, 1943) of "The Jack Benny Program", radio's most popular show, when Benny contracted pneumonia on a performance tour of military bases. A half-hour variety show broadcast January 26 – July 19, 1944, on the Columbia Pacific Network, "The Orson Welles Almanac" presented sketch comedy, magic, mindreading, music and readings from classic works. Many of the shows originated on U.S. military camps, where Welles and his repertory company and guests entertained the troops with a reduced version of "The Mercury Wonder Show". The performances of the all-star jazz group Welles brought together for the show were so popular that the band became a regular feature and was an important force in reviving interest in traditional New Orleans jazz.

Welles was placed on the U.S. Treasury payroll on May 15, 1944, as an expert consultant for the duration of the war, with a retainer of $1 a year. On the recommendation of President Franklin D. Roosevelt, Secretary of the Treasury Henry Morgenthau asked Welles to lead the Fifth War Loan Drive, which opened June 12 with a one-hour radio show on all four networks, broadcast from Texarkana, Texas. Including a statement by the President, the program defined the causes of the war and encouraged Americans to buy $16 billion in bonds to finance the Normandy landings and the most violent phase of World War II. Welles produced additional war loan drive broadcasts on June 14 from the Hollywood Bowl, and June 16 from Soldier Field, Chicago. Americans purchased $20.6 billion in War Bonds during the Fifth War Loan Drive, which ended on July 8, 1944.

Welles campaigned ardently for Roosevelt in 1944. A longtime supporter and campaign speaker for FDR, he occasionally sent the president ideas and phrases that were sometimes incorporated into what Welles characterized as "less important speeches". One of these ideas was the joke in what came to be called the Fala speech, Roosevelt's nationally broadcast September 23 address to the International Teamsters Union which opened the 1944 presidential campaign.

Welles campaigned for the Roosevelt–Truman ticket almost full-time in the fall of 1944, traveling to nearly every state to the detriment of his own health and at his own expense. In addition to his radio addresses he filled in for Roosevelt, opposite Republican presidential nominee Thomas E. Dewey, at "The New York Herald Tribune Forum" broadcast October 18 on the Blue Network. Welles accompanied FDR to his last campaign rally, speaking at an event November 4 at Boston's Fenway Park before 40,000 people, and took part in a historic election-eve campaign broadcast November 6 on all four radio networks.

On November 21, 1944, Welles began his association with "This Is My Best", a CBS radio series he would briefly produce, direct, write and host (March 13 – April 24, 1945). He wrote a political column called "Orson Welles' Almanac" (later titled "Orson Welles Today") for "The New York Post" January–November 1945, and advocated the continuation of FDR's New Deal policies and his international vision, particularly the establishment of the United Nations and the cause of world peace.

On April 12, 1945, the day Franklin D. Roosevelt died, the Blue-ABC network marshalled its entire executive staff and national leaders to pay homage to the late president. "Among the outstanding programs which attracted wide attention was a special tribute delivered by Orson Welles", reported "Broadcasting" magazine. Welles spoke at 10:10 p.m Eastern War Time, from Hollywood, and stressed the importance of continuing FDR's work: "He has no need for homage and we who loved him have no time for tears … Our fighting sons and brothers cannot pause tonight to mark the death of him whose name will be given to the age we live in."

Welles presented another special broadcast on the death of Roosevelt the following evening: "We must move on beyond mere death to that free world which was the hope and labor of his life."

He dedicated the April 17 episode of "This Is My Best" to Roosevelt and the future of America on the eve of the United Nations Conference on International Organization. Welles was an advisor and correspondent for the Blue-ABC radio network's coverage of the San Francisco conference that formed the UN, taking place April 24 – June 23, 1945. He presented a half-hour dramatic program written by Ben Hecht on the opening day of the conference, and on Sunday afternoons (April 29 – June 10) he led a weekly discussion from the San Francisco Civic Auditorium.

In the fall of 1945 Welles began work on "The Stranger" (1946), a film noir drama about a war crimes investigator who tracks a high-ranking Nazi fugitive to an idyllic New England town. Edward G. Robinson, Loretta Young and Welles star.

Producer Sam Spiegel initially planned to hire director John Huston, who had rewritten the screenplay by Anthony Veiller. When Huston entered the military, Welles was given the chance to direct and prove himself able to make a film on schedule and under budget—something he was so eager to do that he accepted a disadvantageous contract. One of its concessions was that he would defer to the studio in any creative dispute.

"The Stranger" was Welles's first job as a film director in four years. He was told that if the film was successful he could sign a four-picture deal with International Pictures, making films of his own choosing. Welles was given some degree of creative control, and he endeavored to personalize the film and develop a nightmarish tone. He worked on the general rewrite of the script and wrote scenes at the beginning of the picture that were shot but subsequently cut by the producers. He filmed in long takes that largely thwarted the control given to editor Ernest J. Nims under the terms of the contract.

"The Stranger" was the first commercial film to use documentary footage from the Nazi concentration camps. Welles had seen the footage in early May 1945 in San Francisco, as a correspondent and discussion moderator at the UN Conference on International Organization. He wrote of the Holocaust footage in his syndicated "New York Post" column May 7, 1945.

Completed a day ahead of schedule and under budget, "The Stranger" was the only film made by Welles to have been a "bona fide" box office success upon its release. Its cost was $1.034 million; 15 months after its release it had grossed $3.216 million. Within weeks of the completion of the film, International Pictures backed out of its promised four-picture deal with Welles. No reason was given, but the impression was left that "The Stranger" would not make money.

In the summer of 1946, Welles moved to New York to direct the Broadway musical "Around the World", a stage adaptation of the Jules Verne novel "Around the World in Eighty Days" with a book by Welles and music by Cole Porter. Producer Mike Todd, who would later produce the successful 1956 film adaptation, pulled out from the lavish and expensive production, leaving Welles to support the finances. When Welles ran out of money he convinced Columbia Pictures president Harry Cohn to send enough money to continue the show, and in exchange Welles promised to write, produce, direct and star in a film for Cohn for no further fee. The stage show soon failed due to poor box-office, with Welles unable to claim the losses on his taxes.

In 1946, Welles began two new radio series—"The Mercury Summer Theatre of the Air" for CBS, and "Orson Welles Commentaries" for ABC. While "Mercury Summer Theatre" featured half-hour adaptations of some classic Mercury radio shows from the 1930s, the first episode was a condensation of his "Around the World" stage play, and is the only record of Cole Porter's music for the project. Several original Mercury actors returned for the series, as well as Bernard Herrmann. Welles invested his earnings into his failing stage play. "Commentaries" was a political vehicle for him, continuing the themes from his "New York Post" column. Again, Welles lacked a clear focus, until the NAACP brought to his attention the case of Isaac Woodard. Welles brought significant attention to Woodard's cause.

The last broadcast of "Orson Welles Commentaries" on October 6, 1946, marked the end of Welles's own radio shows.

The film that Welles was obliged to make in exchange for Harry Cohn's help in financing the stage production "Around the World" was "The Lady from Shanghai", filmed in 1947 for Columbia Pictures. Intended as a modest thriller, the budget skyrocketed after Cohn suggested that Welles's then-estranged second wife Rita Hayworth co-star.

Cohn disliked Welles's rough cut, particularly the confusing plot and lack of close-ups, and was not in sympathy with Welles's Brechtian use of irony and black comedy, especially in a farcical courtroom scene. Cohn ordered extensive editing and re-shoots. After heavy editing by the studio, approximately one hour of Welles's first cut was removed, including much of a climactic confrontation scene in an amusement park funhouse. While expressing displeasure at the cuts, Welles was appalled particularly with the musical score. The film was considered a disaster in America at the time of release, though the closing shootout in a hall of mirrors has since become a touchstone of film noir. Not long after release, Welles and Hayworth finalized their divorce.

Although "The Lady From Shanghai" was acclaimed in Europe, it was not embraced in the U.S. until decades later, where it is now often regarded as a classic of film noir. A similar difference in reception on opposite sides of the Atlantic followed by greater American acceptance befell the Welles-inspired Chaplin film "Monsieur Verdoux", originally to be directed by Welles starring Chaplin, then directed by Chaplin with the idea credited to Welles.

Prior to 1948, Welles convinced Republic Pictures to let him direct a low-budget version of "Macbeth", which featured highly stylized sets and costumes, and a cast of actors lip-syncing to a pre-recorded soundtrack, one of many innovative cost-cutting techniques Welles deployed in an attempt to make an epic film from B-movie resources. The script, adapted by Welles, is a violent reworking of Shakespeare's original, freely cutting and pasting lines into new contexts via a collage technique and recasting "Macbeth" as a clash of pagan and proto-Christian ideologies. Some voodoo trappings of the famous Welles/Houseman Negro Theatre stage adaptation are visible, especially in the film's characterization of the Weird Sisters, who create an effigy of Macbeth as a charm to enchant him. Of all Welles's post-"Kane" Hollywood productions, "Macbeth" is stylistically closest to "Citizen Kane" in its long takes and deep focus photography.

Republic initially trumpeted the film as an important work but decided it did not care for the Scottish accents and held up general release for almost a year after early negative press reaction, including "Life"s comment that Welles's film "doth foully slaughter Shakespeare." Welles left for Europe, while co-producer and lifelong supporter Richard Wilson reworked the soundtrack. Welles returned and cut 20 minutes from the film at Republic's request and recorded narration to cover some gaps. The film was decried as a disaster. "Macbeth" had influential fans in Europe, especially the French poet and filmmaker Jean Cocteau, who hailed the film's "crude, irreverent power" and careful shot design, and described the characters as haunting "the corridors of some dreamlike subway, an abandoned coal mine, and ruined cellars oozing with water."

In Italy he starred as Cagliostro in the 1948 film "Black Magic". His co-star, Akim Tamiroff, impressed Welles so much that Tamiroff would appear in four of Welles's productions during the 1950s and 1960s.

The following year, Welles starred as Harry Lime in Carol Reed's "The Third Man", alongside Joseph Cotten, his friend and co-star from "Citizen Kane", with a script by Graham Greene and a memorable score by Anton Karas.

A few years later, British radio producer Harry Alan Towers would resurrect the Lime character in the radio series "The Adventures of Harry Lime".

Welles appeared as Cesare Borgia in the 1949 Italian film "Prince of Foxes", with Tyrone Power and Mercury Theatre alumnus Everett Sloane, and as the Mongol warrior Bayan in the 1950 film version of the novel "The Black Rose" (again with Tyrone Power).

During this time, Welles was channeling his money from acting jobs into a self-financed film version of Shakespeare's play "Othello". From 1949 to 1951, Welles worked on "Othello", filming on location in Europe and Morocco. The film featured Welles's friends, Micheál Mac Liammóir as Iago and Hilton Edwards as Desdemona's father Brabantio. Suzanne Cloutier starred as Desdemona and Campbell Playhouse alumnus Robert Coote appeared as Iago's associate Roderigo.

Filming was suspended several times as Welles ran out of funds and left for acting jobs, accounted in detail in MacLiammóir's published memoir "Put Money in Thy Purse". The American release prints had a technically flawed soundtrack, suffering from a drop-out of sound at every quiet moment. Welles's daughter, Beatrice Welles-Smith, restored "Othello" in 1992 for a wide re-release. The restoration included reconstructing Angelo Francesco Lavagnino's original musical score, which was originally inaudible, and adding ambient stereo sound effects, which were not in the original film. The restoration went on to a successful theatrical run in America.

In 1952, Welles continued finding work in England after the success of the "Harry Lime" radio show. Harry Alan Towers offered Welles another series, "The Black Museum", which ran for 52 weeks with Welles as host and narrator. Director Herbert Wilcox offered Welles the part of the murdered victim in "Trent's Last Case", based on the novel by E. C. Bentley. In 1953, the BBC hired Welles to read an hour of selections from Walt Whitman's epic poem "Song of Myself". Towers hired Welles again, to play Professor Moriarty in the radio series, "The Adventures of Sherlock Holmes", starring John Gielgud and Ralph Richardson.

Welles briefly returned to America to make his first appearance on television, starring in the "Omnibus" presentation of "King Lear", broadcast live on CBS October 18, 1953. Directed by Peter Brook, the production costarred Natasha Parry, Beatrice Straight and Arnold Moss.

In 1954, director George More O'Ferrall offered Welles the title role in the 'Lord Mountdrago' segment of "Three Cases of Murder", co-starring Alan Badel. Herbert Wilcox cast Welles as the antagonist in "Trouble in the Glen" opposite Margaret Lockwood, Forrest Tucker and Victor McLaglen. Old friend John Huston cast him as Father Mapple in his 1956 film adaptation of Herman Melville's "Moby-Dick", starring Gregory Peck.

Welles's next turn as director was the film "Mr. Arkadin" (1955), which was produced by his political mentor from the 1940s, Louis Dolivet. It was filmed in France, Germany, Spain and Italy on a very limited budget. Based loosely on several episodes of the Harry Lime radio show, it stars Welles as a billionaire who hires a man to delve into the secrets of his past. The film stars Robert Arden, who had worked on the Harry Lime series; Welles's third wife, Paola Mori, whose voice was dubbed by actress Billie Whitelaw; and guest stars Akim Tamiroff, Michael Redgrave, Katina Paxinou and Mischa Auer. Frustrated by his slow progress in the editing room, producer Dolivet removed Welles from the project and finished the film without him. Eventually five different versions of the film would be released, two in Spanish and three in English. The version that Dolivet completed was retitled "Confidential Report". In 2005 Stefan Droessler of the Munich Film Museum oversaw a reconstruction of the surviving film elements.

In 1955, Welles also directed two television series for the BBC. The first was "Orson Welles' Sketch Book", a series of six 15-minute shows featuring Welles drawing in a sketchbook to illustrate his reminiscences for the camera (including such topics as the filming of "It's All True" and the Isaac Woodard case), and the second was "Around the World with Orson Welles", a series of six travelogues set in different locations around Europe (such as Venice, the Basque Country between France and Spain, and England). Welles served as host and interviewer, his commentary including documentary facts and his own personal observations (a technique he would continue to explore in later works).

In 1956, Welles completed "Portrait of Gina". The film cans would remain in a lost-and-found locker at the hotel for several decades, where they were discovered after Welles's death.

In 1956, Welles returned to Hollywood.

He began filming a projected pilot for Desilu, owned by Lucille Ball and her husband Desi Arnaz, who had recently purchased the former RKO studios. The film was "The Fountain of Youth", based on a story by John Collier. Originally deemed not viable as a pilot, the film was not aired until 1958—and won the Peabody Award for excellence.

Welles guest starred on television shows including "I Love Lucy". On radio, he was narrator of "Tomorrow" (October 17, 1956), a nuclear holocaust drama produced and syndicated by ABC and the Federal Civil Defense Administration.

Welles's next feature film role was in "Man in the Shadow" for Universal Pictures in 1957, starring Jeff Chandler.

Welles stayed on at Universal to direct (and co-star with) Charlton Heston in the 1958 film "Touch of Evil", based on Whit Masterson's novel "Badge of Evil". Originally only hired as an actor, Welles was promoted to director by Universal Studios at the insistence of Charlton Heston. The film reunited many actors and technicians with whom Welles had worked in Hollywood in the 1940s, including cameraman Russell Metty ("The Stranger"), makeup artist Maurice Seiderman ("Citizen Kane"), and actors Joseph Cotten, Marlene Dietrich and Akim Tamiroff. Filming proceeded smoothly, with Welles finishing on schedule and on budget, and the studio bosses praising the daily rushes. Nevertheless, after the end of production, the studio re-edited the film, re-shot scenes, and shot new exposition scenes to clarify the plot. Welles wrote a 58-page memo outlining suggestions and objections, stating that the film was no longer his version—it was the studio's, but as such, he was still prepared to help with it.

In 1978, a longer preview version of the film was discovered and released.

As Universal reworked "Touch of Evil", Welles began filming his adaptation of Miguel de Cervantes' novel "Don Quixote" in Mexico, starring Mischa Auer as Quixote and Akim Tamiroff as Sancho Panza.

He continued shooting "Don Quixote" in Spain and Italy, but replaced Mischa Auer with Francisco Reiguera, and resumed acting jobs.
In Italy in 1959, Welles directed his own scenes as King Saul in Richard Pottier's film "David and Goliath". In Hong Kong he co-starred with Curt Jürgens in Lewis Gilbert's film "Ferry to Hong Kong". In 1960, in Paris he co-starred in Richard Fleischer's film "Crack in the Mirror". In Yugoslavia he starred in Richard Thorpe's film "The Tartars" and Veljko Bulajić's "Battle of Neretva".

Throughout the 1960s, filming continued on "Quixote" on-and-off until the end of the decade, as Welles evolved the concept, tone and ending several times. Although he had a complete version of the film shot and edited at least once, he would continue toying with the editing well into the 1980s, he never completed a version film he was fully satisfied with, and would junk existing footage and shoot new footage. (In one case, he had a complete cut ready in which Quixote and Sancho Panza end up going to the moon, but he felt the ending was rendered obsolete by the 1969 moon landings, and burned 10 reels of this version.) As the process went on, Welles gradually voiced all of the characters himself and provided narration. In 1992, the director Jesús Franco constructed a film out of the portions of "Quixote" left behind by Welles. Some of the film stock had decayed badly. While the Welles footage was greeted with interest, the post-production by Franco was met with harsh criticism.
In 1961, Welles directed "In the Land of Don Quixote", a series of eight half-hour episodes for the Italian television network RAI. Similar to the "Around the World with Orson Welles" series, they presented travelogues of Spain and included Welles's wife, Paola, and their daughter, Beatrice. Though Welles was fluent in Italian, the network was not interested in him providing Italian narration because of his accent, and the series sat unreleased until 1964, by which time the network had added Italian narration of its own. Ultimately, versions of the episodes were released with the original musical score Welles had approved, but without the narration.

In 1962, Welles directed his adaptation of "The Trial", based on the novel by Franz Kafka and produced by Michael and Alexander Salkind. The cast included Anthony Perkins as Josef K, Jeanne Moreau, Romy Schneider, Paola Mori and Akim Tamiroff. While filming exteriors in Zagreb, Welles was informed that the Salkinds had run out of money, meaning that there could be no set construction. No stranger to shooting on found locations, Welles soon filmed the interiors in the Gare d'Orsay, at that time an abandoned railway station in Paris. Welles thought the location possessed a "Jules Verne modernism" and a melancholy sense of "waiting", both suitable for Kafka. To remain in the spirit of Kafka Welles set up the cutting room together with the Film Editor, Frederick Muller (as Fritz Muller), in the old un-used, cold, depressing, station master office. The film failed at the box-office. Peter Bogdanovich would later observe that Welles found the film riotously funny. Welles also told a BBC interviewer that it was his best film. While filming "The Trial" Welles met Oja Kodar, who later became his mistress and collaborator for the last 20 years of his life.

Welles played a film director in "La Ricotta" (1963), Pier Paolo Pasolini's segment of the "Ro.Go.Pa.G." movie, although his renowned voice was dubbed by Italian writer Giorgio Bassani. He continued taking what work he could find acting, narrating or hosting other people's work, and began filming "Chimes at Midnight", which was completed in 1966.

Filmed in Spain, "Chimes at Midnight" was based on Welles's play, "Five Kings", in which he drew material from six Shakespeare plays to tell the story of Sir John Falstaff (Welles) and his relationship with Prince Hal (Keith Baxter). The cast includes John Gielgud, Jeanne Moreau, Fernando Rey and Margaret Rutherford; the film's narration, spoken by Ralph Richardson, is taken from the chronicler Raphael Holinshed. Welles held the film in high regard: "It's my favorite picture, yes. If I wanted to get into heaven on the basis of one movie, that's the one I would offer up."

In 1966, Welles directed a film for French television, an adaptation of "The Immortal Story", by Karen Blixen. Released in 1968, it stars Jeanne Moreau, Roger Coggio and Norman Eshley. The film had a successful run in French theaters. At this time Welles met Oja Kodar again, and gave her a letter he had written to her and had been keeping for four years; they would not be parted again. They immediately began a collaboration both personal and professional. The first of these was an adaptation of Blixen's "The Heroine", meant to be a companion piece to "The Immortal Story" and starring Kodar. Unfortunately, funding disappeared after one day's shooting. After completing this film, he appeared in a brief cameo as Cardinal Wolsey in Fred Zinnemann's adaptation of "A Man for All Seasons"—a role for which he won considerable acclaim.
In 1967, Welles began directing "The Deep", based on the novel "Dead Calm" by Charles Williams and filmed off the shore of Yugoslavia. The cast included Jeanne Moreau, Laurence Harvey and Kodar. Personally financed by Welles and Kodar, they could not obtain the funds to complete the project, and it was abandoned a few years later after the death of Harvey. The surviving footage was eventually edited and released by the Filmmuseum München. In 1968 Welles began filming a TV special for CBS under the title "Orson's Bag", combining travelogue, comedy skits and a condensation of Shakespeare's play "The Merchant of Venice" with Welles as Shylock. In 1969 Welles called again the Film Editor Frederick Muller to work with him re-editing the material and they set up cutting rooms at the Safa Palatino Studios in Rome. Funding for the show sent by CBS to Welles in Switzerland was seized by the IRS. Without funding, the show was not completed. The surviving film clips portions were eventually released by the Filmmuseum München.

In 1969, Welles authorized the use of his name for a cinema in Cambridge, Massachusetts. The Orson Welles Cinema remained in operation until 1986, with Welles making a personal appearance there in 1977. Also in 1969 he played a supporting role in John Huston's "The Kremlin Letter". Drawn by the numerous offers he received to work in television and films, and upset by a tabloid scandal reporting his affair with Kodar, Welles abandoned the editing of "Don Quixote" and moved back to America in 1970.

Welles returned to Hollywood, where he continued to self-finance his film and television projects. While offers to act, narrate and host continued, Welles also found himself in great demand on television talk shows. He made frequent appearances for Dick Cavett, Johnny Carson, Dean Martin and Merv Griffin.

Welles's primary focus during his final years was "The Other Side of the Wind", an unfinished project that was filmed intermittently between 1970 and 1976. Written by Welles, it is the story of an aging film director (John Huston) looking for funds to complete his final film. The cast includes Peter Bogdanovich, Susan Strasberg, Norman Foster, Edmond O'Brien, Cameron Mitchell and Dennis Hopper. Financed by Iranian backers, ownership of the film fell into a legal quagmire after the Shah of Iran was deposed. While there have been several reports of all the legal disputes concerning ownership of the film being settled, enough disputes still exist to prevent its release.
Welles portrayed Louis XVIII of France in the 1970 film "Waterloo", and narrated the beginning and ending scenes of the historical comedy "Start the Revolution Without Me" (1970).

In 1971, Welles directed a short adaptation of "Moby-Dick", a one-man performance on a bare stage, reminiscent of his 1955 stage production "Moby Dick—Rehearsed". Never completed, it was eventually released by the Filmmuseum München. He also appeared in "Ten Days' Wonder", co-starring with Anthony Perkins and directed by Claude Chabrol, based on a detective novel by Ellery Queen. That same year, the Academy of Motion Picture Arts and Sciences gave him an honorary award "For superlative artistry and versatility in the creation of motion pictures". Welles pretended to be out of town and sent John Huston to claim the award, thanking the Academy on film. Huston criticized the Academy for awarding Welles, even while they refused to give Welles any work.

In 1972, Welles acted as on-screen narrator for the film documentary version of Alvin Toffler's 1970 book "Future Shock". Working again for a British producer, Welles played Long John Silver in director John Hough's "Treasure Island" (1972), an adaptation of the Robert Louis Stevenson novel, which had been the second story broadcast by "The Mercury Theatre on the Air" in 1938. This was the last time he played the lead role in a major film. Welles also contributed to the script, his writing credit was attributed to the pseudonym 'O. W. Jeeves'. In some versions of the film Welles's original recorded dialog was redubbed by Robert Rietty.

In 1973, Welles completed "F for Fake", a personal essay film about art forger Elmyr de Hory and the biographer Clifford Irving. Based on an existing documentary by François Reichenbach, it included new material with Oja Kodar, Joseph Cotten, Paul Stewart and William Alland. An excerpt of Welles's 1930s "War of the Worlds" broadcast was recreated for this film; however, none of the dialogue heard in the film actually matches what was originally broadcast. Welles filmed a five-minute trailer, rejected in the U.S., that featured several shots of a topless Kodar.

Welles hosted a British syndicated anthology series, "Orson Welles's Great Mysteries", during the 1973–74 television season. His brief introductions to the 26 half-hour episodes were shot in July 1973 by Gary Graver. The year 1974 also saw Welles lending his voice for that year's remake of Agatha Christie's classic thriller "Ten Little Indians" produced by his former associate, Harry Alan Towers and starring an international cast that included Oliver Reed, Elke Sommer and Herbert Lom.

In 1975, Welles narrated the documentary "", focusing on Warner Bros. cartoons from the 1940s. Also in 1975, the American Film Institute presented Welles with its third Lifetime Achievement Award (the first two going to director John Ford and actor James Cagney). At the ceremony, Welles screened two scenes from the nearly finished "The Other Side of the Wind".

In 1976, Paramount Television purchased the rights for the entire set of Rex Stout's Nero Wolfe stories for Orson Welles. Welles had once wanted to make a series of Nero Wolfe movies, but Rex Stout—who was leery of Hollywood adaptations during his lifetime after two disappointing 1930s films—turned him down. Paramount planned to begin with an ABC-TV movie and hoped to persuade Welles to continue the role in a mini-series. Frank D. Gilroy was signed to write the television script and direct the TV movie on the assurance that Welles would star, but by April 1977 Welles had bowed out. In 1980 the Associated Press reported "the distinct possibility" that Welles would star in a Nero Wolfe TV series for NBC television. Again, Welles bowed out of the project due to creative differences and William Conrad was cast in the role.

In 1979, Welles completed his documentary "Filming Othello", which featured Michael MacLiammoir and Hilton Edwards. Made for West German television, it was also released in theaters. That same year, Welles completed his self-produced pilot for "The Orson Welles Show" television series, featuring interviews with Burt Reynolds, Jim Henson and Frank Oz and guest-starring the Muppets and Angie Dickinson. Unable to find network interest, the pilot was never broadcast. Also in 1979, Welles appeared in the biopic "The Secret of Nikola Tesla", and a cameo in "The Muppet Movie" as Lew Lord.

Beginning in the late 1970s, Welles participated in a series of famous television commercial advertisements. For two years he was on-camera spokesman for the Paul Masson Vineyards, and sales grew by one third during the time Welles intoned what became a popular catchphrase: "We will sell no wine before its time." He was also the voice behind the long-running Carlsberg "Probably the best lager in the world" campaign, promoted Domecq sherry on British television and provided narration on adverts for Findus, though the actual adverts have been overshadowed by a famous blooper reel of voice recordings, known as the Frozen Peas reel. He also did commercials for the Preview Subscription Television Service seen on stations around the country including WCLQ/Cleveland, KNDL/St. Louis and WSMW/Boston. As money ran short, he began directing commercials to make ends meet, including the famous British "Follow the Bear" commercials for Hofmeister lager.

In 1981, Welles hosted the documentary "The Man Who Saw Tomorrow", about Renaissance-era prophet Nostradamus. In 1982, the BBC broadcast "The Orson Welles Story" in the "Arena" series. Interviewed by Leslie Megahey, Welles examined his past in great detail, and several people from his professional past were interviewed as well. It was reissued in 1990 as "With Orson Welles: Stories of a Life in Film". Welles provided narration for the tracks "Defender" from Manowar's 1987 album "Fighting the World" and "Dark Avenger" on their 1982 album, "Battle Hymns".

During the 1980s, Welles worked on such film projects as "The Dreamers", based on two stories by Isak Dinesen and starring Oja Kodar, and "Orson Welles' Magic Show", which reused material from his failed TV pilot. Another project he worked on was "Filming The Trial", the second in a proposed series of documentaries examining his feature films. While much was shot for these projects, none of them was completed. All of them were eventually released by the Filmmuseum München.

In 1984, Welles narrated the short-lived television series "Scene of the Crime". During the early years of "Magnum, P.I.", Welles was the voice of the unseen character Robin Masters, a famous writer and playboy. Welles's death forced this minor character to largely be written out of the series. In an oblique homage to Welles, the "Magnum, P.I." producers ambiguously concluded that story arc by having one character accuse another of having hired an actor to portray Robin Masters. He also, in this penultimate year released a music single, titled "I Know What It Is To Be Young (But You Don't Know What It Is To Be Old)", which he recorded under Italian label Compagnia Generale del Disco. The song was performed with the Nick Perito Orchestra and the Ray Charles Singers and produced by Jerry Abbott (father of guitarist "Dimebag Darrell" Abbott).

The last film roles before Welles's death included voice work in the animated films "Enchanted Journey" (1984) and "" (1986), in which he played the planet-eating robot Unicron. His last film appearance was in Henry Jaglom's 1987 independent film "Someone to Love", released after his death but produced before his voice-over in "Transformers: The Movie". His last television appearance was on the television show "Moonlighting". He recorded an introduction to an episode entitled "The Dream Sequence Always Rings Twice", which was partially filmed in black and white. The episode aired five days after his death and was dedicated to his memory.

In the mid-1980s, Henry Jaglom taped lunch conversations with Welles at Los Angeles's Ma Maison as well as in New York. Edited transcripts of these sessions appear in Peter Biskind's 2013 book "My Lunches With Orson: Conversations Between Henry Jaglom and Orson Welles".

Orson Welles and Chicago-born actress and socialite Virginia Nicolson (1916–1996) were married on November 14, 1934. The couple separated in December 1939 and were divorced on February 1, 1940. After bearing with Welles's romances in New York, Virginia had learned that Welles had fallen in love with Mexican actress Dolores del Río.

Infatuated with her since adolescence, Welles met del Río at Darryl Zanuck's ranch soon after he moved to Hollywood in 1939. Their relationship was kept secret until 1941, when del Río filed for divorce from her second husband. They openly appeared together in New York while Welles was directing the Mercury stage production "Native Son". They acted together in the movie "Journey into Fear" (1943). Their relationship came to an end due, among other things, to Welles's infidelities. Del Río returned to México in 1943, shortly before Welles married Rita Hayworth.

Welles married Rita Hayworth on September 7, 1943. They were divorced on November 10, 1947. During his last interview, recorded for "The Merv Griffin Show" on the evening before his death, Welles called Hayworth "one of the dearest and sweetest women that ever lived … and we were a long time together—I was lucky enough to have been with her longer than any of the other men in her life."

In 1955, Welles married actress Paola Mori (née Countess Paola di Girifalco), an Italian aristocrat who starred as Raina Arkadin in his 1955 film, "Mr. Arkadin". The couple began a passionate affair, and they were married at her parents' insistence. They were wed in London May 8, 1955, and never divorced.

Croatian-born artist and actress Oja Kodar became Welles's longtime companion both personally and professionally from 1966 onward, and they lived together for some of the last 20 years of his life.

Welles had three daughters from his marriages: Christopher Welles Feder (born March 27, 1938, with Virginia Nicolson); Rebecca Welles Manning (December 17, 1944 – October 17, 2004, with Rita Hayworth); and Beatrice Welles (born November 13, 1955, with Paola Mori).

Welles is thought to have had a son, British director Michael Lindsay-Hogg (born May 5, 1940), with Irish actress Geraldine Fitzgerald, then the wife of Sir Edward Lindsay-Hogg, 4th baronet. When Lindsay-Hogg was 16, his mother reluctantly divulged pervasive rumors that his father was Welles, and she denied them—but in such detail that he doubted her veracity. Fitzgerald evaded the subject for the rest of her life. Lindsay-Hogg knew Welles, worked with him in the theatre and met him at intervals throughout Welles's life. After learning that Welles's oldest daughter, Chris, his childhood playmate, had long suspected that he was her brother, Lindsay-Hogg initiated a DNA test that proved inconclusive. In his 2011 autobiography, Lindsay-Hogg reported that his questions were resolved by his mother's close friend Gloria Vanderbilt, who wrote that Fitzgerald had told her that Welles was his father. A 2015 Welles biography by Patrick McGilligan, however, reports the impossibility of Welles's paternity: Fitzgerald left the U.S. for Ireland in May 1939, and her son was conceived before her return in late October, whereas Welles did not travel overseas during that period.

After the death of Rebecca Welles Manning, a man named Marc McKerrow was revealed to be her son—and therefore a direct descendant of Orson Welles and Rita Hayworth. McKerrow's reactions to the revelation and his meeting with Oja Kodar are documented in the 2008 film "Prodigal Sons". McKerrow died on June 18, 2010.

Despite an urban legend promoted by Welles, he was not related to Abraham Lincoln's wartime Secretary of the Navy, Gideon Welles. The myth dates back to the first newspaper feature ever written about Welles—"Cartoonist, Actor, Poet and only 10"—in the February 19, 1926, issue of "The Capital Times". The article falsely states that he was descended from "Gideon Welles, who was a member of President Lincoln's cabinet". As presented by Charles Higham in a genealogical chart that introduces his 1985 biography of Welles, Orson Welles's father was Richard Head Welles (born Wells), son of Richard Jones Wells, son of Henry Hill Wells (who had an uncle named Gideon "Wells"), son of William Hill Wells, son of Richard Wells (1734–1801).

Peter Noble's 1956 biography describes Welles as "a magnificent figure of a man, over six feet tall, handsome, with flashing eyes and a gloriously resonant speaking-voice". Welles said that a voice specialist once told him he was born to be a heldentenor, a heroic tenor, but that when he was young and working at the Gate Theatre in Dublin, he forced his voice down into a bass-baritone.

Even as a baby, Welles was prone to illness, including diphtheria, measles, whooping cough, and malaria. From infancy he suffered from asthma, sinus headaches, and backache that was later found to be caused by congenital anomalies of the spine. Foot and ankle trouble throughout his life was the result of flat feet. "As he grew older", Brady wrote, "his ill health was exacerbated by the late hours he was allowed to keep [and] an early penchant for alcohol and tobacco".

In 1928, at age 13, Welles was already more than six feet tall and weighed over 180 pounds. His passport recorded his height as six feet three inches, with brown hair and green eyes.

"Crash diets, drugs, and corsets had slimmed him for his early film roles", wrote biographer Barton Whaley. "Then always back to gargantuan consumption of high-caloric food and booze. By summer 1949, when he was 34, his weight had crept up to a stout 230 pounds. In 1953, he ballooned from 250 to 275 pounds. After 1960, he remained permanently obese."

When Peter Bogdanovich once asked him about his religion, Welles gruffly replied that it was none of his business, then misinformed him that he was raised Catholic.

Although the Welles family was no longer devout, it was fourth-generation Protestant Episcopalian and, before that, Quaker and Puritan.

The funeral of Welles's father, Richard H. Welles, was Episcopalian.

In April 1982, when interviewer Merv Griffin asked him about his religious beliefs, Welles replied, "I try to be a Christian. I don't pray really, because I don't want to bore God." Near the end of his life, Welles was dining at Ma Maison, his favorite restaurant in Los Angeles, when proprietor Patrick Terrail conveyed an invitation from the head of the Greek Orthodox Church, who asked Welles to be his guest of honor at divine liturgy at Saint Sophia Cathedral. Welles replied, "Please tell him I really appreciate that offer, but I am an atheist."

"Orson never joked or teased about the religious beliefs of others", wrote biographer Barton Whaley. "He accepted it as a cultural artifact, suitable for the births, deaths, and marriages of strangers and even some friends—but without emotional or intellectual meaning for himself."

Welles was politically active from the beginning of his career. He remained aligned with the left throughout his life, and always defined his political orientation as "progressive". He was a strong supporter of Franklin D. Roosevelt and the New Deal and often spoke out on radio in support of progressive politics. He campaigned heavily for Roosevelt in the 1944 election. Welles did not support the 1948 presidential bid of Roosevelt's vice president Henry A. Wallace for the Progressive Party, however, later describing Wallace as "a prisoner of the Communist Party."

"During a White House dinner," Welles recalled in a 1983 conversation with his friend Roger Hill, "when I was campaigning for Roosevelt, in a toast, with considerable tongue in cheek, he said, 'Orson, you and I are the two greatest actors alive today.' In private that evening, and on several other occasions, he urged me to run for a Senate seat in either California or Wisconsin. He wasn't alone." In the 1980s, Welles still expressed admiration for Roosevelt but also described his presidency as "a semidictatorship."

For several years, he wrote a newspaper column on political issues and considered running for the U.S. Senate in 1946, representing his home state of Wisconsin—a seat that was ultimately won by Joseph McCarthy.

Welles's political activities were reported on pages 155–157 of "Red Channels", the anti-Communist publication that, in part, fueled the already flourishing Hollywood Blacklist. He was in Europe during the height of the Red Scare, thereby adding one more reason for the Hollywood establishment to ostracize him. 

In 1970, Welles narrated (but did not write) a satirical political record on the administration of President Richard Nixon titled "The Begatting of the President".

He was also an outspoken critic of racism in the United States and the practice of segregation.

On the evening of October 9, 1985, Welles recorded his final interview on syndicated TV program "The Merv Griffin Show", appearing with biographer Barbara Leaming. "Both Welles and Leaming talked of Welles's life, and the segment was a nostalgic interlude," wrote biographer Frank Brady. Welles returned to his house in Hollywood and worked into the early hours typing stage directions for the project he and Gary Graver were planning to shoot at UCLA the following day. Welles died sometime on the morning of October 10, following a heart attack. He was found by his chauffeur at around 10 a.m.; the first of Welles's friends to arrive was Paul Stewart.

Welles was cremated by prior agreement with the executor of his estate, Greg Garrison, whose advice about making lucrative TV appearances in the 1970s made it possible for Welles to pay off a portion of the taxes he owed the IRS. A brief private funeral was attended by Paola Mori and Welles's three daughters—the first time they had ever been together. Only a few close friends were invited: Garrison, Graver, Roger Hill and Prince Alessandro Tasca di Cuto. Chris Welles Feder later described the funeral as an awful experience.

A public memorial tribute took place November 2, 1985, at the Directors Guild of America Theater in Los Angeles. Host Peter Bogdanovich introduced speakers including Charles Champlin, Geraldine Fitzgerald, Greg Garrison, Charlton Heston, Roger Hill, Henry Jaglom, Arthur Knight, Oja Kodar, Barbara Leaming, Janet Leigh, Norman Lloyd, Dan O'Herlihy, Patrick Terrail and Robert Wise.

"I know what his feelings were regarding his death", Joseph Cotten later wrote. "He did not want a funeral; he wanted to be buried quietly in a little place in Spain. He wanted no memorial services ..." Cotten declined to attend the memorial program; instead he sent a short message, ending with the last two lines of a Shakespeare sonnet that Welles had sent him on his most recent birthday:

But if the while I think on thee, dear friend,All losses are restored and sorrows end.

In 1987 the ashes of Welles and Mori (killed in a 1986 car crash) were taken to Ronda, Spain, and buried in an old well covered by flowers on the rural estate of a longtime friend, bullfighter Antonio Ordóñez.

Welles's reliance on self-production meant that many of his later projects were filmed piecemeal or were not completed. Welles financed his later projects through his own fundraising activities. He often also took on other work to obtain money to fund his own films.

In the mid-1950s, Welles began work on "Don Quixote", initially a commission from CBS television. Welles expanded the film to feature length, developing the screenplay to take Quixote and Sancho Panza into the modern age. Filming stopped with the death of Francisco Reiguera, the actor playing Quixote, in 1969. Orson Welles continued editing the film into the early 1970s. At the time of his death, the film remained largely a collection of footage in various states of editing. The project and, more important, Welles's conception of the project changed radically over time. A version of the film was created from available fragments in 1992 and released to a very negative reception.

A version Oja Kodar supervised, with help from Jess Franco, assistant director during production, was released in 2008 to mixed reactions.

Frederick Muller—the film editor for The "Trial", "Chimes at Midnight" and the CBS Special "Orson Bag" was fortunate to work on editing three reels of the original, unadulterated version—and when asked for his opinion in 2013 from a journalist of "Time Out", his reply was that he felt that if released without image re-editing but with the addition of "ad hoc" sound and music, it probably would have been rather successful.

In 1969, Welles was given another TV commission to film a condensed adaptation of "The Merchant of Venice". Although Welles had actually completed the film by 1970, the finished negative was later mysteriously stolen from his Rome production office. A restored and reconstructed version of the film, made by using the original script and composer's notes, premiered at the 72nd Venice International Film Festival alongside "Othello" as part of the pre-opening ceremonies in 2015.

In 1970, Welles began shooting "The Other Side of the Wind". The film relates the efforts of a film director (played by John Huston) to complete his last Hollywood picture and is largely set at a lavish party. By 1972 the filming was reported by Welles as being "96% complete", though it is likely that Welles had only edited about 40 minutes of the film by 1979. In that year, legal complications over the ownership of the film forced the negative into a Paris vault. In 2004 director Peter Bogdanovich, who acted in the film, announced his intention to complete the production. As of 2009, legal complications over the Welles estate had kept the film from being finished or released.

On October 28, 2014, Los Angeles-based production company Royal Road Entertainment announced it had negotiated an agreement, with the assistance of producer Frank Marshall, and would purchase the rights to complete and release "The Other Side of the Wind". Bogdanovich and Marshall planned to complete Welles's nearly finished film in Los Angeles, aiming to have it ready for screening May 6, 2015, the 100th anniversary of Welles's birth. Royal Road Entertainment and German producer Jens Koethner Kaul acquired the rights held by Les Films de l'Astrophore and the late Mehdi Boushehri. They reached an agreement with Oja Kodar, who inherited Welles's ownership of the film, and Beatrice Welles, manager of the Welles estate; but at the end of 2015, efforts to complete the film were at an impasse.

In March 2017, Netflix acquired distribution rights to the film. That same month, the original negative, dallies and other footage arrived in Los Angeles, thus resuming the post-production process.

Some footage is included in the documentaries "Working with Orson Welles" (1993) and "Orson Welles: One Man Band" (1995).

"Too Much Johnson" is a 1938 comedy film written and directed by Welles. Designed as the cinematic aspect of Welles's Mercury Theatre stage presentation of William Gillette's 1894 comedy, the film was not completely edited or publicly screened. "Too Much Johnson" was considered a lost film until August 2013 news reports that a pristine print was discovered in Italy in 2008. A copy restored by the George Eastman House museum was scheduled to premiere October 9, 2013, at the Pordenone Silent Film Festival, with a U.S. premiere to follow. A single performance of "Too Much Johnson", on February 2, 2015, at the Film Forum in New York City, was a great success. Produced by Bruce Goldstein and adapted and directed by Allen Lewis Rickman, it featured the Film Forum Players with live piano.

"Heart of Darkness" was Welles's projected first film, in 1940. It was planned in extreme detail and some test shots were filmed; the footage is now lost. It was planned to be entirely shot in long takes from the point of view of the narrator, Marlow, who would be played by Welles; his reflection would occasionally be seen in the window as his boat sailed down river. The project was abandoned because it could not be delivered on budget, and "Citizen Kane" was made instead.

In 1941, Welles planned a film with his then partner, the Mexican actress Dolores del Río. "Santa" was adapted from the novel by Mexican writer Federico Gamboa. The film would have marked the debut of Dolores del Río in the Mexican cinema. Welles made a correction of the script in 13 extraordinary sequences. Unfortunately, the high salary demanded by Del Río stopped the project. In 1943, the film was finally completed with the settings of Welles, led by Norman Foster and starring Mexican actress Esther Fernández.

In 1941 Welles also planned a Mexican drama with Dolores del Río, which he gave to RKO to be budgeted. The film was a movie version of the novel by the same name by Calder Marshall. In the story, Dolores del Río would play Elena Medina, "the most beautiful girl in the world", with Welles playing an American who becomes entangled in a mission to disrupt a Nazi plot to overthrow the Mexican government. Welles planned to shoot in Mexico, but the Mexican government had to approve the story, and this never occurred.

In 1941, Welles received the support of Bishop Fulton Sheen for a retelling of the life of Christ, to be set in the American West in the 1890s. After filming of "Citizen Kane" was complete, Welles, Perry Ferguson and Gregg Toland scouted locations in Baja California and Mexico. Welles wrote a screenplay with dialogue from the Gospels of Mark, Matthew and Luke. "Every word in the film was to be from the Bible — no original dialogue, but done as a sort of American primitive," Welles said, "set in the frontier country in the last century." The unrealized project was revisited by Welles in the 1950s, when he wrote a second unfilmed screenplay, to be shot in Egypt.

Welles did not originally want to direct "It's All True", a 1942 documentary on South America, but after its abandonment by RKO, he spent much of the 1940s attempting to buy the negative of his material from RKO, so that he could edit and release it in some form. The footage remained unseen in vaults for decades, and was assumed lost. Over 50 years later, some (but not all) of the surviving material saw release in the 1993 documentary "It's All True: Based on an Unfinished Film by Orson Welles".

In 1944, Welles wrote the first-draft script of "Monsieur Verdoux", a film that he also intended to direct. Charlie Chaplin initially agreed to star in it, but later changed his mind, citing never having been directed by someone else in a feature before. Chaplin bought the film rights and made the film himself in 1947, with some changes. The final film credits Chaplin with the script, "based on an idea by Orson Welles".

Welles spent around nine months c. 1947–48 co-writing the screenplay for "Cyrano de Bergerac" along with Ben Hecht, a project Welles was assigned to direct for Alexander Korda. He began scouting for locations in Europe whilst filming "Black Magic", but Korda was short of money, so sold the rights to Columbia pictures, who eventually dismissed Welles from the project, and then sold the rights on to United Artists, who in turn made made a film version in 1950, which was not based on Welles's script.

After Welles's elaborate musical stage version of this Jules Verne novel, encompassing 38 different sets, he began shooting some test footage in Morocco for a film version in 1947. The footage was never edited, funding never came through, and Welles abandoned the project. Nine years later, the stage show's producer Mike Todd made his own award-winning film version of the book.

"Moby Dick—Rehearsed" was a film version of Welles's 1955 London meta-play, starring Gordon Jackson, Christopher Lee, Patrick McGoohan, and with Welles as Ahab. Using bare, minimalist sets, Welles alternated between a cast of nineteenth-century actors rehearsing a production of "Moby Dick", with scenes from "Moby Dick" itself. Kenneth Williams, a cast member who was apprehensive about the entire project, recorded in his autobiography that Welles's dim, atmospheric stage lighting made some of the footage so dark as to be unwatchable. The entire play was filmed, but is now presumed lost. This was made during one weekend at the Hackney Empire theatre.

The producers of "Histoires extraordinaires", a 1968 anthology film based on short stories by Edgar Allan Poe, announced in June 1967 that Welles would direct one segment based on both "Masque of the Red Death" and "The Cask of Amontillado" for the omnibus film. Welles withdrew in September 1967 and was replaced. The script, written in English by Welles and Oja Kodar, is in the Filmmuseum Munchen collection.

This Monty Python-esque spoof in which Welles plays all but one of the characters (including two characters in drag), was made around 1968-9. Welles intended this completed sketch to be one of several items in a television special on London. Other items filmed for this special – all included in the "One Man Band" documentary by his partner Oja Kodar — comprised a sketch on Winston Churchill (played in silhouette by Welles), a sketch on peers in a stately home, a feature on London gentlemen's clubs, and a sketch featuring Welles being mocked by his snide Savile Row tailor (played by Charles Gray).

Welles wrote two screenplays for "Treasure Island" in the 1960s, and was eager to seek financial backing to direct it. Eventually, his own screenplay (under the pseudonym of O.W. Jeeves) was further rewritten, and formed the basis of the 1972 film version directed by John Hough, in which Welles played Long John Silver.

"The Deep", an adaptation of Charles Williams' "Dead Calm", was entirely set on two boats and shot mostly in close-ups. It was filmed off the coasts of Yugoslavia and the Bahamas between 1966 and 1969, with all but one scene completed. It was originally planned as a commercially viable thriller, to show that Welles could make a popular, successful film. It was put on hold in 1970 when Welles worried that critics would not respond favorably to this film as his theatrical follow-up to the much-lauded "Chimes at Midnight", and Welles focused instead on "F for Fake". It was abandoned altogether in 1973 due to the death of its star Laurence Harvey.

"Dune", an early attempt at adapting Frank Herbert's sci-fi novel by Chilean film director Alejandro Jodorowsky, was to star Welles as the evil Baron Vladimir Harkonnen. Jodorowsky had personally chosen Welles for the role, but the planned film never advanced past pre-production.

In 1978 Welles was lined up by his long-time protégé Peter Bogdanovich (who was then acting as Welles's "de facto" agent) to direct "Saint Jack", an adaptation of the 1973 Paul Theroux novel about an American pimp in Singapore. Hugh Hefner and Bogdanovich's then-partner Cybill Shepherd were both attached to the project as producers, with Hefner providing finance through his Playboy productions. However, both Hefner and Shepherd became convinced that Bogdanovich himself would be a more commercially viable director than Welles, and insisted that Bogdanovich take over. Since Bogdanovich was also in need of work after a series of box office flops, he agreed. When the film was finally made in 1979 by Bogdanovich and Hefner (but without Welles or Shepherd's participation), Welles felt betrayed and according to Bogdanovich the two "drifted apart a bit".

After the success of his 1978 film "Filming Othello" made for West German television, and mostly consisting of a monologue to the camera, Welles began shooting scenes for this follow-up film, but never completed it. What Welles did film was an 80-minute question-and-answer session in 1981 with film students asking about the film. The footage was kept by Welles's cinematographer Gary Graver, who donated it to the Munich Film Museum, which then pieced it together with Welles's trailer for the film, into an 83-minute film which is occasionally screened at film festivals.

Written by Welles with Oja Kodar, "The Big Brass Ring" was adapted and filmed by director George Hickenlooper in partnership with writer F.X. Feeney. Both the Welles script and the 1999 film center on a U.S. Presidential hopeful in his 40s, his elderly mentor—a former candidate for the Presidency, brought low by homosexual scandal—and the Italian journalist probing for the truth of the relationship between these men. During the last years of his life, Welles struggled to get financing for the planned film; however, his efforts at casting Jack Nicholson, Robert Redford, Warren Beatty, Clint Eastwood, Burt Reynolds and Paul Newman as the main character were unsuccessful. All of the actors turned down the role for various reasons.

In 1984, Welles wrote the screenplay for a film he planned to direct, an autobiographical drama about the 1937 staging of "The Cradle Will Rock". Rupert Everett was slated to play the young Welles. However, Welles was unable to acquire funding. Tim Robbins later directed a similar film, but it was not based on Welles's script.

At the time of his death, Welles was in talks with a French production company to direct a film version of the Shakespeare play "King Lear", in which he would also play the title role.

"" was an adaptation of Vladimir Nabokov's novel. Welles flew to Paris to discuss the project personally with the Russian author.










</doc>
<doc id="22197" url="https://en.wikipedia.org/wiki?curid=22197" title="Open content">
Open content

Open content is a neologism coined by David Wiley in 1998 which describes a creative work that others can copy or modify freely, without asking for permission. The term evokes the related concept of open-source software. Such content is said to be under an open licence.

Originally, the Open content concept was invented by Michael Stutz, who in 1994 wrote the paper "Applying Copyleft to Non-Software Information" for the GNU Project. The "Open Content" term was later evangelized via the "Open Content Project" by David A. Wiley in 1998, and described works licensed under the Open Content License (a non-free share-alike license, see 'Free content' below) and other works licensed under similar terms.

It has since come to describe a broader class of content without conventional copyright restrictions. The openness of content can be assessed under the '5Rs Framework' based on the extent to which it can be reused, revised, remixed and redistributed by members of the public without violating copyright law. Unlike open-source and free content, there is no clear threshold that a work must reach to qualify as 'open content'.

Although open content has been described as a counterbalance to copyright, open content licenses rely on a copyright holder's power to license their work, similarly as copyleft which also utilizes copyright for such a purpose.

In 2003 Wiley announced that the Open Content Project has been succeeded by Creative Commons and their licenses, where he joined as "Director of Educational Licenses".

In 2006 the Creative Commons' successor project was the "Definition of Free Cultural Works" for free content, put forth by Erik Möller, Richard Stallman, Lawrence Lessig, Benjamin Mako Hill, Angela Beesley, and others. The "Definition of Free Cultural Works" is used by the Wikimedia Foundation. In 2008, the Attribution and Attribution-ShareAlike Creative Commons licenses were marked as "Approved for Free Cultural Works" among other licenses.
Another successor project is the "Open Knowledge Foundation" ("OKF"), founded by Rufus Pollock in Cambridge, UK in 2004 as a global non-profit network to promote and share open content and data. In 2007 the Open Knowledge Foundation gave an "Open Knowledge Definition" for ""Content such as music, films, books; Data be it scientific, historical, geographic or otherwise; Government and other administrative information"". In October 2014 with version 2.0 "Open Works" and "Open Licenses" were defined and "open" is described as synonymous to the definitions of open/free in the Open Source Definition, the Free Software Definition and the Definition of Free Cultural Works. A distinct difference is the focus given to the public domain and that it focuses also on the accessibility ("open access") and the readability ("open formats"). Among several conformant licenses, six are recommended, three own (Open Data Commons Public Domain Dedication and Licence (PDDL), Open Data Commons Attribution License (ODC-BY), Open Data Commons Open Database License (ODbL)) and the CC BY, CC BY-SA, and CC0 creative commons licenses.

The OpenContent website once defined OpenContent as 'freely available for modification, use and redistribution under a license similar to those used by the open-source / free software community'. However, such a definition would exclude the Open Content License (OPL) because that license forbade charging 'a fee for the [OpenContent] itself', a right required by free and open-source software licenses.

The term since shifted in meaning. OpenContent ""is licensed in a manner that provides users with free and perpetual permission to engage in the 5R activities.""

The 5Rs are put forward on the OpenContent website as a framework for assessing the extent to which content is open:

This broader definition distinguishes open content from open-source software, since the latter must be available for commercial use by the public. However, it is similar to several definitions for open educational resources, which include resources under noncommercial and verbatim licenses.

The later "Open Definition" by the Open Knowledge Foundation (now known as Open Knowledge International) define open knowledge with open content and open data as sub-elements and draws heavily on the Open Source Definition; it preserves the limited sense of open content as free content, unifying both.

"Open access" refers to toll-free or gratis access to content, mainly published originally peer-reviewed scholarly journals. Some open access works are also licensed for reuse and redistribution ("libre open access"), which would qualify them as open content.

Over the past decade, open content has been used to develop alternative routes towards higher education. Traditional universities are expensive, and their tuition rates are increasing. Open content allows a free way of obtaining higher education that is "focused on collective knowledge and the sharing and reuse of learning and scholarly content."
There are multiple projects and organizations that promote learning through open content, including OpenCourseWare Initiative, The Saylor Foundation and Khan Academy. Some universities, like MIT, Yale, and Tufts are making their courses freely available on the internet.

The textbook industry is one of the educational industries in which open content can make the biggest impact. Traditional textbooks, aside from being expensive, can also be inconvenient and out of date, because of publishers' tendency to constantly print new editions. Open textbooks help to eliminate this problem, because they are online and thus easily updatable. Being openly licensed and online can be helpful to teachers, because it allows the textbook to be modified according to the teacher's unique curriculum. There are multiple organizations promoting the creation of openly licensed textbooks. Some of these organizations and projects include The University of Minnesota's Open Textbook Library, Connexions, OpenStax College, The Saylor Foundation Open Textbook Challenge and Wikibooks

According to the current definition of open content on the OpenContent website, any general, royalty-free copyright license would qualify as an open license because it 'provides users with the right to make more kinds of uses than those normally permitted under the law. These permissions are granted to users free of charge.'

However, the narrower definition used in the Open Definition effectively limits open content to libre content, any free content license, defined by the Definition of Free Cultural Works, would qualify as an open content license. According to this narrower criteria, the following still-maintained licenses qualify:

(For more licenses see Open Knowledge, Free content and Free Cultural Works licenses)




</doc>
<doc id="22199" url="https://en.wikipedia.org/wiki?curid=22199" title="Ohio">
Ohio

Ohio is a Midwestern state in the Great Lakes region of the United States. Ohio is the 34th largest by area, the 7th most populous, and the 10th most densely populated of the 50 United States. The state's capital and largest city is Columbus.

The state takes its name from the Ohio River. The name originated from the Seneca language word " ohiːyo"', meaning "great river" or "large creek". Partitioned from the Northwest Territory, the state was admitted to the Union as the 17th state (and the first under the Northwest Ordinance) on March 1, 1803. Ohio is historically known as the "Buckeye State" after its Ohio buckeye trees, and Ohioans are also known as "Buckeyes".

The government of Ohio is composed of the executive branch, led by the Governor; the legislative branch, which comprises the Ohio General Assembly; and the judicial branch, which is led by the state Supreme Court. Ohio occupies 16 seats in the United States House of Representatives. Ohio is known for its status as both a swing state and a bellwether in national elections. Six Presidents of the United States have been elected who had Ohio as their home state.

Ohio derives from Seneca (an Iroquois language) as their name for the Ohio River/ Alleghany River, "Ohi:yo". This is pronounced ""Oh-hee-yoh,"" with the "i" sound being held an extra second. Folk etymology claims that this translates as "Beautiful River," however it appears that the word can be broken down as ""O-"" (pronoun prefix. Translates as "it" & implies that whatever is about to follow it is considered a permanent condition of the item), ""Hih"" (verb. to spill) & ""Gihedenyo"" (noun. creek, stream). That being said, the most sensible translation ought to be "Continuously-spilling Creek," or "Continuously-giving creek." The word for "creek" is used instead of "river" since it still flows into a larger river, the Mississippi.

The common accent of Ohio shifts regularly, so there are multiple different accepted ways of saying Ohio that have been common throughout the last century, such as ""Oh-hai-yuh,"" ""Uh-hai-yoh,"" & ""Uh-hai-yuh."" The most recent shift that is beginning to surface sounds something along the lines of ""wh-hai-yuh.""

Ohio's geographic location has proven to be an asset for economic growth and expansion. Because Ohio links the Northeast to the Midwest, much cargo and business traffic passes through its borders along its well-developed highways. Ohio has the nation's 10th largest highway network and is within a one-day drive of 50% of North America's population and 70% of North America's manufacturing capacity. To the north, Lake Erie gives Ohio of coastline, which allows for numerous cargo ports. Ohio's southern border is defined by the Ohio River (with the border being at the 1792 low-water mark on the north side of the river), and much of the northern border is defined by Lake Erie. Ohio's neighbors are Pennsylvania to the east, Michigan to the northwest, Lake Erie to the north, Indiana to the west, Kentucky on the south, and West Virginia on the southeast. Ohio's borders were defined by metes and bounds in the Enabling Act of 1802 as follows:

Ohio is bounded by the Ohio River, but nearly all of the river itself belongs to Kentucky and West Virginia. In 1980, the U.S. Supreme Court held that, based on the wording of the cessation of territory by Virginia (which at that time included what is now Kentucky and West Virginia), the boundary between Ohio and Kentucky (and, by implication, West Virginia) is the northern low-water mark of the river as it existed in 1792. Ohio has only that portion of the river between the river's 1792 low-water mark and the present high-water mark.

The border with Michigan has also changed, as a result of the Toledo War, to angle slightly northeast to the north shore of the mouth of the Maumee River.

Much of Ohio features glaciated till plains, with an exceptionally flat area in the northwest being known as the Great Black Swamp. This glaciated region in the northwest and central state is bordered to the east and southeast first by a belt known as the glaciated Allegheny Plateau, and then by another belt known as the unglaciated Allegheny Plateau. Most of Ohio is of low relief, but the unglaciated Allegheny Plateau features rugged hills and forests.
The rugged southeastern quadrant of Ohio, stretching in an outward bow-like arc along the Ohio River from the West Virginia Panhandle to the outskirts of Cincinnati, forms a distinct socio-economic unit. Geologically similar to parts of West Virginia and southwestern Pennsylvania, this area's coal mining legacy, dependence on small pockets of old manufacturing establishments, and distinctive regional dialect set this section off from the rest of the state. In 1965 the United States Congress passed the Appalachian Regional Development Act, an attempt to "address the persistent poverty and growing economic despair of the Appalachian Region." This act defines 29 Ohio counties as part of Appalachia. While 1/3 of Ohio's land mass is part of the federally defined Appalachian region, only 12.8% of Ohioans live there (1.476 million people.)

Significant rivers within the state include the Cuyahoga River, Great Miami River, Maumee River, Muskingum River, and Scioto River. The rivers in the northern part of the state drain into the northern Atlantic Ocean via Lake Erie and the St. Lawrence River, and the rivers in the southern part of the state drain into the Gulf of Mexico via the Ohio River and then the Mississippi.

The worst weather disaster in Ohio history occurred along the Great Miami River in 1913. Known as the Great Dayton Flood, the entire Miami River watershed flooded, including the downtown business district of Dayton. As a result, the Miami Conservancy District was created as the first major flood plain engineering project in Ohio and the United States.

Grand Lake St. Marys in the west-central part of the state was constructed as a supply of water for canals in the canal-building era of 1820–1850. For many years this body of water, over , was the largest artificial lake in the world. were not the economic fiasco that similar efforts were in other states. Some cities, such as Dayton, owe their industrial emergence to location on canals, and as late as 1910 interior canals carried much of the bulk freight of the state.

The climate of Ohio is a humid continental climate (Köppen climate classification "Dfa/Dfb") throughout most of the state, except in the extreme southern counties of Ohio's Bluegrass region section, which are located on the northern periphery of the humid subtropical climate ("Cfa") and Upland South region of the United States. Summers are typically hot and humid throughout the state, while winters generally range from cool to cold. Precipitation in Ohio is moderate year-round. Severe weather is not uncommon in the state, although there are typically fewer tornado reports in Ohio than in states located in what is known as the Tornado Alley. Severe lake effect snowstorms are also not uncommon on the southeast shore of Lake Erie, which is located in an area designated as the Snowbelt.

Although predominantly not in a subtropical climate, some warmer-climate flora and fauna do reach well into Ohio. For instance, some trees with more southern ranges, such as the blackjack oak, "Quercus marilandica", are found at their northernmost in Ohio just north of the Ohio River. Also evidencing this climatic transition from a subtropical to continental climate, several plants such as the Southern magnolia "(Magnolia grandiflora)", Albizia julibrissin (mimosa), Crape Myrtle, and even the occasional needle palm are hardy landscape materials regularly used as street, yard, and garden plantings in the Bluegrass region of Ohio; but these same plants will simply not thrive in much of the rest of the state. This interesting change may be observed while traveling through Ohio on Interstate 75 from Cincinnati to Toledo; the observant traveler of this diverse state may even catch a glimpse of Cincinnati's common wall lizard, one of the few examples of permanent "subtropical" fauna in Ohio.

The highest recorded temperature was , near Gallipolis on July 21, 1934.
The lowest recorded temperature was , at Milligan on February 10, 1899, during the Great Blizzard of 1899.

Although few have registered as noticeable to the average resident, more than 30 earthquakes occurred in Ohio between 2002 and 2007, and more than 200 quakes with a magnitude of 2.0 or higher have occurred since 1776.

The most substantial known earthquake in Ohio history was the Anna (Shelby County) earthquake, which occurred on March 9, 1937. It was centered in western Ohio, and had a magnitude of 5.4, and was of intensity VIII.

Other significant earthquakes in Ohio include: one of magnitude 4.8 near Lima on September 19, 1884; one of magnitude 4.2 near Portsmouth on May 17, 1901; and one of 5.0 in LeRoy Township in Lake County on January 31, 1986, which continued to trigger 13 aftershocks of magnitude 0.5 to 2.4 for two months.

The most recent earthquake in Ohio of any appreciable magnitude occurred on December 31, 2011, at 3:05pm EST. It had a magnitude of 4.0, and its epicenter was located approximately 4 kilometres northwest of Youngstown (), near the Trumbull/Mahoning county border.

The Ohio Seismic Network (OhioSeis), a group of seismograph stations at several colleges, universities, and other institutions, and coordinated by the Division of Geological Survey of the Ohio Department of Natural Resources, maintains an extensive catalog of Ohio earthquakes from 1776 to the present day, as well as earthquakes located in other states whose effects were felt in Ohio.

Columbus (home of The Ohio State University, Franklin University, Capital University, and Ohio Dominican University) is the capital of Ohio, near the geographic center of the state.

Other Ohio cities functioning as centers of United States metropolitan areas include:

The Cincinnati metropolitan area extends into Kentucky and Indiana, the Steubenville metropolitan area extends into West Virginia, The Toledo metropolitan area extends into Michigan, and the Youngstown metropolitan area extends into Pennsylvania.

Ohio cities that function as centers of United States micropolitan areas include:

Archeological evidence suggests that the Ohio Valley was inhabited by nomadic people as early as 13,000 BC. These early nomads disappeared from Ohio by 1,000 BC, "but their material culture provided a base for those who followed them". Between 1,000 and 800 BC, the sedentary Adena culture emerged. As Ohio historian George W. Knepper notes, this sophisticated culture was "so named because evidences of their culture were excavated in 1902 on the grounds of Adena, Thomas Worthington's estate located near Chillicothe". The Adena were able to establish "semi-permanent" villages because they domesticated plants, which included squash, sunflowers, and perhaps corn. Cultivation of these in addition to hunting and gathering supported more settled, complex villages. The most spectacular remnant of the Adena culture is the Great Serpent Mound, located in Adams County, Ohio.
Around 100 BC, the Adena evolved into the Hopewell people, who were named for the farm owned by Captain M. C. Hopewell, where evidence of their unique culture was discovered. Like the Adena, the Hopewell people participated in a mound-building culture. Their complex, large and technologically sophisticated earthworks can be found in modern-day Marietta, Newark, and Circleville. They were also a powerful trading society, managing to knit together a network that passed goods throughout a third of the continent. The Hopewell, however, disappeared from the Ohio Valley in about 600 AD. Little is known about the people who replaced them, although many Siouan-speaking peoples from the Plains & East Coast claim them as ancestors & say they lived throughout the Ohio region until approx. the 13th century. It is possible that the rise of the Mississippian Culture was the downfall of the Hopewell, as they began to rise to prominence on the Mississippi River around the same time that the Hopewell Culture died out.

Researchers have identified three additional, distinct prehistoric cultures: the Fort Ancient people, the Whittlesey Focus people & the Monongahela Culture. All three cultures apparently disappeared in the 17th century, perhaps decimated by infectious diseases spread in epidemics from early European contact. The Native Americans had no immunity to common European diseases. No one has ever definitively concluded which historically known peoples they may have been analogous to. That being said, it is generally believed that the Shawnees may have absorbed the Fort Ancient people. It's also possible that the Monongahela held no land in Ohio during by the Colonial Era. The Mississippian Culture were close to, contemporaneous with, and traded extensively with the Fort Ancient people.

American Indians in the Ohio Valley were greatly affected by the aggressive tactics of the Iroquois Confederation, based in central and western New York. After the Beaver Wars in the mid-17th century, the Iroquois claimed much of the Ohio country as hunting and, more importantly, beaver-trapping ground. After the devastation of epidemics and war in the mid-17th century, which largely emptied the Ohio country of indigenous people by the mid-to-late 17th century, the land gradually became repopulated by the mostly Algonquian. Many of these Ohio-country nations were multi-ethnic (sometimes multi-linguistic) societies born out of the earlier devastation brought about by disease, war, and subsequent social instability. They subsisted on agriculture (corn, sunflowers, beans, etc.) supplemented by seasonal hunts. By the 18th century, they were part of a larger global economy brought about by European entry into the fur trade.

The indigenous nations to inhabit Ohio in the historical period included the Iroquoian Petun (known for their Tobacco plantations), Erie (thought to have been from Northeast Ohio & western Pennsylvania, but may have come from Canada), Chonnonton (Conquered their way down from Canada during Beaver Wars before being defeated by the Iroquois Confederacy & their allies), Wyandot (a group of Petun who became isolated around Cleveland after the Beaver Wars. Commonly mistaken for the Huron, whom most surviving Petun later joined), the Mingo Seneca (split off from the Iroquois Confederacy & moved to Ohio in 18th century. Remained approx. 100 years.) & the Iroquois Confederacy (conquered most of Ohio at the bequest of the English in the 1660s. Pushed back to Pennsylvania by French in 1701.), The Algonquian Miami (Mostly from Indiana.), Mascouten (close sister tribe to Miamis. Scattered during Beaver Wars. Mostly relocated to Kentucky) Lenape (Arrived around the turn of the 18th century from east coast), Shawnee (Seceded from Powhatan Confederacy. Eventually came to Ohio River & most likely merged with several other lesser known people in the region) & Odawa (part of a Confederacy that surrounded Lake Superior. Relocated to Michigan & Northwest Ohio around the American Revolution.) & the Siouan Mosopelea (moved to Arkansas during Beaver Wars). Ohio country was also the site of Indian massacres, such as the Yellow Creek Massacre, Gnadenhutten and Pontiac's Rebellion school massacre. Most Native Peoples who remained in Ohio were slowly bought out and convinced to leave, or ordered to do so by law, in the early 19th century with the Indian Removal Act of 1830.

During the 18th century, the French set up a system of trading posts to control the fur trade in the region. Beginning in 1754, France and Great Britain fought a war that was known in North America as the French and Indian War and in Europe as the Seven Years' War. As a result of the Treaty of Paris, the French ceded control of Ohio and the remainder of the Old Northwest to Great Britain.

Pontiac's Rebellion in the 1760s, however, posed a challenge to British military control. This came to an end with the colonists' victory in the American Revolution. In the Treaty of Paris in 1783, Britain ceded all claims to Ohio country to the United States.

The United States created the Northwest Territory under the Northwest Ordinance of 1787. Slavery was not permitted in the new territory. Settlement began with the founding of Marietta by the Ohio Company of Associates, which had been formed by a group of American Revolutionary War veterans. Following the Ohio Company, the Miami Company (also referred to as the "Symmes Purchase") claimed the southwestern section, and the Connecticut Land Company surveyed and settled the Connecticut Western Reserve in present-day Northeast Ohio.

The old Northwest Territory originally included areas previously known as Ohio Country and Illinois Country. As Ohio prepared for statehood, the Indiana Territory was created, reducing the Northwest Territory to approximately the size of present-day Ohio plus the eastern half of the Lower Peninsula of Michigan and the eastern tip of the Upper Peninsula.

Under the Northwest Ordinance, areas of the territory could be defined and admitted as states once their population reached 60,000. Although Ohio's population numbered only 45,000 in December 1801, Congress determined that the population was growing rapidly and Ohio could begin the path to statehood. The assumption was that it would exceed 60,000 residents by the time it was admitted as a state. Furthermore, in regards to the Leni Lenape Native Americans living in the region, Congress decided that 10,000 acres on the Muskingum River in the present state of Ohio would "be set apart and the property thereof be vested in the Moravian Brethren ... or a society of the said Brethren for civilizing the Indians and promoting Christianity".

On February 19, 1803, U.S. President Thomas Jefferson signed an act of Congress that approved Ohio's boundaries and constitution. However, Congress had never passed a resolution formally admitting Ohio as the 17th state. The current custom of Congress declaring an official date of statehood did not begin until 1812, with Louisiana's admission as the 18th state. Although no formal resolution of admission was required, when the oversight was discovered in 1953, Ohio congressman George H. Bender introduced a bill in Congress to admit Ohio to the Union retroactive to March 1, 1803, the date on which the Ohio General Assembly first convened. At a special session at the old state capital in Chillicothe, the Ohio state legislature approved a new petition for statehood that was delivered to Washington, D.C. on horseback. On August 7, 1953 (the year of Ohio's 150th anniversary), President Eisenhower signed a congressional joint resolution that officially declared March 1, 1803, the date of Ohio's admittance into the Union.

Ohio has had three capital cities: Chillicothe, Zanesville, and Columbus. Chillicothe was the capital from 1803 to 1810. The capital was then moved to Zanesville for two years, as part of a state legislative compromise to get a bill passed. The capital was then moved back to Chillicothe, which was the capital from 1812 to 1816. Finally, the capital was moved to Columbus, to have it near the geographic center of the state, where it would be more accessible to most citizens.

Although many Native Americans had migrated west to evade American encroachment, others remained settled in the state, sometimes assimilating in part. Shawnee leader Tecumseh led an American Indian confederacy in Tecumseh's Rebellion, from 1811 to 1813. In 1830 under President Andrew Jackson, the US government forced Indian Removal of most tribes to the Indian Territory west of the Mississippi River.

In 1835, Ohio fought with Michigan in the Toledo War, a mostly bloodless boundary war over the Toledo Strip. Only one person was injured in the conflict. Congress intervened, making Michigan's admittance as a state conditional on ending the conflict. In exchange for giving up its claim to the Toledo Strip, Michigan was given the western two-thirds of the Upper Peninsula, in addition to the eastern third that was already considered part of the state.

Ohio's central position and its population gave it an important place during the Civil War. The Ohio River was a vital artery for troop and supply movements, as were Ohio's railroads. The industry of Ohio made the state one of the most important states in the union during the Civil war. Ohio contributed more soldiers per-capita than any other state in the Union. In 1862, the state's morale was badly shaken in the aftermath of the battle of Shiloh, a costly victory in which Ohio forces suffered 2,000 casualties. Later that year, when Confederate troops under the leadership of Stonewall Jackson threatened Washington, D.C., Ohio governor David Tod still could recruit 5,000 volunteers to provide three months of service. From July 12 to July 23, 1863, Southern Ohio and Indiana were attacked in Morgan's Raid. While this raid was insignificant and small, it aroused fear among people in Ohio and Indiana. Almost 35,000 Ohioans died in the conflict, and 30,000 were physically wounded. By the end of the Civil War, the Union's top three generals–Ulysses S. Grant, William Tecumseh Sherman, and Philip Sheridan–were all from Ohio.

In 1912 a Constitutional Convention was held with Charles B. Galbreath as secretary. The result reflected the concerns of the Progressive Era. It introduced the initiative and the referendum. Also, it allowed the General Assembly to put questions on the ballot for the people to ratify laws and constitutional amendments originating in the Legislature. Under the Jeffersonian principle that laws should be reviewed once a generation, the constitution provided for a recurring question to appear on Ohio's general election ballots every 20 years. The question asks whether a new convention is required. Although the question has appeared in 1932, 1952, 1972, and 1992, it has never been approved. Instead, constitutional amendments have been proposed by petition to the legislature hundreds of times and adopted in a majority of cases.

Eight US Presidents hailed from Ohio at the time of their elections, giving rise to its nickname "Mother of Presidents," a sobriquet it shares with Virginia. It is also termed "Modern Mother of Presidents," in contrast to Virginia's status as the origin of presidents earlier in American history. Seven Presidents were born in Ohio, making it second to Virginia's eight. Virginia-born William Henry Harrison lived most of his life in Ohio and is also buried there. Harrison conducted his political career while living on the family compound, founded by his father-in-law, John Cleves Symmes, in North Bend, Ohio. The seven presidents born in Ohio were Ulysses S. Grant, Rutherford B. Hayes, James A. Garfield, Benjamin Harrison (grandson of William Henry Harrison), William McKinley, William Howard Taft and Warren G. Harding.

From just over 45,000 residents in 1800, Ohio's population grew at rates of over 10% per decade (except for the 1940 census) until the 1970 census, which recorded just over 10.65 million Ohioans. Growth then slowed for the next four decades. The United States Census Bureau estimates that the population of Ohio was 11,613,423 on July 1, 2015, a 0.67% increase since the 2010 United States Census. Ohio's population growth lags that of the entire United States, and Caucasians are found in a greater density than the United States average. , Ohio's center of population is located in Morrow County, in the county seat of Mount Gilead. This is approximately south and west of Ohio's population center in 1990.

As of 2011, 27.6% of Ohio's children under the age of 1 belonged to minority groups.

6.2% of Ohio's population is under five years of age, 23.7 percent under 18 years of age, and 14.1 percent were 65 or older. Females made up approximately 51.2 percent of the population.

"Note: Births in table don't add up, because Hispanics are counted both by their ethnicity and by their race, giving a higher overall number."


According to the 2010 United States Census, the racial composition of Ohio was the following:

In 2010, there were 469,700 foreign-born residents in Ohio, corresponding to 4.1% of the total population. Of these, 229,049 (2.0%) were naturalized US citizens and 240,699 (2.1%) were not. The largest groups were: Mexico (54,166), India (50,256), China (34,901), Germany (19,219), Philippines (16,410), United Kingdom (15,917), Canada (14,223), Russia (11,763), South Korea (11,307), and Ukraine (10,681). Though predominantly white, Ohio has large black populations in all major metropolitan areas throughout the state, Ohio has a significant Hispanic population made up of Mexicans in Toledo and Columbus, and Puerto Ricans in Cleveland and Columbus, and also has a significant and diverse Asian population in Columbus.

The largest ancestry groups (which the Census defines as not including racial terms) in the state are:

Ancestries claimed by less than 1% of the population include Sub-Saharan African, Puerto Rican, Swiss, Swedish, Arab, Greek, Norwegian, Romanian, Austrian, Lithuanian, Finnish, West Indian, Portuguese and Slovene.
About 6.7% of the population age 5 years and over reported speaking a language other than English, with 2.2% of the population speaking Spanish, 2.6% speaking other Indo-European languages, 1.1% speaking Asian and Austronesian languages, and 0.8% speaking other languages. Numerically: 10,100,586 spoke English, 239,229 Spanish, 55,970 German, 38,990 Chinese, 33,125 Arabic, and 32,019 French. In addition 59,881 spoke a Slavic language and 42,673 spoke another West Germanic language according to the 2010 Census. Ohio also had the nation's largest population of Slovene speakers, second largest of Slovak speakers, second largest of Pennsylvania Dutch (German) speakers, and the third largest of Serbian speakers.

According to a Pew Forum poll, as of 2008, 76% of Ohioans identified as Christian. Specifically, 26% of Ohio's population identified as Evangelical Protestant, 22% as Mainline Protestant, and 21% as Catholic. 17% of the population is unaffiliated with any religious body. 1.3% (148,380) were Jewish. There are also small minorities of Jehovah's Witnesses (1%), Muslims (1%), Hindus (<0.5%), Buddhists (<0.5%), Mormons (<0.5%), and other faiths (1-1.5%).

According to the Association of Religion Data Archives (ARDA), in 2010 the largest denominations by adherents were the Catholic Church with 1,992,567; the United Methodist Church with 496,232; the Evangelical Lutheran Church in America with 223,253, the Southern Baptist Convention with 171,000, the Christian Churches and Churches of Christ with 141,311, the United Church of Christ with 118,000, and the Presbyterian Church (USA) with 110,000. With about 70,000 people in 2015 Ohio had the second largest Amish population of all states of the US.

According to the same data, a majority of Ohioans, 55%, feel that religion is "very important," 30% say that it is "somewhat important," and 15% responded that religion is "not too important/not important at all." 36% of Ohioans indicate that they attend religious services at least once weekly, 35% attend occasionally, and 27% seldom or never participate in religious services.

In 2010, Ohio was ranked No. 2 in the country for best business climate by Site Selection magazine, based on a business-activity database. The state has also won three consecutive Governor's Cup awards from the magazine, based on business growth and developments. , Ohio's gross domestic product (GDP) was $626 billion. This ranks Ohio's economy as the seventh-largest of all fifty states and the District of Columbia.

The Small Business & Entrepreneurship Council ranked the state No. 10 for best business-friendly tax systems in their Business Tax Index 2009, including a top corporate tax and capital gains rate that were both ranked No. 6 at 1.9%. Ohio was ranked No. 11 by the council for best friendly-policy states according to their Small Business Survival Index 2009. The Directorship's Boardroom Guide ranked the state No. 13 overall for best business climate, including No. 7 for best litigation climate. Forbes ranked the state No. 8 for best regulatory environment in 2009. Ohio has 5 of the top 115 colleges in the nation, according to U.S. News and World Report's 2010 rankings, and was ranked No. 8 by the same magazine in 2008 for best high schools.

Ohio's unemployment rate stands at 4.5% as of February 2018, , down from 10.7% in May 2010. The state still lacks 45,000 jobs compared to the prerecession numbers of 2007. The labor force participation as of April 2015 is 63%, slightly above the national average. Ohio's per capita income stands at $34,874. , Ohio's median household income is $52,334, and 14.6% of the population is below the poverty line 

The manufacturing and financial activities sectors each compose 18.3% of Ohio's GDP, making them Ohio's largest industries by percentage of GDP. Ohio has the third largest manufacturing workforce behind California and Texas. Ohio has the largest bioscience sector in the Midwest, and is a national leader in the "green" economy. Ohio is the largest producer in the country of plastics, rubber, fabricated metals, electrical equipment, and appliances. 5,212,000 Ohioans are currently employed by wage or salary.

By employment, Ohio's largest sector is trade/transportation/utilities, which employs 1,010,000 Ohioans, or 19.4% of Ohio's workforce, while the health care and education sector employs 825,000 Ohioans (15.8%). Government employs 787,000 Ohioans (15.1%), manufacturing employs 669,000 Ohioans (12.9%), and professional and technical services employs 638,000 Ohioans (12.2%). Ohio's manufacturing sector is the third-largest of all fifty United States states in terms of gross domestic product. Fifty-nine of the United States' top 1,000 publicly traded companies (by revenue in 2008) are headquartered in Ohio, including Procter & Gamble, Goodyear Tire & Rubber, AK Steel, Timken, Abercrombie & Fitch, and Wendy's.

Ohio is also one of 41 states with its own lottery, the Ohio Lottery. The Ohio Lottery has contributed over $15.5 billion to public education in its 34-year history.

Many major east-west transportation corridors go through Ohio. One of those pioneer routes, known in the early 20th century as "Main Market Route 3", was chosen in 1913 to become part of the historic Lincoln Highway which was the first road across America, connecting New York City to San Francisco. In Ohio, the Lincoln Highway linked many towns and cities together, including Canton, Mansfield, Wooster, Lima, and Van Wert. The arrival of the Lincoln Highway to Ohio was a major influence on the development of the state. Upon the advent of the federal numbered highway system in 1926, the Lincoln Highway through Ohio became U.S. Route 30.

Ohio also is home to of the Historic National Road, now U.S. Route 40.

Ohio has a highly developed network of roads and interstate highways. Major east-west through routes include the Ohio Turnpike (I-80/I-90) in the north, I-76 through Akron to Pennsylvania, I-70 through Columbus and Dayton, and the Appalachian Highway (State Route 32) running from West Virginia to Cincinnati. Major north-south routes include I-75 in the west through Toledo, Dayton, and Cincinnati, I-71 through the middle of the state from Cleveland through Columbus and Cincinnati into Kentucky, and I-77 in the eastern part of the state from Cleveland through Akron, Canton, New Philadelphia and Marietta south into West Virginia. Interstate 75 between Cincinnati and Dayton is one of the heaviest traveled sections of interstate in Ohio.

Ohio also has a highly developed network of signed state bicycle routes. Many of them follow rail trails, with conversion ongoing. The Ohio to Erie Trail (route 1) connects Cincinnati, Columbus, and Cleveland. U.S. Bicycle Route 50 traverses Ohio from Steubenville to the Indiana state line outside Richmond.

Ohio has several long-distance hiking trails, the most prominent is the Buckeye Trail which is a 1,444-mile (2,324 km)[1] hiking trail that loops around the state of Ohio. Part of it is on roads and part is on wooded trail. Additionally, the North Country Trail (the longest of the eleven National Scenic Trails authorized by Congress) and the American Discovery Trail (a system of recreational trails and roads that collectively form a coast-to-coast route across the mid-tier of the United States) pass through Ohio. Much of these two trails coincide with the Buckeye Trail.

Ohio has five international airports, four commercial, and two military. The five international include Cleveland Hopkins International Airport, John Glenn Columbus International Airport, and Dayton International Airport, Ohio's third largest airport. Akron Fulton International Airport handles cargo and for private use. Rickenbacker International Airport is one of two military airfields which is also home to the 7th largest FedEx building in America. The other military airfield is Wright Patterson Air Force Base which is one of the largest Air Force bases in the United States. Other major airports are located in Toledo and Akron.

Cincinnati/Northern Kentucky International Airport is in Hebron, Kentucky, and therefore is not listed above.


The state government of Ohio consists of the executive, judicial, and legislative branches.

The executive branch is headed by the Governor of Ohio. The current governor is John Kasich, a Republican elected in 2010. A lieutenant governor succeeds the governor in the event of any removal from office, and performs any duties assigned by the governor. The current lieutenant governor is Mary Taylor. The other elected constitutional offices in the executive branch are the secretary of state (Jon A. Husted), auditor (Dave Yost), treasurer (Josh Mandel), and attorney general (Mike DeWine).

There are three levels of the Ohio state judiciary. The lowest level is the court of common pleas: each county maintains its own constitutionally mandated court of common pleas, which maintain jurisdiction over "all justiciable matters". The intermediate-level court system is the district court system. Twelve courts of appeals exist, each retaining jurisdiction over appeals from common pleas, municipal, and county courts in a set geographical area. A case heard in this system is decided by a three-judge panel, and each judge is elected.

The highest-ranking court, the Ohio Supreme Court, is Ohio's "court of last resort". A seven-justice panel composes the court, which, by its own discretion, hears appeals from the courts of appeals, and retains original jurisdiction over limited matters.

The Ohio General Assembly is a bicameral legislature consisting of the Senate and House of Representatives. The Senate is composed of 33 districts, each of which is represented by one senator. Each senator represents approximately 330,000 constituents. The House of Representatives is composed of 99 members.

Ohio, nicknamed the "Mother of Presidents," has sent seven of its native sons (Ulysses S. Grant, Rutherford B. Hayes, James A. Garfield, Benjamin Harrison, William McKinley, William Howard Taft, and Warren G. Harding) to the White House. All seven were Republicans. Virginia native William Henry Harrison, a Whig, resided in Ohio. Historian R. Douglas Hurt asserts that not since Virginia "had a state made such a mark on national political affairs". "The Economist" notes that "This slice of the mid-west contains a bit of everything American — part north-eastern and part southern, part urban and part rural, part hardscrabble poverty and part booming
suburb", Ohio is the only state that has voted for the winning Presidential candidate in each election since 1964, and in 33 of the 37 held since the Civil War. No Republican has ever won the presidency without winning Ohio.

, Ohio's voter demographic leans towards the Democratic Party. An estimated 2,408,178 Ohioans are registered to vote as Democrats, while 1,471,465 Ohioans are registered to vote as Republicans. These are changes from 2004 of 72% and 32%, respectively, and Democrats have registered over 1,000,000 new Ohioans since 2004. Unaffiliated voters have an attrition of 15% since 2004, losing an estimated 718,000 of their kind. The total now rests at 4,057,518 Ohioans. In total, there are 7,937,161 Ohioans registered to vote. In United States presidential election of 2008, then-Senator Barack Obama of Illinois won 51.50% of Ohio's popular vote, 4.59 percentage points more than his nearest rival, Senator John McCain of Arizona (with 46.91% of the popular vote). However, Obama won only 22 of Ohio's 88 counties. Since 2010, the Republicans have largely controlled Ohio state politics, including a super-majority in the state's House, a majority in the state Senate, the Governorship, etc. As of 2014, the state Senate is 1 Republican away from a super-majority.

Following the 2000 census, Ohio lost one congressional district in the United States House of Representatives, which left Ohio with 18 districts, and consequently, 18 representatives. The state lost two more seats following the 2010 Census, leaving it with 16 seats for the next three presidential elections in 2012, 2016 and 2020. In the 2008 elections, Democrats gained three seats in Ohio's delegation to the House of Representatives. This left eight Republican-controlled seats in the Ohio delegation. Ohio's U.S. Senators in the 112th Congress are Republican Rob Portman and Democrat Sherrod Brown. Marcy Kaptur (D-9) is the dean, or most senior member, of the Ohio delegation to the United States House of Representatives.

Ohio's system of public education is outlined in Article VI of the state constitution, and in Title XXXIII of the Ohio Revised Code. Ohio University, the first university in the Northwest Territory, was also the first public institution in Ohio. Substantively, Ohio's system is similar to those found in other states. At the State level, the Ohio Department of Education, which is overseen by the Ohio State Board of Education, governs primary and secondary educational institutions. At the municipal level, there are approximately 700 school districts statewide. The Ohio Board of Regents coordinates and assists with Ohio's institutions of higher education which have recently been reorganized into the University System of Ohio under Governor Strickland. The system averages an annual enrollment of over 400,000 students, making it one of the five largest state university systems in the U.S.


Ohio is home to some of the nation's highest-ranked public libraries. The 2008 study by Thomas J. Hennen Jr. ranked Ohio as number one in a state-by-state comparison. For 2008, 31 of Ohio's library systems were all ranked in the top ten for American cities of their population category.

The Ohio Public Library Information Network (OPLIN) is an organization that provides Ohio residents with internet access to their 251 public libraries. OPLIN also provides Ohioans with free home access to high-quality, subscription research databases.

Ohio also offers the OhioLINK program, allowing Ohio's libraries (particularly those from colleges and universities) access to materials for the other libraries. The program is largely successful in allowing researchers for access to books and other media that might not be otherwise available.

Ohio is home to major professional sports teams in baseball, basketball, football, hockey, lacrosse and soccer. The state's major professional sporting teams include: Cincinnati Reds (Major League Baseball), Ohio Machine (Major League Lacrosse), Cleveland Indians (Major League Baseball), Cincinnati Bengals (National Football League), Cleveland Browns (National Football League), Cleveland Cavaliers (National Basketball Association), Columbus Blue Jackets (National Hockey League), and the Columbus Crew (Major League Soccer).

Ohio played a central role in the development of both Major League Baseball and the National Football League. Baseball's first fully professional team, the Cincinnati Red Stockings of 1869, were organized in Ohio. An informal early-20th-century American football association, the Ohio League, was the direct predecessor of the NFL, although neither of Ohio's modern NFL franchises trace their roots to an Ohio League club. The Pro Football Hall of Fame is located in Canton.

On a smaller scale, Ohio hosts minor league baseball, arena football, indoor football, mid-level hockey, and lower division soccer.

The Mid-Ohio Sports Car Course has hosted several auto racing championships, including CART World Series, IndyCar Series, NASCAR Nationwide Series, Can-Am, Formula 5000, IMSA GT Championship, American Le Mans Series and Rolex Sports Car Series.
The Grand Prix of Cleveland also hosted CART races from 1982 to 2007. The Eldora Speedway is a major dirt oval that hosts NASCAR Camping World Truck Series, World of Outlaws Sprint Cars and USAC Silver Crown Series races.

Ohio hosts two PGA Tour events, the WGC-Bridgestone Invitational and Memorial Tournament.
The Cincinnati Masters is an ATP World Tour Masters 1000 and WTA Premier 5 tennis tournament.

Ohio has eight NCAA Division I FBS college football teams, divided among three different conferences. It has also experienced considerable success in the secondary and tertiary tiers of college football divisions.

In Division I-A, representing the Big Ten, the Ohio State Buckeyes football team ranks 5th among all-time winningest programs, with seven national championships and seven Heisman Trophy winners. Their biggest rivals are the Michigan Wolverines, whom they traditionally play each year as the last game of their regular season schedule.

Ohio has six teams represented in the Mid-American Conference: the University of Akron, Bowling Green, Kent State, Miami University, Ohio University and the University of Toledo. The MAC headquarters are in Cleveland.
The University of Cincinnati Bearcats represent Ohio in the American Athletic Conference.

Ohio's state symbols:




</doc>
<doc id="22201" url="https://en.wikipedia.org/wiki?curid=22201" title="Orbital">
Orbital

Orbital may refer to:

In chemistry and physics:

In astronomy and space flight:

In medicine and physiology:

In entertainment:




In other fields:



</doc>
<doc id="22203" url="https://en.wikipedia.org/wiki?curid=22203" title="Organic compound">
Organic compound

In chemistry, an organic compound is generally any chemical compound that contains carbon. Due to carbon's ability to catenate (form chains with other carbon atoms), millions of organic compounds are known. Study of the properties and synthesis of organic compounds is the discipline known as organic chemistry. For historical reasons, a few classes of carbon-containing compounds (e.g., carbonates and cyanides), along with a handful of other exceptions (e.g., carbon dioxide), are not classified as organic compounds and are considered inorganic. No consensus exists among chemists on precisely which carbon-containing compounds are excluded, making the definition of an organic compound elusive. Although organic compounds only make up a small percentage of the Earth's crust, they are of central importance because all known life is based on organic compounds. Most synthetically produced organic compounds are ultimately derived from petrochemicals consisting mainly of hydrocarbons.

For historical reasons discussed below, a few types of carbon-containing compounds, such as carbides, carbonates, simple oxides of carbon (for example, CO and CO), and cyanides are considered inorganic. Allotropes of carbon, such as diamond and graphite, are also excluded because they are simple substances composed of only a single element and therefore are not chemical "compound"s at all.

Organic chemistry is the science concerned with all aspects of organic compounds. Organic synthesis is the methodology of their preparation.

For many centuries, Western physicians and chemists believed in vitalism. This was the widespread conception that substances found in organic nature are created from the chemical elements by the action of a "vital force" or "life-force" ("vis vitalis") that only living organisms possess. Vitalism taught that these "organic" compounds were fundamentally different from the "inorganic" compounds that could be obtained from the elements by chemical manipulations.

Vitalism survived for a while even after the rise of modern ideas about the atomic theory and chemical elements. It first came under question in 1824, when Friedrich Wöhler synthesized oxalic acid, a compound known to occur only in living organisms, from cyanogen. A more decisive experiment was Wöhler's 1828 synthesis of urea from the inorganic salts potassium cyanate and ammonium sulfate. Urea had long been considered an "organic" compound, as it was known to occur only in the urine of living organisms. Wöhler's experiments were followed by many others, in which increasingly complex "organic" substances were produced from "inorganic" ones without the involvement of any living organism.

Even though vitalism has been discredited, scientific nomenclature retains the distinction between "organic" and "inorganic" compounds. The modern meaning of "organic compound" is any compound that contains a significant amount of carbon—even though many of the organic compounds known today have no connection to any substance found in living organisms. The term "carbogenic" has been proposed by E. J. Corey as a modern alternative to "organic", but this neologism remains relatively obscure.

The organic compound -isoleucine molecule presents some features typical of organic compounds: carbon–carbon bonds, carbon–hydrogen bonds, as well as covalent bonds from carbon to oxygen and to nitrogen.

As described in detail below, any definition of organic compound that uses simple, broadly applicable criteria turns out to be unsatisfactory, to varying degrees. The modern, commonly accepted definition of organic compound essentially amounts to any carbon containing compound, excluding several classes of substances traditionally considered as 'inorganic'. However, the list of substances so excluded varies from author to author. Still, it is generally agreed upon that there are (at least) a few carbon containing compounds that should not be considered organic. For instance, almost all authorities would require the exclusion of alloys that contain carbon, including steel (which contains cementite, FeC), as well as other metal and semimetal carbides (including "ionic" carbides, e.g, AlC and CaC and "covalent" carbides, e.g. BC and SiC, and graphite intercalation compounds, e.g. KC). Other compounds and materials that are considered 'inorganic' by most authorities include: metal carbonates, simple oxides (CO, CO, and arguably, CO), the allotropes of carbon, cyanides excluding those containing an organic residue (e.g., KCN, (CN), BrCN, CNO, etc.), and heavier analogs thereof (e.g., CP 'cyaphide anion', CSe, COS; although CS 'carbon disulfide' is often classed as an "organic" solvent). Halides of carbon without hydrogen (e.g., CF and CClF), phosgene (COCl), carboranes, metal carbonyls (e.g., nickel carbonyl), mellitic anhydride (CO), and other exotic oxocarbons are also considered inorganic by some authorities.

Nickel carbonyl (Ni(CO)) and other metal carbonyls present an interesting case. They are often volatile liquids, like other organic compounds, yet they contain only carbon bonded to a transition metal and to oxygen and are often prepared directly from metal and carbon monoxide. Nickel carbonyl is frequently considered to be "organometallic". Although many organometallic chemists employ a broad definition, in which any compound containing a carbon-metal covalent bond is considered organometallic, it is debatable whether organometallic compounds form a subset of organic compounds. 

Metal complexes with organic ligands but no carbon-metal bonds (e.g., Cu(OAc)) are not considered organometallic; instead they are classed as "metalorganic". Likewise, it is also unclear whether metalorganic compounds should automatically be considered organic.

The relatively narrow definition of organic compounds as those containing C-H bonds excludes compounds that are (historically and practically) considered organic. Neither urea nor oxalic acid is organic by this definition, yet they were two key compounds in the vitalism debate. The IUPAC Blue Book on organic nomenclature specifically mentions urea and oxalic acid. Other compounds lacking C-H bonds but traditionally considered organic include benzenehexol, mesoxalic acid, and carbon tetrachloride. Mellitic acid, which contains no C-H bonds, is considered a possible organic substance in Martian soil. Terrestrially, it, and its anhydride, mellitic anhydride, are associated with the mineral mellite (AlC(COO)·16HO).

A slightly broader definition of organic compound includes all compounds bearing C-H or C-C bonds. This would still exclude urea. Moreover, this definition still leads to somewhat arbitrary divisions in sets of carbon-halogen compounds. For example, CF and CCl would be considered by this rule to be "inorganic", whereas CFH and CHCl would be organic, though these compounds share many physical and chemical properties.

Organic compounds may be classified in a variety of ways. One major distinction is between natural and synthetic compounds. Organic compounds can also be classified or subdivided by the presence of heteroatoms, e.g., organometallic compounds, which feature bonds between carbon and a metal, and organophosphorus compounds, which feature bonds between carbon and a phosphorus.
Another distinction, based on the size of organic compounds, distinguishes between small molecules and polymers.
Natural compounds refer to those that are produced by plants or animals. Many of these are still extracted from natural sources because they would be more expensive to produce artificially. Examples include most sugars, some alkaloids and terpenoids, certain nutrients such as vitamin B, and, in general, those natural products with large or stereoisometrically complicated molecules present in reasonable concentrations in living organisms.
Further compounds of prime importance in biochemistry are antigens, carbohydrates, enzymes, hormones, lipids and fatty acids, neurotransmitters, nucleic acids, proteins, peptides and amino acids, lectins, vitamins, and fats and oils.

Compounds that are prepared by reaction of other compounds are known as "synthetic". They may be either compounds that already are found in plants or animals or those that do not occur naturally.

Most polymers (a category that includes all plastics and rubbers), are organic synthetic or semi-synthetic compounds.

Many organic compounds—two examples are ethanol and insulin—are manufactured industrially using organisms such as bacteria and yeast. Typically, the DNA of an organism is altered to express compounds not ordinarily produced by the organism. Many such biotechnology-engineered compounds did not previously exist in nature.


A great number of more specialized databases exist for diverse branches of organic chemistry.

The main tools are proton and carbon-13 NMR spectroscopy, IR Spectroscopy, Mass spectrometry, UV/Vis Spectroscopy and X-ray crystallography.




</doc>
<doc id="22204" url="https://en.wikipedia.org/wiki?curid=22204" title="Oligopoly">
Oligopoly

An oligopoly (, from Ancient Greek ὀλίγος (olígos) "few" + πωλεῖν (poleîn) "to sell") is a market form wherein a market or industry is dominated by a small number of large sellers (oligopolists). Oligopolies can result from various forms of collusion which reduce competition and lead to higher prices for consumers. Oligopoly has its own market structure.

With few sellers, each oligopolist is likely to be aware of the actions of the others. According to game theory, the decisions of one firm therefore influence and are influenced by decisions of other firms. Strategic planning by oligopolists needs to take into account the likely responses of the other market. Entry barriers include high investment requirements, strong consumer loyalty for existing brands and economics of scale.

Oligopoly is a common market form where a number of firms are in competition. As a quantitative description of oligopoly, the four-firm concentration ratio is often utilized. This measure expresses, as a percentage, the market share of the four largest firms in any particular industry. For example, as of fourth quarter 2008, if we combine total market share of Verizon Wireless, AT&T, Sprint, and T-Mobile, we see that these firms, together, control 97% of the U.S. cellular telephone market.

Oligopolistic competition can give rise to both wide-ranging and diverse outcomes. In some situations, particular companies may employ restrictive trade practices (collusion, market sharing etc.) in order to inflate prices and restrict production in much the same way that a monopoly does. Whenever there is a formal agreement for such collusion, between companies that usually compete with one another, this practice is known as a cartel. A prime example of such a cartel is OPEC, which has a profound influence on the international price of oil.

Firms often collude in an attempt to stabilize unstable markets, so as to reduce the risks inherent in these markets for investment and product development. There are legal restrictions on such collusion in most countries. There does not have to be a formal agreement for collusion to take place (although for the act to be illegal there must be actual communication between companies)–for example, in some industries there may be an acknowledged market leader which informally sets prices to which other producers respond, known as price leadership.

In other situations, competition between sellers in an oligopoly can be fierce, with relatively low prices and high production. This could lead to an efficient outcome approaching perfect competition. The competition in an oligopoly can be greater when there are more firms in an industry than if, for example, the firms were only regionally based and did not compete directly with each other.

Thus the welfare analysis of oligopolies is sensitive to the parameter values used to define the market's structure. In particular, the level of dead weight loss is hard to measure. The study of product differentiation indicates that oligopolies might also create excessive levels of differentiation in order to stifle competition.

Oligopoly theory makes heavy use of game theory to model the behavior of oligopolies:


Oligopolies become "mature" when they realise they can profit maximise through joint profit maximising. As a result of operating in countries with enforced competition laws, the Oligopolists will operate under tacit collusion, being collusion through an understanding that if all the competitors in the market raise their prices, then collectively all the competitors can achieve economic profits close to a monopolist, with out evidence of breaching government market regulations. Hence, the kinked demand curve for a joint profit maximising Oligopoly industry can model the behaviours of oligopolists pricing decisions other than that of the price leader (the price leader being the firm that all other firms follow in terms of pricing decisions). This is because if a firm unilaterally raises the prices of their good/service, and other competitors do not follow then, the firm that raised their price will then lose a significant market as they face the elastic upper segment of the demand curve. As the joint profit maximising achieves greater economic profits for all the firms, there is an incentive for an individual firm to "cheat" by expanding output to gain greater market share and profit. In Oligopolist cheating, and the incumbent firm discovering this breach in collusion, the other firms in the market will retaliate by matching or dropping prices lower than the original drop. Hence, the market share that the firm that dropped the price gained, will have that gain minimised or eliminated. This is why on the kinked demand curve model the lower segment of the demand curve is inelastic. As a result, price rigidity prevails in such markets.

There is no single model describing the operation of an oligopolistic market. The variety and complexity of the models exist because you can have two to 10 firms competing on the basis of price, quantity, technological innovations, marketing, and reputation. Fortunately, there are a series of simplified models that attempt to describe market behavior by considering certain circumstances. Some of the better-known models are the dominant firm model, the Cournot–Nash model, the Bertrand model and the kinked demand model.

The Cournot–Nash model is the simplest oligopoly model. The model assumes that there are two "equally positioned firms"; the firms compete on the basis of quantity rather than price and each firm makes an "output decision assuming that the other firm's behavior is fixed." The market demand curve is assumed to be linear and marginal costs are constant. To find the Cournot–Nash equilibrium one determines how each firm reacts to a change in the output of the other firm. The path to equilibrium is a series of actions and reactions. The pattern continues until a point is reached where neither firm desires "to change what it is doing, given how it believes the other firm will react to any change." The equilibrium is the intersection of the two firm's reaction functions. The reaction function shows how one firm reacts to the quantity choice of the other firm. For example, assume that the firm 1's demand function is "P" = ("M" − "Q") − "Q" where "Q" is the quantity produced by the other firm and Q is the amount produced by firm 1, and M=60 is the market. Assume that marginal cost is C=12. Firm 1 wants to know its maximizing quantity and price. Firm 1 begins the process by following the profit maximization rule of equating marginal revenue to marginal costs. Firm 1's total revenue function is "R" = "Q" "P" = "Q"("M" − "Q" − "Q") = "MQ" − "Q" "Q" − "Q". The marginal revenue function is formula_1.

Equation 1.1 is the reaction function for firm 1. Equation 1.2 is the reaction function for firm 2.

To determine the Cournot–Nash equilibrium you can solve the equations simultaneously. The equilibrium quantities can also be determined graphically. The equilibrium solution would be at the intersection of the two reaction functions. Note that if you graph the functions the axes represent quantities. The reaction functions are not necessarily symmetric. The firms may face differing cost functions in which case the reaction functions would not be identical nor would the equilibrium quantities.

The Bertrand model is essentially the Cournot–Nash model except the strategic variable is price rather than quantity.

The model assumptions are:

The only Nash equilibrium is P = P = MC.

Neither firm has any reason to change strategy. If the firm raises prices it will lose all its customers. If the firm lowers price P < MC then it will be losing money on every unit sold.

The Bertrand equilibrium is the same as the competitive result. Each firm will produce where P = marginal costs and there will be zero profits. A generalization of the Bertrand model is the Bertrand–Edgeworth model that allows for capacity constraints and more general cost functions.

According to this model, each firm faces a demand curve kinked at the existing price. The conjectural assumptions of the model are; if the firm raises its price above the current existing price, competitors will not follow and the acting firm will lose market share and second if a firm lowers prices below the existing price then their competitors will follow to retain their market share and the firm's output will increase only marginally.

If the assumptions hold then:

The gap in the marginal revenue curve means that marginal costs can fluctuate without changing equilibrium price and quantity. Thus prices tend to be rigid.

In industrialized economies, barriers to entry have resulted in oligopolies forming in many sectors, with unprecedented levels of competition fueled by increasing globalization. Market shares in an oligopoly are typically determined by product development and advertising. For example, there are now only a small number of manufacturers of civil passenger aircraft, though Brazil (Embraer) and Canada (Bombardier) have participated in the small passenger aircraft market sector. Oligopolies have also arisen in heavily-regulated markets such as wireless communications: in some areas only two or three providers are licensed to operate.









In an oligopoly, firms operate under imperfect competition. With the fierce price competitiveness created by this sticky-upward demand curve, firms use non-price competition in order to accrue greater revenue and market share.

"Kinked" demand curves are similar to traditional demand curves, as they are downward-sloping. They are distinguished by a hypothesized convex bend with a discontinuity at the bend–"kink". Thus the first derivative at that point is undefined and leads to a jump discontinuity in the marginal revenue curve.

Classical economic theory assumes that a profit-maximizing producer with some market power (either due to oligopoly or monopolistic competition) will set marginal costs equal to marginal revenue. This idea can be envisioned graphically by the intersection of an upward-sloping marginal cost curve and a downward-sloping marginal revenue curve (because the more one sells, the lower the price must be, so the less a producer earns per unit). In classical theory, any change in the marginal cost structure (how much it costs to make each additional unit) or the marginal revenue structure (how much people will pay for each additional unit) will be immediately reflected in a new price and/or quantity sold of the item. This result does not occur if a "kink" exists. Because of this jump discontinuity in the marginal revenue curve, marginal costs could change without necessarily changing the price or quantity.

The motivation behind this kink is the idea that in an oligopolistic or monopolistically competitive market, firms will not raise their prices because even a small price increase will lose many customers. This is because competitors will generally ignore price increases, with the hope of gaining a larger market share as a result of now having comparatively lower prices. However, even a large price decrease will gain only a few customers because such an action will begin a price war with other firms. The curve is therefore more price-elastic for price increases and less so for price decreases. Theory predicts that firms will enter the industry in the long run.




</doc>
<doc id="22205" url="https://en.wikipedia.org/wiki?curid=22205" title="Oasis">
Oasis

In geography, an oasis (; plural: oases ) is an isolated area in a desert, typically surrounding a spring or similar water source, such as a pond or small lake. Oases also provide habitat for animals and even humans if the area is big enough. 

The word "oasis" came into English via from , which in turn is a direct borrowing from Demotic Egyptian. The word for "oasis" in the later attested Coptic language (the descendant of Demotic Egyptian) is "wahe" or "ouahe" which means a "dwelling place".

Oases are made fertile when sources of freshwater, such as underground rivers or aquifers, irrigate the surface naturally or via man-made wells. Oases can vary in size from about to much larger areas that can support many farms.

Rain showers provide subterranean water to sustain natural oases, such as the Tuat. Substrata of impermeable rock and stone can trap water and retain it in pockets, or on long faulting subsurface ridges or volcanic dikes water can collect and percolate to the surface. Any incidence of water is then used by migrating birds, which also pass seeds with their droppings which will grow at the water's edge forming an oasis. It can also be used to plant crops.

The location of oases has been of critical importance for trade and transportation routes in desert areas; caravans must travel via oases so that supplies of water and food can be replenished. Thus, political or military control of an oasis has in many cases meant control of trade on a particular route. For example, the oases of Awjila, Ghadames, and Kufra, situated in modern-day Libya, have at various times been vital to both North-South and East-West trade in the Sahara Desert. The Silk Road across Central Asia also incorporated several oases.

In North American history, oases have been less prominent since the desert regions are smaller, but in the USA they have allowed colonisation of the western desert regions around the Rockies. Las Vegas is an example of such a settlement.

People who live in an oasis must manage land and water use carefully; fields must be irrigated to grow plants like apricots, dates, figs, and olives. The most important plant in an oasis is the date palm, which forms the upper layer. These palm trees provide shade for smaller trees like peach trees, which form the middle layer. By growing plants in different layers, the farmers make best use of the soil and water. Many vegetables are also grown and some cereals, such as barley, millet, and wheat, are grown where there is more moisture.




</doc>
<doc id="22206" url="https://en.wikipedia.org/wiki?curid=22206" title="Oboe">
Oboe

Oboes ( ) are a family of double reed woodwind instruments. The most common oboe plays in the treble or soprano range. Oboes are usually made of wood, but there are also oboes made of synthetic materials. A soprano oboe measures roughly long, with metal keys, a conical bore and a flared bell. Sound is produced by blowing into the reed at a sufficient air pressure, causing it to vibrate with the air column. The distinctive tone is versatile and has been described as "bright". When "oboe" is used alone, it is generally taken to mean the treble instrument rather than other instruments of the family, such as the "cor anglais" (English horn) or oboe "d'amore".

In English, prior to 1770, the standard instrument was called a "hautbois", "hoboy", or "French hoboy" ( ; borrowed from the French name, a compound word made of "haut" ["high", "loud"] and "bois" ["wood", "woodwind"]). The spelling of "oboe" was adopted into English c. 1770 from the Italian "oboè", a transliteration of the 17th-century pronunciation of the French name. A musician who plays the oboe is called an oboist.

Today, the oboe is commonly used in concert bands, orchestras, chamber music, film music, some genres of folk music, and as a solo instrument, and occasionally heard in jazz, rock, pop, and popular music.

In comparison to other modern woodwind instruments, the treble oboe is sometimes referred to as having a clear and penetrating voice. "The Sprightly Companion", an instruction book published by Henry Playford in 1695, describes the oboe as "Majestical and Stately, and not much Inferior to the Trumpet." Humorously, the sound is described in the play "Angels in America" as like "that of a duck if the duck were a songbird". The rich timbre is derived from its conical bore (as opposed to the generally cylindrical bore of flutes and clarinets). As a result, oboes are readily audible over other instruments in large ensembles. The highest note is a semitone lower than the nominally highest note of the B clarinet. Since the clarinet has a wider range, the lowest note of the B clarinet is significantly deeper (a minor sixth) than the lowest note of the oboe.

Music for the standard oboe is written in concert pitch (i.e., it is not a transposing instrument), and the instrument has a soprano range, usually from B to G. Orchestras tune to a concert A played by the first oboe. According to the League of American Orchestras, this is done because the pitch is secure and its penetrating sound makes it ideal for tuning. The pitch of the oboe is affected by the way in which the reed is made. The reed has a significant effect on the sound. Variations in cane and other construction materials, the age of the reed, and differences in scrape and length all affect the pitch. German and French reeds, for instance, differ in many ways, causing the sound to vary accordingly. Weather conditions such as temperature and humidity also affect the pitch. Skilled oboists adjust their embouchure to compensate for these factors. Subtle manipulation of embouchure and air pressure allows the oboist to express timbre and dynamics.

The regular oboe first appeared in the mid-17th century, when it was called a "hautbois". This name was also used for its predecessor, the shawm, from which the basic form of the "hautbois" was derived. Major differences between the two instruments include the division of the "hautbois" into three sections, or joints (which allowed for more precise manufacture), and the elimination of the "pirouette", the wooden ledge below the reed which allowed players to rest their lips.

The exact date and place of origin of the "hautbois" are obscure, as are the individuals who were responsible. Circumstantial evidence, such as the statement by the flautist composer Michel de la Barre in his "Memoire", points to members of the Philidor (Filidor) and Hotteterre families. The instrument may in fact have had multiple inventors. The "hautbois" quickly spread throughout Europe, including Great Britain, where it was called "hautboy", "hoboy", "hautboit", "howboye", and similar variants of the French name. It was the main melody instrument in early military bands, until it was succeeded by the clarinet.

The standard Baroque oboe is generally made of boxwood and has three keys: a "great" key and two side keys (the side key is often doubled to facilitate use of either the right or left hand on the bottom holes). In order to produce higher pitches, the player has to "overblow", or increase the air stream to reach the next harmonic. Notable oboe-makers of the period are the Germans Jacob Denner and J.H. Eichentopf, and the English Thomas Stanesby (died 1734) and his son Thomas Jr (died 1754). The range for the Baroque oboe comfortably extends from C to D. With the resurgence of interest in early music in the mid 20th century, a few makers began producing copies to specifications taken from surviving historical instruments.

The Classical period brought a regular oboe whose bore was gradually narrowed, and the instrument became outfitted with several keys, among them were those for the notes D, F, and G. A key similar to the modern octave key was also added called the "slur key", though it was at first used more like the "flick" keys on the modern German bassoon. Only later did French instrument makers redesign the octave key to be used in the manner of the modern key (i.e. held open for the upper register, closed for the lower). The narrower bore allows the higher notes to be more easily played, and composers began to more often utilize the oboe's upper register in their works. Because of this, the oboe's tessitura in the Classical era was somewhat broader than that found in Baroque works. The range for the Classical oboe extends from C to F (using the scientific pitch notation system), though some German and Austrian oboes are capable of playing one half-step lower. Classical-era composers who wrote concertos for oboe include Mozart (both the solo concerto in C major K. 314/285d and the lost original of Sinfonia Concertante in E major K. 297b, as well as a fragment of F major concerto K. 417f), Haydn, (both the Sinfonia Concertante in B Hob. I:105 and the spurious concerto in C major Hob. VIIg:C1), Beethoven (the F major concerto, Hess 12, of which only sketches survive, though the second movement was reconstructed in the late 20th century), and numerous other composers including Johann Christian Bach, Johann Christian Fischer, Jan Antonín Koželuh, and Ludwig August Lebrun. Many solos exist for the regular oboe in chamber, symphonic, and operatic compositions from the Classical era.

The Wiener oboe is a type of modern oboe that retains the essential bore and tonal characteristics of the historical oboe. The Akademiemodel Wiener Oboe, first developed in the late 19th century by Josef Hajek from earlier instruments by C. T. Golde of Dresden (1803–73), is now made by several makers such as André Constantinides, Karl Rado, Guntram Wolf, Christian Rauch and Yamaha. It has a wider internal bore, a shorter and broader reed and the fingering-system is very different than the conservatoire oboe. In "The Oboe", Geoffrey Burgess and Bruce Haynes write "The differences are most clearly marked in the middle register, which is reedier and more pungent, and the upper register, which is richer in harmonics on the Viennese oboe". Guntram Wolf describes them: "From the concept of the bore, the Viennese oboe is the last representative of the historical oboes, adapted for the louder, larger orchestra, and fitted with an extensive mechanism. Its great advantage is the ease of speaking, even in the lowest register. It can be played very expressively and blends well with other instruments." The Viennese oboe is, along with the Vienna horn, perhaps the most distinctive member of the Wiener Philharmoniker instrumentarium.

This oboe was developed further in the 19th century by the Triebert family of Paris. Using the Boehm flute as a source of ideas for key work, Guillaume Triebert and his sons, Charles and Frederic, devised a series of increasingly complex yet functional key systems. A variant form using large tone holes, the Boehm system oboe, was never in common use, though it was used in some military bands in Europe into the 20th century. F. Lorée of Paris made further developments to the modern instrument. Minor improvements to the bore and key work have continued through the 20th century, but there has been no fundamental change to the general characteristics of the instrument for several decades.

The modern standard oboe is most commonly made from grenadilla, also known as African blackwood, though some manufacturers also make oboes out of other members of the genus "Dalbergia", which includes cocobolo, rosewood, and violetwood (also known as kingwood). Ebony (genus Diospyros) has also been used. Student model oboes are often made from plastic resin, to avoid instrument cracking to which wood instruments are prone, but also to make the instrument more economical. The oboe has an extremely narrow conical bore. It is played with a double reed consisting of two thin blades of cane tied together on a small-diameter metal tube (staple) which is inserted into the reed socket at the top of the instrument. The commonly accepted range for the oboe extends from B to about G, over two and a half octaves, though its common tessitura lies from C to E. Some student oboes only extend down to B (the key for B is not present). However this variant is becoming less common.

A modern oboe with the "full conservatoire" ("conservatory" in the US) or Gillet key system has 45 pieces of keywork, with the possible additions of a third octave key and alternate (left little finger) F- or C-key. The keys are usually made of nickel silver, and are silver- or occasionally gold-plated. Besides the full conservatoire system, oboes are also made using the British thumbplate system. Most have "semi-automatic" octave keys, in which the second-octave action closes the first, and some have a fully automatic octave key system, as used on saxophones. Some full-conservatory oboes have finger holes covered with rings rather than plates ("open-holed"), and most of the professional models have at least the right-hand third key open-holed. Professional oboes used in the UK and Iceland frequently feature conservatoire system combined with a thumb plate. Releasing the thumb plate has the same effect as pressing down the right-hand index-finger key. This produces alternate options which eliminate the necessity for most of the common cross-intervals (intervals where two or more keys need to be released and pressed down simultaneously), but cross intervals are much more difficult to execute in such a way that the sound remains clear and continuous throughout the frequency change (a quality also called legato and often called-for in the oboe repertoire).

The standard oboe has several siblings of various sizes and playing ranges. The most widely known and used today is the cor anglais, or English horn, the tenor (or alto) member of the family. A transposing instrument; it is pitched in F, a perfect fifth lower than the oboe. The oboe d'amore, the alto (or mezzo-soprano) member of the family, is pitched in A, a minor third lower than the oboe. J.S. Bach made extensive use of both the oboe d'amore as well as the "taille" and oboe da caccia, Baroque antecedents of the cor anglais. Even less common is the bass oboe (also called baritone oboe), which sounds one octave lower than the oboe. Delius and Holst both scored for the instrument. Similar to the bass oboe is the more powerful heckelphone, which has a wider bore and larger tone than the baritone oboe. Only 165 heckelphones have ever been made. Not surprisingly, competent heckelphone players are difficult to find due to the extreme rarity of this particular instrument. The least common of all are the musette (also called oboe musette or piccolo oboe), the sopranino member of the family (it is usually pitched in E or F above the oboe), and the contrabass oboe (typically pitched in C, two octaves deeper than the standard oboe).

Folk versions of the oboe, sometimes equipped with extensive keywork, are found throughout Europe. These include the musette (France) and the piston oboe and bombarde (Brittany), the piffero and ciaramella (Italy), and the xirimia (also spelled chirimia) (Spain). Many of these are played in tandem with local forms of bagpipe, particularly with the Italian zampogna or Breton biniou. Similar oboe-like instruments, most believed to derive from Middle Eastern models, are also found throughout Asia as well as in North Africa.

Most professional oboists make their reeds to suit their individual needs. By making their reeds, oboists can precisely control factors such as tone color, intonation, and responsiveness.
Occasionally, novice oboists may begin with a "Fibrecane" reed, which is made of a synthetic material. Commercially available cane reeds are available in several degrees of hardness; a medium reed is very popular, and most beginners use medium-soft reeds. These reeds, like clarinet, saxophone, and bassoon reeds, are made from "Arundo donax".
As oboists gain more experience, they may start making their own reeds after the model of their teacher or buying handmade reeds (usually from a professional oboist) and using special tools including gougers, pre-gougers, guillotines, knives, and other tools to make the reed to their liking.



Although folk oboes are still used in many European folk music traditions, the modern oboe has been little used in folk music. One exception was Derek Bell, harpist for the Irish group The Chieftains, who used the regular instrument in some performances and recordings. The United States contra dance band Wild Asparagus, based in western Massachusetts, also uses the oboe, played by David Cantieni. The folk musician Paul Sartin plays the oboe in several English folk bands including Faustus and Bellowhead. Welsh bagpipe player and bagpipe maker Jonathan Shorland plays a 'rustic oboe' similar to the Breton 'piston' with the bands Primeaval and Juice. He formerly played with Fernhill, who play traditional Welsh music. The popular traditional music of Brittany boasts a significant professional class of musicians playing increasingly sophisticated double reed instruments, supported by professional instrument makers, reed manufacturers and the educational system. The Breton 'piston' oboe and bombard have expanded from traditional roles into genres as diverse as jazz, rock, and classical music.

The oboe remains uncommon in jazz music, but there have been notable uses of the instrument. Some early bands in the 1920s and '30s, most notably that of Paul Whiteman, included it for coloristic purposes. The multi-instrumentalist Garvin Bushell (1902–1991) played the oboe in jazz bands as early as 1924 and used the instrument throughout his career, eventually recording with John Coltrane in 1961. Gil Evans featured oboe in sections of his famous "Sketches of Spain" collaboration with trumpeter Miles Davis. Though primarily a tenor saxophone and flute player, Yusef Lateef was among the first (in 1961) to use the oboe as a solo instrument in modern jazz performances and recordings. Composer and double bassist Charles Mingus gave the oboe a brief but prominent role (played by Dick Hafer) in his composition "I.X. Love" on the 1963 album "Mingus Mingus Mingus Mingus Mingus". Marshall Allen occasionally played an oboe with Sun Ra.

With the birth of jazz fusion in the late 1960s, and its continuous development through the following decade, the oboe became somewhat more prominent, replacing on some occasions the saxophone as the focal point. The oboe was used with great success by the Welsh multi-instrumentalist Karl Jenkins in his work with the groups Nucleus and Soft Machine, and by the American woodwind player Paul McCandless, co-founder of the Paul Winter Consort and later Oregon. Romeo Penque also played the oboe on Roland Kirk's 1975 album "Return of the 5000 Lb. Man", in the song "Theme for the Eulipions."

The 1980s saw an increasing number of oboists try their hand at non-classical work, and many players of note have recorded and performed alternative music on oboe. Some present-day jazz groups influenced by classical music, such as the Maria Schneider Orchestra, feature the oboe.

The oboe has been used sporadically in rock/pop recordings (e.g., Frankie Valli and The Four Seasons "Big Man In Town" 1964; Dion "Abraham, Martin & John" 1968; The Carpenters' "For All We Know," 1970; Donovan's "Jennifer Juniper," 1968), generally by studio musicians on recordings of specific songs.

Peter Gabriel, during his period as lead singer in the progressive rock band Genesis, played oboe on some of the group's studio recordings. Andy Mackay played oboe for Roxy Music both in the studio and on stage.

In the 2000s, Robbie J. de Klerk, the vocalist of the Dutch melodic doom/death metal band Another Messiah also played the oboe in most songs. In America, the band Hoboe defines itself as a rock band showcasing amplified oboe since 2000, fronted by oboist Zen Ben. Indie singer-songwriter and composer Sufjan Stevens, having studied the instrument in school, often includes the instrument in his arrangements and compositions, most frequently in his geographic tone-poems "Illinois", "Michigan", and his orchestral suite "The BQE".


The oboe is frequently featured in film music, often to underscore a particularly poignant or sad scene, for example in the motion picture "Born on the Fourth of July", where an oboe delicately takes the theme with a romantic and harmonic touch before the strings hand it over once again to the trumpet. One of the most prominent uses of the oboe in a film score is Ennio Morricone's "Gabriel's Oboe" theme from the 1986 film "The Mission".

It is featured as a solo instrument in the theme "Across the Stars" from the John Williams score to "". The oboe is also used in "The Search" from the Basil Poledouris score to "Conan the Barbarian".

Ilaiyaraja, a famous Indian film music composer, has also used the oboe in much of his film music. Examples include "Dalapathi" (1991); the title track of "Aditya 369" (1991); "Pazhassiraja" (2009); and "Nandalaala" (2010). The oboe has also been used by more recent Indian music composers, such as A. R. Rahman, who has used it in the movie "Jodha Akbar" (2008).




</doc>
<doc id="22208" url="https://en.wikipedia.org/wiki?curid=22208" title="Organic chemistry">
Organic chemistry

Organic chemistry is a chemistry subdiscipline involving the scientific study of the structure, properties, and reactions of organic compounds and organic materials, i.e., matter in its various forms that contain carbon atoms. Study of structure includes many physical and chemical methods to determine the chemical composition and the chemical constitution of organic compounds and materials. Study of properties includes both physical properties and chemical properties, and uses similar methods as well as methods to evaluate chemical reactivity, with the aim to understand the behavior of the organic matter in its pure form (when possible), but also in solutions, mixtures, and fabricated forms. The study of organic reactions includes probing their scope through use in preparation of target compounds (e.g., natural products, drugs, polymers, etc.) by chemical synthesis, as well as the focused study of the reactivities of individual organic molecules, both in the laboratory and via theoretical (in silico) study.

The range of chemicals studied in organic chemistry include hydrocarbons (compounds containing only carbon and hydrogen), as well as myriad compositions based always on carbon, but also containing other elements, especially oxygen, nitrogen, sulfur, phosphorus (these included in many organic chemicals in biology) and the radiostable elements of the halogens.

In the modern era, the range extends further into the periodic table, with main group elements, including:

In addition, much modern research focuses on organic chemistry involving further organometallics, including the lanthanides, but especially the transition metals; (e.g., zinc, copper, palladium, nickel, cobalt, titanium and chromium)
Finally, organic compounds form the basis of all earthly life and constitute a significant part of human endeavors in chemistry. The bonding patterns open to carbon, with its valence of four—formal single, double, and triple bonds, as well as various structures with delocalized electrons—make the array of organic compounds structurally diverse, and their range of applications enormous. They either form the basis of, or are important constituents of, many commercial products including pharmaceuticals; petrochemicals and agrichemicals, and products made from them (including lubricants, solvents, etc.); plastics; fuels and explosives; etc. As indicated, the study of organic chemistry overlaps with organometallic chemistry and biochemistry, but also with medicinal chemistry, polymer chemistry, as well as many aspects of materials science.

Before the nineteenth century, chemists generally believed that compounds obtained from living organisms were endowed with a vital force that distinguished them from inorganic compounds. According to the concept of vitalism (vital force theory), organic matter was endowed with a "vital force". During the first half of the nineteenth century, some of the first systematic studies of organic compounds were reported. Around 1816 Michel Chevreul started a study of soaps made from various fats and alkalis. He separated the different acids that, in combination with the alkali, produced the soap. Since these were all individual compounds, he demonstrated that it was possible to make a chemical change in various fats (which traditionally come from organic sources), producing new compounds, without "vital force". In 1828 Friedrich Wöhler produced the "organic" chemical urea (carbamide), a constituent of urine, from "inorganic" starting materials (the salts potassium cyanate and ammonium sulfate), in what is now called the Wöhler synthesis. Although Wöhler himself was cautious about claiming he had disproved vitalism, this was the first time a substance thought to be organic was synthesized in the laboratory without biological (organic) starting materials. The event is now generally accepted as indeed disproving the doctrine of vitalism.

In 1856 William Henry Perkin, while trying to manufacture quinine accidentally produced the organic dye now known as Perkin's mauve. His discovery, made widely known through its financial success, greatly increased interest in organic chemistry.

A crucial breakthrough for organic chemistry was the concept of chemical structure, developed independently in 1858 by both Friedrich August Kekulé and Archibald Scott Couper. Both researchers suggested that tetravalent carbon atoms could link to each other to form a carbon lattice, and that the detailed patterns of atomic bonding could be discerned by skillful interpretations of appropriate chemical reactions.

The era of the pharmaceutical industry began in the last decade of the 19th century when the manufacturing of acetylsalicylic acidmore commonly referred to as aspirinin Germany was started by Bayer. By 1910 Paul Ehrlich and his laboratory group began developing arsenic-based arsphenamine, (Salvarsan), as the first effective medicinal treatment of syphilis, and thereby initiated the medical practice of chemotherapy. Ehrlich popularized the concepts of "magic bullet" drugs and of systematically improving drug therapies. His laboratory made decisive contributions to developing antiserum for diphtheria and standardizing therapeutic serums.

Early examples of organic reactions and applications were often found because of a combination of luck and preparation for unexpected observations. The latter half of the 19th century however witnessed systematic studies of organic compounds. The development of synthetic indigo is illustrative. The production of indigo from plant sources dropped from 19,000 tons in 1897 to 1,000 tons by 1914 thanks to the synthetic methods developed by Adolf von Baeyer. In 2002, 17,000 tons of synthetic indigo were produced from petrochemicals.

In the early part of the 20th century, polymers and enzymes were shown to be large organic molecules, and petroleum was shown to be of biological origin.

The multiple-step synthesis of complex organic compounds is called total synthesis. Total synthesis of complex natural compounds increased in complexity to glucose and terpineol. For example, cholesterol-related compounds have opened ways to synthesize complex human hormones and their modified derivatives. Since the start of the 20th century, complexity of total syntheses has been increased to include molecules of high complexity such as lysergic acid and vitamin B.
The discovery of petroleum and the development of the petrochemical industry spurred the development of organic chemistry. Converting individual petroleum compounds into different "types" of compounds by various chemical processes led to organic reactions enabling a broad range of industrial and commercial products including, among (many) others: plastics, synthetic rubber, organic adhesives, and various property-modifying petroleum additives and catalysts.

The majority of chemical compounds occurring in biological organisms are in fact carbon compounds, so the association between organic chemistry and biochemistry is so close that biochemistry might be regarded as in essence a branch of organic chemistry. Although the history of biochemistry might be taken to span some four centuries, fundamental understanding of the field only began to develop in the late 19th century and the actual term "biochemistry" was coined around the start of 20th century. Research in the field increased throughout the twentieth century, without any indication of slackening in the rate of increase, as may be verified by inspection of abstraction and indexing services such as BIOSIS Previews and Biological Abstracts, which began in the 1920s as a single annual volume, but has grown so drastically that by the end of the 20th century it was only available to the everyday user as an online electronic database.

Since organic compounds often exist as mixtures, a variety of techniques have also been developed to assess purity, especially important being chromatography techniques such as HPLC and gas chromatography. Traditional methods of separation include distillation, crystallization, and solvent extraction.

Organic compounds were traditionally characterized by a variety of chemical tests, called "wet methods", but such tests have been largely displaced by spectroscopic or other computer-intensive methods of analysis. Listed in approximate order of utility, the chief analytical methods are:

Traditional spectroscopic methods such as infrared spectroscopy, optical rotation, UV/VIS spectroscopy provide relatively nonspecific structural information but remain in use for specific classes of compounds. Traditionally refractive index and density were also important for substance identification.

Physical properties of organic compounds typically of interest include both quantitative and qualitative features. Quantitative information includes melting point, boiling point, and index of refraction. Qualitative properties include odor, consistency, solubility, and color.

Organic compounds typically melt and many boil. In contrast, while inorganic materials generally can be melted, many do not boil, tending instead to degrade. In earlier times, the melting point (m.p.) and boiling point (b.p.) provided crucial information on the purity and identity of organic compounds. The melting and boiling points correlate with the polarity of the molecules and their molecular weight. Some organic compounds, especially symmetrical ones, sublime, that is they evaporate without melting. A well-known example of a sublimable organic compound is para-dichlorobenzene, the odiferous constituent of modern mothballs. Organic compounds are usually not very stable at temperatures above 300 °C, although some exceptions exist.

Neutral organic compounds tend to be hydrophobic; that is, they are less soluble in water than in organic solvents. Exceptions include organic compounds that contain ionizable (which can be converted in ions) groups as well as low molecular weight alcohols, amines, and carboxylic acids where hydrogen bonding occurs. Organic compounds tend to dissolve in organic solvents. Solvents can be either pure substances like ether or ethyl alcohol, or mixtures, such as the paraffinic solvents such as the various petroleum ethers and white spirits, or the range of pure or mixed aromatic solvents obtained from petroleum or tar fractions by physical separation or by chemical conversion. Solubility in the different solvents depends upon the solvent type and on the functional groups if present in the solution.

Various specialized properties of molecular crystals and organic polymers with conjugated systems are of interest depending on applications, e.g. thermo-mechanical and electro-mechanical such as piezoelectricity, electrical conductivity (see conductive polymers and organic semiconductors), and electro-optical (e.g. non-linear optics) properties. For historical reasons, such properties are mainly the subjects of the areas of polymer science and materials science.

The names of organic compounds are either systematic, following logically from a set of rules, or nonsystematic, following various traditions. Systematic nomenclature is stipulated by specifications from IUPAC. Systematic nomenclature starts with the name for a parent structure within the molecule of interest. This parent name is then modified by prefixes, suffixes, and numbers to unambiguously convey the structure. Given that millions of organic compounds are known, rigorous use of systematic names can be cumbersome. Thus, IUPAC recommendations are more closely followed for simple compounds, but not complex molecules. To use the systematic naming, one must know the structures and names of the parent structures. Parent structures include unsubstituted hydrocarbons, heterocycles, and monofunctionalized derivatives thereof.

Nonsystematic nomenclature is simpler and unambiguous, at least to organic chemists. Nonsystematic names do not indicate the structure of the compound. They are common for complex molecules, which includes most natural products. Thus, the informally named lysergic acid diethylamide is systematically named
(6a"R",9"R")-"N","N"-diethyl-7-methyl-4,6,6a,7,8,9-hexahydroindolo-[4,3-"fg"] quinoline-9-carboxamide.

With the increased use of computing, other naming methods have evolved that are intended to be interpreted by machines. Two popular formats are SMILES and InChI.

Organic molecules are described more commonly by drawings or structural formulas, combinations of drawings and chemical symbols. The line-angle formula is simple and unambiguous. In this system, the endpoints and intersections of each line represent one carbon, and hydrogen atoms can either be notated explicitly or assumed to be present as implied by tetravalent carbon.
By 1880 an explosion in the number of chemical compounds being discovered occurred assisted by new synthetic and analytical techniques. Grignard described the situation as "chaos le plus complet" as due to the lack of convention it was possible to have multiple names for the same compound. This led to the creation of the Geneva rules in 1892.

The concept of functional groups is central in organic chemistry, both as a means to classify structures and for predicting properties. A functional group is a molecular module, and the reactivity of that functional group is assumed, within limits, to be the same in a variety of molecules. Functional groups can have decisive influence on the chemical and physical properties of organic compounds. Molecules are classified on the basis of their functional groups. Alcohols, for example, all have the subunit C-O-H. All alcohols tend to be somewhat hydrophilic, usually form esters, and usually can be converted to the corresponding halides. Most functional groups feature heteroatoms (atoms other than C and H). Organic compounds are classified according to functional groups, alcohols, carboxylic acids, amines, etc.

The aliphatic hydrocarbons are subdivided into three groups of homologous series according to their state of saturation: 
The rest of the group is classed according to the functional groups present. Such compounds can be "straight-chain", branched-chain or cyclic. The degree of branching affects characteristics, such as the octane number or cetane number in petroleum chemistry.

Both saturated (alicyclic) compounds and unsaturated compounds exist as cyclic derivatives. The most stable rings contain five or six carbon atoms, but large rings (macrocycles) and smaller rings are common. The smallest cycloalkane family is the three-membered cyclopropane ((CH)). Saturated cyclic compounds contain single bonds only, whereas aromatic rings have an alternating (or conjugated) double bond. Cycloalkanes do not contain multiple bonds, whereas the cycloalkenes and the cycloalkynes do.

Aromatic hydrocarbons contain conjugated double bonds. This means that every carbon atom in the ring is sp2 hybridized, allowing for added stability. The most important example is benzene, the structure of which was formulated by Kekulé who first proposed the delocalization or resonance principle for explaining its structure. For "conventional" cyclic compounds, aromaticity is conferred by the presence of 4n + 2 delocalized pi electrons, where n is an integer. Particular instability (antiaromaticity) is conferred by the presence of 4n conjugated pi electrons.

The characteristics of the cyclic hydrocarbons are again altered if heteroatoms are present, which can exist as either substituents attached externally to the ring (exocyclic) or as a member of the ring itself (endocyclic). In the case of the latter, the ring is termed a heterocycle. Pyridine and furan are examples of aromatic heterocycles while piperidine and tetrahydrofuran are the corresponding alicyclic heterocycles. The heteroatom of heterocyclic molecules is generally oxygen, sulfur, or nitrogen, with the latter being particularly common in biochemical systems.

Heterocycles are commonly found in a wide range of products including aniline dyes and medicines. Additionally, they are prevalent in a wide range of biochemical compounds such as alkaloids, vitamins, steroids, and nucleic acids (e.g. DNA, RNA).

Rings can fuse with other rings on an edge to give polycyclic compounds. The purine nucleoside bases are notable polycyclic aromatic heterocycles. Rings can also fuse on a "corner" such that one atom (almost always carbon) has two bonds going to one ring and two to another. Such compounds are termed spiro and are important in a number of natural products.

One important property of carbon is that it readily forms chains, or networks, that are linked by carbon-carbon (carbon-to-carbon) bonds. The linking process is called polymerization, while the chains, or networks, are called polymers. The source compound is called a monomer.

Two main groups of polymers exist: synthetic polymers and biopolymers. Synthetic polymers are artificially manufactured, and are commonly referred to as industrial polymers. Biopolymers occur within a respectfully natural environment, or without human intervention.

Since the invention of the first synthetic polymer product, bakelite, synthetic polymer products have frequently been invented.

Common synthetic organic polymers are polyethylene (polythene), polypropylene, nylon, teflon (PTFE), polystyrene, polyesters, polymethylmethacrylate (called perspex and plexiglas), and polyvinylchloride (PVC). 

Both synthetic and natural rubber are polymers. 

Varieties of each synthetic polymer product may exist, for purposes of a specific use. Changing the conditions of polymerization alters the chemical composition of the product and its properties. These alterations include the chain length, or branching, or the tacticity. 

With a single monomer as a start, the product is a homopolymer. 

Secondary component(s) may be added to create a heteropolymer (co-polymer) and the degree of clustering of the different components can also be controlled. 

Physical characteristics, such as hardness, density, mechanical or tensile strength, abrasion resistance, heat resistance, transparency, colour, etc. will depend on the final composition. 

Biomolecular chemistry is a major category within organic chemistry which is frequently studied by biochemists. Many complex multi-functional group molecules are important in living organisms. Some are long-chain biopolymers, and these include peptides, DNA, RNA and the polysaccharides such as starches in animals and celluloses in plants. The other main classes are amino acids (monomer building blocks of peptides and proteins), carbohydrates (which includes the polysaccharides), the nucleic acids (which include DNA and RNA as polymers), and the lipids. In addition, animal biochemistry contains many small molecule intermediates which assist in energy production through the Krebs cycle, and produces isoprene, the most common hydrocarbon in animals. Isoprenes in animals form the important steroid structural (cholesterol) and steroid hormone compounds; and in plants form terpenes, terpenoids, some alkaloids, and a class of hydrocarbons called biopolymer polyisoprenoids present in the latex of various species of plants, which is the basis for making rubber.


In pharmacology, an important group of organic compounds is small molecules, also referred to as 'small organic compounds'. In this context, a small molecule is a small organic compound that is biologically active, but is not a polymer. In practice, small molecules have a molar mass less than approximately 1000 g/mol.

Fullerenes and carbon nanotubes, carbon compounds with spheroidal and tubular structures, have stimulated much research into the related field of materials science. The first fullerene was discovered in 1985 by Sir Harold W. Kroto of the United Kingdom and by Richard E. Smalley and Robert F. Curl, Jr., of the United States. Using a laser to vaporize graphite rods in an atmosphere of helium gas, these chemists and their assistants obtained cagelike molecules composed of 60 carbon atoms (C60) joined together by single and double bonds to form a hollow sphere with 12 pentagonal and 20 hexagonal faces—a design that resembles a football, or soccer ball. In 1996 the trio was awarded the Nobel Prize for their pioneering efforts. The C60 molecule was named buckminsterfullerene (or, more simply, the buckyball) after the American architect R. Buckminster Fuller, whose geodesic dome is constructed on the same structural principles.

Organic compounds containing bonds of carbon to nitrogen, oxygen and the halogens are not normally grouped separately. Others are sometimes put into major groups within organic chemistry and discussed under titles such as organosulfur chemistry, organometallic chemistry, organophosphorus chemistry and organosilicon chemistry.

Organic reactions are chemical reactions involving organic compounds. Many of these reactions are associated with functional groups. The general theory of these reactions involves careful analysis of such properties as the electron affinity of key atoms, bond strengths and steric hindrance. These factors can determine the relative stability of short-lived reactive intermediates, which usually directly determine the path of the reaction.

The basic reaction types are: addition reactions, elimination reactions, substitution reactions, pericyclic reactions, rearrangement reactions and redox reactions. An example of a common reaction is a substitution reaction written as:

where X is some functional group and Nu is a nucleophile.

The number of possible organic reactions is basically infinite. However, certain general patterns are observed that can be used to describe many common or useful reactions. Each reaction has a stepwise reaction mechanism that explains how it happens in sequence—although the detailed description of steps is not always clear from a list of reactants alone.

The stepwise course of any given reaction mechanism can be represented using arrow pushing techniques in which curved arrows are used to track the movement of electrons as starting materials transition through intermediates to final products.

Synthetic organic chemistry is an applied science as it borders engineering, the "design, analysis, and/or construction of works for practical purposes". Organic synthesis of a novel compound is a problem solving task, where a synthesis is designed for a target molecule by selecting optimal reactions from optimal starting materials. Complex compounds can have tens of reaction steps that sequentially build the desired molecule. The synthesis proceeds by utilizing the reactivity of the functional groups in the molecule. For example, a carbonyl compound can be used as a nucleophile by converting it into an enolate, or as an electrophile; the combination of the two is called the aldol reaction. Designing practically useful syntheses always requires conducting the actual synthesis in the laboratory. The scientific practice of creating novel synthetic routes for complex molecules is called total synthesis.

Strategies to design a synthesis include retrosynthesis, popularized by E.J. Corey, which starts with the target molecule and splices it to pieces according to known reactions. The pieces, or the proposed precursors, receive the same treatment, until available and ideally inexpensive starting materials are reached. Then, the retrosynthesis is written in the opposite direction to give the synthesis. A "synthetic tree" can be constructed, because each compound and also each precursor has multiple syntheses.




</doc>
<doc id="22209" url="https://en.wikipedia.org/wiki?curid=22209" title="Orthography">
Orthography

An orthography is a set of conventions for writing a language. It includes norms of spelling, hyphenation, capitalization, word breaks, emphasis, and punctuation.

Most significant languages in the modern era are written down, and for most such languages a standard orthography has been developed, often based on a standard variety of the language, and thus exhibiting less dialect variation than the spoken language. Sometimes there may be variation in a language's orthography, as between American and British spelling in the case of English orthography. In some languages orthography is regulated by language academies, although for many languages (including English) there are no such authorities, and orthography develops in a more organic way. Even in the latter languages, a significant amount of consensus arises naturally, although a maximum of consistency or standardization occurs only when prescriptively imposed according to style guides.

The English word "orthography" dates from the 15th century. It comes from the French "orthographie", from Latin "orthographia", which derives from Greek ὀρθός "orthós", "correct", and γράφειν "gráphein", "to write".

Orthography is largely concerned with matters of spelling, and in particular the relationship between phonemes and graphemes in a language. Other elements that may be considered part of orthography include hyphenation, capitalization, word breaks, emphasis, and punctuation. Orthography thus describes or defines the set of symbols used in writing a language, and the rules regarding how to use those symbols.

Most natural languages developed as oral languages, and writing systems have usually been crafted or adapted as ways of representing the spoken language. The rules for doing this tend to become standardized for a given language, leading to the development of an orthography that is generally considered "correct". In linguistics the term "orthography" is often used to refer to any method of writing a language, without judgment as to right and wrong, with a scientific understanding that orthographic standardization exists on a spectrum of strength of convention. The original sense of the word, though, implies a dichotomy of correct and incorrect, and the word is still most often used to refer specifically to a thoroughly standardized, prescriptively correct, way of writing a language. A distinction may be made here between "etic" and "emic" viewpoints: the purely descriptive (etic) approach, which simply considers any system that is actually used—and the emic view, which takes account of language users' perceptions of correctness.

Orthographic units, such as letters of an alphabet, are technically called graphemes. These are a type of abstraction, analogous to the phonemes of spoken languages; different physical forms of written symbols are considered to represent the same grapheme if the differences between them are not significant for meaning. For example, different forms of the letter "b" are all considered to represent a single grapheme in the orthography of, say, English.
Graphemes or sequences of them are sometimes placed between angle brackets, as in or . This distinguishes them from phonemic transcription, which is placed between slashes (, ), and from phonetic transcription, which is placed between square brackets (, ).

The writing systems on which orthographies are based can be divided into a number of types, depending on what type of unit each symbol serves to represent. The principal types are "logographic" (with symbols representing words or morphemes), "syllabic" (with symbols representing syllables), and "alphabetic" (with symbols roughly representing phonemes). Many writing systems combine features of more than one of these types, and a number of detailed classifications have been proposed. Japanese is an example of a language that can be written in all three: logographic kanji, syllabic hiragana and katakana, and alphabetic romaji. 

Orthographies that use alphabets and syllabaries are based on the principle that the written symbols (graphemes) correspond to units of sound of the spoken language: phonemes in the former case, and syllables in the latter. However, in virtually all cases, this correspondence is not exact. Different languages' orthographies offer different degrees of correspondence between spelling and pronunciation. English orthography, for example, is highly irregular, whereas the orthographies of languages such as Russian, Spanish and Finnish represent pronunciation much more faithfully, although the correspondence between letters and phonemes is still not exact. Bosnian, Croatian and Serbian orthographies are remarkably consistent: approximation of the principle "one letter per sound".

An orthography in which the correspondences between spelling and pronunciation are highly complex or inconsistent is called a "deep orthography" (or less formally, the language is said to have "irregular spelling"). An orthography with relatively simple and consistent correspondences is called "shallow" (and the language has "regular spelling").

One of the main reasons for which spelling and pronunciation deviate is that sound changes taking place in the spoken language are not always reflected in the orthography, and hence spellings correspond to historical rather than present-day pronunciation. One consequence of this is that many spellings come to reflect a word's morphophonemic structure rather than its purely phonemic structure (for example, the English regular past tense morpheme is consistently spelled "-ed" in spite of its different pronunciations in various words). This is discussed further at .

The syllabary systems of Japanese (hiragana and katakana) are examples of almost perfectly shallow orthographies—the kana correspond with almost perfect consistency to the spoken syllables, although with a few exceptions where symbols reflect historical or morphophonemic features: notably the use of ぢ "ji" and づ "zu" (rather than じ "ji" and ず "zu", their pronunciation in standard Tokyo dialect) when the character is a voicing of an underlying ち or つ (see rendaku), and the use of は, を, and へ to represent the sounds わ, お, and え, as relics of historical kana usage.

The Korean "hangul" system was also originally an extremely shallow orthography, but as a representation of the modern language it frequently also reflects morphophonemic features.

For full discussion of degrees of correspondence between spelling and pronunciation in alphabetic orthographies, including reasons why such correspondence may break down, see Phonemic orthography.

An orthography based on the principle that symbols correspond to phonemes may, in some cases, lack characters to represent all the phonemes or all the phonemic distinctions in the language. This is called a defective orthography. An example in English is the lack of any indication of stress. Another is the digraph "th", which represents two different phonemes (as in "then" and "thin"). A more systematic example is that of abjads like the Arabic and Hebrew alphabets, in which the short vowels are normally left unwritten and must be inferred by the reader.

When an alphabet is borrowed from its original language for use with a new language—as has been done with the Latin alphabet for many languages, or Japanese Katakana for non-Japanese words—it often proves defective in representing the new language's phonemes. Sometimes this problem is addressed by the use of such devices as digraphs (such as "sh" and "ch" in English, where pairs of letters represent single sounds), diacritics (like the caron on the letters "š" and "č", which represent those same sounds in Czech), or the addition of completely new symbols (as some languages have introduced the letter "w" to the Latin alphabet) or of symbols from another alphabet, such as the rune "þ" in Icelandic.

After the classical period, Greek developed a lowercase letter system that introduced diacritic marks to enable foreigners to learn pronunciation and in some cases, grammatical features. However, as pronunciation of letters changed over time, the diacritic marks were reduced to representing the stressed syllable. In Modern Greek typesetting, this system has been simplified to only have a single accent to indicate which syllable is stressed.




</doc>
<doc id="22210" url="https://en.wikipedia.org/wiki?curid=22210" title="One-time pad">
One-time pad

In cryptography, the one-time pad (OTP) is an encryption technique that cannot be cracked, but requires the use of a one-time pre-shared key the same size as, or longer than, the message being sent. In this technique, a plaintext is paired with a random secret key (also referred to as "a one-time pad"). Then, each bit or character of the plaintext is encrypted by combining it with the corresponding bit or character from the pad using modular addition. If the key is truly random, is at least as long as the plaintext, is never reused in whole or in part, and is kept completely secret, then the resulting ciphertext will be impossible to decrypt or break. It has also been proven that any cipher with the perfect secrecy property must use keys with effectively the same requirements as OTP keys. Digital versions of one-time pad ciphers have been used by nations for some critical diplomatic and military communication, but the problems of secure key distribution have made them impractical for most applications.

First described by Frank Miller in 1882, the one-time pad was re-invented in 1917. On July 22, 1919, U.S. Patent 1,310,719 was issued to Gilbert S. Vernam for the XOR operation used for the encryption of a one-time pad. Derived from his "Vernam cipher", the system was a cipher that combined a message with a key read from a punched tape. In its original form, Vernam's system was vulnerable because the key tape was a loop, which was reused whenever the loop made a full cycle. One-time use came later, when Joseph Mauborgne recognized that if the key tape were totally random, then cryptanalysis would be impossible.

The "pad" part of the name comes from early implementations where the key material was distributed as a pad of paper, so that the top sheet could be easily torn off and destroyed after use. For ease of concealment, the pad was sometimes reduced to such a small size that a powerful magnifying glass was required to use it. The KGB used pads of such size that they could fit in the palm of a hand, or in a walnut shell. To increase security, one-time pads were sometimes printed onto sheets of highly flammable nitrocellulose, so that they could be quickly burned after use.

There is some ambiguity to the term "Vernam cipher" because some sources use "Vernam cipher" and "one-time pad" synonymously, while others refer to any additive stream cipher as a "Vernam cipher", including those based on a cryptographically secure pseudorandom number generator (CSPRNG).

Frank Miller in 1882 was the first to describe the one-time pad system for securing telegraphy.

The next one-time pad system was electrical. In 1917, Gilbert Vernam (of AT&T Corporation) invented and later patented in 1919 () a cipher based on teleprinter technology. Each character in a message was electrically combined with a character on a paper tape key. Joseph Mauborgne (then a captain in the U.S. Army and later chief of the Signal Corps) recognized that the character sequence on the key tape could be completely random and that, if so, cryptanalysis would be more difficult. Together they invented the first one-time tape system.

The next development was the paper pad system. Diplomats had long used codes and ciphers for confidentiality and to minimize telegraph costs. For the codes, words and phrases were converted to groups of numbers (typically 4 or 5 digits) using a dictionary-like codebook. For added security, secret numbers could be combined with (usually modular addition) each code group before transmission, with the secret numbers being changed periodically (this was called superencryption). In the early 1920s, three German cryptographers (Werner Kunze, Rudolf Schauffler and Erich Langlotz), who were involved in breaking such systems, realized that they could never be broken if a separate randomly chosen additive number was used for every code group. They had duplicate paper pads printed with lines of random number groups. Each page had a serial number and eight lines. Each line had six 5-digit numbers. A page would be used as a work sheet to encode a message and then destroyed. The serial number of the page would be sent with the encoded message. The recipient would reverse the procedure and then destroy his copy of the page. The German foreign office put this system into operation by 1923.

A separate notion was the use of a one-time pad of letters to encode plaintext directly as in the example below. Leo Marks describes inventing such a system for the British Special Operations Executive during World War II, though he suspected at the time that it was already known in the highly compartmentalized world of cryptography, as for instance at Bletchley Park.

The final discovery was made by Claude Shannon in the 1940s who recognized and proved the theoretical significance of the one-time pad system. Shannon delivered his results in a classified report in 1945, and published them openly in 1949. At the same time, Vladimir Kotelnikov had independently proved absolute security of the one-time pad; his results were delivered in 1941 in a report that apparently remains classified.

Suppose Alice wishes to send the message "HELLO" to Bob. Assume two pads of paper containing identical random sequences of letters were somehow previously produced and securely issued to both. Alice chooses the appropriate unused page from the pad. The way to do this is normally arranged for in advance, as for instance 'use the 12th sheet on 1 May', or 'use the next available sheet for the next message'.

The material on the selected sheet is the "key" for this message. Each letter from the pad will be combined in a predetermined way with one letter of the message. (It is common, but not required, to assign each letter a numerical value, e.g., "A" is 0, "B" is 1, and so on.)

In this example, the technique is to combine the key and the message using modular addition. The numerical values of corresponding message and key letters are added together, modulo 26. So, if key material begins with "XMCKL" and the message is "HELLO", then the coding would be done as follows:

If a number is larger than 26, then the remainder after subtraction of 26 is taken in modular arithmetic fashion. This simply means that if the computations "go past" Z, the sequence starts again at A.

The ciphertext to be sent to Bob is thus "EQNVZ". Bob uses the matching key page and the same process, but in reverse, to obtain the plaintext. Here the key is "subtracted" from the ciphertext, again using modular arithmetic:

Similar to the above, if a number is negative then 26 is added to make the number zero or higher.

Thus Bob recovers Alice's plaintext, the message "HELLO". Both Alice and Bob destroy the key sheet immediately after use, thus preventing reuse and an attack against the cipher. The KGB often issued its agents one-time pads printed on tiny sheets of "flash paper"—paper chemically converted to nitrocellulose, which burns almost instantly and leaves no ash.

The classical one-time pad of espionage used actual pads of minuscule, easily concealed paper, a sharp pencil, and some mental arithmetic. The method can be implemented now as a software program, using data files as input (plaintext), output (ciphertext) and key material (the required random sequence). The XOR operation is often used to combine the plaintext and the key elements, and is especially attractive on computers since it is usually a native machine instruction and is therefore very fast. It is, however, difficult to ensure that the key material is actually random, is used only once, never becomes known to the opposition, and is completely destroyed after use. The auxiliary parts of a software one-time pad implementation present real challenges: secure handling/transmission of plaintext, truly random keys, and one-time-only use of the key.

To continue the example from above, suppose Eve intercepts Alice's ciphertext: "EQNVZ". If Eve had infinite time, she would find that the key "XMCKL" would produce the plaintext "HELLO", but she would also find that the key "TQURI" would produce the plaintext "LATER", an equally plausible message:
In fact, it is possible to "decrypt" out of the ciphertext any message whatsoever with the same number of characters, simply by using a different key, and there is no information in the ciphertext that will allow Eve to choose among the various possible readings of the ciphertext.

One-time pads are "information-theoretically secure" in that the encrypted message (i.e., the ciphertext) provides no information about the original message to a cryptanalyst (except the maximum possible length of the message). This is a very strong notion of security first developed during WWII by Claude Shannon and proved, mathematically, to be true for the one-time pad by Shannon about the same time. His result was published in the "Bell Labs Technical Journal" in 1949. Properly used, one-time pads are secure in this sense even against adversaries with infinite computational power.

Claude Shannon proved, using information theory considerations, that the one-time pad has a property he termed "perfect secrecy"; that is, the ciphertext "C" gives absolutely no additional information about the plaintext. This is because, given a truly random key that is used only once, a ciphertext can be translated into "any" plaintext of the same length, and all are equally likely. Thus, the "a priori" probability of a plaintext message "M" is the same as the "a posteriori" probability of a plaintext message "M" given the corresponding ciphertext. Mathematically, this is expressed as "H"("M")="H"("M"|"C"), where "H"("M") is the entropy of the plaintext and "H"("M"|"C") is the conditional entropy of the plaintext given the ciphertext "C". This implies that for every message "M" and corresponding ciphertext "C", there must be at least one key "K" that binds them. Mathematically speaking, this means formula_1. In other words, if you need to be able to go from any plaint-text in message space "M" to any cipher in cipher-space "C" (encryption) and from any cipher in cipher-space "C" to a plain text in message space "M" (decryption), you need at least formula_2 keys (all keys used with equal probability of formula_3 to ensure perfect secrecy).

Another way of stating perfect secrecy is based on the idea that for all messages formula_4 in message space "M", and for all ciphers "c" in cipher space "C", we have formula_5, where formula_6 represents the probabilities, taken over a choice of formula_7 in key space formula_8 over the coin tosses of a probabilistic algorithm, formula_9. Perfect secrecy is a strong notion of cryptanalytic difficulty.

Conventional symmetric encryption algorithms use complex patterns of substitution and transpositions. For the best of these currently in use, it is not known whether there can be a cryptanalytic procedure that can reverse (or, usefully, partially reverse) these transformations without knowing the key used during encryption. Asymmetric encryption algorithms depend on mathematical problems that are thought to be difficult to solve, such as integer factorization and discrete logarithms. However, there is no proof that these problems are hard, and a mathematical breakthrough could make existing systems vulnerable to attack.

Given perfect secrecy, in contrast to conventional symmetric encryption, OTP is immune even to brute-force attacks. Trying all keys simply yields all plaintexts, all equally likely to be the actual plaintext. Even with known plaintext, like part of the message being known, brute-force attacks cannot be used, since an attacker is unable to gain any information about the parts of the key needed to decrypt the rest of the message. The parts that are known will reveal "only" the parts of the key corresponding to them, and they correspond on a strictly one-to-one basis; no part of the key is dependent on any other part.

Despite Shannon's proof of its security, the one-time pad has serious drawbacks in practice because it requires:


One-time pads solve few current practical problems in cryptography. High quality ciphers are widely available and their security is not considered a major worry at present. Such ciphers are almost always easier to employ than one-time pads; the amount of key material that must be properly generated and securely distributed is far smaller, and public key cryptography overcomes this problem.

High-quality random numbers are difficult to generate. The random number generation functions in most programming language libraries are not suitable for cryptographic use. Even those generators that are suitable for normal cryptographic use, including /dev/random and many hardware random number generators, may make some use of cryptographic functions whose security has not been proven. An example of how true randomness can be achieved is by measuring radioactive emissions.

In particular, one-time use is absolutely necessary. If a one-time pad is used just twice, simple mathematical operations can reduce it to a running key cipher. If both plaintexts are in a natural language (e.g., English or Russian) then, even though both are secret, each stands a very high chance of being recovered by heuristic cryptanalysis, with possibly a few ambiguities. Of course the longer message can only be broken for the portion that overlaps the shorter message, plus perhaps a little more by completing a word or phrase. The most famous exploit of this vulnerability occurred with the Venona project.

Because the pad, like all shared secrets, must be passed and kept secure, and the pad has to be at least as long as the message, there is often no point in using one-time padding, as one can simply send the plain text instead of the pad (as both can be the same size and have to be sent securely). However, once a very long pad has been securely sent (e.g., a computer disk full of random data), it can be used for numerous future messages, until the sum of their sizes equals the size of the pad. Quantum key distribution also proposes a solution to this problem.

Distributing very long one-time pad keys is inconvenient and usually poses a significant security risk. The pad is essentially the encryption key, but unlike keys for modern ciphers, it must be extremely long and is much too difficult for humans to remember. Storage media such as thumb drives, DVD-Rs or personal digital audio players can be used to carry a very large one-time-pad from place to place in a non-suspicious way, but even so the need to transport the pad physically is a burden compared to the key negotiation protocols of a modern public-key cryptosystem, and such media cannot reliably be erased securely by any means short of physical destruction (e.g., incineration). A 4.7 GB DVD-R full of one-time-pad data, if shredded into particles 1 mm² in size, leaves over 4 megabits of (admittedly hard to recover, but not impossibly so) data on each particle. In addition, the risk of compromise during transit (for example, a pickpocket swiping, copying and replacing the pad) is likely to be much greater in practice than the likelihood of compromise for a cipher such as AES. Finally, the effort needed to manage one-time pad key material scales very badly for large networks of communicants—the number of pads required goes up as the square of the number of users freely exchanging messages. For communication between only two persons, or a star network topology, this is less of a problem.

The key material must be securely disposed of after use, to ensure the key material is never reused and to protect the messages sent. Because the key material must be transported from one endpoint to another, and persist until the message is sent or received, it can be more vulnerable to forensic recovery than the transient plaintext it protects (see data remanence).

As traditionally used, one-time pads provide no message authentication, the lack of which can pose a security threat in real-world systems. For example, an attacker who knows that the message contains "meet jane and me tomorrow at three thirty pm" can derive the corresponding codes of the pad directly from the two known elements (the encrypted text and the known plaintext). The attacker can then replace that text by any other text of exactly the same length, such as "three thirty meeting is canceled, stay home." The attacker's knowledge of the one-time pad is limited to this byte length, which must be maintained for any other content of the message to remain valid. This is a little different from malleability where it is not taken necessarily that the plaintext is known. "See also" stream cipher attack.

Standard techniques to prevent this, such as the use of a message authentication code can be used along with a one-time pad system to prevent such attacks, as can classical methods such as variable length padding and Russian copulation, but they all lack the perfect security the OTP itself has. Universal hashing provides a way to authenticate messages up to an arbitrary security bound (i.e., for any p>0, a large enough hash ensures that even a computationally unbounded attacker's likelihood of successful forgery is less than p), but this uses additional random data from the pad, and removes the possibility of implementing the system without a computer.

Despite its problems, the one-time-pad retains some practical interest. In some hypothetical espionage situations, the one-time pad might be useful because it can be computed by hand with only pencil and paper. Indeed, nearly all other high quality ciphers are entirely impractical without computers. Spies can receive their pads in person from their "handlers." In the modern world, however, computers (such as those embedded in personal electronic devices such as mobile phones) are so ubiquitous that possessing a computer suitable for performing conventional encryption (for example, a phone that can run concealed cryptographic software) will usually not attract suspicion.


One-time pads have been used in special circumstances since the early 1900s. In 1923, it was employed for diplomatic communications by the German diplomatic establishment. The Weimar Republic Diplomatic Service began using the method in about 1920. The breaking of poor Soviet cryptography by the British, with messages made public for political reasons in two instances in the 1920s (ARCOS case), appear to have induced the U.S.S.R. to adopt one-time pads for some purposes by around 1930. KGB spies are also known to have used pencil and paper one-time pads more recently. Examples include Colonel Rudolf Abel, who was arrested and convicted in New York City in the 1950s, and the 'Krogers' (i.e., Morris and Lona Cohen), who were arrested and convicted of espionage in the United Kingdom in the early 1960s. Both were found with physical one-time pads in their possession.

A number of nations have used one-time pad systems for their sensitive traffic. Leo Marks reports that the British Special Operations Executive used one-time pads in World War II to encode traffic between its offices. One-time pads for use with its overseas agents were introduced late in the war. A few British one-time tape cipher machines include the Rockex and Noreen. The German Stasi Sprach Machine was also capable of using one time tape that East Germany, Russia, and even Cuba used to send encrypted messages to their agents.

The World War II voice scrambler SIGSALY was also a form of one-time system. It added noise to the signal at one end and removed it at the other end. The noise was distributed to the channel ends in the form of large shellac records that were manufactured in unique pairs. There were both starting synchronization and longer-term phase drift problems that arose and were solved before the system could be used.

The hotline between Moscow and Washington D.C., established in 1963 after the Cuban missile crisis, used teleprinters protected by a commercial one-time tape system. Each country prepared the keying tapes used to encode its messages and delivered them via their embassy in the other country. A unique advantage of the OTP in this case was that neither country had to reveal more sensitive encryption methods to the other.

U.S. Army Special Forces used one-time pads in Vietnam. By using Morse code with one-time pads and continuous wave radio transmission (the carrier for Morse code), they achieved both secrecy and reliable communications.

During the 1983 Invasion of Grenada, U.S. forces found a supply of pairs of one-time pad books in a Cuban warehouse.

Starting in 1988, the African National Congress (ANC) used disk-based one-time pads as part of a secure communication system between ANC leaders outside South Africa and in-country operatives as part of Operation Vula, a successful effort to build a resistance network inside South Africa. Random numbers on the disk were erased after use. A Belgian airline stewardess acted as courier to bring in the pad disks. A regular resupply of new disks was needed as they were used up fairly quickly. One problem with the system was that it could not be used for secure data storage. Later Vula added a stream cipher keyed by book codes to solve this problem.

A related notion is the one-time code—a signal, used only once, e.g., "Alpha" for "mission completed", "Bravo" for "mission failed" or even "Torch" for "Allied invasion of French Northern Africa" cannot be "decrypted" in any reasonable sense of the word. Understanding the message will require additional information, often 'depth' of repetition, or some traffic analysis. However, such strategies (though often used by real operatives, and baseball coaches) are not a cryptographic one-time pad in any significant sense.

At least into the 1970s, the U.S. National Security Agency (NSA) produced a variety of manual one-time pads, both general purpose and specialized, with 86,000 one-time pads produced in fiscal year 1972. Special purpose pads were produced for what NSA called "pro forma" systems, where “the basic framework, form or format of every message text is identical or nearly so; the same kind of information, message after message. is to be presented in the same order, and only specific values, like numbers, change with each message.” Examples included nuclear launch messages and radio direction finding reports (COMUS).

General purpose pads were produced in several formats, a simple list of random letters (DIANA) or just numbers (CALYPSO), tiny pads for covert agents (MICKEY MOUSE), and pads designed for more rapid encoding of short messages, at the cost of lower density. One example, ORION, had 50 rows of plaintext alphabets on one side and the corresponding random cipher text letters on the other side. By placing a sheet on top of a piece of carbon paper with the carbon face up, one could circle one letter in each row on one side and the corresponding letter one the other side would be circled by the carbon paper. Thus one ORION sheet could quickly encode or decode a message up to 50 characters long. Production of ORION pads required printing both sides in exact registration, a difficult process, so NSA switched to another pad format, MEDEA, with 25 rows of paired alphabets and random characters. ("See" for illustrations.)
The NSA also built automated systems for the “centralized headquarters of CIA and Special Forces units so that they can efficiently process the many separate one-time pad messages to and from individual pad holders in the field.”

During World War II and into the 1950s, the U.S. made extensive use of one-time tape systems. In addition to providing confidentiality, circuits secured by one-time tape ran continually, even when there was no traffic, thus protecting against traffic analysis. In 1955, NSA produced some 1,660,000 rolls of one time tape. Each roll was 8 inches in diameter, contained 100,000 characters, lasted 166 minutes and cost $4.55 to produce. By 1972, only 55,000 rolls were produced, as one-time tapes were replaced by rotor machines such as SIGTOT, and later by electronic devices based on shift registers. The NSA describes one-time tape systems like 5-UCO and SIGTOT as being used for intelligence traffic until the introduction of the electronic cipher based KW-26 in 1957.

While one-time pads provide perfect secrecy if generated and used properly, small mistakes can lead to successful cryptanalysis:



</doc>
<doc id="22211" url="https://en.wikipedia.org/wiki?curid=22211" title="Oelde">
Oelde

Oelde () is a town in the district of Warendorf, in North Rhine-Westphalia, Germany. It is located near Beckum.

Oelde consists of 5 districts:


Oelde is twinned with:

Records from the 9th century show that there was a settlement named "Ulidi" on the site, although Oelde only received township in the year 1800. In the 14th century, a castle was built in Oelde.

Oelde is a centre of metal and lumber production, publishing, and also higher education through its nursing college.
It is also home to the headquarters of GEA ( Westfalia Separator), a manufacturer of centrifuges and dairy machines.

Oelde is connected to the Bundesautobahn 2.

The Hamm–Minden railway connects Oelde station to the German rail network. The line is served by the Rhein-Weser-Express and the Ems-Börde-Bahn every hour.



</doc>
<doc id="22213" url="https://en.wikipedia.org/wiki?curid=22213" title="Operator (mathematics)">
Operator (mathematics)

In mathematics, an operator is generally a mapping that acts on the elements of a space to produce other elements of the same space. The most common operators are linear maps, which act on vector spaces. However, when using "linear operator" instead of "linear map", mathematicians often mean actions on vector spaces of functions, which also preserve other properties, such as continuity. For example, differentiation and indefinite integration are linear operators; operators that are built from them are called differential operators, integral operators or integro-differential operators.

Operator is also used for denoting the symbol of a mathematical operation. This is related with the meaning of "operator" in computer programming, see operator (computer programming).

The most common kind of operator encountered are "linear operators". Let "U" and "V" be vector spaces over a field "K". A mapping "A": "U" → "V" is linear if
for all x, y in "U" and for all "α, β" in "K". 
This means that a linear operator preserves vector space operations, in the sense that it does not matter whether you apply the linear operator before or after the operations of addition and scalar multiplication. In more technical words, linear operators are morphisms between vector spaces.

In finite-dimensional case linear operators can be represented by matrices in the following way. Let formula_2 be a field, and formula_3 and formula_4 be finite-dimensional vector spaces over formula_2. Let us select a basis formula_6 in formula_3 and formula_8 in formula_4. Then let formula_10 be an arbitrary vector in formula_3 (assuming Einstein convention), and formula_12 be a linear operator. Then
Then formula_14 is the matrix of the operator formula_15 in fixed bases. formula_16 does not depend on the choice of formula_17, and formula_18 iff formula_19. Thus in fixed bases n-by-m matrices are in bijective correspondence to linear operators from formula_3 to formula_4.

The important concepts directly related to operators between finite-dimensional vector spaces are the ones of rank, determinant, inverse operator, and eigenspace.

Linear operators also play a great role in the infinite-dimensional case. The concepts of rank and determinant cannot be extended to infinite-dimensional matrices. This is why very different techniques are employed when studying linear operators (and operators in general) in the infinite-dimensional case. The study of linear operators in the infinite-dimensional case is known as functional analysis (so called because various classes of functions form interesting examples of infinite-dimensional vector spaces).

The space of sequences of real numbers, or more generally sequences of vectors in any vector space, themselves form an infinite-dimensional vector space. The most important cases are sequences of real or complex numbers, and these spaces, together with linear subspaces, are known as sequence spaces. Operators on these spaces are known as sequence transformations.

Bounded linear operators over Banach space form a Banach algebra in respect to the standard operator norm. The theory of Banach algebras develops a very general concept of spectra that elegantly generalizes the theory of eigenspaces.

Let "U" and "V" be two vector spaces over the same ordered field (for example, formula_22), and they are equipped with norms. Then a linear operator from "U" to "V" is called bounded if there exists "C > 0" such that
for all x in "U".

Bounded operators form a vector space. On this vector space we can introduce a norm that is compatible with the norms of "U" and "V":

In case of operators from "U" to itself it can be shown that

Any unital normed algebra with this property is called a Banach algebra. It is possible to generalize spectral theory to such algebras. C*-algebras, which are Banach algebras with some additional structure, play an important role in quantum mechanics.

In geometry, additional structures on vector spaces are sometimes studied. Operators that map such vector spaces to themselves bijectively are very useful in these studies, they naturally form groups by composition.

For example, bijective operators preserving the structure of a vector space are precisely the invertible linear operators. They form the general linear group under composition. They "do not" form a vector space under the addition of operators, e.g. both "id" and "-id" are invertible (bijective), but their sum, 0, is not.

Operators preserving the Euclidean metric on such a space form the isometry group, and those that fix the origin form a subgroup known as the orthogonal group. Operators in the orthogonal group that also preserve the orientation of vector tuples form the special orthogonal group, or the group of rotations.

Operators are also involved in probability theory, such as expectation, variance, and covariance.

From the point of view of functional analysis, calculus is the study of two linear operators: the differential operator formula_26, and the indefinite integral operator formula_27.

The Fourier transform is useful in applied mathematics, particularly physics and signal processing. It is another integral operator; it is useful mainly because it converts a function on one (temporal) domain to a function on another (frequency) domain, in a way effectively invertible. No information is lost, as there is an inverse transform operator. In the simple case of periodic functions, this result is based on the theorem that any continuous periodic function can be represented as the sum of a series of sine waves and cosine waves:
The tuple "(a, a, b, a, b, ...)" is in fact an element of an infinite-dimensional vector space ℓ, and thus Fourier series is a linear operator.

When dealing with general function R → C, the transform takes on an integral form:

The "Laplace transform" is another integral operator and is involved in simplifying the process of solving differential equations.

Given "f" = "f"("s"), it is defined by:

Three operators are key to vector calculus:

As an extension of vector calculus operators to physics, engineering and tensor spaces, Grad, Div and Curl operators also are often associated with Tensor calculus as well as vector calculus.



</doc>
<doc id="22216" url="https://en.wikipedia.org/wiki?curid=22216" title="O Brother, Where Art Thou?">
O Brother, Where Art Thou?

O Brother, Where Art Thou? is a 2000 crime comedy film written, produced, and directed by Joel and Ethan Coen, and starring George Clooney, John Turturro, and Tim Blake Nelson, with John Goodman, Holly Hunter, and Charles Durning in supporting roles.

The film's story is a modern satire loosely based on Homer's epic poem "The Odyssey" that incorporates mythology from the American South. The title of the film is a reference to the 1941 film "Sullivan's Travels", in which the protagonist is a director who wants to film "O Brother, Where Art Thou?", a fictional book about the 1930s Great Depression.

Much of the music used in the film is period folk music, including that of Virginia bluegrass singer Ralph Stanley. The movie was one of the first to extensively use digital color correction to give the film an autumnal, sepia-tinted look. The film received positive reviews, and the soundtrack won a Grammy Award for Album of the Year in 2001 using American folk music. The original band became popular after the film release. The country and folk musicians who were dubbed into the film included John Hartford, Alison Krauss, Emmylou Harris, Gillian Welch, Chris Sharp, and others. They joined together to perform the music from the film in a "Down from the Mountain" concert tour which was filmed for TV and DVD.

Set in 1937 rural Mississippi during the Great Depression, three convicts, Ulysses Everett McGill, Pete Hogwallop, and Delmar O'Donnell, escape from a chain gang and set out to retrieve a supposed treasure Everett buried before the area is flooded to make a lake. The three get a lift from a blind man driving a handcar on a railway. He tells them, among other prophecies, that they will find a fortune but not the one they seek. The trio make their way to the house of Wash, Pete's cousin. They sleep in the barn, but Wash reports them to Sheriff Cooley, who, along with his men, torches the barn. Wash's son helps them escape.

Pete and Delmar are baptized by a group of Christians at a river. The group then picks up Tommy Johnson, a young black man, who claims he sold his soul to the devil in exchange for the ability to play guitar. In need of money, the four stop at a radio broadcast tower where they record a song as The Soggy Bottom Boys. That night, the trio part ways with Tommy after their car is discovered by the police. Unbeknownst to them, the recording becomes a major hit.

The trio inadvertently fall in with bank robber Baby Face Nelson, and help him with a heist, before he leaves them with his share of the loot. The next day, the group hears singing. They see three women washing clothes in a river and singing. The women drug them with corn whiskey and they lose consciousness. Upon waking, Delmar finds Pete's clothes lying next to him, empty except for a toad. Delmar is convinced the women were Sirens and transformed Pete into the toad. Later, one-eyed Bible salesman Big Dan Teague invites them for a picnic lunch, then mugs them and kills the toad.

Everett and Delmar arrive in Everett's home town. Everett confronts his wife Penny, who changed her last name and told his daughters he was dead. He gets into a fight with Vernon T. Waldrip, her new "suitor." They later see Pete working on a chain gang. Later that night, they sneak into Pete's holding cell and free him. As it turns out, the women had dragged Pete away and turned him in to the authorities. Under torture, Pete gave away the treasure's location to the police. Everett then confesses that there is no treasure. He made it up to convince the guys he was chained with to escape with him in order to stop his wife from getting married. Pete is enraged at Everett, because he had two weeks left on his original sentence, and must serve fifty more years for the escape.

The trio stumble upon a rally of the Ku Klux Klan, who are planning to hang Tommy. The trio disguise themselves as Klansmen and attempt to rescue Tommy. However, Big Dan, now a Klan member, reveals their identities. Chaos ensues, and the Grand Wizard reveals himself as Homer Stokes, a candidate in the upcoming gubernatorial election. The trio rush Tommy away and cut the supports of a large burning cross, leaving it to collapse on top of Big Dan, killing him.

Everett convinces Pete, Delmar and Tommy to help him win his wife back. They sneak into a Stokes campaign gala dinner she is attending, disguised as musicians. The group begins a performance of their radio hit. The crowd recognizes the song and goes wild. Homer recognizes them as the group who humiliated his mob. When he demands the group be arrested and reveals his white supremacist views, the crowd runs him out of town on a rail. Pappy O'Daniel, the incumbent candidate, seizes the opportunity, endorses the Soggy Bottom Boys and grants them full pardons. Penny agrees to re-marry Everett with the condition that he find her original wedding ring.

The next morning, the group sets out to retrieve the ring, which is at a cabin in the valley which Everett had earlier claimed was the location of his treasure. The police, having learned of the place from Pete, arrest the group. Dismissing their claims of having received pardons, Sheriff Cooley orders them hanged. Just as Everett prays to God, begging to reunite with his daughters, the valley is flooded and they are saved. Tommy finds the ring in a rolltop desk that floats by, and they return to town. However, when Everett presents the ring to Penny, it turns out it was not her ring, she doesn't want that one, and she can't remember where she put the real ring.


The idea of "O Brother, Where Art Thou?" arose spontaneously. Work on the script began in December 1997, long before the start of production, and was at least half-written by May 1998. Despite the fact that Ethan Coen described the "Odyssey" as "one of my favorite storyline schemes," neither of the brothers had read the epic and were only familiar with its content through adaptations and numerous references to the "Odyssey" in popular culture. According to the brothers, Nelson (who has a degree in classics from Brown University) was the only person on the set who had read the "Odyssey".

The title of the film is a reference to the 1941 Preston Sturges film "Sullivan's Travels", in which the protagonist (a director) wants to direct a film about the Great Depression called "O Brother, Where Art Thou?" that will be a "commentary on modern conditions, stark realism, and the problems that confront the average man." Lacking any experience in this area, the director sets out on a journey to experience the human suffering of the average man but is sabotaged by his anxious studio. The film has some similarity in tone to Sturges's film, including scenes with prison gangs and a black church choir. The prisoners at the picture show scene is also a direct homage to a nearly identical scene in Sturges's film.

Joel Coen revealed in a 2000 interview that he came to Phoenix, Arizona, to offer the lead role to Clooney. Clooney agreed to do the role immediately, without reading the script. He stated that he liked even the Coens' least successful films. Clooney did not immediately understand his character and sent the script to his uncle Jack who lived in Kentucky and asked him to read the entire script into a tape recorder. Unknown to Clooney, in his recording, Jack, a devout Baptist, omitted all instances of the words "damn" and "hell" from the Coens' script, which only became known to Clooney after the directors pointed this out to him in the middle of shooting.

This was the fourth film of the brothers in which John Turturro has starred. Other actors in "O Brother, Where Art Thou?" who had worked previously with the Coens include John Goodman (three films), Holly Hunter (two), Michael Badalucco and Charles Durning (one film each).

The Coens used digital color correction to give the film a sepia-tinted look. Joel stated this was because the actual set was "greener than Ireland." Cinematographer Roger Deakins stated, "Ethan and Joel favored a dry, dusty Delta look with golden sunsets. They wanted it to look like an old hand-tinted picture, with the intensity of colors dictated by the scene and natural skin tones that were all shades of the rainbow." Initially the crew tried to perform the color correction using a physical process, however after several tries with various chemical processes proved unsatisfactory, it became necessary to perform the process digitally.

This was the fifth film collaboration between the Coen Brothers and Deakins, and it was slated to be shot in Mississippi at a time of year when the foliage, grass, trees, and bushes would be a lush green. It was filmed near locations in Canton, Mississippi and Florence, South Carolina in the summer of 1999. After shooting tests, including film bipack and bleach bypass techniques, Deakins suggested digital mastering be used. Deakins subsequently spent 11 weeks fine-tuning the look, mainly targeting the greens, making them a burnt yellow and desaturating the overall image in the digital files. This made it the first feature film to be entirely color corrected by digital means, narrowly beating Nick Park's "Chicken Run".

"O Brother, Where Art Thou?" was the first time a digital intermediate was used on the entirety of a first-run Hollywood film that otherwise had very few visual effects. The work was done in Los Angeles by Cinesite using a Spirit DataCine for scanning at 2K resolution, a Pandora MegaDef to adjust the color, and a Kodak Lightning II recorder to put out to film.

A major theme of the film is the connection between old-time music and political campaigning in the Southern U.S. It makes reference to the traditions, institutions, and campaign practices of bossism and political reform that defined Southern politics in the first half of the 20th century.

The Ku Klux Klan, at the time a political force of white populism, is depicted burning crosses and engaging in ceremonial dance. The character Menelaus "Pappy" O'Daniel, the governor of Mississippi and host of the radio show "The Flour Hour", is similar in name and demeanor to W. Lee "Pappy" O'Daniel, one-time Governor of Texas and later U.S. Senator from that state. W. Lee O'Daniel was in the flour business, and used a backing band called the Light Crust Doughboys on his radio show. In one campaign, W. Lee O'Daniel carried a broom, an oft-used campaign device in the reform era, promising to sweep away patronage and corruption. His theme song had the hook, "Please pass the biscuits, Pappy", emphasizing his connection with flour.

While the film borrows from real-life politics, differences are obvious between the characters in the film and historical political figures. The O'Daniel of the movie used "You Are My Sunshine" as his theme song (which was originally recorded by real-life Governor of Louisiana James Houston "Jimmie" Davis) and Homer Stokes, as the challenger to the incumbent O'Daniel, portrays himself as the "reform candidate", using a broom as a prop.

Music in the film was originally conceived as a major component of the film, not merely as a background or a support. Producer and musician T-Bone Burnett worked with the Coens while the script was still in its working phases, and the soundtrack was recorded before filming commenced.

Much of the music used in the film is period-specific folk music, including that of Virginia bluegrass singer Ralph Stanley. The musical selection also includes religious music, including Primitive Baptist and traditional African American gospel, most notably The Fairfield Four, an "a cappella" quartet with a career extending back to 1921 who appear in the soundtrack and as gravediggers towards the film's end. Selected songs in the film reflect the possible spectrum of musical styles typical of the old culture of the American South: gospel, delta blues, country, swing and bluegrass.

The use of dirges and other macabre songs is a theme that often recurs in Appalachian music ("O Death", "Lonesome Valley", "Angel Band", "I Am Weary") in contrast to bright, cheerful songs ("Keep On the Sunny Side", "In the Highways") in other parts of the film.

The voices of the Soggy Bottom Boys were provided by Dan Tyminski (lead vocal on "Man of Constant Sorrow"), Nashville songwriter Harley Allen, and the Nashville Bluegrass Band's Pat Enright. The three won a CMA Award for Single of the Year and a Grammy Award for Best Country Collaboration with Vocals, both for the song "Man of Constant Sorrow". Tim Blake Nelson sang the lead vocal on "In the Jailhouse Now".

"Man of Constant Sorrow" has five variations: two are used in the film, one in the music video, and two in the soundtrack album. Two of the variations feature the verses being sung back-to-back, and the other three variations feature additional music between each verse. Though the song received little significant radio airplay, it reached #35 on the U.S. "Billboard" Hot Country Singles & Tracks chart in 2002. The version of "I'll Fly Away" heard in the film is performed not by Krauss and Welch (as it is on the CD and concert tour), but by the Kossoy Sisters with Erik Darling accompanying on long-neck five-string banjo, recorded in 1956 for the album "Bowling Green" on Tradition Records.

The film premiered at the AFI Film Festival on October 19, 2000. It grossed $71,868,327 worldwide off its $26 million budget.

Review aggregation website Rotten Tomatoes gives it a score of 77% based on 147 reviews and an average score of 7.1/10. The consensus reads: "Though not as good as Coen brothers' classics such as "Blood Simple", the delightfully loopy "O Brother, Where Art Thou?" is still a lot of fun." The film holds an average score of 69/100 on Metacritic based on 30 reviews.

Roger Ebert gave two and a half out of four stars to the film, saying all the scenes in the film were "wonderful in their different ways, and yet I left the movie uncertain and unsatisfied".

The film was selected into the main competition of the 2000 Cannes Film Festival.

The film also received two Academy Award nominations at the 73rd Academy Awards: Best Adapted Screenplay and Best Cinematography. Cinematographer Roger Deakins was recognized with both Academy Award and ASC Outstanding Achievement Award nominations for his work on the film.

For his portrayal of Ulysses Everett McGill, George Clooney received the Golden Globe Award for Best Actor – Motion Picture Musical or Comedy. The film was also nominated for the Golden Globe Award for Best Motion Picture – Musical or Comedy.

The Soggy Bottom Boys is the musical group that the main characters form to serve as accompaniment for the film. The name is in homage to the Foggy Mountain Boys, a bluegrass band led by Lester Flatt and Earl Scruggs. In the film, the songs credited to the band are lip-synched by the actors, except that Tim Blake Nelson does sing his own vocals on "In the Jailhouse Now." The band's hit single is Dick Burnett's "Man of Constant Sorrow," a song that had enjoyed much success prior to the movie's release. After the film's release, the fictitious band became so popular that the country and folk musicians who were dubbed into the film got together and performed the music from the film in a Down from the Mountain concert tour which was filmed for TV and DVD. This included Ralph Stanley, John Hartford, Alison Krauss, Emmylou Harris, Gillian Welch, Chris Sharp, and others.



</doc>
<doc id="22217" url="https://en.wikipedia.org/wiki?curid=22217" title="Ohio State University">
Ohio State University

The Ohio State University, commonly referred to as Ohio State or OSU, is a large, primarily residential, public university in Columbus, Ohio. Founded in 1870 as a land-grant university and the ninth university in Ohio with the Morrill Act of 1862, the university was originally known as the Ohio Agricultural and Mechanical College (Mech). The college began with a focus on training students in various agricultural and mechanical disciplines but it developed into a comprehensive university under the direction of then Governor (later, President) Rutherford B. Hayes, and in 1878 the Ohio General Assembly passed a law changing the name to "The Ohio State University". It has since grown into the third-largest university campus in the United States. Along with its main campus in Columbus, Ohio State also operates regional campuses in Lima, Mansfield, Marion, Newark, and Wooster.

The university has an extensive student life program, with over 1,000 student organizations; intercollegiate, club and recreational sports programs; student media organizations and publications, fraternities and sororities; and three student governments. Ohio State athletic teams compete in Division I (Football Bowl Subdivision for football) of the NCAA and are known as the Ohio State Buckeyes. Athletes from Ohio State have won 100 Olympic medals (44 gold, 35 silver, and 21 bronze). The university is a member of the Big Ten Conference for the majority of sports. The Ohio State men's ice hockey program competes in the Big Ten Conference, while its women's hockey program competes in the Western Collegiate Hockey Association. In addition, the OSU men's volleyball team is a member of the Midwestern Intercollegiate Volleyball Association (MIVA). OSU is one of only 14 universities that plays Division I FBS football and Division I ice hockey.

As of August 2017, the university had awarded a total of 747,216 degrees. Alumni and former students have gone on to prominent careers in government, business, science, medicine, education, sports, and entertainment.

The proposal of a manufacturing and agriculture university in central Ohio was initially met in the 1870s with hostility from the state's agricultural interests and competition for resources from Ohio University, which was chartered by the Northwest Ordinance, and Miami University. Championed by the Republican stalwart Governor Rutherford B. Hayes, the Ohio State University was founded in 1870 as a land-grant university under the Morrill Act of 1862 as the Ohio Agricultural and Mechanical College. The school was originally within a farming community on the northern edge of Columbus. While some interests in the state had hoped the new university would focus on matriculating students of various agricultural and mechanical disciplines, Hayes manipulated both the university's location and its initial board of trustees towards a more comprehensive end. The university opened its doors to 24 students on September 17, 1873. In 1878, the first class of six men graduated. The first woman graduated the following year. Also in 1878, in light of its expanded focus, the Ohio legislature changed the name to "The Ohio State University", with "The" as part of its official name.

Ohio State began accepting graduate students in the 1880s, and in 1891, the school saw the founding of its law school, Moritz College of Law. It would later acquire colleges of medicine, dentistry, optometry, veterinary medicine, commerce, and journalism in subsequent years. In 1916, Ohio State was elected into membership in the Association of American Universities.

Michael V. Drake, former chancellor of the University of California, Irvine, became the 15th president of The Ohio State University on June 30, 2014.

Ohio State's main campus is about north of the city's downtown. The historical center of campus is the Oval, a quad of about . Four buildings are listed on the National Register of Historic Places: Hale Hall (originally Enarson Hall), Hayes Hall, Ohio Stadium, and Orton Hall.
Unlike earlier public universities such as Ohio University and Miami University, whose campuses have a consistent architectural style, the Ohio State campus is a mix of traditional, modern and post-modern styles.
The William Oxley Thompson Memorial Library, anchoring the Oval's western end, is Ohio State library's main branch and largest repository. The Thompson Library was designed in 1913 by the Boston firm of Allen and Collens in the Italianate Renaissance Revival style, and its placement on the Oval was suggested by the Olmsted brothers who had designed New York City's Central Park. In 2006, the Thompson Library began a $100 million renovation to maintain the building's classical Italian Renaissance architecture.

Ohio State operates the North America's 18th-largest university research library with a combined collection of over 5.8 million volumes. Additionally, the libraries regularly receive about 35,000 serial titles. Its recent acquisitions were 16th among university research libraries in North America. Along with 21 libraries on its Columbus campus, the university has eight branches at off-campus research facilities and regional campuses, and a book storage depository near campus. In all, the Ohio State library system encompasses 55 branches and specialty collections. Some more significant collections include The Byrd Polar Research Center Archival Program, which has the archives of Admiral Richard E. Byrd and other polar research materials; The Hilandar Research Library, which has the world's largest collection of medieval Slavic manuscripts on microform; the Ohio State Cartoon Library & Museum, the world's largest repository of original cartoons; The Lawrence and Lee Theatre Research Institute; and the archives of Senator John Glenn.

Anchoring the traditional campus gateway at the eastern end of the Oval is the 1989 Wexner Center for the Arts. Designed by architects Peter Eisenman of New York and Richard Trott of Columbus, the center was funded in large part by Ohio State alumnus Leslie Wexner's gift of $25 million in the 1980s. The center was founded to encompass all aspects of visual and performing arts with a focus on new commissions and artist residencies. Part of its design was to pay tribute to the armory that formerly had the same location. Its groundbreaking deconstructivist architecture has resulted in it being lauded as one of the most important buildings of its generation. Its design has also been criticized as proving less than ideal for many of the art installations it has attempted to display. The centerpiece of The Wexner Center's permanent collection is Picasso's "Nude on a Black Armchair", which was purchased by alumnus Leslie Wexner at auction for $45 million.

To the south of the Oval is another, somewhat smaller, expanse of green space commonly referred to as the South Oval. At its eastern end, it is anchored by the Ohio Union. To the west are Hale Hall, the Kuhn Honors House, Browning Amphitheatre (a traditional stone Greek theatre) and Mirror Lake.

Knowlton Hall, dedicated in October 2004, is at the corner of West Woodruff Avenue and Tuttle Park Place, next to Ohio Stadium. Knowlton Hall along with the Fisher College of Business and Hitchcock Hall form an academic nucleus in the Northwestern corner of North campus. Knowlton Hall is home to the KSA Café, the disciplines of Architecture, Landscape Architecture, City and Regional Planning, and about 550 undergraduate and graduate students. Knowlton Hall stands out from the general reddish-brown brick of Ohio State's campus with distinctive white marble tiles that cover the building's exterior. This unique wall cladding was requested by Austin E. Knowlton, the namesake of and main patron to the creation of Knowlton Hall. Knowlton also requested 5 white marble columns be erected on the site, each column representing one of the classical orders of Architecture.

The Ohio State College of Medicine is on the southern edge of the central campus. It is home to the James Cancer Hospital, a cancer research institute and one of the National Cancer Institute's forty-one comprehensive cancer centers, along with the Richard M. Ross Heart Hospital, a research institute for cardiovascular disease.

In 1916, Ohio State became the first university in Ohio to be extended membership into the Association of American Universities, and remains the only public university in Ohio among the organization's 60 members. "The Public Ivies: America's Flagship Public Universities" (2000) by Howard and Matthew Greene listed Ohio State as one of a select number of public universities offering the highest educational quality.

In its 2016 edition, "U.S. News & World Report" ranked Ohio State as tied for the 16th-best public university in the United States, and tied for 52nd among all national universities.

The "Academic Ranking of World Universities" placed Ohio State 42nd nationally and 79th globally for 2016. In its 2015-16 rankings, "Times Higher Education World University Rankings" ranked it tied for 90th in the world. In 2016, "QS World University Rankings" ranked the university 88th in the world.

The Lombardi Program on Measuring University Performance at Arizona State University detailed analysis and rankings of American universities in 2007 placed Ohio State as the 24th ranked university in America, the 10th ranked public university in the country and the top overall university in Ohio. Of its nine ranking criteria, Ohio State ranked in the top-25 in four categories and between 26–50 in an additional four categories. The "Washington Monthly" college rankings, which seek to evaluate colleges' contributions to American society based on factors of social mobility, research, and service to the country by their graduates, in 2016 placed Ohio State 69th in the nation.

Ohio State is also the only public university in Ohio to which the Carnegie Foundation for the Advancement of Teaching has given both its highest overall classification of "R1: Doctoral Universities – Highest Research Activity" and highest undergraduate admissions classification of "more selective".

"Bloomberg Businessweek" ranked the undergraduate business program at Ohio State's Fisher College of Business as the 14th best in the nation in its 2016 rankings. "U.S. News & World Report" ranks the MBA program tied for 30th in America. Fisher's Executive MBA program was ranked 3rd nationally for return on investment by The Wall Street Journal in 2008 citing a 170 percent return on an average of $66,900 invested in tuition and expenses during the 18-month program.

The Ohio State law school is ranked by "U.S. News & World Report" tied for 34th overall in America for 2016, with the nursing school tied for 22nd, public affairs tied for 25th, and the medical school ranked tied for 31st for research and tied for 40th for primary care; the graduate engineering program was ranked 32nd best and the College of Education ranked 15th in America. Nineteen Ohio State graduate programs or specialties were rated among the nation's top ten for 2016.

The Ohio State political science department is ranked 15th in the country by "U.S. News & World Report" for 2016, with the international politics section 8th, American politics 10th, and political methodology 10th. Professor Alexander Wendt was ranked the most influential scholar of international relations in the world in a 2011 survey of American professors of international relations. The history department was recently ranked 18th in the nation (6th among public universities) by the National Research Council. The Ohio State linguistics department was recently ranked among the top 10 programs nationally, and top 20 internationally by "QS World University Rankings".

Ohio State is one of a select few American universities to offer multiple area studies programs under "Comprehensive National Resource Center" (often called "Title VI") funding from the U.S. Department of Education. The most notable of these is the Center for Slavic and East European Studies founded in 1965 by Professor Leon Twarog. Subsequently, Ohio State's Middle Eastern Studies Center and East Asian Studies Center also achieved Comprehensive National Resource Center status. The university is also home to the interdisciplinary Mershon Center for International Security Studies, which was founded in 1952 through a bequest of 7 million dollars (54.3 million in 2006 value) from alumnus Colonel Ralph D. Mershon. In 2003, the United States Department of Homeland Security decided to base the National Academic Consortium for Homeland Security at The Mershon Center.

"U.S. News & World Report" ranked the graduate program in interior design 2nd in the nation for 2016. Overall, "U.S. News & World Report" ranked the graduate art program 18th, with the ceramics program at 4th. In its 2008 edition of "America's Best Architecture & Design Schools, the journal "DesignIntelligence" ranked the undergraduate Industrial Design program #3 nationwide, and the graduate program in Design #10 nationwide. The DFC conducted their research by polling 270 corporations regarding how design schools were preparing their students for the future of professional practice in design. OSU was in the top ten rankings of the corporate leaders' assessments in all regions (#4 in the south, #2 in the midwest, #7 in the east, and #4 in the west). The graduate program placed at #3 in the south and #2 in the east, resulting in 10th overall in the nation.

In a 2007 report released by the National Science Foundation, Ohio State's research expenditures for 2006 were $652 million, placing it 7th among public universities and 11th overall, also ranking 3rd among all American universities for private industry sponsored research. Research expenditures at Ohio State were $720 million in 2007. In 2006, Ohio State announced it would designate at least $110 million of its research efforts to what it termed "fundamental concerns" such as research towards a cure for cancer, renewable energy sources and sustainable drinking water supplies.

Research facilities include Aeronautical/Astronautical Research Laboratory, Byrd Polar Research Center, Center for Automotive Research (OSU CAR), Chadwick Arboretum, Biomedical Research Tower, Biological Sciences Building, Comprehensive Cancer Center, David Heart and Lung Research Institute, Electroscience Laboratory, Large Binocular Telescope (LBT, originally named the Columbus Project), Mershon Center for International Security Studies, Museum of Biological Diversity, National Center for the Middle Market, Stone Laboratory on Gibraltar Island, OH, Center for Urban and Regional Analysis and Ohio Agricultural Research and Development Center.

Ohio State is a participant in the Big Ten Academic Alliance. The Big Ten Academic Alliance (BTAA) is the academic consortium of the universities in the Big Ten Conference. Engaging in $10 billion in research in 2014-2015, BTAA universities provide powerful insight into important issues in medicine, technology, agriculture, and communities. Students at participating schools are also allowed "in-house" borrowing privileges at other schools' libraries. The BTAA uses collective purchasing and licensing, and has saved member institutions $19 million to date. Course sharing, professional development programs, study abroad and international collaborations, and other initiatives are also part of the BTAA.

Undergraduate admissions to Ohio State are classified as "more selective" by "U.S. News & World Report" and "The Princeton Review" and according to the data are the most selective for any public university in Ohio. 67% of incoming freshmen in autumn 2017 were ranked in the top 10% of their high school class. The middle 50% range of ACT scores is 28-32, while the middle 50% SAT scores (Critical Reading and Math only) is 1310–1430. Ohio State's freshman class has included at least 100 National Merit Scholars for nine of the last ten years.

Tuition and fees for full-time, Ohio residents enrolled at the Columbus campus for the 2014–2015 academic year were $10,037. For the 2006–2007 academic year, tuition at Ohio State for Ohio residents placed it as the fifth-most expensive public university and slightly beneath the weighted average tuition of $8,553 among Ohio's thirteen public four-year universities. In addition to being named a "Best in the Midwest" selection by "The Princeton Review", Ohio State was the only public university in Ohio to make their list of "America's 150 Best Value Colleges".

Ohio State was among the first group of four public universities to raise a $1 billion endowment when it passed the $1 billion mark in 1999. At year's end 2005, Ohio State's endowment stood at $1.73 billion, ranking it seventh among public universities and 27th among all American universities. In June 2006, the endowment passed the $2 billion mark.

In recent decades, and in response to continually shrinking state funding, Ohio State has conducted two significant multi-year fundraising campaigns. The first concluded in 1987 and raised $460 million—a record at the time for a public university. The "Affirm Thy Friendship Campaign" took place between 1995 and 2000. With an initial goal of raising $850 million, the campaign's final tally was $1.23 billion, placing Ohio State among the small group of public universities to have successfully conducted a $1 billion campaign. At his welcoming ceremony, returning President E. Gordon Gee announced, in the Fall of 2007, Ohio State would launch a $2.5 billion fund-raising campaign.

The Office of Student Life is responsible for many of the outside-the-classroom aspects of student life at Ohio State. It has more than 30 departments. Among these are student housing; dining services; health, wellness and counseling offices; the Ohio Union, student activities, organizations and leadership development; recreation and intramural sports. The Office of Student Life has partnership affiliations with the Schottenstein Center, the Blackwell Inn, and the Drake Events Center. Services supporting student wellness include the Wilce Student Health Center, named for university physician John Wilce, The Mary A. Daniels Student Wellness Center and the Counseling and Consultation Service and the Recreational and Physical Activity Center (RPAC).

The Office of Student Life also oversees the operation of the RPAC. The RPAC is the main recreational facility on campus and offers over half a million square feet of recreation, aquatic, fitness, and meeting space. The RPAC features two on-campus dining locations, a 50-meter competitive pool, 12 wood courts, 10 racquetball courts, 4 squash courts, a four-lane jogging/walking track, five multipurpose rooms, and 27,500 square feet of fitness space. is also inside of the RPAC. The Wellness Center within the RPAC offers services such as nutrition counseling, financial coaching, HIV and STI testing, sexual assault services, and alcohol and other drug education. The Outdoor Adventure Center (OAC) is another recreational facility on campus. The OAC features the Tom W. Davis Climbing Center with a 4,000-square-foot, 35-foot tall climbing structure and bouldering cave. The OAC also has an outdoor equipment rental office and a trip-planning resource center.
The marching band is also a longstanding tradition at Ohio State. It is the largest all-brass and percussion band in the world. The traditional school songs from "Carmen Ohio" to "Hang on Sloopy" to "Fight the Team Across the Field", are arranged to fit this instrumentation. The band is famous for "Script Ohio", during which the band marches single-file through the curves of the word "Ohio", much like a pen writes the word, all while playing the French march "Le Regiment de Sambre et Meuse." At the end of the performance, a high-stepping senior sousaphone player "dots" the "i" in Ohio.

"Across the Field", Ohio State's fight song, and "Buckeye Battle Cry" are commonly played and sung at athletic events, as well as commencement and convocation exercises.

The tradition of high-quality bands is not limited to the football field. OSU's School of Music contains several high-quality concert bands made up of graduate and undergraduate music majors and non-music majors. The OSU Wind Symphony often receives praise on the national level and was selected to perform at the 2003 College Band Directors National Association (CBDNA) Convention and at the Ohio Music Educators Association Conference in 2001, 2004, 2006, and 2008; the OSU Symphonic Band performed in 2007. The OSU Wind Symphony released its newest album, "Southern Harmony", on the Naxos Label in 2009. The Ohio State Jazz Ensemble performed at the Montreux Jazz Festival in 1975, 1978, 1986, 1996, and 2001. It also appeared at the Mexico City International Jazz Festival in 1990 and the North Sea Jazz Festival in 1986, 1996, and 2001. There is also an OSU Symphony Orchestra.

In addition to strong bands, the university is recognized for outstanding choral performance. The Ohio State University Men's Glee Club was formed in 1875. In 1990, led by Professor James Gallagher, the Men's Glee Club participated in the International Musical Eisteddfod in Llangollen, Wales, and won the male chorus competition by an unprecedented 20 points before, in a unanimous decision of the judges, being named "Choir of the World"—the first American choir to win such an honor. Robert J. Ward directs the Glee Club. The Ohio State Women's Glee Club was established in 1903. In the group's recent past, under the leadership of Dr. Hilary Apfelstadt, the Glee Club has been selected to sing for state and regional conferences of the Ohio Music Education Association and the American Choral Directors Association. Beginning its season under the direction of Dr. Richard Schnipke, the OSU Women's Glee Club was honored to sing for the Ohio Choral Directors Association annual conference in June 2010.

Ohio State's "Buckeye Bullet" electric car broke the world record for the fastest speed by an electric vehicle on October 3, 2004, with a speed of 271.737 mph (437.3 km/h) at the Bonneville Salt Flats in Utah. The vehicle also holds the U.S. record for fastest electric vehicle with a speed of 314.958 mph (506.9 km/h), and peak timed mile speed of 321.834 mph (517.9 km/h). A team of engineering students from the university's "Center for Automotive Research-Intelligent Transportation" (CAR-IT) designed, bult and managed the vehicle. In 2007, Buckeye Bullet 2 was launched. This follow-up effort was a collaboration between Ohio State engineering students and engineers from the Ford Motor Company and will seek to break the land speed record for hydrogen cell powered vehicles.

A unique aspect to Ohio State's multibillion-dollar endowment is the Student Investment Management Program. Upperclass finance students taking Business Finance 724 are given the opportunity to manage a twenty million dollar investment fund. Returns from the student-managed funds often outperform the S&P 500 and frequently even the university's own professional fund managers.

Jon Stewart hosted "The Daily Show's" "Battlefield Ohio: "The Daily Show"'s Midwest Midterm Midtacular" from Ohio State's Roy Bowen Theatre during the week of October 30 to November 2, 2006.In June 2018, The Ohio State dissolved its Sexual Civility and Empowerment unit and eliminated four positions in the unit due to concerns about mismanagement and a lack of support for survivors of sexual assault. This occurred after the unit was suspended in February 2018 and following an external review. "The Columbus Dispatch" and the school newspaper, "The Lantern" reported that "[SCE] failed to properly report students’ sexual-assault complaints" and that some victims were told that they were "'lying,' 'delusional,' 'suffering from mental illness,' 'have an active imagination,' that they 'didn’t understand their own experience' and also 'fabricated their story.'" With help from the Philadelphia law firm Cozen O'Connor, the university will be creating a new framework to handle sexual assault cases and reevaluating its Title IX program.On July 20, 2018, the Associated Press reported that over 100 students, including male athletes from 14 sports, had reported sexual misconduct against a deceased university team physician. The reports date back to 1978 and include claims that he groped and took nude photographs of his patients. The investigation is ongoing, and four former wrestlers have filed a lawsuit against Ohio State for ignoring complaints of "rampant sexual misconduct." U.S. Representative Jim Jordan has been named in the lawsuit and has since denied the former wrestlers' claims that he knew about the abuse while he was an assistant coach for eight years at the university.
Ohio State's main campus has been lauded for the racial diversity of its student body. In various surveys and rankings, it has been included among the best campuses in the nation for African Americans. Additionally, Ohio State ranked 10th in the nation in 2006 for the numbers of African American doctors graduated. "The Advocate College Guide for LGBT Students" lists Ohio State as one of the 20 best campuses in America for LGBT students. One campus feature that helps aid student diversity is the Multicultural Center.

Ohio State, despite selective admissions, has also maintained a high amount of socio-economic diversity among its students. The 2007 freshman class contained 22.7% of first-generation college students, which far exceeded the national norm on American campuses of 15.9%.

Ohio State operates 38 on-campus residence halls divided into three geographic clusters: South Campus (site of the university's original dormitories) (currently include joint dorms known as Smith-Steeb and Park-Stradley), North Campus (largely constructed during the post-war enrollment boom) and West Campus or "The Towers". The residence hall system has 40 smaller living and learning environments defined by social or academic considerations. Ohio State also offers three honors residence halls: Bradley Hall, Lincoln Tower, and Taylor Tower.

Separate housing for graduate and professional students is maintained on the Southern tier of campus within the Gateway Residential Complex and the William H. Hall Student Residential Complex. Family housing is maintained at Buckeye Village at the far northern edge of campus beyond the athletic complex.

Student Life University Housing also administers student residential housing on the OSU Newark, OSU Mansfield, and OSU Agricultural Technical Institute (ATI) campuses.

The Residence Hall Advisory Council (RHAC), which is a representative body of all students living in the University's residence halls, helps evaluate and improve the living conditions of the residence halls.

Ohio State offers two distinct honors programs for high ability undergraduates: Honors and Scholars. The Honors program is open to students in all majors. The Scholars program is centered on thirteen specific programs such as "Architecture Scholars", "Media, Marketing, and Communications Scholars", "Biological Sciences Scholars", "International Affairs Scholars", "Business Scholars" and "Politics, Society and Law Scholars." Students in the Scholars program are expected to live and take select classes with other members of the program. Additionally, Ohio State offers the Honors Collegium with membership extended to ten incoming freshmen and following the Spring of a student's first or second year to the university's top undergraduates. Collegium students try to compete for internships, graduate schools and nationally competitive awards, such as the Marshall, Rhodes, or Truman Scholarships.

Ohio State also administers two large-scale scholarship programs to ensure access to the university to high-ability students from low-income or traditionally underrepresented groups. The first, The Young Scholars Program, was initiated in 1988. 120 promising minority students from Ohio's nine largest urban public school districts are selected prior to entering high school. The program offers a series of academic camps each summer and counseling throughout the students' high school careers. Upon completion of the program, which also mandates a college preparatory curriculum and minimum grade point average, the students are guaranteed admission to Ohio State as well as any need-based financial aid. The Land Grant Scholarship was initiated in 2005. This program seeks to ensure access to Ohio State to high-ability students from low-income backgrounds. Ohio State has committed to offering a full-ride scholarship each academic year to at least one student from each of Ohio's 88 counties.

Ohio State maintains an honors center in the Kuhn Honors and Scholars House, which served as the University President's residence until the 1960s. Three residences are designated all or in part as honors residences: Taylor Tower, Bradley Hall, and Lincoln House.

The Ohio Union was the first student union built by an American public university. The Ohio Union is dedicated to the enrichment of the student experience, on and off the university campus. The first Ohio Union, on the south edge of the South Oval, was constructed in 1909 and was later renamed Enarson Hall. The second Ohio Union was completed in 1950 and was prominently along High Street, southeast of the Oval. It was a center of student life for more than 50 years, providing facilities for student activities, organizations and events and serving as an important meeting place for campus and community interaction. The union also housed many student services and programs, along with dining and recreational facilities. The second Ohio Union was demolished in February 2007 to make way for the new Ohio Union, which was finished in 2010. During this time, student activities were relocated to Ohio Stadium and other academic buildings.

Student organizations at Ohio State provide students with opportunities to get involved in a wide variety of interest areas including academic, social, religious, artistic, service-based, diversity and many more.
There are over 1,000 registered student organizations that involve many thousands of students. The university's forensics team has won the state National Forensics Association tournament several times.

Block "O" is currently the largest student-run organization on the campus of Ohio State. With over 2,400 annual members, Block "O" serves as the official student cheering section at athletic events for the University. According to the Student Organization Office in the Ohio Union, Agricultural Education Society is the oldest student organization on campus. The Men's Glee Club often disputes the claim, but after consultation with Ohio Union Staff, Agricultural Education Society was named as the university's oldest organization.

Each year, students may sign-up to participate in BuckeyeThon, Ohio State's student-led philanthropy. The organization hosts events throughout the year to support the hematology/oncology/bone marrow transplant unit at Nationwide Children's Hospital in Columbus, Ohio. Although BuckeyeThon is operated entirely by student volunteers, it is embedded within Student Life and the Ohio State University Foundation. The organization receives support, advising, and specialized leadership training from the University. Each February, thousands of students and community members attend BuckeyeThon's signature event, a Dance Marathon consisting of two separate 12-hour shifts. In the past 15 years, students have raised over $5 million to support treatment, research, and various therapies at the hospital. Unique to BuckeyeThon is the use of an operational fund separate from the main philanthropic cancer fund. As a registered non-profit, BuckeyeThon is subject to University audit and issues gift receipts through the Foundation. An annual operational fund relies on University grants, outside sponsors, and event registration fees. This allows the entirety of donations made to the cancer fund to solely support patients without hindrance from outside costs.

Ohio State has several student-managed publications and media outlets. "The Makio" is the official yearbook. "The Makio's" sales plummeted by 60% during the early 1970s; the organization went bankrupt and stopped publication during the late 1970s. The book was revived from 1985 to 1994 and revived again in 2000 thanks to several student organizations. "The Lantern" is the school's daily newspaper and has operated as a laboratory newspaper in the School of Communication (formerly the School of Journalism) since 1881. "Mosaic" is a literary magazine published by Ohio State, which features undergraduate fiction, poetry, and art. "The Sundial" is a student-written and published humor magazine. Founded in 1911 it is one of the oldest humor magazines in the country. After a 17-year hiatus in which no magazine was published it has recently been revived, first in print form, and now in an online humor blog, as well as multiple social media outlets. Ohio State has two improvisational comedy groups, "The 8th Floor Improv" and "Fishbowl Improv", who regularly perform long and short-form improv around campus and across the U.S. There are two student-run radio stations on campus. AROUSE, the music station, is home to over 100 student DJs, streaming music and independent content. Scarlet and Gray Sports Radio broadcasts eleven different Ohio State sports. Both stations broadcast on an Internet audio stream (no broadcast signals are available in Columbus). Students also operate a local cable TV channel known as Buckeye TV, which airs primarily on the campus closed cable system operated by the Office of the Chief Information Officer (OCIO).

The Union's vision is to prepare students to be responsible, engaged leaders committed to community participation for social action and change. Programs with which students can get involved include are the Leadership Collaborative, Leadership Ohio State, Residence Halls Advisory Council, LeaderShape, Buckeye Service Council, Community Commitment Day, SERV team, Service Squad, ImpactOSU, and BUCK I SERV alternative break trips. Additionally, the Service-Learning Institute offers courses that educate students while also helping the greater community. All of these programs have the ultimate goal of making students better leaders, people, and citizens of Ohio.

In 1914, with the approval of President William Oxley Thompson and under the watchful eye of Dean Caroline Breyfogle, Ph.D., Mortar Board Senior Honor Society was established by seven senior women. Four years later, the members of the group then became one of the four founding chapters of Mortar Board National College Senior Honor Society, which now has charters at 231 campuses in the U.S. For more than 100 years at Ohio State, members of Mortar Board have been selected for their significant contributions in scholarship, leadership and service.

At The Ohio State University, three recognized student governments represent their constituents.

Ohio State's intercollegiate sports teams are called the "Buckeyes" (derived from the colloquial term for people from the state of Ohio and after the state tree, the Ohio Buckeye, "Aesculus glabra"), and participate in the NCAA's Division I in all sports (Division I FBS in football) and the Big Ten Conference in most sports. (The women's hockey program competes in the Western Collegiate Hockey Association). The school colors are scarlet and gray. Brutus Buckeye is the mascot. Ohio State currently has 36 varsity teams.

Ohio State is one of six universities (the University of Michigan, the University of Florida, Stanford University, UCLA, and the University of California at Berkeley being the others) to have won national championships in all three major men's sports (baseball, men's basketball, and football). Ohio State is also one of only two universities to appear in the national championship games in both football and men's basketball in the same calendar year (the other university is the University of Florida.) Ohio State has also won national championships in wrestling, men's volleyball, men's swimming & diving, men's outdoor track & field, men's golf, men's gymnastics, men's fencing, women's rowing, co-ed fencing, and multiple synchronized swimming championships. The Ohio State equestrian team has won eight Intercollegiate Horse Show Association national championships. Since the inception of the Athletic Director's Cup, Ohio State has finished in the top 25 each year, including top 6 finishes in three of the last five years. During the 2005–2006 school year Ohio State became the first Big Ten team to win conference championships in Football, Men's Basketball, and Women's Basketball. Ohio State repeated the feat during the 2006–2007 school year, winning solo championships in all three sports. In 2007, Sports Illustrated nicknamed Ohio State's athletic program as being "The Program" due to the unsurpassed facilities, an unparalleled number of men's and women's sports teams, their success, and the financial support of an impressive fan base.

Outstanding sports figures that were student athletes at Ohio State include 1936 Olympics gold medalist Jesse Owens "the Buckeye Bullet" (track and field), John Havlicek, Jerry Lucas, Bobby Knight, and Larry Siegfried (basketball), 2010 Olympics silver medalist Ryan Kesler (ice hockey), Katie Smith and the first 3-time player of the year in Big Ten Basketball history Jessica Davenport (women's basketball), Frank Howard (basketball and baseball), Jack Nicklaus (golf); and Chic Harley (three-time All-American football running back). Ohio State football players have combined for seven Heisman Awards including the only two-time winner Archie Griffin in 1974 and 1975, Eddie George in 1995, and most recently Troy Smith in 2006. Hall of Fame coaches at Ohio State have included Paul Brown, Woody Hayes, and Jim Tressel in football, Fred Taylor in basketball, Larry Snyder in track and field, and Mike Peppe in swimming and diving. Hall of fame players, in pro-football, include Sid Gillman, Lou Groza, Dante Lavelli, Jim Parker, Paul Warfield, Dick LeBeau, and Bill Willis.

Ohio State operates a public television station, WOSU-TV (virtual channel 34 / DT 38, a local PBS TV station), as well as two public radio stations, WOSU-FM 89.7(NPR/BBC news/talk) and WOSA-FM 101.1 (Classical, "Classical 101") in Columbus.

In 2003, the television station began broadcasting in high definition.

Ohio State's faculty currently includes 21 members of the National Academy of Sciences or National Academy of Engineering, four members of the Institute of Medicine, and 177 elected fellows of the American Association for the Advancement of Science. In 2009, 17 Ohio State faculty were elected as AAAS Fellows. Each year since 2002, Ohio State has either led or been second among all American universities in the number of their faculty elected as fellows to the AAAS.

In a recent study by Harvard University's Graduate School of Education, Ohio State was one of five universities rated as "exemplary" workplaces for junior faculty. In the study, 31 universities and 11 liberal arts colleges were evaluated on tenure clarity and fairness, nature of work including workloads, quality of students, and teaching environment, compensation, work and family balance, collegiality and overall satisfaction.

In the last quarter century, 32 Ohio State faculty members have received the prestigious Guggenheim Fellowship, which is more than all other public and private Ohio universities combined. In 2008, three Ohio State faculty were awarded Guggenheim Fellowships, placing Ohio State among the top 15 universities in the nation. Since the 2000–2001 award year, 55 Ohio State faculty members have been named as Fulbright Fellows, the highest of any Ohio university.

Ohio State has over 475,000 living alumni around the world. Ohio State alumni include Nobel Prize recipients, Pulitzer Prize recipients, Olympic Games gold medalists, and Medal of Honor recipients, ambassadors, as well as Fortune 500 CEOs and members of the Forbes 400 list of the world's wealthiest individuals. Numerous graduates have gone on to become U.S. governors, senators and members of Congress. Ohio State alumni have appeared on the cover of "TIME" magazine twelve times, with the artwork of alumnus Roy Lichtenstein featured on an additional two "TIME" covers. George Steinbrenner, former owner of the New York Yankees who won seven World Series with the team, earned his master's degree from Ohio State. One of the founders of Wikipedia, Larry Sanger, and Steve May, Chief Technology Officer at Pixar, both graduated from Ohio State.

Ohio State alumni are enshrined in the Baseball Hall of Fame in Cooperstown, New York, the NFL Hall of Fame and the Basketball Hall of Fame. Its athletes have won a combined eighty-three Olympic medals and three times received the Sullivan Award as the nation's top amateur athlete. Jack Nicklaus has been called "the greatest golfer in history," while Jesse Owens has been called "the greatest Olympian in history." Twice, Ohio State alumni have appeared on the cover of "Sports Illustrated" as its Sportsman of the Year. Roboticist James S. Albus was named a "Hero of US Manufacturing" by "Fortune Magazine" in 1997.



</doc>
<doc id="22218" url="https://en.wikipedia.org/wiki?curid=22218" title="Ontario">
Ontario

Ontario (; ) is one of the 13 provinces and territories of Canada and is located in east-central Canada. It is Canada's most populous province accounting for 38.3 percent of the country's population, and is the second-largest province in total area. Ontario is fourth-largest in total area when the territories of the Northwest Territories and Nunavut are included. It is home to the nation's capital city, Ottawa, and the nation's most populous city, Toronto, which is also Ontario's provincial capital.

Ontario is bordered by the province of Manitoba to the west, Hudson Bay and James Bay to the north, and Quebec to the east and northeast, and to the south by the U.S. states of (from west to east) Minnesota, Michigan, Ohio, Pennsylvania and New York. Almost all of Ontario's border with the United States follows inland waterways: from the west at Lake of the Woods, eastward along the major rivers and lakes of the Great Lakes/Saint Lawrence River drainage system. These are the Rainy River, the Pigeon River, Lake Superior, the St. Marys River, Lake Huron, the St. Clair River, Lake St. Clair, the Detroit River, Lake Erie, the Niagara River, Lake Ontario and along the St. Lawrence River from Kingston, Ontario, to the Quebec boundary just east of Cornwall, Ontario. There is only about of land border made up of portages including Height of Land Portage on the Minnesota border.

Ontario is sometimes conceptually divided into two regions, Northern Ontario and Southern Ontario. The great majority of Ontario's population and arable land is in the south. In contrast, the larger, northern part of Ontario is sparsely populated with cold winters and heavy forestation.

The province is named after Lake Ontario, a term thought to be derived from ', a Huron (Wyandot) word meaning "great lake", or possibly ', which means "beautiful water" in the Iroquoian languages. Ontario has about 250,000 freshwater lakes.

The province consists of three main geographical regions:

Despite the absence of any mountainous terrain in the province, there are large areas of uplands, particularly within the Canadian Shield which traverses the province from northwest to southeast and also above the Niagara Escarpment which crosses the south. The highest point is Ishpatina Ridge at above sea level in Temagami, Northeastern Ontario. In the south, elevations of over are surpassed near Collingwood, above the Blue Mountains in the Dundalk Highlands and in hilltops near the Madawaska River in Renfrew County.

The Carolinian forest zone covers most of the southwestern region of the province. The temperate and fertile Great Lakes-Saint Lawrence Valley in the south is part of the Eastern Great Lakes lowland forests ecoregion where the forest has now been largely replaced by agriculture, industrial and urban development. A well-known geographic feature is Niagara Falls, part of the Niagara Escarpment. The Saint Lawrence Seaway allows navigation to and from the Atlantic Ocean as far inland as Thunder Bay in Northwestern Ontario. Northern Ontario occupies roughly 87 percent of the surface area of the province; conversely Southern Ontario contains 94 percent of the population.

Point Pelee is a peninsula of Lake Erie in southwestern Ontario (near Windsor and Detroit, Michigan) that is the southernmost extent of Canada's mainland. Pelee Island and Middle Island in Lake Erie extend slightly farther. All are south of 42°N – slightly farther south than the northern border of California.

The climate of Ontario varies by season and location. It is affected by three air sources: cold, dry, arctic air from the north (dominant factor during the winter months, and for a longer part of the year in far northern Ontario); Pacific polar air crossing in from the western Canadian Prairies/US Northern Plains; and warm, moist air from the Gulf of Mexico and the Atlantic Ocean. The effects of these major air masses on temperature and precipitation depend mainly on latitude, proximity to major bodies of water and to a small extent, terrain relief. In general, most of Ontario's climate is classified as humid continental. Ontario has three main climatic regions.

The surrounding Great Lakes greatly influence the climatic region of southern Ontario. During the fall and winter months, heat stored from the lakes is released, moderating the climate near the shores of the lakes. This gives some parts of southern Ontario milder winters than mid-continental areas at lower latitudes. Parts of Southwestern Ontario (generally south of a line from Sarnia-Toronto) have a moderate humid continental climate (Köppen climate classification "Dfa"), similar to that of the inland Mid-Atlantic states and the Great Lakes portion of the Midwestern United States. The region has warm to hot, humid summers and cold winters. Annual precipitation ranges from and is well distributed throughout the year. Most of this region lies in the lee of the Great Lakes, making for abundant snow in some areas. In December 2010, the snowbelt set a new record when it was hit by more than a metre of snow within 48 hours. The next climatic region is Central and Eastern Ontario which has a moderate humid continental climate (Köppen "Dfb"). This region has warm and sometimes hot summers with colder, longer winters, ample snowfall (even in regions not directly in the snowbelts) and annual precipitation similar to the rest of Southern Ontario.
In the northeastern parts of Ontario, extending far as south as Kirkland Lake, the cold waters of Hudson Bay depress summer temperatures, making it cooler than other locations at similar latitudes. The same is true on the northern shore of Lake Superior, which cools hot humid air from the south, leading to cooler summer temperatures. Along the eastern shores of Lake Superior and Lake Huron winter temperatures are slightly moderated but come with frequent heavy lake-effect snow squalls that increase seasonal snowfall totals upwards of in some places. These regions have higher annual precipitation in some case over .
The northernmost parts of Ontario – primarily north of 50°N – have a subarctic climate (Köppen "Dfc") with long, severely cold winters and short, cool to warm summers with dramatic temperature changes possible in all seasons. With no major mountain ranges blocking sinking Arctic air masses, temperatures of are not uncommon; snowfall remains on the ground for sometimes over half the year. Snowfall accumulation can be high in some areas. Precipitation is generally less than and peaks in the summer months in the form of showers or thunderstorms.

Severe thunderstorms peak in summer. London, situated in Southern (Southwestern) Ontario, has the most lightning strikes per year in Canada, averaging 34 days of thunderstorm activity per year. In a typical year, Ontario averages 11 confirmed tornado touchdowns. However, over the last 4 years, it has had upwards of 20 tornado touchdowns per year, with the highest frequency occurring in the Windsor-Essex – Chatham Kent area, though few are very destructive (the majority between F0 to F2 on the Fujita scale). Ontario had a record 29 tornadoes in both 2006 and 2009. Tropical depression remnants occasionally bring heavy rains and winds in the south, but are rarely deadly. A notable exception was Hurricane Hazel which struck Southern Ontario centred on Toronto, in October 1954.

Land was not legally subdivided into administrative units until a treaty had been concluded with the Aboriginal people ceding the land. In 1788, while part of the Province of Quebec, southern Ontario was divided into four districts: Hesse, Lunenburg, Mecklenburg, and Nassau.

In 1792, the four districts were renamed: Hesse became the Western District, Lunenburg became the Eastern District, Mecklenburg became the Midland District, and Nassau became the Home District. Counties were created within the districts.

By 1798, there were eight districts: Eastern, Home, Johnstown, London, Midland, Newcastle, Niagara, and Western.

By 1826, there were eleven districts: Bathurst, Eastern, Gore, Home, Johnstown, London, Midland, Newcastle, Niagara, Ottawa, and Western.

By 1838, there were twenty districts: Bathurst, Brock, Colbourne, Dalhousie, Eastern, Gore, Home, Huron, Johnstown, London, Midland, Newcastle, Niagara, Ottawa, Prince Edward, Simcoe, Talbot, Victoria, Wellington, and Western.

In 1849, the districts of southern Ontario were abolished by the Province of Canada, and county governments took over certain municipal responsibilities. The Province of Canada also began creating "districts" in sparsely populated Northern Ontario with the establishment of Algoma District and Nipissing District in 1858.

The borders of Ontario, its new name in 1867, were provisionally expanded north and west. When the Province of Canada was formed, its borders were not entirely clear, and Ontario claimed eventually to reach all the way to the Rocky Mountains and Arctic Ocean. With Canada's acquisition of Rupert's Land, Ontario was interested in clearly defining its borders, especially since some of the new areas in which it was interested were rapidly growing. After the federal government asked Ontario to pay for construction in the new disputed area, the province asked for an elaboration on its limits, and its boundary was moved north to the 51st parallel north.

The northern and western boundaries of Ontario were in dispute after Canadian Confederation. Ontario's right to Northwestern Ontario was determined by the Judicial Committee of the Privy Council in 1884 and confirmed by the "Canada (Ontario Boundary) Act, 1889" of the Parliament of the United Kingdom. By 1899, there were seven northern districts: Algoma, Manitoulin, Muskoka, Nipissing, Parry Sound, Rainy River, and Thunder Bay. Four more northern districts were created between 1907 and 1912: Cochrane, Kenora, Sudbury and Timiskaming.

Prior to the arrival of the Europeans, the region was inhabited by Algonquian (Ojibwe, Cree and Algonquin) in the northern/western portions, and Iroquois and Wyandot (Huron) people more in the south/east. During the 17th century, the Algonquians and Hurons fought the Beaver Wars against the Iroquois. The French explorer Étienne Brûlé explored part of the area in 1610–12. The English explorer Henry Hudson sailed into Hudson Bay in 1611 and claimed the area for England.

Samuel de Champlain reached Lake Huron in 1615, and French missionaries began to establish posts along the Great Lakes. French settlement was hampered by their hostilities with the Iroquois, who allied themselves with the British. From 1634 to 1640, Hurons were devastated by European infectious diseases, such as measles and smallpox, to which they had no immunity. By 1700, the Iroquois had seceded from Ontario and the Mississaugas of the Ojibwa had settled the north shore of Lake Ontario. The remaining Huron settled north of Quebec.

The British established trading posts on Hudson Bay in the late 17th century and began a struggle for domination of Ontario with the French. After the French of New France were defeated during the Seven Years' War, the two powers awarded nearly all of France's North American possessions (New France) to Britain in the 1763 Treaty of Paris, including those lands of Ontario not already claimed by Britain. The British annexed the Ontario region to Quebec in 1774. The first European settlements were in 1782–1784 when 5,000 American loyalists entered what is now Ontario following the American Revolution. The Kingdom of Great Britain granted them land and other items with which to rebuild their lives. The British also set up reservations in Ontario for the Mohawks who had fought for the British and had lost their land in New York state. Other Iroquois, also displaced from New York were resettled in 1784 at the Six Nations reserve at the west end of Lake Ontario. The Mississaugas, displaced by European settlements, would later move to Six Nations also.

The population of Canada west of the St. Lawrence-Ottawa River confluence substantially increased during this period, a fact recognized by the "Constitutional Act" of 1791, which split Quebec into the Canadas: Upper Canada southwest of the St. Lawrence-Ottawa River confluence, and Lower Canada east of it. John Graves Simcoe was appointed Upper Canada's first Lieutenant governor in 1793.

American troops in the War of 1812 invaded Upper Canada across the Niagara River and the Detroit River, but were defeated and pushed back by the British, Canadian fencibles and militias, and First Nations warriors. However, eventually, the Americans gained control of Lake Erie and Lake Ontario. The 1813 Battle of York saw American troops defeat the garrison at the Upper Canada capital of York. The Americans looted the town and burned the Upper Canada Parliament Buildings during the brief occupation. The British would burn the American capital of Washington, D.C. in 1814.

After the War of 1812, relative stability allowed for increasing numbers of immigrants to arrive from Europe rather than from the United States. As was the case in the previous decades, this immigration shift was encouraged by the colonial leaders. Despite affordable and often free land, many arriving newcomers, mostly from Britain and Ireland, found frontier life with the harsh climate difficult, and some of those with the means eventually returned home or went south. However, population growth far exceeded emigration in the decades that followed. It was a mostly agrarian-based society, but canal projects and a new network of plank roads spurred greater trade within the colony and with the United States, thereby improving previously damaged relations over time.

Meanwhile, Ontario's numerous waterways aided travel and transportation into the interior and supplied water power for development. As the population increased, so did the industries and transportation networks, which in turn led to further development. By the end of the century, Ontario vied with Quebec as the nation's leader in terms of growth in population, industry, arts and communications.

Unrest in the colony began to chafe against the aristocratic Family Compact who governed while benefiting economically from the region's resources, and who did not allow elected bodies power. This resentment spurred republican ideals and sowed the seeds for early Canadian nationalism. Accordingly, rebellion in favour of responsible government rose in both regions; Louis-Joseph Papineau led the Lower Canada Rebellion and William Lyon Mackenzie led the Upper Canada Rebellion.

Although both rebellions were put down in short order, the British government sent Lord Durham to investigate the causes of the unrest. He recommended that self-government be granted and that Lower and Upper Canada be re-joined in an attempt to assimilate the French Canadians. Accordingly, the two colonies were merged into the Province of Canada by the "Act of Union 1840", with the capital at Kingston, and Upper Canada becoming known as Canada West. Parliamentary self-government was granted in 1848. There were heavy waves of immigration in the 1840s, and the population of Canada West more than doubled by 1851 over the previous decade. As a result, for the first time, the English-speaking population of Canada West surpassed the French-speaking population of Canada East, tilting the representative balance of power.

An economic boom in the 1850s coincided with railway expansion across the province, further increasing the economic strength of Central Canada. With the repeal of the Corn Laws and a reciprocity agreement in place with the United States, various industries such as timber, mining, farming and alcohol distilling benefited tremendously.

A political stalemate between the French- and English-speaking legislators, as well as fear of aggression from the United States during and immediately after the American Civil War, led the political elite to hold a series of conferences in the 1860s to effect a broader federal union of all British North American colonies. The "British North America Act" took effect on July 1, 1867, establishing the Dominion of Canada, initially with four provinces: Nova Scotia, New Brunswick, Quebec and Ontario. The Province of Canada was divided into Ontario and Quebec so that each linguistic group would have its own province. Both Quebec and Ontario were required by section 93 of the "British North America Act" to safeguard existing educational rights and privileges of Protestant and the Catholic minority. Thus, separate Catholic schools and school boards were permitted in Ontario. However, neither province had a constitutional requirement to protect its French- or English-speaking minority. Toronto was formally established as Ontario's provincial capital.

Once constituted as a province, Ontario proceeded to assert its economic and legislative power. In 1872, the lawyer Oliver Mowat became Premier of Ontario and remained as premier until 1896. He fought for provincial rights, weakening the power of the federal government in provincial matters, usually through well-argued appeals to the Judicial Committee of the Privy Council. His battles with the federal government greatly decentralized Canada, giving the provinces far more power than John A. Macdonald had intended. He consolidated and expanded Ontario's educational and provincial institutions, created districts in Northern Ontario, and fought to ensure that those parts of Northwestern Ontario not historically part of Upper Canada (the vast areas north and west of the Lake Superior-Hudson Bay watershed, known as the District of Keewatin) would become part of Ontario, a victory embodied in the "Canada (Ontario Boundary) Act, 1889". He also presided over the emergence of the province into the economic powerhouse of Canada. Mowat was the creator of what is often called "Empire Ontario".

Beginning with Sir John A. Macdonald's National Policy (1879) and the construction of the Canadian Pacific Railway (1875–1885) through Northern Ontario and the Canadian Prairies to British Columbia, Ontario manufacturing and industry flourished. However, population increase slowed after a large recession hit the province in 1893, thus slowing growth drastically but for only a few years. Many newly arrived immigrants and others moved west along the railway to the Prairie Provinces and British Columbia, sparsely settling Northern Ontario.

Mineral exploitation accelerated in the late 19th century, leading to the rise of important mining centres in the northeast, such as Sudbury, Cobalt and Timmins. The province harnessed its water power to generate hydro-electric power and created the state-controlled Hydro-Electric Power Commission of Ontario, later Ontario Hydro. The availability of cheap electric power further facilitated the development of industry. The Ford Motor Company of Canada was established in 1904. General Motors Canada was formed in 1918. The motor vehicle industry became the most lucrative industry for the Ontario economy during the 20th century.

In July 1912, the Conservative government of Sir James Whitney issued Regulation 17 which severely limited the availability of French-language schooling to the province's French-speaking minority. French Canadians reacted with outrage, journalist Henri Bourassa denouncing the "Prussians of Ontario". The regulation was eventually repealed in 1927.

Influenced by events in the United States, the government of Sir William Hearst introduced prohibition of alcoholic drinks in 1916 with the passing of the Ontario Temperance Act. However, residents could distill and retain their own personal supply, and liquor producers could continue distillation and export for sale, allowing this already sizeable industry to strengthen further. Ontario became a hotbed for the illegal smuggling of liquor and the biggest supplier into the United States, which was under complete prohibition. Prohibition in Ontario came to an end in 1927 with the establishment of the Liquor Control Board of Ontario under the government of Howard Ferguson. The sale and consumption of liquor, wine, and beer are still controlled by some of the most extreme laws in North America to ensure that strict community standards and revenue generation from the alcohol retail monopoly are upheld. In April 2007, Ontario Member of Provincial Parliament Kim Craitor suggested that local brewers should be able to sell their beer in local corner stores; however, the motion was quickly rejected by Premier Dalton McGuinty.

The post-World War II period was one of exceptional prosperity and growth. Ontario has been the recipients of most immigration to Canada, largely immigrants from war-torn Europe in the 1950s and 1960s and following changes in federal immigration law, a massive influx of non-Europeans since the 1970s. From a largely ethnically British province, Ontario has rapidly become culturally very diverse.

The nationalist movement in Quebec, particularly after the election of the "Parti Québécois" in 1976, contributed to driving many businesses and English-speaking people out of Quebec to Ontario, and as a result Toronto surpassed Montreal as the largest city and economic centre of Canada. Depressed economic conditions in the Maritime Provinces have also resulted in de-population of those provinces in the 20th century, with heavy migration into Ontario.

Ontario's official language is English. Numerous French-language services are available under the French Language Services Act of 1990 in designated areas where sizeable francophone populations exist.

In the 2011 census, Ontario had a population of 12,851,821 living in 4,887,508 of its 5,308,785 total dwellings, a 5.7 percent change from its 2006 population of 12,160,282. With a land area of , it had a population density of in 2011. In 2013, Statistics Canada estimated the province's population to be 13,537,994.

The percentages given below add to more than 100 percent because of dual responses (e.g., "French and Canadian" response generates an entry both in the category "French Canadian" and in the category "Canadian").

The majority of Ontarians are of English or other European descent including large Scottish, Irish and Italian communities. Slightly less than 5 percent of the population of Ontario is Franco-Ontarian, that is those whose native tongue is French, although those with French ancestry account for 11 percent of the population. In relation to natural increase or inter-provincial migration, immigration is a huge population growth force in Ontario, as it has been over the last two centuries. More recent sources of immigrants with large or growing communities in Ontario include South Asians, Caribbeans, Latin Americans, Europeans, Asians, and Africans. Most populations have settled in the larger urban centres.

In 2011, 25.9 percent of the population consisted of visible minorities and 2.4 percent of the population was Aboriginal, mostly of First Nations and Métis descent. There was also a small number of Inuit people in the province. The number of Aboriginal people and visible minorities has been increasing at a faster rate than the general population of Ontario.

In 2011, the largest religious denominations in Ontario were the Roman Catholic Church (with 31.4% of the population), the United Church of Canada (7.5%), and the Anglican Church (6.1%). 23.1% of Ontarians had no religious affiliation, making it the second-largest religious grouping in the province after Roman Catholics.

The major religious groups in Ontario in 2011 were:

The principal language of Ontario is English, the province's de facto official language, which is spoken natively by about 70% of the province's population, according to the 2011 census. There is also a French-speaking population concentrated in the northeastern, eastern, and extreme Southern parts of the province, where under the French Language Services Act, provincial government services are required to be available in French if at least 10% of a designated area's population report French as their native language. Roughly 4% of Ontarians speak French as their mother tongue, and 11% are bilingual, speaking both English and French, according to the 2011 census. Other languages spoken by residents include Arabic, Bengali, Cantonese, Dutch, German, Greek, Gujarati, Hindi, Italian, Korean, Mandarin, Persian, Polish, Portuguese, Punjabi, Russian, Somali, Spanish, Tagalog, Tamil, Urdu and Vietnamese.

Ontario is Canada's leading manufacturing province, accounting for 52% of the total national manufacturing shipments in 2004. Ontario's largest trading partner is the American state of Michigan. , Moody's bond-rating agency rated Ontario debt at AA2/stable, while S&P rated it AA-. Dominion Bond Rating Service rated it AA(low) in January 2013. Long known as a bastion of Canadian manufacturing and financial solvency, Ontario's public debt-to-GDP ratio is projected to be 37.2% in fiscal year 2019–2020, compared to 26% in 2007–2008.

Ontario's rivers make it rich in hydroelectric energy. In 2009, Ontario Power Generation generated 70 percent of the electricity of the province, of which 51 percent is nuclear, 39% is hydroelectric and 10% is fossil-fuel derived. By 2025, nuclear power is projected to supply 42%, while fossil-fuel-derived generation is projected to decrease slightly over the next 20 years. Much of the newer power generation coming online in the last few years is natural gas or combined-cycle natural gas plants. OPG is not, however, responsible for the transmission of power, which is under the control of Hydro One. Despite its diverse range of power options, problems related to increasing consumption, lack of energy efficiency and aging nuclear reactors, Ontario has been forced in recent years to purchase power from its neighbours Quebec and Michigan to supplement its power needs during peak consumption periods. Ontario's basic domestic rate in 2010 was 11.17 cents per kWH; by contrast. Quebec's was 6.81. In December 2013, the government projected a 42 percent hike by 2018, and 68 percent by 2033.
Industrial rates are projected to rise by 33% by 2018, and 55% in 2033.

An abundance of natural resources, excellent transportation links to the American heartland and the inland Great Lakes making ocean access possible via container ships, have all contributed to making manufacturing the principal industry of the province, found mainly in the Golden Horseshoe region, which is the largest dustrialized area in Canada, the southern end of the region being part of the North American Rust Belt. Important products include motor vehicles, iron, steel, food, electrical appliances, machinery, chemicals, and paper.

Ontario surpassed Michigan in car production, assembling 2.696 million vehicles in 2004. Ontario has Chrysler plants in Windsor and Bramalea, two GM plants in Oshawa and one in Ingersoll, a Honda assembly plant in Alliston, Ford plants in Oakville and St. Thomas and Toyota assembly plants in Cambridge and Woodstock. However, as a result of steeply declining sales, in 2005, General Motors announced massive layoffs at production facilities across North America including two large GM plants in Oshawa and a drive train facility in St. Catharines resulting in 8,000 job losses in Ontario alone. In 2006, Ford Motor Company announced between 25,000 and 30,000 layoffs phased until 2012; Ontario was spared the worst, but job losses were announced for the St Thomas facility and the Windsor Casting plant. However, these losses will be offset by Ford's recent announcement of a hybrid vehicle facility slated to begin production in 2007 at its Oakville plant and GM's re-introduction of the Camaro which will be produced in Oshawa. On December 4, 2008 Toyota announced the grand opening of the RAV4 plant in Woodstock, and Honda also has plans to add an engine plant at its facility in Alliston. Despite these new plants coming online, Ontario has not yet fully recovered following massive layoffs caused by the global recession; its unemployment rate was 7.3% in May 2013, compared to 8.7 percent in January 2010 and approximately 6% in 2007. In September 2013, the Ontario government committed CAD$70.9 million to the Ford plant in Oakville, while the federal government committed CAD$71.1mn, to secure 2,800 jobs. The province has lost 300,000 manufacturing jobs in the decade from 2003, and the Bank of Canada noted that "while the energy and mining industries have benefitted from these movements, the pressure on the manufacturing sector has intensified, since many firms in this sector were already dealing with growing competition from low-cost economies such as China."

Ontario's steel industry once centred on Hamilton. Hamilton harbour, which can be seen as one drives the QEW Skyway bridge, is an industrial wasteland; U.S. Steel-owned Stelco announced in the autumn of 2013 that it would close in 2014, with the loss of 875 jobs. The move flummoxed a union representative, who seemed puzzled why a plant with capacity of 2 million tons per annum would be shut while Canada imported 8 million tons of steel the year before. Algoma Steel maintains a plant in Sault Ste Marie.
Toronto, the capital of Ontario, is the centre of Canada's financial services and banking industry. Neighbouring cities are home to product distribution, IT centres, and various manufacturing industries. Canada's Federal Government is the largest single employer in the National Capital Region, which centres on the border cities of Ontario's Ottawa and Quebec's Gatineau.
The information technology sector is important, particularly in the "Silicon Valley North" section of Ottawa, as well as the Waterloo Region, where the world headquarters of Research in Motion (the developers of the BlackBerry smartphone) is located. BlackBerry once provided more than 19 percent of the local jobs and employed more than 13% of the entire local population before it supplied 9,500 layoffs in 2013. OpenText and ATS Automation Tooling Systems of Cambridge make their homes in the area too. Mike Lazaridis, one of the founders of RIM, founded in 1999 the Perimeter Institute, then in 2002 the Institute for Quantum Computing, then in 2013 Quantum Valley Investments, to plow a portion of the benefits of RIM back into research and development.

In 2014, the section of Highway 401 between Toronto and Waterloo became the world's second-largest innovation corridor after California's Silicon Valley, employing nearly 280,000 tech workers from around the world and containing over 60% of Canada's high tech industry.

Hamilton is the largest steel manufacturing city in Canada followed closely by Sault Ste. Marie, and Sarnia is the centre for petrochemical production. Construction employed more than 6.5% of the province's work force in June 2011.

Mining and the forest products industry, notably pulp and paper, are vital to the economy of Northern Ontario. There has been controversy over the Ring of Fire mineral deposit, and whether the province can afford to spend CAD$2.25 billion on a road from the Trans-Canada Highway near Kenora to the deposit, currently valued at CAD$60 billions.

Tourism contributes heavily to the economy of Central Ontario, peaking during the summer months owing to the abundance of fresh water recreation and wilderness found there in reasonable proximity to the major urban centres. At other times of the year, hunting, skiing and snowmobiling are popular. This region has some of the most vibrant fall colour displays anywhere on the continent, and tours directed at overseas visitors are organized to see them. Tourism also plays a key role in border cities with large casinos, among them Windsor, Cornwall, Sarnia and Niagara Falls, the latter of which attracts millions of US and other international visitors.

Once the dominant industry, agriculture occupies a small percentage of the population. However, much of the land in southern Ontario is given over to agriculture. As the following table shows, while the number of individual farms has steadily decreased and their overall size has shrunk at a lower rate, greater mechanization has supported increased supply to satisfy the ever-increasing demands of a growing population base; this has also meant a gradual increase in the total amount of land used for growing crops.
Common types of farms reported in the 2001 census include those for cattle, small grains and dairy. The fruit- and grape-growing industry is primarily on the Niagara Peninsula and along Lake Erie, where tobacco farms are also situated. Market vegetables grow in the rich soils of the Holland Marsh near Newmarket. The area near Windsor is also very fertile. The Heinz plant in Leamington was taken over in these autumn of 2013 by Warren Buffett and a Brazilian partner, following which it put 740 people out of work. Government subsidies followed shortly; Premier Kathleen Wynne offered CAD$200,000 to cushion the blow, and promised that another processed-food operator would soon be found. On December 10, 2013, Kellogg's announced layoffs for more than 509 workers at a cereal manufacture plant in London. Kellogg's plans to relocate jobs to Thailand.

The area defined as the Corn Belt covers much of the southwestern area of the province, extending as far north as close to Goderich, but corn and soy are grown throughout the southern portion of the province. Apple orchards are a common sight along the southern shore of Nottawasaga Bay (part of Georgian Bay) near Collingwood and along the northern shore of Lake Ontario near Cobourg. Tobacco production, centred in Norfolk County, has decreased, allowing an increase in alternative crops such as hazelnuts and ginseng. The Ontario origins of Massey Ferguson, once one of the largest farm-implement manufacturers in the world, indicate the importance agriculture once had to the Canadian economy.

Southern Ontario's limited supply of agricultural land is going out of production at an increasing rate. Urban sprawl and farmland severances contribute to the loss of thousands of acres of productive agricultural land in Ontario each year. Over 2,000 farms and of farmland in the GTA alone were lost to production in the two decades between 1976 and 1996. This loss represented approximately 18%". of Ontario's Class 1 farmland being converted to urban purposes. In addition, increasing rural severances provide ever-greater interference with agricultural production.

The Green Energy and Green Economy Act, 2009 (GEA), takes a two-pronged approach to commercializing renewable energy:


The bill envisaged appointing a Renewable Energy Facilitator to provide "one-window" assistance and support to project developers to facilitate project approvals.

The approvals process for transmission projects would also be streamlined and (for the first time in Ontario) the bill would enact standards for renewable energy projects. Homeowners would have access to incentives to develop small-scale renewables such as low- or no-interest loans to finance the capital cost of renewable energy generating facilities like solar panels.

Ontario is home to Niagara Falls, which supplies a large amount of electricity to the province. The Bruce Nuclear Generating Station, the largest operational nuclear power plant in the world, is also in Ontario and uses 8 CANDU reactors to generate electricity for the province.

The "British North America Act 1867" section 69 stipulated "There shall be a Legislature for Ontario consisting of the Lieutenant Governor and of One House, styled the Legislative Assembly of Ontario." The assembly has 107 seats representing ridings elected in a first-past-the-post system across the province.

The legislative buildings at Queen's Park are the seat of government. Following the Westminster system, the leader of the party holding the most seats in the assembly is known as the "Premier and President of the Council" (Executive Council Act R.S.O. 1990). The Premier chooses the cabinet or Executive Council whose members are deemed ministers of the Crown.

Although the "Legislative Assembly Act (R.S.O. 1990)" refers to "members of the assembly", the legislators are now commonly called MPPs (Members of the Provincial Parliament) in English and "députés de l'Assemblée législative" in French, but they have also been called MLAs (Members of the Legislative Assembly), and both are acceptable. The title of Prime Minister of Ontario, correct in French ("le Premier ministre"), is permissible in English but now generally avoided in favour of the title "Premier" to avoid confusion with the Prime Minister of Canada.

Ontario has grown, from its roots in Upper Canada, into a modern jurisdiction. The old titles of the chief law officers, the Attorney-General and the Solicitor-General, remain in use. They both are responsible to the Legislature. The Attorney-General drafts the laws and is responsible for criminal prosecutions and the administration of justice, while the Solicitor-General is responsible for law enforcement and the police services of the province.

Ontario has numerous political parties which run for election. The four main parties are the centre-right Progressive Conservative Party of Ontario, the social democratic Ontario New Democratic Party (NDP), the centre-left Ontario Liberal Party and the centre-left Ontario Green Party. The Progressive Conservatives, Liberals and New Democrats have each governed the province, while the Greens elected their first-ever member to the Legislative Assembly in 2018.

The 2018 provincial election resulted in a Progressive Conservative majority under Doug Ford, who was sworn in to office on June 29.

Statistics Canada's measure of a "metro area", the Census Metropolitan Area (CMA), roughly bundles together population figures from the core municipality with those from "commuter" municipalities.

<nowiki>*</nowiki>Parts of Quebec (including Gatineau) are included in the Ottawa CMA. The population of the Ottawa CMA, in both provinces, is shown.

In Canada, education falls under provincial jurisdiction. Publicly funded elementary and secondary schools are administered by the Ontario Ministry of Education, while colleges and universities are administered by the Ontario Ministry of Training, Colleges and Universities. The Minister of Education is Mitzie Hunter, and the Minister of Training, Colleges and Universities is Reza Moridi.

Higher education in Ontario includes postsecondary education and skills training regulated by the Ministry of Training, Colleges, and Universities and provided by universities, colleges of applied arts and technology, and private career colleges. The minister is Reza Moridi. The ministry administers laws covering 22 public universities, 24 public colleges (21 Colleges of Applied Arts and Technology (CAATs) and three Institutes of Technology and Advanced Learning (ITALs)), 17 privately funded religious universities, and over 500 private career colleges. The Canadian constitution provides each province with the responsibility for higher education and there is no corresponding national federal ministry of higher education. Within Canadian federalism the division of responsibilities and taxing powers between the Ontario and Canadian governments creates the need for co-operation to fund and deliver higher education to students. Each higher education system aims to improve participation, access, and mobility for students. There are two central organizations that assist with the process of applying to Ontario universities and colleges: the Ontario Universities' Application Centre and Ontario College Application Service. While application services are centralized, admission and selection processes vary and are the purview of each institution independently. Admission to many Ontario postsecondary institutions can be highly competitive. Upon admission, students may get involved with regional student representation with the Canadian Federation of Students, the Canadian Alliance of Student Associations, the Ontario Undergraduate Student Alliance, or through the College Student Alliance in Ontario.

In 1973 the first slogan to appear on licence plates in Ontario was "Keep It Beautiful". This was replaced by "Yours to Discover" in 1982, apparently inspired by a tourism slogan, "Discover Ontario", dating back to 1927. Plates with the French equivalent, "Tant à découvrir", were made available to the public beginning in May 2008. (From 1988 to 1990, "Ontario Incredible" gave "Yours to Discover" a brief respite.)

In 2007, a new song replaced "A Place to Stand" after four decades. "There's No Place Like This" is featured in television advertising, performed by Ontario artists including Molly Johnson, Brian Byrne, Keshia Chanté, as well as Tomi Swick and Arkells.

The province has professional sports teams in baseball, basketball, Canadian football, ice hockey, lacrosse, rugby and soccer.

Transportation routes in Ontario evolved from early waterway travel and First Nations paths followed by European explorers. Ontario has two major east-west routes, both starting from Montreal in the neighbouring province of Quebec. The northerly route, which was a major fur trade route, travels west from Montreal along the Ottawa River, then continues northwestward towards Manitoba. Major cities on or near the route include Ottawa, North Bay, Sudbury, Sault Ste. Marie, and Thunder Bay. The southerly route, which was driven by growth in settlements originated by the United Empire Loyalists and later other European immigrants, travels southwest from Montreal along the St. Lawrence River, Lake Ontario, and Lake Erie before entering the United States in Michigan. Major cities on or near the route include Kingston, Belleville, Peterborough, Oshawa, Toronto, Mississauga, Kitchener-Waterloo, Hamilton, London, Sarnia, and Windsor. This route was also heavily used by immigrants to the Midwestern US particularly in the late 19th century.

400-series highways make up the primary vehicular network in the south of province, and they connect to numerous border crossings with the US, the busiest being the Detroit–Windsor Tunnel and Ambassador Bridge and the Blue Water Bridge (via Highway 402). Some of the primary highways along the southern route are Highway 401, Highway 417, and Highway 400, while other provincial highways and regional roads inter-connect the remainder of the province.

The Saint Lawrence Seaway, which extends across most of the southern portion of the province and connects to the Atlantic Ocean, is the primary water transportation route for cargo, particularly iron ore and grain. In the past, the Great Lakes and St. Lawrence River were also a major passenger transportation route, but over the past half century passenger travel has been reduced to ferry services and sightseeing cruises.

Via Rail operates the inter-regional passenger train service on the Quebec City–Windsor Corridor, along with "The Canadian", a transcontinental rail service from Southern Ontario to Vancouver, and the Sudbury–White River train. Additionally, Amtrak rail connects Ontario with key New York cities including Buffalo, Albany, and New York City. Ontario Northland provides rail service to destinations as far north as Moosonee near James Bay, connecting them with the south.

Freight rail is dominated by the founding cross-country Canadian National Railway and CP Rail companies, which during the 1990s sold many short rail lines from their vast network to private companies operating mostly in the south.

Regional commuter rail is limited to the provincially owned GO Transit, and serves a train-bus network spanning the Golden Horseshoe region, with Union Station in Toronto serving as the transport hub.

The Toronto Transit Commission operates the province's only subway and streetcar system, one of the busiest in North America. OC Transpo operates, in addition to bus service, Ontario's only light rail transit line, the O-Train in Ottawa.

A light-rail metro called the Confederation Line is under construction in Ottawa. It will have 13 stations on and part of it will run under the city's Downtown and feature three underground stations. In addition, the Ion light rail and bus rapid transit system is under construction in the province's Waterloo region.
Important airports in the province include Toronto Pearson International Airport, which is the busiest airport in Canada, handling over 47 million passengers in 2017. Ottawa Macdonald–Cartier International Airport is Ontario's second largest airport. Toronto/Pearson and Ottawa/Macdonald-Cartier form two of the three points in Canada's busiest set of air routes (the third point being Montréal–Pierre Elliott Trudeau International Airport).

Most Ontario cities have regional airports, many of which have scheduled commuter flights from Air Canada Jazz or smaller airlines and charter companies – flights from the mid-size cities such as Thunder Bay, Sault Ste. Marie, Sudbury, North Bay, Timmins, Windsor, London, and Kingston feed directly into larger airports in Toronto and Ottawa. Bearskin Airlines also runs flights along the northerly east-west route, connecting Ottawa, North Bay, Sudbury, Sault Ste. Marie, Kitchener and Thunder Bay directly.

Isolated towns and settlements in the northern areas of the province rely partly or entirely on air service for travel, goods, and even ambulance services (MEDIVAC), since much of the far northern area of the province cannot be reached by road or rail.




</doc>
<doc id="22219" url="https://en.wikipedia.org/wiki?curid=22219" title="Ottawa">
Ottawa

Ottawa (, ; ) is the capital city of Canada. It stands on the south bank of the Ottawa River in the eastern portion of southern Ontario. Ottawa borders Gatineau, Quebec; the two form the core of the Ottawa–Gatineau census metropolitan area (CMA) and the National Capital Region (NCR). As of 2016, Ottawa had a city population of 934,243 and a metropolitan population of 1,323,783 making it the fourth-largest city and the fifth-largest CMA in Canada.

Founded in 1826 as Bytown, and incorporated as Ottawa in 1855, the city has evolved into the political centre of Canada. Its original boundaries were expanded through numerous annexations and were ultimately replaced by a new city incorporation and amalgamation in 2001 which significantly increased its land area. The city name "Ottawa" was chosen in reference to the Ottawa River, the name of which is derived from the Algonquin "Odawa", meaning "to trade".

Ottawa has the most educated population among Canadian cities and is home to a number of post-secondary, research, and cultural institutions, including the National Arts Centre, the National Gallery, and numerous national museums. Ottawa has the highest standard of living in the nation and low unemployment. It ranked second nationally and 24th worldwide in the quality of life index and is consistently rated the best place to live in Canada.

With the draining of the Champlain Sea around ten thousand years ago, the Ottawa Valley became habitable. Local populations used the area for wild edible harvesting, hunting, fishing, trade, travel, and camps for over 6500 years. The Ottawa river valley has archaeological sites with arrow heads, pottery, and stone tools. Three major rivers meet within Ottawa, making it an important trade and travel area for thousands of years. The Algonquins called the Ottawa River "Kichi Sibi" or "Kichissippi" meaning "Great River" or "Grand River".

Étienne Brûlé, widely regarded as the first European to travel up the Ottawa River, passed by Ottawa in 1610 on his way to the Great Lakes. Three years later, Samuel de Champlain wrote about the waterfalls in the area and about his encounters with the Algonquins, who had been using the Ottawa River for centuries. Many missionaries would follow the early explorers and traders. The first maps of the area used the word Ottawa, derived from the Algonquin word "adawe" ("to trade", used in reference to the area's importance to First Nations traders), to name the river. Philemon Wright, a New Englander, created the first settlement in the area on 7 March 1800 on the north side of the river, across from the present day city of Ottawa in Hull. He, with five other families and twenty-five labourers, set about to create an agricultural community called Wrightsville. Wright pioneered the Ottawa Valley timber trade (soon to be the area's most significant economic activity) by transporting timber by river from the Ottawa Valley to Quebec City. Bytown, Ottawa's original name, was founded as a community in 1826 when hundreds of land speculators were attracted to the south side of the river when news spread that British authorities were immediately constructing the northerly end of the Rideau Canal military project at that location. The following year, the town was named after British military engineer Colonel John By who was responsible for the entire Rideau Waterway construction project.

The canal's military purpose was to provide a secure route between Montreal and Kingston on Lake Ontario, bypassing a particularly vulnerable stretch of the St. Lawrence River bordering the state of New York that had left re-supply ships bound for southwestern Ontario easily exposed to enemy fire during the War of 1812. Colonel By set up military barracks on the site of today's Parliament Hill. He also laid out the streets of the town and created two distinct neighbourhoods named "Upper Town" west of the canal and "Lower Town" east of the canal. Similar to its Upper Canada and Lower Canada namesakes, historically 'Upper Town' was predominantly English speaking and Protestant whereas 'Lower Town' was predominantly French, Irish and Catholic. Bytown's population grew to 1,000 as the Rideau Canal was being completed in 1832. Bytown encountered some impassioned and violent times in her early pioneer period that included Irish labour unrest that attributed to the Shiners' War from 1835 to 1845 and political dissension that was evident from the 1849 Stony Monday Riot. In 1855 Bytown was renamed "Ottawa" and incorporated as a city. William Pittman Lett was installed as the first city clerk guiding it through 36 years of development.
On New Year's Eve 1857, Queen Victoria, as a symbolic and political gesture, was presented with the responsibility of selecting a location for the permanent capital of the Province of Canada. In reality, Prime Minister John A. Macdonald had assigned this selection process to the Executive Branch of the Government, as previous attempts to arrive at a consensus had ended in deadlock. The 'Queen's choice' turned out to be the small frontier town of Ottawa for two main reasons: Firstly, Ottawa's isolated location in a back country surrounded by dense forest far from the Canada–US border and situated on a cliff face would make it more defensible from attack. Secondly, Ottawa was approximately midway between Toronto and Kingston (in Canada West) and Montreal and Quebec City (in Canada East). Additionally, despite Ottawa's regional isolation it had seasonal water transportation access to Montreal over the Ottawa River and to Kingston via the Rideau Waterway. By 1854 it also had a modern all season Bytown and Prescott Railway that carried passengers, lumber and supplies the 82-kilometres to Prescott on the Saint Lawrence River and beyond. Ottawa's small size, it was thought, would make it less prone to rampaging politically motivated mobs, as had happened in the previous Canadian capitals. The government already owned the land that would eventually become Parliament Hill which they thought would be an ideal location for building the Parliament Buildings. Ottawa was the only settlement of any substantial size that was already directly on the border of French populated former Lower Canada and English populated former Upper Canada thus additionally making the selection an important political compromise. Queen Victoria made her "Queen's choice" very quickly just before welcoming in the New Year.

Starting in the 1850s, entrepreneurs known as lumber barons began to build large sawmills, which became some of the largest mills in the world. Rail lines built in 1854 connected Ottawa to areas south and to the transcontinental rail network via Hull and Lachute, Quebec in 1886. The original Parliament buildings which included the Centre, East and West Blocks were constructed between 1859 and 1866 in the Gothic Revival style. At the time, this was the largest North American construction project ever attempted and Public Works Canada and its architects were not initially well prepared. The Library of Parliament and Parliament Hill landscaping would not be completed until 1876. By 1885 Ottawa was the only city in Canada whose downtown street lights were powered entirely by electricity. In 1889 the Government developed and distributed 60 'water leases' (still currently in use) to mainly local industrialists which gave them permission to generate electricity and operate hydroelectric generators at Chaudière Falls. Public transportation began in 1870 with a horsecar system, overtaken in the 1890s by a vast electric streetcar system that lasted until 1959.

The Hull–Ottawa fire of 1900 destroyed two-thirds of Hull, including 40 per cent of its residential buildings and most of its largest employers along the waterfront. It also spread across the Ottawa River and destroyed about one fifth of Ottawa from the Lebreton Flats south to Booth Street and down to Dow's Lake. On 1 June 1912 the Grand Trunk Railway opened both the Château Laurier hotel and its neighbouring downtown Union Station. On 3 February 1916 the Centre Block of the Parliament buildings was destroyed by a fire. The House of Commons and Senate was temporarily relocated to the then recently constructed Victoria Memorial Museum, now the Canadian Museum of Nature until the completion of the new Centre Block in 1922, the centrepiece of which is a dominant Gothic revival styled structure known as the Peace Tower. The current location of what is now Confederation Square was a former commercial district centrally located in a triangular area downtown surrounded by historically significant heritage buildings which includes the Parliament buildings. It was redeveloped as a ceremonial centre in 1938 as part of the City Beautiful Movement and became the site of the National War Memorial in 1939 and designated a National Historic Site in 1984. A new Central Post Office (now the Privy Council of Canada) was constructed in 1939 beside the War Memorial because the original post office building on the proposed Confederation Square grounds had to be demolished.

Ottawa's former industrial appearance was vastly altered by the 1950 Greber Plan. Prime Minister Mackenzie King hired French architect-planner Jacques Greber to design an urban plan for managing development in the National Capital Region, to make it more aesthetically pleasing and more befitting a location for Canada's political centre. Greber's plan included the creation of the National Capital Greenbelt, the Parkway, the Queensway highway system, the relocation of downtown Union Station (now the Government Conference Centre) to the suburbs, the removal of the street car system, the decentralization of selected government offices, the relocation of industries and removal of substandard housing from the downtown and the creation of the Rideau Canal and Ottawa River pathways to name just a few of its recommendations. In 1958 the National Capital Commission was established as a Crown Corporation from the passing of the National Capital Act to implement the Greber Plan recommendations-which it accomplished during the 1960s and 1970s. 

In the previous 50 years, other commissions, plans and projects had failed to implement plans to improve the capital such as the 1899 Ottawa Improvement Commission (OIC), The Todd Plan in 1903, The Holt Report in 1915 and The Federal District Commission (FDC) established in 1927. In 1958 a new City Hall opened on Green Island near Rideau falls where urban renewal had recently transformed this former industrial location into green space. Until then, City Hall had temporarily been located for 27 years (1931–1958) at the Transportation Building adjacent to Union Station and now part of the Rideau Centre. In 2001, Ottawa City Hall returned downtown to a relatively new building (1990) on 110 Laurier Avenue West, the prior home of the now defunct Regional Municipality of Ottawa-Carleton. This new location was close to Ottawa's first (1849–1877) and second (1877–1931) City Halls. This new city hall complex also contained an adjacent 19th century restored heritage building formerly known as the Ottawa Normal School.

From the 1960s until the 1980s, the National Capital Region experienced a building boom, which was followed by large growth in the high-tech industry during the 1990s and 2000s. Ottawa became one of Canada's largest high tech cities and was nicknamed Silicon Valley North. By the 1980s, Bell Northern Research (later Nortel) employed thousands, and large federally assisted research facilities such as the National Research Council contributed to an eventual technology boom. The early adopters led to offshoot companies such as Newbridge Networks, Mitel and Corel.

Ottawa's city limits had been increasing over the years, but it acquired the most territory on 1 January 2001, when it amalgamated all the municipalities of the Regional Municipality of Ottawa–Carleton into one single city. Regional Chair Bob Chiarelli was elected as the new city's first mayor in the 2000 municipal election, defeating Gloucester mayor Claudette Cain. The city's growth led to strains on the public transit system and on road bridges. On 15 October 2001, a diesel-powered light rail transit (LRT) line was introduced on an experimental basis. Known today as the Trillium Line, it was dubbed the O-Train and connected downtown Ottawa to the southern suburbs via Carleton University. The decision to extend the O-Train, and to replace it with an electric light rail system was a major issue in the 2006 municipal elections where Chiarelli was defeated by businessman Larry O'Brien. After O'Brien's election transit plans were changed to establish a series of light rail stations from the east side of the city into downtown, and for using a tunnel through the downtown core. Jim Watson, the last mayor of Ottawa prior to amalgamation, was re-elected in the 2010 election.

In October 2012, City Council approved the final Lansdowne Park plan, an agreement with the Ottawa Sports and Entertainment Group that saw a new stadium, increased green space, and housing and retail added to the site. In December 2012, City Council voted unanimously to move forward with the Confederation Line, a 12.5 km light rail transit line, to be fully operational by 2018.

Ottawa is on the south bank of the Ottawa River and contains the mouths of the Rideau River and Rideau Canal. The older part of the city (including what remains of Bytown) is known as "Lower Town", and occupies an area between the canal and the rivers. Across the canal to the west lies "Centretown" and "Downtown Ottawa", which is the city's financial and commercial hub and home to the Parliament of Canada and numerous federal government department headquarters, notably the Privy Council Office. On 29 June 2007, the Rideau Canal, which stretches to Kingston, Fort Henry and four Martello towers in the Kingston area, was recognized as a UNESCO World Heritage Site.

Located within the major, yet mostly dormant Western Quebec Seismic Zone, Ottawa is occasionally struck by earthquakes. Examples include the 2000 Kipawa earthquake, a magnitude-4.5 earthquake on 24 February 2006, the 2010 Central Canada earthquake, and a magnitude-5.2 earthquake on 17 May 2013.

Ottawa sits at the confluence of three major rivers: the Ottawa River, the Gatineau River and the Rideau River. The Ottawa and Gatineau rivers were historically important in the logging and lumber industries and the Rideau as part of the Rideau Canal system for military, commercial and, subsequently, recreational purposes. The Rideau Canal (Rideau Waterway) first opened in 1832 and is 202 km long. It connects the Saint Lawrence River on Lake Ontario at Kingston to the Ottawa River near Parliament Hill. It was able to bypass the unnavigable sections of the Cataraqui and Rideau rivers and various small lakes along the waterway due to flooding techniques and the construction of 47 water transport locks.The Rideau River got its name from early French explorers who thought that the waterfalls located at the point where the Rideau River empties into the Ottawa River resembled a 'curtain'. Hence they began naming the falls and river 'rideau' which is the French equivalent of the English word for curtain. During part of the winter season the Ottawa section of the canal forms the world's largest skating rink, thereby providing both a recreational venue and a transportation path to downtown for ice skaters (from Carleton University and Dow's Lake to the Rideau Centre and National Arts Centre).

Across the Ottawa River, which forms the border between Ontario and Quebec, lies the city of Gatineau, itself the result of amalgamation of the former Quebec cities of Hull and Aylmer together with Gatineau. Although formally and administratively separate cities in two separate provinces, Ottawa and Gatineau (along with a number of nearby municipalities) collectively constitute the National Capital Region, which is considered a single metropolitan area. One federal crown corporation, the National Capital Commission, or NCC, has significant land holdings in both cities, including sites of historical and touristic importance. The NCC, through its responsibility for planning and development of these lands, is an important contributor to both cities. Around the main urban area is an extensive greenbelt, administered by the NCC for conservation and leisure, and comprising mostly forest, farmland and marshland.

Ottawa has a humid continental climate (Köppen "Dfb") with four distinct seasons and is between Zones 5a and 5b on the Canadian Plant Hardiness Scale. The average July maximum temperature is . The average January minimum temperature is 

Summers are warm and humid in Ottawa. On average 11 days of the three summer months have temperatures exceeding , or 37 days if the humidex is considered. Average relative humidity averages 54% in the afternoon and 84% by morning.

Snow and ice are dominant during the winter season. On average Ottawa receives of snowfall annually but maintains an average of snowpack throughout the three winter months. An average 16 days of the three winter months experience temperatures below , or 41 days if the wind chill is considered.

Spring and fall are variable, prone to extremes in temperature and unpredictable swings in conditions. Hot days above have occurred as early as April or as late as October. Annual precipitation averages around .

Ottawa experiences about 2,130 hours of average sunshine annually (46% of possible). Winds in Ottawa are generally Westerlies averaging 13 km/h but tend to be slightly more dominant during the winter.

The highest temperature ever recorded in Ottawa was on 4 July 1913, 1 August 1917 and 11 August 1944. The coldest temperature ever recorded was on 29 December 1933.

Ottawa is bounded on the east by the United Counties of Prescott and Russell; by Renfrew County and Lanark County in the west; on the south by the United Counties of Leeds and Grenville and the United Counties of Stormont, Dundas and Glengarry; and on the north by the Regional County Municipality of Les Collines-de-l'Outaouais and the City of Gatineau. Modern Ottawa is made up of eleven historic townships, ten of which are from Carleton County and one from Russell.

The city has a main urban area but many other urban, suburban and rural areas exist within the modern city's limits. The main suburban area extends a considerable distance to the east, west and south of the centre, and it includes the former cities of Gloucester, Nepean and Vanier, the former village of Rockcliffe Park (a high-income neighbourhood which is adjacent to the Prime Minister's official residence at 24 Sussex and the Governor General's residence), and the communities of Blackburn Hamlet and Orléans. The Kanata suburban area includes the former village of Stittsville to the southwest. Nepean is another major suburb which also includes Barrhaven. The communities of Manotick and Riverside South are located on the other side of the Rideau River, and Greely, southeast of Riverside South.
A number of rural communities (villages and hamlets) lie beyond the greenbelt but are administratively part of the Ottawa municipality. Some of these communities are Burritts Rapids; Ashton; Fallowfield; Kars; Fitzroy Harbour; Munster; Carp; North Gower; Metcalfe; Constance Bay and Osgoode and Richmond. Several towns are located within the federally defined National Capital Region but outside the city of Ottawa municipal boundaries, these include the urban communities of Almonte, Carleton Place, Embrun, Kemptville, Rockland, and Russell.

In 2011, the populations of the City of Ottawa and the Ottawa–Gatineau census metropolitan area (CMA) were 883,391 and 1,236,324 respectively. The city had a population density of 316.6 persons per km in 2006, while the CMA had a population density of 196.6 persons per km. It is the second-largest city in Ontario, fourth-largest city in the country, and the fourth-largest CMA in the country.

Ottawa's median age of 39.2 is both below the provincial and national averages . Youths under 15 years constituted 16.8% of the total population , while those of retirement age (65 years and older) made up 13.2%. In 2011, females made up 51.5% of the amalgamated Ottawa population.

Between 1987 and 2002, 131,816 individuals relocated to the city, which represents 75% of the population growth for that period. Over 20 percent of the city's population is foreign-born, with the most common non-Canadian countries of origin being the United Kingdom (8.8% of those foreign-born), China (8.0%), and Lebanon (4.8%). About 6.1% of residents are not Canadian citizens.

Members of visible minority groups (non-white/European) constitute 23.7%, while those of Aboriginal origin make up 2.1% of the total population. The largest visible minority groups are: Black Canadians: 5.7%, Chinese Canadians: 4.0%, South Asians: 3.9%, and Arabs: 3.7%. Smaller groups include Latin Americans, Southeast Asians, Filipinos, and West Asians.

Around 65% of Ottawa residents describe themselves as Christian , with Catholics accounting for 38.5% of the population and members of Protestant churches 25%. Non-Christian religions are also very well established in Ottawa, the largest being Islam (6.7%), Hinduism (1.4%), Buddhism (1.3%), and Judaism (1.2%). Those with no religious affiliation represent 22.8%.

Bilingualism became official policy for the conduct of municipal business in 2002, and 37% of the population can speak both languages , making it the largest city in Canada with both English and French as co-official languages. Those who identify their mother tongue as English constitute 62.4 percent, while those with French as their mother tongue make up 14.2 percent of the population. In terms of respondents' knowledge of one or both official languages, 59.9 percent and 1.5 percent of the population have knowledge of English only and French only, respectively; while 37.2 percent have a 
knowledge of both official languages. The overall Ottawa–Gatineau census metropolitan area (CMA) has a larger proportion of French speakers than Ottawa itself, since Gatineau is overwhelmingly French speaking. An additional 20.4 percent of the population list languages other than English and French as their mother tongue. These include Arabic (3.2%), Chinese (3.0%), Spanish (1.2%), Italian (1.1%), and many others.

Ottawa has a high standard of living, low unemployment, and the fourth highest GDP growth rate among major Canadian cities in 2007 at 2.7%, which exceeded the Canadian average of 2.4%. The region of Ottawa-Gatineau has the third highest income of all major Canadian cities. The average gross income in the region amounted to $40,078, an increase of 4.9% compared to the previous year. The annual cost of living rate in 2007 grew 1.9%. Mercer ranks Ottawa with the third highest quality of living of any large city in the Americas, and 16th highest in the world. It is also rated the second cleanest city in Canada, and third cleanest city in the world. In 2012, the city was ranked for the third consecutive year as the best community in Canada to live in by MoneySense.

Ottawa's primary employers are the Public Service of Canada and the high-tech industry, although tourism and healthcare also represent increasingly sizeable economic activities. The Federal government is the city's largest employer, employing over 110,000 individuals from the National Capital region. The national headquarters for many federal departments are located in Ottawa, particularly throughout Centretown and in the Terrasses de la Chaudière and Place du Portage complexes in Hull. The National Defence Headquarters located in Ottawa is the main command centre for the Canadian Armed Forces and hosts the Department of National Defence. The Ottawa area includes CFS Leitrim, CFB Uplands, and the former CFB Rockcliffe. During the summer, the city hosts the Ceremonial Guard, which performs functions such as the Changing the Guard. As the national capital of Canada, tourism is an important part of Ottawa's economy, particularly after the 150th anniversary of Canada which was centred in Ottawa. The lead-up to the festivities saw much investment in civic infrastructure, upgrades to tourist infrastructure and increases in national cultural attractions. The National Capital Region annually attracts an estimated 7.3 million tourists, who spend about 1.18 billion dollars.

In addition to the economic activities that come with being the national capital, Ottawa is an important technology centre; in 2015, its 1800 companies employed approximately 63,400 people. The concentration of companies in this industry earned the city the nickname of "Silicon Valley North". Most of these companies specialize in telecommunications, software development and environmental technology. Large technology companies such as Nortel, Corel, Mitel, Cognos, Halogen Software, Shopify and JDS Uniphase were founded in the city. Ottawa also has regional locations for Nokia, 3M, Adobe Systems, Bell Canada, IBM and Hewlett-Packard. Many of the telecommunications and new technology are located in the western part of the city (formerly Kanata). The "tech sector" was doing particularly well in 2015/2016. 

Another major employer is the health sector, which employs over 18,000 people. Four active general hospitals are in the Ottawa area: Queensway-Carleton Hospital, The Ottawa Hospital, Montfort Hospital, and Children's Hospital of Eastern Ontario. Several specialized hospital facilities are also present, such as the University of Ottawa Heart Institute and the Royal Ottawa Mental Health Centre. Nordion, i-Stat and the National Research Council of Canada and OHRI are part of the growing life science sector. Business, finance, administration, and sales and service rank high among types of occupations. Approximately ten percent of Ottawa's GDP is derived from finance, insurance and real estate whereas employment in goods-producing industries is only half the national average. The City of Ottawa is the second largest employer with over 15,000 employees.

In 2006, Ottawa experienced an increase of 40,000 jobs over 2001 with a five-year average growth that was relatively slower than in the late 1990s. While the number of employees in the federal government stagnated, the high-technology industry grew by 2.4%. The overall growth of jobs in Ottawa-Gatineau was 1.3% compared to the previous year, down to sixth place among Canada's largest cities. The unemployment rate in Ottawa-Gatineau was 5.2% (only in Ottawa: 5.1%), which was below the national average of 6.0%. The economic downturn resulted in an increase in the unemployment rate between April 2008 and April 2009 from 4.7 to 6.3%. In the province, however, this rate increased over the same period from 6.4 to 9.1%.

Traditionally the ByWard Market (in Lower Town), Parliament Hill and the Golden Triangle (both in Centretown – Downtown) have been the focal points of the cultural scenes in Ottawa. Modern thoroughfares such as Wellington Street, Rideau Street, Sussex Drive, Elgin Street, Bank Street, Somerset Street, Preston Street, Richmond Road in Westboro, and Sparks Street are home to many boutiques, museums, theatres, galleries, landmarks and memorials in addition to eating establishments, cafes, bars and nightclubs.

Ottawa hosts a variety of annual seasonal activities—such as Winterlude, the largest festival in Canada, and Canada Day celebrations on Parliament Hill and surrounding downtown area, as well as Bluesfest, Canadian Tulip Festival, Ottawa Dragon Boat Festival, Ottawa International Jazz Festival, Fringe Festival and Folk Music Festival, that have grown to become some of the largest festivals of their kind in the world. In 2010, Ottawa's Festival industry received the IFEA "World Festival and Event City Award" for the category of North American cities with a population between 500,000 and 1,000,000.

As Canada's capital, Ottawa has played host to a number of significant cultural events in Canadian history, including the first visit of the reigning Canadian sovereign—King George VI, with his consort, Queen Elizabeth—to his parliament, on 19 May 1939. VE Day was marked with a large celebration on 8 May 1945, the first raising of the country's new national flag took place on 15 February 1965, and the centennial of Confederation was celebrated on 1 July 1967. Elizabeth II was in Ottawa on 17 April 1982, to issue a royal proclamation of the enactment of the Constitution Act. In 1983, Prince Charles and Diana Princess of Wales came to Ottawa for a state dinner hosted by then Prime Minister Pierre Trudeau. In 2011, Ottawa was selected as the first city to receive Prince William, Duke of Cambridge, and Catherine, Duchess of Cambridge during their tour of Canada.

Influenced by government structures, much of the city's architecture tends to be formalistic and functional; however, the city is also marked by Romantic and Picturesque styles of architecture such as the Parliament Buildings' gothic revival architecture. Ottawa's domestic architecture is dominated by single family homes, but also includes smaller numbers of semi-detached houses, rowhouses, and apartment buildings. Many domestic buildings are clad in brick, with small numbers covered in wood, stone, or siding of different materials; variations are common, depending on neighbourhoods and the age of dwellings within them.

The skyline has been controlled by building height restrictions originally implemented to keep Parliament Hill and the Peace Tower at visible from most parts of the city. Today, several buildings are slightly taller than the Peace Tower, with the tallest located on Albert Street being the 29-storey Place de Ville (Tower C) at . Federal buildings in the National Capital Region are managed by Public Works Canada, while most of the federal land in the region is managed by the National Capital Commission; its control of much undeveloped land gives the NCC a great deal of influence over the city's development.

Amongst the city's national museums and galleries is the National Gallery of Canada; designed by famous architect Moshe Safdie, it is a permanent home to the Maman sculpture. The Canadian War Museum houses over 3.75 million artifacts and was moved to an expanded facility in 2005. The Canadian Museum of Nature was built in 1905, and underwent a major renovation between 2004 and 2010. Across the Ottawa river in Gatineau is the most visited museum in Canada, the Canadian Museum of History. Designed by Canadian Aboriginal architect Douglas Cardinal, the curving-shaped complex, built at a cost of 340 million USD, also houses the Canadian Children's Museum, the Canadian Postal Museum and a 3D IMAX theatre.

The city is also home to the Canada Agriculture Museum, the Canada Aviation and Space Museum, the Canada Science and Technology Museum, Billings Estate Museum, Bytown Museum, Canadian Museum of Contemporary Photography, the Bank of Canada Museum, and the Portrait Gallery of Canada.

The Ottawa Little Theatre, originally called the Ottawa Drama League at its inception in 1913, is the longest-running community theatre company in Ottawa. Since 1969, Ottawa has been the home of the National Arts Centre, a major performing arts venue that houses four stages and is home to the National Arts Centre Orchestra, the Ottawa Symphony Orchestra and Opera Lyra Ottawa. Established in 1975, the Great Canadian Theatre Company specializes in the production of Canadian plays at a local level.

The Rideau Canal is the oldest continuously operated canal system in North America, and in 2007, it was registered as a UNESCO World Heritage Site. In addition, 24 other National Historic Sites of Canada are in Ottawa, including: the Central Chambers, the Central Experimental Farm, the Château Laurier, Confederation Square, the former Ottawa Teachers' College, Office of the Prime Minister and Privy Council, Laurier House and the Parliament Buildings. Many other properties of cultural value have been designated as having "heritage elements" by the City of Ottawa under Part IV of the Ontario Heritage Act.

Sport in Ottawa has a history dating back to the 19th century. Ottawa is currently home to four professional sports teams. The Ottawa Senators are a professional ice hockey team playing in the National Hockey League. The Senators play their home games at the Canadian Tire Centre. The Ottawa Redblacks are a professional Canadian Football team playing in the Canadian Football League. Professional soccer club Ottawa Fury FC play in the United Soccer League, the second division in North American pro soccer after Major League Soccer. Both Ottawa Fury FC and the Ottawa Redblacks play their home games at TD Place Stadium. The Ottawa Champions play professional baseball in the Can-Am League at Raymond Chabot Grant Thornton Park, following the departure of the Lynx International League franchise. Several non-professional teams also play in Ottawa, including the Ottawa 67's junior ice hockey team. The city was previously home to a professional basketball team, the Ottawa SkyHawks, of the National Basketball League of Canada

Collegiate teams in various sports compete in Canadian Interuniversity Sport. The Carleton Ravens are nationally ranked in basketball, and the Ottawa Gee-Gees are nationally ranked in football and basketball. Algonquin College has also won numerous national championships. The city is home to an assortment of amateur organized team sports such as soccer, basketball, baseball, curling, rowing, hurling and horse racing. Casual recreational activities, such as skating, cycling, hiking, sailing, golfing, skiing, and fishing/ice fishing are also popular.

The City of Ottawa is a single-tier municipality, meaning it is in itself a census division and has no county or regional municipality government above it. As a single-tier municipality, Ottawa has responsibility for all municipal services, including fire, emergency medical services, police, parks, roads, sidewalks, public transit, drinking water, storm water, sanitary sewage and solid waste. Ottawa is governed by the 24-member Ottawa City Council consisting of 23 councillors each representing one ward and the mayor, currently Jim Watson, elected in a citywide vote.

Along with being the capital of Canada, Ottawa is politically diverse in local politics. Most of the city has traditionally supported the Liberal Party. Perhaps the safest areas for the Liberals are the ones dominated by Francophones, especially in Vanier and central Gloucester. Central Ottawa is usually more left-leaning, and the New Democratic Party have won ridings there. Some of Ottawa's suburbs are swing areas, notably central Nepean and, despite its francophone population, Orléans. The southern and western parts of the old city of Ottawa are generally moderate and swing to the Conservative Party. The farther one goes outside the city centre like to Kanata and Barrhaven and rural areas, the voters tend to be increasingly conservative, both fiscally and socially. This is especially true in the former Townships of West Carleton, Goulbourn, Rideau and Osgoode, which are more in line with the conservative areas in the surrounding counties. However, not all rural areas support the Conservative Party. Rural parts of the former township of Cumberland, with a large number of Francophones, traditionally support the Liberal Party, though their support has recently weakened.

At present, Ottawa is host to 130 embassies. A further 49 countries accredit their embassies and missions in the United States to Canada.

Ottawa is served by a number of airlines that fly into the Ottawa Macdonald–Cartier International Airport, as well as two main regional airports Gatineau-Ottawa Executive Airport, and Ottawa/Carp Airport. The city is also served by inter-city passenger rail service at the Ottawa Train Station by Via Rail, located near the Alta Vista neighbourhood, and inter-city bus service operating out of the Ottawa Bus Central Station.

OC Transpo, a department of the city, operates the public transit system. An integrated hub-and-spoke system of services consists of: regular buses traveling on fixed routes in mixed traffic, typical of most urban transit systems; a bus rapid transit (BRT) system which is a high-frequency bus service operating on the transitway (a network of mostly grade-separated dedicated bus lanes within their own right of way) and having full stations with Park & Ride facilities, further supported by on-road reserved bus lanes and priority traffic signal controls; a light rail transit (LRT) system known as the "O-Train" operating on one north-south route (the Trillium Line); and a door-to-door bus service for the disabled known as ParaTranspo. Both OC Transpo and the Quebec-based "Société de transport de l'Outaouais (STO)" operate bus services between Ottawa and Gatineau.

Construction is underway on the Confederation Line, a light-rail transit line (LRT), which includes a tunnel through the downtown area featuring three underground stations. The project broke ground in 2013, with operation scheduled to start in 2018. A further 30 kilometers and 19 stations will be built by 2023, referred to as the Stage 2 plan.

The city is served by two freeway corridors. The primary corridor is east-west and consists of provincial Highway 417 (designated as The Queensway) and Ottawa-Carleton Regional Road 174 (formerly Provincial Highway 17); a north-south corridor, Highway 416 (designated as Veterans' Memorial Highway), connects Ottawa to the rest of the 400-Series Highway network in Ontario at the 401. Highway 417 is also the Ottawa portion of the Trans-Canada Highway. The city also has several scenic parkways (promenades), such as Colonel By Drive, Queen Elizabeth Driveway, the Sir John A. Macdonald Parkway, Rockcliffe Parkway and the Aviation Parkway and has a freeway connection to Autoroute 5 and Autoroute 50, in Gatineau. In 2006, the National Capital Commission completed aesthetic enhancements to Confederation Boulevard, a ceremonial route of existing roads linking key attractions on both sides of the Ottawa River.

Numerous paved multi-use trails wind their way through much of the city, including along the Ottawa River, Rideau River, and Rideau Canal. These pathways are used for transportation, tourism, and recreation. Because many streets either have wide curb lanes or bicycle lanes, cycling is a popular mode of transportation throughout the year. As of 31 December 2015, 900 km of cycling facilities are found in Ottawa, including 435 km of multi use pathways, 8 km of cycle tracks, 200 km of on-road bicycle lanes, and 257 km of paved shoulders. 204 km of new cycling facilities were added between 2011 and 2014. A downtown street that is restricted to pedestrians only, Sparks Street was turned into a pedestrian mall in 1966. On Sundays (since 1960) and selected holidays and events additional avenues and streets are reserved for pedestrian and/or bicycle uses only. In May 2011, The NCC introduced the Capital Bixi bicycle-sharing system.

Ottawa is known as one of the most educated cities in Canada, with over half the population having graduated from college and/or university. Ottawa has the highest per capita concentration of engineers, scientists, and residents with PhDs in Canada.

The city has two main public universities:


Ottawa also has two main public colleges – Algonquin College and La Cité collégiale. It also has two Catholic universities – Dominican University College and Saint Paul University. Other colleges and universities in nearby areas (namely, the neighbouring city of Gatineau) include the University of Quebec en Outaouais, Cégep de l'Outaouais, and Heritage College.

Four main public school boards exist in Ottawa: English, English-Catholic, French, and French-Catholic. The English-language Ottawa-Carleton District School Board (OCDSB) is the largest board with 147 schools, followed by the English-Catholic Ottawa Catholic School Board with 85 schools. The two French-language boards are the French-Catholic "Conseil des écoles catholiques du Centre-Est" with 49 schools, and the French "Conseil des écoles publiques de l'Est de l'Ontario" with 37 schools. Ottawa also has numerous private schools which are not part of a board.

The Ottawa Public Library was created in 1906 as part of the famed Carnegie library system. The library system had 2.3 million items .

Three main daily local newspapers are printed in Ottawa: two English newspapers, the "Ottawa Citizen" established as "the Bytown Packet" in 1845 and the "Ottawa Sun", with weekly circulation of 900,197 and 274,628, respectively, and one French newspaper, "Le Droit". Another free commuter daily paper, "Metro Ottawa", was added in the 2000s. Several weekly and monthly community papers are also published, including the "Kitchissippi Times". Multiple Canadian television broadcast networks and systems, and an extensive number of radio stations, broadcast in both English and French.

In addition to the market's local media services, Ottawa is home to several national media operations, including CPAC (Canada's national legislature broadcaster) and the parliamentary bureau staff of virtually all of Canada's major newsgathering organizations in television, radio and print. The city is also home to the head office of the Canadian Broadcasting Corporation, although it is not the primary production location of most CBC radio or television programming.

Ottawa is twinned with:



</doc>
<doc id="22256" url="https://en.wikipedia.org/wiki?curid=22256" title="Objectivism (Ayn Rand)">
Objectivism (Ayn Rand)

Objectivism is a philosophical system developed by Russian-American writer Ayn Rand. Rand first expressed Objectivism in her fiction, most notably "The Fountainhead" (1943) and "Atlas Shrugged" (1957), and later in non-fiction essays and books. Leonard Peikoff, a professional philosopher and Rand's designated intellectual heir, later gave it a more formal structure. Rand described Objectivism as "the concept of man as a heroic being, with his own happiness as the moral purpose of his life, with productive achievement as his noblest activity, and reason as his only absolute". Peikoff characterizes Objectivism as a "closed system" that is not subject to change.

Objectivism's central tenets are that reality exists independently of consciousness, that human beings have direct contact with reality through sense perception (see "Direct and indirect realism"), that one can attain objective knowledge from perception through the process of concept formation and inductive logic, that the proper moral purpose of one's life is the pursuit of one's own happiness (see "Rational egoism"), that the only social system consistent with this morality is one that displays full respect for individual rights embodied in "laissez-faire" capitalism, and that the role of art in human life is to transform humans' metaphysical ideas by selective reproduction of reality into a physical form—a work of art—that one can comprehend and to which one can respond emotionally.

Academic philosophers have mostly ignored or rejected Rand's philosophy. Nonetheless, Objectivism has been a significant influence among libertarians and American conservatives. The Objectivist movement, which Rand founded, attempts to spread her ideas to the public and in academic settings.

Rand originally expressed her philosophical ideas in her novels, most notably, "The Fountainhead" and "Atlas Shrugged". She further elaborated on them in her periodicals "The Objectivist Newsletter", "The Objectivist", and "The Ayn Rand Letter", and in non-fiction books such as "Introduction to Objectivist Epistemology" and "The Virtue of Selfishness".

The name "Objectivism" derives from the idea that human knowledge and values are objective: they exist and are determined by the nature of reality, to be discovered by one's mind, and are not created by the thoughts one has. Rand stated that she chose the name because her preferred term for a philosophy based on the primacy of existence—"existentialism"—had already been taken.

Rand characterized Objectivism as "a philosophy for living on earth", grounded in reality, and aimed at defining human nature and the nature of the world in which we live.
Rand's philosophy begins with three axioms: existence, consciousness, and identity. Rand defined an axiom as "a statement that identifies the base of knowledge and of any further statement pertaining to that knowledge, a statement necessarily contained in all others whether any particular speaker chooses to identify it or not. An axiom is a proposition that defeats its opponents by the fact that they have to accept it and use it in the process of any attempt to deny it." As Objectivist philosopher Leonard Peikoff argued, Rand's argument for axioms "is not a proof that the axioms of existence, consciousness, and identity are true. It is proof that they are "axioms", that they are at the base of knowledge and thus inescapable."

Rand held that "existence" is the perceptually self-evident fact at the base of all other knowledge, i.e., that "existence exists." She further held that to be is to be "something", that "existence "is" identity." That is, to be is to be "an entity of a specific nature made of specific attributes." That which has no nature or attributes does not and cannot exist. The axiom of existence is grasped in differentiating something from nothing, while the law of identity is grasped in differentiating one thing from another, i.e., one's first awareness of the law of non-contradiction, another crucial base for the rest of knowledge. As Rand wrote, "A leaf ... cannot be all red and green at the same time, it cannot freeze and burn at the same time... A is A." Objectivism rejects belief in anything alleged to transcend existence.

Rand argued that consciousness is "the faculty of perceiving that which exists." As she put it, "to be conscious is to be conscious of "something"", that is consciousness itself cannot be distinguished or grasped except in relation to an independent reality. "It cannot be aware only of itself—there is no 'itself' until it is aware of something." Thus, Objectivism holds that the mind does not create reality, but rather, it is a means of discovering reality. Expressed differently, existence has "primacy" over consciousness, which must conform to it. Any other approach Rand termed "the primacy of consciousness", including any variant of metaphysical subjectivism or theism.

Objectivist philosophy derives its explanations of action and causation from the axiom of identity, calling causation "the law of identity applied to action." According to Rand, it is entities that act, and every action is the action of an entity. The way entities act is caused by the specific nature (or "identity") of those entities; if they were different they would act differently. As with the other axioms, an implicit understanding of causation is derived from one's primary observations of causal connections among entities even before it is verbally identified, and serves as the basis of further knowledge.

According to Rand, attaining knowledge beyond what is given in perception requires both volition (or the exercise of free will) and adherence to a specific method of validation through observation, concept-formation, and the application of inductive and deductive reasoning. For example, a belief in dragons, however sincere, does not mean reality contains any dragons. A process of proof identifying the basis in reality of a claimed item of knowledge is necessary to establish its truth.

Objectivist epistemology begins with the principle that "consciousness is identification". This is understood to be a direct consequence of the metaphysical principle that "existence is identity." Rand defined "reason" as "the faculty that identifies and integrates the material provided by man's senses." Says Rand, "The fundamental concept of method, the one on which all the others depend, is logic. The distinguishing characteristic of logic (the art of non-contradictory identification) indicates the nature of the actions (actions of consciousness required to achieve a correct identification) and their goal (knowledge)—while omitting the length, complexity or specific steps of the process of logical inference, as well as the nature of the particular cognitive problem involved in any given instance of using logic."

According to Rand, consciousness possesses a specific and finite identity, just like everything else that exists; therefore, it must operate by a specific method of validation. An item of knowledge cannot be "disqualified" by being arrived at by a specific process in a particular form. Thus, for Rand, the fact that consciousness must itself possess identity implies the rejection of both universal skepticism based on the "limits" of consciousness, as well as any claim to revelation, emotion or faith based belief.

Objectivist epistemology maintains that all knowledge is ultimately based on perception. "Percepts, not sensations, are the given, the self-evident." Rand considered the validity of the senses to be axiomatic, and claimed that purported arguments to the contrary all commit the fallacy of the "stolen concept" by presupposing the validity of concepts that, in turn, presuppose the validity of the senses. She held that perception, being physiologically determined, is incapable of error. For example, optical illusions are errors in the conceptual identification of what is seen, not errors in sight itself. The validity of sense perception, therefore, is not susceptible to proof (because it is presupposed by all proof as proof is only a matter of adducing sensory evidence) nor should its validity be denied (since the conceptual tools one would have to use to do this are derived from sensory data). Perceptual error, therefore, is not possible. Rand consequently rejected epistemological skepticism, as she holds that the skeptics' claim to knowledge "distorted" by the form or the means of perception is impossible.

The Objectivist theory of perception distinguishes between the "form" and "object." The form in which an organism perceives is determined by the physiology of its sensory systems. Whatever form the organism perceives it in, what it perceives—the object of perception—is reality. Rand consequently rejected the Kantian dichotomy between "things as we perceive them" and "things as they are in themselves." Says Rand, "The attack on man's consciousness and particularly on his conceptual faculty has rested on the unchallenged premise that any knowledge acquired by a "process" of consciousness is necessarily subjective and cannot correspond to the facts of reality, since it is ""processed" knowledge...[but] all knowledge "is" processed knowledge—whether on the sensory, perceptual or conceptual level. An "unprocessed" knowledge would be a knowledge acquired without means of cognition."

The aspect of epistemology given the most elaboration by Rand is the theory of concept-formation, which she presented in "Introduction to Objectivist Epistemology". She argued that concepts are formed by a process of measurement omission. Peikoff described her view as follows:

According to Rand, "[T]he term 'measurements omitted' does not mean, in this context, that measurements are regarded as non-existent; it means that "measurements exist, but are not specified". That measurements "must" exist is an essential part of the process. The principle is: the relevant measurements must exist in "some" quantity, but may exist in "any" quantity."

Rand argued that concepts are hierarchically organized. Concepts such as 'dog,' which bring together "concretes" available in perception, can be differentiated (into the concepts of 'dachshund,' 'poodle,' etc.) or integrated (along with 'cat,' etc., into the concept of 'animal'). Abstract concepts such as 'animal' can be further integrated, via "abstraction from abstractions", into such concepts as 'living thing.' Concepts are formed in the context of knowledge available. A young child differentiates dogs from cats and chickens, but need not explicitly differentiate them from deep-sea tube worms, or from other types of animals not yet known to him, to form a concept 'dog.'

Because of its view of concepts as "open-ended" classifications that go well beyond the characteristics included in their past or current definitions, Objectivist epistemology rejects the analytic-synthetic distinction as a false dichotomy and denies the possibility of "a priori" knowledge.

Rand rejected "feeling" as sources of knowledge. Rand acknowledged the importance of emotion for human beings, but she maintained that emotions are a consequence of the conscious or subconscious ideas that a person already accepts, not a means of achieving awareness of reality. "Emotions are not tools of cognition." Rand also rejected all forms of faith or mysticism, terms that she used synonymously. She defined faith as "the acceptance of allegations without evidence or proof, either apart from or "against" the evidence of one's senses and reason... Mysticism is the claim to some non-sensory, non-rational, non-definable, non-identifiable means of knowledge, such as 'instinct,' 'intuition,' 'revelation,' or any form of 'just knowing.'" Reliance on revelation is like reliance on a Ouija board; it bypasses the need to show how it connects its results to reality. Faith, for Rand, is not a "short-cut" to knowledge, but a "short-circuit" destroying it.

Objectivism acknowledges the facts that human beings have limited knowledge, are vulnerable to error, and do not instantly understand all of the implications of their knowledge. According to Peikoff, one can be certain of a proposition if all of the available evidence supports it, i.e., it can be logically integrated with the rest of one's knowledge; one is then certain within the context of the evidence.

Rand rejected the traditional rationalist/empiricist dichotomy, arguing that it embodies a false alternative: conceptually-based knowledge independent of perception (rationalism) versus perceptually-based knowledge independent of concepts (empiricism). Rand argued that neither is possible because the senses provide the material of knowledge while conceptual processing is also needed to establish knowable propositions.

The philosopher John Hospers, who was influenced by Rand and shared her moral and political views, disagreed with her over issues of epistemology. Some philosophers, such as Tibor Machan, have argued that the Objectivist epistemology is incomplete.

Psychology professor Robert L. Campbell says the relationship between Objectivist epistemology and cognitive science remains unclear because Rand made claims about human cognition and its development which belong to psychology, yet Rand also argued that philosophy is logically prior to psychology and in no way dependent on it.

The philosophers Randall Dipert and Roderick Long have argued that Objectivist epistemology conflates the perceptual process by which judgments are formed with the way in which they are to be justified, thereby leaving it unclear how sensory data can validate propositionally structured judgments.

Objectivism includes an extensive treatment of ethical concerns. Rand wrote on morality in her works "The Virtue of Selfishness," "We the Living," and "Atlas Shrugged". Rand defines morality as "a code of values to guide man's choices and actions—the choices and actions that determine the purpose and the course of his life." Rand maintained that the first question is not what should the code of values be, the first question is "Does man need values at all—and why?" According to Rand, "it is only the concept of 'Life' that makes the concept of 'Value' possible," and, "the fact that a living entity "is", determines what it "ought" to do." Rand writes: "there is only one fundamental alternative in the universe: existence or non-existence—and it pertains to a single class of entities: to living organisms. The existence of inanimate matter is unconditional, the existence of life is not: it depends on a specific course of action... It is only a living organism that faces a constant alternative: the issue of life or death..."

Rand argued that the primary focus of man's free will is in the choice: 'to think or not to think'. "Thinking is not an automatic function. In any hour and issue of his life, man is free to think or to evade that effort. Thinking requires a state of full, focused awareness. The act of focusing one's consciousness is volitional. Man can focus his mind to a full, active, purposefully directed awareness of reality—or he can unfocus it and let himself drift in a semiconscious daze, merely reacting to any chance stimulus of the immediate moment, at the mercy of his undirected sensory-perceptual mechanism and of any random, associational connections it might happen to make." According to Rand, therefore, possessing free will, human beings must "choose" their values: one does not "automatically" hold one's own life as his ultimate value. Whether in fact a person's actions promote and fulfill his own life or not is a question of fact, as it is with all other organisms, but whether a person will act to promote his well-being is up to him, not hard-wired into his physiology. "Man has the power to act as his own destroyer—and that is the way he has acted through most of his history."

Says Rand, "Man's mind is his basic tool of survival. Life is given to him, survival is not. His body is given to him, its sustenance is not. His mind is given to him, its content is not. To remain alive he must act and before he can act he must know the nature and purpose of his action. He cannot obtain his food without knowledge of food and of the way to obtain it. He cannot dig a ditch—or build a cyclotron—without a knowledge of his aim and the means to achieve it. To remain alive, he must think." In her novels, "The Fountainhead" and "Atlas Shrugged", she also emphasizes the central importance of productive work, romantic love and art to human happiness, and dramatizes the ethical character of their pursuit. The primary virtue in Objectivist ethics is rationality, as Rand meant it "the recognition and acceptance of reason as one's only source of knowledge, one's only judge of values and one's only guide to action."

The purpose of a moral code, Rand held, is to provide the principles by reference to which man can achieve the values his survival requires. Rand summarizes:

Rand's explanation of values presents the view that an individual's primary moral obligation is to achieve his own well-being—it is for his life and his self-interest that an individual ought to adhere to a moral code. Ethical egoism is a corollary of setting man's life as the moral standard. Rand believed that rational egoism is the logical consequence of humans following evidence wherever it leads them. The only alternative would be that they live without orientation to reality.

A corollary to Rand's endorsement of self-interest is her rejection of the ethical doctrine of altruism—which she defined in the sense of Auguste Comte's altruism (he coined the term), as a moral obligation to live for the sake of others. Rand also rejected subjectivism. A "whim-worshiper" or "hedonist," according to Rand, is not motivated by a desire to live his own human life, but by a wish to live on a sub-human level. Instead of using "that which promotes my (human) life" as his standard of value, he mistakes "that which I (mindlessly happen to) value" for a standard of value, in contradiction of the fact that, existentially, he is a human and therefore rational organism. The "I value" in whim-worship or hedonism can be replaced with "we value," "he values," "they value," or "God values," and still it would remain dissociated from reality. Rand repudiated the equation of rational selfishness with hedonistic or whim-worshiping "selfishness-without-a-self." She held that the former is good, and the latter evil, and that there is a fundamental difference between them.

For Rand, all of the principal virtues are applications of the role of reason as man's basic tool of survival: rationality, honesty, justice, independence, integrity, productiveness, and pride—each of which she explains in some detail in "The Objectivist Ethics." The essence of Objectivist ethics is summarized by the oath her "Atlas Shrugged" character John Galt adhered to: "I swear—by my life and my love of it—that I will never live for the sake of another man, nor ask another man to live for mine."

Many philosophers have criticized Objectivist ethics. The philosopher Robert Nozick argues that Rand's foundational argument in ethics is unsound because it does not explain why someone could not rationally prefer dying and having no values. He argues that her attempt to defend the morality of selfishness is, therefore, an instance of begging the question. Nozick also argues that Rand's solution to David Hume's famous is-ought problem is unsatisfactory. In response, the philosophers Douglas B. Rasmussen and Douglas Den Uyl have argued that Nozick misstated Rand's case.

Charles King criticized Rand's example of an indestructible robot to demonstrate the value of life as incorrect and confusing. In response, Paul St. F. Blair defended Rand's ethical conclusions, while maintaining that his arguments might not have been approved by Rand.

Rand's defense of individual liberty integrates elements from her entire philosophy. Since reason is the means of human knowledge, it is therefore each person's most fundamental means of survival and is necessary to the achievement of values. The use or threat of force neutralizes the practical effect of an individual's reason, whether the force originates from the state or from a criminal. According to Rand, "man's mind will not function at the point of a gun." Therefore, the only type of organized human behavior consistent with the operation of reason is that of voluntary cooperation. Persuasion is the method of reason. By its nature, the overtly irrational cannot rely on the use of persuasion and must ultimately resort to force to prevail. Thus, Rand saw reason and freedom as correlates, just as she saw mysticism and force as corollaries. Based on this understanding of the role of reason, Objectivists hold that the initiation of physical force against the will of another is immoral, as are indirect initiations of force through threats, fraud, or breach of contract. The use of defensive or retaliatory force, on the other hand, is appropriate.

Objectivism holds that because the opportunity to use reason without the initiation of force is necessary to achieve moral values, each individual has an inalienable moral right to act as his own judgment directs and to keep the product of his effort. Peikoff, explaining the basis of rights, stated, "In content, as the founding fathers recognized, there is one fundamental right, which has several major derivatives. The fundamental right is the right to life. Its major derivatives are the right to liberty, property, and the pursuit of happiness." "A 'right' is a moral principle defining and sanctioning a man's freedom of action in a social context." These rights are specifically understood to be rights to action, not to specific results or objects, and the obligations created by rights are negative in nature: each individual must refrain from violating the rights of others. Objectivists reject alternative notions of rights, such as positive rights, collective rights, or animal rights. Objectivism holds that the only social system which fully recognizes individual rights is capitalism, specifically what Rand described as "full, pure, uncontrolled, unregulated laissez-faire capitalism." Objectivism regards capitalism as the social system which is most beneficial to the poor, but does not consider this its primary justification. Rather, it is the only moral social system. Objectivism maintains that only societies seeking to establish freedom (or free nations) have a right to self-determination.

Objectivism views government as "the means of placing the retaliatory use of physical force under objective control—i.e., under objectively defined laws;" thus, government is both legitimate and critically important in order to protect individual rights. Rand opposed anarchism because she saw putting police and courts on the market as an inherent miscarriage of justice. Objectivism holds that the proper functions of a government are ""the police", to protect men from criminals—"the armed services", to protect men from foreign invaders—"the law courts", to settle disputes among men according to objectively defined laws," the executive, and legislatures. Furthermore, in protecting individual rights, the government is acting as an agent of its citizens and "has no rights except the rights "delegated" to it by the citizens" and it must act in an impartial manner according to specific, objectively defined laws. Prominent Objectivists Peikoff and Yaron Brook have since expressed support for other government functions.

Rand argued that limited intellectual property monopolies being granted to certain inventors and artists on a first-to-file basis are moral because she viewed all property as fundamentally intellectual. Furthermore, the value of a commercial product comes in part from the necessary work of its inventors. However, Rand viewed limits on patents and copyrights as important and held that if they were granted in perpetuity, it would necessarily lead to "de facto" collectivism.

Rand opposed racism and any legal application of racism. She considered affirmative action to be an example of legal racism. Rand advocated the right to legal abortion. Rand believed capital punishment is morally justified as retribution against a murderer, but dangerous due to the risk of mistakenly executing innocent people and opening the door to state murder. She therefore said she opposed capital punishment "on epistemological, not moral, grounds." She opposed involuntary military conscription. She opposed any form of censorship, including legal restrictions on pornography, opinion or worship, famously quipping; "In the transition to statism, every infringement of human rights has begun with a given right's least attractive practitioners".

Objectivists have also opposed a number of government activities commonly supported by both liberals and conservatives, including antitrust laws, the minimum wage, public education, and existing child labor laws. Objectivists have argued against faith-based initiatives, displaying religious symbols in government facilities, and the teaching of "intelligent design" in public schools. Maintaining that it should be phased out gradually, Rand opposed taxation as she considered it theft and an endorsement of force over reason.

Some critics, including economists and political philosophers such as, Murray Rothbard, David D. Friedman, Roy Childs, Norman P. Barry, and Chandran Kukathas, have argued that Objectivist ethics are consistent with anarcho-capitalism instead of minarchism.

The Objectivist theory of art flows from its epistemology, by way of "psycho-epistemology" (Rand's term for an individual's characteristic mode of functioning in acquiring knowledge). Art, according to Objectivism, serves a human cognitive need: it allows human beings to grasp concepts as though they were percepts. Objectivism defines "art" as a "selective re-creation of reality according to an artist's metaphysical value-judgments"—that is, according to what the artist believes to be ultimately true and important about the nature of reality and humanity. In this respect Objectivism regards art as a way of presenting abstractions concretely, in perceptual form.

The human need for art, on this view, stems from the need for cognitive economy. A concept is already a sort of mental shorthand standing for a large number of concretes, allowing a human being to think indirectly or implicitly of many more such concretes than can be held explicitly in mind. But a human being cannot hold indefinitely many concepts explicitly in mind either—and yet, on the Objectivist view, needs a comprehensive conceptual framework to provide guidance in life. Art offers a way out of this dilemma by providing a perceptual, easily grasped means of communicating and thinking about a wide range of abstractions, including one's metaphysical value-judgments. Objectivism regards art as an effective way to communicate a moral or ethical ideal. Objectivism does not, however, regard art as propagandistic: even though art involves moral values and ideals, its purpose is not to educate, only to show or project. Moreover, art need not be, and usually is not, the outcome of a full-blown, explicit philosophy. Usually it stems from an artist's "sense of life" (which is preconceptual and largely emotional).

The end goal of Rand's own artistic endeavors was to portray the ideal man. "The Fountainhead" is the best example of this effort. Rand uses the character of Roark to embody the concept of the higher man which she believes is what great art should do - embody the characteristics of the best of humanity. This higher symbolism should be represented in all art; artistic expression should be an extension of the greatness in humanity.

Rand held that Romanticism was the highest school of literary art, noting that Romanticism was "based on the recognition of the principle that man possesses the faculty of volition," absent which, Rand believed, literature is robbed of dramatic power, adding:

The term "romanticism," however, is often affiliated with emotionalism, to which Objectivism is completely opposed. Historically, many romantic artists were philosophically subjectivist. Most Objectivists who are also artists subscribe to what they call romantic realism, which is how Rand labeled her own work.

Several authors have developed and applied Rand's ideas in their own work. Rand described Peikoff's "The Ominous Parallels" (1982), as "the first book by an Objectivist philosopher other than myself." In 1991, Peikoff published "", a comprehensive exposition of Rand's philosophy. Chris Matthew Sciabarra discusses Rand's ideas and theorizes about their intellectual origins in "" (1995). Surveys such as "On Ayn Rand" by Allan Gotthelf (1999), "Ayn Rand" by Tibor R. Machan (2000), and "Objectivism in One Lesson" by Andrew Bernstein (2009) provide briefer introductions to Rand's ideas.

Some scholars have focused on applying Objectivism in more specific areas. Machan has developed Rand's contextual conception of human knowledge (while also drawing on the insights of J. L. Austin and Gilbert Harman) in works such as "Objectivity" (2004), and David Kelley has explicated Rand's epistemological ideas in works such as "The Evidence of the Senses" (1986) and "A Theory of Abstraction" (2001). In the field of ethics, Kelley has argued in works such as "Unrugged Individualism" (1996) and "The Contested Legacy of Ayn Rand" (2000) that Objectivists should pay more attention to the virtue of benevolence and place less emphasis on issues of moral sanction. Kelley's views have been controversial, and critics Peikoff and Peter Schwartz have argued that he contradicts important principles of Objectivism. Kelley has used the term "Open Objectivism" for a version of Objectivism that involves "a commitment to reasoned, non-dogmatic discussion and debate," "the recognition that Objectivism is open to expansion, refinement, and revision," and "a policy of benevolence toward others, including fellow-travelers and critics." Arguing against Kelley, Peikoff characterized Objectivism as a "closed system" that is not subject to change.

An author who focuses on Rand's ethics, Tara Smith, stays closer to Rand's original ideas in such works as "Moral Rights and Political Freedom" (1995), "Viable Values" (2000), and "Ayn Rand's Normative Ethics" (2006). In collaboration with Peikoff, David Harriman has developed a theory of scientific induction based upon Rand's theory of concepts in "The Logical Leap: Induction in Physics" (2010).

The political aspects of Rand's philosophy are discussed by Bernstein in "The Capitalist Manifesto" (2005). In "Capitalism: A Treatise on Economics" (1996), George Reisman attempts to integrate Objectivist methodology and insights with both Classical and Austrian economics. In psychology, Professor Edwin A. Locke and Ellen Kenner have explored Rand's ideas in "The Selfish Path to Romance: How to Love with Passion & Reason". Other writers have explored the application of Objectivism to fields ranging from art, as in "What Art Is" by Louis Torres and Michelle Marder Kamhi (2000), to teleology, as in "The Biological Basis of Teleological Concepts" by Harry Binswanger (1990).

According to one Rand biographer, most people first read Rand's works in their "formative years." Rand's former protégé Nathaniel Branden referred to Rand's "especially powerful appeal to the young," while Onkar Ghate of the Ayn Rand Institute said Rand "appeals to the idealism of youth." This appeal has alarmed a number of critics of the philosophy. Many of these young people later abandon their positive view of Rand and are often said to have "outgrown" her ideas. Supporters of Rand's work recognize the phenomenon, but attribute it to the loss of youthful idealism and inability to resist social pressures for intellectual conformity. In contrast, historian Jennifer Burns, writing in "Goddess of the Market" (2009), says some critics "dismiss Rand as a shallow thinker appealing only to adolescents," although she thinks the critics "miss her significance" as a "gateway drug" to right-wing politics.

Academic philosophers have generally dismissed Objectivism since Rand first presented it. Objectivism has been called "fiercely anti-academic" because of Rand's criticism of contemporary intellectuals. David Sidorsky, a professor of moral and political philosophy at Columbia University, says Rand's work is "outside the mainstream" and is more of an ideological movement than a well-grounded philosophy. British philosopher Ted Honderich notes that he deliberately excluded an article on Rand from "The Oxford Companion to Philosophy" (Rand is, however, mentioned in the article on popular philosophy by Anthony Quinton). Rand is the subject of entries in the "Stanford Encyclopedia of Philosophy", "The Dictionary of Modern American Philosophers", the "Internet Encyclopedia of Philosophy", "The Routledge Dictionary of Twentieth-Century Political Thinkers", and "The Penguin Dictionary of Philosophy". A listing of Rand also appears in the "Routledge Encyclopedia of Philosophy", featuring the assessment, "The influence of Rand's ideas was strongest among college students in the USA but attracted little attention from academic philosophers. Her outspoken defense of capitalism in works like "" (1967), and her characterization of her position as a defence of the 'virtue of selfishness' in her essay collection of the same title published in 1964, also brought notoriety, but kept her out of the intellectual mainstream."

In recent decades Rand's works are more likely to be encountered in the classroom. The Ayn Rand Society, dedicated to fostering the scholarly study of Objectivism, is affiliated with the American Philosophical Association's Eastern Division. Aristotle scholar and Objectivist Allan Gotthelf, late chairman of the Society, and his colleagues argued for more academic study of Objectivism, viewing the philosophy as a unique and intellectually interesting defense of classical liberalism that is worth debating. In 1999, a refereed "Journal of Ayn Rand Studies" began. In 2006, the University of Pittsburgh held a conference focusing on Objectivism. Programs and fellowships for the study of Objectivism have been supported at the University of Pittsburgh, University of Texas at Austin and University of North Carolina at Chapel Hill.




</doc>
