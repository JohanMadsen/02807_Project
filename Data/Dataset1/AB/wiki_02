<doc id="13224" url="https://en.wikipedia.org/wiki?curid=13224" title="History of Germany">
History of Germany

The concept of Germany as a distinct region in central Europe can be traced to Roman commander Julius Caesar, who referred to the unconquered area east of the Rhine as "Germania", thus distinguishing it from Gaul (France), which he had conquered. The victory of the Germanic tribes in the Battle of the Teutoburg Forest (AD 9) prevented annexation by the Roman Empire, although the Roman provinces of Germania Superior and Germania Inferior were established along the Rhine. Following the Fall of the Western Roman Empire, the Franks conquered the other West Germanic tribes. When the Frankish Empire was divided among Charles the Great's heirs in 843, the eastern part became East Francia. In 962, Otto I became the first Holy Roman Emperor of the Holy Roman Empire, the medieval German state.

In the Late Middle Ages, the regional dukes, princes and bishops gained power at the expense of the emperors. Martin Luther led the Protestant Reformation against the Catholic Church after 1517, as the northern states became Protestant, while the southern states remained as the Catholics. The two parts of the Holy Roman Empire clashed in the Thirty Years' War (1618–1648), which was ruinous to the twenty million civilians living in both parts. The Thirty Years' War brought tremendous destruction to Germany; more than 1/4 of the population and 1/2 of the male population in the German states were killed by the catastrophic war. 1648 marked the effective end of the Holy Roman Empire and the beginning of the modern nation-state system, with Germany divided into numerous independent states, such as Prussia, Bavaria, Saxony, Austria and other states, which also controlled land outside of the area considered as "Germany".

After the French Revolution and the Napoleonic Wars from 1803–1815, feudalism fell away and liberalism and nationalism clashed with reaction. The German revolutions of 1848–49 failed. The Industrial Revolution modernized the German economy, led to the rapid growth of cities and to the emergence of the Socialist movement in Germany. Prussia, with its capital Berlin, grew in power. German universities became world-class centers for science and humanities, while music and art flourished. The Unification of Germany (excluding Austria and the German-speaking areas of Switzerland) was achieved under the leadership of the Chancellor Otto von Bismarck with the formation of the German Empire in 1871 which solved the "Kleindeutsche Lösung", the small Germany solution (Germany without Austria), or "Großdeutsche Lösung", the greater Germany solution (Germany with Austria), the former prevailing. The new "Reichstag", an elected parliament, had only a limited role in the imperial government. Germany joined the other powers in colonial expansion in Africa and the Pacific.

Germany was the dominant power on the continent. By 1900, its rapidly expanding industrial economy passed Britain's, allowing a naval race. Germany led the Central Powers in World War I (1914–1918) against France, Great Britain, Russia and (by 1917) the United States. Defeated and partly occupied, Germany was forced to pay war reparations by the Treaty of Versailles and was stripped of its colonies as well as areas given to re-established Poland and Alsace-Lorraine. The German Revolution of 1918–19 deposed the emperor and the various kings and princes, leading to the establishment of the Weimar Republic, an unstable parliamentary democracy.

In the early 1930s, the worldwide Great Depression hit Germany hard, as unemployment soared and people lost confidence in the government. In January 1933, Adolf Hitler was appointed Chancellor of Germany. The Nazi Party then began to eliminate all political opposition and consolidate its power. Hitler quickly established a totalitarian regime. Beginning in the late 1930s, Nazi Germany made increasingly aggressive territorial demands, threatening war if they were not met. First came the remilitarization of the Rhineland in 1936, the annexing of Austria in the "Anschluss" and parts of Czechoslovakia with the Munich Agreement in 1938 (although in 1939 Hitler annexed further territory of Czechoslovakia). On 1 September 1939, Germany initiated World War II in Europe with the invasion of Poland. After forming a pact with the Soviet Union in 1939, Hitler and Stalin divided Eastern Europe. After a "Phoney War" in spring 1940, the Germans swept Denmark and Norway, the Low Countries and France, giving Germany control of nearly all of Western Europe. Hitler invaded the Soviet Union in June 1941.

Racism, especially antisemitism, was a central feature of the regime. In Germany, but predominantly in the German-occupied areas, the systematic genocide program known as The Holocaust killed six million Jews, as well as five million others including German dissidents, gipsies, disabled people, Poles, Romanies, Soviets (Russian and non-Russian), and others. In 1942, the German invasion of the Soviet Union faltered, and after the United States had entered the war, Britain became the base for massive Anglo-American bombings of German cities. Germany fought the war on multiple fronts through 1942–1944, however following the Allied invasion of Normandy (June 1944), the German Army was pushed back on all fronts until the final collapse in May 1945.

Under occupation by the Allies, German territories were split up, Austria was again made a separate country, denazification took place, and the Cold War resulted in the division of the country into democratic West Germany and communist East Germany. Millions of ethnic Germans were deported or fled from Communist areas into West Germany, which experienced rapid economic expansion, and became the dominant economy in Western Europe. West Germany was rearmed in the 1950s under the auspices of NATO, but without access to nuclear weapons. The Franco-German friendship became the basis for the political integration of Western Europe in the European Union. In 1989, the Berlin Wall was destroyed, the Soviet Union collapsed and East Germany was reunited with West Germany in 1990. In 1998–1999, Germany was one of the founding countries of the eurozone. Germany remains one of the economic powerhouses of Europe, contributing about one quarter of the eurozone's annual gross domestic product. In the early 2010s, Germany played a critical role in trying to resolve the escalating euro crisis, especially with regard to Greece and other Southern European nations. In the middle of the decade, the country faced the European migrant crisis, as the main receiver of asylum seekers from Syria and other troubled regions.

"For more events, see Timeline of German history."

The discovery of the Mauer 1 mandible in 1907 shows that ancient humans were present in Germany at least 600,000 years ago. The oldest complete hunting weapons ever found anywhere in the world were discovered in a coal mine in Schoningen, Germany in 1995 where three 380,000-year-old wooden javelins 6–7.5 feet (1.8–2.3 meter) long were unearthed. The Neander valley in Germany was the location where the first ever non-modern human fossil was discovered and recognised in 1856; the new species of human was named Neanderthal man. The Neanderthal 1 fossils are now known to be 40,000 years old. At a similar age, evidence of modern humans has been found in caves in the Swabian Jura near Ulm. The finds include 42,000-year-old bird bone and mammoth ivory flutes which are the oldest musical instruments ever found, the 40,000-year-old Ice Age Löwenmensch figurine which is the oldest uncontested figurative art ever discovered, and the 35,000-year-old Venus of Hohle Fels which is the oldest uncontested human figurative art ever discovered.

The ethnogenesis of the Germanic tribes is assumed to have occurred during the Nordic Bronze Age, or at the latest during the Pre-Roman Iron Age. From their homes in southern Scandinavia and northern Germany the tribes began expanding south, east and west in the 1st century BC, coming into contact with the Celtic tribes of Gaul, as well as with Iranian, Baltic, and Slavic cultures in Central/Eastern Europe.

Researchers know few details of early Germanic activity, except through the tribes' recorded interactions with the Roman Empire, through etymological research and from archaeological finds.

In the first years of the 1st century AD Roman legions conducted a long campaign in Germania, the area north of the Upper Danube and east of the Rhine, in an attempt to expand the Empire's frontiers and to shorten its frontier line. Rome subdued several Germanic tribes, such as the Cherusci. The tribes became familiar with Roman tactics of warfare while maintaining their tribal identity. In 9 AD a Cherusci chieftain known to the Romans as Arminius defeated a Roman army in the Battle of the Teutoburg Forest, a victory credited with stopping the Roman advance into Germanic territories and marking the beginning of recorded German history. That part of the territory of modern Germany that lay east of the Rhine remained outside the Roman Empire. By AD 100, the time of Tacitus's "Germania", Germanic tribes had settled along the Roman frontier along the Rhine and the Danube (the "Limes Germanicus"), occupying most of the area of modern Germany; however, imperial Rome organised territory later included in the modern states of Austria, Baden-Württemberg, southern Bavaria, southern Hesse, Saarland and the Rhineland as Roman provinces (Noricum, Raetia, and Germania). The Roman provinces in western Germany, Germania Inferior (with the capital situated at Colonia Claudia Ara Agrippinensium, modern Cologne) and Germania Superior (with its capital at Mogontiacum, modern Mainz), were formally established in 85 AD, after a long period of military occupation beginning in the reign of the Roman emperor Augustus (27 BC – 14 AD).

The 3rd century saw the emergence of a number of large West Germanic tribes: the Alamanni, Franks, Bavarii, Chatti, Saxons, Frisii, Sicambri, and Thuringii. Around 260 the Germanic peoples broke through the "limes" and the Danube frontier into Roman-controlled lands.

Seven large German-speaking tribes – the Visigoths, Ostrogoths, Vandals, Burgundians, Lombards, Saxons and Franks – moved west and witnessed the decline of the Roman Empire and the transformation of the old Western Roman Empire.

Christianity was spread to western Germany during the Roman era, and Christian religious structures such as the Aula Palatina of Trier were built during the reign of Constantine I (r. (306–337 AD). At the end of the 4th century the Huns invaded the unoccupied part of present-day Germany and the Migration Period began. Hunnic hegemony over Germania lasted until the death of Attila's son Dengizich in 469.

Stem duchies (tribal duchies) in Germany originated as the areas of the Germanic tribes of a given region. The concept of such duchies survived especially in the areas which in the mid-9th century would become part of East Francia (for example: Bavaria, Swabia, Saxony, Franconia, Thuringia) rather than further west in Middle Francia (for example: Burgundy, Lorraine

In the 5th century, the "Völkerwanderung" (or Germanic migrations) brought a number of "barbarian" tribes into the failing Roman Empire. Tribes that became stem duchies were originally the Alamanni, the Thuringii, the Saxons, the Franks, the Burgundians, and the Rugii.
In contrast to later duchies, these entities did not have strictly delineated administrative boundaries, but approximated the area of settlement of major Germanic tribes. Over the next few centuries, some tribes warred, migrated, and merged. Eventually the Franks subjugated all these tribes in Germania. However, remnants of several stem duchies survive today as states or regions in modern Western Europe countries: German states such as Bavaria and Saxony, German regions like Swabia, and French "région"s such as of Burgundy/Franche-Comté and Lorraine.

In the east, successive rulers of the German lands founded a series of border counties or marches. To the north, these included Lusatia, the North March (which would become Brandenburg and the heart of the future Prussia), and the Billung March. In the south, the marches included Carniola, Styria, and the March of Austria that would become Austria.

After the fall of the Western Roman Empire in the 5th century, the Franks, like other post-Roman Western Europe, emerged as a tribal confederacy in the Rhine-Weser region referred to as "Austrasia," now Franconia. They absorbed much former Roman territory as they spread west into Gaul beginning in 250, unlike the Alamanni to their south in Swabia. By 500, the Frankish king Clovis I, of the Merovingian dynasty, had united the Frankish tribes and ruled all of Gaul, and was proclaimed king some time from 509 to 511. Clovis also, contrary to the tradition of Germanic rulers of the time, was baptized directly into Roman Catholicism and not Arianism, and his successors would work closely with papal missionaries, among them Saint Boniface. The faith of the Franks, the vast size of Francia, and the Franks' control of the passes through the Alps led to the alliance between the Merovingian realm, which by 750 now extended Gaul and north-western Germany to include Swabia, Burgundy (and western Switzerland by extension), with the Pope in Rome against the Lombards, whom now posed the greatest threat to the Holy See. A Papal envoy was sent to Charles Martel, Mayor of the Palace, in 732 following his victory at the Battle of Tours, though this alliance would lapse with Charles' death and be renewed after the Frankish Civil War.

The Merovingian kings of the Germanic Franks conquered northern Gaul in 486 AD. Swabia became a duchy under the Frankish Empire in 496, following the Battle of Tolbiac; in 530 the Saxons and the Franks destroyed the Kingdom of Thuringia. In the 5th and 6th centuries the Merovingian kings conquered several other Germanic tribes and kingdoms. King Chlothar I (reigned 558–561) ruled the greater part of what is now Germany and made expeditions into Saxony, while the Southeast of modern Germany remained under the influence of the Ostrogoths. Saxons inhabited the area down to the Unstrut River.

The Merovingians placed the various regions of their Frankish Empire under the control of semi-autonomous dukes – Franks or local rulers. Frankish colonists were encouraged to move to the newly conquered territories. While allowed to preserve their own laws, the local Germanic tribes faced pressure to adopt non-Arian Christianity.

The territories which would later become parts of modern Germany came under the region of Austrasia (meaning "eastern land"), the northeastern portion of the Kingdom of the Merovingian Franks. As a whole, Austrasia comprised parts of present-day France, Germany, Belgium, Luxembourg and the Netherlands. After the death of the Frankish king Clovis I in 511, his four sons partitioned his kingdom including Austrasia. Authority over Austrasia passed back and forth from autonomy to royal subjugation, as successive Merovingian kings alternately united and subdivided the Frankish lands.

In 718 Charles Martel, the Frankish Mayor of the Palace, made war against Saxony because of its help for the Neustrians. His son Carloman started a new war against Saxony in 743, because the Saxons gave aid to Duke Odilo of Bavaria.

In 751 Pippin III, Mayor of the Palace under the Merovingian king, himself assumed the title of king and was anointed by the Church. Now the Frankish kings were set up as protectors of the pope, and Charles the Great (who ruled the Franks from 774 to 814) launched a decades-long military campaign against the Franks' heathen rivals, the Saxons and the Avars. The campaigns and insurrections of the Saxon Wars lasted from 772 to 804. The Franks eventually overwhelmed the Saxons and Avars, forcibly converted the people to Christianity, and annexed their lands to the Carolingian Empire.

After the death of Frankish king Pepin the Short in 768, his oldest son "Charlemagne" ("Charles the Great") consolidated his power over and expanded the Kingdom. In 773-74, Charlemagne ended 200 years of Royal Lombard rule with the Siege of Pavia, and installed himself as King of the Lombards and loyal Frankish nobles replaced the old Lombard elite following a rebellion in 776. The next 30 years of his reign were spent ruthlessly strengthening his power in Francia and conquering the territories of all west Germanic peoples, including the Saxons and the Baiuvarii (Bavarians). On Christmas Day, 800 AD, Charlemagne was crowned Emperor in Rome by Pope Leo III.

Fighting among Charlemagne's grandchildren caused the Carolingian empire to be partitioned into three parts in 843. The German region developed out of the East Frankish kingdom, East Francia. From 919 to 936, the Germanic peoples – Franks, Saxons, Swabians, and Bavarians – were united under Henry the Fowler, Duke of Saxony, who took the title of king. Imperial strongholds, called "Kaiserpfalzen", became economic and cultural centers, of which Aachen was the most famous.

In 936, Otto I was crowned as king at Aachen; his coronation as emperor by Pope John XII at Rome in 962 inaugurated what became later known as the Holy Roman Empire, which came to be identified with Germany. Otto strengthened the royal authority by re-asserting the old Carolingian rights over ecclesiastical appointments. Otto wrested from the nobles the powers of appointment of the bishops and abbots, who controlled large land holdings. Additionally, Otto revived the old Carolingian program of appointing missionaries in the border lands. Otto continued to support celibacy for the higher clergy, so ecclesiastical appointments never became hereditary. By granting land to the abbots and bishops he appointed, Otto actually made these bishops into "princes of the Empire" ("Reichsfürsten"); in this way, Otto was able to establish a national church. Outside threats to the kingdom were contained with the decisive defeat of the Hungarian Magyars at the Battle of Lechfeld in 955. The Slavs between the Elbe and the Oder rivers were also subjugated. Otto marched on Rome and drove John XII from the papal throne and for years controlled the election of the pope, setting a firm precedent for imperial control of the papacy for years to come.

During the reign of Conrad II's son, Henry III (1039 to 1056), the empire supported the Cluniac reforms of the Church, the Peace of God, prohibition of simony (the purchase of clerical offices), and required celibacy of priests. Imperial authority over the Pope reached its peak. In the Investiture Controversy which began between Henry IV and Pope Gregory VII over appointments to ecclesiastical offices, the emperor was compelled to submit to the Pope at Canossa in 1077, after having been excommunicated. In 1122 a temporary reconciliation was reached between Henry V and the Pope with the Concordat of Worms. The consequences of the investiture dispute were a weakening of the Ottonian church ("Reichskirche"), and a strengthening of the Imperial secular princes.

The time between 1096 and 1291 was the age of the crusades. Knightly religious orders were established, including the Knights Templar, the Knights of St John (Knights Hospitaller), and the Teutonic Order.

The term "sacrum imperium" (Holy Empire) was first used under Friedrich I, documented first in 1157, but the words "Sacrum Romanum Imperium", Holy Roman Empire, were only combined in July 1180 and would never consistently appear on official documents from 1254 onwards.

Long-distance trade in the Baltic intensified, as the major trading towns became drawn together in the Hanseatic League, under the leadership of Lübeck. The Hanseatic League was a business alliance of trading cities and their guilds that dominated trade along the coast of Northern Europe. Each of the Hanseatic cities had its own legal system and a degree of political autonomy. The chief cities were Cologne on the Rhine River, Hamburg and Bremen on the North Sea, and Lübeck on the Baltic. The League flourished from 1200 to 1500, and continued with lesser importance after that.

The German colonisation and the chartering of new towns and villages began into largely Slav-inhabited territories east of the Elbe, such as Bohemia, Silesia, Pomerania, and Livonia. Beginning in 1226, the Teutonic Knights began their conquest of Prussia. The native Baltic Prussians were conquered and Christianized by the Knights with much warfare, and numerous German towns were established along the eastern shore of the Baltic Sea.

Henry V (1086–1125), great-grandson of Conrad II, became Holy Roman Emperor in 1106 in the midst of a civil war. Hoping to gain complete control over the church inside the Empire, Henry V appointed Adalbert of Saarbrücken as the powerful archbishop of Mainz in 1111. Adalbert began to assert the powers of the Church against secular authorities, that is, the Emperor. This precipitated the "Crisis of 1111", part of the long-term Investiture Controversy. In 1137 the magnates turned back to the Hohenstaufen family for a candidate, Conrad III. Conrad III tried to divest Henry the Proud of his two duchies – Bavaria and Saxony – leading to war in southern Germany as the Empire divided into two factions. The first faction called themselves the "Welfs" or "Guelphs" after Henry the Proud's family, which was the ruling dynasty in Bavaria; the other faction was known as the "Waiblings." In this early period, the Welfs generally represented ecclesiastical independence under the papacy plus "particularism" (a strengthening of the local duchies against the central imperial authority). The Waiblings, on the other hand, stood for control of the Church by a strong central Imperial government.

Between 1152 and 1190, during the reign of Frederick I (Barbarossa), of the Hohenstaufen dynasty, an accommodation was reached with the rival Guelph party by the grant of the duchy of Bavaria to Henry the Lion, duke of Saxony. Austria became a separate duchy by virtue of the Privilegium Minus in 1156. Barbarossa tried to reassert his control over Italy. In 1177 a final reconciliation was reached between the emperor and the Pope in Venice.

In 1180, Henry the Lion was outlawed; Saxony was divided, and Bavaria was given to Otto of Wittelsbach. (Otto founded the Wittelsbach dynasty, which was to rule Bavaria until 1918.)

From 1184 to 1186, the Hohenstaufen empire under Frederick I Barbarossa reached its peak in the "Reichsfest" (imperial celebrations) held at Mainz and the marriage of his son Henry in Milan to the Norman princess Constance of Sicily. The power of the feudal lords was undermined by the appointment of "ministerials" (unfree servants of the Emperor) as officials. Chivalry and the court life flowered, leading to a development of German culture and literature (see Wolfram von Eschenbach).

Between 1212 and 1250, Frederick II established a modern, professionally administered state from his base in Sicily. He resumed the conquest of Italy, leading to further conflict with the Papacy. In the Empire, extensive sovereign powers were granted to ecclesiastical and secular princes, leading to the rise of independent territorial states. The struggle with the Pope sapped the Empire's strength, as Frederick II was excommunicated three times. After his death, the Hohenstaufen dynasty fell, followed by an interregnum during which there was no Emperor.

The failure of negotiations between Emperor Louis IV and the papacy led in 1338 to the declaration at Rhense by six electors to the effect that election by all or the majority of the electors automatically conferred the royal title and rule over the empire, without papal confirmation. As result, the monarch was no longer subject to papal approbation and became increasingly dependent on the favour of the electors. Between 1346 and 1378 Emperor Charles IV of Luxembourg, king of Bohemia, sought to restore the imperial authority. The Golden Bull of 1356 stipulated that in future the emperor was to be chosen by four secular electors and three spiritual electors. The secular electors were the King of Bohemia, the Count Palatine of the Rhine, the Duke of Saxony, and the Margrave of Brandenburg; the three spiritual electors were the Archbishops of Mainz, Trier, and Cologne.

Around 1350, Germany and almost the whole of Europe were ravaged by the Black Death. Jews were persecuted on religious and economic grounds; many fled to Poland. The Black Death is estimated to have killed 30–60 percent of Europe's population in the 14th century.

After the disasters of the 14th century – war, plague, and schism – early-modern European society gradually came into being as a result of economic, religious, and political changes. A money economy arose which provoked social discontent among knights and peasants. Gradually, a proto-capitalistic system evolved out of feudalism. The Fugger family gained prominence through commercial and financial activities and became financiers to both ecclesiastical and secular rulers. The knightly classes established their monopoly on arms and military skill. However, it was undermined by the introduction of mercenary armies and foot soldiers. Predatory activity by "robber knights" became common.

From 1438 the Habsburgs, who controlled most of the southeast of the Empire (more or less modern-day Austria and Slovenia, and Bohemia and Moravia after the death of King Louis II in 1526), maintained a constant grip on the position of the Holy Roman Emperor until 1806 (with the exception of the years between 1742 and 1745). This situation, however, gave rise to increased disunity among the Holy Roman Empire's territorial rulers and prevented sections of the country from coming together to form nations in the manner of France and England.

During his reign from 1493 to 1519, Maximilian I tried to reform the Empire. An Imperial supreme court ("Reichskammergericht") was established, imperial taxes were levied, and the power of the Imperial Diet ("Reichstag") was increased. The reforms, however, were frustrated by the continued territorial fragmentation of the Empire.

The German lands had a population of about 5 or 6 million. The great majority were farmers, typically in a state of serfdom under the control of nobles and monasteries. A few towns were starting to emerge. From 1100, new towns were founded around imperial strongholds, castles, bishops' palaces, and monasteries. The towns began to establish municipal rights and liberties (see German town law). Several cities such as Cologne became Imperial Free Cities, which did not depend on princes or bishops, but were immediately subject to the Emperor. The towns were ruled by patricians: merchants carrying on long-distance trade. Craftsmen formed guilds, governed by strict rules, which sought to obtain control of the towns; a few were open to women. Society was divided into sharply demarcated classes: the clergy, physicians, merchants, various guilds of artisans, and peasants; full citizenship was not available to paupers. Political tensions arose from issues of taxation, public spending, regulation of business, and market supervision, as well as the limits of corporate autonomy.

Cologne's central location on the Rhine river placed it at the intersection of the major trade routes between east and west and was the basis of Cologne's growth. The economic structures of medieval and early modern Cologne were characterized by the city's status as a major harbor and transport hub upon the Rhine. It was the seat of the archbishops, who ruled the surrounding area and (from 1248 to 1880) built the great Cologne Cathedral, with sacred relics that made it a destination for many worshippers. By 1288 the city had secured its independence from the archbishop (who relocated to Bonn), and was ruled by its burghers.

From the early medieval period and continuing through to the 18th century, Germanic law assigned women to a subordinate and dependent position relative to men. Salic (Frankish) law, from which the laws of the German lands would be based, placed women at a disadvantage with regard to property and inheritance rights. Germanic widows required a male guardian to represent them in court. Unlike Anglo-Saxon law or the Visigothic Code, Salic law barred women from royal succession. Social status was based on military and biological roles, a reality demonstrated in rituals associated with newborns, when female infants were given a lesser value than male infants. The use of physical force against wives was condoned until the 18th century in Bavarian law.

Some women of means asserted their influence during the Middle Ages, typically in royal court or convent settings. Hildegard of Bingen, Gertrude the Great, Elisabeth of Bavaria (1478–1504), and Argula von Grumbach are among the women who pursued independent accomplishments in fields as diverse as medicine, music composition, religious writing, and government and military politics.

Benedictine abbess Hildegard von Bingen (1098–1179) wrote several influential theological, botanical, and medicinal texts, as well as letters, liturgical songs, poems, and arguably the oldest surviving morality play, while supervising brilliant miniature Illuminations. About 100 years later, Walther von der Vogelweide (c. 1170 – c. 1230) became the most celebrated of the Middle High German lyric poets.

Around 1439, Johannes Gutenberg of Mainz, used movable type printing and issued the Gutenberg Bible. He was the global inventor of the printing press, thereby starting the Printing Revolution. Cheap printed books and pamphlets played central roles for the spread of the Reformation and the Scientific Revolution.

Around the transition from the 15th to the 16th century, Albrecht Dürer from Nuremberg established his reputation across Europe as painter, printmaker, mathematician, engraver, and theorist when he was still in his twenties and secured his reputation as one of the most important figures of the Northern Renaissance.

The addition "Nationis Germanicæ" (of German Nation) to the emperor's title appeared first in the 15th century: in a 1486 law decreed by Frederick III and in 1512 in reference to the Imperial Diet in Cologne by Maximilian I. By then, the emperors had lost their influence in Italy and Burgundy. In 1525, the Heilbronn reform plan – the most advanced document of the German Peasants' War ("Deutscher Bauernkrieg") – referred to the "Reich" as "von Teutscher Nation" (of German nation).

In the early 16th century there was much discontent occasioned by abuses such as indulgences in the Catholic Church, and a general desire for reform.

In 1517 the Reformation began with the publication of Martin Luther's 95 Theses; he posted them in the town square and gave copies of them to German nobles, but it is debated whether he nailed them to the church door in Wittenberg as is commonly said. The list detailed 95 assertions Luther believed to show corruption and misguidance within the Catholic Church. One often cited example, though perhaps not Luther's chief concern, is a condemnation of the selling of indulgences; another prominent point within the 95 Theses is Luther's disagreement both with the way in which the higher clergy, especially the pope, used and abused power, and with the very idea of the pope.

In 1521 Luther was outlawed at the Diet of Worms. But the Reformation spread rapidly, helped by the Emperor Charles V's wars with France and the Turks. Hiding in the Wartburg Castle, Luther translated the Bible from Latin to German, establishing the basis of the German language. A curious fact is that Luther spoke a dialect which had minor importance in the German language of that time. After the publication of his Bible, his dialect suppressed the others and evolved into what is now the modern German.

In 1524 the German Peasants' War broke out in Swabia, Franconia and Thuringia against ruling princes and lords, following the preaching of Reformers. But the revolts, which were assisted by war-experienced noblemen like Götz von Berlichingen and Florian Geyer (in Franconia), and by the theologian Thomas Münzer (in Thuringia), were soon repressed by the territorial princes. As many as 100,000 German peasants were massacred during the revolt. With the protestation of the Lutheran princes at the Imperial Diet of Speyer (1529) and rejection of the Lutheran "Augsburg Confession" at Augsburg (1530), a separate Lutheran church emerged.

From 1545 the Counter-Reformation began in Germany. The main force was provided by the Jesuit order, founded by the Spaniard Ignatius of Loyola. Central and northeastern Germany were by this time almost wholly Protestant, whereas western and southern Germany remained predominantly Catholic. In 1547, Holy Roman Emperor Charles V defeated the Schmalkaldic League, an alliance of Protestant rulers. The Peace of Augsburg in 1555 brought recognition of the Lutheran faith. But the treaty also stipulated that the religion of a state was to be that of its ruler (Cuius regio, eius religio).

In 1608/1609 the Protestant Union and the Catholic League were formed.

From 1618 to 1648 the Thirty Years' War raged in the Holy Roman Empire. Its causes were the conflicts between Catholics and Protestants, the efforts by the various states within the Empire to increase their power, and the Catholic Emperor's attempt to achieve the religious and political unity of the Empire. The immediate occasion for the war was the uprising of the Protestant nobility of Bohemia against the emperor, but the conflict was widened into a European war by the intervention of King Christian IV of Denmark (1625–29), Gustavus Adolphus of Sweden (1630–48) and France under Cardinal Richelieu. Germany became the main theatre of war and the scene of the final conflict between France and the Habsburgs for predominance in Europe.

The fighting often was out of control, with marauding bands of hundreds or thousands of starving soldiers spreading plague, plunder, and murder. The armies that were under control moved back and forth across the countryside year after year, levying heavy taxes on cities, and seizing the animals and food stocks of the peasants without payment. The enormous social disruption over three decades caused a dramatic decline in population because of killings, disease, crop failures, declining birth rates and random destruction, and the out-migration of terrified people. One estimate shows a 38% drop from 16 million people in 1618 to 10 million by 1650, while another shows "only" a 20% drop from 20 million to 16 million. The Altmark and Württemberg regions were especially hard hit. It took generations for Germany to fully recover.

The war ended in 1648 with the Peace of Westphalia. Alsace was permanently lost to France, Pomerania was temporarily lost to Sweden, and the Netherlands officially left the Empire. Imperial power declined further as the states' rights were increased.

The German population reached about twenty million people, the great majority of whom were peasant farmers.

The Reformation was a triumph of literacy and the new printing press. Luther's translation of the Bible into German was a decisive moment in the spread of literacy, and stimulated as well the printing and distribution of religious books and pamphlets. From 1517 onward religious pamphlets flooded Germany and much of Europe. By 1530 over 10,000 publications are known, with a total of ten million copies. The Reformation was thus a media revolution. Luther strengthened his attacks on Rome by depicting a "good" against "bad" church. From there, it became clear that print could be used for propaganda in the Reformation for particular agendas. Reform writers used pre-Reformation styles, clichés, and stereotypes and changed items as needed for their own purposes. Especially effective were Luther's "Small Catechism", for use of parents teaching their children, and "Larger Catechism," for pastors. Using the German vernacular they expressed the Apostles' Creed in simpler, more personal, Trinitarian language. Illustrations in the newly translated Bible and in many tracts popularized Luther's ideas. Lucas Cranach the Elder (1472–1553), the great painter patronized by the electors of Wittenberg, was a close friend of Luther, and illustrated Luther's theology for a popular audience. He dramatized Luther's views on the relationship between the Old and New Testaments, while remaining mindful of Luther's careful distinctions about proper and improper uses of visual imagery.

Luther's German translation of the Bible was also decisive for the German language and its evolution from Early New High German to Modern Standard. His bible promoted the development of non-local forms of language and exposed all speakers to forms of German from outside their own area.

Decisive scientific developments took place during the 16th and 17th centuries, especially in the fields of astronomy, mathematics and physics. The German astronomical community played a dominant role in Europe at this time, as its scientists kept in close touch with one another. Several non-German scientists influenced this community too, like astronomers Copernicus who worked in Poland and Tycho Brahe, who worked in Denmark and Bohemia. Copernicus, for example, was better known inside the German community. Astronomer Johannes Kepler from Weil am Stadt was one of the leaders in the 17th-century scientific revolution. He is best known for his laws of planetary motion. His ideas influenced contemporary Italian scientist Galileo Galilei and provided one of the foundations for Englishman Isaac Newton's theory of universal gravitation.

From 1640, Brandenburg-Prussia had started to rise under the "Great Elector," Frederick William. The Peace of Westphalia in 1648 strengthened it even further, through the acquisition of East Pomerania. From 1713 to 1740, King Frederick William I, also known as the "Soldier King", established a highly centralized, militarized state with a heavily rural population of about three million (compared to the nine million in Austria).

In terms of the boundaries of 1914, Germany in 1700 had a population of 16 million, increasing slightly to 17 million by 1750, and growing more rapidly to 24 million by 1800. Wars continued, but they were no longer so devastating to the civilian population; famines and major epidemics did not occur, but increased agricultural productivity led to a higher birth rate, and a lower death rate.

Louis XIV of France conquered parts of Alsace and Lorraine (1678–1681), and had invaded and devastated the Electorate of the Palatinate (1688–1697) in the War of Palatinian Succession. Louis XIV benefited from the Empire's problems with the Turks, which were menacing Austria. Louis XIV ultimately had to relinquish the Electorate of the Palatinate. Afterwards Hungary was reconquered from the Turks; Austria, under the Habsburgs, developed into a great power.

Frederick II "the Great" is best known for his military genius, his reorganization of Prussian armies, his battlefield successes, his enlightened rule, and especially his making Prussia one of the great powers, as well as escaping from almost certain national disaster at the last minute. He was especially a role model for an aggressively expanding Germany down to 1945, and even today retains his heroic image in Germany.

In the War of Austrian Succession (1740–1748) Maria Theresa fought successfully for recognition of her succession to the throne. But in the Silesian Wars and in the Seven Years' War she had to cede 95% of Silesia to Frederick the Great. After the Peace of Hubertsburg in 1763 between Austria, Prussia and Saxony, Prussia won recognition as a great power, thus launching a century-long rivalry with Austria for the leadership of the German peoples.

From 1763, against resistance from the nobility and citizenry, an "enlightened absolutism" was established in Prussia and Austria, according to which the ruler governed according to the best precepts of the philosophers. The economies developed and legal reforms were undertaken, including the abolition of torture and the improvement in the status of Jews. Emancipation of the peasants slowly began. Compulsory education was instituted.

In 1772–1795 Prussia took the lead in the partitions of Poland, with Austria and Russia splitting the rest. Prussia occupied the western territories of the former Polish–Lithuanian Commonwealth that surrounded existing Prussian holdings. Poland again became independent in 1918.

Completely overshadowed by Prussia and Austria, according to historian Hajo Holborn, the smaller German states were generally characterized by political lethargy and administrative inefficiency, often compounded by rulers who were more concerned with their mistresses and their hunting dogs than with the affairs of state. Bavaria was especially unfortunate in this regard; it was a rural land with very heavy debts and few growth centers. Saxony was in economically good shape, although its government was seriously mismanaged, and numerous wars had taken their toll. During the time when Prussia rose rapidly within Germany, Saxony was distracted by foreign affairs. The house of Wettin concentrated on acquiring and then holding on to the Polish throne which was ultimately unsuccessful. In Württemberg the duke lavished funds on palaces, mistresses, great celebration, and hunting expeditions. Many of the city-states of Germany were run by bishops, who in reality were from powerful noble families and showed scant interest in religion. None developed a significant reputation for good government.

In Hesse-Kassel, the Landgrave Frederick II, ruled 1760–1785 as an enlightened despot, and raised money by renting soldiers (called "Hessians") to Great Britain to help fight the American Revolutionary War. He combined Enlightenment ideas with Christian values, cameralist plans for central control of the economy, and a militaristic approach toward diplomacy.

Hanover did not have to support a lavish court—its rulers were also kings of England and resided in London. George III, elector (ruler) from 1760 to 1820, never once visited Hanover. The local nobility who ran the country opened the University of Göttingen in 1737; it soon became a world-class intellectual center. Baden sported perhaps the best government of the smaller states. Karl Friedrich ruled well for 73 years (1738–1811) and was an enthusiast for The Enlightenment; he abolished serfdom in 1783.

The smaller states failed to form coalitions with each other, and were eventually overwhelmed by Prussia. Between 1807 and 1871, Prussia swallowed up many of the smaller states, with minimal protest, then went on to found the German Empire. In the process, Prussia became too heterogeneous, lost its identity, and by the 1930s had become an administrative shell of little importance.

In a heavily agrarian society, land ownership played a central role. Germany's nobles, especially those in the East – called Junkers – dominated not only the localities, but also the Prussian court, and especially the Prussian army. Increasingly after 1815, a centralized Prussian government based in Berlin took over the powers of the nobles, which in terms of control over the peasantry had been almost absolute. To help the nobility avoid indebtedness, Berlin set up a credit institution to provide capital loans in 1809, and extended the loan network to peasants in 1849. When the German Empire was established in 1871, the Junker nobility controlled the army and the Navy, the bureaucracy, and the royal court; they generally set governmental policies.

Peasants continued to center their lives in the village, where they were members of a corporate body, and to help manage the community resources and monitor the community life. In the East, they were serfs who were bound permanently to parcels of land. In most of Germany, farming was handled by tenant farmers who paid rents and obligatory services to the landlord, who was typically a nobleman. Peasant leaders supervised the fields and ditches and grazing rights, maintained public order and morals, and supported a village court which handled minor offenses. Inside the family the patriarch made all the decisions, and tried to arrange advantageous marriages for his children. Much of the villages' communal life centered around church services and holy days. In Prussia, the peasants drew lots to choose conscripts required by the army. The noblemen handled external relationships and politics for the villages under their control, and were not typically involved in daily activities or decisions.

The emancipation of the serfs came in 1770–1830, beginning with Schleswig in 1780. The peasants were now ex-serfs and could own their land, buy and sell it, and move about freely. The nobles approved for now they could buy land owned by the peasants. The chief reformer was Baron vom Stein (1757–1831), who was influenced by The Enlightenment, especially the free market ideas of Adam Smith. The end of serfdom raised the personal legal status of the peasantry. A bank was set up so that landowners could borrow government money to buy land from peasants (the peasants were not allowed to use it to borrow money to buy land until 1850). The result was that the large landowners obtained larger estates, and many peasants became landless tenants, or moved to the cities or to America. The other German states imitated Prussia after 1815. In sharp contrast to the violence that characterized land reform in the French Revolution, Germany handled it peacefully. In Schleswig the peasants, who had been influenced by the Enlightenment, played an active role; elsewhere they were largely passive. Indeed, for most peasants, customs and traditions continued largely unchanged, including the old habits of deference to the nobles whose legal authority remained quite strong over the villagers. Although the peasants were no longer tied to the same land as serfs had been, the old paternalistic relationship in East Prussia lasted into the 20th century.

The agrarian reforms in northwestern Germany in the era 1770–1870 were driven by progressive governments and local elites. They abolished feudal obligations and divided collectively owned common land into private parcels and thus created a more efficient market-oriented rural economy, which increased productivity and population growth and strengthened the traditional social order because wealthy peasants obtained most of the former common land, while the rural proletariat was left without land; many left for the cities or America. Meanwhile, the division of the common land served as a buffer preserving social peace between nobles and peasants. In the east the serfs were emancipated but the Junker class maintained its large estates and monopolized political power.

Around 1800 the Catholic monasteries, which had large land holdings, were nationalized and sold off by the government. In Bavaria they had controlled 56% of the land.

A major social change occurring between 1750–1850, depending on region, was the end of the traditional "whole house" ("ganzes Haus") system, in which the owner's family lived together in one large building with the servants and craftsmen he employed. They reorganized into separate living arrangements. No longer did the owner's wife take charge of all the females in the different families in the whole house. In the new system, farm owners became more professionalized and profit-oriented. They managed the fields and the household exterior according to the dictates of technology, science, and economics. Farm wives supervised family care and the household interior, to which strict standards of cleanliness, order, and thrift applied. The result was the spread of formerly urban bourgeois values into rural Germany.

The lesser families were now living separately on wages. They had to provide for their own supervision, health, schooling, and old-age. At the same time, because of the demographic transition, there were far fewer children, allowing for much greater attention to each child. Increasingly the middle-class family valued its privacy and its inward direction, shedding too-close links with the world of work. Furthermore, the working classes, the middle classes and the upper classes became physically, psychologically and politically more separate. This allowed for the emergence of working-class organizations. It also allowed for declining religiosity among the working-class, who were no longer monitored on a daily basis.

Before 1750 the German upper classes looked to France for intellectual, cultural and architectural leadership; French was the language of high society. By the mid-18th century the "Aufklärung" (German for "The Enlightenment") had transformed German high culture in music, philosophy, science and literature. Christian Wolff (1679–1754) was the pioneer as a writer who expounded the Enlightenment to German readers; he legitimized German as a philosophic language.

Prussia took the lead among the German states in sponsoring the political reforms that Enlightenment thinkers urged absolute rulers to adopt. However, there were important movements as well in the smaller states of Bavaria, Saxony, Hanover, and the Palatinate. In each case Enlightenment values became accepted and led to significant political and administrative reforms that laid the groundwork for the creation of modern states. The princes of Saxony, for example, carried out an impressive series of fundamental fiscal, administrative, judicial, educational, cultural, and general economic reforms. The reforms were aided by the country's strong urban structure and influential commercial groups, and modernized pre-1789 Saxony along the lines of classic Enlightenment principles.

Johann Gottfried von Herder (1744–1803) broke new ground in philosophy and poetry, as a leader of the Sturm und Drang movement of proto-Romanticism. Weimar Classicism ("Weimarer Klassik") was a cultural and literary movement based in Weimar that sought to establish a new humanism by synthesizing Romantic, classical, and Enlightenment ideas. The movement, from 1772 until 1805, involved Herder as well as polymath Johann Wolfgang von Goethe (1749–1832) and Friedrich Schiller (1759–1805), a poet and historian. Herder argued that every folk had its own particular identity, which was expressed in its language and culture. This legitimized the promotion of German language and culture and helped shape the development of German nationalism. Schiller's plays expressed the restless spirit of his generation, depicting the hero's struggle against social pressures and the force of destiny.

German music, sponsored by the upper classes, came of age under composers Johann Sebastian Bach (1685–1750), Joseph Haydn (1732–1809), and Wolfgang Amadeus Mozart (1756–1791).

In remote Königsberg philosopher Immanuel Kant (1724–1804) tried to reconcile rationalism and religious belief, individual freedom, and political authority. Kant's work contained basic tensions that would continue to shape German thought – and indeed all of European philosophy – well into the 20th century.

The German Enlightenment won the support of princes, aristocrats, and the middle classes, and it permanently reshaped the culture.

Before the 19th century, young women lived under the economic and disciplinary authority of their fathers until they married and passed under the control of their husbands. In order to secure a satisfactory marriage, a woman needed to bring a substantial dowry. In the wealthier families, daughters received their dowry from their families, whereas the poorer women needed to work in order to save their wages so as to improve their chances to wed. Under the German laws, women had property rights over their dowries and inheritances, a valuable benefit as high mortality rates resulted in successive marriages. Before 1789, the majority of women lived confined to society’s private sphere, the home.

The Age of Reason did not bring much more for women: men, including Enlightenment aficionados, believed that women were naturally destined to be principally wives and mothers. Within the educated classes, there was the belief that women needed to be sufficiently educated to be intelligent and agreeable interlocutors to their husbands. However, the lower-class women were expected to be economically productive in order to help their husbands make ends meet.

German reaction to the French Revolution was mixed at first. German intellectuals celebrated the outbreak, hoping to see the triumph of Reason and The Enlightenment. The royal courts in Vienna and Berlin denounced the overthrow of the king and the threatened spread of notions of liberty, equality, and fraternity. By 1793, the execution of the French king and the onset of the Terror disillusioned the Bildungsbürgertum (educated middle classes). Reformers said the solution was to have faith in the ability of Germans to reform their laws and institutions in peaceful fashion.

Europe was racked by two decades of war revolving around France's efforts to spread its revolutionary ideals, and the opposition of reactionary royalty. War broke out in 1792 as Austria and Prussia invaded France, but were defeated at the Battle of Valmy (1792). The German lands saw armies marching back and forth, bringing devastation (albeit on a far lower scale than the Thirty Years' War, almost two centuries before), but also bringing new ideas of liberty and civil rights for the people. Prussia and Austria ended their failed wars with France but (with Russia) partitioned Poland among themselves in 1793 and 1795. The French took control of the Rhineland, imposed French-style reforms, abolished feudalism, established constitutions, promoted freedom of religion, emancipated Jews, opened the bureaucracy to ordinary citizens of talent, and forced the nobility to share power with the rising middle class. Napoleon created the Kingdom of Westphalia (1807–1813) as a model state. These reforms proved largely permanent and modernized the western parts of Germany. When the French tried to impose the French language, German opposition grew in intensity. A Second Coalition of Britain, Russia, and Austria then attacked France but failed. Napoleon established direct or indirect control over most of western Europe, including the German states apart from Prussia and Austria. The old Holy Roman Empire was little more than a farce; Napoleon simply abolished it in 1806 while forming new countries under his control. In Germany Napoleon set up the "Confederation of the Rhine," comprising most of the German states except Prussia and Austria.

Prussia tried to remain neutral while imposing tight controls on dissent, but with German nationalism sharply on the rise, the small nation blundered by going to war with Napoleon in 1806. Its economy was weak, its leadership poor, and the once mighty Prussian army was a hollow shell. Napoleon easily crushed it at the Battle of Jena (1806). Napoleon occupied Berlin, and Prussia paid dearly. Prussia lost its recently acquired territories in western Germany, its army was reduced to 42,000 men, no trade with Britain was allowed, and Berlin had to pay Paris heavy reparations and fund the French army of occupation. Saxony changed sides to support Napoleon and join his Confederation of the Rhine; its elector was rewarded with the title of king and given a slice of Poland taken from Prussia.

After Napoleon's fiasco in Russia in 1812, including the deaths of many Germans in his invasion army, Prussia joined with Russia. Major battles followed in quick order, and when Austria switched sides to oppose Napoleon, his situation grew tenuous. He was defeated in a great Battle of Leipzig in late 1813, and Napoleon's empire started to collapse. One after another the German states switched to oppose Napoleon, but he rejected peace terms. Allied armies invaded France in early 1814, Paris fell, and in April Napoleon surrendered. He returned for 100 days in 1815, but was finally defeated by the British and German armies at Waterloo. Prussia was the big winner at the Vienna peace conference, gaining extensive territory.

Europe in 1815 was a continent in a state of complete exhaustion following the French Revolutionary and Napoleonic Wars, and started to turn from the liberal ideas of the Enlightenment and Revolutionary era and to Romanticism under such writers as Edmund Burke, Joseph de Maistre, and Novalis. Politically, the victorious allies set out to build a new balance of powers in order to keep the peace, and decided that a stable German region would be able to keep French imperialism at bay. To make this a possibility, the idea of reforming the defunct Holy Roman Empire was discarded, and Napoleon's reorganization of the German states was kept and the remaining princes were allowed to keep their titles. In 1813, in return for guarantees from the Allies that the sovereignty and integrity of the Southern German states (Baden, Württemberg, and Bavaria) would be preserved, they broke with the French.

The German Confederation () was the loose association of 39 states created in 1815 to coordinate the economies of separate German-speaking countries. It acted as a buffer between the powerful states of Austria and Prussia. Britain approved of it because London felt that there was need for a stable, peaceful power in central Europe that could discourage aggressive moves by France or Russia. According to Lee (1985), most historians have judged the Confederation to be weak and ineffective, as well as an obstacle to German nationalist aspirations. It collapsed because of the rivalry between Prussia and Austria (known as German dualism), warfare, the 1848 revolution, and the inability of the multiple members to compromise. It was replaced by the North German Confederation in 1866.

The population of the German Confederation (excluding Austria) grew 60% from 1815 to 1865, from 21,000,000 to 34,000,000. The era saw the Demographic Transition take place in Germany. It was a transition from high birth rates and high death rates to low birth and death rates as the country developed from a pre-industrial to a modernized agriculture and supported a fast-growing industrialized urban economic system. In previous centuries, the shortage of land meant that not everyone could marry, and marriages took place after age 25. After 1815, increased agricultural productivity meant a larger food supply, and a decline in famines, epidemics, and malnutrition. This allowed couples to marry earlier, and have more children. Arranged marriages became uncommon as young people were now allowed to choose their own marriage partners, subject to a veto by the parents. The high birthrate was offset by a very high rate of infant mortality and emigration, especially after about 1840, mostly to the German settlements in the United States, plus periodic epidemics and harvest failures. The upper and middle classes began to practice birth control, and a little later so too did the peasants.

Before 1850 Germany lagged far behind the leaders in industrial development – Britain, France, and Belgium. In 1800, Germany's social structure was poorly suited to entrepreneurship or economic development. Domination by France during the era of the French Revolution (1790s to 1815), however, produced important institutional reforms. Reforms included the abolition of feudal restrictions on the sale of large landed estates, the reduction of the power of the guilds in the cities, and the introduction of a new, more efficient commercial law. Nevertheless, traditionalism remained strong in most of Germany. Until mid-century, the guilds, the landed aristocracy, the churches, and the government bureaucracies had so many rules and restrictions that entrepreneurship was held in low esteem, and given little opportunity to develop. From the 1830s and 1840s, Prussia, Saxony, and other states reorganized agriculture. The introduction of sugar beets, turnips, and potatoes yielded a higher level of food production, which enabled a surplus rural population to move to industrial areas. The beginnings of the industrial revolution in Germany came in the textile industry, and was facilitated by eliminating tariff barriers through the Zollverein, starting in 1834.

By mid-century, the German states were catching up. By 1900 Germany was a world leader in industrialization, along with Britain and the United States. Historian Thomas Nipperdey sums it up:

Industrialization brought rural Germans to the factories, mines and railways. The population in 1800 was heavily rural, with only 10% of the people living in communities of 5000 or more people, and only 2% living in cities of more than 100,000. After 1815, the urban population grew rapidly, due primarily to the influx of young people from the rural areas. Berlin grew from 172,000 in 1800, to 826,000 in 1870; Hamburg grew from 130,000 to 290,000; Munich from 40,000 to 269,000; and Dresden from 60,000 to 177,000. Offsetting this growth, there was extensive emigration, especially to the United States. Emigration totaled 480,000 in the 1840s, 1,200,000 in the 1850s, and 780,000 in the 1860s.

The takeoff stage of economic development came with the railroad revolution in the 1840s, which opened up new markets for local products, created a pool of middle managers, increased the demand for engineers, architects and skilled machinists and stimulated investments in coal and iron. Political disunity of three dozen states and a pervasive conservatism made it difficult to build railways in the 1830s. However, by the 1840s, trunk lines did link the major cities; each German state was responsible for the lines within its own borders. Economist Friedrich List summed up the advantages to be derived from the development of the railway system in 1841:

Lacking a technological base at first, the Germans imported their engineering and hardware from Britain, but quickly learned the skills needed to operate and expand the railways. In many cities, the new railway shops were the centres of technological awareness and training, so that by 1850, Germany was self-sufficient in meeting the demands of railroad construction, and the railways were a major impetus for the growth of the new steel industry. Observers found that even as late as 1890, their engineering was inferior to Britain’s. However, German unification in 1870 stimulated consolidation, nationalisation into state-owned companies, and further rapid growth. Unlike the situation in France, the goal was support of industrialisation, and so, heavy lines crisscrossed the Ruhr and other industrial districts, and provided good connections to the major ports of Hamburg and Bremen. By 1880, Germany had 9,400 locomotives pulling 43,000 passengers and 30,000 tons of freight a day, and forged ahead of France.

A large number of newspapers and magazines flourished; A typical small city had one or two newspapers; Berlin and Leipzig had dozens. The audience was limited to perhaps five percent of the adult men, chiefly from the aristocratic and middle classes, who followed politics. Liberal papers outnumbered conservative ones by a wide margin. Foreign governments bribed editors to guarantee a favorable image. Censorship was strict, and the government issued the political news they were supposed to report. After 1871, strict press laws were used by Bismarck to shut down the Socialist, and to threaten hostile editors. There were no national newspapers. Editors focused on political commentary, but also included in a nonpolitical cultural page, focused on the arts and high culture. Especially popular was the serialized novel, with a new chapter every week. Magazines were politically more influential, and attracted the leading intellectuals as authors.

German artists and intellectuals, heavily influenced by the French Revolution and by the great German poet and writer Johann Wolfgang von Goethe (1749–1832), turned to Romanticism after a period of Enlightenment. Philosophical thought was decisively shaped by Immanuel Kant (1724–1804). Ludwig van Beethoven (1770–1827) was the leading composer of Romantic music. His use of tonal architecture in such a way as to allow significant expansion of musical forms and structures was immediately recognized as bringing a new dimension to music. His later piano music and string quartets, especially, showed the way to a completely unexplored musical universe, and influenced Franz Schubert (1797–1828) and Robert Schumann (1810–1856). In opera, a new Romantic atmosphere combining supernatural terror and melodramatic plot in a folkloric context was first successfully achieved by Carl Maria von Weber (1786–1826) and perfected by Richard Wagner (1813–1883) in his Ring Cycle. The Brothers Grimm (1785–1863 & 1786–1859) not only collected folk stories into the popular Grimm's Fairy Tales, but were also linguists, now counted among the founding fathers of German studies. They were commissioned to begin the Deutsches Wörterbuch ("The German Dictionary"), which remains the most comprehensive work on the German language.

At the universities high-powered professors developed international reputations, especially in the humanities led by history and philology, which brought a new historical perspective to the study of political history, theology, philosophy, language, and literature. With Georg Wilhelm Friedrich Hegel (1770–1831) in philosophy, Friedrich Schleiermacher (1768–1834) in theology and Leopold von Ranke (1795–1886) in history, the University of Berlin, founded in 1810, became the world's leading university. Von Ranke, for example, professionalized history and set the world standard for historiography. By the 1830s mathematics, physics, chemistry, and biology had emerged with world class science, led by Alexander von Humboldt (1769–1859) in natural science and Carl Friedrich Gauss (1777–1855) in mathematics. Young intellectuals often turned to politics, but their support for the failed Revolution of 1848 forced many into exile.

Two main developments reshaped religion in Germany. Across the land, there was a movement to unite the larger Lutheran and the smaller Reformed Protestant churches. The churches themselves brought this about in Baden, Nassau, and Bavaria. However, in Prussia King Frederick William III was determined to handle unification entirely on his own terms, without consultation. His goal was to unify the Protestant churches, and to impose a single standardized liturgy, organization and even architecture. The long-term goal was to have fully centralized royal control of all the Protestant churches. In a series of proclamations over several decades the "Church of the Prussian Union" was formed, bringing together the more numerous Lutherans, and the less numerous Reformed Protestants. The government of Prussia now had full control over church affairs, with the king himself recognized as the leading bishop. Opposition to unification came from the "Old Lutherans" in Silesia who clung tightly to the theological and liturgical forms they had followed since the days of Luther. The government attempted to crack down on them, so they went underground. Tens of thousands migrated, to South Australia, and especially to the United States, where they formed the Missouri Synod, which is still in operation as a conservative denomination. Finally in 1845 a new king Frederick William IV offered a general amnesty and allowed the Old Lutherans to form a separate church association with only nominal government control.

From the religious point of view of the typical Catholic or Protestant, major changes were underway in terms of a much more personalized religiosity that focused on the individual more than the church or the ceremony. The rationalism of the late 19th century faded away, and there was a new emphasis on the psychology and feeling of the individual, especially in terms of contemplating sinfulness, redemption, and the mysteries and the revelations of Christianity. Pietistic revivals were common among Protestants. Among Catholics there was a sharp increase in popular pilgrimages. In 1844 alone, half a million pilgrims made a pilgrimage to the city of Trier in the Rhineland to view the Seamless robe of Jesus, said to be the robe that Jesus wore on the way to his crucifixion. Catholic bishops in Germany had historically been largely independent Of Rome, but now the Vatican exerted increasing control, a new "ultramontanism" of Catholics highly loyal to Rome. A sharp controversy broke out in 1837–38 in the largely Catholic Rhineland over the religious education of children of mixed marriages, where the mother was Catholic and the father Protestant. The government passed laws to require that these children always be raised as Protestants, contrary to Napoleonic law that had previously prevailed and allowed the parents to make the decision. It put the Catholic Archbishop under house arrest. In 1840, the new King Frederick William IV sought reconciliation and ended the controversy by agreeing to most of the Catholic demands. However Catholic memories remained deep and led to a sense that Catholics always needed to stick together in the face of an untrustworthy government.

After the fall of Napoleon, Europe's statesmen convened in Vienna in 1815 for the reorganisation of European affairs, under the leadership of the Austrian Prince Metternich. The political principles agreed upon at this Congress of Vienna included the restoration, legitimacy and solidarity of rulers for the repression of revolutionary and nationalist ideas.

The German Confederation () was founded, a loose union of 39 states (35 ruling princes and 4 free cities) under Austrian leadership, with a Federal Diet () meeting in Frankfurt am Main. It was a loose coalition that failed to satisfy most nationalists. The member states largely went their own way, and Austria had its own interests.

In 1819 a student radical assassinated the reactionary playwright August von Kotzebue, who had scoffed at liberal student organisations. In one of the few major actions of the German Confederation, Prince Metternich called a conference that issued the repressive Carlsbad Decrees, designed to suppress liberal agitation against the conservative governments of the German states. The Decrees terminated the fast-fading nationalist fraternities (), removed liberal university professors, and expanded the censorship of the press. The decrees began the "persecution of the demagogues", which was directed against individuals who were accused of spreading revolutionary and nationalist ideas. Among the persecuted were the poet Ernst Moritz Arndt, the publisher Johann Joseph Görres and the "Father of Gymnastics" Ludwig Jahn.
In 1834 the Zollverein was established, a customs union between Prussia and most other German states, but excluding Austria. As industrialisation developed, the need for a unified German state with a uniform currency, legal system, and government became more and more obvious.

Growing discontent with the political and social order imposed by the Congress of Vienna led to the outbreak, in 1848, of the March Revolution in the German states. In May the German National Assembly (the Frankfurt Parliament) met in Frankfurt to draw up a national German constitution.

But the 1848 revolution turned out to be unsuccessful: King Frederick William IV of Prussia refused the imperial crown, the Frankfurt parliament was dissolved, the ruling princes repressed the risings by military force, and the German Confederation was re-established by 1850. Many leaders went into exile, including a number who went to the United States and became a political force there.

The 1850s were a period of extreme political reaction. Dissent was vigorously suppressed, and many Germans emigrated to America following the collapse of the 1848 uprisings. Frederick William IV became extremely depressed and melancholy during this period, and was surrounded by men who advocated clericalism and absolute divine monarchy. The Prussian people once again lost interest in politics. Prussia not only expanded its territory but began to industrialize rapidly, while maintaining a strong agricultural base.

In 1857, the king had a stroke and his brother William became regent, then became King William I in 1861. Although conservative, William I was far more pragmatic. His most significant accomplishment was naming Otto von Bismarck as chancellor in 1862. The combination of Bismarck, Defense Minister Albrecht von Roon, and Field Marshal Helmut von Moltke set the stage for victories over Denmark, Austria, and France, and led to the unification of Germany. The obstacle to German unification was Austria, and Bismarck solved the problem with a series of wars that united the German states north of Austria.

In 1863–64, disputes between Prussia and Denmark grew over Schleswig, which was not part of the German Confederation, and which Danish nationalists wanted to incorporate into the Danish kingdom. The dispute led to the short Second War of Schleswig in 1864. Prussia, joined by Austria, easily defeated Denmark and occupied Jutland. The Danes were forced to cede both the duchy of Schleswig and the duchy of Holstein to Austria and Prussia. In the aftermath, the management of the two duchies caused escalating tensions between Austria and Prussia. The former wanted the duchies to become an independent entity within the German Confederation, while the latter wanted to annex them. The Seven Weeks War between Austria and Prussia broke out in June 1866. In July, the two armies clashed at Sadowa-Königgrätz (Bohemia) in an enormous battle involving half a million men. The Prussian breech-loading needle guns carried the day over the slow muzzle-loading rifles of the Austrians, who lost a quarter of their army in the battle. Austria ceded Venice to Italy, but Bismarck was deliberately lenient with the loser to keep alive a long-term alliance with Austria in a subordinate role. Now the French faced an increasingly strong Prussia.

In 1866, the German Confederation was dissolved. In its place the North German Federation (German "Norddeutscher Bund") was established, under the leadership of Prussia. Austria was excluded, and the Austrian influence in Germany that had begun in the 15th century finally came to an end. The North German Federation was a transitional organisation that existed from 1867 to 1871, between the dissolution of the German Confederation and the founding of the German Empire.

After Germany was united by Otto von Bismarck into the "German Reich", he determined German politics until 1890. Bismarck tried to foster alliances in Europe, on one hand to contain France, and on the other hand to consolidate Germany's influence in Europe. On the domestic front Bismarck tried to stem the rise of socialism by anti-socialist laws, combined with an introduction of health care and social security. At the same time Bismarck tried to reduce the political influence of the emancipated Catholic minority in the Kulturkampf, literally "culture struggle". The Catholics only grew stronger, forming the Center (Zentrum) Party. Germany grew rapidly in industrial and economic power, matching Britain by 1900. Its highly professional army was the best in the world, but the navy could never catch up with Britain's Royal Navy.

In 1888, the young and ambitious Kaiser Wilhelm II became emperor. He could not abide advice, least of all from the most experienced politician and diplomat in Europe, so he fired Bismarck. The Kaiser opposed Bismarck's careful foreign policy and wanted Germany to pursue colonialist policies, as Britain and France had been doing for decades, as well as build a navy that could match the British. The Kaiser promoted active colonization of Africa and Asia for those areas that were not already colonies of other European powers; his record was notoriously brutal and set the stage for genocide. The Kaiser took a mostly unilateral approach in Europe with as main ally the Austro-Hungarian Empire, and an arms race with Britain, which eventually led to the situation in which the assassination of the Austrian-Hungarian crown prince could spark off World War I.

Disputes between France and Prussia increased. In 1868, the Spanish queen Isabella II was expelled by a revolution, leaving that country's throne vacant. When Prussia tried to put a Hohenzollern candidate, Prince Leopold, on the Spanish throne, the French angrily protested. In July 1870, France declared war on Prussia (the Franco-Prussian War). The debacle was swift. A succession of German victories in northeastern France followed, and one French army was besieged at Metz. After a few weeks, the main army was finally forced to capitulate in the fortress of Sedan. French Emperor Napoleon III was taken prisoner and a republic hastily proclaimed in Paris. The new government, realising that a victorious Germany would demand territorial acquisitions, resolved to fight on. They began to muster new armies, and the Germans settled down to a grim siege of Paris. The starving city surrendered in January 1871, and the Prussian army staged a victory parade in it. France was forced to pay indemnities of 5 billion francs and cede Alsace-Lorraine. It was a bitter peace that would leave the French thirsting for revenge.

During the Siege of Paris, the German princes assembled in the Hall of Mirrors of the Palace of Versailles and proclaimed the Prussian King Wilhelm I as the "German Emperor" on 18 January 1871. The German Empire was thus founded, with the German states unified into a single economic, political, and administrative unit. The empire comprised 25 states, three of which were Hanseatic free cities. It was dubbed the "Little German" solution, since it excluded the Austrian territories and the Habsburgs. Bismarck, again, was appointed to serve as Chancellor.

The new empire was characterised by a great enthusiasm and vigor. There was a rash of heroic artwork in imitation of Greek and Roman styles, and the nation possessed a vigorous, growing industrial economy, while it had always been rather poor in the past. The change from the slower, more tranquil order of the old Germany was very sudden, and many, especially the nobility, resented being displaced by the new rich. And yet, the nobles clung stubbornly to power, and they, not the bourgeois, continued to be the model that everyone wanted to imitate. In imperial Germany, possessing a collection of medals or wearing a uniform was valued more than the size of one's bank account, and Berlin never became a great cultural center as London, Paris, or Vienna were. The empire was distinctly authoritarian in tone, as the 1871 constitution gave the emperor exclusive power to appoint or dismiss the chancellor. He also was supreme commander-in-chief of the armed forces and final arbiter of foreign policy. But freedom of speech, association, and religion were nonetheless guaranteed by the constitution.

Bismarck's domestic policies as Chancellor of Germany were characterised by his fight against perceived enemies of the Protestant Prussian state. In the Kulturkampf (1871–1878), he tried to minimize the influence of the Roman Catholic Church and of its political arm, the Catholic Centre Party, through various measures—like the introduction of civil marriage—but without much success. The Kulturkampf antagonised many Protestants as well as Catholics, and was eventually abandoned. Millions of non-Germans subjects in the German Empire, like the Polish, Danish and French minorities, were discriminated against, and a policy of Germanisation was implemented.

The new Empire provided rich new opportunities at the top for the nobility of Prussia, and the other states, to fill. They dominated the diplomatic service, the Army, and the civil service. Through their control of the civil service, the aristocracy had a dominant voice in decisions affecting the universities and the churches. In 1914, Germany's diplomats consisted of eight princes 29 counts 20 barons 54 other nobles, and a mere 11 commoners. The commoners were chiefly the sons of leading industrialists or bankers. Almost all the diplomats had been socialized into the feudal student corps at the universities. The consular corps comprised commoners, but they had little decision-making ability. Since the days of Frederick the great, it had been difficult for commoners to achieve high ranking the Army. It was considered a suitable role for young aristocrats. The new Constitution put Military affairs under the direct control of the Emperor, and largely out of reach of the Reichstag. With its large corps of reserve officers across Germany, the military strengthened its role as "The estate which upheld the nation." Historian Hans-Ulrich Wehler says, "it became an almost separate, self-perpetuating caste."

Power increasingly was centralized in the national capital of Berlin (including neighboring Potsdam.) where 7000 aristocrats drew a sharp line between themselves and everyone else. Berlin's rapidly increasing rich middle-class aped and copied the aristocracy and tried to marry into it. The closed system stood in contrast to Britain where the top levels of the elite were far more open with routes available through a public school education, Oxford, and Cambridge, the Inns of Court, appointment to high office, or leadership in the House of Commons. A peerage could permanently boost a rich industrial family into the upper reaches of the establishment. In Germany, the process worked in the other direction as the nobility became industrialists. For example, 221 of the 243 mines in Silesia were owned by nobles or by the King of Prussia himself.

Germany's middle class, based in the cities, grew exponentially, although it never gained the political power it had in France, Britain or the United States. The Bund Deutscher Frauenvereine (Association of German Women's Organizations or BDF) was established in 1894 to encompass the proliferating women's organizations that had sprung up since the 1860s. From the beginning the BDF was a bourgeois organization, its members working toward equality with men in such areas as education, financial opportunities, and political life. Working-class women were not welcome; they were organized by the Socialists.

The rise of the Socialist Workers' Party (later known as the Social Democratic Party of Germany, SPD), declared its aim to establish peacefully a new socialist order through the transformation of existing political and social conditions. From 1878, Bismarck tried to repress the social democratic movement by outlawing the party's organisation, its assemblies and most of its newspapers. When it finally was allowed to run candidates, the Social Democrats were stronger than ever.

Bismarck built on a tradition of welfare programs in Prussia and Saxony that began as early as the 1840s. In the 1880s he introduced old age pensions, accident insurance, medical care, and unemployment insurance that formed the basis of the modern European welfare state. His paternalistic programs won the support of German industry because its goals were to win the support of the working classes for the Empire and reduce the outflow of immigrants to America, where wages were higher but welfare did not exist. Bismarck further won the support of both industry and skilled workers by his high tariff policies, which protected profits and wages from American competition, although they alienated the liberal intellectuals who wanted free trade.

Bismarck would not tolerate any power outside Germany—as in Rome—having a say in German affairs. He launched a Kulturkampf ("culture war") against the power of the pope and the Catholic Church in 1873, but only in Prussia. This gained strong support from German liberals, who saw the Catholic Church as the bastion of reaction and their greatest enemy. The Catholic element, in turn, saw in the National-Liberals as its worst enemy and formed the Center Party.

Catholics, although nearly a third of the national population, were seldom allowed to hold major positions in the Imperial government, or the Prussian government. After 1871, there was a systematic purge of the remaining Catholics; in the powerful interior ministry, which handled all police affairs, the only Catholic was a messenger boy. Jews were likewise heavily discriminated against.

Most of the Kulturkampf was fought out in Prussia, but Imperial Germany passed the Pulpit Law which made it a crime for any cleric to discuss public issues in a way that displeased the government. Nearly all Catholic bishops, clergy, and laymen rejected the legality of the new laws and defiantly faced the increasingly heavy penalties and imprisonments imposed by Bismarck's government. Historian Anthony Steinhoff reports the casualty totals:

Bismarck underestimated the resolve of the Catholic Church and did not foresee the extremes that this struggle would attain. The Catholic Church denounced the harsh new laws as anti-Catholic and mustered the support of its rank and file voters across Germany. In the following elections, the Center Party won a quarter of the seats in the Imperial Diet. The conflict ended after 1879 because Pope Pius IX died in 1878 and Bismarck broke with the Liberals to put his main emphasis on tariffs, foreign policy, and attacking socialists. Bismarck negotiated with the conciliatory new pope Leo XIII. Peace was restored, the bishops returned and the jailed clerics were released. Laws were toned down or taken back (Mitigation Laws 1880–1883 and Peace Laws 1886/87), but the laws concerning education, civil registry of marriages and religious disaffiliation remained in place. The Center Party gained strength and became an ally of Bismarck, especially when he attacked socialism.

Bismarck's post-1871 foreign policy was conservative and basically aimed at security and preventing the dreaded scenario of a Franco-Russian alliance, which would trap Germany between the two in a war.
The League of Three Emperors ("Dreikaisersbund") was signed in 1872 by Russia, Austria, and Germany. It stated that republicanism and socialism were common enemies and that the three powers would discuss any matters concerning foreign policy. Bismarck needed good relations with Russia in order to keep France isolated. In 1877–1878, Russia fought a victorious war with the Ottoman Empire and attempted to impose the Treaty of San Stefano on it. This upset the British in particular, as they were long concerned with preserving the Ottoman Empire and preventing a Russian takeover of the Bosphorus Strait. Germany hosted the Congress of Berlin (1878), whereby a more moderate peace settlement was agreed to. Germany had no direct interest in the Balkans, however, which was largely an Austrian and Russian sphere of influence, although King Carol of Romania was a German prince.

In 1879, Bismarck formed a Dual Alliance of Germany and Austria-Hungary, with the aim of mutual military assistance in the case of an attack from Russia, which was not satisfied with the agreement reached at the Congress of Berlin. The establishment of the Dual Alliance led Russia to take a more conciliatory stance, and in 1887, the so-called Reinsurance Treaty was signed between Germany and Russia: in it, the two powers agreed on mutual military support in the case that France attacked Germany, or in case of an Austrian attack on Russia. Russia turned its attention eastward to Asia and remained largely inactive in European politics for the next 25 years. In 1882, Italy joined the Dual Alliance to form a Triple Alliance. Italy wanted to defend its interests in North Africa against France's colonial policy. In return for German and Austrian support, Italy committed itself to assisting Germany in the case of a French military attack.

For a long time, Bismarck had refused to give in to widespread public demands to give Germany "a place in the sun" through the acquisition of overseas colonies. In 1880 Bismarck gave way, and a number of colonies were established overseas. In Africa, these were Togo, the Cameroons, German South-West Africa, and German East Africa; in Oceania, they were German New Guinea, the Bismarck Archipelago, and the Marshall Islands. In fact, it was Bismarck himself who helped initiate the Berlin Conference of 1885. He did it to "establish international guidelines for the acquisition of African territory" (see Colonisation of Africa). This conference was an impetus for the "Scramble for Africa" and "New Imperialism".

In 1888, emperor William I died at the age of 90. His son Frederick III, the hope of German liberals, was already stricken with throat cancer and died three months later. Frederick's son Wilhelm II then became emperor at the age of 29. Having had a problematic relationship with his liberal parents, Wilhelm had early on decided to renew the top level of the state. The two years that Bismarck remained in office feigned continuity, but a difference of opinion on social politics served as an excuse for the young Kaiser to force the chancellor into retirement in March 1890. Following a principle known as "personal regiment" (German: "persönliches Regiment"), Wilhelm aimed to exercise influence on every government decision.

The young Kaiser Wilhelm sought aggressively to increase Germany's influence in the world ("Weltpolitik"). After the removal of Bismarck, foreign policy was in the hands of the erratic Kaiser, who played an increasingly reckless hand, and the powerful foreign office under the leadership of Friedrich von Holstein. The foreign office argued that: first, a long-term coalition between France and Russia had to fall apart; secondly, Russia and Britain would never get together; and, finally, Britain would eventually seek an alliance with Germany. Germany refused to renew its treaties with Russia. But Russia did form a closer relationship with France in the Dual Alliance of 1894, since both were worried about the possibilities of German aggression. Furthermore, Anglo–German relations cooled as Germany aggressively tried to build a new empire and engaged in a naval race with Britain; London refused to agree to the formal alliance that Germany sought. Berlin's analysis proved mistaken on every point, leading to Germany's increasing isolation and its dependence on the Triple Alliance, which brought together Germany, Austria-Hungary, and Italy. The Triple Alliance was undermined by differences between Austria and Italy, and in 1915 Italy switched sides.

Meanwhile, the German Navy under Admiral Alfred von Tirpitz had ambitions to rival the great British Navy, and dramatically expanded its fleet in the early 20th century to protect the colonies and exert power worldwide. Tirpitz started a programme of warship construction in 1898. In 1890, Germany had gained the island of Heligoland in the North Sea from Britain in exchange for the eastern African island of Zanzibar, and proceeded to construct a great naval base there. This posed a direct threat to British hegemony on the seas, with the result that negotiations for an alliance between Germany and Britain broke down. The British, however, kept well ahead in the naval race by the introduction of the highly advanced new "Dreadnought" battleship in 1907.

In the First Moroccan Crisis of 1905, Germany nearly came to blows with Britain and France when the latter attempted to establish a protectorate over Morocco. The Germans were upset at having not been informed about French intentions, and declared their support for Moroccan independence. William II made a highly provocative speech regarding this. The following year, a conference was held in which all of the European powers except Austria-Hungary (by now little more than a German satellite) sided with France. A compromise was brokered by the United States where the French relinquished some, but not all, control over Morocco.

The Second Moroccan Crisis of 1911 saw another dispute over Morocco erupt when France tried to suppress a revolt there. Germany, still smarting from the previous quarrel, agreed to a settlement whereby the French ceded some territory in central Africa in exchange for Germany's renouncing any right to intervene in Moroccan affairs. This confirmed French control over Morocco, which became a full protectorate of that country in 1912.

The economy continued to industrialize and urbanize, with heavy industry – especially coal and steel – becoming important in the Ruhr, and manufacturing growing in the cities, the Ruhr, and Silesia. Perkins (1981) argues that more important than Bismarck's new tariff on imported grain was the introduction of the sugar beet as a main crop. Farmers quickly abandoned traditional, inefficient practices in favor of modern methods, including use of new fertilizers and new tools. The knowledge and tools gained from the intensive farming of sugar and other root crops made Germany the most efficient agricultural producer in Europe by 1914. Even so, farms were small in size, and women did much of the field work. An unintended consequence was the increased dependence on migratory, especially foreign, labor.
Based on its leadership in chemical research in the universities and industrial laboratories, Germany became dominant in the world's chemical industry in the late 19th century. At first, the production of dyes was critical.

Germany became Europe's leading steel-producing nation in the 1890s, thanks in large part to the protection from American and British competition afforded by tariffs and cartels. The leading firm was "Friedrich Krupp AG Hoesch-Krupp," run by the Krupp family. The merger of several major firms into the "Vereinigte Stahlwerke" (United Steel Works) in 1926 was modeled on the U.S. Steel corporation in the United States. The new company emphasized rationalization of management structures and modernization of the technology; it employed a multi-divisional structure and used return on investment as its measure of success. By 1913, American and German exports dominated the world steel market, as Britain slipped to third place.

In machinery, iron and steel, and other industries, German firms avoided cut-throat competition and instead relied on trade associations. Germany was a world leader because of its prevailing "corporatist mentality", its strong bureaucratic tradition, and the encouragement of the government. These associations regulate competition and allowed small firms to function in the shadow of much larger companies.

Germany's unification process after 1871 was heavily dominated by men and give priority to the "Fatherland" theme and related male issues, such as military prowess. Nevertheless, middle class women enrolled in the "Bund Deutscher Frauenvereine", the Union of German Feminist Organizations (BDF). Founded in 1894, it grew to include 137 separate women's rights groups from 1907 until 1933, when the Nazi regime disbanded the organization. The BDF gave national direction to the proliferating women's organizations that had sprung up since the 1860s. From the beginning the BDF was a bourgeois organization, its members working toward equality with men in such areas as education, financial opportunities, and political life. Working-class women were not welcome; they were organized by the Socialists.

Formal organizations for promoting women's rights grew in numbers during the Wilhelmine period. German feminists began to network with feminists from other countries, and participated in the growth of international organizations.

By the 1890s, German colonial expansion in Asia and the Pacific (Kiauchau in China, the Marianas, the Caroline Islands, Samoa) led to frictions with Britain, Russia, Japan and the United States. The construction of the Baghdad Railway, financed by German banks, was designed to eventually connect Germany with the Turkish Empire and the Persian Gulf, but it also collided with British and Russian geopolitical interests.

The largest colonial enterprises were in Africa. The harsh treatment of the Nama and Herero in what is now Namibia in Africa in 1906–07 led to charges of genocide against the Germans. Historians are examining the links and precedents between the Herero and Namaqua Genocide and the Holocaust of the 1940s.

Ethnic demands for nation states upset the balance between the empires that dominated Europe, leading to World War I, which started in August 1914. Germany stood behind its ally Austria in a confrontation with Serbia, but Serbia was under the protection of Russia, which was allied to France. Germany was the leader of the Central Powers, which included Austria-Hungary, the Ottoman Empire, and later Bulgaria; arrayed against them were the Allies, consisting chiefly of Russia, France, Britain, and in 1915 Italy.

In explaining why neutral Britain went to war with Germany, Kennedy (1980) recognized it was critical for war that Germany become economically more powerful than Britain, but he downplays the disputes over economic trade imperialism, the Baghdad Railway, confrontations in Central and Eastern Europe, high-charged political rhetoric and domestic pressure-groups. Germany's reliance time and again on sheer power, while Britain increasingly appealed to moral sensibilities, played a role, especially in seeing the invasion of Belgium as a necessary military tactic or a profound moral crime. The German invasion of Belgium was not important because the British decision had already been made and the British were more concerned with the fate of France (pp. 457–62). Kennedy argues that by far the main reason was London's fear that a repeat of 1870 — when Prussia and the German states smashed France — would mean that Germany, with a powerful army and navy, would control the English Channel and northwest France. British policy makers insisted that would be a catastrophe for British security.

In the west, Germany sought a quick victory by encircling Paris using the Schlieffen Plan. But it failed due to Belgian resistance, Berlin's diversion of troops, and very stiff French resistance on the Marne, north of Paris.

The Western Front became an extremely bloody battleground of trench warfare. The stalemate lasted from 1914 until early 1918, with ferocious battles that moved forces a few hundred yards at best along a line that stretched from the North Sea to the Swiss border. The British imposed a tight naval blockade in the North Sea which lasted until 1919, sharply reducing Germany's overseas access to raw materials and foodstuffs. Food scarcity became a serious problem by 1917.

The United States joined with the Allies in April 1917. The entry of the United States into the war – following Germany's declaration of unrestricted submarine warfare – marked a decisive turning-point against Germany.

More wide open was the fighting on the Eastern Front. In the east, there were decisive victories against the Russian army, the trapping and defeat of large parts of the Russian contingent at the Battle of Tannenberg, followed by huge Austrian and German successes. The breakdown of Russian forces – exacerbated by internal turmoil caused by the 1917 Russian Revolution – led to the Treaty of Brest-Litovsk the Bolsheviks were forced to sign on 3 March 1918 as Russia withdrew from the war. It gave Germany control of Eastern Europe. Spencer Tucker says, "The German General Staff had formulated extraordinarily harsh terms that shocked even the German negotiator." When Germany later complained that the Treaty of Versailles of 1919 was too harsh on them, the Allies responded that it was more benign than Brest-Litovsk.

By defeating Russia in 1917 Germany was able to bring hundreds of thousands of combat troops from the east to the Western Front, giving it a numerical advantage over the Allies. By retraining the soldiers in new storm-trooper tactics, the Germans expected to unfreeze the Battlefield and win a decisive victory before the American army arrived in strength. However, the spring offensives all failed, as the Allies fell back and regrouped, and the Germans lacked the reserves necessary to consolidate their gains. In the summer, with the Americans arriving at 10,000 a day, and the German reserves exhausted, it was only a matter of time before multiple Allied offenses destroyed the German army.

Unexpectedly Germany plunged into World War I (1914–1918). It rapidly mobilized its civilian economy for the war effort, the economy was handicapped by the British blockade that cut off food supplies.
Meanwhile, conditions deteriorated rapidly on the home front, with severe food shortages reported in all urban areas. Causes involved the transfer of many farmers and food workers into the military, an overburdened railroad system, shortages of coal, and the British blockade that cut off imports from abroad. The winter of 1916–1917 was known as the "turnip winter," because that vegetable, usually fed to livestock, was used by people as a substitute for potatoes and meat, which were increasingly scarce. Thousands of soup kitchens were opened to feed the hungry people, who grumbled that the farmers were keeping the food for themselves. Even the army had to cut the rations for soldiers. Morale of both civilians and soldiers continued to sink.

1918 was also the year of the deadly 1918 Spanish Flu pandemic which struck hard at a population weakened by years of malnutrition.

The end of October 1918, in Wilhelmshaven, in northern Germany, saw the beginning of the German Revolution of 1918–19. Units of the German Navy refused to set sail for a last, large-scale operation in a war which they saw as good as lost, initiating the uprising. On 3 November, the revolt spread to other cities and states of the country, in many of which workers' and soldiers' councils were established. Meanwhile, Hindenburg and the senior commanders had lost confidence in the Kaiser and his government. The Kaiser and all German ruling princes abdicated. On 9 November 1918, the Social Democrat Philipp Scheidemann proclaimed a Republic.
On 11 November, the Compiègne armistice was signed, ending the war. The Treaty of Versailles was signed on 28 June 1919. Germany was to cede Alsace-Lorraine to France. Eupen-Malmédy would temporarily be ceded to Belgium, with a plebiscite to be held to allow the people the choice of the territory either remaining with Belgium or being returned to German control. Following a plebiscite, the territory was allotted to Belgium on 20 September 1920. The future of North Schleswig was to be decided by plebiscite. In the Schleswig Plebiscites, the Danish-speaking population in the north voted for Denmark and the southern, German speaking populace, part voted for Germany. Schleswig was thus partitioned. Holstein remained German without a referendum. Memel was ceded to the Allied and Associated powers, to decide the future of the area. On 9 January 1923, Lithuanian forces invaded the territory. Following negotiations, on 8 May 1924, the League of Nations ratified the annexation on the grounds that Lithuania accepted the Memel Statute, a power-sharing arrangement to protect non-Lithuanians in the territory and its autonomous status. Until 1929, German-Lithuanian co-operation increased and this power sharing arrangement worked. Poland was restored and most of the provinces of Posen and West Prussia, and some areas of Upper Silesia were reincorporated into the reformed country after plebiscites and independence uprisings. All German colonies were to be handed over to League of Nations, who then assigned them as Mandates to Australia, France, Japan, New Zealand, Portugal, and the United Kingdom. The new owners were required to act as a disinterested trustee over the region, promoting the welfare of its inhabitants in a variety of ways until they were able to govern themselves. The left and right banks of the Rhine were to be permanently demilitarised. The industrially important Saarland was to be governed by the League of Nations for 15 years and its coalfields administered by France. At the end of that time a plebiscite was to determine the Saar's future status. To ensure execution of the treaty's terms, Allied troops would occupy the left (German) bank of the Rhine for a period of 5–15 years. The German army was to be limited to 100,000 officers and men; the general staff was to be dissolved; vast quantities of war material were to be handed over and the manufacture of munitions rigidly curtailed. The navy was to be similarly reduced, and no military aircraft were allowed. Germany was also required to pay reparations for all civilian damage caused during the war.

The humiliating peace terms in the Treaty of Versailles provoked bitter indignation throughout Germany, and seriously weakened the new democratic regime. The greatest enemies of democracy had already been constituted. In December 1918, the Communist Party of Germany (KPD) was founded, and in 1919 it tried and failed to overthrow the new republic. Adolf Hitler in 1919 took control of the new National Socialist German Workers' Party (NSDAP), which failed in a coup in Munich in 1923. Both parties, as well as parties supporting the republic, built militant auxiliaries that engaged in increasingly violent street battles. Electoral support for both parties increased after 1929 as the Great Depression hit the economy hard, producing many unemployed men who became available for the paramilitary units. The Nazis (formerly the German Workers' Party), with a mostly rural and lower middle class base, overthrew the Weimar regime and ruled Germany in 1933–1945; the KPD, with a mostly urban and working class base, came to power (in the East) in 1945–1989.

On 11 August 1919 the Weimar constitution came into effect, with Friedrich Ebert as first President.

On 30 December 1918, the Communist Party of Germany was founded by the Spartacus League, who had split from the Social Democratic Party during the war. It was headed by Rosa Luxemburg and Karl Liebknecht, and rejected the parliamentary system. In 1920, about 300,000 members from the Independent Social Democratic Party of Germany joined the party, transforming it into a mass organization. The Communist Party had a following of about 10% of the electorate.

In the first months of 1920, the Reichswehr was to be reduced to 100,000 men, in accordance with the Treaty of Versailles. This included the dissolution of many Freikorps – units made up of volunteers. In an attempt at a coup d'état in March 1920, the Kapp Putsch, extreme right-wing politician Wolfgang Kapp let Freikorps soldiers march on Berlin and proclaimed himself Chancellor of the Reich. After four days the coup d'état collapsed, due to popular opposition and lack of support by the civil servants and the officers. Other cities were shaken by strikes and rebellions, which were bloodily suppressed.

Germany was the first state to establish diplomatic relations with the new Soviet Union. Under the Treaty of Rapallo, Germany accorded the Soviet Union "de jure" recognition, and the two signatories mutually cancelled all pre-war debts and renounced war claims.

When Germany defaulted on its reparation payments, French and Belgian troops occupied the heavily industrialised Ruhr district (January 1923). The German government encouraged the population of the Ruhr to passive resistance: shops would not sell goods to the foreign soldiers, coal-miners would not dig for the foreign troops, trams in which members of the occupation army had taken seat would be left abandoned in the middle of the street. The passive resistance proved effective, insofar as the occupation became a loss-making deal for the French government. But the Ruhr fight also led to hyperinflation, and many who lost all their fortune would become bitter enemies of the Weimar Republic, and voters of the anti-democratic right. See 1920s German inflation.

In September 1923, the deteriorating economic conditions led Chancellor Gustav Stresemann to call an end to the passive resistance in the Ruhr. In November, his government introduced a new currency, the Rentenmark (later: Reichsmark), together with other measures to stop the hyperinflation. In the following six years the economic situation improved. In 1928, Germany's industrial production even regained the pre-war levels of 1913.

The national elections of 1924 led to a swing to the right. Field Marshal Paul von Hindenburg was elected President in 1925.

In October 1925 the Treaty of Locarno was signed by Germany, France, Belgium, Britain and Italy; it recognised Germany's borders with France and Belgium. Moreover, Britain, Italy and Belgium undertook to assist France in the case that German troops marched into the demilitarised Rheinland. Locarno paved the way for Germany's admission to the League of Nations in 1926.

The actual amount of reparations that Germany was obliged to pay out was not the 132 billion marks decided in the London Schedule of 1921 but rather the 50 million marks stipulated in the A and B Bonds. Historian Sally Marks says the 112 billion marks in "C bonds" were entirely chimerical—a device to fool the public into thinking Germany would pay much more. The actual total payout from 1920 to 1931 (when payments were suspended indefinitely) was 20 billion German gold marks, worth about $5 billion US dollars or £1 billion British pounds. 12.5 billion was cash that came mostly from loans from New York bankers. The rest was goods like coal and chemicals, or from assets like railway equipment. The reparations bill was fixed in 1921 on the basis of a German capacity to pay, not on the basis of Allied claims. The highly publicized rhetoric of 1919 about paying for all the damages and all the veterans' benefits was irrelevant for the total, but it did determine how the recipients spent their share. Germany owed reparations chiefly to France, Britain, Italy and Belgium; the US received $100 million.

The Wall Street Crash of 1929 marked the beginning of the worldwide Great Depression, which hit Germany as hard as any nation. In July 1931, the "Darmstätter und Nationalbank" – one of the biggest German banks – failed. In early 1932, the number of unemployed had soared to more than 6,000,000.

On top of the collapsing economy came a political crisis: the political parties represented in the "Reichstag" were unable to build a governing majority in the face of escalating extremism from the far right (the Nazis, NSDAP) and the far left (the Communists, KPD). In March 1930, President Hindenburg appointed Heinrich Brüning Chancellor, invoking article 48 of Weimar's constitution, which allowed him to override the Parliament. To push through his package of austerity measures against a majority of Social Democrats, Communists and the NSDAP (Nazis), Brüning made use of emergency decrees and dissolved Parliament. In March and April 1932, Hindenburg was re-elected in the German presidential election of 1932.

The Nazi Party was the largest party in the national elections of 1932. On 31 July 1932 it received 37.3% of the votes, and in the election on 6 November 1932 it received less, but still the largest share, 33.1%, making it the biggest party in the "Reichstag". The Communist KPD came third, with 15%. Together, the anti-democratic parties of far right and far left were now able to hold the majority of seats in Parliament, but they were at sword's point with each other, fighting it out in the streets. The Nazis were particularly successful among Protestants, among unemployed young voters, among the lower middle class in the cities and among the rural population. It was weakest in Catholic areas and in large cities. On 30 January 1933, pressured by former Chancellor Franz von Papen and other conservatives, President Hindenburg appointed Hitler as Chancellor.

The Weimar years saw a flowering of German science and high culture, before the Nazi regime resulted in a decline in the scientific and cultural life in Germany and forced many renowned scientists and writers to flee.
German recipients dominated the Nobel prizes in science. Germany dominated the world of physics before 1933, led by Hermann von Helmholtz, Joseph von Fraunhofer, Daniel Gabriel Fahrenheit, Wilhelm Conrad Röntgen, Albert Einstein, Max Planck and Werner Heisenberg. Chemistry likewise was dominated by German professors and researchers at the great chemical companies such as BASF and Bayer and persons like Fritz Haber. Theoretical mathematicians included Carl Friedrich Gauss in the 19th century and David Hilbert in the 20th century. Karl Benz, the inventor of the automobile, was one of the pivotal figures of engineering.

Among the most important German writers were Thomas Mann (1875–1955), Hermann Hesse (1877–1962) and Bertolt Brecht (1898–1956). The pessimistic historian Oswald Spengler wrote "The Decline of the West" (1918–23) on the inevitable decay of Western Civilization, and influenced intellectuals in Germany such as Martin Heidegger, Max Scheler, and the Frankfurt School, as well as intellectuals around the world.

After 1933, Nazi proponents of "Aryan physics," led by the Nobel Prize-winners Johannes Stark and Philipp Lenard, attacked Einstein's theory of relativity as a degenerate example of Jewish materialism in the realm of science. Many scientists and humanists emigrated; Einstein moved permanently to the U.S. but some of the others returned after 1945.

The Nazi regime restored economic prosperity and ended mass unemployment using heavy spending on the military, while suppressing labor unions and strikes. The return of prosperity gave the Nazi Party enormous popularity, with only minor, isolated and subsequently unsuccessful cases of resistance among the German population over the 12 years of rule. The Gestapo (secret police) under Heinrich Himmler destroyed the political opposition and persecuted the Jews, trying to force them into exile, while taking their property. The Party took control of the courts, local government, and all civic organizations except the Protestant and Catholic churches. All expressions of public opinion were controlled by Hitler's propaganda minister, Joseph Goebbels, who made effective use of film, mass rallies, and Hitler's hypnotic speaking. The Nazi state idolized Hitler as its Führer (leader), putting all powers in his hands. Nazi propaganda centered on Hitler and was quite effective in creating what historians called the "Hitler Myth"—that Hitler was all-wise and that any mistakes or failures by others would be corrected when brought to his attention. In fact Hitler had a narrow range of interests and decision making was diffused among overlapping, feuding power centers; on some issues he was passive, simply assenting to pressures from whoever had his ear. All top officials reported to Hitler and followed his basic policies, but they had considerable autonomy on a daily basis.

In order to secure a majority for his Nazi Party in the "Reichstag", Hitler called for new elections. On the evening of 27 February 1933, the "Reichstag" building was set afire. Hitler swiftly blamed an alleged Communist uprising, and convinced President Hindenburg to sign the Reichstag Fire Decree, which rescinded most German civil liberties, including rights of assembly and freedom of the press. The decree allowed the police to detain people indefinitely without charges or a court order. Four thousand members of the Communist Party of Germany were arrested. Communist agitation was banned, but at this time not the Communist Party itself. Communists and Socialists were brought into hastily prepared Nazi concentration camps such as Kemna concentration camp, where they were at the mercy of the Gestapo, the newly established secret police force. Communist "Reichstag" deputies were taken into protective custody (despite their constitutional privileges).
Despite the terror and unprecedented propaganda, the last free General Elections of 5 March 1933, while resulting in 43.9% failed to gave the majority for the NSDAP as Hitler had hoped. Together with the German National People's Party (DNVP), however, he was able to form a slim majority government. In March 1933, the Enabling Act, an amendment to the Weimar Constitution, passed in the Reichstag by a vote of 444 to 94. To obtain the two-thirds majority needed to pass the bill, accommodations were made to the Catholic Centre Party, and the Nazis used the provisions of the Reichstag Fire Decree to keep several Social Democratic deputies from attending, and the Communists deputies had already been banned. This amendment allowed Hitler and his cabinet to pass laws—even laws that violated the constitution—without the consent of the president or the Reichstag. The Enabling Act formed the basis for the dictatorship, dissolution of the Länder; the trade unions and all political parties other than the Nazi Party were suppressed. A centralised totalitarian state was established, no longer based on the liberal Weimar constitution. Germany left the League of Nations. The coalition parliament was rigged by defining the absence of arrested and murdered deputies as voluntary and therefore cause for their exclusion as wilful absentees. Subsequently, in July the Centre Party was voluntarily dissolved in a "quid pro quo" with the Pope under the "anti-communist" Pope Pius XI for the "Reichskonkordat"; and by these manoeuvres Hitler achieved movement of these Catholic voters into the Nazi Party, and a long-awaited international diplomatic acceptance of his regime. It is interesting to note, that according to Professor Dick Geary the Nazis gained a larger share of their vote in Protestant areas than in Catholic areas, in the elections held between 1928 and November 1932. The Communist Party was proscribed in April 1933.

Thereafter, the Chief of Staff of the SA, Ernst Röhm, demanded more political and military power for he and his men, which caused anxiety among military, industrial, and political leaders. In response, Hitler used the SS and Gestapo to purge the entire SA leadership—along with a number of Hitler's political adversaries (such as Gregor Strasser and former chancellor Kurt von Schleicher). It became known as the Night of the Long Knives and took place from 30 June to 2 July 1934. As a reward, the SS became an independent organisation under the command of the "Reichsführer-SS" Heinrich Himmler. He would rise to become Chief of German Police in June 1936 and already had control over the concentration camps system. Upon Hindenburg's death on 2 August 1934, Hitler's cabinet passed a law proclaiming the presidency to be vacant and transferred the role and powers of the head of state to Hitler as Chancellor and Führer (Leader).

The Nazi regime was particularly hostile towards Jews, who became the target of unending antisemitic propaganda attacks. The Nazis attempted to convince the German people to view and treat Jews as "subhumans" and immediately after winning almost 44% of parliamentary seats in the 1933 federal elections the Nazis imposed a nationwide boycott of Jewish businesses. In March 1933 the first official Nazi concentration camp was established at Dachau in Bavaria and from 1933 to 1935 the Nazi regime consolidated their power. The Law for the Restoration of the Professional Civil Service passed on 7 April 1933, which forced all Jewish civil servants to retire from the legal profession and civil service. The Nuremberg Laws of 1935 ban sexual relations between Jews and Germans and only those of German or related blood were eligible to be considered citizens; the remainder were classed as state subjects, without citizenship rights. This stripped Jews, Roma and others of their legal rights. Jews continued to suffer persecution under the Nazi regime, exemplified by the Kristallnacht pogrom of 1938, and about half of Germany's 500,000 Jews fled the country before 1939, after which escape became almost impossible.

In 1941, the Nazi leadership decided to implement a plan that they called the "Final Solution" which came to be known as the Holocaust. Under the plan, Jews and other "lesser races" along with political opponents from Germany as well as occupied countries were systematically murdered at murder sites, Nazi concentration camps, and starting in 1942, at extermination camps. Between 1941 and 1945 Jews, Gypsies, Slavs, communists, homosexuals, the mentally and physically disabled and members of other groups were targeted and methodically murdered — the origin of the word "genocide". In total approximately 11 million people were killed during the Holocaust including 1.1 million children.

In 1935, Hitler officially re-established the Luftwaffe (air force) and reintroduced universal military service. This was in breach of the Treaty of Versailles; Britain, France and Italy issued notes of protest. Hitler had the officers swear their personal allegiance to him. In 1936 German troops marched into the demilitarised Rhineland. As the territory was part of Germany, the British and French governments did not feel that attempting to enforce the treaty was worth the risk of war. The move strengthened Hitler's standing in Germany. His reputation swelled further with the 1936 Summer Olympics, which were held in the same year in Berlin, and proved another great propaganda success for the regime as orchestrated by master propagandist Joseph Goebbels.

Historians have paid special attention to the efforts by Nazi Germany to reverse the gains women made before 1933, especially in the relatively liberal Weimar Republic. It appears the role of women in Nazi Germany changed according to circumstances. Theoretically the Nazis advocated a patriarchal society in which the German woman would recognise that her "world is her husband, her family, her children, and her home". However, before 1933, women played important roles in the Nazi organization and were allowed some autonomy to mobilize other women. After Hitler came to power in 1933, feminist groups were shut down or incorporated into the National Socialist Women's League, which coordinated groups throughout the country to promote feminine virtues, motherhood and household activities. Courses were offered on childrearing, sewing and cooking. The Nazi regime did promote a liberal code of conduct regarding heterosexual relations among Germans and was sympathetic to women who bore children out of wedlock. The "Lebensborn" (Fountain of Life) association, founded by Himmler in 1935, created a series of maternity homes where single mothers could be accommodated during their pregnancies.

As Germany prepared for war, large numbers were incorporated into the public sector and with the need for full mobilization of factories by 1943, all women under the age of fifty were required to register with the employment office for work assignments to help the war effort. Women's wages remained unequal and women were denied positions of leadership or control. In 1944–45 more than 500,000 women were volunteer uniformed auxiliaries in the German armed forces (Wehrmacht). About the same number served in civil aerial defense, 400,000 volunteered as nurses, and many more replaced drafted men in the wartime economy. In the Luftwaffe they served in combat roles helping to operate the anti-aircraft systems that shot down Allied bombers.

Hitler's diplomatic strategy in the 1930s was to make seemingly reasonable demands, threatening war if they were not met. When opponents tried to appease him, he accepted the gains that were offered, then went to the next target. That aggressive strategy worked as Germany pulled out of the League of Nations (1933), rejected the Versailles Treaty and began to re-arm (1935), won back the Saar (1935), remilitarized the Rhineland (1936), formed an alliance ("axis") with Mussolini's Italy (1936), sent massive military aid to Franco in the Spanish Civil War (1936–39), annexed Austria (1938), took over Czechoslovakia after the British and French "appeasement" of the Munich Agreement of 1938, formed a peace pact with Joseph Stalin's Soviet Union in August 1939, and finally invaded Poland on 1 September 1939. Britain and France declared war on Germany two days later and World War II in Europe began.

After establishing the "Rome-Berlin axis" with Benito Mussolini, and signing the Anti-Comintern Pact with Japan – which was joined by Italy a year later in 1937 – Hitler felt able to take the offensive in foreign policy. On 12 March 1938, German troops marched into Austria, where an attempted Nazi coup had been unsuccessful in 1934. When Austrian-born Hitler entered Vienna, he was greeted by loud cheers. Four weeks later, 99% of Austrians voted in favour of the annexation (Anschluss) of their country Austria to the German Reich. After Austria, Hitler turned to Czechoslovakia, where the 3.5 million-strong Sudeten German minority was demanding equal rights and self-government. At the Munich Conference of September 1938, Hitler, the Italian leader Benito Mussolini, British Prime Minister Neville Chamberlain and French Prime Minister Édouard Daladier agreed upon the cession of Sudeten territory to the German Reich by Czechoslovakia. Hitler thereupon declared that all of German Reich's territorial claims had been fulfilled. However, hardly six months after the Munich Agreement, in March 1939, Hitler used the smoldering quarrel between Slovaks and Czechs as a pretext for taking over the rest of Czechoslovakia as the Protectorate of Bohemia and Moravia. In the same month, he secured the return of Memel from Lithuania to Germany. Chamberlain was forced to acknowledge that his policy of appeasement towards Hitler had failed.

At first Germany was very successful in its military operations, including the invasions of Poland (1939), Norway (1940), the Low Countries (1940), and France in 1940. The unexpectedly swift defeat of France resulted in an upswing in Hitler's popularity and an upsurge in war fever. Hitler made peace overtures to the new British leader Winston Churchill in July 1940, but Churchill, remained dogged in his defiance. Churchill had major financial, military, and diplomatic help from President Franklin D. Roosevelt in the U.S. Hitler's emphasis on maintaining a higher living standard postponed the full mobilization of the national economy until 1942. Germany's armed forces invaded the Soviet Union in June 1941 – weeks behind schedule due to the invasion of Yugoslavia – but swept forward until they reached the gates of Moscow.
The tide began to turn in December 1941, when the invasion of the Soviet Union hit determined resistance in the Battle of Moscow and Hitler declared war on the United States in the wake of the Japanese Pearl Harbor attack. After surrender in North Africa and losing the Battle of Stalingrad in 1942–43, the Germans were forced into the defensive. By late 1944, the United States, Canada, France, and Great Britain were closing in on Germany in the West, while the Soviets were victoriously advancing in the East. Overy estimated in 2014 that in all about 353,000 civilians were killed by British and American strategic bombing of German cities, and nine million left homeless.

Nazi Germany collapsed as Berlin was taken by the Red Army in a fight to the death on the city streets. Hitler committed suicide on 30 April 1945. The final German Instrument of Surrender was signed on 8 May 1945.

By September 1945, Nazi Germany and its Axis partners (Italy and Japan) had all been defeated, chiefly by the forces of the Soviet Union, the United States, and Great Britain. Much of Europe lay in ruins, over 60 million people worldwide had been killed (most of them civilians), including approximately 6 million Jews and 5 million non-Jews in what became known as the Holocaust. World War II resulted in the destruction of Germany's political and economic infrastructure and led directly to its partition, considerable loss of territory (especially in the East), and historical legacy of guilt and shame.

As a consequence of the defeat of Nazi Germany in 1945 and the onset of the Cold War in 1947, the country was split between the two global blocs in the East and West, a period known as the division of Germany. Millions of refugees from Central and Eastern Europe moved west, most of them to West Germany. Two countries emerged: West Germany was a parliamentary democracy, a NATO member, a founding member of what since became the European Union and one of the world's largest economies and is controlled by the US, while East Germany was a totalitarian Communist dictatorship controlled by the Soviet Union that was a satellite of Moscow. With the collapse of Communism in 1989, reunion on West Germany's terms followed.

No one doubted Germany's economic and engineering prowess; the question was how long bitter memories of the war would cause Europeans to distrust Germany, and whether Germany could demonstrate it had rejected totalitarianism and militarism and embraced democracy and human rights.

The total of German war dead was 8% to 10% out of a prewar population of 69,000,000, or between 5.5 million and 7 million people. This included 4.5 million in the military, and between 1 and 2 million civilians. There was chaos as 11 million foreign workers and POWs left, while 14 million displaced refugees from the east and soldiers returned home. During the Cold War, the West German government estimated a death toll of 2.2 million civilians due to the flight and expulsion of Germans and through forced labour in the Soviet Union. This figure remained unchallenged until the 1990s, when some historians put the death toll at 500,000–600,000 confirmed deaths. In 2006 the German government reaffirmed its position that 2.0–2.5 million deaths occurred.
At the Potsdam Conference, Germany was divided into four military occupation zones by the Allies and did not regain independence until 1949. The provinces east of the Oder and Neisse rivers (the Oder-Neisse line) were transferred to Poland, Lithuania, and Russia (Kaliningrad oblast); the 6.7 million Germans living in Poland and the 2.5 million in Czechoslovakia were forced to move west, although most had already left when the war ended.

Denazification removed, imprisoned, or executed most top officials of the old regime, but most middle and lower ranks of civilian officialdom were not seriously affected. In accordance with the Allied agreement made at the Yalta conference millions of POWs were used as forced labor by the Soviet Union and other European countries.

In the East, the Soviets crushed dissent and imposed another police state, often employing ex-Nazis in the dreaded Stasi. The Soviets extracted about 23% of the East German GNP for reparations, while in the West reparations were a minor factor.

In 1945–46 housing and food conditions were bad, as the disruption of transport, markets, and finances slowed a return to normal. In the West, bombing had destroyed the fourth of the housing stock, and over 10 million refugees from the east had crowded in, most living in camps. Food production in 1946–48 was only two-thirds of the prewar level, while grain and meat shipments – which usually supplied 25% of the food – no longer arrived from the East. Furthermore, the end of the war brought the end of large shipments of food seized from occupied nations that had sustained Germany during the war. Coal production was down 60%, which had cascading negative effects on railroads, heavy industry, and heating. Industrial production fell more than half and reached prewar levels only at the end of 1949.

Allied economic policy originally was one of industrial disarmament plus building the agricultural sector. In the western sectors, most of the industrial plants had minimal bomb damage and the Allies dismantled 5% of the industrial plants for reparations.

However, deindustrialization became impractical and the U.S. instead called for a strong industrial base in Germany so it could stimulate European economic recovery. The U.S. shipped food in 1945–47 and made a $600 million loan in 1947 to rebuild German industry. By May 1946 the removal of machinery had ended, thanks to lobbying by the U.S. Army. The Truman administration finally realised that economic recovery in Europe could not go forward without the reconstruction of the German industrial base on which it had previously been dependent. Washington decided that an "orderly, prosperous Europe requires the economic contributions of a stable and productive Germany."

In 1945 the occupying powers took over all newspapers in Germany and purged them of Nazi influence. The American occupation headquarters, the Office of Military Government, United States (OMGUS) began its own newspaper based in Munich, "Die Neue Zeitung." It was edited by German and Jewish émigrés who fled to the United States before the war. Its mission was to encourage democracy by exposing Germans to how American culture operated. The paper was filled with details on American sports, politics, business, Hollywood, and fashions, as well as international affairs.

In 1949 the western half of the Soviet zone became the "Deutsche Demokratische Republik" – "DDR" ("German Democratic Republic" – "GDR", simply often "East Germany"), under control of the Socialist Unity Party. Neither country had a significant army until the 1950s, but East Germany built the Stasi into a powerful secret police that infiltrated every aspect of the society.

East Germany was an Eastern bloc state under political and military control of the Soviet Union through her occupation forces and the Warsaw Treaty. Political power was solely executed by leading members ("Politburo") of the communist-controlled Socialist Unity Party (SED). A Soviet-style command economy was set up; later the GDR became the most advanced Comecon state. While East German propaganda was based on the benefits of the GDR's social programs and the alleged constant threat of a West German invasion, many of her citizens looked to the West for political freedoms and economic prosperity.

Walter Ulbricht (1893–1973) was the party boss from 1950 to 1971. In 1933, Ulbricht had fled to Moscow, where he served as a Comintern agent loyal to Stalin. As World War II was ending, Stalin assigned him the job of designing the postwar German system that would centralize all power in the Communist Party. Ulbricht became deputy prime minister in 1949 and secretary (chief executive) of the Socialist Unity (Communist) party in 1950. Some 2.6 million people had fled East Germany by 1961 when he built the Berlin Wall to stop them — shooting those who attempted it. What the GDR called the "Anti-Fascist Protective Wall" was a major embarrassment for the program during the Cold War, but it did stabilize East Germany and postpone its collapse. Ulbricht lost power in 1971, but was kept on as a nominal head of state. He was replaced because he failed to solve growing national crises, such as the worsening economy in 1969–70, the fear of another popular uprising as had occurred in 1953, and the disgruntlement between Moscow and Berlin caused by Ulbricht's détente policies toward the West.

The transition to Erich Honecker (General Secretary from 1971 to 1989) led to a change in the direction of national policy and efforts by the Politburo to pay closer attention to the grievances of the proletariat. Honecker's plans were not successful, however, with the dissent growing among East Germany's population.

In 1989, the socialist regime collapsed after 40 years, despite its omnipresent secret police, the Stasi. Main reasons for the collapse include severe economic problems and growing emigration towards the West.

East Germany's culture was shaped by Communism and particularly Stalinism. It was characterized by East German psychoanalyst Hans-Joachim Maaz in 1990 as having produced a "Congested Feeling" among Germans in the East as a result of Communist policies criminalizing personal expression that deviates from government approved ideals, and through the enforcement of Communist principals by physical force and intellectual repression by government agencies, particularly the Stasi. Critics of the East German state have claimed that the state's commitment to communism was a hollow and cynical tool of a ruling elite. This argument has been challenged by some scholars who claim that the Party was committed to the advance of scientific knowledge, economic development, and social progress. However, the vast majority regarded the state's Communist ideals to be nothing more than a deceptive method for government control.

According to German historian Jürgen Kocka (2010):

In 1949, the three western occupation zones (American, British, and French) were combined into the Federal Republic of Germany (FRG, West Germany). The government was formed under Chancellor Konrad Adenauer and his conservative CDU/CSU coalition. The CDU/CSU was in power during most of the period since 1949. The capital was Bonn until it was moved to Berlin in 1990. In 1990 FRG absorbed East Germany and gained full sovereignty over Berlin. At all points West Germany was much larger and richer than East Germany, which became a dictatorship under the control of the Communist Party and was closely monitored by Moscow. Germany, especially Berlin, was a cockpit of the Cold War, with NATO and the Warsaw Pact assembling major military forces in west and east. However, there was never any combat.

West Germany enjoyed prolonged economic growth beginning in the early 1950s ("Wirtschaftswunder" or "Economic Miracle"). Industrial production doubled from 1950 to 1957, and gross national product grew at a rate of 9 or 10% per year, providing the engine for economic growth of all of Western Europe. Labor union supported the new policies with postponed wage increases, minimized strikes, support for technological modernization, and a policy of co-determination ("Mitbestimmung"), which involved a satisfactory grievance resolution system as well as requiring representation of workers on the boards of large corporations. The recovery was accelerated by the currency reform of June 1948, U.S. gifts of $1.4 billion as part of the Marshall Plan, the breaking down of old trade barriers and traditional practices, and the opening of the global market. West Germany gained legitimacy and respect, as it shed the horrible reputation Germany had gained under the Nazis.

West Germany played a central role in the creation of European cooperation; it joined NATO in 1955 and was a founding member of the European Economic Community in 1958.

The most dramatic and successful policy event was the currency reform of 1948. Since the 1930s, prices and wages had been controlled, but money had been plentiful. That meant that people had accumulated large paper assets, and that official prices and wages did not reflect reality, as the black market dominated the economy and more than half of all transactions were taking place unofficially. On 21 June 1948, the Western Allies withdrew the old currency and replaced it with the new Deutsche Mark at the rate of 1 new per 10 old. This wiped out 90% of government and private debt, as well as private savings. Prices were decontrolled, and labor unions agreed to accept a 15% wage increase, despite the 25% rise in prices. The result was that prices of German export products held steady, while profits and earnings from exports soared and were poured back into the economy. The currency reforms were simultaneous with the $1.4 billion in Marshall Plan money coming in from the United States, which was used primarily for investment.

In addition, the Marshall Plan forced German companies, as well as those in all of Western Europe, to modernize their business practices and take account of the international market. Marshall Plan funding helped overcome bottlenecks in the surging economy caused by remaining controls (which were removed in 1949), and Marshall Plan business reforms opened up a greatly expanded market for German exports. Overnight, consumer goods appeared in the stores, because they could be sold for realistic prices, emphasizing to Germans that their economy had turned a corner.

The success of the currency reform angered the Soviets, who cut off all road, rail, and canal links between the western zones and West Berlin. This was the Berlin Blockade, which lasted from 24 June 1948 to 12 May 1949. In response, the U.S. and Britain launched an airlift of food and coal and distributed the new currency in West Berlin as well. The city thereby became economically integrated into West Germany.

Konrad Adenauer (1876–1967) was the dominant leader in West Germany. He was the first chancellor (top official) of the FRG, 1949–63, and until his death was the founder and leader of the Christian Democratic Union (CDU), a coalition of conservatives, ordoliberals, and adherents of Protestant and Catholic social teaching that dominated West Germany politics for most of its history. During his chancellorship, the West Germany economy grew quickly, and West Germany established friendly relations with France, participated in the emerging European Union, established the country's armed forces (the "Bundeswehr"), and became a pillar of NATO as well as firm ally of the United States. Adenauer's government also commenced the long process of reconciliation with the Jews and Israel after the Holocaust.

Ludwig Erhard (1897–1977) was in charge of economic policy as economics director for the British and American occupation zones and was Adenauer's long-time economics minister. Erhard's decision to lift many price controls in 1948 (despite opposition from both the social democratic opposition and Allied authorities), plus his advocacy of free markets, helped set the Federal Republic on its strong growth from wartime devastation. Norbert Walter, a former chief economist at Deutsche Bank, argues that "Germany owes its rapid economic advance after World War II to the system of the Social Market Economy, established by Ludwig Erhard." Erhard was politically less successful when he served as the CDU Chancellor from 1963 until 1966. Erhard followed the concept of a social market economy, and was in close touch with professional economists. Erhard viewed the market itself as social and supported only a minimum of welfare legislation. However, Erhard suffered a series of decisive defeats in his effort to create a free, competitive economy in 1957; he had to compromise on such key issues as the anti-cartel legislation. Thereafter, the West German economy evolved into a conventional west European welfare state.

Meanwhile, in adopting the Godesberg Program in 1959, the Social Democratic Party of Germany (SPD) largely abandoned Marxism ideas and embraced the concept of the market economy and the welfare state. Instead it now sought to move beyond its old working class base to appeal the full spectrum of potential voters, including the middle class and professionals. Labor unions cooperated increasingly with industry, achieving labor representation on corporate boards and increases in wages and benefits.

In 1966 Erhard lost support and Kurt Kiesinger (1904–1988) was elected as Chancellor by a new CDU/CSU-SPD alliance combining the two largest parties. Socialist (SPD) leader Willy Brandt was Deputy Federal Chancellor and Foreign Minister. The Grand Coalition lasted 1966–69 and is best known for reducing tensions with the Soviet bloc nations and establishing diplomatic relations with Czechoslovakia, Romania and Yugoslavia.

With a booming economy short of unskilled workers, especially after the Berlin Wall cut off the steady flow of East Germans, the FRG negotiated migration agreements with Italy (1955), Spain (1960), Greece (1960), and Turkey (1961) that brought in hundreds of thousands of temporary guest workers, called "Gastarbeiter". In 1968 the FRG signed a guest worker agreement with Yugoslavia that employed additional guest workers. "Gastarbeiter" were young men who were paid full-scale wages and benefits, but were expected to return home in a few years.

The agreement with Turkey ended in 1973 but few workers returned because there were few good jobs in Turkey. By 2010 there were about 4 million people of Turkish descent in Germany. The generation born in Germany attended German schools, but had a poor command of either German or Turkish, and had either low-skilled jobs or were unemployed.

Willy Brandt (1913–1992) was the leader of the Social Democratic Party in 1964–87 and West German Chancellor in 1969–1974. Under his leadership, the German government sought to reduce tensions with the Soviet Union and improve relations with the German Democratic Republic, a policy known as the "Ostpolitik". Relations between the two German states had been icy at best, with propaganda barrages in each direction. The heavy outflow of talent from East Germany prompted the building of the Berlin Wall in 1961, which worsened Cold War tensions and prevented East Germans from travel. Although anxious to relieve serious hardships for divided families and to reduce friction, Brandt's "Ostpolitik" was intent on holding to its concept of "two German states in one German nation."

"Ostpolitik" was opposed by the conservative elements in Germany, but won Brandt an international reputation and the Nobel Peace Prize in 1971. In September 1973, both West and East Germany were admitted to the United Nations. The two countries exchanged permanent representatives in 1974, and, in 1987, East Germany's leader Erich Honecker paid an official state visit to West Germany.

After 1973, Germany was hard hit by a worldwide economic crisis, soaring oil prices, and stubbornly high unemployment, which jumped from 300,000 in 1973 to 1.1 million in 1975. The Ruhr region was hardest hit, as its easy-to-reach coal mines petered out, and expensive German coal was no longer competitive. Likewise the Ruhr steel industry went into sharp decline, as its prices were undercut by lower-cost suppliers such as Japan. The welfare system provided a safety net for the large number of unemployed workers, and many factories reduce their labor force and began to concentrate on high-profit specialty items. After 1990 the Ruhr moved into service industries and high technology. Cleaning up the heavy air and water pollution became a major industry in its own right. Meanwhile, formerly rural Bavaria became a high-tech center of industry.

A spy scandal forced Brandt to step down as Chancellor while remaining as party leader. He was replaced by Helmut Schmidt (b. 1918), of the SPD, who served as Chancellor in 1974–1982. Schmidt continued the "Ostpolitik" with less enthusiasm. He had a PhD in economics and was more interested in domestic issues, such as reducing inflation. The debt grew rapidly as he borrowed to cover the cost of the ever more expensive welfare state. After 1979, foreign policy issues grew central as the Cold War turned hot again. The German peace movement mobilized hundreds of thousands of demonstrators to protest against American deployment in Europe of new medium-range ballistic missiles. Schmidt supported the deployment but was opposed by the left wing of the SPD and by Brandt.

The pro-business Free Democratic Party (FDP) had been in coalition with the SPD, but now it changed direction. Led by Finance Minister Otto Graf Lambsdorff (1926–2009) the FDP adopted the market-oriented "Kiel Theses" in 1977; it rejected the Keynesian emphasis on consumer demand, and proposed to reduce social welfare spending, and try to introduce policies to stimulate production and facilitate jobs. Lambsdorff argued that the result would be economic growth, which would itself solve both the social problems and the financial problems. As a consequence, the FDP switched allegiance to the CDU and Schmidt lost his parliamentary majority in 1982. For the only time in West Germany's history, the government fell on a vote of no confidence.

Helmut Kohl (1930–2017) brought the conservatives back to power with a CDU/CSU-FDP coalition in 1982, and served as Chancellor until 1998. After repeated victories in 1983, 1987, 1990 and 1994 he was finally defeated by a landslide that was the biggest on record, for the left in the 1998 federal elections, and was succeeded as Chancellor by Gerhard Schröder of the SPD. Kohl is best known for orchestrating reunification with the approval of all the Four Powers from World War II, who still had a voice in German affairs.

During the summer of 1989, rapid changes known as "peaceful revolution" or "Die Wende" took place in East Germany, which quickly led to German reunification. Growing numbers of East Germans emigrated to West Germany, many via Hungary after Hungary's reformist government opened its borders. Thousands of East Germans also tried to reach the West by staging sit-ins at West German diplomatic facilities in other East European capitals, most notably in Prague. The exodus generated demands within East Germany for political change, and mass demonstrations in several cities continued to grow.

Unable to stop the growing civil unrest, Erich Honecker was forced to resign in October, and on 9 November, East German authorities unexpectedly allowed East German citizens to enter West Berlin and West Germany. Hundreds of thousands of people took advantage of the opportunity; new crossing points were opened in the Berlin Wall and along the border with West Germany. This led to the acceleration of the process of reforms in East Germany that ended with the German reunification that came into force on 3 October 1990.

The SPD in coalition with the Greens won the elections of 1998. SPD leader Gerhard Schröder positioned himself as a centrist "Third Way" candidate in the mold of Britain's Tony Blair and America's Bill Clinton.

Schröder, in March 2003, reversed his position and proposed a significant downsizing of the welfare state, known as Agenda 2010. He had enough support to overcome opposition from the trade unions and the SPD's left wing. Agenda 2010 had five goals: tax cuts; labor market deregulation, especially relaxing rules protecting workers from dismissal and setting up Hartz concept job training; modernizing the welfare state by reducing entitlements; decreasing bureaucratic obstacles for small businesses; and providing new low-interest loans to local governments.

From 2005 to 2009, Germany was ruled by a grand coalition led by the CDU's Angela Merkel as chancellor. Since the 2009 elections, Merkel has headed a centre-right government of the CDU/CSU and FDP.

Together with France and other EU states, Germany has played the leading role in the European Union. Germany (especially under Chancellor Helmut Kohl) was one of the main supporters of admitting many East European countries to the EU. Germany is at the forefront of European states seeking to exploit the momentum of monetary union to advance the creation of a more unified and capable European political, defence and security apparatus. German Chancellor Schröder expressed an interest in a permanent seat for Germany in the UN Security Council, identifying France, Russia, and Japan as countries that explicitly backed Germany's bid. Germany formally adopted the Euro on 1 January 1999 after permanently fixing the Deutsche Mark rate on 21 December 1998.

Since 1990, the German Bundeswehr has participated in a number of peacekeeping and disaster relief operations abroad. Since 2002, German troops formed part of the International Security Assistance Force in the war in Afghanistan, resulting in the first German casualties in combat missions since World War II.

In the worldwide economic recession that began in 2008, Germany did relatively well. However, the economic instability of Greece and several other EU nations in 2010–11 forced Germany to reluctantly sponsor a massive financial rescue.

In the wake of the disaster to the nuclear industry in Japan following its 2011 earthquake and tsunami, German public opinion turned sharply against nuclear power in Germany, which produces a fourth of the electricity supply. In response Merkel has announced plans to close down the nuclear system over the next decade, and to rely even more heavily on wind and other alternative energy sources, in addition to coal and natural gas. For further information, see Germany in 2011.

Germany was affected by the European migrant crisis in 2015 as it became the final destination of choice for many asylum seekers from Africa and the Middle East entering the EU. The country took in over a million refugees and migrants and developed a quota system which redistributed migrants around its federal states based on their tax income and existing population density. The decision by Merkel to authorize unrestricted entry led to heavy criticism in Germany as well as within Europe.

A major historiographical debate about the German history concerns the "Sonderweg", the alleged "special path" that separated German history from the normal course of historical development, and whether or not Nazi Germany was the inevitable result of the "Sonderweg". Proponents of the "Sonderweg" theory such as Fritz Fischer point to such events of the Revolution of 1848, the authoritarianism of the Second Empire and the continuation of the Imperial elite into the Weimar and Nazi periods. Opponents such as Gerhard Ritter of the "Sonderweg" theory argue that proponents of the theory are guilty of seeking selective examples, and there was much contingency and chance in German history. In addition, there was much debate within the supporters of the "Sonderweg" concept as for the reasons for the "Sonderweg", and whether or not the "Sonderweg" ended in 1945. Was there a Sonderweg? Winkler says:
















</doc>
<doc id="13225" url="https://en.wikipedia.org/wiki?curid=13225" title="Hades">
Hades

Hades (; "Háidēs") was the ancient Greek chthonic god of the underworld, which eventually took his name.

In Greek mythology, Hades was regarded as the oldest son of Cronus and Rhea, although the last son regurgitated by his father. He and his brothers Zeus and Poseidon defeated their father's generation of gods, the Titans, and claimed rulership over the cosmos. Hades received the underworld, Zeus the sky, and Poseidon the sea, with the solid earth—long the province of Gaia—available to all three concurrently. Hades was often portrayed with his three-headed guard dog Cerberus.

The Etruscan god Aita and Roman gods Dis Pater and Orcus were eventually taken as equivalent to the Greek Hades and merged as Pluto, a Latinization of his euphemistic Greek name Plouton ( "Ploútōn").

The origin of Hades' name is uncertain, but has generally been seen as meaning "The Unseen One" since antiquity. An extensive section of Plato's dialogue "Cratylus" is devoted to the etymology of the god's name, in which Socrates is arguing for a folk etymology not from "unseen" but from "his knowledge ("eidenai") of all noble things". Modern linguists have proposed the Proto-Greek form *"Awides" ("unseen"). The earliest attested form is "Aḯdēs" (), which lacks the proposed digamma. West argues instead for an original meaning of "the one who presides over meeting up" from the universality of death.

In Homeric and Ionic Greek, he was known as "Áïdēs". Other poetic variations of the name include "Aïdōneús" () and the inflected forms "Áïdos" (, gen.), "Áïdi" (, dat.), and "Áïda" (, acc.), whose reconstructed nominative case *"Áïs" () is, however, not attested. The name as it came to be known in classical times was "Háidēs" (). Later the iota became silent, then a subscript marking (), and finally omitted entirely (). 

Perhaps from fear of pronouncing his name, around the 5th century BC, the Greeks started referring to Hades as Pluto ( "Ploútōn"), with a root meaning "wealthy", considering that from the abode below (i.e., the soil) come riches (e.g., fertile crops, metals and so on). Plouton became the Roman god who both rules the underworld and distributed riches from below. This deity was a mixture of the Greek god Hades and the Eleusinian icon Ploutos, and from this he also received a priestess, which was not previously practiced in Greece. More elaborate names of the same genre were "Ploutodótēs" () or "Ploutodotḗr" () meaning "giver of wealth".

Epithets of Hades include "Agesander" () and "Agesilaos" (), both from "ágō" (, "lead", "carry" or "fetch") and "anḗr" (, "man") or "laos" (, "men" or "people"), describing Hades as the god who carries away all. Nicander uses the form "Hegesilaus" (). He was also referred to as "Zeus katachthonios" (Ζεὺς καταχθόνιος), meaning "the Zeus of the Underworld", by those avoiding his actual name, as he had complete control over the Underworld.

In Greek mythology, Hades, the god of the underworld, was a son of the Titans Cronus and Rhea. He had three sisters, Demeter, Hestia, and Hera, as well as two brothers, Poseidon and Zeus, the youngest of the three.
Upon reaching adulthood, Zeus managed to force his father to disgorge his siblings. After their release, the six younger gods, along with allies they managed to gather, challenged the elder gods for power in the Titanomachy, a divine war. The war lasted for ten years and ended with the victory of the younger gods. Following their victory, according to a single famous passage in the "Iliad" (xv.187–93), Hades and his two brothers, Poseidon and Zeus, drew lots for realms to rule. Zeus received the sky, Poseidon received the seas, and Hades received the underworld, the unseen realm to which the souls of the dead go upon leaving the world as well as any and all things beneath the earth. Some myths suggest that Hades was dissatisfied with his turnout, but had no choice and moved to his new realm.

Hades obtained his wife and queen, Persephone, through abduction at the behest of Zeus. This myth is the most important one Hades takes part in; it also connected the Eleusinian Mysteries with the Olympian pantheon, particularly as represented in the "Homeric Hymn to Demeter", which is the oldest story of the abduction, most likely dating back to the beginning of the 6th Century BC. Helios told the grieving Demeter that Hades was not unworthy as a consort for Persephone:

Despite modern connotations of death as evil, Hades was actually more altruistically inclined in mythology. Hades was often portrayed as passive rather than evil; his role was often maintaining relative balance. That said, he was also depicted as cold and stern, and he held all of his subjects equally accountable to his laws. Any other individual aspects of his personality are not given, as Greeks refrained from giving him much thought to avoid attracting his attention. 

Hades ruled the dead, assisted by others over whom he had complete authority. The House of Hades was described as full of "guests," though he rarely left the Underworld. He cared little about what happened in the Upperworld, as his primary attention was ensuring none of his subjects ever left. He strictly forbade his subjects to leave his domain and would become quite enraged when anyone tried to leave, or if someone tried to steal the souls from his realm. His wrath was equally terrible for anyone who tried to cheat death or otherwise crossed him, as Sisyphus and Pirithous found out to their sorrow. While usually indifferent to his subjects, Hades was very focused on the punishment of these two people; particularly Pirithous, as he entered the underworld in an attempt to steal Persephone for himself, and consequently was forced onto the "Chair of Forgetfulness". Another myth is about the Roman god Asclepius who was originally a demigod, fathered by Apollo and birthed by Coronis, a Thessalian princess. During his lifetime, he became a famous and talented physician, who eventually was able to bring the dead back to life. Feeling cheated, Plouton persuaded Zeus to kill him with a thunderbolt. After his death, he was brought to Olympus where he became a god. Hades was only depicted outside of the Underworld once in myth, and even that is believed to have been an instance where he had just left the gates of the Underworld, which was when Heracles shot him with an arrow as Hades was attempting to defend the city of Plyus. After he was shot, however, he traveled to Olympus to heal. Besides Heracles, the only other living people who ventured to the Underworld were also heroes: Odysseus, Aeneas (accompanied by the Sibyl), Orpheus, who Hades showed uncharacteristic mercy towards at Persephone's persuasion, who was moved by Orpheus' music, Theseus with Pirithous, and, in a late romance, Psyche. None of them were pleased with what they witnessed in the realm of the dead. In particular, the Greek war hero Achilles, whom Odysseus conjured with a blood libation, said:

Hades, as the god of the dead, was a fearsome figure to those still living; in no hurry to meet him, they were reluctant to swear oaths in his name, and averted their faces when sacrificing to him. Since to many, simply to say the word "Hades" was frightening, euphemisms were pressed into use. Since precious minerals come from under the earth (i.e., the "underworld" ruled by Hades), he was considered to have control of these as well, and was referred to as Πλούτων ("Plouton", related to the word for "wealth"), Latinized as Pluto. Sophocles explained the notion of referring to Hades as "the rich one" with these words: "the gloomy Hades enriches himself with our sighs and our tears." In addition, he was called Clymenus ("notorious"), Polydegmon ("who receives many"), and perhaps Eubuleus ("good counsel" or "well-intentioned"), all of them euphemisms for a name that was unsafe to pronounce, which evolved into epithets.

He spent most of the time in his dark realm. Formidable in battle, he proved his ferocity in the famous Titanomachy, the battle of the Olympians versus the Titans, which established the rule of Zeus.

Feared and loathed, Hades embodied the inexorable finality of death: "Why do we loathe Hades more than any god, if not because he is so adamantine and unyielding?" The rhetorical question is Agamemnon's. He was not, however, an evil god, for although he was stern, cruel, and unpitying, he was still just. Hades ruled the Underworld and was therefore most often associated with death and feared by men, but he was not Death itself — the actual embodiment of Death was Thanatos, although Euripides' play ""Alkestis"" states fairly clearly that Thanatos and Hades were one and the same deity, and gives an interesting description of him as dark-cloaked and winged; moreover, Hades was also referred to as ""Hesperos Theos"" (""God of Death and Darkness"").

When the Greeks propitiated Hades, they banged their hands on the ground to be sure he would hear them. Black animals, such as sheep, were sacrificed to him, and the very vehemence of the rejection of human sacrifice expressed in myth suggests an unspoken memory of some distant past. The blood from all chthonic sacrifices including those to propitiate Hades dripped into a pit or cleft in the ground. The person who offered the sacrifice had to avert his face.

One ancient source says that he possessed the Cap of invisibility. His chariot, drawn by four black horses, made for a fearsome and impressive sight. His other ordinary attributes were the narcissus and cypress plants, the Key of Hades and Cerberus, the three-headed dog. In certain portraits, snakes also appeared to be attributed to Hades as he was occasionally portrayed to be either holding them or accompanied by them. This is believed to hold significance as in certain classical sources Hades ravished Kore in the guise of a snake, who went on to give birth to Zagreus-Dionysus. While bearing the name 'Zeus', Zeus Olympios, the great king of the gods, noticeably differs from the Zeus Meilichios, a decidedly Chthonian character, often portrayed as a snake, and as seen beforehand, they cannot be different manifestations of the same god, in fact whenever 'another Zeus' is mentioned, this always refers to Hades. Zeus Meilichios and Zeus Eubouleus are often referred to being alternate names for Hades.

The philosopher Heraclitus, unifying opposites, declared that Hades and Dionysus, the very essence of indestructible life "(zoë)", are the same god. Among other evidence Kerényi notes that the grieving goddess Demeter refused to drink wine, which is the gift of Dionysus, after Persephone's abduction, because of this association, and suggests that Hades may in fact have been a "cover name" for the underworld Dionysus. He suggests that this dual identity may have been familiar to those who came into contact with the Mysteries. One of the epithets of Dionysus was "Chthonios", meaning "the subterranean". The role of unifying Hades, Zeus and Dionysus as a single tripartite god was used to represent the birth, death and resurrection of a deity and to unify the 'shining' realm of Zeus and the dark underworld realm of Hades.

 Hades was depicted so infrequently in artwork, as well as mythology, because the Greeks were so afraid of him. His artistic representations, which are generally found in Archaic pottery, are not even concretely thought of as the deity; however at this point in time it is heavily believed that the figures illustrated are indeed Hades. He was later presented in the classical arts in the depictions of the Rape of Persephone. Within these illustrations, Hades was often young, yet he was also shown as varying ages in other works. Due to this lack of depictions, there weren't very strict guidelines when representing the deity. On pottery, he has a dark beard and is presented as a stately figure on an "ebony throne." His attributes in art include a scepter, cornucopia, rooster, and a key, which both represented his control over the underworld and acted as a reminder that the gates of the Underworld were always locked so that souls could not leave. Even if the doors were open, Cerberus, the three-headed guard dog of the Underworld, ensured that while all souls were allowed to enter into The Underworld freely, none could ever escape. The dog is often portrayed next to the god as a means of easy identification, since no other deity relates to it so directly. Sometimes, artists painted Hades as looking away from the other gods, as he was disliked by them as well as humans.

As Plouton, he was regarded in a more positive light. He holds a cornucopia, representing the gifts he bestows upon people as well as fertility, which he becomes connected to.
The consort of Hades was Persephone, represented by the Greeks as the beautiful daughter of Demeter.

Persephone did not submit to Hades willingly, but was abducted by him while picking flowers in the fields of Nysa. In protest of his act, Demeter cast a curse on the land and there was a great famine; though, one by one, the gods came to request she lift it, lest mankind perish, she asserted that the earth would remain barren until she saw her daughter again. Finally, Zeus intervened; via Hermes, he requested that Hades return Persephone. Hades complied,
Demeter questioned Persephone on her return to light and air:

This bound her to Hades and the Underworld, much to the dismay of Demeter. It is not clear whether Persephone was accomplice to the ploy. Zeus proposed a compromise, to which all parties agreed: of the year, Persephone would spend one third with her husband.

It is during this time that winter casts on the earth "an aspect of sadness and mourning."

Theseus and Pirithous pledged to kidnap and marry daughters of Zeus. Theseus chose Helen and together they kidnapped her and decided to hold onto her until she was old enough to marry. Pirithous chose Persephone. They left Helen with Theseus' mother, Aethra, and traveled to the Underworld. Hades knew of their plan to capture his wife, so he pretended to offer them hospitality and set a feast; as soon as the pair sat down, snakes coiled around their feet and held them there. Theseus was eventually rescued by Heracles but Pirithous remained trapped as punishment for daring to seek the wife of a god for his own.

Heracles' final labour was to capture Cerberus. First, Heracles went to Eleusis to be initiated into the Eleusinian Mysteries. He did this to absolve himself of guilt for killing the centaurs and to learn how to enter and exit the underworld alive. He found the entrance to the underworld at Taenarum. Athena and Hermes helped him through and back from Hades. Heracles asked Hades for permission to take Cerberus. Hades agreed as long as Heracles didn't harm Cerberus. When Heracles dragged the dog out of Hades, he passed through the cavern Acherusia.

The nymph Minthe, associated with the river Cocytus, loved by Hades, was turned into the mint plant, by a jealous Persephone.

In older Greek myths, the realm of Hades is the misty and gloomy abode of the dead (also called Erebus) where all mortals go when they die. Very few mortals could leave Hades once they entered. The exceptions, Heracles and Theseus, are heroic. Even Odysseus in his "Nekyia" ("Odyssey", xi) calls up the spirits of the departed, rather than descend to them. Later Greek philosophy introduced the idea that all mortals are judged after death and are either rewarded or cursed.

There were several sections of the realm of Hades, including Elysium, the Asphodel Meadows, and Tartarus. Greek mythographers were not perfectly consistent about the geography of the afterlife. A contrasting myth of the afterlife concerns the Garden of the Hesperides, often identified with the Isles of the Blessed, where the blessed heroes may dwell.

In Roman mythology, the entrance to the Underworld located at Avernus, a crater near Cumae, was the route Aeneas used to descend to the realm of the dead. By synecdoche, "Avernus" could be substituted for the underworld as a whole. The "di inferi" were a collective of underworld divinities.

For Hellenes, the deceased entered the underworld by crossing the Styx, ferried across by Charon kair'-on), who charged an "obolus," a small coin for passage placed in the mouth of the deceased by pious relatives. Paupers and the friendless gathered for a hundred years on the near shore according to Book VI of Vergil's Aeneid. Greeks offered propitiatory libations to prevent the deceased from returning to the upper world to "haunt" those who had not given them a proper burial. The far side of the river was guarded by Cerberus, the three-headed dog defeated by Heracles (Roman Hercules). Passing beyond Cerberus, the shades of the departed entered the land of the dead to be judged.

The five rivers of the realm of Hades, and their symbolic meanings, are Acheron (the river of sorrow, or woe), Cocytus (lamentation), Phlegethon (fire), Lethe (oblivion), and Styx (hate), the river upon which even the gods swore and in which Achilles was dipped to render him invincible. The Styx forms the boundary between the upper and lower worlds. See also Eridanos.

The first region of Hades comprises the Fields of Asphodel, described in "Odyssey" xi, where the shades of heroes wander despondently among lesser spirits, who twitter around them like bats. Only libations of blood offered to them in the world of the living can reawaken in them for a time the sensations of humanity.

Beyond lay Erebus, which could be taken for a euphonym of Hades, whose own name was dread. There were two pools, that of Lethe, where the common souls flocked to erase all memory, and the pool of Mnemosyne ("memory"), where the initiates of the Mysteries drank instead. In the forecourt of the palace of Hades and Persephone sit the three judges of the Underworld: Minos, Rhadamanthus, and Aeacus. There at the trivium sacred to Hecate, where three roads meet, souls are judged, returned to the Fields of Asphodel if they are neither virtuous nor evil, sent by the road to Tartarus if they are impious or evil, or sent to Elysium (Islands of the Blessed) with the "blameless" heroes.

In the Sibylline oracles, a curious hodgepodge of Greco-Roman and Judaeo-Christian elements, Hades again appears as the abode of the dead, and by way of folk etymology, it even derives "Hades" from the name Adam (the first man), saying it is because he was the first to enter there. Owing to its appearance in the New Testament of the Bible, "Hades" also has a distinct meaning in Christianity.





</doc>
<doc id="13236" url="https://en.wikipedia.org/wiki?curid=13236" title="GNU Hurd">
GNU Hurd

GNU Hurd is the multiserver microkernel written as part of GNU. It has been under development since 1990 by the GNU Project of the Free Software Foundation, designed as a replacement for the Unix kernel, and released as free software under the GNU General Public License. While the Linux kernel soon proved to be a more viable solution, development of GNU Hurd continued, albeit at a slow pace.

GNU Hurd consists of a set of protocols and server processes (or daemons, in Unix terminology) that run on the GNU Mach microkernel. The Hurd aims to surpass the Unix kernel in functionality, security, and stability, while remaining largely compatible with it. The GNU Project chose the multiserver microkernel for the operating system, due to perceived advantages over the traditional Unix monolithic kernel architecture, a view that had been advocated by some developers in the 1980s.

In December 1991 the primary architect of the Hurd described the name as a mutually recursive acronym:
As both "hurd" and "hird" are homophones of the English word "herd", the full name "GNU Hurd" is also a play on the words "herd of gnus", reflecting how the kernel works. The logo is called the "Hurd boxes" and it also reflects on architecture. The logo is a graph where nodes represent the Hurd kernel's servers and directed edges are IPC messages.

Richard Stallman founded the GNU Project in September 1983 with an aim to create a free GNU operating system. Initially the components required for kernel development were written: editors, shell, compiler and all the others. By 1989, the GNU GPL came into being and the only major component missing was the kernel.

Development on the Hurd began in 1990 after an abandoned kernel attempt in 1986, based on the research TRIX operating system developed by Professor Steve Ward and his group at MIT's Laboratory for Computer Science (LCS). According to Thomas Bushnell, the initial Hurd architect, their early plan was to adapt the 4.4BSD-Lite kernel and, in hindsight, "It is now perfectly obvious to me that this would have succeeded splendidly and the world would be a very different place today". In 1987 Richard Stallman proposed using the Mach microkernel developed at Carnegie Mellon University. Work on this was delayed for three years due to uncertainty over whether CMU would release the Mach code under a suitable license.

With the release of the Linux kernel in 1991, the primary user of GNU's userland components soon became operating systems based on the Linux kernel (Linux distributions), prompting the coining of the term "GNU/Linux".

Development of the Hurd has proceeded slowly. Despite an optimistic announcement by Stallman in 2002 predicting a release of GNU/Hurd later that year, the Hurd is still not considered suitable for production environments. Development in general has not met expectations, and there are still a significant number of bugs and missing features. This has resulted in a poorer product than many (including Stallman) had expected. In 2010, after twenty years under development, Stallman said that he was "not very optimistic about the GNU Hurd. It makes some progress, but to be really superior it would require solving a lot of deep problems", but added that "finishing it is not crucial" for the GNU system because a free kernel already existed (Linux), and completing Hurd would not address the main remaining problem for a free operating system: device support.

The Debian project, among others, have worked on the Hurd project to produce binary distributions of Hurd-based GNU operating systems for IBM PC compatible systems.

After years of stagnation, development picked up again in 2015 and 2016, with four releases during these two years.

On August 20, 2015, amid the Google Summer of Code, it was announced that GNU Guix had been ported to GNU Hurd, making it the first native package manager on the Hurd.

Unlike most Unix-like kernels, the Hurd uses a server–client architecture, built on a microkernel that is responsible for providing the most basic kernel services – coordinating access to the hardware: the CPU (through process management and scheduling), RAM (via memory management), and other various input/output devices (via I/O scheduling) for sound, graphics, mass storage, etc. In theory the microkernel design would allow for all device drivers to be built as servers working in user space, but today most drivers of this kind are still contained in the GNU Mach kernel space.

According to Hurd developers, the main advantage of microkernel-based design is the ability to extend the system: developing a new module would not require in depth knowledge of the rest of the kernel, and a bug in one module would not crash the entire system. Hurd provides a concept of "translators", a framework of modules used to extend a file system functionality.

From early on, the Hurd was developed to use GNU Mach as the microkernel. This was a technical decision made by Richard Stallman, who thought it would speed up the work by saving a large part of it. He has admitted that he was wrong about that. Other Unix-like systems working on the Mach microkernel include OSF/1, Lites, and MkLinux. macOS and NeXTSTEP use hybrid kernels based on Mach.

From 2004 onward, various efforts were launched to port the Hurd to more modern microkernels. The L4 microkernel was the original choice in 2004, but progress slowed to a halt. Nevertheless, during 2005, Hurd developer Neal Walfield finished the initial memory management framework for the L4/Hurd port, and Marcus Brinkmann ported essential parts of glibc; namely, getting the process startup code working, allowing programs to run, thus allowing the first user programs (trivial ones such as the hello world program) in C to run.

Since 2005 Brinkmann and Walfield started researching Coyotos as a new kernel for HURD. In 2006, Brinkmann met with Jonathan Shapiro (a primary architect of the Coyotos Operating System) to aid in and discuss the use of the Coyotos kernel for GNU/Hurd. In further discussion HURD developers realised that Coyotos (as well as other similar kernels) are not suitable for HURD.

In 2007, Hurd developers Neal Walfield and Marcus Brinkmann gave a critique of the Hurd architecture, known as "the critique", and a proposal for how a future system may be designed, known as "the position paper". In 2008, Neal Walfield began working on the Viengoos microkernel as a modern native kernel for HURD. , development on Viengoos is paused due to Walfield lacking time to work on it.

In the meantime, others have continued working on the Mach variant of Hurd.

A number of traditional Unix concepts are replaced or extended in the Hurd.

Under Unix, every running program has an associated user id, which normally corresponds to the user that started the process. This id largely dictates the actions permitted to the program. No outside process can change the user id of a running program. A Hurd process, on the other hand, runs under a "set" of user ids, which can contain multiple ids, one, or none. A sufficiently privileged process can add and remove ids to another process. For example, there is a password server that will hand out ids in return for a correct login password.

Regarding the file system, a suitable program can be designated as a "translator" for a single file or a whole directory hierarchy. Every access to the translated file, or files below a hierarchy in the second case, is in fact handled by the program. For example, a file translator may simply redirect read and write operations to another file, like a Unix symbolic link. The effect of Unix "mounting" is achieved by setting up a filesystem translator (using the "settrans" command). Translators can also be used to provide services to the user. For example, the ftpfs translator allows a user to encapsulate remote FTP sites within a directory. Then, standard tools such as ls, cp, and rm can be used to manipulate files on the remote system. Even more powerful translators are ones such as UnionFS, which allows a user to unify multiple directories into one; thus listing the unified directory reveals the contents of all the directories.

The Hurd requires a multiboot-compliant boot loader, such as GRUB.

According to the Debian documentation, there are 24 servers (18 core servers and 6 file system servers) named as follows:



The servers collectively implement the POSIX API, with each server implementing a part of the interface. For instance, the various filesystem servers each implement the filesystem calls. The storage server will work as a wrapping layer, similar to the block layer of Linux. The equivalent of VFS of Linux is achieved by libdiskfs and libpager libraries.

Hurd-based GNU distributions include:




</doc>
<doc id="13240" url="https://en.wikipedia.org/wiki?curid=13240" title="Hollywood cycles">
Hollywood cycles

In the classic era of the cinema of the United States (1930 – 1945) "cycles" or 
genres matured. They were called cycles, which was a short term for stories that were similar. While we would recognize many of the genres as Westerns, gangsters, musicals, etc., often the cycles were significantly more specific. Instead of "romantic comedy" it might be "Boy-meets-girl-boy-loses-girl-boy-gets-girl" cycle.



</doc>
<doc id="13250" url="https://en.wikipedia.org/wiki?curid=13250" title="Health care reform">
Health care reform

Health care reform is a general rubric used for discussing major health policy creation or changes—for the most part, governmental policy that affects health care delivery in a given place. Health care reform typically attempts to:

In the United States, the debate regarding health care reform includes questions of a right to health care, access, fairness, sustainability, quality and amounts spent by government. The mixed public-private health care system in the United States is the most expensive in the world, with health care costing more per person than in any other nation, and a greater portion of gross domestic product (GDP) is spent on it than in any other United Nations member state except for East Timor (Timor-Leste). A study of international health care spending levels in the year 2000, published in the health policy journal "Health Affairs", found that while the U.S. spends more on health care than other countries in the Organization for Economic Co-operation and Development (OECD), the use of health care services in the U.S. is below the OECD median by most measures. The authors of the study concluded that the prices paid for health care services are much higher in the U.S.

In spite of the amount spent on health care in the U.S., according to a 2008 Commonwealth Fund report, the United States ranks last in the quality of health care among developed countries. The World Health Organization (WHO), in 2000, ranked the US health care system 37th in overall performance and 72nd by overall level of health (among 191 member nations included in the study). International comparisons that could lead to conclusions about the quality of the health care received by Americans are subject to debate. The US pays twice as much yet lags other wealthy nations in such measures as infant mortality and life expectancy, which are among the most widely collected, hence easily compared, international statistics. Many people are underinsured, for example, in Colorado "of those with insurance for a full year, 36.3% were underinsured." About 10.7 million insured Americans spend more than a quarter of their annual paychecks on health care because of the high deductible policies.

The Patient Protection and Affordable Care Act (Public Law 111-148) was signed into law by President Barack Obama on March 23, 2010. Along with the Health Care and Education Reconciliation Act of 2010 (signed March 30), the Act is a product of the health care reform efforts of the Democratic 111th Congress and the Obama administration. The law includes health-related provisions to take effect over the next four years, including expanding Medicaid eligibility for people making up to 133% of the federal poverty level (FPL), subsidizing insurance premiums for people making up to 400% of the FPL ($88,000 for family of 4 in 2010) so their maximum "out-of-pocket" payment for annual premiums will be from 2% to 9.5% of income, providing incentives for businesses to provide health care benefits, prohibiting denial of coverage and denial of claims based on pre-existing conditions, establishing health insurance exchanges, prohibiting insurers from establishing annual coverage caps, and support for medical research. According to White House and Congressional Budget Office figures, the maximum share of income that enrollees would have to pay for the would vary depending on their income relative to the federal poverty level, as follows: for families with income 133–150% of FPL will be 3–4% of income, for families with income of 150–200% of FPL will be 4–6.3% of income, for families with income 200–250% of FPL will be 6.3–8.1% of income, for families with income 250–300% of FPL will be 8.1–9.5% of income, for families with income from 300 to 400% of FPL will be 9.5% of income.

The costs of these provisions are offset by a variety of taxes, fees, and cost-saving measures, such as new Medicare taxes for those in high-income brackets, taxes on indoor tanning, cuts to the Medicare Advantage program in favor of traditional Medicare, and fees on medical devices and pharmaceutical companies; there is also a tax penalty for those who do not obtain health insurance, unless they are exempt due to low income or other reasons. The Congressional Budget Office estimates that the net effect of both laws will be a reduction in the federal deficit by $143 billion over the first decade.

The universal health care proposal pending in the U.S. Congress is called the United States National Health Care Act (H.R. 676, formerly the "Medicare for All Act.") The Congressional Budget Office and related government agencies scored the cost of a universal health care system several times since 1991, and have uniformly predicted cost savings, probably because of the 40% cost savings associated with universal preventative care and elimination of insurance company overhead costs.

In 2009, the Health Information Technology for Economic and Clinical Health Act (HITECH) offered monetary incentives from 2011 to 2015 for adopting EHR technology to decrease the length of time for hospitals and other healthcare facilities to move from paper records to an electronic health record system. The technology, while not without its pitfalls, should allow easier documentation and storage, the ability to access the information from a bedside, and the ability to sync prescriptions with a bar code.

The Affordable Care Act was enacted with the goals of increasing the quality and affordability of health insurance, lowering the uninsured rate by expanding public and private insurance coverage, and reducing the costs of healthcare for individuals and the government. Health care providers receive payment more frequently as the number of insured people increases and the number of uninsured patients unable to pay out of pocket declines. Competition between insurers in the new health insurance marketplace has increased pressure on insurance companies to reduce premium rates, leading to reduced compensation rates to providers in some plans.

Many healthcare facilities are struggling to break even since the cost of providing health services has increased, due to wages, technology, and resources. Medicare reimbursement payments to health providers for orthopaedic procedures such as total knee arthroplasty, lumbar spine repair, open rotator cuff repair, and open ankle fracture repair, declined from 1992–2010 which means the providers must rely on self-pay patients and patients with commercial insurances to make up the difference. The changes in regulations regarding risk pool assessment and the inclusion of 10 essential health benefits to every insurance plan have also contributed to the rise in cost of insurance premiums. 

Both Hawaii and Massachusetts have implemented some incremental reforms in health care, but neither state has complete coverage of its citizens. For example, data from the Kaiser Family Foundation shows that 5% of Massachusetts and 8% of Hawaii residents are uninsured. To date, The U.S. Uniform Law Commission, sponsored by the National Conference of Commissioners on Uniform State Laws has not submitted a uniform act or model legislation regarding health care insurance or health care reform.

The United States spends more on health care than any other country in the world, and, yet, has poorer health status by many measures. In 2007, the United States spent $7,290 per capita on health care. The average among peer nations in the Organisation for Economic Cooperation and Development (OECD) is $3075, just 42 percent of U.S. spending. Health spending is concentrated on a few consumers. In 2006, almost half of all health care spending was used to treat just 5 percent of the population, according to the Kaiser Family Foundation. More than half of bankruptcy filings are related to health care expenses, and sixty-eight percent of these cases are filed by people who have health insurance. According to the White House Council of Economic Advisors, the average family income will be $2,600 lower by 2020, if the growth in the cost of health care is not slowed by at least 1.5 percent. The cost of health insurance premiums more than doubled between 1999 and 2008 while workers' earnings stagnated. In 2008, the average annual cost for family insurance coverage was $12,700.

Even though the United States spends more on health care than any other country in the world, in 2015 the Organization for Economic Co-operation and Development (OECD) reported that about 38.2% of adults in the United States are obese. The obesity rates among American adults is almost triple of any other country on the top ten list of countries spending the most money on health care in the world. The United States is also the only country in the top 10 of health care spending with an average lifespan under 80 years of age. The incredibly high health care expenditures in the United States results from a combination of various factors; medical practitioner salaries, expensive medical procedures, hospital costs, and most of all pharmaceutical products. Drug manufacturers in the United States set their own prices, while also allowing "government-protected monopolies" for certain drug manufacturers by granting sole drug manufacturers patents for 20 years or more.

An estimated 52 million people – more than 15 percent of the people in the United States – are currently without health insurance or access to a government health care program. Nationally, 77 percent of the people who are uninsured are workers or are dependents of someone who works. In 2008, employees of small businesses contributed an average of $4,101 for family coverage, compared to $2,982 paid by employees in large firms. About 59 percent of employees with incomes below the poverty level ($18,310 for a family of three) do not have health insurance. At income levels twice to three times the poverty level, about 34 percent lack insurance. Half as many lack insurance at four times the poverty level.

Healthcare was reformed in 1948 after the Second World War, broadly along the lines of the 1942 Beveridge Report, with the creation of the National Health Service or NHS. It was originally established as part of a wider reform of social services and funded by a system of National Insurance, though receipt of healthcare was never contingent upon making contributions towards the National Insurance Fund. Private health care was not abolished but had to compete with the NHS. About 15% of all spending on health in the UK is still privately funded but this includes the patient contributions towards NHS provided prescription drugs, so private sector healthcare in the UK is quite small. As part of a wider reform of social provision it was originally thought that the focus would be as much about the prevention of ill-health as it was about curing disease. The NHS for example would distribute baby formula milk fortified with vitamins and minerals in an effort to improve the health of children born in the post war years as well as other supplements such as cod liver oil and malt. Many of the common childhood diseases such as measles, mumps, and chicken pox were mostly eradicated with a national program of vaccinations.

The NHS has been through many reforms since 1974. The Conservative Thatcher administrations attempted to bring competition into the NHS by developing a supplier/buyer role between hospitals as suppliers and health authorities as buyers. This necessitated the detailed costing of activities, something which the NHS had never had to do in such detail, and some felt was unnecessary. The Labour Party generally opposed these changes, although after the party became New Labour, the Blair government retained elements of competition and even extended it, allowing private health care providers to bid for NHS work. Some treatment and diagnostic centres are now run by private enterprise and funded under contract. However, the extent of this privatisation of NHS work is still small, though remains controversial. The administration committed more money to the NHS raising it to almost the same level of funding as the European average and as a result, there was large expansion and modernisation programme and waiting times improved.

The government of Gordon Brown proposed new reforms for care in England. One is to take the NHS back more towards health prevention by tackling issues that are known to cause long term ill health. The biggest of these is obesity and related diseases such as diabetes and cardio-vascular disease. The second reform is to make the NHS a more personal service, and it is negotiating with doctors to provide more services at times more convenient to the patient, such as in the evenings and at weekends. This personal service idea would introduce regular health check-ups so that the population is screened more regularly. Doctors will give more advice on ill-health prevention (for example encouraging and assisting patients to control their weight, diet, exercise more, cease smoking etc.) and so tackle problems before they become more serious. Waiting times, which fell considerably under Blair (median wait time is about 6 weeks for elective non-urgent surgery) are also in focus. A target was set from December 2008, to ensure that no person waits longer than 18 weeks from the date that a patient is referred to the hospital to the time of the operation or treatment. This 18-week period thus includes the time to arrange a first appointment, the time for any investigations or tests to determine the cause of the problem and how it should be treated. An NHS Constitution was published which lays out the legal rights of patients as well as promises (not legally enforceable) the NHS strives to keep in England.

Numerous healthcare reforms in Germany were legislative interventions to stabilise the public health insurance since 1983. 9 out of 10 citizens are publicly insured, only 8% privately. Health care in Germany, including its industry and all services, is one of the largest sectors of the German economy. The total expenditure in health economics of Germany was about 287.3 billion euro in 2010, equivalent to 11.6 percent of the gross domestic product (GDP) this year and about 3,510 euro per capita. Direct inpatient and outpatient care equal just about a quarter of the entire expenditure - depending on the perspective. Expenditure on pharmaceutical drugs is almost twice the amount of those for the entire hospital sector. Pharmaceutical drug expenditure grew by an annual average of 4.1% between 2004 and 2010.

These developments have caused numerous healthcare reforms since the 1980s. An actual example of 2010 and 2011: First time since 2004 the drug expenditure fell from 30.2 billion euro in 2010, to 29.1 billion Euro in 2011, i. e. minus 1.1 billion Euro or minus 3.6%. That was caused by restructuring the Social Security Code: manufacturer discount 16% instead of 6%, price moratorium, increasing discount contracts, increasing discount by wholesale trade and pharmacies.

The Netherlands has introduced a new system of health care insurance based on risk equalization through a risk equalization pool. In this way, a compulsory insurance package is available to all citizens at affordable cost without the need for the insured to be assessed for risk by the insurance company. Furthermore, health insurers are now willing to take on high risk individuals because they receive compensation for the higher risks.

A 2008 article in the journal Health Affairs suggested that the Dutch health system, which combines mandatory universal coverage with competing private health plans, could serve as a model for reform in the US.

Following the collapse of the Soviet Union, Russia embarked on a series of reforms intending to deliver better healthcare by compulsory medical insurance with privately owned providers in addition to the state run institutions. According to the OECD none of 1991-93 reforms worked out as planned and the reforms had in many respects made the system worse. Russia has more physicians, hospitals, and healthcare workers than almost any other country in the world on a per capita basis, but since the collapse of the Soviet Union, the health of the Russian population has declined considerably as a result of social, economic, and lifestyle changes. However, after Putin became president in 2000 there was significant growth in spending for public healthcare and in 2006 it exceed the pre-1991 level in real terms. Also life expectancy increased from 1991-93 levels, infant mortality rate dropped from 18.1 in 1995 to 8.4 in 2008. Russian Prime Minister Vladimir Putin announced a large-scale health care reform in 2011 and pledged to allocate more than 300 billion rubles ($10 billion) in the next few years to improve health care in the country.

Taiwan changed its healthcare system in 1995 to a National Health Insurance model similar to the US Medicare system for seniors. As a result, the 40% of Taiwanese people who had previously been uninsured are now covered. It is said to deliver universal coverage with free choice of doctors and hospitals and no waiting lists. Polls in 2005 are reported to have shown that 72.5% of Taiwanese are happy with the system, and when they are unhappy, it's with the cost of premiums (equivalent to less than US$20 a month).

Employers and the self-employed are legally bound to pay National Health Insurance (NHI) premiums which are similar to social security contributions in other countries. However, the NHI is a pay-as-you-go system. The aim is for the premium income to pay costs. The system is also subsidized by a tobacco tax surcharge and contributions from the national lottery.

As evidenced by the large variety of different healthcare systems seen across the world, there are several different pathways that a country could take when thinking about reform. In comparison to the UK, physicians in Germany have more bargaining power through professional organizations (i.e., physician associations); this ability to negotiate affects reform efforts. Germany makes use of sickness funds, which citizens are obliged to join but are able to opt out if they have a very high income (Belien 87). The Netherlands used a similar system but the financial threshold for opting out was lower (Belien 89). The Swiss, on the other hand use more of a privately based health insurance system where citizens are risk-rated by age and sex, among other factors (Belien 90). The United States government provides healthcare to just over 25% of its citizens through various agencies, but otherwise does not employ a system. Healthcare is generally centered around regulated private insurance methods.

One key component to healthcare reform is the reduction of healthcare fraud and abuse. In the U.S. and the EU, it is estimated that as much as 10 percent of all healthcare transactions and expenditures may be fraudulent. See Terry L. Leap, "Phantom Billing, Fake Prescriptions, and the High Cost of Medicine: Health Care Fraud and What to do about It" (Cornell University Press, 2011).

Also interesting to notice is the oldest healthcare system in the world and its advantages and disadvantages, see Health in Germany.

In "“Getting Health Reform Right: A Guide to Improving Performance and Equity,”" Marc Roberts, William Hsiao, Peter Berman, and Michael Reich of the Harvard T.H. Chan School of Public Health aim to provide decision-makers with tools and frameworks for health care system reform. They propose five “control knobs” of health reform: financing, payment, organization, regulation, and behavior. These control knobs refer to the “mechanisms and processes that reformers can adjust to improve system performance”. The authors selected these control knobs as representative of the most important factors upon which a policymaker can act to determine health system outcomes. 

Their method emphasizes the importance of “identifying goals explicitly, diagnosing causes of poor performance systematically, and devising reforms that will produce real changes in performance”. The authors view health care systems as a means to an end. Accordingly, the authors advocate for three intrinsic performance goals of the health system that can be adjusted through the control knobs. These goals include: 
The authors also propose three intermediate performance measures, which are useful in determining the performance of system goals, but are not final objectives. These include:
While final performance goals are largely agreed upon, other frameworks suggest alternative intermediate goals to those mentioned here, such as equity, productivity, safety, innovation, and choice. 

The five proposed control knobs represent the mechanisms and processes that policy-makers can use to design effective health care reforms. These control knobs are not only the most important elements of a healthcare system, but they also represent the aspect that can be deliberately adjusted by reforms to affect change. The five control knobs are:
The five control knobs of health care reform are not designed to work in isolation; health care reform may require the adjustment of more than one knob or of multiple knobs simultaneously. Further, there is no agreed-upon order of turning control knobs to achieve specific reforms or outcomes. Health care reform varies by setting and reforms from one context may not necessarily apply in another. It is important to note that the knobs interact with cultural and structural factors that are not illustrated within this framework, but which have an important effect on health care reform in a given context. 

In summary, the authors of "“Getting Health Reform Right: A Guide to Improving Performance and Equity”" propose a framework for assessing health systems that guides decision-makers’ understanding of the reform process. Rather than a prescriptive proposal of recommendations, the framework allows users to adapt their analysis and actions based on cultural context and relevance of interventions. As noted above, many frameworks for health care reform exist in the literature. Using a comprehensive yet responsive approach such as the control knobs framework proposed by Roberts, Hsiao, Berman, and Reich allows decision-makers to more precisely determine the “mechanisms and processes” that can be changed in order to achieve improved health status, customer satisfaction, and financial risk protection.



</doc>
<doc id="13253" url="https://en.wikipedia.org/wiki?curid=13253" title="Henry Mayhew">
Henry Mayhew

Henry Mayhew (25 November 1812 – 25 July 1887) was an English social researcher, journalist, playwright and advocate of reform. He was one of the co-founders of the satirical and humorous magazine "Punch" in 1841, and was the magazine's joint-editor, with Mark Lemon, in its early days. He is also known for his work as a social researcher, publishing an extensive series of newspaper articles in the "Morning Chronicle" that was later compiled into the book series "London Labour and the London Poor" (1851), a groundbreaking and influential survey of the city's poor.

He was born in London, one of seventeen children of Joshua Mayhew. He was educated at Westminster School before running away from his studies to sea. He then served with the East India Company as a midshipman on a ship bound for Calcutta. He returned after several years, in 1829, becoming a trainee lawyer in Wales. He left this and became a freelance journalist. He contributed to "The Thief", a readers' digest, followed quickly by editing a weekly journal – "Figaro in London". Mayhew reputedly fled his creditors and holed up at The Erwood Inn, a small public house in the village of Erwood, south of Builth Wells in Wales.

In 1835 Mayhew found himself in a state of debt and, along with a fellow writer, escaped to Paris to avoid his creditors. He spent his time writing and in the company of other writers including William Thackeray and Douglas Jerrold. Mayhew spent over ten years in Paris returning to England in the 1850s whereby he was involved in several literary adventures, mostly the writing of plays. Two of his plays – "But, However" and the "Wandering Minstrel" – were successful, whilst his early work "Figaro in London" was less successful.

On 17 July 1841 Mayhew cofounded Punch magazine. At its founding the magazine was jointly edited by Mayhew and Mark Lemon. The two men hired a group of writers and also illustrators to aid them. These included Douglas Jerrold, Angus Reach, John Leech, Richard Doyle and Shirley Brooks. Initially it was subtitled "The London Charivari", this being a reference to a satirical humour magazine published in France under the title "Le Charivari" (a work read often whilst Mayhew was in Paris). Reflecting their satiric and humorous intent, the two editors took for their name and masthead the anarchic glove puppet Mr. Punch.

"Punch" was an unexpected success, selling about 6,000 copies a week in the early years. However, sales of as many as 10,000 issues a week were required to cover all costs of the magazine. In December 1842, the magazine was sold to Bradbury and Evans; Mayhew resigned as joint editor, and he continued at the magazine as "suggestor in chief" with Mark Lemon reappointed as editor. Mayhew eventually severed his connection with the magazine, writing his last article in February 1845. His brother Horace stayed on the board of Punch until his own death.

The "Punch" years gave Mayhew the opportunity to meet talented illustrators who he later employed to work from daguerreotypes on "London Labour and the London Poor". Following "Punch" magazine, Mayhew new launched "Iron Times", a railway magazine. However this venture lost Mayhew so much money that he was forced to appear in a Court of Bankruptcy in 1846.

In 1842 Mayhew contributed to the pioneering Illustrated London News. By this time Mayhew had become reasonably secure financially, had settled his debts and married Jane Jerrold, the daughter of his friend Douglas Jerrold. She lived until 1880.

The articles comprising "London Labour and the London Poor" were initially collected into three volumes in 1851; the 1861 edition included a fourth volume, co-written with Bracebridge Hemyng, John Binny and Andrew Halliday, on the lives of prostitutes, thieves and beggars. This Extra Volume took a more general and statistical approach to its subject than Volumes 1 to 3.

Mayhew wrote in volume one: ""I shall consider the whole of the metropolitan poor under three separate phases, according as they "will" work, they "can't" work, and they "won't" work"". He interviewed everyone—beggars, street-entertainers (such as Punch and Judy men), market traders, prostitutes, labourers, sweatshop workers, even down to the "mudlarks" who searched the stinking mud on the banks of the River Thames for wood, metal, rope and coal from passing ships, and the "pure-finders" who gathered dog faeces to sell to tanners. He described their clothes, how and where they lived, their entertainments and customs, and made detailed estimates of the numbers and incomes of those practising each trade. The books show how marginal and precarious many people's lives were, in what, at that time, was the richest city in the world.

Mayhew's richly detailed descriptions give an impression of what the street markets of his day were like. An example from Volume 1:

Some of the London street traders did not like the way Mayhew wrote about them. In spring/summer 1851 they established a "Street Trader's Protection Association" to guard themselves against the journalist.

Mayhew was the grandfather of Audrey Mayhew Allen (b. 1870), an author of a number of children's stories published in various periodicals, and of "Gladys in Grammarland", an imitation of Lewis Carroll's "Wonderland" books.

Mayhew's work was embraced by and was an influence on the Christian Socialists, such as Thomas Hughes, Charles Kingsley, and F. D. Maurice. Radicals also published sizeable excerpts from the reports in the Northern Star, the Red Republican, and other newspapers. The often sympathetic investigations, with their immediacy and unswerving eye for detail, offered unprecedented insights into the condition of the Victorian poor. Alongside the earlier work of Edwin Chadwick, they are also regarded as a decisive influence on the thinking of Charles Dickens.

Mayhew's work inspired the script of director Christine Edzard's 1990 film "The Fool". Mayhew has appeared as a character in television and radio histories of Victorian London ; he was played by Timothy West in the documentary "London" (2004), and David Haig in the Afternoon Play "A Chaos of Wealth and Want" (2010). In the 2012 novel "Dodger" by Terry Pratchett, Mayhew and his wife appear as fictionalised versions of themselves, and he is mentioned in the dedication.




</doc>
<doc id="13255" url="https://en.wikipedia.org/wiki?curid=13255" title="Hydrogen">
Hydrogen

Hydrogen is a chemical element with symbol H and atomic number 1. With a standard atomic weight of , hydrogen is the lightest element on the periodic table. Its monatomic form (H) is the most abundant chemical substance in the Universe, constituting roughly 75% of all baryonic mass. Non-remnant stars are mainly composed of hydrogen in the plasma state. The most common isotope of hydrogen, termed "protium" (name rarely used, symbol H), has one proton and no neutrons.

The universal emergence of atomic hydrogen first occurred during the recombination epoch. At standard temperature and pressure, hydrogen is a colorless, odorless, tasteless, non-toxic, nonmetallic, highly combustible diatomic gas with the molecular formula H. Since hydrogen readily forms covalent compounds with most nonmetallic elements, most of the hydrogen on Earth exists in molecular forms such as water or organic compounds. Hydrogen plays a particularly important role in acid–base reactions because most acid-base reactions involve the exchange of protons between soluble molecules. In ionic compounds, hydrogen can take the form of a negative charge (i.e., anion) when it is known as a hydride, or as a positively charged (i.e., cation) species denoted by the symbol H. The hydrogen cation is written as though composed of a bare proton, but in reality, hydrogen cations in ionic compounds are always more complex. As the only neutral atom for which the Schrödinger equation can be solved analytically, study of the energetics and bonding of the hydrogen atom has played a key role in the development of quantum mechanics.

Hydrogen gas was first artificially produced in the early 16th century by the reaction of acids on metals. In 1766–81, Henry Cavendish was the first to recognize that hydrogen gas was a discrete substance, and that it produces water when burned, the property for which it was later named: in Greek, hydrogen means "water-former".

Industrial production is mainly from steam reforming natural gas, and less often from more energy-intensive methods such as the electrolysis of water. Most hydrogen is used near the site of its production, the two largest uses being fossil fuel processing (e.g., hydrocracking) and ammonia production, mostly for the fertilizer market. Hydrogen is a concern in metallurgy as it can embrittle many metals, complicating the design of pipelines and storage tanks.

Hydrogen gas (dihydrogen or molecular hydrogen, also called diprotium when consisting specifically of a pair of protium atoms) is highly flammable and will burn in air at a very wide range of concentrations between 4% and 75% by volume. The enthalpy of combustion is −286 kJ/mol:

Hydrogen gas forms explosive mixtures with air in concentrations from 4–74% and with chlorine at 5–95%. The explosive reactions may be triggered by spark, heat, or sunlight. The hydrogen autoignition temperature, the temperature of spontaneous ignition in air, is . Pure hydrogen-oxygen flames emit ultraviolet light and with high oxygen mix are nearly invisible to the naked eye, as illustrated by the faint plume of the Space Shuttle Main Engine, compared to the highly visible plume of a Space Shuttle Solid Rocket Booster, which uses an ammonium perchlorate composite. The detection of a burning hydrogen leak may require a flame detector; such leaks can be very dangerous. Hydrogen flames in other conditions are blue, resembling blue natural gas flames.

The destruction of the Hindenburg airship was a notorious example of hydrogen combustion and the cause is still debated. The visible orange flames in that incident were the result of a rich mixture of hydrogen to oxygen combined with carbon compounds from the airship skin.

H reacts with every oxidizing element. Hydrogen can react spontaneously and violently at room temperature with chlorine and fluorine to form the corresponding hydrogen halides, hydrogen chloride and hydrogen fluoride, which are also potentially dangerous acids.

The ground state energy level of the electron in a hydrogen atom is −13.6 eV, which is equivalent to an ultraviolet photon of roughly 91 nm wavelength.

The energy levels of hydrogen can be calculated fairly accurately using the Bohr model of the atom, which conceptualizes the electron as "orbiting" the proton in analogy to the Earth's orbit of the Sun. However, the atomic electron and proton are held together by electromagnetic force, while planets and celestial objects are held by gravity. Because of the discretization of angular momentum postulated in early quantum mechanics by Bohr, the electron in the Bohr model can only occupy certain allowed distances from the proton, and therefore only certain allowed energies.

A more accurate description of the hydrogen atom comes from a purely quantum mechanical treatment that uses the Schrödinger equation, Dirac equation or even the Feynman path integral formulation to calculate the probability density of the electron around the proton. The most complicated treatments allow for the small effects of special relativity and vacuum polarization. In the quantum mechanical treatment, the electron in a ground state hydrogen atom has no angular momentum at all—illustrating how the "planetary orbit" differs from electron motion.
There exist two different spin isomers of hydrogen diatomic molecules that differ by the relative spin of their nuclei. In the orthohydrogen form, the spins of the two protons are parallel and form a triplet state with a molecular spin quantum number of 1 (+); in the parahydrogen form the spins are antiparallel and form a singlet with a molecular spin quantum number of 0 (–). At standard temperature and pressure, hydrogen gas contains about 25% of the para form and 75% of the ortho form, also known as the "normal form". The equilibrium ratio of orthohydrogen to parahydrogen depends on temperature, but because the ortho form is an excited state and has a higher energy than the para form, it is unstable and cannot be purified. At very low temperatures, the equilibrium state is composed almost exclusively of the para form. The liquid and gas phase thermal properties of pure parahydrogen differ significantly from those of the normal form because of differences in rotational heat capacities, as discussed more fully in "spin isomers of hydrogen". The ortho/para distinction also occurs in other hydrogen-containing molecules or functional groups, such as water and methylene, but is of little significance for their thermal properties.

The uncatalyzed interconversion between para and ortho H increases with increasing temperature; thus rapidly condensed H contains large quantities of the high-energy ortho form that converts to the para form very slowly. The ortho/para ratio in condensed H is an important consideration in the preparation and storage of liquid hydrogen: the conversion from ortho to para is exothermic and produces enough heat to evaporate some of the hydrogen liquid, leading to loss of liquefied material. Catalysts for the ortho-para interconversion, such as ferric oxide, activated carbon, platinized asbestos, rare earth metals, uranium compounds, chromic oxide, or some nickel compounds, are used during hydrogen cooling.


While H is not very reactive under standard conditions, it does form compounds with most elements. Hydrogen can form compounds with elements that are more electronegative, such as halogens (e.g., F, Cl, Br, I), or oxygen; in these compounds hydrogen takes on a partial positive charge. When bonded to fluorine, oxygen, or nitrogen, hydrogen can participate in a form of medium-strength noncovalent bonding with the hydrogen of other similar molecules, a phenomenon called hydrogen bonding that is critical to the stability of many biological molecules. Hydrogen also forms compounds with less electronegative elements, such as metals and metalloids, where it takes on a partial negative charge. These compounds are often known as hydrides.

Hydrogen forms a vast array of compounds with carbon called the hydrocarbons, and an even vaster array with heteroatoms that, because of their general association with living things, are called organic compounds. The study of their properties is known as organic chemistry and their study in the context of living organisms is known as biochemistry. By some definitions, "organic" compounds are only required to contain carbon. However, most of them also contain hydrogen, and because it is the carbon-hydrogen bond which gives this class of compounds most of its particular chemical characteristics, carbon-hydrogen bonds are required in some definitions of the word "organic" in chemistry. Millions of hydrocarbons are known, and they are usually formed by complicated synthetic pathways that seldom involve elementary hydrogen.

Compounds of hydrogen are often called hydrides, a term that is used fairly loosely. The term "hydride" suggests that the H atom has acquired a negative or anionic character, denoted H, and is used when hydrogen forms a compound with a more electropositive element. The existence of the hydride anion, suggested by Gilbert N. Lewis in 1916 for group 1 and 2 salt-like hydrides, was demonstrated by Moers in 1920 by the electrolysis of molten lithium hydride (LiH), producing a stoichiometry quantity of hydrogen at the anode. For hydrides other than group 1 and 2 metals, the term is quite misleading, considering the low electronegativity of hydrogen. An exception in group 2 hydrides is , which is polymeric. In lithium aluminium hydride, the anion carries hydridic centers firmly attached to the Al(III).

Although hydrides can be formed with almost all main-group elements, the number and combination of possible compounds varies widely; for example, more than 100 binary borane hydrides are known, but only one binary aluminium hydride. Binary indium hydride has not yet been identified, although larger complexes exist.

In inorganic chemistry, hydrides can also serve as bridging ligands that link two metal centers in a coordination complex. This function is particularly common in group 13 elements, especially in boranes (boron hydrides) and aluminium complexes, as well as in clustered carboranes.

Oxidation of hydrogen removes its electron and gives H, which contains no electrons and a nucleus which is usually composed of one proton. That is why is often called a proton. This species is central to discussion of acids. Under the Brønsted–Lowry acid–base theory, acids are proton donors, while bases are proton acceptors.

A bare proton, , cannot exist in solution or in ionic crystals because of its unstoppable attraction to other atoms or molecules with electrons. Except at the high temperatures associated with plasmas, such protons cannot be removed from the electron clouds of atoms and molecules, and will remain attached to them. However, the term 'proton' is sometimes used loosely and metaphorically to refer to positively charged or cationic hydrogen attached to other species in this fashion, and as such is denoted "" without any implication that any single protons exist freely as a species.

To avoid the implication of the naked "solvated proton" in solution, acidic aqueous solutions are sometimes considered to contain a less unlikely fictitious species, termed the "hydronium ion" (). However, even in this case, such solvated hydrogen cations are more realistically conceived as being organized into clusters that form species closer to H. Other oxonium ions are found when water is in acidic solution with other solvents.

Although exotic on Earth, one of the most common ions in the universe is the ion, known as protonated molecular hydrogen or the trihydrogen cation.

NASA has investigated the use of atomic hydrogen as a rocket propellant. It could be stored in liquid helium to prevent it from recombining into molecular hydrogen. When the helium is vaporized, the atomic hydrogen would be released and combine back to molecular hydrogen. The result would be a intensely hot stream of hydrogen and helium gas. The liftoff weight of rockets could be reduced by 50% by this method.

Most interstellar hydrogen is in the form of atomic hydrogen because the atoms can seldom collide and combine. They are the source of the important 21cm hydrogen line in astronomy at 1420 MHz. 

Hydrogen has three naturally occurring isotopes, denoted , and . Other, highly unstable nuclei ( to ) have been synthesized in the laboratory but not observed in nature.

Hydrogen is the only element that has different names for its isotopes in common use today. During the early study of radioactivity, various heavy radioactive isotopes were given their own names, but such names are no longer used, except for deuterium and tritium. The symbols D and T (instead of and ) are sometimes used for deuterium and tritium, but the corresponding symbol for protium, P, is already in use for phosphorus and thus is not available for protium. In its nomenclatural guidelines, the International Union of Pure and Applied Chemistry (IUPAC) allows any of D, T, , and to be used, although and are preferred.

The exotic atom muonium (symbol Mu), composed of an antimuon and an electron, is also sometimes considered as a light radioisotope of hydrogen, due to the mass difference between the antimuon and the electron. Muonium was discovered in 1960. During the muon's lifetime, muonium can enter into compounds such as muonium chloride (MuCl) or sodium muonide (NaMu), analogous to hydrogen chloride and sodium hydride respectively.

In 1671, Robert Boyle discovered and described the reaction between iron filings and dilute acids, which results in the production of hydrogen gas. In 1766, Henry Cavendish was the first to recognize hydrogen gas as a discrete substance, by naming the gas from a metal-acid reaction "inflammable air". He speculated that "inflammable air" was in fact identical to the hypothetical substance called "phlogiston" and further finding in 1781 that the gas produces water when burned. He is usually given credit for the discovery of hydrogen as an element. In 1783, Antoine Lavoisier gave the element the name hydrogen (from the Greek ὑδρο- "hydro" meaning "water" and -γενής "genes" meaning "creator") when he and Laplace reproduced Cavendish's finding that water is produced when hydrogen is burned.

Lavoisier produced hydrogen for his experiments on mass conservation by reacting a flux of steam with metallic iron through an incandescent iron tube heated in a fire. Anaerobic oxidation of iron by the protons of water at high temperature can be schematically represented by the set of following reactions:

Many metals such as zirconium undergo a similar reaction with water leading to the production of hydrogen.

Hydrogen was liquefied for the first time by James Dewar in 1898 by using regenerative cooling and his invention, the vacuum flask. He produced solid hydrogen the next year. Deuterium was discovered in December 1931 by Harold Urey, and tritium was prepared in 1934 by Ernest Rutherford, Mark Oliphant, and Paul Harteck. Heavy water, which consists of deuterium in the place of regular hydrogen, was discovered by Urey's group in 1932. François Isaac de Rivaz built the first de Rivaz engine, an internal combustion engine powered by a mixture of hydrogen and oxygen in 1806. Edward Daniel Clarke invented the hydrogen gas blowpipe in 1819. The Döbereiner's lamp and limelight were invented in 1823.

The first hydrogen-filled balloon was invented by Jacques Charles in 1783. Hydrogen provided the lift for the first reliable form of air-travel following the 1852 invention of the first hydrogen-lifted airship by Henri Giffard. German count Ferdinand von Zeppelin promoted the idea of rigid airships lifted by hydrogen that later were called Zeppelins; the first of which had its maiden flight in 1900. Regularly scheduled flights started in 1910 and by the outbreak of World War I in August 1914, they had carried 35,000 passengers without a serious incident. Hydrogen-lifted airships were used as observation platforms and bombers during the war.

The first non-stop transatlantic crossing was made by the British airship "R34" in 1919. Regular passenger service resumed in the 1920s and the discovery of helium reserves in the United States promised increased safety, but the U.S. government refused to sell the gas for this purpose. Therefore, H was used in the "Hindenburg" airship, which was destroyed in a midair fire over New Jersey on 6 May 1937. The incident was broadcast live on radio and filmed. Ignition of leaking hydrogen is widely assumed to be the cause, but later investigations pointed to the ignition of the aluminized fabric coating by static electricity. But the damage to hydrogen's reputation as a lifting gas was already done and commercial hydrogen airship travel ceased. Hydrogen is still used, in preference to non-flammable but more expensive helium, as a lifting gas for weather balloons.

In the same year the first hydrogen-cooled turbogenerator went into service with gaseous hydrogen as a coolant in the rotor and the stator in 1937 at Dayton, Ohio, by the Dayton Power & Light Co.; because of the thermal conductivity of hydrogen gas, this is the most common type in its field today.

The nickel hydrogen battery was used for the first time in 1977 aboard the U.S. Navy's Navigation technology satellite-2 (NTS-2). For example, the ISS, Mars Odyssey and the Mars Global Surveyor are equipped with nickel-hydrogen batteries. In the dark part of its orbit, the Hubble Space Telescope is also powered by nickel-hydrogen batteries, which were finally replaced in May 2009, more than 19 years after launch and 13 years beyond their design life.

Because of its simple atomic structure, consisting only of a proton and an electron, the hydrogen atom, together with the spectrum of light produced from it or absorbed by it, has been central to the development of the theory of atomic structure. Furthermore, study of the corresponding simplicity of the hydrogen molecule and the corresponding cation brought understanding of the nature of the chemical bond, which followed shortly after the quantum mechanical treatment of the hydrogen atom had been developed in the mid-1920s.

One of the first quantum effects to be explicitly noticed (but not understood at the time) was a Maxwell observation involving hydrogen, half a century before full quantum mechanical theory arrived. Maxwell observed that the specific heat capacity of H unaccountably departs from that of a diatomic gas below room temperature and begins to increasingly resemble that of a monatomic gas at cryogenic temperatures. According to quantum theory, this behavior arises from the spacing of the (quantized) rotational energy levels, which are particularly wide-spaced in H because of its low mass. These widely spaced levels inhibit equal partition of heat energy into rotational motion in hydrogen at low temperatures. Diatomic gases composed of heavier atoms do not have such widely spaced levels and do not exhibit the same effect.

Antihydrogen () is the antimatter counterpart to hydrogen. It consists of an antiproton with a positron. Antihydrogen is the only type of antimatter atom to have been produced as of 2015.

Hydrogen, as atomic H, is the most abundant chemical element in the universe, making up 75% of normal matter by mass and more than 90% by number of atoms. (Most of the mass of the universe, however, is not in the form of chemical-element type matter, but rather is postulated to occur as yet-undetected forms of mass such as dark matter and dark energy.) This element is found in great abundance in stars and gas giant planets. Molecular clouds of H are associated with star formation. Hydrogen plays a vital role in powering stars through the proton-proton reaction and the CNO cycle nuclear fusion.

Throughout the universe, hydrogen is mostly found in the atomic and plasma states, with properties quite different from those of molecular hydrogen. As a plasma, hydrogen's electron and proton are not bound together, resulting in very high electrical conductivity and high emissivity (producing the light from the Sun and other stars). The charged particles are highly influenced by magnetic and electric fields. For example, in the solar wind they interact with the Earth's magnetosphere giving rise to Birkeland currents and the aurora. Hydrogen is found in the neutral atomic state in the interstellar medium. The large amount of neutral hydrogen found in the damped Lyman-alpha systems is thought to dominate the cosmological baryonic density of the Universe up to redshift "z"=4.

Under ordinary conditions on Earth, elemental hydrogen exists as the diatomic gas, H. However, hydrogen gas is very rare in the Earth's atmosphere (1 ppm by volume) because of its light weight, which enables it to escape from Earth's gravity more easily than heavier gases. However, hydrogen is the third most abundant element on the Earth's surface, mostly in the form of chemical compounds such as hydrocarbons and water. Hydrogen gas is produced by some bacteria and algae and is a natural component of flatus, as is methane, itself a hydrogen source of increasing importance.

A molecular form called protonated molecular hydrogen () is found in the interstellar medium, where it is generated by ionization of molecular hydrogen from cosmic rays. This charged ion has also been observed in the upper atmosphere of the planet Jupiter. The ion is relatively stable in the environment of outer space due to the low temperature and density. is one of the most abundant ions in the Universe, and it plays a notable role in the chemistry of the interstellar medium. Neutral triatomic hydrogen H can exist only in an excited form and is unstable. By contrast, the positive hydrogen molecular ion () is a rare molecule in the universe.

 is produced in chemistry and biology laboratories, often as a by-product of other reactions; in industry for the hydrogenation of unsaturated substrates; and in nature as a means of expelling reducing equivalents in biochemical reactions.

The electrolysis of water is a simple method of producing hydrogen. A low voltage current is run through the water, and gaseous oxygen forms at the anode while gaseous hydrogen forms at the cathode. Typically the cathode is made from platinum or another inert metal when producing hydrogen for storage. If, however, the gas is to be burnt on site, oxygen is desirable to assist the combustion, and so both electrodes would be made from inert metals. (Iron, for instance, would oxidize, and thus decrease the amount of oxygen given off.) The theoretical maximum efficiency (electricity used vs. energetic value of hydrogen produced) is in the range 88-94%.

When determining the electrical efficiency of PEM (proton exchange membrane) electrolysis, the higher heat value (HHV) is used. This is because the catalyst layer interacts with water as steam. As the process operates at 80°C for PEM electrolysers the waste heat can be redirected through the system to create the steam, resulting in a higher overall electrical efficiency. The lower heat value (LHV) must be used for alkaline electrolysers as the process within these electrolysers requires water in liquid form and uses alkalinity to facilitate the breaking of the bond holding the hydrogen and oxygen atoms together. The lower heat value must also be used for fuel cells, as steam is the output rather than input.

Hydrogen is often produced using natural gas, which involves the removal of hydrogen from hydrocarbons at very high temperatures, with about 95% of hydrogen production coming from steam reforming around year 2000. Commercial bulk hydrogen is usually produced by the steam reforming of natural gas. At high temperatures (1000–1400 K, 700–1100 °C or 1300–2000 °F), steam (water vapor) reacts with methane to yield carbon monoxide and .

This reaction is favored at low pressures but is nonetheless conducted at high pressures (2.0  MPa, 20 atm or 600 inHg). This is because high-pressure is the most marketable product and pressure swing adsorption (PSA) purification systems work better at higher pressures. The product mixture is known as "synthesis gas" because it is often used directly for the production of methanol and related compounds. Hydrocarbons other than methane can be used to produce synthesis gas with varying product ratios. One of the many complications to this highly optimized technology is the formation of coke or carbon:

Consequently, steam reforming typically employs an excess of . Additional hydrogen can be recovered from the steam by use of carbon monoxide through the water gas shift reaction, especially with an iron oxide catalyst. This reaction is also a common industrial source of carbon dioxide:

Other important methods for production include partial oxidation of hydrocarbons:

and the coal reaction, which can serve as a prelude to the shift reaction above:

Hydrogen is sometimes produced and consumed in the same industrial process, without being separated. In the Haber process for the production of ammonia, hydrogen is generated from natural gas. Electrolysis of brine to yield chlorine also produces hydrogen as a co-product.

In the laboratory, is usually prepared by the reaction of dilute non-oxidizing acids on some reactive metals such as zinc with Kipp's apparatus.

Aluminium can also produce upon treatment with bases:

An alloy of aluminium and gallium in pellet form added to water can be used to generate hydrogen. The process also produces alumina, but the expensive gallium, which prevents the formation of an oxide skin on the pellets, can be re-used. This has important potential implications for a hydrogen economy, as hydrogen can be produced on-site and does not need to be transported.

There are more than 200 thermochemical cycles which can be used for water splitting, around a dozen of these cycles such as the iron oxide cycle, cerium(IV) oxide–cerium(III) oxide cycle, zinc zinc-oxide cycle, sulfur-iodine cycle, copper-chlorine cycle and hybrid sulfur cycle are under research and in testing phase to produce hydrogen and oxygen from water and heat without using electricity. A number of laboratories (including in France, Germany, Greece, Japan, and the USA) are developing thermochemical methods to produce hydrogen from solar energy and water.

Under anaerobic conditions, iron and steel alloys are slowly oxidized by the protons of water concomitantly reduced in molecular hydrogen (). The anaerobic corrosion of iron leads first to the formation of ferrous hydroxide (green rust) and can be described by the following reaction:

In its turn, under anaerobic conditions, the ferrous hydroxide () can be oxidized by the protons of water to form magnetite and molecular hydrogen.
This process is described by the Schikorr reaction:

The well crystallized magnetite () is thermodynamically more stable than the ferrous hydroxide ().

This process occurs during the anaerobic corrosion of iron and steel in oxygen-free groundwater and in reducing soils below the water table.

In the absence of atmospheric oxygen (), in deep geological conditions prevailing far away from Earth atmosphere, hydrogen () is produced during the process of serpentinization by the anaerobic oxidation by the water protons (H) of the ferrous (Fe) silicate present in the crystal lattice of the fayalite (, the olivine iron-endmember). The corresponding reaction leading to the formation of magnetite (), quartz (Si) and hydrogen () is the following:

This reaction closely resembles the Schikorr reaction observed in the anaerobic oxidation of the ferrous hydroxide in contact with water.

From all the fault gases formed in power transformers, hydrogen is the most common and is generated under most fault conditions; thus, formation of hydrogen is an early indication of serious problems in the transformer's life cycle.

Large quantities of are needed in the petroleum and chemical industries. The largest application of is for the processing ("upgrading") of fossil fuels, and in the production of ammonia. The key consumers of in the petrochemical plant include hydrodealkylation, hydrodesulfurization, and hydrocracking. has several other important uses. is used as a hydrogenating agent, particularly in increasing the level of saturation of unsaturated fats and oils (found in items such as margarine), and in the production of methanol. It is similarly the source of hydrogen in the manufacture of hydrochloric acid. is also used as a reducing agent of metallic ores.

Hydrogen is highly soluble in many rare earth and transition metals and is soluble in both nanocrystalline and amorphous metals. Hydrogen solubility in metals is influenced by local distortions or impurities in the crystal lattice. These properties may be useful when hydrogen is purified by passage through hot palladium disks, but the gas's high solubility is a metallurgical problem, contributing to the embrittlement of many metals, complicating the design of pipelines and storage tanks.

Apart from its use as a reactant, has wide applications in physics and engineering. It is used as a shielding gas in welding methods such as atomic hydrogen welding. H is used as the rotor coolant in electrical generators at power stations, because it has the highest thermal conductivity of any gas. Liquid H is used in cryogenic research, including superconductivity studies. Because is lighter than air, having a little more than of the density of air, it was once widely used as a lifting gas in balloons and airships.

In more recent applications, hydrogen is used pure or mixed with nitrogen (sometimes called forming gas) as a tracer gas for minute leak detection. Applications can be found in the automotive, chemical, power generation, aerospace, and telecommunications industries. Hydrogen is an authorized food additive (E 949) that allows food package leak testing among other anti-oxidizing properties.

Hydrogen's rarer isotopes also each have specific applications. Deuterium (hydrogen-2) is used in nuclear fission applications as a moderator to slow neutrons, and in nuclear fusion reactions. Deuterium compounds have applications in chemistry and biology in studies of reaction isotope effects. Tritium (hydrogen-3), produced in nuclear reactors, is used in the production of hydrogen bombs, as an isotopic label in the biosciences, and as a radiation source in luminous paints.

The triple point temperature of equilibrium hydrogen is a defining fixed point on the ITS-90 temperature scale at 13.8033 kelvins.

Hydrogen is commonly used in power stations as a coolant in generators due to a number of favorable properties that are a direct result of its light diatomic molecules. These include low density, low viscosity, and the highest specific heat and thermal conductivity of all gases.

Hydrogen is not an energy resource, except in the hypothetical context of commercial nuclear fusion power plants using deuterium or tritium, a technology presently far from development. The Sun's energy comes from nuclear fusion of hydrogen, but this process is difficult to achieve controllably on Earth. Elemental hydrogen from solar, biological, or electrical sources requires more energy to make than is obtained by burning it, so in these cases hydrogen functions as an energy carrier, like a battery. Hydrogen may be obtained from fossil sources (such as methane), but these sources are unsustainable.

The energy density per unit "volume" of both liquid hydrogen and compressed hydrogen gas at any practicable pressure is significantly less than that of traditional fuel sources, although the energy density per unit fuel "mass" is higher. Nevertheless, elemental hydrogen has been widely discussed in the context of energy, as a possible future "carrier" of energy on an economy-wide scale. For example, sequestration followed by carbon capture and storage could be conducted at the point of production from fossil fuels. Hydrogen used in transportation would burn relatively cleanly, with some NO emissions, but without carbon emissions. However, the infrastructure costs associated with full conversion to a hydrogen economy would be substantial. Fuel cells can convert hydrogen and oxygen directly to electricity more efficiently than internal combustion engines.

Hydrogen is employed to saturate broken ("dangling") bonds of amorphous silicon and amorphous carbon that helps stabilizing material properties. It is also a potential electron donor in various oxide materials, including ZnO, SnO, CdO, MgO, ZrO, HfO, LaO, YO, TiO, SrTiO, LaAlO, SiO, AlO, ZrSiO, HfSiO, and SrZrO.

H is a product of some types of anaerobic metabolism and is produced by several microorganisms, usually via reactions catalyzed by iron- or nickel-containing enzymes called hydrogenases. These enzymes catalyze the reversible redox reaction between H and its component two protons and two electrons. Creation of hydrogen gas occurs in the transfer of reducing equivalents produced during pyruvate fermentation to water. The natural cycle of hydrogen production and consumption by organisms is called the hydrogen cycle.

Water splitting, in which water is decomposed into its component protons, electrons, and oxygen, occurs in the light reactions in all photosynthetic organisms. Some such organisms, including the alga "Chlamydomonas reinhardtii" and cyanobacteria, have evolved a second step in the dark reactions in which protons and electrons are reduced to form H gas by specialized hydrogenases in the chloroplast. Efforts have been undertaken to genetically modify cyanobacterial hydrogenases to efficiently synthesize H gas even in the presence of oxygen. Efforts have also been undertaken with genetically modified alga in a bioreactor.

Hydrogen poses a number of hazards to human safety, from potential detonations and fires when mixed with air to being an asphyxiant in its pure, oxygen-free form. In addition, liquid hydrogen is a cryogen and presents dangers (such as frostbite) associated with very cold liquids. Hydrogen dissolves in many metals, and, in addition to leaking out, may have adverse effects on them, such as hydrogen embrittlement, leading to cracks and explosions. Hydrogen gas leaking into external air may spontaneously ignite. Moreover, hydrogen fire, while being extremely hot, is almost invisible, and thus can lead to accidental burns.

Even interpreting the hydrogen data (including safety data) is confounded by a number of phenomena. Many physical and chemical properties of hydrogen depend on the parahydrogen/orthohydrogen ratio (it often takes days or weeks at a given temperature to reach the equilibrium ratio, for which the data is usually given). Hydrogen detonation parameters, such as critical detonation pressure and temperature, strongly depend on the container geometry.





</doc>
<doc id="13256" url="https://en.wikipedia.org/wiki?curid=13256" title="Helium">
Helium

Helium (from ) is a chemical element with symbol He and atomic number 2. It is a colorless, odorless, tasteless, non-toxic, inert, monatomic gas, the first in the noble gas group in the periodic table. Its boiling point is the lowest among all the elements.

After hydrogen, helium is the second lightest and second most abundant element in the observable universe, being present at about 24% of the total elemental mass, which is more than 12 times the mass of all the heavier elements combined. Its abundance is similar to this figure in the Sun and in Jupiter. This is due to the very high nuclear binding energy (per nucleon) of helium-4 with respect to the next three elements after helium. This helium-4 binding energy also accounts for why it is a product of both nuclear fusion and radioactive decay. Most helium in the universe is helium-4, the vast majority of which was formed during the Big Bang. Large amounts of new helium are being created by nuclear fusion of hydrogen in stars.

Helium is named for the Greek Titan of the Sun, Helios. It was first detected as an unknown yellow spectral line signature in sunlight during a solar eclipse in 1868 by Georges Rayet, Captain C. T. Haig, Norman R. Pogson, and Lieutenant John Herschel, and was subsequently confirmed by French astronomer Jules Janssen. Janssen is often jointly credited with detecting the element along with Norman Lockyer. Janssen recorded the helium spectral line during the solar eclipse of 1868 while Lockyer observed it from Britain. Lockyer was the first to propose that the line was due to a new element, which he named. The formal discovery of the element was made in 1895 by two Swedish chemists, Per Teodor Cleve and Nils Abraham Langlet, who found helium emanating from the uranium ore cleveite. In 1903, large reserves of helium were found in natural gas fields in parts of the United States, which is by far the largest supplier of the gas today.

Liquid helium is used in cryogenics (its largest single use, absorbing about a quarter of production), particularly in the cooling of superconducting magnets, with the main commercial application being in MRI scanners. Helium's other industrial uses—as a pressurizing and purge gas, as a protective atmosphere for arc welding and in processes such as growing crystals to make silicon wafers—account for half of the gas produced. A well-known but minor use is as a lifting gas in balloons and airships. As with any gas whose density differs from that of air, inhaling a small volume of helium temporarily changes the timbre and quality of the human voice. In scientific research, the behavior of the two fluid phases of helium-4 (helium I and helium II) is important to researchers studying quantum mechanics (in particular the property of superfluidity) and to those looking at the phenomena, such as superconductivity, produced in matter near absolute zero.

On Earth it is relatively rare—5.2 ppm by volume in the atmosphere. Most terrestrial helium present today is created by the natural radioactive decay of heavy radioactive elements (thorium and uranium, although there are other examples), as the alpha particles emitted by such decays consist of helium-4 nuclei. This radiogenic helium is trapped with natural gas in concentrations as great as 7% by volume, from which it is extracted commercially by a low-temperature separation process called fractional distillation. Previously, terrestrial helium—a non-renewable resource, because once released into the atmosphere it readily escapes into space—was thought to be in increasingly short supply. However, recent studies suggest that helium produced deep in the earth by radioactive decay can collect in natural gas reserves in larger than expected quantities, in some cases having been released by volcanic activity.

The first evidence of helium was observed on August 18, 1868, as a bright yellow line with a wavelength of 587.49 nanometers in the spectrum of the chromosphere of the Sun. The line was detected by French astronomer Jules Janssen during a total solar eclipse in Guntur, India. This line was initially assumed to be sodium. On October 20 of the same year, English astronomer Norman Lockyer observed a yellow line in the solar spectrum, which he named the D because it was near the known D and D Fraunhofer line lines of sodium. He concluded that it was caused by an element in the Sun unknown on Earth. Lockyer and English chemist Edward Frankland named the element with the Greek word for the Sun, ἥλιος ("helios").

In 1881, Italian physicist Luigi Palmieri detected helium on Earth for the first time through its D spectral line, when he analyzed a material that had been sublimated during a recent eruption of Mount Vesuvius.

On March 26, 1895, Scottish chemist Sir William Ramsay isolated helium on Earth by treating the mineral cleveite (a variety of uraninite with at least 10% rare earth elements) with mineral acids. Ramsay was looking for argon but, after separating nitrogen and oxygen from the gas liberated by sulfuric acid, he noticed a bright yellow line that matched the D line observed in the spectrum of the Sun. These samples were identified as helium by Lockyer and British physicist William Crookes. It was independently isolated from cleveite in the same year by chemists Per Teodor Cleve and Abraham Langlet in Uppsala, Sweden, who collected enough of the gas to accurately determine its atomic weight. Helium was also isolated by the American geochemist William Francis Hillebrand prior to Ramsay's discovery when he noticed unusual spectral lines while testing a sample of the mineral uraninite. Hillebrand, however, attributed the lines to nitrogen. His letter of congratulations to Ramsay offers an interesting case of discovery and near-discovery in science.

In 1907, Ernest Rutherford and Thomas Royds demonstrated that alpha particles are helium nuclei by allowing the particles to penetrate the thin glass wall of an evacuated tube, then creating a discharge in the tube to study the spectrum of the new gas inside. In 1908, helium was first liquefied by Dutch physicist Heike Kamerlingh Onnes by cooling the gas to less than one kelvin. He tried to solidify it by further reducing the temperature but failed because helium does not solidify at atmospheric pressure. Onnes' student Willem Hendrik Keesom was eventually able to solidify 1 cm of helium in 1926 by applying additional external pressure.

In 1913, Niels Bohr published his "trilogy" on atomic structure that included a reconsideration of the Pickering–Fowler series as central evidence in support of his model of the atom. This series is named for Edward Charles Pickering, who in 1896 published observations of previously unknown lines in the spectrum of the star ζ Puppis (these are now known to occur with Wolf–Rayet and other hot stars). Pickering attributed the observation (lines at 4551, 5411, and 10123 Å) to a new form of hydrogen with half-integer transition levels. In 1912, Alfred Fowler managed to produce similar lines from a hydrogen-helium mixture, and supported Pickering's conclusion as to their origin. Bohr's model does not allow for half-integer transitions (nor does quantum mechanics) and Bohr concluded that Pickering and Fowler were wrong, and instead assigned these spectral lines to ionised helium, He. Fowler was initially skeptical but was ultimately convinced that Bohr was correct, and by 1915 "spectroscopists had transferred [the Pickering–Fowler series] definitively [from hydrogen] to helium." Bohr's theoretical work on the Pickering series had demonstrated the need for "a re-examination of problems that seemed already to have been solved within classical theories" and provided important confirmation for his atomic theory.

In 1938, Russian physicist Pyotr Leonidovich Kapitsa discovered that helium-4 has almost no viscosity at temperatures near absolute zero, a phenomenon now called superfluidity. This phenomenon is related to Bose–Einstein condensation. In 1972, the same phenomenon was observed in helium-3, but at temperatures much closer to absolute zero, by American physicists Douglas D. Osheroff, David M. Lee, and Robert C. Richardson. The phenomenon in helium-3 is thought to be related to pairing of helium-3 fermions to make bosons, in analogy to Cooper pairs of electrons producing superconductivity.

After an oil drilling operation in 1903 in Dexter, Kansas, produced a gas geyser that would not burn, Kansas state geologist Erasmus Haworth collected samples of the escaping gas and took them back to the University of Kansas at Lawrence where, with the help of chemists Hamilton Cady and David McFarland, he discovered that the gas consisted of, by volume, 72% nitrogen, 15% methane (a combustible percentage only with sufficient oxygen), 1% hydrogen, and 12% an unidentifiable gas. With further analysis, Cady and McFarland discovered that 1.84% of the gas sample was helium. This showed that despite its overall rarity on Earth, helium was concentrated in large quantities under the American Great Plains, available for extraction as a byproduct of natural gas.

This enabled the United States to become the world's leading supplier of helium. Following a suggestion by Sir Richard Threlfall, the United States Navy sponsored three small experimental helium plants during World War I. The goal was to supply barrage balloons with the non-flammable, lighter-than-air gas. A total of of 92% helium was produced in the program even though less than a cubic meter of the gas had previously been obtained. Some of this gas was used in the world's first helium-filled airship, the U.S. Navy's C-7, which flew its maiden voyage from Hampton Roads, Virginia, to Bolling Field in Washington, D.C., on December 1, 1921, nearly two years before the Navy's first "rigid" helium-filled airship, the Naval Aircraft Factory-built "USS Shenandoah", flew in September 1923.

Although the extraction process, using low-temperature gas liquefaction, was not developed in time to be significant during World War I, production continued. Helium was primarily used as a lifting gas in lighter-than-air craft. During World War II, the demand increased for helium for lifting gas and for shielded arc welding. The helium mass spectrometer was also vital in the atomic bomb Manhattan Project.

The government of the United States set up the National Helium Reserve in 1925 at Amarillo, Texas, with the goal of supplying military airships in time of war and commercial airships in peacetime. Because of the Helium Act of 1925, which banned the export of scarce helium on which the US then had a production monopoly, together with the prohibitive cost of the gas, the Hindenburg, like all German Zeppelins, was forced to use hydrogen as the lift gas. The helium market after World War II was depressed but the reserve was expanded in the 1950s to ensure a supply of liquid helium as a coolant to create oxygen/hydrogen rocket fuel (among other uses) during the Space Race and Cold War. Helium use in the United States in 1965 was more than eight times the peak wartime consumption.

After the "Helium Acts Amendments of 1960" (Public Law 86–777), the U.S. Bureau of Mines arranged for five private plants to recover helium from natural gas. For this "helium conservation" program, the Bureau built a pipeline from Bushton, Kansas, to connect those plants with the government's partially depleted Cliffside gas field near Amarillo, Texas. This helium-nitrogen mixture was injected and stored in the Cliffside gas field until needed, at which time it was further purified.

By 1995, a billion cubic meters of the gas had been collected and the reserve was US$1.4 billion in debt, prompting the Congress of the United States in 1996 to phase out the reserve. The resulting Helium Privatization Act of 1996 (Public Law 104–273) directed the United States Department of the Interior to empty the reserve, with sales starting by 2005.

Helium produced between 1930 and 1945 was about 98.3% pure (2% nitrogen), which was adequate for airships. In 1945, a small amount of 99.9% helium was produced for welding use. By 1949, commercial quantities of Grade A 99.95% helium were available.

For many years, the United States produced more than 90% of commercially usable helium in the world, while extraction plants in Canada, Poland, Russia, and other nations produced the remainder. In the mid-1990s, a new plant in Arzew, Algeria, producing 17 million cubic meters (600 million cubic feet) began operation, with enough production to cover all of Europe's demand. Meanwhile, by 2000, the consumption of helium within the U.S. had risen to more than 15 million kg per year. In 2004–2006, additional plants in Ras Laffan, Qatar, and Skikda, Algeria were built. Algeria quickly became the second leading producer of helium. Through this time, both helium consumption and the costs of producing helium increased. From 2002 to 2007 helium prices doubled.

As of 2012, the United States National Helium Reserve accounted for 30 percent of the world's helium. The reserve was expected to run out of helium in 2018. Despite that, a proposed bill in the United States Senate would allow the reserve to continue to sell the gas. Other large reserves were in the Hugoton in Kansas, United States, and nearby gas fields of Kansas and the panhandles of Texas and Oklahoma. New helium plants were scheduled to open in 2012 in Qatar, Russia, and the US state of Wyoming, but they were not expected to ease the shortage.

In 2013, Qatar started up the world's largest helium unit, although the 2017 Qatar diplomatic crisis severely affected helium production there. 2014 was widely acknowledged to be a year of over-supply in the helium business, following years of renowned shortages. Nasdaq reported (2015) that for Air Products, an international corporation that sells gases for industrial use, helium volumes remain under economic pressure due to feedstock supply constraints.

In the perspective of quantum mechanics, helium is the second simplest atom to model, following the hydrogen atom. Helium is composed of two electrons in atomic orbitals surrounding a nucleus containing two protons and (usually) two neutrons. As in Newtonian mechanics, no system that consists of more than two particles can be solved with an exact analytical mathematical approach (see 3-body problem) and helium is no exception. Thus, numerical mathematical methods are required, even to solve the system of one nucleus and two electrons. Such computational chemistry methods have been used to create a quantum mechanical picture of helium electron binding which is accurate to within < 2% of the correct value, in a few computational steps. Such models show that each electron in helium partly screens the nucleus from the other, so that the effective nuclear charge "Z" which each electron sees, is about 1.69 units, not the 2 charges of a classic "bare" helium nucleus.

The nucleus of the helium-4 atom is identical with an alpha particle. High-energy electron-scattering experiments show its charge to decrease exponentially from a maximum at a central point, exactly as does the charge density of helium's own electron cloud. This symmetry reflects similar underlying physics: the pair of neutrons and the pair of protons in helium's nucleus obey the same quantum mechanical rules as do helium's pair of electrons (although the nuclear particles are subject to a different nuclear binding potential), so that all these fermions fully occupy 1s orbitals in pairs, none of them possessing orbital angular momentum, and each cancelling the other's intrinsic spin. Adding another of any of these particles would require angular momentum and would release substantially less energy (in fact, no nucleus with five nucleons is stable). This arrangement is thus energetically extremely stable for all these particles, and this stability accounts for many crucial facts regarding helium in nature.

For example, the stability and low energy of the electron cloud state in helium accounts for the element's chemical inertness, and also the lack of interaction of helium atoms with each other, producing the lowest melting and boiling points of all the elements.

In a similar way, the particular energetic stability of the helium-4 nucleus, produced by similar effects, accounts for the ease of helium-4 production in atomic reactions that involve either heavy-particle emission or fusion. Some stable helium-3 (2 protons and 1 neutron) is produced in fusion reactions from hydrogen, but it is a very small fraction compared to the highly favorable helium-4.
The unusual stability of the helium-4 nucleus is also important cosmologically: it explains the fact that in the first few minutes after the Big Bang, as the "soup" of free protons and neutrons which had initially been created in about 6:1 ratio cooled to the point that nuclear binding was possible, almost all first compound atomic nuclei to form were helium-4 nuclei. So tight was helium-4 binding that helium-4 production consumed nearly all of the free neutrons in a few minutes, before they could beta-decay, and also leaving few to form heavier atoms such as lithium, beryllium, or boron. Helium-4 nuclear binding per nucleon is stronger than in any of these elements (see nucleogenesis and binding energy) and thus, once helium had been formed, no energetic drive was available to make elements 3, 4 and 5. It was barely energetically favorable for helium to fuse into the next element with a lower energy per nucleon, carbon. However, due to lack of intermediate elements, this process requires three helium nuclei striking each other nearly simultaneously (see triple alpha process). There was thus no time for significant carbon to be formed in the few minutes after the Big Bang, before the early expanding universe cooled to the temperature and pressure point where helium fusion to carbon was no longer possible. This left the early universe with a very similar ratio of hydrogen/helium as is observed today (3 parts hydrogen to 1 part helium-4 by mass), with nearly all the neutrons in the universe trapped in helium-4.

All heavier elements (including those necessary for rocky planets like the Earth, and for carbon-based or other life) have thus been created since the Big Bang in stars which were hot enough to fuse helium itself. All elements other than hydrogen and helium today account for only 2% of the mass of atomic matter in the universe. Helium-4, by contrast, makes up about 23% of the universe's ordinary matter—nearly all the ordinary matter that is not hydrogen.

Helium is the second least reactive noble gas after neon, and thus the second least reactive of all elements. It is chemically inert and monatomic in all standard conditions. Because of helium's relatively low molar (atomic) mass, its thermal conductivity, specific heat, and sound speed in the gas phase are all greater than any other gas except hydrogen. For these reasons and the small size of helium monatomic molecules, helium diffuses through solids at a rate three times that of air and around 65% that of hydrogen.

Helium is the least water-soluble monatomic gas, and one of the least water-soluble of any gas (CF, SF, and CF have lower mole fraction solubilities: 0.3802, 0.4394, and 0.2372 x/10, respectively, versus helium's 0.70797 x/10), and helium's index of refraction is closer to unity than that of any other gas. Helium has a negative Joule–Thomson coefficient at normal ambient temperatures, meaning it heats up when allowed to freely expand. Only below its Joule–Thomson inversion temperature (of about 32 to 50 K at 1 atmosphere) does it cool upon free expansion. Once precooled below this temperature, helium can be liquefied through expansion cooling.

Most extraterrestrial helium is found in a plasma state, with properties quite different from those of atomic helium. In a plasma, helium's electrons are not bound to its nucleus, resulting in very high electrical conductivity, even when the gas is only partially ionized. The charged particles are highly influenced by magnetic and electric fields. For example, in the solar wind together with ionized hydrogen, the particles interact with the Earth's magnetosphere, giving rise to Birkeland currents and the aurora.

Unlike any other element, helium will remain liquid down to absolute zero at normal pressures. This is a direct effect of quantum mechanics: specifically, the zero point energy of the system is too high to allow freezing. Solid helium requires a temperature of 1–1.5 K (about −272 °C or −457 °F) at about 25 bar (2.5 MPa) of pressure. It is often hard to distinguish solid from liquid helium since the refractive index of the two phases are nearly the same. The solid has a sharp melting point and has a crystalline structure, but it is highly compressible; applying pressure in a laboratory can decrease its volume by more than 30%. With a bulk modulus of about 27 MPa it is ~100 times more compressible than water. Solid helium has a density of at 1.15 K and 66 atm; the projected density at 0 K and 25 bar (2.5 MPa) is . At higher temperatures, helium will solidify with sufficient pressure. At room temperature, this requires about 114,000 atm.

Below its boiling point of 4.22 kelvins and above the lambda point of 2.1768 kelvins, the isotope helium-4 exists in a normal colorless liquid state, called "helium I". Like other cryogenic liquids, helium I boils when it is heated and contracts when its temperature is lowered. Below the lambda point, however, helium does not boil, and it expands as the temperature is lowered further. 

Helium I has a gas-like index of refraction of 1.026 which makes its surface so hard to see that floats of Styrofoam are often used to show where the surface is. This colorless liquid has a very low viscosity and a density of 0.145–0.125 g/mL (between about 0 and 4 K), which is only one-fourth the value expected from classical physics. Quantum mechanics is needed to explain this property and thus both states of liquid helium (helium I and helium II) are called "quantum fluids", meaning they display atomic properties on a macroscopic scale. This may be an effect of its boiling point being so close to absolute zero, preventing random molecular motion (thermal energy) from masking the atomic properties.

Liquid helium below its lambda point (called "helium II") exhibits very unusual characteristics. Due to its high thermal conductivity, when it boils, it does not bubble but rather evaporates directly from its surface. Helium-3 also has a superfluid phase, but only at much lower temperatures; as a result, less is known about the properties of the isotope.
Helium II is a superfluid, a quantum mechanical state (see: macroscopic quantum phenomena) of matter with strange properties. For example, when it flows through capillaries as thin as 10 to 10 m it has no measurable viscosity. However, when measurements were done between two moving discs, a viscosity comparable to that of gaseous helium was observed. Current theory explains this using the "two-fluid model" for helium II. In this model, liquid helium below the lambda point is viewed as containing a proportion of helium atoms in a ground state, which are superfluid and flow with exactly zero viscosity, and a proportion of helium atoms in an excited state, which behave more like an ordinary fluid.

In the "fountain effect", a chamber is constructed which is connected to a reservoir of helium II by a sintered disc through which superfluid helium leaks easily but through which non-superfluid helium cannot pass. If the interior of the container is heated, the superfluid helium changes to non-superfluid helium. In order to maintain the equilibrium fraction of superfluid helium, superfluid helium leaks through and increases the pressure, causing liquid to fountain out of the container.

The thermal conductivity of helium II is greater than that of any other known substance, a million times that of helium I and several hundred times that of copper. This is because heat conduction occurs by an exceptional quantum mechanism. Most materials that conduct heat well have a valence band of free electrons which serve to transfer the heat. Helium II has no such valence band but nevertheless conducts heat well. The flow of heat is governed by equations that are similar to the wave equation used to characterize sound propagation in air. When heat is introduced, it moves at 20 meters per second at 1.8 K through helium II as waves in a phenomenon known as "second sound".

Helium II also exhibits a creeping effect. When a surface extends past the level of helium II, the helium II moves along the surface, against the force of gravity. Helium II will escape from a vessel that is not sealed by creeping along the sides until it reaches a warmer region where it evaporates. It moves in a 30 nm-thick film regardless of surface material. This film is called a Rollin film and is named after the man who first characterized this trait, Bernard V. Rollin. As a result of this creeping behavior and helium II's ability to leak rapidly through tiny openings, it is very difficult to confine liquid helium. Unless the container is carefully constructed, the helium II will creep along the surfaces and through valves until it reaches somewhere warmer, where it will evaporate. Waves propagating across a Rollin film are governed by the same equation as gravity waves in shallow water, but rather than gravity, the restoring force is the van der Waals force. These waves are known as "third sound".

There are nine known isotopes of helium, but only helium-3 and helium-4 are stable. In the Earth's atmosphere, one atom is for every million that are . Unlike most elements, helium's isotopic abundance varies greatly by origin, due to the different formation processes. The most common isotope, helium-4, is produced on Earth by alpha decay of heavier radioactive elements; the alpha particles that emerge are fully ionized helium-4 nuclei. Helium-4 is an unusually stable nucleus because its nucleons are arranged into complete shells. It was also formed in enormous quantities during Big Bang nucleosynthesis.

Helium-3 is present on Earth only in trace amounts. Most of it has been present since Earth's formation, though some falls to Earth trapped in cosmic dust. Trace amounts are also produced by the beta decay of tritium. Rocks from the Earth's crust have isotope ratios varying by as much as a factor of ten, and these ratios can be used to investigate the origin of rocks and the composition of the Earth's mantle. is much more abundant in stars as a product of nuclear fusion. Thus in the interstellar medium, the proportion of to is about 100 times higher than on Earth. Extraplanetary material, such as lunar and asteroid regolith, have trace amounts of helium-3 from being bombarded by solar winds. The Moon's surface contains helium-3 at concentrations on the order of 10 ppb, much higher than the approximately 5 ppt found in the Earth's atmosphere. A number of people, starting with Gerald Kulcinski in 1986, have proposed to explore the moon, mine lunar regolith, and use the helium-3 for fusion.

Liquid helium-4 can be cooled to about 1 kelvin using evaporative cooling in a 1-K pot. Similar cooling of helium-3, which has a lower boiling point, can achieve about in a helium-3 refrigerator. Equal mixtures of liquid and below separate into two immiscible phases due to their dissimilarity (they follow different quantum statistics: helium-4 atoms are bosons while helium-3 atoms are fermions). Dilution refrigerators use this immiscibility to achieve temperatures of a few millikelvins.

It is possible to produce exotic helium isotopes, which rapidly decay into other substances. The shortest-lived heavy helium isotope is helium-5 with a half-life of . Helium-6 decays by emitting a beta particle and has a half-life of 0.8 second. Helium-7 also emits a beta particle as well as a gamma ray. Helium-7 and helium-8 are created in certain nuclear reactions. Helium-6 and helium-8 are known to exhibit a nuclear halo.

Helium has a valence of zero and is chemically unreactive under all normal conditions. It is an electrical insulator unless ionized. As with the other noble gases, helium has metastable energy levels that allow it to remain ionized in an electrical discharge with a voltage below its ionization potential. Helium can form unstable compounds, known as excimers, with tungsten, iodine, fluorine, sulfur, and phosphorus when it is subjected to a glow discharge, to electron bombardment, or reduced to plasma by other means. The molecular compounds HeNe, HgHe, and WHe, and the molecular ions , , , and have been created this way. HeH is also stable in its ground state, but is extremely reactive—it is the strongest Brønsted acid known, and therefore can exist only in isolation, as it will protonate any molecule or counteranion it contacts. This technique has also produced the neutral molecule He, which has a large number of band systems, and HgHe, which is apparently held together only by polarization forces.

Van der Waals compounds of helium can also be formed with cryogenic helium gas and atoms of some other substance, such as LiHe and He.

Theoretically, other true compounds may be possible, such as helium fluorohydride (HHeF) which would be analogous to HArF, discovered in 2000. Calculations show that two new compounds containing a helium-oxygen bond could be stable. Two new molecular species, predicted using theory, CsFHeO and N(CH)FHeO, are derivatives of a metastable FHeO anion first theorized in 2005 by a group from Taiwan. If confirmed by experiment, the only remaining element with no known stable compounds would be neon.

Helium atoms have been inserted into the hollow carbon cage molecules (the fullerenes) by heating under high pressure. The endohedral fullerene molecules formed are stable at high temperatures. When chemical derivatives of these fullerenes are formed, the helium stays inside. If helium-3 is used, it can be readily observed by helium nuclear magnetic resonance spectroscopy. Many fullerenes containing helium-3 have been reported. Although the helium atoms are not attached by covalent or ionic bonds, these substances have distinct properties and a definite composition, like all stoichiometric chemical compounds.

Under high pressures helium can form compounds with various other elements. Helium-nitrogen clathrate (He(N)) crystals have been grown at room temperature at pressures ca. 10 GPa in a diamond anvil cell. The insulating electride NaHe has been shown to be thermodynamically stable at pressures above 113 GPa. It has a fluorite structure.

Although it is rare on Earth, helium is the second most abundant element in the known Universe (after hydrogen), constituting 23% of its baryonic mass. The vast majority of helium was formed by Big Bang nucleosynthesis one to three minutes after the Big Bang. As such, measurements of its abundance contribute to cosmological models. In stars, it is formed by the nuclear fusion of hydrogen in proton-proton chain reactions and the CNO cycle, part of stellar nucleosynthesis.

In the Earth's atmosphere, the concentration of helium by volume is only 5.2 parts per million. The concentration is low and fairly constant despite the continuous production of new helium because most helium in the Earth's atmosphere escapes into space by several processes. In the Earth's heterosphere, a part of the upper atmosphere, helium and other lighter gases are the most abundant elements.

Most helium on Earth is a result of radioactive decay. Helium is found in large amounts in minerals of uranium and thorium, including cleveite, pitchblende, carnotite and monazite, because they emit alpha particles (helium nuclei, He) to which electrons immediately combine as soon as the particle is stopped by the rock. In this way an estimated 3000 metric tons of helium are generated per year throughout the lithosphere. In the Earth's crust, the concentration of helium is 8 parts per billion. In seawater, the concentration is only 4 parts per trillion. There are also small amounts in mineral springs, volcanic gas, and meteoric iron. Because helium is trapped in the subsurface under conditions that also trap natural gas, the greatest natural concentrations of helium on the planet are found in natural gas, from which most commercial helium is extracted. The concentration varies in a broad range from a few ppm to more than 7% in a small gas field in San Juan County, New Mexico.

As of 2011 the world's helium reserves were estimated at 40 billion cubic meters, with a quarter of that being in the South Pars / North Dome Gas-Condensate field owned jointly by Qatar and Iran. In 2015 and 2016 more probable reserves were announced to be under the Rocky Mountains in North America and in east Africa.

For large-scale use, helium is extracted by fractional distillation from natural gas, which can contain as much as 7% helium. Since helium has a lower boiling point than any other element, low temperature and high pressure are used to liquefy nearly all the other gases (mostly nitrogen and methane). The resulting crude helium gas is purified by successive exposures to lowering temperatures, in which almost all of the remaining nitrogen and other gases are precipitated out of the gaseous mixture. Activated charcoal is used as a final purification step, usually resulting in 99.995% pure Grade-A helium. The principal impurity in Grade-A helium is neon. In a final production step, most of the helium that is produced is liquefied via a cryogenic process. This is necessary for applications requiring liquid helium and also allows helium suppliers to reduce the cost of long distance transportation, as the largest liquid helium containers have more than five times the capacity of the largest gaseous helium tube trailers.

In 2008, approximately 169 million standard cubic meters (SCM) of helium were extracted from natural gas or withdrawn from helium reserves with approximately 78% from the United States, 10% from Algeria, and most of the remainder from Russia, Poland and Qatar. By 2013, increases in helium production in Qatar (under the company RasGas managed by Air Liquide) had increased Qatar's fraction of world helium production to 25%, and made it the second largest exporter after the United States.
An estimated deposit of helium was found in Tanzania in 2016.

In the United States, most helium is extracted from natural gas of the Hugoton and nearby gas fields in Kansas, Oklahoma, and the Panhandle Field in Texas. Much of this gas was once sent by pipeline to the National Helium Reserve, but since 2005 this reserve is being depleted and sold off, and is expected to be largely depleted by 2021, under the October 2013 "Responsible Helium Administration and Stewardship Act" (H.R. 527).

Diffusion of crude natural gas through special semipermeable membranes and other barriers is another method to recover and purify helium. In 1996, the U.S. had "proven" helium reserves, in such gas well complexes, of about 147 billion standard cubic feet (4.2 billion SCM). At rates of use at that time (72 million SCM per year in the U.S.; see pie chart below) this would have been enough helium for about 58 years of U.S. use, and less than this (perhaps 80% of the time) at world use rates, although factors in saving and processing impact effective reserve numbers.

Helium must be extracted from natural gas because it is present in air at only a fraction of that of neon, yet the demand for it is far higher. It is estimated that if all neon production were retooled to save helium, that 0.1% of the world's helium demands would be satisfied. Similarly, only 1% of the world's helium demands could be satisfied by re-tooling all air distillation plants. Helium can be synthesized by bombardment of lithium or boron with high-velocity protons, or by bombardment of lithium with deuterons, but these processes are a completely uneconomical method of production.

Helium is commercially available in either liquid or gaseous form. As a liquid, it can be supplied in small insulated containers called dewars which hold as much as 1,000 liters of helium, or in large ISO containers which have nominal capacities as large as 42 m (around 11,000 U.S. gallons). In gaseous form, small quantities of helium are supplied in high-pressure cylinders holding as much as 8 m (approx. 282 standard cubic feet), while large quantities of high-pressure gas are supplied in tube trailers which have capacities of as much as 4,860 m (approx. 172,000 standard cubic feet).

According to helium conservationists like Nobel laureate physicist Robert Coleman Richardson, writing in 2010, the free market price of helium has contributed to "wasteful" usage (e.g. for helium balloons). Prices in the 2000s had been lowered by the decision of the U.S. Congress to sell off the country's large helium stockpile by 2015. According to Richardson, the price needed to be multiplied by 20 to eliminate the excessive wasting of helium. In their book, the "Future of helium as a natural resource" (Routledge, 2012), Nuttall, Clarke & Glowacki (2012) also proposed to create an International Helium Agency (IHA) to build a sustainable market for this precious commodity.

While balloons are perhaps the best known use of helium, they are a minor part of all helium use. Helium is used for many purposes that require some of its unique properties, such as its low boiling point, low density, low solubility, high thermal conductivity, or inertness. Of the 2014 world helium total production of about 32 million kg (180 million standard cubic meters) helium per year, the largest use (about 32% of the total in 2014) is in cryogenic applications, most of which involves cooling the superconducting magnets in medical MRI scanners and NMR spectrometers. Other major uses were pressurizing and purging systems, welding, maintenance of controlled atmospheres, and leak detection. Other uses by category were relatively minor fractions.

Helium is used as a protective gas in growing silicon and germanium crystals, in titanium and zirconium production, and in gas chromatography, because it is inert. Because of its inertness, thermally and calorically perfect nature, high speed of sound, and high value of the heat capacity ratio, it is also useful in supersonic wind tunnels and impulse facilities.

Helium is used as a shielding gas in arc welding processes on materials that at welding temperatures are contaminated and weakened by air or nitrogen. A number of inert shielding gases are used in gas tungsten arc welding, but helium is used instead of cheaper argon especially for welding materials that have higher heat conductivity, like aluminium or copper.

One industrial application for helium is leak detection. Because helium diffuses through solids three times faster than air, it is used as a tracer gas to detect leaks in high-vacuum equipment (such as cryogenic tanks) and high-pressure containers. The tested object is placed in a chamber, which is then evacuated and filled with helium. The helium that escapes through the leaks is detected by a sensitive device (helium mass spectrometer), even at the leak rates as small as 10 mbar·L/s (10 Pa·m/s). The measurement procedure is normally automatic and is called helium integral test. A simpler procedure is to fill the tested object with helium and to manually search for leaks with a hand-held device.

Helium leaks through cracks should not be confused with gas permeation through a bulk material. While helium has documented permeation constants (thus a calculable permeation rate) through glasses, ceramics, and synthetic materials, inert gases such as helium will not permeate most bulk metals.

Because it is lighter than air, airships and balloons are inflated with helium for lift. While hydrogen gas is more buoyant, and escapes permeating through a membrane at a lower rate, helium has the advantage of being non-flammable, and indeed fire-retardant. Another minor use is in rocketry, where helium is used as an ullage medium to displace fuel and oxidizers in storage tanks and to condense hydrogen and oxygen to make rocket fuel. It is also used to purge fuel and oxidizer from ground support equipment prior to launch and to pre-cool liquid hydrogen in space vehicles. For example, the Saturn V rocket used in the Apollo program needed about 370,000 m (13 million cubic feet) of helium to launch.

Helium as a breathing gas has no narcotic properties, so helium mixtures such as trimix, heliox and heliair are used for deep diving to reduce the effects of narcosis, which worsen with increasing depth. As pressure increases with depth, the density of the breathing gas also increases, and the low molecular weight of helium is found to considerably reduce the effort of breathing by lowering the density of the mixture. This reduces the Reynolds number of flow, leading to a reduction of turbulent flow and an increase in laminar flow, which requires less work of breathing. At depths below divers breathing helium–oxygen mixtures begin to experience tremors and a decrease in psychomotor function, symptoms of high-pressure nervous syndrome. This effect may be countered to some extent by adding an amount of narcotic gas such as hydrogen or nitrogen to a helium–oxygen mixture.

Helium–neon lasers, a type of low-powered gas laser producing a red beam, had various practical applications which included barcode readers and laser pointers, before they were almost universally replaced by cheaper diode lasers.

For its inertness and high thermal conductivity, neutron transparency, and because it does not form radioactive isotopes under reactor conditions, helium is used as a heat-transfer medium in some gas-cooled nuclear reactors.

Helium, mixed with a heavier gas such as xenon, is useful for thermoacoustic refrigeration due to the resulting high heat capacity ratio and low Prandtl number. The inertness of helium has environmental advantages over conventional refrigeration systems which contribute to ozone depletion or global warming.

Helium is also used in some hard disk drives.

The use of helium reduces the distorting effects of temperature variations in the space between lenses in some telescopes, due to its extremely low index of refraction. This method is especially used in solar telescopes where a vacuum tight telescope tube would be too heavy.

Helium is a commonly used carrier gas for gas chromatography.

The age of rocks and minerals that contain uranium and thorium can be estimated by measuring the level of helium with a process known as helium dating.

Helium at low temperatures is used in cryogenics, and in certain cryogenics applications. As examples of applications, liquid helium is used to cool certain metals to the extremely low temperatures required for superconductivity, such as in superconducting magnets for magnetic resonance imaging. The Large Hadron Collider at CERN uses 96 metric tons of liquid helium to maintain the temperature at 1.9 kelvin.

Neutral helium at standard conditions is non-toxic, plays no biological role and is found in trace amounts in human blood.
The speed of sound in helium is nearly three times the speed of sound in air. Because the fundamental frequency of a gas-filled cavity is proportional to the speed of sound in the gas, when helium is inhaled there is a corresponding increase in the resonant frequencies of the vocal tract. The fundamental frequency (sometimes called pitch) does not change, since this is produced by direct vibration of the vocal folds, which is unchanged. However, the higher resonant frequencies cause a change in timbre, resulting in a reedy, duck-like vocal quality. The opposite effect, lowering resonant frequencies, can be obtained by inhaling a dense gas such as sulfur hexafluoride or xenon.

Inhaling helium can be dangerous if done to excess, since helium is a simple asphyxiant and so displaces oxygen needed for normal respiration. Fatalities have been recorded, including a youth who suffocated in Vancouver in 2003 and two adults who suffocated in South Florida in 2006. In 1998, an Australian girl (her age is not known) from Victoria fell unconscious and temporarily turned blue after inhaling the entire contents of a party balloon.
Inhaling helium directly from pressurized cylinders or even balloon filling valves is extremely dangerous, as high flow rate and pressure can result in barotrauma, fatally rupturing lung tissue.

Death caused by helium is rare. The first media-recorded case was that of a 15-year-old girl from Texas who died in 1998 from helium inhalation at a friend's party; the exact type of helium death is unidentified.

In the United States only two fatalities were reported between 2000 and 2004, including a man who died in North Carolina of barotrauma in 2002. A youth asphyxiated in Vancouver during 2003, and a 27-year-old man in Australia had an embolism after breathing from a cylinder in 2000. Since then two adults asphyxiated in South Florida in 2006, and there were cases in 2009 and 2010, one a Californian youth who was found with a bag over his head, attached to a helium tank, and another teenager in Northern Ireland died of asphyxiation. At Eagle Point, Oregon a teenage girl died in 2012 from barotrauma at a party. A girl from Michigan died from hypoxia later in the year.

On February 4, 2015 it was revealed that during the recording of their main TV show on January 28, a 12-year-old member (name withheld) of Japanese all-girl singing group 3B Junior suffered from air embolism, losing consciousness and falling in a coma as a result of air bubbles blocking the flow of blood to the brain, after inhaling huge quantities of helium as part of a game. The incident was not made public until a week later. The staff of TV Asahi held an emergency press conference to communicate that the member had been taken to the hospital and is showing signs of rehabilitation such as moving eyes and limbs, but her consciousness has not been sufficiently recovered as of yet. Police have launched an investigation due to a neglect of safety measures.

On July 13, 2017 CBS News reported that a political operative who reportedly attempted to recover e-mails missing from the Clinton server, Peter W. Smith, "apparently" committed suicide in May at a hotel room in Rochester, Minnesota and that his death was recorded as "asphyxiation due to displacement of oxygen in confined space with helium". More details followed in the Chicago Tribune.

The safety issues for cryogenic helium are similar to those of liquid nitrogen; its extremely low temperatures can result in cold burns, and the liquid-to-gas expansion ratio can cause explosions if no pressure-relief devices are installed. Containers of helium gas at 5 to 10 K should be handled as if they contain liquid helium due to the rapid and significant thermal expansion that occurs when helium gas at less than 10 K is warmed to room temperature.

At high pressures (more than about 20 atm or two MPa), a mixture of helium and oxygen (heliox) can lead to high-pressure nervous syndrome, a sort of reverse-anesthetic effect; adding a small amount of nitrogen to the mixture can alleviate the problem.



General

More detail

Miscellaneous

Helium shortage


</doc>
<doc id="13257" url="https://en.wikipedia.org/wiki?curid=13257" title="Hydrocarbon">
Hydrocarbon

Aromatic hydrocarbons (arenes), alkanes, cycloalkanes and alkyne-based compounds are different types of hydrocarbons. 

Most hydrocarbons found on Earth naturally occur in crude oil, where decomposed organic matter provides an abundance of carbon and hydrogen which, when bonded, can catenate to form seemingly limitless chains.

As defined by IUPAC nomenclature of organic chemistry, the classifications for hydrocarbons are:

Hydrocarbons can be gases (e.g. methane and propane), liquids (e.g. hexane and benzene), waxes or low melting solids (e.g. paraffin wax and naphthalene) or polymers (e.g. polyethylene, polypropylene and polystyrene).

Because of differences in molecular structure, the empirical formula remains different between hydrocarbons; in linear or "straight-run" alkanes, alkenes and alkynes, the amount of bonded hydrogen lessens in alkenes and alkynes due to the "self-bonding" or catenation of carbon preventing entire saturation of the hydrocarbon by the formation of double or triple bonds.

This inherent ability of hydrocarbons to bond to themselves is known as catenation, and allows hydrocarbons to form more complex molecules, such as cyclohexane, and in rarer cases, arenes such as benzene. This ability comes from the fact that the bond character between carbon atoms is entirely non-polar, in that the distribution of electrons between the two elements is somewhat even due to the same electronegativity values of the elements (~0.30), and does not result in the formation of an electrophile.

Generally, with catenation comes the loss of the total amount of bonded hydrocarbons and an increase in the amount of energy required for bond cleavage due to strain exerted upon the molecule; in molecules such as cyclohexane, this is referred to as ring strain, and occurs due to the "destabilized" spatial electron configuration of the atom.

In simple chemistry, as per valence bond theory, the carbon atom must follow the ""4-hydrogen rule"", which states that the maximum number of atoms available to bond with carbon is equal to the number of electrons that are attracted into the outer shell of carbon. In terms of shells, carbon consists of an incomplete outer shell, which comprises 4 electrons, and thus has 4 electrons available for covalent or dative bonding.

Hydrocarbons are hydrophobic like lipids.

Some hydrocarbons also are abundant in the solar system. Lakes of liquid methane and ethane have been found on Titan, Saturn's largest moon, confirmed by the Cassini-Huygens Mission. Hydrocarbons are also abundant in nebulae forming polycyclic aromatic hydrocarbon (PAH) compounds.

Hydrocarbons are a primary energy source for current civilizations. The predominant use of hydrocarbons is as a combustible fuel source. In their solid form, hydrocarbons take the form of asphalt (bitumen).

Mixtures of volatile hydrocarbons are now used in preference to the chlorofluorocarbons as a propellant for aerosol sprays, due to chlorofluorocarbons' impact on the ozone layer.

Methane (CH) and ethane (CH) are gaseous at ambient temperatures and cannot be readily liquefied by pressure alone. Propane (CH) is however easily liquefied, and exists in 'propane bottles' mostly as a liquid. Butane (CH) is so easily liquefied that it provides a safe, volatile fuel for small pocket lighters. Pentane (CH) is a clear liquid at room temperature, commonly used in chemistry and industry as a powerful nearly odorless solvent of waxes and high molecular weight organic compounds, including greases. Hexane (CH) is also a widely used non-polar, non-aromatic solvent, as well as a significant fraction of common gasoline.
The C through C alkanes, alkenes and isomeric cycloalkanes are the top components of gasoline, naphtha, jet fuel and specialized industrial solvent mixtures. With the progressive addition of carbon units, the simple non-ring structured hydrocarbons have higher viscosities, lubricating indices, boiling points, solidification temperatures, and deeper color. At the opposite extreme from methane lie the heavy tars that remain as the "lowest fraction" in a crude oil refining retort. They are collected and widely utilized as roofing compounds, pavement composition, wood preservatives (the creosote series) and as extremely high viscosity shear-resisting liquids.

Hydrocarbon use is also prevalent in nature. Some eusocial arthropods, such as the Brazilian stingless bee "Schwarziana quadripunctata", use unique hydrocarbon "scents" in order to determine kin from non-kin. The chemical hydrocarbon composition varies between age, sex, nest location, and hierarchal position.

Hydrocarbon poisoning such as that of benzene and petroleum usually occurs accidentally by inhalation or ingestion of these cytotoxic chemical compounds. Intravenous or subcutaneous injection of petroleum compounds with intent of suicide or abuse is an extraordinary event that can result in local damage or systemic toxicity such as tissue necrosis, abscess formation, respiratory system failure and partial damage to the kidneys, the brain and the nervous system. Moaddab and Eskandarlou report a case of chest wall necrosis and empyema resulting from attempting suicide by injection of petroleum into the pleural cavity.

There are three main types of reactions:


Substitution reactions only occur in saturated hydrocarbons (single carbon–carbon bonds). In this reaction, an alkane reacts with a chlorine molecule. One of the chlorine atoms displaces a hydrogen atom. This forms hydrochloric acid as well as the hydrocarbon with one chlorine atom.
all the way to CCl (carbon tetrachloride)

all the way to CCl (hexachloroethane)

Addition reactions involve alkenes and alkynes. In this reaction a halogen molecule breaks the double or triple bond in the hydrocarbon and forms a bond.

Hydrocarbons are currently the main source of the world's electric energy and heat sources (such as home heating) because of the energy produced when burnt. Often this energy is used directly as heat such as in home heaters, which use either petroleum or natural gas. The hydrocarbon is burnt and the heat is used to heat water, which is then circulated. A similar principle is used to create electric energy in power plants.

Common properties of hydrocarbons are the facts that they produce steam, carbon dioxide and heat during combustion and that oxygen is required for combustion to take place. The simplest hydrocarbon, methane, burns as follows:

In inadequate supply of air, carbon monoxide gas and water vapour are formed:

Another example is the combustion of propane:

And finally, for any linear alkane of n carbon atoms,

Burning of hydrocarbons is an example of an exothermic chemical reaction.

Hydrocarbons can also be burned with elemental fluorine, resulting in carbon tetrafluoride and hydrogen fluoride products.

Extracted hydrocarbons in a liquid form are referred to as petroleum (literally "rock oil") or mineral oil, whereas hydrocarbons in a gaseous form are referred to as natural gas. Petroleum and natural gas are found in the Earth's subsurface with the tools of petroleum geology and are a significant source of fuel and raw materials for the production of organic chemicals.

The extraction of liquid hydrocarbon fuel from sedimentary basins is integral to modern energy development. Hydrocarbons are mined from oil sands and oil shale, and potentially extracted from sedimentary methane hydrates. These reserves require distillation and upgrading to produce synthetic crude and petroleum.

Oil reserves in sedimentary rocks are the source of hydrocarbons for the energy, transport and petrochemical industries.

Economically important hydrocarbons include fossil fuels such as coal, petroleum and natural gas, and its derivatives such as plastics, paraffin, waxes, solvents and oils. Hydrocarbons – along with NO and sunlight – contribute to the formation of tropospheric ozone and greenhouse gases.

Bacteria in the gabbroic layer of the ocean's crust can degrade hydrocarbons; but the extreme environment makes research difficult. Other bacteria such as "Lutibacterium anuloederans" can also degrade hydrocarbons.
Mycoremediation or breaking down of hydrocarbon by mycelium and mushroom is possible.

Many hydrocarbons are highly flammable, therefore, care should be taken to prevent injury. Benzene and many aromatic compounds are possible carcinogens, and proper safety equipment must be worn to prevent these harmful compounds from entering the body. If hydrocarbons undergo combustion in tight areas, toxic carbon monoxide can form. Hydrocarbons should be kept away from fluorine compounds due to the high probability of forming toxic hydrofluoric acid.

Hydrocarbons are introduced into the environment through their extensive use as fuels and chemicals as well as through leaks or accidental spills during exploration, production, refining, or transport. Anthropogenic hydrocarbon contamination of soil is a serious global issue due to contaminant persistence and the negative impact on human health.




</doc>
<doc id="13258" url="https://en.wikipedia.org/wiki?curid=13258" title="Halogen">
Halogen

The halogens () are a group in the periodic table consisting of five chemically related elements: fluorine (F), chlorine (Cl), bromine (Br), iodine (I), and astatine (At). The artificially created element 117 (tennessine, Ts) may also be a halogen. In the modern IUPAC nomenclature, this group is known as group 17. The symbol X is often used generically to refer to any halogen.

The name "halogen" means "salt-producing". When halogens react with metals they produce a wide range of salts, including calcium fluoride, sodium chloride (common table salt), silver bromide and potassium iodide.

The group of halogens is the only periodic table group that contains elements in all three main states of matter at standard temperature and pressure. All of the halogens form acids when bonded to hydrogen. Most halogens are typically produced from minerals or salts. The middle halogens, that is chlorine, bromine and iodine, are often used as disinfectants. Organobromides are the most important class of flame retardants. Elemental halogens are dangerous and can potentially be lethally toxic.
The fluorine mineral fluorospar was known as early as 1529. Early chemists realized that fluorine compounds contain an undiscovered element, but were unable to isolate it. In 1860, George Gore, an English chemist, ran a current of electricity through hydrofluoric acid and probably produced fluorine, but he was unable to prove his results at the time. In 1886, Henri Moissan, a chemist in Paris, performed electrolysis on potassium bifluoride dissolved in anhydrous hydrogen fluoride, and successfully isolated fluorine.

Hydrochloric acid was known to alchemists and early chemists. However, elemental chlorine was not produced until 1774, when Carl Wilhelm Scheele heated hydrochloric acid with manganese dioxide. Scheele called the element "dephlogisticated muriatic acid", which is how chlorine was known for 33 years. In 1807, Humphry Davy investigated chlorine and discovered that it is an actual element. Chlorine was used as a poison gas during World War I.

Bromine was discovered in the 1820s by Antoine Jérôme Balard. Balard discovered bromine by passing chlorine gas through a sample of brine. He originally proposed the name "muride" for the new element, but the French Academy changed the element's name to bromine.

Iodine was discovered by Bernard Courtois, who was using seaweed ash as part of a process for saltpeter manufacture. Courtois typically boiled the seaweed ash with water to generate potassium chloride. However, in 1811, Courtois added sulfuric acid to his process, and found that his process produced purple fumes that condensed into black crystals. Suspecting that these crystals were a new element, Courtois sent samples to other chemists for investigation. Iodine was proven to be a new element by Joseph Gay-Lussac.

In 1931, Fred Allison claimed to have discovered element 85 with a magneto-optical machine, and named the element Alabamine, but was mistaken. In 1937, Rajendralal De claimed to have discovered element 85 in minerals, and called the element dakine, but he was also mistaken. An attempt at discovering element 85 in 1939 by Horia Hulubei and Yvette Cauchois via spectroscopy was also unsuccessful, as was an attempt in the same year by Walter Minder, who discovered an iodine-like element resulting from beta decay of polonium. Element 85, now named astatine, was produced successfully in 1940 by Dale R. Corson, K.R. Mackenzie, and Emilio G. Segrè, who bombarded bismuth with alpha particles.

In 1811, the German chemist Johann Schweigger proposed that the name "halogen" – meaning "salt producer", from αλς [als] "salt" and γενειν [genein] "to beget" – replace the name "chlorine", which had been proposed by the English chemist Humphry Davy. Davy's name for the element prevailed. However, in 1826, the Swedish chemist Baron Jöns Jacob Berzelius proposed the term "halogen" for the elements fluorine, chlorine, and iodine, which produce a sea-salt-like substance when they form a compound with an alkaline metal.

Fluorine's name comes from the Latin word "fluere", meaning "to flow", because it was derived from the mineral fluorospar, which was used as a flux in metal working. Chlorine's name comes from the Greek word "chloros", meaning "greenish-yellow". Bromine's name comes from the Greek word "bromos", meaning "stench". Iodine's name comes from the Greek word "iodes", meaning "violet". Astatine's name comes from the Greek word "astatos", meaning "unstable". Tennessine is named after the US state of Tennessee.

The halogens show trends in chemical bond energy moving from top to bottom of the periodic table column with fluorine deviating slightly. (It follows trend in having the highest bond energy in compounds with other atoms, but it has very weak bonds within the diatomic F molecule.) This means, as you go down the periodic table, the reactivity of the element will decrease because of the increasing size of the atoms.

Halogens are highly reactive, and as such can be harmful or lethal to biological organisms in sufficient quantities. This high reactivity is due to the high electronegativity of the atoms due to their high effective nuclear charge. Because the halogens have seven valence electrons in their outermost energy level, they can gain an electron by reacting with atoms of other elements to satisfy the octet rule. Fluorine is one of the most reactive elements, attacking otherwise-inert materials such as glass, and forming compounds with the usually inert noble gases. It is a corrosive and highly toxic gas. The reactivity of fluorine is such that, if used or stored in laboratory glassware, it can react with glass in the presence of small amounts of water to form silicon tetrafluoride (SiF). Thus, fluorine must be handled with substances such as Teflon (which is itself an organofluorine compound), extremely dry glass, or metals such as copper or steel, which form a protective layer of fluoride on their surface.

The high reactivity of fluorine allows paradoxically some of the strongest bonds possible, especially to carbon. For example, Teflon is fluorine bonded with carbon and is extremely resistant to thermal and chemical attack and has a high melting point.

The halogens form homonuclear diatomic molecules (not proven for astatine).
Due to relatively weak intermolecular forces, chlorine and fluorine form part of the group known as "elemental gases".

The elements become less reactive and have higher melting points as the atomic number increases. The higher melting points are caused by stronger London dispersion forces resulting from more electrons.

All of the halogens have been observed to react with hydrogen to form hydrogen halides. For fluorine, chlorine, and bromine, this reaction is in the form of:

However, hydrogen iodide and hydrogen astatide can split back into their constituent elements.

The hydrogen-halogen reactions get gradually less reactive toward the heavier halogens. A fluorine-hydrogen reaction is explosive even when it is dark and cold. A chlorine-hydrogen reaction is also explosive, but only in the presence of light and heat. A bromine-hydrogen reaction is even less explosive; it is explosive only when exposed to flames. Iodine and astatine only partially react with hydrogen, forming equilibria.

All halogens form binary compounds with hydrogen known as the hydrogen halides: hydrogen fluoride (HF), hydrogen chloride (HCl), hydrogen bromide (HBr), hydrogen iodide (HI), and hydrogen astatide (HAt). All of these compounds form acids when mixed with water. Hydrogen fluoride is the only hydrogen halide that forms hydrogen bonds. Hydrochloric acid, hydrobromic acid, hydroiodic acid, and hydroastatic acid are all strong acids, but hydrofluoric acid is a weak acid.

All of the hydrogen halides are irritants. Hydrogen fluoride and hydrogen chloride are highly acidic. Hydrogen fluoride is used as an industrial chemical, and is highly toxic, causing pulmonary edema and damaging cells. Hydrogen chloride is also a dangerous chemical. Breathing in gas with more than fifty parts per million of hydrogen chloride can cause death in humans. Hydrogen bromide is even more toxic and irritating than hydrogen chloride. Breathing in gas with more than thirty parts per million of hydrogen bromide can be lethal to humans. Hydrogen iodide, like other hydrogen halides, is toxic.

All the halogens are known to react with sodium to form sodium fluoride, sodium chloride, sodium bromide, sodium iodide, and sodium astatide. Heated sodium's reaction with halogens produces bright-orange flames. Sodium's reaction with chlorine is in the form of:

Iron reacts with fluorine, chlorine, and bromine to form Iron(III) halides. These reactions are in the form of:

However, when iron reacts with iodine, it forms only iron(II) iodide.

Iron wool can react rapidly with fluorine to form the white compound iron(III) fluoride even in cold temperatures. When chlorine comes into contact with heated iron, they react to form the black iron (III) chloride. However, if the reaction conditions are moist, this reaction will instead result in a reddish-brown product. Iron can also react with bromine to form iron(III) bromide. This compound is reddish-brown in dry conditions. Iron's reaction with bromine is less reactive than its reaction with fluorine or chlorine. Hot iron can also react with iodine, but it forms iron(II) iodide. This compound may be gray, but the reaction is always contaminated with excess iodine, so it is not known for sure. Iron's reaction with iodine is less vigorous than its reaction with the lighter halogens.

Interhalogen compounds are in the form of XY where X and Y are halogens and n is one, three, five, or seven. Interhalogen compounds contain at most two different halogens. Large interhalogens, such as can be produced by a reaction of a pure halogen with a smaller interhalogen such as . All interhalogens except can be produced by directly combining pure halogens in various conditions.

Interhalogens are typically more reactive than all diatomic halogen molecules except F because interhalogen bonds are weaker. However, the chemical properties of interhalogens are still roughly the same as those of diatomic halogens. Many interhalogens consist of one or more atoms of fluorine bonding to a heavier halogen. Chlorine can bond with up to 3 fluorine atoms, bromine can bond with up to five fluorine atoms, and iodine can bond with up to seven fluorine atoms. Most interhalogen compounds are covalent gases. However, there are some interhalogens that are liquids, such as BrF, and many iodine-containing interhalogens are solids.

Many synthetic organic compounds such as plastic polymers, and a few natural ones, contain halogen atoms; these are known as "halogenated" compounds or organic halides. Chlorine is by far the most abundant of the halogens in seawater, and the only one needed in relatively large amounts (as chloride ions) by humans. For example, chloride ions play a key role in brain function by mediating the action of the inhibitory transmitter GABA and are also used by the body to produce stomach acid. Iodine is needed in trace amounts for the production of thyroid hormones such as thyroxine. Organohalogens are also synthesized through the nucleophilic abstraction reaction.

Polyhalogenated compounds are industrially created compounds substituted with multiple halogens. Many of them are very toxic and bioaccumulate in humans, and have a very wide application range. They include PCBs, PBDEs, and perfluorinated compounds (PFCs), as well as numerous other compounds.

Fluorine reacts vigorously with water to produce oxygen (O) and hydrogen fluoride (HF):

Chlorine has maximum solubility of ca. 7.1 g Cl per kg of water at ambient temperature (21 °C). Dissolved chlorine reacts to form hydrochloric acid (HCl) and hypochlorous acid, a solution that can be used as a disinfectant or bleach:

Bromine has a solubility of 3.41 g per 100 g of water, but it slowly reacts to form hydrogen bromide (HBr) and hypobromous acid (HBrO):

Iodine, however, is minimally soluble in water (0.03 g/100 g water at 20 °C) and does not react with it. However, iodine will form an aqueous solution in the presence of iodide ion, such as by addition of potassium iodide (KI), because the triiodide ion is formed.

The table below is a summary of the key physical and atomic properties of the halogens. Data marked with question marks are either uncertain or are estimations partially based on periodic trends rather than observations.

Fluorine has one stable and naturally occurring isotope, fluorine-19. However, there are trace amounts in nature of the radioactive isotope fluorine-23, which occurs via cluster decay of protactinium-231. A total of eighteen isotopes of fluorine have been discovered, with atomic masses ranging from 14 to 31. Chlorine has two stable and naturally occurring isotopes, chlorine-35 and chlorine-37. However, there are trace amounts in nature of the isotope chlorine-36, which occurs via spallation of argon-36. A total of 24 isotopes of chlorine have been discovered, with atomic masses ranging from 28 to 51.

There are two stable and naturally occurring isotopes of bromine, bromine-79 and bromine-81. A total of 32 isotopes of bromine have been discovered, with atomic masses ranging 67 to 98. There is one stable and naturally occurring isotope of iodine, iodine-127. However, there are trace amounts in nature of the radioactive isotope iodine-129, which occurs via spallation and from the radioactive decay of uranium in ores. Several other radioactive isotopes of iodine have also been created naturally via the decay of uranium. A total of 38 isotopes of iodine have been discovered, with atomic masses ranging from 108 to 145.

There are no stable isotopes of astatine. However, there are three naturally occurring radioactive isotopes of astatine produced via radioactive decay of uranium, neptunium, and plutonium. These isotopes are astatine-215, astatine-217, and astatine-219. A total of 31 isotopes of astatine have been discovered, with atomic masses ranging from 193 to 223.

Approximately six million metric tons of the fluorine mineral fluorite are produced each year. Four hundred-thousand metric tons of hydrofluoric acid are made each year. Fluorine gas is made from hydrofluoric acid produced as a by-product in phosphoric acid manufacture. Approximately 15,000 metric tons of fluorine gas are made per year.

The mineral halite is the mineral that is most commonly mined for chlorine, but the minerals carnallite and sylvite are also mined for chlorine. Forty million metric tons of chlorine are produced each year by the electrolysis of brine.

Approximately 450,000 metric tons of bromine are produced each year. Fifty percent of all bromine produced is produced in the United States, 35% in Israel, and most of the remainder in China. Historically, bromine was produced by adding sulfuric acid and bleaching powder to natural brine. However, in modern times, bromine is produced by electrolysis, a method invented by Herbert Dow. It is also possible to produce bromine by passing chlorine through seawater and then passing air through the seawater.

In 2003, 22,000 metric tons of iodine were produced. Chile produces 40% of all iodine produced, Japan produces 30%, and smaller amounts are produced in Russia and the United States. Until the 1950s, iodine was extracted from kelp. However, in modern times, iodine is produced in other ways. One way that iodine is produced is by mixing sulfur dioxide with nitrate ores, which contain some iodates. Iodine is also extracted from natural gas fields.

Even though astatine is naturally occurring, it is usually produced by bombarding bismuth with alpha particles.

Both chlorine and bromine are used as disinfectants for drinking water, swimming pools, fresh wounds, spas, dishes, and surfaces. They kill bacteria and other potentially harmful microorganisms through a process known as sterilization. Their reactivity is also put to use in bleaching. Sodium hypochlorite, which is produced from chlorine, is the active ingredient of most fabric bleaches, and chlorine-derived bleaches are used in the production of some paper products. Chlorine also reacts with sodium to create sodium chloride, which is table salt.

Halogen lamps are a type of incandescent lamp using a tungsten filament in bulbs that have a small amounts of a halogen, such as iodine or bromine added. This enables the production of lamps that are much smaller than non-halogen incandescent lightbulbs at the same wattage. The gas reduces the thinning of the filament and blackening of the inside of the bulb resulting in a bulb that has a much greater life. Halogen lamps glow at a higher temperature (2800 to 3400 kelvins) with a whiter color than other incandescent bulbs. However, this requires bulbs to be manufactured from fused quartz rather than silica glass to reduce breakage.

In drug discovery, the incorporation of halogen atoms into a lead drug candidate results in analogues that are usually more lipophilic and less water-soluble. As a consequence, halogen atoms are used to improve penetration through lipid membranes and tissues. It follows that there is a tendency for some halogenated drugs to accumulate in adipose tissue.

The chemical reactivity of halogen atoms depends on both their point of attachment to the lead and the nature of the halogen. Aromatic halogen groups are far less reactive than aliphatic halogen groups, which can exhibit considerable chemical reactivity. For aliphatic carbon-halogen bonds, the C-F bond is the strongest and usually less chemically reactive than aliphatic C-H bonds. The other aliphatic-halogen bonds are weaker, their reactivity increasing down the periodic table. They are usually more chemically reactive than aliphatic C-H bonds. As a consequence, the most common halogen substitutions are the less reactive aromatic fluorine and chlorine groups.

Fluoride anions are found in ivory, bones, teeth, blood, eggs, urine, and hair of organisms. Fluoride anions in very small amounts may be essential for humans. There are 0.5 milligrams of fluorine per liter of human blood. Human bones contain 0.2 to 1.2% fluorine. Human tissue contains approximately 50 parts per billion of fluorine. A typical 70-kilogram human contains 3 to 6 grams of fluorine.

Chloride anions are essential to a large number of species, humans included. The concentration of chlorine in the dry weight of cereals is 10 to 20 parts per million, while in potatoes the concentration of chloride is 0.5%. Plant growth is adversely affected by chloride levels in the soil falling below 2 parts per million. Human blood contains an average of 0.3% chlorine. Human bone typically contains 900 parts per million of chlorine. Human tissue contains approximately 0.2 to 0.5% chlorine. There is a total of 95 grams of chlorine in a typical 70-kilogram human.

Some bromine in the form of the bromide anion is present in all organisms. A biological role for bromine in humans has not been proven, but some organisms contain organobromine compounds. Humans typically consume 1 to 20 milligrams of bromine per day. There are typically 5 parts per million of bromine in human blood, 7 parts per million of bromine in human bones, and 7 parts per million of bromine in human tissue. A typical 70-kilogram human contains 260 milligrams of bromine.

Humans typically consume less than 100 micrograms of iodine per day. Iodine deficiency can cause intellectual disability. Organoiodine compounds occur in humans in some of the glands, especially the thyroid gland, as well as the stomach, epidermis, and immune system. Foods containing iodine include cod, oysters, shrimp, herring, lobsters, sunflower seeds, seaweed, and mushrooms. However, iodine is not known to have a biological role in plants. There are typically 0.06 milligrams per liter of iodine in human blood, 300 parts per billion of iodine in human bones, and 50 to 700 parts per billion of iodine in human tissue. There are 10 to 20 milligrams of iodine in a typical 70-kilogram human.

Astatine has no biological role.

The halogens tend to decrease in toxicity towards the heavier halogens.

Fluorine gas is extremely toxic; breathing in fluorine at a concentration of 25 parts per million is potentially lethal. Hydrofluoric acid is also toxic, being able to penetrate skin and cause highly painful burns. In addition, fluoride anions are toxic, but not as toxic as pure fluorine. Fluoride can be lethal in amounts of 5 to 10 grams. Prolonged consumption of fluoride above concentrations of 1.5 mg/L is associated with a risk of dental fluorosis, an aesthetic condition of the teeth. At concentrations above 4 mg/L, there is an increased risk of developing skeletal fluorosis, a condition in which bone fractures become more common due to the hardening of bones. Current recommended levels in water fluoridation, a way to prevent dental caries, range from 0.7 to 1.2 mg/L to avoid the detrimental effects of fluoride while at the same time reaping the benefits. People with levels between normal levels and those required for skeletal fluorosis tend to have symptoms similar to arthritis.

Chlorine gas is highly toxic. Breathing in chlorine at a concentration of 3 parts per million can rapidly cause a toxic reaction. Breathing in chlorine at a concentration of 50 parts per million is highly dangerous. Breathing in chlorine at a concentration of 500 parts per million for a few minutes is lethal. Breathing in chlorine gas is highly painful.

Pure bromine is somewhat toxic, but less toxic than fluorine and chlorine. One hundred milligrams of bromine is lethal. Bromide anions are also toxic, but less so than bromine. Bromide has a lethal dose of 30 grams.

Iodine is somewhat toxic, being able to irritate the lungs and eyes, with a safety limit of 1 milligram per cubic meter. When taken orally, 3 grams of iodine can be lethal. Iodide anions are mostly nontoxic, but these can also be deadly if ingested in large amounts.

Astatine is very radioactive and thus highly dangerous, but it has not been produced in macroscopic quantities and hence it is most unlikely that its toxicity will be of much relevance to the average individual.

Certain aluminium clusters have superatom properties. These aluminium clusters are generated as anions ( with "n" = 1, 2, 3, ... ) in helium gas and reacted with a gas containing iodine. When analyzed by mass spectrometry one main reaction product turns out to be .<ref name="bergeron/2004"></ref> These clusters of 13 aluminium atoms with an extra electron added do not appear to react with oxygen when it is introduced in the same gas stream. Assuming each atom liberates its 3 valence electrons, this means 40 electrons are present, which is one of the magic numbers for sodium and implies that these numbers are a reflection of the noble gases.

Calculations show that the additional electron is located in the aluminium cluster at the location directly opposite from the iodine atom. The cluster must therefore have a higher electron affinity for the electron than iodine and therefore the aluminium cluster is called a superhalogen (i.e., the vertical electron detachment energies of the moieties that make up the negative ions are larger than those of any halogen atom). The cluster component in the ion is similar to an iodide ion or a bromide ion. The related cluster is expected to behave chemically like the triiodide ion.<ref name="bergeron/2005"></ref>



</doc>
<doc id="13259" url="https://en.wikipedia.org/wiki?curid=13259" title="Home page">
Home page

A home page or a start page is the initial or main web page of a website or a browser. The initial page of a website is sometimes called main page as well.

A home page is generally the main page a visitor navigating to a website from a web search engine will see, and it may also serve as a landing page to attract visitors. The home page is used to facilitate navigation to other pages on the site by providing links to prioritized and recent articles and pages, and possibly a search box. For example, a news website may present headlines and first paragraphs of top stories, with links to full articles, in a dynamic web page that reflects the popularity and recentness of stories. Meanwhile, other websites use the homepage to attract users to create an account. Once they are logged in, the homepage may be redirected to their profile page. This may in turn be referred to as the "personal home page".

A website may have multiple home pages, although most have one. Wikipedia, for example, has a home page at wikipedia.org, as well as language-specific home pages, such as en.wikipedia.org and de.wikipedia.org.

The majority of websites have a home page with underlying content pages, although some websites contain only a single page.

The uniform resource locator (URL) of a home page is most often the base-level domain name, such as https://wikipedia.org. Historically it may also be found at <nowiki>http://domain.tld/index.html</nowiki> or <nowiki>http://domain.tld/default.html</nowiki>, where "tld" refers to the top-level domain used by the website.

If a home page has not been created for a web site, many web servers will default to display a list of files located in the site's directory, if the security settings of the directory permit. This list will include hyperlinks to the files, allowing for simple file sharing without maintaining a separate HTML file.

A home page also refers to the first page that appears upon opening a web browser, sometimes called the start page, although the home page of a website can be used as a start page. This start page can be a website, or it can be a page with various browser functions such as the display of thumbnails of frequently visited websites. Multiple websites can be set as a start page, to open in different tabs. Some websites are intended to be used as start pages, such as iGoogle (now defunct), My Yahoo!, and MSN.com, and provide links to commonly used services such as webmail and online weather forecasts.

In the early days of the World Wide Web in the first half of the 1990s, an important part of web pages belonged to students or teachers with a UNIX account in their university. System administrators of such systems installed an HTTP server pointing its root directory to the directory containing the users accounts. On UNIX, the base directory of an account is called "home", and the codice_1 environment variable contains its path (for example codice_2). The URL of the home page usually has the format codice_3. Thus the term home page appeared and then spread to its current usage.

A personal home page historically has served as a means of self-portrayal, job-related presentation, and pure enjoyment, giving way to professional advancement and social interaction. Owing to the rise of social media sites, personal home pages are no longer as common as during the mid-late 1990s and early-2000s.

A personal web page is also commonly called a home page, although such websites can contain many pages. In Germany the term "homepage" is often used as a synonym for the term "website".

A home page can also be used outside the context of web browsers, such as to refer to the principal screen of a user interface, frequently referred to as a home screen on mobile devices such as mobile phones.




</doc>
<doc id="13260" url="https://en.wikipedia.org/wiki?curid=13260" title="Hee Haw">
Hee Haw

Hee Haw was an American television variety show featuring country music and humor with the fictional rural "Kornfield Kounty" as a backdrop. It aired first-run on CBS from 1969 to 1971, and in syndication from 1971 to 1993. Reruns aired on TNN from 1996 to 1997. RFD-TV began airing reruns in 2008, where it currently remains.

The show was inspired by "Rowan & Martin's Laugh-In", the major difference being that "Hee Haw" was far less topical, and was centered on country music and rural culture. Hosted by country music artists Buck Owens and Roy Clark for most of its run, the show was equally well known for its voluptuous, scantily clad women in stereotypical farmer's daughter outfits and country-style minidresses (a group that came to be known as the "Hee Haw Honeys"), and its corn pone humor.

"Hee Haw"'s appeal, however, was not limited to a rural audience. It was successful in all of the major markets, including New York, Los Angeles, Boston, and Chicago. Other niche programs such as "The Lawrence Welk Show" (which targeted older audiences) and "Soul Train" (which targeted black audiences) also rose to prominence in syndication during the era. Like "Laugh-In", the show minimized production costs by taping all of the recurring sketches for a season in batches, setting up for the Cornfield one day, the Joke Fence on another day, etc. At the height of its popularity, an entire season's worth of shows would be taped in two separate week-long sessions, then individual shows were assembled from edited sections. Only musical performances were taped with a live audience; a laugh track was added to all other segments.

The series was taped for CBS at its network affiliate WLAC-TV (now WTVF) in downtown Nashville, and later at Opryland USA in the Donelson area of Nashville. The show was produced by Yongestreet Productions through the mid-1980s; it was later produced by Gaylord Entertainment, which distributed the show in syndication. The show's name was coined by show business talent manager and producer Bernie Brillstein and derives from a common English onomatopoeia used to describe the braying sound that a donkey makes.

After 25 seasons, the series initially ended its run in June 1993, where it was soon picked up by TNN for reruns. TNN would eventually order an additional season of first-run episodes, beginning November 23, 1996. The show ultimately ended for good on December 27, 1997.

Much of "Hee Haw's" origin was Canadian. The series' creators, comedy writers Frank Peppiatt and John Aylesworth, were from Canada. From 1969 until the late 1980s, "Hee Haw" was produced by Yongestreet Productions, named after Yonge Street, a major thoroughfare in Toronto. Gordie Tapp and Don Harron, both writer/performers on the show, were also Canadian. Its two hosts represented both sides in a divide in country/western music at the time: Buck Owens was the prominent architect of the California-based Bakersfield sound, while Roy Clark was a stalwart of Tennessee's Music Row.

"Hee Haw" premiered on CBS as a summer 1969 replacement for "The Smothers Brothers Comedy Hour". Though the show had respectable ratings (it sat at #16 for the 1970-71 season), it was dropped in July 1971 by CBS as part of the so-called "Rural Purge" (along with fellow country-themed shows "The Beverly Hillbillies", "Mayberry R.F.D.", and "Green Acres"). The success of "Hee Haw" and other country-themed shows was the source of a heated dispute in CBS's corporate offices; Michael Dann, although he personally disliked the shows, considered total viewership the benchmark of success and encouraged the shows to stay on the air, while Fred Silverman believed certain demographics—the ones in which "Hee Haw" and the others performed poorly—could draw more advertising dollars. Silverman's view won out, and CBS canceled the rural shows in summer 1971.

Undaunted, the producers put together a syndication deal for the show, which continued in roughly the same format for 20 more years (though Owens departed in 1986). After Owens left, Clark was assisted each week by a country music celebrity co-host.

During the show's peak in popularity, "Hee Haw" often competed in syndication against "The Lawrence Welk Show", a long-running ABC program which had also been canceled in 1971, also in an attempt to purge the networks of older demographic-leaning programs. Like "Hee Haw", "Lawrence Welk" was picked up for syndication in the fall of 1971, and there were some markets where the same station aired both programs. (The success of "Hee Haw" and "Lawrence Welk" in syndication, and the network decisions that led to their respective cancellations, were the inspiration for a novelty song called "The Lawrence Welk-Hee Haw Counter-Revolution Polka," performed by Clark; the song became a top 10 hit on the "Billboard" Hot Country Singles chart in the fall of 1972.) "Welk" and "Hee Haw" also competed against another music-oriented niche program that moved to syndication in 1971: "Soul Train", a black-oriented program (originally a local program based in Chicago) that also went on to a very long run in syndication.

Mirroring the long downward trend in the popularity of variety shows in general that had taken place in the 1970s, ratings began to decline for "Hee Haw" by the mid-1980s, a trend that continued into the early 1990s. In the fall of 1991, in an attempt to win back viewers and attract a younger audience, the show's format and setting underwent a dramatic overhaul. The changes included a new title ("The Hee Haw Show"), more pop-oriented country music, and the barnyard-cornfield setting replaced by a city street and shopping mall set. The first of the new shows aired in January 1992.

Despite the attempt to keep the show fresh, the changes alienated many of its longtime viewers while failing to gain the hoped-for younger viewers, and the ratings continued their decline.

During the summer of 1992, a decision was made to end first-run production, and instead air highlights of the show's earlier years in a revamped program called "Hee Haw Silver" (as part of celebrating the show's 25th season). Under the new format, Clark hosted a mixture of classic clips and new footage.

The "Hee Haw Silver" episodes spotlighted many of their classic sketches and musical performances from the show, with a series of retrospective looks at performers who had since died, such as David "Stringbean" Akeman, Archie Campbell, Junior Samples, and Kenny Price. According to the show's producer, Sam Lovullo, the ratings showed improvement with these classic reruns; however, the series was finally canceled in June 1993 at the conclusion of its 25th season. "Hee Haw" continued to pop up in reruns (see below for details) throughout the 1990s and later during the following decade, in a series of successful DVD releases from Time Life.

After the show's syndication run ended, reruns aired on The Nashville Network from 1993 until 1996. Upon the cancellation of reruns in 1996 the program resurfaced, for another first-run season, ultimately concluding the series in 1997. Its 22 years in TV syndication (1971–93) was the record for the longest-running U.S. syndicated TV program, until "Soul Train" surpassed it in 1993; "Hee Haw" remains the fifth longest-running syndicated American TV program, though the longest-running of its genre.

During the 2006–07 season CMT aired a series of reruns and TV Land also recognized the series with an award presented by k.d. lang; in attendance were Roy Clark, Gunilla Hutton, Barbi Benton, the Hager twins, Linda Thompson, Misty Rowe, and others. It was during this point, roughly between the years of 2004 and 2007, that Time Life began selling selected episodes of the show on DVD. Among the DVD content offered was the 1978 10th anniversary special that hadn't been seen since its original airing. CMT sporadically aired the series, usually in graveyard slots, and primarily held the rights in order to be able to air the musical performances as part of their music video library (such as during the "Pure Vintage" block on CMT Pure Country).

Reruns of "Hee Haw" began airing on RFD-TV in September 2008, where it currently remains, anchoring the network's Sunday night lineup, although beginning in January 2014 an episode airs on Saturday afternoon and the same episode is rerun the following Sunday night. In 2011, the network began re-airing the earliest episodes from 1969–70 on Thursday evenings. That summer, many of the surviving cast members and an ensemble of country artists taped a "Country's Family Reunion" special, entitled "Salute to the Kornfield", which aired on RFD-TV in January 2012. The special is also part of "Country's Family Reunion's" DVD series. Concurrent with the special was the unveiling of a "Hee Haw" exhibit, titled "Pickin' and Grinnin"', at the Oklahoma History Center in Oklahoma City.

As part of the promotions for its DVD products, Time-Life also compiles and syndicates a half-hour clip show series, "The Hee Haw Collection".

Two rural-style comedians, already well known in their native Canada, gained their first major U.S. exposure: Gordie Tapp and Don Harron (whose KORN Radio character, newscaster Charlie Farquharson, had been a fixture of Canadian television since 1952 and later appeared on "The Red Green Show").

Other cast members over the years included, but were not limited to:
Roy Acuff,
Cathy Baker (as the show's emcee),
Billy Jim Baker,
Barbi Benton,
Kelly Billingsley,
Vicki Bird,
Jennifer Bishop,
Archie Campbell,
Phil Campbell,
Harry Cole (Weeping Willie),
Mackenzie Colt,
John Henry Faulk,
Tennessee Ernie Ford,
Marianne Gordon (Rogers),
Jim and Jon Hager,
Victoria Hallman,
Diana Goodman,
Gunilla Hutton,
Linda Johnson,
Grandpa Jones,
Zella Lehr (the "unicycle girl"),
George Lindsey (reprising his "Goober" character from "The Andy Griffith Show"),
Jimmy Little,
Irlene Mandrell,
Charlie McCoy,
Dawn McKinley,
Patricia McKinnon,
Sherry Miles,
Rev. Grady Nutt,
Minnie Pearl,
Claude "Jackie" Phelps,
Slim Pickens,
Kenny Price,
Anne Randall,
Chase Randolph,
Susan Raye,
Jimmie Riddle,
Jeannine Riley,
Alice Ripley,
Lulu Roman,
Misty Rowe,
Junior Samples,
Ray Sanders,
Terry Sanders,
Gailard Sartain,
Diana Scott,
Shotgun Red,
Gerald Smith (the "Georgia Quacker"),
Jeff Smith,
Donna Stokes,
Dennis Stone,
Roni Stoneman,
Mary Taylor,
Nancy Taylor,
Linda Thompson,
Lisa Todd,
Pedro Tomas,
Nancy Traylor, 
Buck Trent,
Jackie Waddell, 
Pat Woodell, and
Jonathan Winters, among many others.

The Buckaroos (Buck Owens' band) initially served as the house band on the show and consisted of members Don Rich, Jim Shaw, Jerry Brightman, Jerry Wiggins, Rick Taylor, Doyle Singer (Doyle Curtsinger), Don Lee, Ronnie Jackson, Terry Christoffersen, Doyle Holly, and in later seasons fiddle player Jana Jae, and Victoria Hallman, who replaced Don Rich on harmony vocals (Rich was killed in a motorcycle accident in 1974). In later seasons, harmonica player Charlie McCoy joined the cast and became the show's music director, forming the "Hee Haw Band", which became the house band for the remainder of the series' run. The Nashville Edition, a four-member (two male, two female) singing group, served as the background singers for most of the musical performances.

Some of the cast members made national headlines: Lulu Roman was twice charged with drug possession in 1971, David "Stringbean" Akeman and his wife were murdered in November 1973 during a robbery at their home; and as mentioned above, Buck Owens' lead guitarist and harmony singer Don Rich of the Buckaroos was killed in a motorcycle crash in 1974.

Some cast members, such as Charlie McCoy and Tennessee Ernie Ford, originally appeared on the show as guest stars.

After Buck Owens left the show, a different country music artist would accompany Roy Clark as a guest co-host each week, who would give the episode's opening performance, participate with Clark in the "Pickin' and Grinnin'" sketch, and assist Clark in introducing the other guest stars' performances. The show's final season ("Hee Haw Silver") was hosted by Clark alone.

Some of the most popular sketches and segments on "Hee Haw" included, but were not limited to:

<poem>
Where, oh where, are you tonight?
Why did you leave me here all alone?
I searched the world over, and I thought I'd found true love,
You met another, and PFFT! You was gone!
</poem>


<poem>
Gloom, despair, and agony on me-e!
Deep dark depression, excessive misery-y!
If it weren't for bad luck I'd have no luck at all!
Gloom, despair, and agony on me-e-e!
</poem>


<poem>
Now, we're not ones to go 'round spreadin' rumors,
Why, really we're just not the gossipy kind,
No, you'll never hear one of us repeating gossip,
So you'd better be sure and listen close the first time!
</poem>




Guest stars often participated in some of the sketches (mostly the "PFFT! You Was Gone" and "The Cornfield" sketches); however, this did not occur until later seasons.

Hee Haw was a premiere showcase on commercial television throughout its run for country, bluegrass, gospel, and other styles of American traditional music, featuring hundreds of elite musical performances that were paramount to the success, popularity and legacy of the series for a broad audience of Southern, rural and purely music fans alike. Although country music was the primary genre of music featured on the show, guest stars and cast members alike also performed music from other genres, such as oldies and pop standards.

Some of the music-based segments on the show (other than guest stars' performances) included:

Lovullo also has made the claim the show presented "what were, in reality, the first musical videos." Lovullo said his videos were conceptualized by having the show's staff go to nearby rural areas and film animals and farmers, before editing the footage to fit the storyline of a particular song. "The video material was a very workable production item for the show," he wrote. "It provided picture stories for songs. However, some of our guests felt the videos took attention away from their live performances, which they hoped would promote record sales. If they had a hit song, they didn't want to play it under comic barnyard footage." The concept's mixed reaction eventually spelled an end to the "video" concept on "Hee Haw". However, several of co-host Owens' songs – including "Tall, Dark Stranger," "Big in Vegas", and "I Wouldn't Live in New York City (If They Gave Me the Whole Dang Town)" – aired on the series and have since aired on Great American Country and CMT as part of their classic country music programming blocks.

"Hee Haw" featured at least two, and sometimes three or four, guest celebrities each week. While most of the guest stars were country music artists, a wide range of other famous luminaries were featured from actors and actresses to sports stars to politicians.

Sheb Wooley, one of the original cast members, wrote the show's theme song. After filming the initial 13 episodes, other professional demands caused him to leave the show, but he returned from time to time as a guest.

Loretta Lynn was the first guest star of "Hee Haw" and made more guest appearances (24) than any other artist. She also co-hosted the show more than any other guest co-host and therefore appears on more of the DVD releases for retail sale than any other guest star. Tammy Wynette was second with 21 guest appearances.Tammy Wynette married George Richey (the musical director for Hee Haw from 1970 to 1977) in 1978.

From 1990–92, country megastar Garth Brooks appeared on the show four times. In 1992, producer Sam Lovullo tried unsuccessfully to contact Brooks because he wanted him for the final show. Brooks then surprised Lovullo by showing up at the last minute, ready to don his overalls and perform for the final episode.

A barn interior set was used as the main stage for most of the musical performances from the show's premiere until the debut of the "Hee Haw Honky Tonk" sketch in the early 1980s. Afterwards, the "Hee Haw Honky Tonk" set would serve as the main stage for the remainder of the series' run. Buck Owens then began using the barn interior set for his performances after it was replaced by the "Hee Haw Honky Tonk" set and was named "Buck's Place" (as a nod to one of Owens' hits, "Sam's Place"). Other settings for the musical performances throughout the series' run included a haystack (where the entire cast performed songs), the living room of a Victorian house, the front porch and lawn of the Samuel B. Sternwheeler home, a grist mill (where Roy Clark performed many of his songs in earlier seasons), and a railroad depot, where Buck Owens performed his songs before acquiring "Buck's Place."

Elvis Presley was a fan of "Hee Haw" and wanted to appear as a guest on the program, but Presley was afraid that his manager, Colonel Tom Parker, would not allow him to do so. Two of the Hee Haw Honeys dated Presley long before they joined the cast, Linda Thompson in the mid-1970s, whom Presley had a long-term relationship with after his divorce from Priscilla; and Diana Goodman shortly afterwards. Shortly after Presley's death, his father, Vernon Presley, made a cameo appearance on the show, alongside Thompson and Buck Owens, and paid tribute to his late son, noting how much Elvis enjoyed watching the show, and introduced one of his favorite gospel songs, as performed by the Hee Haw Gospel Quartet.

"Hee Haw" produced a short-lived spin-off series, "Hee Haw Honeys" (not to be confused with "Hee Haw's" female cast members), for the 1978–79 television seasons. The musical sitcom starred Kathie Lee Johnson (Gifford) along with "Hee Haw" regulars Misty Rowe, Gailard Sartain, Lulu Roman, and Kenny Price as a family who owned a truck stop restaurant (likely inspired by the "Lulu's Truck Stop" sketch on "Hee Haw"). Their restaurant included a bandstand, where guest country artists would perform a couple of their hits of the day, sometimes asking the cast to join them. Cast members would also perform songs occasionally; and the Nashville Edition, "Hee Haw's" backup singing group, frequently appeared on the show, portraying regular patrons of the restaurant. Notable guest stars on "Honeys" included, but were not limited to: Loretta Lynn, The Oak Ridge Boys, Larry Gatlin, Dave & Sugar, and the Kendalls.

The Hee Haw Theater opened in Branson, Missouri, in 1981 and operated through 1983. It featured live shows using the cast of the television series, as well as guests and other talent. The format was similar with a country variety show-type family theme.

Charlton Comics also published humor comics based on "Hee Haw". They were drawn by Frank Roberge.

When "Hee Haw" went into syndication, its normal time slot was on Saturday night in the pre-prime time hour (7:00pm ET).

"Hee Haw" continues to remain popular with its long-time fans and those who have discovered the program through DVD releases or its reruns on RFD-TV. In spite of the loving of the series by its fans, the program has never been a favorite of television critics or reviewers; the "Hee Haw Honeys" spin-off, in particular, was cited in a 2002 "TV Guide" article as one of the ten worst television series ever.

On at least four episodes of the animated Fox series "Family Guy", when the storyline hits a dead-end, a cutaway to Conway Twitty performing a song is inserted. The handoff is done in "Hee Haw" style, and often uses actual footage of Twitty performing on the show.

Lulu Roman released a new album titled "At Last" on January 15, 2013. The album features Lulu's versions of 12 classics and standards including guest appearances by Dolly Parton, T. Graham Brown, Linda Davis, and Georgette Jones (daughter of George Jones and Tammy Wynette).



</doc>
<doc id="13263" url="https://en.wikipedia.org/wiki?curid=13263" title="Hexadecimal">
Hexadecimal

In mathematics and computing, hexadecimal (also base , or hex) is a positional numeral system with a radix, or base, of 16. It uses sixteen distinct symbols, most often the symbols 0–9 to represent values zero to nine, and A–F (or alternatively a–f) to represent values ten to fifteen.

Hexadecimal numerals are widely used by computer system designers and programmers, as they provide a more human-friendly representation of binary-coded values. Each hexadecimal digit represents four binary digits, also known as a nibble, which is half a byte. For example, a single byte can have values ranging from 0000 0000 to 1111 1111 in binary form, which can be more conveniently represented as 00 to FF in hexadecimal.

In mathematics, a subscript is typically used to specify the radix. For example the decimal value would be expressed in hexadecimal as . In programming, a number of notations are used to support hexadecimal representation, usually involving a prefix or suffix. The prefix codice_1 is used in C and related languages, which would denote this value by 0x.

Hexadecimal is used in the transfer encoding Base16, in which each byte of the plaintext is broken into two 4-bit values and represented by two hexadecimal digits.

In contexts where the base is not clear, hexadecimal numbers can be ambiguous and confused with numbers expressed in other bases. There are several conventions for expressing values unambiguously. A numerical subscript (itself written in decimal) can give the base explicitly: 159 is decimal 159; 159 is hexadecimal 159, which is equal to 345. Some authors prefer a text subscript, such as 159 and 159, or 159 and 159.

In linear text systems, such as those used in most computer programming environments, a variety of methods have arisen:

There is no universal convention to use lowercase or uppercase for the letter digits, and each is prevalent or preferred in particular environments by community standards or convention.

The use of the letters "A" through "F" to represent the digits above 9 was not universal in the early history of computers.

There are no traditional numerals to represent the quantities from ten to fifteen – letters are used as a substitute – and most European languages lack non-decimal names for the numerals above ten. Even though English has names for several non-decimal powers ("pair" for the first binary power, "score" for the first vigesimal power, "dozen", "gross" and "great gross" for the first three duodecimal powers), no English name describes the hexadecimal powers (decimal 16, 256, 4096, 65536, ... ). Some people read hexadecimal numbers digit by digit like a phone number, or using the NATO phonetic alphabet, the Joint Army/Navy Phonetic Alphabet, or a similar ad hoc system.
Systems of counting on digits have been devised for both binary and hexadecimal.
Arthur C. Clarke suggested using each finger as an on/off bit, allowing finger counting from zero to 1023 on ten fingers. Another system for counting up to FF (255) is illustrated on the right.

The hexadecimal system can express negative numbers the same way as in decimal: −2A to represent −42 and so on.

Hexadecimal can also be used to express the exact bit patterns used in the processor, so a sequence of hexadecimal digits may represent a signed or even a floating point value. This way, the negative number −42 can be written as FFFF FFD6 in a 32-bit CPU register (in two's-complement), as C228 0000 in a 32-bit FPU register or C045 0000 0000 0000 in a 64-bit FPU register (in the IEEE floating-point standard).

Just as decimal numbers can be represented in exponential notation, so too can hexadecimal numbers. By convention, the letter "P" (or "p", for "power") represents "times two raised to the power of", whereas "E" (or "e") serves a similar purpose in decimal as part of the E notation. The number after the "P" is "decimal" and represents the "binary" exponent.

Usually the number is normalised so that the leading hexadecimal digit is 1 (unless the value is exactly 0).

Example: 1.3DEp42 represents .

Hexadecimal exponential notation is required by the IEEE 754-2008 binary floating-point standard.
This notation can be used for floating-point literals in the C99 edition of the C programming language.
Using the "%a" or "%A" conversion specifiers, this notation can be produced by implementations of the "printf" family of functions following the C99 specification and
Single Unix Specification (IEEE Std 1003.1) POSIX standard.

Most computers manipulate binary data, but it is difficult for humans to work with the large number of digits for even a relatively small binary number. Although most humans are familiar with the base 10 system, it is much easier to map binary to hexadecimal than to decimal because each hexadecimal digit maps to a whole number of bits (4).
This example converts 1111 to base ten. Since each position in a binary numeral can contain either a 1 or a 0, its value may be easily determined by its position from the right:
Therefore:

With little practice, mapping 1111 to F in one step becomes easy: see table in Written representation. The advantage of using hexadecimal rather than decimal increases rapidly with the size of the number. When the number becomes large, conversion to decimal is very tedious. However, when mapping to hexadecimal, it is trivial to regard the binary string as 4-digit groups and map each to a single hexadecimal digit.

This example shows the conversion of a binary number to decimal, mapping each digit to the decimal value, and adding the results.

Compare this to the conversion to hexadecimal, where each group of four digits can be considered independently, and converted directly:

The conversion from hexadecimal to binary is equally direct.

Although quaternary (base 4) is little used, it can easily be converted to and from hexadecimal or binary. Each hexadecimal digit corresponds to a pair of quaternary digits and each quaternary digit corresponds to a pair of binary digits. In the above example 5 E B 5 2 = 11 32 23 11 02.

The octal (base 8) system can also be converted with relative ease, although not quite as trivially as with bases 2 and 4. Each octal digit corresponds to three binary digits, rather than four. Therefore we can convert between octal and hexadecimal via an intermediate conversion to binary followed by regrouping the binary digits in groups of either three or four.

As with all bases there is a simple algorithm for converting a representation of a number to hexadecimal by doing integer division and remainder operations in the source base. In theory, this is possible from any base, but for most humans only decimal and for most computers only binary (which can be converted by far more efficient methods) can be easily handled with this method.

Let d be the number to represent in hexadecimal, and the series hh...hh be the hexadecimal digits representing the number.


"16" may be replaced with any other base that may be desired.

The following is a JavaScript implementation of the above algorithm for converting any number to a hexadecimal in String representation. Its purpose is to illustrate the above algorithm. To work with data seriously, however, it is much more advisable to work with bitwise operators.

It is also possible to make the conversion by assigning each place in the source base the hexadecimal representation of its place value and then performing multiplication and addition to get the final representation.
That is, to convert the number B3AD to decimal one can split the hexadecimal number into its digits: B (11), 3 (3), A (10) and D (13), and then get the final result by multiplying each decimal representation by 16, where "p" is the corresponding hex digit position, counting from right to left, beginning with 0. In this case we have , which is 45997 base 10.

Most modern computer systems with graphical user interfaces provide a built-in calculator utility, capable of performing conversions between various radices, in general including hexadecimal.

In Microsoft Windows, the Calculator utility can be set to Scientific mode (called Programmer mode in some versions), which allows conversions between radix 16 (hexadecimal), 10 (decimal), 8 (octal) and 2 (binary), the bases most commonly used by programmers. In Scientific Mode, the on-screen numeric keypad includes the hexadecimal digits A through F, which are active when "Hex" is selected. In hex mode, however, the Windows Calculator supports only integers.

As with other numeral systems, the hexadecimal system can be used to represent rational numbers, although repeating expansions are common since sixteen (10) has only a single prime factor (two):

where an overline denotes a recurring pattern.

For any base, 0.1 (or "1/10") is always equivalent to one divided by the representation of that base value in its own number system. Thus, whether dividing one by two for binary or dividing one by sixteen for hexadecimal, both of these fractions are written as codice_48. Because the radix 16 is a perfect square (4), fractions expressed in hexadecimal have an odd period much more often than decimal ones, and there are no cyclic numbers (other than trivial single digits). Recurring digits are exhibited when the denominator in lowest terms has a prime factor not found in the radix; thus, when using hexadecimal notation, all fractions with denominators that are not a power of two result in an infinite string of recurring digits (such as thirds and fifths). This makes hexadecimal (and binary) less convenient than decimal for representing rational numbers since a larger proportion lie outside its range of finite representation.

All rational numbers finitely representable in hexadecimal are also finitely representable in decimal, duodecimal and sexagesimal: that is, any hexadecimal number with a finite number of digits has a finite number of digits when expressed in those other bases. Conversely, only a fraction of those finitely representable in the latter bases are finitely representable in hexadecimal. For example, decimal 0.1 corresponds to the infinite recurring representation 0.199999999999... in hexadecimal. However, hexadecimal is more efficient than bases 12 and 60 for representing fractions with powers of two in the denominator (e.g., decimal one sixteenth is 0.1 in hexadecimal, 0.09 in duodecimal, 0;3,45 in sexagesimal and 0.0625 in decimal).

The table below gives the expansions of some common irrational numbers in decimal and hexadecimal.
Powers of two have very simple expansions in hexadecimal. The first sixteen powers of two are shown below.

The word "hexadecimal" is composed of "hexa-", derived from the Greek ἕξ (hex) for "six", and "-decimal", derived from the Latin for "tenth". Webster's Third New International online derives "hexadecimal" as an alteration of the all-Latin "sexadecimal" (which appears in the earlier Bendix documentation). The earliest date attested for "hexadecimal" in Merriam-Webster Collegiate online is 1954, placing it safely in the category of international scientific vocabulary (ISV). It is common in ISV to mix Greek and Latin combining forms freely. The word "sexagesimal" (for base 60) retains the Latin prefix. Donald Knuth has pointed out that the etymologically correct term is "senidenary" (or possibly, "sedenary"), from the Latin term for "grouped by 16". (The terms "binary", "ternary" and "quaternary" are from the same Latin construction, and the etymologically correct terms for "decimal" and "octal" arithmetic are "denary" and "octonary", respectively.) Alfred B. Taylor used "senidenary" in his mid-1800s work on alternative number bases, although he rejected base 16 because of its "incommodious number of digits". Schwartzman notes that the expected form from usual Latin phrasing would be "sexadecimal", but computer hackers would be tempted to shorten that word to "sex". The etymologically proper Greek term would be "hexadecadic" / "ἑξαδεκαδικός" / "hexadekadikós" (although in Modern Greek, "decahexadic" / "δεκαεξαδικός" / "dekaexadikos" is more commonly used).

The traditional Chinese units of weight were base-16. For example, one jīn (斤) in the old system equals sixteen taels. The suanpan (Chinese abacus) could be used to perform hexadecimal calculations.

As with the duodecimal system, there have been occasional attempts to promote hexadecimal as the preferred numeral system. These attempts often propose specific pronunciation and symbols for the individual numerals. Some proposals unify standard measures so that they are multiples of 16.

An example of unified standard measures is hexadecimal time, which subdivides a day by 16 so that there are 16 "hexhours" in a day.

Base16 (as a proper name without a space) can also refer to a binary to text encoding belonging to the same family as Base32, Base58, and Base64.

In this case, data is broken into 4-bit sequences, and each value (between 0 and 15 inclusively) is encoded using 16 symbols from the ASCII character set. Although any 16 symbols from the ASCII character set can be used, in practice the ASCII digits '0'-'9' and the letters 'A'-'F' (or the lowercase 'a'-'f') are always chosen in order to align with standard written notation for hexadecimal numbers.

There are several advantages of Base16 encoding:

The main disadvantages of Base16 encoding are:

Support for Base16 encoding is ubiquitous in modern computing. It is the basis for the W3C standard for URL Percent Encoding, where a character is replaced with a percent sign "%" and its Base16-encoded form. Most modern programming languages directly include support for formatting and parsing Base16-encoded numbers.



</doc>
<doc id="13264" url="https://en.wikipedia.org/wiki?curid=13264" title="Hex">
Hex

Hex or HEX may refer to:












</doc>
<doc id="13265" url="https://en.wikipedia.org/wiki?curid=13265" title="Hitler (disambiguation)">
Hitler (disambiguation)

Adolf Hitler (1889–1945) was the authoritarian Chancellor of Germany from 1933 to 1945.

Hitler may also refer to:






</doc>
<doc id="13266" url="https://en.wikipedia.org/wiki?curid=13266" title="Histogram">
Histogram

A histogram is an accurate representation of the distribution of numerical data. It is an estimate of the probability distribution of a continuous variable (quantitative variable) and was first introduced by Karl Pearson. It differs from a bar graph, in the sense that a bar graph relates two variables, but a histogram relates only one. To construct a histogram, the first step is to "bin" (or "bucket") the range of values—that is, divide the entire range of values into a series of intervals—and then count how many values fall into each interval. The bins are usually specified as consecutive, non-overlapping intervals of a variable. The bins (intervals) must be adjacent, and are often (but are not required to be) of equal size.

If the bins are of equal size, a rectangle is erected over the bin with height proportional to the frequency—the number of cases in each bin. A histogram may also be normalized to display "relative" frequencies. It then shows the proportion of cases that fall into each of several categories, with the sum of the heights equaling 1.

However, bins need not be of equal width; in that case, the erected rectangle is defined to have its "area" proportional to the frequency of cases in the bin. The vertical axis is then not the frequency but "frequency density"—the number of cases per unit of the variable on the horizontal axis. Examples of variable bin width are displayed on Census bureau data below.

As the adjacent bins leave no gaps, the rectangles of a histogram touch each other to indicate that the original variable is continuous.

Histograms give a rough sense of the density of the underlying distribution of the data, and often for density estimation: estimating the probability density function of the underlying variable. The total area of a histogram used for probability density is always normalized to 1. If the length of the intervals on the "x"-axis are all 1, then a histogram is identical to a relative frequency plot.

A histogram can be thought of as a simplistic kernel density estimation, which uses a kernel to smooth frequencies over the bins. This yields a smoother probability density function, which will in general more accurately reflect distribution of the underlying variable. The density estimate could be plotted as an alternative to the histogram, and is usually drawn as a curve rather than a set of boxes. Histograms are nevertheless preferred in applications, when their statistical properties need to be modeled. The correlated variation of a kernel density estimate is very difficult to describe mathematically, while it is simple for a histogram where each bin varies independently.

An alternative to kernel density estimation is the average shifted histogram,
which is fast to compute and gives a smooth curve estimate of the density without using kernels.

The histogram is one of the seven basic tools of quality control.

Histograms are sometimes confused with bar charts. A histogram is used for continuous data, where the bins represent ranges of data, while a bar chart is a plot of categorical variables. Some authors recommend that bar charts have gaps between the rectangles to clarify the distinction.

The etymology of the word "histogram" is uncertain. Sometimes it is said to be derived from the Ancient Greek ("histos") – "anything set upright" (as the masts of a ship, the bar of a loom, or the vertical bars of a histogram); and ("gramma") – "drawing, record, writing". It is also said that Karl Pearson, who introduced the term in 1891, derived the name from "historical diagram".

This is the data for the histogram to the right, using 500 items:

The words used to describe the patterns in a histogram are: "symmetric", "skewed left" or "right", "unimodal", "bimodal" or "multimodal".

It is a good idea to plot the data using several different bin widths to learn more about it. Here is an example on tips given in a restaurant.

Here are a couple more examples:
The U.S. Census Bureau found that there were 124 million people who work outside of their homes. Using their data on the time occupied by travel to work, the table below shows the absolute number of people who responded with travel times "at least 30 but less than 35 minutes" is higher than the numbers for the categories above and below it. This is likely due to people rounding their reported journey time. The problem of reporting values as somewhat arbitrarily rounded numbers is a common phenomenon when collecting data from people.

This histogram shows the number of cases per unit interval as the height of each block, so that the area of each block is equal to the number of people in the survey who fall into its category. The area under the curve represents the total number of cases (124 million). This type of histogram shows absolute numbers, with Q in thousands.

This histogram differs from the first only in the vertical scale. The area of each block is the fraction of the total that each category represents, and the total area of all the bars is equal to 1 (the fraction meaning "all"). The curve displayed is a simple density estimate. This version shows proportions, and is also known as a unit area histogram.
In other words, a histogram represents a frequency distribution by means of rectangles whose widths represent class intervals and whose areas are proportional to the corresponding frequencies: the height of each is the average frequency density for the interval. The intervals are placed together in order to show that the data represented by the histogram, while exclusive, is also contiguous. (E.g., in a histogram it is possible to have two connecting intervals of 10.5–20.5 and 20.5–33.5, but not two connecting intervals of 10.5–20.5 and 22.5–32.5. Empty intervals are represented as empty and not skipped.)

In a more general mathematical sense, a histogram is a function "m" that counts the number of observations that fall into each of the disjoint categories (known as "bins"), whereas the graph of a histogram is merely one way to represent a histogram. Thus, if we let "n" be the total number of observations and "k" be the total number of bins, the histogram "m" meets the following conditions:

A cumulative histogram is a mapping that counts the cumulative number of observations in all of the bins up to the specified bin. That is, the cumulative histogram "M" of a histogram "m" is defined as:

There is no "best" number of bins, and different bin sizes can reveal different features of the data. Grouping data is at least as old as Graunt's work in the 17th century, but no systematic guidelines were given until Sturges's work in 1926.

Using wider bins where the density of the underlying data points is low reduces noise due to sampling randomness; using narrower bins where the density is high (so the signal drowns the noise) gives greater precision to the density estimation. Thus varying the bin-width within a histogram can be beneficial. Nonetheless, equal-width bins are widely used.

Some theoreticians have attempted to determine an optimal number of bins, but these methods generally make strong assumptions about the shape of the distribution. Depending on the actual data distribution and the goals of the analysis, different bin widths may be appropriate, so experimentation is usually needed to determine an appropriate width. There are, however, various useful guidelines and rules of thumb.

The number of bins "k" can be assigned directly or can be calculated from a suggested bin width "h" as:

The braces indicate the ceiling function.

which takes the square root of the number of data points in the sample (used by Excel histograms and many others).

Sturges' formula is derived from a binomial distribution and implicitly assumes an approximately normal distribution.

It implicitly bases the bin sizes on the range of the data and can perform poorly if "n" < 30, because the number of bins will be small—less than seven—and unlikely to show trends in the data well. It may also perform poorly if the data are not normally distributed.

The Rice Rule is presented as a simple alternative to Sturges's rule.

Doane's formula is a modification of Sturges' formula which attempts to improve its performance with non-normal data.

where formula_8 is the estimated 3rd-moment-skewness of the distribution and

where formula_11 is the sample standard deviation. Scott's normal reference rule is optimal for random samples of normally distributed data, in the sense that it minimizes the integrated mean squared error of the density estimate.

The Freedman–Diaconis rule is:

which is based on the interquartile range, denoted by IQR. It replaces 3.5σ of Scott's rule with 2 IQR, which is less sensitive than the standard deviation to outliers in data.

This approach of minimizing integrated mean squared error from Scott's rule can be generalized beyond normal distributions, by using leave-one out cross validation:

Here, formula_14 is the number of datapoints in the "k"th bin, and choosing the value of "h" that minimizes "J" will minimize integrated mean squared error.

The choice is based on minimization of an estimated "L" risk function

where formula_16 and formula_17 are mean and biased variance of a histogram with bin-width formula_18, formula_19 and formula_20.

A good reason why the number of bins should be proportional to formula_21 is the following: suppose that the data are obtained as formula_22 independent realizations of a bounded probability distribution with smooth density. Then the histogram remains equally "rugged" as formula_22 tends to infinity. If formula_24 is the "width" of the distribution (e. g., the standard deviation or the inter-quartile range), then the number of units in a bin (the frequency) is of order formula_25 and the "relative" standard error is of order formula_26. Comparing to the next bin, the relative change of the frequency is of order formula_27 provided that the derivative of the density is non-zero. These two are of the same order if formula_28 is of order formula_29, so that formula_30 is of order formula_31. This simple cubic root choice can also be applied to bins with non-constant width.





</doc>
<doc id="13269" url="https://en.wikipedia.org/wiki?curid=13269" title="Hilter">
Hilter

Hilter is a municipality in the district Osnabrück, Lower Saxony, Germany. It is located in the hills of the Teutoburg Forest.

As of 2002 it has a population of 10,178, and covers an area of 52.61 km². Highest elevation is the Hohnangel with 262 m above sea level.

The municipality was united on July 14, 1972, by merging the municipalities Borgloh, Hankenberge and Hilter. Already in 1977 the municipalities Allendorf, Borgloh-Wellendorf, Ebbendorf, Eppendorf and Uphöfen were joined into the "Einheitsgemeinde" Borgloh.

Hilter was well known for mining "Hilter Gold" ochre as well as its big margarine factory which owned one of the largest whaling fleets in the early 20th century.



</doc>
<doc id="13270" url="https://en.wikipedia.org/wiki?curid=13270" title="Hawaii">
Hawaii

Hawaii ( ; ) is the 50th and most recent state to have joined the United States, having received statehood on August 21, 1959. Hawaii is the only U.S. state located in Oceania and the only one composed entirely of islands. It is the northernmost island group in Polynesia, occupying most of an archipelago in the central Pacific Ocean. Hawaii is the only U.S. state located outside North America.

The state encompasses nearly the entire volcanic Hawaiian archipelago, which comprises hundreds of islands spread over . At the southeastern end of the archipelago, the eight main islands are—in order from northwest to southeast: Niihau, Kauai, Oahu, Molokai, Lānai, Kahoolawe, Maui, and the Island of Hawaii. The last is the largest island in the group; it is often called the "Big Island" or "Hawaii Island" to avoid confusion with the state or archipelago. The archipelago is physiographically and ethnologically part of the Polynesian subregion of Oceania.

Hawaii's diverse natural scenery, warm tropical climate, abundance of public beaches, oceanic surroundings, and active volcanoes make it a popular destination for tourists, surfers, biologists, and volcanologists. Because of its central location in the Pacific and 19th-century labor migration, Hawaii's culture is strongly influenced by North American and East Asian cultures, in addition to its indigenous Hawaiian culture. Hawaii has over a million permanent residents, along with many visitors and U.S. military personnel. Its capital is Honolulu on the island of Oahu.

Hawaii is the 8th-smallest and the 11th-least populous, but the 13th-most densely populated of the 50 U.S. states. It is the only state with an Asian plurality. The state's coastline is about long, the fourth longest in the U.S. after the coastlines of Alaska, Florida, and California.

The state of Hawaii derives its name from the name of its largest island, Hawaii. A common Hawaiian explanation of the name of Hawaii is that was named for Hawaiiloa, a legendary figure from Hawaiian myth. He is said to have discovered the islands when they were first settled.

The Hawaiian language word "Hawaii" is very similar to Proto-Polynesian *"Sawaiki", with the reconstructed meaning "homeland". Cognates of "Hawaii" are found in other Polynesian languages, including Māori ("Hawaiki"), Rarotongan ("ʻAvaiki") and Samoan ("Savaii") . According to linguists Pukui and Elbert, "[e]lsewhere in Polynesia, Hawaii or a cognate is the name of the underworld or of the ancestral home, but in Hawaii, the name has no meaning".

A somewhat divisive political issue arose in 1978 when the Constitution of the State of Hawaii added Hawaiian as a second official state language. The title of the state constitution is "The Constitution of the State of Hawaii". ArticleXV, Section1 of the Constitution uses "The State of Hawaii". Diacritics were not used because the document, drafted in 1949, predates the use of the okina () and the kahakō in modern Hawaiian orthography. The exact spelling of the state's name in the Hawaiian language is "Hawaii". In the Hawaii Admission Act that granted Hawaiian statehood, the federal government recognized "Hawaii" as the official state name. Official government publications, department and office titles, and the Seal of Hawaii use the traditional spelling with no symbols for glottal stops or vowel length. In contrast, the National and State Parks Services, the University of Hawaii and some private enterprises implement these symbols. No precedent for changes to U.S. state names exists since the adoption of the United States Constitution in 1789. However, the Constitution of Massachusetts formally changed the "Province of Massachusetts Bay" to the Commonwealth of Massachusetts in 1780, and in 1819, the Territory of Arkansaw was created but was later admitted to statehood as the State of Arkansas.

There are eight main Hawaiian islands, seven of which are permanently inhabited. The island of Niihau is privately managed by brothers Bruce and Keith Robinson; access is restricted to those who have permission from the island's owners. Access to uninhabited Kahoʻolawe island is also restricted.

The Hawaiian archipelago is located southwest of the contiguous United States. Hawaii is the southernmost U.S. state and the second westernmost after Alaska. Hawaii, like Alaska, does not border any other U.S. state. It is the only U.S. state that is not geographically located in North America, the only state completely surrounded by water and that is entirely an archipelago, and the only state in which coffee is commercially cultivable.

In addition to the eight main islands, the state has many smaller islands and islets. Kaula is a small island near Niihau. The Northwest Hawaiian Islands is a group of nine small, older islands to the northwest of Kauai that extend from Nihoa to Kure Atoll; these are remnants of once much larger volcanic mountains. Across the archipelago are around 130 small rocks and islets, such as Molokini, which are either volcanic, marine sedimentary or erosional in origin.

Hawaii's tallest mountain Mauna Kea is above mean sea level; it is taller than Mount Everest if measured from the base of the mountain, which lies on the floor of the Pacific Ocean and rises about .

The Hawaiian islands were formed by volcanic activity initiated at an undersea magma source called the Hawaii hotspot. The process is continuing to build islands; the tectonic plate beneath much of the Pacific Ocean continually moves northwest and the hot spot remains stationary, slowly creating new volcanoes. Because of the hotspot's location, all currently active land volcanoes are located on the southern half of Hawaii Island. The newest volcano, Lōihi Seamount, is located south of the coast of Hawaii Island.

The last volcanic eruption outside Hawaii Island occurred at Haleakalā on Maui before the late 18thcentury, possibly hundreds of years earlier. In 1790, Kīlauea exploded; it was the deadliest eruption known to have occurred in the modern era in what is now the United States. Up to 5,405 warriors and their families marching on Kīlauea were killed by the eruption. Volcanic activity and subsequent erosion have created impressive geological features. Hawaii Island has the second-highest point among the world's islands.

On the flanks of the volcanoes, slope instability has generated damaging earthquakes and related tsunamis, particularly in 1868 and 1975. Steep cliffs have been created by catastrophic debris avalanches on the submerged flanks of ocean island volcanoes.

The Kīlauea erupted in May 2018, opening 22 fissure vents on its East Rift Zone. The Leilani Estates and Lanipuna Gardens are situated within this territory. The destruction affected at least 36 buildings and this coupled with the lava flows and the Sulfur dioxide fumes, necessitated the evacuation of more than 2,000 local inhabitants from the neighborhoods.

Because the islands of Hawaii are distant from other land habitats, life is thought to have arrived there by wind, waves (i.e. by ocean currents) and wings (i.e. birds, insects, and any seeds they may have carried on their feathers). This isolation, in combination with the diverse environment (including extreme altitudes, tropical climates, and arid shorelines), allowed for the evolution of new endemic flora and fauna. Hawaii has more endangered species and has lost a higher percentage of its endemic species than any other U.S. state. One endemic plant, "Brighamia", now requires hand-pollination because its natural pollinator is presumed to be extinct. The two species of "Brighamia"—"B. rockii" and "B. insignis"—are represented in the wild by around 120 individual plants. To ensure these plants set seed, biologists rappel down cliffs to brush pollen onto their stigmas.

The extant main islands of the archipelago have been above the surface of the ocean for fewer than 10million years; a fraction of the time biological colonization and evolution have occurred there. The islands are well known for the environmental diversity that occurs on high mountains within a trade winds field. On a single island, the climate around the coasts can range from dry tropical (less than annual rainfall) to wet tropical; on the slopes, environments range from tropical rainforest (more than per year), through a temperate climate, to alpine conditions with a cold, dry climate. The rainy climate impacts soil development, which largely determines ground permeability, affecting the distribution of streams and wetlands.

Several areas in Hawaii are under the protection of the National Park Service. Hawaii has two national parks: Haleakalā National Park located near Kula on the island of Maui, which features the dormant volcano Haleakalā that formed east Maui, and Hawaii Volcanoes National Park in the southeast region of the Hawaii Island, which includes the active volcano Kīlauea and its rift zones.

There are three national historical parks; Kalaupapa National Historical Park in Kalaupapa, Molokai, the site of a former leper colony; Kaloko-Honokōhau National Historical Park in Kailua-Kona on Hawaii Island; and Puuhonua o Hōnaunau National Historical Park, an ancient place of refuge on Hawaii Island's west coast. Other areas under the control of the National Park Service include Ala Kahakai National Historic Trail on Hawaii Island and the USS "Arizona" Memorial at Pearl Harbor on Oahu.

The Papahānaumokuākea Marine National Monument was proclaimed by President George W. Bush on June 15, 2006. The monument covers roughly of reefs, atolls, and shallow and deep sea out to offshore in the Pacific Ocean—an area larger than all of the national parks in the U.S. combined.

Hawaii's climate is typical for the tropics, although temperatures and humidity tend to be less extreme because of near-constant trade winds from the east. Summer highs usually reach around during the day, with the temperature reaching a low of at night. Winter day temperatures are usually around ; at low elevation they seldom dip below at night. Snow, not usually associated with the tropics, falls at on Mauna Kea and Mauna Loa on Hawaii Island in some winter months. Snow rarely falls on Haleakalā. Mount Waialeale on Kauai has the second-highest average annual rainfall on Earth, about per year. Most of Hawaii experiences only two seasons; the dry season runs from May to October and the wet season is from October to April.

The warmest temperature recorded in the state, in Pahala on April 27, 1931, is , making it tied with Alaska as the lowest record high temperature observed in a U.S. state. Hawaii's record low temperature is observed in May1979, on the summit of Mauna Kea. Hawaii is the only state to have never recorded sub-zero Fahrenheit temperatures.

Climates vary considerably on each island; they can be divided into windward and leeward ("koolau" and "kona", respectively) areas based upon location relative to the higher mountains. Windward sides face cloud cover.

Hawaii is one of four U.S. states—apart from the original thirteen, along with the Vermont Republic (1791), the Republic of Texas (1845), and the California Republic (1846)—that were independent nations prior to statehood. Along with Texas, Hawaii had formal, international diplomatic recognition as a nation.

The Kingdom of Hawaii was sovereign from 1810 until 1893 when the monarchy was overthrown by resident American and European capitalists and landholders. Hawaii was an independent republic from 1894 until August 12, 1898, when it officially became a territory of the United States. Hawaii was admitted as a U.S. state on August 21, 1959.

Based on archaeological evidence, the earliest habitation of the Hawaiian Islands dates to around 300 CE, probably by Polynesian settlers from the Marquesas Islands. A second wave of migration from Raiatea and Bora Bora took place in the century. The date of the human discovery and habitation of the Hawaiian Islands is the subject of academic debate. Some archaeologists and historians think it was a later wave of immigrants from Tahiti around 1000 CE who introduced a new line of high chiefs, the kapu system, the practice of human sacrifice, and the building of "heiau". This later immigration is detailed in Hawaiian mythology ("moolelo") about Paao. Other authors say there is no archaeological or linguistic evidence for a later influx of Tahitian settlers and that Paao must be regarded as a myth.

The history of the islands is marked by a slow, steady growth in population and the size of the chiefdoms, which grew to encompass whole islands. Local chiefs, called alii, ruled their settlements, and launched wars to extend their influence and defend their communities from predatory rivals. Ancient Hawaii was a caste-based society, much like that of Hindus in India.

It is possible that Spanish explorers arrived in the Hawaiian Islands in the 16th century—200 years before Captain James Cook's first documented visit in 1778. Ruy López de Villalobos commanded a fleet of six ships that left Acapulco in 1542 bound for the Philippines with a Spanish sailor named Juan Gaetano aboard as pilot. Depending on the interpretation, Gaetano's reports describe an encounter with either Hawaii or the Marshall Islands. If de Villalobos' crew spotted Hawaii, Gaetano would be considered the first European to see the islands. Some scholars have dismissed these claims due to a lack of credibility.

Spanish archives contain a chart that depicts islands at the same latitude as Hawaii but with a longitude ten degrees east of the islands. In this manuscript, the island of Maui is named "La Desgraciada" (The Unfortunate Island), and what appears to be Hawaii Island is named "La Mesa" (The Table). Islands resembling Kahoolawe, Lanai, and Molokai are named "Los Monjes" (The Monks). For two-and-a-half centuries, Spanish galleons crossed the Pacific from Mexico along a route that passed south of Hawaii on their way to Manila. The exact route was kept secret to protect the Spanish trade monopoly against competing powers.

The 1778 arrival of British explorer James Cook was the first documented contact by a European explorer with Hawaii. Cook named the archipelago as the Sandwich Islands in honor of his sponsor John Montagu, 4th Earl of Sandwich. Cook published the islands' location and rendered the native name as "Owyhee". This spelling lives on in Owyhee County, Idaho. It was named after three native Hawaiian members of a trapping party who went missing in that area. The Owyhee Mountains were also named for them.
Cook visited the Hawaiian Islands twice. As he prepared for departure after his second visit in 1779, a quarrel ensued as Cook took temple idols and fencing as "firewood", and a minor chief and his men took a ship's boat. Cook abducted the King of Hawaii Island, Kalaniōpuu, and held him for ransom aboard his ship in order to gain return of Cook's boat. This tactic had worked in Tahiti and other islands. Instead, Kalaniōpuu's supporters fought back, killing Cook and four marines as Cook's party retreated along the beach to their ship. They departed without the ship's boat.

After Cook's visit and the publication of several books relating his voyages, the Hawaiian islands attracted many European visitors: explorers, traders, and eventually whalers, who found the islands to be a convenient harbor and source of supplies. Early British influence can be seen in the design of the flag of Hawaii, which bears the Union Jack in the top-left corner. These visitors introduced diseases to the once-isolated islands, causing the Hawaiian population to drop precipitously. Native Hawaiians had no resistance to Eurasian diseases, such as influenza, smallpox and measles. By 1820, disease, famine and wars between the chiefs killed more than half of the Native Hawaiian population. During the 1850s, measles killed a fifth of Hawaii's people.

Historical records indicated the earliest Chinese immigrants to Hawaii originated from Guangdong Province; a few sailors arrived in 1778 with Captain Cook's journey and more arrived in 1789 with an American trader, who settled in Hawaii in the late 18th century. It is said that leprosy was introduced by Chinese workers by 1830; as with the other new infectious diseases, it proved damaging to the Hawaiians.

During the 1780s, and 1790s, chiefs often fought for power. After a series of battles that ended in 1795, all inhabited islands were subjugated under a single ruler, who became known as King Kamehameha the Great. He established the House of Kamehameha, a dynasty that ruled the kingdom until 1872.

After Kamehameha II inherited the throne in 1819, American Protestant missionaries to Hawaii converted many Hawaiians to Christianity. They used their influence to end many traditional practices of the people. During the reign of King Kamehameha III, Hawai'i turned into a Christian monarchy with the signing of the 1840 Constitution. Hiram Bingham I, a prominent Protestant missionary, was a trusted adviser to the monarchy during this period. Other missionaries and their descendants became active in commercial and political affairs, leading to conflicts between the monarchy and its restive American subjects. Catholic and Mormon missionaries were also active in the kingdom, but they converted a minority of the Native Hawaiian population. Missionaries from each major group administered to the leper colony at Kalaupapa on Molokai, which was established in 1866 and operated well into the 20th century. The best known were Father Damien and Mother Marianne Cope, both of whom were canonized in the early 21st century as Roman Catholic saints.

The death of the bachelor King Kamehameha V—who did not name an heir—resulted in the popular election of Lunalilo over Kalākaua. Lunalilo died the next year, also without naming an heir. In 1874, the election was contested within the legislature between Kalākaua and Emma, Queen Consort of Kamehameha IV. After riots broke out, the United States and Britain landed troops on the islands to restore order. King Kalākaua was chosen as monarch by the Legislative Assembly by a vote of 39 to 6 on February 12, 1874.

In 1887, Kalākaua was forced to sign the 1887 Constitution of the Kingdom of Hawaii. Drafted by white businessmen and lawyers, the document stripped the king of much of his authority. It established a property qualification for voting that effectively disenfranchised most Hawaiians and immigrant laborers and favored the wealthier, white elite. Resident whites were allowed to vote but resident Asians were not. As the 1887 Constitution was signed under threat of violence, it is known as the Bayonet Constitution. King Kalākaua, reduced to a figurehead, reigned until his death in 1891. His sister, Queen Liliuokalani, succeeded him; she was the last monarch of Hawaii.

In 1893, Queen Liliuokalani announced plans for a new constitution to proclaim herself an absolute monarch. On January 14, 1893, a group of mostly Euro-American business leaders and residents formed the Committee of Safety to stage a coup d'état against the kingdom and seek annexation by the United States. United States Government Minister John L. Stevens, responding to a request from the Committee of Safety, summoned a company of U.S. Marines. The Queen's soldiers did not resist. According to historian William Russ, the monarchy was unable to protect itself.

On January 17, 1893, Queen Liliuokalani was overthrown and replaced by a provisional government composed of members of the Committee of Safety. The United States Minister to the Kingdom of Hawaii (John L. Stevens) conspired with U.S. citizens to overthrow the monarchy. After the overthrow, Lawyer Sanford B. Dole, a citizen of Hawaii, became President of the Republic when the Provisional Government of Hawaii ended on July 4, 1894. Controversy ensued in the following years as the Queen tried to regain her throne. The administration of President Grover Cleveland commissioned the Blount Report, which concluded that the removal of Liliuokalani had been illegal. The U.S. government first demanded that Queen Liliuokalani be reinstated, but the Provisional Government refused.

Congress conducted an independent investigation, and on February 26, 1894, submitted the Morgan Report, which found all parties, including Minister Stevens—with the exception of the Queen—"not guilty" and not responsible for the coup. Partisans on both sides of the debate questioned the accuracy and impartiality of both the Blount and Morgan reports over the events of 1893.

In 1993, the US Congress passed a joint Apology Resolution regarding the overthrow; it was signed by President Bill Clinton. The resolution apologized and said that the overthrow was illegal in the following phrase: "The Congress — on the occasion of the 100th anniversary of the illegal overthrow of the Kingdom of Hawaii on January 17, 1893, acknowledges the historical significance of this event which resulted in the suppression of the inherent sovereignty of the Native Hawaiian people." The Apology Resolution also "acknowledges that the overthrow of the Kingdom of Hawaii occurred with the active participation of agents and citizens of the United States and further acknowledges that the Native Hawaiian people never directly relinquished to the United States their claims to their inherent sovereignty as a people over their national lands, either through the Kingdom of Hawaii or through a plebiscite or referendum".

After William McKinley won the 1896 U.S. presidential election, advocates pressed to annex the Republic of Hawaii. The previous president, Grover Cleveland, was a friend of Queen Liliuokalani. McKinley was open to persuasion by U.S. expansionists and by annexationists from Hawaii. He met with three non-native annexationists: Lorrin A. Thurston, Francis March Hatch and William Ansel Kinney. After negotiations in June 1897, Secretary of State John Sherman agreed to a treaty of annexation with these representatives of the Republic of Hawaii. The U.S. Senate never ratified the treaty. Despite the opposition of most native Hawaiians, the Newlands Resolution was used to annex the Republic to the U.S.; it became the Territory of Hawaii. The Newlands Resolution was passed by the House on June 15, 1898, by 209 votes in favor to 91 against, and by the Senate on July 6, 1898, by a vote of 42 to 21.

In 1900, Hawaii was granted self-governance and retained Iolani Palace as the territorial capitol building. Despite several attempts to become a state, Hawaii remained a territory for 60 years. Plantation owners and capitalists, who maintained control through financial institutions such as the Big Five, found territorial status convenient because they remained able to import cheap, foreign labor. Such immigration and labor practices were prohibited in many states.
Puerto Rican immigration to Hawaii began in 1899, when Puerto Rico's sugar industry was devastated by two hurricanes, causing a worldwide shortage of sugar and a huge demand for sugar from Hawaii. Hawaiian sugarcane plantation owners began to recruit experienced, unemployed laborers in Puerto Rico. Two waves of Korean immigration to Hawaii occurred in the 20th century. The first wave arrived between 1903 and 1924; the second wave began in 1965 after President Lyndon B. Johnson signed the Immigration and Nationality Act of 1965, which removed racial and national barriers and resulted in significantly altering the demographic mix in the U.S.

Oahu was the target of a surprise attack on Pearl Harbor by Imperial Japan on December 7, 1941. The attack on Pearl Harbor and other military and naval installations, carried out by aircraft and by midget submarines, brought the United States into World War II.

In the 1950s, the power of the plantation owners was broken by the descendants of immigrant laborers, who were born in Hawaii and were U.S. citizens. They voted against the Hawaii Republican Party, strongly supported by plantation owners. The new majority voted for the Democratic Party of Hawaii, which dominated territorial and state politics for more than 40 years. Eager to gain full representation in Congress and the Electoral College, residents actively campaigned for statehood. In Washington there was talk that Hawaii would be a Republican Party stronghold so it was matched with the admission of Alaska, seen as a Democratic Party stronghold. These predictions turned out to be inaccurate; today, Hawaii votes Democratic predominantly, while Alaska votes Republican.

In March 1959, Congress passed the Hawaii Admission Act, which U.S. President Dwight D. Eisenhower signed into law. The act excluded Palmyra Atoll from statehood; it had been part of the Kingdom and Territory of Hawaii. On June 27, 1959, a referendum asked residents of Hawaii to vote on the statehood bill; 94.3% voted in favor of statehood and 5.7% opposed it. The referendum asked voters to choose between accepting the Act and remaining a U.S. territory. The United Nations' Special Committee on Decolonization later removed Hawaii from its list of non-self-governing territories.

After attaining statehood, Hawaii quickly modernized through construction and a rapidly growing tourism economy. Later, state programs promoted Hawaiian culture. The Hawaii State Constitutional Convention of 1978 created institutions such as the Office of Hawaiian Affairs to promote indigenous language and culture.

After Europeans and mainland Americans first arrived during the Kingdom of Hawaii period, the overall population of Hawaii, until that time composed solely of indigenous Hawaiians, fell dramatically. The indigenous Hawaiian population succumbed to foreign diseases, declining from 300,000 in the 1770s, to 60,000 in the 1850s, to 24,000 in 1920. The population of Hawaii began to finally increase after an influx of primarily Asian settlers that arrived as migrant laborers at the end of the 19thcentury.

The unmixed indigenous Hawaiian population has still not restored itself to its 300,000 pre-contact level. As of 2010, only 156,000 persons declared themselves to be of Native Hawaiian only ancestry, just over half of the pre-contact level Native Hawaiian population, although an additional 371,000 persons declared themselves to possess Native Hawaiian ancestry in combination with one or more other races (including other Polynesian groups, but mostly Asian and/or Caucasian).

The United States Census Bureau estimates the population of Hawaii was 1,431,603 on July 1, 2015; an increase of 5.2% since the 2010 United States Census.

, Hawaii had an estimated population of 1,431,603; an increase of 12,042 from the previous year and an increase of 71,302 (5.2%) since 2010. This includes a natural increase of 48,111 (96,028 births minus 47,917 deaths) and an increase due to net migration of 16,956 people into the state. Immigration from outside the United States resulted in a net increase of 30,068; migration within the country produced a net loss of 13,112 people.

The center of population of Hawaii is located between the two islands of O'ahu and Moloka'i. Large numbers of Native Hawaiians have moved to Las Vegas, which has been called the "ninth island" of Hawaii.

Hawaii has a "de facto" population of over 1.4million, due in part to a large number of military personnel and tourist residents. O'ahu is the most populous island; it has the highest population density with a resident population of just under one million in , approximately 1,650 people per square mile. Hawaii's 1.4million residents, spread across of land, result in an average population density of 188.6 persons per square mile. The state has a lower population density than Ohio and Illinois.

The average projected lifespan of people born in Hawaii in 2000 is 79.8 years; 77.1 years if male, 82.5 if female—longer than the average lifespan of any other U.S. state. the U.S. military reported it had 42,371 personnel on the islands.

According to the 2010 United States Census, Hawaii had a population of 1,360,301. The state's population identified as 38.6% Asian; 24.7% White (22.7% Non-Hispanic White Alone); 23.6% from two or more races; 10.0% Native Hawaiians and other Pacific Islanders; 8.9% Hispanics and Latinos of any race; 1.6% Black or African American; 1.2% from some other race; and 0.3% Native American and Alaska Native.

Hawaii has the highest percentage of Asian Americans and multiracial Americans and the lowest percentage of White Americans of any state. It is the only state where Asian Americans identify as the largest ethnic group. In 2012, 14.5% of the resident population under age 1 was non-Hispanic white. Hawaii's Asian population consists mainly of 198,000 (14.6%) Filipino Americans, 185,000 (13.6%) Japanese Americans, roughly 55,000 (4.0%) Chinese Americans, and 24,000 (1.8%) Korean Americans. There are over 80,000 Indigenous Hawaiians—5.9% of the population. Including those with partial ancestry, Samoan Americans constitute 2.8% of Hawaii's population, and Tongan Americans constitute 0.6%.

Over 120,000 (8.8%) Hispanic and Latino Americans live in Hawaii. Mexican Americans number over 35,000 (2.6%); Puerto Ricans exceed 44,000 (3.2%). Multiracial Americans constitute almost 25% of Hawaii's population, exceeding 320,000 people. Eurasian Americans are a prominent mixed-race group, numbering about 66,000 (4.9%). The Non-Hispanic White population numbers around 310,000—just over 20% of the population. The multi-racial population outnumbers the non-Hispanic white population by about 10,000 people. In 1970, the Census Bureau reported Hawaii's population was 38.8% white and 57.7% Asian and Pacific Islander.

The five largest European ancestries in Hawaii are German (7.4%), Irish (5.2%), English (4.6%), Portuguese (4.3%) and Italian (2.7%). About 82.2% of the state's residents were born in the United States. Roughly 75% of foreign-born residents originate in Asia. Hawaii is a majority-minority state. It was expected to be one of three states that will not have a non-Hispanic white plurality in 2014; the other two are California and New Mexico.

The third group of foreigners to arrive in Hawaii were from China. Chinese workers on Western trading ships settled in Hawaii starting in 1789. In 1820, the first American missionaries arrived to preach Christianity and teach the Hawaiians Western ways. , a large proportion of Hawaii's population have Asian ancestry—especially Filipino, Japanese and Chinese. Many are descendants of immigrants brought to work on the sugarcane plantations in the mid-to-late 19th century. The first 153 Japanese immigrants arrived in Hawaii on June 19, 1868. They were not approved by the then-current Japanese government because the contract was between a broker and the Tokugawa shogunate—by then replaced by the Meiji Restoration. The first Japanese current-government-approved immigrants arrived on February 9, 1885, after Kalākaua's petition to Emperor Meiji when Kalākaua visited Japan in 1881.

Almost 13,000 Portuguese migrants had arrived by 1899; they also worked on the sugarcane plantations. By 1901, over 5,000 Puerto Ricans were living in Hawaii.

English and Hawaiian are listed as Hawaii's official languages in the state's 1978 constitution, in Article XV, Section 4. However, the use of Hawai'ian is limited because the constitution specifies that "Hawaiian shall be required for public acts and transactions only as provided by law". Hawaii Creole English, locally referred to as "Pidgin", is the native language of many native residents and is a second language for many others.

As of the 2000 Census, 73.4% of Hawaii residents aged five and older exclusively speak English at home. According to the 2008 American Community Survey, 74.6% of Hawaii's residents over the age of five speak only English at home. In their homes, 21.0% of state residents speak an additional Asian language, 2.6% speak Spanish, 1.6% speak other Indo-European languages and 0.2% speak another language.

After English, other languages popularly spoken in the state are Tagalog, Japanese and Ilocano. Significant numbers of European immigrants and their descendants also speak their native languages; the most numerous are German, Portuguese, Italian and French. 5.4% of residents speak Tagalog—which includes non-native speakers of Filipino language, the national, co-official, Tagalog-based language; 5.0% speak Japanese and 4.0% speak Ilocano; 1.2% speak Chinese, 1.7% speak Hawaiian; 1.7% speak Spanish; 1.6% speak Korean; and 1.0% speak Samoan.

The keyboard layout used for Hawaiian is QWERTY.

The Hawaiian language has about 2,000 native speakers, about 0.15% of the total population. According to the United States Census, there were over 24,000 total speakers of the language in Hawaii in 2006–2008. Hawaiian is a Polynesian member of the Austronesian language family. It is closely related to other Polynesian languages, such as Marquesan, Tahitian, Māori, Rapa Nui (the language of Easter Island), and less closely to Samoan and Tongan.

According to Schütz, the Marquesans colonized the archipelago in roughly 300 CE and were later followed by waves of seafarers from the Society Islands, Samoa and Tonga.

These Polynesians remained in the islands; they eventually became the Hawaiian people and their languages evolved into the Hawaiian language. Kimura and Wilson say, "[l]inguists agree that Hawaiian is closely related to Eastern Polynesian, with a particularly strong link in the Southern Marquesas, and a secondary link in Tahiti, which may be explained by voyaging between the Hawaiian and Society Islands". Before the arrival of Captain James Cook, the Hawaiian language had no written form. That form was developed mainly by American Protestant missionaries between 1820 and 1826. They assigned to the Hawaiian phonemes letters from the Latin alphabet.

Interest in Hawaiian increased significantly in the late 20th century. With the help of the Office of Hawaiian Affairs, specially designated immersion schools in which all subjects would be taught in Hawaiian were established. The University of Hawaii developed a Hawaiian language graduate studies program. Municipal codes were altered to favor Hawaiian place and street names for new civic developments. Hawai'i Sign Language, a sign language for the deaf based on the Hawaiian language, has been in use in the islands since the early 1800s. It is dwindling in numbers due to American Sign Language supplanting HSL through schooling and various other domains.

Hawaiian distinguishes between long and short vowel sounds. In modern practice, vowel length is indicated with a macron ("kahakō"). Hawaiian-language newspapers ("nūpepa") published from 1834 to 1948 and traditional native speakers of Hawaiian generally omit the marks in their own writing. The okina and kahakō are intended to help non-native speakers. The Hawaiian language uses the glottal stop ("okina") as a consonant. It is written as a symbol similar to the apostrophe or left-hanging (opening) single quotation mark.

Some residents of Hawaii speak Hawaii Creole English (HCE), endonymically called "pidgin" or "pidgin English". The lexicon of HCE derives mainly from English but also uses words that have derived from Hawaiian, Chinese, Japanese, Portuguese, Ilocano and Tagalog. During the 19th century, the increase in immigration—mainly from China, Japan, Portugal—especially from the Azores and Madeira, and Spain—catalyzed the development of a hybrid variant of English known to its speakers as "pidgin". By the early 20th century, pidgin speakers had children who acquired it as their first language. HCE speakers use some Hawaiian words without those words being considered archaic. Most place names are retained from Hawaiian, as are some names for plants and animals. For example, tuna fish is often called by its Hawaiian name, "ahi".

HCE speakers have modified the meanings of some English words. For example, "aunty" and "uncle" may either refer to any adult who is a friend or be used to show respect to an elder. Syntax and grammar follow distinctive rules different from those of General American English. For example, instead of "it is hot today, isn't it?", an HCE speaker would say simply "stay hot, eh?" The term "da kine" is used as a filler; a substitute for virtually any word or phrase. During the surfing boom in Hawaii, HCE was influenced by surfer slang. Some HCE expressions, such as "brah" and "da kine", have found their ways elsewhere through surfing communities.

Christianity is the most widespread religion in Hawaii. It is mainly represented by various Protestants, Roman Catholics and Mormons. Buddhism is the second most popular religion, especially among the archipelago's Japanese community. Unaffilliated account for one-quarter of the population.

The largest denominations by number of adherents were the Roman Catholic Church with 249,619 adherents in 2010 and the Church of Jesus Christ of Latter-day Saints with 68,128 adherents in 2009. The third-largest religious group includes all non-denominational churches, with 128 congregations and 32,000 members. The third-largest denominational group is the United Church of Christ, with 115 congregations and 20,000 members. The Southern Baptist Convention has 108 congregations and 18,000 members in Hawaii.

According to data provided by religious establishments, religion in Hawaii in 2000 was distributed as follows:


A Pew poll found that the religious composition was as follows:

"Note: Births in table don't add up, because Hispanics are counted both by their ethnicity and by their race, giving a higher overall number."


Hawaii has had a long history of queer identities. "Māhū" people, who often traversed gender as defined by Western standards, were a respected group of pre-colonization people who were widely known in society as healers. Another Hawaiian word, "aikāne", referred to same-sex relationships. According to journals written by Captain Cook's crew, it is widely believed that many "alii" engaged in "aikāne" relationships. Hawaiian scholar Lilikalā Kameeleihiwa said, "If you didn't sleep with a man, how could you trust him when you went into battle? How would you know if he was going to be the warrior that would protect you at all costs, if he wasn't your lover?"

A 2012 poll by Gallup found that Hawaii had the largest proportion of lesbian, gay, bisexual and transgender (LGBT) adults in the U.S., at 5.1%, comprising an estimated adult LGBT population of 53,966 individuals. The number of same-sex couple households in 2010 was 3,239; a 35.5% increase of figures from a decade earlier. In 2013, Hawaii became the fifteenth U.S. state to legalize same-sex marriage; a University of Hawaii researcher said the law may boost tourism by $217 million.

The history of Hawaii's economy can be traced through a succession of dominant industries; sandalwood, whaling, sugarcane, pineapple, the military, tourism and education. Since statehood in 1959, tourism has been the largest industry, contributing 24.3% of the gross state product (GSP) in 1997, despite efforts to diversify. The state's gross output for 2003 was billion; per capita income for Hawaii residents in 2014 was . Hawaiian exports include food and clothing. These industries play a small role in the Hawaiian economy, due to the shipping distance to viable markets, such as the West Coast of the contiguous U.S. The state's food exports include coffee, macadamia nuts, pineapple, livestock, sugarcane and honey.

By weight, honey bees may be the state's most valuable export. According to the Hawaii Agricultural Statistics Service, agricultural sales were million from diversified agriculture, million from pineapple, and million from sugarcane. Hawaii's relatively consistent climate has attracted the seed industry, which is able to test three generations of crops per year on the islands, compared with one or two on the mainland. Seeds yielded million in 2012, supporting 1,400 workers.

As of December 2015, the state's unemployment rate was 3.2%. In 2009, the United States military spent billion in Hawaii, accounting for 18% of spending in the state for that year. 75,000 United States Department of Defense personnel live in Hawaii. According to a 2013 study by Phoenix Marketing International, Hawaii had the fourth-largest number of millionaires per capita in the United States, with a ratio of 7.2%.

Hawaii residents pay the most per person in state taxes in the United States. Millions of tourists pay general excise tax and hotel room tax.

The Hawaii Tax Foundation considers the state's tax burden too high, which it says contributes to higher prices and the perception of an unfriendly business climate.

State Senator Sam Slom says state taxes are comparatively higher than other states because the state government handles education, health care, and social services that are usually handled at a county or municipal level in most other states.

The cost of living in Hawaii, specifically Honolulu, is high compared to that of most major U.S. cities, although it is 6.7% lower than in New York City and 3.6% lower than in San Francisco. These numbers may not take into account some costs, such as increased travel costs for flights, additional shipping fees, and the loss of promotional participation opportunities for customers outside the contiguous U.S. While some online stores offer free shipping on orders to Hawaii, many merchants exclude Hawaii, Alaska, Puerto Rico and certain other U.S. territories.

Hawaiian Electric Industries, a privately owned company, provides 95% of the state's population with electricity, mostly from fossil-fuel power stations. Average electricity prices in October 2014 () were nearly three times the national average () and 80% higher than the second-highest state, Connecticut.

The median home value in Hawaii in the 2000 U.S. Census was , while the national median home value was . Hawaii home values were the highest of all states, including California with a median home value of . Research from the National Association of Realtors places the 2010 median sale price of a single family home in Honolulu, Hawaii, at and the U.S. median sales price at . The sale price of single family homes in Hawaii was the highest of any U.S. city in 2010, just above that of the Silicon Valley area of California ().

Hawaii's very high cost of living is the result of several interwoven factors of the global economy in addition to domestic U.S. government trade policy. Like other regions with desirable weather throughout the year, such as areas of California, Arizona and Florida, Hawaii's residents can be considered to be subject to a "Sunshine tax". This situation is further exacerbated by the natural factors of geography and world distribution that lead to higher prices for goods due to increased shipping costs, a problem which many island states and territories suffer from as well. Also, contributing to the relativity higher cost of living includes shipping goods across an ocean, which may further be compounded by the requirements of the Jones Act. The Jones Act generally prohibits a foreign built, owned, crewed, or flagged vessels from transporting goods between places within the U.S., including the U.S. west coast and Hawaii. Jones Act compliant vessels are generally more expensiveness to build and operate than are many foreign equivalents which can drive up shipping costs. While the Jones Act does not prohibit transportation of goods to Hawaii directly from Asia, this type of trade is nonetheless not common; this is a result of other primarily economic reasons including additional costs associated with stopping over in Hawaii (e.g. pilot and port fees), market size of Hawaii, and economics of using ever larger ships, that cannot be handled in Hawaii, for transoceanic voyages. Therefore, Hawaii relies on receiving most inbound goods on Jones Act qualified vessels originating from the U.S. west coast which may contribute to the increased cost of some consumer goods and therefore the overall cost of living.

Hawaiian consumers ultimately bear the expense of transporting goods imposed by the Jones Act. This law makes Hawaii less competitive than West Coast ports as a shopping destination for tourists from countries with much higher taxes like Japan, even though prices for Asian-manufactured goods should be cheaper because Hawaii is much closer than mainland states to Asia.

The aboriginal culture of Hawaii is Polynesian. Hawaii represents the northernmost extension of the vast Polynesian Triangle of the south and central Pacific Ocean. While traditional Hawaiian culture remains as vestiges in modern Hawaiian society, there are re-enactments of the ceremonies and traditions throughout the islands. Some of these cultural influences, including the popularity (in greatly modified form) of "lūau" and "hula", are strong enough to affect the wider United States.

The cuisine of Hawaii is a fusion of many foods brought by immigrants to the Hawaiian Islands, including the earliest Polynesians and Native Hawaiian cuisine, and American, Chinese, Filipino, Japanese, Korean, Polynesian and Portuguese origins. Plant and animal food sources are imported from around the world for agricultural use in Hawaii. "Poi", a starch made by pounding taro, is one of the traditional foods of the islands. Many local restaurants serve the ubiquitous plate lunch, which features two scoops of rice, a simplified version of American macaroni salad and a variety of toppings including hamburger patties, a fried egg, and gravy of a "loco moco", Japanese style "tonkatsu" or the traditional lūau favorites, including "kālua" pork and "laulau". "Spam musubi" is an example of the fusion of ethnic cuisine that developed on the islands among the mix of immigrant groups and military personnel. In the 1990s, a group of chefs developed Hawaii regional cuisine as a contemporary fusion cuisine.

Some key customs and etiquette in Hawaii are as follows: when visiting a home, it is considered good manners to bring a small gift for one's host (for example, a dessert). Thus, parties are usually in the form of potlucks. Most locals take their shoes off before entering a home. It is customary for Hawaiian families, regardless of ethnicity, to hold a luau to celebrate a child's first birthday. It is also customary at Hawaiian weddings, especially at Filipino weddings, for the bride and groom to do a money dance (also called the pandanggo). Print media and local residents recommend that one refer to non-Hawaiians as "locals of Hawaii" or "people of Hawaii".

Hawaiian mythology comprises the legends, historical tales, and sayings of the ancient Hawaiian people. It is considered a variant of a more general Polynesian mythology that developed a unique character for several centuries before "circa" 1800. It is associated with the Hawaiian religion, which was officially suppressed in the 19th century but was kept alive by some practitioners to the modern day. Prominent figures and terms include Aumakua, the spirit of an ancestor or family god and Kāne, the highest of the four major Hawaiian deities.

Polynesian mythology is the oral traditions of the people of Polynesia, a grouping of Central and South Pacific Ocean island archipelagos in the Polynesian triangle together with the scattered cultures known as the Polynesian outliers. Polynesians speak languages that descend from a language reconstructed as Proto-Polynesian that was probably spoken in the area around Tonga and Samoa in around 1000 BCE.

Prior to the 15th century, Polynesian people migrated east to the Cook Islands, and from there to other island groups such as Tahiti and the Marquesas. Their descendants later discovered the islands Tahiti, Rapa Nui and later the Hawaiian Islands and New Zealand.

The Polynesian languages are part of the Austronesian language family. Many are close enough in terms of vocabulary and grammar to be mutually intelligible. There are also substantial cultural similarities between the various groups, especially in terms of social organization, childrearing, horticulture, building and textile technologies. Their mythologies in particular demonstrate local reworkings of commonly shared tales. The Polynesian cultures each have distinct but related oral traditions; legends or myths are traditionally considered to recount ancient history (the time of "pō") and the adventures of gods ("atua") and deified ancestors.

There are many Hawaiian state parks.

The literature of Hawaii is diverse and includes authors Kiana Davenport, Lois-Ann Yamanaka, and Kaui Hart Hemmings. Hawaiian magazines include "Hana Hou!", "Hawaii Business Magazine" and "Honolulu", among others.

The music of Hawaii includes traditional and popular styles, ranging from native Hawaiian folk music to modern rock and hip hop. Hawaii's musical contributions to the music of the United States are out of proportion to the state's small size.

Styles such as slack-key guitar are well-known worldwide, while Hawaiian-tinged music is a frequent part of Hollywood soundtracks. Hawaii also made a major contribution to country music with the introduction of the steel guitar.

Traditional Hawaiian folk music is a major part of the state's musical heritage. The Hawaiian people have inhabited the islands for centuries and have retained much of their traditional musical knowledge. Their music is largely religious in nature, and includes chanting and dance music.

Hawaiian music has had an enormous impact on the music of other Polynesian islands; according to Peter Manuel, the influence of Hawaiian music a "unifying factor in the development of modern Pacific musics". Native Hawaiian musician and Hawaiian sovereignty activist Israel Kamakawiwoʻole, famous for his medley of "Somewhere Over the Rainbow/What a Wonderful World", was named "The Voice of Hawaii" by NPR in 2010 in its 50 great voices series.

Surfing has been a central part of Polynesian culture for centuries. Since the late 19th century, Hawaii has become a major site for surfists from around the world. Notable competitions include the Triple Crown of Surfing and The Eddie.

The only NCAA Division I team in Hawaii is the Hawaii Rainbow Warriors and Rainbow Wahine, which competes at the Big West Conference (major sports), Mountain West Conference (football) and Mountain Pacific Sports Federation (minor sports). There are three teams in NCAA Division II: Chaminade Silverswords, Hawaii Pacific Sharks and Hawaii-Hilo Vulcans, all of which compete at the Pacific West Conference.

Notable college sports events in Hawaii include the Maui Invitational Tournament, Diamond Head Classic (basketball) and Hawaii Bowl (football).

Notable professional teams include The Hawaiians, which played at the World Football League in 1974 and 1975; the Hawaii Islanders, a Triple-A minor league baseball team that played at the Pacific Coast League from 1961 to 1987; and Team Hawaii, a North American Soccer League team that played in 1977.

Hawaii has hosted the Sony Open in Hawaii golf tournament since 1965, the Tournament of Champions golf tournament since 1999, the Lotte Championship golf tournament since 2012, the Honolulu Marathon since 1973, the Ironman World Championship triathlon race since 1978, the Ultraman triathlon since 1983, the National Football League's Pro Bowl from 1980 to 2016, the 2000 FINA World Open Water Swimming Championships, and the 2008 Pan-Pacific Championship and 2012 Hawaiian Islands Invitational soccer tournaments.

Tourism is an important part of the Hawaiian economy. In 2003, according to state government data, there were over 6.4 million visitors, with expenditures of over $10 billion, to the Hawaiian Islands. Due to the mild year-round weather, tourist travel is popular throughout the year. The major holidays are the most popular times for outsiders to visit, especially in the winter months. Substantial numbers of Japanese tourists still visit the islands but have now been surpassed by Chinese and Koreans due to the collapse of the value of the Yen and the weak Japanese economy. The average Japanese stays only 5 days while other Asians spend over 9.5 days and spend 25% more.

Hawaii hosts numerous cultural events. The annual Merrie Monarch Festival is an international Hula competition. The Hawaii International Film Festival is the premier film festival for Pacific rim cinema. Honolulu hosts the state's long-running LGBT film festival, the Rainbow Film Festival.

, Hawaii's health care system insures 92% of residents. Under the state's plan, businesses are required to provide insurance to employees who work more than twenty hours per week. Heavy regulation of insurance companies helps reduce the cost to employers. Due in part to heavy emphasis on preventive care, Hawaiians require hospital treatment less frequently than the rest of the United States, while total health care expenses measured as a percentage of state GDP are substantially lower. Proponents of universal health care elsewhere in the U.S. sometimes use Hawaii as a model for proposed federal and state health care plans.

Hawaii has the only school system within the U.S. that is unified statewide. Policy decisions are made by the fourteen-member state Board of Education, which sets policy and hires the superintendent of schools, who oversees the state Department of Education. The Department of Education is divided into seven districts; four on Oahu and one for each of the other three counties. The main rationale for centralization is to combat inequalities between highly populated Oahu and the more rural Neighbor Islands, and between lower-income and more affluent areas.

Public elementary, middle and high school test scores in Hawaii are below national averages on tests mandated under the No Child Left Behind Act. The Hawaii Board of Education requires all eligible students to take these tests and report all student test scores. This may have unbalanced the results that reported in August 2005 that of 282 schools across the state, 185 failed to reach federal minimum performance standards in mathematics and reading. The ACT college placement tests show that in 2005, seniors scored slightly above the national average (21.9 compared with 20.9), but in the widely accepted SAT examinations, Hawaii's college-bound seniors tend to score below the national average in all categories except mathematics.

Hawaii has the highest rates of private school attendance in the nation. During the 2011–2012 school year, Hawaii public and charter schools had an enrollment of 181,213, while private schools had 37,695. Private schools educated over 17% of students in Hawaii that school year, nearly three times the approximate national average of 6%. It has four of the largest independent schools; Iolani School, Kamehameha Schools, Mid-Pacific Institute and Punahou School. Pacific Buddhist Academy, the second Buddhist high school in the U.S. and first such school in Hawaii, was founded in 2003. The first native controlled public charter school was the Kanu O Ka Aina New Century Charter School.

Independent and charter schools can select their students, while the public schools are open to all students in their district. The Kamehameha Schools are the only schools in the U.S. that openly grant admission to students based on ancestry; collectively, they are one of the wealthiest schools in the United States, if not the world, having over eleven billion US dollars in estate assets. In 2005, Kamehameha enrolled 5,398 students, 8.4% of the Native Hawaiian children in the state.

Graduates of secondary schools in Hawaii often enter directly into the workforce. Some attend colleges and universities on the mainland or other countries, and the rest attend an institution of higher learning in Hawaii. The largest is the University of Hawaii System, which consists of: the research university at Mānoa, two comprehensive campuses at Hilo and West Oahu, and seven community colleges. Private universities include Brigham Young University–Hawaii, Chaminade University of Honolulu, Hawaii Pacific University, and Wayland Baptist University. Saint Stephen Diocesan Center is a seminary of the Roman Catholic Diocese of Honolulu. Kona hosts the University of the Nations, which is not an accredited university.

First opened in 1984 illegally in Kekaha, Kaua'i, the Pūnana Leo or "Language Nest" (lit. "Nest of Voices") were the first indigenous language immersion schools in the United States. Modelled after the Māori language Kōhanga reo of New Zealand, they provide preschool aged children the opportunity to engage in early education through a Hawaiian language medium, generally taught by elders. Graduates from the Pūnana Leo schools have achieved several measures of academic success in later life. As of 2006, there were a total of eleven Pūnana Leo preschools, with locations on five of the islands.

A system of state highways encircles each main island. Only Oahu has federal highways, and is the only area outside the contiguous 48 states to have signed Interstate highways. Narrow, winding roads and congestion in populated places can slow traffic. Each major island has a public bus system.

Honolulu International Airport (IATA:HNL), which shares runways with the adjacent Hickam Field (IATA:HIK), is the major commercial aviation hub of Hawaii. The commercial aviation airport offers intercontinental service to North America, Asia, Australia and Oceania. Hawaiian Airlines, Mokulele Airlines and go! use jets to provide services between the large airports in Honolulu, Līhue, Kahului, Kona and Hilo. Island Air and Pacific Wings serve smaller airports. These airlines also provide air freight services between the islands. On May 30, 2017, the airport was officially renamed as the Daniel K. Inouye International Airport (HNL), after U.S. Senator Daniel K. Inouye.

Until air passenger services began in the 1920s, private boats were the sole means of traveling between the islands. Seaflite operated hydrofoils between the major islands in the mid-1970s.

The Hawaii Superferry operated between Oahu and Maui between December 2007 and March 2009, with additional routes planned for other islands. Protests and legal problems over environmental impact statements ended the service, though the company operating Superferry has expressed a wish to recommence ferry services in the future. Currently there is a passenger ferry service in Maui County between Lanai and Maui, which does not take vehicles; a passenger ferry to Molokai ended in 2016. Currently Norwegian Cruise Lines and Princess Cruises provide passenger cruise ship services between the larger islands.

At one time Hawaii had a network of railroads on each of the larger islands that transported farm commodities and passengers. Most were narrow gauge systems but there were some gauge on some of the smaller islands. The standard gauge in the U.S. is . By far the largest railroad was the Oahu Railway and Land Company (OR&L) that ran lines from Honolulu across the western and northern part of Oahu.

The OR&L was important for moving troops and goods during World War II. Traffic on this line was busy enough for signals to be used to facilitate movement of trains and to require wigwag signals at some railroad crossings for the protection of motorists. The main line was officially abandoned in 1947, although part of it was bought by the U.S. Navy and operated until 1970. of track remain; preservationists occasionally run trains over a portion of this line. The Honolulu High-Capacity Transit Corridor Project aims to add elevated passenger rail on Oahu to relieve highway congestion.

The movement of the Hawaiian royal family from Hawaii Island to Maui, and subsequently to Oahu, explains the modern-day distribution of population centers. Kamehameha III chose the largest city, Honolulu, as his capital because of its natural harbor—the present-day Honolulu Harbor. Now the state capital, Honolulu is located along the southeast coast of Oahu. The previous capital was Lahaina, Maui, and before that Kailua-Kona, Hawaii. Some major towns are Hilo; Kāneohe; Kailua; Pearl City; Waipahu; Kahului; Kailua-Kona. Kīhei; and Līhue.

Hawaii comprises five counties: the City and County of Honolulu, Hawaii County, Maui County, Kauai County, and Kalawao County.

Hawaii has the fewest local governments among U.S. states. Unique to this state is the lack of municipal governments. All local governments are generally administered at the county level. The only incorporated area in the state is Honolulu County, a consolidated city–county that governs the entire island of Oahu. County executives are referred to as mayors; these are the Mayor of Hawaii County, Mayor of Honolulu, Mayor of Kauai, and the Mayor of Maui. The mayors are all elected in nonpartisan elections. Kalawao County has no elected government, and as mentioned above there are no local school districts and instead all local public education is administered at the state level by the Hawaii Department of Education. The remaining local governments are special districts.

The state government of Hawaii is modeled after the federal government with adaptations originating from the kingdom era of Hawaiian history. As codified in the Constitution of Hawaii, there are three branches of government: executive, legislative and judicial. The executive branch is led by the Governor of Hawaii, who is assisted by the Lieutenant Governor of Hawaii, both of whom are elected on the same ticket. The governor is the only state public official elected statewide; all others are appointed by the governor. The lieutenant governor acts as the Secretary of State. The governor and lieutenant governor oversee twenty agencies and departments from offices in the State Capitol. The official residence of the governor is Washington Place. 

The legislative branch consists of the bicameral Hawaii State Legislature, which is composed of the 51-member Hawaii House of Representatives led by the Speaker of the House, and the 25-member Hawaii Senate led by the President of the Senate. The Legislature meets at the State Capitol. The unified judicial branch of Hawaii is the Hawaii State Judiciary. The state's highest court is the Supreme Court of Hawaii, which uses Aliiōlani Hale as its chambers.

Hawaii is represented in the United States Congress by two senators and two representatives. , all four seats are held by Democrats. Colleen Hanabusa won a special election for the 1st congressional district representing southeastern Oahu, including central Honolulu, on November 8, 2016 to finish the term of Rep. Mark Takai who died July 20, 2016. Tulsi Gabbard represents the 2nd congressional district, representing the rest of the state, which is largely rural and semi-rural.

Brian Schatz is the senior United States Senator from Hawaii. He was appointed to the office on December 26, 2012, by Governor Neil Abercrombie, following the death of former senator Daniel Inouye. The state's junior senator is Mazie Hirono, the former representative from the second congressional district. Hirono is the first female Asian American senator and the first Buddhist senator. Hawaii incurred the biggest seniority shift between the 112th and 113th Congresses. The state went from a delegation consisting of senators who were first and twenty-first in seniority to their respective replacements, relative newcomers Schatz and Hirono.

Federal officials in Hawaii are based at the Prince Kūhiō Federal Building near the Aloha Tower and Honolulu Harbor. The Federal Bureau of Investigation, Internal Revenue Service and the Secret Service maintain their offices there; the building is also the site of the federal District Court for the District of Hawaii and the United States Attorney for the District of Hawaii.

Since gaining statehood and participating in its first election in1960, Hawaii has supported Democrats in all but two presidential elections; 1972 and1984, both of which were landslide reelection victories for Republicans Richard Nixon and Ronald Reagan respectively. In Hawaii's statehood tenure, only Minnesota has supported Republican candidates fewer times in presidential elections.

Hawaii hasn't elected a Republican to represent the state in the U.S. Senate since Hiram Fong in 1970; since 1977, both of the state's U.S. Senators have been Democrats.

In 2004, John Kerry won the state's four electoral votes by a margin of nine percentage points with 54% of the vote. Every county supported the Democratic candidate. In 1964, favorite son candidate senator Hiram Fong of Hawaii sought the Republican presidential nomination, while Patsy Mink ran in the Oregon primary in 1972.

Honolulu-born Barack Obama, then serving as United States Senator from Illinois, was elected the 44th President of the United States on November 4, 2008 and was re-elected for a second term on November 6, 2012. Obama had won the Hawaii Democratic caucus on February 19, 2008, with 76% of the vote. He was the third Hawaii-born candidate to seek the nomination of a major party and the first presidential nominee from Hawaii.

While Hawaii is internationally recognized as a state of the United States while also being broadly accepted as such in mainstream understanding, the legality of this status has been questioned in U.S. District Court, the U.N., and other international forums. Domestically, the debate is a topic covered in the Kamehameha Schools curriculum, and in classes at the University of Hawaiʻi at Mānoa.

Political organizations seeking some form of sovereignty for Hawaii have been active since the late 19th century. Generally, their focus is on self-determination and self-governance, either for Hawaii as an independent nation (in many proposals, for "Hawaiian nationals" descended from subjects of the Hawaiian Kingdom or declaring themselves as such by choice), or for people of whole or part native Hawaiian ancestry in an indigenous ""nation to nation"" relationship akin to tribal sovereignty with US federal recognition of Native Hawaiians. In the 2000s, it was found that the large majority of Hawaiian residents opposed the Akaka Bill. Opponents to the tribal approach argue it is not a legitimate path to Hawaiian nationhood; they also argue that the U.S. government should not be involved in re-establishing Hawaiian sovereignty.

The Hawaiian sovereignty movement views the overthrow of the Kingdom of Hawaii in 1893 as illegal, and views the subsequent annexation of Hawaii by the United States as illegal; the movement seeks some form of greater autonomy for Hawaii, such as free association or independence from the United States.

Some groups also advocate some form of redress from the United States for the 1893 overthrow of Queen Liliuokalani, and for what is described as a prolonged military occupation beginning with the 1898 annexation. The Apology Resolution passed by US Congress in 1993 is cited as a major impetus by the movement for Hawaiian sovereignty. The sovereignty movement considers Hawaii to be an illegally occupied nation.





</doc>
<doc id="13274" url="https://en.wikipedia.org/wiki?curid=13274" title="Hearse">
Hearse

A hearse is a vehicle used to carry the dead in a coffin/casket. They range from deliberately anonymous vehicles to very formal heavily decorated vehicles. 

In the funeral trade of some countries hearses are called funeral coaches.

The name is derived, through the French herse, from the Latin herpex, which means a harrow. The funeral hearse was originally a wooden or metal framework, which stood over the bier or coffin and supported the pall. It was provided with numerous spikes to hold burning candles, and, owing to the resemblance of these spikes to the teeth of a harrow, was called a hearse. Later on, the word was applied, not only to the construction above the coffin, but to any receptacle in which the coffin was placed. Thus from about 1650 it came to denote the vehicle on which the dead are carried to the grave.

Hearses were originally hand-drawn then horse-drawn after the decoration and weight of the hearse increased. The first electric motorized hearses were introduced to the United States in the early 1900s. Petrol-powered hearses began to be produced from 1907 and, after slow initial uptake due to their high cost, became widely accepted in the 1920s. The vast majority of hearses since then have been based on larger, more powerful car chassis, generally retaining the front end up to and possibly including the front doors but with custom bodywork to the rear to contain the coffin.

A First Call vehicle is used to pick up the remains of a recently deceased person, and transport that person to the funeral home for preparation.
A few big cities provided special rail lines and/or funeral trolley cars and/or subway cars to carry bodies and mourners to remote cemeteries such as in Sydney, NSW and London and tram services were common. Chicago, Illinois operated 3 different funeral trolley cars over the elevated tracks in downtown Chicago to outlying cemeteries in the western suburbs. A special funeral bureau handled the funeral trains which sometimes operated 3–4 funeral trains a week over the "L".
The motorcycle hearse has become popular and is often used during the funeral of motorcycle enthusiasts.
This type of hearse is either a motorcycle with a special sidecar built to carry a casket or an urn at the side of the rider, or it is a trike that carries the casket behind the rider.
Two styles of formal hearse bodywork are common. One style has opaque rear panels so the coffin is barely glimpsed. This American style is fitted with a heavily-padded leather or vinyl roof and each side decorated with large mock landau bars resembling the braces used for the folding leather tops on some horse-drawn carriages. The other has narrow pillars and large windows revealing the coffin.
Since the working life of a hearse is generally one of light duty and short, sedate drives, hearses often remain serviceable for a long time and hearses 30 years old or more may still be in service. Due to the costs of owning an expensive custom vehicle that sits idle "80 to 90 percent of the week", individual funeral homes reduce costs by renting or utilizing a shared motor pool.

Perhaps owing to the morbid associations of the hearse, its luxurious accommodations for the driver, or both, the hearse has a number of enthusiasts who own and drive retired hearses. There are several hearse clubs.

Usually more luxurious automobile brands are used as a base for funeral cars; the vast majority of hearses in the United States and Canada are Cadillacs, and Lincolns.

The Cadillac Commercial Chassis was a longer and strengthened version of the long-wheelbase Fleetwood limousine frame to carry the extra weight of bodywork, rear deck and cargo. The rear of the Cadillac commercial chassis was considerably lower than the passenger car frame, thereby lowering the rear deck height as well for ease of loading and unloading. The Cadillac hearses were shipped as incomplete cars to coachbuilders for final assembly.

The fleet division of Ford Motor Company sells a Lincoln Town Car with a special "hearse package" strictly to coachbuilders. Shipped without rear seat, rear interior trim, rear window or decklid, the hearse package also features upgraded suspension, brakes, charging system and tires.

The limousine style of hearse is more popular in the United States. It is common practice in the USA for the windows to be curtained, while in other countries the windows are normally left unobscured.

Until the 1970s, it was common for hearses to also be used as ambulances, due to the large cargo capacity in the rear of the vehicle. These vehicles were called "combination cars" and were especially used in rural areas. Car-based ambulances and combination coaches were unable to meet stricter Federal specifications for such vehicles and were discontinued after 1979.

Coachbuilders modify Mercedes-Benz, Jaguar, Opel, Ford, Vauxhall Motors and Volvo products to hearses. Some second-hand Rolls-Royce cars have traditionally been used as hearses though the high cost of newer models is generally considered prohibitive.

In Japan, hearses, called , can come in two styles: "Foreign" style, which is similar in build and style to an American hearse, or a "Japanese" style, in which the rear area of the vehicle is modified to resemble a small, ornate Buddhist temple.

The Japanese-style hearse generally requires the rear of the vehicle to be extensively altered; commonly, the rear roof is cut away from the front windows back and all interior parts are removed from the rear as well. The ornate Buddhist-style rear area, generally constructed of wood and in which the casket or urn is placed, is built on top of this empty cavity and most often is wider than the base of the vehicle, so that it sticks out on the sides, over the rear body panels. Popular bases for these hearses are large sedans, minivans and pickup trucks.

The ornaments on a Japanese-style hearse vary by region. Nagoya style decorates both the upper and lower halves of the car body.
Kansai style has a relatively modest decorations unpainted.
Kanazawa style is known for having a red body (other styles mostly have black bodies) with gilded ornaments.
Tokyo style, found anywhere else in Japan, features painted/gilded ornaments on the upper half of the body.

"Foreign" style hearses are mostly similar in appearance to their US counterparts, although their exterior dimensions and interiors reflect the Japanese preference for smaller, less ornate caskets (this in light of the national preference for cremation). This means that, in contrast to American hearses, the rear quarter panels require less, and sometimes no, alteration. These are generally built from station wagons such as the Nissan Stagea, or from executive sedans such as the Toyota Celsior (Lexus LS in the US) and Nissan Cima (Infiniti Q45 in the US). American market vehicles such as the Lincoln Town Car and Cadillac DeVille, which are otherwise fairly uncommon in Japan, are often converted to hearses in both styles.

In Hong Kong, light goods vehicles of Isuzu, Volkswagen and Ford are used as hearses by most of the privately operated funeral homes.

In Singapore, the grand/traditional Chinese/Indian hearse is built with a lorry chassis.

Amongst enthusiasts, the 1959 Cadillac Miller-Meteor hearse is considered one of the most desirable, due to its especially ornate styling and appearances in feature films, notably an ambulance version (Ecto-1) in the motion picture "Ghostbusters".

In the 1971 film "Harold and Maude" the character Harold, played by Bud Cort, drives two hearses: originally a 1959 Cadillac Superior 3-way; and then later a custom hearse he makes from a 1971 Jaguar XK-E 4.2 Series II. The Cadillac hearse is now privately owned in central California and is preserved, looking essentially identical to the way it did in the film. Only one Jaguar "hearse" was built and was destroyed as part of the film's storyline. Several "Harold and Maude" fans have since built similar hearses from E-Types and photos of them can be found online. Jane Goldman, wife of British TV and radio personality Jonathan Ross, owns a similar style "hearse" built from a Jaguar XK8 convertible.

The Rogues prowl around in a graffitied 1955 Cadillac Hearse in the film "The Warriors".

Musician Neil Young's first car was a hearse, which was used to transport the band's equipment.

Celebrity hearse enthusiasts include rock singer Neil Young and three-time NASCAR Sprint Cup Champion Tony Stewart, who had his hearse customised for a television show. Sam the Sham of the Pharaohs (known for Wooly Bully and Lil' Red Riding Hood) was known for transporting all his equipment in a 1952 Packard hearse.

In the HBO television show "Six Feet Under", which dealt with death every week, premieres with the Fisher family patriarch Nathaniel, a funeral director, killed in an accident involving his new hearse. His daughter Claire also owned and drove a hearse. 

In the Canadian television program "", character Eli Goldsworthy, a 'death obsessed' 16-year-old, drives a 1960s era vintage hearse, affectionately nicknamed Morty. Cleve Hall, of the Syfy television show Monster Man, drives a 1980 Superior, with added coach lights on each side, in the 1st season of the show. He now drives a 1963 Miller Meteor named "Lucy".

Hearse was not used until about 1650 as the name for a carriage or car for the coffin.


</doc>
<doc id="13275" url="https://en.wikipedia.org/wiki?curid=13275" title="Hungary">
Hungary

Hungary ( ) is a country in Central Europe that covers an area of in the Carpathian Basin, bordered by Slovakia to the north, Ukraine to the northeast, Austria to the northwest, Romania to the east, Serbia to the south, Croatia to the southwest, and Slovenia to the west. With about 10 million inhabitants, Hungary is a medium-sized member state of the European Union. The official language is Hungarian, which is the most widely spoken Uralic language in the world. Hungary's capital and its largest city and metropolis is Budapest, a significant economic hub, classified as a leading global city. Major urban areas include Debrecen, Szeged, Miskolc, Pécs and Győr.

Following centuries of successive habitation by Celts, Romans, Germanic people, West Slavs, Avars, and the Huns the foundation of Hungary was laid in the late 9th century by the Hungarian grand prince Árpád in the conquest of the Carpathian Basin. His great-grandson Stephen I ascended the throne in 1000, converting the country to a Christian kingdom. By the 12th century, Hungary became a middle power within the Western world, reaching a golden age by the 15th century. Following the Battle of Mohács in 1526 and about 150 years of partial Ottoman occupation (1541–1699), Hungary came under Habsburg rule, and later formed the great power Austro–Hungarian Empire together with Austria.

Hungary's current borders were established in 1920 by the Treaty of Trianon after World War I, when the country lost 71% of its territory, 58% of its population, and 32% of ethnic Hungarians. Following the interwar period, Hungary joined the Axis Powers in World War II, suffering significant damage and casualties. Hungary became a satellite state of the Soviet Union, which contributed to the establishment of a socialist republic spanning four decades (1949–1989). The country gained widespread international attention as a result of its Revolution of 1956 and the seminal opening of its previously-restricted border with Austria in 1989, which accelerated the collapse of the Eastern Bloc. On 23 October 1989, Hungary became a democratic parliamentary republic.

In the 21st century, Hungary is a middle power and has the world's 57th largest economy by nominal GDP, as well as the 58th largest by PPP, out of 191 countries measured by IMF. As a substantial actor in several industrial and technological sectors, it is the world's 35th largest exporter and 34th largest importer of goods. Hungary is an OECD high-income economy with a very high standard of living. It keeps up a social security and universal health care system, and a tuition-free university education. Hungary performs well in international rankings: it is 20th in quality of life, 24th in Good Country Index, 28th in inequality-adjusted human development, 32nd in the Social Progress Index, 33rd in Global Innovation Index and ranks as the 15th safest country in the world.

Hungary joined the European Union in 2004 and has been part of the Schengen Area since 2007. Hungary is a member of the United Nations, NATO, WTO, World Bank, the AIIB, the Council of Europe, the Visegrád Group and more. Well known for its rich cultural history, Hungary has contributed significantly to arts, music, literature, sports and science and technology. Hungary is the 11th most popular country as a tourist destination in Europe, attracting 14.3 million international tourists in 2015. It is home to the largest thermal water cave system and the second largest thermal lake in the world, the largest lake in Central Europe and the largest natural grasslands in Europe.
The "H" in the name of Hungary (and Latin "Hungaria") is most likely due to early founded historical associations with the Huns, who had settled Hungary prior to the Avars. The rest of the word comes from the Latinized form of Medieval Greek "Oungroi" (Οὔγγροι). According to an explanation the Greek name was borrowed from Proto-Slavic "Ǫgǔri" (Ѫгъри), in turn borrowed from Oghur-Turkic "Onogur" ('ten [tribes of the] Ogurs'). "Onogur" was the collective name for the tribes who later joined the Bulgar tribal confederacy that ruled the eastern parts of Hungary after the Avars.

The Hungarian endonym is "Magyarország", composed of "magyar" ('Hungarian') and "ország" ('country'). The word "magyar" is taken from the name of one of the seven major semi-nomadic Hungarian tribes, "magyeri". The first element "magy" is likely from Proto-Ugric *"mäńć-" 'man, person', also found in the name of the Mansi people ("mäńćī, mańśi, måńś"). The second element "eri", 'man, men, lineage', survives in Hungarian "férj" 'husband', and is cognate with Mari "erge" 'son', Finnish archaic "yrkä" 'young man'.

The Roman Empire conquered the territory west of the Danube between 35 and 9 BC. From 9 BC to the end of the 4th century, Pannonia was part of the Roman Empire, located within part of later Hungary's territory. Around AD 41-54, a 500-strong cavalry unit created the settlement of Aquincum and a Roman legion of 6,000 men was stationed here by AD 89. A civil city grew gradually in the neighbourhood of the military settlement and in AD 106 Aquincum became the focal point of the commercial life of this area and the capital city of the Pannonian Inferior region. This area now corresponds to the Óbuda district of Budapest, with the Roman ruins now forming part of the modern Aquincum museum. Later came the Huns, a Central Asian tribe who built a powerful empire. After Hunnish rule, the Germanic Ostrogoths, Lombards, and Gepids, and the polyethnic Avar Khaganate, had a presence in the Carpathian Basin.

In the 9th century, Turkish origin rulers of East Francia, the First Bulgarian Empire and Great Moravia ruled the territory of the Carpathian Basin. The area was previously under Avar Khaganate rule until 796. Both contemporary sources and growing archaeological evidence suggests that groups of the Avars survived the disintegration of their empire. According to Hungarian primary sources Gesta Hungarorum, by Anonymous, and Gesta Hunnorum et Hungarorum, by Simon de Keza, upon their arrival in the Eastern Carpathian Basin and in Pannonia around 895, the Hungarians are said to have encountered a mixed population of Slavs, Romanians/Vlachs, as well as certain Turkic tribes such as the Bulgars and their ancestor Avars. The Russian Primary Chronicle, by Nestor, also suggests a Romanian and Slavic presence. The Magyars advancing through the Carpathian Basin also are said to have encountered the Hungarian-speaking / ethnically related Székely people who inhabited the land at that time.

The freshly unified Hungarians led by Árpád settled in the Carpathian Basin starting in 895. According to linguistic evidence, they originated from an ancient Uralic-speaking population that formerly inhabited the forested area between the Volga River and the Ural Mountains.

As a federation of united tribes, Hungary was established in 895, some 50 years after the division of the Carolingian Empire at the Treaty of Verdun in 843, before the unification of the Anglo-Saxon kingdoms. Initially, the rising Principality of Hungary ("Western Tourkia" in medieval Greek sources) was a state consisting of a semi-nomadic people. It accomplished an enormous transformation into a Christian realm during the 10th century.

This state was well-functioning and the nation's military power allowed the Hungarians to conduct successful fierce campaigns and raids from Constantinople to as far as today's Spain. The Hungarians defeated no fewer than three major East Frankish Imperial Armies between 907 and 910. A later defeat at the Battle of Lechfeld in 955 signaled a provisory end to most campaigns on foreign territories, at least towards the West.

The year 972 marked the date when the ruling prince () Géza of the Árpád dynasty officially started to integrate Hungary into the Christian Western Europe. His first-born son, Saint Stephen I, became the first King of Hungary after defeating his pagan uncle Koppány, who also claimed the throne. Under Stephen, Hungary was recognized as a Catholic Apostolic Kingdom. Applying to Pope Sylvester II, Stephen received the insignia of royalty (including probably a part of the Holy Crown of Hungary, currently kept in the Hungarian Parliament) from the papacy.

By 1006, Stephen consolidated his power, and started sweeping reforms to convert Hungary into a Western feudal state. The country switched to using the Latin language, and until as late as 1844, Latin remained the official language of Hungary. Hungary became a powerful kingdom. Ladislaus I extended Hungary's frontier in Transylvania and invaded Croatia in 1091. The Croatian campaign culminated in the Battle of Gvozd Mountain in 1097 and a personal union of Croatia and Hungary in 1102, ruled by Coloman i.e. Könyves Kálmán.

The most powerful and wealthiest king of the Árpád dynasty was Béla III, who disposed of the equivalent of 23 tonnes of pure silver a year. This exceeded the income of the French king (estimated at 17 tonnes) and was double the receipts of the English Crown.

Andrew II issued the Diploma Andreanum which secured the special privileges of the Transylvanian Saxons and is considered the first Autonomy law in the world. He led the Fifth Crusade to the Holy Land in 1217, setting up the largest royal army in the history of Crusades. His Golden Bull of 1222 was the first constitution in Continental Europe. The lesser nobles also began to present Andrew with grievances, a practice that evolved into the institution of the parliament ("parlamentum publicum").

In 1241–1242, the kingdom received a major blow with the Mongol (Tatar) invasion. Up to half of Hungary's then population of 2,000,000 were victims of the invasion. King Béla IV let Cumans and Jassic people into the country, who were fleeing the Mongols. Over the centuries, they were fully assimilated into the Hungarian population.

As a consequence, after the Mongols retreated, King Béla ordered the construction of hundreds of stone castles and fortifications, to defend against a possible second Mongol invasion. The Mongols returned to Hungary in 1285, but the newly built stone-castle systems and new tactics (using a higher proportion of heavily armed knights) stopped them. The invading Mongol force was defeated near Pest by the royal army of Ladislaus IV of Hungary. As with later invasions, it was repelled handily, the Mongols losing much of their invading force.

The Kingdom of Hungary reached one of its greatest extents during the Árpádian kings, yet royal power was weakened at the end of their rule in 1301. After a destructive period of interregnum (1301–1308), the first Angevin king, Charles I of Hungary – a bilineal descendant of the Árpád dynasty – successfully restored royal power, and defeated oligarch rivals, the so-called "little kings". The second Angevin Hungarian king, Louis the Great (1342–1382), led many successful military campaigns from Lithuania to Southern Italy (Kingdom of Naples), and was also King of Poland from 1370. After King Louis died without a male heir, the country was stabilized only when Sigismund of Luxembourg (1387–1437) succeeded to the throne, who in 1433 also became Holy Roman Emperor. Sigismund was also (in several ways) a bilineal descendant of the Árpád dynasty.

The first Hungarian Bible translation was completed in 1439. For half a year in 1437, there was an antifeudal and anticlerical peasant revolt in Transylvania, the Budai Nagy Antal Revolt, which was strongly influenced by Hussite ideas.

From a small noble family in Transylvania, John Hunyadi grew to become one of the country's most powerful lords, thanks to his outstanding capabilities as a mercenary commander. He was elected governor then regent. He was a successful crusader against the Ottoman Turks, one of his greatest victories being the Siege of Belgrade in 1456.

The last strong king of medieval Hungary was the Renaissance king Matthias Corvinus (1458–1490), son of John Hunyadi. His election was the first time that a member of the nobility mounted to the Hungarian royal throne without dynastic background. He was a successful military leader and an enlightened patron of the arts and learning. His library, the Bibliotheca Corviniana, was Europe's greatest collection of historical chronicles, philosophic and scientific works in the 15th century, and second only in size to the Vatican Library. Items from the Bibliotheca Corviniana were inscribed on UNESCO’s Memory of the World Register in 2005.

The serfs and common people considered him a just ruler because he protected them from excessive demands from and other abuses by the magnates. Under his rule, in 1479, the Hungarian army destroyed the Ottoman and Wallachian troops at the Battle of Breadfield. Abroad he defeated the Polish and German imperial armies of Frederick at Breslau (Wrocław). Matthias' mercenary standing army, the Black Army of Hungary, was an unusually large army for its time, and it conquered parts of Austria, Vienna (1485) and parts of Bohemia.

King Matthias died without lawful sons, and the Hungarian magnates procured the accession of the Pole Vladislaus II (1490–1516), supposedly because of his weak influence on Hungarian aristocracy. Hungary's international role declined, its political stability shaken, and social progress was deadlocked. In 1514, the weakened old King Vladislaus II faced a major peasant rebellion led by György Dózsa, which was ruthlessly crushed by the nobles, led by John Zápolya.

The resulting degradation of order paved the way for Ottoman pre-eminence. In 1521, the strongest Hungarian fortress in the South, Nándorfehérvár (today's Belgrade, Serbia), fell to the Turks. The early appearance of Protestantism further worsened internal relations in the country.

After some 150 years of wars with the Hungarians and other states, the Ottomans gained a decisive victory over the Hungarian army at the Battle of Mohács in 1526, where King Louis II died while fleeing. Amid political chaos, the divided Hungarian nobility elected two kings simultaneously, John Zápolya and Ferdinand I of the Habsburg dynasty. With the conquest of Buda by the Turks in 1541, Hungary was divided into three parts and remained so until the end of the 17th century. The north-western part, termed as Royal Hungary, was annexed by the Habsburgs who ruled as Kings of Hungary. The eastern part of the kingdom became independent as the Principality of Transylvania, under Ottoman (and later Habsburg) suzerainty. The remaining central area, including the capital Buda, was known as the Pashalik of Buda.

The vast majority of the seventeen and nineteen thousand Ottoman soldiers in service in the Ottoman fortresses in the territory of Hungary were Orthodox and Muslim Balkan Slavs rather than ethnic Turkish people. Orthodox Southern Slavs were also acting as akinjis and other light troops intended for pillaging in the territory of present-day Hungary. In 1686, the Holy League's army, containing over 74,000 men from various nations, reconquered Buda from the Turks. After some more crushing defeats of the Ottomans in the next few years, the entire Kingdom of Hungary was removed from Ottoman rule by 1718. The last raid into Hungary by the Ottoman vassals Tatars from Crimea took place in 1717. The constrained Habsburg Counter-Reformation efforts in the 17th century reconverted the majority of the kingdom to Catholicism. The ethnic composition of Hungary was fundamentally changed as a consequence of the prolonged warfare with the Turks. A large part of the country became devastated, population growth was stunted, and many smaller settlements perished. The Austrian-Habsburg government settled large groups of Serbs and other Slavs in the depopulated south, and settled Germans (called Danube Swabians) in various areas, but Hungarians were not allowed to settle or re-settle in the south of the Great Plain.

Between 1703 and 1711, there was a large-scale uprising led by Francis II Rákóczi, who after the dethronement of the Habsburgs in 1707 at the Diet of Ónod, took power provisionally as the Ruling Prince of Hungary for the wartime period, but refused the Hungarian Crown and the title "King". The uprisings lasted for years. After 8 years of war with the Habsburg Empire, the Hungarian Kuruc army lost the last main battle at Trencsén (1708).

During the Napoleonic Wars and afterwards, the Hungarian Diet had not convened for decades. In the 1820s, the Emperor was forced to convene the Diet, which marked the beginning of a Reform Period (1825–1848, ). Count István Széchenyi, one of the most prominent statesmen of the country, recognized the urgent need of modernization and his message got through. The Hungarian Parliament was reconvened in 1825 to handle financial needs. A liberal party emerged and focused on providing for the peasantry. Lajos Kossuth – a famous journalist at that time – emerged as leader of the lower gentry in the Parliament. A remarkable upswing started as the nation concentrated its forces on modernization even though the Habsburg monarchs obstructed all important liberal laws relating to civil and political rights and economic reforms. Many reformers (Lajos Kossuth, Mihály Táncsics) were imprisoned by the authorities.

On 15 March 1848, mass demonstrations in Pest and Buda enabled Hungarian reformists to push through a list of 12 demands. Under governor and president Lajos Kossuth and the first Prime Minister, Lajos Batthyány, the House of Habsburg was dethroned.
The Habsburg Ruler and his advisors skillfully manipulated the Croatian, Serbian and Romanian peasantry, led by priests and officers firmly loyal to the Habsburgs, and induced them to rebel against the Hungarian government, though the Hungarians were supported by the vast majority of the Slovak, German and Rusyn nationalities and by all the Jews of the kingdom, as well as by a large number of Polish, Austrian and Italian volunteers. In July 1849 the Hungarian Parliament proclaimed and enacted the first laws of ethnic and minority rights in the world. Many members of the nationalities gained the coveted highest positions within the Hungarian Army, like General János Damjanich, an ethnic Serb who became a Hungarian national hero through his command of the 3rd Hungarian Army Corps or Józef Bem, who was Polish and also became a national hero in Hungary. Initially, the Hungarian forces ("Honvédség") defeated Austrian armies. To counter the successes of the Hungarian revolutionary army, Habsburg Emperor Franz Joseph I asked for help from the "Gendarme of Europe", Czar Nicholas I, whose Russian armies invaded Hungary. This made Artúr Görgey surrender in August 1849. The leader of the Austrian army, Julius Jacob von Haynau, became governor of Hungary for a few months, and ordered the execution of the 13 Martyrs of Arad, leaders of the Hungarian army, and Prime Minister Batthyány in October 1849. Lajos Kossuth escaped into exile. Following the war of 18481849, the whole country was in "passive resistance".

Because of external and internal problems, reforms seemed inevitable and major military defeats of Austria forced the Habsburgs to negotiate the Austro-Hungarian Compromise of 1867, by which the dual Monarchy of Austria–Hungary was formed. This Empire had the second largest area in Europe (after the Russian Empire), and it was the third most populous (after Russia and the German Empire). The two realms were governed separately by two parliaments from two capital cities, with a common monarch and common external and military policies. Economically, the empire was a customs union. The old Hungarian Constitution was restored, and Franz Joseph I was crowned as King of Hungary. The era witnessed impressive economic development. The formerly backward Hungarian economy became relatively modern and industrialized by the turn of the 20th century, although agriculture remained dominant until 1890. In 1873, the old capital Buda and Óbuda were officially united with Pest, thus creating the new metropolis of Budapest. Many of the state institutions and the modern administrative system of Hungary were established during this period.

After the Assassination in Sarajevo, the Hungarian prime minister István Tisza and his cabinet tried to avoid the outbreak and escalating of a war in Europe, but their diplomatic efforts were unsuccessful. Austria–Hungary drafted 9 million (fighting forces: 7.8 million) soldiers in World War I (over 4 million from the Kingdom of Hungary) on the side of Germany, Bulgaria and Turkey. The troops raised in the Kingdom of Hungary spent little time defending the actual territory of Hungary, with the exceptions of the Brusilov Offensive in June 1916, and a few months later, when the Romanian army made an attack into Transylvania, both of which were repelled. In comparison, of the total army, Hungary's loss ratio was more than any other nations of Austria-Hungary. The Central Powers conquered Serbia. Romania declared war. The Central Powers conquered Southern Romania and the Romanian capital Bucharest. In 1916 Emperor Franz Joseph died, and the new monarch Charles IV sympathized with the pacifists. With great difficulty, the Central powers stopped and repelled the attacks of the Russian Empire.

The Eastern front of the Allied (Entente) Powers completely collapsed. The Austro-Hungarian Empire then withdrew from all defeated countries. On the Italian front, the Austro-Hungarian army made no progress against Italy after January 1918. Despite great Eastern successes, Germany suffered complete defeat on the more important Western front. By 1918, the economic situation had deteriorated (strikes in factories were organized by leftist and pacifist movements) and uprisings in the army had become commonplace. In the capital cities, the Austrian and Hungarian leftist liberal movements (the maverick parties) and their leaders supported the separatism of ethnic minorities. Austria-Hungary signed a general armistice in Padua on 3 November 1918. In October 1918, Hungary's union with Austria was dissolved.

Following the First World War, Hungary underwent a period of profound political upheaval, beginning with the Aster Revolution in 1918, which brought the social-democratic Mihály Károlyi to power as Prime Minister. Károlyi dissolved the union with Austria and disarmed the Hungarian Army, leaving the country without any national defense. The Little Entente, sensing an opportunity, invaded the country from three sides—Romania invaded Transylvania, Czechoslovakia annexed Upper Hungary (today's Slovakia), and a joint Serb-French coalition annexed Vojvodina and other southern regions. In March 1919, communists led by Béla Kun ousted the Károlyi government and proclaimed the Hungarian Soviet Republic ("Tanácsköztársaság"), followed by a thorough Red Terror campaign. Despite some successes on the Czechoslovak front, Kun's forces were ultimately unable to resist the Romanian invasion; by August 1919, Romanian troops occupied Budapest and ousted Kun.

In November 1919, rightist forces led by former Austro-Hungarian admiral Miklós Horthy entered Budapest; exhausted by the war and its aftermath, the populace accepted Horthy's leadership. In January 1920, parliamentary elections were held and Horthy was proclaimed Regent of the reestablished Kingdom of Hungary, inaugurating the so-called "Horthy era" ("Horthy-kor"). The new government worked quickly to normalize foreign relations while turning a blind eye to a White Terror that swept through the countryside; extrajudicial killings of suspected communists and Jews lasted well into 1920. On June 4 of that year, the Treaty of Trianon established new borders for Hungary. The country lost 71% of its territory and 66% of its antebellum population, as well as many sources of raw materials and its sole port, Fiume. Though the revision of the Treaty quickly rose to the top of the national political agenda, the Horthy government was not willing to resort to military intervention to do so.

The initial years of the Horthy regime were occupied by putsch attempts by Charles IV, the Austro-Hungarian pretender; continued suppression of communists; and a migration crisis triggered by the Trianon territorial changes. Though free elections continued, Horthy's personality, and those of his personally selected prime ministers, dominated the political scene. The government's actions continued to drift right with the passage of antisemitic laws and, due to the continued isolation of the Little Entente, economic and then political gravitation toward Italy and Germany. The Great Depression further exacerbated the situation and the popularity of fascist politicians such as Gyula Gömbös and Ferenc Szálasi, promising economic and social recovery, rose.

Horthy's nationalist agenda reached its apogee in 1938 and 1940, when the Nazis rewarded Hungary's staunchly pro-Germany foreign policy in the First and Second Vienna Awards, respectively, peacefully restoring ethnic-Hungarian-majority areas lost after Trianon. In 1939, Hungary regained further territory from Czechoslovakia through force. Hungary formally joined the Axis Powers on 20 November 1940, and in 1941, participated in the invasion of Yugoslavia, gaining some of its former territories in the south.

Hungary formally entered World War II as an Axis Power on 26 June 1941, declaring war on the Soviet Union after unidentified planes bombed Kassa, Munkács, and Rahó. Hungarian troops fought on the Eastern Front for two years. Despite some early successes, the Hungarian government began seeking a secret peace pact with the Allies after the Second Army suffered catastrophic losses at the River Don in January 1943. Learning of the planned defection, German troops occupied Hungary on 19 March 1944 to guarantee Horthy's compliance. In October, as the Soviet front approached and the Hungarian government made further efforts to disengage from the war, German troops ousted Horthy and installed a puppet government under Szálasi's fascist Arrow Cross Party. Szálasi pledged all the country's capabilities in service of the German war machine. By October 1944, the Soviets had reached the river Tisza, and despite some losses, succeeded in encircling and besieging Budapest in December.

After German occupation, Hungary participated in the Holocaust. During the German occupation in May–June 1944, the Arrow Cross and Hungarian police deported nearly 440,000 Jews, mainly to Auschwitz. Nearly all of them were murdered. The Swedish Diplomat Raoul Wallenberg managed to save a considerable number of Hungarian Jews by giving them Swedish passports. Rudolf Kastner (original spelling Kasztner), one of the leaders of the Hungarian Aid and Rescue Committee, bribed senior SS officers such as Adolf Eichmann to allow some Jews to escape. The Horthy government's complicity in the Holocaust remains a point of controversy and contention.

The war left Hungary devastated, destroying over 60% of the economy and causing significant loss of life. In addition to the over 600,000 Hungarian Jews killed,<ref name="ind09/96"></ref> as many as 280,000 other Hungarians were raped, murdered and executed or deported for slave labor by Czechoslovaks, Soviet Red Army troops, and Yugoslavs.

On 13 February 1945, Budapest surrendered; by April, German troops left the country under Soviet military occupation. 200,000 Hungarians were expelled from Czechoslovakia in exchange for 70,000 Slovaks living in Hungary. 202,000 ethnic Germans were expelled to Germany, and through the 1947 Paris Peace Treaties, Hungary was again reduced to its immediate post-Trianon borders.

Following the defeat of Nazi Germany, Hungary became a satellite state of the Soviet Union. The Soviet leadership selected Mátyás Rákosi to front the Stalinization of the country, and Rákosi "de facto" ruled Hungary from 1949 to 1956. His government's policies of militarization, industrialization, collectivization, and war compensation led to a severe decline in living standards. In imitation of Stalin's KGB, the Rákosi government established a secret political police, the ÁVH, to enforce the new regime. The purges that followed saw approximately 350,000 officials and intellectuals imprisoned or executed from 1948 to 1956. Many freethinkers, democrats, and Horthy-era dignitaries were secretly arrested and extrajudicially interned in domestic and foreign Gulags. Some 600,000 Hungarians were deported to Soviet labor camps, where at least 200,000 died.

After Stalin's death in 1953, the Soviet Union pursued a program of destalinization that was inimical to Rákosi, leading to his deposition. The following political cooling saw the ascent of Imre Nagy to the premiership, and the growing interest of students and intellectuals in political life. Nagy promised market liberalization and political openness, while Rákosi opposed both vigorously. Rákosi eventually managed to discredit Nagy and replace him with the more hard-line Ernő Gerő. Hungary joined the Warsaw Pact in May 1955, as societal dissatisfaction with the regime swelled. Following the firing on peaceful demonstrations by Soviet soldiers and secret police, and rallies throughout the country on 23 October 1956, protesters took to the streets in Budapest, initiating the 1956 Revolution. In an effort to quell the chaos, Nagy returned as premier, promised free elections, and took Hungary out of the Warsaw Pact.

The violence nonetheless continued as revolutionary militias sprung up against the Soviet Army and the ÁVH; the roughly 3,000-strong resistance fought Soviet tanks using Molotov cocktails and machine-pistols. Though the preponderance of the Soviets was immense, they suffered heavy losses, and by 30 October 1956 most Soviet troops had withdrawn from Budapest to garrison the countryside. For a time, the Soviet leadership was unsure how to respond to developments in Hungary, but eventually decided to intervene to prevent a destabilization of the Soviet bloc. On 4 November reinforcements of more than 150,000 troops and 2,500 tanks entered the country from the Soviet Union. Nearly 20,000 Hungarians were killed resisting the intervention, while an additional 21,600 were imprisoned afterwards for political reasons. Some 13,000 were interned and 230 brought to trial and executed. Nagy was secretly tried, found guilty, sentenced to death and executed by hanging in June 1958. Because borders were briefly opened, nearly a quarter of a million people fled the country by the time the revolution was suppressed.

After a second, briefer period of Soviet military occupation, János Kádár, Nagy's former Minister of State, was chosen by the Soviet leadership to head the new government and chair the new ruling Socialist Workers' Party (MSzMP). Kádár quickly normalized the situation. In 1963, the government granted a general amnesty and released the majority of those imprisoned for their active participation in the uprising. Kádár proclaimed a new policy line, according to which the people were no longer compelled to profess loyalty to the party if they tacitly accepted the Socialist regime as a fact of life. In many speeches, he described this as, "Those who are not against us are with us." Kádár introduced new planning priorities in the economy, such as allowing farmers significant plots of private land within the collective farm system ("háztáji gazdálkodás"). The living standard rose as consumer good and food production took precedence over military production, which was reduced to one tenth of pre-revolutionary levels.

In 1968, the New Economic Mechanism (NEM) introduced free-market elements into socialist command economy. From the 1960s through the late 1980s, Hungary was often referred to as "the happiest barrack" within the Eastern bloc. During the latter part of the Cold War Hungary's GDP per capita was fourth only to East Germany, Czechoslovakia, and the Soviet Union itself. As a result of this relatively high standard of living, a more liberalized economy, a less censored press, and less restricted travel rights, Hungary was generally considered one of the more liberal countries in which to live in Central Europe during communism. In the 1980s, however, living standards steeply declined again due to a worldwide recession to which communism was unable to respond. By the time Kádár died in 1989, the Soviet Union was in steep decline and a younger generation of reformists saw liberalization as the solution to economic and social issues.

Hungary's transition from communism to democracy and capitalism ("rendszerváltás", "regime change") was peaceful and prompted by economic stagnation, domestic political pressure, and changing relations with other Warsaw Pact countries. Although the MSzMP began Round Table Talks with various opposition groups in March 1989, the reburial of Imre Nagy as a revolutionary martyr that June is widely considered the symbolic end of communism in Hungary. Over 100,000 people attended the Budapest ceremony without any significant government interference, and many speakers openly called for Soviet troops to leave the country. Free elections were held in May 1990, which saw the Hungarian Democratic Forum, a major conservative opposition group, elected to the head of a coalition government. József Antall became the first democratically elected Prime Minister since World War II.

With the removal of state subsidies and rapid privatization in 1991, Hungary was affected by a severe economic recession. The Antall government's austerity measures proved unpopular, and the Communist Party's legal and political heir, the Socialist Party, won the subsequent 1994 elections. This abrupt shift in the political landscape was repeated in 1998 and 2002; each electoral cycle, the governing party was ousted and the erstwhile opposition elected. Like most other post-communist European states, however, Hungary broadly pursued an integrationist agenda, joining NATO in 1999 and the European Union in 2004. As a NATO member, Hungary was involved in the Yugoslav Wars.

In 2006, major protests erupted after it leaked that socialist PM Ferenc Gyurcsány's had claimed in a private speech that his party "lied" to win the recent elections. The popularity of left-wing parties plummeted in the ensuing political upheaval, and in 2010, Viktor Orbán's national-conservative Fidesz was elected to a parliamentary supermajority. The legislature consequently approved a new constitution, among other sweeping governmental and legal changes. Although these developments were met with and still engender controversy, Fidesz secured a second parliamentary supermajority in 2014 and a third in 2018.

Hungary's geography has traditionally been defined by its two main waterways, the Danube and Tisza rivers. The common tripartite division of the country into three sections—"Dunántúl" ("beyond the Danube", Transdanubia), "Tiszántúl" ("beyond the Tisza"), and "Duna-Tisza köze" ("between the Danube and Tisza")—is a reflection of this. The Danube flows north-south right through the center of contemporary Hungary, and the entire country lies within its drainage basin.

Transdanubia, which stretches westward from the center of the country toward Austria, is a primarily hilly region with a terrain varied by low mountains. These include the very eastern stretch of the Alps, "Alpokalja", in the west of the country, the Transdanubian Mountains in the central region of Transdanubia, and the Mecsek Mountains and Villány Mountains in the south. The highest point of the area is the Írott-kő in the Alps, at . The Little Hungarian Plain ("Kisalföld") is found in northern Transdanubia. Lake Balaton and Lake Hévíz, the largest lake in Central Europe and the largest thermal lake in the world, respectively, are in Transdanubia as well.

The "Duna-Tisza köze" and "Tiszántúl" are characterized mainly by the Great Hungarian Plain ("Alföld"), which stretches across most of the eastern and southeastern areas of the country. To the north of the Plain are the foothills of the Carpathians in a wide band near the Slovakian border. The Kékes at is the tallest mountain in Hungary and is found here.

Phytogeographically, Hungary belongs to the Central European province of the Circumboreal Region within the Boreal Kingdom. According to the WWF, the territory of Hungary belongs to the ecoregion of Pannonian mixed forests.

Hungary has 10 national parks, 145 minor nature reserves, and 35 landscape protection areas.

Hungary has a continental climate, with hot summers with low overall humidity levels but frequent rainshowers and cold snowy winters. Average annual temperature is . Temperature extremes are on 20 July 2007 at Kiskunhalas in the summer and on 16 February 1940 Miskolc-Görömbölytapolca in the winter. Average high temperature in the summer is and average low temperature in the winter is . The average yearly rainfall is approximately . A small, southern region of the country near Pécs enjoys a reputation for a Mediterranean climate, but in reality it is only slightly warmer than the rest of the country and still receives snow during the winter.
Hungary is ranked sixth in an environmental protection index by "GW"/"CAN".

Hungary is a unitary, parliamentary, representative democratic republic. The Hungarian political system operates under a framework reformed in 2012; this constitutional document is the Fundamental Law of Hungary. Amendments generally require a two-thirds majority of parliament; the fundamental principles of the constitution (as expressed in the articles guaranteeing human dignity, the separation of powers, the state structure, and the rule of law) are valid in perpetuity. 199 Members of Parliament ("országgyűlési képviselő") are elected to the highest organ of state authority, the unicameral "Országgyűlés" (National Assembly), every four years in a single-round first-past-the-post election with an election threshold of 5%.

The Prime Minister ("miniszterelnök") is elected by the National Assembly, serving as the head of government and exercising executive power. Traditionally, the Prime Minister is the leader of the largest party in parliament. The Prime Minister selects Cabinet ministers and has the exclusive right to dismiss them, although cabinet nominees must appear before consultative open hearings before one or more parliamentary committees, survive a vote in the National Assembly, and be formally approved by the president. The cabinet reports to parliament.

The President of the Republic ("köztársasági elnök") serves as the head of state and is elected by the National Assembly every five years. The president is invested primarily with representative responsibilities and powers: receiving foreign heads of state, formally nominating the Prime Minister at the recommendation of the National Assembly, and serving as Commander-in-chief of the armed forces. Importantly, the president is also invested with veto power, and may send legislation to the 15-member Constitutional Court for review. The third most-significant governmental position in Hungary is the Speaker of the National Assembly, who is elected by the National Assembly and responsible for overseeing the daily sessions of the body.

The debt-to-GDP ratio of Hungary had its peak in 2011 when it stood at 83% and decreased since then. According to Eurostat, the government gross debt of Hungary amounts to 25.119 billion HUF or 74.1% of its GDP in 2016. The government achieved a budget deficit 1.9% of the GDP in 2015. Hungary's credit rating by credit rating agencies Standard & Poor's, Moody's and Fitch Ratings stands at Investment Grade "BBB" with a stable outlook in 2016.

Since the fall of communism, Hungary has a multi-party system. The last Hungarian parliamentary election took place on 8 April 2018. This parliamentary election was the 7th since the 1990 first multi-party election. The result was a victory for Fidesz–KDNP alliance, preserving its two-thirds majority with Viktor Orbán remaining Prime Minister. It was the second election according to the new Constitution of Hungary which went into force on 1 January 2012. The new electoral law also entered into force that day. The voters elected 199 MPs instead of previous 386 lawmakers. The current political landscape in Hungary is dominated by the conservative Fidesz, who have a near supermajority, and two medium-sized parties, the left-wing Hungarian Socialist Party ("MSZP") and nationalist Jobbik.

The democratic character of the Hungarian parliament was reestablished with the fall of the Iron Curtain and the end of communist dictatorship in 1989. Today's parliament is still called "Országgyűlés" just like in royal times, but in order to differentiate between the historical royal diet is referred to as "National Assembly" now. The Diet of Hungary was a legislative institution in the medieval kingdom of Hungary from the 1290s, and in its successor states, Royal Hungary and the Habsburg kingdom of Hungary throughout the Early Modern period. The articles of the 1790 diet set out that the diet should meet at least once every 3 years, but, since the diet was called by the Habsburg monarchy, this promise was not kept on several occasions thereafter. As a result of the Austro-Hungarian Compromise, it was reconstituted in 1867. The Latin term "Natio Hungarica" ("Hungarian nation") was used to designate the political elite which had participation in the diet, consisting of the nobility, the Catholic clergy, and a few enfranchised burghers, regardless of language or ethnicity.

The judicial system of Hungary is a civil law system divided between courts with regular civil and criminal jurisdiction and administrative courts with jurisdiction over litigation between individuals and the public administration. Hungarian law is codified and based on German law and in a wider sense, civil law or Roman law. The court system for civil and criminal jurisdiction consists of local courts ("járásbíróság"), regional appellate courts ("ítélőtábla"), and the supreme court ("Kúria"). Hungary's highest courts are located in Budapest.

Law enforcement in Hungary is split among the police and Border Guards, and the National Tax and Customs Administration. The Hungarian Police is the main and largest state law enforcement agency in Hungary. It carries nearly all general police duties such as criminal investigation, patrol activity, traffic policing, border control. It is led by the National Police Commissioner under the control of the Minister of the Interior. The body is divided into county police departments which are also divided into regional and town police departments. The National Police also have child agencies with nationwide jurisdiction, such as the police force often mocked as the Hungarian FBI "Nemzeti Nyomozó Iroda" (National Bureau of Investigation), a civilian police force specialised in investigating serious crimes, the gendarmerie-like, militarised "Készenléti Rendőrség" (Operational Police) mainly dealing with riots and often enforcing local police forces. Due to Hungary's accession to the Schengen Treaty, the Police and Border Guards were merged into a single national corps, with the Border Guards becoming Police Officers. This merger took place in January 2008. The Customs and Excise Authority remained to be subject to the Ministry of Finance under the National Tax and Customs Administration.

Hungary is a unitary state nation divided into 19 counties ("megye"). In addition, the capital ("főváros"), Budapest, is an independent entity. The states and the capital are the 20 NUTS third-level units of Hungary. The states are further subdivided into 174 districts ("járás") as of 1 January 2013. The districts are further divided into towns and villages, of which 23 are designated towns with county rights ("megyei jogú város"), sometimes known as "urban counties" in English. The local authorities of these towns have extended powers, but these towns belong to the territory of the respective district instead of being independent territorial units. County and district councils and municipalities have different roles and separate responsibilities relating to local government. The role of the counties are basically administrative and focus on strategic development, while preschools, public water utilities, garbage disposal, elderly care and rescue services are administered by the municipalities.

Since 1996, the counties and City of Budapest have been grouped into 7 regions for statistical and development purposes. These seven regions constitute NUTS' second-level units of Hungary. They are Central Hungary, Central Transdanubia, Northern Great Plain, Northern Hungary, Southern Transdanubia, Southern Great Plain, and Western Transdanubia.

Hungary wields considerable influence in Central and Eastern Europe and is a middle power in international affairs. The foreign policy of Hungary is based on four basic commitments: to Atlantic co-operation, to European integration, to international development and to international law. The Hungarian economy is fairly open and relies strongly on international trade.

Hungary has been a member of the United Nations since December 1955 and a member of the European Union, NATO, the OECD, the Visegrád Group, the WTO, the World Bank, the AIIB and the IMF. Hungary took on the presidency of the Council of the European Union for half a year in 2011 and the next will be in 2024. In 2015, Hungary was the fifth largest OECD Non-DAC donor of development aid in the world, which represents 0.13% of its Gross National Income.

Hungary's capital city, Budapest, is home to more than 100 embassies and representative bodies as an international political actor. Hungary hosts the main and regional headquarters of many international organizations as well, including European Institute of Innovation and Technology, European Police College, United Nations High Commissioner for Refugees, Food and Agriculture Organization of the United Nations, International Centre for Democratic Transition, Institute of International Education, International Labour Organization, International Organization for Migration, International Red Cross, Regional Environmental Center for Central and Eastern Europe, Danube Commission and others.

Since 1989, Hungary's top foreign policy goal has been achieving integration into Western economic and security organizations. Hungary joined the Partnership for Peace program in 1994 and has actively supported the IFOR and SFOR missions in Bosnia. Hungary since 1989 has also improved its often frosty neighborly relations by signing basic treaties with Romania, Slovakia, and Ukraine. These renounce all outstanding territorial claims and lay the foundation for constructive relations. However, the issue of ethnic Hungarian minority rights in Romania, Slovakia and Serbia periodically causes bilateral tensions to flare up. Since 2017, the relations with Ukraine rapidly deteriorated over the issue of the Hungarian minority. Hungary since 1989 has signed all of the OSCE documents, and served as the OSCE's Chairman-in-Office in 1997. 

The 2016 Global Peace Index ranked Hungary 19th out of 163 countries. The President holds the title of commander-in-chief of the nation's armed forces. The Ministry of Defence jointly with Chief of staff administers the armed forces, including the Hungarian Ground Force and the Hungarian Air Force. Since 2007, the Hungarian Armed Forces is under a unified command structure. The Ministry of Defence maintains the political and civil control over the army. A subordinate Joint Forces Command is coordinating and commanding the HDF corps. In 2016, the armed forces had 31,080 personnel on active duty, the operative reserve brought the total number of troops to fifty thousand. In 2017, military spending will be $1.21 billion, about 0.94% of the country's GDP, well below the NATO target of 2%. In 2012, the government adopted a resolution in which it pledged to increase defence spending to 1.4% of GDP by 2022.

Military service is voluntary, though conscription may occur in wartime. In a significant move for modernization, Hungary decided in 2001 to buy 14 JAS 39 Gripen fighter aircraft for about 800 million EUR. Hungarian National Cyber Security Center is re-organized in 2016 in order to become more efficient through cyber security.

In 2016, the Hungarian military has about 700 troops stationed in foreign countries as part of international peacekeeping forces, including 100 HDF troops in the NATO-led ISAF force in Afghanistan, 210 Hungarian soldiers in Kosovo under command of KFOR, and 160 troops in Bosnia and Herzegovina. Hungary sent 300 strong logistics unit to Iraq in order to help the US occupation with armed transport convoys, though public opinion opposed the country's participation in the war. One soldier was killed in action because of a roadside bomb in Iraq.

During the 18th and 19th century, Hungarian Hussars rose to international fame and served as a model for light cavalry in many European countries. In 1848–49 HDF achieved successes against better-trained and equipped Austrian forces, despite the Austrian advantage in numbers. In 1872, the Ludovica Military Academy officially began training cadets. By 1873 HDF already had over 2,800 officers and 158,000 men organized into eighty-six battalions and fifty-eight squadrons. During WWI, out of the eight million men mobilized by Austro Hungarian Empire, over one million died. During the 1930s and early 1940s, Hungary was preoccupied with regaining the territories and population lost in the Trianon peace treaty at Versailles in 1920. Conscription was introduced on a national basis in 1939. The peacetime strength of the Royal Hungarian Army grew to 80,000 men organized into seven corps commands. During WWII the Hungarian Second Army was near to total devastation on banks of the Don River in December 1942 in the Battle for Stalingrad. During the Socialist and the Warsaw Pact era (1947–1989), the entire 200,000 strong Southern Group of Forces was garrisoned in Hungary, complete with artillery, tank regiments, air force and missile troops with nuclear weapons.

Hungary is an OECD high-income mixed economy with very high human development index and skilled labour force with the 16th lowest income inequality in the world, furthermore it is the 15th most complex economy according to the Economic Complexity Index. The Hungarian is the 57th-largest economy in the world (out of 188 countries measured by IMF) with $265.037 billion output, and ranks 49th in the world in terms of GDP per capita measured by purchasing power parity. Hungary is an export-oriented market economy with a heavy emphasis on foreign trade, thus the country is the 36th largest export economy in the world. The country has more than $100 billion export in 2015 with high, $9.003 billion trade surplus, of which 79% went to the EU and 21% was extra-EU trade. Hungary has a more than 80% privately owned economy with 39,1% overall taxation, which provides the basis for the country's welfare economy. On the expenditure side, household consumption is the main component of GDP and accounts for 50 percent of its total use, followed by gross fixed capital formation with 22 percent and government expenditure with 20 percent.

Hungary continues to be one of the leading nations for attracting foreign direct investment in Central and Eastern Europe, the inward FDI in the country was $119.8 billion in 2015, while Hungary invests more than $50 billion abroad. , the key trading partners of Hungary were Germany, Austria, Romania, Slovakia, France, Italy, Poland and Czech Republic. Major industries include food processing, pharmaceuticals, motor vehicles, information technology, chemicals, metallurgy, machinery, electrical goods, and tourism (in 2014 Hungary welcomed 12.1 million international tourists).
Hungary is the largest electronics producer in Central and Eastern Europe. Electronics manufacturing and research are among the main drivers of innovation and economic growth in the country. In the past 20 years Hungary has also grown into a major center for mobile technology, information security, and related hardware research.
The employment rate in the economy was 68.3% in 2017, the employment structure shows the characteristics of post-industrial economies, 63.2% of employed workforce work in service sector, the industry contributed by 29.7%, while agriculture with 7.1%. Unemployment rate was 4.1% in 2017 September, down from 11% during the financial crisis of 2007–08.
Hungary is part of the European single market which represents more than 508 million consumers. Several domestic commercial policies are determined by agreements among European Union members and by EU legislation.

Large Hungarian companies are included in the BUX, the Hungarian stock market index listed on Budapest Stock Exchange. Well-known companies include the Fortune Global 500 firm MOL Group, the OTP Bank, Gedeon Richter Plc., Magyar Telekom, CIG Pannonia, FHB Bank, Zwack Unicum and more. Besides this Hungary has a large portion of specialised small and medium enterprise, for example a significant number of automotive suppliers and technology start ups among others.

Budapest is the financial and business capital of Hungary. The capital is a significant economic hub, classified as an Beta+ world city in the study by the Globalization and World Cities Research Network and it is the second fastest-developing urban economy in Europe as GDP per capita in the city increased by 2.4 per cent and employment by 4.7 per cent compared to the previous year in 2014. On the national level, Budapest is the primate city of Hungary regarding business and economy, accounting for 39% of the national income, the city has a gross metropolitan product more than $100 billion in 2015, making it one of the largest regional economies in the European Union. Budapest is also among the Top 100 GDP performing cities in the world, measured by PricewaterhouseCoopers and in a global city competitiveness ranking by EIU, Budapest stands before Tel Aviv, Lisbon, Moscow and Johannesburg among others.

Hungary maintains its own currency, the Hungarian forint (HUF), although the economy fulfills the Maastricht criteria with the exception of public debt, but it is also significantly below the EU average with the level of 75.3% in 2015. The Hungarian National Bank—founded in 1924, after the dissolution of Austro-Hungarian Empire—is currently focusing on price stability with an inflation target of 3%.

Hungary's achievements in science and technology have been significant, and research and development efforts form an integral part of the country's economy. Hungary spent 1.4% of its gross domestic product (GDP) on civil research and development in 2015, which is the 25th highest ratio in the world. Hungary ranks 32nd among the most innovative countries in the Bloomberg Innovation Index, standing before Hong Kong, Iceland or Malta. The Global Innovation Index places Hungary 33th among the countries of the world in 2016. In 2014, Hungary counted 2,651 full-time equivalent researchers per million inhabitants, steadily increasing from 2,131 in 2010 and compares with 3,984 in the US or 4,380 in Germany. Hungary's high technology industry has benefited from both the country's skilled workforce and the strong presence of foreign high-tech firms and research centres. Hungary also has one of the highest rates of filed patents, the 6th highest ratio of high-tech and medium high-tech output in the total industrual output, the 12th highest research FDI inflow, placed 14th in research talent in business enterprise and has the 17th best overall innovation efficiency ratio in the world.

The key actor of research and development in Hungary is the National Research, Development and Innovation Office (NRDI Office), which is a national strategic and funding agency for scientific research, development and innovation, the primary source of advice on RDI policy for the Hungarian Government, and the primary RDI funding agency. Its role is to develop RDI policy and ensure that Hungary adequately invest in RDI by funding excellent research and supporting innovation to increase competitiveness and to prepare the RDI strategy of the Hungarian Government, to handle the National Research, Development and Innovation Fund, and represents the Hungarian Government and a Hungarian RDI community in international organizations.

Scientific research in the country is supported partly by industry and partly by the state, through the network of Hungarian universities and by scientific state-institutions such as Hungarian Academy of Sciences. Hungary has been the home of some of the most prominent researchers in various scientific disciplines, notably physics, mathematics, chemistry and engineering. 13 Hungarian scientists have received the Nobel Prize yet. Until 2012 three individuals: Csoma, János Bolyai and Tihanyi were included in the UNESCO Memory of the world register as well as the collective contributions: Tabula Hungariae and Bibliotheca Corviniana. Contemporary, internationally well-known Hungarian scientists include: mathematician László Lovász, physicist Albert-László Barabási, physicist Ferenc Krausz, and biochemist Árpád Pusztai. Hungary is famous for its excellent mathematics education which has trained numerous outstanding scientists. Famous Hungarian mathematicians include father Farkas Bolyai and son János Bolyai, who was one of the founders of non-Euclidean geometry; Paul Erdős, famed for publishing in over forty languages and whose Erdős numbers are still tracked, and John von Neumann, a key contributor in the fields of quantum mechanics and game theory, a pioneer of digital computing, and the chief mathematician in the Manhattan Project.

Hungary has a highly developed road, railway, air and water transport system. Budapest, the capital, serves as an important hub for the Hungarian railway system ("MÁV"). The capital is served by three large train stations called "Keleti" (Eastern), "Nyugati" (Western), and "Déli" (Southern) "pályaudvar"s. Szolnok is the most important railway hub outside Budapest, while Tiszai Railway Station in Miskolc and the main stations of Szombathely, Győr, Szeged, and Székesfehérvár are also key to the network.

Budapest, Debrecen, Miskolc, and Szeged have tram networks. The Budapest Metro is the second-oldest underground metro system in the world; its Line 1 dates from 1896. The system consists of four lines. A commuter rail system, "HÉV", operates in the Budapest metropolitan area.
Hungary has a total length of approximately motorways (). Motorway sections are being added to the existing network, which already connects many major economically important cities to the capital.
The most important port is Budapest. Other important ones include Dunaújváros and Baja.

There are five international airports in Hungary: Budapest Liszt Ferenc (informally called "Ferihegy" after its previous name), Debrecen, Sármellék (also called Hévíz-Balaton Airport), Győr-Pér, and Pécs-Pogány. The national carrier, MALÉV, operated flights to over 60, mostly European cities, but ceased operations in 2012. Low-budget airline WizzAir is based in Hungary, at Ferihegy.

Hungary's population was 9,937,628 according to the 2011 census, thus the country is the 5th most populous in the Central and Eastern European region and medium-sized member state of the European Union. Population density stands at 107 inhabitants per square kilometre, which is about two times higher than the world average. More than one quarter of the population lived in the Budapest metropolitan area, 6,903,858 people (69.5%) in cities and towns overall. Like most other European countries, Hungary is experiencing sub-replacement fertility, with the total fertility rate estimated at 1.43 children born/woman in 2015, lower than the replacement rate of 2.1. This is leading to gradual population decline and rapid aging. The recent decrease in birth rate occurred in the 1990s; dropping from 1.87 in 1990 to 1.28 in 1999. In 2011, the conservative government began a program to increase the birth rate with a focus on ethnic Magyars by reinstating 3 year maternity leave as well as boosting part-time jobs. The birth rate has gradually increased from 1.27 children born/woman in 2011. The natural decrease in the first 10 months of 2016 was only 25,828 which was 8,162 less than the corresponding period in 2015. In 2015, 47.9% of births were to unmarried women. Life expectancy was 71.96 years for men and 79.62 years for women in 2015, growing continuously since the fall of Communism.

Two sizable groups of people are referred to as "national minorities" because their ancestors have lived in their respective regions for centuries in Hungary. There is a German minority (about 130,000) living throughout the whole country, and there is a Romani minority (about 300,000) that mainly resides in the northern part of the country. According to the 2011 census, there were 8,014,029 (80.7%) Hungarians, 608,957 (6.1%) Romani, 131,951 (1.3%) Germans, 29,647 (0.3%) Slovaks, 26,345 (0.3%) Romanians, and 23,561 (0.2%) Croats in Hungary. 1,455,883 people (14.7% of the total population) did not declare their ethnicity. Thus, Hungarians made up more than 90% of people who declared their ethnicity. In Hungary, people can declare more than one ethnicity, so the sum of ethnicities is higher than the total population.

Today approximately 5 million Hungarians live outside Hungary.

Hungarian is the official and predominant spoken language in Hungary. Hungarian is the 13th most widely spoken first language in Europe with around 13 million native speakers and it is one of 24 official and working languages of the European Union. Outside Hungary it is also spoken by communities of Hungarian people in neighbouring countries and by Hungarian diaspora communities worldwide. According to the 2011 census, 9,896,333 people (99.6%) speak Hungarian in Hungary, of whom 9,827,875 people (99%) speak it as a first language, while 68,458 people (0.7%) speak it as a second language. English (1,589,180 speakers, 16.0%), and German (1,111,997 speakers, 11.2%) are the most widely spoken foreign languages, while there are several recognized minority languages in Hungary (Armenian, Bulgarian, Croatian, German, Greek, Romanian, Romani, Rusyn, Serbian, Slovak, Slovenian, and Ukrainian).

Hungarian (Magyar) is a member of the Uralic language family, unrelated to any neighboring language and distantly related to Finnish and Estonian. It is the largest of the Uralic languages in terms of the number of speakers and the only one spoken in Central Europe. There are sizable populations of Hungarian speakers in Romania, the Czech and Slovak Republics, the former Yugoslavia, Ukraine, Israel, and the U.S. Smaller groups of Hungarian speakers live in Canada, Slovenia, and Austria, but also in Australia, Brazil, Argentina, Mexico, Venezuela and Chile. Standard Hungarian is based on the variety spoken in the capital of Budapest, although use of the standard dialect is enforced, Hungarian has a number of urban and rural dialects.

Hungary is a historically Christian country. Hungarian historiography identifies the foundation of the Hungarian state with Stephen I's baptism and coronation with the Holy Crown in A.D. 1000. Stephen promulgated Roman Catholicism as the state religion, and his successors were traditionally known as the Apostolic Kings. The Catholic Church in Hungary remained strong through the centuries, and the Archbishop of Esztergom was granted extraordinary temporal privileges as prince-primate ("hercegprímás") of Hungary. Contemporary Hungary, however, has no official religion. While the constitution "recognizes Christianity's nation-building role", freedom of religion is a fundamental right.

With the onset of the Protestant Reformation, most Hungarians took up first Lutheranism, then soon afterwards Calvinism. In the second half of the 16th century, however, Jesuits led a Counterreformation campaign and the population once again became predominantly Catholic. However, in comparison to other European regions where such efforts were undertaken, it was not at all successful largely because of religious freedom secured by Hungarian nobles, who often happened to be Calvinist themselves. Some localities all over Hungary are still majority Protestant (either Lutheran or Reformed) and the country's eastern regions, especially around Debrecen (the "Calvinist Rome"), remain predominantly Reformed.

Orthodox Christianity in Hungary is associated with the country's ethnic minorities:Armenians, Bulgarians, Greeks, Romanians, Rusyns, Ukrainians, and Serbs.

Historically, Hungary was home to a significant Jewish community. Some Hungarian Jews were able to escape the Holocaust during World War II, but most (perhaps 550,000) were either deported to concentration camps, whence most did not return, or murdered in Hungary by Arrow Cross members.

The 2011 census showed that the majority of Hungarians were Christians (54.2%), with Roman Catholics ("Katolikusok") (37.1%) and Hungarian Reformed Calvinists ("Reformátusok") (11.1%) making up the bulk of these alongside Lutherans ("Evangélikusok") (2.2%), Greek Catholics (1.8%), and other Christians (1.3%). Jewish (0.1%), Buddhist (0.1%) and Muslim (0.06%) communities are in the minority. 27.2% of the population did not declare a religious affiliation while 16.7% declared themselves explicitly irreligious, another 1.5% atheist.

Education in Hungary is predominantly public, run by the Ministry of Education. Preschool-kindergarten education is compulsory and provided for all children between three and six years old, after which school attendance is also compulsory until the age of sixteen. Primary education usually lasts for eight years. Secondary education includes three traditional types of schools focused on different academic levels: the Gymnasium enrolls the most gifted children and prepares students for university studies; the secondary vocational schools for intermediate students lasts four years and the technical school prepares pupils for vocational education and the world of work. The system is partly flexible and bridges exist, graduates from a vocational school can achieve a two years program to have access to vocational higher education for instance. The Trends in International Mathematics and Science Study (TIMSS) rated 13–14-year-old pupils in Hungary among the bests in the world for maths and science.

Most of the Hungarian universities are public institutions, and students traditionally study without fee payment. The general requirement for university is the Matura. The Hungarian public higher education system includes universities and other higher education institutes, that provide both education curricula and related degrees up to doctoral degree and also contribute to research activities. Health insurance for students is free until the end of their studies. English and German language is important in Hungarian higher education, there are a number of degree programs that are taught in these languages, which attracts thousands of exchange students every year. Hungary's higher education and training has been ranked 44 out of 148 countries in the Global competitiveness Report 2014.

Hungary has a long tradition of higher education reflecting the existence of established knowledge economy. The established universities in Hungary include some of the oldest in the world, the first was the University of Pécs founded in 1367 which is still functioning, although, in the year 1276, the university of Veszprém was destroyed by the troops of Peter Csák, but it was never rebuilt. Sigismund established Óbuda University in 1395. Another, Universitas Istropolitana, was established 1465 in Pozsony by Mattias Corvinus.
Nagyszombat University was founded in 1635 and moved to Buda in 1777 and it is called Eötvös Loránd University today. The world's first institute of technology was founded in Selmecbánya, Kingdom of Hungary in 1735, its legal successor is the University of Miskolc. The Budapest University of Technology and Economics is considered the oldest institute of technology in the world with university rank and structure, its legal predecessor the Institutum Geometrico-Hydrotechnicum was founded in 1782 by Emperor Joseph II.

The Hungarian health care system is one of universal health care largely financed by government national health insurance. According to the OECD, 100% of the total population is covered by universal health insurance, which is absolutely free for children, students, pensioners, people with low income, handicapped people, priests and other church employees. According to the OECD Hungary spent 7.8% of its GDP on health care in 2012. Total health expenditure was 1,688.7 US$ per capita in 2011, 1,098.3 US$ governmental-fund (65%) and 590.4 US$ private-fund (35%).

Hungary is one of the main destinations of medical tourism in Europe. The country leads in dental tourism, its share is 42% in Europe and 21% worldwide. Plastic surgery is also a key sector, 30% of the clients come from abroad. Hungary is home to numerous medicinal spas, spa tourism sometimes combined with other treatments.

62,979 deaths (49.4% of all) in Hungary were caused by cardiovascular disease in 2013. A number of cardiovascular disease deaths peaked in 1985 with 79,355, declining continuously since the fall of Communism. The second most important cause of death was cancer with 33,274 (26.2% of all), stagnating since the 1990s. A number of accident deaths dropped from 8,760 in 1990 to 3,654 in 2013, the number of suicides from 4,911 in 1983 to 2,093 in 2013 (21.1 per 100,000 people), the lowest data registered since 1956. There are huge differences between the western and eastern parts of Hungary, heart disease, hypertension, stroke, and suicide is prevalent in the mostly agricultural and low-income characteristic Great Plain, but infrequent in the high-income and middle class characteristic Western Transdanubia and Central Hungary. Smoking also causes significant losses to Hungarian society. 28% of the adult population smoked in 2012, dropped to 19% in 2013 due to strict regulation. Nationwide smoking bans expanded to every indoor public place, the sale of tobacco is limited to state-controlled tobacco shops called National Tobacco Shop. The homicide rate was 1.3 per 100,000 people, which is among the lowest in the World.

Hungary is home to the largest synagogue in Europe (Great Synagogue), built in 1859 in Moorish Revival style with a capacity of 3000 people, the largest medicinal bath in Europe (Széchenyi Medicinal Bath), completed in 1913 in Modern Renaissance Style and located in the City park, the biggest building in Hungary with its length (the Parliament building), one of the largest basilicas in Europe (Esztergom Basilica), the second largest territorial abbey in the world (Pannonhalma Archabbey), and the largest early Christian necropolis outside Italy (Pécs).

Notable architectural styles in Hungary include Historicism and Art Nouveau, or rather several variants of Art Nouveau. In contrast to Historicism, Hungarian Art Nouveau is based on the national architectural characteristics. Taking the eastern origins of the Hungarians into account, Ödön Lechner (1845–1914), the most important figure in Hungarian Art Nouveau, was initially inspired by Indian and Syrian architecture, and later by traditional Hungarian decorative designs. In this way, he created an original synthesis of architectural styles. By applying them to three-dimensional architectural elements, he produced a version of Art Nouveau that was specific to Hungary.

Turning away from the style of Lechner, yet taking inspiration from his approach, the group of "Young People" ("Fiatalok"), which included Károly Kós and Dezsö Zrumeczky, were to use the characteristic structures and forms of traditional Hungarian architecture to achieve the same end.

Besides the two principal styles, Budapest also displays local versions of trends originating from other European countries. The Sezession from Vienna, the German Jugendstil, Art Nouveau from Belgium and France, and the influence of English and Finnish architecture are all reflected in the buildings constructed at the turn of the 20th century. Béla Lajta initially adopted Lechner's style, subsequently drawing his inspiration from English and Finnish trends; after developing an interest in the Egyptian style, he finally arrived at modern architecture. Aladár Árkay took almost the same route. István Medgyaszay developed his own style, which differed from Lechner's, using stylised traditional motifs to create decorative designs in concrete. In the sphere of applied arts, those chiefly responsible for promoting the spread of Art Nouveau were the School and Museum of Decorative Arts, which opened in 1896.

Foreigners have unexpectedly "discovered" that a significantly large portion of the citizens live in old and architecturally valuable buildings. In the Budapest downtown area almost all the buildings are about one hundred years old, with thick walls, high ceilings, and motifs on the front wall.

Hungarian music consists mainly of traditional Hungarian folk music and music by prominent composers such as Liszt and Bartók, considered to be among the greatest Hungarian composers. Other renowned composers are Dohnányi, Franz Schmidt, Zoltán Kodály, Gabriel von Wayditch, Rudolf Wagner-Régeny, László Lajtha, Franz Lehár, Imre Kálmán, Sándor Veress and Rózsa. Hungarian traditional music tends to have a strong dactylic rhythm, as the language is invariably stressed on the first syllable of each word.

Hungary has renowned composers of contemporary classical music, György Ligeti, György Kurtág, Péter Eötvös, Zoltán Kodály and Zoltán Jeney among them. One of the greatest Hungarian composers, Béla Bartók, was also among the most significant musicians of the 20th century. His music was invigorated by the themes, modes, and rhythmic patterns of the Hungarian and neighboring folk music traditions he studied, which he synthesized with influences from his contemporaries into his own distinctive style.

Hungary has made many contributions to the fields of folk, popular and classical music. Hungarian folk music is a prominent part of the national identity and continues to play a major part in Hungarian music. Hungarian folk music has been significant in former country parts that belong – since the 1920 Treaty of Trianon – to neighbouring countries such as Romania, Slovakia, Poland and especially in southern Slovakia and Transylvania; both regions have significant numbers of Hungarians.
After the establishment of a music academy led by Ferenc Erkel and Franz Liszt Hungary produced an important number of art musicians:

Broughton claims that Hungary's "infectious sound has been surprisingly influential on neighboring countries (thanks perhaps to the common Austro-Hungarian history) and it's not uncommon to hear Hungarian-sounding tunes in Romania, Slovakia and Poland". It is also strong in the Szabolcs-Szatmár area and in the southwest part of Transdanubia, near the border with Croatia. The Busójárás carnival in Mohács is a major Hungarian folk music event, formerly featuring the long-established and well-regarded Bogyiszló orchestra.

Hungarian classical music has long been an "experiment, made from Hungarian antecedents and on Hungarian soil, to create a conscious musical culture [using the] musical world of the folk song". Although the Hungarian upper class has long had cultural and political connections with the rest of Europe, leading to an influx of European musical ideas, the rural peasants maintained their own traditions such that by the end of the 19th century Hungarian composers could draw on rural peasant music to (re)create a Hungarian classical style. For example, Bartók collected folk songs from across Central and Eastern Europe, including Romania and Slovakia, while Kodály was more interested in creating a distinctively Hungarian musical style.

During the era of Communist rule in Hungary (1944–1989), a Song Committee scoured and censored popular music for traces of subversion and ideological impurity. Since then, however, the Hungarian music industry has begun to recover, producing successful performers in the fields of jazz such as trumpeter Rudolf Tomsits, pianist-composer Károly Binder and, in a modernized form of Hungarian folk, Ferenc Sebő and Márta Sebestyén. The three giants of Hungarian rock, Illés, Metró and Omega, remain very popular, especially Omega, which has followings in Germany and beyond as well as in Hungary. Older veteran underground bands such as Beatrice, from the 1980s, also remain popular.

In the earliest times, Hungarian language was written in a runic-like script (although it was not used for literature purposes in the modern interpretation). The country switched to the Latin alphabet after being Christianized under the reign of Stephen I of Hungary (1000–1038).
The oldest remained written record in Hungarian language is a fragment in the Establishing charter of the abbey of Tihany (1055) which contains several Hungarian terms, among them the words "feheruuaru rea meneh hodu utu rea", "up the military road to Fehérvár" The rest of the document was written in Latin.

The oldest remaining complete text in Hungarian language is the Funeral Sermon and Prayer "(Halotti beszéd és könyörgés)" (1192–1195), a translation of a Latin sermon.
The oldest remaining poem in Hungarian is the Old Hungarian Laments of Mary "(Ómagyar Mária-siralom)", also a (not very strict) translation from Latin, from the 13th century. It is also the oldest surviving Uralic poem.
Among the first chronicles about Hungarian history were Gesta Hungarorum ("Deeds of the Hungarians") by the unknown author usually called "Anonymus", and Gesta Hunnorum et Hungarorum ("Deeds of the Huns and the Hungarians") by Simon Kézai. Both are in Latin. These chronicles mix history with legends, so historically they are not always authentic. Another chronicle is the "Képes krónika" (Illustrated Chronicle), which was written for Louis the Great.

Renaissance literature flourished under the reign of King Matthias (1458–1490). Janus Pannonius, although he wrote in Latin, counts as one of the most important persons in Hungarian literature, being the only significant Hungarian Humanist poet of the period. The first printing house was also founded during Matthias' reign, by András Hess, in Buda. The first book printed in Hungary was the Chronica Hungarorum.
The most important poets of the period was Bálint Balassi (1554–1594) and Miklós Zrínyi (1620–1664).

Balassi's poetry shows Mediaeval influences, his poems can be divided into three sections: love poems, war poems and religious poems. Zrínyi's most significant work, the epic "Szigeti veszedelem" ("Peril of Sziget", written in 1648/49) is written in a fashion similar to the "Iliad", and recounts the heroic Battle of Szigetvár, where his great-grandfather died while defending the castle of Szigetvár.
Among the religious literary works the most important is the Bible translation by Gáspár Károli (The second Hungarian Bible translation in the history), the Protestant pastor of Gönc, in 1590. The translation is called the "Bible of Vizsoly", after the town where it was first published. (See Bible translations into Hungarian for more details.)
The Hungarian enlightenment took place about fifty years after the French enlightenment. The first enlightened writers were Maria Theresia's bodyguards (György Bessenyei, János Batsányi and others). The greatest poets of the time were Mihály Csokonai Vitéz and Dániel Berzsenyi.
The greatest figure of the language reform was Ferenc Kazinczy. The Hungarian language became feasible for all type of scientific explanations from this time, and furthermore many new words were coined for describing new inventions.

Hungarian literature has recently gained some renown outside the borders of Hungary (mostly through translations into German, French and English). Some modern Hungarian authors have become increasingly popular in Germany and Italy especially Sándor Márai, Péter Esterházy, Péter Nádas and Imre Kertész. The latter is a contemporary Jewish writer who survived the Holocaust and won the Nobel Prize for literature in 2002.
The older classics of Hungarian literature and Hungarian poetry have remained almost totally unknown outside Hungary. János Arany, a famous 19th-century Hungarian poet, is still much loved in Hungary (especially his collection of Ballads), among several other "true classics" like Sándor Petőfi, the poet of the Revolution of 1848, Endre Ady, Mihály Babits, Dezső Kosztolányi, Attila József, Miklós Radnóti and János Pilinszky. Other well-known Hungarian authors are László Krasznahorkai, Ferenc Móra, Géza Gárdonyi, Zsigmond Móricz, Gyula Illyés, Albert Wass, Miklós Szentkuthy and Magda Szabó.

Traditional dishes such as the world-famous Goulash ("gulyás" stew or "gulyás" soup) feature prominently in Hungarian cuisine. Dishes are often flavoured with paprika (ground red peppers), a Hungarian innovation. The paprika powder, obtained from a special type of pepper, is one of the most common spices used in typical Hungarian cuisine. Thick, heavy Hungarian sour cream called "tejföl" is often used to soften the dishes' flavour. The famous Hungarian hot river fish soup called Fisherman's soup or "halászlé" is usually a rich mixture of several kinds of poached fish.

Other dishes are chicken paprikash, foie gras made of goose liver, "pörkölt" stew, "vadas", (game stew with vegetable gravy and dumplings), trout with almonds and salty and sweet dumplings, like "túrós csusza", (dumplings with fresh quark cheese and thick sour cream). Desserts include the iconic Dobos Cake, strudels ("rétes"), filled with apple, cherry, poppy seed or cheese, Gundel pancake, plum dumplings ("szilvás gombóc"), "somlói" dumplings, dessert soups like chilled sour cherry soup and sweet chestnut puree, "gesztenyepüré" (cooked chestnuts mashed with sugar and rum and split into crumbs, topped with whipped cream). "Perec" and "kifli" are widely popular pastries.

The "csárda" is the most distinctive type of Hungarian inn, an old-style tavern offering traditional cuisine and beverages. "Borozó" usually denotes a cozy old-fashioned wine tavern, "pince" is a beer or wine cellar and a "söröző" is a pub offering draught beer and sometimes meals. The "bisztró" is an inexpensive restaurant often with self-service. The "büfé" is the cheapest place, although one may have to eat standing at a counter. Pastries, cakes and coffee are served at the confectionery called "cukrászda", while an "eszpresszó" is a café.

Pálinka: is a fruit brandy, distilled from fruit grown in the orchards situated on the Great Hungarian Plain. It is a spirit native to Hungary and comes in a variety of flavours including apricot ("barack") and cherry ("cseresznye"). However, plum ("szilva") is the most popular flavour. Beer: Beer goes well with many traditional Hungarian dishes. The five main Hungarian brands are: Borsodi, Soproni, Arany Ászok, Kõbányai, and Dreher.

Wine: As Hugh Johnson says in "The History of Wine", the territory of Hungary is ideal for wine-making. Since the fall of communism there has been a renaissance in Hungarian wine-making. The choice of quality wine is widening from year to year. The country can be divided to six wine regions: North-Transdanubia, Lake Balaton, South-Pannónia, Duna-region or Alföld, Upper-Hungary and Tokaj-Hegyalja.

Hungarian wine regions offer a great variety of styles: the main products of the country are elegant and full-bodied dry whites with good acidity, although complex sweet whites (Tokaj), elegant (Eger) and full-bodied robust reds (Villány and Szekszárd). The main varieties are: Olaszrizling, Hárslevelű, Furmint, Pinot gris or Szürkebarát, Chardonnay (whites), Kékfrankos (or Blaufrankisch in German), Kadarka, Portugieser, Zweigelt, Cabernet sauvignon, Cabernet franc and Merlot. The most famous wines from Hungary are Tokaji Aszú and Egri Bikavér. Tokaji, meaning "of Tokaj", or "from Tokaj" in Hungarian, is used to label wines from the wine region of Tokaj-Hegyalja. Tokaji wine has received accolades from numerous great writers and composers including Beethoven, Liszt, Schubert and Goethe; Joseph Haydn's favorite wine was a Tokaji. Louis XV and Frederick the Great tried to outdo one another when they entertained guests with Tokaji. Napoleon III, the last Emperor of France, ordered 30–40 barrels of Tokaji at the French Royal Court every year. Gustav III, King of Sweden, loved Tokaji. In Russia, customers included Peter the Great and Empress Elizabeth, while Catherine the Great actually established a Russian garrison in the town of Tokaj with the aim of assuring regular wine deliveries to St. Petersburg.

For over 150 years, a blend of 40 Hungarian herbs has been used to create the liqueur Unicum. Unicum is a bitter, dark-coloured liqueur that can be drunk as an apéritif or after a meal, thus helping the digestion.

Hungary is a land of thermal water. A passion for spa culture and Hungarian history have been connected from the very beginning. Hungarian spas feature Roman, Greek, Turkish, and northern country architectural elements.

Because of an advantageous geographical location, good quality thermal water can be found in great quantities on over 80% of Hungary's territory. Approximately 1,500 thermal springs can be found in Hungary (more than 100 just in the Capital area). There are approximately 450 public baths in Hungary.

The Romans heralded the first age of spas in Hungary. The remains of their bath complexes are still to be seen in Óbuda. Spa culture was revived during the Turkish Invasion and the thermal springs of Buda were used for the construction of a number of bathhouses, some of which such as (Király Baths, Rudas Baths) are still functioning.

In the 19th century, the advancement in deep drilling and medical science provided the springboard for a further leap in bathing culture. Grand spas such as Gellért Baths, Lukács Baths, Margaret Island, and Széchenyi Medicinal Bath are a reflection of this resurgence in popularity. The Széchenyi Thermal Bath is the largest spa complex in Europe and it was the first thermal bath built in the Pest side of Budapest. This building is a noted example of modern Renaissance Style. Located on the Buda side of Budapest, the Gellért spa is the most famous and luxurious thermal complex of the capital city.

Ugrós (Jumping dances): Old style dances dating back to the Middle Ages.
Solo or couple dances accompanied by old style music, shepherd and other solo man's dances from Transylvania, and marching dances along with remnants of medieval weapon dances belong in this group.

Karikázó: a circle dance performed by women only accompanied by singing of folksongs.

Csárdás: New style dances developed in the 18–19th centuries is the Hungarian name for the national dances, with Hungarian embroidered costumes and energetic music. From the men's intricate bootslapping dances to the ancient women's circle dances, Csárdás demonstrates the infectious exuberance of the Hungarian folk dancing still celebrated in the villages.

Verbunkos: a solo man's dance evolved from the recruiting performances of the Austro-Hungarian army.

The Legényes is a men's solo dance done by the ethnic Hungarian people living in the Kalotaszeg region of Transylvania. Although usually danced by young men, it can be also danced by older men. The dance is generally performed freestyle by one dancer at a time in front of a band. Women participate in the dance by standing in lines to the side, and singing or shouting verses while the men dance. Each man performs a number of points (dance phrases), typically four to eight without repetition. Each point consists of four parts, each lasting four counts. The first part is usually the same for everyone (there are only a few variations).

It was in the beginning of the 18th-century that the present style of Hungarian folk art took shape, incorporating both Renaissance and Baroque elements, depending on the area, as well as Persian Sassanide influences. Flowers and leaves, sometimes a bird or a spiral ornament, are the principal decorative themes. The most frequent ornament is a flower with a centerpiece resembling the eye of a peacock's feather.

Nearly all the manifestations of folk art practiced elsewhere in Europe also flourished among the Magyar peasantry at one time or another, their ceramics and textile being the most highly developed of all.

The finest achievements in their textile arts are the embroideries which vary from region to region. Those of Kalotaszeg in Transylvania are charming products of Oriental design, sewn chiefly in a single color – red, blue, or black. Soft in line, the embroideries are applied on altar cloths, pillow-cases and sheets.

In Hungary proper, Sárköz in Transdanubia and the Matyóföld in the Great Hungarian Plain produce the finest embroideries. In the Sárköz region the women's caps show black and white designs as delicate as lace, and give evidence of the people's wonderfully subtle artistic feeling. The embroidery motifs applied to women's wear have also been transposed to tablecloths and runners suitable for modern use as wall decorations.

These vessels, made of black clay, reflect more than three hundred years of traditional Transdanubian folk patterns and shapes. No two are precisely alike, since all work is done by hand, including both the shaping and the decorating. The imprints are made by the thumb or a finger of the ceramist who makes the piece.

Founded in 1826, Herend Porcelain is one of the world's largest ceramic factories, specializing in luxury hand painted and gilded porcelain. In the mid-19th century it was purveyor to the Habsburg Dynasty and aristocratic customers throughout Europe. Many of its classic patterns are still in production. After the fall of communism in Hungary, the factory was privatised and is now 75% owned by its management and workers, exporting to over 60 countries of the world.

Zsolnay Porcelain Manufacture is a Hungarian manufacturer of porcelain, pottery, ceramics, tiles and stoneware. The company introduced the eosin glazing process and pyrogranite ceramics.
The Zsolnay factory was established by Miklós Zsolnay in Pécs, Hungary, to produce stoneware and ceramics in 1853. In 1863, his son, Vilmos Zsolnay (1828–1900) joined the company and became its manager and director after several years. He led the factory to worldwide recognition by demonstrating its innovative products at world fairs and international exhibitions, including the 1873 World Fair in Vienna, then at the 1878 World Fair in Paris, where Zsolnay received a Grand Prix.

Hungarian athletes have been successful contenders in the Olympic Games, only ten countries have won more Olympic medals than Hungary, with a total of 498 medals ranking eighth in an all-time Olympic Games medal count. Hungary has the third-highest number of Olympic medals per capita and second-highest number of gold medals per capita in the world. Hungary has historically excelled in Olympic water sports. In water polo the Hungarian team is the leading medal winner by a significant margin and in swimming Hungarian men are fourth most successful overall, while the women are eighth most successful overall. They have also seen success in canoeing and kayaking they are the third most successful overall.

In 2015 the Assembly of the Hungarian Olympic Committee and the Assembly of Budapest decided to bid for the 2024 Summer Olympics but eventually awarded to Paris. Budapest has also lost several bids to host the games, in 1916, 1920, 1936, 1944, and 1960 to Berlin, Antwerp, London, and Rome, respectively.

Hungary hosted many global sport event in the past, among others the 1997 World Amateur Boxing Championships, 2000 World Fencing Championships, 2001 World Allround Speed Skating Championships, 2008 World Interuniversity Games, 2008 World Modern Pentathlon Championships, 2010 ITU World Championship Series, 2011 IIHF World Championship, 2013 World Fencing Championships, 2013 World Wrestling Championships, 2014 World Masters Athletics Championships, 2017 World Aquatics Championships and 2017 World Judo Championships, only in the last two decade. Besides these, Hungary was the home of many European-level tournaments, like 2006 European Aquatics Championships, 2010 European Aquatics Championships, 2013 European Judo Championships, 2013 European Karate Championships and will be the host of 4 matches in the UEFA Euro 2020, which will be held in the 67,889-seat new multi-purpose Puskás Ferenc Stadium.

The Hungarian Grand Prix in Formula One has been held at the Hungaroring just outside Budapest, which circuit has FIA Grade 1 license. Since 1986, the race has been a round of the FIA Formula One World Championship. At the 2013 Hungarian Grand Prix, it was confirmed that Hungary will continue to host a Formula 1 race until 2021. The track was completely resurfaced for the first time in early 2016, and it was announced the Grand Prix's deal was extended for a further 5 years, until 2026.

Chess is also a popular and successful sport in Hungary, the Hungarian players are the 10th most powerful overall on the ranking of World Chess Federation. There are about 54 Grandmasters and 118 International Masters in Hungary, which is more than in France or United Kingdom. World top junior player is the Hungarian Richárd Rapport currently on the FIDE World Rankings, while Judit Polgár generally considered the strongest female chess player of all time. Some of the world's best sabre athletes have historically also hailed from Hungary, and in 2009, the Hungarian national ice hockey team qualified for their first IIHF World Championship, in 2015, they qualified for their second World Championship in the top division.

Hungary has won its first gold medal in Winter Olympics in 2018 in mens short track speed skating with a team of four: Csaba Burján, Sándor Liu, Shaoang Liu, Viktor Knoch.

Hungary has won three Olympic football titles, finished runners-up in the 1938 and 1954 FIFA World Cups, and third in the 1964 UEFA European Football Championship. Hungary revolutionized the sport in the 1950s, laying the tactical fundamentals of total football and dominating international football with the "Aranycsapat" ("Golden Team"), which included Ferenc Puskás, top goalscorer of the 20th century, to whom FIFA dedicated its newest award, the Puskás Award. The side of that era has the second all-time highest Football Elo Ranking in the world, with 2166, and one of the longest undefeated runs in football history, remaining unbeaten in 31 games spanning more than four years.

The post-golden age decades saw a gradually weakening Hungary, though recently there is renewal in all aspects. The Hungarian Children's Football Federation was founded in 2008, as youth development thrives. For the first time in Hungarian football's history, they hosted the 2010 UEFA Futsal Championship in Budapest and Debrecen, the first time the MLSZ staged a UEFA finals tournament. Also, the national teams have produced some surprise successes such as beating Euro 2004 winner Greece 3–2 and 2006 FIFA World Cup winner Italy 3–1. During UEFA Euro 2016 Hungary won Group F and were eventually defeated in the round of 16.




</doc>
<doc id="13276" url="https://en.wikipedia.org/wiki?curid=13276" title="Historiography">
Historiography

Historiography is the study of the methods of historians in developing history as an academic discipline, and by extension is any body of historical work on a particular subject. The historiography of a specific topic covers how historians have studied that topic using particular sources, techniques, and theoretical approaches. Scholars discuss historiography by topic – such as the "historiography of the United Kingdom", the "historiography of Canada", "historiography of the British Empire", the "historiography of early Islam", the "historiography of China" – and different approaches and genres, such as political history and social history. Beginning in the nineteenth century, with the ascent of academic history, there developed a body of historiographic literature. The extent to which historians are influenced by their own groups and loyalties – such as to their nation state – is a debated question.

The research interests of historians change over time, and there has been a shift away from traditional diplomatic, economic, and political history toward newer approaches, especially social and cultural studies. From 1975 to 1995, the proportion of professors of history in American universities identifying with social history increased from 31 to 41 percent, while the proportion of political historians decreased from 40 to 30 percent. In 2007, of 5,723 faculty in the departments of history at British universities, 1,644 (29%) identified themselves with social history and 1,425 (25%) identified themselves with political history.

In the early modern period, the term "historiography" meant "the writing of history", and "historiographer" meant "historian". In that sense certain official historians were given the title "Historiographer Royal" in Sweden (from 1618), England (from 1660), and Scotland (from 1681). The Scottish post is still in existence.

Historiography was more recently defined as "the study of the way history has been and is written – the history of historical writing", which means that, "When you study 'historiography' you do not study the events of the past directly, but the changing interpretations of those events in the works of individual historians."

Understanding the past appears to be a universal human need, and the "telling of history" has emerged independently in civilisations around the world. 
What constitutes history is a philosophical question (see philosophy of history).

The earliest chronologies date back to Mesopotamia and ancient Egypt, though no historical writers in these early civilizations were known by name. 
By contrast, the term "historiography" is taken to refer to written history recorded in a narrative format for the purpose of informing future generations about events. In this limited sense, "ancient history" begins with the early historiography of Classical Antiquity, in about the 5th century BCE.

In China, the "Zuo Zhuan", attributed to Zuo Qiuming in the , is the earliest written of narrative history in the world and covers the period from . The "Classic of History" is one of the Five Classics of Chinese classic texts and one of the earliest narratives of China. The "Spring and Autumn Annals", the official chronicle of the State of Lu covering the period from , is among the earliest surviving historical texts to be arranged on annalistic principles in the world. It is traditionally attributed to Confucius (551–479 BCE). "Zhan Guo Ce" was a renowned ancient Chinese historical compilation of sporadic materials on the Warring States period compiled between the .

Sima Qian (around ) was the first in China to lay the groundwork for professional historical writing. His written work was the "Shiji" ("Records of the Grand Historian"), a monumental lifelong achievement in literature. Its scope extends as far back as the , and it includes many treatises on specific subjects and individual biographies of prominent people, and also explores the lives and deeds of commoners, both contemporary and those of previous eras. His work influenced every subsequent author of history in China, including the prestigious Ban family of the Eastern Han Dynasty era.

Traditional Chinese historiography describes history in terms of dynastic cycles. In this view, each new dynasty is founded by a morally righteous founder. Over time, the dynasty becomes morally corrupt and dissolute. Eventually, the dynasty becomes so weak as to allow its replacement by a new dynasty.

The earliest works of history produced in Japan were the "Rikkokushi", a corpus of six national histories covering the history of Japan from its mythological beginnings until the 9th century. The first of these works were the "Nihon Shoki", compiled by Prince Toneri in 720.

The tradition of Korean historiography was established with the "Samguk Sagi", a history of Korea from its allegedly earliest times. It was compiled by Goryeo court historian Kim Busik after its commission by King Injong of Goryeo (r. 1122 – 1146). It was completed in 1145 and relied not only on earlier Chinese histories for source material, but also on the "Hwarang Segi" written by the Silla historian Kim Daemun in the 8th century. The latter work is now lost.

The earliest known systematic historical thought emerged in ancient Greece, a development which would be an important influence on the writing of history elsewhere around the Mediterranean region. Greek historians greatly contributed to the development of historical methodology. The earliest known critical historical works were "The Histories", composed by Herodotus of Halicarnassus (484–425 BCE) who became known as the "father of history". Herodotus attempted to distinguish between more and less reliable accounts, and personally conducted research by travelling extensively, giving written accounts of various Mediterranean cultures. Although Herodotus' overall emphasis lay on the actions and characters of men, he also attributed an important role to divinity in the determination of historical events.

The generation following Herodotus witnessed a spate of local histories of the individual city-states ("poleis"), written by the first of the local historians who employed the written archives of city and sanctuary. Dionysius of Halicarnassus characterized these historians as the forerunners of Thucydides, and these local histories continued to be written into Late Antiquity, as long as the city-states survived. Two early figures stand out: Hippias of Elis, who produced the lists of winners in the Olympic Games that provided the basic chronological framework as long as the pagan classical tradition lasted, and Hellanicus of Lesbos, who compiled more than two dozen histories from civic records, all of them now lost.

Thucydides largely eliminated divine causality in his account of the war between Athens and Sparta, establishing a rationalistic element which set a precedent for subsequent Western historical writings. He was also the first to distinguish between cause and immediate origins of an event, while his successor Xenophon ( – ) introduced autobiographical elements and character studies in his "Anabasis".

The proverbial Philippic attacks of the Athenian orator Demosthenes () on Philip II of Macedon marked the height of ancient political agitation. The now lost history of Alexander's campaigns by the diadoch Ptolemy I () may represent the first historical work composed by a ruler. Polybius ( – ) wrote on the rise of Rome to world prominence, and attempted to harmonize the Greek and Roman points of view.

The Chaldean priest Berossus () composed a Greek-language "History of Babylonia" for the Seleucid king Antiochus I, combining Hellenistic methods of historiography and Mesopotamian accounts to form a unique composite. Reports exist of other near-eastern histories, such as that of the Phoenician historian Sanchuniathon; but he is considered semi-legendary and writings attributed to him are fragmentary, known only through the later historians Philo of Byblos and Eusebius, who asserted that he wrote before even the Trojan war.

The Romans adopted the Greek tradition, writing at first in Greek, but eventually chronicling their history in a freshly non-Greek language. While early Roman works were still written in Greek, the "Origines", composed by the Roman statesman Cato the Elder (), was written in Latin, in a conscious effort to counteract Greek cultural influence. It marked the beginning of Latin historical writings. Hailed for its lucid style, Julius Caesar's () "de Bello Gallico" exemplifies autobiographical war coverage. The politician and orator Cicero () introduced rhetorical elements in his political writings.

Strabo ( – ) was an important exponent of the Greco-Roman tradition of combining geography with history, presenting a descriptive history of peoples and places known to his era. Livy ( – ) records the rise of Rome from city-state to empire. His speculation about what would have happened if Alexander the Great had marched against Rome represents the first known instance of alternate history.

Biography, although popular throughout antiquity, was introduced as a branch of history by the works of Plutarch ( – ) and Suetonius ( – after ) who described the deeds and characters of ancient personalities, stressing their human side. Tacitus () denounces Roman immorality by praising German virtues, elaborating on the topos of the Noble savage.

Christian historiography began early, perhaps as early as Luke-Acts, which is the primary source for the Apostolic Age, though its historical reliability is disputed. In the first Christian centuries, the New Testament canon was developed. The growth of Christianity and its enhanced status in the Roman Empire after Constantine I (see State church of the Roman Empire) led to the development of a distinct Christian historiography, influenced by both Christian theology and the nature of the Christian Bible, encompassing new areas of study and views of history. The central role of the Bible in Christianity is reflected in the preference of Christian historians for written sources, compared to the classical historians' preference for oral sources and is also reflected in the inclusion of politically unimportant people. Christian historians also focused on development of religion and society. This can be seen in the extensive inclusion of written sources in the "Ecclesiastical History" written by Eusebius of Caesarea around 324 and in the subjects it covers. Christian theology considered time as linear, progressing according to divine plan. As God's plan encompassed everyone, Christian histories in this period had a universal approach. For example, Christian writers often included summaries of important historical events prior to the period covered by the work.

Writing history was popular among Christian monks and clergy in the Middle Ages. They wrote about the history of Jesus Christ, that of the Church and that of their patrons, the dynastic history of the local rulers. In the Early Middle Ages historical writing often took the form of annals or chronicles recording events year by year, but this style tended to hamper the analysis of events and causes. An example of this type of writing is the "Anglo-Saxon Chronicle", which was the work of several different writers: it was started during the reign of Alfred the Great in the late 9th century, but one copy was still being updated in 1154. Some writers in the period did construct a more narrative form of history. These included Gregory of Tours and more successfully Bede, who wrote both secular and ecclesiastical history and who is known for writing the "Ecclesiastical History of the English People".

During the Renaissance, history was written about states or nations. The study of history changed during the Enlightenment and Romanticism. Voltaire described the history of certain ages that he considered important, rather than describing events in chronological order. History became an independent discipline. It was not called "philosophia historiae" anymore, but merely history ("historia").

Muslim historical writings first began to develop in the 7th century, with the reconstruction of the Prophet Muhammad's life in the centuries following his death. With numerous conflicting narratives regarding Muhammad and his companions from various sources, it was necessary to verify which sources were more reliable. In order to evaluate these sources, various methodologies were developed, such as the "science of biography", "science of hadith" and "Isnad" (chain of transmission). These methodologies were later applied to other historical figures in the Islamic civilization. Famous historians in this tradition include Urwah (d. 712), Wahb ibn Munabbih (d. 728), Ibn Ishaq (d. 761), al-Waqidi (745–822), Ibn Hisham (d. 834), Muhammad al-Bukhari (810–870) and Ibn Hajar (1372–1449). Historians of the medieval Islamic world also developed an interest in world history.
Islamic historical writing eventually culminated in the works of the Arab Muslim historian Ibn Khaldun (1332–1406), who published his historiographical studies in the "Muqaddimah" (translated as "Prolegomena") and "Kitab al-I'bar" ("Book of Advice"). His work was forgotten until it was rediscovered in the late 19th century.

During the Age of Enlightenment, the modern development of historiography through the application of scrupulous methods began. Among the many Italians who contributed to this were Leonardo Bruni (c. 1370–1444), Francesco Guicciardini (1483–1540), and Cesare Baronio (1538–1607).

French "philosophe" Voltaire (1694–1778) had an enormous influence on the development of historiography during the Age of Enlightenment through his demonstration of fresh new ways to look at the past. Guillaume de Syon argues:

Voltaire's best-known histories are "The Age of Louis XIV" (1751), and his "Essay on the Customs and the Spirit of the Nations" (1756). He broke from the tradition of narrating diplomatic and military events, and emphasized customs, social history and achievements in the arts and sciences. He was the first scholar to make a serious attempt to write the history of the world, eliminating theological frameworks, and emphasizing economics, culture and political history. Although he repeatedly warned against political bias on the part of the historian, he did not miss many opportunities to expose the intolerance and frauds of the church over the ages. Voltaire advised scholars that anything contradicting the normal course of nature was not to be believed. Although he found evil in the historical record, he fervently believed reason and educating the illiterate masses would lead to progress.

Voltaire explains his view of historiography in his article on "History" in Diderot's "Encyclopédie": ""One demands of modern historians more details, better ascertained facts, precise dates, more attention to customs, laws, mores, commerce, finance, agriculture, population."" Already in 1739 he had written: ""My chief object is not political or military history, it is the history of the arts, of commerce, of civilization – in a word, – of the human mind."" Voltaire's histories used the values of the Enlightenment to evaluate the past. He helped free historiography from antiquarianism, Eurocentrism, religious intolerance and a concentration on great men, diplomacy, and warfare. Peter Gay says Voltaire wrote "very good history", citing his "scrupulous concern for truths", "careful sifting of evidence", "intelligent selection of what is important", "keen sense of drama", and "grasp of the fact that a whole civilization is a unit of study."

At the same time, philosopher David Hume was having a similar effect on the study of history in Great Britain. In 1754 he published the "History of England", a 6-volume work which extended "From the Invasion of Julius Caesar to the Revolution in 1688". Hume adopted a similar scope to Voltaire in his history; as well as the history of Kings, Parliaments, and armies, he examined the history of culture, including literature and science, as well. His short biographies of leading scientists explored the process of scientific change and he developed new ways of seeing scientists in the context of their times by looking at how they interacted with society and each other – he paid special attention to Francis Bacon, Robert Boyle, Isaac Newton and William Harvey.

He also argued that the quest for liberty was the highest standard for judging the past, and concluded that after considerable fluctuation, England at the time of his writing had achieved "the most entire system of liberty, that was ever known amongst mankind."

The apex of Enlightenment history was reached with Edward Gibbon's monumental six-volume work, "The History of the Decline and Fall of the Roman Empire", published on 17 February 1776. Because of its relative objectivity and heavy use of primary sources, its methodology became a model for later historians. This has led to Gibbon being called the first "modern historian". The book sold impressively, earning its author a total of about £9000. Biographer Leslie Stephen wrote that thereafter, "His fame was as rapid as it has been lasting."

Gibbon's work has been praised for its style, its piquant epigrams and its effective irony. Winston Churchill memorably noted, "I set out upon...Gibbon's "Decline and Fall of the Roman Empire" [and] was immediately dominated both by the story and the style... I devoured Gibbon. I rode triumphantly through it from end to end and enjoyed it all." Gibbon was pivotal in the secularizing and 'desanctifying' of history, remarking, for example, on the "want of truth and common sense" of biographies composed by Saint Jerome. Unusually for an 18th-century historian, Gibbon was never content with secondhand accounts when the primary sources were accessible (though most of these were drawn from well-known printed editions). "I have always endeavoured," he says, "to draw from the fountain-head; that my curiosity, as well as a sense of duty, has always urged me to study the originals; and that, if they have sometimes eluded my search, I have carefully marked the secondary evidence, on whose faith a passage or a fact were reduced to depend." In this insistence upon the importance of primary sources, Gibbon broke new ground in the methodical study of history:

In accuracy, thoroughness, lucidity, and comprehensive grasp of a vast subject, the 'History' is unsurpassable. It is the one English history which may be regarded as definitive... Whatever its shortcomings the book is artistically imposing as well as historically unimpeachable as a vast panorama of a great period.

The tumultuous events surrounding the French Revolution inspired much of the historiography and analysis of the early 19th century. Interest in the 1688 Glorious Revolution was also rekindled by the Great Reform Act of 1832 in England.

Thomas Carlyle published his three-volume "", in 1837. The first volume was accidentally burned by John Stuart Mill's maid. Carlyle rewrote it from scratch. Carlyle's style of historical writing stressed the immediacy of action, often using the present tense. He emphasised the role of forces of the spirit in history and thought that chaotic events demanded what he called 'heroes' to take control over the competing forces erupting within society. He considered the dynamic forces of history as being the hopes and aspirations of people that took the form of ideas, and were often ossified into ideologies. Carlyle's "The French Revolution" was written in a highly unorthodox style, far removed from the neutral and detached tone of the tradition of Gibbon. Carlyle presented the history as dramatic events unfolding in the present as though he and the reader were participants on the streets of Paris at the famous events. Carlyle's invented style was epic poetry combined with philosophical treatise. It is rarely read or cited in the last century.

In his main work "Histoire de France" (1855), French historian Jules Michelet (1798–1874) coined the term Renaissance (meaning "rebirth" in French), as a period in Europe's cultural history that represented a break from the Middle Ages, creating a modern understanding of humanity and its place in the world. The 19-volume work covered French history from Charlemagne to the outbreak of the French Revolution. His inquiry into manuscript and printed authorities was most laborious, but his lively imagination, and his strong religious and political prejudices, made him regard all things from a singularly personal point of view.

Michelet was one of the first historians to shift the emphasis of history to the common people, rather than the leaders and institutions of the country. He had a decisive impact on scholars. Gayana Jurkevich argues that led by Michelet:

Hippolyte Taine (1828–1893), although unable to secure an academic position, was the chief theoretical influence of French naturalism, a major proponent of sociological positivism, and one of the first practitioners of historicist criticism. He pioneered the idea of "the milieu" as an active historical force which amalgamated geographical, psychological, and social factors. Historical writing for him was a search for general laws. His brilliant style kept his writing in circulation long after his theoretical approaches were passé.

One of the major progenitors of the history of culture and art, was the Swiss historian Jacob Burckhardt Siegfried Giedion described Burckhardt's achievement in the following terms: "The great discoverer of the age of the Renaissance, he first showed how a period should be treated in its entirety, with regard not only for its painting, sculpture and architecture, but for the social institutions of its daily life as well." 

His most famous work was "The Civilization of the Renaissance in Italy", published in 1860; it was the most influential interpretation of the Italian Renaissance in the nineteenth century and is still widely read. According to John Lukacs, he was the first master of cultural history, which seeks to describe the spirit and the forms of expression of a particular age, a particular people, or a particular place. His innovative approach to historical research stressed the importance of art and its inestimable value as a primary source for the study of history. He was one of the first historians to rise above the narrow nineteenth-century notion that "history is past politics and politics current history.

By the mid-19th century, scholars were beginning to analyse the history of institutional change, particularly the development of constitutional government. William Stubbs's "Constitutional History of England" (3 vols., 1874–78) was an important influence on this developing field. The work traced the development of the English constitution from the Teutonic invasions of Britain until 1485, and marked a distinct step in the advance of English historical learning. He argued that the theory of the unity and continuity of history should not remove distinctions between ancient and modern history. He believed that, though work on ancient history is a useful preparation for the study of modern history, either may advantageously be studied apart. He was a good palaeographer, and excelled in textual criticism, in examination of authorship, and other such matters, while his vast erudition and retentive memory made him second to none in interpretation and exposition.

The modern academic study of history and methods of historiography were pioneered in 19th-century German universities, especially the University of Göttingen. Leopold von Ranke (1795–1886) at Berlin was a pivotal influence in this regard, and was the founder of modern source-based history. According to Caroline Hoefferle, "Ranke was probably the most important historian to shape historical profession as it emerged in Europe and the United States in the late 19th century."

Specifically, he implemented the seminar teaching method in his classroom, and focused on archival research and analysis of historical documents. Beginning with his first book in 1824, the "History of the Latin and Teutonic Peoples from 1494 to 1514", Ranke used an unusually wide variety of sources for a historian of the age, including "memoirs, diaries, personal and formal missives, government documents, diplomatic dispatches and first-hand accounts of eye-witnesses". Over a career that spanned much of the century, Ranke set the standards for much of later historical writing, introducing such ideas as reliance on primary sources, an emphasis on narrative history and especially international politics ("aussenpolitik"). Sources had to be solid, not speculations and rationalizations. His credo was to write history the way it was. He insisted on primary sources with proven authenticity.

Ranke also rejected the 'teleological approach' to history, which traditionally viewed each period as inferior to the period which follows. In Ranke's view, the historian had to understand a period on its own terms, and seek to find only the general ideas which animated every period of history. In 1831 and at the behest of the Prussian government, Ranke founded and edited the first historical journal in the world, called "Historisch-Politische Zeitschrift".

Another important German thinker was Georg Wilhelm Friedrich Hegel, whose theory of historical progress ran counter to Ranke's approach. In Hegel's own words, his philosophical theory of "World history... represents the development of the spirit's consciousness of its own freedom and of the consequent realization of this freedom.". This realization is seen by studying the various cultures that have developed over the millennia, and trying to understand the way that freedom has worked itself out through them:

World history is the record of the spirit's efforts to attain knowledge of what it is in itself. The Orientals do not know that the spirit or man as such are free in themselves. And because they do not know that, they are not themselves free. They only know that One is free... The consciousness of freedom first awoke among the Greeks, and they were accordingly free; but, like the Romans, they only knew that Some, and not all men as such, are free... The Germanic nations, with the rise of Christianity, were the first to realize that All men are by nature free, and that freedom of spirit is his very essence.
Karl Marx introduced the concept of historical materialism into the study of world historical development. In his conception, the economic conditions and dominant modes of production determined the structure of society at that point. In his view five successive stages in the development of material conditions would occur in Western Europe. The first stage was primitive communism where property was shared and there was no concept of "leadership". This progressed to a slave society where the idea of class emerged and the State developed. Feudalism was characterized by an aristocracy working in partnership with a theocracy and the emergence of the Nation-state. Capitalism appeared after the bourgeois revolution when the capitalists (or their merchant predecessors) overthrew the feudal system and established a market economy, with
private property and Parliamentary democracy. Marx then predicted the eventual proletarian revolution that would result in the attainment of socialism, followed by Communism, where property would be communally owned.

Previous historians had focused on cyclical events of the rise and decline of rulers and nations. Process of nationalization of history, as part of national revivals in the 19th century, resulted with separation of "one's own" history from common universal history by such way of perceiving, understanding and treating the past that constructed history as history of a nation. A new discipline, sociology, emerged in the late 19th century and analyzed and compared these perspectives on a larger scale.

Thomas Macaulay produced his most famous work of history, "The History of England from the Accession of James the Second", in 1848. His writings are famous for their ringing prose and for their confident, sometimes dogmatic, emphasis on a progressive model of British history, according to which the country threw off superstition, autocracy and confusion to create a balanced constitution and a forward-looking culture combined with freedom of belief and expression. This model of human progress has been called the Whig interpretation of history.

His legacy continues to be controversial; Gertrude Himmelfarb wrote that "most professional historians have long since given up reading Macaulay, as they have given up writing the kind of history he wrote and thinking about history as he did." However, J. R. Western wrote that: "Despite its age and blemishes, Macaulay's "History of England" has still to be superseded by a full-scale modern history of the period".

The term Whig history, coined by Herbert Butterfield in his short book "The Whig Interpretation of History" in 1931, means the approach to historiography which presents the past as an inevitable progression towards ever greater liberty and enlightenment, culminating in modern forms of liberal democracy and constitutional monarchy. In general, Whig historians emphasized the rise of constitutional government, personal freedoms and scientific progress. The term has been also applied widely in historical disciplines outside of British history (the history of science, for example) to criticize any teleological (or goal-directed), hero-based, and transhistorical narrative.

Paul Rapin de Thoyras's history of England, published in 1723, became "the classic Whig history" for the first half of the 18th century. It was later supplanted by the immensely popular "The History of England" by David Hume. Whig historians emphasized the achievements of the Glorious Revolution of 1688. This included James Mackintosh's "History of the Revolution in England in 1688", William Blackstone's "Commentaries on the Laws of England" and Henry Hallam's "Constitutional History of England".

The most famous exponent of 'Whiggery' was Thomas Babington Macaulay, who published the first volumes of his "The History of England from the Accession of James II" in 1848. It proved an immediate success and replaced Hume's history to become the new orthodoxy. His 'Whiggish convictions' are spelled out in his first chapter:

This consensus was steadily undermined during the post-World War I re-evaluation of European history, and Butterfield's critique exemplified this trend. Intellectuals no longer believed the world was automatically getting better and better. Subsequent generations of academic historians have similarly rejected Whig history because of its presentist and teleological assumption that history is driving toward some sort of goal. Other criticized 'Whig' assumptions included viewing the British system as the apex of human political development, assuming that political figures in the past held current political beliefs (anachronism), considering British history as a march of progress with inevitable outcomes and presenting political figures of the past as heroes, who advanced the cause of this political progress, or villains, who sought to hinder its inevitable triumph. J. Hart says "a Whig interpretation requires human heroes and villains in the story."

20th-century historiography in major countries is characterized by a move to universities and academic research centers. Popular history continued to be written by self-educated amateurs, but scholarly history increasingly became the province of PhD's trained in research seminars at a university. The training emphasized working with primary sources in archives. Seminars taught graduate students how to review the historiography of the topics, so that they could understand the conceptual frameworks currently in use, and the criticisms regarding their strengths and weaknesses. Western Europe and the United States took leading roles in this development. The emergence of area studies of other regions also developed historiographical practices.

The French "Annales" school radically changed the focus of historical research in France during the 20th century by stressing long-term social history, rather than political or diplomatic themes. The school emphasized the use of quantification and the paying of special attention to geography.

The "Annales d'histoire économique et sociale" journal was founded in 1929 in Strasbourg by Marc Bloch and Lucien Febvre. These authors, the former a medieval historian and the latter an early modernist, quickly became associated with the distinctive "Annales" approach, which combined geography, history, and the sociological approaches of the Année Sociologique (many members of which were their colleagues at Strasbourg) to produce an approach which rejected the predominant emphasis on politics, diplomacy and war of many 19th and early 20th-century historians as spearheaded by historians whom Febvre called Les Sorbonnistes. Instead, they pioneered an approach to a study of long-term historical structures ("la longue durée") over events and political transformations. Geography, material culture, and what later Annalistes called "mentalités", or the psychology of the epoch, are also characteristic areas of study. The goal of the "Annales" was to undo the work of the "Sorbonnistes", to turn French historians away from the narrowly political and diplomatic toward the new vistas in social and economic history. For early modern Mexican history, the work of Marc Bloch's student François Chevalier on the formation of landed estates (haciendas) from the sixteenth century to the seventeenth had a major impact on Mexican history and historiography, setting off an important debate about whether landed estates were basically feudal or capitalistic.

An eminent member of this school, Georges Duby, described his approach to history as one that relegated the sensational to the sidelines and was reluctant to give a simple accounting of events, but strived on the contrary to pose and solve problems and, neglecting surface disturbances, to observe the long and medium-term evolution of economy, society and civilisation. The Annalistes, especially Lucien Febvre, advocated a "histoire totale", or "histoire tout court", a complete study of a historical problem.

The second era of the school was led by Fernand Braudel and was very influential throughout the 1960s and 1970s, especially for his work on the Mediterranean region in the era of Philip II of Spain. Braudel developed the idea, often associated with Annalistes, of different modes of historical time: "l'histoire quasi immobile" (motionless history) of historical geography, the history of social, political and economic structures ("la longue durée"), and the history of men and events, in the context of their structures. His 'longue durée' approach stressed slow, and often imperceptible effects of space, climate and technology on the actions of human beings in the past. The "Annales" historians, after living through two world wars and major political upheavals in France, were deeply uncomfortable with the notion that multiple ruptures and discontinuities created history. They preferred to stress slow change and the longue durée. They paid special attention to geography, climate, and demography as long-term factors. They considered the continuities of the deepest structures were central to history, beside which upheavals in institutions or the superstructure of social life were of little significance, for history lies beyond the reach of conscious actors, especially the will of revolutionaries.

Noting the political upheavals in Europe and especially in France in 1968, Eric Hobsbawm argued that "in France the virtual hegemony of Braudelian history and the "Annales" came to an end after 1968, and the international influence of the journal dropped steeply." Multiple responses were attempted by the school. Scholars moved in multiple directions, covering in disconnected fashion the social, economic, and cultural history of different eras and different parts of the globe. By the time of crisis the school was building a vast publishing and research network reaching across France, Europe, and the rest of the world. Influence indeed spread out from Paris, but few new ideas came in. Much emphasis was given to quantitative data, seen as the key to unlocking all of social history. However, the "Annales" ignored the developments in quantitative studies underway in the U.S. and Britain, which reshaped economic, political and demographic research.

Marxist historiography developed as a school of historiography influenced by the chief tenets of Marxism, including the centrality of social class and economic constraints in determining historical outcomes (historical materialism). Friedrich Engels wrote "The Peasant War in Germany", which analysed social warfare in early Protestant Germany in terms of emerging capitalist classes. Although it lacked a rigorous engagement with archival sources, it indicated an early interest in history from below and class analysis, and it attempts a dialectical analysis. Another treatise of Engels, "The Condition of the Working Class in England in 1844", was salient in creating the socialist impetus in British politics from then on, e.g. the Fabian Society.

R. H. Tawney was an early historian working in this tradition. "The Agrarian Problem in the Sixteenth Century" (1912) and "Religion and the Rise of Capitalism" (1926), reflected his ethical concerns and preoccupations in economic history. He was profoundly interested in the issue of the enclosure of land in the English countryside in the sixteenth and seventeenth centuries and in Max Weber's thesis on the connection between the appearance of Protestantism and the rise of capitalism. His belief in the rise of the gentry in the century before the outbreak of the Civil War in England provoked the 'Storm over the Gentry' in which his methods were subjected to severe criticisms by Hugh Trevor-Roper and John Cooper.

Historiography in the Soviet Union was greatly influenced by Marxist historiography, as historical materialism was extended into the Soviet version of dialectical materialism.

A circle of historians inside the Communist Party of Great Britain (CPGB) formed in 1946 and became a highly influential cluster of British Marxist historians, who contributed to history from below and class structure in early capitalist society. While some members of the group (most notably Christopher Hill and E. P. Thompson) left the CPGB after the 1956 Hungarian Revolution, the common points of British Marxist historiography continued in their works. They placed a great emphasis on the subjective determination of history.

Christopher Hill's studies on 17th-century English history were widely acknowledged and recognised as representative of this school. His books include "Puritanism and Revolution" (1958), "Intellectual Origins of the English Revolution" (1965 and revised in 1996), "The Century of Revolution" (1961), "AntiChrist in 17th-century England" (1971), "The World Turned Upside Down" (1972) and many others.

E. P. Thompson pioneered the study of history from below in his work, "The Making of the English Working Class", published in 1963. It focused on the forgotten history of the first working-class political left in the world in the late-18th and early-19th centuries. In his preface to this book, Thompson set out his approach to writing history from below:

Thompson's work was also significant because of the way he defined "class." He argued that class was not a structure, but a relationship that changed over time. He opened the gates for a generation of labor historians, such as David Montgomery and Herbert Gutman, who made similar studies of the American working classes.

Other important Marxist historians included Eric Hobsbawm, C. L. R. James, Raphael Samuel, A. L. Morton and Brian Pearce.

Although Marxist historiography made important contributions to the history of the working class, oppressed nationalities, and the methodology of history from below, its chief problematic aspect was its argument on the nature of history as "determined" or "dialectical"; this can also be stated as the relative importance of subjective and objective factors in creating outcomes. It increasingly fell out of favour in the 1960s and '70s. Geoffrey Elton was important in undermining the case for a Marxist historiography, which he argued was presenting seriously flawed interpretations of the past. In particular, Elton was opposed to the idea that the English Civil War was caused by socioeconomic changes in the 16th and 17th centuries, arguing instead that it was due largely to the incompetence of the Stuart kings.

In dealing with the era of the Second World War, Addison notes that in Britain by the 1990s, labour history was, "in sharp decline", because:

Biography has been a major form of historiography since the days when Plutarch wrote the parallel lives of great Roman and Greek leaders. It is a field especially attractive to nonacademic historians, and often to the spouses or children of famous people, who have access to the trove of letters and documents. Academic historians tend to downplay biography because it pays too little attention to broad social, cultural, political and economic forces, and perhaps too much attention to popular psychology. The ",Great Man" tradition in Britain originated in the multi-volume "Dictionary of National Biography" (which originated in 1882 and issued updates into the 1970s); it continues to this day in the new "Oxford Dictionary of National Biography." In the United States, the "Dictionary of American Biography" was planned in the late 1920s and appeared with numerous supplements into the 1980s. It has now been displaced by the "American National Biography" as well as numerous smaller historical encyclopedias that give thorough coverage to Great Persons. Bookstores do a thriving business in biographies, which sell far more copies than the esoteric monographs based on post-structuralism, cultural, racial or gender history. Michael Holroyd says the last forty years ",may be seen as a golden age of biography" but nevertheless calls it the "shallow end of history." Nicolas Barker argues that ",more and more biographies command an ever larger readership", as he speculates that biography has come "to express the spirit of our age."

Daniel R. Meister argues that:

Marxist historian E. H. Carr developed a controversial theory of history in his 1961 book "What Is History?", which proved to be one of the most influential books ever written on the subject. He presented a middle-of-the-road position between the empirical or (Rankean) view of history and R. G. Collingwood's idealism, and rejected the empirical view of the historian's work being an accretion of "facts" that he or she has at their disposal as nonsense. He maintained that there is such a vast quantity of information that the historian always chooses the "facts" he or she decides to make use of. In Carr's famous example, he claimed that millions had crossed the Rubicon, but only Julius Caesar's crossing in 49 BC is declared noteworthy by historians. For this reason, Carr argued that Leopold von Ranke's famous dictum "wie es eigentlich gewesen" (show what actually happened) was wrong because it presumed that the "facts" influenced what the historian wrote, rather than the historian choosing what "facts of the past" he or she intended to turn into "historical facts". At the same time, Carr argued that the study of the facts may lead the historian to change his or her views. In this way, Carr argued that history was "an unending dialogue between the past and present".

Carr is held by some critics to have had a deterministic outlook in history. Others have modified or rejected this use of the label "determinist". He took a hostile view of those historians who stress the workings of chance and contingency in the workings of history. In Carr's view, no individual is truly free of the social environment in which they live, but contended that within those limitations, there was room, albeit very narrow room for people to make decisions that affect history. Carr emphatically contended that history was a social science, not an art, because historians like scientists seek generalizations that helped to broaden the understanding of one's subject.

One of Carr's most forthright critics was Hugh Trevor-Roper, who argued that Carr's dismissal of the "might-have-beens of history" reflected a fundamental lack of interest in examining historical causation. Trevor-Roper asserted that examining possible alternative outcomes of history was far from being a "parlour-game" was rather an essential part of the historians' work, as only by considering all possible outcomes of a given situation could a historian properly understand the period.

The controversy inspired Sir Geoffrey Elton to write his 1967 book "The Practice of History". Elton criticized Carr for his "whimsical" distinction between the "historical facts" and the "facts of the past", arguing that it reflected "...an extraordinarily arrogant attitude both to the past and to the place of the historian studying it". Elton, instead, strongly defended the traditional methods of history and was also appalled by the inroads made by postmodernism. Elton saw the duty of historians as empirically gathering evidence and objectively analyzing what the evidence has to say. As a traditionalist, he placed great emphasis on the role of individuals in history instead of abstract, impersonal forces. Elton saw political history as the highest kind of history. Elton had no use for those who seek history to make myths, to create laws to explain the past, or to produce theories such as Marxism.

Classical and European history was part of the 19th-century grammar curriculum. American history became a topic later in the 19th century.

In the historiography of the United States, there were a series of major approaches in the 20th century. In 2009–2012, there were an average of 16,000 new academic history books published in the U.S. every year.

From 1910 to the 1940s, "Progressive" historiography was dominant, especially in political studies. It stressed the central importance of class conflict in American history. Important leaders included Vernon L. Parrington, Carl L. Becker, Arthur M. Schlesinger, Sr., John Hicks, and C. Vann Woodward. The movement established a strong base at the History Department at the University of Wisconsin with Curtis Nettels, William Hesseltine, Merle Curti, Howard K. Beale, Merrill Jensen, Fred Harvey Harrington (who became the university president), William Appleman Williams, and a host of graduate students. Charles A. Beard was the most prominent representative with his "Beardian" approach that reached both scholars and the general public.

In covering the Civil War, Charles and Mary Beard did not find it useful to examine nationalism, unionism, states' rights, slavery, abolition or the motivations of soldiers in battle. Instead, they proclaimed it was a:

Arthur Schlesinger, Jr. wrote the "Age of Jackson" (1945), one of the last major books from this viewpoint. Schlesinger made Jackson a hero for his successful attacks on the Second Bank of the United States. His own views were clear enough: "Moved typically by personal and class, rarely by public, considerations, the business community has invariably brought national affairs to a state of crisis and exasperated the rest of society into dissatisfaction bordering on revolt."

Consensus history emphasizes the basic unity of American values and downplays conflict as superficial. It was especially attractive in the 1950s and 1960s. Prominent leaders included Richard Hofstadter, Louis Hartz, Daniel Boorstin, Allan Nevins, Clinton Rossiter, Edmund Morgan, and David M. Potter. In 1948 Hofstadter made a compelling statement of the consensus model of the U.S. political tradition:
Consensus history was rejected by New Left viewpoints that attracted a younger generation of radical historians in the 1960s. These viewpoints stress conflict and emphasize the central roles of class, race and gender. The history of dissent, and the experiences of racial minorities and disadvantaged classes was central to the narratives produced by New Left historians.

Social history, sometimes called the "new social history", is a broad branch that studies the experiences of ordinary people in the past. It had major growth as a field in the 1960s and 1970s, and still is well represented in history departments. However, after 1980 the "cultural turn" directed the next generation to new topics. In the two decades from 1975 to 1995, the proportion of professors of history in U.S. universities identifying with social history rose from 31% to 41%, while the proportion of political historians fell from 40% to 30%.

The growth was enabled by the social sciences, computers, statistics, new data sources such as individual census information, and summer training programs at the Newberry Library and the University of Michigan. The New Political History saw the application of social history methods to politics, as the focus shifted from politicians and legislation to voters and elections.

The Social Science History Association was formed in 1976 as an interdisciplinary group with a journal "Social Science History" and an annual convention. The goal was to incorporate in historical studies perspectives from all the social sciences, especially political science, sociology and economics. The pioneers shared a commitment to quantification. However, by the 1980s the first blush of quantification had worn off, as traditional historians counterattacked. Harvey J. Graff says:
Meanwhile, quantitative history became well-established in other disciplines, especially economics (where they called it "cliometrics"), as well as in political science. In history, however, quantification remained central to demographic studies, but slipped behind in political and social history as traditional narrative approaches made a comeback.

Latin America is the former Spanish American empire in the Western Hemisphere plus Portuguese Brazil. Professional historians pioneered the creation of this field, starting in the late nineteenth century. The term “Latin America” did not come into general usage until the twentieth century and in some cases it was rejected. The historiography of the field has been more fragmented than unified, with historians of Spanish America and Brazil generally remaining in separate spheres. Another standard division within the historiography is the temporal factor, with works falling into either the early modern period (or “colonial era”) or the post-independence (or “national”) period, from the early nineteenth onward. Relatively few works span the two eras and few works except textbooks unite Spanish America and Brazil. There is a tendency to focus on histories of particular countries or regions (the Andes, the Southern Cone, the Caribbean) with relatively little comparative work.

Historians of Latin America have contributed to various types of historical writing, but one major, innovative development in Spanish American history is the emergence of ethnohistory, the history of indigenous peoples, especially in Mexico based on alphabetic sources in Spanish or in indigenous languages.

For the early modern period, the emergence of Atlantic history, based on comparisons and linkages of Europe, the Americas, and Africa from 1450–1850 that developed as a field in its own right has integrated early modern Latin American history into a larger framework. For all periods, global or world history have focused on the connections between areas, likewise integrating Latin America into a larger perspective. Latin America's importance to world history is notable but often overlooked. “Latin America’s central, and sometimes pioneering, role in the development of globalization and modernity did not cease with the end of colonial rule and the early modern period. Indeed, the region’s political independence places it at the forefront of two trends that are regularly considered thresholds of the modern world. The first is the so-called liberal revolution, the shift from monarchies of the ancien régime, where inheritance legitimated political power, to constitutional republics... The second, and related, trend consistently considered a threshold of modern history that saw Latin America in the forefront is the development of nation-states.”

Historical research appears in a number of specialized journals. These include "Hispanic American Historical Review" (est. 1918), published by the Conference on Latin American History; "The Americas", (est. 1944); "Journal of Latin American Studies" (1969); "Canadian Journal of Latin American and Caribbean Studies",( est.1976) "Bulletin of Latin American Research", (est. 1981); "Colonial Latin American Review" (1992); and "Colonial Latin American Historical Review" (est. 1992). "Latin American Research Review" (est. 1969), published by the Latin American Studies Association, does not focus primarily on history, but it has often published historiographical essays on particular topics. 

General works on Latin American history have appeared since the 1950s, when the teaching of Latin American history expanded in U.S. universities and colleges. Most attempt full coverage of Spanish America and Brazil from the conquest to the modern era, focusing on institutional, political, social and economic history. An important, eleven volume treatment of Latin American history is "The Cambridge History of Latin America", with separate volumes on the colonial era, nineteenth century, and the twentieth century. There is a small number of general works that have gone through multiple editions. Major trade publishers have also issued edited volumes on Latin American history and historiography. Reference works include the Handbook of Latin American Studies, which publishes articles by area experts, with annotated bibliographic entries, and the "Encyclopedia of Latin American History and Culture".

World history, as a distinct field of historical study, emerged as an independent academic field in the 1980s. It focused on the examination of history from a global perspective and looked for common patterns that emerged across all cultures. The basic thematic approach of this field was to analyse two major focal points: integration – (how processes of world history have drawn people of the world together), and difference – (how patterns of world history reveal the diversity of the human experience).

Arnold J. Toynbee's ten-volume "A Study of History", took an approach that was widely discussed in the 1930s and 1940s. By the 1960s his work was virtually ignored by scholars and the general public. He compared 26 independent civilizations and argued that they displayed striking parallels in their origin, growth, and decay. He proposed a universal model to each of these civilizations, detailing the stages through which they all pass: genesis, growth, time of troubles, universal state, and disintegration. The later volumes gave too much emphasis on spirituality to satisfy critics. 

Chicago historian William H. McNeill wrote "The Rise of the West" (1965) to show how the separate civilizations of Eurasia interacted from the very beginning of their history, borrowing critical skills from one another, and thus precipitating still further change as adjustment between traditional old and borrowed new knowledge and practice became necessary. He then discusses the dramatic effect of Western civilization on others in the past 500 years of history. McNeill took a broad approach organized around the interactions of peoples across the globe. Such interactions have become both more numerous and more continual and substantial in recent times. Before about 1500, the network of communication between cultures was that of Eurasia. The term for these areas of interaction differ from one world historian to another and include "world-system" and "ecumene." His emphasis on cultural fusions influenced historical theory significantly.

The "cultural turn" of the 1980s and 1990s affected scholars in most areas of history. Inspired largely by anthropology, it turned away from leaders, ordinary people and famous events to look at the use of language and cultural symbols to represent the changing values of society.

The British historian Peter Burke finds that cultural studies has numerous spinoffs, or topical themes it has strongly influenced. The most important include gender studies and postcolonial studies, as well as memory studies, and film studies.

Diplomatic historian Melvyn P. Leffler finds that the problem with the "cultural turn" is that the culture concept is imprecise, and may produce excessively broad interpretations, because it:
Memory studies is a new field, focused on how nations and groups (and historians) construct and select their memories of the past in order to celebrate (or denounce) key features, thus making a statement of their current values and beliefs. Historians have played a central role in shaping the memories of the past as their work is diffused through popular history books and school textbooks. French sociologist Maurice Halbwachs, opened the field with "La mémoire collective" (Paris: 1950).

Many historians examine the how the memory of the past has been constructed, memorialized or distorted. Historians examine how legends are invented. For example, there are numerous studies of the memory of atrocities from World War II, notably the Holocaust in Europe and Japanese behavior in Asia. British historian Heather Jones argues that the historiography of the First World War in recent years has been reinvigorated by the cultural turn. Scholars have raised entirely new questions regarding military occupation, radicalization of politics, race, and the male body.

Representative of recent scholarship is a collection of studies on the "Dynamics of Memory and Identity in Contemporary Europe" SAGE has published the scholarly journal "Memory Studies" since 2008, and the book series ‘Memory Studies’ was launched by Palgrave Macmillan in 2010 with 5–10 titles a year.

The historical journal, a forum where academic historians could exchange ideas and publish newly discovered information, came into being in the 19th century. The early journals were similar to those for the physical sciences, and were seen as a means for history to become more professional. Journals also helped historians to establish various historiographical approaches, the most notable example of which was "Annales. Économies, sociétés, civilisations", a publication of the "Annales" school in France. Journals now typically have one or more editors and associate editors, an editorial board, and a pool of scholars to whom articles that are submitted are sent for confidential evaluation. The editors will send out new books to recognized scholars for reviews that usually run 500 to 1000 words. The vetting and publication process often takes months or longer. Publication in a prestigious journal (which accept 10% or fewer of the articles submitted) is an asset in the academic hiring and promotion process. Publication demonstrates that the author is conversant with the scholarly field. Page charges and fees for publication are uncommon in history. Journals are subsidized by universities or historical societies, scholarly associations, and subscription fees from libraries and scholars. Increasingly they are available through library pools that allow many academic institutions to pool subscriptions to online versions. Most libraries have a system for obtaining specific articles through inter-library loan.


According to Lawrence Stone, narrative has traditionally been the main rhetorical device used by historians. In 1979, at a time when the new Social History was demanding a social-science model of analysis, Stone detected a move back toward the narrative. Stone defined narrative as follows: it is organized chronologically; it is focused on a single coherent story; it is descriptive rather than analytical; it is concerned with people not abstract circumstances; and it deals with the particular and specific rather than the collective and statistical. He reported that, "More and more of the 'new historians' are now trying to discover what was going on inside people's heads in the past, and what it was like to live in the past, questions which inevitably lead back to the use of narrative."

Historians committed to a social science approach, however, have criticized the narrowness of narrative and its preference for anecdote over analysis, and its use of clever examples rather than statistically verified empirical regularities.

Some of the common topics in historiography are:

How a historian approaches historical events is one of the most important decisions within historiography. It is commonly recognised by historians that, in themselves, individual historical facts dealing with names, dates and places are not particularly meaningful. Such facts will only become useful when assembled with other historical evidence, and the process of assembling this evidence is understood as a particular historiographical approach.

The most influential historiographical approaches are:


Important related fields include:




















</doc>
<doc id="13277" url="https://en.wikipedia.org/wiki?curid=13277" title="Holy Roman Empire">
Holy Roman Empire

The Holy Roman Empire (; ) was a multi-ethnic complex of territories in central Europe that developed during the Early Middle Ages and continued until its dissolution in 1806. The largest territory of the empire after 962 was the Kingdom of Germany, though it also came to include the Kingdom of Bohemia, the Kingdom of Burgundy, the Kingdom of Italy, and numerous other territories.

On 25 December 800, Pope Leo III crowned the Frankish king Charlemagne as Emperor, reviving the title in Western Europe, more than three centuries after the fall of the Western Roman Empire. The title continued in the Carolingian family until 888 and from 896 to 899, after which it was contested by the rulers of Italy in a series of civil wars until the death of the last Italian claimant, Berengar, in 924.

The title was revived in 962 when Otto I was crowned emperor, fashioning himself as the successor of Charlemagne and beginning a continuous existence of the empire for over eight centuries. Some historians refer to the coronation of Charlemagne as the origin of the empire, while others prefer the coronation of Otto I as its beginning. Scholars generally concur, however, in relating an evolution of the institutions and principles constituting the empire, describing a gradual assumption of the imperial title and role.

The precise term "Holy Roman Empire" was not used until the 13th century, but the concept of "translatio imperii", the notion that he – the sovereign ruler – held supreme power inherited from the emperors of Rome, was fundamental to the prestige of the emperor. The office of Holy Roman Emperor was traditionally elective, although frequently controlled by dynasties. The mostly German prince-electors, the highest-ranking noblemen of the empire, usually elected one of their peers as "King of the Romans", and he would later be crowned emperor by the Pope; the tradition of papal coronations was discontinued in the 16th century. The empire never achieved the extent of political unification formed in France, evolving instead into a decentralized, limited elective monarchy composed of hundreds of sub-units: kingdoms, principalities, duchies, counties, Free Imperial Cities, and other domains. The power of the emperor was limited, and while the various princes, lords, bishops, and cities of the empire were vassals who owed the emperor their allegiance, they also possessed an extent of privileges that gave them "de facto" independence within their territories. Emperor Francis II dissolved the empire on 6 August 1806, after the creation of the Confederation of the Rhine by Napoleon.

In various languages the Holy Roman Empire was known as: , , (before Otto I), (by Otto I), , , , (before Otto I), (by Otto I). Before 1157, the realm was merely referred to as the Roman Empire. The term "sacrum" ("holy", in the sense of "consecrated") in connection with the medieval Roman Empire was used beginning in 1157 under Frederick I Barbarossa ("Holy Empire"): the term was added to reflect Frederick's ambition to dominate Italy and the Papacy. The form "Holy Roman Empire" is attested from 1254 onward.

In a decree following the 1512 Diet of Cologne, the name was changed to the Holy Roman Empire of the German Nation (, ), a form first used in a document in 1474. The new title was adopted partly because the Empire had lost most of its Italian and Burgundian (Kingdom of Arles) territories by the late 15th century, but also to emphasize the new importance of the German Imperial Estates in ruling the Empire due to the Imperial Reform. By the end of the 18th century, the term "Holy Roman Empire of the German Nation" had fallen out of official use. Besides, contradicting the traditional view concerning that designation, Hermann Weisert has stated in a study on imperial titulature that, despite the claim of many textbooks, the name "Holy Roman Empire of the German Nation" never had an official status and points out that documents were thirty times as likely to omit the national suffix as include it.

In a famous assessment of the name, Voltaire remarked sardonically: "This agglomeration which was called and which still calls itself the Holy Roman Empire was in no way holy, nor Roman, nor an empire."

As Roman power in Gaul declined during the 5th century, local Germanic tribes assumed control. In the late 5th and early 6th centuries, the Merovingians, under Clovis I and his successors, consolidated Frankish tribes and extended hegemony over others to gain control of northern Gaul and the middle Rhine river valley region. By the middle of the 8th century, however, the Merovingians had been reduced to figureheads, and the Carolingians, led by Charles Martel, had become the "de facto" rulers. In 751, Martel’s son Pepin became King of the Franks, and later gained the sanction of the Pope. The Carolingians would maintain a close alliance with the Papacy.

In 768 Pepin’s son Charlemagne became King of the Franks and began an extensive expansion of the realm. He eventually incorporated the territories of present-day France, Germany, northern Italy, and beyond, linking the Frankish kingdom with Papal lands. 

In 797, the Eastern Roman Emperor Constantine VI was removed from the throne by his mother Irene who declared herself Empress. As the Church regarded a male Roman Emperor as the head of Christendom, Pope Leo III sought a new candidate for the dignity. Charlemagne's good service to the Church in his defense of Papal possessions against the Lombards made him the ideal candidate. On Christmas Day of 800, Pope Leo III crowned Charlemagne emperor, restoring the title in the West for the first time in over three centuries. In 802, Irene was overthrown by Nikephoros I and henceforth there were two Roman Emperors.

After Charlemagne died in 814, the imperial crown passed to his son, Louis the Pious. Upon Louis' death in 840, it passed to his son Lothair, who had been his co-ruler. By this point the territory of Charlemagne had been divided into several territories, and over the course of the later ninth century the title of Emperor was disputed by the Carolingian rulers of Western Francia and Eastern Francia, with first the western king (Charles the Bald) and then the eastern (Charles the Fat), who briefly reunited the Empire, attaining the prize. After the death of Charles the Fat in 888, however, the Carolingian Empire broke apart, and was never restored. According to Regino of Prüm, the parts of the realm "spewed forth kinglets", and each part elected a kinglet "from its own bowels". After the death of Charles the Fat, those crowned emperor by the pope controlled only territories in Italy. The last such emperor was Berengar I of Italy, who died in 924.

Around 900, autonomous stem duchies (Franconia, Bavaria, Swabia, Saxony, and Lotharingia) reemerged in East Francia. After the Carolingian king Louis the Child died without issue in 911, East Francia did not turn to the Carolingian ruler of West Francia to take over the realm but instead elected one of the dukes, Conrad of Franconia, as "Rex Francorum Orientalium". On his deathbed, Conrad yielded the crown to his main rival, Henry the Fowler of Saxony (r. 919–36), who was elected king at the Diet of Fritzlar in 919. Henry reached a truce with the raiding Magyars, and in 933 he won a first victory against them in the Battle of Riade.

Henry died in 936, but his descendants, the Liudolfing (or Ottonian) dynasty, would continue to rule the Eastern kingdom for roughly a century. Upon Henry the Fowler's death, Otto, his son and designated successor, was elected King in Aachen in 936. He overcame a series of revolts from a younger brother and from several dukes. After that, the king managed to control the appointment of dukes and often also employed bishops in administrative affairs.

In 951, Otto came to the aid of Adelaide, the widowed queen of Italy, defeating her enemies, marrying her, and taking control over Italy. In 955, Otto won a decisive victory over the Magyars in the Battle of Lechfeld. In 962, Otto was crowned Emperor by Pope John XII, thus intertwining the affairs of the German kingdom with those of Italy and the Papacy. Otto's coronation as Emperor marked the German kings as successors to the Empire of Charlemagne, which through the concept of "translatio imperii", also made them consider themselves as successors to Ancient Rome.

The kingdom had no permanent capital city. Kings traveled between residences (called Kaiserpfalz) to discharge affairs. However, each king preferred certain places; in Otto's case, this was the city of Magdeburg. Kingship continued to be transferred by election, but Kings often ensured their own sons were elected during their lifetimes, enabling them to keep the crown for their families. This only changed after the end of the Salian dynasty in the 12th century.

In 963, Otto deposed the current Pope John XII and chose Pope Leo VIII as the new pope (although John XII and Leo VIII both claimed the papacy until 964 when John XII died). This also renewed the conflict with the Eastern Emperor in Constantinople, especially after Otto's son Otto II (r. 967–83) adopted the designation "imperator Romanorum". Still, Otto II formed marital ties with the east when he married the Byzantine princess Theophanu. Their son, Otto III, came to the throne only three years old, and was subjected to a power struggle and series of regencies until his age of majority in 994. Up to that time, he had remained in Germany, while a deposed Duke, Crescentius II, ruled over Rome and part of Italy, ostensibly in his stead.

In 996 Otto III appointed his cousin Gregory V the first German Pope. A foreign pope and foreign papal officers were seen with suspicion by Roman nobles, who were led by Crescentius II to revolt. Otto III's former mentor Antipope John XVI briefly held Rome, until the Holy Roman Emperor seized the city.

Otto died young in 1002, and was succeeded by his cousin Henry II, who focused on Germany.

Henry II died in 1024 and Conrad II, first of the Salian Dynasty, was elected king only after some debate among dukes and nobles. This group eventually developed into the college of Electors.

The Holy Roman Empire became eventually composed of four kingdoms. The kingdoms were:

Kings often employed bishops in administrative affairs and often determined who would be appointed to ecclesiastical offices. In the wake of the Cluniac Reforms, this involvement was increasingly seen as inappropriate by the Papacy. The reform-minded Pope Gregory VII was determined to oppose such practices, which led to the Investiture Controversy with King Henry IV (r. 1056–1106). He repudiated the Pope's interference and persuaded his bishops to excommunicate the Pope, whom he famously addressed by his born name "Hildebrand", rather than his regnal name "Pope Gregory VII". The Pope, in turn, excommunicated the king, declared him deposed, and dissolved the oaths of loyalty made to Henry. The king found himself with almost no political support and was forced to make the famous Walk to Canossa in 1077, by which he achieved a lifting of the excommunication at the price of humiliation. Meanwhile, the German princes had elected another king, Rudolf of Swabia. Henry managed to defeat him but was subsequently confronted with more uprisings, renewed excommunication, and even the rebellion of his sons. After his death, his second son, Henry V, reached an agreement with the Pope and the bishops in the 1122 Concordat of Worms. The political power of the Empire was maintained, but the conflict had demonstrated the limits of the ruler's power, especially in regard to the Church, and it robbed the king of the sacral status he had previously enjoyed. The Pope and the German princes had surfaced as major players in the political system of the empire.

When the Salian dynasty ended with Henry V's death in 1125, the princes chose not to elect the next of kin, but rather Lothair, the moderately powerful but already old Duke of Saxony. When he died in 1137, the princes again aimed to check royal power; accordingly they did not elect Lothair's favoured heir, his son-in-law Henry the Proud of the Welf family, but Conrad III of the Hohenstaufen family, the grandson of Emperor Henry IV and thus a nephew of Emperor Henry V. This led to over a century of strife between the two houses. Conrad ousted the Welfs from their possessions, but after his death in 1152, his nephew Frederick I "Barbarossa" succeeded him and made peace with the Welfs, restoring his cousin Henry the Lion to his – albeit diminished – possessions.

The Hohenstaufen rulers increasingly lent land to "ministerialia", formerly non-free servicemen, who Frederick hoped would be more reliable than dukes. Initially used mainly for war services, this new class of people would form the basis for the later knights, another basis of imperial power. A further important constitutional move at Roncaglia was the establishment of a new peace mechanism for the entire empire, the Landfrieden, with the first imperial one being issued in 1103 under Henry IV at Mainz. This was an attempt to abolish private feuds, between the many dukes and other people, and to tie the Emperor's subordinates to a legal system of jurisdiction and public prosecution of criminal acts – a predecessor of the modern concept of "rule of law". Another new concept of the time was the systematic foundation of new cities by the Emperor and by the local dukes. These were partly caused by the explosion in population, and they also concentrated economic power at strategic locations. Before this, cities had only existed in the form of old Roman foundations or older bishoprics. Cities that were founded in the 12th century include Freiburg, possibly the economic model for many later cities, and Munich.

Frederick I, also called Frederick Barbarossa, was crowned Emperor in 1155. He emphasized the "Romanness" of the empire, partly in an attempt to justify the power of the Emperor independent of the (now strengthened) Pope. An imperial assembly at the fields of Roncaglia in 1158 reclaimed imperial rights in reference to Justinian's Corpus Juris Civilis. Imperial rights had been referred to as "regalia" since the Investiture Controversy but were enumerated for the first time at Roncaglia. This comprehensive list included public roads, tariffs, coining, collecting punitive fees, and the investiture or seating and unseating of office holders. These rights were now explicitly rooted in Roman Law, a far-reaching constitutional act.

Frederick's policies were primarily directed at Italy, where he clashed with the increasingly wealthy and free-minded cities of the north, especially Milan. He also embroiled himself in another conflict with the Papacy by supporting a candidate elected by a minority against Pope Alexander III (1159–81). Frederick supported a succession of antipopes before finally making peace with Alexander in 1177. In Germany, the Emperor had repeatedly protected Henry the Lion against complaints by rival princes or cities (especially in the cases of Munich and Lübeck). Henry gave only lackluster support to Frederick's policies, and in a critical situation during the Italian wars, Henry refused the Emperor's plea for military support. After returning to Germany, an embittered Frederick opened proceedings against the Duke, resulting in a public ban and the confiscation of all his territories. In 1190, Frederick participated in the Third Crusade and died in the Armenian Kingdom of Cilicia.

During the Hohenstaufen period, German princes facilitated a successful, peaceful eastward settlement of lands that were uninhabited or inhabited sparsely by West Slavs. German speaking farmers, traders, and craftsmen from the western part of the Empire, both Christians and Jews, moved into these areas. The gradual Germanization of these lands was a complex phenomenon that should not be interpreted in the biased terms of 19th-century nationalism. The eastward settlement expanded the influence of the empire to include Pomerania and Silesia, as did the intermarriage of the local, still mostly Slavic, rulers with German spouses. The Teutonic Knights were invited to Prussia by Duke Konrad of Masovia to Christianize the Prussians in 1226. The monastic state of the Teutonic Order () and its later German successor state of Prussia were, however, never part of the Holy Roman Empire.

Under the son and successor of Frederick Barbarossa, Henry VI, the Hohenstaufen dynasty reached its apex. Henry added the Norman kingdom of Sicily to his domains, held English king Richard the Lionheart captive, and aimed to establish a hereditary monarchy when he died in 1197. As his son, Frederick II, though already elected king, was still a small child and living in Sicily, German princes chose to elect an adult king, resulting in the dual election of Frederick Barbarossa's youngest son Philip of Swabia and Henry the Lion's son Otto of Brunswick, who competed for the crown. Otto prevailed for a while after Philip was murdered in a private squabble in 1208 until he began to also claim Sicily.

Pope Innocent III, who feared the threat posed by a union of the empire and Sicily, now supported by Frederick II, who marched to Germany and defeated Otto. After his victory, Frederick did not act upon his promise to keep the two realms separate. Though he had made his son Henry king of Sicily before marching on Germany, he still reserved real political power for himself. This continued after Frederick was crowned Emperor in 1220. Fearing Frederick's concentration of power, the Pope finally excommunicated the Emperor. Another point of contention was the crusade, which Frederick had promised but repeatedly postponed. Now, although excommunicated, Frederick led the Sixth Crusade in 1228, which ended in negotiations and a temporary restoration of the Kingdom of Jerusalem.

Despite his imperial claims, Frederick's rule was a major turning point towards the disintegration of central rule in the Empire. While concentrated on establishing a modern, centralized state in Sicily, he was mostly absent from Germany and issued far-reaching privileges to Germany's secular and ecclesiastical princes: In the 1220 "Confoederatio cum principibus ecclesiasticis," Frederick gave up a number of "regalia" in favour of the bishops, among them tariffs, coining, and fortification. The 1232 "Statutum in favorem principum" mostly extended these privileges to secular territories. Although many of these privileges had existed earlier, they were now granted globally, and once and for all, to allow the German princes to maintain order north of the Alps while Frederick concentrated on Italy. The 1232 document marked the first time that the German dukes were called "domini terræ," owners of their lands, a remarkable change in terminology as well.

The Kingdom of Bohemia was a significant regional power during the Middle Ages. In 1212, King Ottokar I (bearing the title "king" since 1198) extracted a Golden Bull of Sicily (a formal edict) from the emperor Frederick II, confirming the royal title for Ottokar and his descendants and the Duchy of Bohemia was raised to a kingdom. Bohemian kings would be exempt from all future obligations to the Holy Roman Empire except for participation in the imperial councils. Charles IV set Prague to be the seat of the Holy Roman Emperor.

After the death of Frederick II in 1250, the German kingdom was divided between his son Conrad IV (died 1254) and the anti-king, William of Holland (died 1256). Conrad's death was followed by the Interregnum, during which no king could achieve universal recognition, allowing the princes to consolidate their holdings and become even more independent rulers. After 1257, the crown was contested between Richard of Cornwall, who was supported by the Guelph party, and Alfonso X of Castile, who was recognized by the Hohenstaufen party but never set foot on German soil. After Richard's death in 1273, the Interregnum ended with the unanimous election of Rudolf I of Germany, a minor pro-Staufen count.

During the 13th century, a general structural change in how land was administered prepared the shift of political power towards the rising bourgeoisie at the expense of aristocratic feudalism that would characterize the Late Middle Ages. Instead of personal duties, money increasingly became the common means to represent economic value in agriculture. Peasants were increasingly required to pay tribute to their lands. The concept of "property" began to replace more ancient forms of jurisdiction, although they were still very much tied together. In the territories (not at the level of the Empire), power became increasingly bundled: Whoever owned the land had jurisdiction, from which other powers derived. It is important to note, however, that jurisdiction at this time did not include legislation, which virtually did not exist until well into the 15th century. Court practice heavily relied on traditional customs or rules described as customary.

During this time territories began to transform into the predecessors of modern states. The process varied greatly among the various lands and was most advanced in those territories that were almost identical to the lands of the old Germanic tribes, "e.g." Bavaria. It was slower in those scattered territories that were founded through imperial privileges.

The difficulties in electing the king eventually led to the emergence of a fixed college of prince-electors ("Kurfürsten"), whose composition and procedures were set forth in the Golden Bull of 1356, which remained valid until 1806. This development probably best symbolizes the emerging duality between emperor and realm ("Kaiser und Reich"), which were no longer considered identical. The Golden Bull also set forth the system for election of the Holy Roman Emperor. The emperor now was to be elected by a majority rather than by consent of all seven electors. For electors the title became hereditary, and they were given the right to mint coins and to exercise jurisdiction. Also their sons were to know the imperial languages – German, Latin, Italian, and Czech.

The shift in power away from the emperor is also revealed in the way the post-Hohenstaufen kings attempted to sustain their power. Earlier, the Empire's strength (and finances) greatly relied on the Empire's own lands, the so-called "Reichsgut", which always belonged to the king of the day and included many Imperial Cities. After the 13th century, the relevance of the "Reichsgut" faded, even though some parts of it did remain until the Empire's end in 1806. Instead, the "Reichsgut" was increasingly pawned to local dukes, sometimes to raise money for the Empire, but more frequently to reward faithful duty or as an attempt to establish control over the dukes. The direct governance of the "Reichsgut" no longer matched the needs of either the king or the dukes.

The kings beginning with Rudolf I of Germany increasingly relied on the lands of their respective dynasties to support their power. In contrast with the "Reichsgut", which was mostly scattered and difficult to administer, these territories were relatively compact and thus easier to control. In 1282, Rudolf I thus lent Austria and Styria to his own sons. In 1312, Henry VII of the House of Luxembourg was crowned as the first Holy Roman Emperor since Frederick II. After him all kings and emperors relied on the lands of their own family ("Hausmacht"): Louis IV of Wittelsbach (king 1314, emperor 1328–47) relied on his lands in Bavaria; Charles IV of Luxembourg, the grandson of Henry VII, drew strength from his own lands in Bohemia. It was thus increasingly in the king's own interest to strengthen the power of the territories, since the king profited from such a benefit in his own lands as well.

The "constitution" of the Empire still remained largely unsettled at the beginning of the 15th century. Although some procedures and institutions had been fixed, for example by the Golden Bull of 1356, the rules of how the king, the electors, and the other dukes should cooperate in the Empire much depended on the personality of the respective king. It therefore proved somewhat damaging that Sigismund of Luxemburg (king 1410, emperor 1433–1437) and Frederick III of Habsburg (king 1440, emperor 1452–1493) neglected the old core lands of the empire and mostly resided in their own lands. Without the presence of the king, the old institution of the "Hoftag", the assembly of the realm's leading men, deteriorated. The "Imperial Diet" as a legislative organ of the Empire did not exist at that time. The dukes often conducted feuds against each other – feuds that, more often than not, escalated into local wars.

Simultaneously, the Catholic Church experienced crises of its own, with wide-reaching effects in the Empire. The conflict between several papal claimants (two anti-popes and the "legitimate" Pope) ended only with the Council of Constance (1414–1418); after 1419 the Papacy directed much of its energy to suppress the Hussites. The medieval idea of unifying all Christendom into a single political entity, with the Church and the Empire as its leading institutions, began to decline.

With these drastic changes, much discussion emerged in the 15th century about the Empire itself. Rules from the past no longer adequately described the structure of the time, and a reinforcement of earlier "Landfrieden" was urgently needed. During this time, the concept of "reform" emerged, in the original sense of the Latin verb "re-formare" – to regain an earlier shape that had been lost.

When Frederick III needed the dukes to finance a war against Hungary in 1486, and at the same time had his son (later Maximilian I) elected king, he faced a demand from the united dukes for their participation in an Imperial Court. For the first time, the assembly of the electors and other dukes was now called the Imperial Diet (German "Reichstag") (to be joined by the Imperial Free Cities later). While Frederick refused, his more conciliatory son finally convened the Diet at Worms in 1495, after his father's death in 1493. Here, the king and the dukes agreed on four bills, commonly referred to as the "Reichsreform" (Imperial Reform): a set of legal acts to give the disintegrating Empire some structure. For example, this act produced the Imperial Circle Estates and the "Reichskammergericht" (Imperial Chamber Court), institutions that would – to a degree – persist until the end of the Empire in 1806.

However, it took a few more decades for the new regulation to gain universal acceptance and for the new court to begin to function effectively; only in 1512 would the Imperial Circles be finalized. The King also made sure that his own court, the "Reichshofrat", continued to operate in parallel to the "Reichskammergericht". Also in 1512, the Empire received its new title, the "Heiliges Römisches Reich Deutscher Nation" ("Holy Roman Empire of the German Nation").

In 1516, Ferdinand II of Aragon, grandfather of the future Holy Roman Emperor Charles V, died. Due to a combination of (1) the traditions of dynastic succession in Aragon, which permitted maternal inheritance with no precedence for female rule; (2) the insanity of Charles's mother, Joanna of Castile; and (3) the insistence by his remaining grandfather, Maximilian I, that he take up his royal titles, Charles initiated his reign in Castile and Aragon, a union which evolved into Spain, in conjunction with his mother. This ensured for the first time that all the realms of what is now Spain would be united by one monarch under one nascent Spanish crown. The founding territories retained their separate governance codes and laws. In 1519, already reigning as "Carlos I" in Spain, Charles took up the imperial title as "Karl V". The balance (and imbalance) between these separate inheritances would be defining elements of his reign and would ensure that personal union between the Spanish and German crowns would be short-lived. The latter would end up going to a more junior branch of the Habsburgs in the person of Charles's brother Ferdinand, while the senior branch continued to rule in Spain and in the Burgundian inheritance in the person of Charles's son, Philip II of Spain.

In addition to conflicts between his Spanish and German inheritances, conflicts of religion would be another source of tension during the reign of Charles V. Before Charles's reign in the Holy Roman Empire began, in 1517, Martin Luther launched what would later be known as the Reformation. At this time, many local dukes saw it as a chance to oppose the hegemony of Emperor Charles V. The empire then became fatally divided along religious lines, with the north, the east, and many of the major cities – Strasbourg, Frankfurt, and Nuremberg – becoming Protestant while the southern and western regions largely remained Catholic.

Charles V continued to battle the French and the Protestant princes in Germany for much of his reign. After his son Philip married Queen Mary of England, it appeared that France would be completely surrounded by Habsburg domains, but this hope proved unfounded when the marriage produced no children. In 1555, Paul IV was elected pope and took the side of France, whereupon an exhausted Charles finally gave up his hopes of a world Christian empire. He abdicated and divided his territories between Philip and Ferdinand of Austria. The Peace of Augsburg ended the war in Germany and accepted the existence of Protestantism in form of Lutheranism, while Calvinism was still not recognized. Anabaptist, Arminian and other minor Protestant communities were also forbidden.

Germany would enjoy relative peace for the next six decades. On the eastern front, the Turks continued to loom large as a threat, although war would mean further compromises with the Protestant princes, and so the Emperor sought to avoid it. In the west, the Rhineland increasingly fell under French influence. After the Dutch revolt against Spain erupted, the Empire remained neutral, "de facto" allowing the Netherlands to depart the empire in 1581, a secession acknowledged in 1648. A side effect was the Cologne War, which ravaged much of the upper Rhine.

After Ferdinand died in 1564, his son Maximilian II became Emperor, and like his father accepted the existence of Protestantism and the need for occasional compromise with it. Maximilian was succeeded in 1576 by Rudolf II, a strange man who preferred classical Greek philosophy to Christianity and lived an isolated existence in Bohemia. He became afraid to act when the Catholic Church was forcibly reasserting control in Austria and Hungary, and the Protestant princes became upset over this. Imperial power sharply deteriorated by the time of Rudolf's death in 1612. When Bohemians rebelled against the Emperor, the immediate result was the series of conflicts known as the Thirty Years' War (1618–48), which devastated the Empire. Foreign powers, including France and Sweden, intervened in the conflict and strengthened those fighting Imperial power, but also seized considerable territory for themselves. The long conflict so bled the Empire that it never recovered its strength.

The actual end of the empire came in several steps. The Peace of Westphalia in 1648, which ended the Thirty Years' War, gave the territories almost complete independence. Calvinism was now allowed, but Anabaptists, Arminians and other Protestant communities would still lack any support and continue to be persecuted well until the end of the Empire. The Swiss Confederation, which had already established quasi-independence in 1499, as well as the Northern Netherlands, left the Empire. The Habsburg Emperors focused on consolidating their own estates in Austria and elsewhere.

At the Battle of Vienna (1683), the Army of the Holy Roman Empire, led by the Polish King John III Sobieski, decisively defeated a large Turkish army, stopping the western Ottoman advance and leading to the eventual dismemberment of the Ottoman Empire in Europe. The army was half forces of the Polish–Lithuanian Commonwealth, mostly cavalry, and half forces of the Holy Roman Empire (German/Austrian), mostly infantry.

By the rise of Louis XIV, the Habsburgs were chiefly dependent on their hereditary lands to counter the rise of Prussia; some of whose territories lay inside the Empire. Throughout the 18th century, the Habsburgs were embroiled in various European conflicts, such as the War of the Spanish Succession, the War of the Polish Succession, and the War of the Austrian Succession. The German dualism between Austria and Prussia dominated the empire's history after 1740.

From 1792 onwards, revolutionary France was at war with various parts of the Empire intermittently.

The German mediatization was the series of mediatizations and secularizations that occurred between 1795 and 1814, during the latter part of the era of the French Revolution and then the Napoleonic Era. "Mediatization" was the process of annexing the lands of one imperial estate to another, often leaving the annexed some rights. For example, the estates of the Imperial Knights were formally mediatized in 1806, having "de facto" been seized by the great territorial states in 1803 in the so-called "Rittersturm". "Secularization" was the abolition of the temporal power of an ecclesiastical ruler such as a bishop or an abbot and the annexation of the secularized territory to a secular territory.

The empire was dissolved on 6 August 1806, when the last Holy Roman Emperor Francis II (from 1804, Emperor Francis I of Austria) abdicated, following a military defeat by the French under Napoleon at Austerlitz (see Treaty of Pressburg). Napoleon reorganized much of the Empire into the Confederation of the Rhine, a French satellite. Francis' House of Habsburg-Lorraine survived the demise of the empire, continuing to reign as Emperors of Austria and Kings of Hungary until the Habsburg empire's final dissolution in 1918 in the aftermath of World War I.

The Napoleonic Confederation of the Rhine was replaced by a new union, the German Confederation, in 1815, following the end of the Napoleonic Wars. It lasted until 1866 when Prussia founded the North German Confederation, a forerunner of the German Empire which united the German-speaking territories outside of Austria and Switzerland under Prussian leadership in 1871. This state developed into modern Germany.

The only princely member state of the Holy Roman Empire that has preserved its status as a monarchy until today is the Principality of Liechtenstein. The only Free Imperial Cities still being states within Germany are Hamburg and Bremen. All other historic member states of the HRE were either dissolved or are republican successor states to their princely predecessor states.

The Holy Roman Empire was not a highly centralized state like most countries today. Instead, it was divided into dozens – eventually hundreds – of individual entities governed by kings, dukes, counts, bishops, abbots, and other rulers, collectively known as princes. There were also some areas ruled directly by the Emperor. At no time could the Emperor simply issue decrees and govern autonomously over the Empire. His power was severely restricted by the various local leaders.

From the High Middle Ages onwards, the Holy Roman Empire was marked by an uneasy coexistence of the princes of the local territories who were struggling to take power away from it. To a greater extent than in other medieval kingdoms such as France and England, the Emperors were unable to gain much control over the lands that they formally owned. Instead, to secure their own position from the threat of being deposed, Emperors were forced to grant more and more autonomy to local rulers, both nobles, and bishops. This process began in the 11th century with the Investiture Controversy and was more or less concluded with the 1648 Peace of Westphalia. Several Emperors attempted to reverse this steady dissemination of their authority but were thwarted both by the papacy and by the princes of the Empire.

The number of territories represented in the Imperial Diet was considerable, numbering about 300 at the time of the Peace of Westphalia. Many of these "Kleinstaaten" ("little states") covered no more than a few square miles, and/or included several non-contiguous pieces, so the Empire was often called a "Flickenteppich" ("patchwork carpet"). 
An entity was considered a "Reichsstand" (imperial estate) if, according to feudal law, it had no authority above it except the Holy Roman Emperor himself. The imperial estates comprised:

A sum total of 1,500 Imperial estates has been reckoned. For a list of "Reichsstände" in 1792, see List of Imperial Diet participants (1792).

A prospective Emperor had first to be elected King of the Romans (Latin: "Rex Romanorum"; German: "römischer König"). German kings had been elected since the 9th century; at that point they were chosen by the leaders of the five most important tribes (the Salian Franks of Lorraine, Ripuarian Franks of Franconia, Saxons, Bavarians, and Swabians). In the Holy Roman Empire, the main dukes and bishops of the kingdom elected the King of the Romans. In 1356, Emperor Charles IV issued the Golden Bull, which limited the electors to seven: the King of Bohemia, the Count Palatine of the Rhine, the Duke of Saxony, the Margrave of Brandenburg, and the archbishops of Cologne, Mainz, and Trier. During the Thirty Years' War, the Duke of Bavaria was given the right to vote as the eighth elector, and the Duke of Brunswick-Lüneburg (colloquially, Hanover) was granted a ninth electorate; additionally, the Napoleonic Wars resulted in several electorates being reallocated, but these new electors never voted before the Empire's dissolution. A candidate for election would be expected to offer concessions of land or money to the electors in order to secure their vote.

After being elected, the King of the Romans could theoretically claim the title of "Emperor" only after being crowned by the Pope. In many cases, this took several years while the King was held up by other tasks: frequently he first had to resolve conflicts in rebellious northern Italy or was quarreling with the Pope himself. Later Emperors dispensed with the papal coronation altogether, being content with the styling "Emperor-Elect": the last Emperor to be crowned by the Pope was Charles V in 1530.

The Emperor had to be male and of noble blood. No law required him to be a Catholic, but as the majority of the Electors adhered to this faith, no Protestant was ever elected. Whether and to what degree he had to be German was disputed among the Electors, contemporary experts in constitutional law, and the public. During the Middle Ages, some Kings and Emperors were not of German origin, but since the Renaissance, German heritage was regarded as vital for a candidate in order to be eligible for imperial office.

The Imperial Diet ("Reichstag", or "Reichsversammlung") was not a legislative body as we understand it today, as its members envisioned it more like a central forum where it was more important to negotiate than to decide. The Diet was theoretically superior to the emperor himself. It was divided into three classes. The first class, the Council of Electors, consisted of the electors, or the princes who could vote for King of the Romans. The second class, the Council of Princes, consisted of the other princes. The Council of Princes was divided into two "benches," one for secular rulers and one for ecclesiastical ones. Higher-ranking princes had individual votes, while lower-ranking princes were grouped into "colleges" by geography. Each college had one vote.

The third class was the Council of Imperial Cities, which was divided into two colleges: Swabia and the Rhine. The Council of Imperial Cities was not fully equal with the others; it could not vote on several matters such as the admission of new territories. The representation of the Free Cities at the Diet had become common since the late Middle Ages. Nevertheless, their participation was formally acknowledged only as late as in 1648 with the Peace of Westphalia ending the Thirty Years' War.

The Empire also had two courts: the "Reichshofrat" (also known in English as the Aulic Council) at the court of the King/Emperor, and the "Reichskammergericht" (Imperial Chamber Court), established with the Imperial Reform of 1495.

As part of the Imperial Reform, six Imperial Circles was established in 1500; four more were established in 1512. These were regional groupings of most (though not all) of the various states of the Empire for the purposes of defense, imperial taxation, supervision of coining, peace-keeping functions, and public security. Each circle had its own parliament, known as a "Kreistag" ("Circle Diet"), and one or more directors, who coordinated the affairs of the circle. Not all imperial territories were included within the imperial circles, even after 1512; the Lands of the Bohemian Crown were excluded, as were Switzerland, the imperial fiefs in northern Italy, the lands of the Imperial Knights, and certain other small territories like the Lordship of Jever.

The Army of the Holy Roman Empire (German "Reichsarmee", "Reichsheer" or "Reichsarmatur"; Latin "exercitus imperii") was created in 1422 and came to an end even before the Empire as the result of the Napoleonic Wars. It must not be confused with the Imperial Army ("Kaiserliche Armee") of the Emperor.

Despite appearances to the contrary, the Army of the Empire did not constitute a permanent standing army that was always at the ready to fight for the Empire. When there was danger, an Army of the Empire was mustered from among the elements constituting it, in order to conduct an imperial military campaign or "Reichsheerfahrt". In practice, the imperial troops often had local allegiances stronger than their loyalty to the Emperor.

"Reichshofrat" resided in Vienna.

"Reichskammergericht " resided in Worms, Augsburg, Nuremberg, Regensburg, Speyer and Esslingen before it was moved permanently to Wetzlar.

"Reichstag" resided variously in Paderborn, Bad Lippspringe, Ingelheim am Rhein, Diedenhofen (now Thionville), Aachen, Worms, Forchheim, Trebur, Fritzlar, Ravenna, Quedlinburg, Dortmund, Verona, Minden, Mainz, Frankfurt am Main, Merseburg, Goslar, Würzburg, Bamberg, Schwäbisch Hall, Augsburg, Nuremberg, Quierzy-sur-Oise, Speyer, Gelnhausen, Erfurt, Eger (now Cheb), Esslingen, Lindau, Freiburg, Cologne, Konstanz and Trier before it was moved permanently to Regensburg.

The Holy Roman Empire never had a capital city. Usually, the Holy Roman Emperor ruled from a place of his own choice. This was called an imperial seat. Seats of the Holy Roman Emperor included: Aachen (from 794), Munich (1328–1347 and 1744–1745), Prague (1355–1437 and 1576–1611), Vienna (1438–1576, 1611–1740 and 1745–1806) and Frankfurt am Main (1742–1744) among other cities.

Imperial elections were mostly held in Frankfurt am Main, but also took place in Augsburg, Rhens, Cologne and Regensburg. Going as far as into the 16th century, the elected Holy Roman Emperor was then crowned and appointed by the Pope in Rome, but individual coronations also happened in Ravenna, Bologna and Reims.

Largest cities or towns of the Empire by year:

Roman Catholicism constituted the single official religion of the Empire until 1555. The Holy Roman Emperor was always a Roman Catholic.

Lutheranism was officially recognized in the Peace of Augsburg of 1555, and Calvinism in the Peace of Westphalia of 1648. Those two constituted the only officially recognized Protestant denominations, while various other Protestant confessions such as Anabaptism, Arminianism, etc. coexisted illegally within the Empire. Anabaptism came in a variety of denominations, including Mennonites, Schwarzenau Brethren, Hutterites, the Amish, and multiple other groups.






</doc>
<doc id="13279" url="https://en.wikipedia.org/wiki?curid=13279" title="Holiday">
Holiday

A holiday is a day set aside by custom or by law on which normal activities, especially business or work including school, are suspended or reduced. Generally, holidays are intended to allow individuals to celebrate or commemorate an event or tradition of cultural or religious significance. Holidays may be designated by governments, religious institutions, or other groups or organizations. The degree to which normal activities are reduced by a holiday may depend on local laws, customs, the type of job being held or personal choices.

The concept of holidays often originated in connection with religious observances. The intention of a holiday was typically to allow individuals to tend to religious duties associated with important dates on the calendar. In most modern societies, however, holidays serve as much of a recreational function as any other weekend days or activities.

In many societies there are important distinctions between holidays designated by governments and holidays designated by religious institutions. For example, in many predominantly Christian nations, government-designed holidays may center on Christian holidays, though non-Christians may instead observe religious holidays associated with their faith. In some cases, a holiday may only be nominally observed. For example, many Jews in the Americas and Europe treat the relatively minor Jewish holiday of Hanukkah as a "working holiday", changing very little of their daily routines for this day.

The word "holiday" has differing connotations in different regions. In the United States the word is used exclusively to refer to the nationally, religiously or culturally observed day(s) of rest or celebration, or the events themselves, whereas in the United Kingdom and other Commonwealth nations, the word may refer to the period of time where leave from one’s duties has been agreed, and is used as a synonym to the US preferred "vacation". This time is usually set aside for rest, travel or the participation in recreational activities, with entire industries targeted to coincide or enhance these experiences. The days of leave may not coincide with any specific customs or laws. Employers and educational institutes may designate ‘holidays’ themselves which may or may not overlap nationally or culturally relevant dates, which again comes under this connotation, but it is the first implication detailed that this article is concerned with.

The word "holiday" comes from the Old English word "hāligdæg" ("hālig" "holy" + "dæg" "day"). The word originally referred only to special religious days. In modern use, it means any special day of rest or relaxation, as opposed to normal days away from work or school.

Winter in the Northern Hemisphere features many holidays that involve festivals and feasts. The Christmas and holiday season surrounds the Christmas and other holidays, and is celebrated by many religions and cultures. Usually, this period begins near the start of November and ends with New Year's Day. "Holiday season" in the US, to the period that begins with Thanksgiving and ends with New Year's Eve. Some Christian countries consider the end of the festive season to be after the feast of Epiphany.

Sovereign nations and territories observe holidays based on events of significance to their history. For example, Americans celebrate Independence Day, celebrating the signing of the Declaration of Independence in 1776.

Other secular (non-religious) holidays are observed nationally, internationally (often in conjunction with organizations such as the United Nations), and across multi-country regions. The United Nations Calendar of Observances dedicates decades to a specific topic, but also a complete year, month, week and days. Holidays dedicated to an observance s.a. the commemoration of the ending of World War II, or the Shoah, can also be part of the reparation obligation as per UN OHCHR Basic Principles and Guidelines on the Right to a Remedy and Reparation for Victims of Gross Violations of International Human Rights Law and Serious Violations of International Humanitarian Law.
Another example of a major secular holiday is the Lunar New Year, which is celebrated across Asia. Many other days are marked to celebrate events or people, but are not strictly holidays as time off work is rarely given; examples include Arbor Day (originally U.S.), Labor Day (celebrated sometimes under different names and on different days in different countries), and Earth Day (22 April).

These are holidays that are not traditionally marked on calendars. These holidays are celebrated by various groups and individuals. Some promote a cause, others recognize historical events not officially recognized, and others are "funny" holidays celebrated with humorous intent. For example, Monkey Day is celebrated on December 14, International Talk Like a Pirate Day is observed on September 19, and Blasphemy Day is held on September 30. Other examples are April Fool's Day on April 1 and Liberation Day (Expatriates) on May 31. Various community organizers and marketers promote odd social media holidays.

Many holidays are linked to faiths and religions (see etymology above). Christian holidays are defined as part of the liturgical year, the chief ones being Easter and Christmas. The Orthodox Christian and Western-Roman Catholic patronal feast day or "name day" are celebrated in each place's patron saint's day, according to the Calendar of saints. Jehovah's Witnesses annually commemorate "The Memorial of Jesus Christ's Death", but do not celebrate other holidays with any religious significance such as Easter, Christmas or New Year's. This holds especially true for those holidays that have combined and absorbed rituals, overtones or practices from non-Christian beliefs into the celebration, as well as those holidays that distract from or replace the worship of Jehovah. In Islam, the largest holidays are Eid ul-Fitr (immediately after Ramadan) and Eid al-Adha (at the end of the Hajj). Ahmadi Muslims additionally celebrate Promised Messiah Day, Promised Reformer Day, and Khilafat Day, but contrary to popular belief, neither are regarded as holidays. Hindus, Jains and Sikhs observe several holidays, one of the largest being Diwali (Festival of Light). Japanese holidays contain references to several different faiths and beliefs. Celtic, Norse, and Neopagan holidays follow the order of the Wheel of the Year. Some are closely linked to Swedish festivities. The Bahá'í Faith observes 11 annual holidays on dates determined using the Bahá'í calendar. Jews have two holiday seasons: the Spring Feasts of Pesach (Passover) and Shavuot (Weeks, called Pentecost in Greek); and the Fall Feasts of Rosh Hashanah (Head of the Year), Yom Kippur (Day of Atonement), Sukkot (Tabernacles), and Shemini Atzeret (Eighth Day of Assembly).

See for complete listings of holidays associated with particular religions.






</doc>
<doc id="13287" url="https://en.wikipedia.org/wiki?curid=13287" title="Hobby">
Hobby

A hobby is a regular activity that is done for enjoyment, typically during one's leisure time. Hobbies can include collecting themed items and objects, engaging in creative and artistic pursuits, playing sports, or pursuing other amusements. A list of hobbies is lengthy and always changing as interests and fashions change. By continually participating in a particular hobby, one can acquire substantial skills and knowledge in that area. Engagement in hobbies has increased since the late nineteenth century as workers have more leisure time and advancing production and technology have provided more support for leisure activities. Hobbies tend to follow trends in society, for example stamp collecting was popular during the nineteenth and twentieth centuries as postal systems were the main means of communication, while video games are more popular nowadays following technological advances.

Hobbyists are a part of a wider group of people engaged in leisure pursuits where the boundaries of each group overlap to some extent. The "Serious Leisure Perspective" groups hobbyists with amateurs and volunteers and identifies three broad groups of leisure activity with hobbies being found mainly in the Serious leisure category.

"a. Casual leisure" is intrinsically rewarding, short-lived, pleasurable activity requiring little or no preparation.

"b. Serious leisure" is the systematic pursuit of an amateur, hobbyist, or volunteer that is substantial, rewarding and results in a sense of accomplishment.

"c. Project-based leisure" is a short-term often a one-off project that is rewarding.

In the 16th century, the term "hobyn" had the meaning of "small horse and pony". The term "hobby horse" was documented in a 1557 payment confirmation for a "Hobbyhorse" from Reading, England. The item, originally called a "Tourney Horse", was made of a wooden or basketwork frame with an artificial tail and head. It was designed for a child to mimic riding a real horse. By 1816 the derivative, "hobby", was introduced into the vocabulary of a number of English people. Over the course of subsequent centuries, the term came to be associated with recreation and leisure. In the 17th century, the term was used in a pejorative sense by suggesting that a hobby was a childish pursuit, however, in the 18th century with a more industrial society and more leisure time, hobbies took on greater respectability A hobby is also called a pastime, derived from the use of hobbies to pass the time. A hobby became an activity that is practised regularly and usually with some worthwhile purpose. Hobbies are usually, but not always, practised primarily for interest and enjoyment, rather than financial reward.

The origins pursuits that others thought somewhat childish or trivial. However, as early as 1676 Sir Matthew Hale, in "Contemplations Moral and Divine", wrote "Almost every person hath some hobby horse or other wherein he prides himself." He was acknowledging that a "hobby horse" produces a legitimate sense of pride. By the mid 18th century there was a flourishing of hobbies as working people had more regular hours of work and greater leisure time. They spent more time to pursue interests that brought them satisfaction. However, there was concern that these working people might not use their leisure time in worthwhile pursuits. "The hope of weaning people away from bad habits by the provision of counter-attractions came to the fore in the 1830s, and has rarely waned since. Initially the bad habits were perceived to be of a sensual and physical nature, and the counter attractions, or perhaps more accurately alternatives, deliberately cultivated rationality and the intellect." The flourishing book and magazine trade of the day encouraged worthwhile hobbies and pursuits. The burgeoning manufacturing trade made materials used in hobbies cheap and was responsive to the changing interests of hobbyists.

The English have been identified as enthusiastic hobbyists, as George Orwell observed. "[A]nother English characteristic which is so much a part of us that we barely notice it … is the addiction to hobbies and spare-time occupations, the privateness of English life. We are a nation of flower-lovers, but also a nation of stamp-collectors, pigeon-fanciers, amateur carpenters, coupon-snippers, darts-players, crossword-puzzle fans. All the culture that is most truly native centres round things which even when they are communal are not official—the pub, the football match, the back garden, the fireside and the 'nice cup of tea'."

Deciding what to include in a list of hobbies provokes debate because it is difficult to decide which pleasurable pass-times can also be described as hobbies. During the 20th century the term hobby usually brought to mind activities such as stamp collecting, embroidery, knitting, painting, woodwork, photography, but not activities like listening to music, watching television or reading. These latter activities bring pleasure but lack the sense of achievement that is usually associated with a hobby. They are usually not structured, organised pursuits, as most hobbies are. The pleasure of a hobby is usually associated with making something of value or achieving something of value. "Such leisure is socially valorised precisely because it produces feelings of satisfaction with something that looks very much like work but that is done of its own sake." "Hobbies are a contradiction: they take work and turn it into leisure, and take leisure and turn it into work."

The terms amateur and hobbyist are often used interchangeably. Stebbins has a framework which distinguishes the terms has a useful categorisation of leisure in which he separates "casual leisure" from "serious Leisure". He describes serious leisure as undertaken by "amateurs", "hobbyists" and "volunteers". "Amateurs" engage in pursuits that have a professional counterpart, such as playing an instrument or astronomy. Hobbyists engage in five broad types of activity: "collecting", "making and tinkering" (like embroidery and car restoration), "activity participation" (like fishing and singing), "sports and games", and "liberal-arts" hobbies (like languages, cuisine, literature). Volunteers commit to organisations where they work as guides, counsellors, gardeners and so on. The separation of the amateur from the hobbyist is because the amateur has the ethos of the professional practitioner as a guide to practice. An amateur clarinetist is conscious of the role and procedures of a professional clarinetist.

A large proportion of hobbies are mainly solitary in nature. However, individual pursuit of a hobby often includes club memberships, organised sharing of products and regular communication between participants. For many hobbies there is an important role in being in touch with fellow hobbyists. Some hobbies are of communal nature, like choral singing and volunteering.

During the 20th century there was extensive research into the important role that play has in human development. While most evident in childhood, play continues throughout life for many adults in the form of games, hobbies, and sport.

The type of hobbies that people engage in changes with time. In the 21st century the video game industry is very large hobby involving millions of kids and adults in various forms of 'play'. Stamp collecting has declined along with the decline in the importance of the postal system. Woodwork and knitting have declined as hobbies as manufactured goods provide cheap alternatives for handmade goods. Through the internet an online community has become a hobby for many people; sharing advice, information and support, and in some cases, allowing a traditional hobby, such as collecting, to flourish and support trading in a new environment.

People who engage in hobbies have an interest in and time to pursue them. Children have been an important group of hobbyists because they are enthusiastic for collecting, making and exploring, in addition to this they have the leisure time that allows them to pursue those hobbies. The growth in hobbies occurred during industrialisation which gave workers set time for leisure. During the Depression there was an increase in the participation in hobbies because the unemployed had the time and a desire to be purposefully occupied. Hobbies are often pursued with an increased interest by retired people because they have the time and seek the intellectual and physical stimulation a hobby provides. Studies of ageing and society support the value of hobbies in healthy ageing.

Hobbies are a diverse set of activities and it is difficult to categorize them in a logical manner. The following categorization of hobbies was developed by Stebbins. 

Collecting includes seeking, locating, acquiring, organizing, cataloging, displaying and storing. Collecting is appealing to many people due to their interest in a particular subject and a desire to categorise and make order out of complexity. Some collectors are generalists, accumulating items from countries of the world. Others focus on a subtopic within their area of interest, perhaps 19th century postage stamps, milk bottle labels from Sussex, or Mongolian harnesses and tack. 
Collecting is an ancient hobby, with the list of coin collectors showing Caesar Augustus as one. Sometimes collectors have turned their hobby into a business, becoming commercial dealers that trade in the items being collected.

An alternative to collecting physical objects is collecting records of events of a particular kind. Examples include train spotting, bird-watching, aircraft spotting, railfans, and any other form of systematic recording a particular phenomenon. The recording form can be written, photographic, online, etc.

Scale modeling is making a replica of a real life object in a smaller scale and dates back to prehistoric times with small clay "dolls" and other children's toys that have been found near known populated areas. The Persians, Greeks, and Romans took the form to a greater depth during their years of domination of the Western World, using scale replicas of enemy fortifications, coastal defense lines, and other geographic fixtures to plan battles.

At the turn of the Industrial Age and through the 1920s, families could afford things such as electric trains, wind-up toys (typically boats or cars) and the increasingly valuable tin toy soldiers.

Model engineering refers to building functioning machinery in metal, such as internal combustion motors and live steam models or locomotives. This is a demanding hobby that requires a multitude of large and expensive tools, such as lathes and mills. This hobby originated in the United Kingdom in the late 19th century, later spreading and flourishing in the mid-20th century. Due to the expense and space required, it is becoming rare.

Scale modeling as we know it today became popular shortly after World War II. Before 1946, children as well as adults were content in carving and shaping wooden replicas from block wood kits, often depicting enemy aircraft to help with identification in case of an invasion.

With the advent of modern plastics, the amount of skill required to get the basic shape accurately shown for any given subject was lessened, making it easier for people of all ages to begin assembling replicas in varying scales. Superheroes, aeroplanes, boats, cars, tanks, artillery, and even figures of soldiers became quite popular subjects to build, paint and display. Although almost any subject can be found in almost any scale, there are common scales for such miniatures which remain constant today. 

3D Printing is a relatively new technology and already a major hobby as the cost of printers has fallen sharply. It is a good example of how hobbyists quickly engage with new technologies, communicate with one another and become producers related to their former hobby. 3D modeling is the process of making mathematical representations of three dimensional items and is an aspect of 3D printing.

Dressmaking has been a major hobby up until the late 20th century, in order to make cheap clothes, but also as a creative design and craft challenge. It has been reduced by the low cost manufactured clothes.

Cooking is for some people an interest, a hobby, a challenge and a source of significant satisfaction. For many other people it is a job, a chore, a duty, like cleaning. In the early 21st century the importance of cooking as a hobby was demonstrated by the high popularity of competitive television cooking programs.

Residential gardening most often takes place in or about one's own residence, in a space referred to as the garden. Although a garden typically is located on the land near a residence, it may also be located on a roof, in an atrium, on a balcony, in a windowbox, or on a patio or vivarium.

Gardening also takes place in non-residential green areas, such as parks, public or semi-public gardens (botanical gardens or zoological gardens), amusement and theme parks, along transportation corridors, and around tourist attractions and hotels. In these situations, a staff of gardeners or groundskeepers maintains the gardens.
Indoor gardening is growing houseplants within a residence or building, in a conservatory, or in a greenhouse. Indoor gardens are sometimes incorporated into air conditioning or heating systems.

Water gardening is growing plants that have adapted to pools and ponds. Bog gardens are also considered a type of water garden. These all require special conditions and considerations. A simple water garden may consist solely of a tub containing the water and plant(s).

Container gardening is concerned with growing plants in containers that are placed above the ground.

Tinkering is 'dabbling' with the making process, often applied to the hobby of tinkering with car repairs, and various kinds of restoration: of furniture, antique cars, etc. It also applies to household tinkering: repairing a wall, laying a pathway, etc.

Making and Tinkering hobbies also include higher-end projects like building or restoring a car, or building a computer from individual parts, like CPUs and SSDs.
For computer savvy do-it-yourself hobbyists, CNC (Computer Numerical Control) machining is also popular. A CNC machine can be assembled and programmed to make different parts from wood or metal.

Outdoor pursuits are the group of activities which occur outdoors. These hobbies include gardening, hill walking, hiking, backpacking, cycling, canoeing, climbing, caving, fishing, hunting, wildlife viewing (as birdwatching) and engaging in watersports and snowsports.

Depending on an individual's desired level of adrenaline, outdoors experiences are considered one type of hobby. While many enjoy an adrenaline rush or just an escape from reality, outdoor recreational activities can also be an extremely effective medium in education and team building.

As interest increases, so has the desire for commercial outdoor pursuits. Outdoor recreational supply stores have opened in large numbers and are thriving, as have outdoor pursuit journalism and magazines, both on paper and the Internet.

The increased accessibility of outdoor pursuit resources has been the source of some negative publicity over the years, with complaints of the destruction of landscape. An example is the destruction of hillsides as footpaths are eroded due to an excessive number of visitors.

Many hobbies involve performances by the hobbyist, such as singing, acting, juggling, magic, dancing, playing a musical instrument, martial arts and other performing arts.

Some hobbies may result in an end product. Examples of this would be woodworking, photography, moviemaking, jewelry making, software projects such as Photoshopping and home music or video production, making bracelets, artistic projects such as drawing, painting, writing..., Cosplay (design, creation, and wearing a costume based on an already existing creative property), creating models out of card stock or paper – called papercraft. Many of these fall under the category visual arts.

Reading, books, ebooks, magazines, comics, or newspapers, along with browsing the internet is a common hobby, and one that can trace its origins back hundreds of years. A love of literature, later in life, may be sparked by an interest in reading children's literature as a child. Many of these fall under the category literary arts.

Stebbins makes a distinction between an amateur sports person playing a sport that has a professional equivalent such as football or tennis and a hobbyist playing a less formal sport or game that are rule bound but have no professional equivalent like deck tennis and long distance trekking. Amateur sport ranges from very informal play to highly competitive practice.

Evidence suggests that playing sports helps improve physical and mental health.

There have been many instances where hobbyists and amateurs have achieved significant discoveries and developments. These are a small sample. 



</doc>
<doc id="13288" url="https://en.wikipedia.org/wiki?curid=13288" title="Holland">
Holland

Holland is a region and former province on the western coast of the Netherlands. The name "Holland" is also frequently used informally to refer to the whole of the country of the Netherlands. This usage is commonly accepted in other countries, and sometimes employed by the Dutch themselves. However, some in the Netherlands, particularly in other regions of the country, may find it undesirable or misrepresentative.

From the 10th to the 16th century, Holland proper was a unified political region within the Holy Roman Empire as a county ruled by the Counts of Holland. By the 17th century, the province of Holland had risen to become a maritime and economic power, dominating the other provinces of the newly independent Dutch Republic.

The area of the former County of Holland roughly coincides with the two current Dutch provinces of North Holland and South Holland in which it was divided, which together include the Netherlands' three largest cities: the "de jure" capital city of Amsterdam; Rotterdam, home of Europe's largest port; and the seat of government of The Hague.

The name "Holland" first appeared in sources for the region around Haarlem, and by 1064 was being used as the name of the entire county. By the early twelfth century, the inhabitants of Holland were called "Hollandi" in a Latin text. "Holland" is derived from the Old Dutch term "holtlant" ("wood-land"). This spelling variation remained in use until around the 14th century, at which time the name stabilised as "Holland" (alternative spellings at the time were "Hollant" and "Hollandt"). A popular folk etymology holds that "Holland" is derived from "hol land" ("hollow land") and was inspired by the low-lying geography of Holland.

The proper name of the area in both Dutch and English is "Holland". Holland is a part of the Netherlands. "Holland" is informally used in English and other languages, including sometimes the Dutch language itself, to mean the whole of the modern country of the Netherlands. This example of "pars pro toto" or synecdoche is similar to the tendency to refer to the United Kingdom as "England", and developed due to Holland becoming the dominant province and thus having the majority of political and economic interactions with other countries.

Under Napoleon this usage was made official, the puppet kingdom ruled by his brother Louis Bonaparte being given the name "Kingdom of Holland" – but this was dropped after Napoleon's defeat and the restoration of the House of Orange.

The people of Holland are referred to as "Hollanders" in both Dutch and English, though in English this now unusual and nearly-archaic. Today this refers specifically to people from the current provinces of North Holland and South Holland. Strictly speaking, the term "Hollanders" does not refer to people from the other provinces in the Netherlands, but colloquially "Hollanders" is sometimes used in this wider sense.

In Dutch, the Dutch word ""Hollands"" is the adjectival form for ""Holland"". The Dutch word ""Hollands"" is also colloquially and occasionally used by some Dutch people in the sense of ""Nederlands"" (Dutch), but then often with the intention of contrasting with other types of Dutch people or language, for example Limburgish, the Belgian form of the Dutch language ("Flemish"), or even any southern variety of Dutch within the Netherlands itself.

In English, "Dutch" refers to the Netherlands as a whole, but there is no commonly used adjective for "Holland". The word "Hollandish" is no longer in common use. "Hollandic" is the name linguists give to the dialect spoken in Holland, and is occasionally also used by historians and when referring to pre-Napoleonic Holland.

Initially, Holland was a remote corner of the Holy Roman Empire. Gradually, its regional importance increased until it began to have a decisive, and ultimately dominant, influence on the History of the Netherlands.

Until the start of the 12th century, the inhabitants of the area that became Holland were known as Frisians. The area was initially part of Frisia. At the end of the 9th century, West-Frisia became a separate county in the Holy Roman Empire. The first Count known about with certainty was Dirk I, who ruled from 896 to 931. He was succeeded by a long line of counts in the House of Holland (who were in fact known as counts of Frisia until 1101). When John I, count of Holland, died childless in 1299, the county was inherited by John II of Avesnes, count of Hainaut. By the time of William V (House of Wittelsbach; 1354–1388) the count of Holland was also the count of Hainaut and Zealand.

After the St. Lucia's flood in 1287 the part of Frisia west of the later Zuiderzee, West Friesland, was conquered. As a result, most provincial institutions, including the States of Holland and West Frisia, would for more than five centuries refer to "Holland and West Frisia" as a unit. The Hook and Cod wars started around this time and ended when the countess of Holland, Jacoba or Jacqueline was forced to give up Holland to the Burgundian Philip III, known as Philip the Good, in 1432.

In 1432, Holland became part of the Burgundian Netherlands and since 1477 of the Habsburg Seventeen Provinces. In the 16th century the county became the most densely urbanised region in Europe, with the majority of the population living in cities. Within the Burgundian Netherlands, Holland was the dominant province in the north; the political influence of Holland largely determined the extent of Burgundian dominion in that area. The last count of Holland was Philip III, better known as Philip II, king of Spain. He was deposed in 1581 by the Act of Abjuration, although the kings of Spain continued to carry the titular appellation of Count of Holland until the Peace of Münster signed in 1648.

In the Dutch Rebellion against the Habsburgs during the Eighty Years' War, the naval forces of the rebels, the Watergeuzen, established their first permanent base in 1572 in the town of Brill. In this way, Holland, now a sovereign state in a larger Dutch confederation, became the centre of the rebellion. It became the cultural, political and economic centre of the United Provinces (), in the 17th century, the Dutch Golden Age, the wealthiest nation in the world. After the King of Spain was deposed as the count of Holland, the executive and legislative power rested with the States of Holland, which was led by a political figure who held the office of Grand Pensionary.

The largest cities in the Dutch Republic were in the province of Holland, such as Amsterdam, Rotterdam, Leiden, Alkmaar, The Hague, Delft, Dordrecht and Haarlem. From the great ports of Holland, Hollandic merchants sailed to and from destinations all over Europe, and merchants from all over Europe gathered to trade in the warehouses of Amsterdam and other trading cities of Holland.

Many Europeans thought of the United Provinces first as "Holland" rather than as the "Republic of the Seven United Provinces of the Netherlands". A strong impression of "Holland" was planted in the minds of other Europeans, which then was projected back onto the Republic as a whole. Within the provinces themselves, a gradual slow process of cultural expansion took place, leading to a "Hollandification" of the other provinces and a more uniform culture for the whole of the Republic. The dialect of urban Holland became the standard language.

The formation of the Batavian Republic, inspired by the French revolution, led to a more centralised government. Holland became a province of a unitary state. Its independence was further reduced by an administrative reform in 1798, in which its territory was divided into several departments called "Amstel", "Delf", "Texel", and part of "Schelde en Maas".

From 1806 to 1810 Napoleon styled his vassal state, governed by his brother Louis Napoleon and shortly by the son of Louis, Napoleon Louis Bonaparte, as the "Kingdom of Holland". This kingdom encompassed much of what would become the modern Netherlands. The name reflects how natural at the time it had become to equate Holland with the non-Belgian Netherlands as a whole.

During the period the Low Countries were annexed by the French Empire and actually incorporated into France (from 1810 to 1813), Holland was divided into départements Zuyderzée, and Bouches-de-la-Meuse. From 1811 to 1813 Charles-François Lebrun, duc de Plaisance served as governor-general. He was assisted by Antoine de Celles, Goswin de Stassart and François Jean-Baptiste d'Alphonse.

After 1813, Holland was restored as a province of the United Kingdom of the Netherlands. Holland was divided into the present provinces North Holland and South Holland in 1840, after the Belgian Revolution of 1830. This reflected a historical division of Holland along the IJ into a Southern Quarter ("Zuiderkwartier") and a Northern Quarter ("Noorderkwartier"), but the actual division is different from the old division. From 1850, a strong process of nation formation took place, the Netherlands being culturally unified and economically integrated by a modernisation process, with the cities of Holland as its centre.

Holland is situated in the west of the Netherlands. A maritime region, Holland lies on the North Sea at the mouths of the Rhine and the Meuse (Maas). It has numerous rivers and lakes and an extensive inland canal and waterway system. To the south is Zealand. The region is bordered on the east by the IJsselmeer and four different provinces of the Netherlands.

Holland is protected from the sea by a long line of coastal dunes. The highest point in Holland (about above sea level) is in the (Schoorl Dunes). Most of the land area behind the dunes consists of polder landscape lying well below sea level. At present the lowest point in Holland is a polder near Rotterdam, which is about below sea level. Continuous drainage is necessary to keep Holland from flooding. In earlier centuries windmills were used for this task. The landscape was (and in places still is) dotted with windmills, which have become a symbol of Holland.

Holland is (land and water included), making it roughly 13% of the area of the Netherlands. Looking at land alone, it is in area. The combined population is 6.1 million.

The main cities in Holland are Amsterdam, Rotterdam and The Hague. Amsterdam is formally the capital of the Netherlands and its largest city. The Port of Rotterdam is Europe's largest and most important harbour and port. The Hague is the seat of government of the Netherlands. These cities, combined with Utrecht and other smaller municipalities, effectively form a single metroplex—a conurbation called Randstad.

The Randstad area is one of the most densely populated regions of Europe, but still relatively free of urban sprawl. There are strict zoning laws. Population pressures are enormous, property values are high, and new housing is constantly under development on the edges of the built-up areas. Surprisingly, much of the province still has a rural character. The remaining agricultural land and natural areas are highly valued and protected. Most of the arable land is used for intensive agriculture, including horticulture and greenhouse agri-businesses.

The land that is now Holland had never been stable. Over the millennia the geography of the region had been dynamic. The western coastline shifted up to to the east and storm surges regularly broke through the row of coastal dunes. The Frisian Isles, originally joined to the mainland, became detached islands in the north. The main rivers, the Rhine and the Meuse (Maas), flooded regularly and changed course repeatedly and dramatically.

The people of Holland found themselves living in an unstable, watery environment. Behind the dunes on the coast of the Netherlands a high peat plateau had grown, forming a natural protection against the sea. Much of the area was marsh and bog. By the tenth century the inhabitants set about cultivating this land by draining it. However, the drainage resulted in extreme soil shrinkage, lowering the surface of the land by up to .

To the south of Holland, in Zeeland, and to the north, in Frisia, this development led to catastrophic storm floods literally washing away entire regions, as the peat layer disintegrated or became detached and was carried away by the flood water. From the Frisian side the sea even flooded the area to the east, gradually hollowing Holland out from behind and forming the Zuiderzee (the present IJsselmeer). This inland sea threatened to link up with the "drowned lands" of Zealand in the south, reducing Holland to a series of narrow dune barrier islands in front of a lagoon. Only drastic administrative intervention saved the county from utter destruction. The counts and large monasteries took the lead in these efforts, building the first heavy emergency dikes to bolster critical points. Later special autonomous administrative bodies were formed, the "waterschappen" ("water control boards"), which had the legal power to enforce their regulations and decisions on water management. As the centuries went by, they eventually constructed an extensive dike system that covered the coastline and the polders, thus protecting the land from further incursions by the sea.

However, the Hollanders did not stop there. Starting around the 16th century, they took the offensive and began land reclamation projects, converting lakes, marshy areas and adjoining mudflats into polders. This continued right into the 20th century. As a result, historical maps of mediaeval and early modern Holland bear little resemblance to the maps of today.

This ongoing struggle to master the water played an important role in the development of Holland as a maritime and economic power and in the development of the character of the people of Holland.

Holland tends to be associated with a particular image. The stereotypical image of Holland is an artificial amalgam of tulips, windmills, clogs, cheese and traditional dress ("klederdracht"). As is the case with many stereotypes, this is far from the truth and reality of life in Holland. This can at least in part be explained by the active exploitation of these stereotypes in promotions of Holland and the Netherlands. In fact only in a few of the more traditional villages, such as Volendam and locations in the Zaan area, are the different costumes with wooden shoes still worn by some inhabitants.

The predominance of Holland in the Netherlands has resulted in regionalism on the part of the other provinces. This is a reaction to the perceived threat that Holland poses to the identities and local cultures of the other provinces. The other provinces have a strong, and often negative, image of Holland and the Hollanders, to whom certain qualities are ascribed within a mental geography, a conceptual mapping of spaces and their inhabitants. On the other hand, some Hollanders take Holland's cultural dominance for granted and treat the concepts of "Holland" and the "Netherlands" as coincidental. Consequently, they see themselves not primarily as "Hollanders", but simply as "Dutch" ("Nederlanders"). This phenomenon has been called "hollandocentrism".

The predominant language spoken in Holland is Dutch. Hollanders sometimes refer to the Dutch language as ""Hollands,"" instead of the standard term "Nederlands". Inhabitants of Belgium and other provinces of the Netherlands refer to "Hollands" to indicate someone speaking in a Hollandic dialect, or strong accent.

Standard Dutch was historically largely based on the dialect of the County of Holland, incorporating many traits derived from the dialects of the previously more powerful Duchy of Brabant and County of Flanders. Strong dialectal variation still exists throughout the Low Countries. Today, Holland-proper is the region where the original dialects are least spoken, in many areas having been completely replaced by standard Dutch, and the Randstad has the largest influence on the developments of the standard language—with the exception of the Dutch spoken in Belgium.

Despite this correspondence between standard Dutch and the Dutch spoken in the Randstad, there are local variations within Holland itself that differ from standard Dutch. The main cities each have their own modern urban dialect, that can be considered a sociolect. A small number of people, especially in the area north of Amsterdam, still speak the original dialect of the county, Hollandic. The Hollandic dialect is present in the north: Volendam and Marken and the area around there, West Friesland and the Zaanstreek; and in a south-eastern fringe bordering on the provinces of North Brabant and Utrecht. In the south on the island of Goeree-Overflakkee, Zealandic is spoken.

The province of Holland gave its name to a number of colonial settlements and discovered regions that were called "Nieuw Holland" or New Holland. The most extensive of these was the island continent presently known as Australia: New Holland was first applied to Australia in 1644 by the Dutch seafarer Dirk Hartog as a Latin "Nova Hollandia", and remained in international use for 190 years. Another Dutch explorer, Abel Tasman named New Zealand after the Dutch province of Zealand. In the Netherlands "Nieuw Holland" would remain the usual name of the continent until the end of the 19th century; it is now no longer in use there, the Dutch name today being "Australië".

While "Holland" has been replaced in English as the official name for the country of the Netherlands, other languages still use it or a variant of it to officially refer to the Netherlands. This is still the case in all Indonesian languages, for example:


</doc>
<doc id="13289" url="https://en.wikipedia.org/wiki?curid=13289" title="History of the Netherlands">
History of the Netherlands

The history of the Netherlands is the history of seafaring people thriving on a lowland river delta on the North Sea in northwestern Europe. Records begin with the four centuries during which the region formed a militarized border zone of the Roman empire. This came under increasing pressure from Germanic peoples moving westwards. As Roman power collapsed and the Middle Ages began, three dominant Germanic peoples coalesced in the area, Frisians in the north and coastal areas, Low Saxons in the northeast, and the Franks in the south.

During the Middle Ages, the descendants of the Carolingian dynasty came to dominate the area and then extended their rule to a large part of Western Europe. The region of the Netherlands therefore became part of Lower Lotharingia within the Frankish Holy Roman Empire. For several centuries, lordships such as Brabant, Holland, Zeeland, Friesland, Guelders and others held a changing patchwork of territories. There was no unified equivalent of the modern Netherlands.
By 1433, the Duke of Burgundy had assumed control over most of the lowlands territories in Lower Lotharingia; he created the Burgundian Netherlands which included modern Belgium, Luxembourg, and a part of France.

The Catholic kings of Spain took strong measures against Protestantism, which polarized the peoples of present-day Belgium and Holland. The subsequent Dutch revolt led to splitting the Burgundian Netherlands into a Catholic French and Dutch-speaking "Spanish Netherlands" (approximately corresponding to modern Belgium and Luxembourg), and a northern "United Provinces", which spoke Dutch and were predominantly Protestant with a Catholic minority. It became the modern Netherlands.

In the Dutch Golden Age, which had its zenith around 1667, there was a flowering of trade, industry, the arts and the sciences. A rich worldwide Dutch empire developed and the Dutch East India Company became one of the earliest and most important of national mercantile companies based on entrepreneurship and trade.

During the 18th century the power and wealth of the Netherlands declined. A series of wars with the more powerful British and French neighbors weakened it. Britain seized the North American colony of New Amsterdam, turning it into New York. There was growing unrest and conflict between the Orangists and the Patriots. The French Revolution spilled over after 1789, and a pro-French Batavian Republic was established in 1795–1806. Napoleon made it a satellite state, the Kingdom of Holland (1806–1810), and later simply a French imperial province.

After the collapse of Napoleon in 1813–15, an expanded "United Kingdom of the Netherlands" was created with the House of Orange as monarchs, also ruling Belgium and Luxembourg. The King imposed unpopular Protestant reforms on Belgium, which revolted in 1830 and became independent in 1839. After an initially conservative period, in the 1848 constitution the country became a parliamentary democracy with a constitutional monarch. Modern Luxembourg became officially independent from the Netherlands in 1839, but a personal union remained until 1890. Since 1890 it is ruled by another branch of the House of Nassau.

The Netherlands was neutral during the First World War, but during the Second World War, it was invaded and occupied by Nazi Germany. The Nazis, including many collaborators, rounded up and killed almost all the Jews (most famously Anne Frank). When the Dutch resistance increased, the Nazis cut off food supplies to much of the country, causing severe starvation in 1944–45. In 1942, the Dutch East Indies was conquered by Japan, but first the Dutch destroyed the oil wells that Japan needed so badly. Indonesia proclaimed its independence in 1945. Suriname gained independence in 1975. The postwar years saw rapid economic recovery (helped by the American Marshall Plan), followed by the introduction of a welfare state during an era of peace and prosperity. The Netherlands formed a new economic alliance with Belgium and Luxembourg, the Benelux, and all three became founding members of the European Union and NATO. In recent decades, the Dutch economy has been closely linked to that of Germany, and is highly prosperous.

The prehistory of the area that is now the Netherlands was largely shaped by its constantly shifting, low-lying geography.
The area that is now the Netherlands was inhabited by early humans at least 37,000 years ago, as attested by flint tools discovered in Woerden in 2010. In 2009 a fragment of a 40,000-year-old Neanderthal skull was found in sand dredged from the North Sea floor off the coast of Zeeland.

During the last ice age, the Netherlands had a tundra climate with scarce vegetation and the inhabitants survived as hunter-gatherers. After the end of the ice age, various Paleolithic groups inhabited the area. It is known that around 8000 BC a Mesolithic tribe resided near Burgumer Mar (Friesland). Another group residing elsewhere is known to have made canoes. The oldest recovered canoe in the world is the Pesse canoe. According to C14 dating analysis it was constructed somewhere between 8200 BC and 7600 BC. This canoe is exhibited in the Drents Museum in Assen.

Autochthonous hunter-gatherers from the Swifterbant culture are attested from around 5600 BC onwards. They are strongly linked to rivers and open water and were related to the southern Scandinavian Ertebølle culture (5300–4000 BC). To the west, the same tribes might have built hunting camps to hunt winter game, including seals.

Agriculture arrived in the Netherlands somewhere around 5000 BC with the Linear Pottery culture, who were probably central European farmers. Agriculture was practised only on the loess plateau in the very south (southern Limburg), but even there it was not established permanently. Farms did not develop in the rest of the Netherlands.

There is also some evidence of small settlements in the rest of the country. These people made the switch to animal husbandry sometime between 4800 BC and 4500 BC. Dutch archaeologist Leendert Louwe Kooijmans wrote, "It is becoming increasingly clear that the agricultural transformation of prehistoric communities was a purely indigenous process that took place very gradually." This transformation took place as early as 4300 BC–4000 BC and featured the introduction of grains in small quantities into a traditional broad-spectrum economy.

The Funnelbeaker culture was a farming culture extending from Denmark through northern Germany into the northern Netherlands. In this period of Dutch prehistory the first notable remains were erected: the dolmens, large stone grave monuments. They are found in Drenthe, and were probably built between 4100 BC and 3200 BC.

To the west, the Vlaardingen culture (around 2600 BC), an apparently more primitive culture of hunter-gatherers survived well into the Neolithic period.

Around 2950 BCE there was a transition from the Funnelbeaker farming culture to the Corded Ware pastoralist culture, a large archeological horizon appearing in western and central Europe, that is associated with the advance of Indo-European languages. This transition was probably caused by developments in eastern Germany, and it occurred within two generations.

The Bell Beaker culture was also present in the Netherlands.

The Corded Ware and Bell Beaker cultures were not indigenous to the Netherlands but were pan-European in nature, extending across much of northern and central Europe.

The first evidence of the use of the wheel dates from this period, about 2400 BC. This culture also experimented with working with copper. Evidence of this, including stone anvils, copper knives, and a copper spearhead, was found on the Veluwe. Copper finds show that there was trade with other areas in Europe, as natural copper is not found in Dutch soil.

The Bronze Age probably started somewhere around 2000 BC and lasted until around 800 BC. The earliest bronze tools have been found in the grave of a Bronze Age individual called "the smith of Wageningen". More Bronze Age objects from later periods have been found in Epe, Drouwen and elsewhere. Broken bronze objects found in Voorschoten were apparently destined for recycling. This indicates how valuable bronze was considered in the Bronze Age. Typical bronze objects from this period included knives, swords, axes, fibulae and bracelets.
Most of the Bronze Age objects found in the Netherlands have been found in Drenthe. One item shows that trading networks during this period extended a far distance. Large bronze "situlae" (buckets) found in Drenthe were manufactured somewhere in eastern France or in Switzerland. They were used for mixing wine with water (a Roman/Greek custom). The many finds in Drenthe of rare and valuable objects, such as tin-bead necklaces, suggest that Drenthe was a trading centre in the Netherlands in the Bronze Age.

The Bell Beaker cultures (2700–2100) locally developed into the Bronze Age Barbed-Wire Beaker culture (2100–1800). In the second millennium BC, the region was the boundary between the Atlantic and Nordic horizons and was split into a northern and a southern region, roughly divided by the course of the Rhine.

In the north, the Elp culture (c. 1800 to 800 BC) was a Bronze Age archaeological culture having earthenware pottery of low quality known as ""Kümmerkeramik"" (or ""Grobkeramik"") as a marker. The initial phase was characterized by tumuli (1800–1200 BC) that were strongly tied to contemporary tumuli in northern Germany and Scandinavia, and were apparently related to the Tumulus culture (1600–1200 BC) in central Europe. This phase was followed by a subsequent change featuring Urnfield (cremation) burial customs (1200–800 BC). The southern region became dominated by the Hilversum culture (1800–800), which apparently inherited the cultural ties with Britain of the previous Barbed-Wire Beaker culture.

The Iron Age brought a measure of prosperity to the people living in the area of the present-day Netherlands. Iron ore was available throughout the country, including bog iron extracted from the ore in peat bogs ("moeras ijzererts") in the north, the natural iron-bearing balls found in the Veluwe and the red iron ore near the rivers in Brabant. Smiths travelled from small settlement to settlement with bronze and iron, fabricating tools on demand, including axes, knives, pins, arrowheads and swords. Some evidence even suggests the making of Damascus steel swords using an advanced method of forging that combined the flexibility of iron with the strength of steel.

In Oss, a grave dating from around 500 BC was found in a burial mound 52 metres wide (and thus the largest of its kind in western Europe). Dubbed the "king's grave" ("Vorstengraf (Oss)"), it contained extraordinary objects, including an iron sword with an inlay of gold and coral.

In the centuries just before the arrival of the Romans, northern areas formerly occupied by the Elp culture emerged as the probably Germanic Harpstedt culture while the southern parts were influenced by the Hallstatt culture and assimilated into the Celtic La Tène culture. The contemporary southern and western migration of Germanic groups and the northern expansion of the Hallstatt culture drew these peoples into each other's sphere of influence. This is consistent with Caesar's account of the Rhine forming the boundary between Celtic and Germanic tribes.

The Germanic tribes originally inhabited southern Scandinavia, Schleswig-Holstein and Hamburg, but subsequent Iron Age cultures of the same region, like Wessenstedt (800–600 BC) and Jastorf, may also have belonged to this grouping.
The climate deteriorating in Scandinavia around 850 BC to 760 BC and later and faster around 650 BC might have triggered migrations. Archaeological evidence suggests around 750 BC a relatively uniform Germanic people from the Netherlands to the Vistula and southern Scandinavia. In the west, the newcomers settled the coastal floodplains for the first time, since in adjacent higher grounds the population had increased and the soil had become exhausted.

By the time this migration was complete, around 250 BC, a few general cultural and linguistic groupings had emerged.

One grouping - labelled the "North Sea Germanic" – inhabited the northern part of the Netherlands (north of the great rivers) and extending along the North Sea and into Jutland. This group is also sometimes referred to as the "Ingvaeones". Included in this group are the peoples who would later develop into, among others, the early Frisians and the early Saxons.

A second grouping, which scholars subsequently dubbed the "Weser-Rhine Germanic" (or "Rhine-Weser Germanic"), extended along the middle Rhine and Weser and inhabited the southern part of the Netherlands (south of the great rivers). This group, also sometimes referred to as the "Istvaeones", consisted of tribes that would eventually develop into the Salian Franks.
The Celtic culture had its origins in the central European Hallstatt culture (c. 800–450 BC), named for the rich grave finds in Hallstatt, Austria. By the later La Tène period (c. 450 BC up to the Roman conquest), this Celtic culture had, whether by diffusion or migration, expanded over a wide range, including into the southern area of the Netherlands. This would have been the northern reach of the Gauls.

In March 2005 17 Celtic coins were found in Echt (Limburg). The silver coins, mixed with copper and gold, date from around 50 BC to 20 AD. In October 2008 a hoard of 39 gold coins and 70 silver Celtic coins was found in the Amby area of Maastricht. The gold coins were attributed to the Eburones people. Celtic objects have also been found in the area of Zutphen.

Although it is rare for hoards to be found, in past decades loose Celtic coins and other objects have been found throughout the central, eastern and southern part of the Netherlands. According to archaeologists these finds confirmed that at least the Maas river valley in the Netherlands was within the influence of the La Tène culture. Dutch archaeologists even speculate that Zutphen (which lies in the centre of the country) was a Celtic area before the Romans arrived, not a Germanic one at all.

Scholars debate the actual extent of the Celtic influence. The Celtic influence and contacts between Gaulish and early Germanic culture along the Rhine is assumed to be the source of a number of Celtic loanwords in Proto-Germanic. But according to Belgian linguist Luc van Durme, toponymic evidence of a former Celtic presence in the Low Countries is near to utterly absent. Although there were Celts in the Netherlands, Iron Age innovations did not involve substantial Celtic intrusions and featured a local development from Bronze Age culture.

Some scholars (De Laet, Gysseling, Hachmann, Kossack & Kuhn) have speculated that a separate ethnic identity, neither Germanic nor Celtic, survived in the Netherlands until the Roman period. They see the Netherlands as having been part of an Iron Age "Nordwestblock" stretching from the Somme to the Weser. Their view is that this culture, which had its own language, was being absorbed by the Celts to the south and the Germanic peoples from the east as late as the immediate pre-Roman period.

During the Gallic Wars, the Belgic area south of the Oude Rijn and west of the Rhine was conquered by Roman forces under Julius Caesar in a series of campaigns from 57 BC to 53 BC. The tribes located in the area of the Netherlands at this time did not leave behind written records, so all the information known about them during this pre-Roman period is based on what the Romans and Greeks wrote about them. One of the most important is Caesar's own "Commentarii de Bello Gallico". Two main tribes he described as living in what is now the Netherlands were the Menapii, and the Eburones, both in the south, which is where Caesar was active. He established the principle that the Rhine defined a natural boundary between Gaul and Germania magna. But the Rhine was not a strong border, and he made it clear that there was a part of Belgic Gaul where many of the local tribes (including the Eburones) were "Germani cisrhenani", or in other cases, of mixed origin.

The Menapii stretched from the south of Zeeland, through North Brabant (and possibly South Holland), into the southeast of Gelderland. In later Roman times their territory seems to have been divided or reduced, so that it became mainly contained in what is now western Belgium.

The Eburones, the largest of the "Germani Cisrhenani" group, covered a large area including at least part of modern Dutch Limburg, stretching east to the Rhine in Germany, and also northwest to the delta, giving them a border with the Menapii. Their territory may have stretched into Gelderland.

In the delta itself, Caesar makes a passing comment about the "Insula Batavorum" ("Island of the Batavi") in the Rhine river, without discussing who lived there. Later, in imperial times, a tribe called the Batavi became very important in this region. Much later Tacitus wrote that they had originally been a tribe of the Chatti, a tribe in Germany never mentioned by Caesar. However, archaeologists find evidence of continuity, and suggest that the Chattic group may have been a small group, moving into a pre-existing (and possibly non-Germanic) people, who could even have been part of a known group such as the Eburones.

The approximately 450 years of Roman rule that followed would profoundly change the area that would become the Netherlands. Very often this involved large-scale conflict with the free Germanic tribes over the Rhine.

Other tribes who eventually inhabited the islands in the delta during Roman times are mentioned by Pliny the Elder are the Cananefates in South Holland; the Frisii, covering most of the modern Netherlands north of the Oude Rijn; the Frisiabones, who apparently stretched from the delta into the North of North Brabant; the Marsacii, who stretched from the Flemish coast, into the delta; and the Sturii.

Caesar reported that he eliminated the name of the Eburones but in their place the Texuandri inhabited most of North Brabant, and the modern province of Limburg, with the Maas running through it, appears to have been inhabited in imperial times by (from north to south) the Baetasii, the Catualini, the Sunuci and the Tungri. (Tacitus reported that the Tungri was a new name for the earlier "Germani cisrhenani".)

North of the Old Rhine, apart from the Frisii, Pliny reports some Chauci reached into the delta, and two other tribes known from the eastern Netherlands were the Tuihanti (or Tubantes) from Twenthe in Overijssel, and the Chamavi, from Hamaland in northern Gelderland, who became one of the first tribes to be named as Frankish (see below). The Salians, also Franks, probably originated in Salland in Overijssel, before they moved into the empire, forced by Saxons in the 4th century, first into Batavia, and then into Toxandria.

Starting about 15 BC, the Rhine, in the Netherlands came to be defended by the Lower Limes Germanicus. After a series of military actions, the Rhine became fixed around 12 AD as Rome's northern frontier on the European mainland. A number of towns and developments would arise along this line. The area to the south would be integrated into the Roman Empire. At first part of Gallia Belgica, this area became part of the province of Germania Inferior. The tribes already within, or relocated to, this area became part of the Roman Empire. The area to the north of the Rhine, inhabited by the Frisii and the Chauci, remained outside Roman rule but not its presence and control.

Romans built military forts along the Limes Germanicus and a number of towns and smaller settlements in the Netherlands. The more notable Roman towns were at Nijmegen () and at Voorburg (Forum Hadriani).

Perhaps the most evocative Roman ruin is the mysterious Brittenburg, which emerged from the sand at the beach in Katwijk several centuries ago, only to be buried again. These ruins were part of .

Other Roman settlements, fortifications, temples and other structures have been found at Alphen aan de Rijn (Albaniana); Bodegraven; Cuijk; Elst, Overbetuwe; Ermelo; Esch; Heerlen; Houten; Kessel, North Brabant; Oss, i.e. De Lithse Ham near Maren-Kessel; Kesteren in Neder-Betuwe; Leiden (Matilo); Maastricht; Meinerswijk (now part of Arnhem); Tiel; Utrecht (Traiectum); Valkenburg (South Holland) (Praetorium Agrippinae); Vechten (Fectio) now part of Bunnik; Velsen; Vleuten; Wijk bij Duurstede (); Woerden ( or ); and Zwammerdam ().

The Batavians, Cananefates, and the other border tribes were held in high regard as soldiers throughout the empire, and traditionally served in the Roman cavalry. The frontier culture was influenced by the Romans, Germanic people, and Gauls. In the first centuries after Rome's conquest of Gaul, trade flourished. And Roman, Gaulish and Germanic material culture are found combined in the region.

However, the Batavians rose against the Romans in the Batavian rebellion of 69 AD. The leader of this revolt was Batavian Gaius Julius Civilis. One of the causes of the rebellion was that the Romans had taken young Batavians as slaves. A number of Roman "castella" were attacked and burnt. Other Roman soldiers in Xanten and elsewhere and auxiliary troops of Batavians and Canninefatae in the legions of Vitellius) joined the revolt, thus splitting the northern part of the Roman army. In April 70 AD, a few legions sent by Vespasianus and commanded by Quintus Petillius Cerialis eventually defeated the Batavians and negotiated surrender with Gaius Julius Civilis somewhere between the Waal and the Maas near Noviomagus (Nijmegen), which was probably called "Batavodurum" by the Batavians. The Batavians later merged with other tribes and became part of the Salian Franks.

Dutch writers in the 17th and 18th centuries saw the rebellion of the independent and freedom-loving Batavians as mirroring the Dutch revolt against Spain and other forms of tyranny. According to this nationalist view, the Batavians were the "true" forefathers of the Dutch, which explains the recurring use of the name over the centuries. Jakarta was named "Batavia" by the Dutch in 1619. The Dutch republic created in 1795 on the basis of French revolutionary principles was called the Batavian Republic. Even today "Batavian" is a term sometimes used to describe the Dutch people. (This is similar to use of "Gallic" to describe the French and "Teutonic" to describe the Germans.)

Modern scholars of the Migration Period are in agreement that the Frankish identity emerged at the first half of the 3rd century out of various earlier, smaller Germanic groups, including the Salii, Sicambri, Chamavi, Bructeri, Chatti, Chattuarii, Ampsivarii, Tencteri, Ubii, Batavi and the Tungri, who inhabited the lower and middle Rhine valley between the Zuyder Zee and the river Lahn and extended eastwards as far as the Weser, but were the most densely settled around the IJssel and between the Lippe and the Sieg. The Frankish confederation probably began to coalesce in the 210s.

The Franks eventually were divided into two groups: the Ripuarian Franks (Latin: Ripuari), who were the Franks that lived along the middle-Rhine River during the Roman Era, and the Salian Franks, who were the Franks that originated in the area of the Netherlands.

Franks appear in Roman texts as both allies and enemies ("laeti" and "dediticii"). By about 320, the Franks had the region of the Scheldt river (present day west Flanders and southwest Netherlands) under control, and were raiding the Channel, disrupting transportation to Britain. Roman forces pacified the region, but did not expel the Franks, who continued to be feared as pirates along the shores at least until the time of Julian the Apostate (358), when Salian Franks were allowed to settle as "foederati" in Toxandria, according to Ammianus Marcellinus.

Three factors contributed to the disappearance of the Frisii from the northern Netherlands. First, according to the "Panegyrici Latini" (Manuscript VIII), the ancient Frisii were forced to resettle within Roman territory as "laeti" (i.e., Roman-era serfs) in c. 296. This is the last reference to the ancient Frisii in the historical record. What happened to them, however, is suggested in the archaeological record. The discovery of a type of earthenware unique to 4th-century Frisia, called "terp Tritzum", shows that an unknown number of them were resettled in Flanders and Kent, likely as "laeti" under Roman coercion.
Second, the environment in the low-lying coastal regions of northwestern Europe began to lower c. 250 and gradually receded over the next 200 years. Tectonic subsidence, a rising water table and storm surges combined to flood some areas with marine transgressions. This was accelerated by a shift to a cooler, wetter climate in the region. If there had been any Frisii left in Frisia, they would have drowned. 
Third, after the collapse of the Roman Empire, there was a decline in population as Roman activity stopped and Roman institutions withdrew. As a result of these three factors, the Frisii and Frisiaevones disappeared from the area. The coastal lands remained largely unpopulated for the next two centuries.

As climatic conditions improved, there was another mass migration of Germanic peoples into the area from the east. This is known as the "Migration Period" ("Volksverhuizingen"). The northern Netherlands received an influx of new migrants and settlers, mostly Saxons, but also Angles and Jutes. Many of these migrants did not stay in the northern Netherlands but moved on to England and are known today as the Anglo-Saxons. The newcomers who stayed in the northern Netherlands would eventually be referred to as "Frisians", although they were not descended from the ancient Frisii. These new Frisians settled in the northern Netherlands and would become the ancestors of the modern Frisians. (Because the early Frisians and Anglo-Saxons were formed from largely identical tribal confederacies, their respective languages were very similar. Old Frisian is the most closely related language to Old English and the modern Frisian dialects are in turn the closest related languages to contemporary English.) By the end of the 6th century, the Frisian territory in the northern Netherlands had expanded west to the North Sea coast and, by the 7th century, south to Dorestad. During this period most of the northern Netherlands was known as Frisia. This extended Frisian territory is sometimes referred to as "Frisia Magna" (or Greater Frisia).
In the 7th and 8th centuries, the Frankish chronologies mention this area as the kingdom of the Frisians. This kingdom comprised the coastal provinces of the Netherlands and the German North Sea coast. During this time, the Frisian language was spoken along the entire southern North Sea coast. The 7th-century Frisian Kingdom (650–734) under King Aldegisel and King Redbad, had its centre of power in Utrecht.

Dorestad was the largest settlement (emporia) in northwestern Europe. It had grown around a former Roman fortress. It was a large, flourishing trading place, three kilometers long and situated where the rivers Rhine and Lek diverge southeast of Utrecht near the modern town of Wijk bij Duurstede. Although inland, it was a North Sea trading centre that primarily handled goods from the Middle Rhineland. Wine was among the major products traded at Dorestad, likely from vineyards south of Mainz. It was also widely known because of its mint. Between 600 and around 719 Dorestad was often fought over between the Frisians and the Franks.

After Roman government in the area collapsed, the Franks expanded their territories until there were numerous small Frankish kingdoms, especially at Cologne, Tournai, Le Mans and Cambrai. The kings of Tournai eventually came to subdue the other Frankish kings. By the 490s, Clovis I had conquered and united all the Frankish territories to the west of the Meuse, including those in the southern Netherlands. He continued his conquests into Gaul.

After the death of Clovis I in 511, his four sons partitioned his kingdom amongst themselves, with Theuderic I receiving the lands that were to become Austrasia (including the southern Netherlands). A line of kings descended from Theuderic ruled Austrasia until 555, when it was united with the other Frankish kingdoms of Chlothar I, who inherited all the Frankish realms by 558. He redivided the Frankish territory amongst his four sons, but the four kingdoms coalesced into three on the death of Charibert I in 567. Austrasia (including the southern Netherlands) was given to Sigebert I. The southern Netherlands remained the northern part of Austrasia until the rise of the Carolingians.

The Franks who expanded south into Gaul settled there and eventually adopted the Vulgar Latin of the local population. However, a Germanic language was spoken as a second tongue by public officials in western Austrasia and Neustria as late as the 850s. It completely disappeared as a spoken language from these regions during the 10th century. During this expansion to the south, many Frankish people remained in the north (i.e. southern Netherlands, Flanders and a small part of northern France). A widening cultural divide grew between the Franks remaining in the north and the rulers far to the south in what is now France. Salian Franks continued to reside in their original homeland and the area directly to the south and to speak their original language, Old Frankish, which by the 9th century had evolved into Old Dutch. A Dutch-French language boundary came into existence (but this was originally south of where it is today). In the Maas and Rhine areas of the Netherlands, the Franks had political and trading centres, especially at Nijmegen and Maastricht. These Franks remained in contact with the Frisians to the north, especially in places like Dorestad and Utrecht.

In the late 19th century, Dutch historians believed that the Franks, Frisians, and Saxons were the original ancestors of the Dutch people. Some went further by ascribing certain attributes, values and strengths to these various groups and proposing that they reflected 19th-century nationalist and religious views. In particular, it was believed that this theory explained why Belgium and the southern Netherlands (i.e. the Franks) had become Catholic and the northern Netherlands (Frisians and Saxons) had become Protestant. The success of this theory was partly due to anthropological theories based on a tribal paradigm. Being politically and geographically inclusive, and yet accounting for diversity, this theory was in accordance with the need for nation-building and integration during the 1890–1914 period. The theory was taught in Dutch schools.

However, the disadvantages of this historical interpretation became apparent. This tribal-based theory suggested that external borders were weak or non-existent and that there were clear-cut internal borders. This origins myth provided an historical premise, especially during the Second World War, for regional separatism and annexation to Germany. After 1945 the tribal paradigm lost its appeal for anthropological scholars and historians. When the accuracy of the three-tribe theme was fundamentally questioned, the theory fell out of favour.

Due to the scarcity of written sources, knowledge of this period depends to a large degree on the interpretation of archaeological data. The traditional view of a clear-cut division between Frisians in the north and coast, Franks in the south and Saxons in the east has proven historically problematic. Archeological evidence suggests dramatically different models for different regions, with demographic continuity for some parts of the country and depopulation and possible replacement in other parts, notably the coastal areas of Frisia and Holland.

The language from which Old Dutch (also sometimes called Old West Low Franconian, Old Low Franconian or Old Frankish) arose is not known with certainty, but it is thought to be the language spoken by the Salian Franks. Even though the Franks are traditionally categorized as Weser-Rhine Germanic, Dutch has a number of Ingvaeonic characteristics and is classified by modern linguists as an Ingvaeonic language. Dutch also has a number of Old Saxon characteristics. There was a close relationship between Old Dutch, Old Saxon, Old English and Old Frisian. Because texts written in the language spoken by the Franks are almost non-existent, and Old Dutch texts scarce and fragmentary, not much is known about the development of Old Dutch. Old Dutch made the transition to Middle Dutch around 1150.

The Christianity that arrived in the Netherlands with the Romans appears not to have died out completely (in Maastricht, at least) after the withdrawal of the Romans in about 411.

The Franks became Christians after their king Clovis I converted to Catholicism, an event which is traditionally set in 496. Christianity was introduced in the north after the conquest of Friesland by the Franks. The Saxons in the east were converted before the conquest of Saxony, and became Frankish allies.

Hiberno-Scottish and Anglo-Saxon missionaries, particularly Willibrord, Wulfram and Boniface, played an important role in converting the Frankish and Frisian peoples to Christianity by the 8th century. Boniface was martyred by the Frisians in Dokkum (754).

In the early 8th century the Frisians came increasingly into conflict with the Franks to the south, resulting in a series of wars in which the Frankish Empire eventually subjugated Frisia. In 734, at the Battle of the Boarn, the Frisians in the Netherlands were defeated by the Franks, who thereby conquered the area west of the Lauwers. The Franks then conquered the area east of the Lauwers in 785 when Charlemagne defeated Widukind.

The linguistic descendants of the Franks, the modern Dutch-speakers of the Netherlands and Flanders, seem to have broken with the endonym "Frank" around the 9th century. By this time Frankish identity had changed from an ethnic identity to a national identity, becoming localized and confined to the modern "Franconia" and principally to the French province of "Île-de-France".

Although the people no longer referred to themselves as "Franks", the Netherlands was still part of the Frankish empire of Charlemagne. Indeed, because of the Austrasian origins of the Carolingians in the area between the Rhine and the Maas, the cities of Aachen, Maastricht, Liège and Nijmegen were at the heart of Carolingian culture. Charlemagne maintained his "palatium" in Nijmegen at least four times.

The Carolingian empire would eventually include France, Germany, northern Italy and much of Western Europe. In 843, the Frankish empire was divided into three parts, giving rise to West Francia in the west, East Francia in the east, and Middle Francia in the centre. Most of what is today the Netherlands became part of Middle Francia; Flanders became part of West Francia. This division was an important factor in the historical distinction between Flanders and the other Dutch-speaking areas.

Middle Francia () was an ephemeral Frankish kingdom that had no historical or ethnic identity to bind its varied peoples. It was created by the Treaty of Verdun in 843, which divided the Carolingian Empire among the sons of Louis the Pious. Situated between the realms of East and West Francia, Middle Francia comprised the Frankish territory between the rivers Rhine and Scheldt, the Frisian coast of the North Sea, the former Kingdom of Burgundy (except for a western portion, later known as "Bourgogne"), Provence and the Kingdom of Italy.

Middle Francia fell to Lothair I, the eldest son and successor of Louis the Pious, after an intermittent civil war with his younger brothers Louis the German and Charles the Bald. In acknowledgement of Lothair's Imperial title, Middle Francia contained the imperial cities of Aachen, the residence of Charlemagne, as well as Rome. In 855, on his deathbed at Prüm Abbey, Emperor Lothair I again partitioned his realm amongst his sons. Most of the lands north of the Alps, including the Netherlands, passed to Lothair II and consecutively were named Lotharingia. After Lothair II died in 869, Lotharingia was partitioned by his uncles Louis the German and Charles the Bald in the Treaty of Meerssen in 870. Although some of the Netherlands had come under Viking control, in 870 it technically became part of East Francia, which became the Holy Roman Empire in 962.

In the 9th and 10th centuries, the Vikings raided the largely defenceless Frisian and Frankish towns lying on the coast and along the rivers of the Low Countries. Although Vikings never settled in large numbers in those areas, they did set up long-term bases and were even acknowledged as lords in a few cases. In Dutch and Frisian historical tradition, the trading centre of Dorestad declined after Viking raids from 834 to 863; however, since no convincing Viking archaeological evidence has been found at the site (as of 2007), doubts about this have grown in recent years.

One of the most important Viking families in the Low Countries was that of Rorik of Dorestad (based in Wieringen) and his brother the "younger Harald" (based in Walcheren), both thought to be nephews of Harald Klak. Around 850, Lothair I acknowledged Rorik as ruler of most of Friesland. And again in 870, Rorik was received by Charles the Bald in Nijmegen, to whom he became a vassal. Viking raids continued during that period. Harald’s son Rodulf and his men were killed by the people of Oostergo in 873. Rorik died sometime before 882.

Buried Viking treasures consisting mainly of silver have been found in the Low Countries. Two such treasures have been found in Wieringen. A large treasure found in Wieringen in 1996 dates from around 850 and is thought perhaps to have been connected to Rorik. The burial of such a valuable treasure is seen as an indication that there was a permanent settlement in Wieringen.

Around 879, Godfrid arrived in Frisian lands as the head of a large force that terrorised the Low Countries. Using Ghent as his base, they ravaged Ghent, Maastricht, Liège, Stavelot, Prüm, Cologne, and Koblenz. Controlling most of Frisia between 882 and his death in 885, Godfrid became known to history as Godfrid, Duke of Frisia. His lordship over Frisia was acknowledged by Charles the Fat, to whom he became a vassal. Godfried was assassinated in 885, after which Gerolf of Holland assumed lordship and Viking rule of Frisia came to an end.

Viking raids of the Low Countries continued for over a century. Remains of Viking attacks dating from 880 to 890 have been found in Zutphen and Deventer. In 920, King Henry of Germany liberated Utrecht. According to a number of chronicles, the last attacks took place in the first decade of the 11th century and were directed at Tiel and/or Utrecht.

These Viking raids occurred about the same time that French and German lords were fighting for supremacy over the middle empire that included the Netherlands, so their sway over this area was weak. Resistance to the Vikings, if any, came from local nobles, who gained in stature as a result.

The German kings and emperors ruled the Netherlands in the 10th and 11th century. Germany was called the Holy Roman Empire after the coronation of King Otto the Great as emperor. The Dutch city of Nijmegen used to be the spot of an important domain of the German emperors. Several German emperors were born and died there, including for example Byzantine empress Theophanu, who died in Nijmegen. Utrecht was also an important city and trading port at the time.

The Holy Roman Empire was not able to maintain political unity. In addition to the growing independence of the towns, local rulers turned their counties and duchies into private kingdoms and felt little sense of obligation to the emperor who reigned over large parts of the nation in name only. Large parts of what now comprise the Netherlands were governed by the Count of Holland, the Duke of Gelre, the Duke of Brabant and the Bishop of Utrecht. Friesland and Groningen in the north maintained their independence and were governed by the lower nobility.

The various feudal states were in a state of almost continual war. Gelre and Holland fought for control of Utrecht. Utrecht, whose bishop had in 1000 ruled over half of what is today the Netherlands, was marginalised as it experienced continuing difficulty in electing new bishops. At the same time, the dynasties of neighbouring states were more stable. Groningen, Drenthe and most of Gelre, which used to be part of Utrecht, became independent. Brabant tried to conquer its neighbours, but was not successful. Holland also tried to assert itself in Zeeland and Friesland, but its attempts failed.

The language and culture of most of the people who lived in the area that is now Holland were originally Frisian. The sparsely populated area was known as "West Friesland" ("Westfriesland"). As Frankish settlement progressed, the Frisians migrated away or were absorbed and the area quickly became Dutch. (The part of North Holland situated north of Alkmaar is still colloquially known as West Friesland).

The rest of Friesland in the north continued to maintain its independence during this time. It had its own institutions (collectively called the "Frisian freedom") and resented the imposition of the feudal system and the patriciate found in other European towns. They regarded themselves as allies of Switzerland. The Frisian battle cry was "better dead than a slave". They later lost their independence when they were defeated in 1498 by the German Landsknecht mercenaries of Duke Albrecht of Saxony-Meissen.

The center of power in these emerging independent territories was in the County of Holland. Originally granted as a fief to the Danish chieftain Rorik in return for loyalty to the emperor in 862, the region of Kennemara (the region around modern Haarlem) rapidly grew under Rorik's descendants in size and importance. By the early 11th century, Dirk III, Count of Holland was levying tolls on the Meuse estuary and was able to resist military intervention from his overlord, the Duke of Lower Lorraine.

In 1083, the name "Holland" first appears in a deed referring to a region corresponding more or less to the current province of South Holland and the southern half of what is now North Holland. Holland's influence continued to grow over the next two centuries. The counts of Holland conquered most of Zeeland but it was not until 1289 that Count Floris V was able to subjugate the Frisians in West Friesland (that is, the northern half of North Holland).

Around 1000 AD there were several agricultural developments (described sometimes as an agricultural revolution) that resulted in an increase in production, especially food production. The economy started to develop at a fast pace, and the higher productivity allowed workers to farm more land or to become tradesmen.

Much of the western Netherlands was barely inhabited between the end of the Roman period until around 1100 AD, when farmers from Flanders and Utrecht began purchasing the swampy land, draining it and cultivating it. This process happened quickly and the uninhabited territory was settled in a few generations. They built independent farms that were not part of villages, something unique in Europe at the time.

Guilds were established and markets developed as production exceeded local needs. Also, the introduction of currency made trading a much easier affair than it had been before. Existing towns grew and new towns sprang into existence around monasteries and castles, and a mercantile middle class began to develop in these urban areas. Commerce and town development increased as the population grew.

The Crusades were popular in the Low Countries and drew many to fight in the Holy Land. At home, there was relative peace. Viking pillaging had stopped. Both the Crusades and the relative peace at home contributed to trade and the growth in commerce.

Cities arose and flourished, especially in Flanders and Brabant. As the cities grew in wealth and power, they started to buy certain privileges for themselves from the sovereign, including city rights, the right to self-government and the right to pass laws. In practice, this meant that the wealthiest cities became quasi-independent republics in their own right. Two of the most important cities were Brugge and Antwerp (in Flanders) which would later develop into some of the most important cities and ports in Europe.

The Hook and Cod Wars () were a series of wars and battles in the County of Holland between 1350 and 1490. Most of these wars were fought over the title of count of Holland, but some have argued that the underlying reason was because of the power struggle of the bourgeois in the cities against the ruling nobility.

The Cod faction generally consisted of the more progressive cities of Holland. The Hook faction consisted for a large part of the conservative noblemen. Some of the main figures in this multi-generational conflict were William IV, Margaret, William V, William VI, Count of Holland and Hainaut, John and Philip the Good, Duke of Burgundy. But perhaps the most well known is Jacqueline, Countess of Hainaut.

The conquest of the county of Holland by the Duke Philip the Good of Burgundy was an odd affair. Leading noblemen in Holland invited the duke to conquer Holland, even though he had no historical claim to it. Some historians say that the ruling class in Holland wanted Holland to integrate with the Flemish economic system and adopt Flemish legal institutions. Europe had been wracked by many civil wars in the 14th and 15th centuries, while Flanders had grown rich and enjoyed peace.

Most of what is now the Netherlands and Belgium was eventually united by the Duke of Burgundy in 1433. Before the Burgundian union, the Dutch identified themselves by the town they lived in, their local duchy or county or as subjects of the Holy Roman Empire. The Burgundian period is when the Dutch began the road to nationhood.

Holland's trade developed rapidly, especially in the areas of shipping and transport. The new rulers defended Dutch trading interests. The fleets of Holland defeated the fleets of the Hanseatic League several times. Amsterdam grew and in the 15th century became the primary trading port in Europe for grain from the Baltic region. Amsterdam distributed grain to the major cities of Belgium, Northern France and England. This trade was vital to the people of Holland, because Holland could no longer produce enough grain to feed itself. Land drainage had caused the peat of the former wetlands to reduce to a level that was too low for drainage to be maintained.

Charles V (1500–58) was born and raised in the Flemish city of Ghent; he spoke French. Charles extended the Burgundian territory with the annexation of Tournai, Artois, Utrecht, Groningen and Guelders. The Seventeen Provinces had been unified by Charles's Burgundian ancestors, but nominally were fiefs of either France or the Holy Roman Empire. When he was a minor, his aunt Margaret acted as regent until 1515. France relinquished its ancient claim on Flanders in 1528.
From 1515 to 1523, Charles's government in the Netherlands had to contend with the rebellion of Frisian peasants (led by Pier Gerlofs Donia and Wijard Jelckama). Gelre attempted to build up its own state in northeast Netherlands and northwest Germany. Lacking funds in the 16th century, Gelre had its soldiers provide for themselves by pillaging enemy terrain. These soldiers were a great menace to the Burgundian Netherlands, as when they pillaged The Hague.

The dukes of Burgundy over the years through astute marriages, purchases and wars, had taken control of the Seventeen Provinces that made up the Low Countries. They are now the Netherlands in the north, the Southern Netherlands (now Belgium) in the south, and Luxemburg in the southeast. Known as the "Burgundian Circle," these lands came under the control of the Habsburg family. Charles (1500–58) became the owner in 1506, but in 1515 he left to become king of Spain and later became the Holy Roman Emperor. Charles turned over control to regents (his close relatives), and in practice rule was exercised by Spaniards he controlled. The provinces each had their own governments and courts, controlled by the local nobility, and their own traditions and rights ("liberties") dating back centuries. Likewise the numerous cities had their own legal rights and local governments, usually controlled by the merchants, On top of this the Spanish had imposed an overall government, the Estates General of the Netherlands, with its own officials and courts. The Spanish officials sent by Charles ignored traditions and the Dutch nobility as well as local officials, inciting an anti-Spanish sense of nationalism, and leading to the Dutch Revolt. With the emergence of the Protestant Reformation, Charles—now the Emperor—was determined to crush Protestantism and never compromise with it. Unrest began in the south, centered in the large rich metropolis of Antwerp. The Netherlands was an especially rich unit of the Spanish realm, especially after the Treaty of Cateau-Cambresis of 1559; it ended four decades of warfare between France and Spain and allowed Spain to reposition its army.

In 1548, Charles granted the Netherlands status as an entity in which many of the laws of the Holy Roman Empire became obsolete. The "Transaction of Augsburg." created the Burgundian Circle of the Holy Roman Empire, which comprised the Netherlands and Franche-Comté. A year later the Pragmatic Sanction of 1549 stated that the Seventeen Provinces could only be passed on to his heirs as a composite entity.

During the 16th century, the Protestant Reformation rapidly gained ground in northern Europe, especially in its Lutheran and Calvinist forms. Dutch Protestants, after initial repression, were tolerated by local authorities. By the 1560s, the Protestant community had become a significant influence in the Netherlands, although it clearly formed a minority then. In a society dependent on trade, freedom and tolerance were considered essential. Nevertheless, the Catholic rulers Charles V, and later Philip II, made it their mission to defeat Protestantism, which was considered a heresy by the Catholic Church and a threat to the stability of the whole hierarchical political system. On the other hand, the intensely moralistic Dutch Protestants insisted their Biblical theology, sincere piety and humble lifestyle was morally superior to the luxurious habits and superficial religiosity of the ecclesiastical nobility. The rulers' harsh punitive measures led to increasing grievances in the Netherlands, where the local governments had embarked on a course of peaceful coexistence. In the second half of the century, the situation escalated. Philip sent troops to crush the rebellion and make the Netherlands once more a Catholic region.

In the first wave of the Reformation, Lutheranism won over the elites in Antwerp and the South. The Spanish successfully suppressed it there, and Lutheranism only flourished in east Friesland.

The second wave of the Reformation, came in the form of Anabaptism, that was popular among ordinary farmers in Holland and Friesland. Anabaptists were socially very radical and equalitarian; they believed that the apocalypse was very near. They refused to live the old way, and began new communities, creating considerable chaos. A prominent Dutch Anabaptist was Menno Simons, who initiated the Mennonite church. The movement was allowed in the north, but never grew to a large scale.

The third wave of the Reformation, that ultimately proved to be permanent, was Calvinism. It arrived in the Netherlands in the 1540s, attracting both the elite and the common population, especially in Flanders. The Catholic Spanish responded with harsh persecution and introduced the Inquisition of the Netherlands. Calvinists rebelled. First there was the iconoclasm in 1566, which was the systematic destruction of statues of saints and other Catholic devotional depictions in churches. In 1566, William the Silent, a Calvinist, started the Eighty Years' War to liberate all Dutch of whatever religion from Catholic Spain. Blum says, "His patience, tolerance, determination, concern for his people, and belief in government by consent held the Dutch together and kept alive their spirit of revolt." The provinces of Holland and Zeeland, being mainly Calvinist by 1572, submitted to the rule of William. The other states remained almost entirely Catholic.

The Netherlands was a valuable part of the Spanish Empire, especially after the Treaty of Cateau-Cambresis of 1559. This treaty ended a forty-year period of warfare between France and Spain conducted in Italy from 1521 to 1559. The Treaty of Cateau-Cambresis was somewhat of a watershed—not only for the battleground that Italy had been, but also for northern Europe. Spain had been keeping troops in the Netherlands to be ready to attack France from the north as well as from the south.

With the settlement of so many major issues between France and Spain by the Treaty of Cateau-Cambresis, there was no longer any reason to keep Spanish troops in the Netherlands. Thus, the people of the Netherlands could get on with their peacetime pursuits. As they did so they found that there was a great deal of demand for their products. Fishing had long been an important part of the economy of the Netherlands. However, now the fishing of herring alone came to occupy 2,000 boats operating out of Dutch ports. Spain, still the Dutch trader's best customer, was buying fifty large ships full of furniture and household utensils from Flanders merchants. Additionally, Dutch woolen goods were desired everywhere. The Netherlands bought and processed enough Spanish wool to sell four million florins of wool products through merchants in Bruges. So strong was the Dutch appetite for raw wool at this time that they bought nearly as much English wool as they did Spanish wool. Total commerce with England alone amounted to 24 million florins. Much of the export going to England resulted in pure profit to the Dutch because the exported items were of their own manufacture. The Netherlands was just starting to enter its "Golden Age." Brabant and Flanders were the richest and most flourishing parts of the Dutch Republic at the time. The Netherlands was one of the richest places in the world. The population reached 3 million in 1560, with 25 cities of 10,000 people or more, by far the largest urban presence in Europe; with the trading and financial center of Antwerp being especially important (population 100,000). Spain could not afford to lose this rich land, nor allow it to fall from Catholic control. Thus came 80 years of warfare.

A devout Catholic, Philip was appalled by the success of the Reformation in the Low Countries, which had led to an increasing number of Calvinists. His attempts to enforce religious persecution of the Protestants, and his centralization of government, law enforcement, and taxes, made him unpopular and led to a revolt. Fernando Alvarez de Toledo, Duke of Alba, was sent with a Spanish Army to punish the unruly Dutch in 1567.

The only opposition the Duke of Alba faced in his march across the Netherlands were the nobles, Lamoral, Count of Egmont; Philippe de Montmorency, Count of Horn and others. With the approach of Alba and the Spanish army, William the Silent of Orange fled to Germany with his three brothers and his whole family on 11 April 1567. The Duke of Alba sought to meet and negotiate with the nobles that now faced him with armies. However, when the nobles arrived in Brussels they were all arrested and Egmont and Horn were executed. Alba then revoked all the prior treaties that Margaret, the Duchess of Parma had signed with the Protestants of the Netherlands and instituted the Inquisition to enforce the decrees of the Council of Trent.

The Dutch War for Independence from Spain is frequently called the Eighty Years' War (1568–1648). The first fifty years (1568 through 1618) were uniquely a war between Spain and the Netherlands. During the last thirty years (1618–1648) the conflict between Spain and the Netherlands was submerged in the general European War that became known as the Thirty Years' War. The seven rebellious provinces of the Netherlands were eventually united by the Union of Utrecht in 1579 and formed the Republic of the Seven United Netherlands (also known as the "United Provinces"). The Act of Abjuration or "Plakkaat van Verlatinghe" was signed on 26 July 1581, and was the formal declaration of independence of the northern Low Countries from the Spanish king.

William of Orange (Slot Dillenburg, 24 April 1533 – Delft, 10 July 1584), the founder of the Dutch royal family, led the Dutch during the first part of the war, following the death of Egmont and Horn in 1568. The very first years were a success for the Spanish troops. However, the Dutch countered subsequent sieges in Holland. In November and December 1572, all the citizens of Zutphen and Naarden were slaughtered by the Spanish. From 11 December that year the city of Haarlem was besieged, holding out for seven months until 13 July 1573. Oudewater was conquered by the Spanish on 7 August 1575, and most of its inhabitants were killed. Maastricht was besieged, sacked and destroyed twice in succession (in 1576 and 1579) by the Spanish.

In a war composed mostly of sieges rather than battles, Governor-General Alexander Farnese proved his mettle. His strategy was to offer generous terms for the surrender of a city: there would be no more massacres or looting; historic urban privileges were retained; there was a full pardon and amnesty; return to the Catholic Church would be gradual. The conservative Catholics in the south and east supported the Spanish. Farnese recaptured Antwerp and nearly all of what became Belgium. Most of the Dutch-speaking territory in the Netherlands was taken from Spain, but not in Flanders, which to this day remains part of Belgium. Flanders was the most radical anti-Spanish territory. Many Flemish fled to Holland, among them half of the population of Antwerp, 3/4 of Bruges and Ghent and the entire population of Nieuwpoort, Dunkerque and countryside. His successful campaign gave the Catholics control of the lower half of the Low Countries, and was part of the Catholic Counter-Reformation.

The war dragged on for another half century, but the main fighting was over. The Peace of Westphalia, signed in 1648, confirmed the independence of the United Provinces from Spain. The Dutch people started to develop a national identity since the 15th century, but they officially remained a part of the Holy Roman Empire until 1648. National identity was mainly formed by the province people came from. Holland was the most important province by far. The republic of the Seven Provinces came to be known as Holland across Europe.

The Catholics in the Netherlands were an outlawed minority that had been suppressed by the Calvinists. After 1572, however, they made a striking comeback (also as part of the Catholic Counter-Reformation), setting up seminaries, reforming their Church, and sending missionaries into Protestant districts. Laity often took the lead; the Calvinist government often arrested or harassed priests who seemed too effective. Catholic numbers stabilized at about a third of the population in the Netherlands; they were strongest in the southeast.

During the Eighty Years' War the Dutch provinces became the most important trading centre of Northern Europe, replacing Flanders in this respect. During the Golden Age, there was a great flowering of trade, industry, the arts and the sciences in the Netherlands. In the 17th and 18th centuries, the Dutch were arguably the most economically wealthy and scientifically advanced of all European nations. This new, officially Calvinist nation flourished culturally and economically, creating what historian Simon Schama has called an "embarrassment of riches". Speculation in the tulip trade led to a first stock market crash in 1637, but the economic crisis was soon overcome. Due to these developments the 17th century has been dubbed the Golden Age of the Netherlands.

The invention of the sawmill enabled the construction of a massive fleet of ships for worldwide trading and for defence of the republic's economic interests by military means. National industries such as shipyards and sugar refineries expanded as well.
The Dutch, traditionally able seafarers and keen mapmakers, obtained an increasingly dominant position in world trade, a position which before had been occupied by the Portuguese and Spaniards. In 1602 the Dutch East India Company (Dutch: "Verenigde Oostindische Compagnie" or "VOC") was founded. It was the first-ever multinational corporation, financed by shares that established the first modern stock exchange. It became the world's largest commercial enterprise of the 17th century. To finance the growing trade within the region, the Bank of Amsterdam was established in 1609, the precursor to, if not the first true central bank.

Dutch ships hunted whales off Svalbard, traded spices in India and Indonesia (via the Dutch East India Company) and founded colonies in New Amsterdam (now New York), South Africa and the West Indies. In addition some Portuguese colonies were conquered, namely in Northeastern Brazil, Angola, Indonesia and Ceylon. In 1640 by the Dutch East India Company began a trade monopoly with Japan through the trading post on Dejima.

The Dutch also dominated trade between European countries. The Low Countries were favorably positioned on a crossing of east-west and north-south trade routes and connected to a large German hinterland through the Rhine river. Dutch traders shipped wine from France and Portugal to the Baltic lands and returned with grain destined for countries around the Mediterranean Sea. By the 1680s, an average of nearly 1000 Dutch ships entered the Baltic Sea each year. The Dutch were able to gain control of much of the trade with the nascent English colonies in North America and following the end of war with Spain in 1648, Dutch trade with that country also flourished.
Renaissance Humanism, of which Desiderius Erasmus (c. 1466–1536) was an important advocate, had also gained a firm foothold and was partially responsible for a climate of tolerance. Overall, levels of tolerance were sufficiently high to attract religious refugees from other countries, notably Jewish merchants from Portugal who brought much wealth with them. The revocation of the Edict of Nantes in France in 1685 resulted in the immigration of many French Huguenots, many of whom were shopkeepers or scientists. Still tolerance had its limits, as philosopher Baruch de Spinoza (1632–1677) would find out. Due to its climate of intellectual tolerance the Dutch Republic attracted scientists and other thinkers from all over Europe. Especially the renowned University of Leiden (established in 1575 by the Dutch stadtholder, William of Oranje, as a token of gratitude for Leiden's fierce resistance against Spain during the Eighty Years' War) became a gathering place for these people. For instance French philosopher René Descartes lived in Leiden from 1628 until 1649.

Dutch lawyers were famous for their knowledge of international law of the sea and commercial law. Hugo Grotius (1583–1645) played a leading part in the foundation of international law. Again due to the Dutch climate of tolerance, book publishers flourished. Many books about religion, philosophy and science that might have been deemed controversial abroad were printed in the Netherlands and secretly exported to other countries. Thus during the 17th century the Dutch Republic became more and more Europe's publishing house.

Christiaan Huygens (1629–1695) was a famous astronomer, physicist and mathematician. He invented the pendulum clock, which was a major step forward towards exact timekeeping. He contributed to the fields of optics. The most famous Dutch scientist in the area of optics is certainly Anton van Leeuwenhoek, who invented or greatly improved the microscope (opinions differ) and was the first to methodically study microscopic life, thus laying the foundations for the field of microbiology. Famous Dutch hydraulic engineer Jan Leeghwater (1575–1650) gained important victories in The Netherlands's eternal battle against the sea. Leeghwater added a considerable amount of land to the republic by converting several large lakes into polders, pumping all water out with windmills.

The painting was the dominant art form in 17th-century Holland. Dutch Golden Age painting followed many of the tendencies that dominated Baroque art in other parts of Europe, as with the Utrecht Caravaggisti, but was the leader in developing the subjects of still life, landscape, and genre painting. Portraiture were also popular, but history painting – traditionally the most-elevated genre struggled to find buyers. Church art was virtually non-existent, and little sculpture of any kind produced. While art collecting and painting for the open market was also common elsewhere, art historians point to the growing number of wealthy Dutch middle-class and successful mercantile patrons as driving forces in the popularity of certain pictorial subjects. Today, the best-known painters of the Dutch Golden Age are the period's most dominant figure Rembrandt, the Delft master of genre Johannes Vermeer, the innovative landscape painter Jacob van Ruisdael, and Frans Hals, who infused new life into portraiture. Some notable artistic styles and trends include Haarlem Mannerism, Utrecht Caravaggism, the School of Delft, the Leiden fijnschilders, and Dutch classicism.
Due to the thriving economy, cities expanded greatly. New town halls, weighhouses and storehouses were built. Merchants that had gained a fortune ordered a new house built along one of the many new canals that were dug out in and around many cities (for defence and transport purposes), a house with an ornamented façade that befitted their new status. In the countryside, many new castles and stately homes were built. Most of them have not survived. Starting at 1595 Reformed churches were commissioned, many of which are still landmarks today. The most famous Dutch architects of the 17th century were Jacob van Campen, Pieter Post, Pieter Vingbooms, Lieven de Key, Hendrick de Keyser. Overall, Dutch architecture, which generally combined traditional building styles with some foreign elements, did not develop to the level of painting.

The Golden Age was also an important time for developments in literature. Some of the major figures of this period were Gerbrand Adriaenszoon Bredero, Jacob Cats, Pieter Corneliszoon Hooft and Joost van den Vondel. Since Latin was the lingua franca of education, relatively few men could speak, write, and read Dutch all at the same time.

Music did not develop very much in the Netherlands since the Calvinists considered it an unnecessary extravagance, and organ music was forbidden in Reformed Church services, although it remained common at secular functions.

The "Dutch West India Company" was a chartered company (known as the "GWC") of Dutch merchants. On 2 June 1621, it was granted a for a trade monopoly in the West Indies (meaning the Caribbean) by the Republic of the Seven United Netherlands and given jurisdiction over the African slave trade, Brazil, the Caribbean, and North America. Its area of operations stretched from West Africa to the Americas, and the Pacific islands. The company became instrumental in the Dutch colonization of the Americas. The first forts and settlements in Guyana and on the Amazon River date from the 1590s. Actual colonization, with Dutch settling in the new lands, was not as common as with England and France. Many of the Dutch settlements were lost or abandoned by the end of that century, but the Netherlands managed to retain possession of Suriname and a number of Dutch Caribbean islands.
The colony was a private business venture to exploit the fur trade in beaver pelts. New Netherland was slowly settled during its first decades, partially as a result of policy mismanagement by the Dutch West India Company (WIC), and conflicts with Native Americans. During the 1650s, the colony experienced dramatic growth and became a major port for trade in the Atlantic World, tolerating a highly diverse ethnic mix. The surrender of Fort Amsterdam to the British control in 1664 was formalized in 1667, contributing to the Second Anglo–Dutch War. In 1673 the Dutch re-took the area, but later relinquished it under the 1674 Treaty of Westminster ending the Third Anglo-Dutch War.

Descendants of the original settlers played a prominent role in the History of the United States, as typified by the Roosevelt and Vanderbilt families. The Hudson Valley still boasts a Dutch heritage. The concepts of civil liberties and pluralism introduced in the province became mainstays of American political and social life.

Although slavery was illegal inside the Netherlands it flourished in the Dutch Empire, and helped support the economy. In 1619 The Netherlands took the lead in building a large-scale slave trade between Africa and Virginia, by 1650 becoming the pre-eminent slave trading country in Europe. It was overtaken by Britain around 1700. Historians agree that in all the Dutch shipped about 550,000 African slaves across the Atlantic, about 75,000 of whom died on board before reaching their destinations. From 1596–1829, the Dutch traders sold 250,000 slaves in the Dutch Guianas, 142,000 in the Dutch Caribbean islands, and 28,000 in Dutch Brazil. In addition, tens of thousands of slaves, mostly from India and some from Africa, were carried to the Dutch East Indies and slaves from the East Indies to Africa and the West Indies.

The Dutch East India Company, called the VOC began in 1602, when the government gave it a monopoly to trade with Asia. It had many world firsts—the first multinational corporation, the first company to issue stock, and was the first megacorporation, possessing quasi-governmental powers, including the ability to wage war, negotiate treaties, coin money, and establish colonial settlements.

England and France soon copied its model but could not match its record. Between 1602 and 1796 the VOC sent almost a million Europeans to work in the Asia trade on 4,785 ships. It returned over 2.5 million tons of Asian trade goods. The VOC enjoyed huge profits from its spice monopoly through most of the 17th century. The VOC was active chiefly in the Dutch East Indies, now Indonesia, where its base was Batavia (now Jakarta), which remained an important trading concern and paid an 18% annual dividend for almost 200 years; colonized parts of Taiwan between 1624–1662 and 1664–1667 and the only western trading post in Japan, Dejima. 
By the 17th century, the Dutch East India Company established their base in parts of Ceylon (modern-day Sri Lanka). Afterward, they established ports in Dutch occupied Malabar, leading to Dutch settlements and trading posts in India. However, their expansion into India was halted, after their defeat in the Battle of Colachel by the Kingdom of Travancore, during the Travancore-Dutch War. The Dutch never recovered from the defeat and no longer posed a large colonial threat to India. 

Eventually, the Dutch East India Company was weighted down by corruption, the VOC went bankrupt in 1800. Its possessions were taken over by the government and turned into the Dutch East Indies.

In 1647, a Dutch vessel was wrecked in the present-day Table Bay at Cape Town. The marooned crew, the first Europeans to attempt settlement in the area, built a fort and stayed for a year until they were rescued. Shortly thereafter, the Dutch East India Company (in the Dutch of the day: "Vereenigde Oostindische Compagnie", or VOC) decided to establish a permanent settlement. The VOC, one of the major European trading houses sailing the spice route to East Asia, had no intention of colonizing the area, instead wanting only to establish a secure base camp where passing ships could shelter, and where hungry sailors could stock up on fresh supplies of meat, fruit, and vegetables. To this end, a small VOC expedition under the command of Jan van Riebeeck reached Table Bay on 6 April 1652.

To remedy a labour shortage, the VOC released a small number of VOC employees from their contracts and permitted them to establish farms with which they would supply the VOC settlement from their harvests. This arrangement proved highly successful, producing abundant supplies of fruit, vegetables, wheat, and wine; they also later raised livestock. The small initial group of "free burghers", as these farmers were known, steadily increased in number and began to expand their farms further north and east.

The majority of burghers had Dutch ancestry and belonged to the Calvinist Reformed Church of the Netherlands, but there were also numerous Germans as well as some Scandinavians. In 1688 the Dutch and the Germans were joined by French Huguenots, also Calvinists, who were fleeing religious persecution in France under King Louis XIV. The Huguenots in South Africa were absorbed into the Dutch population but they played a prominent role in South Africa's history.

From the beginning, the VOC used the cape as a place to supply ships travelling between the Netherlands and the Dutch East Indies. There was a close association between the cape and these Dutch possessions in the far east. Van Riebeeck and the VOC began to import large numbers of slaves, primarily from Madagascar and Indonesia. These slaves often married Dutch settlers, and their descendants became known as the Cape Coloureds and the Cape Malays.
During the 18th century, the Dutch settlement in the area of the cape grew and prospered. By the late 1700s, the Cape Colony was one of the best developed European settlements outside Europe or the Americas. The two bases of the Cape Colony's economy for almost the entirety of its history were shipping and agriculture. Its strategic position meant that almost every ship sailing between Europe and Asia stopped off at the colony's capital Cape Town. The supplying of these ships with fresh provisions, fruit, and wine provided a very large market for the surplus produce of the colony.

Some free burghers continued to expand into the rugged hinterlands of the north and east, many began to take up a semi-nomadic pastoralist lifestyle, in some ways not far removed from that of the Khoikhoi they had displaced. In addition to its herds, a family might have a wagon, a tent, a Bible, and a few guns. As they became more settled, they would build a mud-walled cottage, frequently located, by choice, days of travel from the nearest European settlement. These were the first of the Trekboers (Wandering Farmers, later shortened to Boers), completely independent of official controls, extraordinarily self-sufficient, and isolated from the government and the main settlement in Cape Town.
Dutch was the official language, but a dialect had formed that was quite distinct from Dutch. The Afrikaans language originated mainly from 17th-century Dutch dialects.

This Dutch dialect sometimes referred to as the "kitchen language" ("kombuistaal"), would eventually in the late 19th century be recognised as a distinct language called Afrikaans and replace Dutch as the official language of the Afrikaners.

As the 18th century drew to a close, Dutch mercantile power began to fade and the British moved in to fill the vacuum. They seized the Cape Colony in 1795 to prevent it from falling into French hands, then briefly relinquished it back to the Dutch (1803), before definitively conquering it in 1806. British sovereignty of the area was recognised at the Congress of Vienna in 1815. By the time the Dutch colony was seized by the British in 1806, it had grown into an established settlement with 25,000 slaves, 20,000 white colonists, 15,000 Khoisan, and 1,000 freed black slaves. Outside Cape Town and the immediate hinterland, isolated black and white pastoralists populated the country.

Dutch interest in South Africa was mainly as a strategically located VOC port. Yet in the 17th and 18th centuries the Dutch created the foundation of the modern state of South Africa. The Dutch legacy in South Africa is evident everywhere, but particularly in the Afrikaner people and the Afrikaans language.

The Netherlands gained independence from Spain as a result of the Eighty Years' War, during which the Dutch Republic was founded. As the Netherlands was a republic, it was largely governed by an aristocracy of city-merchants called the regents, rather than by a king. Every city and province had its own government and laws, and a large degree of autonomy. After attempts to find a competent sovereign proved unsuccessful, it was decided that sovereignty would be vested in the various provincial Estates, the governing bodies of the provinces. The Estates-General, with its representatives from all the provinces, would decide on matters important to the Republic as a whole. However, at the head of each province was the stadtholder of that province, a position held by a descendant of the House of Orange. Usually the stadtholdership of several provinces was held by a single man.

After having gained its independence in 1648, the Netherlands tried in various coalitions to help to contain France, which had replaced Spain as the strongest nation of Europe. The end of the War of the Spanish Succession (1713) marked the end of the Dutch Republic as a major player. In the 18th century, it just tried to maintain its independence and stuck to a policy of neutrality.

The economy, based on Amsterdam's role as the center of world trade, remained robust. In 1670 the Dutch merchant marine totalled 568,000 tons of shipping—about half the European total. The province of Holland was highly commercial and dominated the country. Its nobility was small and closed and had little influence, for it was numerically small, politically weak, and formed a strictly closed caste. Most land in the province of Holland was commercialized for cash crops and was owned by urban capitalists, not nobles; there were few links between Holland's nobility and the merchants. By 1650 the burgher families which had grown wealthy through commerce and become influential in government controlled the province of Holland, and to a large extent shaped national policies. The other six provinces were more rural and traditional in life style, had an active nobility, and played a small role in commerce and national politics. Instead they concentrated on their flood protections and land reclamation projects.

The Netherlands sheltered many notable refugees, including Protestants from Antwerp and Flanders, Portuguese and German Jews, French Protestants (Huguenots) (including Descartes) and English Dissenters (including the Pilgrim Fathers). Many immigrants came to the cities of Holland in the 17th and 18th century from the Protestant parts of Germany and elsewhere. The amount of first generation immigrants from outside the Netherlands in Amsterdam was nearly 50% in the 17th and 18th centuries. Indeed, Amsterdam's population consisted primarily of immigrants, if one includes second and third generation immigrants and migrants from the Dutch countryside. People in most parts of Europe were poor and many were unemployed. But in Amsterdam there was always work. Tolerance was important, because a continuous influx of immigrants was necessary for the economy. Travellers visiting Amsterdam reported their surprise at the lack of control over the influx.

The era of explosive economic growth is roughly coterminous with the period of social and cultural bloom that has been called the Dutch Golden Age, and that actually formed the material basis for that cultural era. Amsterdam became the hub of world trade, the center into which staples and luxuries flowed for sorting, processing, and distribution, and then reexported around Europe and the world.

During 1585 through 1622 there was the rapid accumulation of trade capital, often brought in by refugee merchantes from Antwerp and other ports. The money was typically invested in high-risk ventures like pioneering expeditions to the East Indies to engage in the spice trade. These ventures were soon consolidated in the Dutch East India Company (VOC). There were similar ventures in different fields however, like the trade on Russia and the Levant. The profits of these ventures were ploughed back in the financing of new trade, which led to its exponential growth.

Rapid industrialization led to the rapid growth of the nonagricultural labor force and the increase in real wages during the same time. In the half-century between 1570 and 1620 this labor supply increased 3 percent per annum, a truly phenomenal growth. Despite this, nominal wages were repeatedly increased, outstripping price increases. In consequence, real wages for unskilled laborers were 62 percent higher in 1615–1619 than in 1575–1579.

By the mid-1660s Amsterdam had reached the optimum population (about 200,000) for the level of trade, commerce and agriculture then available to support it. The city contributed the largest quota in taxes to the States of Holland which in turn contributed over half the quota to the States General. Amsterdam was also one of the most reliable in settling tax demands and therefore was able to use the threat to withhold such payments to good effect.

Amsterdam was governed by a body of regents, a large, but closed, oligarchy with control over all aspects of the city's life, and a dominant voice in the foreign affairs of Holland. Only men with sufficient wealth and a long enough residence within the city could join the ruling class. The first step for an ambitious and wealthy merchant family was to arrange a marriage with a long-established regent family. In the 1670s one such union, that of the Trip family (the Amsterdam branch of the Swedish arms makers) with the son of Burgomaster Valckenier, extended the influence and patronage available to the latter and strengthened his dominance of the council. The oligarchy in Amsterdam thus gained strength from its breadth and openness. In the smaller towns family interest could unite members on policy decisions but contraction through intermarriage could lead to the degeneration of the quality of the members.

In Amsterdam the network was so large that members of the same family could be related to opposing factions and pursue widely separated interests. The young men who had risen to positions of authority in the 1670s and 1680s consolidated their hold on office well into the 1690s and even the new century.

Amsterdam's regents provided good services to residents. They spent heavily on the water-ways and other essential infrastructure, as well as municipal almshouses for the elderly, hospitals and churches.

Amsterdam's wealth was generated by its commerce, which was in turn sustained by the judicious encouragement of entrepreneurs whatever their origin. This open door policy has been interpreted as proof of a tolerant ruling class. But toleration was practiced for the convenience of the city. Therefore, the wealthy Sephardic Jews from Portugal were welcomed and accorded all privileges except those of citizenship, but the poor Ashkenazi Jews from Eastern Europe were far more carefully vetted and those who became dependent on the city were encouraged to move on. Similarly, provision for the housing of Huguenot immigrants was made in 1681 when Louis XIV's religious policy was beginning to drive these Protestants out of France; no encouragement was given to the dispossessed Dutch from the countryside or other towns of Holland. The regents encouraged immigrants to build churches and provided sites or buildings for churches and temples for all except the most radical sects and the Catholics by the 1670s (although even the Catholics could practice quietly in a chapel within the Beguinhof).

During the wars a tension had arisen between the Orange-Nassau leaders and the patrician merchants. The former—the Orangists—were soldiers and centralizers who seldom spoke of compromise with the enemy and looked for military solutions. They included many rural gentry as well as ordinary folk attached to the banner of the House of Orange. The latter group were the Republicans, led by the Grand Pensionary (a sort of prime minister) and the regents stood for localism, municipal rights, commerce, and peace. In 1650, the stadtholder William II, Prince of Orange suddenly died; his son was a baby and the Orangists were leaderless. The regents seized the opportunity: there would be no new stadtholder in Holland for 22 years. Johan de Witt, a brilliant politician and diplomat, emerged as the dominant figure. Princes of Orange became the stadtholder and an almost hereditary ruler in 1672 and 1748. The Dutch Republic of the United Provinces was a true republic from 1650–1672 and 1702–1748. These periods are called the First Stadtholderless Period and Second Stadtholderless Period.

The Republic and England were major rivals in world trade and naval power. Halfway through the 17th century the Republic's navy was the rival of Britain's Royal Navy as the most powerful navy in the world. The Republic fought a series of three naval wars against England in 1652–74.

In 1651, England imposed its first Navigation Act, which severely hurt Dutch trade interests. An incident at sea concerning the Act resulted in the First Anglo-Dutch War, which lasted from 1652 to 1654, ending in the Treaty of Westminster (1654), which left the Navigation Act in effect.

After the English Restoration in 1660, Charles II tried to serve his dynastic interests by attempting to make Prince William III of Orange, his nephew, stadtholder of the Republic, using some military pressure. King Charles thought a naval war would weaken the Dutch traders and strengthen the English economy and empire, so the Second Anglo-Dutch War was launched in 1665. At first many Dutch ships were captured and the English scored great victories. However, the Raid on the Medway, in June 1667, ended the war with a Dutch victory. The Dutch recovered their trade, while the English economy was seriously hurt and its treasury nearly bankrupt. The greatly expanded Dutch navy was for years after the world's strongest. The Dutch Republic was at the zenith of its power.

The year 1672 is known in the Netherlands as the "Disaster Year" ("Rampjaar"). England declared war on the Republic, (the Third Anglo-Dutch War), followed by France, Münster and Cologne, which had all signed alliances against the Republic. France, Cologne and Münster invaded the Republic. Johan de Witt and his brother Cornelis, who had accomplished a diplomatic balancing act for a long time, were now the obvious scapegoats. They were lynched, and a new stadtholder, William III, was appointed.

An Anglo-French attempt to land on the Dutch shore was barely repelled in three desperate naval battles under command of Admiral Michiel de Ruyter. The advance of French troops from the south was halted by a costly inundation of its own heartland, by breaching river dikes. With the aid of friendly German princes, the Dutch succeeded in fighting back Cologne and Münster, after which the peace was signed with both of them, although some territory in the east was lost forever. Peace was signed with England as well, in 1674 (Second Treaty of Westminster). In 1678, peace was made with France at the Treaty of Nijmegen, although France's Spanish and German allies felt betrayed by this.

In 1688, the relations with England reached crisis level once again. Stadtholder William III decided he had to take a huge gamble when he was invited to invade England by Protestant British nobles feuding with William's father-in-law the Catholic James II of England. This led to the Glorious Revolution and cemented the principle of parliamentary rule and Protestant ascendency in England. James fled to France, and William ascended to the English throne as co-monarch with his wife Mary, James' eldest daughter. This manoeuvre secured England as a critical ally of the United Provinces in its ongoing wars with Louis XIV of France. William was the commander of the Dutch and English armies and fleets until his death in 1702. During William's reign as King of England, his primary focus was leveraging British manpower and finances to aid the Dutch against the French. The combination continued after his death as the combined Dutch, British, and mercenary army conquered Flanders and Brabant, and invaded French territory before the alliance collapsed in 1713 due to British political infighting.

The "Second Stadtholderless Period" () is the designation in Dutch historiography of the period between the death of stadtholder William III on 19 March 1702 and the appointment of William IV, Prince of Orange as stadtholder and captain general in all provinces of the Dutch Republic on 2 May 1747. During this period the office of stadtholder was left vacant in the provinces of Holland, Zeeland, and Utrecht, though in other provinces that office was filled by members of the House of Nassau-Dietz (later called Orange-Nassau) during various periods.

During the period, the Republic lost its Great-Power status and its primacy in world trade, processes that went hand-in-hand, the latter causing the former. Though the economy declined considerably, causing deindustralization and deurbanization in the maritime provinces, a "rentier"-class kept accumulating a large capital fund that formed the basis for the leading position the Republic achieved in the international capital market. A military crisis at the end of the period caused the fall of the States-Party regime and the restoration of the Stadtholderate in all provinces. However, though the new stadtholder acquired near-dictatorial powers, this did not improve the situation.

The slow economic decline after 1730 was relative: other countries grew faster, eroding the Dutch lead and surpassing it. Wilson identifies three causes. Holland lost its world dominance in trade as competitors emerged and copied its practices, built their own ships and ports, and traded on their own account directly without going through Dutch intermediaries. Second, there was no growth in manufacturing, due perhaps to a weaker sense of industrial entrepreneurship and to the high wage scale. Third the wealthy turned their investments to foreign loans. This helped jump-start other nations and provided the Dutch with a steady income from collecting interest, but leaving them with few domestic sectors with a potential for rapid growth.

After the Dutch fleet declined, merchant interests became dependent on the goodwill of Britain. The main focus of Dutch leaders was reducing the country's considerable budget deficits. Dutch trade and shipping remained at a fairly steady level through the 18th century, but no longer had a near monopoly and also could not match growing English and French competition. The Netherlands lost its position as the trading centre of Northern Europe to London.

Although the Netherlands remained wealthy, investors for the nation's money became more difficult to find. Some investment went into purchases of land for estates, but most went to foreign bonds and Amsterdam remained one of Europe's banking capitals.

Dutch culture also declined both in the arts and sciences. Literature for example largely imitated English and French styles with little in the way of innovation or originality. The most influential intellectual was Pierre Bayle (1647–1706), a Protestant refugee from France who settled in Rotterdam where he wrote the massive Dictionnaire Historique et Critique ("Historical and Critical Dictionary", 1696). It had a major impact on the thinking of The Enlightenment across Europe, giving an arsenal of weapons to critics who wanted to attack religion. It was an encyclopaedia of ideas that argued that most "truths" were merely opinions, and that gullibility and stubbornness were prevalent.

Life for the average Dutchman became slower and more relaxed than in the 18th century. The upper and middle classes continued to enjoy prosperity and high living standards. The drive to succeed seemed less urgent. Unskilled laborers remained locked in poverty and hardship. The large underclass of unemployed beggars and riffraff required government and private charity to survive.

Religious life became more relaxed as well. Catholics grew from 18% to 23% of the population during the 18th century and enjoyed greater tolerance, even as they continued to be outside the political system. They became divided by the feud between moralistic Jansenists (who denied free will) and orthodox believers. One group of Jansenists formed a splinter sect, the Old Catholic Church in 1723. The upper classes willingly embraced the ideas of the Enlightenment, tempered by the tolerance that meant less hostility to organized religion compared to France.

During the term of Anthonie van der Heim as Grand Pensionary from 1737 to 1746, the Republic slowly drifted into the War of Austrian Succession. This started as a Prusso-Austrian conflict, but eventually all the neighbours of the Dutch Republic became involved. On one side were Prussia, France and their allies and on the other Austria, Britain (after 1744) and their allies. At first the Republic strove to remain neutral in this European conflict, but it maintained garrisons in a number of fortresses in the Austrian Netherlands. French grievances and threats spurred the Republic into bring its army up to European standards (84,000 men in 1743).

In 1744 and 1745 the French attacked Dutch fortresses at Menen and Tournai. This prompted the Dutch Republic in 1745 to join the Quadruple Alliance, but this alliance was severely defeated at the Battle of Fontenoy in May 1745. In 1746 the French occupied most of the large cities in the Austrian Netherlands. Then, in April 1747, apparently as an exercise in armed diplomacy, a relatively small French military force occupied Zeelandic Flanders, part of the Dutch Republic.

This relatively innocuous invasion fully exposed the rot underlying the Dutch defences. The consequences were spectacular. Still mindful of the French invasion in the "Disaster Year" of 1672, many fearful people clamored for the restoration of the stadtholderate. William IV, Prince of Orange, had been waiting impatiently in the wings since acquiring his princely title in 1732. Over the next year he and his supporters engaged in a number of political battles in various provinces and towns in the Netherlands to wrest control from the regents. The aim was for William IV to obtain a firm grip on government patronage and place loyal officials in all strategic government positions. Eventually he managed to achieve this aim in all provinces.

Willem Bentinck van Rhoon was a prominent Orangist. People like Bentinck hoped that gathering the reins of power in the hands of a single "eminent head" would soon help restore the state of the Dutch economy and finances. The regents they opposed included the Grand Pensionary Jacob Gilles and Adriaen van der Hoop. This popular revolt had religious, anti-Catholic and democratic overtones and sometimes involved mob violence. It eventually involved political agitation by Daniel Raap, Jean Rousset de Missy and the Doelisten, attacks on tax farmers (pachtersoproer), religious agitation for enforcement of the Sabbath laws and preference for followers of Gisbertus Voetius and various demands by the civil militia.

The war against the French was itself brought to a not-too-devastating end for the Dutch Republic with the Treaty of Aix-la-Chapelle (1748). The French retreated of their own accord from the Dutch frontier. William IV died unexpectedly, at the age of 40, on 22 October 1751.

His son, William V, was 3 years old when his father died, and a long regency characterised by corruption and misrule began. His mother delegated most of the powers of the regency to Bentinck and her favorite, Duke Louis Ernest of Brunswick-Lüneburg. All power was concentrated in the hands of an unaccountable few, including the Frisian nobleman Douwe Sirtema van Grovestins. Still a teenager, William V assumed the position of stadtholder in 1766, the last to hold that office. In 1767, he married Princess Wilhelmina of Prussia, the daughter of Augustus William of Prussia, niece of Frederick the Great.

The position of the Dutch during the American War of Independence was one of neutrality. William V, leading the pro-British faction within the government, blocked attempts by pro-independence, and later pro-French, elements to drag the government to war. However, things came to a head with the Dutch attempt to join the Russian-led League of Armed Neutrality, leading to the outbreak of the disastrous Fourth Anglo-Dutch War in 1780. After the signing of the Treaty of Paris (1783), the impoverished nation grew restless under William's rule.

An English historian summed him up uncharitably as "a Prince of the profoundest lethargy and most abysmal stupidity." And yet he would guide his family through the difficult French-Batavian period and his son would be crowned king.

The Fourth Anglo–Dutch War (1780–1784) was a conflict between the Kingdom of Great Britain and the Dutch Republic. The war, tangentially related to the American Revolutionary War, broke out over British and Dutch disagreements on the legality and conduct of Dutch trade with Britain's enemies in that war.

Although the Dutch Republic did not enter into a formal alliance with the United States and their allies, U.S. ambassador (and future President) John Adams managed to establish diplomatic relations with the Dutch Republic, making it the second European country to diplomatically recognize the Continental Congress in April 1782. In October 1782, a treaty of amity and commerce was concluded as well.

Most of the war consisted of a series of largely successful British operations against Dutch colonial economic interests, although British and Dutch naval forces also met once off the Dutch coast. The war ended disastrously for the Dutch and exposed the weakness of the political and economic foundations of the country. The Treaty of Paris (1784), according to Fernand Braudel, "sounded the knell of Dutch greatness."

After the war with Great Britain ended disastrously in 1784, there was growing unrest and a rebellion by the anti-Orangist Patriots. The French Revolution resulted first in the establishment of a pro-French Batavian Republic (1795–1806), then the creation of the Kingdom of Holland, ruled by a member of the House of Bonaparte (1806–1810), and finally annexation by the French Empire (1810–1813).

Influenced by the American Revolution, the Patriots sought a more democratic form of government. The opening shot of this revolution is often considered to be the 1781 publication of a manifesto called "Aan het Volk van Nederland" ("To the People of the Netherlands") by Joan van der Capellen tot den Pol, who would become an influential leader of the Patriot movement. Their aim was to reduce corruption and the power held by the stadtholder, William V, Prince of Orange.

Support for the Patriots came mostly from the middle class. They formed militias called "exercitiegenootschappen". In 1785, there was an open Patriot rebellion, which took the form of an armed insurrection by local militias in certain Dutch towns, "Freedom" being the rallying cry. Herman Willem Daendels attempted to organise an overthrow of various municipal governments (vroedschap). The goal was to oust government officials and force new elections. "Seen as a whole this revolution was a string of violent and confused events, accidents, speeches, rumours, bitter enmities and armed confrontations", wrote French historian Fernand Braudel, who saw it as a forerunner of the French Revolution.

In 1785 the stadholder left The Hague and moved his court to Nijmegen in Guelders, a city remote from the heart of Dutch political life. In June 1787, his energetic wife Wilhelmina (the sister of Frederick William II of Prussia) tried to travel to The Hague. Outside Schoonhoven, she was stopped by Patriot militiamen and taken to a farm near Goejanverwellesluis. Within two days she was forced to return to Nijmegen, an insult not unnoticed in Prussia.

The House of Orange reacted with severity, relying on Prussian troops led by Charles William Ferdinand, Duke of Brunswick and a small contingent of British troops to suppress the rebellion. Dutch banks at this time still held much of the world's capital. Government-sponsored banks owned up to 40% of Great Britain's national debt and there were close connections to the House of Stuart. The stadholder had supported British policies after the American Revolution.

This severe military response overwhelmed the Patriots and put the stadholder firmly back in control. A small unpaid Prussian army was billeted in the Netherlands and supported themselves by looting and extortion. The exercitiegenootschappen continued urging citizens to resist the government. They distributed pamphlets, formed "Patriot Clubs" and held public demonstrations. The government responded by pillaging those towns where opposition continued. Five leaders were sentenced to death (but fled first). Lynchings also occurred. For a while, no one dared appear in public without an orange cockade to show their support for Orangism. Many Patriots, perhaps around 40,000 in all, fled to Brabant, France (especially Dunkirk and St. Omer) and elsewhere. However, before long the French became involved in Dutch politics and the tide turned.

The French Revolution was popular, and numerous underground clubs were promoting it when in January 1795 the French army invaded. The underground rose up, overthrew the municipal and provincial governments, and proclaimed the Batavian Republic () in Amsterdam. Stadtholder William V fled to England and the States General dissolved itself. The new government was virtually a puppet of France. The Batavian Republic enjoyed widespread support and sent soldiers to fight in the French armies. The 1799 Anglo-Russian invasion of Holland was repulsed by Batavian–French forces. Nevertheless, Napoleon replaced it because the regime of Grand Pensionary Rutger Jan Schimmelpenninck (1805–06) was insufficiently docile.

The confederal structure of the old Dutch Republic was permanently replaced by a unitary state. The 1798 constitution had a genuinely democratic character, though a coup d'état of 1801 put an authoritarian regime in power. Ministerial government was introduced for the first time in Dutch history and many of the current government departments date their history back to this period. Meanwhile, the exiled stadholder handed over the Dutch colonies in "safekeeping" to Great Britain and ordered the colonial governors to comply. This permanently ended the colonial empire in Guyana, Ceylon and the Cape Colony. The Dutch East Indies was returned to the Netherlands under the Anglo-Dutch Treaty of 1814.

In 1806 Napoleon restyled the Netherlands (along with a small part of what is now Germany) into the Kingdom of Holland, putting his brother Louis Bonaparte (1778–1846), on the throne. The new king was unpopular, but he was willing to cross his brother for the benefit of his new kingdom. Napoleon forced his abdication in 1810 and incorporated the Netherlands directly into the French empire, imposing economic controls and conscription of all young men as soldiers. When the French retreated from the northern provinces in 1813, a Triumvirate took over at the helm of a provisional government. Although most members of the provisional government had been among the men who had driven out William V 18 years earlier, the leaders of the provisional government knew that any new regime would have to be headed by his son, William Frederick. They also knew that it would be better in the long term if the Dutch people themselves installed the prince, rather than have him imposed on the country by the anti-French alliance. Accordingly, the Triumvirate called William Frederick back on November 30 and offered him the crown. He refused, but instead proclaimed himself "hereditary sovereign prince" on December 6.

The Great Powers had secretly agreed to merge the northern Netherlands with the more populated Austrian Netherlands and the smaller Prince-Bishopric of Liège into a single constitutional monarchy. Having a stronger country on France's northern border was considered (especially by Tsar Alexander) to be an important part of the strategy to keep France's power in check. In 1814, William Frederick gained sovereignty over the Austrian Netherlands and Liège as well. On March 15, 1815; with the encouragement of the powers gathered at the Congress of Vienna, William Frederick raised the Netherlands to the status of a kingdom and proclaimed himself King William I. This was made official later in 1815, when the Low Countries were formally recognized as the United Kingdom of the Netherlands, with the House of Orange-Nassau as hereditary rulers. William had thus fulfilled the nearly three-century quest of the House of Orange to unite the Low Countries under a single rule.

William I became king and also became the hereditary Grand Duke of Luxembourg, that was part of the Netherlands but at the same time part of the German Confederation. The newly created country had two capitals: Amsterdam and Brussels. The new nation had two equal parts. The north (Netherlands proper) had 2 million people. They spoke chiefly Dutch but were divided religiously between a Protestant majority and a large Catholic minority. The south (which would be known as "Belgium" after 1830) had a population of 3.4 million people. Nearly all were Catholic, but it was divided between French-speaking Walloons and Dutch-speaking Flemings. The upper and middle classes in the south were mostly French-speaking. About 60,000 Belgians were eligible to vote, compared to about 80,000 Dutchmen. Officially Amsterdam was the capital, but in a compromise the government met alternately in Brussels and The Hague.

Adolphe Quetelet (1796–1874), the great Belgian statistician, calculated that the new nation was significantly better off than other states. Mortality was low, the food supply was good, education was good, public awareness was high and the charity rate was the highest in the world. The best years were in the mid-1820s.

The quality of schooling was dismal, however. According to Schama, about 1800 the local school teacher was the "humble auxiliary of the local priest. Despised by his co-villagers and forced to subsist on the gleanings of the peasants, he combined drumming the catechism into the heads of his unruly charges with the duties of winding the town clock, ringing the church bells or digging its graves. His principal use to the community was to keep its boys out of mischief when there was no labour for them in the fields, or setting the destitute orphans of the town to the 'useful arts' of picking tow or spinning crude flax. As one would expect, standards in such an occupation were dismal." But in 1806 the Dutch, led by Adriaan van den Ende, energetically set out to modernise education, focusing on a new system for advanced training of teachers with an elaborate system of inspectors, training courses, teacher examinations and teaching societies. By 1826, although much smaller than France, the Dutch national government was spending 12 times more than Paris on education.

William I, who reigned from 1815–1840, had great constitutional power. An enlightened despot, he accepted the modernizing transformations of the previous 25 years, including equality of all before the law. However, he resurrected the estates as a political class and elevated a large number of people to the nobility. Voting rights were still limited, and only the nobility were eligible for seats in the upper house. The old provinces were reestablished in name only. The government was now fundamentally unitary, and all authority flowed from the center.

William I was a Calvinist and unsympathetic to the religious culture and practices of the Catholic majority. He promulgated the "Fundamental Law of Holland", with some modifications. This entirely overthrew the old order of things in the southern Netherlands: it abolished the privileges of the Catholic Church, and guaranteed equal protection to every religious creed and the enjoyment of the same civil and political rights to every subject of the king. It reflected the spirit of the French Revolution and in so doing did not please the Catholic bishops in the south, who had detested the Revolution.

William I actively promoted economic modernization. The first 15 years of the Kingdom showed progress and prosperity, as industrialization proceeded rapidly in the south, where the Industrial Revolution allowed entrepreneurs and labor to combine in a new textile industry, powered by local coal mines. There was little industry in the northern provinces, but most overseas colonies were restored, and highly profitable trade resumed after a 25-year hiatus. Economic liberalism combined with moderate monarchical authoritarianism to accelerate the adaptation of the Netherlands to the new conditions of the 19th century. The country prospered until a crisis arose in relations with the southern provinces.

William was determined to create a united people, even though the north and south had drifted far apart in the past three centuries. Protestants were the largest denomination in the North (population 2 million), but formed a quarter of the population in the overwhelmingly Catholic South (population 3.5 million). Nevertheless, Protestants dominated William's government and army. The Catholics did not consider themselves an integral part of the United Netherlands, preferring instead to identify with mediaeval Dutch culture. Other factors that contributed to this feeling were economic (the South was industrialising, the North had always been a merchants' nation) and linguistic (French was spoken in Wallonia and a large part of the bourgeoisie in Flemish cities).
After having been dominant for centuries, the French-speaking elite in the Southern Netherlands now felt like second-class citizens.
In the Catholic South, William's policies were unpopular. The French-speaking Walloons strenuously rejected his attempt to make Dutch the universal language of government, while the population of Flanders was divided. Flemings in the south spoke a Dutch dialect ("Flemish") and welcomed the encouragement of Dutch with a revival of literature and popular culture. Other Flemings, notably the educated bourgeoisie, preferred to speak French. Although Catholics possessed legal equality, they resented their subordination to a government that was fundamentally Protestant in spirit and membership after having been the state church for centuries in the south. Few Catholics held high office in state or army. Furthermore, political liberals in the south complained about the king's authoritarian methods. All southerners complained of underrepresentation in the national legislature. Although the south was industrializing and was more prosperous than the north the accumulated grievances allowed the multiple opposition forces to coalesce. The outbreak of revolution in France in 1830 was a signal for action, at first on behalf of autonomy for Belgium, as the southern provinces were now called, and later on behalf of total independence. William dithered and his half-hearted efforts to reconquer Belgium were thwarted both by the efforts of the Belgians themselves and by the diplomatic opposition of the great powers.

At the London Conference of 1830, the chief powers of Europe ordered (in November 1830) an armistice between the Dutch and the Belgians. The first draft for a treaty of separation of Belgium and the Netherlands was rejected by the Belgians. A second draft (June 1831) was rejected by William I, who resumed hostilities. Franco-British intervention forced William to withdraw Dutch forces from Belgium late in 1831, and in 1833 an armistice of indefinite duration was concluded. Belgium was effectively independent but William’s attempts to recover Luxembourg and Limburg led to renewed tension. The London Conference of 1838–39 prepared the final Dutch-Belgian separation treaty of 1839. It divided Luxembourg and Limburg between the Dutch and Belgian crowns. The Kingdom of the Netherlands thereafter was made up of the 11 northern provinces.

The Netherlands did not industrialize as rapidly as Belgium after 1830, but it was prosperous enough. Griffiths argues that certain government policies facilitated the emergence of a national economy in the 19th century. They included the abolition of internal tariffs and guilds, a unified coinage system, modern methods of tax collection, standardized weights and measures, and the building of many roads, canals, and railroads. However, compared to Belgium, which was leading in industrialization on the Continent, the Netherlands moved slowly. Possible explanations for this difference are the higher costs due to geography and high wages, and the emphasis of entrepreneurs on trade rather than industry.
For example, in the Dutch coastal provinces agricultural productivity was relatively high. Hence, industrial growth arrived relatively late – after 1860 – because incentives to move to labour-intensive industry were quite weak.
However, the provinces of North Brabant and Overijssel did industrialize, and they became the most economically advanced areas of the country.

As in the rest of Europe, the 19th century saw the gradual transformation of the Netherlands into a modern middle-class industrial society. The number of people employed in agriculture decreased, while the country made a strong effort to revive its stake in the highly competitive shipping and trade business. The Netherlands lagged behind Belgium until the late 19th century in industrialization, and caught up around 1920. Major industries included textiles and (later) the great Philips industrial conglomerate. Rotterdam became a major shipping and manufacturing center. Poverty slowly declined as begging largely disappeared along with steadily improving working conditions for the population.

In 1840 William I abdicated in favor of his son, William II, who attempted to carry on the policies of his father in the face of a powerful liberal movement. In 1848 unrest broke out all over Europe. Although there were no major events in the Netherlands, these foreign developments persuaded King William II to agree to liberal and democratic reform. That same year Johan Rudolf Thorbecke, a prominent liberal, was asked by the king to draft a constitution that would turn the Netherlands into a constitutional monarchy. The new constitution was proclaimed on 3 November 1848. It severely limited the king's powers (making the government accountable only to an elected parliament), and it protected civil liberties. The new liberal constitution, which put the government under the control of the States General, was accepted by the legislature in 1848. The relationship between monarch, government and parliament has remained essentially unchanged ever since.

William II was succeeded by William III in 1849. The new king reluctantly chose Thorbecke to head the new government, which introduced several liberal measures, notably the extension of suffrage. However, Thorbecke's government soon fell, when Protestants rioted against the Vatican's reestablishment of the Catholic episcopate, in abeyance since the 16th century. A conservative government was formed, but it did not undo the liberal measures, and the Catholics were finally given equality after two centuries of subordination. Dutch political history from the middle of the 19th century until the First World War was fundamentally one of the extension of liberal reforms in government, the reorganization and modernization of the Dutch economy, and the rise of trade unionism and socialism as working-class movements independent of traditional liberalism. The growth in prosperity was enormous, as real per capita GNP soared from 106 guilders in 1804 to 403 in 1913.

Religion was a contentious issue with repeated struggles over the relations of church and state in the field of education. In 1816, the government took full control of the Dutch Reformed Church ("Nederlands Hervormde Kerk"). In 1857, all religious instruction was ended in public schools, but the various churches set up their own schools, and even universities. Dissident members broke away from the Dutch Reformed Church in the Secession of 1834. They were harassed by the government under an onerous Napoleonic law prohibiting gatherings of more than 20 members without a permit. After the harassment ended in the 1850s, a number of these dissidents eventually created the Christian Reformed Church in 1869; thousands migrated to Michigan, Illinois, and Iowa in the United States. By 1900, the dissidents represented about 10% of the population, compared to 45% of the population who were in the Dutch Reformed Church, which continued to be the only church to receive state money.

At mid-century, most Dutch belonged either to the Dutch Reformed Church or dissenter groups that separated from it (around 55%), or the Roman Catholic Church (35% to 40%), together with smaller Protestant (for example, Lutheran) and Jewish groups. A large and powerful sector of nominal Protestants were in fact secular liberals seeking to minimize religious influence. In reaction a novel alliance developed with Catholics and devout Calvinists joining against secular liberals. The Catholics, who had been loosely allied with the liberals in earlier decades, turned against them on the issue of state support, which the liberals insisted should be granted only to public schools, and joined with Protestant political parties in demanding equal state support to schools maintained by religious groups.

The Netherlands remained one of the most tolerant countries in Europe towards religious belief, although conservative Protestants objected to the liberalization of the Dutch Reformed Church during the 19th century and faced opposition from the government when they tried to establish separate communities (Catholics and other non-Protestants were left unmolested by Dutch authorities). Some moved to the United States as a consequence, but as the century drew to a close, religious persecution had totally ceased.
Dutch social and political life became divided by fairly clear-cut internal borders that were emerging as the society pillarized into three separate parts based on religion. The economy was not affected. One of the people most responsible for designing pillarization was Abraham Kuyper (1837–1920), a leading politician, neo-Calvinist theologian, and journalist. Kuyper established orthodox Calvinist organizations, and also provided a theoretical framework by developing such concepts as "sphere-sovereignty" that celebrated Dutch society as a society of organized minorities. "Verzuiling" ("pillarization" or "pluralism") after 1850 became the solution to the danger of internal conflict. Everyone was part of one (and only one) pillar ("zuil") based chiefly on religion (Protestant, Catholic, secular). The secular pillar eventually split into a socialist/working class pillar and a liberal (pro-business) secular pillar. Each pillar built a full set of its own social organizations, including churches (for the religious pillars), political parties, schools, universities, labor unions, sport clubs, boy scout unions and other youth clubs, and newspapers. The members of different "zuilen" lived in close proximity in cities and villages, spoke the same language, and did business with one another, but seldom interacted informally and rarely intermarried. In politics Kuyper formed the Anti-Revolutionary Party (ARP) in 1879, and headed it until 1905.

Pillarization was officially recognized in the Pacification of 1917, whereby socialists and liberals achieved their goal of universal male suffrage and the religious parties were guaranteed equal funding of all schools. In 1930 radio was organized so that each pillar had full control of its own network. When television began in the late 1940s the pillars divided up time equally on the one station. In politics and civic affairs leaders of the pillar organizations cooperated and the acknowledged the right of the other pillars, so public life generally ran smoothly.

The late 19th century saw a cultural revival. The Hague School brought a revival of realist painting, 1860-1890. The world-famous Dutch painter was Vincent van Gogh, but he spent most of his career in France. Literature, music, architecture and science also flourished. A representative leader of science was Johannes Diderik van der Waals (1837–1923), a working class youth who taught himself physics, earned a PhD at the nation's leading school Leiden University, and in 1910 won the Nobel Prize for his discoveries in thermodynamics. Hendrik Lorentz (1853–1928) and his student Pieter Zeeman (1865–1943) shared the 1902 Nobel Prize in physics. Other notable scientists included biologist Hugo de Vries (1848–1935), who rediscovered Mendelian genetics.

In 1890, William III died after a long reign and was succeeded by his young daughter, Queen Wilhelmina (1880-1962). She would rule the Netherlands for 58 years. On her accession to the throne, the personal union between the Netherlands and Luxembourg ended because Luxembourg law excluded women from rule. Her remote cousin Adolphe became the Grand Duke of Luxembourg.

This was a time of further growth and colonial development, but it was marked by the difficulties of the World War I (in which the Netherlands was neutral) 
and the Great Depression. The Dutch population grew rapidly in the 20th century, as death rates fell, more lands were opened up, and industrialisation created urban jobs. Between 1900 and 1950 the population doubled from 5.1 to 10 million people.

The Dutch empire comprised the Dutch East Indies (Indonesia), as well as Surinam in South America and some minor possessions. It was smaller in 1945 than in 1815 because the Netherlands was the only colonial power that did not expand into Africa or anywhere else. The empire was run from Batavia (in Java), where the governor and his technical experts had almost complete authority with little oversight from the Hague. Successive governors improved their bureaucratic and military controls, and allowed very little voice to the locals until the 1920s.

The colony brought economic opportunity to the mother country and there was little concern at the time about it. One exception came in 1860 when Eduard Dekker, under the pen name "Multatuli" wrote the novel "", one of the most notable books in the history of Dutch literature. He criticized the exploitation of the colony and as well had harsh words about the indigenous princes who collaborated with the governor. The book helped inspire the Indonesian independence movement in the mid-20th century as well as the "Fair trade" movement for coffee at the end of the century.

The military forces in the Dutch East Indies were controlled by the governor and were not part of the regular Dutch army. As the map shows, the Dutch slowly expanded their holdings from their base in Java to include all of modern Indonesia by 1920. Most islands were not a problem but there was a long, costly campaign against the Achin (Aceh) state in northern Sumatra.

The Netherlands had not fought a major military campaign since the 1760s, and the strength of its armed forces had gradually dwindled. The Dutch decided not to ally themselves with anyone, and kept out of all European wars especially the First World War that swirled about it.

The German war plan (the Schlieffen Plan) of 1905 was modified in 1908 to invade Belgium on the way to Paris but not the Netherlands. It supplied many essential raw materials to Germany such as rubber, tin, quinine, oil and food. The British used its blockade to limit supplies that the Dutch could pass on. There were other factors that made it expedient for both the Allies and the Central Powers for the Netherlands to remain neutral. The Netherlands controlled the mouths of the Scheldt, the Rhine and the Meuse Rivers. Germany had an interest in the Rhine since it ran through the industrial areas of the Ruhr and connected it with the Dutch port of Rotterdam. Britain had an interest in the Scheldt River and the Meuse flowed from France. All countries had an interest in keeping the others out of the Netherlands so that no one's interests could be taken away or be changed. If one country were to have invaded the Netherlands, another would certainly have counterattacked to defend their own interest in the rivers. It was too big a risk for any of the belligerent nations and none wanted to risk fighting on another front.
The Dutch were affected by the war, troops were mobilized and conscription was introduced in the face of harsh criticism from opposition parties. In 1918, mutinies broke out in the military. Food shortages were extensive, due to the control the belligerents exercised over the Dutch. Each wanted their share of Dutch produce. As a result, the price of potatoes rose sharply because Britain had demanded so much from the Dutch. Food riots even broke out in the country. A big problem was smuggling. When Germany had conquered Belgium, the Allies saw it as enemy territory and stopped exporting to Belgium. Food became scarce for the Belgian people, since the Germans seized all food. This gave the Dutch the opportunity to start to smuggle. This, however, caused great problems in the Netherlands, including inflation and further food shortages. The Allies demanded that the Dutch stop the smuggling, and the government took measures to remain neutral. The government placed many cities under 'state of siege'. On 8 January 1916, a zone was created by the government along the border. In that zone, goods could be moved on main roads with a permit. German authorities in Belgium had an electrified fence erected all along the Belgian–Dutch border that caused many refugees from Belgium to lose their lives. The fence was guarded by older German Landsturm soldiers.

Although both houses of the Dutch parliament were elected by the people, only men with high incomes were eligible to vote until 1917, when pressure from socialist movements resulted in elections in which all men were allowed to vote. In 1919 women also obtained the right to vote.

The worldwide Great Depression of 1929 and the early 1930s had crippling effects on the Dutch economy, lasting longer than in most other European countries. The long duration of the Great Depression in the Netherlands is often explained by the very strict fiscal policy of the Dutch government at the time, and its decision to adhere to the gold standard for much longer than most of its trading partners. The depression led to high unemployment and widespread poverty, as well as increasing social unrest.

The rise of Nazism in Germany did not go unnoticed in the Netherlands, and there was growing concern at the possibility of armed conflict, but most Dutch citizens expected that Germany would again respect Dutch neutrality.

There were separate fascist and nazi movements in the 1930s. Dutch Fascists admired Mussolini's Italy and called for a traditional corporate ideology. The membership was small, elitist and ineffective. The pro-Nazi movement, however, won support from Berlin and attempted to build a mass base by 1935. It failed because most Dutch rejected its racial ideology and calls for violence.

The defense budget was not increased until Nazi Germany remilitarized the Rhineland in 1936. The budget was further increased in 1938 (after the annexation of Austria and occupation of the Czech Sudetenland). The colonial government also increased its military budget because of increasing tension with Japan. The Dutch did not mobilize their forces until shortly before France and Great Britain declared war in September 1939. Neutrality was still the policy but the Dutch government tried to buy new arms for their badly equipped forces but a considerable share of ordered weapons never arrived.

At the outbreak of World War II in 1939, the Netherlands once again declared its neutrality. However, on 10 May 1940, Nazi Germany launched an attack on the Netherlands and Belgium and quickly overran most of the two countries. Fighting against the Dutch army proved more of a burden than foreseen; the northern attack was stopped dead, the one in the middle came to a grinding halt near the Grebbeberg and many airborne assault troops were killed and taken prisoner in the west of the country.
Only in the south defenses broke but the one passage over the river Maas at Rotterdam was held by the Dutch. By 14 May, fighting in many locations had ceased and the German army could make little or no headway, so the Luftwaffe bombed Rotterdam, the second largest city of the Netherlands, killing about 900 people, destroying the inner city and leaving 78,000 people homeless.

Following the bombing and German threats of the same treatment for Utrecht, the Netherlands capitulated on 15 May, except for the province of Zeeland where French and French Moroccan troops stood side by side with the Dutch forces. Still, the royal family and some armed forces fled to the United Kingdom. Some members of the royal family eventually moved to Ottawa, Ontario, Canada until the Netherlands was liberated; Princess Margriet was born in Canadian exile.

Resentment of the Germans grew as the occupation became more harsh, prompting many Dutch in the latter years of the war to join the resistance. But collaboration was not uncommon either; many thousands of young Dutch males volunteered for combat service on the Russian Front with the Waffen-SS and many companies worked for the Germans.

About 140,000 Jews lived in the Netherlands at the beginning of the war. Persecution of Dutch Jews started shortly after the occupation. At the end of the war, 40,000 Jews were still alive. Of the 100,000 Jews who did not go into hiding, about 1,000 survived the war.

One who perished was Anne Frank, who gained worldwide fame posthumously when her diary, written in the "achterhuis" ('backhouse') while hiding from the Nazis, was found and published by her father, Otto Frank, the only survivor of the family.

On 8 December 1941, the day after the attack on Pearl Harbor, the Netherlands declared war on Japan. The Dutch government in exile in London had for long been working with London and with Washington to cut off oil supplies to Japan. Japanese forces invaded the Dutch East Indies on 11 January 1942. The Dutch surrendered 8 March after Japanese troops landed on Java. Dutch citizens and everybody with Dutch ancestry, the so-called "Indo's" were captured and put to work in labour camps or interned. As in the homeland, many Dutch ships, planes and military personnel managed to reach safe territory, in this case Australia, from where they were able to fight again.

In Europe, after the Allies landed in Normandy in June 1944, progress was slow until the Battle of Normandy ended in August 1944. German resistance collapsed in western Europe and the allied armies advanced quickly towards the Dutch border. The First Canadian Army and the Second British Army conducted operations on Dutch soil from September onwards. On 17 September a daring operation, Operation Market Garden, was executed with the goal of capturing bridges across three major rivers in the southern Netherlands. Despite desperate fighting by American, British and Polish forces, the bridge at Arnhem, across the Neder Rijn, could not be captured.

Areas south of the Rhine river were liberated in the period September–December 1944, including the province of Zeeland, which was liberated in October and November in the Battle of the Scheldt. This opened Antwerp to allied shipping. The First Canadian Army held a static line along the river Meuse (Maas) from December 1944 through February 1945.

The rest of the country remained occupied until the spring of 1945. In the face of Dutch defiance the Nazis deliberately cut off food supplies resulting in near-starvation in the cities during the "Hongerwinter" (Hunger winter) of 1944–45. Soup kitchens were set up but many fragile people died. A few days before the Allied victory the Germans allowed emergency shipments of food.
The First Canadian Army launched Operation Veritable in early February, cracking the Siegfried Line and reaching the banks of the Rhine in early March. In the final weeks of the war in Europe, the First Canadian Army was charged with clearing the Netherlands of German forces.

The Liberation of Arnhem began on 12 April 1945 and proceeded to plan, as the three infantry brigades of the 49th Division leapfrogged each other through the city. Within four days Arnhem, now a ruined city, was totally under Allied control.

The Canadians then immediately advanced further into the country, encountering and defeating a German counterattack at Otterlo and Dutch SS resistance at Ede. On 27 April a temporary truce came into effect, allowing the distribution of food aid to the starving Dutch civilians in areas under German control (Operation Manna). On 5 May 1945, Generaloberst Blaskowitz agreed to the unconditional surrender of all German forces in the Netherlands, signing the surrender to Canadian general Charles Foulkes at Wageningen. (The fifth of May is now celebrated annually in the Netherlands as Liberation Day.) Three days later Germany unconditionally surrendered, bringing the war in Europe to a close.

After the euphoria and settling of scores had ended, the Dutch were a traumatized people with a ruined economy, a shattered infrastructure and several destroyed cities including Rotterdam, Nijmegen, Arnhem and part of The Hague.

After the war, there were reprisals against those who had collaborated with the Nazis. Artur Seyss-Inquart, Nazi Commissioner of the Netherlands, was tried at Nüremberg.

In the early post-war years the Netherlands made continued attempts to expand its territory by annexing neighbouring German territory. The larger annexation plans were continuously rejected by the United States, but the London conference of 1949 permitted the Netherlands to perform a smaller scale annexation. Most of the annexed territory was returned to Germany on 1 August 1963.

Operation Black Tulip was a plan in 1945 by Dutch minister of Justice Kolfschoten to evict all Germans from the Netherlands. The operation lasted from 1946 to 1948 and in the end 3691 Germans (15% of Germans resident in the Netherlands) were deported. The operation started on 10 September 1946 in Amsterdam, where Germans and their families were taken from their homes in the middle of the night and given one hour to collect 50 kg of luggage. They were allowed to take 100 guilders. The rest of their possessions went to the state. They were taken to concentration camps near the German border, the biggest of which was Mariënbosch near Nijmegen.

The post-war years were a time of hardship, shortages and natural disaster. This was followed by large-scale public works programmes, economic recovery, European integration and the gradual introduction of a welfare state.

Immediately after the war, there was rationing, including of cigarettes, textiles, washing powder and coffee. Even wooden shoes were rationed. There were severe housing shortages. In the 1950s, there was mass emigration, especially to Canada, Australia and New Zealand. Government-encouraged emigration efforts to reduce population density prompted some 500,000 Dutch people to leave the country after the war. The Netherlands failed to hold the Dutch East Indies, as Indonesia became independent and 300,000 Dutch inhabitants (and their Indonesian allies) left the islands.

Postwar politics saw shifting coalition governments. The 1946 Parliamentary elections saw the Catholic People's Party (KVP) come in first just ahead of the socialist Labour party (PvdA). Louis J. M. Beel formed a new coalition cabinet. The United States began Marshall Plan aid in 1948 that pumped cash into the economy, fostered modernization of business, and encouraged economic cooperation. 

The 1948 elections led to a new coalition led by Labor's Willem Drees. He led four successive cabinets Drees I, Drees II, Drees III and Drees IV until late 1958. His terms saw four major political developments: the traumas of decolonization, economic reconstruction, the establishment of the Dutch welfare state, and international integration and co-operation, including the formation of Benelux, the OEEC, NATO, the ECSC, and the EEC.

Despite the problems, this was a time of optimism for many. A baby boom followed the war, as young Dutch couples started planning their families. They had lived through the hardships of depression and the hell of war. They wanted to start fresh and live better lives without the poverty, starvation, terror, and extreme frugality they knew so well. They had little taste for a strictly imposed rule-oriented traditional system with its rigid hierarchies, sharp pillarized boundaries and strictly orthodox religious doctrines. They made a best seller out of the translation of "The Common Sense Book of Baby and Child Care" (1946), by American pediatrician Benjamin Spock. His vision of family life as companionate, permissive, enjoyable and even fun took hold, and seemed the best way to achieve family happiness in a dawning age of freedom and prosperity.

Wages were kept low and the recovery of consumption to prewar levels was delayed to permit rapid rebuilding of the infrastructure. In the years after the war, unemployment fell and the economy grew at an astonishing pace, despite the high birth rate. The shattered infrastructure and destroyed cities were rebuilt. A key contribution to the recovery in the postwar Netherlands came from the Marshall Plan, which provided the country with funds, goods, raw materials and produce.

The Dutch became internationally active again. Dutch corporations, particularly Royal Dutch Shell and Philips, became internationally prominent. Business people, scientists, engineers and artists from the Netherlands made important international contributions. For example, Dutch economists, especially Jan Tinbergen (1903–1994), Tjalling Koopmans (1910–1985) and Henri Theil (1924–2000), made major contributions to the mathematical and statistical methodology known as econometrics.

Across Western Europe, the period from 1973 to 1981 marked the end of the booming economy of the 1960s. The Netherlands also experienced years of negative growth after that. Unemployment increased steadily, causing rapid growth in social-security expenditures. Inflation reached double digits; government surpluses disappeared. On the positive side, rich natural gas resources were developed, providing a current account trade surplus during most of the period. Public deficits were high. According to the long-term economic analysis of Horlings and Smits, the major gains in the Dutch economy were concentrated between 1870 and 1930 and between 1950 and 1970. Rates were much lower in 1930–45 and after 1987.

The last major flood in the Netherlands took place in early February 1953, when a huge storm caused the collapse of several dikes in the southwest of the Netherlands. More than 1,800 people drowned in the ensuing inundation.

The Dutch government subsequently decided on a large-scale programme of public works (the "Delta Works") to protect the country against future flooding. The project took more than thirty years to complete. The Oosterscheldedam, an advanced sea storm barrier, became operational in 1986. According to Dutch government engineers, the odds of a major inundation anywhere in the Netherlands are now one in 10,000 years.

The European Coal and Steel Community (ECSC), was founded in 1951 by the six founding members: Belgium, the Netherlands and Luxembourg (the Benelux countries) and West Germany, France and Italy. Its purpose was to pool the steel and coal resources of the member states, and to support the economies of the participating countries. As a side effect, the ECSC helped defuse tensions between countries which had recently been enemies in the war. In time, this economic merger grew, adding members and broadening in scope, to become the European Economic Community, and later the European Union.

The United States started to have more influence. After the war higher education changed from a German model to more of an American model. American influences had been small in the interwar era, and during the war the Nazis had emphasised the dangers of a "degraded" American culture as represented by jazz. However, the Dutch became more attracted to the United States during the postwar era, perhaps partly because of antipathy towards the Nazis but certainly because of American movies and consumer goods. The Marshall Plan also introduced the Dutch to American management practices. NATO brought in American military doctrine and technology. Intellectuals, artists and the political left, however, remained more reserved about the Americans. According to Rob Kroes, the anti-Americanism in the Netherlands was ambiguous: American culture was both accepted and criticised at the same time.

The Netherlands is a founding member of the EU, NATO, OECD and WTO. Together with Belgium and Luxembourg it forms the Benelux economic union. The country is host to the Organization for the Prohibition of Chemical Weapons and five international courts: the Permanent Court of Arbitration, the International Court of Justice, the International Criminal Tribunal for the Former Yugoslavia, the International Criminal Court and the Special Tribunal for Lebanon. The first four are situated in The Hague, as is the EU's criminal intelligence agency Europol and judicial co-operation agency Eurojust. This has led to the city being dubbed "the world's legal capital".

The Dutch East Indies had long been a valuable resource to the Netherlands, generating in the 1930s about 14 percent of the Dutch national income, and home to thousands of Dutch and officials, businessmen and missionaries. By the first half of the 20th century, new organisations and leadership had developed in the Dutch East Indies. Under its Ethical Policy, the government had helped create an educated Indonesian elite. These profound changes constituted the "Indonesian National Revival". Increased political activism and Japanese occupation undermining Dutch rule culminated in nationalists proclaiming independence on 17 August 1945, two days after the surrender of Japan. The Dutch did not plan to let go, for they would be left as merely a minor second-class power ranking with Denmark perhaps. However the Netherlands was much too weak to reconquer Indonesia. The Japanese had imprisoned all the Dutch residents, and turned the islands over to a native government, which was widely popular. The British military arrived to disarm the Japanese. The Dutch finally returned and attempted to eradicate the Indonesian National Revolution with force, (sometimes brutal in nature). 

Hundreds of thousands of Indonesians supported the Dutch position; when Independence finally arrived, most of them were relocated to the Netherlands. Britain mediated a compromise signed in March 1947 whereby de facto control of the new Indonesian Republic was acknowledged over Java, Maduro and Sumatra, while acknowledging Dutch control over the numerous smaller and far less important islands. Supposedly there would be a federated Indonesian state and a union with the Netherlands, but that never happened. The Indonesians wanted complete transfer of power, and the Dutch refused. By 1946 the United States was financing the Dutch in Indonesia, and was able to exert pressure on The Hague. Increasing international pressure--including American hints about cutting off military funds-- forced the Netherlands to withdraw. A decisive episode was the success of the Indonesian Republic in crushing a communist revolt. Washington now realize that Indonesia was part of the Cold War against communism, and the Indonesian government was a necessary ally-- and that the Dutch tactics were counterproductive and chaotic, and could only help communist insurgencies. The Netherlands formally recognised Indonesian independence on 27 December 1949. Public opinion blamed the Washington for the Dutch colonial failure. Only Irian, the western half of New Guinea remained under Dutch control as Netherlands New Guinea until 1961, when the Netherlands transferred sovereignty of this area to Indonesia.

During and after the Indonesian National Revolution, around 300,000 people, predominantly "Indos" (Dutch-Indonesian Eurasians), left Indonesia for the Netherlands. This migration occurred in five distinct waves over a period of 20 years. It included Indos (many of whom spent the war years in Japanese concentration camps), former South Moluccan soldiers and their families, "New-Guinea Issue" Dutch citizens, Dutch citizens from Netherlands New Guinea (including Papuan civil servants and their families), and other Indos who had remained behind but later regretted their decision to take out Indonesian citizenship.

The Indos of Indonesian descent (now numbering around 680,000) is the largest minority group in the Netherlands. They are integrated into Dutch society, but they have also retained many aspects of their culture and have added a distinct Indonesian flavour to the Netherlands.

Although it was originally feared that the loss of the Dutch East Indies would contribute to an economic decline, the Dutch economy experienced exceptional growth (partly because a disproportionate amount of Marshall Aid was received) in the 1950s and 1960s. In fact, the demand for labour was so strong that immigration was actively encouraged, first from Italy and Spain then later on, in larger numbers, from Turkey and Morocco.

Suriname became independent on 25 November 1975. The Dutch government supported independence because it wanted to stem the flow of immigrants from Suriname and also to end its colonial status. However, about one third of the entire population of Suriname, fearing political unrest and economic decline, relocated to the Netherlands, creating a Surinamese community in the Netherlands that is now roughly as large as the population of Suriname itself.

When the postwar baby-boom children grew up, they led the revolt in the 1960s against all rigidities in Dutch life. The 1960s and 1970s were a time of great social and cultural change, such as rapid "ontzuiling" (literally: depillarisation), a term that describes the decay of the old divisions along class and religious lines. A youth culture emerged all across Western Europe and the U.S., characterised by student rebellion, informality, sexual freedom, informal clothes, new hair styles, protest music, drugs and idealism. Young people, and students in particular, rejected traditional mores, and pushed for change in matters like women's rights, sexuality, disarmament and environmental issues.

Secularization, or the decline in religiosity, first became noticeable after 1960 in the Protestant rural areas of Friesland and Groningen. Then, it spread to Amsterdam, Rotterdam and the other large cities in the west. Finally the Catholic southern areas showed religious declines. As the social distance between the Calvinists and Catholics narrowed (and they began to intermarry), it became possible to merge their parties. The Anti-Revolutionary Party (ARP) in 1977 merged with the Catholic People's Party (KVP) and the Protestant Christian Historical Union (CHU) to form the Christian Democratic Appeal (CDA). However, a countervailing trend later appeared as the result of a religious revival in the Protestant Bible Belt, and the growth of the Muslim and Hindu communities as a result of immigration and high fertility levels.

After 1982, there was a retrenchment of the welfare system, especially regarding old-age pensions, unemployment benefits, and disability pensions/early retirement benefits.

Following the election of 1994, in which the Christian democratic CDA lost a considerable portion of its representatives, the social-liberal Democrats 66 (D66) doubled in size and formed a coalition with the labour party (Netherlands) (PvdA), and the People's Party for Freedom and Democracy (VVD). This purple (government) coalition marked the first absence of the CDA in government in decades. During the Purple Coalition years, a period lasting until the rise of the populist politician Pim Fortuyn, the government addressed issues previously viewed as taboo under the Christian-influenced cabinet. At this time, the Dutch government introduced unprecedented legislation based on a policy of official tolerance ("gedoogbeleid"). Abortion and euthanasia were decriminalized, but stricter guidelines were set for their implementation. Drug policy, especially with regard to the regulation of cannabis, was reformed. Prostitution was legalised, but confined to brothels where the health and safety of those involved could be properly monitored. With the 2001 Same-Sex Marriage Act, the Netherlands became the first country to legalise same-sex marriage. In addition to social reforms, the Purple Coalition also presided over a period of remarkable economic prosperity.

In the 1998 election the Purple Coalition consisting of Social Democrats, and left and right wing Liberals, increased its majority. Both the social-democratic PvdA and the conservative liberal VVD grew at the cost of their junior partner in cabinet, the progressive liberal D66. The voters rewarded the Purple Coalition for its economic performance, which had included reduction of unemployment and the budget deficit, steady growth and job creation combined with wage freezes and trimming of the welfare state, together with a policy of fiscal restraint. The result was the second Kok cabinet.

The power of the coalition waned with the introduction of List Pim Fortuyn in the Dutch general election of 2002, a populist party, which ran a distinctly anti-immigration and anti-purple campaign, citing "Purple Chaos" ("Puinhopen van Paars") as the source of the countries social woes. In the first political assassination in three centuries, Fortuyn was murdered with little over a week left before the election. In the wake of its leader's death, LPF swept the elections, entering parliament with one sixth of the seats, while the PvdA (Labour) lost half of its seats. The ensuing cabinet was formed by CDA, VVD and LPF, led by Prime Minister Jan Peter Balkenende. Though the party succeeded in displacing the rival Purple Coalition, without the charismatic figure of Pim Fortuyn at its helm, it proved to be short-lived lasting 87 days in power.

Two events changed the political landscape:


By 2000 the population had increased to 15.9 million people, making the Netherlands one of the most densely populated countries in the world. Urban development has led to the development of a conurbation called the "Randstad" (), which includes the four largest cities (Amsterdam, Rotterdam, The Hague and Utrecht), and the surrounding areas. With a population of 7,100,000 it is one of the largest conurbations in Europe.

This small nation has successfully developed into one of the most open, dynamic and prosperous countries in the world. It had the tenth-highest per capita income in the world in 2011. It has an open, market-based mixed economy, ranking 13th of 157 countries according to the Index of Economic Freedom. In May 2011, the OECD ranked the Netherlands as the "happiest" country in the world.


The American John Lothrop Motley was the first foreign historian to write a major history of the Dutch Republic. In 3500 pages he crafted a literary masterpiece that was translated into numerous languages; his dramatic story reached a wide audience in the 19th century. Motley relied heavily on Dutch scholarship and immersed himself in the sources. His style no longer attracts readers, and scholars have moved away from his simplistic dichotomies of good versus evil, Dutch versus Spanish, Catholic versus Protestant, freedom versus authoritarianism. His theory of causation over-emphasized ethnicity as an unchanging characteristic, exaggerated the importance of William of Orange, and gave undue importance to the issue religious tolerance.

The pioneering Dutch cultural historian Johan Huizinga (1872–1945), author of "The Autumn of the Middle Ages" (1919) (the English translation was called "The Waning of the Middle Ages") and "Homo Ludens: A Study of the Play Element in Culture" (1935), which expanded the field of cultural history and influenced the historical anthropology of younger historians of the French Annales School. He was influenced by art history and advised historians to trace "patterns of culture" by studying "themes, figures, motifs, symbols, styles and sentiments."

The "polder model" continues to strongly influence historians as well as Dutch political discussion. The polder model stresses the need for finding consensus; it discourages furious debate and angry dissent in both academia and politics – in contrast to the highly developed, intense debates in Germany.

The H-Net list H-Low-Countries is published free by email and is edited by scholars. Its occasional messages serve an international community with diverse methodological approaches, archival experiences, teaching styles, and intellectual traditions, promotes discussion relevant to the region and to the different national histories in particular, with an emphasis on the Netherlands. H-Low-Countries publishes conference announcements, questions and discussions; reviews of books, journals, and articles; and tables of contents of journals on the history of the Low Countries (in both Dutch and English). After World War II both research-oriented and teaching-oriented historians have been rethinking their interpretive approaches to Dutch history, balancing traditional memories and modern scholarship. In terms of popular history, there has been an effort to ensure greater historical accuracy in museums and historic tourist sites.

Once heralded as the leading event of modern Dutch history, the Dutch Revolt lasted from 1568 to 1648, and historians have worked to interpret it for even longer. Cruz (2007) explains the major debates among scholars regarding the Dutch bid for independence from Spanish rule. While agreeing that the intellectual milieus of late 19th and 20th centuries affected historians' interpretations, Cruz argues that writings about the revolt trace changing perceptions of the role played by small countries in the history of Europe. In recent decades grand theory has fallen out of favor among most scholars, who emphasize the particular over the general. Dutch and Belgian historiography since 1945 no longer says the revolt was the culmination of an inevitable process leading to independence and freedom. Instead scholars have put the political and economic details of the towns and provinces under the microscope, while agreeing on the weaknesses of attempts at centralization by the Habsburg rulers. The most influential new studies have been rooted in demographic and economic history, though scholars continue to debate the relationship between economics and politics. The religious dimension has been viewed in terms of mentalities, exposing the minority position of Calvinism, while the international aspects have been studied more seriously by foreign historians than by the Dutch themselves.

Pieter Geyl was the leading historian of the Dutch Revolt, and a highly influential professor at the University of London (1919–1935) and at the State University of Utrecht (1936–58). He wrote a six-volume history of the Dutch-speaking peoples. The Nazis imprisoned him in World War II. In his political views, Geyl adopted the views of the 17th-century Dutch Louvestein faction, led by Johan van Oldenbarneveldt (1547–1619) and Johan de Witt (1625–72). It stood for liberty, toleration, and national interests in contrast to the Orange stadholders who sought to promote their own self-interest. According to Geyl, the Dutch Republic reached the peak of its powers during the 17th century. He was also a staunch nationalist and suggested that Flanders could split off from Belgium and join the Netherlands. Later he decried what he called radical nationalism and stressed more the vitality of Western Civilization. Geyl was highly critical of the world history approach of Arnold J. Toynbee.

Jan Romein (1893-1962) created a "theoretical history" in an attempt to reestablish the relevance of history to public life in the 1930s at a time of immense political uncertainty and cultural crisis, when Romein thought that history had become too inward-looking and isolated from other disciplines. Romein, a Marxist, wanted history to contribute to social improvement. At the same time, influenced by the successes of theoretical physics and his study of Oswald Spengler, Arnold J. Toynbee, Frederick John Teggart, and others, he spurred on the development of theoretical history in the Netherlands, to the point where it became a subject in its own right at the university level after the war. Romein used the term integral history as a substitute for cultural history and focused his attention on the period around the turn of the century. He concluded that a serious crisis occurred in European civilization in 1900 because of the rise of anti-Semitism, extreme nationalism, discontent with the parliamentary system, depersonalization of the state, and the rejection of positivism. European civilization waned as the result of this crisis which was accompanied by the rise of the United States, the Americanization of the world, and the emergence of Asia. His interpretation is reminiscent of that of his mentor Johan Huizinga and was criticized by his colleague Pieter Geyl.

See also: 




</doc>
<doc id="13290" url="https://en.wikipedia.org/wiki?curid=13290" title="Harold and Maude">
Harold and Maude

Harold and Maude is a 1971 American romantic black comedy drama directed by Hal Ashby and released by Paramount Pictures. It incorporates elements of dark humor and existentialist drama. The plot revolves around the exploits of a young man named Harold Chasen (Bud Cort) who is intrigued with death. Harold drifts away from the life that his detached mother (Vivian Pickles) prescribes for him, and slowly develops a strong friendship, and eventually a romantic relationship, with a 79-year-old woman named Maude (Ruth Gordon) who teaches Harold about living life to its fullest and that life is the most precious gift of all.

The film was based on a screenplay written by Colin Higgins and published as a novel in 1971. Filming locations in the San Francisco Bay Area included both Holy Cross Cemetery and Golden Gate National Cemetery, and the ruins of the Sutro Baths.

Critically and commercially unsuccessful when originally released, the film developed a cult following and in 1983 began making a profit. The film is ranked number 45 on the American Film Institute's list of 100 Funniest Movies of all Time and was selected for preservation in the National Film Registry of the Library of Congress in 1997, for being "culturally, historically or aesthetically significant". The Criterion Collection special-edition Blu-ray and DVD were released June 12, 2012.

Harold Chasen is a young man obsessed with death. He stages elaborate fake suicides, attends funerals, and drives a hearse, all to the chagrin of his socialite mother. She sets him up appointments with a psychoanalyst, but the analyst is befuddled by the case and fails to get Harold to talk about his real emotions.

At another stranger's funeral service, Harold meets Maude, a 79-year-old woman who shares Harold's hobby of attending funerals. He is entranced by her quirky outlook on life, which is bright and excessively carefree in contrast with his morbidity. The pair form a bond and Maude shows Harold the pleasures of art and music (including how to play banjo), and teaches him how to "[make] the most of his time on earth". Meanwhile, Harold's mother is determined, against Harold's wishes, to find him a wife. One by one, Harold frightens and horrifies each of his appointed dates, by appearing to commit gruesome acts such as self-immolation, self-mutilation and seppuku. She tries enlisting him in the military instead, but he deters his recruiting officer uncle by staging a scene in which Maude poses as a pacifist protester and Harold seemingly murders her out of militaristic fanaticism.

When Harold and Maude are talking at her home he tells her, without prompting, the motive for his fake suicides: When he was at boarding school, he accidentally caused an explosion in his chemistry lab, leading police to assume his death. Harold returned home just in time to witness his mother react to the news of his death with a ludicrously dramatized faint. As he reaches this part of the story, Harold bursts into tears and says, "I decided then I enjoyed being dead."

As they become closer, their friendship soon blossoms into a romance and Harold announces that he will marry Maude, resulting in disgusted outbursts from his family, analyst, and priest. Maude's 80th birthday arrives, and Harold throws a surprise party for her. As the couple dance, Maude tells Harold that she "couldn't imagine a lovelier farewell." Confused, he questions Maude as to her meaning and she reveals that she has taken an overdose of sleeping pills and will be dead by morning. She restates her firm belief that eighty is the proper age to die.

Harold rushes Maude to the hospital, where she is treated unsuccessfully and dies. In the final sequence, Harold's car is seen going off a seaside cliff but after the crash, the final shot reveals Harold standing calmly atop the cliff, holding his banjo. After gazing down at the wreckage, he dances away, picking out on his banjo Cat Stevens' song "If You Want to Sing Out, Sing Out".


Director Hal Ashby appears in an uncredited cameo, watching a model train at an amusement park. The amusement park is Santa Cruz Beach Boardwalk (California USA) / Penny Arcade.

UCLA student Colin Higgins wrote "Harold and Maude" as his master's thesis. While working as producer Edward Lewis's pool boy, Higgins showed the script to Lewis's wife, Mildred. Mildred was so impressed that she got Edward to give it to Stanley Jaffe at Paramount. Higgins sold the script with the understanding that he would direct the film but he was told he wasn't ready, after tests he shot proved unsatisfactory to the studio heads. Ashby would only commit to directing the film after getting Higgins' blessing and then, so Higgins could watch and learn from him on the set, Ashby made Higgins a co-producer. Higgins says he originally thought of the story as a play. It then became a 20-minute thesis while at film school. After the film came out, the script was turned into a novel then a play, which ran for several years in Paris.

Ashby felt that Maude should ideally be European and his list of possible actresses included dames Peggy Ashcroft, Edith Evans, Gladys Cooper and Celia Johnson as well as Lotte Lenya, Luise Rainer, Pola Negri, Minta Durfee, and Agatha Christie. Ruth Gordon indicated that in addition she heard that Edwige Feuillère, Elisabeth Bergner, Mildred Natwick, Mildred Dunnock, and Dorothy Stickney had been considered.

For Harold, in addition to Bud Cort, Ashby considered all promising unknowns, Richard Dreyfuss, Bob Balaban, and John Savage. Also on his list were John Rubinstein, for whom Higgins had written the part, and then-up-and-coming British pop star Elton John, whom Ashby had seen live and hoped would also do the music.

Anne Brebner, the casting director, was almost cast as Harold's mother, when Vivian Pickles was briefly unable to do the role.

"Harold and Maude" received mixed reviews, with several critics being offended by the film's dark humor. Roger Ebert, in a review dated January 1, 1972, gave the film one-and-a-half out of four stars. He wrote, "And so what we get, finally, is a movie of attitudes. Harold is death, Maude life, and they manage to make the two seem so similar that life's hardly worth the extra bother. The visual style makes everyone look fresh from the Wax Museum, and all the movie lacks is a lot of day-old gardenias and lilies and roses in the lobby, filling the place with a cloying sweet smell. Nothing more to report today. Harold doesn't even make pallbearer." Vincent Canby also panned the film, stating that the actors "are so aggressive, so creepy and off-putting, that Harold and Maude are obviously made for each other, a point the movie itself refuses to recognize with a twist ending that betrays, I think, its life-affirming pretensions."

The reputation of the film has increased greatly; Rotten Tomatoes, which labeled the film as "Certified Fresh", gave it a score of 86% based on 42 reviews, with an average score of 7.6/10. A consensus on the site read, "Hal Ashby's comedy is too dark and twisted for some, and occasionally oversteps its bounds, but there's no denying the film's warm humor and big heart." In 2005, the Writers Guild of America ranked the screenplay #86 on its list of 101 Greatest Screenplays ever written. Sight & Sound magazine conducts a poll every ten years of the world's finest film directors, to find out the Ten Greatest Films of All Time. This poll has been going since 1992 and has become the most recognized poll of its kind in the world. In 2012, Niki Caro, Wanuri Kahiu, and Cyrus Frisch voted for "Harold and Maude". Frisch commented: "An encouragement to think beyond the obvious!" In 2017, "Chicago Tribune" critic Mark Caro wrote a belated appreciation, "I'm sorry, "Harold and Maude", for denying you for so long. You're my favorite movie once again."

On June 12, 2012, The Criterion Collection released "Harold and Maude" for Region 1 on DVD and Blu-ray, both of which includes a collection of audio excerpts of director Hal Ashby from January 11, 1972 and of screenwriter Colin Higgins from January 10, 1979, a new video interview with Yusuf/Cat Stevens, a new audio commentary by Ashby biographer Nick Dawson and producer Charles B. Mulvehill, and a booklet which includes a new film essay by film and television critic Matt Zoller Seitz. Exclusive to the Blu-ray edition are a new digital restoration of the film with uncompressed monaural soundtrack and an optional remastered uncompressed stereo soundtrack. Other exclusives are a "New York Times" profile of actress Ruth Gordon from 1971, an interview from 1997 with actor Bud Cort and cinematographer John Alonzo, and an interview from 2001 with executive producer Mildred Lewis.

"Harold and Maude" is #45 on the American Film Institute's list of 100 Years... 100 Laughs, the list of the top 100 films in American comedy. The list was released in 2000. Two years later, AFI released the list AFI's 100 Years... 100 Passions honoring the most romantic films for the past 100 years, "Harold and Maude" ranked #69. In September 2008, "Empire" listed "Harold and Maude" as #65 in "Empire"s 500 Greatest Movies of All Time. "Entertainment Weekly" ranked the film #4 on their list of "The Top 50 Cult Films."

In June 2008, AFI revealed its "Ten Top Ten"—the best ten films in ten "classic" American film genres—after polling over 1,500 people from the creative community. "Harold and Maude" was acknowledged as the ninth-best film in the romantic comedy genre.

The film is recognized by American Film Institute in these lists:

At the 29th Golden Globe Awards, Bud Cort and Ruth Gordon received a nomination for Best Actor and Best Actress in a Musical or Comedy film, respectively.

The music in "Harold and Maude" was composed and performed by Cat Stevens. He had been suggested by Elton John to do the music after John had dropped out of the project. Stevens composed two original songs for the film, "Don't Be Shy" and "If You Want to Sing Out, Sing Out" and performed instrumental and alternate versions of the songs "On the Road to Find Out", "I Wish, I Wish", "Miles from Nowhere", "Tea for the Tillerman", "I Think I See the Light", "Where Do the Children Play?" and "Trouble" which were either on the album "Mona Bone Jakon" or "Tea for the Tillerman". Those albums had been released before the film. "Don't Be Shy" and "If You Want to Sing Out, Sing Out" were not released on an album, until his 1984 compilation "".

There is some additional non–Cat Stevens music in the film. "Greensleeves" is played on the harp during dinner. During the scene where Harold is floating face-down in the swimming pool, the opening bars of Tchaikovsky's Piano Concerto No. 1 are heard. A marching band is also heard playing a march titled "The Klaxon" by Henry Fillmore outside the church following a funeral.

The first soundtrack was released in Japan in 1972 on vinyl and cassette (A&M Records GP-216). It omitted the two original songs and all instrumental and alternate versions of songs and was generally composed of re-released material that was in the film, along with five songs that were not in the film.


The second soundtrack was released in December 2007, by Vinyl Films Records, as a vinyl-only limited-edition release of 2,500 copies. It contained a 30-page oral history of the making of the film, the most extensive series of interviews yet conducted on "Harold and Maude".


Colin Higgins later adapted the story into a stage play. The original Broadway production, starring Janet Gaynor as Maude and Keith McDermott as Harold, closed after four performances in February 1980.

A French adaptation for television, translated and written by Jean-Claude Carrière, appeared in 1978. It was also adapted for the stage by the Compagnie Viola Léger in Moncton, New Brunswick, starring Roy Dupuis.

Higgins expressed interest in 1978 about both a sequel and prequel to "Harold and Maude". The sequel, "Harold's Story", would have Cort portray Harold's life after Maude. Higgins also imagined a prequel showing Maude's life before Harold, "Grover and Maude" had Maude learning how to steal cars from Grover Muldoon, the character portrayed by Richard Pryor in Higgins' 1976 film "Silver Streak". Higgins wanted Gordon and Pryor to reprise their roles.




</doc>
<doc id="13291" url="https://en.wikipedia.org/wiki?curid=13291" title="Habitus (sociology)">
Habitus (sociology)

Habitus is a system of embodied dispositions, tendencies that organize the ways in which individuals perceive the social world around them and react to it. These dispositions are usually shared by people with similar background (in terms of social class, religion, nationality, ethnicity, education, profession etc.), as the habitus is acquired through "mimesis" and reflects the lived reality to which individuals are socialized, their individual experience and objective opportunities. Thus, the habitus represents the way group culture and personal history shape the body and the mind, and as a result, shape social action in the present.

Pierre Bourdieu suggested that the habitus consists of both the "hexis" (the tendency to hold and use one's body in a certain way, such as posture and accent) and more abstract mental habits, schemes of perception, classification, appreciation, feeling, and action. These schemes are not mere habits: Bourdieu suggested they allow individuals to find new solutions to new situations without calculated deliberation, based on their gut feelings and intuitions, which Bourdieu believed were collective and socially shaped. These attitudes, mannerisms, tastes, moral intuitions and habits have influence on the individual's life chances, thus the habitus is both structured by an individuals' objective past position in the social structure; and structuring its future life path. Pierre Bourdieu argued that the reproduction of the social structure results from the habitus of individuals (Bourdieu, 1987).

The notion of habitus is extremely influential (with 400,000 Google Scholar publications using it), yet it also evoked criticism for its alleged determinism, as Bourdieu compared social actors to "automata" (while relying on Leibniz's theory of Monads).

The concept of habitus has been used as early as Aristotle but in contemporary usage was introduced by Marcel Mauss and later Maurice Merleau-Ponty. However, it was Pierre Bourdieu who turned it into a cornerstone of his sociology, and used it to address the sociological problem of agency and structure: the habitus is shaped by structural position and generates action, thus when people act and demonstrate agency they simultaneously reflect and reproduce social structure. Bourdieu elaborated his theory of the habitus while borrowing ideas on cognitive and generative schemes from Noam Chomsky and Jean Piaget dependency on history and human memory. For instance, a certain behaviour or belief becomes part of a society's structure when the original purpose of that behaviour or belief can no longer be recalled and becomes socialized into individuals of that culture.

Loïc Wacquant wrote that habitus is an old philosophical notion, originating in the thought of Aristotle, whose notion of "hexis" ("state") was translated into "habitus" by the Medieval Scholastics. Bourdieu first adapted the term in his 1967 postface to Erwin Panofsky's "Gothic Architecture and Scholasticism". The term was earlier used in sociology by Norbert Elias in "The Civilizing Process" (1939) and in Marcel Mauss's account of "body techniques" (techniques du corps). The concept is also present in the work of Max Weber, Gilles Deleuze, and Edmund Husserl.

Mauss defined habitus as those aspects of culture that are anchored in the body or daily practices of individuals, groups, societies, and nations. It includes the totality of learned habits, bodily skills, styles, tastes, and other non-discursive knowledges that might be said to "go without saying" for a specific group (Bourdieu 1990:66-67)—in that way it can be said to operate beneath the level of rational ideology.

According to Bourdieu, habitus is composed of:

The term has also been adopted in literary criticism, adapting from Bourdieu's usage of the term. For example, Joe Moran's examination of authorial identities in "Star Authors: Literary Celebrity in America" uses the term in discussion of how authors develop a habitus formed around their own celebrity and status as authors, which manifests in their writing.

Bourdieu's principle of habitus is interwoven with the concept of structuralism in literary theory. Peter Barry explains, "in the structuralist approach to literature there is a constant movement away from interpretation of the individual literary work and a parallel drive towards understanding the larger structures which contain them" (2009, p. 39). There is therefore a strong desire to understand the larger influencing factors which makes an individual literary work. As Bourdieu explains, habitus "are structured structures, generative principles of distinct and distinctive practices – what the worker eats, and especially the way he eats it, the sport he practices and the way he practices it, his political opinions and the way he expresses them are systematically different from the industrial proprietor's corresponding activities / habitus are also structuring structures, different classifying schemes classification principles, different principles of vision and division, different tastes. Habitus make different differences; they implement distinctions between what is good and what is bad, what is right and what is wrong, between what is distinguished and what is vulgar, and so on, but they are not the same. Thus, for instance, the same behaviour or even the same good can appear distinguished to one person, pretentious to someone else, and cheap or showy to yet another" (Bourdieu, 1996). As a result, habitus may be employed in literary theory in order to understand those larger, external structures which influence individual theories and works of literature.

Body habitus (or "bodily habitus") is the medical term for physique, and is categorized as either endomorphic (relatively short and stout), ectomorphic (relatively long and thin) or mesomorphic (average dimensions). In this sense, habitus has in the past been interpreted as the physical and constitutional characteristics of an individual, especially as related to the tendency to develop a certain disease. For example, "Marfanoid bodily habitus".




</doc>
<doc id="13292" url="https://en.wikipedia.org/wiki?curid=13292" title="Hypoxia (medical)">
Hypoxia (medical)

Hypoxia is a condition in which the body or a region of the body is deprived of adequate oxygen supply at the tissue level. Hypoxia may be classified as either "generalized", affecting the whole body, or "local", affecting a region of the body. Although hypoxia is often a pathological condition, variations in arterial oxygen concentrations can be part of the normal physiology, for example, during hypoventilation training or strenuous physical exercise.

Hypoxia differs from hypoxemia and anoxemia in that hypoxia refers to a state in which oxygen supply is insufficient, whereas hypoxemia and anoxemia refer specifically to states that have low or zero arterial oxygen supply. Hypoxia in which there is complete deprivation of oxygen supply is referred to as anoxia.

Generalized hypoxia occurs in healthy people when they ascend to high altitude, where it causes altitude sickness leading to potentially fatal complications: high altitude pulmonary edema (HAPE) and high altitude cerebral edema (HACE). Hypoxia also occurs in healthy individuals when breathing mixtures of gases with a low oxygen content, e.g. while diving underwater especially when using closed-circuit rebreather systems that control the amount of oxygen in the supplied air. Mild, non-damaging intermittent hypoxia is used intentionally during altitude training to develop an athletic performance adaptation at both the systemic and cellular level.

Hypoxia is a common complication of preterm birth in newborn infants. Because the lungs develop late in pregnancy, premature infants frequently possess underdeveloped lungs. To improve lung function, doctors frequently place infants at risk of hypoxia inside incubators (also known as humidicribs) that provide continuous positive airway pressure.

The symptoms of generalized hypoxia depend on its severity and acceleration of onset.

In the case of altitude sickness, where hypoxia develops gradually, the symptoms include fatigue, numbness / tingling of extremities, nausea, and anoxia. These symptoms are often difficult to identify, but early detection of symptoms can be critical.

In severe hypoxia, or hypoxia of very rapid onset, ataxia, confusion / disorientation / hallucinations / behavioral change, severe headaches / reduced level of consciousness, papilloedema, breathlessness, pallor, tachycardia, and pulmonary hypertension eventually leading to the late signs cyanosis, slow heart rate / cor pulmonale, and low blood pressure followed by death.

Because hemoglobin is a darker red when it is not bound to oxygen (deoxyhemoglobin), as opposed to the rich red color that it has when bound to oxygen (oxyhemoglobin), when seen through the skin it has an increased tendency to reflect blue light back to the eye. In cases where the oxygen is displaced by another molecule, such as carbon monoxide, the skin may appear 'cherry red' instead of cyanotic. Hypoxia can cause premature birth, and injure the liver, among other deleterious effects.

If tissue is not being perfused properly, it may feel cold and appear pale; if severe, hypoxia can result in cyanosis, a blue discoloration of the skin. If hypoxia is very severe, a tissue may eventually become gangrenous.
Extreme pain may also be felt at or around the site.

Tissue hypoxia from low oxygen delivery may be due to low haemoglobin concentration (anaemic hypoxia), low cardiac output (stagnant hypoxia) or low haemoglobin saturation (hypoxic hypoxia). The consequence of oxygen deprivation in tissues is a switch to anaerobic metabolism at the cellular level. As such, reduced systemic blood flow may result in increased serum lactate. Serum lactate levels have been correlated with illness severity and mortality in critically ill adults and in ventilated neonates with respiratory distress.

Oxygen passively diffuses in the lung alveoli according to a pressure gradient. Oxygen diffuses from the breathed air, mixed with water vapour, to arterial blood, where its partial pressure is around 100 mmHg (13.3 kPa). In the blood, oxygen is bound to hemoglobin, a protein in red blood cells. The binding capacity of hemoglobin is influenced by the partial pressure of oxygen in the environment, as described in the oxygen–hemoglobin dissociation curve. A smaller amount of oxygen is transported in solution in the blood.

In peripheral tissues, oxygen again diffuses down a pressure gradient into cells and their mitochondria, where it is used to produce energy in conjunction with the breakdown of glucose, fats, and some amino acids.

Hypoxia can result from a failure at any stage in the delivery of oxygen to cells. This can include decreased partial pressures of oxygen, problems with diffusion of oxygen in the lungs, insufficient available hemoglobin, problems with blood flow to the end tissue, and problems with breathing rhythm.

Experimentally, oxygen diffusion becomes rate limiting (and lethal) when arterial oxygen partial pressure falls to 60 mmHg (5.3 kPa) or below. 

Almost all the oxygen in the blood is bound to hemoglobin, so interfering with this carrier molecule limits oxygen delivery to the periphery. Hemoglobin increases the oxygen-carrying capacity of blood by about 40-fold, with the ability of hemoglobin to carry oxygen influenced by the partial pressure of oxygen in the environment, a relationship described in the oxygen–hemoglobin dissociation curve. When the ability of hemoglobin to carry oxygen is interfered with, a hypoxic state can result.

Ischemia, meaning insufficient blood flow to a tissue, can also result in hypoxia. This is called 'ischemic hypoxia'. This can include an embolic event, a heart attack that decreases overall blood flow, or trauma to a tissue that results in damage. An example of insufficient blood flow causing local hypoxia is gangrene that occurs in diabetes.

Diseases such as peripheral vascular disease can also result in local hypoxia. For this reason, symptoms are worse when a limb is used. Pain may also be felt as a result of increased hydrogen ions leading to a decrease in blood pH (acidity) created as a result of anaerobic metabolism.

This refers specifically to hypoxic states where the arterial content of oxygen is insufficient. This can be caused by alterations in respiratory drive, such as in respiratory alkalosis, physiological or pathological shunting of blood, diseases interfering in lung function resulting in a ventilation-perfusion mismatch, such as a pulmonary embolus, or alterations in the partial pressure of oxygen in the environment or lung alveoli, such as may occur at altitude or when diving.

Carbon monoxide competes with oxygen for binding sites on hemoglobin molecules. As carbon monoxide binds with hemoglobin hundreds of times tighter than oxygen, it can prevent the carriage of oxygen.
Carbon monoxide poisoning can occur acutely, as with smoke intoxication, or over a period of time, as with cigarette smoking. Due to physiological processes, carbon monoxide is maintained at a resting level of 4–6 ppm. This is increased in urban areas (7–13 ppm) and in smokers (20–40 ppm). A carbon monoxide level of 40 ppm is equivalent to a reduction in hemoglobin levels of 10 g/L.

CO has a second toxic effect, namely removing the allosteric shift of the oxygen dissociation curve and shifting the foot of the curve to the left. In so doing, the hemoglobin is less likely to release its oxygens at the peripheral tissues. Certain abnormal hemoglobin variants also have higher than normal affinity for oxygen, and so are also poor at delivering oxygen to the periphery.

High altitude is accompanied by a reduction in atmospheric pressure. The reduction in atmospheric pressure includes a reduction in the amount of oxygen in the atmosphere. As such, a there is a reduction in the partial pressure of inspired oxygen at higher altitudes and oxygen saturation. Lowered oxygen saturation ultimately leads to hypoxia, which manifests as the clinical features of altitude sickness. Features of altitude sickness include: sleep problems, dizziness, headache and oedema.

The breathing gas in scuba diving may contain an insufficient partial pressure of oxygen, particularly in malfunction of rebreathers. Such situations may lead to unconsciousness without symptoms since carbon dioxide levels are normal and the human body senses pure hypoxia poorly.

A similar problem exists when inhaling certain odorless asphyxiant gases. Asphyxiant gases reduce/displace the normal oxygen concentration in breathing air, where prolonged exposure to this hypoxic breathing gas leads to unconsciousness, followed by death by inert gas asphyxiation (suffocation). When oxygen level dips below 19.5% v/v, the air is considered oxygen-deficient, where oxygen concentrations below 16% volume are considered highly dangerous for humans. As asphyxiant gases are relatively inert and odorless, their presence may not be noticed until the effects of elevated blood carbon dioxide (hypercapnia) are recognized by the body. Inert gas asphyxiation may be deliberate with use of a suicide bag. Accidental death has occurred in cases where concentrations of nitrogen in controlled atmospheres, or methane in mines, has not been detected or appreciated.

Hemoglobin's function can also be lost by chemically oxidizing its iron atom to its ferric form. This form of inactive hemoglobin is called methemoglobin and can be made by ingesting sodium nitrite as well as certain drugs and other chemicals.

Hemoglobin plays a substantial role in carrying oxygen throughout the body, and when it is deficient, anemia can result, causing 'anaemic hypoxia' if tissue perfusion is decreased. Iron deficiency is the most common cause of anemia. As iron is used in the synthesis of hemoglobin, less hemoglobin will be synthesised when there is less iron, due to insufficient intake, or poor absorption.

Anemia is typically a chronic process that is compensated over time by increased levels of red blood cells via upregulated erythropoetin. A chronic hypoxic state can result from a poorly compensated anaemia.

Histotoxic hypoxia results when the quantity of oxygen reaching the cells is normal, but the cells are unable to use the oxygen effectively as a result of disabled oxidative phosphorylation enzymes. This may occur in cyanide poisoning.

If oxygen delivery to cells is insufficient for the demand (hypoxia), electrons will be shifted to pyruvic acid in the process of lactic acid fermentation. This temporary measure (anaerobic metabolism) allows small amounts of energy to be released. Lactic acid build up (in tissues and blood) is a sign of inadequate mitochondrial oxygenation, which may be due to hypoxemia, poor blood flow (e.g., shock) or a combination of both. If severe or prolonged it could lead to cell death. 

In humans, hypoxia is detected by the peripheral chemoreceptors in the carotid body and aortic body, with the carotid body chemoreceptors being the major mediators of reflex responses to hypoxia. This response does not control ventilation rate at normal p, but below normal the activity of neurons innervating these receptors increases dramatically, so much so to override the signals from central chemoreceptors in the hypothalamus, increasing p despite a falling p

It is seen in a few humans (encountered with hypoxia), there is word loss in their speech due to their state of confusion and cell damage in the brain.

In most tissues of the body, the response to hypoxia is vasodilation. By widening the blood vessels, the tissue allows greater perfusion.

By contrast, in the lungs, the response to hypoxia is vasoconstriction. This is known as hypoxic pulmonary vasoconstriction, or "HPV".

When the pulmonary capillary pressure remains elevated chronically (for at least 2 weeks), the lungs become even more resistant to pulmonary edema because the lymph vessels expand greatly, increasing their capability of carrying fluid away from the interstitial spaces perhaps as much as 10-fold. Therefore, in patients with chronic mitral stenosis, pulmonary capillary pressures of 40 to 45 mm Hg have been measured without the development of lethal pulmonary edema.[Guytun and Hall physiology]

Hypoxia exists when there is a reduced amount of oxygen in the tissues of the body. Hypoxemia refers to a reduction in PO2 below the normal range, regardless of whether gas exchange is impaired in the lung, CaO2 is adequate, or tissue hypoxia exists. There are several potential physiologic mechanisms for hypoxemia, but in patients with COPD the predominant one is V/Q mismatching, with or without alveolar hypoventilation, as indicated by PaCO2. Hypoxemia caused by V/Q mismatching as seen in COPD is relatively easy to correct, so that only comparatively small amounts of supplemental oxygen (less than 3 L/min for the majority of patients) are required for LTOT. Although hypoxemia normally stimulates ventilation and produces dyspnea, these phenomena and the other symptoms and signs of hypoxia are sufficiently variable in patients with COPD as to be of limited value in patient assessment. Chronic alveolar hypoxia is the main factor leading to development of cor pulmonale—right ventricular hypertrophy with or without overt right ventricular failure—in patients with COPD. Pulmonary hypertension adversely affects survival in COPD, to an extent that parallels the degree to which resting mean pulmonary artery pressure is elevated. Although the severity of airflow obstruction as measured by FEV1 is the best correlate with overall prognosis in patients with COPD, chronic hypoxemia increases mortality and morbidity for any severity of disease. Large-scale studies of LTOT in patients with COPD have demonstrated a dose-response relationship between daily hours of oxygen use and survival. There is reason to believe that continuous, 24-hours-per-day oxygen use in appropriately selected patients would produce a survival benefit even greater than that shown in the NOTT and MRC studies.

To counter the effects of high-altitude diseases, the body must return arterial p toward normal. Acclimatization, the means by which the body adapts to higher altitudes, only partially restores p to standard levels. Hyperventilation, the body’s most common response to high-altitude conditions, increases alveolar p by raising the depth and rate of breathing. However, while p does improve with hyperventilation, it does not return to normal. Studies of miners and astronomers working at 3000 meters and above show improved alveolar p with full acclimatization, yet the p level remains equal to or even below the threshold for continuous oxygen therapy for patients with chronic obstructive pulmonary disease (COPD). In addition, there are complications involved with acclimatization. Polycythemia, in which the body increases the number of red blood cells in circulation, thickens the blood, raising the danger that the heart can’t pump it.

In high-altitude conditions, only oxygen enrichment can counteract the effects of hypoxia. By increasing the concentration of oxygen in the air, the effects of lower barometric pressure are countered and the level of arterial p is restored toward normal capacity. A small amount of supplemental oxygen reduces the equivalent altitude in climate-controlled rooms. At 4000 m, raising the oxygen concentration level by 5 percent via an oxygen concentrator and an existing ventilation system provides an altitude equivalent of 3000 m, which is much more tolerable for the increasing number of low-landers who work in high altitude. In a study of astronomers working in Chile at 5050 m, oxygen concentrators increased the level of oxygen concentration by almost 30 percent (that is, from 21 percent to 27 percent). This resulted in increased worker productivity, less fatigue, and improved sleep.

Oxygen concentrators are uniquely suited for this purpose. They require little maintenance and electricity, provide a constant source of oxygen, and eliminate the expensive, and often dangerous, task of transporting oxygen cylinders to remote areas. Offices and housing already have climate-controlled rooms, in which temperature and humidity are kept at a constant level. Oxygen can be added to this system easily and relatively cheaply.

A prescription renewal for home oxygen following hospitalization requires an assessment of the patient for ongoing hypoxemia.



</doc>
<doc id="13293" url="https://en.wikipedia.org/wiki?curid=13293" title="Historical revisionism">
Historical revisionism

In historiography, the term historical revisionism identifies the re-interpretation of the historical record. It usually means challenging the orthodox views held by professional scholars about a historical event, introducing contrary evidence, or reinterpreting the motivations and decisions of the people involved. The revision of the historical record can reflect new discoveries of fact, evidence, and interpretation, which then provokes a revised history. In dramatic cases, revisionism involves a reversal of older moral judgments.

At a basic level, historical revisionism is a common and not especially controversial process of developing and refining the writing of history. Much more controversial is the reversal of moral findings, in which what had been considered to be positive forces are depicted as being negative. This revisionism is then challenged by the supporters of the previous view, often in heated terms. It becomes historical negationism, a form of historical revisionism that presents a re-interpretation of the moral meaning of the historical record. 

The term "revisionism" is used pejoratively by those who claim that revisionists are distorting the historical record. This is especially the case when it is applied to Holocaust denial.

Historical revisionism is the means by which the historical record — the history of a society, as understood in their collective memory — continually integrates new facts and interpretations of the events commonly understood as history; about which the historian James M. McPherson, said:

In the field of historiography, the historian who works within the existing establishment of society, and who has produced a body of history books, from which he or she can claim authority, usually benefits from the "status quo". As such, the professional-historian paradigm is manifested as a denunciative stance towards any form of historical revisionism — either of fact or interpretation, or both. In contrast to the single-paradigm form of writing history, the philosopher of science, Thomas Kuhn, said, in contrast to the quantifiable hard sciences, characterized by a single paradigm, the social sciences are characterized by several paradigms that derive from a “tradition of claims, counterclaims, and debates over [the] fundamentals” of research. About resistance against the works of revised history that present a culturally comprehensive historical narrative of the U.S. — the perspectives of black people, women, and the labour movement — the historian David Williams said:

After the Second World War, the study and production of history in the U.S. was expanded by the G.I. Bill, which funding allowed “a new and more broadly-based generation of scholars” with perspectives and interpretations drawn from the feminist movement, the civil rights movement, and the American Indian Movement. That expansion and deepening of the pool of historians voided the existence of a definitive and universally accepted history, therefore, the revisionist historian presents the national public with a history that has been corrected and augmented with new facts, evidence, and interpretations of the historical record. In "The Cycles of American History" (1986), in contrasting and comparing the U.S. and the U.S.S.R. during the Russo–American Cold War (1945–91), the historian Arthur M. Schlesinger Jr. said:

Revisionist historians contest the mainstream or traditional view of historical events, they raise views at odds with traditionalists, which must be freshly judged. Revisionist history is often practiced by those who are in the minority, such as feminist historians, ethnic minority historians, those working outside of mainstream academia in smaller and less known universities, or the youngest scholars, essentially historians who have the most to gain and the least to lose in challenging the status quo. In the friction between the mainstream of accepted beliefs and the new perspectives of historical revisionism, received historical ideas are either changed, solidified, or clarified. If over a period of time the revisionist ideas become the new establishment "status quo" a paradigm shift is said to have occurred. Historian Forrest McDonald is often critical of the turn that revisionism has taken, but he nevertheless admits that the turmoil of the 1960s in the United States changed the way history was written:

Historians are influenced by the "zeitgeist" (spirit of the time), and the usually progressive changes to society, politics, and culture, which occurred after the Second World War (1939–45); in "The Future of the Past" (1989), the historian C. Vann Woodward said:

Developments in the academy, culture, and politics shaped the contemporary model of writing history — the accepted paradigm of historiography; the philosopher Karl Popper said: "each generation has its own troubles and problems, and, therefore, its own interests and its own point of view", and that:

As the social, political, and cultural influences change a society, most historians revise and update their explanation of historical events. The old consensus, based upon limited evidence, might no longer be considered historically valid in explaining the particulars — of cause and effect, of motivation and self-interest — that tell "How?" and "Why?" the past occurred as it occurred; therefore, the historical revisionism of the factual record is revised to concord with the contemporary understanding of history. As such, in 1986, the historian John Hope Franklin described four stages in the historiography of the African experience of life in the U.S., which were based upon different models of historical consensus.

The historian Deborah Lipstadt ("Denying the Holocaust: The Growing Assault on Truth and Memory", 1993), and the historians Michael Shermer and Alex Grobman ("Denying History: Who Says the Holocaust Never Happened and Why Do They Say It?", 2002), distinguish between historical revisionism and historical negationism, the latter of which is a form of denialism. Lipstadt said that Holocaust deniers, such as Harry Elmer Barnes, disingenuously self-identify as "historical revisionists" in order to obscure their denialism as academic revision of the historical record.

As such, Lipstadt, Shermer, and Grobman said that legitimate historical revisionism entails the refinement of existing knowledge about a historical event, not a denial of the event, itself; that such refinement of history emerges from the examination of new, empirical evidence, and a re-examination, and consequent re-interpretation of the existing documentary evidence. That legitimate historical revisionism acknowledges the existence of a "certain body of irrefutable evidence" and the existence of a "convergence of evidence", which suggest that an event — such as the Black Death, American slavery, and the Holocaust — did occur; whereas the denialism of history rejects the entire foundation of historical evidence, which is a form of historical negationism.

Some of the influences on historians, which may change over time are:


As non-Latin texts, such as Welsh, Gaelic and the Norse sagas have been analysed and added to the canon of knowledge about the period and a much more archaeological evidence has come to light, the period known as the Dark Ages has narrowed to the point where many historians no longer believe that such a term is useful. Moreover, the term "dark" implies less of a void of culture and law, but more a lack of many source texts in mainland Europe. Many modern scholars who study the era tend to avoid the term altogether for its negative connotations, finding it misleading and inaccurate for any part of the Middle Ages.

The concept of feudalism has been questioned. Revisionist scholars led by historian Elizabeth A. R. Brown have rejected the term.

For centuries, historians thought the Battle of Agincourt was an engagement in which the English army, though overwhelmingly outnumbered four to one by the French army, pulled off a stunning victory—a version especially popularised by Shakespeare's play "Henry V". However, recent research by Professor Anne Curry using the original enrollment records, has brought into question this interpretation. Though her research is not finished, she has published her initial findings, that the French only outnumbered the English and Welsh 12,000 to 8,000. If true, the numbers may have been exaggerated for patriotic reasons by the English.

In recounting the European colonization of the Americas, some history books of the past paid little attention to the indigenous peoples of the Americas, usually mentioning them only in passing and making no attempt to understand the events from their point of view. This was reflected in the description of Christopher Columbus having discovered America. The portrayal of these events has since been revised, avoiding the word "discovery."

In his 1990 revisionist book, "The Conquest of Paradise: Christopher Columbus and the Columbian Legacy", Kirkpatrick Sale argued that Christopher Columbus was an imperialist bent on conquest from his first voyage. In a "New York Times" book review, historian and member of the Christopher Columbus Quincentenary Jubilee Committee William Hardy McNeill wrote about Sale: 

McNeill declares Sale's work to be "unhistorical, in the sense that [it] selects from the often cloudy record of Columbus's actual motives and deeds what suits the researcher's 20th-century purposes." McNeill states that detractors and advocates of Columbus present a "sort of history [that] caricatures the complexity of human reality by turning Columbus into either a bloody ogre or a plaster saint, as the case may be."

The military historian James R. Arnold argues that:

In reaction to the orthodox interpretation enshrined in the Versailles Treaty (which declared that Germany was guilty of starting World War I), the self-described "revisionist" historians of the 1920s rejected the orthodox view and presented a complex causation in which several other countries were equally guilty. Intense debate continues among scholars.

The military leadership of the British Army during the World War I was frequently condemned as poor by historians and politicians for decades after the war ended. Common charges were that the generals commanding the army were blind to the realities of trench warfare, ignorant of the conditions of their men and were unable to learn from their mistakes, thus causing enormous numbers of casualties ('lions led by donkeys'). However, during the 1960s historians such as John Terraine began to challenge this interpretation. In recent years as new documents have come forth and the passage of time has allowed for more objective analysis, historians such as Gary D. Sheffield and Richard Holmes observe that the military leadership of the British Army on the Western Front had to cope with many problems that they could not control such as a lack of adequate military communications, which was not known before. Furthermore, military leadership improved throughout the war culminating in the Hundred Days Offensive advance to victory in 1918. Some historians, even revisionists, still criticise the British High Command severely, but they are less inclined to portray the war in a simplistic manner with brave troops being led by foolish officers.

There has been a similar movement regarding the French Army during the war with contributions by historians such as Anthony Clayton. Revisionists are far more likely to view commanders such as French General Ferdinand Foch, British General Douglas Haig and other figures, such as American General Pershing, in a sympathetic light.

Revisionist historians of Reconstruction after the U.S. Civil War rejected the dominant Dunning School that stated the blacks were used by Carpetbaggers, and instead has stressed economic greed on the part of northern businessmen. Indeed, in recent years a "neoabolitionist" revisionism has become standard, that uses the moral standards of racial equality of the 19th century abolitionists to criticize racial policies. "Foner's book represents the mature and settled Revisionist perspective," historian Michael Perman has concluded regarding Eric Foner's "Reconstruction: America's Unfinished Revolution, 1863–1877" (1988)

The orthodox interpretation blamed Hitler and Nazi Germany and Imperial Japan for causing the war. Revisionist historians of World War II, notably Charles A. Beard, said the U.S. was partly to blame because it pressed the Japanese too hard in 1940–41 and rejected compromises. Other notable contributions to this discussion include Charles Tansill, "Back Door To War" (Chicago, 1952); Frederic Sanborn, "Design For War" (New York, 1951); and David Hoggan, "The Forced War" (Costa Mesa, 1989). British historian A. J. P. Taylor ignited a firestorm when he argued Hitler was a rather ordinary diplomat and did not deliberately set out to cause a war.

Patrick Buchanan, an American conservative pundit, argued the Anglo–French guarantee to Poland in 1939 encouraged Poland not to seek a compromise over Danzig, though Britain and France were in no position to come to Poland's aid, and Hitler was offering the Poles an alliance in return. He argues that they thereby turned a minor border dispute into a catastrophic world conflict, and handed East Europe, including Poland, to Stalin. Buchanan further argued the British pact with Poland ensured the country would be invaded, as Stalin knew the British Empire would not be able to declare war on Germany and the Soviet Union in 1939.

The role of American business and the alleged "robber barons" began to be revised in the 1930s. Termed "business revisionism" by Gabriel Kolko, historians such as Allan Nevins, and, later, Alfred D. Chandler emphasized the positive contributions of individuals who were previously pictured as villains. Peter Novick writes, "The argument that whatever the moral delinquencies of the robber barons, these were far outweighed by their decisive contributions to American military [and industrial] prowess, was frequently invoked by Allan Nevins."

In the historiography of the Cold War a debate exists between historians advocating an "orthodox" and "revisionist" interpretation of Soviet history and other aspects of the cold war such as the Vietnam War.

"America in Vietnam" (1978), by Guenter Lewy, is an example of historical revisionism that differs much from the popular view of the role of the U.S. in the Vietnam War (1955–75), for which the author was criticised and supported for belonging to the revisionist school on the history of the Vietnam War. Lewy's reinterpretation was the first book of a body of work by historians of the revisionist school about the geopolitical role and the military behavior of the United States in the country of Vietnam.

In the Introduction to "America in Vietnam", Lewy said:

Other reinterpretations of the historical record of the U.S. war in Vietnam, which offer alternative explanations for American behavior, include "Why We Are in Vietnam" (1982), by Norman Podhoretz, "Triumph Forsaken: The Vietnam War, 1954–1965" (2006), by Mark Moyar, and "Vietnam: The Necessary War" (1999), by Michael Lind.


</doc>
<doc id="13294" url="https://en.wikipedia.org/wiki?curid=13294" title="History of the petroleum industry in the United States">
History of the petroleum industry in the United States

The first successful oil well in North America was established in Oil Springs, Ontario, Canada in 1858. The field is still in production although quantities are low.

The history of the petroleum industry in the United States goes back to the early 19th century, although the indigenous peoples, like many ancient societies, have used petroleum seeps since prehistoric times; where found, these seeps signaled the growth of the industry from the earliest discoveries to the more recent.

Petroleum became a major industry following the oil discovery at Oil Creek Pennsylvania in 1859. For much of the 19th and 20th centuries, the US was the largest oil producing country in the world. As of October 2015, the US was the world's third-largest producer of crude oil.

Native Americans had known of the oil in western Pennsylvania, and had made some use of it for many years before the mid-19th century. Early European explorers noted seeps of oil and natural gas in western Pennsylvania and New York. Interest grew substantially in the mid-1850s as scientists reported on the potential to manufacture kerosene from crude oil, if a sufficiently large oil supply could be found.

The Jesuit Relations of 1657 states:
Salt was a valuable commodity, and an industry developed near salt springs in the Ohio River Valley, producing salt by evaporating brine from the springs. Salt wells were sunk at the salt springs to increase the supply of brine for evaporation. Some of the wells were hand-dug, but salt producers also learned to drill wells by percussion (cable tool) methods. In a number of locations in western Virginia, Ohio, and Kentucky, oil and natural gas came up the wells along with the brine. The oil was mostly a nuisance, but some salt producers saved it and sold it as illuminating oil or medicine. In some locations, enough natural gas was produced to be used as fuel for the salt evaporating pans. Early salt brine wells that produced byproduct oil included the Thorla-McKee Well of Ohio in 1814, a well near Burkesville, Kentucky, in 1828, and wells at Burning Springs, West Virginia, by 1836.

The US natural gas industry started in 1821 at Fredonia, Chautauqua County, New York, when William Hart dug a well to a depth of into gas-bearing shale, then drilled a borehole further, and piped the natural gas to a nearby inn where it was burned for illumination. Soon many gas wells were drilled in the area, and the gas-lit streets of Fredonia became a tourist attraction.

On August 28, 1859, George Bissell and Edwin L. Drake made the first successful use of a drilling rig on a well drilled especially to produce oil, at a site on Oil Creek near Titusville, Pennsylvania. The Drake partners were encouraged by Benjamin Silliman (1779-1864), a chemistry professor at Yale, who tested a sample of the oil, and assured them that it could be distilled into useful products such as illuminating oil.

The Drake well is often referred to as the "first" commercial oil well, although that title is also claimed for wells in Azerbaijan, Ontario, West Virginia, and Poland, among others. However, before the Drake well, oil-producing wells in the United States were wells that were drilled for salt brine, and produced oil and gas only as accidental byproducts. An intended drinking water well at Oil Springs, Ontario found oil in 1858, a year before the Drake well, but it had not been drilled for oil. Historians have noted that the importance of the Drake well was not in being the first well to produce oil, but in attracting the first great wave of investment in oil drilling, refining, and marketing:

The success of the Drake well quickly led to oil drilling in other locations in the western Appalachian mountains, where oil was seeping to the surface, or where salt drillers had previously found oil fouling their salt wells. During the American Civil War, the oil-producing region spread over much of western Pennsylvania, up into western New York state, and down the Ohio River valley into the states of Ohio, Kentucky, and the western part of Virginia (now West Virginia). The Appalachian Basin continued to be the leading oil-producing region in the United States through 1904.

The first commercial oil well in New York was drilled in 1865. New York's (and Northwestern Pennsylvania) crude oil is very high in paraffin.

The principal product of the oil in the 19th century was kerosene, which quickly replaced whale oil for illuminating purposes in the United States. Originally dealing in whale oil which was widely used for illumination, Charles Pratt (1830–1891) of Massachusetts was an early pioneer of the natural oil industry in the United States. He was founder of Astral Oil Works in the Greenpoint section of Brooklyn, New York. Pratt's product later gave rise to the slogan, ""The holy lamps of Tibet are primed with Astral Oil"." He joined with his protégé Henry H. Rogers to form Charles Pratt and Company in 1867. Both companies became part of John D. Rockefeller's Standard Oil in 1874.

The Mid-continent area is an area generally including Kansas, Oklahoma, Arkansas, North Louisiana and the part of Texas away from the Gulf Coast. The first commercially successful oil well drilled in Kansas was the Norman No. 1 near Neodesha, Kansas, on November 28, 1892.


Oil was discovered at Bartlesville and Burbank in 1897. But the initial discoveries created no great excitement until the discovery gusher of the Glenn Pool in 1905. The Glenn discovery came when Gulf Coast production was declining rapidly, and the operators were eager for new areas to drill. The increased drilling resulted in major discoveries at Cushing in 1912 and Healdton in 1913.


The largest oil field in the lower 48 states, the East Texas oil field, was not discovered until 1930, when wildcatter Columbus Marion Joiner (more commonly known as "Dad" Joiner) drilled the Daisy Bradford No. 3 well, in Rusk County, Texas.

In 1906, the Caddo-Pine Island Field in northern Caddo Parish, Louisiana was discovered, and a rush of leasing and drilling activity ensued. In 1908, the first natural gas pipeline was constructed to transport gas from Caddo-Pine Island to Shreveport, Louisiana. This was one of the earliest commercial uses of natural gas, which was commonly viewed as an undesirable by-product of oil production and often "flared" or burnt off at the well site.

Other innovations in the Caddo-Pine Island Field included the first over-water oil platform, which was constructed in the field on Caddo Lake in 1910. In that same year, a major oil pipeline was constructed from Caddo-Pine Island Field to a refinery built and operated by Standard Oil Company of Louisiana in Baton Rouge, Louisiana. The refinery continues to operate today.

Other early petroleum discoveries in North Louisiana included the Bull Bayou Field, Red River Parish, Louisiana (1913), Monroe Gas Field, Ouachita Parish, Louisiana (1916), Homer Field, Claiborne Parish, Louisiana (1919) and Haynesville Field, Claiborne Parish, Louisiana (1921).

Native Americans had known of the tar seeps in southern California for thousands of years, and used the tar to waterproof their canoes. Spanish settlers also knew of the seeps, such as at Rancho La Brea (Spanish for "Tar Ranch") in present-day Los Angeles, from which the priests obtained tar to waterproof the roofs of the Los Angeles and San Gabriel missions.

Despite the abundance of well-known seeps in southern California, the first commercial oil well in California was drilled in Humboldt County, northern California in 1865.

Some attempts were made in the 1860s to exploit oil deposits under tar seeps in the Ventura Basin of Ventura County and northeastern Los Angeles county. The early efforts failed because of complex geology, and, more importantly, because the refining techniques then available could not manufacture high-quality kerosene from California crude oil, which differed chemically from Pennsylvania crude oil. Most California crude oil in the early years was turned into the less lucrative products of fuel oil and asphalt.

Oil production in the Los Angeles Basin started with the discovery of the Brea-Olinda Oil Field in 1880, and continued with the development of the Los Angeles City Oil Field in 1893, the Beverly Hills Oil Field in 1900, the Salt Lake Oil Field in 1902, and many others. The discovery of the Long Beach Oil Field in 1921, which proved to be the world's richest in production per-acre of the time, increased the importance of the Los Angeles Basin as a worldwide oil producer. This increased again with the discovery of the Wilmington Oil Field in 1932, and the development of the Port of Los Angeles as a means of shipping crude oil overseas.

Production in Santa Barbara County began in the 1890s with the development of the Summerland Oil Field, which included the world's first offshore oil wells. With the discovery of the Orcutt and Lompoc fields, northern Santa Barbara County became a regional center of production; towns such as Orcutt owe their existence to the quickly growing industry.

Oil in the San Joaquin Basin was first discovered at the Coalinga field in 1890. By 1901, the San Joaquin Basin was the main oil-producing region of California, and it remains so in the 21st century, with huge oil fields including the Midway-Sunset, Kern River, and Belridge fields producing much of California's onshore oil.

The first commercial oil well in the Rocky Mountains was drilled near Canon City, Colorado in 1862. The wells in the Canyon City-Florence field, drilled near surface oil seeps, produced from fractures in the Pierre Shale.


A Russian sea captain noted oil seeps along the shore of the Cook Inlet as early as 1853, and oil drilling began in 1898 in a number of locations along the southern coast of Alaska. Production was relatively small, however, until huge discoveries were made on Alaska's remote North Slope.

Petroleum seeps on the North Slope have been known for many years, and in 1923, the federal government created US Naval Petroleum Reserve No. 4 to cover the presumed oil fields beneath the seeps. Some exploration drilling was done in the reserve during World War II and the 1950s, but the remote location deterred intensive exploration until the 1960s. The Prudhoe Bay Oil Field, the largest oil field in the United States in terms of total oil produced, was discovered in 1968. Production began in 1977, following completion of the Trans-Alaska Pipeline. Through 2005, the field has produced of oil (an average of 1.5 million barrels/day), and is estimated to contain another of economically recoverable oil.

Capt. Anthony Francis Lucas, an experienced mining engineer and salt driller, drilled a well to find oil at Spindletop Hill. On the morning of January 10, 1901, the little hill south of Beaumont, Texas began to tremble and mud bubbled up over the rotary table. A low rumbling sound came from underground, and then, with a force that shot 6 tons of 4-inch (100 mm) diameter pipe out over the top of the derrick, knocking off the crown block, the Lucas Gusher roared in and the Spindletop oil field was born. Spindletop became the focus of frenzied drilling; oil production from the field peaked in 1902 at , but by 1905 production had declined 90% from the peak.

Spindletop Hill turned out to be the surface expression of an underground salt dome, around which the oil accumulated. The Spindletop gusher started serious oil exploration of the Gulf Coast in Texas and Louisiana, an area that had previously been dismissed by oil men. Other salt dome mounds were quickly drilled, resulting in discoveries at Sour Lake (1902), Batson (1904) and Humble (1905).

The Standard Oil Company was slow to appreciate the economic potential of the Spindletop oil field, and the Gulf Coast generally, which gave greater opportunity to others; Spindletop became the birthplace of oil giants Texaco and Gulf Oil. Although in 1899 Standard Oil controlled more than 85% of the oil production in the older oil regions in the Appalachian Basin and the Lima-Indiana trend, it never controlled more than 10% of the oil production in the new Gulf Coast province.

By the Natural Gas Act of 1938, the federal government imposed price controls on natural gas in interstate commerce. The Federal Power Commission was mandated to set interstate gas prices at "just and reasonable" rates. The FPC at first only regulated the price at which pipelines sold gas to utilities and industry, but later put limits on the wellhead price of gas sold to an interstate pipeline. Gas producers challenged the controls, but lost in the Supreme Court in Phillips Petroleum Co. v. Wisconsin (1954).

The federal government had controlled the price of natural gas that crossed state lines, but not of gas produced and sold within a state. In the 1970s, the low interstate price set by the federal government caused supply shortages of gas in consuming states, because gas producers sold as much as they could of their product for higher prices in the local markets within gas-producing states. In the Natural Gas Policy Act of 1978, the federal government extended price controls to all natural gas in the country. At the same time, the government created a complex price system in which the price paid to the producer depended on the date the well was drilled, the depth of the well, the geological formation, the distance to other gas wells, and several other factors. The price system was an attempt to keep the average price low while encouraging new production.

The last federal price controls on natural gas were removed by the Natural Gas Decontrol Act of 1989, which phased out the last remaining price control as of 1 January 1993.

As of December, 2012, North Dakota was producing oil at the rate of 750,000 barrels/day.




</doc>
<doc id="13297" url="https://en.wikipedia.org/wiki?curid=13297" title="Hudson's Bay Company">
Hudson's Bay Company

The Hudson's Bay Company (HBC; ) is a Canadian retail business group. A fur trading business for much of its existence, HBC now owns and operates retail stores in Canada, the United States and parts of Europe, including Belgium, the Netherlands and Germany. The company's namesake business division is Hudson's Bay, commonly referred to as The Bay ("La Baie" in French). Other divisions include Galeria Kaufhof, Gilt, Home Outfitters, Lord & Taylor and Saks Fifth Avenue. HBC's head office was in the Simpson Tower in Toronto, but it relocated northwest of Toronto to Brampton, Ontario. The company is listed on the Toronto Stock Exchange under the symbol "HBC".

The company was incorporated by English royal charter in 1670 as The Governor and Company of Adventurers of England trading into Hudson's Bay. It functioned as the "de facto" government in parts of North America before European states and later the United States laid claim to some of those territories. It was once the world's largest landowner, controlling the area of the Hudson Bay watershed, known as Rupert's Land, which has 15% of North American acreage. From its long-time headquarters at York Factory on Hudson Bay, the company controlled the fur trade throughout much of the English and later British-controlled North America for several centuries. Undertaking early exploration, its traders and trappers forged relationships with many groups of aboriginal peoples. Its network of trading posts formed the nucleus for later official authority in many areas of Western Canada and the United States. In the late 19th century, with its signing of the Deed of Surrender, its vast territory became the largest portion of the newly formed Dominion of Canada, in which the company was the largest private landowner.

By the mid-19th century, the company evolved into a mercantile business selling everything from furs to fine homeware. They "quickly introduced a new type of client to the HBC – one that shopped for pleasure and not with skins"; the retail era had begun as the HBC began establishing stores across the country. 
In July 2008, HBC was acquired by NRDC Equity Partners, which also owns the upmarket American department store Lord & Taylor. From 2008 to 2012, the HBC was run through a holding company of NRDC, Hudson's Bay Trading Company, which was dissolved on 23 January 2012. Since 2012, the HBC directly oversees its Canadian subsidiaries Hudson's Bay (formerly The Bay) and Home Outfitters, in addition to the operations of Lord & Taylor in the United States.

On 29 July 2013, the HBC announced its takeover of Saks, Inc., operator of the US Saks Fifth Avenue brand. The merger was completed on 3 November 2013. In September 2015, HBC acquired the German department store chain Galeria Kaufhof and its Belgian subsidiary from Metro Group for US$3.2 billion. In late July 2017, German trade credit insurance Euler Hermes announced that it has drastically reduced its coverage for Kaufhof; which in general means that the rating and credit worthiness of a company is severely questioned.

In May 2016, HBC announced it would expand to the Netherlands by taking over up to 20 former Vroom & Dreesmann sites by 2017. V&D was a historic Dutch department store chain that went bankrupt and shut down in early 2016. HBC said the expansion would cost CA$340 million and create 2,500 jobs in the stores and another 2,500 temporary construction jobs. The Dutch stores would operate under the "Hudson's Bay" and "Saks Off Fifth" brands.

In January 2016, HBC announced it would also expand deeper into digital space with its acquisition of online flash sales site, the Gilt Groupe, for US$250 million.

In June 2018, HBC announced it sold Gilt Groupe to online fashion store Rue La La for an undisclosed sum.

In the 17th century the French had a de facto monopoly on the Canadian fur trade with their colony of New France. Two French traders, Pierre-Esprit Radisson and Médard des Groseilliers (Médard de Chouart, Sieur des Groseilliers), Radisson's brother-in-law, learned from the Cree that the best fur country lay north and west of Lake Superior, and that there was a "frozen sea" still further north. Assuming this was Hudson Bay, they sought French backing for a plan to set up a trading post on the Bay, to reduce the cost of moving furs overland. According to Peter C. Newman, "concerned that exploration of the Hudson Bay route might shift the focus of the fur trade away from the St. Lawrence River, the French governor", Marquis d'Argenson (in office 1658–61), "refused to grant the coureurs de bois permission to scout the distant territory". Despite this refusal, in 1659 Radisson and Groseilliers set out for the upper Great Lakes basin. A year later they returned with premium furs, evidence of the potential of the Hudson Bay region. Subsequently, they were arrested for trading without a licence and fined, and their furs were confiscated by the government.

Determined to establish trade in the Hudson Bay, Radisson and Groseilliers approached a group of English colonial businessmen in Boston, Massachusetts to help finance their explorations. The Bostonians agreed on the plan's merits but their speculative voyage in 1663 failed when their ship ran into pack ice in Hudson Strait. Boston-based English commissioner Colonel George Cartwright learned of the expedition and brought the two to England to raise financing. Radisson and Groseilliers arrived in London in 1665 at the height of the Great Plague. Eventually, the two met and gained the sponsorship of Prince Rupert. Prince Rupert also introduced the two to his cousin, King Charles II. In 1668 the English expedition acquired two ships, the "Nonsuch" and the "Eaglet", to explore possible trade into Hudson Bay. Groseilliers sailed on the "Nonsuch", commanded by Captain Zachariah Gillam, while the "Eaglet" was commanded by Captain William Stannard and accompanied by Radisson. On 5 June 1668, both ships left port at Deptford, England, but the "Eaglet" was forced to turn back off the coast of Ireland.

The "Nonsuch" continued to James Bay, the southern portion of Hudson Bay, where its explorers founded, in 1668, the first fort on Hudson Bay, Charles Fort at the mouth of the Rupert River. (It was later known as Rupert House, and developed as the community of present-day Waskaganish, Quebec.) Both the fort and the river were named after the sponsor of the expedition, Prince Rupert of the Rhine, one of the major investors and soon to be the new company's first governor. After a successful trading expedition over the winter of 1668–69, "Nonsuch" returned to England on 9 October 1669 with the first cargo of fur resulting from trade in Hudson Bay. The bulk of the fur – worth £1,233 – was sold to Thomas Glover, one of London's most prominent furriers. This and subsequent purchases by Glover made it clear the fur trade in Hudson Bay was viable.

The Governor and Company of Adventurers of England Trading into Hudson's Bay was incorporated on 2 May 1670, with a royal charter from King Charles II. The charter granted the company a monopoly over the region drained by all rivers and streams flowing into Hudson Bay in northern Canada. The area was named "Rupert's Land" after Prince Rupert, the first governor of the company appointed by the King. This drainage basin of Hudson Bay constitutes , comprising over one-third of the area of modern-day Canada and stretches into the present-day north-central United States. The specific boundaries were unknown at the time. Rupert's Land would eventually become Canada's largest land "purchase" in the 19th century.

The HBC established six posts between 1668 and 1717. Rupert House(1668, southeast), Moose Factory (1673, south) and Fort Albany, Ontario (1679, west) were erected on James Bay; three other posts were established on the western shore of Hudson Bay proper: Fort Severn (1689), York Factory (1684) and Fort Churchill (1717). Inland posts were not built until 1774. After 1774, York Factory became the main post because of its convenient access to the vast interior waterway systems of the Saskatchewan and Red rivers. Called "factories" (because the "factor," i.e., a person acting as a mercantile agent did business from there), these posts operated in the manner of the Dutch fur trading operations in New Netherlands. By adoption of the Standard of Trade in the 18th century, the HBC ensured consistent pricing throughout Rupert's Land. A means of exchange arose based on the "Made Beaver" (MB); a prime pelt, worn for a year and ready for processing: "the prices of all trade goods were set in values of Made Beaver (MB) with other animal pelts, such as squirrel, otter and moose quoted in their MB (made beaver) equivalents. For example, two otter pelts might equal 1 MB".

During the fall and winter, First Nations men and European trappers accomplished the vast majority of the animal trapping and pelt preparation. They travelled by canoe and on foot to the forts to sell their pelts. In exchange they typically received popular trade goods such as knives, kettles, beads, needles, and the Hudson's Bay point blanket. The arrival of the First Nations trappers was one of the high points of the year, met with pomp and circumstance. The highlight was very formal, an almost ritualized "Trading Ceremony" between the Chief Trader and the Captain of the aboriginal contingent who traded on their behalf. During the initial years of the fur trade, prices for items varied from post to post.

The early coastal factory model of the English contrasted with the system of the French. They established an extensive system of inland posts at native villages, and sent traders to live among the tribes of the region, learning their languages and often forming alliances through marriages with indigenous women. In March 1686, the French sent a raiding party under the Chevalier des Troyes more than to capture the HBC posts along James Bay. The French appointed Pierre Le Moyne d'Iberville, who had shown great heroism during the raids, as commander of the company's captured posts. In 1687 an English attempt to resettle Fort Albany failed due to strategic deceptions by d'Iberville. After 1688 England and France were officially at war, and the conflict played out in North America as well. D'Iberville raided Fort Severn in 1690 but did not attempt to raid the well-defended local headquarters at York Factory. In 1693 the HBC recovered Fort Albany; d'Iberville captured York Factory in 1694, but the company recovered it the next year.

In 1697, d'Iberville again commanded a French naval raid on York Factory. On the way to the fort, he defeated three ships of the Royal Navy in the Battle of Hudson's Bay (5 September 1697), the largest naval battle in the history of the North American Arctic. D'Iberville's depleted French force captured York Factory by laying siege to the fort and pretending to be a much larger army. The French retained all of the outposts except Fort Albany until 1713. (A small French and Indian force attacked Fort Albany again in 1709 during Queen Anne's War but was unsuccessful. The economic consequences of the French possession of these posts for the company were significant; HBC did not pay any dividends for more than 20 years. See Anglo-French conflicts on Hudson Bay.

With the ending of the Nine Years' War in 1697, and the War of the Spanish Succession in 1713 with the signing of the Treaty of Utrecht, France had gotten the short end of the stick. Among the treaty's many provisions, it required France to relinquish all claims to Great Britain on the Hudson Bay, which again became a British possession. (The Kingdom of Great Britain had been established following the union of Scotland and England in 1707). After the treaty, the HBC built Prince of Wales Fort, a stone star fort at the mouth of the nearby Churchill River. In 1782, during the American Revolutionary War, a French squadron under Jean-François de Galaup, comte de Lapérouse captured and demolished York Factory and Prince of Wales Fort in support of the American rebels.

In its trade with native peoples, Hudson's Bay Company exchanged wool blankets, called Hudson's Bay point blankets, for the beaver pelts trapped by aboriginal hunters. By 1700, point blankets accounted for more than 60% of the trade. The number of indigo stripes (a.k.a. points) woven into the blankets identified its finished size. A long-held misconception is that the number of stripes was related to its value in beaver pelts.

A parallel may be drawn between the HBC's control over Rupert's Land with the trade monopoly and government functions enjoyed by the Honourable East India Company over India during roughly the same period. The HBC invested £10,000 in the East India Company in 1732, which it viewed as a major competitor.

Hudson's Bay Company's first inland trading post was established by Samuel Hearne in 1774 with Cumberland House, Saskatchewan.

In 1779, other traders founded the North West Company (NWC) in Montreal as a seasonal partnership to provide more capital and to continue competing with the HBC. It became operative for the outfit of 1780 and was the first joint-stock company in Canada and possibly North America. The agreement lasted one year. A second agreement established in 1780 had a three-year term. The company became a permanent entity in 1783. By 1784, the NWC had begun to make serious inroads into the HBC's profits.

In 1821, the North West Company of Montreal and Hudson's Bay Company were forcibly merged by intervention of the British government to put an end to often-violent competition. 175 posts, 68 of them the HBC's, were reduced to 52 for efficiency and because many were redundant as a result of the rivalry and were inherently unprofitable. Their combined territory was extended by a licence to the North-Western Territory, which reached to the Arctic Ocean in the north and, with the creation of the Columbia Department in the Pacific Northwest, to the Pacific Ocean in the west. The NWC's regional headquarters at Fort George (Fort Astoria) was relocated to Fort Vancouver on the north bank of the Columbia River; it became the HBC base of operations on the Pacific Slope.

Before the merger, the employees of the HBC, unlike those of the North West Company, did not participate in its profits. After the merger, with all operations under the management of Sir George Simpson (1826–60), the company had a corps of commissioned officers: 25 chief factors and 28 chief traders, who shared in the company's profits during the monopoly years. Its trade covered , and it had 1,500 contract employees.

The career progression for officers, together referred to as the Commissioned Gentlemen, was to enter the company as a fur trader. Typically, they were men who had the capital to invest in starting up their trading. They sought to be promoted to the rank of Chief Trader. A Chief Trader would be in charge of an individual post and was entitled to one share of the company's profits. Chief Factors sat in council with the Governors and were the heads of districts. They were entitled to two shares of the company's profits or losses. The average income of a Chief Trader was £360 and that of a Chief Factor was £720.

Although the HBC maintained a monopoly on the fur trade during the early to mid-19th century, there was competition from James Sinclair and Andrew McDermot (Dermott), independent traders in the Red River Colony. They shipped furs by the Red River Trails to Norman Kittson a buyer in the United States. In addition, Americans controlled the Maritime fur trade on the Northwest Coast until the 1830s.

Throughout the 1820s and 1830s, the HBC controlled nearly all trading operations in the Pacific Northwest, based at the company headquarters at Fort Vancouver on the Columbia River. Although claims to the region were by agreement in abeyance, commercial operating rights were nominally shared by the United States and Britain through the Anglo-American Convention of 1818, but company policy, enforced via Chief Factor John McLoughlin of the company's Columbia District, was to discourage U.S. settlement of the territory. The company's effective monopoly on trade virtually forbade any settlement in the region. It established Fort Boise in 1834 (in present-day southwestern Idaho) to compete with the American Fort Hall, to the east. In 1837, it purchased Fort Hall, also along the route of the Oregon Trail. The outpost director displayed the abandoned wagons of discouraged settlers to those seeking to move west along the trail.

The company's stranglehold on the region was broken by the first successful large wagon train to reach Oregon in 1843, led by Marcus Whitman. In the years that followed, thousands of emigrants poured into the Willamette Valley of Oregon. In 1846, the United States acquired full authority south of the 49th parallel; the most settled areas of the Oregon Country were south of the Columbia River in what is now Oregon. McLoughlin, who had once turned away would-be settlers as company director, then welcomed them from his general store at Oregon City. He was later proclaimed the "Father of Oregon". The company retains no presence today in what is now the United States portion of the Pacific Northwest.

During the 1820s and 1830s, HBC trappers were deeply involved in the early exploration and development of Northern California. Company trapping brigades were sent south from Fort Vancouver, along what became known as the Siskiyou Trail, into Northern California as far south as the San Francisco Bay Area, where the company operated a trading post at Yerba Buena (San Francisco). These trapping brigades in Northern California faced serious risks, and were often the first to explore relatively uncharted territory. They included the lesser known Peter Skene Ogden and Samuel Black.

Between 1820 and 1870, the HBC issued its own paper money. The notes, denominated in pounds sterling, were printed in London and issued at the York Factory, Fort Garry and the Red River Colony. For forty or so years beginning in 1870, the company employed paddle wheel steamships on the rivers of the prairies.

The Guillaume Sayer Trial in 1849 contributed to the end of the HBC monopoly. Sayer, a Métis trapper and trader, was accused of illegal trading in furs. The Court of Assiniboia brought Sayer to trial, before a jury of HBC officials and supporters. During the trial, a crowd of armed Métis men led by Louis Riel, Sr. gathered outside the courtroom. Although Sayer was found guilty of illegal trade, having evaded the HBC monopoly, Judge Adam Thom did not levy a fine or punishment. Some accounts attributed that to the intimidating armed crowd gathered outside the courthouse. With the cry, "Le commerce est libre! Le commerce est libre!" ("Trade is free! Trade is free!"), the Métis loosened the HBC's previous control of the courts, which had enforced their monopoly on the settlers of Red River.

Another factor was the findings of the Palliser Expedition of 1857 to 1860, led by Captain John Palliser. He surveyed the area of the prairies and wilderness from Lake Superior to the southern passes of the Rocky Mountains. Although he recommended against settlement of the region, the report sparked a debate. It ended the myth publicized by Hudson's Bay Company: that the Canadian West was unfit for agricultural settlement. In 1863, the International Financial Society became the majority shareholders of the HBC.

In 1869, after rejecting the American government offer of , the company approved the return of Rupert’s Land to Britain. The government gave it to Canada and loaned the new country the £300,000 required to compensate HBC for its losses. The deal, known as The Deed of Surrender, came into force the following year. The resulting territory, now known as the Northwest Territories, was brought under Canadian jurisdiction under the terms of the Rupert's Land Act 1868, enacted by the Parliament of the United Kingdom. The Deed enabled the admission of the fifth province, Manitoba, to the Confederation on 15 July 1870, the same day that the deed itself came into force.

During the 19th century the Hudson Bay's Company went through great changes in response to such factors as growth of population and new settlements in part of its territory, and ongoing pressure from Britain. It seemed unlikely that it would continue to control the future of the West.

The iconic department store today evolved from trading posts at the start of the 19th century, when they began to see demand for general merchandise grow rapidly. HBC soon expanded into the interior and set-up posts along river settlements that later developed into the modern cities of Winnipeg, Calgary and Edmonton. In 1857, the first sales shop was established in Fort Langley. This was followed by other sales shops in Fort Victoria (1859), Winnipeg (1881), Calgary (1884), Vancouver (1887), Vernon (1887), Edmonton (1890), Yorkton (1898), and Nelson (1902). The first of the grand "original six" department stores was built in Calgary in 1913. The other department stores that followed were in Edmonton, Vancouver, Victoria, Saskatoon, and Winnipeg.

The First World War interrupted a major remodelling and restoration of retail trade shops planned in 1912. Following the war, the company revitalized its fur-trade and real-estate activities, and diversified its operations by venturing into the oil business.
Today, the department store business is the only remaining part of the company's operations, in the form of department stores under the Hudson's Bay brand.

The company co-founded Hudson's Bay Oil and Gas Company (HBOG) in 1926 with Marland Oil Company (which merged with Conoco in 1929). HBOG expanded during the 1940s and 1950s, and in 1960 began shipping Canadian crude through a new link to the Glacier pipeline and on to the refinery in Billings, Montana. The company became the sixth-largest Canadian oil producer in 1967. In 1973, HBOG acquired a 35% stake in Siebens Oil and Gas, and, in 1979, it divested that interest. In 1980, it bought a controlling interest in Roxy Petroleum. In the 1980s, sales and oil prices slipped, while debt from acquisitions piled up which led to Hudson's Bay Company selling its 52.9% stake in HBOG to Dome Petroleum in 1981.

In 1960, the company acquired Morgan's allowing it to expand into Montreal, Toronto, Hamilton, and Ottawa. In 1965, HBC rebranded its department stores as The Bay. The Morgan's logo was changed to match the new visual identity. By 1972 the last of the former Morgan’s stores had been rebranded to Bay stores.

In 1970, on the company's 300th anniversary, as a result of punishing new British tax laws, the company relocated to Canada, and was rechartered as a Canadian business corporation under Canadian law, Head Office functions were transferred from London to Winnipeg. By 1974, as the company expanded into eastern Canada, head office functions were moved to Toronto.

In 1972, the company acquired the four-store Shop-Rite chain of catalogue stores. The chain was quickly expanded to 65 stores in Ontario, but closed in 1982 due to declining sales. In these stores, little merchandise was displayed; customers made their selections from catalogues, and staff would retrieve the merchandise from storerooms. The HBC also acquired Freimans department stores in Ottawa and converted them to The Bay.

In 1978, the Zellers discount store chain made a bid to acquire the HBC, but the HBC turned the tables and acquired Zellers. Also in 1978, Simpson's department stores were acquired by Hudson's Bay Company, and were converted to Bay stores in 1991. (The related chain Simpsons-Sears was not acquired by the Bay, but became Sears Canada in 1978.) In 1991, Simpsons disappeared, when the last Simpsons store was converted to the Bay banner.

In 1979, Canadian billionaire Kenneth Thomson won control of the company in a battle with George Weston Limited, and acquired a 75% stake for $400 million. Thomson sold the company's oil and gas business, financial services, distillery, and other interests for approximately $550 million, transforming the company into a leaner, more focused operation. In 1997, the Thomson family sold the last of its remaining shares.

Hudson's Bay Company reversed a formidable debt problem in 1987, by shedding non-strategic assets such as its wholesale division and getting completely out of the oil and gas business. HBC also sold its Canadian fur-auction business to Hudson's Bay Fur Sales Canada (now North American Fur Auctions). The Northern Stores Division was sold that same year to a group of investors and employees, which adopted The North West Company name three years later.

The HBC acquired Towers Department Stores in 1990, combining them with the Zellers chain, and Woodward's stores in 1993, converting them into Bay or Zellers stores. Kmart Canada was acquired in 1998 and merged with Zellers.

In 1991, the Bay agreed to stop retailing fur in response to complaints from people opposed to killing animals for this purpose. In 1997, the Bay reopened its fur salons to meet the demand of consumers.

In December 2003, Maple Leaf Heritage Investments, a Nova Scotia-based company created to acquire shares of Hudson's Bay Company, announced that it was considering making an offer to acquire all or some of the common shares of Hudson's Bay Company. Maple Leaf Heritage Investments is a subsidiary of B-Bay Inc. Its CEO and chairman is American businesswoman Anita Zucker, widow of Jerry Zucker. Zucker had previously been the head of the Polymer Group, which acquired another Canadian institution, Dominion Textile.

On 26 January 2006, the HBC's board unanimously agreed to a bid of $15.25 CAD/share from Jerry Zucker, whose original bid was $14.75 CAD/share, ending a prolonged fight between the HBC and Zucker. The South Carolina billionaire financier was a longtime HBC minority shareholder. In a 9 March 2006 press release, the HBC announced that Zucker would replace Yves Fortier as governor and George Heller as CEO, becoming the first US citizen to lead the company. After Jerry Zucker's death the board named his widow, Anita Zucker, as HBC Governor and HBC Deputy-Governor Rob Johnston as CEO.

On 16 July 2008, the company was sold to NRDC Equity Partners, a private equity firm based in Purchase, New York, which already owned Lord & Taylor, the oldest luxury department store chain in the United States. The Canadian and U.S. holdings were transferred to NRDC Equity Partners' holding company, Hudson's Bay Trading Company, as of fall 2008.

In September 2011, the HBC began downsizing the Zellers chain with the announcement that it would sell the majority of the leases for its locations to the U.S.-based retailer Target Corporation and close all of their remaining locations by early 2013. Target used the acquisition of this real estate as a means to enable its entry in the Canadian market. HBC used the proceeds to allow it to pay down debt and to invest in growing its Hudson's Bay and Lord & Taylor banners. In January 2013, it was confirmed that only three of the remaining Zellers locations would remain open.

On 24 January 2012, the "Financial Post" reported that Richard Baker (owner of NDRC and governor of Hudson's Bay Company) had dissolved Hudson's Bay Trading Company and that the HBC would now also operate the Lord & Taylor chain. At the time, the company was run by President Bonnie Brooks. Baker remained governor and CEO of the business and Donald Watros stayed on as chief operating officer.

In October 2012, the HBC announced a $1.6 billion initial public offering (IPO); Baker planned to use the IPO to allow Canadian ownership to return to the company, and to help pay off debts with other partners. Additionally, the company also announced that it would re-brand The Bay department store chain as "Hudson's Bay".

From 2004 to 2008, the HBC owned and operated a small chain of off-price stores called Designer Depot. Similar to the Winners and HomeSense retail format, Designer Depot did not meet sales expectations, and its nine stores were sold. Another HBC chain, Fields, was sold to a private firm in 2012. Established in 1950, Fields was acquired by Zellers in 1976. When Zellers was acquired by HBC in 1978, Fields became part of the HBC portfolio. Zellers is still owned by HBC but has been reduced to a chain of two liquidation stores following the sale of its lease portfolio to Target Canada in 2011. The Target Canada chain folded in 2015; these leases have since been returned to landlords or re-sold to other retailers.

The new Hudson's Bay brand was launched in March 2013, incorporating a new logo with an updated rendition of the classic Hudson's Bay Company coat of arms, designed to be modern and better reflect the company's heritage. Following the IPO, HBC had also introduced a new corporate logo of its own (reviving a wordmark from the original HBC flag), but the new logo was not intended to be a consumer-facing brand.

On 29 July 2013, Hudson's Bay Company announced that it would buy Saks Incorporated for US$2.9 billion, or $16 per share. The company also stated that as a result of the purchase, Canadian consumers would see Saks stores arriving in their country soon. After the purchase was finalized, HBC had a net loss of $124.2 million in the 2013 3Q due to the cost of the purchase and promotions.

In early 2017, the Hudson's Bay Company made an overture to Macy's for a potential takeover of the struggling department store. More recently it considered a purchase of the struggling Neiman Marcus Group Inc. It did not proceed with either deal. 

The company also has retail operations in Europe, including 20 Hudson’s Bay stores in the Netherlands and five Saks Off Fifth stores in Germany as well as the 135 stores of the Galeria Kaufhof department store chain in Germany. The latter was acquired in 2015 in a deal that included the Belgian Galeria Inno retail chain (that was operated by Kaufhof) and some other properties. On 1 November 2017, HBC received an unsolicited offer from Austrian firm SIGNA Holding for Kaufhof and other real estate. An unnamed source told CNBC that the value of the offer was approximately 3 billion euros. This information on the offer was also reiterated in a press release by activist shareholder Land & Buildings Investment Management who urged HBC to accept the offer; the company replied that the offer was incomplete and did not provide indication of financing for the deal.

At the time, HBC had recently sold the building that houses its Lord & Taylor store on Fifth Avenue in Manhattan to WeWork Property Advisors after pressure from Land & Buildings Investment Management. The deal also includes the use of floors of certain HBC owned department stores in New York, Toronto, Vancouver and Germany as WeWork’s shared office workspaces. In late October, HBC was also considering the sale the building that houses its flagship Vancouver store. 

By that time, CEO Gerald Storch was scheduled to leave HBC on 1 November, with Richard Baker taking over as interim CEO; both CFO Paul Beesley (who was replaced by Edward Record) and Don Watros, president of HBC International, had departed earlier. All left the company during a time of intense pressure on the executive and directors from Land & Buildings Investment Management, an entity that owns less than 5% of HBC shares.

On 1 April 2018, HBC disclosed that more than 5 million credit and debit cards used for in-store purchases had been recently breached by hackers. The compromised credit card transactions took place at Saks Fifth Avenue, Saks Off 5th and Lord & Taylor stores. The hack had been discovered by Gemini Advisory, which called the breach "amongst the biggest and most damaging to ever hit retail companies".

The HBC is diversified into joint ventures and other types of business products. The HBC has credit card, mortgage, and personal insurance branches. These other products and services are joint partnerships with other corporations. The HBC also has other HBC Rewards corporate partners such as: Imperial Oil/Esso, M&M Meat Shops, Chapters/Indigo Books, Kelsey's/Montana's Restaurants, Thrifty Car Rental, Cineplex Entertainment Theatres, etc. HBC Rewards points can be redeemed in house or into corporate partners' gift cards and certificates. Points can also be converted to Air Miles.

The HBC is involved in community and charity activities. The HBC Rewards Community Program raises funds for community causes. The HBC Foundation is a charity agency involved in social issues and service. The HBC used to sponsor the annual HBC Run for Canada, a series of public-participation runs and walks held across the country on Canada Day to raise funds for Canadian athletes. The company discontinued this event in 2009.
In May 2016, Hudson's Bay Company announced that they are expanding their operations to the Netherlands and plan to open 20 new stores as part of their European expansion.

The HBC was the official outfitter of clothing for members of the Canadian Olympic team in 1936, 1960, 1964, 1968, 2006, 2008, 2010, 2012, 2014 and 2016. The sponsorship has been renewed through 2020. Since the late 2000s, HBC has used its status as the official Canadian Olympics team outfitter to gain global exposure, as part of a turnaround plan that included shedding under-performing brands and luring new high-end brands.

On 2 March 2005, the company was announced as the new clothing outfitter for the Canadian Olympic team, in a $100 million deal, providing apparel for the 2006, 2008, 2010, and 2012 Games, having outbid the existing Canadian Olympic wear-supplier, Roots Canada, which had supplied Canada's Olympic teams from 1998 to 2004. The Canadian Olympic collection is sold through Hudson's Bay (and Zellers until 2013 when the Zellers leases were sold to Target Canada).

HBC's 2006 Winter Olympics and 2008 Summer Olympics uniforms and toques received a mixed reception for their multicoloured stripes (green, red, yellow, blue) which seemed to be not-so-subtle advertising for HBC rather than representing the Canadian Olympic team's traditional colours of red and white (with black as a secondary), in contrast to well-received Root's 1998 collection with its trendy red letter jackets and Poor Boy caps. HBC produced 80% to 90% of their Olympic clothes in China which was criticized, as Roots ensured that the Olympic clothes were made in Canada using Canadian material.

HBC's apparel for the 2010 Winter Olympics held in Vancouver proved to be extremely successful, in part because Canada was the host country and their athletes had a record medal haul. The "Red Mittens" (red-and-white mittens featuring a large maple leaf) that were sold for $10 CAD, with one-third of the proceeds going to the Canadian Olympic Committee, proved very popular, as were the "Canada" hoodies.

The HBC's 2010 Winter Olympics apparel was also controversial due to a knitted, machine-made sweater that looked like a Cowichan sweater. After a meeting between HBC representatives and Cowichan Tribes, a compromise was made between the parties; knitters would have an opportunity to sell their sweaters at the downtown Vancouver HBC store, alongside the HBC imitations.

Lord Sebastian Coe, chairman of the 2012 London Olympic Games Organizing Committee, who attended the Vancouver Olympics, noted that the Canadians were passionate in embracing the Games with 'their "Canada" hoodies and their red mittens (of which 2.6 million pairs sold that year). HBC has continued to produce these red mittens for subsequent Olympic Games.

The legacy of the HBC has been maintained in part by the detailed record-keeping and archiving of material by the company. Before 1974, the records of the HBC were kept in the London office headquarters. The HBC opened an archives department to researchers in 1931. In 1974, Hudson's Bay Company Archives (HBCA) were transferred from London and placed on deposit with the Manitoba archives in Winnipeg. The company granted public access to the collection the following year.

On 27 January 1994, the company’s archives were formally donated to the Archives of Manitoba.

At the time of the donation, the appraised value of the records was nearly $60 million. A foundation, Hudson's Bay Company History Foundation funded through the tax savings resulting from the donation, was established to support the operations of the HBC Archive as a division of the Archives of Manitoba, along with other activities and programs., More than two kilometers of filed documents and hundreds of microfilm reels are now stored in a special climate-controlled vault in the Manitoba Archives Building.

In 2007, Hudson's Bay Company Archives became part of the United Nations "Memory of the World Programme" project, under UNESCO. The records covered the HBC history from the founding of the company in 1670. The records contained business transactions, medical records, personal journals of officials, inventories, company reports, etc.

, the members of the board of directors of Hudson's Bay Company are:

In the 18th and 19th Centuries, Hudson's Bay Company operated with a very rigid hierarchy when it came to its employees. This hierarchy essentially broke down into two levels; the officers and the servants. Comprising the officers were the factors, masters and chief traders, clerks and surgeons. The servants were the tradesmen, boatmen, and labourers. The officers essentially ran the fur trading posts. They had many duties which included supervising the workers in their trade posts, valuing the furs, and keeping trade and post records. In 1821, when Hudson's Bay Company and the North West Company merged, the hierarchy became even stricter and the lines between officers and servants became virtually impossible to cross. Officers in charge of individual trading posts had much responsibility because they were directly in charge of enforcing the policies made by the governor and committee (the board) of the company. One of these policies was the price of particular furs and trade goods. These prices were called the Official and Comparative Standards. Made-Beaver, the quality measurement of the pelt, was the means of exchange used by Hudson's Bay Company to define the Official and Comparative Standards. Because the governor was stationed in London, England, they needed to have reliable officers managing the trade posts halfway around the world. Because the fur trade was a very dynamic market, HBC needed to have some form of flexibility when dealing with prices and traders. Price fluctuation was deferred to the officers in charge of the trade posts, and the head office recorded any difference between the company's standard and that set by the individual officers. Overplus, or any excess revenue gained by officers was strictly documented to insure that it wasn't being pocketed and taken from the company. This strict yet flexible hierarchy exemplifies how Hudson's Bay Company was able to be so successful while still having its central management and trade posts located so far apart.

Chronological list of Governors of the Hudson's Bay Company:

Under the charter establishing Hudson's Bay Company, the company was required to give two elk skins and two black beaver pelts to the English king, then Charles II, or his heirs, whenever the monarch visited Rupert's Land. The exact text from the 1670 Charter reads:

The ceremony was first conducted with the Prince of Wales (the future Edward VIII) in 1927, then with King George VI in 1939, and last with his daughter, Queen Elizabeth II in 1959 and 1970. On the last such visit, the pelts were given in the form of two live beavers, which the Queen donated to the Winnipeg Zoo in Assiniboine Park. However, when the company permanently moved its headquarters to Canada, the Charter was amended to remove the rent obligation. Each of the four "rent ceremonies" took place in or around Winnipeg.



The HBC is the only European trading company to have survived and outlived all its rivals.




</doc>
<doc id="13298" url="https://en.wikipedia.org/wiki?curid=13298" title="Hoplite">
Hoplite

Hoplites () were citizen-soldiers of Ancient Greek city-states who were primarily armed with spears and shields. Hoplite soldiers utilized the phalanx formation in order to be effective in war with fewer soldiers. The formation discouraged the soldiers from acting alone, for this would compromise the formation and minimize its strengths. The hoplites were primarily represented by free citizens—propertied farmers and artisans—who were able to afford the bronze armour suit and weapons (estimated at a third to a half of its able-bodied adult male population). Hoplites were not professional soldiers and often lacked sufficient military training. Although some states did maintain a small elite professional unit, hoplite soldiers were relied on heavily and made up the bulk of ancient Greek armies of the time.

In the 8th or 7th century BC, Greek armies adopted a military innovation known as the phalanx formation. The formation proved successful in defeating the Persians when employed by the Athenians at the Battle of Marathon in 490 BC during the First Greco-Persian War. The Persian archers and light troops who fought in the Battle of Marathon failed, because their bows were too weak for their arrows to penetrate the wall of Greek shields that made up the phalanx formation. The phalanx was also employed by the Greeks at the Battle of Thermopylae in 480 BC and at the Battle of Plataea in 479 BC during the Second Greco-Persian War.

The word "hoplite" (Greek: "hoplitēs"; pl. "hoplitai") derives from "hoplon" (, plural "hopla" ), the name for the type of shield used by the soldiers. However, the shield was more commonly known as an aspis, so the word "hopla" may refer to the soldiers' weapons or even their full armament. In the modern Hellenic Army, the word "hoplite" (Greek: ) is used to refer to an infantryman.

The fragmented political structure of Ancient Greece, with many competing city-states, increased the frequency of conflict, but at the same time limited the scale of warfare. Limited manpower did not allow most Greek city-states to form large armies which could operate for long periods because they were generally not formed from professional soldiers. Most soldiers had careers as farmers or workers and returned to these professions after the campaign. All hoplites were expected to take part in any military campaign when called for duty by leaders of the state. The Lacedaemonian citizens of Sparta were renowned for their lifelong combat training and almost mythical military prowess, while their greatest adversaries, the Athenians, were exempted from service only after the 60th year of their lives. This inevitably reduced the potential duration of campaigns and often resulted in the campaign season being restricted to one summer.

Armies generally marched directly to their destination, and in some cases the battlefield was agreed to by the contestants in advance. Battles were fought on level ground, and hoplites preferred to fight with high terrain on both sides of the phalanx so the formation could not be flanked. An example of this was the Battle of Thermopylae, where the Spartans specifically chose a narrow coastal pass to make their stand against the massive Persian army. The vastly outnumbered Greeks held off the Persians for seven days.

When battles occurred, they were usually set piece and intended to be decisive. The battlefield would be flat and open to facilitate phalanx warfare. These battles were usually short and required a high degree of discipline. At least in the early classical period, when cavalry was present, its role was restricted to protection of the flanks of the phalanx, pursuit of a defeated enemy, and covering a retreat if required. Light infantry and missile troops took part in the battles but their role was less important. Before the opposing phalanxes engaged, the light troops would skirmish with the enemy's light forces, and then protect the flanks and rear of the phalanx.

The military structure created by the Spartans was a rectangular phalanx formation. The formation was organized from eight to ten rows deep and could cover a front of a quarter of a mile or more if sufficient hoplites were available. The two lines would close to a short distance to allow effective use of their spears, while the psiloi threw stones and javelins from behind their lines. The shields would clash and the first lines (protostates) would stab at their opponents, at the same time trying to keep in position. The ranks behind them would support them with their own spears and the mass of their shields gently pushing them, not to force them into the enemy formation but to keep them steady and in place. The soldiers in the back provided motivation to the ranks in the front being that most hoplites were close community members. At certain points, a command would be given to the phalanx or a part thereof to collectively take a certain number of steps forward (ranging from half to multiple steps). This was the famed "othismos".
At this point, the phalanx would put its collective weight to push back the enemy line and thus create fear and panic among its ranks. There could be multiple such instances of attempts to push, but it seems from the accounts of the ancients that these were perfectly orchestrated and attempted organized "en masse". Once one of the lines broke, the troops would generally flee from the field, sometimes chased by psiloi, peltasts, or light cavalry.

If a hoplite escaped, he would sometimes be forced to drop his cumbersome aspis, thereby disgracing himself to his friends and family (becoming a "ripsaspis", one who threw his shield). To lessen the amount of casualties inflicted by the enemy during battles, soldiers were positioned to stand shoulder to shoulder with their hoplon. The hoplites' most prominent citizens and generals led from the front. Thus, the whole war could be decided by a single field battle; victory was enforced by ransoming the fallen back to the defeated, called the "Custom of the Greeks".

Individual hoplites carried their shields on their left arm, protecting not only themselves but also the soldier to the left. This meant that the men at the extreme right of the phalanx were only half-protected. In battle, opposing phalanxes would exploit this weakness by attempting to overlap the enemy's right flank. It also meant that, in battle, a phalanx would tend to drift to the right (as hoplites sought to remain behind the shield of their neighbour). The most experienced hoplites were often placed on the right side of the phalanx, to counteract these problems. According to Plutarch's "Sayings of Spartans", "a man carried a shield for the sake of the whole line".

The phalanx is an example of a military formation in which single combat and other individualistic forms of battle were suppressed for the good of the whole. In earlier Homeric, dark age combat, the words and deeds of supremely powerful heroes turned the tide of battle. Instead of having individual heroes, hoplite warfare relied heavily on the community and unity of soldiers. With friends and family pushing on either side and enemies forming a solid wall of shields in front, the hoplite had little opportunity for feats of technique and weapon skill, but great need for commitment and mental toughness. By forming a human wall to provide a powerful defensive armour, the hoplites became much more effective while taking fewer casualties. The hoplites had much discipline and were taught to be loyal and trustworthy. They had to trust their neighbours for mutual protection, so a phalanx was only as strong as its weakest elements. Its effectiveness depended on how well the hoplites could maintain this formation while in combat, and how well they could stand their ground, especially when engaged against another phalanx. The more disciplined and courageous the army, the more likely it was to win—often engagements between the various city-states of Greece would be resolved by one side fleeing after their phalanx had broken formation.

Each hoplite provided his own equipment. Thus, only those who could afford such weaponry fought as hoplites; as with the Roman Republican army it was the middle classes who formed the bulk of the infantry. Equipment was not standardized, although there were doubtless trends in general designs over time, and between city-states. Hoplites had customized armour, the shield was decorated with family or clan emblems, although in later years these were replaced by symbols or monograms of the city states. The equipment might well be passed down in families, since it would have been expensive to manufacture.

The hoplite army consisted of heavily armoured infantrymen. Their armour, also called panoply, was made of full bronze, weighing nearly . The average farmer-peasant hoplite typically wore no armour, carrying only a shield, a spear, and perhaps a helmet plus a secondary weapon.The linothorax was the most popular type armour worn by the hoplites, since it was cost-effective and provided decent protection. The richer upper-class hoplites typically had a bronze cuirass of either the bell or muscled variety, a bronze helmet with cheekplates, as well as greaves and other armour. The design of the helmets used varied through time. The Corinthian helmet was at first standardized and was a very successful design. Later variants included the Chalcidian helmet, a lightened version of the Corinthian helmet, and the very simple Pilos helmet worn by the later hoplites. Often the helmet was decorated with one, sometimes more horsehair crests, and/or bronze animal horns and ears. Helmets were often painted as well. The Thracian helmet had a large visor to further increase protection. In later periods, linen breastplates called "linothorax" were used, as they were tougher and cheaper to make. The linen was thick.

By contrast with hoplites, other contemporary infantry (e.g., Persian) tended to wear relatively light armour, use wicker shields, and were armed with shorter spears, javelins, and bows. The most famous are the peltasts, light-armed troops who wore no armour and were armed with a light shield, javelins and a short sword. The Athenian general Iphicrates developed a new type of armour and arms for his mercenary army, which included light linen armour, smaller shields and longer spears, whilst arming his peltasts with larger shields, helmets and a longer spear, thus enabling them to defend themselves more easily against enemy hoplites. With this new type of army he defeated a Spartan army in 392 BC. Nevertheless, most hoplites stuck to the traditional arms and armour.

Hoplites carried a large concave shield called an "aspis" (often referred to as a "hoplon"), measuring between 80–100 centimetres (31–39 in) in diameter and weighing between 6.5–8 kilograms (14–18 lbs). This large shield was made possible partly by its shape, which allowed it to be supported on the shoulder. The hoplon shield was put together in three layers: the center layer was made of thick wood, the outside layer facing the enemy was made of bronze, and leather made up the inside of the shield. The revolutionary part of the shield was, in fact, the grip. Known as an Argive grip, it placed the handle at the edge of the shield, and was supported by a leather fastening (for the forearm) at the centre. These two points of contact eliminated the possibility of the shield swaying to the side after being struck, and as a result soldiers rarely lost their shields. This allowed the hoplite soldier more mobility with the shield, as well as the ability to capitalize on its offensive capabilities and better support the phalanx. The large hoplon shields, designed for pushing ahead, were the most essential equipment for the hoplites.

The main offensive weapon used was a long and in diameter spear called a "doru", or "dory". It was held with the right hand, with the left hand holding the hoplite's shield. Soldiers usually held their spears in an underhand position when approaching but once they came into close contact with their opponents, they were held in an overhand position ready to strike. The spearhead was usually a curved leaf shape, while the rear of the spear had a spike called a "sauroter" ("lizard-killer") which was used to stand the spear in the ground (hence the name). It was also used as a secondary weapon if the main shaft snapped, or for the rear ranks to finish off fallen opponents as the phalanx advanced over them. In addition to being used as a secondary weapon, the sauroter also doubled to balance the spear, but not for throwing purposes. It is a matter of contention, among historians, whether the hoplite used the spear overarm or underarm. Held underarm, the thrusts would have been less powerful but under more control, and vice versa. It seems likely that both motions were used, depending on the situation. If attack was called for, an overarm motion was more likely to break through an opponent's defence. The upward thrust is more easily deflected by armour due to its lesser leverage. However, when defending, an underarm carry absorbed more shock and could be 'couched' under the shoulder for maximum stability. It should also be said that an overarm motion would allow more effective combination of the "aspis" and "doru" if the shield wall had broken down, while the underarm motion would be more effective when the shield had to be interlocked with those of one's neighbours in the battle-line. Hoplites in the rows behind the lead would almost certainly have made overarm thrusts. The rear ranks held their spears underarm, and raised their shields upwards at increasing angles. This was an effective defence against missiles, deflecting their force.

Hoplites also carried a sword, mostly a short sword called a "xiphos", but later also longer and heavier types. The short sword was a secondary weapon, used if or when their spears were broken or lost, or if the phalanx broke rank. The xiphos usually had a blade around long; however, those used by the Spartans were often only 30–45 centimetres long. This very short xiphos would be very advantageous in the press that occurred when two lines of hoplites met, capable of being thrust through gaps in the shieldwall into an enemy's unprotected groin or throat, while there was no room to swing a longer sword. Such a small weapon would be particularly useful after many hoplites had started to abandon body armour during the Peloponnesian War. Hoplites could also alternatively carry the "kopis", a heavy knife with a forward-curving blade.

"For more information on this topic: Phalanx"

Dark age warfare transitioned into hoplite warfare in the 8th century BC. Historians and researchers have debated the reason and speed of the transition for centuries. So far 3 popular theories exist:

Developed by Anthony Snodgrass, the Gradualist Theory states that the hoplite style of battle developed in a series of steps as a result of innovations in armour and weaponry. Chronologically dating the archeological findings of hoplite armour and using the findings to approximate the development of the phalanx formation, Snodgrass claims that the transition took approximately 100 years to complete from 750–650 BC. The progression of the phalanx took time because as the phalanx matured it required denser formations that made the elite warriors recruit Greek citizens. The large amounts of hoplite armour needed to then be distributed to the populations of Greek citizens only increased the time for the phalanx to be implemented. Snodgrass believes, only once the armour was in place that the phalanx formation became popular.

The Rapid Adaptation model was developed by historians Paul Cartledge and Victor Hanson. The historians believe that the phalanx was created individually by military forces, but was so effective that others had to immediately adapt their way of war to combat the formation. Rapid Adoptionists propose that the double grip, hoplon shield that was required for the phalanx formation was so constricting in mobility that once it was introduced, dark age, free flowing warfare was inadequate to fight against the hoplites only escalating the speed of the transition. Quickly, the phalanx formation and hoplite armour became widely used throughout Ancient Greece. Cartledge and Hanson estimate the transition took place from 725–675 BC.

Developed by Hans Van Wees, the Extended Gradualist theory is the most lengthy of the three popular transition theories. Van Wees depicts iconography found on pots of the Dark Ages believing that the foundation of the phalanx formation was birthed during this time. Specifically, he uses an example of the Chigi Vase to point out that hoplite soldiers were carrying normal spears as well as javelins on their backs. Matured hoplites did not carry long range weapons including javelins. The Chigi vase is important for our knowledge of the hoplite soldier because it is one, if not the only one representation of the hoplite formation, known as the phalanx, in Greek art. This led Van Wees to believe that there was a transitional period from long range warfare of the Dark Ages to the close combat of hoplite warfare. Some other evidence of a transitional period lies within the text of Spartan Poet Tyrtaios, when he wrote, "…will they draw back for the pounding [of the missiles, no,] despite the battery of great hurl-stones, the helmets shall abide the rattle [of war unbowed]". At no point in future texts does Tyrtaios involve any talk of missiles or rocks making another case for a transitional period. Extended Gradualists argue that hoplite warriors did not fight in a true phalanx until the 5th century BC. Making estimations of the speed of the transition reached as long as 300 years, from 750–450 BC.

"For more information on this topic: Ancient Greek warfare"

The exact time when hoplite warfare was developed is uncertain, the prevalent theory being that it was established sometime during the 8th or 7th century BC, when the "heroic age was abandoned and a far more disciplined system introduced" and the Argive shield became popular. Peter Krentz argues that "the ideology of hoplitic warfare as a ritualized contest developed not in the 7th century [BC], but only after 480, when non-hoplite arms began to be excluded from the phalanx". Anagnostis Agelarakis, based on recent archaeo-anthropological discoveries of the earliest monumental polyandrion (communal burial of male warriors) at Paros Island in Greece, unveils a last quarter of the 8th century BC date for a hoplitic phalangeal military organization.

The rise and fall of hoplite warfare was tied to the rise and fall of the city-state. As discussed above, hoplites were a solution to the armed clashes between independent city-states. As Greek civilization found itself confronted by the world at large, particularly the Persians, the emphasis in warfare shifted. Confronted by huge numbers of enemy troops, individual city-states could not realistically fight alone. During the Greco-Persian Wars (499–448 BC), alliances between groups of cities (whose composition varied over time) fought against the Persians. This drastically altered the scale of warfare and the numbers of troops involved. The hoplite phalanx proved itself far superior to the Persian infantry at such conflicts as the Battle of Marathon, Thermopylae, and the Battle of Plataea.
During this period, Athens and Sparta rose to a position of political eminence in Greece, and their rivalry in the aftermath of the Persian wars brought Greece into renewed internal conflict. However, the Peloponnesian War was on a scale unlike conflicts before. Fought between leagues of cities, dominated by Athens and Sparta respectively, the pooled manpower and financial resources allowed a diversification of warfare. Hoplite warfare was in decline; there were three major battles in the Peloponnesian War, and none proved decisive. Instead there was increased reliance on navies, skirmishers, mercenaries, city walls, siege engines, and non-set piece tactics. These reforms made wars of attrition possible and greatly increased the number of casualties. In the Persian war, hoplites faced large numbers of skirmishers and missile-armed troops, and such troops (e.g., peltasts) became much more commonly used by the Greeks during the Peloponnesian War. As a result, hoplites began wearing less armour, carrying shorter swords, and in general adapting for greater mobility; this led to the development of the ekdromos light hoplite.

Many famous personalities, philosophers, artists, and poets fought as hoplites.

According to Nefiodkin, fighting against Greek heavy infantry during the Greco-Persian Wars inspired the Persians to introduce scythed chariots.

"For more information on this topic: Spartan army"

Sparta is one of the most famous city-states, along with Athens, which had a unique position in ancient Greece. Contrary to other city states, the free citizens of Sparta served as hoplites their entire life, training and exercising also in peacetime, which gave Sparta a professional standing army. Although small, numbering no more than 1,500 to 2,000 men, divided into six mora or battalions, the Spartan army was feared for its discipline and ferocity. Military service was the primary duty of Spartan men, and Spartan society was organized around its army.
Military service for hoplites lasted until the age of 40, and sometimes even until 60 years of age, depending on a man's physical ability to perform on the battlefield.

"For more information on this topic: Ancient Macedonian army"

Later on in the hoplite era, more sophisticated tactics were developed, in particular by the Theban general Epaminondas. These tactics inspired the future king Philip II of Macedon, who was at the time a hostage in Thebes, and also inspired the development of new kind of infantry, the Macedonian phalanx. After the Macedonian conquests of the 4th century BC, the hoplite was slowly abandoned in favour of the phalangite, armed in the Macedonian fashion, in the armies of the southern Greek states. Although clearly a development of the hoplite, the Macedonian phalanx was tactically more versatile, especially used in the combined arms tactics favoured by the Macedonians. These forces defeated the last major hoplite army, at the Battle of Chaeronea (338 BC), after which Athens and its allies joined the Macedonian empire.

While Alexander's army mainly fielded "Pezhetairoi" (= Foot Companions) as his main force, it is known that his army also included some classic hoplites, either provided by the League of Corinth or from hired mercenaries. Beside these units, the Macedonians also used the so-called "Hypaspists", an elite force of units possibly originally fighting as hoplites and used to guard the exposed right wing of Alexander's phalanx.

Hoplite-style warfare was very influential and influenced several other nations in the Mediterranean. Hoplite warfare was the dominant fighting style on the Italian Peninsula up to the early 3rd century BC, employed by both the Etruscans and the Early Roman army. The Romans later changed their fighting style to a more flexible maniple organization, which was more versatile on rough terrain like that of Samnium. Roman equipment also changed, and they reequipped their soldiers with longer oval shields ("scutum"), swords and heavy javelins ("pilum"). In the end only the "triarii" would keep a long spear ("hasta") as their main weapon. However, the triarii would still fight in a traditional phalanx formation. Though the Italian tribes, namely the socii fighting with the Romans, later adopted the new Roman fighting style, some continued to fight as hoplites. Local levied troops or mercenaries serving under Pyrrhus of Epirus or Hannibal (namely Etruscans) were equipped and fought as hoplites.

Early in its history, Ancient Carthage also equipped its troops as Greek hoplites, in units such as the Sacred Band of Carthage. Many Greek hoplite mercenaries also fought in foreign armies, such as Carthage and Achaemenid Empire, where it is believed by some that they inspired the formation of the Cardaces. Some hoplites served under the Illyrian king Bardylis in the 4th century. The Illyrians were known to import many weapons and tactics from the Greeks.

The Diadochi imported the Greek phalanx to their kingdoms. Though they mostly fielded Greek citizens or mercenaries, they also armed and drilled local natives as hoplites or rather Macedonian phalanx, like the Machimoi of the Ptolemaic army.

The Greek armies of the Hellenistic period mostly fielded troops in the fashion of the Macedonian phalanx. Nonetheless many armies of mainland Greece stuck with hoplite warfare. Besides classical hoplites Hellenistic nations began to field two new types of hoplites, the "Thureophoroi" and the "Thorakitai". They developed when Greeks adopted the Celtic "Thureos" shield, of an oval shape that was similar to the shields of the Romans, but flatter. The Thureophoroi were armed with a long thrusting spear, a short sword and, if needed, javelins. While the Thorakitai were similar to the Thureophoroi, they were more heavily armoured, as their name implies, usually wearing a mail shirt. These troops were used as a link between the light infantry and the phalanx, a form of medium infantry to bridge the gaps.




</doc>
