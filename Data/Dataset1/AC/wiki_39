<doc id="29253" url="https://en.wikipedia.org/wiki?curid=29253" title="Spandrel">
Spandrel

A spandrel, less often spandril or splaundrel, is the space between two arches or between an arch and a rectangular enclosure.

There are four or five accepted and cognate meanings of "spandrel" in architectural and art history, mostly relating to the space between a curved figure and a rectangular boundary – such as the space between the curve of an arch and a rectilinear bounding moulding, or the wallspace bounded by adjacent arches in an arcade and the stringcourse or moulding above them, or the space between the central medallion of a carpet and its rectangular corners, or the space between the circular face of a clock and the corners of the square revealed by its hood. Also included is the space under a flight of stairs, if it is not occupied by another flight of stairs.

In a building with more than one floor, the term spandrel is also used to indicate the space between the top of the window in one story and the sill of the window in the story above. The term is typically employed when there is a sculpted panel or other decorative element in this space, or when the space between the windows is filled with opaque or translucent glass, in this case called "spandrel glass". In concrete or steel construction, an exterior beam extending from column to column usually carrying an exterior wall load is known as a spandrel beam.

The spandrels over doorways in perpendicular work are generally richly decorated. At Magdalen College, Oxford is one which is perforated. The spandrel of doors is sometimes ornamented in the Decorated Period, but seldom forms part of the composition of the doorway itself, being generally over the label.

Spandrels can also occur in the construction of domes and are typical in grand architecture from the medieval period onwards. Where a dome needed to rest on a square or rectangular base, the dome was raised above the level of the supporting pillars, with three-dimensional spandrels called pendentives taking the weight of the dome and concentrating it onto the pillars.




</doc>
<doc id="29257" url="https://en.wikipedia.org/wiki?curid=29257" title="SimpleText">
SimpleText

SimpleText is the native text editor for the Apple classic Mac OS. SimpleText allows editing including text formatting (underline, italic, bold, etc.), fonts, and sizes. It was developed to integrate the features included in the different versions of TeachText that were created by various software development groups within Apple.

It can be considered similar to Windows' WordPad application. In later versions it also gained additional read only display capabilities for PICT files, as well as other Mac OS built-in formats like Quickdraw GX and QTIF, 3DMF and even QuickTime movies. SimpleText can even record short sound samples and, using Apple's PlainTalk speech system, read out text in English. Users who wanted to add sounds longer than 24 seconds, however, needed to use a separate program to create the sound and then paste the desired sound into the document using ResEdit.

SimpleText superseded TeachText, which was included in System Software up until Mac OS 8. The need for SimpleText arose after Apple stopped bundling MacWrite, to ensure that every user could open and read Readme documents.

The key improvement of SimpleText over TeachText was the addition of text styling. The underlying OS required by SimpleText implemented a standard styled text format, which meant that SimpleText could support multiple fonts and font sizes. Prior Macintosh OS versions lacked this feature, so TeachText supported only a single font per document. Adding text styling features made SimpleText WorldScript-savvy, meaning that it can use Simplified and Traditional Chinese characters. Like TeachText, SimpleText was also limited to only 32 kB of text in a document, although images could increase the total file size beyond this limit. SimpleText style information was stored in the file's resource fork in such a way that if the resource fork was stripped (such as by uploading to a non-Macintosh server), the text information would be retained.

In Mac OS X, SimpleText is replaced by the more powerful TextEdit application, which reads and writes more document formats as well as including word processor-like features such as a ruler and spell checking. TextEdit's styled text format is RTF, which is able to survive a single-forked file system intact.

Apple has released the source code for a Carbon version of SimpleText in the Mac OS X Panther Developer Tools. If the Developer Tools are installed, it can be found at /Developer/Examples/Carbon/SimpleText.




</doc>
<doc id="29263" url="https://en.wikipedia.org/wiki?curid=29263" title="Statute of Westminster 1931">
Statute of Westminster 1931

The Statute of Westminster 1931 is an Act of the Parliament of the United Kingdom and modified versions of it are now domestic law within Australia and Canada; it has been repealed in New Zealand and implicitly in former Dominions that are no longer Commonwealth realms. Passed on 11 December 1931, the act, either immediately or upon ratification, effectively both established the legislative independence of the self-governing Dominions of the British Empire from the United Kingdom and bound them all to seek each other's approval for changes to monarchical titles and the common line of succession. It thus became a statutory embodiment of the principles of equality and common allegiance to the Crown set out in the Balfour Declaration of 1926. It was a crucial step in the development of the Dominions as separate states.

The Statute of Westminster's relevance today is that it sets the basis for the continuing relationship between the Commonwealth realms and the Crown.

The Statute of Westminster gave effect to certain political resolutions passed by the Imperial Conferences of 1926 and 1930; in particular, the Balfour Declaration of 1926. The main effect was the removal of the ability of the British parliament to legislate for the Dominions, part of which also required the repeal of the Colonial Laws Validity Act 1865 in its application to the Dominions. King George V expressed his desire that the laws of royal succession be exempt from the statute's provisions, but it was determined that this would be contrary to the principles of equality set out in the Balfour Declaration. Both Canada and the Irish Free State pushed for the ability to amend the succession laws themselves and section 2(2) (allowing a Dominion to amend or repeal laws of paramount force, such as the succession laws, insofar as they are part of the law of that Dominion) was included in the Statute of Westminster at Canada's insistence. After the Statute was passed, the British parliament could no longer make laws for the Dominions, other than with the request and consent of the government of that Dominion. Before then, the Dominions had legally been self-governing colonies of the United Kingdom. However, the Statute had the effect of making them sovereign nations once they adopted it.

The Statute provides in section 4:
No Act of Parliament of the United Kingdom passed after the commencement of this Act shall extend, or be deemed to extend, to a Dominion as part of the law of that Dominion, unless it is expressly declared in that Act that that Dominion has requested, and consented to, the enactment thereof. 

It also provides in section 2(1):
No law and no provision of any law made after the commencement of this Act by the Parliament of a Dominion shall be void or inoperative on the ground that it is repugnant to the Law of England, or to the provisions of any existing or future Act of Parliament of the United Kingdom, or to any order, rule or regulation made under any such Act, and the powers of the Parliament of a Dominion shall include the power to repeal or amend any such Act, order, rule or regulation in so far as the same is part of the law of the Dominion.

The whole Statute applied to Canada, the Irish Free State, and the Union of South Africa without the need for any acts of ratification; the governments of those countries gave their consent to the application of the law to their respective jurisdiction. Section 10 of the Statute provided that sections 2 to 6 would apply in the other three Dominions—Australia, New Zealand, and Newfoundland—only after the parliament of that Dominion had legislated to adopt them.

Since 1931, over a dozen new Commonwealth realms have been created, all of which now hold the same powers as the United Kingdom, Canada, Australia, and New Zealand over matters of change to the monarchy, though the Statute of Westminster is not part of their laws. Ireland and South Africa are now republics and Newfoundland is part of Canada.

Australia adopted sections 2 to 6 of the Statute of Westminster with the Statute of Westminster Adoption Act 1942, in order to clarify the validity of certain Australian legislation relating to the Second World War; the adoption was backdated to 3 September 1939, the beginning of the war.

Adopting section 2 of the Statute clarified that the Commonwealth parliament was able to legislate inconsistently with British legislation, adopting section 3 clarified that it could legislate with extraterritorial effect. Adopting section 4 clarified that Britain could legislate with effect on Australia as a whole only with Australia's request and consent.

Nonetheless, under section 9 of the Statute, on matters not within Commonwealth power Britain could still legislate with effect in all or any of the Australian states, without the agreement of the Commonwealth although only to the extent of "the constitutional practice existing before the commencement" of the Statute. However, this capacity was never used. In particular, it was not used to implement the result of the Western Australian secession referendum, 1933, as it did not have the support of the Australian government.
All British power to legislate with effect in Australia ended with the Australia Act 1986, the British version of which says that it was passed with the request and consent of the Australian parliament, which had obtained the concurrence of the Australian states.

This statute limited the legislative authority of the British parliament over Canada, effectively giving the country legal autonomy as a self-governing Dominion, though the British parliament retained the power to amend Canada's constitution at the request of the Parliament of Canada. That authority remained in effect until the Constitution Act, 1982, which transferred it to Canada, the final step to achieving full sovereignty.
The British North America Acts—the written elements (in 1931) of the Canadian constitution—were excluded from the application of the statute because of disagreements between the Canadian provinces and the federal government over how the British North America Acts could be otherwise amended. These disagreements were resolved only in time for the passage of the Canada Act 1982, thus completing the patriation of the Canadian constitution to Canada. At that time, the Canadian parliament also repealed sections 4 and 7(1) of the Statute of Westminster. The Statute of Westminster remains a part of the constitution of Canada by virtue of section 52(2)(b) of the Constitution Act, 1982.

As a consequence of the statute's adoption, the Parliament of Canada gained the ability to abolish appeals to the Judicial Committee of the Privy Council. Criminal appeals were abolished in 1933, while civil appeals continued until 1949. The passage of the Statute of Westminster meant that changes in British legislation governing the succession to the throne no longer automatically applied to Canada.

The Irish Free State never formally adopted the Statute of Westminster, its Executive Council taking the view that the Anglo-Irish Treaty of 1921 had already ended Westminster's right to legislate for the Free State. The Free State's constitution gave the Oireachtas "sole and exclusive power of making laws". Hence, even before 1931, the Free State did not arrest British Army and Royal Air Force deserters on its territory, even though the UK believed post-1922 British laws gave the Free State's Garda Síochána the power to do so. The UK's Irish Free State Constitution Act 1922 said, however, " in the [Free State] Constitution shall be construed as prejudicing the power of [the British] Parliament to make laws affecting the Irish Free State in any case where, in accordance with constitutional practice, Parliament would make laws affecting other self-governing Dominions".
Motions of approval of the Report of the Commonwealth Conference had been passed by the Dáil and Seanad in May 1931 and the final form of the Statute of Westminster included the Irish Free State among the Dominions the British parliament could not legislate for without the Dominion's request and consent. Originally, the UK government had wanted to exclude from the Statute of Westminster the legislation underpinning the 1921 treaty, from which the Free State's constitution had emerged. President W. T. Cosgrave objected, although he promised the Executive Council would not amend the legislation unilaterally. The other Dominions backed Cosgrave and, when an amendment to similar effect was proposed at Westminster by John Gretton, parliament duly voted it down. When the Statute became law in the UK, Patrick McGilligan, the Free State Minister for External Affairs, stated: "It is a solemn declaration by the British people through their representatives in Parliament that the powers inherent in the Treaty position are what we have proclaimed them to be for the last ten years." He went on to present the Statute as largely the fruit of the Free State's efforts to secure for the other Dominions the same benefits it already enjoyed under the treaty.

After Éamon de Valera led Fianna Fáil to victory in the Free State election of 1932, he began removing the monarchical elements of the constitution, beginning with the Oath of Allegiance. De Valera initially considered invoking the Statute of Westminster in making these changes, but John J. Hearne advised him not to. Abolishing the Oath of Allegiance in effect abrogated the 1921 treaty. Generally, the British thought that this was morally objectionable but legally permitted by the Statute of Westminster. Robert Lyon Moore, a southern unionist from County Donegal, challenged the legality of the abolition in the Free State courts and then appealed to the Judicial Committee of the Privy Council (JCPC) in London. However, the Free State had also abolished the right of appeal to the JCPC. In 1935, the JCPC ruled that both abolitions were valid under the Statute of Westminster. The Free State, which in 1937 was renamed "Ireland", left the Commonwealth in 1949 upon the coming into force of its Republic of Ireland Act.

The Parliament of New Zealand adopted the Statute of Westminster by passing its Statute of Westminster Adoption Act 1947 in November 1947. The New Zealand Constitution Amendment Act, passed the same year, empowered the New Zealand parliament to change the constitution, but did not remove the ability of the British parliament to legislate regarding the New Zealand constitution. The remaining role of the British parliament was removed by the New Zealand Constitution Act 1986 and the Statute of Westminster was repealed in its entirety.

The Dominion of Newfoundland never adopted the Statute of Westminster, especially because of financial troubles and corruption there. By request of the Dominion's government, the United Kingdom established the Commission of Government in 1934, resuming direct rule of Newfoundland. That arrangement remained until Newfoundland became a province of Canada in 1949.

Although the Union of South Africa was not among the Dominions that needed to adopt the Statute of Westminster for it to take effect, two laws—the Status of the Union Act, 1934, and the Royal Executive Functions and Seals Act of 1934—were passed to confirm South Africa's status as a sovereign state.

The preamble to the Statute of Westminster sets out conventions which affect attempts to change the rules of succession to the Crown. The second paragraph of the preamble to the Statute reads:

And whereas it is meet and proper to set out by way of preamble to this Act that, inasmuch as the Crown is the symbol of the free association of the members of the British Commonwealth of Nations, and as they are united by a common allegiance to the Crown, it would be in accord with the established constitutional position of all the members of the Commonwealth in relation to one another that any alteration in the law touching the Succession to the Throne or the Royal Style and Titles shall hereafter require the assent as well of the Parliaments of all the Dominions as of the Parliament of the United Kingdom:

This means, for example, that any change in any realm to the Act of Settlement's provisions barring Roman Catholics from the throne would require the unanimous assent of the parliaments of all the other Commonwealth realms if the shared aspect of the Crown is to be retained. The preamble does not itself contain enforceable provisions, it merely expresses a constitutional convention, albeit one fundamental to the basis of the relationship between the Commonwealth realms. (As sovereign nations, each is free to withdraw from the arrangement, using their respective process for constitutional amendment.) Additionally, per section 4, if a realm wished for a British act amending the Act of Settlement in the UK to become part of that realm's laws, thereby amending the Act of Settlement in that realm, it would have to request and consent to the British act and the British act would have to state that such request and consent had been given. Section 4 of the Statute of Westminster has been repealed in a number of realms, however, and replaced by other constitutional clauses absolutely disallowing the British parliament from legislating for those realms.

This has raised some logistical concerns, as it would mean multiple parliaments would all have to assent to any future changes in any realm to its line of succession, as with the Perth Agreement's proposals to abolish male-preference primogeniture.

During the abdication crisis in 1936, British Prime Minister Stanley Baldwin consulted the Commonwealth prime ministers at the request of King Edward VIII. The King wanted to marry Wallis Simpson, whom Baldwin and other British politicians considered unacceptable as queen, as she was an American divorcée. Baldwin was able to get the then five Dominion prime ministers to agree with this and thus register their official disapproval at the King's planned marriage. The King later requested the Commonwealth prime ministers be consulted on a compromise plan, in which he would wed Simpson under a morganatic marriage pursuant to which she would not become queen. Under Baldwin's pressure, this plan was also rejected by the Dominions. All of these negotiations occurred at a diplomatic level and never went to the Commonwealth parliaments. However, the enabling legislation that allowed for the actual abdication (His Majesty's Declaration of Abdication Act 1936) did require the assent of each Dominion parliament to be passed and the request and consent of the Dominion governments so as to allow it to be part of the law of each Dominion. For expediency and to avoid embarrassment, the British government had suggested the Dominion governments regard whomever is monarch of the UK to automatically be their monarch. However, the Dominions rejected this; Prime Minister of Canada William Lyon Mackenzie King pointed out that the Statute of Westminster required Canada's request and consent to any legislation passed by the British parliament before it could become part of Canada's laws and affect the line of succession in Canada. The text of the British act states that Canada requested and consented (the only Dominion to formally do both) to the act applying in Canada under the Statute of Westminster, while Australia, New Zealand, and the Union of South Africa simply assented.

In February 1937, the South African parliament formally gave its assent by passing His Majesty King Edward the Eighth's Abdication Act, 1937, which declared that Edward had abdicated on 10 December 1936; that he and his descendants, if any, would have no right of succession to the throne; and that the Royal Marriages Act 1772 would not apply to him or his descendants, if any. The move was largely done for symbolic purposes, in an attempt by Prime Minister J. B. M. Hertzog to assert South Africa's independence from Britain. In Canada, the federal parliament passed the Succession to the Throne Act 1937, to assent to His Majesty's Declaration of Abdication Act and ratify the government's request and consent to it. In the Irish Free State, Prime Minister Éamon de Valera used the departure of Edward as an opportunity to remove all explicit mention of the monarch from the constitution of the Irish Free State, through the Constitution (Amendment No. 27) Act 1936, passed on 11 December 1936. The following day, the External Relations Act provided for the king to carry out certain diplomatic functions, if authorised by law. A new Constitution of Ireland, with a president, was approved by Irish voters in 1937, with the Irish Free State becoming simply "Ireland", or, in the Irish language, "Éire". However, the head of state of Ireland remained unclear until 1949, when Ireland unambiguously became a republic outside the Commonwealth of Nations by enacting the Republic of Ireland Act 1948.

In some countries where the Statute of Westminster forms a part of the constitution, the anniversary of the date of the passage of the original British statute is commemorated as Statute of Westminster Day. In Canada, it is mandated that, on 11 December, the Royal Union Flag (as the Union Jack is called by law in Canada) is to be flown at properties owned by the federal Crown, where the requisite second flag pole is available.




</doc>
<doc id="29265" url="https://en.wikipedia.org/wiki?curid=29265" title="Serbia">
Serbia

Serbia ( / "Srbija" ), officially the Republic of Serbia ( / "Republika Srbija" ), is a sovereign state situated at the crossroads of Central and Southeast Europe in the southern Pannonian Plain and the central Balkans. It borders Hungary to the north; Romania and Bulgaria to the east; Macedonia to the south; Croatia, Bosnia and Herzegovina, Montenegro to the west and claims a border with Albania through the disputed territory of Kosovo. Serbia numbers around 7 million residents. Its capital, Belgrade, ranks among the oldest and largest cities in southeastern Europe. 

Following the Slavic migrations to the Balkans postdating the 6th century, Serbs established several states in the early Middle Ages. The Serbian Kingdom obtained recognition by Rome and the Byzantine Empire in 1217, reaching its peak in 1346 as a relatively short-lived Serbian Empire. By the mid-16th century, the entire modern-day Serbia was annexed by the Ottomans, at times interrupted by the Habsburg Empire, which started expanding towards Central Serbia from the end of the 17th century, while maintaining a foothold in modern-day Vojvodina. In the early 19th century, the Serbian Revolution established the nation-state as the region's first constitutional monarchy, which subsequently expanded its territory. Following disastrous casualties in World War I, and the subsequent unification of the former Habsburg crownland of Vojvodina (and other territories) with Serbia, the country co-founded Yugoslavia with other South Slavic peoples, which would exist in various political formations until the Yugoslav Wars of the 1990s. During the breakup of Yugoslavia, Serbia formed a union with Montenegro, which dissolved in 2006. In 2008, the parliament of the province of Kosovo unilaterally declared independence, with mixed responses from the international community.

Serbia is a member of the UN, CoE, OSCE, PfP, BSEC, CEFTA and it is acceding to the WTO. Since 2014 the country has been negotiating its EU accession with perspective of joining the European Union by 2025 and is the only country in the current enlargement agenda which is designated as "free" by Freedom House. Since 2007, Serbia formally adheres to the policy of military neutrality. An upper-middle income economy with a dominant service sector followed by the industrial sector and agriculture, the country ranks high by the Human Development Index (66th), Social Progress Index (45th) as well as the Global Peace Index (54th).

The origin of the name, ""Serbia"" is unclear. Various authors mentioned names of Serbs ( / Срби) and Sorbs (Upper Sorbian: "Serbja"; Lower Sorbian: "Serby") in different variants: Surbii, Suurbi, Serbloi, Zeriuani, Sorabi, Surben, Sarbi, Serbii, Serboi, Zirbi, Surbi, Sorben, etc. These authors used these names to refer to Serbs and Sorbs in areas where their historical (or current) presence was/is not disputed (notably in the Balkans and Lusatia), but there are also sources that mention same or similar names in other parts of the World (most notably in the Asiatic Sarmatia in the Caucasus).

Theoretically, the root *sъrbъ has been variously connected with Russian "paserb" (пасерб, "stepson"), Ukrainian "pryserbytysia" (присербитися, "join in"), Old Indic "sarbh-" ("fight, cut, kill"), Latin "sero" ("make up, constitute"), and Greek "siro" (ειρω, "repeat"). However, Polish linguist Stanisław Rospond (1906–1982) derived the denomination of "Srb" from "srbati" (cf. "sorbo", "absorbo"). Sorbian scholar H. Schuster-Šewc suggested a connection with the Proto-Slavic verb for "to slurp" *sьrb-, with cognates such as "сёрбать" (Russian), "сьорбати" (Ukrainian), "сёрбаць" (Belarusian), "srbati" (Slovak), "сърбам"(Bulgarian) and "серебати" (Old Russian).

From 1945 to 1963, the official name for Serbia was the "People's Republic of Serbia", which became the "Socialist Republic of Serbia" from 1963 to 1990. Since 1990, the official name of the country is the ""Republic of Serbia"".

Archeological evidence of Paleolithic settlements on the territory of present-day Serbia are scarce. A fragment of a human jaw, was found in Sićevo (Mala Balanica) and believed to be up to 525,000—397,000 years old.

Approximately around 6,500 years BC, during the Neolithic, the Starčevo, and Vinča cultures existed in or near modern-day Belgrade and dominated much of the Southeastern Europe, (as well as parts of Central Europe and Asia Minor). Two important local archeological sites from this era, Lepenski Vir and Vinča-Belo Brdo, still exist near the banks of the Danube.

During the Iron Age, Thracians, Dacians, and Illyrians were encountered by the Ancient Greeks during their expansion into the south of modern Serbia in the 4th century BC; the northwesternmost point of Alexander the Great's empire being the town of Kale-Krševica. The Celtic tribe of Scordisci settled throughout the area in the 3rd century BC and formed a tribal state, building several fortifications, including their capital at Singidunum (present-day Belgrade) and Naissos (present-day Niš).

The Romans conquered much of the territory in the 2nd century BC. In 167 BC the Roman province of Illyricum was established; the remainder was conquered around 75 BC, forming the Roman province of Moesia Superior; the modern-day Srem region was conquered in 9 BC; and Bačka and Banat in 106 AD after the Dacian Wars. As a result of this, contemporary Serbia extends fully or partially over several former Roman provinces, including Moesia, Pannonia, Praevalitana, Dalmatia, Dacia and Macedonia.

The chief towns of Upper Moesia (and wider) were: Singidunum (Belgrade), Viminacium (now Old Kostolac), Remesiana (now Bela Palanka), Naissos (Niš), and Sirmium (now Sremska Mitrovica), the latter of which served as a Roman capital during the Tetrarchy. Seventeen Roman Emperors were born in the area of modern-day Serbia, second only to contemporary Italy. The most famous of these was Constantine the Great, the first Christian Emperor, who issued an edict ordering religious tolerance throughout the Empire.

When the Roman Empire was divided in 395, most of Serbia remained under the Eastern Roman Empire, while its northwestern parts were included in the Western Roman Empire. By the early 6th century, South Slavs were present throughout the Byzantine Empire in large numbers.

Serbs, a Slavic tribe that settled the Balkans in the 6th or early 7th century, established the Serbian Principality by the 8th century. It was said in 822 that the Serbs inhabited the greater part of Roman Dalmatia, their territory spanning what is today southwestern Serbia and parts of neighbouring countries. Meanwhile, the Byzantine Empire and Bulgarian Empire held other parts of the territory. Christianity was adopted by the Serbian rulers in ca. 870, and by the mid-10th-century the Serbian state stretched the Adriatic Sea by the Neretva, the Sava, the Morava, and Skadar. Between 1166 and 1371 Serbia was ruled by the Nemanjić dynasty (whose legacy is especially cherished), under whom the state was elevated to a kingdom (and briefly an empire) and Serbian bishopric to an autocephalous archbishopric (through the effort of Sava, the country's patron saint). Monuments of the Nemanjić period survives in many monasteries (several being World Heritage) and fortifications. During these centuries the Serbian state (and influence) expanded significantly. The northern part, Vojvodina, was ruled by the Kingdom of Hungary. The period known as the Fall of the Serbian Empire saw the once-powerful state fragmented into duchies, culminating in the Battle of Kosovo (1389) against the rising Ottoman Empire. The Serbian Despotate was finally conquered by the Ottomans in 1459. The Ottoman threat and eventual conquest saw large migrations of Serbs to the west and north.

After the loss of independence to the Kingdom of Hungary and the Ottoman Empire, Serbia briefly regained sovereignty under Jovan Nenad in the 16th century. Three Habsburg invasions and numerous rebellions constantly challenged Ottoman rule. One famous incident was the Banat Uprising in 1595, which was part of the Long War between the Ottomans and the Habsburgs. The area of modern Vojvodina endured a century-long Ottoman occupation before being ceded to the Habsburg Empire at the end of the 17th century under the Treaty of Karlowitz.

In all Serb lands south of the rivers Danube and Sava, the nobility was eliminated and the peasantry was enserfed to Ottoman masters, while much of the clergy fled or were confined to the isolated monasteries. Under the Ottoman system, Serbs, as Christians, were considered an inferior class of people and subjected to heavy taxes, and a small portion of the Serbian populace experienced Islamisation. The Ottomans abolished the Serbian Patriarchate of Peć (1463), but reestablished it in 1557, providing for limited continuation of Serbian cultural traditions within the empire.

As the Great Serb Migrations depopulated most of southern Serbia, the Serbs sought refuge across the Danube River in Vojvodina to the north and the Military Frontier in the west, where they were granted rights by the Austrian crown under measures such as the "Statuta Wallachorum" of 1630. The ecclesiastical center of the Serbs also moved northwards, to the Metropolitanate of Sremski Karlovci, as the Serbian Patriarchate of Peć was once-again abolished by the Ottomans in 1766. Following several petitions, the Holy Roman Emperor Leopold I formally granted Serbs who wished to leave the right to their autonomous crownland.

In 1718–39, the Habsburg Monarchy occupied Central Serbia and established the "Kingdom of Serbia". Apart from Vojvodina and Northern Belgrade which were absorbed into the Habsburg Empire, Central Serbia was occupied by the Habsburgs again in 1686–91 and in 1788–92.

The Serbian Revolution for independence from the Ottoman Empire lasted eleven years, from 1804 until 1815. The revolution comprised two separate uprisings which gained autonomy from the Ottoman Empire that eventually evolved towards full independence (1835–1867). During the First Serbian Uprising, led by Duke Karađorđe Petrović, Serbia was independent for almost a decade before the Ottoman army was able to reoccupy the country. Shortly after this, the Second Serbian Uprising began. Led by Miloš Obrenović, it ended in 1815 with a compromise between Serbian revolutionaries and Ottoman authorities. Likewise, Serbia was one of the first nations in the Balkans to abolish feudalism. The Convention of Ackerman in 1826, the Treaty of Adrianople in 1829 and finally, the Hatt-i Sharif, recognized the suzerainty of Serbia. The first Serbian Constitution was adopted on 15 February 1835.

Following the clashes between the Ottoman army and Serbs in Belgrade in 1862, and under pressure from the Great Powers, by 1867 the last Turkish soldiers left the Principality, making the country "de facto" independent. By enacting a new constitution without consulting the Porte, Serbian diplomats confirmed the "de facto" independence of the country. In 1876, Serbia declared war on the Ottoman Empire, proclaiming its unification with Bosnia.

The formal independence of the country was internationally recognized at the Congress of Berlin in 1878, which formally ended the Russo-Turkish War; this treaty, however, prohibited Serbia from uniting with Bosnia by placing Bosnia under Austro-Hungarian occupation, alongside the occupation of Sanjak of Novi Pazar. From 1815 to 1903, the Principality of Serbia was ruled by the House of Obrenović, save for the rule of Prince Aleksandar Karađorđević between 1842 and 1858. In 1882, Serbia became a Kingdom, ruled by King Milan I. The House of Karađorđević, descendants of the revolutionary leader Karađorđe Petrović, assumed power in 1903 following the May Overthrow. In the north, the 1848 revolution in Austria led to the establishment of the autonomous territory of Serbian Vojvodina; by 1849, the region was transformed into the Voivodeship of Serbia and Banat of Temeschwar.

In the course of the First Balkan War in 1912, the Balkan League defeated the Ottoman Empire and captured its European territories, which enabled territorial expansion into Raška and Kosovo. The Second Balkan War soon ensued when Bulgaria turned on its former allies, but was defeated, resulting in the Treaty of Bucharest. In two years, Serbia enlarged its territory by 80% and its population by 50%; it also suffered high casualties on the eve of World War I, with around 20,000 dead. Austria-Hungary became wary of the rising regional power on its borders and its potential to become an anchor for unification of all South Slavs, and the relationship between the two countries became tense.
The assassination of Archduke Franz Ferdinand of Austria on 28 June 1914 in Sarajevo by Gavrilo Princip, a member of the Young Bosnia organization, led to Austria-Hungary declaring war on Serbia. In defense of Serbia, and to maintain her status as a Great Power, Russia mobilized its troops, which resulted in Austria-Hungary's ally Germany declaring war on Russia. Serbia won the first major battles of World War I, including the Battle of Cer and Battle of Kolubara – marking the first Allied victories against the Central Powers in World War I.

Despite initial success, it was eventually overpowered by the Central Powers in 1915. Most of its army and some people fled through Albania to Greece and Corfu, suffering immense losses on the way. Serbia was occupied by the Central Powers. After the Central Powers military situation on other fronts worsened, the remains of the Serb army returned east and lead a final breakthrough through enemy lines on 15 September 1918, liberating Serbia and defeating the Austro-Hungarian Empire and Bulgaria. Serbia, with its campaign, was a major Balkan Entente Power which contributed significantly to the Allied victory in the Balkans in November 1918, especially by helping France force Bulgaria's capitulation. Serbia was classified as a "minor Entente power".
Serbia's casualties accounted for 8% of the total Entente military deaths; 58% (243,600) soldiers of the Serbian army perished in the war. The total number of casualties is placed around 700,000, more than 16% of Serbia's prewar size, and a majority (57%) of its overall male population. As the Austro-Hungarian Empire collapsed, the territory of Syrmia united with Serbia on 24 November 1918, followed by Banat, Bačka and Baranja a day later, thereby bringing the entire Vojvodina into the Serb Kingdom. On 26 November 1918, the Podgorica Assembly deposed the House of Petrović-Njegoš and united Montenegro with Serbia. On 1 December 1918, at Krsmanović's House at Terazije, Serbian Prince Regent Alexander of Serbia proclaimed the Kingdom of the Serbs, Croats, and Slovenes under King Peter I of Serbia.

King Peter was succeeded by his son, Alexander, in August 1921. Serb centralists and Croat autonomists clashed in the parliament, and most governments were fragile and short-lived. Nikola Pašić, a conservative prime minister, headed or dominated most governments until his death. King Alexander changed the name of the country to Yugoslavia and changed the internal divisions from the 33 oblasts to nine new banovinas. The effect of Alexander's dictatorship was to further alienate the non-Serbs from the idea of unity.

Alexander was assassinated in Marseille, during an official visit in 1934 by Vlado Chernozemski, member of the IMRO. Alexander was succeeded by his eleven-year-old son Peter II and a regency council was headed by his cousin, Prince Paul. In August 1939 the Cvetković–Maček Agreement established an autonomous Banate of Croatia as a solution to Croatian concerns.

In 1941, in spite of Yugoslav attempts to remain neutral in the war, the Axis powers invaded Yugoslavia. The territory of modern Serbia was divided between Hungary, Bulgaria, Independent State of Croatia (NDH) and Italy (greater Albania and Montenegro), while the remaining part of Serbia was placed under German Military administration, with Serbian puppet governments led by Milan Aćimović and Milan Nedić. The occupied territory was the scene of a civil war between royalist Chetniks commanded by Draža Mihailović and communist partisans commanded by Josip Broz Tito. Against these forces were arrayed Axis auxiliary units of the Serbian Volunteer Corps and the Serbian State Guard. Draginac and Loznica massacre of 2,950 villagers in Western Serbia in 1941 was the first large execution of civilians in occupied Serbia by Germans, with Kragujevac massacre and Novi Sad Raid of Jews and Serbs by Hungarian fascists being the most notorious, with over 3,000 victims in each case. After one year of occupation, around 16,000 Serbian Jews were murdered in the area, or around 90% of its pre-war Jewish population. Many concentration camps were established across the area. Banjica concentration camp was the largest concentration camp, with primary victims being Serbian Jews, Roma, and Serb political prisoners.

During this period, hundreds of thousands of Serbs fled the Axis puppet state known as the Independent State of Croatia and sought refuge in Serbia, seeking to escape the large-scale persecution and genocide of Serbs, Jews, and Roma being committed by the Ustaše regime.

The Republic of Užice was a short-lived liberated territory established by the Partisans and the first liberated territory in World War II Europe, organized as a military mini-state that existed in the autumn of 1941 in the west of occupied Serbia. By late 1944, the Belgrade Offensive swung in favour of the partisans in the civil war; the partisans subsequently gained control of Yugoslavia. Following the Belgrade Offensive, the Syrmian Front was the last major military action of World War II in Serbia. A study by Vladimir Žerjavić estimates total war related deaths in Yugoslavia at 1,027,000, including 273,000 in Serbia. 

The victory of the Communist Partisans resulted in the abolition of the monarchy and a subsequent constitutional referendum. A one-party state was soon established in Yugoslavia by the League of Communists of Yugoslavia, between 60,000 and 70,000 people were killed in Serbia during the communist takeover. All opposition was suppressed and people deemed to be promoting opposition to socialism or promoting separatism were imprisoned or executed for sedition. Serbia became a constituent republic within the SFRY known as the Socialist Republic of Serbia, and had a republic-branch of the federal communist party, the League of Communists of Serbia.

Serbia's most powerful and influential politician in Tito-era Yugoslavia was Aleksandar Ranković, one of the "big four" Yugoslav leaders, alongside Tito, Edvard Kardelj, and Milovan Đilas. Ranković was later removed from the office because of the disagreements regarding Kosovo's nomenklatura and the unity of Serbia. Ranković's dismissal was highly unpopular among Serbs. Pro-decentralization reformers in Yugoslavia succeeded in the late 1960s in attaining substantial decentralization of powers, creating substantial autonomy in Kosovo and Vojvodina, and recognizing a Yugoslav Muslim nationality. As a result of these reforms, there was a massive overhaul of Kosovo's nomenklatura and police, that shifted from being Serb-dominated to ethnic Albanian-dominated through firing Serbs on a large scale. Further concessions were made to the ethnic Albanians of Kosovo in response to unrest, including the creation of the University of Pristina as an Albanian language institution. These changes created widespread fear among Serbs of being treated as second-class citizens.

In 1989, Slobodan Milošević rose to power in Serbia. Milošević promised a reduction of powers for the autonomous provinces of Kosovo and Vojvodina, where his allies subsequently took over power, during the Anti-bureaucratic revolution. This ignited tensions between the communist leadership of the other republics, and awoke nationalism across the country that eventually resulted in its breakup, with Slovenia, Croatia, Bosnia and Herzegovina, Macedonia and Kosovo declaring independence. Serbia and Montenegro remained together as the Federal Republic of Yugoslavia (FRY).

Fueled by ethnic tensions, the Yugoslav Wars erupted, with the most severe conflicts taking place in Croatia and Bosnia, where the large ethnic Serb communities opposed independence from Yugoslavia. The FRY remained outside the conflicts, but provided logistic, military and financial support to Serb forces in the wars. In response, the UN imposed sanctions against Serbia which led to political isolation and the collapse of the economy (GDP was $24 billion in 1990 to under $10 billion in 1993).

Multi-party democracy was introduced in Serbia in 1990, officially dismantling the one-party system. Critics of Milošević claimed that the government continued to be authoritarian despite constitutional changes, as Milošević maintained strong political influence over the state media and security apparatus. When the ruling Socialist Party of Serbia refused to accept its defeat in municipal elections in 1996, Serbians engaged in large protests against the government.

In 1998, peace was broken again, when the situation in Kosovo worsened with continued clashes between the Albanian guerilla Kosovo Liberation Army and Yugoslav security forces. The confrontations led to the short Kosovo War (1998–99), in which NATO intervened, leading to the withdrawal of Serbian forces and the establishment of UN administration in the province.

After presidential elections in September 2000, opposition parties accused Milošević of electoral fraud. A campaign of civil resistance followed, led by the Democratic Opposition of Serbia (DOS), a broad coalition of anti-Milošević parties. This culminated on 5 October when half a million people from all over the country congregated in Belgrade, compelling Milošević to concede defeat. The fall of Milošević ended Yugoslavia's international isolation. Milošević was sent to the International Criminal Tribunal for the former Yugoslavia. The DOS announced that FR Yugoslavia would seek to join the European Union. In 2003, the Federal Republic of Yugoslavia was renamed Serbia and Montenegro; the EU opened negotiations with the country for the Stabilization and Association Agreement. Serbia's political climate remained tense and in 2003, the prime minister Zoran Đinđić was assassinated as result of a plot originating from circles of organized crime and former security officials.

On 21 May 2006, Montenegro held a referendum to determine whether to end its union with Serbia. The results showed 55.4% of voters in favor of independence, which was just above the 55% required by the referendum. On 5 June 2006, the National Assembly of Serbia declared Serbia to be the legal successor to the former state union. The Assembly of Kosovo unilaterally declared independence from Serbia on 17 February 2008. Serbia immediately condemned the declaration and continues to deny any statehood to Kosovo. The declaration has sparked varied responses from the international community, some welcoming it, while others condemned the unilateral move. Status-neutral talks between Serbia and Kosovo-Albanian authorities are held in Brussels, mediated by the EU.

In April 2008 Serbia was invited to join the Intensified Dialogue programme with NATO despite the diplomatic rift with the alliance over Kosovo. Serbia officially applied for membership in the European Union on 22 December 2009, and received candidate status on 1 March 2012, following a delay in December 2011. Following a positive recommendation of the European Commission and European Council in June 2013, negotiations to join the EU commenced in January 2014.

Located at the crossroads between Central and Southern Europe, Serbia is found in the Balkan peninsula and the Pannonian Plain. Serbia lies between latitudes 41° and 47° N, and longitudes 18° and 23° E. The country covers a total of 88,361 km (including Kosovo), which places it at 113th place in the world; with Kosovo excluded, the total area is 77,474 km, which would make it 117th. Its total border length amounts to 2,027 km (Albania 115 km, Bosnia and Herzegovina 302 km, Bulgaria 318 km, Croatia 241 km, Hungary 151 km, Macedonia 221 km, Montenegro 203 km and Romania 476 km). All of Kosovo's border with Albania (115 km), Macedonia (159 km) and Montenegro (79 km) are under control of the Kosovo border police. Serbia treats the 352 km long border between Kosovo and rest of Serbia as an "administrative line"; it is under shared control of Kosovo border police and Serbian police forces, and there are 11 crossing points.

The Pannonian Plain covers the northern third of the country (Vojvodina and Mačva) while the easternmost tip of Serbia extends into the Wallachian Plain. The terrain of the central part of the country, with the region of Šumadija at its heart, consists chiefly of hills traversed by rivers. Mountains dominate the southern third of Serbia. Dinaric Alps stretch in the west and the southwest, following the flow of the rivers Drina and Ibar. The Carpathian Mountains and Balkan Mountains stretch in a north–south direction in eastern Serbia.

Ancient mountains in the southeast corner of the country belong to the Rilo-Rhodope Mountain system. Elevation ranges from the Midžor peak of the Balkan Mountains at (the highest peak in Serbia, excluding Kosovo) to the lowest point of just near the Danube river at Prahovo. The largest lake is Đerdap Lake () and the longest river passing through Serbia is the Danube ().

The climate of Serbia is under the influences of the landmass of Eurasia and the Atlantic Ocean and Mediterranean Sea. With mean January temperatures around , and mean July temperatures of , it can be classified as a warm-humid continental or humid subtropical climate. In the north, the climate is more continental, with cold winters, and hot, humid summers along with well distributed rainfall patterns. In the south, summers and autumns are drier, and winters are relatively cold, with heavy inland snowfall in the mountains.

Differences in elevation, proximity to the Adriatic Sea and large river basins, as well as exposure to the winds account for climate variations. Southern Serbia is subject to Mediterranean influences. The Dinaric Alps and other mountain ranges contribute to the cooling of most of the warm air masses. Winters are quite harsh in the Pešter plateau, because of the mountains which encircle it. One of the climatic features of Serbia is Košava, a cold and very squally southeastern wind which starts in the Carpathian Mountains and follows the Danube northwest through the Iron Gate where it gains a jet effect and continues to Belgrade and can spread as far south as Niš.

The average annual air temperature for the period 1961–1990 for the area with an altitude of up to is . The areas with an altitude of have an average annual temperature of around , and over of altitude around . The lowest recorded temperature in Serbia was on 13 January 1985, Karajukića Bunari in Pešter, and the highest was , on 24 July 2007, recorded in Smederevska Palanka.

Serbia is one of few European countries with "very high risk" exposure to natural hazards (earthquakes, storms, floods, droughts). It is estimated that potential floods, particularly in areas of Central Serbia, threaten over 500 larger settlements and an area of 16,000 square kilometers. The most disastrous were the floods in May 2014, when 57 people died and a damage of over a 1.5 billion euro was inflicted.

Almost all of Serbia's rivers drain to the Black Sea, by way of the Danube river. The Danube, the second largest European river, passes through Serbia with 588 kilometers (21% of its overall length) and represents the largest source of fresh water. It is joined by its biggest tributaries, the Great Morava (longest river entirely in Serbia with 493 km of length), Sava and Tisza rivers. One notable exception is the Pčinja which flows into the Aegean. Drina river forms the natural border between Bosnia and Herzegovina and Serbia, and represents the main kayaking and rafting attraction in both countries.

Due to configuration of the terrain, natural lakes are sparse and small; most of them are located in the lowlands of Vojvodina, like the aeolian lake Palić or numerous oxbow lakes along river flows (like Zasavica and Carska Bara). However, there are numerous artificial lakes, mostly due to hydroelectric dams, the biggest being Đerdap (Iron Gates) on the Danube with 163 km on the Serbian side (a total area of 253 km is shared with Romania) as well as the deepest (with maximum depth of 92 m); Perućac on the Drina, and Vlasina. The largest waterfall, Jelovarnik, located in Kopaonik, is 71 m high. Abundance of relatively unpolluted surface waters and numerous underground natural and mineral water sources of high water quality presents a chance for export and economy improvement; however, more extensive exploitation and production of bottled water began only recently.

With 29.1% of its territory covered by forest, Serbia is considered to be a middle-forested country, compared on a global scale to world forest coverage at 30%, and European average of 35%. The total forest area in Serbia is 2,252,000 ha (1,194,000 ha or 53% are state-owned, and 1,058,387 ha or 47% are privately owned) or 0.3 ha per inhabitant. 

The most common trees are oak, beech, pines and firs. Serbia is a country of rich ecosystem and species diversity – covering only 1.9% of the whole European territory Serbia is home to 39% of European vascular flora, 51% of European fish fauna, 40% of European reptile and amphibian fauna, 74% of European bird fauna, 67% European mammal fauna. Its abundance of mountains and rivers make it an ideal environment for a variety of animals, many of which are protected including wolves, lynx, bears, foxes and stags. There are 17 snake species living all over the country, 8 of them are venomous. Serbia is home to highly protected owl species. In the northernmost part of Vojvodina plain, in the city of Kikinda, a number of endangered 145 long-eared owls is noted, making this town the world's biggest settlement of these species. Serbia is considerably rich with threatened species of bats and butterflies.

Mountain of Tara in western Serbia is one of the last regions in Europe where bears can still live in absolute freedom. Serbia is also home to about 380 species of bird. In Carska Bara, there are over 300 bird species on just a few square kilometers. Uvac Gorge is considered one of the last habitats of the griffon vulture in Europe.

There are 377 protected areas of Serbia, encompassing 4,947 square kilometers or 6.4% of the country. The "Spatial plan of the Republic of Serbia" states that the total protected area should be increased to 12% by 2021. Those protected areas include 5 national parks (Đerdap, Tara, Kopaonik, Fruška Gora and Šar Mountain), 15 nature parks, 15 "landscapes of outstanding features", 61 nature reserves, and 281 natural monuments.

Air pollution is a significant problem in Bor area, due to work of large copper mining and smelting complex, and Pančevo where oil and petrochemical industry is based. Some cities suffer from water supply problems, due to mismanagement and low investments in the past, as well as water pollution (like the pollution of the Ibar River from the Trepča zinc-lead combinate, affecting the city of Kraljevo, or the presence of natural arsenic in underground waters in Zrenjanin).

Poor waste management has been identified as one of the most important environmental problems in Serbia and the recycling is a fledgling activity, with only 15% of its waste being turned back for reuse. The 1999 NATO bombing caused serious damage to the environment, with several thousand tons of toxic chemicals stored in targeted factories and refineries released into the soil and water basins.

Serbia is a parliamentary republic, with the government divided into legislative, executive and judiciary branches.

Serbia had one of the first modern constitutions in Europe, the 1835 Constitution (known as "Sretenje Constitution"), which was at the time considered among the most progressive and liberal constitutions in the world. Since then it has adopted 10 different constitutions. The current constitution was adopted in 2006 in the aftermath of Montenegro independence referendum which by consequence renewed the independence of Serbia itself. The Constitutional Court rules on matters regarding the Constitution.
The President of the Republic ("Predsednik Republike") is the head of state, is elected by popular vote to a five-year term and is limited by the Constitution to a maximum of two terms. In addition to being the commander in chief of the armed forces, the president has the procedural duty of appointing the prime minister with the consent of the parliament, and has some influence on foreign policy.

The Government ("Vlada") is composed of the prime minister and cabinet ministers. The Government is responsible for proposing legislation and a budget, executing the laws, and guiding the foreign and internal policies. The current prime minister is Ana Brnabić of the Serbian Progressive Party.

The National Assembly ("Narodna skupština") is a unicameral legislative body. The National Assembly has the power to enact laws, approve the budget, schedule presidential elections, select and dismiss the Prime Minister and other ministers, declare war, and ratify international treaties and agreements. It is composed of 250 proportionally elected members who serve four-year terms.

The largest political parties in Serbia are the centre-right Serbian Progressive Party, leftist Socialist Party of Serbia and far-right Serbian Radical Party.

Serbia has a three-tiered judicial system, made up of the Supreme Court of Cassation as the court of the last resort, Courts of Appeal as the appellate instance, and Basic and High courts as the general jurisdictions at first instance.

Courts of special jurisdictions are the Administrative Court, commercial courts (including the Commercial Court of Appeal at second instance) and misdemeanor courts (including High Misdemeanor Court at second instance). The judiciary is overseen by the Ministry of Justice. Serbia has a typical civil law legal system.

Law enforcement is the responsibility of the Serbian Police, which is subordinate to the Ministry of the Interior. Serbian Police fields 26,527 uniformed officers. National security and counterintelligence are the responsibility of the Security Intelligence Agency (BIA).

Serbia has established diplomatic relations with 188 UN member states, the Holy See, the Sovereign Military Order of Malta, and the European Union. Foreign relations are conducted through the Ministry of Foreign Affairs. Serbia has a network of 65 embassies and 23 consulates internationally. There are 65 foreign embassies, 5 consulates and 4 liaison offices in Serbia.

Serbian foreign policy is focused on achieving the strategic goal of becoming a member state of the European Union (EU). Serbia started the process of joining the EU by signing of the Stabilisation and Association Agreement on 29 April 2008 and officially applied for membership in the European Union on 22 December 2009. It received a full candidate status on 1 March 2012 and started accession talks on 21 January 2014. The European Commission considers accession possible by 2025.

The province of Kosovo declared independence from Serbia on 17 February 2008, which sparked varied responses from the international community, some welcoming it, while others condemn the unilateral move. In protest, Serbia initially recalled its ambassadors from countries that recognized Kosovo′s independence. The resolution of 26 December 2007 by the National Assembly stated that both the Kosovo declaration of independence and recognition thereof by any state would be gross violation of international law.

Serbia began cooperation and dialogue with NATO in 2006, when the country joined the Partnership for Peace programme and the Euro-Atlantic Partnership Council. The country′s military neutrality was formally proclaimed by a resolution adopted by Serbia′s parliament in December 2007, which makes joining any military alliance contingent on a popular referendum, a stance acknowledged by NATO. On the other hand, Serbia′s relations with Russia are habitually described by mass media as a ″centuries-old religious, ethnic and political alliance″ and Russia is said to have sought to solidify its relationship with Serbia since the imposition of sanctions against Russia in 2014.

The Serbian Armed Forces are subordinate to the Ministry of Defence, and are composed of the Army and the Air Force. Although a landlocked country, Serbia operates a River Flotilla which patrols on the Danube, Sava, and Tisza rivers. The Serbian Chief of the General Staff reports to the Defence Minister. The Chief of Staff is appointed by the President, who is the Commander-in-chief. , Serbia defence budget amounts to $503 million or an estimated 1.4% of the country's GDP.

Traditionally having relied on a large number of conscripts, Serbian Armed Forces went through a period of downsizing, restructuring and professionalisation. Conscription was abolished in 2011. Serbian Armed Forces have 28,000 active troops, supplemented by the "active reserve" which numbers 20,000 members and "passive reserve" with about 170,000.

Serbia participates in the NATO Individual Partnership Action Plan program, but has no intention of joining NATO, due to significant popular rejection, largely a legacy of the NATO bombing of Yugoslavia in 1999. It is an observer member of the Collective Securities Treaty Organization (CSTO) The country also signed the Stability Pact for South Eastern Europe. The Serbian Armed Forces take part in several multinational peacekeeping missions, including deployments in Lebanon, Cyprus, Ivory Coast, and Liberia.

Serbia is a major producer and exporter of military equipment in the region. Defence exports totaled around $483 million in 2016. Serbia exports across the world, notably to the Middle East, Africa, Southeast Asia, and North America. The defence industry has seen significant growth over the years and it continues to grow on a yearly basis.

Serbia is a unitary state composed of municipalities/cities, districts, and two autonomous provinces. In Serbia, excluding Kosovo, there are 145 municipalities ("opštine") and 29 cities ("gradovi"), which form the basic units of local self-government. Apart from municipalities/cities, there are 24 districts ("okruzi", 10 most populated listed below), with the City of Belgrade constituting an additional district. Except for Belgrade, which has an elected local government, districts are regional centers of state authority, but have no powers of their own; they present purely administrative divisions.

Serbia has two autonomous provinces, Vojvodina in the north, and Kosovo and Metohija in the south, while the remaining area, "Central Serbia", never had its own regional authority. Following the Kosovo War, UN peacekeepers entered Kosovo, as per UNSC Resolution 1244. In 2008, Kosovo declared independence. The government of Serbia did not recognize the declaration, considering it illegal and illegitimate.

 census, Serbia (excluding Kosovo) has a total population of 7,186,862 and the overall population density is medium as it stands at 92.8 inhabitants per square kilometer. The census was not conducted in Kosovo which held its own census that numbered their total population at 1,739,825, excluding Serb-inhabited North Kosovo, as Serbs from that area (about 50,000) boycotted the census.

Serbia has been enduring a demographic crisis since the beginning of the 1990s, with a death rate that has continuously exceeded its birth rate, and a total fertility rate of 1.43 children per mother, one of the lowest in the world. 

Serbia subsequently has one of the oldest populations in the world, with the average age of 42.9 years, and its population is shrinking at one of the fastest rates in the world. A fifth of all households consist of only one person, and just one-fourth of four and more persons. Average life expectancy in Serbia at birth is 74.8 years.

During the 1990s, Serbia had the largest refugee population in Europe. Refugees and internally displaced persons (IDPs) in Serbia formed between 7% and 7.5% of its population at the time – about half a million refugees sought refuge in the country following the series of Yugoslav wars, mainly from Croatia (and to a lesser extent from Bosnia and Herzegovina) and the IDPs from Kosovo.

It is estimated that 300,000 people left Serbia during the 1990s, 20% of whom had a higher education.

Serbs with 5,988,150 are the largest ethnic group in Serbia, representing 83% of the total population (excluding Kosovo). With a population of 253,899, Hungarians are the largest ethnic minority in Serbia, concentrated predominantly in northern Vojvodina and representing 3.5% of the country's population (13% in Vojvodina). Romani population stands at 147,604 according to the 2011 census but unofficial estimates place their actual number between 400,000 and 500,000. Bosniaks with 145,278 are concentrated in Raška (Sandžak), in the southwest. Other minority groups include Croats, Slovaks, Albanians, Montenegrins, Vlachs, Romanians, Macedonians and Bulgarians. Chinese, estimated at about 15,000, are the only significant immigrant minority.

The majority of the population, or 59.4%, reside in urban areas and some 16.1% in Belgrade alone. Belgrade is the only city with more than a million inhabitants and there are four more with over 100,000 inhabitants.

The Constitution of Serbia defines it as a secular state with guaranteed religious freedom. Orthodox Christians with 6,079,396 comprise 84.5% of country's population. The Serbian Orthodox Church is the largest and traditional church of the country, adherents of which are overwhelmingly Serbs. Other Orthodox Christian communities in Serbia include Montenegrins, Romanians, Vlachs, Macedonians and Bulgarians.

Roman Catholics number 356,957 in Serbia, or roughly 6% of the population, mostly in Vojvodina (especially its northern part) which is home to minority ethnic groups such as Hungarians, Croats, Bunjevci, as well as to some Slovaks and Czechs.

Protestantism accounts for about 1% of the country's population, chiefly Lutheranism among Slovaks in Vojvodina as well as Calvinism among Reformed Hungarians. Greek Catholic Church is adhered by around 25,000 citizens (0.37% of the population), mostly Rusyns in Vojvodina.

Muslims, with 222,282 or 3% of the population, form the third largest religious group. Islam has a strong historic following in the southern regions of Serbia, primarily in southern Raška. Bosniaks are the largest Islamic community in Serbia; estimates are that around a third of the country's Roma people are Muslim.

There are only 578 Jews in Serbia. Atheists numbered 80,053 or 1.1% of the population and an additional 4,070 declared themselves to be agnostics.

The official language is Serbian, native to 88% of the population. Serbian is the only European language with active digraphia, using both Cyrillic and Latin alphabets. Serbian Cyrillic is designated in the Constitution as the "official script" and was devised in 1814 by Serbian philologist Vuk Karadžić, who based it on phonemic principles., while the Latin alphabet is given status of "script in official use" by the constitution. A survey from 2014 showed that 47% of Serbians favour the Latin alphabet, 36% favour the Cyrillic one and 17% have no preference.

Recognized minority languages are: Hungarian, Bosnian, Slovak, Croatian, Albanian, Romanian, Bulgarian and Rusyn. All these languages are in official use in municipalities or cities where the ethnic minority exceeds 15% of the total population. In Vojvodina, the provincial administration uses, besides Serbian, five other languages (Hungarian, Slovak, Croatian, Romanian and Rusyn).
Serbia has an emerging market economy in upper-middle income range. According to the IMF, Serbian nominal GDP in 2017 is officially estimated at $39.366 billion or $5,599 per capita while purchasing power parity GDP was $106.602 billion or $15,163 per capita. The economy is dominated by services which accounts for 60.8% of GDP, followed by industry with 31.3% of GDP, and agriculture at 7.9% of GDP. The official currency of Serbia is Serbian dinar (ISO code: RSD), and the central bank is National Bank of Serbia. The Belgrade Stock Exchange is the only stock exchange in the country, with market capitalization of $8.65 billion and BELEX15 as the main index representing the 15 most liquid stocks.

The economy has been affected by the global economic crisis. After almost a decade of strong economic growth (average of 4.45% per year), Serbia entered the recession in 2009 with negative growth of −3% and again in 2012 and 2014 with −1% and −1.8%, respectively. As the government was fighting effects of crisis the public debt has more than doubled: from pre-crisis level of just under 30% to about 70% of GDP and trending downwards recently to around 60%. Labor force stands at 3.1 million, of whom 56.2% are employed in services sector, 24.4% are employed in the agriculture and 19.4% are employed in industry. The average monthly net salary in November 2017 stood at 47,575 dinars or $480. The unemployment remains an acute problem, with rate of 13% .

Since 2000, Serbia has attracted over $25 billion in foreign direct investment (FDI). Blue-chip corporations making investments include: Fiat Chrysler Automobiles, Siemens, Bosch, Philip Morris, Michelin, Coca-Cola, Carlsberg and others. In the energy sector, Russian energy giants, Gazprom and Lukoil have made large investments.
Serbia has an unfavorable trade balance: imports exceed exports by 23%. Serbia's exports, however, recorded a steady growth in last couple of years reaching $17 billion in 2017. The country has free trade agreements with the EFTA and CEFTA, a preferential trade regime with the European Union, a Generalized System of Preferences with the United States, and individual free trade agreements with Russia, Belarus, Kazakhstan, and Turkey.

Serbia has very favourable natural conditions (land and climate) for varied agricultural production. It has 5,056,000 ha of agricultural land (0.7 ha per capita), out of which 3,294,000 ha is arable land (0.45 ha per capita). In 2016, Serbia exported agricultural and food products worth $3.2 billion, and the export-import ratio was 178%. Agricultural exports constitute more than one-fifth of all Serbia's sales on the world market. Serbia is one of the largest provider of frozen fruit to the EU (largest to the French market, and 2nd largest to the German market). Agricultural production is most prominent in Vojvodina on the fertile Pannonian Plain. 
Other agricultural regions include Mačva, Pomoravlje, Tamnava, Rasina, and Jablanica.
In the structure of the agricultural production 70% is from the crop field production, and 30% is from the livestock production. Serbia is world's second largest producer of plums (582,485 tons; second to China), second largest of raspberries (89,602 tons, second to Poland), it is also a significant producer of maize (6.48 million tons, ranked 32nd in the world) and wheat (2.07 million tons, ranked 35th in the world). Other important agricultural products are: sunflower, sugar beet, soybean, potato, apple, pork meat, beef, poultry and dairy.

There are 56,000 ha of vineyards in Serbia, producing about 230 million litres of wine annually. Most famous viticulture regions are located in Vojvodina and Šumadija.

The industry is the economy sector which was hardest hit by the UN sanctions and trade embargo and NATO bombing during the 1990s and transition to market economy during the 2000s. The industrial output saw dramatic downsizing: in 2013 it was expected to be only a half of that of 1989. Main industrial sectors include: automotive, mining, non-ferrous metals, food-processing, electronics, pharmaceuticals, clothes.

Automotive industry (with Fiat Chrysler Automobiles as a forebearer) is dominated by cluster located in Kragujevac and its vicinity, and contributes to export with about $2 billion. Serbia's mining industry is comparatively strong: Serbia is the 18th largest producer of coal (7th in the Europe) extracted from large deposits in Kolubara and Kostolac basins; it is also world's 23rd largest (3rd in Europe) producer of copper which is extracted by RTB Bor, a large domestic copper mining company; significant gold extraction is developed around Majdanpek. Serbia notably manufactures intel smartphones named Tesla smartphones.

Food industry is well known both regionally and internationally and is one of the strong points of the economy. Some of the international brand-names established production in Serbia: PepsiCo and Nestlé in food-processing sector; Coca-Cola (Belgrade), Heineken (Novi Sad) and Carlsberg (Bačka Palanka) in beverage industry; Nordzucker in sugar industry. Serbia's electronics industry had its peak in the 1980s and the industry today is only a third of what it was back then, but has witnessed a something of revival in last decade with investments of companies such as Siemens (wind turbines) in Subotica, Panasonic (lighting devices) in Svilajnac, and Gorenje (electrical home appliances) in Valjevo. The pharmaceutical industry in Serbia comprises a dozen manufacturers of generic drugs, of which Hemofarm in Vršac and Galenika in Belgrade, account for 80% of production volume. Domestic production meets over 60% of the local demand.

The energy sector is one of the largest and most important sectors to the country's economy. Serbia is a net exporter of electricity and importer of key fuels (such as oil and gas).

Serbia has an abundance of coal, and significant reserves of oil and gas. Serbia's proven reserves of 5.5 billion tons of coal lignite are the 5th largest in the world (second in Europe, after Germany). Coal is found in two large deposits: Kolubara (4 billion tons of reserves) and Kostolac (1.5 billion tons). Despite being small on a world scale, Serbia's oil and gas resources (77.4 million tons of oil equivalent and 48.1 billion cubic meters, respectively) have a certain regional importance since they are largest in the region of former Yugoslavia as well as the Balkans (excluding Romania). Almost 90% of the discovered oil and gas are to be found in Banat and those oil and gas fields are by size among the largest in the Pannonian basin but are average on a European scale.
The production of electricity in 2015 in Serbia was 36.5 billion kilowatt-hours (KWh), while the final electricity consumption amounted to 35.5 billion kilowatt-hours (KWh). Most of the electricity produced comes from thermal-power plants (72.7% of all electricity) and to a lesser degree from hydroelectric-power plants (27.3%). There are 6 lignite-operated thermal-power plants with an installed power of 3,936 MW; largest of which are 1,502 MW-Nikola Tesla 1 and 1,160 MW-Nikola Tesla 2, both in Obrenovac. Total installed power of 9 hydroelectric-power plants is 2,831 MW, largest of which is Đerdap 1 with capacity of 1,026 MW. In addition to this, there are mazute and gas-operated thermal-power plants with an installed power of 353 MW. The entire production of electricity is concentrated in Elektroprivreda Srbije (EPS), public electric-utility power company.

The current oil production in Serbia amounts to over 1.1 million tons of oil equivalent and satisfies some 43% of country's needs while the rest is imported. National petrol company, Naftna Industrija Srbije (NIS), was acquired in 2008 by Gazprom Neft. The company has completed $700 million modernisation of oil-refinery in Pančevo (capacity of 4.8 million tons) and is currently in the midst of converting oil refinery in Novi Sad into lubricants-only refinery. It also operates network of 334 filling stations in Serbia (74% of domestic market) and additional 36 stations in Bosnia and Herzegovina, 31 in Bulgaria, and 28 in Romania. There are 155 kilometers of crude oil pipelines connecting Pančevo and Novi Sad refineries as a part of trans-national Adria oil pipeline.

Serbia is heavily dependent on foreign sources of natural gas, with only 17% coming from domestic production (totalling 491 million cubic meters in 2012) and the rest is imported, mainly from Russia (via gas pipelines that run through Ukraine and Hungary). Srbijagas, public gas company, operates the natural gas transportation system which comprise 3,177 kilometers of trunk and regional natural gas pipelines and a 450 million cubic meter underground gas storage facility at Banatski Dvor.

Serbia has a strategic transportation location since the country's backbone, Morava Valley, represents by far the easiest route of land travel from continental Europe to Asia Minor and the Near East.

Serbian road network carries the bulk of traffic in the country. Total length of roads is 45,419 km of which 782 km are "class-Ia state roads" (i.e. motorways); 4,481 km are "class-Ib state roads" (national roads); 10,941 km are "class-II state roads" (regional roads) and 23,780 km are "municipal roads". The road network, except for the most of class-Ia roads, are of comparatively lower quality to the Western European standards because of lack of financial resources for their maintenance in the last 20 years.

There are currently 124 kilometers of motorways under construction: two sections 34 km-long of the A1 motorway (from south of Leskovac to Bujanovac), 67 km-long segment of A2 (between Belgrade and Ljig), and 23 kilometers on the A4 (east of Niš to the Bulgarian border). Coach transport is very extensive: almost every place in the country is connected by bus, from largest cities to the villages; in addition there are international routes (mainly to countries of Western Europe with large Serb diaspora). Routes, both domestic and international, are served by more than 100 bus companies, biggest of which are Lasta and Niš-Ekspres. , there were 1,833,215 registered passenger cars or 1 passenger car per 3.8 inhabitants.

Serbia has 3,819 kilometers of rail tracks, of which 1,279 are electrified and 283 kilometers are double-track railroad. The major rail hub is Belgrade (and to a lesser degree Niš), while the most important railroads include: Belgrade–Bar (Montenegro), Belgrade–Šid–Zagreb (Croatia)/Belgrade–Niš–Sofia (Bulgaria) (part of Pan-European Corridor X), Belgrade–Subotica–Budapest (Hungary) and Niš–Thessaloniki (Greece). Although still a major mode of freight transportation, railroads face increasing problems with the maintenance of the infrastructure and lowering speeds. All rail services are operated by public rail company, Serbian Railways.
There are only two airports with regular passenger traffic: Belgrade Nikola Tesla Airport served almost 5 million passengers in 2016, and is a hub of flagship carrier Air Serbia which carried some 2.6 million passengers in 2016. Niš Constantine the Great Airport is mainly catering low-cost airlines.
Serbia has a developed inland water transport since there are 1,716 kilometers of navigable inland waterways (1,043 km of navigable rivers and 673 km of navigable canals), which are almost all located in northern third of the country. The most important inland waterway is the Danube (part of Pan-European Corridor VII). Other navigable rivers include Sava, Tisza, Begej and Timiş River, all of which connect Serbia with Northern and Western Europe through the Rhine–Main–Danube Canal and North Sea route, to Eastern Europe via the Tisza, Begej and Danube Black Sea routes, and to Southern Europe via the Sava river. More than 2 million tons of cargo were transported on Serbian rivers and canals in 2016 while the largest river ports are: Novi Sad, Belgrade, Pančevo, Smederevo, Prahovo and Šabac.

Fixed telephone lines connect 81% of households in Serbia, and with about 9.1 million users the number of cellphones surpasses the total population of by 28%. The largest mobile operator is Telekom Srbija with 4.2 million subscribers, followed by Telenor with 2.8 million users and Vip mobile with about 2 million. Some 58% of households have fixed-line (non-mobile) broadband Internet connection while 67% are provided with pay television services (i.e. 38% cable television, 17% IPTV, and 10% satellite). Digital television transition has been completed in 2015 with DVB-T2 standard for signal transmission.

Serbia is not a mass-tourism destination but nevertheless has a diverse range of touristic products. In 2017, total of over 3 million tourists were recorded in accommodations, of which some 1.5 million were foreign. Foreign exchange earnings from tourism were estimated at $1.44 billion.

Tourism is mainly focused on the mountains and spas of the country, which are mostly visited by domestic tourists, as well as Belgrade and, to a lesser degree, Novi Sad, which are preferred choices of foreign tourists (almost two-thirds of all foreign visits are made to these two cities). The most famous mountain resorts are Kopaonik, Stara Planina, and Zlatibor. There are also many spas in Serbia, the biggest of which are Vrnjačka Banja, Soko Banja, and Banja Koviljača. City-break and conference tourism is developed in Belgrade and Novi Sad. Other touristic products that Serbia offer are natural wonders like Đavolja varoš, Christian pilgrimage to the many Orthodox monasteries across the country and the river cruising along the Danube. There are several internationally popular music festivals held in Serbia, such as EXIT (with 25–30,000 foreign visitors coming from 60 different countries) and the Guča trumpet festival.

According to 2011 census, literacy in Serbia stands at 98% of population while computer literacy is at 49% (complete computer literacy is at 34.2%). Same census showed the following levels of education: 16.2% of inhabitants have higher education (10.6% have bachelors or master's degrees, 5.6% have an associate degree), 49% have a secondary education, 20.7% have an elementary education, and 13.7% have not completed elementary education.

Education in Serbia is regulated by the Ministry of Education and Science. Education starts in either preschools or elementary schools. Children enroll in elementary schools at the age of seven. Compulsory education consists of eight grades of elementary school. Students have the opportunity to attend gymnasiums and vocational schools for another four years, or to enroll in vocational training for 2 to 3 years. Following the completion of gymnasiums or vocational schools, students have the opportunity to attend university. Elementary and secondary education are also available in languages of recognised minorities in Serbia, where classes are held in Hungarian, Slovak, Albanian, Romanian, Rusyn, Bulgarian as well as Bosnian and Croatian languages.

There are 17 universities in Serbia (eight public universities with a total number of 85 faculties and nine private universities with 51 faculties). In 2010/2011 academic year, 181,362 students attended 17 universities (148,248 at public universities and some 33,114 at private universities) while 47,169 attended 81 "higher schools". Public universities in Serbia are: the University of Belgrade (oldest, founded in 1808, and largest university with 89,827 undergraduates and graduates), University of Novi Sad (founded in 1960 and with student body of 47,826), University of Niš (founded in 1965; 27,000 students), University of Kragujevac (founded in 1976; 14,000 students), University of Priština – Kos. Mitrovica, Public University of Novi Pazar as well as two specialist universities – University of Arts and University of Defence. Largest private universities include John Naisbitt University and Singidunum University, both in Belgrade, and Educons University in Novi Sad. Public universities tend to be of a better quality and therefore more renowned than private ones. The University of Belgrade (placed in 301–400 bracket on 2013 Shanghai Ranking of World Universities, being best-placed university in Southeast Europe after those in Athens and Thessaloniki) and University of Novi Sad are generally considered as the best institutions of higher learning in the country.

Serbia spent 0.64% of GDP on scientific research in 2012, which is one of the lowest R&D budgets in Europe. Serbia has a long history of excellence in maths and computer sciences which has created a strong pool of engineering talent, although economic sanctions during the 1990s and chronic underinvestment in research forced many scientific professionals to leave the country. Nevertheless, there are several areas in which Serbia still excels such as growing information technology sector, which includes software development as well as outsourcing. It generated $200 million in exports in 2011, both from international investors and a significant number of dynamic homegrown enterprises. In 2005 the global technology giant, Microsoft, founded the Microsoft Development Center, only its fourth such centre in the world.
Among the scientific institutes operating in Serbia, the largest are the Mihajlo Pupin Institute and Vinča Nuclear Institute, both in Belgrade. The Serbian Academy of Sciences and Arts is a learned society promoting science and arts from its inception in 1841. With a strong science and technological ecosystem, Serbia has produced a number of renowned scientists that have greatly contributed to the field of science and technology.

For centuries straddling the boundaries between East and West, the territory of Serbia had been divided among the Eastern and Western halves of the Roman Empire; then between Byzantium and the Kingdom of Hungary; and in the Early modern period between the Ottoman Empire and the Habsburg Empire. These overlapping influences have resulted in cultural varieties throughout Serbia; its north leans to the profile of Central Europe, while the south is characteristic of the wider Balkans and even the Mediterranean. The Byzantine influence on Serbia was profound, firstly through the introduction of Eastern Christianity (Orthodoxy) in the Early Middle Ages. The Serbian Orthodox Church has had an enduring status in Serbia, with the many Serbian monasteries constituting the most valuable cultural monuments left from Serbia in the Middle Ages. Serbia has seen influences of Republic of Venice as well, mainly though trade, literature and romanesque architecture.

Serbia has five cultural monuments inscribed in the list of UNESCO World Heritage: the early medieval capital Stari Ras and the 13th-century monastery Sopoćani; the 12th-century Studenica monastery; the Roman complex of Gamzigrad–Felix Romuliana; medieval tombstones Stećci; and finally the endangered Medieval Monuments in Kosovo (the monasteries of Visoki Dečani, Our Lady of Ljeviš, Gračanica and Patriarchal Monastery of Peć).

There are two literary monuments on UNESCO's Memory of the World Programme: the 12th-century "Miroslav Gospel", and scientist Nikola Tesla's valuable archive. The "slava" (patron saint veneration) is inscribed on UNESCO Intangible Cultural Heritage Lists. The Ministry of Culture and Information is tasked with preserving the nation's cultural heritage and overseeing its development. Further activities supporting development of culture are undertaken at local government level.

Traces of Roman and early Byzantine Empire architectural heritage are found in many royal cities and palaces in Serbia, like Sirmium, Felix Romuliana and Justiniana Prima.

Serbian monasteries are the pinnacle of Serbian medieval art. At the beginning, they were under the influence of Byzantine Art which was particularly felt after the fall of Constantinople in 1204, when many Byzantine artists fled to Serbia. The most noted of these monasteries is Studenica (built around 1190). It was a model for later monasteries, like the Mileševa, Sopoćani, Žiča, Gračanica and Visoki Dečani. In the end of 14th and the 15th centuries, autochotonous architectural style known as Morava style evolved in area around Morava Valley. A characteristic of this style was the wealthy decoration of the frontal church walls. Examples of this include Manasija, Ravanica and Kalenić monasteries. 

Icons and fresco paintings are often considered the peak of Serbian art. The most famous frescos are White Angel (Mileševa monastery), "Crucifixion" (Studenica monastery) and "Dormition of the Virgin" (Sopoćani).

Country is dotted with many well-preserved medieval fortifications and castles such as Smederevo Fortress (largest lowland fortress in Europe), Golubac, Maglič, Soko grad, Ostrvica and Ram.

During the time of Ottoman occupation, Serbian art was virtually non-existent, with the exception of several Serbian artists who lived in the lands ruled by the Habsburg Monarchy. Traditional Serbian art showed some Baroque influences at the end of the 18th century as shown in the works of Nikola Nešković, Teodor Kračun, Zaharije Orfelin and Jakov Orfelin.

Serbian painting showed the influence of Biedermeier, Neoclassicism and Romanticism during the 19th century. The most important Serbian painters of the first half of the 20th century were Paja Jovanović and Uroš Predić of Realism, Cubist Sava Šumanović, Milena Pavlović-Barili and Nadežda Petrović of Impressionism, Expressionist Milan Konjović. Noted painters of the second half of 20th century include Marko Čelebonović, Petar Lubarda, Milo Milunović, and Vladimir Veličković.

Anastas Jovanović was one of the earliest photographes in the world, while Marina Abramović is one of the world leading performance artists. Pirot carpet is known as one of the most important traditional handicrafts in Serbia.

There are around 100 art museums in Serbia, of which the most prominent is the National Museum of Serbia, founded in 1844; it houses one of the largest art collections in the Balkans with more than 400,000 exhibits, over 5,600 paintings and 8,400 drawings and prints, including many foreign masterpiece collections. Other art museums of note are Museum of Contemporary Art in Belgrade and Museum of Vojvodina in Novi Sad.

The beginning of Serbian literacy dates back to the activity of the brothers Cyril and Methodius in the Balkans. Monuments of Serbian literacy from the early 11th century can be found, written in Glagolitic. Starting in the 12th century, books were written in Cyrillic. From this epoch, the oldest Serbian Cyrillic book editorial are the Miroslav Gospels from 1186. "The Miroslav Gospels" are considered to be the oldest book of Serbian medieval history and as such has entered UNESCO's Memory of the World Register.

Notable medieval authors include Saint Sava, Jefimija, Stefan Lazarević, Constantine of Kostenets and others. Due to Ottoman occupation, when every aspect of formal literacy stopped, Serbia stayed excluded from the entire Renaissance flow in Western culture. However, the tradition of oral story-telling blossomed, shaping itself through epic poetry inspired by at the times still recent Kosovo battle and folk tales deeply rooted in Slavic mythology. Serbian epic poetry in those times has seen as the most effective way in preserving the national identity. The oldest known, entirely fictional poems, make up the "Non-historic cycle"; this one is followed by poems inspired by events before, during and after Kosovo Battle. The special cycles are dedicated to Serbian legendary hero, Marko Kraljević, then about hajduks and uskoks, and the last one dedicated to the liberation of Serbia in 19th century. Some of the best known folk ballads are "The Death of the Mother of the Jugović Family" and The Mourning Song of the Noble Wife of the Asan Aga (1646), translated into European languages by Goethe, Walter Scott, Pushkin and Mérimée. The most notable tale from Serbian folklore is The Nine Peahens and the Golden Apples.

Baroque trends in Serbian literature emerged in the late 17th century. Notable Baroque-influenced authors were Gavril Stefanović Venclović, Jovan Rajić, Zaharije Orfelin, Andrija Zmajević and others. Dositej Obradović was the most prominent figure of the Age of Enlightenment, while the most notable Classicist writer was Jovan Sterija Popović, although his works also contained elements of Romanticism. In the era of national revival, in the first half of the 19th century, Vuk Stefanović Karadžić collected Serbian folk literature, and reformed the Serbian language and spelling, paving the way for Serbian Romanticism. The first half of the 19th century was dominated by Romanticism, with Branko Radičević, Đura Jakšić, Jovan Jovanović Zmaj and Laza Kostić being the most notable representatives, while the second half of the century was marked by Realist writers such as Milovan Glišić, Laza Lazarević, Simo Matavulj, Stevan Sremac, Vojislav Ilić, Branislav Nušić, Radoje Domanović and Borisav Stanković.

The 20th century was dominated by the prose writers Meša Selimović ("Death and the Dervish"), Miloš Crnjanski ("Migrations"), Isidora Sekulić ("The Cronicle of a Small Town Cemetery"), Branko Ćopić ("Eagles Fly Early"), Borislav Pekić ("The Time of Miracles"), Danilo Kiš ("The Encyclopedia of the Dead"), Dobrica Ćosić ("The Roots"), Aleksandar Tišma, Milorad Pavić and others. Pavić is the most widely acclaimed Serbian author of the beginning of the 21st century, most notably for his "Dictionary of the Khazars" "(Хазарски речник/Hazarski rečnik)", which has been translated into 24 languages. Notable poets include Milan Rakić, Jovan Dučić, Vladislav Petković Dis, Rastko Petrović, Stanislav Vinaver, Dušan Matić, Branko Miljković, Vasko Popa, Oskar Davičo, Miodrag Pavlović, and Stevan Raičković. Notable contemporary authors include David Albahari, Svetislav Basara, Goran Petrović, Gordana Kuić, Vuk Drašković, and Vladislav Bajac.

Ivo Andrić ("The Bridge on the Drina") is possibly the best-known Serbian author,; he was awarded the Nobel Prize in Literature in 1961. The most beloved face of Serbian literature was Desanka Maksimović, who for seven decades remained "the leading lady of Yugoslav poetry". She is honored with statues, and postage stamps, and streets are named for her.
There are 551 public libraries biggest of which are: National Library of Serbia in Belgrade with funds of about 5 million volumes, and Matica Srpska (oldest Serbian cultural institution, founded in 1826) in Novi Sad with nearly 3.5 million volumes. In 2010, there were 10,989 books and brochures published. The book publishing market is dominated by several major publishers such as Laguna and Vulkan (both of which operate their own bookstore chains) and the industry's centerpiece event, annual Belgrade Book Fair, is the most visited cultural event in Serbia with 158,128 visitors in 2013. The highlight of the literary scene is awarding of NIN Prize, given every January since 1954 for the best newly published novel in Serbian language (during times of Yugoslavia, in Serbo-Croatian language).

Composer and musicologist Stevan Stojanović Mokranjac is considered the founder of modern Serbian music. The Serbian composers of the first generation Petar Konjović, Stevan Hristić, and Miloje Milojević maintained the national expression and modernized the romanticism into the direction of impressionism. Other famous classical Serbian composers include Isidor Bajić, Stanislav Binički and Josif Marinković. There are three opera houses in Serbia: Opera of the National Theatre and Madlenianum Opera, both in Belgrade, and Opera of the Serbian National Theatre in Novi Sad. Four symphonic orchestra operate in the country: Belgrade Philharmonic Orchestra, Niš Symphony Orchestra, Symphonic Orchestra of Radio Television of Serbia, and Novi Sad Philharmonic Orchestra. The Choir of Radio Television of Serbia is a leading vocal ensemble in the country. The BEMUS is one of the most prominent classical music festivals in the South East Europe.

Traditional Serbian music includes various kinds of bagpipes, flutes, horns, trumpets, lutes, psalteries, drums and cymbals. The "kolo" is the traditional collective folk dance, which has a number of varieties throughout the regions. The most popular are those from Užice and Morava region. Sung epic poetry has been an integral part of Serbian and Balkan music for centuries. In the highlands of Serbia these long poems are typically accompanied on a one-string fiddle called the "gusle", and concern themselves with themes from history and mythology. There are records of "gusle" being played at the court of the 13th-century King Stefan Nemanjić.

Pop music has mainstream popularity. Željko Joksimović won second place at the 2004 Eurovision Song Contest and Marija Šerifović managed to win the 2007 Eurovision Song Contest with the song "Molitva", and Serbia was the host of the 2008 edition of the contest. Most popular pop singers include likes of Đorđe Balašević, Goca Tržan, Zdravko Čolić, Aleksandra Radović, Vlado Georgiev, Jelena Tomašević and Nataša Bekvalac among others.

The Serbian rock which was during the 1960s, 1970s and 1980s part of former Yugoslav rock scene, used to be well developed, featuring various rock genres, and was well covered in the media, which included numerous magazines, radio and TV shows. During the 1990s and 2000s popularity of rock music declined in Serbia, and although several major mainstream acts managed to sustain their popularity, an underground and independent music scene developed. The 2000s saw a revival of the mainstream scene and the appearance of a large number of notable acts. The most notable Serbian rock acts include Bajaga i Instruktori, Disciplina Kičme, Ekatarina Velika, Električni Orgazam, Eva Braun, Kerber, Neverne Bebe, Partibrejkers, Ritam Nereda, Orthodox Celts, Rambo Amadeus, Riblja Čorba, S.A.R.S., Smak, Van Gogh, YU Grupa and others.

Folk music in its original form has been a prominent music style since World War One following the early success of Sofka Nikolić. The music has been further promoted by Danica Obrenić, Anđelija Milić, Nada Mamula, and even later, during 60s and 70s, with stars like Silvana Armenulić, Toma Zdravković, Lepa Lukić, Vasilija Radojčić, Vida Pavlović and Gordana Stojićević.

Turbo-folk music is subgenre that has developed in Serbia in the late 1980s and the beginning of the 1990s and has since enjoyed an immense popularity through acts of Dragana Mirković, Zorica Brunclik, Šaban Šaulić, Ana Bekuta, Sinan Sakić, Vesna Zmijanac, Mile Kitić, Snežana Đurišić, Šemsa Suljaković, and Nada Topčagić. It is a blend of folk music with pop and/or dance elements and can be seen as a result of the urbanization of folk music. In recent period turbo-folk featured even more pop music elements, and some of the performers were labeled as pop-folk. The most famous among them are Ceca (often considered to be the biggest music star of Serbia), Jelena Karleuša, Aca Lukas, Seka Aleksić, Dara Bubamara, Indira Radić, Saša Matić, Viki Miljković, Stoja and Lepa Brena, arguably the most prominent performer of former Yugoslavia.

Balkan Brass, or "truba" ("trumpet") is a popular genre, especially in Central and Southern Serbia where Balkan Brass originated. The music has its tradition from the First Serbian Uprising. The trumpet was used as a military instrument to wake and gather soldiers and announce battles, the trumpet took on the role of entertainment during downtime, as soldiers used it to transpose popular folk songs. When the war ended and the soldiers returned to the rural life, the music entered civilian life and eventually became a music style, accompanying births, baptisms, weddings, and funerals. There are two main varieties of this genre, one from Western Serbia and the other from Southern Serbia. The best known Serbian Brass musician is Boban Marković, also one of the biggest names in the world of modern brass band bandleaders.

Most popular music festival are Guča Trumpet Festival with over 300,000 annual visitors and EXIT in Novi Sad ("The best European festival" in 2007 by UK Festival Awards and Yourope – the European Association of the 40 largest festivals in Europe) with 200,000 visitors in 2013. Other festivals include Nišville Jazz Festival in Niš and Gitarijada rock festival in Zaječar.

Serbia has a well-established theatrical tradition with Joakim Vujić considered the founder of modern Serbian theater. Serbia has 38 professional theatres, the most important of which are National Theatre in Belgrade, Serbian National Theatre in Novi Sad, National Theatre in Subotica, National Theatre in Niš and Knjaževsko-srpski teatar in Kragujevac (the oldest theatre in Serbia, established in 1835). The Belgrade International Theatre Festival – BITEF, founded in 1967, is one of the oldest theater festivals in the world, and it has become one of the five biggest European festivals. Sterijino pozorje is, on the other hand, festival showcasing national drama plays. The most important Serbian playwrighters were Jovan Sterija Popović and Branislav Nušić, while today renowned names are Dušan Kovačević and Biljana Srbljanović.

The Serbian cinema is one of the most dynamic smaller European cinematographies. Serbia's film industry is heavily subsidised by the government, mainly through grants approved by the Film Centre of Serbia. In 2011, there were 17 domestic feature films produced. There are 22 operating cinemas in the country, of which 12 are multiplexes, with total attendance exceeding 2.6 million and comparatively high percentage of 32.3% of total sold tickets for domestic films. Modern PFI Studios located in Šimanovci is nowadays Serbia's only film studio complex; it consists of 9 state-of-the-art sound stages and attracts mainly international productions, primarily American and West European. The Yugoslav Film Archive used to be former Yugoslavia's and now is Serbia national film archive – with over 95 thousand film prints, it is among five largest film archives in the world.

Serbian cinema dates back to 1896 with the release of the oldest movie in the Balkans, "The Life and Deeds of the Immortal Vožd Karađorđe", a biography about Serbian revolutionary leader, Karađorđe.

The most famous Serbian filmmaker is Emir Kusturica who won two Golden Palms for Best Feature Film at the Cannes Film Festival, for "When Father Was Away on Business" in 1985 and then again for "Underground" in 1995. Other renowned directors include Goran Paskaljević, Dušan Makavejev, Želimir Žilnik, Goran Marković, Srđan Dragojević and Srdan Golubović among others. Steve Tesich, Serbian-American screenwriter, won the Academy Award for Best Original Screenplay in 1979 for the movie Breaking Away.

Some of the most prominent movie stars in Serbia have left celebrated heritage in cinematography of Yugoslavia as well. Notable mentions are Zoran Radmilović, Pavle Vuisić, Radmila Savićević, Olivera Marković, Mija Aleksić, Miodrag Petrović Čkalja, Ružica Sokić, Velimir Bata Živojinović, Danilo Bata Stojković, Seka Sablić, Olivera Katarina, Dragan Nikolić, Mira Stupica, Nikola Simić, Bora Todorović, and others. Milena Dravić is the most celebrated actress in Serbian cinematography. The actress has won Best Actress Award on Cannes Film Festival in 1980.

The freedom of the press and the freedom of speech are guaranteed by the constitution of Serbia. Serbia is ranked 54th out of 180 countries in the 2014 Press Freedom Index report compiled by Reporters Without Borders. Both reports noted that media outlets and journalists continue to face partisan and government pressure over editorial policies. Also, the media are now more heavily dependent on advertising contracts and government subsidies to survive financially.

According to AGB Nielsen Research in 2009, Serbs on average watch five hours of television per day, making it the highest average in Europe. There are seven nationwide free-to-air television channels, with public broadcaster Radio Television of Serbia (RTS) operating three (RTS1, RTS2 and RTS3) and remaining four are private broadcasters: Pink, Happy TV, Prva, and O2.TV. Viewing shares for these channels in 2016 were as follows: 20.2% for RTS1, 14.1% for Pink, 9.4% for Happy TV, 9.0% for Prva, 4.7% for O2.TV, and 2.5% for RTS2. There are 28 regional television channels and 74 local television channels. Besides terrestrial channels there are dozens Serbian television channels available only on cable or satellite.

There are 247 radio stations in Serbia. Out of these, six are radio stations with national coverage, including two of public broadcaster Radio Television of Serbia (Radio Belgrade 1 and Radio Belgrade 2/Radio Belgrade 3) and four private ones (Radio S1, Radio S2, Play Radio, and Radio Hit FM). Also, there are 34 regional stations and 207 local stations.

There are 305 newspapers published in Serbia of which 12 are daily newspapers. Dailies "Politika" and "Danas" are Serbia's papers of record, former being the oldest newspaper in the Balkans, founded in 1904. Highest circulation newspapers are tabloids "Večernje Novosti", "Blic", "Kurir", and "Informer", all with more than 100,000 copies sold. There are one daily newspaper devoted to sports – "Sportski žurnal", one business daily "Privredni pregled", two regional newspapers ("Dnevnik" published in Novi Sad and "Narodne novine" from Niš), and one minority-language daily ("Magyar Szo" in Hungarian, published in Subotica).

There are 1,351 magazines published in the country. Those include weekly news magazines "NIN", "Vreme" and "Nedeljnik", popular science magazine of "Politikin Zabavnik", women's "Lepota & Zdravlje", auto magazine "SAT revija", IT magazine "Svet kompjutera". In addition, there is a wide selection of Serbian editions of international magazines, such as "Cosmopolitan", "Elle", "Grazia", "Men's Health", "National Geographic", "Le Monde diplomatique", "Playboy", "Hello!" and others.

There are two main news agencies, Beta and Fonet.

, out of 432 web-portals (mainly on the .rs domain) the most visited are online editions of printed dailies Blic and Kurir, news web-portal B92, and classifieds KupujemProdajem.

Serbian cuisine is largely heterogeneous, sharing characteristics of the Balkans (especially former Yugoslavia), the Mediterranean (Greek in particular), Turkish, and Central European (especially Austrian and Hungarian) cuisines. Food is very important in Serbian social life, particularly during religious holidays such as Christmas, Easter and feast days i.e. slava.

Staples of the Serbian diet include bread, meat, fruits, vegetables, and dairy products. Bread is the basis of all Serbian meals, and it plays an important role in Serbian cuisine and can be found in religious rituals. A traditional Serbian welcome is to offer bread and salt to guests. Meat is widely consumed, as is fish. Serbian specialties include ćevapčići (caseless sausages made of minced meat, which is always grilled and seasoned), pljeskavica, sarma, kajmak (a dairy product similar to clotted cream), gibanica (cheese and kajmak pie), ajvar (a roasted red pepper spread), proja (cornbread), and kačamak (corn-flour porridge).

Serbians claim their country as the birthplace of rakia ("rakija"), a highly alcoholic drink primarily distilled from fruit. Rakia in various forms is found throughout the Balkans, notably in Bulgaria, Croatia, Slovenia, Montenegro, Hungary and Turkey. Slivovitz ("šljivovica"), a plum brandy, is a type of rakia which is considered the national drink of Serbia.

Sports play an important role in Serbian society, and the country has a strong sporting history. The most popular sports in Serbia are football, basketball, tennis, volleyball, water polo and handball.

Professional sports in Serbia are organized by sporting federations and leagues (in case of team sports). One of particularities of Serbian professional sports is existence of many multi-sports clubs (called "sports societies"), biggest and most successful of which are Red Star, Partizan, and Beograd in Belgrade, Vojvodina in Novi Sad, Radnički in Kragujevac, Spartak in Subotica.
Football is the most popular sport in Serbia, and the Football Association of Serbia with 146,845 registered players, is the largest sporting association in the country. Dragan Džajić was officially recognized as "the best Serbian player of all times" by the Football Association of Serbia, and more recently the likes of Nemanja Vidić, Dejan Stanković and Branislav Ivanović play for the elite clubs of Europe, developing the nation's reputation as one of the world's biggest exporters of footballers. 

The Serbia national football team lacks relative success although it qualified for three of the last four FIFA World Cups. Serbia national youth football teams have won 2013 U-19 European Championship and 2015 U-20 World Cup. The two main football clubs in Serbia are Red Star (winner of the 1991 European Cup) and Partizan (finalist of the 1966 European Cup), both from Belgrade. The rivalry between the two clubs is known as the "Eternal Derby", and is often cited as one of the most exciting sports rivalries in the world.

Serbia is one of the traditional powerhouses of world basketball, as Serbia men's national basketball team have won two World Championships (in 1998 and 2002), three European Championships (1995, 1997, and 2001) and two Olympic silver medals (in 1996 and 2016) as well. The women's national basketball team won the European Championship in 2015 and Olympic bronze medal in 2016. A total of 31 Serbian players have played in the NBA in last two decades, including Predrag "Peja" Stojaković (three-time NBA All-Star) and Vlade Divac (2001 NBA All-Star and FIBA Hall of Famer). The renowned "Serbian coaching school" produced many of the most successful European basketball coaches of all times, such as Željko Obradović, who won a record 9 Euroleague titles as a coach. KK Partizan basketball club was the 1992 European champion.

Recent success of Serbian tennis players has led to an immense growth in the popularity of tennis in the country. Novak Đoković, twelve-time Grand Slam champion, finished in 2011, 2012, 2014 and 2015 as No. 1 in the world. Ana Ivanovic (champion of 2008 French Open) and Jelena Janković were both ranked No. 1 in the WTA Rankings. There were two No. 1 ranked-tennis double players as well: Nenad Zimonjić (three-time men's double and four-time mixed double Grand Slam champion) and Slobodan Živojinović. The Serbia men's tennis national team won the 2010 Davis Cup while Serbia women's tennis national team reached the final at 2012 Fed Cup.

Serbia is one of the leading volleyball countries in the world. Its men's national team won the gold medal at 2000 Olympics, and has won the European Championship twice. The women's national volleyball team won the European Championship twice as well as Olympic silver medal in 2016.

The Serbia men's national water polo team is the second most successful national team after Hungary, having won Olympic gold medal in 2016, three World Championships (2005, 2009 and 2015), and six European Championships in 2001, 2003, 2006, 2012, 2014 and 2016 respectively. VK Partizan has won a joint-record seven European champion titles.

Other noted Serbian athletes include: swimmers Milorad Čavić (2009 World champion on 50 meters butterfly and silver medalist on 100 meters butterfly as well as 2008 Olympic silver medalist on 100 meters butterfly in historic race with American swimmer Michael Phelps) and Nađa Higl (2009 World champion in 200 meters breaststroke – the first Serbian woman to become a world champion in swimming); track and field athlete Ivana Španović (long-jumper; 2016 European champion and bronze medalist at the 2016 Olympics); wrestler Davor Štefanek (2016 Olympic gold medalist), and taekwondoist Milica Mandić (2012 Olympic gold medalist).

Serbia has hosted several major sport competitions in the last ten years, including the 2005 Men's European Basketball Championship, 2005 Men's European Volleyball Championship, 2006 and 2016 Men's European Water Polo Championships, 2009 Summer Universiade, 2012 European Men's Handball Championship, and 2013 World Women's Handball Championship. The most important annual sporting events held in the country are Belgrade Marathon and Tour de Serbie cycling race.

The public holidays in Serbia are defined by the "Law of national and other holidays in the Republic of Serbia".


Sources:


</doc>
<doc id="29266" url="https://en.wikipedia.org/wiki?curid=29266" title="Relationship between religion and science">
Relationship between religion and science

Various aspects of the relationship between religion and science have been addressed by modern historians of science and religion, philosophers, theologians, scientists, and others from various geographical regions and cultures. Even though the ancient and medieval worlds did not have conceptions resembling the modern understandings of "science" and "religion", certain elements of these modern ideas are found throughout time. It was in the 19th century when the phrases "religion and science" or "science and religion" first emerged in literature. This coincided with the refining of "science", from "natural philosophy", and "religion" as distinct concepts in the last few centuries partly due to professionalization of the sciences, the Protestant Reformation, colonization, and globalization. Since then, many have characterized the relationship as either conflict, harmony, complexity, or mutual independence.

Both science and religion are complex social and cultural endeavors that vary across cultures and have changed over time. Most scientific and technical innovations prior to the scientific revolution were achieved by societies organized by religious traditions. Elements of the scientific method were pioneered by ancient pagan, Islamic, and Christian scholars. Roger Bacon, who is often credited with formalizing the scientific method, was a Franciscan friar. Hinduism has historically embraced reason and empiricism, holding that science brings legitimate, but incomplete knowledge of the world. Confucian thought has held different views of science over time. Most Buddhists today view science as complementary to their beliefs. While the classification of the material world by the ancient Indians and Greeks into air, earth, fire and water was more philosophical, medieval Middle Easterns used practical and experimental observation to classify materials.

Events in Europe such as the Galileo affair, associated with the scientific revolution and the Age of Enlightenment, led scholars such as John William Draper to postulate a conflict thesis, holding that religion and science have been in conflict methodologically, factually and politically throughout history. This thesis is held by some contemporary scientists such as Richard Dawkins, Steven Weinberg and Carl Sagan, and some creationists. The conflict thesis has lost favor among most contemporary historians of science.

Many scientists, philosophers, and theologians throughout history, such as Francisco Ayala, Kenneth R. Miller and Francis Collins, have seen compatibility or independence between religion and science. Biologist Stephen Jay Gould, other scientists, and some contemporary theologians hold that religion and science are non-overlapping magisteria, addressing fundamentally separate forms of knowledge and aspects of life. Some theologians or historians of science, including John Lennox, Thomas Berry, Brian Swimme and Ken Wilber propose an interconnection between science and religion, while others such as Ian Barbour believe there are even parallels.

Public acceptance of scientific facts may be influenced by religion; many in the United States reject evolution by natural selection, especially regarding human beings. Nevertheless, the American National Academy of Sciences has written that "the evidence for evolution can be fully compatible with religious faith", a view officially endorsed by many religious denominations globally.

The concepts of "science" and "religion" are a recent invention: "religion" emerged in the 17th century in the midst of colonization and globalization and the Protestant Reformation, "science" emerged in the 19th century in the midst of attempts to narrowly define those who studied nature. Furthermore, the phrase "religion and science" or "science and religion" emerged in the 19th century, not before, due to the reification of both concepts.

It was in the 19th century that the terms "Buddhism", "Hinduism", "Taoism", "Confucianism" and "World Religions" first emerged. In the ancient and medieval world, the etymological Latin roots of both science ("scientia") and religion ("religio") were understood as inner qualities of the individual or virtues, never as doctrines, practices, or actual sources of knowledge.

It was in the 19th century that the concept of "science" received its modern shape with new titles emerging such as "biology" and "biologist", "physics" and "physicist" among other technical fields and titles; institutions and communities were founded, and unprecedented applications to and interactions with other aspects of society and culture occurred. The term "scientist" was first coined by the naturalist-theologian William Whewell in 1834 and it was applied to those who sought knowledge and understanding of nature. From the ancient world, starting with Aristotle, to the 19th century, the term "natural philosophy" was the common term used to describe the practice of studying nature. Isaac Newton's book Philosophiae Naturalis Principia Mathematica (1687), whose title translates to "Mathematical Principles of Natural Philosophy", reflects the then-current use of the words "natural philosophy", akin to "systematic study of nature". Even in the 19th century, a treatise by Lord Kelvin and Peter Guthrie Tait's, which helped define much of modern physics, was titled Treatise on Natural Philosophy (1867).

It was in the 17th century that the concept of "religion" received its modern shape despite the fact that ancient texts like the Bible, the Quran, and other sacred texts did not have a concept of religion in the original languages and neither did the people or the cultures in which these sacred texts were written. In the 19th century, Max Müller noted that what is called ancient religion today, would have been called "law" in antiquity. For example, there is no precise equivalent of "religion" in Hebrew, and Judaism does not distinguish clearly between religious, national, racial, or ethnic identities. The Sanskrit word "dharma", sometimes translated as "religion", also means law or duty. Throughout classical South Asia, the study of law consisted of concepts such as penance through piety and ceremonial as well as practical traditions. Medieval Japan at first had a similar union between "imperial law" and universal or "Buddha law", but these later became independent sources of power. Throughout its long history, Japan had no concept of "religion" since there was no corresponding Japanese word, nor anything close to its meaning, but when American warships appeared off the coast of Japan in 1853 and forced the Japanese government to sign treaties demanding, among other things, freedom of religion, the country had to contend with this Western idea.

The development of sciences (especially natural philosophy) in Western Europe during the Middle Ages, has considerable foundation in the works of the Arabs who translated Greek and Latin compositions. The works of Aristotle played a major role in the institutionalization, systematization, and expansion of reason. Christianity accepted reason within the ambit of faith. In Christendom, reason was considered subordinate to revelation, which contained the ultimate truth and this truth could not be challenged. Even though the medieval Christian had the urge to use their reason, they had little on which to exercise it. In medieval universities, the faculty for natural philosophy and theology were separate, and discussions pertaining to theological issues were often not allowed to be undertaken by the faculty of philosophy.

Natural philosophy, as taught in the arts faculties of the universities, was seen as an essential area of study in its own right and was considered necessary for almost every area of study. It was an independent field, separated from theology, which enjoyed a good deal of intellectual freedom as long as it was restricted to the natural world. In general, there was religious support for natural science by the late Middle Ages and a recognition that it was an important element of learning.

The extent to which medieval science led directly to the new philosophy of the scientific revolution remains a subject for debate, but it certainly had a significant influence.

The Middle Ages laid ground for the developments that took place in science, during the Renaissance which immediately succeeded it. With significant developments taking place in science, mathematics, medicine and philosophy, the relationship between science and religion became one of curiosity and questioning. As humanism became more and more popular, people tried to understand the nature around them better, rather than turn to religious aspirations. Renaissance humanism looked to classical Greek and Roman texts to change contemporary thought, allowing for a new mindset after the Middle Ages. Renaissance readers understood these classical texts as focusing on human decisions, actions and creations, rather than blindly following the rules set forth by the Catholic Church as "God's plan." Though many Renaissance humanists remained religious, they believed God gave humans opportunities and it was humanity's duty to do the "best and most moral thing". Renaissance humanism was an "ethical theory and practice that emphasized reason, scientific inquiry and human fulfillment in the natural world," said Abernethy. By 1630, ancient authority from classical literature and philosophy, as well as their necessity, started eroding, although scientists were still expected to be fluent in Latin, the international language of Europe's intellectuals. With the sheer success of science and the steady advance of rationalism, the individual scientist gained prestige.

Along with the inventions of this period, especially the printing press by Johannes Gutenberg, allowed for the dissemination of the Bible in languages of the common people (languages other than Latin). This allowed more people to read and learn from the scripture, leading to the Evangelical movement. The people who spread this message, concentrated more on individual agency rather than the structures of the Church.

The kinds of interactions that might arise between science and religion have been categorized by theologian, Anglican priest, and physicist John Polkinghorne: (1) conflict between the disciplines, (2) independence of the disciplines, (3) dialogue between the disciplines where they overlap and (4) integration of both into one field.

This typology is similar to ones used by theologians Ian Barbour and John Haught. More typologies that categorize this relationship can be found among the works of other science and religion scholars such as theologian and biochemist Arthur Peacocke.

According to Guillermo Paz-y-Miño-C and Avelina Espinosa, the historical conflict between evolution and religion is intrinsic to the incompatibility between scientific rationalism/empiricism and the belief in supernatural causation. According to Jerry Coyne, views on evolution and levels of religiosity in some countries, along with the existence of books explaining reconciliation between evolution and religion, indicate that people have trouble in believing both at the same time, thus implying incompatibility.
According to Lawrence Krauss, compatibility or incompatibility is a theological concern, not a scientific concern. In Lisa Randall's view, questions of incompatibility or otherwise are not answerable, since by accepting revelations one is abandoning rules of logic which are needed to identify if there are indeed contradictions between holding certain beliefs. Daniel Dennett holds that incompatibility exists because religion is not problematic to a certain point before it collapses into a number of excuses for keeping certain beliefs, in light of evolutionary implications.

According to Neil deGrasse Tyson, the central difference between the nature of science and religion is that the claims of science rely on experimental verification, while the claims of religions rely on faith, and these are irreconcilable approaches to knowing. Because of this both are incompatible as currently practiced and the debate of compatibility or incompatibility will be eternal. Philosopher and physicist Victor J. Stenger's view is that science and religion are incompatible due to conflicts between approaches of knowing and the availability of alternative plausible natural explanations for phenomena that is usually explained in religious contexts.

Richard Dawkins is hostile to fundamentalist religion because it actively debauches the scientific enterprise. According to Dawkins, religion "subverts science and saps the intellect". He believes that when science teachers attempt to expound on evolution, there is hostility aimed towards them by parents who are skeptical because they believe it conflicts with their religious beliefs, that even some textbooks have had the word 'evolution' systematically removed. According to Sean M. Carroll, since religion makes claims that are not compatible with science, such as supernatural events, therefore both are incompatible.

Others such as Francis Collins, Kenneth R. Miller, George Coyne and Francisco J. Ayala argue for compatibility since they do not agree that science is incompatible with religion and vice versa. They argue that science provides many opportunities to look for and find God in nature and to reflect on their beliefs. According to Kenneth Miller, he disagrees with Jerry Coyne's assessment and argues that since significant portions of scientists are religious and the proportion of Americans believing in evolution is much higher, it implies that both are indeed compatible. Elsewhere, Miller has argued that when scientists make claims on science and theism or atheism, they are not arguing scientifically at all and are stepping beyond the scope of science into discourses of meaning and purpose. What he finds particularly odd and unjustified is in how atheists often come to invoke scientific authority on their non-scientific philosophical conclusions like there being no point or no meaning to the universe as the only viable option when the scientific method and science never have had any way of addressing questions of meaning or God in the first place. Furthermore, he notes that since evolution made the brain and since the brain can handle both religion and science, there is no natural incompatibility between the concepts at the biological level.

Karl Giberson argues that when discussing compatibility, some scientific intellectuals often ignore the viewpoints of intellectual leaders in theology and instead argue against less informed masses, thereby, defining religion by non intellectuals and slanting the debate unjustly. He argues that leaders in science sometimes trump older scientific baggage and that leaders in theology do the same, so once theological intellectuals are taken into account, people who represent extreme positions like Ken Ham and Eugenie Scott will become irrelevant. Cynthia Tolman notes that religion does not have a method per se partly because religions emerge through time from diverse cultures, but when it comes to Christian theology and ultimate truths, she notes that people often rely on scripture, tradition, reason, and experience to test and gauge what they experience and what they should believe.

The conflict thesis, which holds that religion and science have been in conflict continuously throughout history, was popularized in the 19th century by John William Draper's and Andrew Dickson White's accounts. It was in the 19th century that relationship between science and religion became an actual formal topic of discourse, while before this no one had pitted science against religion or vice versa, though occasional complex interactions had been expressed before the 19th century. Most contemporary historians of science now reject the conflict thesis in its original form and no longer support it. Instead, it has been superseded by subsequent historical research which has resulted in a more nuanced understanding: Historian of science, Gary Ferngren, has stated "Although popular images of controversy continue to exemplify the supposed hostility of Christianity to new scientific theories, studies have shown that Christianity has often nurtured and encouraged scientific endeavour, while at other times the two have co-existed without either tension or attempts at harmonization. If Galileo and the Scopes trial come to mind as examples of conflict, they were the exceptions rather than the rule."

Most historians today have moved away from a conflict model, which is based mainly on two historical episodes (Galileo and Darwin) for a "complexity" model, because religious figures were on both sides of each dispute and there was no overall aim by any party involved to discredit religion.

An often cited example of conflict, that has been clarified by historical research in the 20th century, was the Galileo affair, whereby interpretations of the Bible were used to attack ideas by Copernicus on heliocentrism. By 1616 Galileo went to Rome to try to persuade Catholic Church authorities not to ban Copernicus' ideas. In the end, a decree of the Congregation of the Index was issued, declaring that the ideas that the Sun stood still and that the Earth moved were "false" and "altogether contrary to Holy Scripture", and suspending Copernicus's "De Revolutionibus" until it could be corrected. Galileo was found "vehemently suspect of heresy", namely of having held the opinions that the Sun lies motionless at the center of the universe, that the Earth is not at its centre and moves. He was required to "abjure, curse and detest" those opinions. However, before all this, Pope Urban VIII had personally asked Galileo to give arguments for and against heliocentrism in a book, and to be careful not to advocate heliocentrism as physically proven since the scientific consensus at the time was that the evidence for heliocentrism was very weak. The Church had merely sided with the scientific consensus of the time. Pope Urban VIII asked that his own views on the matter be included in Galileo's book. Only the latter was fulfilled by Galileo. Whether unknowingly or deliberately, Simplicio, the defender of the Aristotelian/Ptolemaic geocentric view in "Dialogue Concerning the Two Chief World Systems", was often portrayed as an unlearned fool who lacked mathematical training. Although the preface of his book claims that the character is named after a famous Aristotelian philosopher (Simplicius in Latin, Simplicio in Italian), the name "Simplicio" in Italian also has the connotation of "simpleton". Unfortunately for his relationship with the Pope, Galileo put the words of Urban VIII into the mouth of Simplicio. Most historians agree Galileo did not act out of malice and felt blindsided by the reaction to his book. However, the Pope did not take the suspected public ridicule lightly, nor the physical Copernican advocacy. Galileo had alienated one of his biggest and most powerful supporters, the Pope, and was called to Rome to defend his writings.

The actual evidences that finally proved heliocentrism came centuries after Galileo: the stellar aberration of light by James Bradley in the 18th century, the orbital motions of binary stars by William Herschel in the 19th century, the accurate measurement of the stellar parallax in the 19th century, and Newtonian mechanics in the 17th century. According to physicist Christopher Graney, Galileo's own observations did not actually support the Copernican view, but were more consistent with Tycho Brahe's hybrid model where that Earth did not move and everything else circled around it and the Sun.

British philosopher A. C. Grayling, still believes there is competition between science and religions and point to the origin of the universe, the nature of human beings and the possibility of miracles

A modern view, described by Stephen Jay Gould as "non-overlapping magisteria" (NOMA), is that science and religion deal with fundamentally separate aspects of human experience and so, when each stays within its own domain, they co-exist peacefully. While Gould spoke of independence from the perspective of science, W. T. Stace viewed independence from the perspective of the philosophy of religion. Stace felt that science and religion, when each is viewed in its own domain, are both consistent and complete.

The USA's National Academy of Science supports the view that science and religion are independent.
Science and religion are based on different aspects of human experience. In science, explanations must be based on evidence drawn from examining the natural world. Scientifically based observations or experiments that conflict with an explanation eventually must lead to modification or even abandonment of that explanation. Religious faith, in contrast, does not depend on empirical evidence, is not necessarily modified in the face of conflicting evidence, and typically involves supernatural forces or entities. Because they are not a part of nature, supernatural entities cannot be investigated by science. In this sense, science and religion are separate and address aspects of human understanding in different ways. Attempts to put science and religion against each other create controversy where none needs to exist.

According to Archbishop John Habgood, both science and religion represent distinct ways of approaching experience and these differences are sources of debate. He views science as descriptive and religion as prescriptive. He stated that if science and mathematics concentrate on what the world "ought to be", in the way that religion does, it may lead to improperly ascribing properties to the natural world as happened among the followers of Pythagoras in the sixth century B.C. In contrast, proponents of a normative moral science take issue with the idea that science has "no" way of guiding "oughts". Habgood also stated that he believed that the reverse situation, where religion attempts to be descriptive, can also lead to inappropriately assigning properties to the natural world. A notable example is the now defunct belief in the Ptolemaic (geocentric) planetary model that held sway until changes in scientific and religious thinking were brought about by Galileo and proponents of his views.

According to Ian Barbour, Thomas S. Kuhn asserted that science is made up of paradigms that arise from cultural traditions, which is similar to the secular perspective on religion.

Michael Polanyi asserted that it is merely a commitment to universality that protects against subjectivity and has nothing at all to do with personal detachment as found in many conceptions of the scientific method. Polanyi further asserted that all knowledge is personal and therefore the scientist must be performing a very personal if not necessarily subjective role when doing science. Polanyi added that the scientist often merely follows intuitions of "intellectual beauty, symmetry, and 'empirical agreement'". Polanyi held that science requires moral commitments similar to those found in religion.

Two physicists, Charles A. Coulson and Harold K. Schilling, both claimed that "the methods of science and religion have much in common." Schilling asserted that both fields—science and religion—have "a threefold structure—of experience, theoretical interpretation, and practical application." Coulson asserted that science, like religion, "advances by creative imagination" and not by "mere collecting of facts," while stating that religion should and does "involve critical reflection on experience not unlike that which goes on in science." Religious language and scientific language also show parallels (cf. rhetoric of science).

The "religion and science community" consists of those scholars who involve themselves with what has been called the "religion-and-science dialogue" or the "religion-and-science field." The community belongs to neither the scientific nor the religious community, but is said to be a third overlapping community of interested and involved scientists, priests, clergymen, theologians and engaged non-professionals. Institutions interested in the intersection between science and religion include the Center for Theology and the Natural Sciences, the Institute on Religion in an Age of Science, the Ian Ramsey Centre, and the Faraday Institute. Journals addressing the relationship between science and religion include "Theology and Science" and "Zygon". Eugenie Scott has written that the "science and religion" movement is, overall, composed mainly of theists who have a healthy respect for science and may be beneficial to the public understanding of science. She contends that the "Christian scholarship" movement is not a problem for science, but that the "Theistic science" movement, which proposes abandoning methodological materialism, does cause problems in understanding of the nature of science.

The modern dialogue between religion and science is rooted in Ian Barbour's 1966 book "Issues in Science and Religion". Since that time it has grown into a serious academic field, with academic chairs in the subject area, and two dedicated academic journals, "Zygon" and "Theology and Science". Articles are also sometimes found in mainstream science journals such as "American Journal of Physics"
and "Science".

Philosopher Alvin Plantinga has argued that there is superficial conflict but deep concord between science and religion, and that there is deep conflict between science and naturalism. Plantinga, in his book "Where the Conflict Really Lies: Science, Religion, and Naturalism", heavily contests the linkage of naturalism with science, as conceived by Richard Dawkins, Daniel Dennett and like-minded thinkers; while Daniel Dennett thinks that Plantinga stretches science to an unacceptable extent. Philosopher Maarten Boudry, in reviewing the book, has commented that he resorts to creationism and fails to "stave off the conflict between theism and evolution." Cognitive scientist Justin L. Barrett, by contrast, reviews the same book and writes that "those most needing to hear Plantinga's message may fail to give it a fair hearing for rhetorical rather than analytical reasons."

As a general view, this holds that while interactions are complex between influences of science, theology, politics, social, and economic concerns, the productive engagements between science and religion throughout history should be duly stressed as the norm.

Scientific and theological perspectives often coexist peacefully. Christians and some non-Christian religions have historically integrated well with scientific ideas, as in the ancient Egyptian technological mastery applied to monotheistic ends, the flourishing of logic and mathematics under Hinduism and Buddhism, and the scientific advances made by Muslim scholars during the Ottoman empire. Even many 19th-century Christian communities welcomed scientists who claimed that science was not at all concerned with discovering the ultimate nature of reality. According to Lawrence M. Principe, the Johns Hopkins University Drew Professor of the Humanities, from a historical perspective this points out that much of the current-day clashes occur between limited extremists—both religious and scientistic fundamentalists—over a very few topics, and that the movement of ideas back and forth between scientific and theological thought has been more usual. To Principe, this perspective would point to the fundamentally common respect for written learning in religious traditions of rabbinical literature, Christian theology, and the Islamic Golden Age, including a Transmission of the Classics from Greek to Islamic to Christian traditions which helped spark the Renaissance. Religions have also given key participation in development of modern universities and libraries; centers of learning & scholarship were coincident with religious institutions – whether pagan, Muslim, or Christian.

A fundamental principle of the Bahá'í Faith is the harmony of religion and science. Bahá'í scripture asserts that true science and true religion can never be in conflict. `Abdu'l-Bahá, the son of the founder of the religion, stated that religion without science is superstition and that science without religion is materialism. He also admonished that true religion must conform to the conclusions of science.

Buddhism and science have been regarded as compatible by numerous authors. Some philosophic and psychological teachings found in Buddhism share points in common with modern Western scientific and philosophic thought. For example, Buddhism encourages the impartial investigation of nature (an activity referred to as "Dhamma-Vicaya" in the Pali Canon)—the principal object of study being oneself. Buddhism and science both show a strong emphasis on causality. However, Buddhism doesn't focus on materialism.

Tenzin Gyatso, the 14th Dalai Lama, maintains that empirical scientific evidence supersedes the traditional teachings of Buddhism when the two are in conflict. In his book "The Universe in a Single Atom" he wrote, "My confidence in venturing into science lies in my basic belief that as in science, so in Buddhism, understanding the nature of reality is pursued by means of critical investigation." and "If scientific analysis were conclusively to demonstrate certain claims in Buddhism to be false," he says, "then we must accept the findings of science and abandon those claims."

Most sources of knowledge available to early Christians were connected to pagan world-views. There were various opinions on how Christianity should regard pagan learning, which included its ideas about nature. For instance, among early Christian teachers, Tertullian (c. 160–220) held a generally negative opinion of Greek philosophy, while Origen (c. 185–254) regarded it much more favorably and required his students to read nearly every work available to them.

Earlier attempts at reconciliation of Christianity with Newtonian mechanics appear quite different from later attempts at reconciliation with the newer scientific ideas of evolution or relativity. Many early interpretations of evolution polarized themselves around a "struggle for existence." These ideas were significantly countered by later findings of universal patterns of biological cooperation. According to John Habgood, all man really knows here is that the universe seems to be a mix of good and evil, beauty and pain, and that suffering may somehow be part of the process of creation. Habgood holds that Christians should not be surprised that suffering may be used creatively by God, given their faith in the symbol of the Cross. 
Robert John Russell has examined consonance and dissonance between modern physics, evolutionary biology, and Christian theology.

Christian philosophers Augustine of Hippo (354–30) and Thomas Aquinas held that scriptures can have multiple interpretations on certain areas where the matters were far beyond their reach, therefore one should leave room for future findings to shed light on the meanings. The "Handmaiden" tradition, which saw secular studies of the universe as a very important and helpful part of arriving at a better understanding of scripture, was adopted throughout Christian history from early on. Also the sense that God created the world as a self operating system is what motivated many Christians throughout the Middle Ages to investigate nature.

Modern historians of science such as J.L. Heilbron, Alistair Cameron Crombie, David Lindberg, Edward Grant, Thomas Goldstein, and Ted Davis have reviewed the popular notion that medieval Christianity was a negative influence in the development of civilization and science. In their views, not only did the monks save and cultivate the remnants of ancient civilization during the barbarian invasions, but the medieval church promoted learning and science through its sponsorship of many universities which, under its leadership, grew rapidly in Europe in the 11th and 12th centuries, St. Thomas Aquinas, the Church's "model theologian", not only argued that reason is in harmony with faith, he even recognized that reason can contribute to understanding revelation, and so encouraged intellectual development. He was not unlike other medieval theologians who sought out reason in the effort to defend his faith. Some of today's scholars, such as Stanley Jaki, have claimed that Christianity with its particular worldview, was a crucial factor for the emergence of modern science.

David C. Lindberg states that the widespread popular belief that the Middle Ages was a time of ignorance and superstition due to the Christian church is a "caricature". According to Lindberg, while there are some portions of the classical tradition which suggest this view, these were exceptional cases. It was common to tolerate and encourage critical thinking about the nature of the world. The relation between Christianity and science is complex and cannot be simplified to either harmony or conflict, according to Lindberg. Lindberg reports that "the late medieval scholar rarely experienced the coercive power of the church and would have regarded himself as free (particularly in the natural sciences) to follow reason and observation wherever they led. There was no warfare between science and the church." Ted Peters in "Encyclopedia of Religion" writes that although there is some truth in the "Galileo's condemnation" story but through exaggerations, it has now become "a modern myth perpetuated by those wishing to see warfare between science and religion who were allegedly persecuted by an atavistic and dogma-bound ecclesiastical authority". In 1992, the Catholic Church's seeming vindication of Galileo attracted much comment in the media.

A degree of concord between science and religion can be seen in religious belief and empirical science. The belief that God created the world and therefore humans, can lead to the view that he arranged for humans to know the world. This is underwritten by the doctrine of imago dei. In the words of Thomas Aquinas, "Since human beings are said to be in the image of God in virtue of their having a nature that includes an intellect, such a nature is most in the image of God in virtue of being most able to imitate God".

During the Enlightenment, a period "characterized by dramatic revolutions in science" and the rise of Protestant challenges to the authority of the Catholic Church via individual liberty, the authority of Christian scriptures became strongly challenged. As science advanced, acceptance of a literal version of the Bible became "increasingly untenable" and some in that period presented ways of interpreting scripture according to its spirit on its authority and truth.

In recent history, the theory of evolution has been at the center of some controversy between Christianity and science. Christians who accept a literal interpretation of the biblical account of creation find incompatibility between Darwinian evolution and their interpretation of the Christian faith. Creation science or scientific creationism is a branch of creationism that attempts to provide scientific support for the Genesis creation narrative in the Book of Genesis and attempts to disprove generally accepted scientific facts, theories and scientific paradigms about the history of the Earth, cosmology and biological evolution. It began in the 1960s as a fundamentalist Christian effort in the United States to prove Biblical inerrancy and falsify the scientific evidence for evolution. It has since developed a sizable religious following in the United States, with creation science ministries branching worldwide. In 1925, The State of Tennessee passed the Butler Act, which prohibited the teaching of the theory of evolution in all schools in the state. Later that year, a similar law was passed in Mississippi, and likewise, Arkansas in 1927. In 1968, these "anti-monkey" laws were struck down by the Supreme Court of the United States as unconstitutional, "because they established a religious doctrine violating both the First and Fourth Amendments to the Constitution.

Most scientists have rejected creation science for several reasons, including that its claims do not refer to natural causes and cannot be tested. In 1987, the United States Supreme Court ruled that creationism is religion, not science, and cannot be advocated in public school classrooms. In 2018, the "Orlando Sentinel" reported that "Some private schools in Florida that rely on public funding teach students" Creationism.

Theistic evolution attempts to reconcile Christian beliefs and science by accepting the scientific understanding of the age of the Earth and the process of evolution. It includes a range of beliefs, including views described as evolutionary creationism, which accepts some findings of modern science but also upholds classical religious teachings about God and creation in Christian context.

In "Reconciling Science and Religion: The Debate in Early-twentieth-century Britain", historian of biology Peter J. Bowler argues that in contrast to the conflicts between science and religion in the U.S. in the 1920s (most famously the Scopes Trial), during this period Great Britain experienced a concerted effort at reconciliation, championed by intellectually conservative scientists, supported by liberal theologians but opposed by younger scientists and secularists and conservative Christians. These attempts at reconciliation fell apart in the 1930s due to increased social tensions, moves towards neo-orthodox theology and the acceptance of the modern evolutionary synthesis.

In the 20th century, several ecumenical organizations promoting a harmony between science and Christianity were founded, most notably the American Scientific Affiliation, The Biologos Foundation, Christians in Science, The Society of Ordained Scientists, and The Veritas Forum.

While refined and clarified over the centuries, the Roman Catholic position on the relationship between science and religion is one of harmony, and has maintained the teaching of natural law as set forth by Thomas Aquinas. For example, regarding scientific study such as that of evolution, the church's unofficial position is an example of theistic evolution, stating that faith and scientific findings regarding human evolution are not in conflict, though humans are regarded as a special creation, and that the existence of God is required to explain both monogenism and the spiritual component of human origins. Catholic schools have included all manners of scientific study in their curriculum for many centuries.

Galileo once stated "The intention of the Holy Spirit is to teach us how to go to heaven, not how the heavens go." In 1981 John Paul II, then pope of the Roman Catholic Church, spoke of the relationship this way: "The Bible itself speaks to us of the origin of the universe and its make-up, not in order to provide us with a scientific treatise, but in order to state the correct relationships of man with God and with the universe. Sacred Scripture wishes simply to declare that the world was created by God, and in order to teach this truth it expresses itself in the terms of the cosmology in use at the time of the writer".

According to Andrew Dickson White's "A History of the Warfare of Science with Theology in Christendom" from the 19th century, a biblical world view affected negatively the progress of science through time. Dickinson also argues that immediately following the Reformation matters were even worse. The interpretations of Scripture by Luther and Calvin became as sacred to their followers as the Scripture itself. For instance, when Georg Calixtus ventured, in interpreting the Psalms, to question the accepted belief that "the waters above the heavens" were contained in a vast receptacle upheld by a solid vault, he was bitterly denounced as heretical. Today, much of the scholarship in which the conflict thesis was originally based is considered to be inaccurate. For instance, the claim that early Christians rejected scientific findings by the Greco-Romans is false, since the "handmaiden" view of secular studies was seen to shed light on theology. This view was widely adapted throughout the early medieval period and afterwards by theologians (such as Augustine) and ultimately resulted in fostering interest in knowledge about nature through time. Also, the claim that people of the Middle Ages widely believed that the Earth was flat was first propagated in the same period that originated the conflict thesis and is still very common in popular culture. Modern scholars regard this claim as mistaken, as the contemporary historians of science David C. Lindberg and Ronald L. Numbers write: "there was scarcely a Christian scholar of the Middle Ages who did not acknowledge [earth's] sphericity and even know its approximate circumference." From the fall of Rome to the time of Columbus, all major scholars and many vernacular writers interested in the physical shape of the earth held a spherical view with the exception of Lactantius and Cosmas.

H. Floris Cohen argued for a biblical Protestant, but not excluding Catholicism, influence on the early development of modern science. He presented Dutch historian R. Hooykaas' argument that a biblical world-view holds all the necessary antidotes for the hubris of Greek rationalism: a respect for manual labour, leading to more experimentation and empiricism, and a supreme God that left nature open to emulation and manipulation. It supports the idea early modern science rose due to a combination of Greek and biblical thought.

Oxford historian Peter Harrison is another who has argued that a biblical worldview was significant for the development of modern science. Harrison contends that Protestant approaches to the book of scripture had significant, if largely unintended, consequences for the interpretation of the book of nature. Harrison has also suggested that literal readings of the Genesis narratives of the Creation and Fall motivated and legitimated scientific activity in seventeenth-century England. For many of its seventeenth-century practitioners, science was imagined to be a means of restoring a human dominion over nature that had been lost as a consequence of the Fall.

Historian and professor of religion Eugene M. Klaaren holds that "a belief in divine creation" was central to an emergence of science in seventeenth-century England. The philosopher Michael Foster has published analytical philosophy connecting Christian doctrines of creation with empiricism. Historian William B. Ashworth has argued against the historical notion of distinctive mind-sets and the idea of Catholic and Protestant sciences. Historians James R. Jacob and Margaret C. Jacob have argued for a linkage between seventeenth century Anglican intellectual transformations and influential English scientists (e.g., Robert Boyle and Isaac Newton). John Dillenberger and Christopher B. Kaiser have written theological surveys, which also cover additional interactions occurring in the 18th, 19th, and 20th centuries. Philosopher of Religion, Richard Jones, has written a philosophical critique of the "dependency thesis" which assumes that modern science emerged from Christian sources and doctrines. Though he acknowledges that modern science emerged in a religious framework, that Christianity greatly elevated the importance of science by sanctioning and religiously legitimizing it in the medieval period, and that Christianity created a favorable social context for it to grow; he argues that direct Christian beliefs or doctrines were not primary sources of scientific pursuits by natural philosophers, nor was Christianity, in and of itself, exclusively or directly necessary in developing or practicing modern science.

Oxford University historian and theologian John Hedley Brooke wrote that "when natural philosophers referred to "laws" of nature, they were not glibly choosing that metaphor. Laws were the result of legislation by an intelligent deity. Thus the philosopher René Descartes (1596–1650) insisted that he was discovering the "laws that God has put into nature." Later Newton would declare that the regulation of the solar system presupposed the "counsel and dominion of an intelligent and powerful Being." Historian Ronald L. Numbers stated that this thesis "received a boost" from mathematician and philosopher Alfred North Whitehead's "Science and the Modern World" (1925). Numbers has also argued, "Despite the manifest shortcomings of the claim that Christianity gave birth to science—most glaringly, it ignores or minimizes the contributions of ancient Greeks and medieval Muslims—it too, refuses to succumb to the death it deserves." The sociologist Rodney Stark of Baylor University, argued in contrast that "Christian theology was essential for the rise of science."

Protestantism had an important influence on science. According to the Merton Thesis there was a positive correlation between the rise of Puritanism and Protestant Pietism on the one hand and early experimental science on the other. The Merton Thesis has two separate parts: Firstly, it presents a theory that science changes due to an accumulation of observations and improvement in experimental techniques and methodology; secondly, it puts forward the argument that the popularity of science in 17th-century England and the religious demography of the Royal Society (English scientists of that time were predominantly Puritans or other Protestants) can be explained by a correlation between Protestantism and the scientific values. In his theory, Robert K. Merton focused on English Puritanism and German Pietism as having been responsible for the development of the scientific revolution of the 17th and 18th centuries. Merton explained that the connection between religious affiliation and interest in science was the result of a significant synergy between the ascetic Protestant values and those of modern science. Protestant values encouraged scientific research by allowing science to study God's influence on the world and thus providing a religious justification for scientific research.

The historical process of Confucianism has largely been antipathic towards scientific discovery. However the religio-philosophical system itself is more neutral on the subject than such an analysis might suggest. In his writings On Heaven, Xunzi espoused a proto-scientific world view. However, during the Han Synthesis the more anti-empirical Mencius was favored and combined with Daoist skepticism regarding the nature of reality. Likewise, during the Medieval period, Zhu Xi argued against technical investigation and specialization proposed by Chen Liang. After contact with the West, scholars such as Wang Fuzhi would rely on Buddhist/Daoist skepticism to denounce all science as a subjective pursuit limited by humanity's fundamental ignorance of the true nature of the world. After the May Fourth Movement, attempts to modernize Confucianism and reconcile it with scientific understanding were attempted by many scholars including Feng Youlan and Xiong Shili. Given the close relationship that Confucianism shares with Buddhism, many of the same arguments used to reconcile Buddhism with science also readily translate to Confucianism. However, modern scholars have also attempted to define the relationship between science and Confucianism on Confucianism's own terms and the results have usually led to the conclusion that Confucianism and science are fundamentally compatible.

In Hinduism, the dividing line between objective sciences and spiritual knowledge ("adhyatma vidya") is a linguistic paradox. Hindu scholastic activities and ancient Indian scientific advancements were so interconnected that many Hindu scriptures are also ancient scientific manuals and vice versa. In 1835, English was made the primary language for teaching in higher education in India, exposing Hindu scholars to Western secular ideas; this started a renaissance regarding religious and philosophical thought. Hindu sages maintained that logical argument and rational proof using Nyaya is the way to obtain correct knowledge. The scientific level of understanding focuses on how things work and from where they originate, while Hinduism strives to understand the ultimate purposes for the existence of living things. To obtain and broaden the knowledge of the world for spiritual perfection, many refer to the Bhāgavata for guidance because it draws upon a scientific and theological dialogue. Hinduism offers methods to correct and transform itself in course of time. For instance, Hindu views on the development of life include a range of viewpoints in regards to evolution, creationism, and the origin of life within the traditions of Hinduism. For instance, it has been suggested that Wallace-Darwininan evolutionary thought was a part of Hindu thought centuries before modern times. The Shankara and the Sāmkhya did not have a problem with the theory of evolution, but instead, argued about the existence of God and what happened after death. These two distinct groups argued among each other's philosophies because of their sacred texts, not the idea of evolution. With the publication of Darwin's "On the Origin of Species", many Hindus were eager to connect their scriptures to Darwinism, finding similarities between Brahma's creation, Vishnu's incarnations, and evolution theories.

Samkhya, the oldest school of Hindu philosophy prescribes a particular method to analyze knowledge. According to Samkhya, all knowledge is possible through three means of valid knowledge –

Nyaya, the Hindu school of logic, accepts all these 3 means and in addition accepts one more – "Upamāna" (comparison).

The accounts of the emergence of life within the universe vary in description, but classically the deity called Brahma, from a Trimurti of three deities also including Vishnu and Shiva, is described as performing the act of 'creation', or more specifically of 'propagating life within the universe' with the other two deities being responsible for 'preservation' and 'destruction' (of the universe) respectively. In this respect some Hindu schools do not treat the scriptural creation myth literally and often the creation stories themselves do not go into specific detail, thus leaving open the possibility of incorporating at least some theories in support of evolution. Some Hindus find support for, or foreshadowing of evolutionary ideas in scriptures, namely the Vedas.

The incarnations of Vishnu (Dashavatara) is almost identical to the scientific explanation of the sequence of biological evolution of man and animals. The sequence of avatars starts from an aquatic organism (Matsya), to an amphibian (Kurma), to a land-animal (Varaha), to a humanoid (Narasimha), to a dwarf human (Vamana), to 5 forms of well developed human beings (Parashurama, Rama, Balarama/Buddha, Krishna, Kalki) who showcase an increasing form of complexity (Axe-man, King, Plougher/Sage, wise Statesman, mighty Warrior). In fact, many Hindu gods are represented with features of animals as well as those of humans, leading many Hindus to easily accept evolutionary links between animals and humans. In India, the home country of Hindus, educated Hindus widely accept the theory of biological evolution. In a survey of 909 people, 77% of respondents in India agreed with Charles Darwin's Theory of Evolution, and 85 per cent of God-believing people said they believe in evolution as well.

As per Vedas, another explanation for the creation is based on the five elements: earth, water, fire, air and aether.
The Hindu religion traces its beginnings to the sacred Vedas. Everything that is established in the Hindu faith such as the gods and goddesses, doctrines, chants, spiritual insights, etc. flow from the poetry of Vedic hymns. The Vedas offer an honor to the sun and moon, water and wind, and to the order in Nature that is universal. This naturalism is the beginning of what further becomes the connection between Hinduism and science.

From an Islamic standpoint, science, the study of nature, is considered to be linked to the concept of "Tawhid" (the Oneness of God), as are all other branches of knowledge. In Islam, nature is not seen as a separate entity, but rather as an integral part of Islam's holistic outlook on God, humanity, and the world. The Islamic view of science and nature is continuous with that of religion and God. This link implies a sacred aspect to the pursuit of scientific knowledge by Muslims, as nature itself is viewed in the Qur'an as a compilation of signs pointing to the Divine. It was with this understanding that science was studied and understood in Islamic civilizations, specifically during the eighth to sixteenth centuries, prior to the colonization of the Muslim world. Robert Briffault, in "The Making of Humanity", asserts that the very existence of science, as it is understood in the modern sense, is rooted in the scientific thought and knowledge that emerged in Islamic civilizations during this time. Ibn al-Haytham, an Arab Muslim, was an early proponent of the concept that a hypothesis must be proved by experiments based on confirmable procedures or mathematical evidence—hence understanding the scientific method 200 years before Renaissance scientists. Ibn al-Haytham described his theology: 
With the decline of Islamic Civilizations in the late Middle Ages and the rise of Europe, the Islamic scientific tradition shifted into a new period. Institutions that had existed for centuries in the Muslim world looked to the new scientific institutions of European powers. This changed the practice of science in the Muslim world, as Islamic scientists had to confront the western approach to scientific learning, which was based on a different philosophy of nature. From the time of this initial upheaval of the Islamic scientific tradition to the present day, Muslim scientists and scholars have developed a spectrum of viewpoints on the place of scientific learning within the context of Islam, none of which are universally accepted or practiced. However, most maintain the view that the acquisition of knowledge and scientific pursuit in general is not in disaccord with Islamic thought and religious belief.

The Ahmadiyya movement emphasize that there is no contradiction between Islam and science. For example, Ahmadi Muslims universally accept in principle the process of evolution, albeit divinely guided, and actively promote it. Over the course of several decades the movement has issued various publications in support of the scientific concepts behind the process of evolution, and frequently engages in promoting how religious scriptures, such as the Qur'an, supports the concept. For general purposes, the second Khalifa of the community, Mirza Basheer-ud-Din Mahmood Ahmad says:
The Holy Quran directs attention towards science, time and again, rather than evoking prejudice against it. The Quran has never advised against studying science, lest the reader should become a non-believer; because it has no such fear or concern. The Holy Quran is not worried that if people will learn the laws of nature its spell will break. The Quran has not prevented people from science, rather it states, "Say, 'Reflect on what is happening in the heavens and the earth.'" (Al Younus)

Jainism does not support belief in a creator deity. According to Jain doctrine, the universe and its constituents – soul, matter, space, time, and principles of motion have always existed (a static universe similar to that of Epicureanism and steady state cosmological model). All the constituents and actions are governed by universal natural laws. It is not possible to create matter out of nothing and hence the sum total of matter in the universe remains the same (similar to law of conservation of mass). Similarly, the soul of each living being is unique and uncreated and has existed since beginningless time.

The Jain theory of causation holds that a cause and its effect are always identical in nature and hence a conscious and immaterial entity like God cannot create a material entity like the universe. Furthermore, according to the Jain concept of divinity, any soul who destroys its karmas and desires, achieves liberation. A soul who destroys all its passions and desires has no desire to interfere in the working of the universe. Moral rewards and sufferings are not the work of a divine being, but a result of an innate moral order in the cosmos; a self-regulating mechanism whereby the individual reaps the fruits of his own actions through the workings of the karmas.

Through the ages, Jain philosophers have adamantly rejected and opposed the concept of creator and omnipotent God and this has resulted in Jainism being labeled as "nastika darsana" or atheist philosophy by the rival religious philosophies. The theme of non-creationism and absence of omnipotent God and divine grace runs strongly in all the philosophical dimensions of Jainism, including its cosmology, karma, moksa and its moral code of conduct. Jainism asserts a religious and virtuous life is possible without the idea of a creator god.

In the 17th century, founders of the Royal Society largely held conventional and orthodox religious views, and a number of them were prominent Churchmen. While theological issues that had the potential to be divisive were typically excluded from formal discussions of the early Society, many of its fellows nonetheless believed that their scientific activities provided support for traditional religious belief. Clerical involvement in the Royal Society remained high until the mid-nineteenth century, when science became more professionalised.

Albert Einstein supported the compatibility of some interpretations of religion with science. In "Science, Philosophy and Religion, A Symposium" published by the Conference on Science, Philosophy and Religion in Their Relation to the Democratic Way of Life, Inc., New York in 1941, Einstein stated:

Einstein thus expresses views of ethical non-naturalism (contrasted to ethical naturalism).

Prominent modern scientists who are atheists include evolutionary biologist Richard Dawkins and Nobel Prize–winning physicist Steven Weinberg. Prominent scientists advocating religious belief include Nobel Prize–winning physicist and United Church of Christ member Charles Townes, evangelical Christian and past head of the Human Genome Project Francis Collins, and climatologist John T. Houghton.

In 1916, 1,000 leading American scientists were randomly chosen from "American Men of Science" and 42% believed God existed, 42% disbelieved, and 17% had doubts/did not know; however when the study was replicated 80 years later using "American Men and Women of Science" in 1996, results were very much the same with 39% believing God exists, 45% disbelieved, and 15% had doubts/did not know. In the same 1996 survey, for scientists in the fields of biology, mathematics, and physics/astronomy, belief in a god that is "in intellectual and affective communication with humankind" was most popular among mathematicians (about 45%) and least popular among physicists (about 22%). In total, in terms of belief toward a personal god and personal immortality, about 60% of United States scientists in these fields expressed either disbelief or agnosticism and about 40% expressed belief. This compared with 62.9% in 1914 and 33% in 1933.

A survey conducted between 2005 and 2007 by Elaine Howard Ecklund of University at Buffalo, The State University of New York of 1,646 natural and social science professors at 21 US research universities found that, in terms of belief in God or a higher power, more than 60% expressed either disbelief or agnosticism and more than 30% expressed belief. More specifically, nearly 34% answered "I do not believe in God" and about 30% answered "I do not know if there is a God and there is no way to find out." In the same study, 28% said they believed in God and 8% believed in a higher power that was not God. Ecklund stated that scientists were often able to consider themselves spiritual without religion or belief in god. Ecklund and Scheitle concluded, from their study, that the individuals from non-religious backgrounds disproportionately had self-selected into scientific professions and that the assumption that becoming a scientist necessarily leads to loss of religion is untenable since the study did not strongly support the idea that scientists had dropped religious identities due to their scientific training. Instead, factors such as upbringing, age, and family size were significant influences on religious identification since those who had religious upbringing were more likely to be religious and those who had a non-religious upbringing were more likely to not be religious. The authors also found little difference in religiosity between social and natural scientists.

Since 1901–2013, 22% of all Nobel prizes have been awarded to Jews despite them being less than 1% of the world population.

Between 1901 and 2000, 654 Laureates belonged to 28 different religions. Most (65%) have identified Christianity in its various forms as their religious preference. Specifically on the science related prizes, Christians have won a total of 73% of all the Chemistry, 65% in Physics, 62% in Medicine, and 54% in all Economics awards. Jews have won 17% of the prizes in Chemistry, 26% in Medicine, and 23% in Physics. Atheists, Agnostics, and Freethinkers have won 7% of the prizes in Chemistry, 9% in Medicine, and 5% in Physics. Muslims have won 13 prizes (three were in scientific categories).

Many studies have been conducted in the United States and have generally found that scientists are less likely to believe in God than are the rest of the population. Precise definitions and statistics vary, with some studies concluding that about of scientists in the U.S. are atheists, agnostic, and have some belief in God (although some might be deistic, for example). This is in contrast to the more than roughly of the general population that believe in some God in the United States. Other studies on scientific organizations like the AAAS show that 51% of their scientists believe in either God or a higher power and 48% having no religion. Belief also varies slightly by field. Two surveys on physicists, geoscientists, biologists, mathematicians, and chemists have noted that, from those specializing in these fields, physicists had lowest percentage of belief in God (29%) while chemists had highest (41%). Other studies show that among members of the National Academy of Sciences, concerning the existence of a personal god who answers prayer, 7% expressed belief, 72% expressed disbelief, and 21% were agnostic, however Eugenie Scott argued that there are methodological issues in the study, including ambiguity in the questions. A study with simplified wording to include impersonal or non-interventionist ideas of God concluded that 40% of leading scientists in the US scientists believe in a god.

In terms of perceptions, most social and natural scientists from 21 American universities did not perceive conflict between science and religion, while 37% did. However, in the study, scientists who had experienced limited exposure to religion tended to perceive conflict. In the same study they found that nearly one in five atheist scientists who are parents (17%) are part of religious congregations and have attended a religious service more than once in the past year. Some of the reasons for doing so are their scientific identity (wishing to expose their children to all sources of knowledge so they can make up their own minds), spousal influence, and desire for community.

A 2009 report by the Pew Research Center found that members of the American Association for the Advancement of Science (AAAS) were "much less religious than the general public," with 51% believing in some form of deity or higher power. Specifically, 33% of those polled believe in God, 18% believe in a universal spirit or higher power, and 41% did not believe in either God or a higher power. 48% say they have a religious affiliation, equal to the number who say they are not affiliated with any religious tradition. 17% were atheists, 11% were agnostics, 20% were nothing in particular, 8% were Jewish, 10% were Catholic, 16% were Protestant, 4% were Evangelical, 10% were other religion. The survey also found younger scientists to be "substantially more likely than their older counterparts to say they believe in God". Among the surveyed fields, chemists were the most likely to say they believe in God.

Elaine Ecklund conducted a study from 2011 to 2014 involving the general US population, including rank and file scientists, in collaboration with the American Association for the Advancement of Science (AAAS). The study noted that 76% of the scientists identified with a religious tradition. 85% of evangelical scientists had no doubts about the existence of God, compared to 35% of the whole scientific population. In terms of religion and science, 85% of evangelical scientists saw no conflict (73% collaboration, 12% independence), while 75% of the whole scientific population saw no conflict (40% collaboration, 35% independence).

Religious beliefs of US professors were examined using a nationally representative sample of more than 1,400 professors. They found that in the social sciences: 23% did not believe in God, 16% did not know if God existed, 43% believed God existed, and 16% believed in a higher power. Out of the natural sciences: 20% did not believe in God, 33% did not know if God existed, 44% believed God existed, and 4% believed in a higher power. Overall, out of the whole study: 10% were atheists, 13% were agnostic, 19% believe in a higher power, 4% believe in God some of the time, 17% had doubts but believed in God, 35% believed in God and had no doubts.

Farr Curlin, a University of Chicago Instructor in Medicine and a member of the MacLean Center for Clinical Medical Ethics, noted in a study that doctors tend to be science-minded religious people. He helped author a study that "found that 76 percent of doctors believe in God and 59 percent believe in some sort of afterlife." Furthermore, "90 percent of doctors in the United States attend religious services at least occasionally, compared to 81 percent of all adults." He reasoned, "The responsibility to care for those who are suffering and the rewards of helping those in need resonate throughout most religious traditions."

Physicians in the United States, by contrast, are much more religious than scientists, with 76% stating a belief in God.

According to the Study of Secularism in Society and Culture's report on 1,100 scientists in India: 66% are Hindu, 14% did not report a religion, 10% are atheist/no religion, 3% are Muslim, 3% are Christian, 4% are Buddhist, Sikh or other. 39% have a belief in a god, 6% have belief in a god sometimes, 30% do not believe in a god but believe in a higher power, 13% do not know if there is a god, and 12% do not believe in a god. 49% believe in the efficacy of prayer, 90% strongly agree or somewhat agree with approving degrees in Ayurvedic medicine. Furthermore, the term "secularism" is understood to have diverse and simultaneous meanings among Indian scientists: 93% believe it to be tolerance of religions and philosophies, 83% see it as involving separation of church and state, 53% see it as not identifying with religious traditions, 40% see it as absence of religious beliefs, and 20% see it as atheism. Accordingly, 75% of Indian scientists had a "secular" outlook in terms of being tolerant of other religions.

According to the Religion Among Scientists in International Context (RASIC) study on 1,581 scientists from the United Kingdom and 1,763 scientists from India, along with 200 interviews: 65% of U.K. scientists identified as nonreligious and only 6% of Indian scientists identify as nonreligious, 12% of scientists in the U.K. attend religious services on a regular basis and 32% of scientists in India do. In terms of the Indian scientists, 73% of scientists responded that there are basic truths in many religions, 27% said they believe in God and 38% expressed belief in a higher power of some kind. In terms of perceptions of conflict between science and religion, less than half of both U.K. scientists (38%) and Indian scientists (18%) perceived conflict between religion and science.

According to Renny Thomas' study on Indian scientists, atheistic scientists in India called themselves atheists even while accepting that their lifestyle is very much a part of tradition and religion. Thus, they differ from Western atheists in that for them following the lifestyle of a religion is not antithetical to atheism.

Over time, scientists and historians have moved away from the conflict thesis and toward compatibility theses (either the integration thesis or non-overlapping magisteria). Many experts have now adopted a "complexity thesis" that combines several other models, further at the expense of the conflict thesis.

Global studies which have pooled data on religion and science from 1981–2001, have noted that countries with high religiosity also have stronger faith in science, while less religious countries have more skepticism of the impact of science and technology. The United States is noted there as distinctive because of greater faith in both God and scientific progress. Other research cites the National Science Foundation's finding that America has more favorable public attitudes towards science than Europe, Russia, and Japan despite differences in levels of religiosity in these cultures.

A study conducted on adolescents from Christian schools in Northern Ireland, noted a positive relationship between attitudes towards Christianity and science once attitudes towards scientism and creationism were accounted for.

A study on people from Sweden concludes that though the Swedes are among the most non-religious, paranormal beliefs are prevalent among both the young and adult populations. This is likely due to a loss of confidence in institutions such as the Church and Science.

Concerning specific topics like creationism, it is not an exclusively American phenomenon. A poll on adult Europeans revealed that 40% believed in naturalistic evolution, 21% in theistic evolution, 20% in special creation, and 19% are undecided; with the highest concentrations of young earth creationists in Switzerland (21%), Austria (20%), Germany (18%). Other countries such as Netherlands, Britain, and Australia have experienced growth in such views as well.

According to a 2015 Pew Research Center Study on the public perceptions on science, people's perceptions on conflict with science have more to do with their perceptions of other people's beliefs than their own personal beliefs. For instance, the majority of people with a religious affiliation (68%) saw no conflict between their own personal religious beliefs and science while the majority of those without a religious affiliation (76%) perceived science and religion to be in conflict. The study noted that people who are not affiliated with any religion, also known as "religiously unaffiliated", often have supernatural beliefs and spiritual practices despite them not being affiliated with any religion and also that "just one-in-six religiously unaffiliated adults (16%) say their own religious beliefs conflict with science." Furthermore, the study observed, "The share of all adults who perceive a conflict between science and their own religious beliefs has declined somewhat in recent years, from 36% in 2009 to 30% in 2014. Among those who are affiliated with a religion, the share of people who say there is a conflict between science and their personal religious beliefs dropped from 41% to 34% during this period."

The 2013 MIT Survey on Science, Religion and Origins examined the views of religious people in America on origins science topics like evolution, the Big Bang, and perceptions of conflicts between science and religion. It found that a large majority of religious people see no conflict between science and religion and only 11% of religious people belong to religions openly rejecting evolution. The fact that the gap between personal and official beliefs of their religions is so large suggests that part of the problem, might be defused by people learning more about their own religious doctrine and the science it endorses, thereby bridging this belief gap. The study concluded that "mainstream religion and mainstream science are neither attacking one another nor perceiving a conflict." Furthermore, they note that this conciliatory view is shared by most leading science organizations such as the American Association for the Advancement of Science (AAAS).

A study collecting data from 2011 to 2014 on the general public, with focus on evangelicals and evangelical scientists was done in collaboration with the American Association for the Advancement of Science (AAAS). Even though evangelicals only make up 26% of the US population, the found that nearly 70 percent of all evangelical Christians do not view science and religion as being in conflict with each other (48% saw them as complementary and 21% saw them as independent) while 73% of the general US population saw no conflict as well.

Other lines of research on perceptions of science among the American public conclude that most religious groups see no general epistemological conflict with science and they have no differences with nonreligious groups in the propensity of seeking out scientific knowledge, although there may be subtle epistemic or moral conflicts when scientists make counterclaims to religious tenets. Findings from the Pew Center note similar findings and also note that the majority of Americans (80–90%) show strong support for scientific research, agree that science makes society and individual's lives better, and 8 in 10 Americans would be happy if their children were to become scientists. Even strict creationists tend to have very favorable views on science.

According to a 2007 poll by the Pew Forum, "while large majorities of Americans respect science and scientists, they are not always willing to accept scientific findings that squarely contradict their religious beliefs." The Pew Forum states that specific factual disagreements are "not common today", though 40% to 50% of Americans do not accept the evolution of humans and other living things, with the "strongest opposition" coming from evangelical Christians at 65% saying life did not evolve. 51% of the population believes humans and other living things evolved: 26% through natural selection only, 21% somehow guided, 4% don't know. In the U.S., biological evolution is the only concrete example of conflict where a significant portion of the American public denies scientific consensus for religious reasons. In terms of advanced industrialized nations, the United States is the most religious.

A 2009 study from the Pew Research Center on Americans perceptions of science, showed a broad consensus that most Americans, including most religious Americans, hold scientific research and scientists themselves in high regard. The study showed that 84% of Americans say they view science as having a mostly positive impact on society. Among those who attend religious services at least once a week, the number is roughly the same at 80%. Furthermore, 70% of U.S. adults think scientists contribute "a lot" to society.

A 2011 study on a national sample of US college students examined whether these students viewed the science / religion relationship as reflecting primarily conflict, collaboration, or independence. The study concluded that the majority of undergraduates in both the natural and social sciences do not see conflict between science and religion. Another finding in the study was that it is more likely for students to move away from a conflict perspective to an independence or collaboration perspective than towards a conflict view.

In the US, people who had no religious affiliation were no more likely than the religious population to have New Age beliefs and practices.

By tradition:

In the US:




</doc>
<doc id="29268" url="https://en.wikipedia.org/wiki?curid=29268" title="Stephen Sondheim">
Stephen Sondheim

Stephen Joshua Sondheim (; born March 22, 1930) is an American composer and lyricist known for more than a half-century of contributions to musical theater. Sondheim has received an Academy Award, eight Tony Awards (more than any other composer, including a Special Tony Award for Lifetime Achievement in the Theatre), eight Grammy Awards, a Pulitzer Prize, a Laurence Olivier Award, and a 2015 Presidential Medal of Freedom. He has been described by Frank Rich of "The New York Times" as "now the greatest and perhaps best-known artist in the American musical theater". His best-known works as composer and lyricist include "A Funny Thing Happened on the Way to the Forum" (1962), "Company" (1970), "Follies" (1971), "A Little Night Music" (1973), "Pacific Overtures" (1976), "" (1979), "Merrily We Roll Along" (1981), "Sunday in the Park with George" (1984), "Into the Woods" (1987), "Assassins" (1990), and "Passion" (1994). He also wrote the lyrics for "West Side Story" (1957) and "Gypsy" (1959).

Sondheim has written film music, contributing "Goodbye for Now" for Warren Beatty’s 1981 "Reds". He wrote five songs for 1990's "Dick Tracy", including "Sooner or Later (I Always Get My Man)" by Madonna, which won the Academy Award for Best Song.

Sondheim was president of the Dramatists Guild from 1973 to 1981. To celebrate his 80th birthday, the former Henry Miller's Theatre was renamed the Stephen Sondheim Theatre on September 15, 2010, and the BBC Proms held a concert in his honor. Cameron Mackintosh has called Sondheim "possibly the greatest lyricist ever".

Sondheim was born into a Jewish family in New York City, the son of Etta Janet ("Foxy," née Fox; 1897–1992) and Herbert Sondheim (1895–1966). His father manufactured dresses designed by his mother. The composer grew up on the Upper West Side of Manhattan and, after his parents divorced, on a farm near Doylestown, Pennsylvania. As the only child of well-to-do parents living in the San Remo on Central Park West, he was described in Meryle Secrest's biography ("Stephen Sondheim: A Life") as an isolated, emotionally-neglected child. When he lived in New York, Sondheim attended ECFS, the Ethical Culture Fieldston School known simply as "Fieldston”. He later attended the New York Military Academy and George School, a private Quaker preparatory school in Bucks County, Pennsylvania where he wrote his first musical, "By George," and from which he graduated in 1946. Sondheim spent several summers at Camp Androscoggin. He later matriculated to Williams College and graduated in 1950.

He traces his interest in theatre to "Very Warm for May", a Broadway musical he saw when he was nine. "The curtain went up and revealed a piano," Sondheim recalled. "A butler took a duster and brushed it up, tinkling the keys. I thought that was thrilling."

When Sondheim was ten, his father (already a distant figure) left his mother for another woman (Alicia, with whom he had two sons). Herbert sought custody of Stephen but was unsuccessful. Sondheim explained to biographer Secrest that he was "what they call an institutionalized child, meaning one who has no contact with any kind of family. You're in, though it's luxurious, you're in an environment that supplies you with everything but human contact. No brothers and sisters, no parents, and yet plenty to eat, and friends to play with and a warm bed, you know?"

Sondheim detested his mother, who was said to be psychologically abusive and projected her anger from her failed marriage on her son: "When my father left her, she substituted me for him. And she used me the way she used him, to come on to and to berate, beat up on, you see. What she did for five years was treat me like dirt, but come on to me at the same time." She once wrote him a letter saying that the "only regret [she] ever had was giving him birth". When his mother died in the spring of 1992, Sondheim did not attend her funeral. He had already been estranged from her for nearly 20 years.

When Sondheim was about ten years old (around the time of his parents' divorce), he became friends with James Hammerstein, son of lyricist and playwright Oscar Hammerstein II. The elder Hammerstein became Sondheim's surrogate father, influencing him profoundly and developing his love of musical theatre. Sondheim met Hal Prince, who would direct many of his shows, at the opening of "South Pacific," Hammerstein's musical with Richard Rodgers. The comic musical he wrote at George School, "By George", was a success among his peers and buoyed the young songwriter's self-esteem. When Sondheim asked Hammerstein to evaluate it as though he had no knowledge of its author, he said it was the worst thing he had ever seen: "But if you want to know why it's terrible, I'll tell you." They spent the rest of the day going over the musical, and Sondheim later said, "In that afternoon I learned more about songwriting and the musical theater than most people learn in a lifetime."

Hammerstein designed a course of sorts for Sondheim on constructing a musical. He had the young composer write four musicals, each with one of the following conditions:

None of the "assignment" musicals was produced professionally. "High Tor" and "Mary Poppins" have never been produced: The rights holder for the original "High Tor" refused permission, and "Mary Poppins" was unfinished.

Sondheim began attending Williams College, a liberal arts college in Williamstown, Massachusetts whose theatre program attracted him. His first teacher there was Robert Barrow:
 ... everybody hated him because he was very dry, and I thought he was wonderful because he was very dry. And Barrow made me realize that all my romantic views of art were nonsense. I had always thought an angel came down and sat on your shoulder and whispered in your ear 'dah-dah-dah-DUM.' Never occurred to me that art was something worked out. And suddenly it was skies opening up. As soon as you find out what a leading tone is, you think, Oh my God. What a diatonic scale is – Oh my God! The logic of it. And, of course, what that meant to me was: Well, I can do that. Because you just don't know. You think it's a talent, you think you're born with this thing. What I've found out and what I believed is that everybody is talented. It's just that some people get it developed and some don't.

The composer told Meryle Secrest, "I just wanted to study composition, theory, and harmony without the attendant musicology that comes in graduate school. But I knew I wanted to write for the theatre, so I wanted someone who did not disdain theatre music." Barrow suggested that Sondheim study with Milton Babbitt, who Sondheim described as "a frustrated show composer" with whom he formed "a perfect combination". When he met Babbitt, he was working on a musical for Mary Martin based on the myth of Helen of Troy. Sondheim and Babbitt would meet once a week in New York City for four hours (at the time, Babbitt was teaching at Princeton University). According to Sondheim, they spent the first hour dissecting Rodgers and Hart or George Gershwin or studying Babbitt's favorites (Buddy DeSylva, Lew Brown and Ray Henderson). They then proceeded to other forms of music (such as Mozart's Jupiter Symphony), critiquing them the same way. Babbitt and Sondheim, fascinated by mathematics, studied songs by a variety of composers (especially Jerome Kern). Sondheim told Secrest that Kern had the ability "to develop a single motif through tiny variations into a long and never boring line and his maximum development of the minimum of material". He said about Babbitt, "I am his maverick, his one student who went into the popular arts with all his serious artillery". At Williams, Sondheim wrote a musical adaption of "Beggar on Horseback" (a 1924 play by George S. Kaufman and Marc Connelly, with permission from Kaufman) which had three performances. A member of the Beta Theta Pi fraternity, he graduated "magna cum laude" in 1950.

"A few painful years of struggle" followed, when Sondheim auditioned songs, lived in his father's dining room to save money and spent time in Hollywood writing for the television series "Topper". He devoured 1940s and 1950s films, and has called cinema his "basic language"; his film knowledge got him through "The $64,000 Question" contestant tryouts. Sondheim dislikes movie musicals, favoring classic dramas such as "Citizen Kane", "The Grapes of Wrath" and "A Matter of Life and Death": "Studio directors like Michael Curtiz and Raoul Walsh ... were heroes of mine. They went from movie to movie to movie, and every third movie was good and every fifth movie was great. There wasn't any cultural pressure to make art".

At age 22, Sondheim had finished the four shows requested by Hammerstein. Julius and Philip Epstein's "Front Porch in Flatbush", unproduced at the time, was being shopped around by Lemuel (Lem) Ayers. Ayers approached Frank Loesser and another composer, who turned him down. Ayers and Sondheim met as ushers at a wedding, and Ayers commissioned Sondheim for three songs for the show; Julius Epstein flew in from California and hired Sondheim, who worked with him in California for four or five months. After eight auditions for backers, half the money needed was raised. The show, retitled "Saturday Night", was intended to open during the 1954–55 Broadway season; however, Ayers died of leukemia in his early forties. The rights transferred to his widow, Shirley, and due to her inexperience the show did not continue as planned; it opened off-Broadway in 2000. Sondheim later said, "I don't have any emotional reaction to "Saturday Night" at all – except fondness. It's not bad stuff for a 23-year-old. There are some things that embarrass me so much in the lyrics – the missed accents, the obvious jokes. But I decided, leave it. It's my baby pictures. You don't touch up a baby picture – you're a baby!"

Burt Shevelove invited Sondheim to a party; Sondheim arrived before him, and knew no one else well. He saw a familiar face: Arthur Laurents, who had seen one of the auditions of "Saturday Night", and they began talking. Laurents told him he was working on a musical version of "Romeo and Juliet" with Leonard Bernstein, but they needed a lyricist; Betty Comden and Adolph Green, who were supposed to write the lyrics, were under contract in Hollywood. He said that although he was not a big fan of Sondheim's music, he enjoyed the lyrics from "Saturday Night" and he could audition for Bernstein. The following day, Sondheim met and played for Bernstein, who said he would let him know. The composer wanted to write music and lyrics; after consulting with Hammerstein, Bernstein told Sondheim he could write music later. In 1957, "West Side Story" opened; directed by Jerome Robbins, it ran for 732 performances. Sondheim has expressed dissatisfaction with his lyrics, saying that they do not always fit the characters and are sometimes too consciously poetic. While Bernstein was working on "Candide", Sondheim reportedly wrote some of "West Side Story"s music; Bernstein's co-lyricist credit disappeared from "West Side Story" during its tryout, possibly as a trade-off. Sondheim insisted that Bernstein told the producers to list him as the sole lyricist. He described the division of the royalties, saying that Bernstein received three percent and he received one percent. Bernstein suggested evening the percentage at two percent each, but Sondheim refused because he wanted the credit. Sondheim later said he wished "someone stuffed a handkerchief in my mouth because it would have been nice to get that extra percentage".

After "West Side Story" opened, Shevelove lamented the lack of "low-brow comedy" on Broadway and mentioned a possible musical based on Plautus' Roman comedies. When Sondheim was interested in the idea he called a friend, Larry Gelbart, to co-write the script. The show went through a number of drafts, and was interrupted briefly by Sondheim's next project.

In 1959, Sondheim was approached by Laurents and Robbins for a musical version of Gypsy Rose Lee's memoir after Irving Berlin and Cole Porter turned it down. Sondheim agreed, but Ethel Merman – cast as Mama Rose – had just finished "Happy Hunting" with an unknown composer (Harold Karr) and lyricist (Matt Dubey). Although Sondheim wanted to write the music and lyrics, Merman refused to let another first-time composer write for her and demanded that Jule Styne write the music. Sondheim, concerned that writing lyrics again would pigeonhole him as a lyricist, called his mentor for advice. Hammerstein told him he should take the job, because writing a vehicle for a star would be a good learning experience. Sondheim agreed; "Gypsy" opened on May 21, 1959, and ran for 702 performances.

In 1960, Sondheim lost his mentor and father figure, Oscar Hammerstein. He remembered that shortly before Hammerstein's death, Hammerstein had given him a portrait of himself. Sondheim asked him to inscribe it, and said later about the request that it was "weird ... it's like asking your father to inscribe something". Reading the inscription ("For Stevie, My Friend and Teacher") choked up the composer, who said: "That describes Oscar better than anything I could say."

When he walked away from the house that evening, Sondheim remembered a sad, sinking feeling that they had said their final goodbye. He never saw his mentor again; three days later, Hammerstein died of stomach cancer and Hammerstein's protégé eulogized him at his funeral.

The first musical for which Sondheim wrote the music and lyrics was "A Funny Thing Happened on the Way to the Forum", which opened in 1962 and ran for 964 performances. The book, based on farces by Plautus, was written by Burt Shevelove and Larry Gelbart. Sondheim's score was not well received; although the show won several Tony Awards (including best musical), he did not receive a nomination.

Sondheim had participated in three straight hits, but his next show – 1964's "Anyone Can Whistle" – was a nine-performance failure (although it introduced Angela Lansbury to musical theatre). "Do I Hear a Waltz?", based on Arthur Laurents' 1952 play "The Time of the Cuckoo", was intended as another Rodgers and Hammerstein musical with Mary Martin in the lead. A new lyricist was needed, and Laurents and Rodgers' daughter, Mary, asked Sondheim to fill in. Although Richard Rodgers and Sondheim agreed that the original play did not lend itself to musicalization, they began writing the musical version. The project had many problems, Rodgers' alcoholism among them; Sondheim, calling it the one project he regretted, then decided to work only when he could write both music and lyrics. He asked author and playwright James Goldman to join him as bookwriter for a new musical. Inspired by a "New York Times" article about a gathering of former Ziegfeld Follies showgirls, it was entitled "The Girl Upstairs" (and would later become "Follies").

In 1966, Sondheim semi-anonymously provided lyrics for "The Boy From...," a parody of "The Girl from Ipanema" in the off-Broadway revue "The Mad Show". The song was credited to "Esteban Ria Nido", Spanish for "Stephen River Nest", and in the show's playbill the lyrics were credited to "Nom De Plume". That year Goldman and Sondheim hit a creative wall on "The Girls Upstairs", and Goldman asked Sondheim about writing a TV musical. The result was "Evening Primrose", with Anthony Perkins and Charmian Carr. Written for the anthology series "ABC Stage 67" and produced by Hubbell Robinson, it was broadcast on November 16, 1966. According to Sondheim and director Paul Bogart, the musical was written only because Goldman needed money for rent. The network disliked the title and Sondheim's alternative, "A Little Night Music".

After Sondheim finished "Evening Primrose", Jerome Robbins asked him to adapt Bertolt Brecht's "The Measures Taken" despite the composer's general dislike of Brecht's work. Robbins wanted to adapt another Brecht play, "The Exception and the Rule", and asked John Guare to adapt the book. Leonard Bernstein had not written for the stage in some time, and his contract as conductor of the New York Philharmonic was ending. Sondheim was invited to Robbins' house in the hope that Guare would convince him to write the lyrics for a musical version of "The Exception and the Rule"; according to Robbins, Bernstein would not work without Sondheim. When Sondheim agreed, Guare asked: "Why haven't you all worked together since "West Side Story"?" Sondheim answered, "You'll see". Guare said that working with Sondheim was like being with an old college roommate, and he depended on him to "decode and decipher their crazy way of working"; Bernstein worked only after midnight, and Robbins only in the early morning. Bernstein's score, which was supposed to be light, was influenced by his need to make a musical statement. Stuart Ostrow, who worked with Sondheim on "The Girls Upstairs", agreed to produce the musical (now entitled "A Pray By Blecht" and, later, "The Race to Urga"). An opening night was scheduled, but during auditions Robbins asked to be excused for a moment. When he did not return, a doorman said he had gotten into a limousine to go to John F. Kennedy International Airport. Bernstein burst into tears and said, "It's over"; Sondheim said, "I was ashamed of the whole project. It was arch and didactic in the worst way." He wrote one-and-a-half songs and threw them away, the only time he has ever done that. Eighteen years later, Sondheim refused Bernstein and Robbins' request to retry the show.
He has lived in a Turtle Bay, Manhattan brownstone since writing "Gypsy" in 1959. Ten years later, while he was playing music he heard a knock on the door. His neighbor, Katharine Hepburn, was in "bare feet – this angry, red-faced lady" and told him "You have been keeping me awake all night!" (she was practicing for her musical debut in "Coco"). When Sondheim asked why she had not asked him to play for her, she said she lost his phone number. According to Sondheim, "My guess is that she wanted to stand there in her bare feet, suffering for her art".

After finishing "Do I Hear a Waltz", Sondheim devoted himself to composing and writing lyrics for a variety of musicals. He collaborated with producer-director Hal Prince on six musicals from 1970 to 1981, beginning with the 1970 concept musical "Company". Without a straightforward plot, "Company" (with a book by George Furth) centered on a set of characters and themes. It opened on April 26, 1970 at the Alvin Theatre, where it ran for 705 performances after seven previews, and won Tony Awards for best musical, best music and best lyrics. It was revived on Broadway in 1995 and 2006.

"Follies" (1971), with a book by James Goldman, opened on April 4, 1971 at the Winter Garden Theatre and ran for 522 performances after 12 previews. The plot centers on a reunion, in a crumbling Broadway theatre scheduled for demolition, of performers in Weismann's Follies (a musical revue, based on the Ziegfeld Follies, which played in that theatre between the world wars). "Follies" focuses on two couples: Buddy and Sally Durant Plummer, and Benjamin and Phyllis Rogers Stone. The show enjoyed two revivals on Broadway in 2001 and 2011.

"A Little Night Music" (1973), with a more traditional plot based on Ingmar Bergman's "Smiles of a Summer Night" and a score primarily in waltz time, was one of the composer's greatest successes. "Time" magazine called it "Sondheim's most brilliant accomplishment to date". "Send in the Clowns", a song from the musical, was a hit for Judy Collins. "A Little Night Music" opened on Broadway at the Shubert Theatre on February 25, 1973 and closed on August 3, 1974, after 601 performances and 12 previews. It moved to the Majestic Theatre on September 17, 1973, where it finished its run. The show received a Broadway revival in 2009.

"By Bernstein" premiered at the off-Broadway Westside Theatre on November 23, 1975 and closed on December 7, running for 40 previews and 17 performances. Its lyrics and music were by Leonard Bernstein, with additional lyrics by others (including Sondheim). Conceived and written by Betty Comden, Adolph Green and Norman L. Berman and directed by Michael Bawtree, "By Bernstein" featured Jack Bittner, Margery Cohen, Jim Corti, Ed Dixon, Patricia Elliott, Kurt Peterson and Janie Sell. The two Sondheim contributions were "In There" (from the adaptation of "The Exception and the Rule") and a song cut from "West Side Story", "Kids Ain't (Like Everybody Else)".

"Pacific Overtures" (1976), with a book by John Weidman, was the most non-traditional of the Sondheim-Prince collaborations. The show explored the westernization of Japan and was originally presented in Kabuki style, and was revived on Broadway in 2004.

"" (1979), Sondheim's most operatic score and libretto (which, with "Pacific Overtures" and "A Little Night Music", has been produced in opera houses), explores an unlikely topic: murderous revenge and cannibalism. The book, by Hugh Wheeler, is based on Christopher Bond's 1973 stage version of the Victorian original. The show has since been revived on Broadway twice (1989, 2005), and has been performed in musical theaters and opera houses alike. It currently runs off-Broadway at the Barrow Street Theatre.

"Merrily We Roll Along" (1981), with a book by George Furth, is one of Sondheim's more traditional scores; Frank Sinatra and Carly Simon have recorded songs from the musical. According to Sondheim's music director, Paul Gemignani, "Part of Steve's ability is this extraordinary versatility." Although "Merrily" closed after 16 performances, its score has been subsequently recorded. Martin Gottfried wrote, "Sondheim had set out to write traditional songs ... But [despite] that there is nothing ordinary about the music." Sondheim and Furth have revised the show since its original production, and Sondheim later said: "Did I feel betrayed? I'm not sure I would put it like that. What did surprise me was the feeling around the Broadway community – if you can call it that, though I guess I will for lack of a better word – that they wanted Hal and me to fail."

"Merrily"s failure greatly affected Sondheim; he was ready to quit theatre and do movies, create video games or write mysteries: "I wanted to find something to satisfy myself that does not involve Broadway and dealing with all those people who hate me and hate Hal." Sondheim and Prince's collaboration was suspended from "Merrily" to the 2003 production of "Bounce", another failure.

However, Sondheim decided "that there are better places to start a show" and found a new collaborator in James Lapine after he saw Lapine's "Twelve Dreams" off-Broadway in 1981: "I was discouraged, and I don't know what would have happened if I hadn't discovered "Twelve Dreams" at the Public Theatre"; Lapine has a taste "for the avant-garde and for visually-oriented theatre in particular". Their first collaboration was "Sunday in the Park with George" (1984), with Sondheim's music evoking Georges Seurat's pointillism. Sondheim and Lapine won the 1985 Pulitzer Prize for Drama for the play, and it was revived on Broadway in 2008, and again in a limited run in 2017.

They collaborated on "Into the Woods" (1987), a musical based on several Brothers Grimm fairy tales. Although Sondheim has been called the first composer to bring rap music to Broadway (with the Witch in the opening number of "Into the Woods"), he attributes the first rap in theatre to Meredith Willson's "Rock Island" from "The Music Man". The show was revived on Broadway in 2002.

Sondheim and Lapine's last work together was the rhapsodic "Passion" (1994), adapted from Ettore Scola's Italian film "Passione D'Amore". With a run of 280 performances, "Passion" was the shortest-running show to win a Tony Award for Best Musical.

"Assassins" opened off-Broadway at Playwrights Horizons on December 18, 1990, with music and lyrics by Sondheim and its book by John Weidman. The musical closed on February 16, 1991, after 73 performances. Its idea derived from Sondheim's days as a panelist at producer Stuart Ostrow's Musical Theater Lab, when he read a script by playwright Charles Gilbert. He asked Gilbert for permission to use his idea; although Gilbert offered to write the book, Sondheim had Weidman in mind. The show finally opened on Broadway in 2004.

"Saturday Night" was shelved until its 1997 production at London's Bridewell Theatre. The following year, its score was recorded; a revised version, with two new songs, ran off-Broadway at Second Stage Theatre in 2000 and at London's Jermyn Street Theatre in 2009.

During the late 1990s, Sondheim and Weidman reunited with Hal Prince for "Wise Guys", a musical comedy following brothers Addison and Wilson Mizner. A Broadway production, starring Nathan Lane and Victor Garber, directed by Sam Mendes and planned for the spring of 2000, was delayed. Renamed "Bounce" in 2003, it was produced at the Goodman Theatre in Chicago and the Kennedy Center in Washington, D.C. Although after poor reviews "Bounce" never reached Broadway, a revised version opened off-Broadway as "Road Show" at the Public Theater on October 28, 2008. Directed by John Doyle, it closed on December 28, 2008.

Asked about writing new work, Sondheim replied in 2006: "No ... It's age. It's a diminution of energy and the worry that there are no new ideas. It's also an increasing lack of confidence. I'm not the only one. I've checked with other people. People expect more of you and you're aware of it and you shouldn't be." In December 2007 he said that in addition to continuing work on "Bounce", he was "nibbling at a couple of things with John Weidman and James Lapine".

Lapine created a multimedia production, originally entitled "Sondheim: a Musical Revue", which was scheduled to open in April 2009 at the Alliance Theatre in Atlanta; however, it was canceled due to "difficulties encountered by the commercial producers attached to the project ... in raising the necessary funds". A revised version, "Sondheim on Sondheim", was produced at Studio 54 by the Roundabout Theatre Company; previews began on March 19, 2010, and it ran from April 22 to June 13. The revue's cast included Barbara Cook, Vanessa L. Williams, Tom Wopat, Norm Lewis and Leslie Kritzer.

Sondheim collaborated with Wynton Marsalis on "A Bed and a Chair: A New York Love Affair", an Encores! concert on November 13–17, 2013 at New York City Center. Directed by John Doyle with choreography by Parker Esse, it consisted of "more than two dozen Sondheim compositions, each piece newly re-imagined by Marsalis". The concert featured Bernadette Peters, Jeremy Jordan, Norm Lewis, Cyrille Aimée, four dancers and the Jazz at Lincoln Center Orchestra conducted by David Loud. In "Playbill", Steven Suskin described the concert as "neither a new musical, a revival, nor a standard songbook revue; it is, rather, a staged-and-sung chamber jazz rendition of a string of songs ... Half of the songs come from "Company" and "Follies"; most of the other Sondheim musicals are represented, including the lesser-known "Passion" and "Road Show"".

Sondheim wrote additional songs for the film adaptation of "Into the Woods", including "Rainbows" (which he included in his second book).

In February 2012 it was announced that Sondheim would collaborate on a new musical with David Ives, and he had "about 20–30 minutes of the musical completed". The show, tentatively called "All Together Now", was assumed to follow the format of "Merrily We Roll Along". Sondheim described the project as "two people and what goes into their relationship ... We'll write for a couple of months, then have a workshop. It seemed experimental and fresh 20 years ago. I have a feeling it may not be experimental and fresh any more". On October 11, 2014, it was confirmed the Sondheim and Ives musical would be based on two Luis Buñuel films ("The Exterminating Angel" and "The Discreet Charm of the Bourgeoisie") and would reportedly open (in previews) at the Public Theater in 2017.

In August 2016 a reading for the musical was held at the Public Theater, and it was reported that only the first act was finished, which cast doubt on the speculated 2017 start of previews. There was a workshop in November 2016, with the participation of Matthew Morrison, Shuler Hensley, Heidi Blickenstaff, Sierra Boggess, Gabriel Ebert, Sara Stiles, Michael Cerveris and Jennifer Simard. The working title was reported to be "Buñuel" by the New York Post and other outlets, but Sondheim later clarified that this was an error and that they still had no title. As of January 2018, no dates regarding the musical had been announced.

The Kennedy Center held a Sondheim Celebration, running from May to August 2002, consisting of six of Sondheim's musicals: "Sweeney Todd", "Company", "Sunday in the Park With George", "Merrily We Roll Along", "Passion" and "A Little Night Music". On April 28, 2002, in connection with the Sondheim Celebration Sondheim and Frank Rich of "the New York Times" had a conversation. They appeared in four interviews, entitled "A Little Night Conversation with Stephen Sondheim", in California and Portland, Oregon in March 2008 and at Oberlin College in September. The "Cleveland Jewish News" reported on their Oberlin appearance: "Sondheim said: 'Movies are photographs; the stage is larger than life.' What musicals does Sondheim admire the most? "Porgy and Bess" tops a list which includes "Carousel", "She Loves Me", and "The Wiz", which he saw six times. Sondheim took a dim view of today's musicals. What works now, he said, are musicals that are easy to take; audiences don't want to be challenged". Sondheim and Rich had additional conversations on January 18, 2009 at Avery Fisher Hall, on February 2 at the Landmark Theatre in Richmond, Virginia, on February 21 at the Kimmel Center in Philadelphia and on April 20 at the University of Akron in Akron, Ohio. The conversations were reprised at Tufts and Brown University in February 2010, at the University of Tulsa in April and at Lafayette College on March 8, 2011. Sondheim had another "conversation with" Sean Patrick Flahaven (associate editor of "The Sondheim Review") at the Kravis Center in West Palm Beach on February 4, 2009, in which he discussed many of his songs and shows: "On the perennial struggles of Broadway: 'I don't see any solution for Broadway's problems except subsidized theatre, as in most civilized countries of the world.'"

On February 1, 2011, Sondheim joined former "Salt Lake Tribune" theatre critic Nancy Melich before an audience of 1,200 at Kingsbury Hall. Melich described the evening: He was visibly taken by the university choir, who sang two songs during the evening, "Children Will Listen" and "Sunday", and then returned to reprise "Sunday". During that final moment, Sondheim and I were standing, facing the choir of students from the University of Utah's opera program, our backs to the audience, and I could see tears welling in his eyes as the voices rang out. Then, all of a sudden, he raised his arms and began conducting, urging the student singers to go full out, which they did, the crescendo building, their eyes locked with his, until the final "on an ordinary Sunday" was sung. It was thrilling, and a perfect conclusion to a remarkable evening – nothing ordinary about it.

On March 13, 2008, "A Salon With Stephen Sondheim" (which sold out in three minutes) was hosted by the Academy for New Musical Theatre in Hollywood.

An avid fan of games, in 1968 and 1969 Sondheim published a series of cryptic crossword puzzles in "New York" magazine. In 1987 "Time" called his love of puzzlemaking "legendary in theater circles," adding that the central character of Anthony Shaffer's play "Sleuth" was inspired by the composer. According to a rumor (denied by Shaffer in a March 10, 1996 "New York Times" interview), "Sleuth" had the working title "Who's Afraid of Stephen Sondheim?" His love of puzzles and mysteries is evident in "The Last of Sheila", an intricate whodunit written with longtime friend Anthony Perkins. The 1973 film, directed by Herbert Ross, featured Dyan Cannon, Raquel Welch, James Mason, James Coburn and Richard Benjamin.

Sondheim tried playwriting one more time, collaborating with "Company" librettist George Furth on "Getting Away with Murder" in 1996, but the unsuccessful Broadway production closed after 29 previews and 17 performances. His compositions have included a number of film scores, including a set of songs written for Warren Beatty's 1990 film version of "Dick Tracy". One of Sondheim's songs for the film, "Sooner or Later (I Always Get My Man)" by Madonna, won him an Academy Award.

According to Sondheim, he was asked to translate "Mahagonny-Songspiel": "But, I'm not a Brecht/Weill fan and that's really all there is to it. I'm an apostate: I like Weill's music when he came to America better than I do his stuff before ... I love "The Threepenny Opera" but, outside of "The Threepenny Opera", the music of his I like is the stuff he wrote in America – when he was not writing with Brecht, when he was writing for Broadway." He turned down an offer to musicalize Nathanael West's "A Cool Million" with James Lapine around 1982.

Sondheim worked with William Goldman on "Singing Out Loud", a musical film, in 1992, penning the song "Water Under the Bridge". According to the composer, Goldman wrote one or two drafts of the script and Sondheim wrote six-and-a-half songs when director Rob Reiner lost interest in the project. "Dawn" and "Sand", from the film, were recorded for the albums "Sondheim at the Movies" and "Unsung Sondheim". Sondheim and Leonard Bernstein wrote "The Race to Urga", scheduled for Lincoln Center in 1969, but when Jerome Robbins left the project it was not produced.

In 1991 Sondheim worked with Terrence McNally on a musical, "All Together Now". McNally said, "Steve was interested in telling the story of a relationship from the present back to the moment when the couple first met. We worked together a while, but we were both involved with so many other projects that this one fell through". The story follows Arden Scott, a 30-something female sculptor, and Daniel Nevin (a slightly-younger, sexually attractive restaurateur). Its script, with concept notes by McNally and Sondheim, is archived in the Harry Ransom Center at the University of Texas at Austin.

In August 2003, Sondheim expressed interest in the idea of a creating a musical adaption of the 1993 comedy film "Groundhog Day". However, in a 2008 live chat, he said that "to make a musical of "Groundhog Day" would be to gild the lily. It cannot be improved." The musical was later created and premiered in 2016 with music and lyrics by Tim Minchin and book by Danny Rubin (screenwriter of the film) with Sondheim's blessing.

Sondheim's 2010 "Finishing the Hat" annotates his lyrics "from productions dating 1954–1981. In addition to published and unpublished lyrics from "West Side Story", "Follies" and "Company", the tome finds Sondheim discussing his relationship with Oscar Hammerstein II and his collaborations with composers, actors and directors throughout his lengthy career". The book, first of a two-part series, is named after a song from "Sunday in the Park With George". Sondheim said, "It's going to be long. I'm not, by nature, a prose writer, but I'm literate, and I have a couple of people who are vetting it for me, whom I trust, who are excellent prose writers". "Finishing the Hat" was published in October 2010. According to a "New York Times" review, "The lyrics under consideration here, written during a 27-year period, aren't presented as fixed and sacred paradigms, carefully removed from tissue paper for our reverent inspection. They're living, evolving, flawed organisms, still being shaped and poked and talked to by the man who created them". The book was 11th on the "New York Times" Hardcover Nonfiction list for November 5, 2010.

Its sequel, "Look, I Made a Hat: Collected Lyrics (1981–2011) with Attendant Comments, Amplifications, Dogmas, Harangues, Digressions, Anecdotes and Miscellany", was published on November 22, 2011. The book, continuing from "Sunday in the Park With George" (where "Finishing the Hat" ended), includes sections on Sondheim's work in film and television.

After he was mentored by Oscar Hammerstein II Sondheim has returned the favor, saying that he loves "passing on what Oscar passed on to me". In an interview with Sondheim for "The Legacy Project", composer-lyricist Adam Guettel (son of Mary Rodgers and grandson of Richard Rodgers) recalls how as a 14-year-old boy he showed Sondheim his work. Guettel was "crestfallen" since he had come in "sort of all puffed up thinking [he] would be rained with compliments and things", which was not the case since Sondheim had some "very direct things to say". Later, Sondheim wrote and apologized to Guettel for being "not very encouraging" when he was actually trying to be "constructive".

Sondheim also mentored a fledgling Jonathan Larson, attending Larson's workshop for his "Superbia" (a musical version of "Nineteen Eighty-Four"). In Larson's musical "Tick, Tick... Boom!", the phone message is played in which Sondheim apologizes for leaving early, says he wants to meet him and is impressed with his work. After Larson's death, Sondheim called him one of the few composers "attempting to blend contemporary pop music with theater music, which doesn't work very well; he was on his way to finding a real synthesis. A good deal of pop music has interesting lyrics, but they are not theater lyrics". A musical-theatre composer "must have a sense of what is theatrical, of how you use music to tell a story, as opposed to writing a song. Jonathan understood that instinctively."

Around 2008, Sondheim approached Lin-Manuel Miranda to work with him translating "West Side Story" lyrics into Spanish for an upcoming Broadway revival. Miranda then approached Sondheim with his new project "Hamilton", then called "The Hamilton Mixtape", which Sondheim gave notes on. Sondheim was originally wary of the project saying he was "worried that an evening of rap might get monotonous". However, Sondheim believed Miranda's attention to, and respect for, good rhyming made it work.

A supporter for writers' rights in the theatre industry, Stephen Sondheim is an active member of the Dramatists Guild of America. In 1973, he was elected as the Guild's sixteenth president, and he continued his presidency for the non-profit organization until 1981.

Unless otherwise noted, music and lyrics are by Stephen Sondheim.

"Side By Side By Sondheim" (1976), "Marry Me A Little" (1980), "Putting It Together" (1993) and "Sondheim on Sondheim" (2010): Anthologies or revues of Sondheim's work as composer and lyricist, with songs performed or cut from productions. "Jerome Robbins' Broadway" features "You Gotta Have a Gimmick" from "Gypsy", "Suite of Dances" from "West Side Story" and "Comedy Tonight" from "A Funny Thing Happened on the Way to the Forum". A new revue, "Secret Sondheim ... a celebration of his lesser known work", conceived and directed by Tim McArthur, was produced at the Jermyn Street Theatre in July 2010. Sondheim's "Pretty Women" and "Everybody Ought to Have a Maid" are featured in "The Madwoman of Central Park West".



Several benefits and concerts were performed to celebrate Sondheim's 80th birthday in 2010. Among them were the New York Philharmonic's March 15 and 16 "Sondheim: The Birthday Concert" at Lincoln Center's Avery Fisher Hall, hosted by David Hyde Pierce. The concert included Sondheim's music, performed by some of the original performers. Lonny Price directed, and Paul Gemignani conducted; performers included Laura Benanti, Matt Cavenaugh, Michael Cerveris, Victoria Clark, Jenn Colella, Jason Danieley, Alexander Gemignani, Joanna Gleason, Nathan Gunn, George Hearn, Patti LuPone, Marin Mazzie, Audra McDonald, John McMartin, Donna Murphy, Karen Olivo, Laura Osnes, Mandy Patinkin, Bernadette Peters, Bobby Steggert, Elaine Stritch, Jim Walton, Chip Zien and the 2009 Broadway revival cast of "West Side Story". A ballet was performed by Blaine Hoven and María Noel Riccetto to Sondheim's score for "Reds", and Jonathan Tunick paid tribute to his longtime collaborator. The concert was broadcast on PBS' "Great Performances" show in November, and its DVD was released on November 16.

"Sondheim 80", a Roundabout Theatre Company benefit, was held on March 22. The evening included a performance of "Sondheim on Sondheim", dinner and a show at the New York Sheraton. "A very personal star-studded musical tribute" featured new songs by contemporary musical-theatre writers. The composers (who sang their own songs) included Tom Kitt and Brian Yorkey, Michael John LaChiusa, Andrew Lippa, Robert Lopez and Kristen Anderson-Lopez, Lin-Manuel Miranda (accompanied by Rita Moreno), Duncan Sheik, and Jeanine Tesori and David Lindsay-Abaire. Bernadette Peters performed a song which had been cut from a Sondheim show.

An April 26 New York City Center birthday celebration and concert to benefit Young Playwrights, among others, featured (in order of appearance) Michael Cerveris, Alexander Gemignani, Donna Murphy, Debra Monk, Joanna Gleason, Maria Friedman, Mark Jacoby, Len Cariou, BD Wong, Claybourne Elder, Alexander Hanson, Catherine Zeta-Jones, Raúl Esparza, Sutton Foster, Nathan Lane, Michele Pawk, the original cast of "Into the Woods", Kim Crosby, Chip Zien, Danielle Ferland and Ben Wright, Angela Lansbury and Jim Walton. The concert, directed by John Doyle, was co-hosted by Mia Farrow; greetings from Sheila Hancock, Julia McKenzie, Milton Babbitt, Judi Dench and Glynis Johns were read. After Catherine Zeta-Jones performed "Send in the Clowns", Julie Andrews sang part of "Not a Day Goes By" in a recorded greeting. Although Patti LuPone, Barbara Cook, Bernadette Peters, Tom Aldredge and Victor Garber were originally scheduled to perform, they did not appear.

A July 31 BBC Proms concert celebrated Sondheim's 80th birthday at the Royal Albert Hall. The concert featured songs from many of his musicals, including "Send in the Clowns" sung by Judi Dench (reprising her role as Desirée in the 1995 production of "A Little Night Music"), and performances by Bryn Terfel and Maria Friedman.

On November 19 the New York Pops, led by Steven Reineke, performed at Carnegie Hall for the composer's 80th birthday. Kate Baldwin, Aaron Lazar, Christiane Noll, Paul Betz, Renee Rakelle, Marilyn Maye (singing "I'm Still Here"), and Alexander Gemignani appeared, and songs included "I Remember," "Another Hundred People," "Children Will Listen" and "Getting Married Today". Sondheim took the stage during an encore of his song, "Old Friends".








In November 2015, Sondheim was awarded the Presidential Medal of Freedom by President Barack Obama in a ceremony at the White House.

Sondheim founded Young Playwrights Inc. in 1981 to introduce young people to writing for the theatre, and is the organization's executive vice-president. The Stephen Sondheim Center for the Performing Arts, at the Fairfield Arts and Convention Center in Fairfield, Iowa, opened in December 2007 with performances by Len Cariou, Liz Callaway, and Richard Kind (all of whom had participated in Sondheim musicals).

The Stephen Sondheim Society was established in 1993 to provide information about his work, with its "Sondheim - the Magazine" provided to its membership. The society maintains a database, organizes productions, meetings, outings and other events and assists with publicity. Its annual Student Performer of the Year Competition awards a £1,000 prize to one of twelve musical-theatre students from UK drama schools and universities. At Sondheim's request, an additional prize is offered for a new song by a young composer. Judged by George Stiles and Anthony Drewe, each contestant performs a Sondheim song and a new song.

Most episode titles of the television series "Desperate Housewives" refer to Sondheim's song titles or lyrics, and the series finale is entitled "Finishing the Hat". In 1990 Sondheim, as the Cameron Mackintosh chair in musical theatre at Oxford, conducted workshops with promising musical writers including George Stiles, Anthony Drewe, Andrew Peggie, Paul James and Stephen Keeling. The writers founded the Mercury Workshop in 1992, which merged with the New Musicals Alliance to become MMD (a UK-based organization to develop new musical theatre, of which Sondheim is a patron).

Signature Theatre in Arlington, Virginia established its Sondheim Award, which includes a $5,000 donation to a nonprofit organization of the recipient's choice, "as a tribute to America's most influential contemporary musical theatre composer". The first award, to Sondheim, was presented at an April 27, 2009 benefit with performances by Bernadette Peters, Michael Cerveris, Will Gartshore and Eleasha Gamble. The 2010 recipient was Angela Lansbury, with Peters and Catherine Zeta-Jones hosting the April benefit. The 2011 honoree was Bernadette Peters. Other recipients were Patti LuPone in 2012, Hal Prince in 2013, Jonathan Tunick in 2014, and James Lapine in 2015. The 2016 awardee was John Weidman and the 2017 awardee was Cameron Mackintosh.

Henry Miller's Theatre, on West 43rd Street in New York City, was renamed the Stephen Sondheim Theatre on September 15, 2010 for the composer's 80th birthday. In attendance were Nathan Lane, Patti LuPone and John Weidman. Sondheim said in response to the honor, "I'm deeply embarrassed. Thrilled, but deeply embarrassed. I've always hated my last name. It just doesn't sing. I mean, it's not Belasco. And it's not Rodgers and it's not Simon. And it's not Wilson. It just doesn't sing. It sings better than Schoenfeld and Jacobs. But it just doesn't sing". Lane said, "We love our corporate sponsors and we love their money, but there's something sacred about naming a theatre, and there's something about this that is right and just".

According to "The Daily Telegraph", Sondheim is "almost certainly" the only living composer with a quarterly journal published in his name; "The Sondheim Review", founded in 1994, chronicles and promotes his work.

According to Sondheim, when he asked Milton Babbitt if he could study atonality, Babbitt replied: "You haven't exhausted tonal resources for yourself yet, so I'm not going to teach you atonal". Sondheim agreed, and despite frequent dissonance and a highly-chromatic style, his music is tonal.

He is noted for complex polyphony in his vocals, such as the five minor characters who make up a Greek chorus in 1973's "A Little Night Music". Sondheim uses angular harmonies and intricate melodies. His musical influences are varied; although he has said that he "loves Bach", his favorite musical period is from Brahms to Stravinsky.

Sondheim has been described as introverted and solitary. In an interview with Frank Rich, he said, "The outsider feeling—somebody who people want to both kiss and kill—occurred quite early in my life". The composer is in a relationship with Jeff Romley, and lived with dramatist Peter Jones for eight years (until 1999).




 


</doc>
<doc id="29269" url="https://en.wikipedia.org/wiki?curid=29269" title="Self-determination">
Self-determination

The right of a people to self-determination is a cardinal principle in modern international law (commonly regarded as a "jus cogens" rule), binding, as such, on the United Nations as authoritative interpretation of the Charter's norms. It states that a people, based on respect for the principle of equal rights and fair equality of opportunity, have the right to freely choose their sovereignty and international political status with no interference.

The concept was first expressed in the 1860s, and spread rapidly thereafter. During and after World War I, the principle was encouraged by both Vladimir Lenin and United States President Woodrow Wilson. Having announced his Fourteen Points on 8 January 1918, on 11 February 1918 Wilson stated: "National aspirations must be respected; people may now be dominated and governed only by their own consent. 'Self determination' is not a mere phrase; it is an imperative principle of action."

During World War II, the principle was included in the Atlantic Charter, signed on 14 August 1941, by Franklin D. Roosevelt, President of the United States, and Winston Churchill, Prime Minister of the United Kingdom, who pledged The Eight Principal points of the Charter. It was recognized as an international legal right after it was explicitly listed as a right in the UN Charter. 

The principle does not state how the decision is to be made, nor what the outcome should be, whether it be independence, federation, protection, some form of autonomy or full assimilation. Neither does it state what the delimitation between peoples should be—nor what constitutes a people. There are conflicting definitions and legal criteria for determining which groups may legitimately claim the right to self-determination.

By extension the term self-determination has come to mean the free choice of one's own acts without external compulsion.

The employment of imperialism, through the expansion of empires, and the concept of political sovereignty, as developed after the Treaty of Westphalia, also explain the emergence of self-determination during the modern era. During, and after, the Industrial Revolution many groups of people recognized their shared history, geography, language, and customs. Nationalism emerged as a uniting ideology not only between competing powers, but also for groups that felt subordinated or disenfranchised inside larger states; in this situation, self-determination can be seen as a reaction to imperialism. Such groups often pursued independence and sovereignty over territory, but sometimes a different sense of autonomy has been pursued or achieved.

The world possessed several traditional, continental empires such as the Ottoman, Russian, Austrian/Habsburg, and the Qing Empire. Political scientists often define competition in Europe during the Modern Era as a balance of power struggle, which also induced various European states to pursue colonial empires, beginning with the Spanish and Portuguese, and later including the British, French, Dutch, and German.
During the early 19th century, competition in Europe produced multiple wars, most notably the Napoleonic Wars. After this conflict, the British Empire became dominant and entered its "imperial century", while nationalism became a powerful political ideology in Europe.

Later, after the Franco-Prussian War in 1870, "New Imperialism" was unleashed with France and later Germany establishing colonies in Asia, the Pacific, and Africa. Japan also emerged as a new power. Multiple theaters of competition developed across the world:


The Ottoman Empire, Austrian Empire, Russian Empire, Qing Empire and the new Empire of Japan maintained themselves, often expanding or contracting at the expense of another empire. All ignored notions of self-determination for those governed.

The revolt of New World British colonists in North America, during the mid-1770s, has been seen as the first assertion of the right of national and democratic self-determination, because of the explicit invocation of natural law, the natural rights of man, as well as the consent of, and sovereignty by, the people governed; these ideas were inspired particularly by John Locke's enlightened writings of the previous century. Thomas Jefferson further promoted the notion that the will of the people was supreme, especially through authorship of the United States Declaration of Independence which inspired Europeans throughout the 19th century. The French Revolution was motivated similarly and legitimatized the ideas of self-determination on that Old World continent.

Within the New World during the early 19th century, most of the nations of Spanish America achieved independence from Spain. The United States supported that status, as policy in the hemisphere relative to European colonialism, with the Monroe Doctrine. The American public, organized associated groups, and Congressional resolutions, often supported such movements, particularly the Greek War of Independence (1821–29) and the demands of Hungarian revolutionaries in 1848. Such support, however, never became official government policy, due to balancing of other national interests. After the American Civil War and with increasing capability, the United States government did not accept self-determination as a basis during its Purchase of Alaska and attempted purchase of the West Indian islands of Saint Thomas and Saint John in the 1860s, or its growing influence in the Hawaiian Islands, that led to annexation in 1898. With its victory in the Spanish–American War in 1899 and its growing stature in the world, the United States supported annexation of the former Spanish colonies of Guam, Puerto Rico and the Philippines, without the consent of their peoples, and it retained "quasi-suzerainty" over Cuba, as well.

Nationalist sentiments emerged inside the traditional empires including: Pan-Slavism in Russia; Ottomanism, Kemalist ideology and Arab nationalism in the Ottoman Empire; State Shintoism and Japanese identity in Japan; and Han identity in juxtaposition to the Manchurian ruling class in China. Meanwhile, in Europe itself there was a rise of nationalism, with nations such as Greece, Hungary, Poland and Bulgaria seeking or winning their independence.

Karl Marx supported such nationalism, believing it might be a "prior condition" to social reform and international alliances. In 1914 Vladimir Lenin wrote: "[It] would be wrong to interpret the right to self-determination as meaning anything but the right to existence as a separate state."

Woodrow Wilson revived America's commitment to self-determination, at least for European states, during World War I. When the Bolsheviks came to power in Russia in November 1917, they called for Russia's immediate withdrawal as a member of the Allies of World War I. They also supported the right of all nations, including colonies, to self-determination." The 1918 Constitution of the Soviet Union acknowledged the right of secession for its constituent republics.

This presented a challenge to Wilson's more limited demands. In January 1918 Wilson issued his Fourteen Points of January 1918 which, among other things, called for adjustment of colonial claims, insofar as the interests of colonial powers had equal weight with the claims of subject peoples. The Treaty of Brest-Litovsk in March 1918 led to Soviet Russia's exit from the war and the nominal independence of Armenia, Finland, Estonia, Latvia, Ukraine, Lithuania, Georgia and Poland, through in fact those territories were under German control. The end of the war led to the dissolution of the defeated Austro-Hungarian Empire and Czechoslovakia and the union of the State of Slovenes, Croats and Serbs and the Kingdom of Serbia as new states out of the wreckage of the Habsburg empire. However, this imposition of states where some nationalities (especially Poles, Czechs, and Serbs and Romanians) were given power over nationalities who disliked and distrusted them eventually used as a pretext for German aggression in World War II. 

One of the German objections to the Treaty of Versailles was a somewhat selective application of the principle of self-determination as the majority of the people in Austria and in the Sudetenland region of Czechoslovakia wanted to join Germany while the majority of people in Danzig wanted to remain within the "Reich", but the Allies ignored the German objections. Wilson's 14 Points had called for Polish independence to be restored and Poland to have "secure access to the sea", which would imply that the German city of Danzig (modern Gdańsk, Poland), which occupied a strategic location where the Vistula river flowed into the Baltic sea, be ceded to Poland. At the Paris peace conference in 1919, the Polish delegation led by Roman Dmowski asked for Wilson to honor point 14 of the 14 points by transferring Danzig to Poland. arguing that Poland would not be economically viable without Danzig. However, as the 90% of the people in Danzig in this period were German, the Allied leaders at the Paris peace conference compromised by creating the Free City of Danzig, a city-state in which Poland had certain special rights. Through the city of Danzig was 90% German and 10% Polish, the surrounding countryside around Danzig was overwhelmingly Polish, and the ethnically Polish rural areas included in the Free City of Danzig objected, arguing that they wanted to be part of Poland. Neither the Poles nor the Germans were happy with this compromise and the Danzig issue became a flash-point of German-Polish tension throughout the interwar period. 

Germany lost land after WWI: Northern Schleswig voted to return to Denmark after a referendum. On 11 July 1920, the East Prussian plebiscite called for by the Treaty of Versailles led to two disputed regions between Germany and Poland choosing the former. In 1921, a plebiscite in Silesia concerning partitioning the region between Germany and Poland led to fighting breaking out between the ethnic German and ethnic Polish residents of Silesia. The defeated Ottoman empire was dissolved into the Republic of Turkey and several smaller nations, including Yemen, plus the new Middle East Allied "mandates" of Syria and Lebanon (future Syria, Lebanon and Hatay State), Palestine (future Transjordan and Israel), Mesopotamia (future Iraq). In 1919, a Greek attempt to add the mostly Greek-speaking western regions of Anatolia led to a war between Greece and Turkey when the Greeks occupied the largely Greek-speaking city of Smyrna (modern İzmir, Turkey) in May 1919. In 1922, the Greeks were defeated and under the terms of the 1923 Treaty of Lausanne compulsorily population exchanges led to almost all the Turks in Greece being expelled into Turkey and almost all of the Greeks in Turkey being expelled into Greece. The League of Nations was proposed as much as a means of consolidating these new states, as a path to peace.

During the 1920s and 1930s there were some successful movements for self-determination in the beginnings of the process of decolonization. In the Statute of Westminster the United Kingdom granted independence to Canada, New Zealand, Newfoundland, the Irish Free State, the Commonwealth of Australia, and the Union of South Africa after the British parliament declared itself as incapable of passing laws over them without their consent. Egypt, Afghanistan and Iraq also achieved independence from Britain and Lebanon from France. Other efforts were unsuccessful, like the Indian independence movement. And Italy, Japan and Germany all initiated new efforts to bring certain territories under their control, leading to World War II. In particular, the National Socialist Program invoked this right of nations in its first point (out of 25), as it was publicly proclaimed on 24 February 1920 by Adolf Hitler.

In Asia, Japan became a rising power and gained more respect from Western powers after its victory in the Russo-Japanese War. Japan joined the Allied Powers in World War I and attacked German colonial possessions in the Far East, adding former German possessions to its own empire. In the 1930s, Japan gained significant influence in Inner Mongolia and Manchuria after it invaded Manchuria. It established Manchukuo, a puppet state in Manchuria and eastern Inner Mongolia. This was essentially the model Japan followed as it invaded other areas in Asia and established the Greater East Asia Co-Prosperity Sphere. Japan went to considerable trouble to argue that Manchukuo was justified by the principle of self-determination, claiming that people of Manchuria wanted to break away from China and asked the Kwantung Army to intervene on their behalf. However, the Lytton commission which had been appointed by the League of Nations to decide if Japan had committed aggression or not, stated the majority of people in Manchuria who were Han Chinese who did not wish to leave China. 

In 1912, the Republic of China officially succeeded the Qing Dynasty, while Outer Mongolia, Tibet and Tuva proclaimed their independence. Independence was not accepted by the government of China. By the Treaty of Kyakhta (1915) Outer Mongolia recognized China's sovereignty. However, the Soviet threat of seizing parts of Inner Mongolia induced China to recognize Outer Mongolia's independence, provided that a referendum was held. The referendum took place on October 20, 1945, with (according to official numbers) 100% of the electorate voting for independence.

Many of Eastern Asia's current disputes to sovereignty and self-determination stem from unresolved disputes from World War II. After its fall, the Empire of Japan renounced control over many of its former possessions including Korea, Sakhalin Island, and Taiwan. In none of these areas were the opinions of affected people consulted, or given significant priority. Korea was specifically granted independence but the receiver of various other areas was not stated in the Treaty of San Francisco, giving Taiwan "de facto" independence although its political status continues to be ambiguous.

In 1941 Allies of World War II declared the Atlantic Charter and accepted the principle of self-determination. In January 1942 twenty-six states signed the Declaration by United Nations, which accepted those principles. The ratification of the United Nations Charter in 1945 at the end of World War II placed the right of self-determination into the framework of international law and diplomacy.

On 14 December 1960, the United Nations General Assembly adopted United Nations General Assembly Resolution 1514 (XV) subtitled "Declaration on the Granting of Independence to Colonial Countries and Peoples", which supported the granting of independence to colonial countries and people by providing an inevitable legal linkage between self-determination and its goal of decolonisation. It postulated a new international law-based right of freedom to exercise economic self-determination. Article 5 states: Immediate steps shall be taken in Trust and Non-Self-Governing Territories, or all other territories which have not yet attained independence, to transfer all powers to the people of those territories, without any conditions or reservations, in accordance with their freely expressed will and desire, without any distinction as to race, creed or colour, in order to enable them to enjoy complete independence and freedom.

On 15 December 1960 the United Nations General Assembly adopted United Nations General Assembly Resolution 1541 (XV), subtitled "Principles which should guide members in determining whether or nor an obligation exists to transmit the information called for under Article 73e of the United Nations Charter in Article 3", which provided that "[t]he inadequacy of political, economic, social and educational preparedness should never serve as a pretext for delaying the right to self-determination and independence." To monitor the implementation of Resolution 1514, in 1961 the General Assembly created the Special Committee referred to popularly as the Special Committee on Decolonization to ensure decolonization complete compliance with the principles of self-determination in General Assembly Resolution 1541 (XV).

However, the charter and other resolutions did not insist on full independence as the best way of obtaining self-government, nor did they include an enforcement mechanism. Moreover, new states were recognized by the legal doctrine of uti possidetis juris, meaning that old administrative boundaries would become international boundaries upon independence if they had little relevance to linguistic, ethnic, and cultural boundaries. Nevertheless, justified by the language of self-determination, between 1946 and 1960, thirty-seven new nations in Asia, Africa, and the Middle East gained independence from colonial powers. The territoriality issue inevitably would lead to more conflicts and independence movements within many states and challenges to the assumption that territorial integrity is as important as self-determination.

Decolonization in the world was contrasted by the Soviet Union's successful post-war expansionism. Tuva and several regional states in Eastern Europe, the Baltic, and Central Asia had been fully annexed by the Soviet Union during World War II. Now, it extended its influence by establishing satellite states Eastern Germany and the countries of Eastern Europe, along with support for revolutionary movements in China and North Korea. Although satellite states were independent and possessed sovereignty, the Soviet Union violated principles of self-determination by suppressing the Hungarian revolution of 1956 and the Prague Spring Czechoslovak reforms of 1968. It invaded Afghanistan to support a communist government assailed by local tribal groups. However, Marxism–Leninism and its theory of imperialism were also strong influences in the national emancipation movements of Third World nations rebelling against colonial or puppet regimes. In many Third World countries, communism became an ideology that united groups to oppose imperialism or colonization.

Soviet actions were contained by the United States which saw communism as a menace to its interests. Throughout the cold war, the United States created, supported, and sponsored regimes with various success that served their economic and political interests, among them anti-communist regimes such as that of Augusto Pinochet in Chile and Suharto in Indonesia. To achieve this, a variety of means was implemented, including the orchestration of coups, sponsoring of anti-communist countries and military interventions. Consequently, many self-determination movements, which spurned some type of anti-communist government, were accused of being Soviet-inspired or controlled.

In Asia, the Soviet Union had already converted Mongolia into a satellite state but abandoned propping up the Second East Turkestan Republic and gave up its Manchurian claims to China. The new People's Republic of China had gained control of mainland China in the Chinese Civil War. The Korean War shifted the focus of the Cold War from Europe to Asia, where competing superpowers took advantage of decolonization to spread their influence.

In 1947, India gained independence from the British Empire. The empire was in decline but adapted to these circumstances by creating the British Commonwealth—since 1949 the Commonwealth of Nations—which is a free association of equal states. As India obtained its independence, multiple ethnic conflicts emerged in relation to the formation of a statehood during the Partition of India which resulted in Islamic Pakistan and Secular India. Before the advent of the British, no empire based in mainland India had controlled any part of what now makes up the country's Northeast, part of the reason for the ongoing insurgency in Northeast India. In 1971 Bangladesh obtained independence from Pakistan.

Burma also gained independence from the British Empire, but declined membership in the Commonwealth.

Indonesia gained independence from the Netherlands in 1949 after the latter failed to restore colonial control. As mentioned above, Indonesia also wanted a powerful position in the region that could be lessened by the creation of united Malaysia. The Netherlands retained Dutch New Guinea, but Indonesia threatened to invade and annex it. A vote was supposedly taken under the UN sponsored Act of Free Choice to allow West New Guineans to decide their fate, although many dispute its veracity. Later, Portugal relinquished control over East Timor in 1975, at which time Indonesia promptly invaded and annexed it.

The Cold War began to wind down after Mikhail Gorbachev assumed power in March 1985. With the cooperation of the American president Ronald Reagan, Gorbachev wound down the size of the Soviet Armed Forces and reduced nuclear arms in Europe, while liberalizing the economy.

In 1989 – 90, the communist regimes of Soviet satellite states collapsed in rapid succession in Poland, Hungary, Czechoslovakia, East Germany, Bulgaria, Romania, and Mongolia. East and West Germany united, Czechoslovakia peacefully split into Czech Republic and Slovakia, while in 1990 Yugoslavia began a violent break up into its former 6 sub-unit republics. Kosovo, which was previously an autonomous unit of Serbia declared independence in 2008, but has received less international recognition.

In December 1991, Gorbachev resigned as president and the Soviet Union dissolved relatively peacefully into fifteen sovereign republics, all of which rejected communism and most of which adopted democratic reforms and free-market economies. Inside those new republics, four major areas have claimed their own independence, but not received widespread international recognition.

After decades of civil war, Indonesia finally recognized the independence of East Timor in 2002.

In 1949, the Communists won the civil war and established the People's Republic of China in Mainland China. The Kuomintang-led Republic of China government retreated to Taipei, its jurisdiction now limited to Taiwan and several outlying islands. Since then, the People's Republic of China has been involved in disputes with the ROC over issues of sovereignty and the political status of Taiwan.

As noted, self-determination movements remain strong in some areas of the world. Some areas possess "de facto" independence, such as Taiwan, North Cyprus, Kosovo, and South Ossetia, but their independence is disputed by one or more major states. Significant movements for self-determination also persist for locations that lack "de facto" independence, such as Kurdistan, Catalonia, Balochistan, Chechnya, and the State of Palestine

Since the early 1990s, the legitimatization of the principle of national self-determination has led to an increase in the number of conflicts within states, as sub-groups seek greater self-determination and full secession, and as their conflicts for leadership within groups and with other groups and with the dominant state become violent. The international reaction to these new movements has been uneven and often dictated more by politics than principle. The year 2000 United Nations Millennium Declaration failed to deal with these new demands, mentioning only "the right to self-determination of peoples which remain under colonial domination and foreign occupation. "

In an issue of "Macquarie University Law Journal" Associate Professor Aleksandar Pavkovic and Senior Lecturer Peter Radan outlined current legal and political issues in self-determination. These include:

There is not yet a recognized legal definition of "peoples" in international law. Vita Gudeleviciute of Vytautas Magnus University Law School, reviewing international law and UN resolutions, finds in cases of non-self-governing peoples (colonized and/or indigenous) and foreign military occupation "a people" is the entire population of the occupied territorial unit, no matter their other differences. In cases where people lack representation by a state's government, the unrepresented become a separate people. Present international law does not recognize ethnic and other minorities as separate peoples, with the notable exception of cases in which such groups are systematically disenfranchised by the government of the state they live in. Other definitions offered are "peoples" being self-evident (from ethnicity, language, history, etc.), or defined by "ties of mutual affection or sentiment", i.e. "loyalty", or by mutual obligations among peoples. Or the definition may be simply that a people is a group of individuals who unanimously choose a separate state. If the "people" are unanimous in their desire for self-determination, it strengthens their claim. For example, the populations of federal units of the Yugoslav federation were considered a people in the breakup of Yugoslavia, although some of those units had very diverse populations. Libertarians who argue for self-determination distinguish between the voluntary nation (the land, the culture, the terrain, the people) and the state, the coercive apparatus, which they have a right to choose or self-determine.

Abulof suggests that self-determination entails the "moral double helix" of duality (personal right to align with a people, and the people's right to determine their politics) and mutuality (the right is as much the other's as the self’s). Thus, self-determination grants individuals the right to form "a people," which then has the right to establish an independent state, as long as they grant the same to all other individuals and peoples.

Criteria for the definition of "people having the right of self-determination" was proposed during 2010 Kosovo case decision of the International Court of Justice: 1. traditions and culture 2. ethnicity 3. historical ties and heritage 4. language 5. religion 6. sense of identity or kinship 7. the will to constitute a people 8. common suffering.

National self-determination appears to challenge the principle of territorial integrity (or sovereignty) of states as it is the will of the people that makes a state legitimate. This implies a people should be free to choose their own state and its territorial boundaries. However, there are far more self-identified nations than there are existing states and there is no legal process to redraw state boundaries according to the will of these peoples. According to the Helsinki Final Act of 1975, the UN, ICJ and international law experts, there is no contradiction between the principles of self-determination and territorial integrity, with the latter taking precedence.
Pavkovic and Radan describe three theories of international relations relevant to self-determination.


Allen Buchanan, author of seven books on self-determination and secession, supports territorial integrity as a moral and legal aspect of constitutional democracy. However, he also advances a "Remedial Rights Only Theory" where a group has "a general right to secede if and only if it has suffered certain injustices, for which secession is the appropriate remedy of last resort. " He also would recognize secession if the state grants, or the constitution includes, a right to secede.

Vita Gudeleviciute holds that in cases of non-self-governing peoples and foreign military occupation the principle of self-determination trumps that of territorial integrity. In cases where people lack representation by a state's government, they also may be considered a separate people, but under current law cannot claim the right to self-determination. On the other hand, she finds that secession within a single state is a domestic matter not covered by international law. Thus there are no on what groups may constitute a seceding people.

A number of states have laid claim to territories, which they allege were removed from them as a result of colonialism. This is justified by reference to Paragraph 6 of UN Resolution 1514(XV), which states that any attempt "aimed at partial or total disruption of the national unity and the territorial integrity of a country is incompatible with the purposes and principles of the Charter". This, it is claimed, applies to situations where the territorial integrity of a state had been disrupted by colonisation, so that the people of a territory subject to a historic territorial claim are prevented from exercising a right to self-determination. This interpretation is rejected by many states, who argue that Paragraph 2 of UN Resolution 1514(XV) states that "all peoples have the right to self-determination" and Paragraph 6 cannot be used to justify territorial claims. The original purpose of Paragraph 6 was "to ensure that acts of self-determination occur within the established boundaries of colonies, rather than within sub-regions". Further, the use of the word "attempt" in Paragraph 6 denotes future action and cannot be construed to justify territorial redress for past action. An attempt sponsored by Spain and Argentina to qualify the right to self-determination in cases where there was a territorial dispute was rejected by the UN General Assembly, which re-iterated the right to self-determination was a universal right.

In order to accommodate demands for minority rights and avoid secession and the creation of a separate new state, many states decentralize or devolve greater decision-making power to new or existing subunits or autonomous areas. More limited measures might include restricting demands to the maintenance of national cultures or granting non-territorial autonomy in the form of national associations which would assume control over cultural matters. This would be available only to groups that abandoned secessionist demands and the territorial state would retain political and judicial control, but only if would remain with the territorially organized state.

Pavković explores how national self-determination, in the form of creation of a new state through secession, could override the principles of majority rule and of equal rights, which are primary liberal principles. This includes the question of how an unwanted state can be imposed upon a minority. He explores five contemporary theories of secession. In "anarcho-capitalist" theory only landowners have the right to secede. In communitarian theory, only those groups that desire direct or greater political participation have the right, including groups deprived of rights, per Allen Buchanan. In two nationalist theories, only national cultural groups have a right to secede. Australian professor Harry Beran's democratic theory endorses the equality of the right of secession to all types of groups. Unilateral secession against majority rule is justified if the group allows secession of any other group within its territory.

Most sovereign states do not recognize the right to self-determination through secession in their constitutions. Many expressly forbid it. However, there are several existing models of self-determination through greater autonomy and through secession.

In liberal constitutional democracies the principle of majority rule has dictated whether a minority can secede. In the United States Abraham Lincoln acknowledged that secession might be possible through amending the United States Constitution. The Supreme Court in "Texas v. White" held secession could occur "through revolution, or through consent of the States." The British Parliament in 1933 held that Western Australia only could secede from Australia upon vote of a majority of the country as a whole; the previous two-thirds majority vote for secession via referendum in Western Australia was insufficient.

The Chinese Communist Party followed the Soviet Union in including the right of secession in its 1931 constitution in order to entice ethnic nationalities and Tibet into joining. However, the Party eliminated the right to secession in later years, and had anti-secession clause written into the Constitution before and after the founding the People's Republic of China. The 1947 Constitution of the Union of Burma contained an express state right to secede from the union under a number of procedural conditions. It was eliminated in the 1974 constitution of the Socialist Republic of the Union of Burma (officially the "Union of Myanmar"). Burma still allows "local autonomy under central leadership. "

As of 1996 the constitutions of Austria, Ethiopia, France, and Saint Kitts and Nevis have express or implied rights to secession. Switzerland allows for the secession from current and the creation of new cantons. In the case of proposed Quebec separation from Canada the Supreme Court of Canada in 1998 ruled that only both a clear majority of the province and a constitutional amendment confirmed by all participants in the Canadian federation could allow secession.

The 2003 draft of the European Union Constitution allowed for the voluntary withdrawal of member states from the union, although the State wanted to leave could not be involved in the vote deciding whether or not they can leave the Union. There was much discussion about such self-determination by minorities before the final document underwent the unsuccessful ratification process in 2005.

As a result of the successful constitutional referendum held in 2003, every municipality in the Principality of Liechtenstein has the right to secede from the Principality by a vote of a majority of the citizens residing in this municipality.

In determining international borders between sovereign states, self-determination has yielded to a number of other principles. Once groups exercise self-determination through secession, the issue of the proposed borders may prove more controversial than the fact of secession. The bloody Yugoslav wars in the 1990s were related mostly to border issues because the international community applied a version of uti possidetis juris in transforming the existing internal borders of the various Yugoslav republics into international borders, despite the conflicts of ethnic groups within those boundaries. In the 1990s indigenous populations of the northern two-thirds of Quebec province opposed being incorporated into a Quebec nation and stated a determination to resist it by force.

The border between Northern Ireland and the Irish Free State was based on the borders of existing counties and did not include all of historic Ulster. A Boundary Commission was established to consider re-drawing it. Its proposals, which amounted to a small net transfer to Northern Ireland, were leaked to the press and then not acted upon. In December 1925, the governments of the Irish Free State, Northern Ireland, and the United Kingdom agreed to accept the existing border.

There have been a number of notable cases of self-determination. For more information on past movements see list of historical autonomist and secessionist movements and lists of decolonized nations. Also see list of autonomous areas by country and list of territorial autonomies and list of active autonomist and secessionist movements.

Republic of Artsakh (Republic of Nagorno-Karabakh) declared its independence basing on self-determination rights on September 2nd, 1991. It successfully defended its independence in subsequent war with Azerbaijan, but remains largely unrecognized by UN states today. 

From 2003 onwards, self-determination has become the topic of some debate in Australia in relation to Aboriginal Australians and Torres Strait Islanders. In the 1970s, the Indigenous community approached the Federal Government and requested the right to administer their own communities. This encompassed basic local government functions, ranging from land dealings and management of community centres to road maintenance and garbage collection, as well as setting education programmes and standards in their local schools.

The traditional homeland of the Tuareg peoples was divided up by the modern borders of Mali, Algeria and Niger. Numerous rebellions occurred over the decades, but in 2012 the Tuaregs succeeded in occupying their land and declaring the independence of Azawad. However, their movement was hijacked by the Islamist terrorist group Ansar Dine.

The Basque Country (, , ) as a cultural region (not to be confused with the homonym Autonomous Community of the Basque country) is a European region in the western Pyrenees that spans the border between France and Spain, on the Atlantic coast. It comprises the autonomous communities of the Basque Country and Navarre in Spain and the Northern Basque Country in France.
Since the 19th century, Basque nationalism has demanded the right of some kind of self-determination. This desire for independence is particularly stressed among leftist Basque nationalists. The right of self-determination was asserted by the Basque Parliament in 1990, 2002 and 2006.
Since self-determination is not recognized in the Spanish Constitution of 1978, some Basques abstained and some voted against it in the referendum of December 6 of that year. It was approved by a clear majority at the Spanish level, and with 74.6% of the votes in the Basque Country. However, the overall turnout in the Basque Country was 45% when the Spanish overall turnover was 67.9%. The derived autonomous regime for the BAC was approved by Spanish Parliament and also by the Basque citizens in referendum. The autonomous statue of Navarre ("Amejoramiento del Fuero": "improvement of the charter") was approved by the Spanish Parliament and, like the statues of 13 out 17 Spanish autonomous communities, it didn´t need a referendum to enter into force.

"Euskadi Ta Askatasuna" or ETA (; pronounced ), is an armed Basque nationalist, separatist and terrorist organization. Founded in 1959, it evolved from a group advocating traditional cultural ways to a paramilitary group with the goal of Basque independence. Its ideology is Marxist-Leninist.
The Nigerian Civil War was fought between Biafran secessionists of the Republic of Biafra and the Nigerian central government. From 1999 to the present day, the indigenous people of Biafra have been agitating for independence to revive their country. They have registered a human rights organization known as Bilie Human Rights Initiative both in Nigeria and in the United Nations to advocate for their right to self-determination and achieve independence by the rule of law.

After the 2012 Catalan march for independence, in which between 600,000 and 1.5 million citizens marched , the President of Catalonia, Artur Mas, called for new parliamentary elections on 25 November 2012 to elect a new parliament that would exercise the right of self-determination for Catalonia, a right not recognised under the Spanish law. The Parliament of Catalonia voted to hold a 'referendum or consultation' in the next four-year legislature in which the people of Catalonia would decide on becoming a new independent and sovereign state. The parliamentary decision was approved by a large majority of MPs: 84 voted for, 21 voted against, and 25 abstained. The Catalan Parliament applied to the Spanish Parliament for the power to call a referendum to be devolved, but this was turned down. In December 2013 the President of the Generalitat Artur Mas and the governing coalition agreed to set the referendum for self-determination on 9 November 2014, and legislation specifically saying that the consultation would not be a "referendum" was enacted, only to be blocked overnight by the Spanish Constitutional Court, at the request of the Spanish government. Given the block, the Government turned it into a simple "consultation to the people" instead.
The question in the consultation was "Do you want Catalonia to be a State?" (possible answers were yes or no) and, if the answer to this question was yes, "Do you want Catalonia to be an independent State?" (possible answers were again yes or no). However, as the consultation was not a formal referendum, these (printed) answers were just suggestions and other answers were also accepted and catalogued as "other answers" instead as null votes. The turnout in this consultation was about 2·3m people out of 6,228,531 people that were called to vote (this figure does not coincide with the official census for two main reasons: first, as the consultation was not a referendum, the organization of the consultation had no access to the census, second, people under 18 but above 16 were also entitled to vote, as opposed to ordinary referenda where the voting age is 18). In the morning there were long queues awaiting the opening of polling stations. As the organization did not had a proper census, it used a system based on the address in the Spanish Identity Card to determine where to vote and to prevent the citizen from being able to vote several times. This is the reason why some claimed irregularities in the voting system and some people even alleged in Spanish media to have exploited the system to vote twice or several times (however, these claims were never confirmed). The overall result was 80·76% in favor of both questions, 11% in favor of the first question but not of the second questions, 4·54% against both; the rest were classified as "other answers". The voter turnout was around 37% (most people against the consultation didn't go to vote). Four top members of Catalonia's political leadership were barred from public office for having defied the Constitutional court's last-minute ban. 
Almost three years later (1 October 2017), the Catalan government called a referendum for independence under legislation adopted in September 2017 (despite being hurriedly blocked by the Constitutional Court of Spain), with the question "Do you want Catalonia to become an independent state in the form of a Republic?". For weeks up to the voting day the Spanish authorities tried fruitlessly to track down the ballot boxes (in the event, they were smuggled in from French Catalonia), and on the day, after thousands of locals had kept the polling stations oppèn oiver the weekend with cultural and educational acitivities, following a judge's instructions, the Catalan police prevented voting in over 500 polling stations, without a single violent incident, while the Spanish police confiscated ballot boxes and closed down 92, but with many incidents involving truncheon charges and over 1,100 people receiving medical treatment. The opposition parties calling for non-participation, the turnout (according to the votes that were counted) was 2,286,217 out of 5,313,564 (43·03% of the census), and 90·18% of the ballots were in favour of independence. 

Under Dzhokhar Dudayev, Chechnya declared independence as the Chechen Republic of Ichkeria, using self-determination, Russia's history of bad treatment of Chechens, and a history of independence before invasion by Russia as main motives. Russia has restored control over Chechnya, but the separatist government functions still in exile, though it has been split into two entities: the Akhmed Zakayev-run secular Chechen Republic (based in Poland, the UK and the US), and the Islamic Caucasus Emirate.

There is an active secessionist movement based on the self-determination of the residents of the Donetsk and Luhansk regions of eastern Ukraine, allegedly against the instability and corruption of the Ukrainian government. However, many in the international community assert that referendums held there in 2014 regarding independence from Ukraine were illegitimate and undemocratic. Similarly, there are reports that presidential elections in May 2014 were prevented from taking place in the two regions after armed gunmen took control of polling stations, kidnapped election officials, and stole lists of electors, thus denying the population the chance to express their will in a free, fair, and internationally recognised election. There are also arguments, that the de facto separation of Eastern Ukraine from the rest of the country is not in fact an expression of self-determination, but rather an invasion by neighbouring Russia, with Ukrainian President Petro Poroshenko reporting to MPs on the 4th June 2015 that up to nine thousand Russian soldiers were deployed in Ukraine. Others have pointed out that Russian troops did not invade, as they were already stationed in Crimea as part of a basing agreement, and that the secessionist movements arose in response to the overthrow of the elected president of Ukraine. The overthrow was backed by western states and involved far-right or neo-Nazi forces, as documented in western media.

Self-determination is referred to in the Falkland Islands Constitution and is a factor in the Falkland Islands sovereignty dispute. The population has existed for over nine generations, continuously for over 175 years. In the 2013 referendum organised by the Falkland Islands Government, 99.8% voted to remain British. As administering power, the British Government considers since the majority of inhabitants wish to remain British, transfer of sovereignty to Argentina would be counter to their right to self-determination.

Argentina states the principle of self-determination is not applicable since the current inhabitants are not aboriginal and were brought to replace the Argentine population, which was expelled by an 'act of force', forcing the Argentinian inhabitants to directly leave the occupied islands. This refers to the re-establishment of British rule in the year 1833 during which Argentina claims the existing population living in the islands was expelled. Argentina thus argues that, in the case of the Falkland Islands, the principle of territorial integrity should have precedence over self-determination. Historical records dispute Argentina's claims and whilst acknowledging the garrison was expelled note the existing civilian population remained at Port Louis and there was no attempt to colonise the islands until 1841.

The right to self-determination is referred to in the pre-amble of Chapter 1 of the Gibraltar constitution, and, since the United Kingdom also gave assurances that the right to self-determination of Gibraltarians would be respected in any transfer of sovereignty over the territory, is a factor in the dispute with Spain over the territory. The impact of the right to self-determination of Gibraltarians was seen in the 2002 Gibraltar sovereignty referendum, where Gibraltarian voters overwhelmingly rejected a plan to share sovereignty over Gibraltar between the UK and Spain. However, the UK government differs with the Gibraltarian government in that it considers Gibraltarian self-determination to be limited by the Treaty of Utrecht, which prevents Gibraltar achieving independence without the agreement of Spain, a position that the Gibraltarian government does not accept. 

The Spanish government denies that Gibraltarians have the right to self-determination, considering them to be "an artificial population without any genuine autonomy" and not "indigenous". However, the Partido Andalucista has agreed to recognise the right to self-determination of Gibraltarians.

Before the United Nations's adoption of resolution 2908 (XXVII) on 2 November 1972, The People's Republic of China vetoed the former British colony of Hong Kong's right to self-determination on 8 March 1972. This sparked several nation's protest along with Great Britain's declaration on 14 December that the decision is invalid. 
Decades later, a nationalist independence movement, dubbed as the Hong Kong independence movement emerged in the now Communist Chinese controlled territory. It advocates the autonomous region to become a fully independent sovereign state.

The city is considered a special administrative region (SAR) which, according to the PRC, enjoys a high degree of autonomy under the People's Republic of China (PRC), guaranteed under Article 2 of Hong Kong Basic Law (which is ratified under the Sino-British Joint Declaration), since the transfer of the sovereignty of Hong Kong from the United Kingdom to the PRC in 1997. Since the handover, many Hongkongers are increasingly concerned about Beijing's growing encroachment on the territory's freedoms and the failure of the Hong Kong government to deliver 'true' democracy.

The 2014–15 Hong Kong electoral reform package deeply divided the city, as it allowed Hongkongers to have universal suffrage, but Beijing would have authority to screen the candidates to restrict the electoral method for the Chief Executive of Hong Kong (CE), the highest-ranking official of the territory. This sparked the 79-day massive peaceful protests which was dubbed as the "Umbrella Revolution" and the pro-independence movement emerged on the Hong Kong political scene. 

Since then, localism has gained momentum, particularly after the failure of the peaceful Umbrella Movement. Young localist leaders have led numerous protest actions against pro-Chinese policies to raise awareness of social problems of Hong Kong under Chinese rule. These include the sit-in protest against the Bill to Strengthen Internet Censorship, demonstrations against Chinese political interference in the University of Hong Kong, the Recover Yuen Long protests and the 2016 Mong Kok civil unrest. According to a survey conducted by the Chinese University of Hong Kong (CUHK) in July 2016, 17.4% of respondents supported the city becoming an independent entity after 2047, while 3.6% stated that it is "possible".

Ever since Pakistan and India’s inception in 1947 the legal state of Jammu and Kashmir, the land between India and Pakistan, has been contested as Britain was resigning from their rule over this land. Maharaja Hari Singh, the ruler residing over Kashmir at the time accession, signed the Instrument of Accession Act on October 26 1947 as his territory was being attacked by Pakistani tribesmen. The passing of this Act allowed Jammu and Kashmir to accede to India on legal terms. When this Act was taken to Lord Mountbatten, the last viceroy of British India, he agreed to it and stated that a referendum needed to be held by the citizens in India, Pakistan, and Kashmir so that they could vote as to where Kashmir should accede to. This referendum that Mountbatten called for never took place and framed one of the legal disputes for Kashmir. In 1948 the United Nations intervened and ordered a plebiscite to be taken in order to hear the voices of the Kashmiris if they would like to accede to Pakistan or India. This plebiscite left out the right for Kashmiris to have the right of self determination and become an autonomous state. To this date the Kashmiris have been faced with numerous human rights violations committed by both India and Pakistan and have yet to gain complete autonomy which they have been seeking through self-determination. 

The insurgency in Kashmir against Indian rule has existed in various forms. A widespread armed insurgency started in Kashmir against India rule in 1989 after allegations of rigging by the Indian government in the 1987 Jammu and Kashmir state election. This led to some parties in the state assembly forming militant wings, which acted as a catalyst for the emergence of armed insurgency in the region. The conflict over Kashmir has resulted in tens of thousands of deaths.

The Inter-Services Intelligence of Pakistan has been accused by India of supporting and training both pro-Pakistan and pro-independence militants to fight Indian security forces in Jammu and Kashmir, a charge that Pakistan denies. According to official figures released in the Jammu and Kashmir assembly, there were 3,400 disappearance cases and the conflict has left more than 47,000 to 100,000 people dead as of July 2009. However, violence in the state had fallen sharply after the start of a slow-moving peace process between India and Pakistan. After the peace process failed in 2008, mass demonstrations against Indian rule, and also low-scale militancy have emerged again.

However, despite boycott calls by separatist leaders in 2014, the Jammu and Kashmir Assembly elections saw highest voters turnout in last 25 years since insurgency erupted. As per the Indian government, it recorded more than 65% of voters turnout which was more than usual voters turnout in other state assembly elections of India. It considered as increase in faith of Kashmiri people in democratic process of India. However, activists say that the voter turnout is highly exaggerated and that elections are held under duress. Votes are cast because the people want stable governance of the state, and this cannot be mistaken as an endorsement of Indian rule.

Kurdistan is a historical region primarily inhabited by the Kurdish people of the middle east. The territory is currently part of 4 states Turkey, Iraq, Syria and Iran. There are Kurdish self-determination movements in each of the 4 states. Iraqi Kurdistan has to date achieved the largest degree of self-determination through the formation of the Kurdistan Regional Government, an entity recognised by the Iraqi Federal Constitution.

Although the right of the creation of a Kurdish state was recognized following World War I in the Treaty of Sèvres, the treaty was then annulled by the Treaty of Lausanne. To date two separate Kurdish republics and one Kurdish Kingdom have declared sovereignty. The Republic of Ararat (Ağrı Province, Turkey), the Republic of Mehabad (West Azerbaijan Province, Iran) and the Kingdom of Kurdistan (Sulaymaniyah Province, Iraqi Kurdistan, Iraq), each of these fledgling states was crushed by military intervention. The Patriotic Union of Kurdistan which currently holds the Iraqi presidency and the Kurdistan Democratic Party which governs the Kurdistan Regional Government both explicitly commit themselves to the development of Kurdish self-determination, but opinions vary as to the question of self-determination sought within the current borders and countries.

Naga refers to a vaguely-defined conglomeration of distinct tribes living on the border of India and Burma. Each of these tribes lived in a sovereign village before the arrival of the British, but developed a common identity as the area was Christianized. After the British left India, a section of Nagas under the leadership of Angami Zapu Phizo sought to establish a separate country for the Nagas. Phizo's group, the Naga National Council (NNC), claimed that 99. 9% of the Nagas wanted an independent Naga country according to a referendum conducted by it. It waged a secessionist insurgency against the Government of India. The NNC collapsed after Phizo got his dissenters killed or forced them to seek refuge with the Government. Phizo escaped to London, while NNC's successor secessionist groups continued to stage violent attacks against the Indian Government. The Naga People's Convention (NPC), another major Naga organization, was opposed to the secessionists. Its efforts led to the creation of a separate Nagaland state within India in 1963. The secessionist violence declined considerably after the Shillong Accord of 1975. However, three factions of the National Socialist Council of Nagaland (NSCN) continue to seek an independent country which would include parts of India and Burma. They envisage a sovereign, predominantly Christian nation called "Nagalim".

Another controversial episode with perhaps more relevance was the British beginning their exit from British Malaya. An experience concerned the findings of a "United Nations Assessment Team" that led the British territories of North Borneo and Sarawak in 1963 to determine whether or not the populations wished to become a part of the new Malaysia Federation. The United Nation Team's mission followed on from an earlier assessment by the British-appointed Cobbold Commission which had arrived in the territories in 1962 and held hearings to determine public opinion. It also sifted through 1600 letters and memoranda submitted by individuals, organisations and political parties. Cobbold concluded that around two thirds of the population favoured to the formation of Malaysia while the remaining third wanted either independence or continuing control by the United Kingdom. The United Nations team largely confirmed these findings, which were later accepted by the General Assembly, and both territories subsequently wish to form the new Federation of Malaysia. The conclusions of both the Cobbold Commission and the United Nations team were arrived at without any referendums self-determination being held. Unlike in Singapore, however, no referendum was ever conducted in Sarawak and North Borneo. they sought to consolidate several of the previous ruled entities then there was Manila Accord, an agreement between the Philippines, Federation of Malaya and Indonesia on 31 July 1963 to abide by the wishes of the people of North Borneo and Sarawak within the context of United Nations General Assembly Resolution 1541 (XV), Principle 9 of the Annex taking into account referendums in North Borneo and Sarawak that would be free and without coercion. This also triggered the Indonesian confrontation because Indonesia opposed the violation of the agreements.

Cyprus was settled by Mycenaean Greeks in two waves in the 2nd millennium BC. As a strategic location in the Middle East, it was subsequently occupied by several major powers, including the empires of the Assyrians, Egyptians and Persians, from whom the island was seized in 333 BC by Alexander the Great. Subsequent rule by Ptolemaic Egypt, the Classical and Eastern Roman Empire, Arab caliphates for a short period and the French Lusignan dynasty. Following the death in 1473 of James II, the last Lusignan king, the Republic of Venice assumed control of the island, while the late king's Venetian widow, Queen Catherine Cornaro, reigned as figurehead. Venice formally annexed the Kingdom of Cyprus in 1489, following the abdication of Catherine. The Venetians fortified Nicosia by building the Walls of Nicosia, and used it as an important commercial hub.

Although the Lusignan French aristocracy remained the dominant social class in Cyprus throughout the medieval period, the former assumption that Greeks were treated only as serfs on the island is no longer considered by academics to be accurate. It is now accepted that the medieval period saw increasing numbers of Greek Cypriots elevated to the upper classes, a growing Greek middle ranks, and the Lusignan royal household even marrying Greeks. This included King John II of Cyprus who married Helena Palaiologina.

Throughout Venetian rule, the Ottoman Empire frequently raided Cyprus. In 1539 the Ottomans destroyed Limassol and so fearing the worst, the Venetians also fortified Famagusta and Kyrenia.

Invaded in 1570, Turks controlled and solely governed all of the Cyprus island from 1571 till its leasing to the United Kingdom in 1878. Cyprus was placed under British administration based on Cyprus Convention in 1878 and formally annexed by Britain in 1914. While Turkish Cypriots made up 18% of the population, the partition of Cyprus and creation of a Turkish state in the north became a policy of Turkish Cypriot leaders and Turkey in the 1950s. Politically, there was no majority/minority relation between Greek Cypriots and Turkish Cypriots; and hence, in 1960, Republic of Cyprus was founded by the constituent communities in Cyprus (Greek Cypriots and Turkish Cypriots) as a non-unitary state; the 1960 Constitution set both Turkish and Greek as the
official languages. During 1963-74, the island experienced ethnic clashes and turmoil, the coup to unify the island to Greece and eventual Turkish operation in 1974. The idea of separation for peace has been amplified by a UN-implemented population exchange agreement in 1975. Turkish Republic of Northern Cyprus was declared in 1983 and recognized only by Turkey. Turkish Cypriots had the right of self-determination, as well as Greek Cypriots. Before the Turkey's operation in 1974, Turkish Cypriots were concentrated in Turkish Cypriot enclaves in the island.

Northern Cyprus fulfills all the classical criteria of statehood. United Nations Peace Force in Cyprus (UNFICYP) operates based on the laws of Northern Cyprus in north of Cyprus island. According to European Court of Human Rights (ECtHR), the laws of Northern Cyprus is valid in the north of Cyprus. ECtHR did "not" accept the claim that the Courts of Northern Cyprus lacked "independence and/or impartiality". ECtHR directed all Cypriots to exhaust "domestic remedies" applied by Northern Cyprus before taking their cases to ECtHR. In 2014, United States' Federal Court qualified Turkish Republic of Northern Cyprus as a "democratic country". In 2017, United Kingdom's High Court decided that "There was no duty in UK law upon the UK's Government to refrain from recognising Northern Cyprus. The United Nations itself works with Northern Cyprus law enforcement agencies and facilitates cooperation between the two parts of the island." UK's High Court also dismissed the claim that "cooperation between UK police and law agencies in northern Cyprus was illegal".

In Canada, many in the province of Quebec have wanted the province to separate from Confederation. The Parti Québécois has asserted Quebec's "right to self-determination. " There is debate on under which conditions would this right be realized. French-speaking Quebec nationalism and support for maintaining Québécois culture would inspire Quebec nationalists, many of whom were supporters of the Quebec sovereignty movement during the late-20th century.

Section 235 of the South African Constitution allows for the right to self-determination of a community, within the framework of "the right of the South African people as a whole to self-determination", and pursuant to national legislation. This section of the constitution was one of the negotiated settlements during the handing over of political power in 1994. Supporters of an independent Afrikaner homeland have argued that their goals are reasonable under this new legislation.

The colonization of the North American continent and its Native American population has been the source of legal battles since the early 19th century. Many Native American tribes were resettled onto separate tracts of land (reservations), which have retained a certain degree of autonomy within the United States. The federal government recognizes Tribal Sovereignty and has established a number of laws attempting to clarify the relationship among the federal, state, and tribal governments. The Constitution and later federal laws recognize the local sovereignty of tribal nations, but do not recognize full sovereignty equivalent to that of foreign nations, hence the term "domestic dependent nations" to qualify the federally recognized tribes.

Certain Chicano nationalist groups seek to "recreate" an ethnic-based state to be called Aztlán, after the legendary homeland of the Aztecs. It would comprise the Southwestern United States, historic territory of indigenous peoples and their descendants, as well as colonists and later settlers under the Spanish colonial and Mexican governments. Black nationalists have argued that, by virtue of slaves' unpaid labor and the harsh experiences of African Americans under slavery and Jim Crow, African Americans have a moral claim to the black belt region of the American South. They believe this area should be the basis of forming an independent state of New Afrika, designed to have an African-American majority and political control.

There are several active Hawaiian autonomy or independence movements, each with the goal of realizing some level of political control over single or several islands. The groups range from those seeking territorial units similar to Indian reservations under the United States, with the least amount of independent control, to the Hawaiian sovereignty movement, which is projected to have the most amount of independence. The Hawaiian Sovereignty movement seeks to revive the Hawaiian nation under the Hawaiian constitution. Supporters of this concept say that Hawaii retained its sovereignty while under control of the United States.

Since 1972, the U.N. Decolonization Committee has called for Puerto Rico's "decolonization" and for the US to recognize the island's right to self-determination and independence. In 2007 the Decolonization Subcommittee called for the United Nations General Assembly to review the political status of Puerto Rico, a power reserved by the 1953 Resolution. This followed the 1967 passage of a plebiscite act that provided for a vote on the status of Puerto Rico with three status options: continued commonwealth, statehood, and independence. In the first plebscite, the commonwealth option won with 60.4% of the votes, but US congressional committees failed to enact legislation to address the status issue. In subsequent plebiscites in 1993 and 1998, the status quo was favored.

In a referendum that took place in November 2012, a majority of Puerto Rican residents voted to change the territory's relationship with the United States, with the statehood option being the preferred option. But a large number of ballots—one-third of all votes cast—were left blank on the question of preferred alternative status. Supporters of the commonwealth status had urged voters to blank their ballots. When the blank votes are counted as anti-statehood votes, the statehood option would have received less than 50% of all ballots received. As of January 2014, Washington has not taken action to address the results of this plebiscite.

Many current US state, regional and city secession groups use the language of self-determination. A 2008 Zogby International poll revealed that 22% of Americans believe that "any state or region has the right to peaceably secede and become an independent republic."

Since the late 20th century, some states periodically discuss desires to secede from the United States. Secession was ruled unconstitutional by the US Supreme Court in "Texas v. White" (1869).

In the case of Hawaii, the struggle for self-determination does not fall under secession, as it is less a break from federal administration, than a return to the process through which cession was claimed to have occurred: namely the ongoing occupation via a US imposed military coup; and/or removal from the UN list of Non-Self-Governing Territories. to educate or properly inform the citizenry of Hawaii of its options for self-determination and sidestepped guidelines laid out in UN General Assembly resolution 742 (1953).

The self-determination of the West Papuan people has been violently suppressed by the Indonesian government since the withdrawal of Dutch colonial rule under the Netherlands New Guinea in 1962.
There is an active movement based on the self-determination of the Sahrawi people in the Western Sahara region. Morocco also claims the entire territory, and maintains control of about two-thirds of the region.





</doc>
<doc id="29271" url="https://en.wikipedia.org/wiki?curid=29271" title="Scale">
Scale

Scale or scales may refer to:










</doc>
<doc id="29275" url="https://en.wikipedia.org/wiki?curid=29275" title="Southcentral Alaska">
Southcentral Alaska

Southcentral Alaska is the portion of the U.S. state of Alaska consisting of the shorelines and uplands of the central Gulf of Alaska. Most of the population of the state lives in this region, concentrated in and around the city of Anchorage.

The area includes Cook Inlet, the Matanuska-Susitna Valley, the Kenai Peninsula, Prince William Sound, and the Copper River Valley. Tourism, fisheries, and petroleum production are important economic activities.

The major city is Anchorage. Other towns include Palmer, Wasilla, Kenai, Soldotna, Homer, Seward, Valdez, and Cordova.

The climate of Southcentral Alaska is subarctic. Temperatures range from an average high of 65°F (18°C) in July to an average low of 10°F (-12°C) in December. The hours of daylight per day varies from 24 hours in June and July to 6 hours in December and January. The coastal areas consist of temperate rainforests and alder shrublands. The interior areas are covered by boreal forests.

The terrain of Southcentral Alaska is shaped by six mountain ranges:

Southcentral Alaska contains several dormant and active volcanoes. The Wrangell Volcanoes are older, lie in the East, and include Mount Blackburn, Mount Bona, Mount Churchill, Mount Drum, Mount Gordon, Mount Jarvis, Mount Sanford, and Mount Wrangell. The Cook Inlet volcanoes, located in the Tordrillo Mountains and in the north end of the Aleutian Range, are newer, lie in the West, and include Mount Redoubt, Mount Iliamna, Hayes Volcano, Mount Augustine, Fourpeaked Mountain and Mount Spurr. Most recently, Augustine and Fourpeaked erupted in 2006, and Mount Redoubt erupted in March 2009, resulting in airplane flight cancellations.



</doc>
<doc id="29276" url="https://en.wikipedia.org/wiki?curid=29276" title="Spinor">
Spinor

In geometry and physics, spinors are elements of a (complex) vector space that can be associated with Euclidean space. Like geometric vectors and more general tensors, spinors transform linearly when the Euclidean space is subjected to a slight (infinitesimal) rotation. When a sequence of such small rotations is composed (integrated) to form an overall final rotation, however, the resulting spinor transformation depends on which sequence of small rotations was used: "unlike" vectors and tensors, a spinor transforms to its negative when the space is rotated through a complete turn from 0° to 360° (see picture). This property characterizes spinors. It is also possible to associate a substantially similar notion of spinor to Minkowski space in which case the Lorentz transformations of special relativity play the role of rotations. Spinors were introduced in geometry by Élie Cartan in 1913. In the 1920s physicists discovered that spinors are essential to describe the intrinsic angular momentum, or "spin", of the electron and other subatomic particles.

Spinors are characterized by the specific way in which they behave under rotations. They change in different ways depending not just on the overall final rotation, but the details of how that rotation was achieved (by a continuous path in the rotation group). There are two topologically distinguishable classes (homotopy classes) of paths through rotations that result in the same overall rotation, as famously illustrated by the belt trick puzzle (below). These two inequivalent classes yield spinor transformations of opposite sign. The spin group is the group of all rotations keeping track of the class. It doubly covers the rotation group, since each rotation can be obtained in two inequivalent ways as the endpoint of a path. The space of spinors by definition is equipped with a (complex) linear representation of the spin group, meaning that elements of the spin group act as linear transformations on the space of spinors, in a way that genuinely depends on the homotopy class. In mathematical terms, spinors are described by a double-valued projective representation of the rotation group SO(3).

Although spinors can be defined purely as elements of a representation space of the spin group (or its Lie algebra of infinitesimal rotations), they are typically defined as elements of a vector space that carries a linear representation of the Clifford algebra. The Clifford algebra is an associative algebra that can be constructed from Euclidean space and its inner product in a basis independent way. Both the spin group and its Lie algebra are embedded inside the Clifford algebra in a natural way, and in applications the Clifford algebra is often the easiest to work with. After choosing an orthonormal basis of Euclidean space, a representation of the Clifford algebra is generated by gamma matrices, matrices that satisfy a set of canonical anti-commutation relations. The spinors are the column vectors on which these matrices act. In three Euclidean dimensions, for instance, the Pauli spin matrices are a set of gamma matrices, and the two-component complex column vectors on which these matrices act are spinors. However, the particular matrix representation of the Clifford algebra, hence what precisely constitutes a "column vector" (or spinor), involves the choice of basis and gamma matrices in an essential way. As a representation of the spin group, this realization of spinors as (complex) column vectors will either be irreducible if the dimension is odd, or it will decompose into a pair of so-called "half-spin" or Weyl representations if the dimension is even.

What characterizes spinors and distinguishes them from geometric vectors and other tensors is subtle. Consider applying a rotation to the coordinates of a system. No object in the system itself has moved, only the coordinates have, so there will always be a compensating change in those coordinate values when applied to any object of the system. Geometrical vectors, for example, have components that will undergo "the same" rotation as the coordinates. More broadly, any tensor associated with the system (for instance, the stress of some medium) also has coordinate descriptions that adjust to compensate for changes to the coordinate system itself. Spinors do not appear at this level of the description of a physical system, when one is concerned only with the properties of a single isolated rotation of the coordinates. Rather, spinors appear when we imagine that instead of a single rotation, the coordinate system is gradually (continuously) rotated between some initial and final configuration. For any of the familiar and intuitive ("tensorial") quantities associated with the system, the transformation law does not depend on the precise details of how the coordinates arrived at their final configuration. Spinors, on the other hand, are constructed in such a way that makes them "sensitive" to how the gradual rotation of the coordinates arrived there: they exhibit path-dependence. It turns out that, for any final configuration of the coordinates, there are actually two ("topologically") inequivalent "gradual" (continuous) rotations of the coordinate system that result in this same configuration. This ambiguity is called the homotopy class of the gradual rotation. The belt trick puzzle (shown) famously demonstrates two different rotations, one through an angle of 2π and the other through an angle of 4π, having the same final configurations but different classes. Spinors actually exhibit a sign-reversal that genuinely depends on this homotopy class. This distinguishes them from vectors and other tensors, none of which can feel the class.

Spinors can be exhibited as concrete objects using a choice of Cartesian coordinates. In three Euclidean dimensions, for instance, spinors can be constructed by making a choice of Pauli spin matrices corresponding to (angular momenta about) the three coordinate axes. These are 2×2 matrices with complex entries, and the two-component complex column vectors on which these matrices act by matrix multiplication are the spinors. In this case, the spin group is isomorphic to the group of 2×2 unitary matrices with determinant one, which naturally sits inside the matrix algebra. This group acts by conjugation on the real vector space spanned by the Pauli matrices themselves, realizing it as a group of rotations among them, but it also acts on the column vectors (that is, the spinors).

More generally, a Clifford algebra can be constructed from any vector space "V" equipped with a (nondegenerate) quadratic form, such as Euclidean space with its standard dot product or Minkowski space with its standard Lorentz metric. Given a suitably normalized basis of "V", the Clifford algebra is generated by gamma matrices, matrices that satisfy a set of canonical anti-commutation relations, and the space of spinors is the space of column vectors with formula_1 components on which those matrices act. Although the Clifford algebra can be defined abstractly in a coordinate-independent way, its particular realization as a specific algebra of matrices depends on which orthogonal axes the gamma matrices represent. So what precisely constitutes a "column vector" (or spinor) also depends on such arbitrary choices. The orthogonal Lie algebra (i.e., the infinitesimal "rotations") and the spin group associated to the quadratic form are both (canonically) contained in the Clifford algebra, so every Clifford algebra representation also defines a representation of the Lie algebra and the spin group. Depending on the dimension and metric signature, this realization of spinors as column vectors may be irreducible or it may decompose into a pair of so-called "half-spin" or Weyl representations.

The space of spinors is formally defined as the fundamental representation of the Clifford algebra. (This may or may not decompose into irreducible representations.) The space of spinors may also be defined as a spin representation of the orthogonal Lie algebra. These spin representations are also characterized as the finite-dimensional projective representations of the special orthogonal group that do not factor through linear representations. Equivalently, a spinor is an element of a finite-dimensional group representation of the spin group on which the center acts non-trivially.

There are essentially two frameworks for viewing the notion of a spinor.

One is representation theoretic. In this point of view, one knows beforehand that there are some representations of the Lie algebra of the orthogonal group that cannot be formed by the usual tensor constructions. These missing representations are then labeled the spin representations, and their constituents "spinors". In this view, a spinor must belong to a representation of the double cover of the rotation group , or more generally of double cover of the generalized special orthogonal group on spaces with metric signature . These double covers are Lie groups, called the spin groups or . All the properties of spinors, and their applications and derived objects, are manifested first in the spin group. Representations of the double covers of these groups yield double-valued projective representations of the groups themselves. (This means that the action of a particular rotation on vectors the quantum Hilbert space is only defined up to a sign.)

The other point of view is geometrical. One can explicitly construct the spinors, and then examine how they behave under the action of the relevant Lie groups. This latter approach has the advantage of providing a concrete and elementary description of what a spinor is. However, such a description becomes unwieldy when complicated properties of spinors, such as Fierz identities, are needed.

The language of Clifford algebras (sometimes called geometric algebras) provides a complete picture of the spin representations of all the spin groups, and the various relationships between those representations, via the classification of Clifford algebras. It largely removes the need for "ad hoc" constructions.

In detail, let "V" be a finite-dimensional complex vector space with nondegenerate bilinear form "g". The Clifford algebra is the algebra generated by "V" along with the anticommutation relation . It is an abstract version of the algebra generated by the gamma or Pauli matrices. If "V" = C, with the standard form we denote the Clifford algebra by Cℓ(C). Since by the choice of an orthonormal basis every complex vectorspace with non-degenerate form is isomorphic to this standard example, this notation is abused more generally if . If is even, Cℓ(C) is isomorphic as an algebra (in a non-unique way) to the algebra of complex matrices (by the Artin-Wedderburn theorem and the easy to prove fact that the Clifford algebra is central simple). If is odd, Cℓ(C) is isomorphic to the algebra of two copies of the complex matrices. Therefore, in either case has a unique (up to isomorphism) irreducible representation (also called simple Clifford module), commonly denoted by Δ, of dimension 2. Since the Lie algebra is embedded as a Lie subalgebra in equipped with the Clifford algebra commutator as Lie bracket, the space Δ is also a Lie algebra representation of called a spin representation. If "n" is odd, this Lie algebra representation is irreducible. If "n" is even, it splits further into two irreducible representations called the Weyl or "half-spin representations".

Irreducible representations over the reals in the case when "V" is a real vector space are much more intricate, and the reader is referred to the Clifford algebra article for more details.

Spinors form a vector space, usually over the complex numbers, equipped with a linear group representation of the spin group that does not factor through a representation of the group of rotations (see diagram). The spin group is the group of rotations keeping track of the homotopy class. Spinors are needed to encode basic information about the topology of the group of rotations because that group is not simply connected, but the simply connected spin group is its double cover. So for every rotation there are two elements of the spin group that represent it. Geometric vectors and other tensors cannot feel the difference between these two elements, but they produce "opposite" signs when they affect any spinor under the representation. Thinking of the elements of the spin group as homotopy classes of one-parameter families of rotations, each rotation is represented by two distinct homotopy classes of paths to the identity. If a one-parameter family of rotations is visualized as a ribbon in space, with the arc length parameter of that ribbon being the parameter (its tangent, normal, binormal frame actually gives the rotation), then these two distinct homotopy classes are visualized in the two states of the belt trick puzzle (above). The space of spinors is an auxiliary vector space that can be constructed explicitly in coordinates, but ultimately only exists up to isomorphism in that there is no "natural" construction of them that does not rely on arbitrary choices such as coordinate systems. A notion of spinors can be associated, as such an auxiliary mathematical object, with any vector space equipped with a quadratic form such as Euclidean space with its standard dot product, or Minkowski space with its Lorentz metric. In the latter case, the "rotations" include the Lorentz boosts, but otherwise the theory is substantially similar.

The most typical type of spinor, the Dirac spinor, is an element of the fundamental representation of , the complexification of the Clifford algebra , into which the spin group may be embedded. On a 2"k"- or 2"k"+1-dimensional space a Dirac spinor may be represented as a vector of 2 complex numbers. (See Special unitary group.) In even dimensions, this representation is reducible when taken as a representation of and may be decomposed into two: the left-handed and right-handed Weyl spinor representations. In addition, sometimes the non-complexified version of has a smaller real representation, the Majorana spinor representation. If this happens in an even dimension, the Majorana spinor representation will sometimes decompose into two Majorana–Weyl spinor representations. Dirac and Weyl spinors are complex representations while Majorana spinors are real representations.

The Dirac, Lorentz, Weyl, and Majorana spinors are interrelated, and their relation can be elucidated on the basis of real geometric algebra.

Massive particles, such as electrons, are described as Dirac spinors (more precisely sections of the associated Spinor bundle to account for spacetime dependence). The classical neutrino of the standard model of particle physics is an example of a Weyl spinor. However, because of observed neutrino oscillation, it is now believed that they are not Weyl spinors, but perhaps instead Majorana spinors. It is not known whether (spin-1/2) Weyl spinors exist in nature. In 2015, an international team led by Princeton University scientists announced that they had found a quasiparticle that behaves as a Weyl fermion.

One major mathematical application of the construction of spinors is to make possible the explicit construction of linear representations of the Lie algebras of the special orthogonal groups, and consequently spinor representations of the groups themselves. At a more profound level, spinors have been found to be at the heart of approaches to the Atiyah–Singer index theorem, and to provide constructions in particular for discrete series representations of semisimple groups.

The spin representations of the special orthogonal Lie algebras are distinguished from the tensor representations given by Weyl's construction by the weights. Whereas the weights of the tensor representations are integer linear combinations of the roots of the Lie algebra, those of the spin representations are half-integer linear combinations thereof. Explicit details can be found in the spin representation article.

The spinor can be described, in simple terms, as "vectors of a space the transformations of which are related in a particular way to rotations in physical space". Stated differently:
Several ways of illustrating everyday analogies have been formulated in terms of the plate trick, tangloids and other examples of orientation entanglement.

Nonetheless, the concept is generally considered notoriously difficult to understand, as illustrated by Michael Atiyah's statement that is recounted by Dirac's biographer Graham Farmelo:
The most general mathematical form of spinors was discovered by Élie Cartan in 1913. The word "spinor" was coined by Paul Ehrenfest in his work on quantum physics.

Spinors were first applied to mathematical physics by Wolfgang Pauli in 1927, when he introduced his spin matrices. The following year, Paul Dirac discovered the fully relativistic theory of electron spin by showing the connection between spinors and the Lorentz group. By the 1930s, Dirac, Piet Hein and others at the Niels Bohr Institute (then known as the Institute for Theoretical Physics of the University of Copenhagen) created toys such as Tangloids to teach and model the calculus of spinors.

Spinor spaces were represented as left ideals of a matrix algebra in 1930, by G. Juvet and by Fritz Sauter. More specifically, instead of representing spinors as complex-valued 2D column vectors as Pauli had done, they represented them as complex-valued 2 × 2 matrices in which only the elements of the left column are non-zero. In this manner the spinor space became a minimal left ideal in .

In 1947 Marcel Riesz constructed spinor spaces as elements of a minimal left ideal of Clifford algebras. In 1966/1967, David Hestenes replaced spinor spaces by the even subalgebra Cℓ(R) of the spacetime algebra Cℓ(R). As of the 1980s, the theoretical physics group at Birkbeck College around David Bohm and Basil Hiley has been developing algebraic approaches to quantum theory that build on Sauter and Riesz' identification of spinors with minimal left ideals.

Some simple examples of spinors in low dimensions arise from considering the even-graded subalgebras of the Clifford algebra . This is an algebra built up from an orthonormal basis of mutually orthogonal vectors under addition and multiplication, "p" of which have norm +1 and "q" of which have norm −1, with the product rule for the basis vectors

The Clifford algebra Cℓ(R) is built up from a basis of one unit scalar, 1, two orthogonal unit vectors, "σ" and "σ", and one unit pseudoscalar . From the definitions above, it is evident that , and .

The even subalgebra Cℓ(R), spanned by "even-graded" basis elements of Cℓ(R), determines the space of spinors via its representations. It is made up of real linear combinations of 1 and "σ""σ". As a real algebra, Cℓ(R) is isomorphic to the field of complex numbers C. As a result, it admits a conjugation operation (analogous to complex conjugation), sometimes called the "reverse" of a Clifford element, defined by
which, by the Clifford relations, can be written

The action of an even Clifford element on vectors, regarded as 1-graded elements of Cℓ(R), is determined by mapping a general vector to the vector
where "γ" is the conjugate of "γ", and the product is Clifford multiplication. In this situation, a spinor is an ordinary complex number. The action of "γ" on a spinor "φ" is given by ordinary complex multiplication:

An important feature of this definition is the distinction between ordinary vectors and spinors, manifested in how the even-graded elements act on each of them in different ways. In general, a quick check of the Clifford relations reveals that even-graded elements conjugate-commute with ordinary vectors:
On the other hand, comparing with the action on spinors , "γ" on ordinary vectors acts as the "square" of its action on spinors.

Consider, for example, the implication this has for plane rotations. Rotating a vector through an angle of "θ" corresponds to , so that the corresponding action on spinors is via . In general, because of logarithmic branching, it is impossible to choose a sign in a consistent way. Thus the representation of plane rotations on spinors is two-valued.

In applications of spinors in two dimensions, it is common to exploit the fact that the algebra of even-graded elements (that is just the ring of complex numbers) is identical to the space of spinors. So, by abuse of language, the two are often conflated. One may then talk about "the action of a spinor on a vector." In a general setting, such statements are meaningless. But in dimensions 2 and 3 (as applied, for example, to computer graphics) they make sense.



The Clifford algebra Cℓ(R) is built up from a basis of one unit scalar, 1, three orthogonal unit vectors, "σ", "σ" and "σ", the three unit bivectors "σ""σ", "σ""σ", "σ""σ" and the pseudoscalar . It is straightforward to show that , and .

The sub-algebra of even-graded elements is made up of scalar dilations,
and vector rotations
where
corresponds to a vector rotation through an angle "θ" about an axis defined by a unit vector .

As a special case, it is easy to see that, if , this reproduces the "σ""σ" rotation considered in the previous section; and that such rotation leaves the coefficients of vectors in the "σ" direction invariant, since

The bivectors "σ""σ", "σ""σ" and "σ""σ" are in fact Hamilton's quaternions i, j and k, discovered in 1843:

With the identification of the even-graded elements with the algebra H of quaternions, as in the case of two dimensions the only representation of the algebra of even-graded elements is on itself. Thus the (real) spinors in three-dimensions are quaternions, and the action of an even-graded element on a spinor is given by ordinary quaternionic multiplication.

Note that the expression (1) for a vector rotation through an angle , "the angle appearing in γ was halved". Thus the spinor rotation (ordinary quaternionic multiplication) will rotate the spinor through an angle one-half the measure of the angle of the corresponding vector rotation. Once again, the problem of lifting a vector rotation to a spinor rotation is two-valued: the expression (1) with in place of "θ"/2 will produce the same vector rotation, but the negative of the spinor rotation.

The spinor/quaternion representation of rotations in 3D is becoming increasingly prevalent in computer geometry and other applications, because of the notable brevity of the corresponding spin matrix, and the simplicity with which they can be multiplied together to calculate the combined effect of successive rotations about different axes.

A space of spinors can be constructed explicitly with concrete and abstract constructions. The
equivalence of these constructions are a consequence of the uniqueness of the spinor representation of the complex Clifford algebra. For a complete example in dimension 3, see spinors in three dimensions.

Given a vector space "V" and a quadratic form "g" an explicit matrix representation of the Clifford algebra can be defined as follows. Choose an orthonormal basis for "V" i.e. where and for . Let . Fix a set of matrices such that (i.e. fix a convention for the gamma matrices). Then the assignment extends uniquely to an algebra homomorphism by sending the monomial in the Clifford algebra to the product of matrices and extending linearly. The space on which the gamma matrices act is now a space of spinors. One needs to construct such matrices explicitly, however. In dimension 3, defining the gamma matrices to be the Pauli sigma matrices gives rise to the familiar two component spinors used in non relativistic quantum mechanics. Likewise using the Dirac gamma matrices gives rise to the 4 component Dirac spinors used in 3+1 dimensional relativistic quantum field theory. In general, in order to define gamma matrices of the required kind, one can use the Weyl–Brauer matrices.

In this construction the representation of the Clifford algebra , the Lie algebra , and the Spin group , all depend on the choice of the orthonormal basis and the choice of the gamma matrices. This can cause confusion over conventions, but invariants like traces are independent of choices. In particular, all physically observable quantities must be independent of such choices. In this construction a spinor can be represented as a vector of 2 complex numbers and is denoted with spinor indices (usually "α", "β", "γ"). In the physics literature, abstract spinor indices are often used to denote spinors even when an abstract spinor construction is used.

There are at least two different, but essentially equivalent, ways to define spinors abstractly. One approach seeks to identify the minimal ideals for the left action of on itself. These are subspaces of the Clifford algebra of the form , admitting the evident action of by left-multiplication: . There are two variations on this theme: one can either find a primitive element that is a nilpotent element of the Clifford algebra, or one that is an idempotent. The construction via nilpotent elements is more fundamental in the sense that an idempotent may then be produced from it. In this way, the spinor representations are identified with certain subspaces of the Clifford algebra itself. The second approach is to construct a vector space using a distinguished subspace of , and then specify the action of the Clifford algebra "externally" to that vector space.

In either approach, the fundamental notion is that of an isotropic subspace . Each construction depends on an initial freedom in choosing this subspace. In physical terms, this corresponds to the fact that there is no measurement protocol that can specify a basis of the spin space, even if a preferred basis of is given.

As above, we let be an -dimensional complex vector space equipped with a nondegenerate bilinear form. If is a real vector space, then we replace by its complexification and let denote the induced bilinear form on . Let be a maximal isotropic subspace, i.e. a maximal subspace of such that . If is even, then let be an isotropic subspace complementary to . If is odd, let be a maximal isotropic subspace with , and let be the orthogonal complement of . In both the even- and odd-dimensional cases and have dimension . In the odd-dimensional case, is one-dimensional, spanned by a unit vector .

Since "W" is isotropic, multiplication of elements of "W" inside is skew. Hence vectors in "W" anti-commute, and is just the exterior algebra Λ"W". Consequently, the "k"-fold product of "W" with itself, "W", is one-dimensional. Let "ω" be a generator of "W". In terms of a basis of in "W", one possibility is to set

Note that (i.e., "ω" is nilpotent of order 2), and moreover, for all . The following facts can be proven easily:

In detail, suppose for instance that "n" is even. Suppose that "I" is a non-zero left ideal contained in . We shall show that "I" must be equal to by proving that it contains a nonzero scalar multiple of "ω".

Fix a basis "w" of "W" and a complementary basis "w"′ of "W" so that

Note that any element of "I" must have the form "αω", by virtue of our assumption that . Let be any such element. Using the chosen basis, we may write

where the "a" are scalars, and the "B" are auxiliary elements of the Clifford algebra. Observe now that the product
Pick any nonzero monomial "a" in the expansion of "α" with maximal homogeneous degree in the elements "w":
then
is a nonzero scalar multiple of "ω", as required.

Note that for "n" even, this computation also shows that
as a vector space. In the last equality we again used that "W" is isotropic. In physics terms, this shows that Δ is built up like a Fock space by creating spinors using anti-commuting creation operators in "W" acting on a vacuum "ω".

The computations with the minimal ideal construction suggest that a spinor representation can
also be defined directly using the exterior algebra of the isotropic subspace "W".
Let denote the exterior algebra of "W" considered as vector space only. This will be the spin representation, and its elements will be referred to as spinors.

The action of the Clifford algebra on Δ is defined first by giving the action of an element of "V" on Δ, and then showing that this action respects the Clifford relation and so extends to a homomorphism of the full Clifford algebra into the endomorphism ring End(Δ) by the universal property of Clifford algebras. The details differ slightly according to whether the dimension of "V" is even or odd.

When dim("V") is even, where "W"′ is the chosen isotropic complement. Hence any decomposes uniquely as with and . The action of "v" on a spinor is given by
where "i"("w"′) is interior product with "w"′ using the non degenerate quadratic form to identify "V" with "V", and ε(w) denotes the exterior product. It may be verified that
and so "c" respects the Clifford relations and extends to a homomorphism from the Clifford algebra to End(Δ).

The spin representation Δ further decomposes into a pair of irreducible complex representations of the Spin group (the half-spin representations, or Weyl spinors) via

When dim("V") is odd, , where "U" is spanned by a unit vector "u" orthogonal to "W". The Clifford action "c" is defined as before on , while the Clifford action of (multiples of) "u" is defined by
As before, one verifies that "c" respects the Clifford relations, and so induces a homomorphism.

If the vector space "V" has extra structure that provides a decomposition of its complexification into two maximal isotropic subspaces, then the definition of spinors (by either method) becomes natural.

The main example is the case that the real vector space "V" is a hermitian vector space , i.e., "V" is equipped with a complex structure "J" that is an orthogonal transformation with respect to the inner product "g" on "V". Then splits in the ±"i" eigenspaces of "J". These eigenspaces are isotropic for the complexification of "g" and can be identified with the complex vector space and its complex conjugate . Therefore, for a hermitian vector space the vector space Λ (as well as its complex conjugate Λ"V") is a spinor space for the underlying real euclidean vector space.

With the Clifford action as above but with contraction using the hermitian form, this construction gives a spinor space at every point of an almost Hermitian manifold and is the reason why every almost complex manifold (in particular every symplectic manifold) has a Spin structure. Likewise, every complex vector bundle on a manifold carries a Spin structure.

A number of Clebsch–Gordan decompositions are possible on the tensor product of one spin representation with another. These decompositions express the tensor product in terms of the alternating representations of the orthogonal group.

For the real or complex case, the alternating representations are

In addition, for the real orthogonal groups, there are three characters (one-dimensional representations)

The Clebsch–Gordan decomposition allows one to define, among other things:

If is even, then the tensor product of Δ with the contragredient representation decomposes as
which can be seen explicitly by considering (in the Explicit construction) the action of the Clifford algebra on decomposable elements . The rightmost formulation follows from the transformation properties of the Hodge star operator. Note that on restriction to the even Clifford algebra, the paired summands are isomorphic, but under the full Clifford algebra they are not.

There is a natural identification of Δ with its contragredient representation via the conjugation in the Clifford algebra:
So also decomposes in the above manner. Furthermore, under the even Clifford algebra, the half-spin representations decompose

For the complex representations of the real Clifford algebras, the associated reality structure on the complex Clifford algebra descends to the space of spinors (via the explicit construction in terms of minimal ideals, for instance). In this way, we obtain the complex conjugate of the representation Δ, and the following isomorphism is seen to hold:

In particular, note that the representation Δ of the orthochronous spin group is a unitary representation. In general, there are Clebsch–Gordan decompositions

In metric signature , the following isomorphisms hold for the conjugate half-spin representations
Using these isomorphisms, one can deduce analogous decompositions for the tensor products of the half-spin representations .

If is odd, then
In the real case, once again the isomorphism holds
Hence there is a Clebsch–Gordan decomposition (again using the Hodge star to dualize) given by

There are many far-reaching consequences of the Clebsch–Gordan decompositions of the spinor spaces. The most fundamental of these pertain to Dirac's theory of the electron, among whose basic requirements are





</doc>
<doc id="29278" url="https://en.wikipedia.org/wiki?curid=29278" title="Safety engineering">
Safety engineering

Safety engineering is an engineering discipline which assures that engineered systems provide acceptable levels of safety. It is strongly related to industrial engineering/systems engineering, and the subset system safety engineering. Safety engineering assures that a life-critical system behaves as needed, even when components fail.

Analysis techniques can be split into two categories: qualitative and quantitative methods. Both approaches share the goal of finding causal dependencies between a hazard on system level and failures of individual components. Qualitative approaches focus on the question "What must go wrong, such that a system hazard may occur?", while quantitative methods aim at providing estimations about probabilities, rates and/or severity of consequences.

The complexity of the technical systems such as Improvements of Design and Materials, Planned Inspections, Fool-proof design, and Backup Redundancy decreases risk and increases the cost. The risk can be decreased to ALARA (as low as reasonably achievable) or ALAPA (as low as practically achievable) levels.

Traditionally, safety analysis techniques rely solely on skill and expertise of the safety engineer. In the last decade model-based approaches have become prominent. In contrast to traditional methods, model-based techniques try to derive relationships between causes and consequences from some sort of model of the system.

The two most common fault modeling techniques are called failure mode and effects analysis and fault tree analysis. These techniques are just ways of finding problems and of making plans to cope with failures, as in probabilistic risk assessment. One of the earliest complete studies using this technique on a commercial nuclear plant was the WASH-1400 study, also known as the Reactor Safety Study or the Rasmussen Report.

Failure Mode and Effects Analysis (FMEA) is a bottom-up, inductive analytical method which may be performed at either the functional or piece-part level. For functional FMEA, failure modes are identified for each function in a system or equipment item, usually with the help of a functional block diagram. For piece-part FMEA, failure modes are identified for each piece-part component (such as a valve, connector, resistor, or diode). The effects of the failure mode are described, and assigned a probability based on the failure rate and failure mode ratio of the function or component. This quantiazation is difficult for software ---a bug exists or not, and the failure models used for hardware components do not apply. Temperature and age and manufacturing variability affect a resistor; they do not affect software.

Failure modes with identical effects can be combined and summarized in a Failure Mode Effects Summary. When combined with criticality analysis, FMEA is known as Failure Mode, Effects, and Criticality Analysis or FMECA, pronounced "fuh-MEE-kuh".

Fault tree analysis (FTA) is a top-down, deductive analytical method. In FTA, initiating primary events such as component failures, human errors, and external events are traced through Boolean logic gates to an undesired top event such as an aircraft crash or nuclear reactor core melt. The intent is to identify ways to make top events less probable, and verify that safety goals have been achieved.

Fault trees are a logical inverse of success trees, and may be obtained by applying de Morgan's theorem to success trees (which are directly related to reliability block diagrams).

FTA may be qualitative or quantitative. When failure and event probabilities are unknown, qualitative fault trees may be analyzed for minimal cut sets. For example, if any minimal cut set contains a single base event, then the top event may be caused by a single failure. Quantitative FTA is used to compute top event probability, and usually requires computer software such as CAFTA from the Electric Power Research Institute or SAPHIRE from the Idaho National Laboratory.

Some industries use both fault trees and event trees. An event tree starts from an undesired initiator (loss of critical supply, component failure etc.) and follows possible further system events through to a series of final consequences. As each new event is considered, a new node on the tree is added with a split of probabilities of taking either branch. The probabilities of a range of "top events" arising from the initial event can then be seen.

Typically, safety guidelines prescribe a set of steps, deliverable documents, and exit criterion focused around planning, analysis and design, implementation, verification and validation, configuration management, and quality assurance activities for the development of a safety-critical system. In addition, they typically formulate expectations regarding the creation and use of traceability in the project. For example, depending upon the criticality level of a requirement, the US Federal Aviation Authority guideline DO-178B/C requires traceability from requirements to design, and from requirements to source code and executable object code for software components of a system. Thereby, higher quality traceability information can simplify the certification process and help to establish trust in the maturity of the applied development process.

Usually a failure in safety-certified systems is acceptable if, on average, less than one life per 10 hours of continuous operation is lost to failure.{as per FAA document AC 25.1309-1A} Most Western nuclear reactors, medical equipment, and commercial aircraft are certified to this level. The cost versus loss of lives has been considered appropriate at this level (by FAA for aircraft systems under Federal Aviation Regulations).

Once a failure mode is identified, it can usually be mitigated by adding extra or redundant equipment to the system. For example, nuclear reactors contain dangerous radiation, and nuclear reactions can cause so much heat that no substance might contain them. Therefore, reactors have emergency core cooling systems to keep the temperature down, shielding to contain the radiation, and engineered barriers (usually several, nested, surmounted by a containment building) to prevent accidental leakage. Safety-critical systems are commonly required to permit no single event or component failure to result in a catastrophic failure mode.

Most biological organisms have a certain amount of redundancy: multiple organs, multiple limbs, etc.

For any given failure, a fail-over or redundancy can almost always be designed and incorporated into a system.

There are two categories of techniques to reduce the probability of failure:
Fault avoidance techniques increase the reliability of individual items (increased design margin, de-rating, etc.).
Fault tolerance techniques increase the reliability of the system as a whole (redundancies, barriers, etc.).

Safety engineering and reliability engineering have much in common, but safety is not reliability. If a medical device fails, it should fail safely; other alternatives will be available to the surgeon. If the engine on a single-engine aircraft fails, there is no backup. Electrical power grids are designed for both safety and reliability; telephone systems are designed for reliability, which becomes a safety issue when emergency (e.g. US "911") calls are placed.

Probabilistic risk assessment has created a close relationship between safety and reliability. Component reliability, generally defined in terms of component failure rate, and external event probability are both used in quantitative safety assessment methods such as FTA. Related probabilistic methods are used to determine system Mean Time Between Failure (MTBF), system availability, or probability of mission success or failure. Reliability analysis has a broader scope than safety analysis, in that non-critical failures are considered. On the other hand, higher failure rates are considered acceptable for non-critical systems.

Safety generally cannot be achieved through component reliability alone. Catastrophic failure probabilities of 10 per hour correspond to the failure rates of very simple components such as resistors or capacitors. A complex system containing hundreds or thousands of components might be able to achieve a MTBF of 10,000 to 100,000 hours, meaning it would fail at 10 or 10 per hour. If a system failure is catastrophic, usually the only practical way to achieve 10 per hour failure rate is through redundancy.

When adding equipment is impractical (usually because of expense), then the least expensive form of design is often "inherently fail-safe". That is, change the system design so its failure modes are not catastrophic. Inherent fail-safes are common in medical equipment, traffic and railway signals, communications equipment, and safety equipment.

The typical approach is to arrange the system so that ordinary single failures cause the mechanism to shut down in a safe way (for nuclear power plants, this is termed a passively safe design, although more than ordinary failures are covered). Alternately, if the system contains a hazard source such as a battery or rotor, then it may be possible to remove the hazard from the system so that its failure modes cannot be catastrophic. The U.S. Department of Defense Standard Practice for System Safety (MIL–STD–882) places the highest priority on elimination of hazards through design selection.

One of the most common fail-safe systems is the overflow tube in baths and kitchen sinks. If the valve sticks open, rather than causing an overflow and damage, the tank spills into an overflow. Another common example is that in an elevator the cable supporting the car keeps spring-loaded brakes open. If the cable breaks, the brakes grab rails, and the elevator cabin does not fall.

Some systems can never be made fail safe, as continuous availability is needed. For example, loss of engine thrust in flight is dangerous. Redundancy, fault tolerance, or recovery procedures are used for these situations (e.g. multiple independent controlled and fuel fed engines). This also makes the system less sensitive for the reliability prediction errors or quality induced uncertainty for the separate items. On the other hand, failure detection & correction and avoidance of common cause failures becomes here increasingly important to ensure system level reliability.






</doc>
<doc id="29279" url="https://en.wikipedia.org/wiki?curid=29279" title="SIGGRAPH">
SIGGRAPH

SIGGRAPH (Special Interest Group on Computer GRAPHics and Interactive Techniques) is the annual conference on computer graphics (CG) convened by the ACM SIGGRAPH organization. The first SIGGRAPH conference was in 1974. The conference is attended by tens of thousands of computer professionals. Past conferences have been held in Los Angeles, Dallas, New Orleans, Boston, Vancouver, and elsewhere in North America. SIGGRAPH Asia, a second yearly conference, has been held since 2008 in various Asian countries.

Some highlights of the conference are its Animation Theater and Electronic Theater presentations, where recently created CG films are played. There is a large exhibition floor, where several hundred companies set up elaborate booths and compete for attention and recruits. Most of the companies are in the engineering, graphics, motion picture, or video game industries. There are also many booths for schools which specialize in computer graphics or interactivity.

Dozens of research papers are presented each year, and SIGGRAPH is widely considered the most prestigious forum for the publication of computer graphics research. The recent paper acceptance rate for SIGGRAPH has been less than 26%. The submitted papers are peer-reviewed in a single-blind process. There has been some criticism about the preference of SIGGRAPH paper reviewers for novel results rather than useful incremental progress. The papers accepted for presentation at SIGGRAPH are printed since 2003 in a special issue of the "ACM Transactions on Graphics" journal. 
Prior to 1992, SIGGRAPH papers were printed as part of the "Computer Graphics" publication; between 1993 and 2001, there was a dedicated "SIGGRAPH Conference Proceedings" series of publications.

In addition to the papers, there are numerous panels of industry experts set up to discuss a wide variety of topics, from computer graphics to machine interactivity to education. SIGGRAPH also offers many full- and half-day courses in state-of-the-art computer graphics topics, as well as shorter "sketch" presentations where artists and researchers discuss their latest work.

In 1984, under LucasFilm Computer Group, John Lasseter's first computer animated short, "The Adventures of André & Wally B.", premiered at SIGGRAPH. Pixar's first computer animated short, "Luxo, Jr." debuted in 1986. Pixar has debuted numerous shorts at the conference since.

SIGGRAPH has several awards programs to recognize outstanding contributions to computer graphics. The most prestigious is the Steven Anson Coons Award for Outstanding Creative Contributions to Computer Graphics. It has been awarded every two years since 1983 to recognize an individual's lifetime achievement in computer graphics.

The following conference areas are the areas scheduled for SIGGRAPH 2012, as some conference areas vary annually.

Since 2008, a second yearly SIGGRAPH conference has been held in Asia. The first SIGGRAPH Asia conference was held in Singapore from 10 to 13 December 2008 at the Suntec Singapore International Convention and Exhibition Centre; the second one in Yokohama, Japan from 16 to 19 December 2009 at Pacifico Yokohama; and the third in Seoul, Korea from 15 to 18 December 2010 at Coex Convention & Exhibition Center Seoul.




</doc>
<doc id="29285" url="https://en.wikipedia.org/wiki?curid=29285" title="Semtex">
Semtex

Semtex is a general-purpose plastic explosive containing RDX and PETN. It is used in commercial blasting, demolition, and in certain military applications. 

Semtex was developed and manufactured in Czechoslovakia, originally under the name B 1 and then under "Semtex" designation since 1964, labeled as "SEMTEX 1A", since 1967 as "SEMTEX H" and since 1987 as "SEMTEX 10".

Originally developed for Czechoslovak military use and export, Semtex eventually became popular with terrorists because it was, until recently, extremely difficult to detect, as in the case of Pan Am Flight 103.

The composition of the two most common variants differ according to their use. The 1A (or 10) variant is used for blasting, and is based mostly on crystalline PETN. The version 1AP and 2P are formed as hexagonal booster charges; a special assembly of PETN and wax inside the charge assures high reliability for detonating cord or detonator. The H (or SE) variant is intended for explosion hardening.

Semtex was invented in the late 1950s by Stanislav Brebera and Radim Fukátko, chemists at VCHZ Synthesia, Czechoslovakia (now Czech Republic). The explosive is named after Semtín, a suburb of Pardubice where the mixture was first manufactured starting in 1964. The plant was later renamed to become Explosia a.s., a subsidiary of Synthesia.

Semtex was very similar to other plastic explosives, especially C-4, in being highly malleable; but it is usable over a greater temperature range than other plastic explosives, since it stays plastic between −40 and +60 °C. It is also waterproof. There are visual differences between Semtex and other plastic explosives, too: while C-4 is off-white in colour, Semtex is red or brick-orange.

The new explosive was widely exported, notably to the government of North Vietnam, which received 14 tons during the Vietnam War. However, the main consumer was Libya; about 700 tons of Semtex were exported to Libya between 1975 and 1981 by Omnipol. It has also been used by Islamic militants in the Middle East and by the Provisional Irish Republican Army (IRA) and the Irish National Liberation Army in Northern Ireland.

Exports fell after the name became closely associated with terrorist attacks. Export of Semtex was progressively tightened and since 2002 all of Explosia's sales have been controlled by a government ministry. , only approximately 10 tons of Semtex were produced annually, almost all for domestic use. On December 21, 1988, 12 ounces (340g) of Semtex brought down a Boeing 747 over Lockerbie, Scotland killing all 259 aboard the aircraft and many on the ground, some bodies were never recovered.

Also in response to international agreements, Semtex has a detection taggant added to produce a distinctive vapor signature to aid detection. First, ethylene glycol dinitrate was used, later switched to 2,3-dimethyl-2,3-dinitrobutane (3,4-dinitrohexane, DMDNB) or "p"-mononitrotoluene, which is used currently. According to the manufacturer, the taggant agent was voluntarily being added by 1991, years before the protocol signed became compulsory. Batches of Semtex made before 1990, however, are untagged, though it is not known whether there are still major stocks of such old batches of Semtex. According to the manufacturer, even this untagged Semtex can now be detected. The shelf life of Semtex was reduced from ten years before the 1990s to five years now. Explosia states that there is no compulsory tagging allowing reliable post-detonation detection of a certain plastic explosive (such as incorporating a unique metallic code into the mass of the explosive), so Semtex is not tagged in this way.

On 25 May 1997, Bohumil Šole, a scientist often said to have been involved with inventing Semtex, strapped the explosive to his body and committed suicide in the Priessnitz spa of Jeseník. Šole, 63, was being treated there for depression. Twenty other people were hurt in the explosion, while six were seriously injured. According to the manufacturer, Explosia, he was not a member of the team that developed the explosive.



</doc>
<doc id="29286" url="https://en.wikipedia.org/wiki?curid=29286" title="Schedl">
Schedl

Schedl is a German surname. Notable people with the surname include: 



</doc>
<doc id="29287" url="https://en.wikipedia.org/wiki?curid=29287" title="Lehi (militant group)">
Lehi (militant group)

Lehi (; "Lohamei Herut Israel – Lehi", "Fighters for the Freedom of Israel – Lehi"), often known pejoratively as the Stern Gang, was a Zionist paramilitary organization founded by Avraham ("Yair") Stern in Mandatory Palestine. Its avowed aim was to evict the British authorities from Palestine by resort to force, allowing unrestricted immigration of Jews and the formation of a Jewish state, a "new totalitarian Hebrew republic". It was initially called the National Military Organization in Israel, upon being founded in August 1940, but was renamed Lehi one month later. According to Jean E. Rosenfeld, the group admitted to having used terrorist attacks.

Lehi split from the Irgun militant group in 1940 in order to continue fighting the British during World War II. Lehi initially sought an alliance with Fascist Italy and Nazi Germany, offering to fight alongside them against the British in return for the transfer of all Jews from Nazi-occupied Europe to Palestine. Believing that Nazi Germany was a lesser enemy of the Jews than Britain, Lehi twice attempted to form an alliance with the Nazis. During World War II, it declared that it would establish a Jewish state based upon "nationalist and totalitarian principles". After Stern's death in 1942, the new leadership of Lehi began to move it towards support for Joseph Stalin's Soviet Union. In 1944, Lehi officially declared its support for National Bolshevism. It said that its National Bolshevism involved an amalgamation of left-wing and right-wing political elements – Stern said Lehi incorporated elements of both the left and the right – however this change was unpopular and Lehi began to lose support as a result.

Lehi and the Irgun were jointly responsible for the massacre in Deir Yassin. Lehi assassinated Lord Moyne, British Minister Resident in the Middle East, and made many other attacks on the British in Palestine. On 29 May 1948, the government of Israel, having inducted its activist members into the Israel Defense Forces, formally disbanded Lehi, though some of its members carried out one more terrorist act, the assassination of Folke Bernadotte some months later, an act condemned by Bernadotte's replacement as mediator, Ralph Bunche. After the assassination, the new Israeli government declared Lehi a terrorist organization, arresting and convicting some 200 members. Just before the first Israeli elections, a general amnesty to Lehi members was granted by the government, on 14 February 1949. In 1980, Israel instituted a military decoration, an "award for activity in the struggle for the establishment of Israel", the Lehi ribbon. Former Lehi leader Yitzhak Shamir became Prime Minister of Israel in 1983.

Lehi was created in August 1940 by Avraham Stern. Stern had been a member of the Irgun ("Irgun Tsvai Leumi" – "National Military Organization") high command. Zeev Jabotinsky, then the Irgun's supreme commander, had decided that diplomacy and working with Britain would best serve the Zionist cause. World War II was in progress, and Britain was fighting Nazi Germany. The Irgun suspended its underground military activities against the British for the duration of the war.

Stern argued that the time for Zionist diplomacy was over and that it was time for armed struggle against the British. Like other Zionists, he objected to the White Paper of 1939, which restricted both Jewish immigration and Jewish land purchases in Palestine. For Stern, "no difference existed between Hitler and Chamberlain, between Dachau or Buchenwald and sealing the gates of Eretz Israel."

Stern wanted to open Palestine to all Jewish refugees from Europe, and considered this as by far the most important issue of the day. Britain would not allow this. Therefore, he concluded, the "Yishuv" (Jews of Palestine) should fight the British rather than support them in the war. When the Irgun made a truce with the British, Stern left the Irgun to form his own group, which he called "Irgun Tsvai Leumi B'Yisrael" ("National Military Organization in Israel"), later "Lohamei Herut Israel" ("Fighters for the Freedom of Israel"). In September 1940, the organization was officially named "Lehi", the Hebrew acronym of the latter name.

Stern and his followers believed that dying for the "foreign occupier" who was obstructing the creation of the Jewish State was useless. They differentiated between "enemies of the Jewish people" (the British) and "Jew haters" (the Nazis), believing that the former needed to be defeated and the latter manipulated.

In 1940, the idea of the Final Solution was still "unthinkable", and Stern believed that Hitler wanted to make Germany "judenrein" through emigration, as opposed to extermination. In December 1940, Lehi even contacted Germany with a proposal to aid German conquest in the Middle East in return for recognition of a Jewish state open to unlimited immigration.

Lehi had three main goals:

Lehi believed in its early years that its goals would be achieved by finding a strong international ally that would expel the British from Palestine, in return for Jewish military help; this would require the creation of a broad and organised military force "demonstrating its desire for freedom through military operations."

Lehi also referred to themselves as 'terrorists' and may have been one of the last organizations to do so.

An article titled "Terror" in the Lehi underground newspaper "He Khazit" ("The Front" ) argued as follows:

Neither Jewish ethics nor Jewish tradition can disqualify terrorism as a means of combat. We are very far from having any moral qualms as far as our national war goes. We have before us the command of the Torah, whose morality surpasses that of any other body of laws in the world: "Ye shall blot them out to the last man."
But first and foremost, terrorism is for us a part of the political battle being conducted under the present circumstances, and it has a great part to play: speaking in a clear voice to the whole world, as well as to our wretched brethren outside this land, it proclaims our war against the occupier.
We are particularly far from this sort of hesitation in regard to an enemy whose moral perversion is admitted by all.

The article described the goals of terror:


Yitzhak Shamir, one of the three leaders of Lehi after Avraham Stern's assassination, argued for the legitimacy of Lehi's actions:
There are those who say that to kill [T.G.] Martin [a CID sergeant who had recognised Shamir in a lineup] is terrorism, but to attack an army camp is guerrilla warfare and to bomb civilians is professional warfare. But I think it is the same from the moral point of view. Is it better to drop an atomic bomb on a city than to kill a handful of persons? I don’t think so. But nobody says that President Truman was a terrorist. All the men we went for individually – Wilkin, Martin, MacMichael and others – were personally interested in succeeding in the fight against us.

So it was more efficient and more moral to go for selected targets. In any case, it was the only way we could operate, because we were so small. For us it was not a question of the professional honor of a soldier, it was the question of an idea, an aim that had to be achieved. We were aiming at a political goal. There are many examples of what we did to be found in the Bible – Gideon and Samson, for instance. This had an influence on our thinking. And we also learned from the history of other peoples who fought for their freedom – the Russian and Irish revolutionaries, Giuseppe Garibaldi and Josip Broz Tito.

Avraham Stern laid out the ideology of Lehi in the essay "18 Principles of Rebirth":




Unlike the left-wing Haganah and right-wing Irgun, Lehi members were not a homogeneous collective with a single political, religious, or economic ideology. They were a combination of militants united by the goal of liberating the land of Israel from British rule. Most Lehi leaders defined their organization as an anti-imperialism movement and stated that their opposition to British colonial rule in Palestine was not based on a particular policy but rather on the presence of a foreign power over the homeland of the Jewish people. Avraham Stern defined the British Mandate as "foreign rule" regardless of British policies and took a radical position against such imperialism even if it were to be benevolent.

In the early years of the state of Israel Lehi veterans could be found supporting nearly all political parties and some Lehi leaders founded a left-wing political party called the Fighters' List with Natan Yellin-Mor as its head. The party took part in the elections in January 1949 and won a single parliamentary seat. A number of Lehi veterans established the Semitic Action movement in 1956 which sought the creation of a regional federation encompassing Israel and its Arab neighbors on the basis of an anti-colonialist alliance with other indigenous inhabitants of the Middle East.

Some writers have stated that Lehi's true goals were the creation of a totalitarian state. Perlinger and Weinberg write that the organisation's ideology placed "its world view in the quasi-fascist radical Right, which is characterised by xenophobia, a national egotism that completely subordinates the individual to the needs of the nation, anti-liberalism, total denial of democracy and a highly centralised government." Perliger and Weinberg state that most Lehi members were admirers of the Italian Fascist movement.

Others counter these claims. They note that when Lehi founder Avraham Stern went to study in fascist Italy, he refused to join the for foreign students, even though members got large reductions in tuition.

Many Lehi combatants received professional training. Some attended the state military academy in Civitavecchia, in Fascist Italy. Others received military training from instructors of the Polish Armed Forces in 1938–1939. This training was conducted in Trochenbrod (Zofiówka) in Wołyń Voivodeship, Podębin near Łódź, and the forests around Andrychów. They were taught how to use explosives. One of them reported later: "Poles treated terrorism as a science. We have mastered mathematical principles of demolishing constructions made of concrete, iron, wood, bricks and dirt."

The group was initially unsuccessful. Early attempts to raise funds through criminal activities, including a bank robbery in Tel Aviv in 1940 and another robbery on 9 January 1942 in which Jewish passers-by were killed, brought about the temporary collapse of the group. An attempt to assassinate the head of the British secret police in Lod in which three police personnel were killed, two Jewish and one British, elicited a severe response from the British and Jewish establishments who collaborated against Lehi.

Stern's group was seen as a terrorist organisation by the British authorities, who instructed the Defence Security Office (the colonial branch of MI5) to track down its leaders. In 1942, Stern, after he was arrested, was shot dead in disputed circumstances by Inspector Geoffrey J. Morton of the CID. The arrest of several other members led momentarily to the group's eclipse, until it was revived after the September 1942 escape of two of its leaders, Yitzhak Shamir and Eliyahu Giladi, aided by two other escapees Natan Yellin-Mor (Friedman) and Israel Eldad (Sheib). (Giladi was later killed by Lehi under circumstances that remain mysterious.) Shamir's codename was "Michael", a reference to one of Shamir's heroes, Michael Collins. Lehi was guided by spiritual and philosophical leaders such as Uri Zvi Greenberg and Israel Eldad. After the killing of Giladi, the organization was led by a triumvirate of Eldad, Shamir, and Yellin-Mor.

Lehi adopted a non-socialist platform of Anti-Imperialist ideology. It viewed the continued British rule of Palestine as a violation of the Mandate's provision generally, and its restrictions on Jewish immigration to be an intolerable breach of international law. However they also targeted Jews whom they regarded as traitors, and during the 1948 Arab-Israeli War they joined in operations with the Haganah and Irgun against Arab targets, for example Deir Yassin.

According to a compilation by Nachman Ben-Yehuda, Lehi was responsible for 42 assassinations, more than twice as many as the Irgun and Haganah combined during the same period. Of those Lehi assassinations that Ben-Yehuda classified as political, more than half the victims were Jews.

Lehi also rejected the authority of the Jewish Agency for Israel and related organizations, operating entirely on its own throughout nearly all of its existence.

Lehi prisoners captured by the British generally refused to present a defence when brought to trial. They would only read out statements in which they declared that the court, representing an occupying force, had no jurisdiction over them and therefore was illegal. For the same reason, Lehi prisoners refused to plead for amnesty, even when it was clear that this would have spared them the death penalty. In one case Moshe Barazani, a Lehi member, and Meir Feinstein, an Irgun member, committed suicide in prison with a grenade smuggled inside an orange so the British could not hang them.

In mid-1940, Stern became convinced that the Italians were interested in the establishment of a fascist Jewish state in Palestine. He conducted negotiations, he thought, with the Italians via an intermediary Moshe Rotstein, and drew up a document that became known as the "Jerusalem Agreement". In exchange for Italy's recognition of, and aid in obtaining, Jewish sovereignty over Palestine, Stern promised that Zionism would come under the aegis of Italian fascism, with Haifa as its base, and the Old City of Jerusalem under Vatican control, except for the Jewish quarter. In Heller's words, Stern's proposal would "turn the 'Kingdom of Israel' into a satellite of the Axis powers."

However, the "intermediary" Rotstein was in fact an agent of the Irgun, conducting a sting operation under the direction of the Irgun intelligence leader in Haifa, Israel Pritzker, in cooperation with the British. Secret British documents about the affair were uncovered by historian Eldad Harouvi (now director of the Palmach Archives) and confirmed by former Irgun intelligence officer Yitzhak Berman. When Rotstein's role later became clear, Lehi sentenced him to death and assigned Yaacov Eliav to kill him, but the assassination never took place. However, Pritzker was killed by Lehi in 1943.

Late in 1940, Lehi, having identified a common interest between the intentions of the new German order and Jewish national aspirations, proposed forming an alliance in World War II with Nazi Germany. It offered assistance in transferring the Jews of Europe to Palestine, in return for Germany's help in expelling Britain from Mandatory Palestine. Late in 1940, Lehi representative Naftali Lubenchik went to Beirut to meet German official Werner Otto von Hentig (who also was involved with the Haavara or Transfer Agreement, which had been transferring German Jews and their funds to Palestine since 1933). Lubenchik told von Hentig that Lehi had not yet revealed its full power and that they were capable of organizing a whole range of anti-British operations.

The organization offered cooperation in the following terms. Lehi would support sabotage and espionage operations in the Middle East and in eastern Europe anywhere where they had cells. Germany would recognize an independent Jewish state in Palestine/Eretz Israel, and all Jews leaving their homes in Europe, by their own will or because of government injunctions, could enter Palestine with no restriction of numbers.

Stern also proposed recruiting some 40,000 Jews from occupied Europe to invade Palestine with German support to oust the British. On 11 January 1941, Vice Admiral Ralf von der Marwitz, the German Naval attaché in Turkey, filed a report (the "Ankara document") conveying an offer by Lehi to "actively take part in the war on Germany's side" in return for German support for "the establishment of the historic Jewish state on a national and totalitarian basis, bound by a treaty with the German Reich."

According to Yellin-Mor:Lubenchik did not take along any written memorandum for the German representatives. Had there been a need for one, he would have formulated it on the spot, since he was familiar with the episode of the Italian "intermediary" and with the numerous drafts connected with it. Apparently one of von Hentig's secretaries noted down the essence of the proposal in his own words.According to Joseph Heller, "The memorandum arising from their conversation is an entirely authentic document, on which the stamp of the 'IZL in Israel' is clearly embossed."

Von der Marwitz delivered the offer, classified as secret, to the German Ambassador in Turkey and on 21 January 1941 it was sent to Berlin. There was never any response.

A second attempt to contact the Nazis was made at the end of 1941, but it was even less successful. The emissary Yellin-Mor was arrested in Syria before he could carry out his mission.

This proposed alliance with Nazi Germany cost Lehi and Stern much support. The Stern Gang also had links with, and support from, the Vichy France Sûreté's Lebanese offices.

As a group that never had over a few hundred members, Lehi relied on audacious but small-scale operations to bring their message home. They adopted the tactics of groups such as the Socialist Revolutionaries and the Combat Organization of the Polish Socialist Party in Czarist Russia, and the Irish Republican Army. To this end, Lehi conducted small-scale operations such as individual assassinations of British officials (notable targets included Lord Moyne, CID detectives, and Jewish "collaborators"), and random shootings against soldiers and police officers. Another strategy, adopted in 1946, was to send bombs in the mail to British politicians. Other actions included sabotaging infrastructure targets: bridges, railroads, telephone and telegraph lines, and oil refineries, as well as the use of vehicle bombs against British military, police, and administrative targets. Lehi financed its operations from private donations, extortion, and bank robbery. Its campaign of violence lasted from 1944 to 1948. Initially conducted together with the Irgun, it included a six-month suspension to avoid being targeted by the Haganah during the Hunting Season, and later operated jointly with the Haganah and Irgun under the Jewish Resistance Movement. After the Jewish Resistance Movement was dissolved, it operated independently as part of the general Jewish insurgency in Palestine.

On 6 November 1944, Lehi assassinated Lord Moyne, the British Minister Resident in the Middle East, in Cairo. Moyne was the highest ranking British official in the region. Yitzhak Shamir claimed later that Moyne was assassinated because of his support for a Middle Eastern Arab Federation and anti-Semitic lectures in which Arabs were held to be racially superior to Jews. The assassination rocked the British government, and outraged Winston Churchill, the British Prime Minister. The two assassins, Eliahu Bet-Zouri and Eliahu Hakim were captured and used their trial as a platform to make public their political propaganda. They were executed. In 1975 their bodies were returned to Israel and given a state funeral. In 1982, postage stamps were issued for 20 Olei Hagardom, including Bet-Zouri and Hakim, in a souvenir sheet called "Martyrs of the struggle for Israel's independence."

On 25 April 1946, a Lehi unit attacked a car park in Tel Aviv occupied by the British 6th Airborne Division. Under a barrage of heavy covering fire, Lehi fighters broke into the car park, shot soldiers they encountered at close range, stole rifles from arms racks, laid mines to cover the retreat, and withdrew. Seven soldiers were killed in the attack, which caused widespread outrage among the British security forces in Palestine. It resulted in retaliatory anti-Jewish violence by British troops and a punitive curfew imposed on Tel Aviv's roads and a closure of places of entertainment in the city by the British Army.

On 12 January 1947, Lehi members drove a truckload of explosives into a British police station in Haifa killing four and injuring 140, in what has been called 'the world's first true truck bomb'.

Following the bombing of the British embassy in Rome, October 1946, a series of operations against targets in the United Kingdom were launched. On 7 March 1947, Lehi's only successful operation in Britain was carried out when a Lehi bomb severely damaged the British Colonial Club, a London recreational facility for soldiers and students from Britain's colonies in Africa and the West Indies. On 15 April 1947 a bomb consisting of twenty-four sticks of explosives was planted in the Colonial Office, Whitehall. It failed to explode due to a fault in the timer. Five weeks later, on 22 May, five alleged Lehi members were arrested in Paris with bomb making material including explosives of the same type as found in London. On 2 June, two Lehi members, Betty Knouth and Yaakov Levstien, were arrested crossing from Belgium to France. Envelopes addressed to British officials, with detonators, batteries and a time fuse were found in one of Knouth's suitcases. Knouth was sentenced to a year in prison, Levstien to eight months. The British Security Services identified Knouth as the person who planted the bomb in the Colonial Office. Shortly after their arrest, 21 letter bombs were intercepted addressed to senior British figures. The letters had been posted in Italy. The intended recipients included Bevin, Attlee, Churchill and Eden. Knouth aka Gilberte/Elizabeth Lazarus. Levstein was travelling as Jacob Elias; his fingerprints connected him to the deaths of several Palestine Policemen as well as an attempt on the life of the British High Commissioner. In 1973, Margaret Truman wrote that letter bombs were also posted to her father, U.S. President Harry S. Truman, in 1947. Former Lehi leader Yellin-Mor admitted that letter bombs had been sent to British targets but denied that any had been sent to Truman.

Shortly after the 1947 publication of "The Last Days of Hitler", Lehi issued a death threat against the author, Hugh Trevor-Roper, for his portrayal of Hitler, feeling that Trevor-Roper had attempted to exonerate the German populace from responsibility.

During the lead-up to the 1948 Arab–Israeli War, Lehi mined the Cairo–Haifa train several times. On 29 February 1948, Lehi mined the train north of Rehovot, killing 28 British soldiers and wounding 35. On 31 March, Lehi mined the train near Binyamina, killing 40 civilians and wounding 60.

One of the most widely known acts of Lehi was the attack on the Palestinian-Arab village of Deir Yassin.

In the months before the British evacuation from Palestine, the Arab League-sponsored Arab Liberation Army (ALA) occupied several strategic points along the road between Jerusalem and Tel Aviv, cutting off supplies to the Jewish part of Jerusalem. One of these points was Deir Yassin. By March 1948, the road was cut off and Jewish Jerusalem was under siege. The Haganah launched Operation "Nachshon" to break the siege.

On 6 April, the Haganah attacked al-Qastal, a village two kilometers north of Deir Yassin, also overlooking the Jerusalem-Tel Aviv road.

Then on 9 April 1948, about 120 Lehi and Irgun fighters, acting in cooperation with the Haganah, attacked and captured Deir Yassin. The attack was at night, the fighting was confused, and many civilian inhabitants of the village were killed. This action had great consequences for the war, and remains a cause celebre for Palestinians ever since.

Exactly what happened has never been established clearly. The Arab League reported a great massacre: 254 killed, with rape and lurid mutilations. Israeli investigations claimed the actual number of dead was between 100 and 120, and there were no mass rapes, but most of the dead were civilians, and admitted some were killed deliberately. Lehi and Irgun both denied an organized massacre. Accounts by Lehi veterans such as Ezra Yakhin note that many of the attackers were killed or wounded, assert that Arabs fired from every building and that Iraqi and Syrian soldiers were among the dead, and even that some Arab fighters dressed as women.

However, Jewish authorities, including Haganah, the Chief Rabbinate, the Jewish Agency, and David Ben-Gurion, also condemned the attack, lending credence to the charge of massacre. The Jewish Agency even sent a letter of condemnation, apology, and condolence to King Abdullah I of Jordan.

Both the Arab reports and Jewish responses had hidden motives: the Arab leaders wanted to encourage Palestinian Arabs to fight rather than surrender, to discredit the Zionists with international opinion, and to increase popular support in their countries for an invasion of Palestine. The Jewish leaders wanted to discredit Irgun and Lehi.

Ironically, the Arab reports backfired in one respect: frightened Palestinian Arabs did not surrender, but did not fight either – they fled, allowing Israel to gain much territory with little fighting and also without absorbing many Arabs.

Lehi similarly interpreted events at Deir Yassin as turning the tide of war in favor of the Jews. Lehi leader Israel Eldad later wrote in his memoirs from the underground period that "without Deir Yassin the State of Israel could never have been established".

The Deir Yassin story did not much sway international opinion. It did increase not only support but pressure on Arab governments to intervene, notably Abdullah of Jordan, who was now compelled to join the invasion of Palestine after Israel's declaration of independence on 14 May.

The conflict between Lehi and mainstream Jewish and subsequently Israeli organizations came to an end when Lehi was formally dissolved and integrated into the Israeli Defense Forces on 31 May 1948, its leaders getting amnesty from prosecution or reprisals as part of the integration.

Although Lehi had stopped operating nationally after May 1948, the group continued to function in Jerusalem. On 17 September 1948, Lehi assassinated UN mediator Count Folke Bernadotte. The assassination was directed by Yehoshua Zettler and carried out by a four-man team led by Meshulam Makover. The fatal shots were fired by Yehoshua Cohen. The Security Council described the assassination as a "cowardly act which appears to have been committed by a criminal group of terrorists".

Three days after the assassination, the Israeli government passed the Ordinance to Prevent Terrorism and declared Lehi to be a terrorist organization. Many Lehi members were arrested, including leaders Nathan Yellin-Mor and Matitiahu Schmulevitz who were arrested on 29 September. Eldad and Shamir managed to escape arrest. Yellin-Mor and Schmulevitz were charged with leadership of a terrorist organization and on 10 February 1949 were sentenced to 8 years and 5 years imprisonment, respectively. However the State (Temporary) Council soon announced a general amnesty for Lehi members and they were released.

Some of the Lehi leadership founded a left-wing political party called the Fighters' List with the jailed Yellin-Mor as its head. The party took part in the elections in January 1949 and won one seat. Thanks to a general amnesty for Lehi members granted on 14 February 1949, Yellin-Mor was released from prison to take up his place in the Knesset. However, the party disbanded after failing to win a seat in the 1951 elections.

In 1956, some Lehi veterans established the Semitic Action movement, which sought the creation of a regional federation encompassing Israel and its Arab neighbors on the basis of an anti-colonialist alliance with other indigenous inhabitants of the Middle East.

Not all Lehi alumni gave up political violence after independence: former members were involved in the activities of the Kingdom of Israel militant group, the 1957 assassination of Rudolf Kastner, and likely the 1952 attempted assassination of David-Zvi Pinkas.

In 1980, Israel instituted the Lehi ribbon, red, black, grey, pale blue and white, which is awarded to former members of the Lehi underground who wished to carry it, "for military service towards the establishment of the State of Israel".

The words and music of a song "Unknown Soldiers" (also translated "Anonymous Soldiers") were written by Avraham Stern in 1932 during the early days of the Irgun. It became the Irgun's anthem until the split with Lehi in 1940, after which it became the Lehi anthem.

A number of Lehi's members went on to play important roles in Israel's public life.





</doc>
<doc id="29288" url="https://en.wikipedia.org/wiki?curid=29288" title="Server-side scripting">
Server-side scripting

Server-side scripting is a technique used in web development which involves employing scripts on a web server which produce a response customized for each user's (client's) request to the website. The alternative is for the web server itself to deliver a static web page. Scripts can be written in any of a number of server-side scripting languages that are available (see below). Server-side scripting is distinguished from client-side scripting where embedded scripts, such as JavaScript, are run client-side in a web browser, but both techniques are often used together.

Server-side scripting is often used to provide a customized interface for the user. These scripts may assemble client characteristics for use in customizing the response based on those characteristics, the user's requirements, access rights, etc. Server-side scripting also enables the website owner to hide the source code that generates the interface, whereas with client-side scripting, the user has access to all the code received by the client. A down-side to the use of server-side scripting is that the client needs to make further requests over the network to the server in order to show new information to the user via the web browser. These requests can slow down the experience for the user, place more load on the server, and prevent use of the application when the user is disconnected from the server.

When the server serves data in a commonly used manner, for example according to the HTTP or FTP protocols, users may have their choice of a number of client programs (most modern web browsers can request and receive data using both of those protocols). In the case of more specialized applications, programmers may write their own server, client, and communications protocol, that can only be used with one another.

Programs that run on a user's local computer without ever sending or receiving data over a network are not considered clients, and so the operations of such programs would not be considered client-side operations.

Netscape introduced an implementation of JavaScript for server-side scripting with Netscape Enterprise Server, first released in December, 1994 (soon after releasing JavaScript for browsers).

Server-side scripting was later used in early 1995 by Fred DuFresne while developing the first web site for Boston, MA television station WCVB. The technology is described in US patent 5835712. The patent was issued in 1998 and is now owned by Open Invention Network (OIN). In 2010 OIN named Fred DuFresne a "Distinguished Inventor" for his work on server-side scripting.

Today, a variety of services use server-side scripting to deliver results back to a client as a paid or free service. An example would be WolframAlpha, which is a computational knowledge engine that computes results outside the clients environment and returns the computed result back. A more commonly used service is Google's proprietary search engine, which searches millions of cached results related to the user specified keyword and returns an ordered list of links back to the client. Apple's Siri application also employs server-side scripting outside of a web application. The application takes an input, computes a result, and returns the result back to the client.

In the earlier days of the web, server-side scripting was almost exclusively performed by using a combination of C programs, Perl scripts, and shell scripts using the Common Gateway Interface (CGI). Those scripts were executed by the operating system, and the results were served back by the web server. Many modern web servers can directly execute on-line scripting languages such as ASP, JSP, Perl, PHP and Ruby either by the web server itself or via extension modules (e.g. mod_perl or mod_php) to the web server. For example, WebDNA includes its own embedded database system. Either form of scripting (i.e., CGI or direct execution) can be used to build up complex multi-page sites, but direct execution usually results in less overhead because of the lower number of calls to external interpreters.

Dynamic websites sometimes use custom web application servers, such as Glassfish, Plack and Python's "Base HTTP Server" library, although some may not consider this to be server-side scripting. When using dynamic web-based scripting techniques, developers must have a keen understanding of the logical, temporal, and physical separation between the client and the server. For a user's action to trigger the execution of server-side code, for example, a developer working with classic ASP must explicitly cause the user's browser to make a request back to the web server. Creating such interactions can easily consume much development time and lead to unreadable code.

Server-side scripts are completely processed by the servers instead of clients. When clients request a page containing server-side scripts, the applicable server processes the scripts and returns an HTML page to the client.

There are a number of server-side scripting languages available, including:



</doc>
<doc id="29290" url="https://en.wikipedia.org/wiki?curid=29290" title="Samuel Huntington">
Samuel Huntington

Samuel Huntington may refer to:




</doc>
<doc id="29292" url="https://en.wikipedia.org/wiki?curid=29292" title="Script">
Script

Script may refer to:







</doc>
<doc id="29293" url="https://en.wikipedia.org/wiki?curid=29293" title="Optical spectrometer">
Optical spectrometer

An optical spectrometer (spectrophotometer, spectrograph or spectroscope) is an instrument used to measure properties of light over a specific portion of the electromagnetic spectrum, typically used in spectroscopic analysis to identify materials. The variable measured is most often the light's intensity but could also, for instance, be the polarization state. The independent variable is usually the wavelength of the light or a unit directly proportional to the photon energy, such as reciprocal centimeters or electron volts, which has a reciprocal relationship to wavelength.

A spectrometer is used in spectroscopy for producing spectral lines and measuring their wavelengths and intensities. Spectrometers may also operate over a wide range of non-optical wavelengths, from gamma rays and X-rays into the far infrared. If the instrument is designed to measure the spectrum in absolute units rather than relative units, then it is typically called a spectrophotometer. The majority of spectrophotometers are used in spectral regions near the visible spectrum.

In general, any particular instrument will operate over a small portion of this total range because of the different techniques used to measure different portions of the spectrum. Below optical frequencies (that is, at microwave and radio frequencies), the spectrum analyzer is a closely related electronic device.

Spectrometers are used in many fields. For example, they are used in astronomy to analyze the radiation from astronomical objects and deduce chemical composition. The spectrometer uses a prism or a grating to spread the light from a distant object into a spectrum. This allows astronomers to detect many of the chemical elements by their characteristic spectral fingerprints. If the object is glowing by itself, it will show spectral lines caused by the glowing gas itself. These lines are named for the elements which cause them, such as the hydrogen alpha, beta, and gamma lines. Chemical compounds may also be identified by absorption. Typically these are dark bands in specific locations in the spectrum caused by energy being absorbed as light from other objects passes through a gas cloud. Much of our knowledge of the chemical makeup of the universe comes from spectra.

Spectroscopes are often used in astronomy and some branches of chemistry. Early spectroscopes were simply prisms with graduations marking wavelengths of light. Modern spectroscopes generally use a diffraction grating, a movable slit, and some kind of photodetector, all automated and controlled by a computer.

Joseph von Fraunhofer developed the first modern spectroscope by combining a prism, diffraction slit and telescope in a manner that increased the spectral resolution and was reproducible in other laboratories. Fraunhofer also went on to invent the first diffraction spectroscope. Gustav Robert Kirchhoff and Robert Bunsen discovered the application of spectroscopes to chemical analysis and used this approach to discover caesium and rubidium. Kirchhoff and Bunsen's analysis also enabled a chemical explanation of stellar spectra, including Fraunhofer lines.

When a material is heated to incandescence it emits light that is characteristic of the atomic makeup of the material.
Particular light frequencies give rise to sharply defined bands on the scale which can be thought of as fingerprints. For example, the element sodium has a very characteristic double yellow band known as the Sodium D-lines at 588.9950 and 589.5924 nanometers, the color of which will be familiar to anyone who has seen a low pressure sodium vapor lamp.

In the original spectroscope design in the early 19th century, light entered a slit and a collimating lens transformed the light into a thin beam of parallel rays. The light then passed through a prism (in hand-held spectroscopes, usually an Amici prism) that refracted the beam into a spectrum because different wavelengths were refracted different amounts due to dispersion. This image was then viewed through a tube with a scale that was transposed upon the spectral image, enabling its direct measurement.

With the development of photographic film, the more accurate spectrograph was created. It was based on the same principle as the spectroscope, but it had a camera in place of the viewing tube. In recent years, the electronic circuits built around the photomultiplier tube have replaced the camera, allowing real-time spectrographic analysis with far greater accuracy. Arrays of photosensors are also used in place of film in spectrographic systems. Such spectral analysis, or spectroscopy, has become an important scientific tool for analyzing the composition of unknown material and for studying astronomical phenomena and testing astronomical theories.

In modern spectrographs in the UV, visible, and near-IR spectral ranges, the spectrum is generally given in the form of photon number per unit wavelength (nm or μm), wavenumber (μm, cm), frequency (THz), or energy (eV), with the units indicated by the abscissa. In the mid- to far-IR, spectra are typically expressed in units of Watts per unit wavelength (μm) or wavenumber (cm). In many cases, the spectrum is displayed with the units left implied (such as "digital counts" per spectral channel).

A spectrograph is an instrument that separates an incoming wave into a frequency spectrum. There are several kinds of machines referred to as "spectrographs", depending on the precise nature of the waves. The first spectrographs used photographic paper as the detector. The star spectral classification and discovery of the main sequence, Hubble's law and the Hubble sequence were all made with spectrographs that used photographic paper. The plant pigment phytochrome was discovered using a spectrograph that used living plants as the detector. More recent spectrographs use electronic detectors, such as CCDs which can be used for both visible and UV light. The exact choice of detector depends on the wavelengths of light to be recorded.

A spectrograph is sometimes called polychromator, as an analogy to monochromator.



</doc>
<doc id="29294" url="https://en.wikipedia.org/wiki?curid=29294" title="IBM System/360">
IBM System/360

The IBM System/360 (S/360) is a family of mainframe computer systems that was announced by IBM on April 7, 1964, and delivered between 1965 and 1978. It was the first family of computers designed to cover the complete range of applications, from small to large, both commercial and scientific. The design made a clear distinction between architecture and implementation, allowing IBM to release a suite of compatible designs at different prices. All but the incompatible model 44 and the most expensive systems used microcode to implement the instruction set, which featured 8-bit byte addressing and binary, decimal and (hexadecimal) floating-point calculations.

The launch of the System/360 family introduced IBM's Solid Logic Technology (SLT), a new technology that was the start of more powerful but smaller computers.

The slowest System/360 model announced in 1964, the Model 30, could perform up to 34,500 instructions per second, with memory from 8 to 64 KB. High performance models came later. The 1967 IBM System/360 Model 91 could do up to 16.6 million instructions per second. The larger 360 models could have up to 8 MB of main memory, though main memory that big was unusual—a large installation might have as little as 256 KB of main storage, but 512 KB, 768 KB or 1024 KB was more common. Up to 8 megabytes of slower (8 microsecond) Large Capacity Storage (LCS) was also available.

The IBM 360 was extremely successful in the market, allowing customers to purchase a smaller system with the knowledge they would always be able to migrate upward if their needs grew, without reprogramming of application software or replacing peripheral devices. Many consider the design one of the most successful computers in history, influencing computer design for years to come.

The chief architect of System/360 was Gene Amdahl, and the project was managed by Fred Brooks, responsible to Chairman Thomas J. Watson Jr. The commercial release was piloted by another of Watson's lieutenants, John R. Opel, who managed the launch of IBM’s System 360 mainframe family in 1964.

Application level compatibility (with some restrictions) for System/360 software is maintained to the present day with the System z servers.

Contrasting with at-the-time normal industry practice, IBM created an entire new series of computers, from small to large, low to high performance, all using the same instruction set (with two exceptions for specific markets). This feat allowed customers to use a cheaper model and then upgrade to larger systems as their needs increased without the time and expense of rewriting software. Before the introduction of System/360, business and scientific applications used different computers with different instruction sets and operating systems. Different-sized computers also had their own instruction sets. IBM was the first manufacturer to exploit microcode technology to implement a compatible range of computers of widely differing performance, although the largest, fastest, models had hard-wired logic instead.

This flexibility greatly lowered barriers to entry. With most other vendors customers had to choose between machines they could outgrow and machines that were potentially too powerful and thus too costly. This meant that many companies simply did not buy computers.

IBM initially announced a series of six computers and forty common peripherals. IBM eventually delivered fourteen models, including rare one-off models for NASA. The least expensive model was the Model 20 with as little as 4096 bytes of core memory, eight 16-bit registers instead of the sixteen 32-bit registers of other System/360 models, and an instruction set that was a subset of that used by the rest of the range.

The initial announcement in 1964 included Models 30, 40, 50, 60, 62, and 70. The first three were low- to middle-range systems aimed at the IBM 1400 series market. All three first shipped in mid-1965. The last three, intended to replace the 7000 series machines, never shipped and were replaced by the 65 and 75, which were first delivered in November 1965, and January 1966, respectively.

Later additions to the low-end included models 20 (1966, mentioned above), 22 (1971), and 25 (1968). The Model 20 had several sub-models; sub-model 5 was at the higher end of the model. The Model 22 was a recycled Model 30 with minor limitations: a smaller maximum memory configuration, and slower I/O channels, which limited it to slower and lower-capacity disk and tape devices than on the 30.

The Model 44 (1966) was a specialized model, designed for scientific computing and for real-time computing and process control, featuring some additional instructions, and with all storage-to-storage instructions and five other complex instructions eliminated.
A succession of high-end machines included the Model 67 (1966, mentioned below, briefly anticipated as the 64 and 66), 85 (1969), 91 (1967, anticipated as the 92), 95 (1968), and 195 (1971). The 85 design was intermediate between the System/360 line and the follow-on System/370 and was the basis for the 370/165. There was a System/370 version of the 195, but it did not include Dynamic Address Translation.

The implementations differed substantially, using different native data path widths, presence or absence of microcode, yet were extremely compatible. Except where specifically documented, the models were architecturally compatible. The 91, for example, was designed for scientific computing and provided out-of-order instruction execution (and could yield "imprecise interrupts" if a program trap occurred while several instructions were being read), but lacked the decimal instruction set used in commercial applications. New features could be added without violating architectural definitions: the 65 had a dual-processor version (M65MP) with extensions for inter-CPU signalling; the 85 introduced cache memory. Models 44, 75, 91, 95, and 195 were implemented with hardwired logic, rather than microcoded as all other models.

The Model 67, announced in August 1965, was the first production IBM system to offer dynamic address translation hardware to support time-sharing. "DAT" is now more commonly referred to as an MMU. An experimental one-off unit was built based on a model 40. Before the 67, IBM had announced models 64 and 66, DAT versions of the 60 and 62, but they were almost immediately replaced by the 67 at the same time that the 60 and 62 were replaced by the 65. DAT hardware would reappear in the S/370 series in 1972, though it was initially absent from the series. Like its close relative, the 65, the 67 also offered dual CPUs.

IBM stopped marketing all System/360 models by the end of 1977.

IBM's existing customers had a large investment in software that executed on second-generation machines. Four models offered the option of emulation of the customer's previous computer using a combination of special hardware, special microcode and an emulation program that used the emulation instructions to simulate the target system, so that old programs could run on the new machine.

However, customers initially had to halt the computer and load the emulation program. 

IBM later added features and modified emulator programs to allow emulation of the 1401, 1440, 1460, 1410 and 7010 under the control of an operating system. 
The Model 85 and later System/370 maintained the precedent, retaining emulation options and allowing emulator programs to execute under operating system control alongside native programs.

System/360 (excepting the Model 20) was replaced by the compatible System/370 range in 1970 and Model 20 users were targeted to move to the IBM System/3. (The idea of a major breakthrough with FS technology was dropped in the mid-1970s for cost-effectiveness and continuity reasons.) Later compatible IBM systems include the 3090, the ES/9000 family, 9672 (System/390 family), the zSeries, System z9, System z10 and IBM zEnterprise System.

Computers that were mostly identical or compatible in terms of the machine code or architecture of the System/360 included Amdahl's 470 family (and its successors), Hitachi mainframes, the UNIVAC 9000 series, Fujitsu as the Facom, the RCA Spectra 70 series, and the English Electric System 4. The System 4 machines were built under license to RCA. RCA sold the Spectra series to what was then UNIVAC, where they became the UNIVAC Series 70. UNIVAC also developed the UNIVAC Series 90 as successors to the 9000 series and Series 70. The Soviet Union produced a System/360 clone named the ES EVM.

The IBM 5100 portable computer, introduced in 1975, offered an option to execute the System/360's APL.SV programming language through a hardware emulator. IBM used this approach to avoid the costs and delay of creating a 5100-specific version of APL.

Special radiation-hardened and otherwise somewhat modified System/360s, in the form of the System/4 Pi avionics computer, are used in several fighter and bomber jet aircraft. In the complete 32-bit AP-101 version, 4 Pi machines were used as the replicated computing nodes of the fault-tolerant Space Shuttle computer system (in five nodes). The U.S. Federal Aviation Administration operated the IBM 9020, a special cluster of modified System/360s for air traffic control, from 1970 until the 1990s. (Some 9020 software is apparently still used via emulation on newer hardware.)

The System/360 introduced a number of industry standards to the marketplace, such as:

The System/360 series has a computer system architecture specification. This specification makes no assumptions on the implementation itself, but rather describes the interfaces and expected behavior of an implementation. The architecture describes mandatory interfaces that must be available on all implementations, and optional interfaces. Some aspects of this architecture are:


Some of the optional features are:


All models of System/360, except for the Model 20 and Model 44, implemented that specification.

Binary arithmetic and logical operations are performed as register-to-register and as memory-to-register/register-to-memory as a standard feature. If the Commercial Instruction Set option was installed, packed decimal arithmetic could be performed as memory-to-memory with some memory-to-register operations. The Scientific Instruction Set feature, if installed, provided access to four floating point registers that could be programmed for either 32-bit or 64-bit floating point operations. The Models 85 and 195 could also operate on 128-bit extended-precision floating point numbers stored in pairs of floating point registers, and software provided emulation in other models. The System/360 used an 8-bit byte, 32-bit word, 64-bit double-word, and 4-bit nibble. Machine instructions had operators with operands, which could contain register numbers or memory addresses. This complex combination of instruction options resulted in a variety of instruction lengths and formats.

Memory addressing was accomplished using a base-plus-displacement scheme, with registers 1 through F (15). A displacement was encoded in 12 bits, thus allowing a 4096-byte displacement (0-4095), as the offset from the address put in a base register.

Register 0 could not be used as a base register nor as an index register (nor as a branch address register), as "0" was reserved to indicate an address in the first 4 KB of memory, that is, if register 0 was specified as described, the value 0x00000000 was implicitly input to the effective address calculation in place of whatever value might be contained within register 0 (or if specified as a branch address register, then no branch was taken, and the content of register 0 was ignored, but any side effect of the instruction was performed).

This specific behavior permitted initial execution of an interrupt routines, since base registers would not necessarily be set to 0 during the first few instruction cycles of an interrupt routine. It isn't needed for IPL ("Initial Program Load" or boot), as one can always clear a register without the need to save it.

With the exception of the Model 67, all addresses were real memory addresses. Virtual memory was not available in most IBM mainframes until the System/370 series. The Model 67 introduced a virtual memory architecture, which MTS, CP-67, and TSS/360 used—but not IBM's mainline System/360 operating systems.

The System/360 machine-code instructions are 2 bytes long (no memory operands), 4 bytes long (one operand), or 6 bytes long (two operands). Instructions are always situated on 2-byte boundaries.

Operations like MVC (Move-Characters) (Hex: D2) can only move at most 256 bytes of information. Moving more than 256 bytes of data required multiple MVC operations. (The System/370 series introduced a family of more powerful instructions such as the MVCL "Move-Characters-Long" instruction, which supports moving up to 16 MB as a single block.)

An operand is two bytes long, typically representing an address as a 4-bit nibble denoting a base register and a 12-bit displacement relative to the contents of that register, in the range 000–FFF (shown here as hexadecimal numbers). The address corresponding to that operand is the contents of the specified general-purpose register plus the displacement. For example, an MVC instruction that moves 256 bytes (with length code 255 in hexadecimal as FF) from base register 7, plus displacement 000, to base register 8, plus displacement 001, would be coded as the 6-byte instruction "D2FF 8001 7000" (operator/length/address1/address2).

The System/360 was designed to separate the "system state" from the "problem state". This provided a basic level of security and recoverability from programming errors. Problem (user) programs could not modify data or program storage associated with the system state. Addressing, data, or operation exception errors made the machine enter the system state through a controlled routine so the operating system could try to correct or terminate the program in error. Similarly, it could recover certain processor hardware errors through the "machine check" routines.

Peripherals interfaced to the system via "channels". A channel is a specialized processor with the instruction set optimized for transferring data between a peripheral and main memory. In modern terms, this could be compared to direct memory access (DMA).

There were initially two types of channels; byte-multiplexer channels (known at the time simply as "multiplexor channels"), for connecting "slow speed" devices such as card readers and punches, line printers, and communications controllers, and selector channels for connecting high speed devices, such as disk drives, tape drives, data cells and drums. Every System/360 (except for the Model 20, which was not a standard 360) has a byte-multiplexer channel and 1 or more selector channels. The smaller models (up to the model 50) have integrated channels, while for the larger models (model 65 and above) the channels are large separate units in separate cabinets, such as the IBM 2860 and 2870. (The 60, 62, and 70 allowed only for 2860 selector channels, on the assumption that they would all have smaller 360s attached, which would do the slow-speed work.)

The byte-multiplexer channel is able to handle I/O to/from several devices simultaneously at the device's highest rated speeds, hence the name, as it multiplexed I/O from those devices onto a single data path to main memory. Devices connected to a byte-multiplexer channel are configured to operate in 1-byte, 2-byte, 4-byte, or "burst" mode. The larger "blocks" of data are used to handle progressively faster devices. For example, a 2501 card reader operating at 600 cards per minute would be in 1-byte mode, while a 1403-N1 printer would be in burst mode. Also, the byte-multiplexer channels on larger models have an optional selector subchannel section that would accommodate tape drives. The byte-multiplexor's channel address was typically "0" and the selector subchannel addresses were from "C0" to "FF." Thus, tape drives on System/360 were commonly addressed at 0C0-0C7. Other common byte-multiplexer addresses are: 00A: 2501 Card Reader, 00C/00D: 2540 Reader/Punch, 00E/00F: 1403-N1 Printers, 010-013: 3211 Printers, 020-0BF: 2701/2703 Telecommunications Units. These addresses are still commonly used in z/VM virtual machines.

System/360 models 40 and 50 have an integrated 1052-7 console that is usually addressed as 01F, however, this was not connected to the byte-multiplexer channel, but rather, had a direct internal connection to the mainframe. The model 30 attached a different model of 1052 through a 1051 control unit. The models 60 through 75 also use the 1052-7.

Selector channels enabled I/O to high speed devices. These storage devices were attached to a control unit and then to the channel. The control unit let clusters of devices be attached to the channels. On higher speed models, multiple selector channels, which could operate simultaneously or in parallel, improved overall performance.

Control units are connected to the channels with "bus and tag" cable pairs. The bus cables carried the address and data information and the tag cables identified what data was on the bus. The general configuration of a channel is to connect the devices in a chain, like this: Mainframe—Control Unit X—Control Unit Y—Control Unit Z. Each control unit is assigned a "capture range" of addresses that it services. For example, control unit X might capture addresses 40-4F, control unit Y: C0-DF, and control unit Z: 80-9F. Capture ranges had to be a multiple of 8, 16, 32, 64, or 128 devices and be aligned on appropriate boundaries. Each control unit in turn has one or more devices attached to it. For example, you could have control unit Y with 6 disks, that would be addressed as C0-C5.

There are three general types of bus-and-tag cables produced by IBM. The first is the standard gray bus-and-tag cable, followed by the blue bus-and-tag cable, and finally the tan bus-and-tag cable. Generally, newer cable revisions are capable of higher speeds or longer distances, and some peripherals specified minimum cable revisions both upstream and downstream.

The cable ordering of the control units on the channel is also significant. Each control unit is "strapped" as High or Low priority. When a device selection was sent out on a mainframe's channel, the selection was sent from X->Y->Z->Y->X. If the control unit was "high" then the selection was checked in the outbound direction, if "low" then the inbound direction. Thus, control unit X was either 1st or 5th, Y was either 2nd or 4th, and Z was 3rd in line. It is also possible to have multiple channels attached to a control unit from the same or multiple mainframes, thus providing a rich high-performance, multiple-access, and backup capability.

Typically the total cable length of a channel is limited to 200 feet, less being preferred. Each control unit accounts for about 10 "feet" of the 200-foot limit.

IBM introduced a new type of I/O channel on the Model 85 and Model 195: the 2880 block multiplexer channel. The channel allowed a device to suspend a channel program, pending the completion of an I/O operation and thus to free the channel for use by another device. These channels can support either standard 1.5 MB/second connections or, with the 2-byte interface feature, 3 MB/second; the latter use one tag cable and two bus cables.

The initial use for this was the 2305 fixed-head disk, which has 8 "exposures" (alias addresses) and rotational position sensing (RPS). They were standard on the System/370 and thereafter.

Block multiplexer channels can operate as a selector channel to allow compatible attachment of legacy subsystems.

Being somewhat uncertain of the reliability and availability of the then new monolithic integrated circuits, IBM chose instead to design custom hybrid integrated circuits using discrete flip chip mounted glass encapsulated transistors and diodes with silk screened resistors on a ceramic substrate. This substrate was then either encapsulated in plastic or covered with a metal lid to create a "Solid Logic Technology" (SLT) module.

A number of these SLT modules were then mounted onto a small multi-layer printed circuit "SLT card". Each card had one or two sockets on one edge that plugged onto pins on one of the computer's "SLT boards". This was the reverse of how most other company's cards were mounted, where the cards had pins which plugged into sockets on the computer's boards.

Up to twenty SLT boards could be assembled side-by-side (vertically and horizontally) to form a "logic gate". Several gates mounted together constituted a box-shaped "logic frame". The outer gates were generally hinged along one vertical edge so they could be swung open to provide access to the fixed inner gates. The larger machines could have more than one frame bolted together to produce the final unit, such as a multi-frame Central Processing Unit (CPU).

The smaller System/360 models used the Basic Operating System/360 (BOS/360), Tape Operating System (TOS/360), or Disk Operating System/360 (DOS/360, which evolved into DOS/VS, DOS/VSE, VSE/AF, VSE/SP, VSE/ESA, and then z/VSE).

The larger models used Operating System/360 (OS/360). IBM developed several versions of OS/360, with increasingly powerful features: Primary Control Program (PCP), Multiprogramming with a Fixed number of Tasks (MFT), and Multiprogramming with a Variable number of Tasks (MVT). MVT took a long time to develop into a usable system, and the less ambitious MFT was widely used. PCP was used on intermediate machines; the final releases of OS/360 included only MFT and MVT. For the System/370 and later machines, MFT evolved into OS/VS1, while MVT evolved into OS/VS2 (SVS) (Single Virtual Storage), then various versions of MVS (Multiple Virtual Storage) culminating in the current z/OS.

When it announced the Model 67 in August 1965, IBM also announced TSS/360 (Time-Sharing System) for delivery at the same time as the 67. TSS/360, a response to Multics, was an ambitious project that included many advanced features. It never worked properly, was delayed, canceled, reinstated, and finally canceled again in 1971. It was replaced by CP-67, MTS (Michigan Terminal System), TSO (Time Sharing Option for OS/360), or one of several other time-sharing systems.

CP-67, the original virtual machine system, was also known as CP/CMS. CP/67 was developed outside the IBM mainstream at IBM's Cambridge Scientific Center, in cooperation with MIT researchers. CP/CMS eventually won wide acceptance, and led to the development of VM/370 (Virtual Machine) which had a primary interactive "sub" operating system known as VM/CMS (Conversational Monitoring System). This evolved into today's z/VM.

The Model 20 offered a simplified and rarely used tape-based system called TPS (Tape Processing System), and DPS (Disk Processing System) that provided support for the 2311 disk drive. TPS could run on a machine with 8 KB of memory; DPS required 12 KB, which was pretty hefty for a Model 20. Many customers ran quite happily with 4 KB and CPS (Card Processing System). With TPS and DPS, the card reader was used to read the Job Control Language cards that defined the stack of jobs to run and to read in transaction data such as customer payments. The operating system was held on tape or disk, and results could also be stored on the tapes or hard drives. Stacked job processing became an exciting possibility for the small but adventurous computer user.

A little-known and little-used suite of 80-column punched-card utility programs known as Basic Programming Support (BPS) (jocularly: Barely Programming Support), a precursor of TOS, was available for smaller systems.

IBM created a new naming system for the new components created for System/360, although well-known old names, like IBM 1403 and IBM 1052, were retained. In this new naming system, components were given four-digit numbers starting with 2. The second digit described the type of component, as follows:
IBM developed a new family of peripheral equipment for System/360, carrying over a few from its older 1400 series. Interfaces were standardized, allowing greater flexibility to mix and match processors, controllers and peripherals than in the earlier product lines.

In addition, System/360 computers could use certain peripherals that were originally developed for earlier computers. These earlier peripherals used a different numbering system, such as the IBM 1403 chain printer. The 1403, an extremely reliable device that had already earned a reputation as a workhorse, was sold as the 1403-N1 when adapted for the System/360.

Also available were optical character recognition (OCR) readers IBM 1287 and IBM 1288 which could read Alpha Numeric (A/N) and Numeric Hand Printed (NHP/NHW) Characters from Cashier's rolls of tape to full legal size pages. At the time this was done with very large optical/logic readers. Software was too slow and expensive at that time.

Most small systems were sold with an IBM 1052-7 as the console typewriter. This was tightly integrated into the CPU — the keyboard would physically lock under program control. Certain high-end machines could optionally be purchased with a 2250 graphical display, costing upwards of US $100,000. The 360/85 used a 5450 display console that was not compatible with anything else in the line; the later 3066 console for the 370/165 and 370/168 used the same basic display design as the 360/85.

The first disk drives for System/360 were IBM 2302s and IBM 2311s.

The 156 KB/second 2302 was based on the earlier 1302 and was available as a model 3 with two 112.79 MB modules or as a model 4 with four such modules.

The 2311, with a removable 1316 disk pack, was based on the IBM 1311 and had a theoretical capacity of 7.2 MB, although actual capacity varied with record design. (When used with a 360/20, the 1316 pack was formatted into fixed-length 270 byte sectors, giving a maximum capacity of 5.4MB.)

In 1966, the first 2314s shipped. This device had up to eight usable disk drives with an integral control unit; there were nine drives, but one was reserved as a spare. Each drive used a removable 2316 disk pack with a capacity of nearly 28 MB. The disk packs for the 2311 and 2314 were "physically" large by today's standards — e.g., the 1316 disk pack was about in diameter and had six platters stacked on a central spindle. The top and bottom outside platters did not store data. Data were recorded on the inner sides of the top and bottom platters and both sides of the inner platters, providing 10 recording surfaces. The 10 read/write heads moved together across the surfaces of the platters, which were formatted with 203 concentric tracks. To reduce the amount of head movement (seeking), data was written in a virtual cylinder from inside top platter down to inside bottom platter. These disks were not usually formatted with fixed-sized sectors as are today's hard drives (though this "was" done with CP/CMS). Rather, most System/360 I/O software could customize the length of the data record (variable-length records), as was the case with magnetic tapes.
Some of the most powerful early System/360s used high-speed head-per-track drum storage devices. The 3,500 RPM 2301, which replaced the 7320, was part of the original System/360 announcement, with a capacity of 4 MB. The 303.8 KB/second IBM 2303 was announced on January 31, 1966, with a capacity of 3.913 MB. These were the only drums announced for System/360 and System/370, and their niche was later filled by fixed-head disks.

The 6,000 RPM 2305 appeared in 1970, with capacities of 5 MB (2305-1) or 11 MB (2305-2) per module. Although these devices did not have large capacity, their speed and transfer rates made them attractive for high-performance needs. A typical use was overlay linkage (e.g. for OS and application subroutines) for program sections written to alternate in the same memory regions. Fixed head disks and drums were particularly effective as paging devices on the early virtual memory systems. The 2305, although often called a "drum" was actually a head-per-track disk device, with 12 recording surfaces and a data transfer rate up to 3 MB per second.

Rarely seen was the IBM 2321 Data Cell, a mechanically complex device that contained multiple magnetic strips to hold data; strips could be randomly accessed, placed upon a cylinder-shaped drum for read/write operations; then returned to an internal storage cartridge. The IBM Data Cell [noodle picker] was among several IBM trademarked "speedy" mass online direct-access storage peripherals (reincarnated in recent years as "virtual tape" and automated tape librarian peripherals). The 2321 file had a capacity of 400 MB, at the time when the 2311 disk drive only had 7.2 MB. The IBM Data Cell was proposed to fill cost/capacity/speed gap between magnetic tapes—which had high capacity with relatively low cost per stored byte—and disks, which had higher expense per byte. Some installations also found the electromechanical operation less dependable and opted for less mechanical forms of direct-access storage.

The Model 44 was unique in offering an integrated single-disk drive as a standard feature. This drive used the 2315 "ramkit" cartridge and provided 1,171,200 bytes of storage.

The 2400 tape drives consisted of a combined drive and control unit, plus individual 1/2" tape drives attached. With System/360, IBM switched from IBM 7 track to 9 track tape format. 2400 drives could be purchased that read and wrote 7 track tapes for compatibility with the older IBM 729 tape drives. In 1967, a slower and cheaper pair of tape drives with integrated control unit was introduced: the 2415. In 1968, the IBM 2420 tape system was released, offering much higher data rates, self-threading tape operation and 1600bpi packing density. It remained in the product line until 1979.


Only a few System/360 computers remain, despite having been sold or leased in very large numbers for a mainframe system of its era. A few of them still run, but most machines were scrapped when they could no longer profitably be leased, certainly for the value of the gold and other precious metal content of their circuits, but possibly also to keep these machines from competing with IBM's newer computers, such as the System/370. As with all classic mainframe systems, complete System/360 computers were prohibitively large to put in storage, and too expensive to maintain.


Six of the twenty IBM System/360 models announced never shipped / were never released.

Fourteen of the twenty IBM System/360 models announced did ship:<br>
20, 22, 25, 30, 40, 44, 50, 65, 67, 75, 85, 91, 95, 195
This gallery shows the operator's console, with register value lamps, toggle switches (middle of pictures), and "emergency pull" switch (upper right of pictures) of the various models.

In the US television series "Mad Men" (2007–2015), the "IBM 360" was featured as a plot device in which a company leased the system to the advertising agency and was a prominent background in the seventh season.





</doc>
<doc id="29298" url="https://en.wikipedia.org/wiki?curid=29298" title="Spouse">
Spouse

A spouse is a life partner in a marriage, civil union, or common-law marriage. The term is gender neutral, whereas a male spouse is a husband and a female spouse is a wife. Although a spouse is a form of significant other, the latter term also includes non-marital partners who play a social role similar to that of a spouse, but do not have rights and duties reserved by law to a spouse.

The legal status of a spouse, and the specific rights and obligations associated with that status, vary significantly between different jurisdictions of the world. These regulations are usually described in family law statutes. However, in many parts of the world, where civil marriage is not that prevalent, there is instead customary marriage, which is usually regulated informally by the community. In many parts of the world, spousal rights and obligations are related to the payment of bride price, dowry or dower. Historically, many societies have given sets of rights and obligations to male marital partners that have been very different from the sets of rights and obligations given to female marital partners. In particular, the control of marital property, inheritance rights, and the right to dictate the activities of children of the marriage, have typically been given to male marital partners. However, this practice was curtailed to a great deal in many countries in the twentieth century, and more modern statutes tend to define the rights and duties of a spouse without reference to gender. Among the last European countries to establish full gender equality in marriage were Switzerland, Greece, Spain, and France in the 1980s. In various marriage laws around the world, however, the husband continues to have authority; for instance the Civil Code of Iran states at Article 1105: ""In relations between husband and wife; the position of the head of the family is the exclusive right of the husband"".

Depending on jurisdiction, the refusal or inability of a spouse to perform the marital obligations may constitute a ground for divorce, legal separation or annulment. The latter two options are more prevalent in countries where the dominant religion is Roman Catholicism, some of which introduced divorce only recently (i.e. Italy in 1970, Portugal in 1975, Brazil in 1977, Spain in 1981, Argentina in 1987, Paraguay in 1991, Colombia in 1991, Ireland in 1996, Chile in 2004 and Malta in 2011). In recent years, many Western countries have adopted no fault divorce. In some parts of the world, the formal dissolution of a marriage is complicated by the payments and goods which have been exchanged between families (this is common where marriages are arranged). This often makes it difficult to leave a marriage, especially for the woman: in some parts of Africa, once the bride price has been paid, the wife is seen as belonging to the husband and his family; and if she wants to leave, the husband may demand back the bride price that he had paid to the girl's family. The girl's family often cannot or does not want to pay it back.

Regardless of legislation, personal relations between spouses may also be influenced by local culture and religion, which may promote male authority over the wife: for instance the word (ba`al), Hebrew for "husband", used throughout the Bible, is synonymous with "owner" and "master".

There is often a minimum legal marriageable age. The United Nations Population Fund stated the following:

Although in Western countries spouses sometimes choose not to have children, such a choice is not accepted in some parts of the world. In some cultures and religions, the quality of a spouse imposes an obligation to have children. In northern Ghana, for example, the payment of bride price signifies a woman's requirement to bear children, and women using birth control are at risks of threats and coercion.

There are many ways in which a spouse is chosen, which vary across the world, and include love marriage, arranged marriage, and forced marriage. The latter is in some jurisdictions a void marriage or a voidable marriage. Forcing someone to marry is also a criminal offense in some countries.



</doc>
<doc id="29299" url="https://en.wikipedia.org/wiki?curid=29299" title="Sexuality (disambiguation)">
Sexuality (disambiguation)

Human sexuality is the capacity to have erotic experiences and responses.

Sexuality may also refer to:



</doc>
<doc id="29301" url="https://en.wikipedia.org/wiki?curid=29301" title="Semiotics">
Semiotics

Semiotics (also called semiotic studies) is the study of meaning-making, the study of sign process (semiosis) and meaningful communication. It is not to be confused with the Saussurean tradition called semiology, which is a subset of semiotics. Semiotics includes the study of signs and sign processes, indication, designation, likeness, analogy, allegory, metonymy, metaphor, symbolism, signification, and communication.

The semiotic tradition explores the study of signs and symbols as a significant part of communications. Different from linguistics, semiotics also studies non-linguistic sign systems.

Semiotics is frequently seen as having important anthropological and sociological dimensions; for example, the Italian semiotician and novelist Umberto Eco proposed that every cultural phenomenon may be studied as communication. Some semioticians focus on the logical dimensions of the science, however. They examine areas belonging also to the life sciences—such as how organisms make predictions about, and adapt to, their semiotic niche in the world (see semiosis). In general, semiotic theories take "signs" or sign systems as their object of study: the communication of information in living organisms is covered in biosemiotics (including zoosemiotics).

The term derives from the Greek σημειωτικός "sēmeiōtikos", "observant of signs" (from σημεῖον "sēmeion", "a sign, a mark") and it was first used in English prior to 1676 by Henry Stubbes (spelt "semeiotics") in a very precise sense to denote the branch of medical science relating to the interpretation of signs. John Locke used the term "sem(e)iotike" in book four, chapter 21 of "An Essay Concerning Human Understanding" (1690). Here he explains how science may be divided into three parts:

Locke then elaborates on the nature of this third category, naming it Σημειωτική ("Semeiotike") and explaining it as "the doctrine of signs" in the following terms:

In the nineteenth century, Charles Sanders Peirce defined what he termed "semiotic" (which he sometimes spelled as "semeiotic") as the "quasi-necessary, or formal doctrine of signs", which abstracts "what must be the characters of all signs used by ... an intelligence capable of learning by experience", and which is philosophical logic pursued in terms of signs and sign processes. The Peirce scholar and editor Max H. Fisch claimed in 1978 that "semeiotic" was Peirce's own preferred rendering of Locke's σημιωτική.

Charles W. Morris followed Peirce in using the term "semiotic" and in extending the discipline beyond human communication to animal learning and use of signals.

Ferdinand de Saussure, however, founded his semiotics, which he called semiology, in the social sciences:

While the Saussurean semiotic is dyadic (sign/syntax, signal/semantics), the Peircean semiotic is triadic (sign, object, interpretant), being conceived as philosophical logic studied in terms of signs that are not always linguistic or artificial. The Peircean semiotic addresses not only the external communication mechanism, as per Saussure, but the internal representation machine, investigating not just sign processes, or modes of inference, but the whole inquiry process in general. Peircean semiotics further subdivides each of the three triadic elements into three sub-types. For example, signs can be icons, indices, and symbols.

Yuri Lotman introduced Eastern Europe to semiotics and adopted Locke's coinage as the name to subtitle ("Σημειωτική") his founding at the University of Tartu in Estonia in 1964 of the first semiotics journal, "Sign Systems Studies".

Thomas Sebeok assimilated "semiology" to "semiotics" as a part to a whole, and was involved in choosing the name "Semiotica" for the first international journal devoted to the study of signs.

Saussurean semiotics have been challenged with serious criticism, for example by Jacques Derrida's assertion that signifier and signified are not fixed, coining the expression "différance", relating to the endless deferral of meaning, and to the absence of a 'transcendent signified'. For Derrida, 'il n'y a pas de hors-texte' ("there is nothing outside the text"). He was in obvious opposition to materialists and marxists who argued that a sign has to point towards a real meaning, and cannot be controlled by the referent's closed-loop references.

The importance of signs and signification has been recognized throughout much of the history of philosophy, and in psychology as well. Plato and Aristotle both explored the relationship between signs and the world, and Augustine considered the nature of the sign within a conventional system. These theories have had a lasting effect in Western philosophy, especially through scholastic philosophy. (More recently, Umberto Eco, in his "Semiotics and the Philosophy of Language", has argued that semiotic theories are implicit in the work of most, perhaps all, major thinkers.)

The general study of signs that began in Latin with Augustine culminated in Latin with the 1632 "Tractatus de Signis" of John Poinsot, and then began anew in late modernity with the attempt in 1867 by Charles Sanders Peirce to draw up a "new list of categories". Peirce aimed to base his new list directly upon experience precisely as constituted by action of signs, in contrast with the list of Aristotle's categories which aimed to articulate within experience the dimension of being that is independent of experience and knowable as such, through human understanding.

The estimative powers of animals interpret the environment as sensed to form a "meaningful world" of objects, but the objects of this world (or "Umwelt", in Jakob von Uexküll's term,) consist exclusively of objects related to the animal as desirable (+), undesirable (–), or "safe to ignore" (0).

In contrast to this, human understanding adds to the animal "Umwelt" a relation of self-identity within objects which transforms objects experienced into "things" as well as +, –, 0 objects. Thus, the generically animal objective world as "Umwelt", becomes a species-specifically human objective world or "Lebenswelt" (life-world), wherein linguistic communication, rooted in the biologically underdetermined "Innenwelt" (inner-world) of humans, makes possible the further dimension of cultural organization within the otherwise merely social organization of non-human animals whose powers of observation may deal only with directly sensible instances of objectivity. This further point, that human culture depends upon language understood first of all not as communication, but as the biologically underdetermined aspect or feature of the human animal's "Innenwelt", was originally clearly identified by Thomas A. Sebeok. Sebeok also played the central role in bringing Peirce's work to the center of the semiotic stage in the twentieth century, first with his expansion of the human use of signs ("anthroposemiosis") to include also the generically animal sign-usage ("zoösemiosis"), then with his further expansion of semiosis (based initially on the work of Martin Krampen, but taking advantage of Peirce's point that an interpretant, as the third item within a sign relation, "need not be mental") to include the vegetative world ("phytosemiosis").

Peirce's distinguished between the interpretant and the interpreter. The interpretant is the internal, mental representation that mediates between the object and its sign. The interpreter is the human who is creating the interpretant. Peirce's "interpretant" notion opened the way to understanding an action of signs beyond the realm of animal life (study of "phytosemiosis" + "zoösemiosis" + "anthroposemiosis" = "biosemiotics"), which was his first advance beyond Latin Age semiotics. Other early theorists in the field of semiotics include Charles W. Morris. Max Black argued that the work of Bertrand Russell was seminal in the field.

Semioticians classify signs or sign systems in relation to the way they are transmitted (see modality). This process of carrying meaning depends on the use of codes that may be the individual sounds or letters that humans use to form words, the body movements they make to show attitude or emotion, or even something as general as the clothes they wear. To coin a word to refer to a "thing" (see lexical words), the community must agree on a simple meaning (a denotative meaning) within their language, but that word can transmit that meaning only within the language's grammatical structures and codes (see syntax and semantics). Codes also represent the values of the culture, and are able to add new shades of connotation to every aspect of life.

To explain the relationship between semiotics and communication studies, communication is defined as the process of transferring data and-or meaning from a source to a receiver. Hence, communication theorists construct models based on codes, media, and contexts to explain the biology, psychology, and mechanics involved. Both disciplines recognize that the technical process cannot be separated from the fact that the receiver must decode the data, i.e., be able to distinguish the data as salient, and make meaning out of it. This implies that there is a necessary overlap between semiotics and communication. Indeed, many of the concepts are shared, although in each field the emphasis is different. In "Messages and Meanings: An Introduction to Semiotics", Marcel Danesi (1994) suggested that semioticians' priorities were to study signification first, and communication second. A more extreme view is offered by Jean-Jacques Nattiez (1987; trans. 1990: 16), who, as a musicologist, considered the theoretical study of communication irrelevant to his application of semiotics.

Semiotics differs from linguistics in that it generalizes the definition of a sign to encompass signs in any medium or sensory modality. Thus it broadens the range of sign systems and sign relations, and extends the definition of language in what amounts to its widest analogical or metaphorical sense. Peirce's definition of the term "semiotic" as the study of necessary features of signs also has the effect of distinguishing the discipline from linguistics as the study of contingent features that the world's languages happen to have acquired in the course of their evolutions. From a subjective standpoint, perhaps more difficult is the distinction between semiotics and the philosophy of language. In a sense, the difference lies between separate traditions rather than subjects. Different authors have called themselves "philosopher of language" or "semiotician". This difference does "not" match the separation between analytic and continental philosophy. On a closer look, there may be found some differences regarding subjects. Philosophy of language pays more attention to natural languages or to languages in general, while semiotics is deeply concerned with non-linguistic signification. Philosophy of language also bears connections to linguistics, while semiotics might appear closer to some of the humanities (including literary theory) and to cultural anthropology.

Semiosis or "semeiosis" is the process that forms meaning from any organism's apprehension of the world through signs. Scholars who have talked about semiosis in their subtheories of semiotics include C. S. Peirce, John Deely, and Umberto Eco. Cognitive semiotics is combining methods and theories developed in the disciplines of cognitive methods and theories developed in semiotics and the humanities, with providing new information into human signification and its manifestation in cultural practices. The research on cognitive semiotics brings together semiotics from linguistics, cognitive science, and related disciplines on a common meta-theoretical platform of concepts, methods, and shared data.

Cognitive semiotics may also be seen as the study of meaning-making by employing and integrating methods and theories developed in the cognitive sciences. This involves conceptual and textual analysis as well as experimental investigations. Cognitive semiotics initially was developed at the Center for Semiotics at Aarhus University (Denmark), with an important connection with the Center of Functionally Integrated Neuroscience (CFIN) at Aarhus Hospital. Amongst the prominent cognitive semioticians are Per Aage Brandt, Svend Østergaard, Peer Bundgård, Frederik Stjernfelt, Mikkel Wallentin, Kristian Tylén, Riccardo Fusaroli, and Jordan Zlatev. Zlatev later in co-operation with Göran Sonesson established CCS (Center for Cognitive Semiotics) at Lund University, Sweden.

Syntactics is the Morris'ean branch of semiotics that deals with the formal properties of signs and symbols; the interrelation of the signs, without regard to meaning. Semantics deals with the relation of signs to their designata and the objects that they may or do denote; the relation between the signs and the objects to which they apply. Finally, pragmatics deals with the biotic aspects of semiosis, with all the psychological, biological, and sociological phenomena that occur in the functioning of signs; the relation between the sign system and its human (or animal) user. Unlike his mentor George Herbert Mead, Morris was a behaviorist and sympathetic to the Vienna Circle positivism of his colleague, Rudolf Carnap. Morris was accused by John Dewey of misreading Peirce.


The flexibility of human semiotics is well demonstrated in dreams. Sigmund Freud spelled out how meaning in dreams rests on a blend of images, affects, sounds, words, and kinesthetic sensations. In his chapter on "The Means of Representation" he showed how the most abstract sorts of meaning and logical relations can be represented by spatial relations. Two images in sequence may indicate "if this, then that" or "despite this, that". Freud thought the dream started with "dream thoughts" which were like logical, verbal sentences. He believed that the dream thought was in the nature of a taboo wish that would awaken the dreamer. In order to safeguard sleep, the mindbrain converts and disguises the verbal dream thought into an imagistic form, through processes he called the "dream-work".

Mark Blechner has proposed a model of dream semiotics that is virtually the opposite of Freud's. Mental meaning starts with images and other nonverbal representations in dreams. These images and other nonverbal signs are the "language of thought" or, more properly, the "substrate of thought" or "mentalese". These may be the underlying medium of signs through which the mindbrain thinks and solves problems. The waking mind may then convert the outcome of such image-thoughts into verbal-thoughts, through a process called the "waking-work" (the inverse of Freud's "dream-work").

Blechner's model would account for how evolutionarily earlier forms of humans and non-human mammals could think, dream, and solve problems without language. Waking thought then becomes a later development in which underlying thinking is transformed into communicable linguistic forms. It would also account for the way problem-solving can occur in dreams. William C. Dement conducted an experiment in which students were told of the infinite series that begins OTTFF. They were told to think about the series every night before going to sleep and to record their dreams.

Many people were misled to look for repeating pairs of letters or other abstract orderings. The series in fact is the first letter of the integers "one, two, three, four, five". Then next elements in the sequence are thus SSENT. Students reported dreams in which the problem was solved with images of enumeration such as, in Blechner's replication of the study, the hour hand of a clock moving sequentially and abruptly from six to seven up to 12. The mindbrain seemed to be solving the problem in and through the image; the task, upon waking, was to convert the semiotic representation of the solution back into words.

Freud and other psychoanalysts proposed dream symbols that are either analogous in shape to body parts (e.g., sword/penis) or associated metonymically with bodily processes, such as water being symbolic of pregnancy and childbirth. Such dream symbols, however, are subject to detailed modifications that signify major and precise shifts in meaning. For example, a woman dreamed she was riding on a motorcycle, and "things were falling out of her bag". While the bag is an expectable symbol of the womb or vagina, things falling out of her bag signified an abortion. Similarly, a woman dreamed of swimming in a "wave-pool" from which she could glimpse the sea but could not get to it. While swimming in a pool would symbolize birth, the artificial waves of the wave-pool signified the IVF (in-vitro fertilization) that she was undergoing. The sea signified natural pregnancy that was out of her reach.

Applications of semiotics include:

In some countries, its role is limited to literary criticism and an appreciation of audio and visual media. This narrow focus may inhibit a more general study of the social and political forces shaping how different media are used and their dynamic status within modern culture. Issues of technological determinism in the choice of media and the design of communication strategies assume new importance in this age of mass media.

Publication of research is both in dedicated journals such as "Sign Systems Studies", established by Yuri Lotman and published by Tartu University Press; "Semiotica", founded by Thomas A. Sebeok and published by Mouton de Gruyter; "Zeitschrift für Semiotik"; "European Journal of Semiotics"; "Versus" (founded and directed by Umberto Eco), et al.; "The American Journal of Semiotics"; and as articles accepted in periodicals of other disciplines, especially journals oriented toward philosophy and cultural criticism.

The major semiotic book series "Semiotics, Communication, Cognition", published by De Gruyter Mouton (series editors Paul Cobley and Kalevi Kull) replaces the former "Approaches to Semiotics" (more than 120 volumes) and "Approaches to Applied Semiotics" (series editor Thomas A. Sebeok). Since 1980 the Semiotic Society of America has produced an annual conference series: "".

Marketing is another application of semiotics. Epure, Eisenstat and Dinu (2014) said, "semiotics allows for the practical distinction of persuasion from manipulation in marketing communication" (p. 592). Semiotics are used in marketing as a persuasive device to influence buyers to change their attitudes and behaviors in the market place. Two ways that Epure, Eisenstat and Dinu (2014) state that semiotics are used are:
Semiotics analysis is used by scholars and professional researchers as a method to interpret meanings behind symbols and how the meanings are created. Below is an example of how semiotic analysis is utilized in a research paper published in an academic journal: Educational Research and Reviews.

Semiotics has sprouted subfields including, but not limited to, the following:

Pictorial semiotics is intimately connected to art history and theory. It goes beyond them both in at least one fundamental way, however. While art history has limited its visual analysis to a small number of pictures that qualify as "works of art", pictorial semiotics focuses on the properties of pictures in a general sense, and on how the artistic conventions of images can be interpreted through pictorial codes. Pictorial codes are the way in which viewers of pictorial representations seem automatically to decipher the artistic conventions of images by being unconsciously familiar with them.

According to Göran Sonesson, a Swedish semiotician, pictures can be analyzed by three models: (a) the narrative model, which concentrates on the relationship between pictures and time in a chronological manner as in a comic strip; (b) the rhetoric model, which compares pictures with different devices as in a metaphor; and (c) the laokoon (or laocoon) model, which considers the limits and constraints of pictorial expressions by comparing textual mediums that utilize time with visual mediums that utilize space.

Roman Jakobson showed that cubist art relies on metonyms, while surrealist art relies more on metaphors. A Picasso cubist painting of a guitar might show five parallel strings without the wood frame on which they are mounted; the strings are a metonym for the guitar. Magritte’s surrealist painting "The Memory" shows a sculpture of a woman’s head with blood on her temple, positioned next to a dead leaf and a bell. The iconography may be read, right to left, as “I have experienced a severe head injury or psychological trauma, which leads to my death, for which the bell tolls.” This follows the narrative model of picture semiotics. By contrast, Magritte’s painting "The Rape" shows a woman’s head, but the facial features are those of a woman’s midriff – breasts for eyes, navel for nose, and pubic hair for mouth. This image follows the rhetoric model, being a reversible metaphor of midriff–face.

The break from traditional art history and theory—as well as from other major streams of semiotic analysis—leaves open a wide variety of possibilities for pictorial semiotics. Some influences have been drawn from phenomenological analysis, cognitive psychology, structuralist, and cognitivist linguistics, and visual anthropology and sociology.

One of the many ways that pictorial semiotics has been changing has been through the use of emojis in email, text or other online conversations. Though not seen as works of art, these small images of happy, sad, winking faces or even a smiling poo image, have made their way into our everyday communication through digital devices. In the early advances of mobile technology and the increasing manner in which such devices are used, many in the linguistic community felt that vital communication cues, such as the importance of nonverbal cues, would be lost. Another concern is that with the high use of these symbols would begin to oversimplify our language to where the language's strength would be lost.

However, others have said that the use of emojis in digital conversation has helped to give more clarity to a conversation. Since the ability to read another person’s facial expressions, nonverbal cues or tone of voice isn’t possible in a typed message, emojis allow a communicator to convey attitudes and emotions to their message receiver. As for oversimplifying our language, some have argued that perhaps our language is not being simplified, but that new generations are revitalizing the early forms of semiotics like cave paintings or hieroglyphics. As technology advances, so will the use of emojis or possibly a more advanced form of pictorial symbols to use in digital communication.

Studies have shown that semiotics may be used to make or break a brand. Culture codes strongly influence whether a population likes or dislikes a brand's marketing, especially internationally. If the company is unaware of a culture's codes, it runs the risk of failing in its marketing. Globalization has caused the development of a global consumer culture where products have similar associations, whether positive or negative, across numerous markets.

Mistranslations may lead to instances of "Engrish" or "Chinglish", terms for unintentionally humorous cross-cultural slogans intended to be understood in English. This may be caused by a sign that, in Peirce's terms, mistakenly indexes or symbolizes something in one culture, that it does not in another. In other words, it creates a connotation that is culturally-bound, and that violates some culture code. Theorists who have studied humor (such as Schopenhauer) suggest that contradiction or incongruity creates absurdity and therefore, humor. Violating a culture code creates this construct of ridiculousness for the culture that owns the code. Intentional humor also may fail cross-culturally because jokes are not on code for the receiving culture.

A good example of branding according to cultural code is Disney's international theme park business. Disney fits well with Japan's cultural code because the Japanese value "cuteness", politeness, and gift giving as part of their culture code; Tokyo Disneyland sells the most souvenirs of any Disney theme park. In contrast, Disneyland Paris failed when it launched as Euro Disney because the company did not research the codes underlying European culture. Its storybook retelling of European folktales was taken as elitist and insulting, and the strict appearance standards that it had for employees resulted in discrimination lawsuits in France. Disney souvenirs were perceived as cheap trinkets. The park was a financial failure because its code violated the expectations of European culture in ways that were offensive.

On the other hand, some researchers have suggested that it is possible to successfully pass a sign perceived as a cultural icon, such as the Coca-Cola or McDonald's logos, from one culture to another. This may be accomplished if the sign is migrated from a more economically-developed to a less developed culture. The intentional association of a product with another culture has been called Foreign Consumer Culture Positioning (FCCP). Products also may be marketed using global trends or culture codes, for example, saving time in a busy world; but even these may be fine-tuned for specific cultures.

Research also found that, as airline industry brandings grow and become more international, their logos become more symbolic and less iconic. The iconicity and symbolism of a sign depends on the cultural convention and, are on that ground in relation with each other. If the cultural convention has greater influence on the sign, the signs get more symbolic value.

Graffiti is used by gang members to mark their territory and to warn off rivals. Graffiti is a great example of semiotics and the use of symbols. Police task forces are now starting to use a programming system called GARI, they upload pictures of gang symbols that they find and it helps them to decipher the meaning of the symbols. Gang members use semiotics and symbols for many different reasons, for example: Government-sanctioned graffiti from the city's Department of Public Works, in red, typically indicates an abandoned building, or the stylized SS stands for South Side, a faction of the 18th Street gang based in southern Indianapolis. A rival gang sprayed red Xs over the work as a sign of disrespect.

In the book "The Lost Boyz: A Dark Side of Graffiti" by Justin Rollins it talks about how Rollins started writing on trains at a very early age, because it helped him find himself, he was now a graffiti writer – a somebody. This is true with a lot of symbols. People use symbols to express themselves by getting tattoos or wearing a symbol on their clothing. This helps them to feel like they belong to something or it helps them to express themselves. Gangs also use their clothing as a symbol, they do something unique for their group so that you aware of the gang you are encountering. An example could be a certain pant leg rolled up or wearing a certain color of bandana. The book also talks about how Rollins joined a graffiti gang that was called the WK which stands for Who Kares but it also had a different meaning which was Wanted Kriminals. Many symbols in semiotics theory have different meanings; these meanings can be different from country to country or even just from person to person depending on where and how a person was raised. For example, in the United States, waving is a form of "hello" but in other cultures this could mean something offensive.

Semiotics is anything that can stand for something else. A symbol does not stand on its own, it is a part of something, a system perhaps. Symbols in gangs are used for different things. Not just to show which gang a person is associated with but to express what has happened in their gang and in their individual lives. Gangs were first created to strengthen a certain ethnic group. They are very territorial. To show which territory is theirs they will mark the streets so that other gangs are aware. There are special ways to read gang signs and their tattoos: left to right, top to bottom. They may also make the tattoo or graffiti cluttered so that it is hard to read.

Each gang has special hand signals or set of signs to identify themselves. There are some gangs who add a dot or something similar to their graffiti to stand as a phrase used in their specific gang. Each gang is unique and has special symbols, and these symbols usually have some sort of meaning. For example, the gang called "Bloods" use the color red in their clothing to symbolize they are a part of this specific gang. They also are known to use the number 5 and have tattoos and graffiti of a five-point crown. The hand sign that they use mostly is a "b" which stands for bloods.

Some gangs use graffiti and tattoos more than others as well as using their clothing as a symbol of their gang. Gangs will also use codes to communicate on the streets. They will oftentimes use a number that will relate to a letter of the alphabet. Depending on the gang, they may use more complex codes.

Street gangs are known for using graffiti in their neighborhoods to mark their territory. Gangs are also using their graffiti to challenge other gangs and to disrespect them. When they do this, they will somehow cross the other gang's symbol, and they will use their gang slang as well. They make sure to do it in a place that is clear and will leave a direct hit on the other gang.

Semiotics and gang graffiti merge on the undercarriage of bridges, the face of billboards, on abandoned buildings, storefronts, the sides of railroad cars, and even in inconspicuous places found along dirt roads in small rural areas. The idea, is to communicate a message. A message that is part of a system.

It is not uncommon for those outside the culture of gangs to judge the meaning of graffiti and its direct connection to semiotics as completely negative. This kind of graffiti was branded "Graffiti of Grief" in an article by Gabrielle Luber. They are a commemoration of mourning; a "funeral" for those who have died on the streets. The murals are often created by
members designated within the gang and the artwork is intended "provide glimpses of their lives, possessions, friends, and surroundings, and map out for us the identities of lost friends." The symbols used in these murals are intentional and communicate significant meanings within the developed culture. It is an art, an expression of respect and loyalty. It is a portable headstone and is often layered (painted over) with the next memorial of death caused by street violence. In its own right, it is a historical timeline, a genealogy of grief, and it is rewritten every day with the same story and a new name. Poverty, marginalism, survival, perpetual crisis, inadequate housing, low or no job skills, poor education, and social constraints and constructs will continue to market for the consumption of lives on the streets. The symbol of grief portrayed in certain kinds of graffiti suggest a depth of meaning and a place or memorial far beyond what the eye can see. To an outsider, it may easily be interpreted without compassion.

A world organisation of semioticians, the International Association for Semiotic Studies, and its journal "Semiotica", was established in 1969. The larger research centers together with teaching program include the semiotics departments at the University of Tartu, Aarhus University, and Bologna University.

The discipline is mentioned in an episode of The Big Bang Theory called The Hamburger Postulate.




</doc>
<doc id="29305" url="https://en.wikipedia.org/wiki?curid=29305" title="Sojourner Truth">
Sojourner Truth

Sojourner Truth (; born Isabella (Belle) Baumfree; – November 26, 1883) was an African-American abolitionist and women's rights activist. Truth was born into slavery in Swartekill, Ulster County, New York, but escaped with her infant daughter to freedom in 1826. After going to court to recover her son, in 1828 she became the first black woman to win such a case against a white man.

She gave herself the name Sojourner Truth in 1843 after she became convinced that God had called her to leave the city and go into the countryside "testifying the hope that was in her". Her best-known speech was delivered extemporaneously, in 1851, at the Ohio Women's Rights Convention in Akron, Ohio. The speech became widely known during the Civil War by the title "Ain't I a Woman?," a variation of the original speech re-written by someone else using a stereotypical Southern dialect; whereas Sojourner Truth was from New York and grew up speaking Dutch as her first language. During the Civil War, Truth helped recruit black troops for the Union Army; after the war, she tried unsuccessfully to secure land grants from the federal government for former slaves.

In 2014, Truth was included in "Smithsonian" magazine's list of the "100 Most Significant Americans of All Time".

Truth was one of the ten or twelve children born to James and Elizabeth Baumfree (or Bomefree). Colonel Hardenbergh bought James and Elizabeth Baumfree from slave traders and kept their family at his estate in a big hilly area called by the Dutch name Swartekill (just north of present-day Rifton), in the town of Esopus, New York, north of New York City. Charles Hardenbergh inherited his father's estate and continued to enslave people as a part of that estate's property.

When Charles Hardenbergh died in 1806, nine-year-old Truth (known as Belle), was sold at an auction with a flock of sheep for $100 to John Neely, near Kingston, New York. Until that time, Truth spoke only Dutch. She later described Neely as cruel and harsh, relating how he beat her daily and once even with a bundle of rods. Neely sold her in 1808, for $105, to Martinus Schryver of Port Ewen, a tavern keeper, who owned her for eighteen months. Schryver sold her in 1810 to John Dumont of West Park, New York. Although this fourth owner was kindly disposed toward her, considerable tension existed between Truth and Dumont's second wife, Elizabeth Waring Dumont, who harassed her and made her life more difficult. (John Dumont's first wife, Sarah "Sally" Waring Dumont (Elizabeth's sister), died around 1805, five years before he bought Truth.)

Around 1815, Truth met and fell in love with a slave named Robert from a neighboring farm. Robert's owner (Charles Catton, Jr., a landscape painter) forbade their relationship; he did not want the people he enslaved to have children with people he was not enslaving, because he would not own the children. One day Robert snuck over to see Truth. When Catton and his son found him, they savagely beat Robert until Dumont finally intervened, and Truth never saw Robert again. He died some years later, perhaps as a result of the injuries, and the experience haunted Truth throughout her life. Truth eventually married an older slave named Thomas. She bore five children: James, her firstborn, who died in childhood, Diana (1815), fathered by either Robert or John Dumont, and Peter (1821), Elizabeth (1825), and Sophia (ca. 1826), all born after she and Thomas united.

The state of New York began, in 1799, to legislate the abolition of slavery, although the process of emancipating those people enslaved in New York was not complete until July 4, 1827. Dumont had promised to grant Truth her freedom a year before the state emancipation, "if she would do well and be faithful." However, he changed his mind, claiming a hand injury had made her less productive. She was infuriated but continued working, spinning 100 pounds of wool, to satisfy her sense of obligation to him.

Late in 1826, Truth escaped to freedom with her infant daughter, Sophia. She had to leave her other children behind because they were not legally freed in the emancipation order until they had served as bound servants into their twenties. She later said "I did not run off, for I thought that wicked, but I walked off, believing that to be all right."

She found her way to the home of Isaac and Maria Van Wagenen in New Paltz, who took her and her baby in. Isaac offered to buy her services for the remainder of the year (until the state's emancipation took effect), which Dumont accepted for $20. She lived there until the New York State Emancipation Act was approved a year later.

Truth learned that her son Peter, then five years old, had been sold illegally by Dumont to an owner in Alabama. With the help of the Van Wagenens, she took the issue to court and in 1828, after months of legal proceedings, she got back her son, who had been abused by those who were enslaving him. Truth became one of the first black women to go to court against a white man and win the case.

Truth had a life-changing religious experience during her stay with the Van Wagenens, and became a devout Christian. In 1829 she moved with her son Peter to New York City, where she worked as a housekeeper for Elijah Pierson, a Christian Evangelist. While in New York, she befriended Mary Simpson, a grocer on John Street who claimed she had once been enslaved by George Washington. They shared an interest in charity for the poor and became intimate friends. In 1832, she met Robert Matthews, also known as Prophet Matthias, and went to work for him as a housekeeper at the Matthias Kingdom communal colony. Elijah Pierson died, and Robert Matthews and Truth were accused of stealing from and poisoning him. Both were acquitted of the murder, though Matthews was convicted of lesser crimes, served time, and moved west.

In 1839, Truth's son Peter took a job on a whaling ship called the "Zone of Nantucket". From 1840 to 1841, she received three letters from him, though in his third letter he told her he had sent five. Peter said he also never received any of her letters. When the ship returned to port in 1842, Peter was not on board and Truth never heard from him again.

1843 was a turning point for Truth. She became a Methodist, and on June 1, she changed her name to "Sojourner Truth." She told friends: "The Spirit calls me, and I must go" and left to make her way traveling and preaching about the abolition of slavery. At that time, Truth began attending Millerite Adventist campmeetings. However, that did not last since Jesus failed to appear in 1843 and then again in 1844. Like many others disappointed, Truth distanced herself from her Millerite friends for a while.

In 1844, she joined the Northampton Association of Education and Industry in Northampton, Massachusetts. Founded by abolitionists, the organization supported women's rights and religious tolerance as well as pacifism. There were, in its four-and-a-half year history, a total of 240 members, though no more than 120 at any one time. They lived on , raising livestock, running a sawmill, a gristmill, and a silk factory. While there, Truth met William Lloyd Garrison, Frederick Douglass, and David Ruggles. In 1846, the group disbanded, unable to support itself. In 1845, she joined the household of George Benson, the brother-in-law of William Lloyd Garrison. In 1849, she visited John Dumont before he moved west.

Truth started dictating her memoirs to her friend Olive Gilbert, and in 1850 William Lloyd Garrison privately published her book, "The Narrative of Sojourner Truth: A Northern Slave". That same year, she purchased a home in what would become the village of Florence in Northampton for $300, and spoke at the first National Women's Rights Convention in Worcester, Massachusetts. In 1854, with proceeds from sales of the Narrative and cartes-de-visite entitled "I sell the shadow to support the substance," she paid off the mortgage held by her friend from the Community, Samuel L. Hill.

In 1851, Truth joined George Thompson, an abolitionist and speaker, on a lecture tour through central and western New York State. In May, she attended the Ohio Women's Rights Convention in Akron, Ohio, where she delivered her famous extemporaneous speech on women's rights, later known as "Ain't I a Woman." Her speech demanded equal human rights for all women as well as for all blacks. Advocating for women and African Americans was dangerous and challenging enough, but being one and doing so was far more difficult. The pressures and severity of her speech did not get to Truth, however. Truth took to the stage with a demanding and composed presence. Audience members were baffled by the way she carried herself and were hesitant to believe that she was even a woman, prompting the name of her speech "Ain't I a Woman?" The convention was organized by Hannah Tracy and Frances Dana Barker Gage, who both were present when Truth spoke. Different versions of Truth's words have been recorded, with the first one published a month later in the "Anti-Slavery Bugle" by Rev. Marius Robinson, the newspaper owner and editor who was in the audience. Robinson's recounting of the speech included no instance of the question "Ain't I a Woman?" Nor did any of the other newspapers reporting of her speech at the time. Twelve years later, in May 1863, Gage published another, very different, version. In it, Truth's speech pattern had characteristics of Southern slaves, and the speech was vastly different than the one Robinson had reported. Gage's version of the speech became the historic standard version, and is known as "Ain't I a Woman?" because that question was repeated four times. It is highly unlikely that Truth's own speech pattern was Southern in nature, as she was born and raised in New York, and she spoke only upper New York State low-Dutch until she was nine years old.

In contrast to Robinson's report, Gage's 1863 version included Truth saying her 13 children were sold away from her into slavery. Truth is widely believed to have had five children, with one sold away, and was never known to boast more children. Gage's 1863 recollection of the convention conflicts with her own report directly after the convention: Gage wrote in 1851 that Akron in general and the press in particular were largely friendly to the woman's rights convention, but in 1863 she wrote that the convention leaders were fearful of the "mobbish" opponents. Other eyewitness reports of Truth's speech told a calm story, one where all faces were "beaming with joyous gladness" at the session where Truth spoke; that not "one discordant note" interrupted the harmony of the proceedings. In contemporary reports, Truth was warmly received by the convention-goers, the majority of whom were long-standing abolitionists, friendly to progressive ideas of race and civil rights. In Gage's 1863 version, Truth was met with hisses, with voices calling to prevent her from speaking.

According to Frances Gage's recount in 1863, Truth argued, "That man over there says that women need to be helped into carriages, and lifted over ditches, and to have the best place everywhere. Nobody helps "me" any best place. "And ain't I a woman?"" Truth's " Ain't I a Woman" showed the lack of recognition that Black women received during this time and whose lack of recognition will continue to be seen long after her time. " Black women, of course, were virtually invisible within the protracted campaign for woman suffrage" as said by Davis supports Truth's argument that nobody gives her " any best place" but not only her but Black women in general. 

Over the next 10 years, Truth spoke before dozens, perhaps hundreds, of audiences. From 1851 to 1853, Truth worked with Marius Robinson, the editor of the Ohio "Anti-Slavery Bugle", and traveled around that state speaking. In 1853, she spoke at a suffragist "mob convention" at the Broadway Tabernacle in New York City; that year she also met Harriet Beecher Stowe. In 1856, she traveled to Battle Creek, Michigan, to speak to a group called the "Friends of Human Progress." In 1858, someone interrupted a speech and accused her of being a man; Truth opened her blouse and revealed her breasts."

Northampton Camp Meeting—-1844, Northampton, Massachusetts: At a camp meeting where she was participating as an itinerant preacher, a band of “wild young men” disrupted the camp meeting, refused to leave, and threatened to burn down the tents. Truth caught the sense of fear pervading the worshipers and hid behind a trunk in her tent, thinking that since she was the only black person present, the mob would attack her first. However, she reasoned with herself and resolved to do something: as the noise of the mob increased and a female preacher was “trembling on the preachers’ stand,” Truth went to a small hill and began to sing “in her most fervid manner, with all the strength of her most powerful voice, the hymn on the resurrection of Christ." Her song, “It was Early in the Morning,” gathered the rioters to her and quieted them. They urged her to sing, preach, and pray for their entertainment. After singing songs and preaching for about an hour, Truth bargained with them to leave after one final song. The mob agreed and left the camp meeting.

Abolitionist Convention—-1840s, Boston, Massachusetts: William Lloyd Garrison invited Sojourner Truth to give a speech at an annual antislavery convention. Wendell Phillips was supposed to speak after her, which made her nervous since he was known as such a good orator. So Truth sang a song, "I am Pleading for My people," which was her own original composition sung to the tune of Auld Lang Syne.

Mob Convention—September 7, 1853: At the convention, young men greeted her with "a perfect storm,” hissing and groaning. In response, Truth said, "You may hiss as much as you please, but women will get their rights anyway. You can't stop us, neither". Sojourner, like other public speakers, often adapted her speeches to how the audience was responding to her. In her speech, Sojourner speaks out for women's rights. She incorporates religious references in her speech, particularly the story of Esther. She then goes on to say that, just as women in scripture, women today are fighting for their rights. Moreover, Sojourner scolds the crowd for all their hissing and rude behavior, reminding them that God says to "Honor thy father and thy mother."

American Equal Rights Association—May 9–10, 1867: Her speech was addressed to the American Equal Rights Association, and divided into three sessions. Sojourner was received with loud cheers instead of hisses, now that she had a better-formed reputation established. "The Call" had advertised her name as one of the main convention speakers. For the first part of her speech, she spoke mainly about the rights of black women. Sojourner argued that because the push for equal rights had led to black men winning new rights, now was the best time to give black women the rights they deserve too. Throughout her speech she kept stressing that "we should keep things going while things are stirring" and fears that once the fight for colored rights settles down, it would take a long time to warm people back up to the idea of colored women's having equal rights.

In the second sessions of Sojourner's speech, she utilized a story from the Bible to help strengthen her argument for equal rights for women. She ended her argument by accusing men of being self-centered, saying, "man is so selfish that he has got women's rights and his own too, and yet he won't give women their rights. He keeps them all to himself." For the final session of Sojourner's speech, the center of her attention was mainly on women's right to vote. Sojourner told her audience that she owned her own house, as did other women, and must therefore pay taxes. Nevertheless, they were still unable to vote because they were women. Black women who were enslaved were made to do hard manual work, such as building roads. Sojourner argues that if these women were able to perform such tasks, then they should be allowed to vote because surely voting is easier than building roads.

Eighth Anniversary of Negro Freedom—New Year's Day, 1871: On this occasion the Boston papers related that “...seldom is there an occasion of more attraction or greater general interest. Every available space of sitting and standing room was crowded". She starts off her speech by giving a little background about her own life. Sojourner recounts how her mother told her to pray to God that she may have good masters and mistresses. She goes on to retell how her masters were not good to her, about how she was whipped for not understanding English, and how she would question God why he had not made her masters be good to her. Sojourner admits to the audience that she had once hated white people, but she says once she met her final master, Jesus, she was filled with love for everyone. Once enslaved folks were emancipated, she tells the crowd she knew her prayers had been answered.
That last part of Sojourner's speech brings in her main focus. Some freed enslaved people were living on government aid at that time, paid for by taxpayers. Sojourner announces that this is not any better for those colored people than it is for the members of her audience. She then proposes that black people are given their own land. Because a portion of the South's population contained rebels that were unhappy with the abolishment of slavery, that region of the United States was not well suited for colored people. She goes on to suggest that colored people be given land out west to build homes and prosper on.

Second Annual Convention of the American Woman Suffrage Association—Boston, 1871: In a brief speech, Truth argued that women's rights were essential, not only to their own well-being, but "for the benefit of the whole creation, not only the women, but all the men on the face of the earth, for they were the mother of them."

In 1856, Truth bought a neighboring lot in Northampton, but she did not keep the new property for long. On September 3, 1857, she sold all her possessions, new and old, to Daniel Ives and moved to Battle Creek, Michigan, where she rejoined former members of the Millerite Movement who had formed the Seventh-day Adventist Church. Antislavery movements had begun early in Michigan and Ohio. Here, she also joined the nucleus of the Michigan abolitionists, the Progressive Friends, some who she had already met at national conventions. According to the 1860 census, her household in Harmonia included her daughter, Elizabeth Banks (age 35), and her grandsons James Caldwell (misspelled as "Colvin"; age 16) and Sammy Banks (age 8).

During the Civil War, Truth helped recruit black troops for the Union Army. Her grandson, James Caldwell, enlisted in the 54th Massachusetts Regiment. In 1864, Truth was employed by the National Freedman's Relief Association in Washington, D.C., where she worked diligently to improve conditions for African-Americans. In October of that year, she met President Abraham Lincoln. In 1865, while working at the Freedman's Hospital in Washington, Truth rode in the streetcars to help force their desegregation.

Truth is credited with writing a song, "", for the 1st Michigan Colored Regiment; it was said to be composed during the war and sung by her in Detroit and Washington, D.C. It is sung to the tune of "John Brown's Body" or "The Battle Hymn of the Republic". Although Truth claimed to have written the words, it has been disputed (see "Marching Song of the First Arkansas").

In 1867, Truth moved from Harmonia to Battle Creek. In 1868, she traveled to western New York and visited with Amy Post, and continued traveling all over the East Coast. At a speaking engagement in Florence, Massachusetts, after she had just returned from a very tiring trip, when Truth was called upon to speak she stood up and said "Children, I have come here like the rest of you, to hear what I have to say."

In 1870, Truth tried to secure land grants from the federal government to former enslaved people, a project she pursued for seven years without success. While in Washington, D.C., she had a meeting with President Ulysses S. Grant in the White House. In 1872, she returned to Battle Creek, became active in Grant's presidential re-election campaign, and even and tried to vote on Election Day, but was turned away at the polling place.

Truth spoke about abolition, women's rights, prison reform, and preached to the Michigan Legislature against capital punishment. Not everyone welcomed her preaching and lectures, but she had many friends and staunch support among many influential people at the time, including Amy Post, Parker Pillsbury, Frances Gage, Wendell Phillips, William Lloyd Garrison, Laura Smith Haviland, Lucretia Mott, Ellen G. White, and Susan B. Anthony."

Several days before Sojourner Truth died, a reporter came from the "Grand Rapids Eagle" to interview her. "Her face was drawn and emaciated and she was apparently suffering great pain. Her eyes were very bright and mind alert although it was difficult for her to talk." Truth died at her Battle Creek home on November 26, 1883. On November 28 her funeral was held at the Congregational-Presbyterian Church officiated by its pastor, the Reverend Reed Stuart. Some of the prominent citizens of Battle Creek acted as pall-bearers. Truth was buried in the city's Oak Hill Cemetery.

The calendar of saints of the Episcopal Church remembers Sojourner Truth annually, together with Elizabeth Cady Stanton, Amelia Bloomer and Harriet Ross Tubman on July 20. The calendar of saints of the Lutheran Church remembers Sojourner Truth together with Harriet Tubman on March 10.

A larger-than-life sculpture of Sojourner Truth by artist Tina Allen, was dedicated in 1999, which is the estimated bicentennial of Sojourner's birth. The 12-foot tall Sojourner monument is cast bronze.

The U.S. Treasury Department announced in 2016 that an image of Sojourner Truth will appear on the back of a newly designed $10 bill along with Lucretia Mott, Susan B. Anthony, Elizabeth Cady Stanton, Alice Paul and the 1913 Woman Suffrage Procession. Designs for new $5, $10 and $20 bills will be unveiled in 2020 in conjunction with the 100th anniversary of American women winning the right to vote via the Nineteenth Amendment to the United States Constitution. 


Other honors and commemorations include (by year):

As of March 2015, K-12 schools in several states, including California, Minnesota, New Jersey, New York and Oregon, are named after her, as is Sojourner–Douglass College in Baltimore.






</doc>
<doc id="29306" url="https://en.wikipedia.org/wiki?curid=29306" title="STOVL">
STOVL

A short take-off and vertical landing aircraft (STOVL aircraft) is a fixed-wing aircraft that is able to take off from a short runway (or take off vertically if it does not have a heavy payload) and land vertically (i.e. with no runway). The formal NATO definition (since 1991) is:

On aircraft carriers, non-catapult-assisted, fixed-wing short takeoffs are accomplished with the use of thrust vectoring, which may also be used in conjunction with a runway "ski-jump". Use of STOVL tends to allow aircraft to carry a larger payload as compared to during VTOL use, while still only requiring a short runway. The most famous examples are the Hawker Siddeley Harrier and the Sea Harrier. Although technically VTOL aircraft, they are operationally STOVL aircraft due to the extra weight carried at take-off for fuel and armaments. The same is true of the F-35B Lightning II, which demonstrated VTOL capability in test flights but is operationally STOVL.

In 1951, the Lockheed XFV and the Convair XFY Pogo tailsitters were both designed around the Allison YT40 turboprop engine driving contra-rotating propellers.

The British Hawker P.1127 took off vertically in 1960, and demonstrated conventional take-off in 1961. It was developed into the Hawker Siddeley Harrier which flew in 1967.

In 1962, Lockheed built the XV-4 Hummingbird for the U.S. Army. It sought to "augment" available thrust by injecting the engine exhaust into an ejector pump in the fuselage. First flying vertically in 1963, it suffered a fatal crash in 1964. It was converted into the XV-4B Hummingbird for the U.S. Air Force as a testbed for separate, vertically mounted lift engines, similar to those used in the Yak-38 Forger. That plane flew and later crashed in 1969. The Ryan XV-5 Vertifan, which was also built for the U.S. Army at the same time as the Hummingbird, experimented with gas-driven lift fans. That plane used fans in the nose and each wing, covered by doors which resembled half garbage can lids when raised. However, it crashed twice, and proved to generate a disappointing amount of lift, and was difficult to transition to horizontal flight.

Of dozens of VTOL and V/STOL designs tried from the 1950s to 1980s, only the subsonic Hawker Siddeley Harrier and Yak-38 Forger reached operational status, with the Forger being withdrawn after the fall of the Soviet Union.

Rockwell International built, and then abandoned, the Rockwell XFV-12 supersonic fighter which had an unusual wing which opened up like window blinds to create an ejector pump for vertical flight. It never generated enough lift to get off the ground despite developing 20,000 lbf of thrust. The French had a nominally Mach 2 Dassault Mirage IIIV fitted with no less than 8 lift engines that flew (and crashed), but did not have enough space for fuel or payload for combat missions. The German EWR VJ 101 used swiveling engines mounted on the wingtips with fuselage mounted lift engines, and the VJ 101C X1 reached supersonic flight (Mach 1.08) on 29 July 1964. The supersonic Hawker Siddeley P.1154, which competed with the Mirage IIIV for use in NATO, was cancelled even as the aircraft were being built.

NASA uses the abbreviation SSTOVL for Supersonic Short Take-Off / Vertical Landing, and as of 2012, the X-35B/F-35B are the only aircraft to conform with this combination within one flight.

The experimental Mach 1.7 Yakovlev Yak-141 did not find an operational customer, but similar rotating rear nozzle technology is used on the F-35B. The F-35B Lightning II entered service on July 31, 2015.

Larger STOVL designs were considered, the Armstrong Whitworth AW.681 cargo aircraft was under development when cancelled in 1965. The Dornier Do 31 got as far as three experimental aircraft before cancellation in 1970.

Although mostly a VTOL design, the V-22 Osprey has increased payload when taking off from a short runway.


</doc>
<doc id="29307" url="https://en.wikipedia.org/wiki?curid=29307" title="Russian aircraft carrier Admiral Kuznetsov">
Russian aircraft carrier Admiral Kuznetsov

Admiral Flota Sovetskogo Soyuza Kuznetsov ( "Admiral of the Fleet of the Soviet Union Kuznetsov") is an aircraft carrier (heavy aircraft-carrying missile cruiser, or TAVKR, in Russian classification) serving as the flagship of the Russian Navy. She was built by the Black Sea Shipyard, the sole manufacturer of Soviet aircraft carriers, in Nikolayev within the Ukrainian Soviet Socialist Republic (SSR). The initial name of the ship was Riga; she was launched as Leonid Brezhnev, embarked on sea trials as Tbilisi, and finally named "Admiral Flota Sovetskogo Soyuza Kuznetsov" after Admiral of the fleet of the Soviet Union Nikolay Gerasimovich Kuznetsov.

She was originally commissioned in the Soviet Navy, and was intended to be the lead ship of her class. However, her sister ship "Varyag" had neither been completed nor been commissioned when the Soviet Union collapsed in 1991. The second hull was eventually sold by Ukraine to the People's Republic of China, completed in Dalian and commissioned as "Liaoning".

The design of "Admiral Kuznetsov"-class implies a mission different from that of the United States Navy's carriers. The term used by her builders to describe the Russian ships is (TAVKR) – "heavy aircraft-carrying cruiser" – intended to support and defend strategic missile-carrying submarines, surface ships, and naval missile-carrying aircraft of the Russian Navy.

"Admiral Kuznetsov"'s main fixed-wing aircraft is the multi-role Sukhoi Su-33. It can perform air superiority, fleet defence, and air support missions and can also be used for direct fire support of amphibious assault, reconnaissance and placement of naval mines. The carrier also carries the Kamov Ka-27 and Kamov Ka-27S helicopters for anti-submarine warfare, search and rescue, and small transport.

For take-off of fixed wing aircraft, "Admiral Kuznetsov" uses a ski-jump at the end of her bow. On take-off aircraft accelerate toward and up the ski-jump using their afterburners. This results in the aircraft leaving the deck at a higher angle and elevation than on an aircraft carrier with a flat deck and catapults. The ski-jump take-off is less demanding on the pilot, since the acceleration is lower, but results in a clearance speed of only 120–140 km/h (75–85 mph) requiring an aircraft design which will not stall at those speeds. The "cruiser" role is facilitated by "Admiral Kuznetsov"'s complement of 12 long-range surface-to-surface anti-ship P-700 Granit (NATO reporting name: Shipwreck) cruise missiles. As a result, this armament is the basis for the ship's Russian type designator of "heavy aircraft-carrying missile cruiser".

"Admiral Kuznetsov"s designation as an aircraft cruiser is very important under international law, as it allows the ship to transit the Turkish Straits. The Montreux Convention prohibits Russia from sending an aircraft carrier heavier than 15,000 tons through the Straits. Since the ship was built in the Ukrainian SSR, "Admiral Kuznetsov" would have been stuck in the Black Sea if Turkey had refused permission to pass into the Mediterranean Sea. The Convention does not limit the displacement of capital ships operated by Black Sea powers. Turkey has always allowed "Admiral Kuznetsov" to transit the Straits, and no other signatory to the Montreux Convention has ever issued a formal protest of her classification as an aircraft cruiser.

"Admiral Flota Sovetskovo Soyuza Kuznetsov", constructed at Chernomorskiy Shipyard, also known as Nikolayev South Shipyard, in Nikolayev, now Mykolaiv, Ukrainian SSR, was launched in 1985, and became fully operational in 1995. An official ceremony marking the start of construction took place on 1 September 1982; in fact she was laid down in 1983. The vessel was first named "Riga", then the name was changed to "Leonid Brezhnev", this was followed by "Tbilisi". Finally, on 4 October 1990, she was renamed "Admiral Flota Sovetskovo Soyuza Kuznetsov", referred to in short as "Admiral Kuznetsov". The ship was 71% complete by mid-1989. In November 1989 she undertook her first aircraft operation trials. In December 1991, she sailed from the Black Sea to join the Northern Fleet. Only from 1993 on did she receive aircraft.

From 23 December 1995 through 22 March 1996 "Admiral Kuznetsov" made her first 90-day Mediterranean deployment with 13 Su-33, 2 Su-25 UTG, and 11 helicopters aboard. The deployment was to allow the carrier, which was accompanied by a frigate, destroyer and oiler, to adapt to the Mediterranean climate and to perform continuous flight operations until 21:00 each day, as the Barents Sea only receives about one hour of sunlight during this time of year. This cruise marked the 300th anniversary of the Russian Navy celebrated in 1996. During that period the carrier lay at anchor off the port of Tartus, Syria. Her aircraft often made flights close to the Israeli shore line and were escorted by Israeli F-16s. During the deployment, a severe water shortage occurred due to evaporators breaking down.

At the end of 1997 she remained immobilized in a Northern Fleet shipyard, awaiting funding for major repairs, which were halted when they were only 20% complete. The overhaul was completed in July 1998, and the ship returned to active service in the Northern fleet on 3 November 1998.

"Admiral Kuznetsov" remained in port for two years before preparing for another Mediterranean deployment scheduled for the winter of 2000–2001. This deployment was cancelled due to the explosion and sinking of the nuclear-powered submarine "Kursk". "Admiral Kuznetsov" participated in the "Kursk" rescue and salvage operations in late 2000. Plans for further operations were postponed or cancelled. In late 2003 and early 2004, "Admiral Kuznetsov" went to sea for inspection and trials. In October 2004, she participated in a fleet exercise of the Russian Navy in the Atlantic Ocean. During a September 2005 exercise, an Su-33 accidentally fell from the carrier into the Atlantic Ocean. On 27 September 2006, it was announced that "Admiral Kuznetsov" would return to service in the Northern Fleet by the year's end, following another modernization to correct some technical issues. Admiral Vladimir Masorin, Commander-in-Chief of the Russian Navy, also stated that Su-33 fighters assigned to her would return after undergoing their own maintenance and refits.

From 5 December 2007 through 3 February 2008 "Admiral Kuznetsov" made its second Mediterranean deployment. On 11 December 2007, "Admiral Kuznetsov" passed by Norwegian oil platforms in the North Sea, outside Bergen, Norway. Su-33 fighters and Kamov helicopters were launched from "Admiral Kuznetsov" while within international waters; Norwegian helicopter services to the rigs were halted due to the collision risk with the Russian aircraft. "Admiral Kuznetsov" later participated in an exercise on the Mediterranean Sea, together with 11 other Russian surface ships and 47 aircraft, performing three tactical training missions using live and simulated air and surface missile launches. "Admiral Kuznetsov" and her escorts returned to Severomorsk on 3 February 2008. Following maintenance, she returned to sea on 11 October 2008 for the Stability-2008 strategic exercises held in the Barents Sea. On 12 October 2008, Russian President Dmitry Medvedev visited the ship during the exercise.

From 5 December 2008 through 2 March 2009, "Admiral Kuznetsov" made her third Mediterranean deployment. On 5 December 2008, she and several other vessels left Severomorsk for the Atlantic for a combat training tour, including joint drills with Russia's Black Sea Fleet and visits to several Mediterranean ports. On 7 January 2009, a small fire broke out onboard "Admiral Kuznetsov" while anchored off Turkey. The fire, caused by a short-circuit, led to the death of one crew member by carbon monoxide poisoning. On 16 February 2009, she was involved in a large oil spill, along with other Russian naval vessels, while refuelling off the south coast of Ireland. On 2 March 2009, "Admiral Kuznetsov" returned to Severomorsk, and on September 2010 she left dry dock after scheduled repairs and preparations for a training mission in the Barents Sea, later that month.

The Russian Main Navy Staff announced that "Admiral Kuznetsov" would begin a deployment to the Atlantic and Mediterranean in December 2011. In November 2011, it was announced that "Admiral Kuznetsov" would lead a squadron to Russia's naval facility in Tartus.

A Russian naval spokesman announced via the Izvestia daily that "The call of the Russian ships in Tartus should not be seen as a gesture towards what is going on in Syria... This was planned already in 2010 when there were no such events there" noting that "Admiral Kuznetsov" would also be making port calls in Beirut, Genoa and Cyprus. On 29 November 2011, Army General Nikolay Makarov, Chief of the Russian General Staff, said that Russian ships in the Mediterranean were due to exercises rather than events in Syria, and noted that "Admiral Kuznetsov"s size does not allow it to moor in Tartus.
On 6 December 2011, "Admiral Kuznetsov" and her escort ships departed the Northern Fleet homebase for a Mediterranean deployment to exercise with ships from the Russian Baltic and Black Sea Fleets. On 12 December 2011 "Admiral Kuznetsov" and her escorts, were spotted northeast of Orkney off the coast of northern Scotland, the first such time she had deployed near the UK. shadowed the group for a week; due to severe weather, the group took shelter in international waters in the Moray Firth, some 30 miles from the UK coast. "Admiral Kuznetsov" then sailed around the top of Scotland and into the Atlantic past western Ireland, where she conducted flight operations with her Sukhoi Su-33 'Flanker' jets and Kamov Ka-27 helicopters in international airspace. On 8 January 2012, "Admiral Kuznetsov" anchored near shore outside Tartus while other ships from her escort entered the port to use the leased Russian naval support facility to replenish their supplies, after which all ships continued their deployment on 9 January. On 17 February 2012, "Admiral Kuznetsov" returned to her homebase of Severomorsk.

On 1 June 2013, it was announced that the ship would return to the Mediterranean by the end of the year, and on 17 December, "Admiral Kuznetsov" departed her homebase for the Mediterranean.
On 1 January 2014, "Admiral Kuznetsov" celebrated New Year's Day while at anchor in international waters of the Moray Firth off northeast Scotland. The anchorage allowed replenishment of ship's supplies and respite for the crew from stormy weather off the southwest coast of Norway. She then proceeded to the Mediterranean Sea, docking in Cyprus on 28 February. In May 2014, the ship and her task group: the "Kirov"-class nuclear-powered cruiser "Petr Velikiy"; tankers; "Sergey Osipov", "Kama" and "Dubna"; ocean-going tug "Altay" and Ropucha-class landing ship "Minsk" (a part of the Black Sea Fleet), passed the UK while sailing for home. Despite financial and technical problems, resulting in limited operations for the ship, it is expected that "Admiral Kuznetsov" will remain in active service until at least 2030.

In April 2010, it was announced that by late 2012, the ship would enter Severodvinsk Sevmash shipyard for a major refit and modernization, including upgrades to obsolete electronics and sensor equipment, installation of a new anti-aircraft system (Pantsir-M) and an increase of the air wing with the removal of the P-700 Granit anti-ship missiles. Possible upgrades include exchanging the troublesome steam powerplant to gas-turbine, or even nuclear propulsion, and installation of catapults to the angled deck.

The Navy expected to acquire Mikoyan MiG-29K aircraft for "Admiral Kuznetsov" by 2011; this later was confirmed by a defense sub-contractor The MiG-29Ks would replace the 19 carrier-based Su-33 fighters, a resource set to expire by 2015. Producing more Su-33s is possible but not cost-effective for such small volumes; the MiG-29K is more convenient as the Indian Navy also placed an order a total for 45, reducing development and manufacture costs. India paid $730 million for the development and delivery of 16 MiG-29Ks; 24 more for the Russian Navy would cost about $1 billion.

Following ongoing maintenance, "Admiral Kuznetsov" set sail on 15 October 2016 from the Kola Bay for the Mediterranean, accompanied by seven other Russian Navy vessels including the nuclear-powered battlecruiser "Pyotr Velikiy" and two Udaloy-class destroyers. The carrier was accompanied by an ocean-going tugboat, as a precaution due to potential propulsion failure. The airwing included 6-8 Su-33 fighters, four Mig-29KR/KUBR multi-role aircraft, Ka-52K "Katran" navalised attack helicopters, Ka-31R "Helix" AEW&C helicopters and Ka-27PS "Helix-D" search and rescue helicopters. All the Su-33 aircraft had been upgraded with the Gefest SVP-24 bombsights for free-fall bombs, giving them a limited ground-attack capability. Analysts, including Mikhail Barabanov of the Moscow Defense Brief, suggested that a lack of trained pilots restricted the number of fixed-wing aircraft that could be deployed from the carrier.

On 21 October, the "Admiral Kuznetsov" battle group sailed through the English Channel, escorted by Royal Navy ships, while UK Defence Minister Michael Fallon speculated that the taskforce was designed to "test" the British naval response. On 26 October 2016, the ship was reported to have passed through the Strait of Gibraltar and refuelled at sea off North Africa the following day. On 3 November 2016, the "Admiral Kuznetsov" battle group paused off the east coast of Crete. On 14 November 2016, a MiG-29K crashed into the sea after taking off from the carrier. The pilot ejected safely from the plane and was rescued by helicopter. According to initial reports from Russian officials, the crash was a result of technical malfunction, but it was later revealed that the plane had actually run out of fuel waiting to land while the crew was attempting to repair a broken arresting wire. The carrier commander could have diverted the aircraft to land at a nearby airbase, but hesitated in the hope that the arrestor gear would be repaired in time.

On 15 November 2016, "Admiral Kuznetsov", took part in "a large-scale operation against the positions of terrorist groups Islamic State and Al-Nusra, in the provinces of Idlib and Homs" in Syria by launching Su-33 fighter strikes. This was the first time a Russian aircraft carrier would take part in combat operations. Russian Defence Ministry later reported that 30 militants had been killed as a result of those strikes, including 3 field commanders, among them" "Abul Baha al-Asfari, leader of Al-Nusra reserves in the provinces of Homs and Aleppo. Al-Asfari had also planned and led several insurgent attacks on the city of Aleppo itself. The Su-33s reportedly used 500-kg precision bombs. On 3 December 2016, an Su-33 crashed into the sea after attempting to land on the carrier. The plane crashed on its second attempt to land on the aircraft carrier in good weather conditions. The pilot was safely recovered by a search and rescue helicopter. Initially it was suspected that the plane missed the wires and failed to go around, falling short of the bow of the warship, but later it was revealed that the arresting cable failed to hold the aircraft, and was damaged in the attempt. Following the two incidents, the air wing was transferred to shore at Khmeimim Air Base near Latakia, Syria to continue military operations while the carrier's arresting gear issues were addressed.

In early January 2017, it was announced that "Admiral Kuznetsov" and her battlegroup would be ceasing operations in Syria and returning to Russia as part of a scaling back of Russian involvement in the conflict. During her deployment off Syria, aircraft from "Admiral Kuznetsov" carried out 420 combat missions, hitting 1,252 hostile targets. On 11 January 2017, "Admiral Kuznetsov" was conducting live-fire training exercises in the Mediterranean off the coast of Libya. The Russian defence ministry announced that on 11 January, "Admiral Kuznetsov" was visited by Libya′s military leader Khalifa Haftar, who had a video conference with Russian defence minister Sergey Shoygu while on board.

On 20 January "Admiral Kuznetsov" was sighted passing west through the Strait of Gibraltar and six days later she was escorted back along the English Channel by three Eurofighter Typhoons of the Royal Air Force and the Type 23 frigate . She arrived back in Severomorsk on 9 February. On 23 February 2017, President Putin said that the ship′s deployment to the Mediterranean had been his personal initiative. The carrier started an overhaul and modernisation in the first quarter of 2017. This is expected to extend its service life by 25 years.

The "Admiral Kuznetsov" is expected to undergo modernization at the 35th Ship Repair Plant in Murmansk between 2020 and 2021, upgrading the ship's power plant and electronics systems.




</doc>
<doc id="29311" url="https://en.wikipedia.org/wiki?curid=29311" title="Subaru Forester">
Subaru Forester

The Subaru Forester is a station-wagon based compact crossover SUV manufactured since 1997 by Subaru. Available in Japan from 1997, the Forester shares its platform with the Impreza. It has been awarded "Motor Trend's" 2009 and 2014 SUV of the Year and The Car Connection's Best Car To Buy 2014.

The Forester was introduced at the Tokyo Motor Show in November 1995 as the Streega concept, and made available for sale February 1997 in Japan, and to the US market in 1997 for MY1998. The Forester was one of the first emerging crossover SUVs. It was built in the style of a car, but had a taller stance, higher h-point seating, and an all-wheel drive drive train. Subaru advertising employed the slogan "SUV tough, Car Easy". It used the Impreza platform but with the larger 2.5-litre DOHC EJ25D four-cylinder boxer engine from the Subaru Outback, making at 5,600 rpm and of torque at 4,000 rpm.

In Japan, the Forester replaced the Subaru Impreza Gravel Express, known in the USA as the Subaru Outback Sport. However, the Outback Sport remained in production for the U.S. market. The Forester appeared after the introduction of the Nissan Rasheen in Japan with a similar appearance, and the Forester's Japanese competitors include the Toyota RAV4, Mitsubishi RVR, and the Suzuki Grand Vitara. Due to the Forester's low center of gravity, it meets the United States federal safety standards for passenger vehicles, and does not require a "risk of rollover" warning label on the driver's visor. Size and price-wise, it fits between the shared Impreza platform, and the larger Legacy.

The automatic transmissions used on AWD equipped vehicles will normally send 60% of the engine's torque to the front wheels and 40% to the rear wheels, using a computer-controlled, continuously variable, multi-plate transfer clutch. When the transmission detects a speed difference between the front and rear axle sets, the transmission progressively sends power to the rear wheels. Under slip conditions it can achieve an equal split in front and rear axle speeds.

When accelerating or driving uphill, the vehicle's weight shifts rearward, reducing front wheel traction, causing the transmission to automatically send torque to the rear wheels to compensate. When braking or driving downhill, the vehicle's weight shifts towards the front, reducing rear wheel traction. The transmission again compensates by sending torque to the front wheels for better steering control and braking performance. If the automatic is placed in reverse or first gear, the transmission divides the torque 50/50 to both front and rear wheels. The manual transmission cars are set up with a near 50/50 torque split as a base setting, and it varies from there. Essentially, the manual cars are set up with more bias towards the rear than the automatic cars.

The trim levels were the basic model "L" and the fully equipped "S" for the USA versions.

Forester L came with a high level of standard equipment, including ABS, air conditioning, power windows, power locks, cruise control, digital temperature gauge, multi-reflector halogen headlights, fog lights, roof rack, rear window defogger, trailer harness connector, reclining front bucket seats with adjustable lumbar support, tilt steering, tinted glass, AM/FM/cassette stereo with its antenna laminated in the left-rear quarter window. Notably new in 2001 were the three-point seatbelts for all five seating positions, including force limiters in front and height-adjustable shoulder belt anchors for front and rear outboard positions, plus rear seat headrests for all three seating positions.

Forester S adds a viscous limited-slip differential, rear disc brakes, 16 × 6.5-inch alloy wheels with 215/60R16 tires (the L uses 15 × 6-inch steel wheels), upgraded moquette upholstery, heated front seats with net storage pockets in back, dual vanity mirrors, heated sideview mirrors, heated windshield wipers, and keyless entry. New equipment for 2001 included Titanium pearl paint for the bumpers and cladding; six-disc in-dash CD sound system; leather-wrapped steering wheel, shift knob and handbrake handle; variable intermittent wipers with de-icers and driver’s side fin; and the five-spoke alloy wheels. Some models were equipped with the $1,000 optional premium package on the Forester S, including monotone paint (Sedona Red Pearl), power moonroof, front side-impact airbags, and gold accent wheels. Other options were the $800 automatic transmission, $39 chrome tailpipe cover and $183 auto-dimming rear-view mirror with compass, bringing the sticker price to $25,412 including $495 delivery (USA dollars quoted).

There was a change in body styling for all 2001–2002 models, and the 2001/2002 GT spec also had a change in engine management and power output was increased from 125 to .



The U.S. market was offered the car starting in 1997 with either the 2.5-Litre DOHC (MY1998 only) or 2.5-Litre SOHC naturally aspirated engine (no turbocharged engines). In 2000 Subaru updated the exterior with a modest facelift to the front, rear and sides, and the interior's dashboard MY2001.

MY1998 - 2000 versions sold in the United States:

The MY2001-2002 versions carried over adding the S Premium model, albeit with the aforementioned mild redesign:

The second generation was introduced as a 2003 model at the 2002 Chicago Auto Show, based on the new Impreza platform, featuring several fine-tune improvements over the past model. The 2003 Forester features weight-saving refinements such as an aluminum hood, perforated rails, and a hydro-formed front sub-frame. The most noticeable change was the offering of 2.5 L versions (normally aspirated and turbocharged) and in the U.S. the introduction of the turbo charged 2.5-liter model.

In the U.S., the naturally aspirated (non-turbo) X (previously L) and XS (previously S) were released in 2003. In 2004, the turbocharged XT version was released. However, the same model had been available since the late 1990s elsewhere in the world. The X and XS models feature a 2.5 L SOHC engine, while the XT model features a 2.5 L turbocharged DOHC engine. Both engines have timing belt driven camshafts. The XT model uses the same Mitsubishi TD04 turbocharger used in the Subaru Impreza WRX. The engine in the 2004 to 2013 Forester XT is the EJ255. The '04 and '05 version was essentially the same engine used in the Impreza WRX STi. Those seeking additional power for their Forester XT can replace the turbocharger and intercooler with used STI components which are readily available. All Forester 2.5 L engines are of the interference engine type.

In 2004, Subaru launched an STI variant of the Forester, the Forester STI, for the Japanese Market. It shared the same engine as the 2005 Subaru Impreza WRX STI, but thanks to different tuning generated . Starting with the 2004 XT, the turbocharged version had active valve control system AVCS cylinder heads. The i-AVLS active valve lift system became standard on the naturally aspirated version of the Forester in 2006. This increased horsepower and torque figures to 173 HP and 166 ft-lbs. The 2006 XT received a higher compression ratio to 8.4:1 from 8.2:1. This increased the XT's power to 230 HP and 235 ft-lbs.

For the 2006 model year, Subaru gave the SG a facelift, using redesigned headlights, tail-lights, bonnet, grille, front bumper and side-moldings.

MY03-04 Models has a 4-Star ANCAP safety rating. MY05 Forester Model had a mid-life update, which update increased its ANCAP safety rating to 5 Stars.

In 2006, the turbocharged engine (powering the Forester XT) was awarded International Engine of the Year. This engine is also used in the Subaru Impreza WRX, as well as the re-badged Saab 9-2XAero.

All of the 2.5-liter 4-cylinder engines have a timing belt made of rubber and cord. This belt must be replaced at . These engines are interference engines, meaning that if the timing belt breaks or stretches, the pistons will hit the valves, resulting in an engine teardown, and a likely rebuild. Also, if this belt is replaced around 105,000 miles, it is a good idea to change the water pump, thermostat, belt tensioner and all the idler pulleys for this belt. The water pump and thermostat are behind this belt.
In Australia for the Series II (MY06) cars, Subaru changed the recommended service interval for the timing belt replacement from 100,000 kilometers to 125,000 kilometers.
The 2.5-liter 4-cylinder engine in the first-generation Foresters featured head gaskets which were prone to premature failure. For 2003 and later, this problem was addressed with a revised, higher performing design, but is still a problem.

The U.S. Market was offered the car with either the 2.5 SOHC naturally aspirated engine, or the 2.5 DOHC turbocharged version
added in 2004.

2004 versions sold in the United States:

In 2005, the L.L. Bean edition is added:

In 2006, styling is updated, Active valve lift system is added to non-turbo engines to improve power and efficiency, XS model deleted, Premium model added:

In 2007, a bottle holder was added to front door panels, the 'Sports' trim level was added, which changed some interior and exterior features and added the VDT/VDC transmission to the XT Sports turbo Automatic model:

In 2008, TPMS was added, L.L. Bean model deletes rear load-leveling suspension, but gains radio upgrade, the XT Turbo Limited models gets the VDT/VDC Auto transmission as well:

The Forester had three main models available in Australia until July 2005:

The Forester at the time had three main models available in Australia from August 2005 Series II:

The Luxury Pack edition was an option on all models - allowing for leather seats and a sunroof. These options were also included with the Columbia edition. The Weekender edition included fog lamps, roof racks and alloy wheels.
Standard with the Manufacture Year 2006 (MY06) Forester came with larger side mirrors with indicator lights, curtain airbags giving a 5 star safety rating, remodelled centre console and exterior with a new look nose, lights and bumpers and the rear lost the large Subaru badge under the rear window.

The Forester was sold in India as a Chevrolet alongside other unique Chevrolet models sold there. However, since General Motors no longer holds an ownership stake in Subaru's parent company, Fuji Heavy Industries, sales in India of the Chevrolet-badged Forester have ended.

A look-alike was produced by Yema and known as the Yema F99 in China. It was a similar design to the pre-facelifted model. Production ran from 2012 to 2014. The engine was a 1.5l 4 cylinder mated to a 5 speed manual gearbox. The car was not related to the Forester even though they look very similar.

The third generation Forester began to move away from a traditional wagon design towards becoming a crossover SUV. It was larger in nearly every dimension and featured a sloping roof line with more cargo space. Subaru unveiled the model year 2008 Forester in Japan on December 25, 2007. The North American version made its debut at the 2008 North American International Auto Show in Detroit.

Styling was by Subaru Chief Designer Mamoru Ishii. The dimensions derive from engineers using the basic body structure of the Japanese-spec Impreza wagon with the rear platform of the U.S.-spec Impreza sedan. The Forester's wheelbase was increased , with overall increases of in length, in width and in height.

The independent double wishbone rear suspension was redesigned for better handling and a smoother ride. A "Sportshift" mode was added to the four-speed computer-controlled automatic transmission. The in-dash, touch-screen satellite navigation system became Bluetooth compatible, and integrated with a premium stereo. A six-speaker surround sound enhancement was optional.

The new model added to the Forester's wheelbase, improving interior space and cargo room ( expandable to ). Ground clearance was .

The Forester was available in Europe with either the 2.0-liter EJ20 petrol engine with Active Valve Control System (AVCS) matched to either five-speed manual or four-speed automatic gearbox, or an all-new diesel-powered horizontally opposed Subaru EE boxer engine, and six-speed manual gearbox. The new model was introduced at the 2008 Paris Motor Show in October. The diesel engine produces a power output of 147 PS ().

In the UK, the petrol-powered Forester was offered in the popular X and XS models, while trim level for the diesel models were X, XC, and XS NavPlus.

In Russia, Belarus and Ukraine 2.5 and 2.5 Turbo engines were also available.

There were seven specifications with various trim and performance levels:
Summary of standard trim and equipment over different Australian models.

The Forester trim levels were the 2.5X, the 2.5X Premium, the 2.5X Limited and the 2.5XT and 2.5XT Limited both with turbo. The interior color was either black or light gray, with three upholstery selections, including leather. Nine exterior colors were offered, with four colors in an pearlescent appearance.

Starting July 2008, Subaru no longer offered a special-edition L.L. Bean trim level on the Forester.

The USA 2.5X model was certified PZEV emissions (Rated instead ), with a badge attached to the rear of the vehicle on the bottom left-hand side of the tailgate. All other USA models were certified LEV2. The PZEV Forester was available for sale in all fifty states, unlike other manufacturers who only sold PZEV-certified vehicles in states that had adopted California emission standards. The engine without the turbo runs on unleaded gasoline rated at 87 octane, and the turbo engine (EJ255) requires premium fuel rated minimum 91 octane.

Safety equipment included front airbags with side curtain airbags and front passenger side airbags (for a total of six airbags) and brake assist that detects panic-braking situations and applies maximum braking force more quickly. The five-speed manual transmission was equipped with Incline Start Assist.

Some of the standard equipment found on the 2.5X included Subaru's VDC (Vehicle Dynamics Control), 16 inch steel wheels, and an auxiliary audio jack for MP3 players. Optional equipment included 17 inch alloy wheels, panoramic moonroof, heated front seats and heated side-view mirrors. The L.L. Bean edition added automatic climate control, leather upholstery, an upgraded stereo with six speakers and a six disc in-dash CD changer over the four-speaker stereo with single disc CD player, and an in-dash navigation system, as well as L.L. Bean signature floor mats and rear cargo tray.

The 2.5 XT came with the premium stereo standard, as well as 17-inch alloy wheels, and the panoramic moonroof. The 2.5 XT Limited added leather upholstery with heated front seats, in-dash navigation, a rear spoiler, and automatic climate control. For 2009, XT models came only with a four-speed automatic with Sport Shift.

The Forester XTI concept vehicle used the 2.5-liter intercooled turbo engine from the Subaru WRX STI, six-speed manual transmission, 18 × 8-inch S204 forged alloy wheels with Yokohama Advan Neova 255/40R18 performance tires, adjustable coil-over suspension, Brembo brakes with four-piston front calipers, 2-piston rear calipers, Super Sport ABS and Electronic Brake-force Distribution (EBD), leather and Alcantara sport seats, a special instrument cluster, front dash and center console and leather-wrapped steering wheel. Engine is rated and torque.

The vehicle was unveiled in 2008 SEMA show.

Subaru produced a specialized vehicle for the National Ski Patrol based on 2.5XT turbo. It includes diamond plate floor, rear steel walls, a 9,500-pound winch and a roof-mounted toboggan. The vehicle was unveiled in 2008 SEMA show.

In 2010 for the 2011 model year, the Subaru Forester received a new grille insert. An optional roof-rack would raise total height by 2.5 inches. The naturally aspirated Foresters were equipped with an all new third generation motor with DOHC 2.5l FB25 and 2.0l flat four FB20.

Pre-facelift styling

Post-facelift styling
The fourth-generation Forester was unveiled in 2012 Guangzhou Motor Show, followed by the 2013 New York International Auto Show.

Changes to the line-up include:

Japan models went on sale in November 2012. Early model includes 2.0i, 2.0i-L, 2.0i-L EyeSight, 2.0i-S EyeSight, 2.0XT (280 PS), 2.0XT EyeSight (280 PS). 2.0i engine models include six-speed manual (2.0i, 2.0i-L) or Lineartronic CVT transmission; 2.0XT (280 PS) engine models include Lineartronic CVT transmission.

Asian models went on sale in March 2013 as 2014 model year. Early model includes 2.0i-L, 2.0i Premium and 2.0XT. ASEAN production of the Subaru Forester began in February 2016. Malaysia-based Tan Chong Motor Assemblies (TCMA) will assemble approximately 10,000 Forester units annually for Malaysia, Thailand and Indonesia respectively.

US models went on sale in March 2013 as 2014 model year vehicles. Early models include 2.5i in base, Premium, Limited and top-line Touring versions, and performance-oriented turbocharged 2.0XT (253 PS) in Premium and Touring versions. Base and Premium model 2014 Foresters can be equipped with the manual six-speed transmission or the Lineartronic CVT. All other models are equipped with the Lineartronic CVT. An option on Limited/Touring 2.5i and Premium/Touring 2.0XT is new X-Mode control and Hill Descent Control(HDC) features. These are not available on other models.

According to IIHS (Insurance Institute for Highway Safety) the 2014 Forester achieved Good crash test ratings in Small Overlap Front, Moderate Overlap Front, Side, Roof Strength, and Head Restraing & Seats categories. The Forester had not been rated Good in the Small Overlap Front test until modifications were made for the 2014 model year. The small overlap test, introduced in 2012 by the IIHS, simulates a frontal collision on 25 percent of the driver's side front corner. Since its adoption, the IIHS has noticed several automakers making non-symmetrical modifications to their vehicles. Another small overlap test was conducted on a number of vehicles, including a 2014 Forester, but was conducted on the passenger side instead. The crash test showed substantially more intrusion into the passenger side than into the driver's side of the Forester.

The 2014 Forester has a new feature called X Mode that allows owners to go through more extreme conditions both on the road and off. The concept is that any driver, regardless of skill level, can drive safely on wet roads or muddy areas. It works by monitoring wheel-slip on all four wheels; should one or more wheels begin to slip, X Mode kicks in and applies the brakes to the affected wheel which results in a transfer of power to the opposite wheel. After it is engaged by a simple push button, X Mode stays engaged up until the vehicle's speed is about then disengages itself.

The 2014 top-of-the-line Touring model Forester offers Subaru's EyeSight driver assist technology that uses stereoscopic CCD cameras mounted on either side of the rearview mirror. Eyesight offers several driver assist technologies/features which include:

The system can be manually turned on or off. Being an optical, instead of radar, based system, it has limitations in limited visibility situations; driving into the sun, fog, or where the windshield is not cleared (snow, mud, etc.) may cause the system to disengage.

The 2014 and 2015 models had a major revamp of interior comfort. The passenger seat is higher, the sound system has been upgraded, the rear bench seats are higher and the console is re-positioned for the person riding in the center. The manual transmission models were also upgraded to a six-speed transmission instead of the previous generation's five-speed transmission. Engines during these year models do have an issue with oil consumption, along with numerous other automotive manufactures at the time. Subaru has a lawsuit due to it; some experience over 1.5 quarts of oil consumed between change intervals with low-level dash lights coming on. Some speculation on this is the use of different style piston rings on the engine style change and synthetic oil.

Pre-facelift styling

Post-facelift styling
The 2019 Subaru Forester was revealed on March 28, 2018 at the New York International Auto Show.




</doc>
<doc id="29313" url="https://en.wikipedia.org/wiki?curid=29313" title="Second-system effect">
Second-system effect

The second-system effect (also known as second-system syndrome) is the tendency of small, elegant, and successful systems, to be succeeded by over-engineered, bloated systems, due to inflated expectations and overconfidence.

The phrase was first used by Fred Brooks in his book "The Mythical Man-Month", first published in 1975. It described the jump from a set of simple operating systems on the IBM 700/7000 series to OS/360 on the 360 series, which happened in 1964.




</doc>
<doc id="29316" url="https://en.wikipedia.org/wiki?curid=29316" title="Sandinista National Liberation Front">
Sandinista National Liberation Front

The Sandinista National Liberation Front (, FSLN) is a democratic socialist political party in Nicaragua.

Its members are called Sandinistas in both English and Spanish. The party is named after Augusto César Sandino, who led the Nicaraguan resistance against the United States occupation of Nicaragua in the 1930s.

The FSLN overthrew Anastasio Somoza DeBayle in 1979, ending the Somoza dynasty, and established a revolutionary government in its place. Having seized power, the Sandinistas ruled Nicaragua from 1979 to 1990, first as part of a Junta of National Reconstruction. Following the resignation of centrist members from this Junta, the FSLN took exclusive power in March 1981. They instituted a policy of mass literacy, devoted significant resources to health care, and promoted gender equality but came under international criticism for human rights abuses, mass execution and oppression of indigenous peoples. A US-backed militia, known as the Contras, was formed in 1981 to overthrow the Sandinista government and was funded and trained by the US Central Intelligence Agency. In 1984 elections were held but were boycotted by some opposition parties. The FSLN won the majority of the votes, and those who opposed the Sandinistas won approximately a third of the seats. The civil war between the Contras and the government continued until 1989. After revising the constitution in 1987, and after years of fighting the Contras, the FSLN lost the 1990 election to Violeta Barrios de Chamorro but retained a plurality of seats in the legislature.

The FSLN is now Nicaragua's sole leading party. The FSLN often polls in opposition to the much smaller Constitutionalist Liberal Party, or PLC. In the 2006 Nicaraguan general election, former FSLN President Daniel Ortega was re-elected President of Nicaragua with 38.7% of the vote compared to 29% for his leading rival, bringing in the country's second Sandinista government after 17 years of the opposition winning elections. Ortega and the FSLN were re-elected again in the presidential elections of November 2011 and of November 2016.

The Sandinistas took their name from Augusto César Sandino (1895–1934), the charismatic leader of Nicaragua's nationalist rebellion against the US occupation of the country during the early 20th century (ca. 1922–1934). The suffix "-ista" is simply the Spanish equivalent of "-ist".

Sandino was assassinated in 1934 by the Nicaraguan National Guard (), the US-equipped police force of Anastasio Somoza, whose family ruled the country from 1936 until they were overthrown by the Sandinistas in 1979.

The FSLN originated in the milieu of various oppositional organizations, youth and student groups in the late 1950s and early 1960s. The University of Léon, and the National Autonomous University of Nicaragua (UNAN) in Managua were two of the principal centers of activity. Inspired by the Revolution and the FLN in Algeria, the FSLN itself was founded in 1961 by Carlos Fonseca, , Tomás Borge and others as "The National Liberation Front" (FLN). Only Tomás Borge lived long enough to see the Sandinista victory in 1979.

The term "Sandinista", was added two years later, establishing continuity with Sandino's movement, and using his legacy in order to develop the newer movement's ideology and strategy. By the early 1970s, the FSLN was launching limited military initiatives.

On December 23, 1972, a magnitude 6.2 earthquake leveled the capital city, Managua. The earthquake killed 10,000 of the city's 400,000 residents and left another 50,000 homeless. About 80% of Managua's commercial buildings were destroyed. President Anastasio Somoza Debayle's National Guard embezzled much of the international aid that flowed into the country to assist in reconstruction, and several parts of downtown Managua were never rebuilt. The president gave reconstruction contracts preferentially to family and friends, thereby profiting from the quake and increasing his control of the city's economy. By some estimates, his personal wealth rose to US$400 million in 1974.

In December 1974, a guerrilla group affiliated with FSLN directed by Eduardo Contreras and Germán Pomares seized government hostages at a party in the house of the Minister of Agriculture in the Managua suburb Los Robles, among them several leading Nicaraguan officials and Somoza relatives. The siege was carefully timed to take place after the departure of the US ambassador from the gathering. At 10:50 pm, a group of 15 young guerrillas and their commanders, Pomares and Contreras, entered the house. They killed the Minister, who tried to shoot them, during the takeover. The guerrillas received US$2 million ransom, and had their official communiqué read over the radio and printed in the newspaper "La Prensa".

Over the next year, the guerrillas also succeeded in getting 14 Sandinista prisoners released from jail, and with them, were flown to Cuba. One of the released prisoners was Daniel Ortega, who would later become the president of Nicaragua. The group also lobbied for an increase in wages for National Guard soldiers to 500 córdobas ($71 at the time). The Somoza government responded with further censorship, intimidation, torture, and murder.

In 1975, Somoza imposed a state of siege, censoring the press, and threatening all opponents with internment and torture. Somoza's National Guard also increased its violence against individuals and communities suspected of collaborating with the Sandinistas. Many of the FSLN guerrillas were killed, including its leader and founder Carlos Fonseca in 1976. Fonseca had returned to Nicaragua in 1975 from his exile in Cuba to try to reunite fractures that existed in the FSLN. He and his group were betrayed by a peasant who informed the National Guard that they were in the area. The guerrilla group was ambushed, and Fonseca was wounded in the process. The next morning Fonseca was executed by the National Guard.

Following the FSLN's defeat at the battle of Pancasán in 1967, the organization adopted the "Prolonged Popular War" ("Guerra Popular Prolongada", GPP) theory as its strategic doctrine. The GPP was based on the "accumulation of forces in silence": while the urban organization recruited on the university campuses and robbed money from banks, the main cadres were to permanently settle in the north central mountain zone. There they would build a grassroots peasant support base in preparation for renewed rural guerrilla warfare.

As a consequence of the repressive campaign of the National Guard, in 1975 a group within the FSLN's urban mobilization arm began to question the viability of the GPP. In the view of the young orthodox Marxist intellectuals, such as Jaime Wheelock, economic development had turned Nicaragua into a nation of factory workers and wage-earning farm laborers. Wheelock's faction was known as the "Proletarian Tendency".

Shortly after, a third faction arose within the FSLN. The "Insurrectional Tendency", also known as the "Third Way" or "Terceristas", led by Daniel Ortega, his brother Humberto Ortega, and Mexican-born Victor Tirado Lopez, was more pragmatic and called for tactical, temporary alliances with non-communists, including the right-wing opposition, in a popular front against the Somoza regime. By attacking the Guard directly, the Terceristas would demonstrate the weakness of the regime and encourage others to take up arms.

In October 1977, a group of prominent Nicaraguan professionals, business leaders, and clergymen allied with the Terceristas to form ""El Grupo de los Doce"" (The Group of Twelve) in Costa Rica. The group's main idea was to organize a provisional government in Costa Rica. The new strategy of the Terceristas also included unarmed strikes and rioting by labor and student groups coordinated by the FSLN's "United People's Movement" (Movimiento Pueblo Unido – MPU).

On January 10, 1978, Pedro Joaquín Chamorro, the editor of the opposition newspaper "La Prensa" and leader of the "Democratic Union of Liberation" (Unión Democrática de Liberación – UDEL), was assassinated. Although his assassins were not identified at the time, evidence implicated President Somoza's son and other members of the National Guard. Spontaneous riots followed in several cities, while the business community organized a general strike demanding Somoza's resignation.

The Terceristas carried out attacks in early February in several Nicaraguan cities. The National Guard responded by further increasing repression and using force to contain and intimidate all government opposition. The nationwide strike that paralyzed the country for ten days weakened the private enterprises and most of them decided to suspend their participation in less than two weeks. Meanwhile, Somoza asserted his intention to stay in power until the end of his presidential term in 1981. The United States government showed its displeasure with Somoza by suspending all military assistance to the regime, but continued to approve economic assistance to the country for humanitarian reasons.

In August, the Terceristas staged a hostage-taking. Twenty-three Tercerista commandos led by Edén Pastora seized the entire Nicaraguan congress and took nearly 1,000 hostages, including Somoza's nephew José Somoza Abrego and cousin Luis Pallais Debayle. Somoza gave in to their demands and paid a $500,000 ransom, released 59 political prisoners (including GPP chief Tomás Borge), broadcast a communiqué with FSLN's call for general insurrection and gave the guerrillas safe passage to Panama.

A few days later six Nicaraguan cities rose in revolt. Armed youths took over the highland city of Matagalpa. Tercerista cadres attacked Guard posts in Managua, Masaya, León, Chinandega and Estelí. Large numbers of semi-armed civilians joined the revolt and put the Guard garrisons of the latter four cities under siege. The September Insurrection of 1978 was subdued at the cost of several thousand, mostly civilian, casualties. Members of all three factions fought in these uprisings, which began to blur the divisions and prepare the way for unified action.

In early 1979, President Jimmy Carter and the United States no longer supported the Somoza regime, but did not want a left-wing government to take power in Nicaragua. The moderate "Broad Opposition Front" ("Frente Amplio Opositor" – FAO) which opposed Somoza was made up of a conglomeration of dissidents within the government as well as the "Democratic Union of Liberation" (UDEL) and the "Twelve", representatives of the Terceristas (whose founding members included Casimiro A. Sotelo, later to become Ambassador to the U.S. AND Canada representing the FSLN). The FAO and Carter came up with a plan that would remove Somoza from office but left no part in government power for the FSLN. The FAO's efforts lost political legitimacy, as Nicaraguans protested that they did not want ""Somocismo sin Somoza"" (Somocism without Somoza).

The "Twelve" abandoned the coalition in protest and formed the "National Patriotic Front" ("Frente Patriotico Nacional" – FPN) together with the "United People's Movement" (MPU). This strengthened the revolutionary organizations as tens of thousands of youths joined the FSLN and the fight against Somoza. A direct consequence of the spread of the armed struggle in Nicaragua was the official reunification of the FSLN that took place on 7 March 1979. Nine men, three from each tendency, formed the National Directorate which would lead the reunited FSLN. They were: Daniel Ortega, Humberto Ortega and Víctor Tirado (Terceristas); Tomás Borge, , and Henry Ruiz (GPP faction); and Jaime Wheelock, Luis Carrión and Carlos Núñez.

The FSLN evolved from one of many opposition groups to a leadership role in the overthrow of the Somoza regime. By mid-April 1979, five guerrilla fronts opened under the joint command of the FSLN, including an internal front in the capital city Managua. Young guerrilla cadres and the National Guardsmen were clashing almost daily in cities throughout the country. The strategic goal of the Final Offensive was the division of the enemy's forces. Urban insurrection was the crucial element because the FSLN could never hope to achieve simple superiority in men and firepower over the National Guard.

On June 4, a general strike was called by the FSLN to last until Somoza fell and an uprising was launched in Managua. On June 16, the formation of a provisional Nicaraguan government in exile, consisting of a five-member Junta of National Reconstruction, was announced and organized in Costa Rica. The members of the new junta were Daniel Ortega (FSLN), Moisés Hassan (FPN), Sergio Ramírez (the "Twelve"), Alfonso Robelo (MDN) and Violeta Barrios de Chamorro, the widow of "La Prensa"s director Pedro Joaquín Chamorro. By the end of that month, with the exception of the capital, most of Nicaragua was under FSLN control, including León and Matagalpa, the two largest cities in Nicaragua after Managua.

On July 9, the provisional government in exile released a government program, in which it pledged to organize an effective democratic regime, promote political pluralism and universal suffrage, and ban ideological discrimination, except for those promoting the "return of Somoza's rule". On July 17, Somoza resigned, handed over power to Francisco Urcuyo, and fled to Miami. While initially seeking to remain in power to serve out Somoza's presidential term, Urcuyo ceded his position to the junta and fled to Guatemala two days later.

On July 19, the FSLN army entered Managua, culminating the first goal of the Nicaraguan revolution. The war left approximately 30,000-50,000 dead and 150,000 Nicaraguans in exile. The five-member junta entered the Nicaraguan capital the next day and assumed power, reiterating its pledge to work for political pluralism, a mixed economic system, and a nonaligned foreign policy.

The Sandinistas inherited a country with a debt of 1.6 billion dollars (US), an estimated 30,000 to 50,000 war dead, 600,000 homeless, and a devastated economic infrastructure. To begin the task of establishing a new government, they created a Council (or ) of National Reconstruction, made up of five appointed members. Three of the appointed members—Sandinista militants Daniel Ortega, Moises Hassan, and novelist Sergio Ramírez (a member of Los Doce "the Twelve")—belonged to the FSLN. Two opposition members, businessman Alfonso Robelo, and Violeta Barrios de Chamorro (the widow of Pedro Joaquín Chamorro), were also appointed. Only three votes were needed to pass law.

The FSLN also established a Council of State, subordinate to the junta, which was composed of representative bodies. However, the Council of State only gave political parties twelve of forty-seven seats; the rest of the seats were given to Sandinista mass-organizations. Of the twelve seats reserved for political parties, only three were not allied to the FSLN. Due to the rules governing the Council of State, in 1980 both non-FSLN junta members resigned. Nevertheless, as of the 1982 State of Emergency, opposition parties were no longer given representation in the council. The preponderance of power also remained with the Sandinistas through their mass organizations, including the Sandinista Workers' Federation (), the Luisa Amanda Espinoza Nicaraguan Women's Association (), the National Union of Farmers and Ranchers (), and most importantly the Sandinista Defense Committees (CDS). The Sandinista-controlled mass organizations were extremely influential over civil society and saw their power and popularity peak in the mid-1980s.

Upon assuming power, the FSLN's official political platform included the following: nationalization of property owned by the Somozas and their supporters; land reform; improved rural and urban working conditions; free unionization for all workers, both urban and rural; price fixing for commodities of basic necessity; improved public services, housing conditions, education; abolition of torture, political assassination and the death penalty; protection of democratic liberties; equality for women; non-aligned foreign policy; formation of a "popular army" under the leadership of the FSLN and Humberto Ortega.

The FSLN's literacy campaign sent teachers into the countryside and within six months, half a million people had been taught rudimentary reading, bringing the national illiteracy rate down from over 50% to just under 12%. Over 100,000 Nicaraguans participated as literacy teachers. One of the stated aims of the literacy campaign was to create a literate electorate which would be able to make informed choices at the promised elections. The successes of the literacy campaign was recognized by UNESCO with the award of a Nadezhda Krupskaya International Prize.

The FSLN also created neighborhood groups similar to the Cuban Committees for the Defense of the Revolution, called Sandinista Defense Committees ( or CDS). Especially in the early days following the overthrow of Somoza, the CDS's served as "de facto" units of local governance. Their obligations included political education, the organization of Sandinista rallies, the distribution of food rations, organization of neighborhood/regional cleanup and recreational activities, and policing to control looting, and the apprehension of counter-revolutionaries. The CDS's organized civilian defense efforts against Contra activities and a network of intelligence systems in order to apprehend their supporters. These activities led critics of the Sandinistas to argue that the CDS was a system of local spy networks for the government used to stifle political dissent, and the CDS did hold limited powers—such as the ability to suspend privileges such as driver licenses and passports—if locals refused to cooperate with the new government. After the initiation of heavier U.S. military involvement in the Nicaraguan conflict the CDS was empowered to enforce wartime bans on political assembly and association with other political parties (i.e., parties associated with the "Contras").

By 1980, conflicts began to emerge between the Sandinista and non-Sandinista members of the governing junta. Violeta Chamorro and Alfonso Robelo resigned from the governing junta in 1980, and rumours began that members of the Ortega junta would consolidate power amongst themselves. These allegations spread, and rumors intensified that it was Ortega's goal to turn Nicaragua into a state modeled after Cuban socialism. In 1979 and 1980, former Somoza supporters and ex-members of Somoza's National Guard formed irregular military forces, while the original core of the FSLN began to splinter. Armed opposition to the Sandinista Government eventually divided into two main groups: The Fuerza Democrática Nicaragüense (FDN), a U.S. supported army formed in 1981 by the CIA, U.S. State Department, and former members of the widely condemned Somoza-era Nicaraguan National Guard; and the Alianza Revolucionaria Democratica (ARDE) Democratic Revolutionary Alliance, a group that had existed since before the FSLN and was led by Sandinista founder and former FSLN supreme commander, Edén Pastora, a.k.a. "Commander Zero". and Milpistas, former anti-Somoza rural militias, which eventually formed the largest pool of recruits for the Contras. Although independent and often at conflict with each other, these guerrilla bands—along with several others—all became generally known as "Contras" (short for "", en. "counter-revolutionaries").

The opposition militias were initially organized and largely remained segregated according to regional affiliation and political backgrounds. They conducted attacks on economic, military, and civilian targets. During the Contra war, the Sandinistas arrested suspected members of the Contra militias and censored publications they accused of collaborating with the enemy (i.e. the U.S., the FDN, and ARDE, among others).

In March 1982 the Sandinistas declared an official State of Emergency. They argued that this was a response to attacks by counter-revolutionary forces. The State of Emergency lasted six years, until January 1988, when it was lifted.

Under the new "Law for the Maintenance of Order and Public Security" the "Tribunales Populares Anti-Somozistas" allowed for the indefinite holding of suspected counter-revolutionaries without trial. The State of Emergency, however, most notably affected rights and guarantees contained in the "Statute on Rights and Guarantees of Nicaraguans". Many civil liberties were curtailed or canceled such as the freedom to organize demonstrations, the inviolability of the home, freedom of the press, freedom of speech, and the freedom to strike.

All independent news program broadcasts were suspended. In total, twenty-four programs were cancelled. In addition, Sandinista censor Nelba Cecilia Blandón issued a decree ordering all radio stations to take broadcasts from government radio station La Voz de La Defensa de La Patria every six hours.

The rights affected also included certain procedural guarantees in the case of detention including habeas corpus. The State of Emergency was not lifted during the 1984 elections. There were many instances where rallies of opposition parties were physically broken up by Sandinista Youth or pro-Sandinista mobs. Opponents to the State of Emergency argued its intent was to crush resistance to the FSLN. James Wheelock justified the actions of the Directorate by saying "... We are annulling the license of the false prophets and the oligarchs to attack the revolution."

Some emergency measures were taken before 1982. In December 1979 special courts called "Tribunales Especiales" were established to speed up the processing of 7,000-8,000 National Guard prisoners. These courts operated through relaxed rules of evidence and due process and were often staffed by law students and inexperienced lawyers. However, the decisions of the "Tribunales Especiales" were subject to appeal in regular courts. Many of the National Guard prisoners were released immediately due to lack of evidence. Others were pardoned or released by decree. By 1986 only 2,157 remained in custody and only 39 were still being held in 1989 when they were released under the Esquipulas II agreement.

On October 5, 1985 the Sandinistas broadened the 1982 State of Emergency and suspended many more civil rights. A new regulation also forced any organization outside of the government to first submit any statement it wanted to make public to the censorship bureau for prior approval.

The FSLN lost power in the presidential election of 1990 when Daniel Ortega was defeated in an election for the Presidency of Nicaragua by Violetta Chamorro.

Upon assuming office in 1981, U.S. President Ronald Reagan condemned the FSLN for joining with Cuba in supporting "Marxist" revolutionary movements in other Latin American countries such as El Salvador. His administration authorized the CIA to begin financing, arming and training rebels, most of whom were the remnants of Somoza's National Guard, as anti-Sandinista guerrillas that were branded "counter-revolutionary" by leftists ( in Spanish). This was shortened to "Contras", a label the force chose to embrace. Edén Pastora and many of the indigenous guerrilla forces, who were not associated with the "Somozistas", also resisted the Sandinistas.

The Contras operated out of camps in the neighboring countries of Honduras to the north and Costa Rica (see Edén Pastora cited below) to the south. As was typical in guerrilla warfare, they were engaged in a campaign of economic sabotage in an attempt to combat the Sandinista government and disrupted shipping by planting underwater mines in Nicaragua's Corinto harbour, an action condemned by the International Court of Justice as illegal. The U.S. also sought to place economic pressure on the Sandinistas, and, as with Cuba, the Reagan administration imposed a full trade embargo.

The Contras also carried out a systematic campaign to disrupt the social reform programs of the government. This campaign included attacks on schools, health centers and the majority of the rural population that was sympathetic to the Sandinistas. Widespread murder, rape, and torture were also used as tools to destabilize the government and to "terrorize" the population into collaborating with the Contras. Throughout this campaign, the Contras received military and financial support from the CIA and the Reagan Administration. This campaign has been condemned internationally for its many human rights violations. Contra supporters have often tried to downplay these violations, or countered that the Sandinista government carried out much more. In particular, the Reagan administration engaged in a campaign to alter public opinion on the Contras that has been termed "white propaganda". In 1984, the International Court of Justice judged that the United States Government had been in violation of International law when it supported the Contras.

After the U.S. Congress prohibited federal funding of the Contras through the Boland Amendment in 1983, the Reagan administration continued to back the Contras by raising money from foreign allies and covertly selling arms to Iran (then engaged in a war with Iraq), and channelling the proceeds to the Contras (see the Iran–Contra affair). When this scheme was revealed, Reagan admitted that he knew about Iranian "arms for hostages" dealings but professed ignorance about the proceeds funding the Contras; for this, National Security Council aide Lt. Col. Oliver North took much of the blame.

Senator John Kerry's 1988 U.S. Senate Committee on Foreign Relations report on links between the Contras and drug imports to the US concluded that "senior U.S. policy makers were not immune to the idea that drug money was a perfect solution to the Contras' funding problems." According to the National Security Archive, Oliver North had been in contact with Manuel Noriega, the US-backed president of Panama. The Reagan administration's support for the Contras continued to stir controversy well into the 1990s. In August 1996, "San Jose Mercury News" reporter Gary Webb published a series titled "Dark Alliance", linking the origins of crack cocaine in California to the CIA-Contra alliance. Webb's allegations were repudiated by reports from the "Los Angeles Times", "The New York Times", and "The Washington Post", and the "San Jose Mercury News" eventually disavowed his work. An investigation by the United States Department of Justice also stated that their "review did not substantiate the main allegations stated and implied in the Mercury News articles." Regarding the specific charges towards the CIA, the DOJ wrote "the implication that the drug trafficking by the individuals discussed in the "Mercury News" articles was connected to the CIA was also not supported by the facts." The CIA also investigated and rejected the allegations.

The Contra war unfolded differently in the northern and southern zones of Nicaragua. Contras based in Costa Rica operated on Nicaragua's Caribbean coast, which is sparsely populated by indigenous groups including the Miskito, Sumo, Rama, Garifuna, and Mestizo. Unlike Spanish-speaking western Nicaragua, the Caribbean Coast is predominantly English-speaking and was largely ignored by the Somoza regime. The "costeños" did not participate in the uprising against Somoza and viewed Sandinismo with suspicion from the outset.

While the Sandinistas encouraged grassroots pluralism, they were perhaps less enthusiastic about national elections. They argued that popular support was expressed in the insurrection and that further appeals to popular support would be a waste of scarce resources. International pressure and domestic opposition eventually pressed the government toward a national election. Tomás Borge warned that the elections were a concession, an act of generosity and of political necessity. On the other hand, the Sandinistas had little to fear from the election given the advantages of incumbency and the restrictions on the opposition, and they hoped to discredit the armed efforts to overthrow them.

A broad range of political parties, ranging in political orientation from far-left to far-right, competed for power. Following promulgation of a new populist constitution, Nicaragua held national elections in 1984. Independent electoral observers from around the world—including groups from the UN as well as observers from Western Europe—found that the elections had been fair. Several groups, however, disputed this, including UNO, a broad coalition of anti-Sandinista activists, COSEP, an organization of business leaders, the Contra group "FDN", organized by former Somozan-era National Guardsmen, landowners, businessmen, peasant highlanders, and what some claimed as their patron, the U.S. government.

Although initially willing to stand in the 1984 elections, the UNO, headed by Arturo Cruz (a former Sandinista), declined participation in the elections based on their own objections to the restrictions placed on the electoral process by the State of Emergency and the official advisement of President Ronald Reagan's State Department, who wanted to de-legitimize the election process. Among other parties that abstained was COSEP, who had warned the FSLN that they would decline participation unless freedom of the press was reinstituted. Coordinadora Democrática (CD) also refused to file candidates and urged Nicaraguans not to take part in the election. The Independent Liberal Party (PLI), headed by Virgilio Godoy Reyes, announced its refusal to participate in October. Consequently, when the elections went ahead the U.S. raised objections based upon political restrictions instituted by the State of Emergency (e.g., censorship of the press, cancellation of habeas corpus, and the curtailing of free assembly).

Daniel Ortega and Sergio Ramírez were elected president and vice-president, and the FSLN won an overwhelming 61 out of 96 seats in the new National Assembly, having taken 67% of the vote on a turnout of 75%. Despite international validation of the elections by multiple political and independent observers (virtually all from among U.S. allies), the United States refused to recognize the elections, with President Ronald Reagan denouncing the elections as a sham. According to a study, since the 1984 election was for posts subordinate to the Sandinista Directorate, the elections were no more subject to approval by vote than the Central Committee of the Communist Party is in countries of the East Bloc. Daniel Ortega began his six-year presidential term on January 10, 1985. After the United States Congress turned down continued funding of the Contras in April 1985, the Reagan administration ordered a total embargo on United States trade with Nicaragua the following month, accusing the Sandinista government of threatening United States security in the region.

The elections of 1990, which had been mandated by the constitution passed in 1987, saw the Bush administration funnel $49.75 million of 'non-lethal' aid to the Contras, as well as $9 million to the opposition UNO—equivalent to $2 billion worth of intervention by a foreign power in a US election at the time, and proportionately five times the amount George Bush had spent on his own election campaign. When Violetta Chamorro visited the White House in November 1989, the US pledged to maintain the embargo against Nicaragua unless Violeta Chamorro won.

In August 1989, the month that campaigning began, the Contras redeployed 8,000 troops into Nicaragua, after a funding boost from Washington, continued their guerrilla war. 50 FSLN candidates were assassinated. The Contras also distributed thousands of UNO leaflets.

Years of conflict had left 50,000 casualties and $12 billion of damages in a society of 3.5 million people and an annual GNP of $2 billion. After the war, a survey was taken of voters: 75.6% agreed that if the Sandinistas had won, the war would never have ended. 91.8% of those who voted for the UNO agreed with this (William I Robinson, op cit). The Library of Congress Country Studies on Nicaragua states:

Despite limited resources and poor organization, the UNO coalition under Violeta Chamorro directed a campaign centered around the failing economy and promises of peace. Many Nicaraguans expected the country's economic crisis to deepen and the Contra conflict to continue if the Sandinistas remained in power. Chamorro promised to end the unpopular military draft, bring about democratic reconciliation, and promote economic growth. In the February 25, 1990, elections, Violeta Barrios de Chamorro carried 55 percent of the popular vote against Daniel Ortega's 41 percent.

In 1987, due to a stalemate with the Contras, the Esquipulas II treaty was brokered by Costa Rican President Óscar Arias Sánchez. The treaty's provisions included a call for a cease-fire, freedom of expression, and national elections. After the February 26, 1990 elections, the Sandinistas lost and peacefully passed power to the National Opposition Union (UNO), an alliance of 14 opposition parties ranging from the conservative business organization COSEP to Nicaraguan communists. UNO's candidate, Violeta Barrios de Chamorro, replaced Daniel Ortega as president of Nicaragua.

Reasons for the Sandinista loss in 1990 are disputed. Defenders of the defeated government assert that Nicaraguans voted for the opposition due to the continuing U.S. economic embargo and potential Contra threat. Others have alleged that the United States threatened to continue to support the Contras and continue the civil war if the regime was not voted out of power.

After their loss, the Sandinista leaders held most of the private property and businesses that had been confiscated and nationalized by the FSLN government. This process became known as the "piñata" and was tolerated by the new Chamorro government. Ortega also claimed to "rule from below" through groups he controls such as labor unions and student groups. Prominent Sandinistas also created nongovernmental organizations to promote their ideas and social goals.

Daniel Ortega remained the head of the FSLN, but his brother Humberto resigned from the party and remained at the head of the Sandinista Army, becoming a close confidante and supporter of Chamorro. The party also experienced internal divisions, with prominent Sandinistas such as Ernesto Cardenal and Sergio Ramírez resigning to protest what they described as heavy-handed domination of the party by Daniel Ortega. Ramírez also founded a separate political party, the Sandinista Renovation Movement (MRS); his faction came to be known as the , who favor a more social democratic approach than the "ortodoxos", or hardliners. In the 1996 Nicaraguan election, Ortega and Ramírez both campaigned unsuccessfully as presidential candidates on behalf of their respective parties, with Ortega receiving 43% of the vote while Arnoldo Alemán of the Constitutional Liberal Party received 51%. The Sandinistas won second place in the congressional elections, with 36 of 93 seats.

Daniel Ortega was re-elected as leader of the FSLN in 1998. Municipal elections in November 2000 saw a strong Sandinista vote, especially in urban areas, and former Tourism Minister Herty Lewites was elected mayor of Managua. This result led to expectations of a close race in the presidential elections scheduled for November 2001. Daniel Ortega and Enrique Bolaños of the Constitutional Liberal Party (PLC) ran neck-and-neck in the polls for much of the campaign, but in the end the PLC won a clear victory. The results of these elections were that the FSLN won 42.6% of the vote for parliament (versus 52.6% for the PLC), giving them 41 out of the 92 seats in the National Assembly (versus 48 for the PLC). In the presidential race, Ortega lost to Bolaños 46.3% to 53.6%.

Daniel Ortega was once again re-elected as leader of the FSLN in March 2002 and re-elected as president of Nicaragua in November 2006.

In 2006, Daniel Ortega was elected president with 38% of the vote (see Nicaraguan general election, 2006). This occurred despite the fact that the breakaway Sandinista Renovation Movement continued to oppose the FSLN, running former Mayor of Managua Herty Lewites as its candidate for president. However, Lewites died several months before the elections.

The FSLN also won 38 seats in the congressional elections, becoming the party with the largest representation in parliament. The split in the Constitutionalist Liberal Party helped to allow the FSLN to become the largest party in Congress, however the Sandinista vote had a minuscule split between the FSLN and MRS, and the liberal party combined is larger than the Frente Faction. In 2010, several liberal congressmen raised accusations about the FSLN presumably attempting to buy votes in order to pass constitutional reforms that would allow Ortega to run for office for the 6th time since 1984. In 2011, Ortega was re-elected as President.

The "Zero Hunger Program", which aims to reduce poverty in the rural areas over a five-year period, was inaugurated by President Daniel Ortega and other members of his administration in the northern department of Jinotega. The program was designed to achieve the first objective of the United Nations' Millennium Development Goals, "to eradicate extreme poverty and reduce hunger to zero."

"Zero Hunger" with its budget of US$150 million plans to deliver a US$2,000 bond or voucher to 75,000 rural families between 2007 and 2012. The voucher will consist of the delivery of a pregnant cow and a pregnant sow, five chickens and a rooster, seeds, fruit-bearing plants and plants for reforestation. The project's short-term objective is to have each rural family capable of producing enough milk, meat, eggs, fruits, vegetables and cereals to cover its basic needs while its medium range objective is to establish local markets and export certain products.

The families that benefit from the project will be required to pay back 20 percent of the amount that they receive in order to create a rural fund that will guarantee the continuity of the program. NGOs and representatives from each community will be in charge of managing the project.

Opposition to proposed social security reforms, which increased taxes and decreased benefits, led to widespread demonstrations against the government in April 2018. A harsh government crackdown, involving mass arrests and snipers firing on demonstrators, resulted in some protesters calling for Ortega's resignation. Over 200 people have been killed in the ongoing unrest.

Through the media and the works of FSLN leaders such as Carlos Fonseca, the life and times of Augusto César Sandino became its unique symbol in Nicaragua. The ideology of Sandinismo gained momentum in 1974, when a Sandinista-initiated hostage situation resulted in the Somoza government adhering to FSLN demands and publicly printing and airing work on Sandino in well known newspapers and media outlets.

During the struggle against Somoza, the FSLN leaders' internal disagreements over strategy and tactics were reflected in three main factions:

Nevertheless, while ideologies varied between FSLN leaders, all leaders essentially agreed that Sandino provided a path for the Nicaragua masses to take charge, and the FSLN would act as the legitimate vanguard. The extreme end of the ideology links Sandino to Roman Catholicism and portrays him as descending from the mountains in Nicaragua knowing he would be betrayed and killed. Generally however, most Sandinistas associated Sandino on a more practical level, as a heroic and honest person who tried to combat the evil forces of imperialist national and international governments that existed in Nicaragua's history.

For purposes of making sense of how to govern, the FSLN drew four fundamental principles from the work of Carlos Fonseca and his understanding of the lessons of Sandino. According to Bruce E. Wright, "the Governing Junta of National Reconstruction agreed, under Sandinista leadership, that these principles had guided it in putting into practice a form of government that was characterized by those principles." It is generally accepted that these following principles have evolved the "ideology of Sandinismo." Three of these (excluding popular participation, which was presumably contained in Article 2 of the Constitution of Nicaragua) were to ultimately be guaranteed by Article 5 of the Constitution of Nicaragua. They are as follows:

It is perceived by some scholars that the period of the FSLN guiding the Nicaraguan revolution through the control of the state was a living experiment in an attempt to construct a truly democratic and revolutionary socialism. Bruce E. Wright claims that "this was a crucial contribution from Fonseca's work that set the template for FSLN governance during the revolutionary years and beyond."

Beginning in 1967, the Cuban General Intelligence Directorate, or DGI, had begun to establish ties with Nicaraguan revolutionary organizations. By 1970 the DGI had managed to train hundreds of Sandinista guerrilla leaders and had vast influence over the organization. After the successful ousting of Somoza, DGI involvement in the new Sandinista government expanded rapidly. An early indication of the central role that the DGI would play in the Cuban-Nicaraguan relationship is a meeting in Havana on July 27, 1979, at which diplomatic ties between the two countries were re-established after more than 25 years. Julián López Díaz, a prominent DGI agent, was named Ambassador to Nicaragua. Cuban military and DGI advisors, initially brought in during the Sandinista insurgency, would swell to over 2,500 and operated at all levels of the new Nicaraguan government.

The Cubans would like to have helped more in the development of Nicaragua towards socialism. Following the US invasion of Grenada, countries previously looking for support from Cuba saw that the United States was likely to take violent action to discourage this.

The early years of the Nicaraguan revolution had strong ties to Cuba. The Sandinista leaders acknowledged that the FSLN owed a great debt to the socialist island. Once the Sandinistas assumed power, Cuba gave Nicaragua military advice, as well as aid in education, health care, vocational training and industry building for the impoverished Nicaraguan economy. In return, Nicaragua provided Cuba with grains and other foodstuffs to help Cuba overcome the effects of the US embargo.

According to Cambridge University historian Christopher Andrew, who undertook the task of processing the Mitrokhin Archive, Carlos Fonseca Amador, one of the original three founding members of the FSLN had been recruited by the KGB in 1959 while on a trip to Moscow. This was one part of Aleksandr Shelepin's 'grand strategy' of using national liberation movements as a spearhead of the Soviet Union's foreign policy in the Third World, and in 1960 the KGB organized funding and training for twelve individuals that Fonseca handpicked. These individuals were to be the core of the new Sandinista organization. In the following several years, the FSLN tried with little success to organize guerrilla warfare against the government of Luis Somoza Debayle. After several failed attempts to attack government strongholds and little initial support from the local population, the National Guard nearly annihilated the Sandinistas in a series of attacks in 1963. Disappointed with the performance of Shelepin's new Latin American "revolutionary vanguard", the KGB reconstituted its core of the Sandinista leadership into the ISKRA group and used them for other activities in Latin America.

According to Andrew, Mitrokhin says during the following three years the KGB handpicked several dozen Sandinistas for intelligence and sabotage operations in the United States. Andrew and Mitrokhin say that in 1966, this KGB-controlled Sandinista sabotage and intelligence group was sent to northern Mexico near the US border to conduct surveillance for possible sabotage.

In July 1961 during the Berlin Crisis of 1961 KGB chief Alexander Shelepin sent a memorandum to Soviet premier Nikita Khrushchev containing proposals to create a situation in various areas of the world which would favor dispersion of attention and forces by the US and their satellites, and would tie them down during the settlement of the question of a German peace treaty and West Berlin. It was planned, inter alia, to organize an armed mutiny in Nicaragua in coordination with Cuba and with the "Revolutionary Front Sandino". Shelepin proposed to make appropriations from KGB funds in addition to the previous assistance $10,000 for purchase of arms.

Khrushchev sent the memo with his approval to his deputy Frol Kozlov and on August 1 it was, with minor revisions, passed as a CPSU Central Committee directive. The KGB and the Soviet Ministry of Defense were instructed to work out more specific measures and present them for consideration by the Central Committee.

Other researchers have documented the contribution made from other Warsaw Pact intelligence agencies to the fledgling Sandinista government including the East German Stasi, by using recently declassified documents from Berlin as well as from former Stasi spymaster Markus Wolf who described the Stasi's assistance in the creation of a secret police force modeled on East Germany's.

Cuba was instrumental in the Nicaraguan Literacy Campaign. Nicaragua was a country with a very high rate of illiteracy, but the campaign succeeded in lowering the rate from 50% to 12%. The revolution in Cuban education since the ousting of the US-backed Batista regime not only served as a model for Nicaragua but also provided technical assistance and advice. Cuba played an important part in the Campaign, providing teachers on a yearly basis after the revolution. Prevost states that "Teachers were not the only ones studying in Cuba, about 2,000 primary and secondary students were studying on the Isle of Youth and the cost was covered by the host country (Cuba)".

The goals of the 1980 Literacy Campaign were socio-political, strategic as well as educational. It was the most prominent campaign with regards to the new education system. Illiteracy in Nicaragua was significantly reduced from 50.3% to 12.9%. One of the government's major concerns was the previous education system under the Somoza regime which did not see education as a major factor on the development of the country. As mentioned in the Historical Program of the FSLN of 1969, education was seen as a right and the pressure to stay committed to the promises made in the program was even stronger. 1980 was declared the "Year of Literacy" and the major goals of the campaign that started only 8 months after the FSLN took over. This included the eradication of illiteracy and the integration of different classes, races, gender and age. Political awareness and the strengthening of political and economic participation of the Nicaraguan people was also a central goal of the Literacy Campaign. The campaign was a key component of the FSLN's cultural transformation agenda.

The basic reader which was disseminated and used by teacher was called "Dawn of the People" based on the themes of Sandino, Carlos Fonseca, and the Sandinista struggle against imperialism and defending the revolution. Political education was aimed at creating a new social values based on the principles of Sandinista socialism, such as social solidarity, worker's democracy, egalitarianism, and anti-imperialism.

Health care was another area where the Sandinistas made significant improvements and are widely recognized for this accomplishment, e.g. by Oxfam. In this area Cuba also played a role by again offering expertise to Nicaragua. Over 1,500 Cuban doctors worked in Nicaragua and provided more than five million consultations. Cuban personnel were essential in the elimination of polio, the decrease in whooping cough, rubella, measles and the lowering of the infant mortality rate. Gary Prevost states that Cuban personnel made it possible for Nicaragua to have a national health care system that reached the majority of its citizens.

Cuba has participated in the training of Nicaraguan workers in the use of new machinery imported to Nicaragua. The Nicaraguan revolution caused the United States to oppose the country's government; therefore the Sandinistas would not receive any aid from the United States. The United States embargo against Nicaragua, imposed by the Reagan administration in May 1985, made it impossible for Nicaragua to receive spare parts for US-made machines, so this led Nicaragua to look to other countries for help. Cuba was the best choice because of the shared language and proximity and also because it had imported similar machinery over the years. Nicaraguans went to Cuba for short periods of three to six months and this training involved close to 3,000 workers. Countries such as the UK, sent farm equipment to Nicaragua.

Cuba helped Nicaragua in large projects such as building roads, power plants and sugar mills. Cuba also attempted to help Nicaragua build the first overland route linking Nicaraguas Atlantic and Pacific coasts. The road was meant to traverse 260 miles of jungle, but completion of the road and usage was hindered by the Contra war, and it was never completed.

Another significant feat was the building of the Tipitapa-Malacatoya sugar mill. It was completed and inaugurated during a visit by Fidel Castro in January 1985. The plant used the newest technology available and was built by workers trained in Cuba. Also during this visit Castro announced that all debts incurred on this project were absolved. Cuba also provided technicians to aid in the sugar harvest and assist in the rejuvenation of several old sugar mills. Cubans also assisted in building schools and similar projects.

After the Nicaraguan revolution, the Sandinista government established a Ministry of Culture in 1980. The ministry was spearheaded by Ernesto Cardenal, a poet and priest. The ministry was established in order to socialize the modes of cultural production. This extended to art forms including dance, music, art, theatre and poetry. The project was created to democratize culture on a national level. The aim of the ministry was to "democratize art" by making it accessible to all social classes as well as protecting the right of the oppressed to produce, distribute and receive art. In particular, the ministry was devoted to the development of working class and "campesino", or peasant culture. Therefore, the ministry sponsored cultural workshops throughout the country until October 1988 when the Ministry of Culture was integrated into the Ministry of Education because of financial troubles.

The objective of the workshops was to recognize and celebrate neglected forms of artistic expression. The ministry created a program of cultural workshops known as, "Casas de Cultura and Centros Populares de Cultura". The workshops were set up in poor neighbourhoods and rural areas and advocated universal access and consumption of art in Nicaragua. The ministry assisted in the creation of theatre groups, folklore and artisanal production, song groups, new journals of creation and cultural criticism, and training programs for cultural workers. The ministry created a Sandinista daily newspaper named "Barricada" and its weekly cultural addition named "Ventana" along with the "Television Sandino, Radio Sandino" and the Nicaraguan film production unit called the INCINE. There were existing papers which splintered after the revolution and produced other independent, pro-Sandinista newspapers, such as "El Nuevo Diario" and its literary addition "Nuevo Amanecer Cultural". Editorial Nueva Nicaragua, a state publishing house for literature, was also created. The ministry collected and published political poetry of the revolutionary period, known as testimonial narrative, a form of literary genre that recorded the experiences of individuals in the course of the revolution.

The ministry developed a new anthology of Rubén Darío, a Nicaraguan poet and writer, established a Rubén Darío prize for Latin American writers, the Leonel Rugama prize for young Nicaraguan writers, as well as public poetry readings and contests, cultural festivals and concerts. The Sandinista regime tried to keep the revolutionary spirit alive by empowering its citizens artistically. At the time of its inception, the Ministry of Culture needed according to Cardenal, "to bring a culture to the people who were marginalized from it. We want a culture that is not the culture of an elite, of a group that is considered 'cultivated,' but rather of an entire people." Nevertheless, the success of the Ministry of Culture had mixed results and by 1985 criticism arose over artistic freedom in the poetry workshops. The poetry workshops became a matter for criticism and debate. Critics argued that the ministry imposed too many principles and guidelines for young writers in the workshop, such as, asking them to avoid metaphors in their poetry and advising them to write about events in their everyday life. Critical voices came from established poets and writers represented by the "Asociacion Sandinista de Trabajadores de la Cultura" (ASTC) and from the "Ventana" both of which were headed by Rosario Murillo. They argued that young writers should be exposed to different poetic styles of writing and resources developed in Nicaragua and elsewhere. Furthermore, they argued that the ministry exhibited a tendency that favored and fostered political and testimonial literature in post-revolutionary Nicaragua.

The new government, formed in 1979 and dominated by the Sandinistas, resulted in a socialist model of economic development. The new leadership was conscious of the social inequities produced during the previous thirty years of unrestricted economic growth and was determined to make the country's workers and peasants, the "economically underprivileged", the prime beneficiaries of the new society. Consequently, in 1980 and 1981, unbridled incentives to private investment gave way to institutions designed to redistribute wealth and income. Private property would continue to be allowed, but all land belonging to the Somozas was confiscated.

However, the ideology of the Sandinistas put the future of the private sector and of private ownership of the means of production in doubt. Although under the new government both public and private ownership were accepted, government spokespersons occasionally referred to a reconstruction phase in the country's development, in which property owners and the professional class would be tapped for their managerial and technical expertise. After reconstruction and recovery, the private sector would give way to expanded public ownership in most areas of the economy. Despite such ideas, which represented the point of view of a faction of the government, the Sandinista government remained officially committed to a mixed economy.

Economic growth was uneven in the 1980s. Restructuring of the economy and the rebuilding immediately following the end of the civil war caused the GDP to rise about 5 percent in 1980 and 1981. Each year from 1984 to 1990, however, showed a drop in the GDP. Reasons for the contraction included the reluctance of foreign banks to offer new loans, the diversion of funds to fight the new insurrection against the government, and, after 1985, the total embargo on trade with the United States, formerly Nicaragua's largest trading partner. After 1985 the government chose to fill the gap between decreasing revenues and mushrooming military expenditures by printing large amounts of paper money. Inflation rose rapidly, peaking in 1988 at more than 14,000 percent annually.

Measures taken by the government to lower inflation were largely defeated by natural disaster. In early 1988, the administration of Daniel José Ortega Saavedra (Sandinista junta coordinator 1979–85, president 1985–90) established an austerity program to lower inflation. Price controls were tightened, and a new currency was introduced. As a result, by August 1988, inflation had dropped to an annual rate of 240 percent. The following month, however, Hurricane Joan cut a path directly across the center of the country. Damage was extensive, and the government's program of large spending to repair the infrastructure destroyed its anti-inflation measures.

In its eleven years in power, the Sandinista government never overcame most of the economic inequalities that it inherited from the Somoza era. Years of war, policy missteps, natural disasters, and the effects of the United States trade embargo all hindered economic development.

The women of Nicaragua prior to, during and after the revolution played a prominent role within the nation's society as they have commonly been recognized, throughout history and across all Latin American states, as its backbone. Nicaraguan women were therefore directly affected by all of the positive and negative events that took place during this revolutionary period. The victory of the Sandinista National Liberation Front (FSLN) in 1979 brought about major changes and gains for women, mainly in legislation, broad educational opportunities, training programs for working women, childcare programs to help women enter the work force and greatly increased participation and leadership positions in a range of political activities. This, in turn, reduced the burdens that the women of Nicaragua were faced with prior to the revolution. During the Sandinista government, women were more active politically. The large majority of members of the neighborhood committees (Comités de Defensa Sandinista) were women. By 1987, 31% of the executive positions in the Sandinista government, 27% of the leadership positions of the FSLN, and 25% of the FSLN's active membership were women.

Supporters of the Sandinistas see their era as characterized by the creation and implementation of successful social programs which were free and made widely available to the entire nation. Some of the more successful programs for women that were implemented by the Sandinistas were in the areas of education (see; Nicaraguan Literacy Campaign), health, and housing. Providing subsidies for basic foodstuffs and the introduction of mass employment were also contributions of the FSLN. The Sandinistas were particularly advantageous for the women of Nicaraguan as they promoted progressive views on gender as early as 1969 claiming that the revolution would "abolish the detestable discrimination that women have suffered with regard to men and establish economic, political and cultural equality between men and women." This was evident as the FSLN began integrating women into their ranks by 1967, unlike other left-wing guerilla groups in the region. This goal was not fully reached because the roots of gender inequality were not explicitly challenged. Women's participation within the public sphere was also substantial, as many took part in the armed struggle as part of the FSLN or as part of counter-revolutionary forces.

Nicaraguan women organized independently in support of the revolution and their cause. Some of those organizations were the Socialist Party (1963), Federación Democrática (which support the FSLN in rural areas), and Luisa Amanda Espinoza Association of Nicaraguan Women (, AMNLAE). However, since Daniel Ortega, was defeated in the 1990 election by the United Nicaraguan Opposition (UNO) coalition headed by Violeta Chamorro, the situation for women in Nicaragua was seriously altered. In terms of women and the labor market, by the end of 1991 AMNLAE reported that almost 16,000 working women—9,000 agricultural laborers, 3,000 industrial workers, and 3,800 civil servants, including 2,000 in health, 800 in education, and 1,000 in administration—had lost their jobs. The change in government also resulted in the drastic reduction or suspension of all Nicaraguan social programs, which brought back the burdens characteristic of pre-revolutionary Nicaragua. The women were forced to maintain and supplement community social services on their own without economic aid or technical and human resource.

The Roman Catholic Church's relationship with the Sandinistas was extremely complex. Initially, the Church was committed to supporting the Somoza regime. The Somoza dynasty was willing to secure the Church a prominent place in society as long as it did not attempt to subvert the authority of the regime. Under the constitution of 1950 the Roman Catholic Church was recognized as the official religion and church-run schools flourished. It was not until the late 1970s that the Church began to speak out against the corruption and human rights abuses that characterized the Somoza regime.

The Catholic hierarchy initially disapproved of the Sandinistas' revolutionary struggle against the Somoza dynasty. The revolutionaries were perceived as proponents of "godless communism" that posed a threat to the traditionally privileged place that the Church occupied within Nicaraguan society. Nevertheless, the increasing corruption and repression characterizing the Somoza rule and the likelihood that the Sandinistas would emerge victorious ultimately influenced Archbishop Miguel Obando y Bravo to declare formal support for the Sandinistas' armed struggle. Throughout the revolutionary struggle, the Sandinistas had the grassroots support of clergy who were influenced by the reforming zeal of Vatican II and dedicated to a "preferential option for the poor" (for comparison, see liberation theology). Numerous Christian base communities (CEBs) were created in which lower level clergy and laity took part in consciousness raising initiatives to educate the peasants about the institutionalized violence they were suffering from. Some priests took a more active role in supporting the revolutionary struggle. For example, Father Gaspar García Laviana took up arms and became a member of FSLN.

Soon after the Sandinistas assumed power, the hierarchy began to oppose the Sandinistas government. The Archbishop was a vocal source of domestic opposition. The hierarchy was alleged to be motivated by fear of the emergence of the 'popular church' which challenged their centralized authority. The hierarchy also opposed social reforms implemented by the Sandinistas to aid the poor, allegedly because they saw it as a threat to their traditionally privileged position within society. In response to this perceived opposition, the Sandinistas shut down the church-run Radio Católica radio station on multiple occasions.

The Sandinistas' relationship with the Roman Catholic Church deteriorated as the Contra War continued. The hierarchy refused to speak out against the counterrevolutionary activities of the contras and failed to denounce American military aid. State media accused the Catholic Church of being reactionary and supporting the Contras. According to former President Ortega, "The conflict with the church was strong, and it costs us, but I don't think it was our fault. ... There were so many people being wounded every day, so many people dying, and it was hard for us to understand the position of the church hierarchy in refusing to condemn the contras." The hierarchy-state tensions were brought to the fore with Pope John Paul II 1983 visit to Nicaragua. Hostility to the Catholic Church became so great that at one point, FSLN militants shouted down Pope John Paul II as he tried to say Mass. Therefore, while the activities of the Catholic church contributed to the success of the Sandinista revolution, the hierarchy's opposition was a major factor in the downfall of the revolutionary government.

"Time" magazine in 1983 published reports of human rights violations in an article which stated that "According to Nicaragua's Permanent Commission on Human Rights, the regime detains several hundred people a month; about half of them are eventually released, but the rest simply disappear." "Time" also interviewed a former deputy chief of Nicaraguan military counterintelligence, who stated that he had fled Nicaragua after being ordered to kill 800 Miskito prisoners and make it look like they had died in combat. Another article described Sandinista neighbourhood "Defense Committees", modeled on similar Cuban Committees for the Defense of the Revolution, which according to critics were used to unleash mobs on anyone who was labeled a counterrevolutionary. Nicaragua's only opposition newspaper, La Prensa, was subject to strict censorship. The newspaper's editors were forbidden to print anything negative about the Sandinistas either at home or abroad.

Nicaragua's Permanent Commission on Human Rights reported 2,000 murders in the first six months and 3,000 disappearances in the first few years. It has since documented 14,000 cases of torture, rape, kidnapping, mutilation and murder.

The Inter-American Commission on Human Rights (IACHR) in a 1981 report found evidence for mass executions in the period following the revolution. It stated: "In the Commission's view, while the government of Nicaragua clearly intended to respect the lives of all those defeated in the civil war, during the weeks immediately subsequent to the Revolutionary triumph, when the government was not in effective control, illegal executions took place which violated the right to life, and these acts have not been investigated and the persons responsible have not been punished." The IACHR also stated that: "The Commission is of the view that the new regime did not have, and does not now have, a policy of violating the right to life of political enemies, including among the latter the former guardsmen of the Government of General Somoza, whom a large sector of the population of Nicaragua held responsible for serious human rights violations during the former regime; proof of the foregoing is the abolition of the death penalty and the high number of former guardsmen who were prisoners and brought to trial for crimes that constituted violations of human rights."

A 1983 IACHR report documented allegations of human rights violations against the Miskito Indians, which were alleged to have taken place after opposition forces (the Contras) infiltrated a Miskito village in order to launch attacks against government soldiers, and as part of a subsequent forced relocation program. Allegations included arbitrary imprisonment without trial, "disappearances" of such prisoners, forced relocation, and destruction of property. In late 1981, the CIA conspiracy "Operation Red Christmas" was exposed to separate the Atlantic region from the rest of Nicaragua. Red Christmas aimed to seize territory on Nicaragua's mainland and overthrow the Nicaraguan government. The Nicaraguan government responded to the provocations by transferring 8,500 Miskitos 50 miles south to a settlement called Tasba Pri. The U.S. government accused Nicaragua of genocide. The U.S. government produced a photo alleged to show Miskito bodies being burned by Sandinista troops; however, the photo was actually of people killed by Somoza's National Guard in 1978.

The IACHR's 1991 annual report states: "In September 1990, the Commission was informed of the discovery of common graves in Nicaragua, especially in areas where fighting had occurred. The information was provided by the Nicaraguan Pro Human Rights Association, which had received its first complaint in June 1990. By December 1991, that Association had received reports of 60 common graves and had investigated 15 of them. While most of the graves seem to be the result of summary executions by members of the Sandinista People's Army or the State Security, some contain the bodies of individuals executed by the Nicaraguan Resistance."

The IACHR's 1992 annual report contains details of mass graves and investigations which suggest that mass executions had been carried out. One such grave contained 75 corpses of peasants who were believed to have been executed in 1984 by government security forces pretending to be members of the Contras. Another grave was also found in the town of Quininowas which contained six corpses, believed to be an entire family killed by government forces when the town was invaded. A further 72 graves were reported as being found, containing bodies of people, the majority of whom were believed to have been executed by agents of the state and some also by the Contras.

The issue of human rights also became highly politicized at this time as human rights is claimed to be a key component of propaganda created by the Reagan administration to help legitimize its policies in the region. The Inter-Church Committee on Human Rights in Latin America (ICCHRLA) in its "Newsletter" stated in 1985 that: "The hostility with which the Nicaraguan government is viewed by the Reagan administration is an unfortunate development. Even more unfortunate is the expression of that hostility in the destabilization campaign developed by the US administration. ... An important aspect of this campaign is misinformation and frequent allegations of serious human rights violations by the Nicaraguan authorities." Among the accusations in The Heritage Foundation report and the Demokratizatsiya article are references to alleged policies of religious persecution, particularly anti-semitism. The ICCHRLA in its newsletter stated that: "From time to time the current U.S. administration, and private organizations sympathetic to it, have made serious and extensive allegations of religious persecution in Nicaragua. Colleague churches in the United States undertook onsite investigation of these charges in 1984. In their report, the delegation organized by the Division of Overseas Ministries of the National Council of Churches of Christ in the United States concluded that there is 'no basis for the charge of systematic religious persecution'. The delegation 'considers this issue to be a device being used to justify aggressive opposition to the present Nicaraguan government.'" On the other hand, some elements of the Catholic Church in Nicaragua, among them Archbishop Miguel Obando y Bravo, strongly criticized the Sandinistas. The Archbishop stated "The government wants a church that is aligned with the Marxist–Leninist regime." The Inter-American Commission on Human Rights states that: "Although it is true that much of the friction between the Government and the churches arises from positions that are directly or indirectly linked to the political situation of the country, it is also true that statements by high government officials, official press statements, and the actions of groups under the control of the Government have gone beyond the limits within which political discussions should take place and have become obstacles to certain specifically religious activities."

Human Rights Watch also stated in its 1989 report on Nicaragua that: "Under the Reagan administration, U.S. policy toward Nicaragua's Sandinista government was marked by constant hostility. This hostility yielded, among other things, an inordinate amount of publicity about human rights issues. Almost invariably, U.S. pronouncements on human rights exaggerated and distorted the real human rights violations of the Sandinista regime, and exculpated those of the U.S.-supported insurgents, known as the "contras"."

In 1987, a report was published by the UK based NGO Catholic Institute for International Relations (CIIR, now known as "Progressio"), a human rights organization which identifies itself with Liberation theology. The report, "Right to Survive: Human Rights in Nicaragua", discussed the politicization of the human rights issue: "The Reagan administration, with scant regard for the truth, has made a concerted effort to paint as evil a picture as possible of Nicaragua, describing it as a 'totalitarian dungeon'. Supporters of the Sandinistas ... have argued that Nicaragua has a good record of human rights compared with other Central American countries and have compared Nicaragua with other countries at war." The CIIR report refers to estimates made by the NGO Americas Watch which count the number of non-battle related deaths and disappearances for which the government was responsible up to the year 1986 as "close to 300".

According to the CIIR report, Amnesty International and Americas Watch stated that there is no evidence that the use of torture was sanctioned by the Nicaraguan authorities, although prisoners reported the use of conditions of detention and interrogation techniques that could be described as psychological torture. The Red Cross made repeated requests to be given access to prisoners held in state security detention centers, but were refused. The CIIR was critical of the Permanent Commission on Human Rights (PCHR or CPDH in Spanish), claiming that the organisation had a tendency to immediately publish accusations against the government without first establishing a factual basis for the allegations. The CIIR report also questioned the independence of the Permanent Commission on Human Rights, referring to an article in "The Washington Post" which claims that the National Endowment for Democracy, an organization funded by the US government, allocated a concession of US$50,000 for assistance in the translation and distribution outside Nicaragua of its monthly report, and that these funds were administered by the Committee for Democracy in Central America (Prodemca), a US-based organization which later published full-page adverisements in the "Washington Post "and "New York Times" supporting military aid to the Contras. The Permanent Commission denies that it received any money which it claims was instead used by others for translating and distributing their monthly reports in other nations.

The Nicaraguan-based magazine "Revista Envio", which describes its stance as one of "critical support for the Sandinistas", refers to the report: "The CPDH: Can It Be Trusted?" written by Scottish lawyer Paul Laverty. In the report, Laverty observes that: "The entire board of directors [of the Permanent Commission], are members of or closely identify with the 'Nicaraguan Democratic Coordinating Committee' (Coordinadora), an alliance of the more rightwing parties and COSEP, the business organization." He goes on to express concern about CPDH's alleged tendency to provide relatively few names and other details in connection with alleged violations. "According to the 11 monthly bulletins of 1987 (July being the only month without an issue), the CPDH claims to have received information on 1,236 abuses of all types. However, of those cases, only 144 names are provided. The majority of those 144 cases give dates and places of alleged incidents, but not all. This means that only in 11.65% of its cases is there the minimal detail provided to identify the person, place, date, incident and perpetrator of the abuse."

On the other hand, the Inter-American Commission on Human Rights states: "During its on-site observation in 1978 under the Government of General Somoza, the Permanent Commission on Human Rights in Nicaragua, (CPDH) gave the Commission notable assistance, which certainly helped it to prepare its report promptly and correctly." and in 1980 "It cannot be denied that the CPDH continues to play an important role in the protection of human rights, and that a good number of people who consider that their human rights have been ignored by the Government are constantly coming to it." The IACHR continued to meet with representatives of the Permanent Commission and report their assessments in later years.

The Heritage Foundation stated that: "While elements of the Somoza National Guard tortured political opponents, they did not employ psychological torture." The International Commission of Jurists stated that under the Somoza regime cruel physical torture was regularly used in the interrogation of political prisoners.

Throughout the 1980s the Sandinista government was regarded as "Partly Free" by Freedom House.

The United States State Department accused the Sandinistas of many cases of illegal foreign intervention.

The first allegation was supporting the FMLN rebels in El Salvador with safe haven, training, command-and-control headquarters, advice, weapons, ammunition, and other vital supplies. Captured documents, testimonials of former rebels and Sandinistas, aerial photographs, the tracing of captured weapons back to Nicaragua, and captured vehicles from Nicaragua smuggling weapons were cited as evidence. El Salvador was in a civil war in the period in question and the US was heavily supporting the Salvadoran government against the FMLN guerrillas.

There were also accusations of subversive activities in Honduras, Costa Rica, and Colombia, and in the case of Honduras and Costa Rica outright military operations by Nicaraguan troops.

The flag of the FSLN consists of an upper half in red, a lower half in black, and the letters F S L N in white. It is a modified version of the flag Sandino used in the 1930s, during the war against the U.S. occupation of Nicaragua which consisted of two vertical stripes, equally in size, one red and the other black with a skull (like the traditional Jolly Roger flag). These colors came from the Mexican anarchist movements that Sandino was involved with during his stay in Mexico in the early 1920s. (The traditional flag of anarcho-syndicalism, which joins diagonally the red color of the labour movement and the black color of anarchism, as in the flag of the CNT, is a negation of nationalism and reaffirmation of internationalism.)

In recent times, there has been a dispute between the FSLN and the dissident Sandinista Renovation Movement (MRS) about the use of the red and black flag in public activities. Although the MRS has its own flag (orange with a silhouette of Sandino's hat in black), they also use the red-and-black flag in honor of Sandino's legacy. They state that the red-and-black flag is a symbol of Sandinismo as a whole, not only of the FSLN party.





I grew up in Urbana three houses down from the Sanderson family -- Milton and Virginia and their boys Steve and Joe. My close friend was Joe. His bedroom was filled with aquariums, terrariums, snakes, hamsters, spiders, and butterfly and beetle collections. I envied him like crazy. After college he hit the road. He never made a break from his parents, but they rarely knew where he was. Sometimes he came home and his mother would have to sew $100 bills into the seams of his blue jeans. He disappeared in Nicaragua. His body was later identified as a dead Sandinista freedom fighter. From a nice little house surrounded by evergreens at the other end of Washington Street, he left to look for something he needed to find. I believe in Sean Penn's Christopher McCandless. I grew up with him.



The party has given the following Presidents of the Republic, namely:

Won, getting the 67.20% of the valid votes cast 735.067 votes equivalent to well above the second party of the Democratic Conservative Party (PCD ) who won 154.127 corresponding to 14.00% of the valid votes.
Lost, as 579.886 A total valid votes equivalent to 40.82%, below that obtained by the main opposition Mrs. Violeta Barrios de Chamorro candidate of the National Opposition Union (UNO) who won 777.552 to obtain valid votes equivalent to 54.74%.
Lost, as 669,443 A total valid votes equivalent to 37.75%, below that obtained by his main opponent on Arnoldo Aleman Lacayo candidate of the Liberal Alliance (AL) who won 904.908 to obtain valid votes equivalent to 51.03%.
Lost, as 915,417 A total valid votes equivalent to 42.30%, below that obtained by the main opposition Enrique Bolaños Geyer candidate Liberal Constitutionalist Party (PLC) who won by getting 1,216,863 valid votes equivalent to 56.30%.
Won, getting the 37.99% of the valid votes cast, 930.802 votes equivalent to relatively higher than the two main opposition parties. They were the party of the Second Nicaraguan Liberal Alliance (ALN) with the degree candidate Eduardo Montealegre Rivas who won 693.391 votes recorded corresponding to a 28.30% and third place went to the Constitutionalist Liberal Party with Dr. José Rizo Castellón who earned a total 664.225 of valid votes corresponding to 27.11%.
Won in National Elections held on November 6, 2011 was the amount of 1,569,287 for 62.46% of the total valid votes, at that moment Commander Daniel Ortega Saavedra became the presidential candidate who won a presidential election with the most votes in the history of Nicaragua, in addition to that obtained a lead of more than 30% of valid votes doubling the number of votes obtained by radial businessman Fabio Gadea Mantilla on behalf of the Independent Liberal Party (PLI) who obtained the amount of 778.889 votes recorded for 31.00%. The big loser of these elections was the former President Arnoldo Aleman Lacayo candidate Liberal Constitutionalist Party (PLC) who was located in a distant third with a 5.91% equivalent to 148.507 votes. These results hint at a continuing and still fluid change in the correlation of political forces in the country.
Won in National Elections held on November 6, 2016 was the amount of 1,806,651 for 72.44% of the total valid votes. In the 2016 Presidential Elections, Commander Daniel Ortega Saavedra accompanied by Rosario Murillo Zambrana became the Presidential Formula that obtained the most votes in a Presidential Election in the history of Nicaragua, obtaining an advantage of more than 57% on the formula of Secondly, demonstrating that the application of the Christian, Socialist and Solidarity Model of the Government of Reconciliation and National Unity implemented by the Sandinista National Liberation Front has the support of the immense majority of Nicaraguans.





</doc>
<doc id="29318" url="https://en.wikipedia.org/wiki?curid=29318" title="Streptococcus">
Streptococcus

Streptococcus is a genus of gram-positive ' (plural '), or spherical bacteria, that belongs to the family Streptococcaceae, within the order Lactobacillales (lactic acid bacteria), in the phylum Firmicutes. Cell division in streptococci occurs along a single axis, so as they grow they tend to form pairs or chains that may appear bent or twisted. (Contrast with that of staphylococci, which divide along multiple axes, thereby generating irregular grape-like clusters of cells.)

The term was coined in 1877 by Viennese surgeon Albert Theodor Billroth (1829–1894), by combining the prefix "strepto-" (from ), together with the suffix "-coccus" (from Modern , from .)

Most streptococci are oxidase-negative and catalase-negative, and many are facultative anaerobes (capable of growth both aerobically and anaerobically).

In 1984, many bacteria formerly grouped in the genus "Streptococcus" were separated out into the genera "Enterococcus" and "Lactococcus". Currently, over 50 species are recognised in this genus. This genus has been found to be part of the salivary microbiome.

In addition to streptococcal pharyngitis (strep throat), certain "Streptococcus" species are responsible for many cases of pink eye, meningitis, bacterial pneumonia, endocarditis, erysipelas, and necrotizing fasciitis (the 'flesh-eating' bacterial infections). However, many streptococcal species are not pathogenic, and form part of the commensal human microbiota of the mouth, skin, intestine, and upper respiratory tract. Furthermore, streptococci are a necessary ingredient in producing Emmentaler ("Swiss") cheese.

Species of "Streptococcus" are classified based on their hemolytic properties. Alpha-hemolytic species cause oxidization of iron in hemoglobin molecules within red blood cells, giving it a greenish color on blood agar. Beta-hemolytic species cause complete rupture of red blood cells. On blood agar, this appears as wide areas clear of blood cells surrounding bacterial colonies. Gamma-hemolytic species cause no hemolysis.

Beta-hemolytic streptococci are further classified by Lancefield grouping, a serotype classification (that is, describing specific carbohydrates present on the bacterial cell wall). The 20 described serotypes are named Lancefield groups A to V (excluding I and J).

In the medical setting, the most important groups are the alpha-hemolytic streptococci "S. pneumoniae" and "Streptococcus" "viridans "group, and the beta-hemolytic streptococci of Lancefield groups A and B (also known as “group A strep” and “group B strep”).

Table: Medically relevant streptococci (not all are alpha hemolytic)
When alpha hemolysis (α-hemolysis) is present, the agar under the colony will appear dark and greenish due to the conversion of hemoglobin to green biliverdin. "Streptococcus pneumoniae" and a group of oral streptococci ("Streptococcus viridans" or viridans streptococci) display alpha hemolysis. 
Alpha-hemolysis is also termed incomplete hemolysis and partial hemolysis because the cell membrane of the red blood cells are left intact. This is also sometimes called green hemolysis because of the color change in the agar. 



Beta hemolysis (β-hemolysis), sometimes called complete hemolysis, is a complete lysis of red cells in the media around and under the colonies: the area appears lightened (yellow) and transparent. Streptolysin, an exotoxin, is the enzyme produced by the bacteria which causes the complete lysis of red blood cells. There are two types of streptolysin: Streptolysin O (SLO) and streptolysin S (SLS). Streptolysin O is an oxygen-sensitive cytotoxin, secreted by most Group A "Streptococcus" (GAS), and interacts with cholesterol in the membrane of eukaryotic cells (mainly red and white blood cells, macrophages, and platelets), and usually results in β-hemolysis under the surface of blood agar. Streptolysin S is an oxygen-stable cytotoxin also produced by most GAS strains which results in clearing on the surface of blood agar. SLS affects immune cells, including polymorphonuclear leukocytes and lymphocytes, and is thought to prevent the host immune system from clearing infection. "Streptococcus pyogenes", or GAS, displays beta hemolysis.

Some weakly beta-hemolytic species cause intense beta hemolysis when grown together with a strain of "Staphylococcus". This is called the CAMP test. "Streptococcus agalactiae" displays this property. "Clostridium perfringens" can be identified presumptively with this test. "Listeria monocytogenes" is also positive on sheep's blood agar.
Group A "S. pyogenes" (GAS) is the causative agent in a wide range of group A streptococcal infections. These infections may be noninvasive or invasive. The noninvasive infections tend to be more common and less severe. The most common of these infections include streptococcal pharyngitis (strep throat) and impetigo. Scarlet fever is also a noninvasive infection, but has not been as common in recent years. 
The invasive infections caused by group A β-hemolytic streptococci tend to be more severe and less common. This occurs when the bacterium is able to infect areas where it is not usually found, such as the blood and the organs. The diseases that may be caused include streptococcal toxic shock syndrome, necrotizing fasciitis, pneumonia, and bacteremia. Globally, GAS has been estimated to cause more than 500,000 deaths every year, making it one of the world's leading pathogens.

Additional complications may be caused by GAS, namely acute rheumatic fever and acute glomerulonephritis. Rheumatic fever, a disease that affects the joints, kidneys, and heart valves, is a consequence of untreated strep A infection caused not by the bacterium itself. Rheumatic fever is caused by the antibodies created by the immune system to fight off the infection cross-reacting with other proteins in the body. This "cross-reaction" causes the body to essentially attack itself and leads to the damage above. A similar autoimmune mechanism initiated by Group A beta-hemolytic streptococcal (GABHS) infection is hypothesized to cause pediatric autoimmune neuropsychiatric disorders associated with streptococcal infections (PANDAS), wherein autoimmune antibodies affect the basal ganglia, causing rapid onset of psychiatric, motor, sleep, and other symptoms in pediatric patients.

GAS infection is generally diagnosed with a rapid strep test or by culture.

"S. agalactiae", or group B "Streptococcus", GBS, causes pneumonia and meningitis in neonates and the elderly, with occasional systemic bacteremia. They can also colonize the intestines and the female reproductive tract, increasing the risk for premature rupture of membranes during pregnancy, and transmission of the organism to the infant. The American Congress of Obstetricians and Gynecologists (formerly the American College of Obstetricians and Gynecologists), American Academy of Pediatrics, and the Centers for Disease Control recommend all pregnant women between 35 and 37 weeks gestation to be tested for GBS. Women who test positive should be given prophylactic antibiotics during labor, which will usually prevent transmission to the infant.

The United Kingdom has chosen to adopt a risk factor-based protocol, rather than the culture-based protocol followed in the US. Current guidelines state that if one or more of the following risk factors is present, then the woman should be treated with "intrapartum" antibiotics:
This protocol results in treatment of 15–20% of pregnant women and prevention of 65–70% of cases of early onset GBS sepsis.

This group includes "S. equi", which causes strangles in horses, and "S. zooepidemicus"—"S. equi" is a clonal descendent or biovar of the ancestral "S. zooepidemicus"—which causes infections in several species of mammals, including cattle and horses. "S. dysgalactiae" is also a member of group C, beta-haemolytic streptococci that can cause pharyngitis and other pyogenic infections similar to group A streptococci.

Many former group D streptococci have been reclassified and placed in the genus "Enterococcus" (including "E. faecalis", "E. faecium", "E. durans", and "E. avium"). For example, "Streptococcus faecalis" is now "Enterococcus faecalis". "E. faecalis" is sometimes alpha hemolytic and "E. faecium" is sometimes beta hemolytic.

The remaining nonenterococcal group D strains include "Streptococcus bovis" and "Streptococcus equinus".

Nonhemolytic streptococci rarely cause illness. However, weakly hemolytic group D beta-hemolytic streptococci and "Listeria monocytogenes" (which is actually a Gram-positive bacillus) should not be confused with nonhemolytic streptococci.

Group F streptococci were first described in 1934 by Long and Bliss amongst the "minute haemolytic streptococci". They are also known as "Streptococcus anginosus" (according to the Lancefield classification system) or as members of the "S. milleri" group (according to the European system).

These streptococci are usually, but not exclusively, beta-hemolytic. "Streptococcus dysgalactiae" is the predominant species encountered, particularly in human disease. "S. canis" is an example of a GGS which is typically found on animals, but can cause infection in humans. "S. phocae" is a GGS subspecies that has been found in marine mammals and marine fish species. In marine mammals it has been mainly associated with meningoencephalitis, septicemia, and endocarditis, but is also associated with many other pathologies. Its environmental reservoir and means of transmission in marine mammals is not well characterized.

Group H streptococci cause infections in medium-sized canines. Group H streptococci rarely cause illness unless a human has direct contact with the mouth of a canine. One of the most common ways this can be spread is human-to-canine, mouth-to-mouth contact. However, the canine may lick the human's hand and infection can be spread, as well.

Streptococci have been divided into six groups on the basis of their 16S rDNA sequences: "S. anginosus, S.bovis, S. mitis, S. mutans, S. pyogenes" and "S. salivarius". The 16S groups have been confirmed by whole genome sequencing (see figure). The important pathogens "S. pneumoniae" and "S. pyogenes" belong to the "S. mitis" and "S. pyogenes" groups, respectively, while the causative agent of dental caries, "Streptococcus mutans", is basal to the "Streptococcus" group.

The genomes of hundreds of species have been sequenced. Most "Streptococcus" genomes are 1.8 to 2.3 Mb in size and encode 1,700 to 2,300 proteins. Some important genomes are listed in the table. The four species shown in the table ("S. pyogenes, S. agalactiae, S. pneumoniae", and "S. mutans") have an average pairwise protein sequence identity of about 70%.

Bacteriophages have been described for many species of "Streptococcus". 18 prophages have been described in "S. pneumoniae" that range in size from 38 to 41 kb in size, encoding from 42 to 66 genes each. Some of the first "Streptococcus" phages discovered were Dp-1 and ω1. In 1981 the Cp (Complutense phage) family was discovered with Cp-1 as its first member. Dp-1 and Cp-1 infect both "S. pneumoniae" and "S. mitis". However, the host ranges of most "Streptococcus" phages have not been investigated systematically.

Natural genetic transformation involves the transfer of DNA from one bacterium to another through the surrounding medium. Transformation is a complex process dependent on expression of numerous genes. To be capable of transformation a bacterium must enter a special physiologic state referred to as competence. "S. pneumoniae", "S. mitis" and "S. oralis" can become competent, and as a result actively acquire homologous DNA for transformation by a predatory fratricidal mechanism This fratricidal mechanism mainly exploits non-competent siblings present in the same niche Among highly competent isolates of "S. pneumoniae", Li et al. showed that nasal colonization fitness and virulence (lung infectivity) depend on an intact competence system. Competence may allow the streptococcal pathogen to use external homologous DNA for recombinational repair of DNA damages caused by the hosts oxidative attack 




</doc>
<doc id="29322" url="https://en.wikipedia.org/wiki?curid=29322" title="SignWriting">
SignWriting

Sutton SignWriting, or simply, SignWriting, is a system of writing sign languages. It is highly featural and visually iconic, both in the shapes of the characters, which are abstract pictures of the hands, face, and body, and in their spatial arrangement on the page, which does not follow a sequential order like the letters that make up written English words. It was developed in 1974 by Valerie Sutton, a dancer who had two years earlier developed DanceWriting.

As Sutton was teaching DanceWriting to the Royal Danish Ballet, Lars von der Lieth, who was doing research on sign language at the University of Copenhagen, thought it would be useful to use a similar notation for the recording of sign languages. Sutton based SignWriting on DanceWriting, and finally expanded the system to the complete repertoire of MovementWriting. However, only SignWriting and DanceWriting have been widely used.

Although not the first writing system for sign languages (see Stokoe notation), SignWriting is the first to adequately represent facial expressions and shifts in posture, and to accommodate representation of series of signs longer than compound words and short phrases. It is the only system in regular use, used for example to publish college newsletters in American Sign Language, and has been used for captioning of YouTube videos. Sutton notes that SignWriting has been used or investigated in over 40 countries on every inhabited continent. However, it is not clear how widespread its use is in each country.
In Brazil, during the FENEIS (National Association of the Deaf) annual meeting in 2001, the association voted to accept SignWriting as the preferred method of transcribing Lingua Brasileira de Sinais (Libras) into a written form. The strong recommendation to the Brazilian government from that association was that SignWriting be taught in all Deaf schools. Currently SignWriting is taught on an academic level at the University Federal de Santa Catarina as part of its Brazilian Sign Language curriculum. SignWriting is also being used in the recently published Brazilian Sign Language Dictionary containing more than 3,600 signs used by the deaf of São Paulo, published by the University of São Paulo under the direction of Prof. Fernando Capovilla (EJ669813 – Brazilian Sign Language Lexicography and Technology: Dictionary, Digital Encyclopedia, Chereme-based Sign Retrieval, and Quadriplegic Deaf Communication Systems. Abstracted from Educational Resources Information Center).

Some initial studies found that Deaf communities prefer video or writing systems for the dominant language, however this claim has been disputed by the work of Steve and Dianne Parkhurst in Spain where they found initial resistance, later renewed interest, and finally pride. "If Deaf people learn to read and write in their own signing system, that increases their self-esteem", says Dianne Parkhurst.

There are two doctoral dissertations that study and promote the application of SignWriting to a specific sign language. Maria Galea wrote about using SignWriting to write Maltese Sign Language. Also, Claudia Savina Bianchini wrote her doctoral dissertation on the implementation of SignWriting to write Italian Sign Language.

In SignWriting, a combination of iconic symbols for handshapes, orientation, body locations, facial expressions, contacts, and movement are used to represent words in sign language. Since SignWriting, as a featural script, represents the actual physical formation of signs rather than their meaning, no phonemic or semantic analysis of a language is required to write it. A person who has learned the system can "feel out" an unfamiliar sign in the same way an English speaking person can "sound out" an unfamiliar word written in the Latin alphabet, without even needing to know what the sign means.

The number of symbols is extensive and often provides multiple ways to write a single sign. Just as it took many centuries for English spelling to become standardized, spelling in SignWriting is not yet standardized for any sign language.

Words may be written from the point of view of the signer or the viewer. However, almost all publications use the point of view of the signer, and assume the right hand is dominant. Sutton originally designed the script to be written horizontally (left-to-right), like English, and from the point of view of the observer, but later changed it to vertical (top-to-bottom) and from the point of view of the signer, to conform to the wishes of Deaf writers.

The orientation of the palm is indicated by filling in the glyph for the hand shape. A hollow outline (white) glyph indicates that one is facing the palm of the hand, a filled (black) glyph indicates that one is facing the back of the hand, and split shading indicates that one is seeing the hand from the side. Although in reality the wrist may turn to intermediate positions, only the four orientations of palm, back, and either side are represented in SignWriting, as they are enough to represent sign languages.

If an unbroken glyph is used, then the hand is placed in the vertical (wall or face) plane in front of the signer, as occurs when finger spelling. A band erased across the glyph through the knuckles shows that the hand lies in the horizontal plane, parallel to the floor. (If one of the basic hand-shape glyphs is used, such as the simple square or circle, this band breaks it in two; however, if there are lines for fingers extended from the base, then they become detached from the base, but the base itself remains intact.)

The diagram to the left shows a BA-hand (flat hand) in six orientations. For the three vertical orientations on the left side, the hand is held in front of the signer, fingers pointing upward. All three glyphs can be rotated, like the hands of a clock, to show the fingers pointing at an angle, to the side, or downward. For the three horizontal orientations on the right side of the diagram, the hand is held outward, with the fingers pointing away from the signer, and presumably toward the viewer. They can also be rotated to show the fingers pointing to the side or toward the signer. Although an indefinite number of orientations can be represented this way, in practice only eight are used for each plane—that is, only multiples of 45° are found.

There are over a hundred glyphs for hand shapes, but all the ones used in ASL are based on five basic elements:

A line halfway across the square or pentagon shows the thumb across the palm. These are the E, B, and (with spread fingers) 4 hands of fingerspelling.

These basic shapes are modified with lines jutting from their faces and corners to represent fingers that are not positioned as described above. Straight lines represent straight fingers (these may be at an angle to indicate that they are not in line with the palm; if they point toward or away from the signer, they have a diamond shape at the tip); curved lines for curved (cupped) fingers; hooked lines for hooked fingers; right-angle lines, for fingers bent at only one joint; and crossed lines, for crossed fingers, as shown in the chart at right. The pentagon and C are only modified to show that the fingers are spread rather than in contact; the angle is only modified to show whether the thumb touches the finger tips or juts out to the side. Although there are some generalizations which can be made for the dozens of other glyphs, which are based on the circle and square, the details are somewhat idiosyncratic and each needs to be memorized.

There are only a few symbols for finger movement. They may be doubled to show that the movement is repeated.

A solid bullet represents flexing the middle joint of a finger or fingers, and a hollow bullet represents straightening a flexed finger. That is, a 'D' hand with a solid bullet means that it becomes an 'X' hand, while an 'X' hand with a hollow bullet means that it becomes a 'D' hand. If the fingers are already flexed, then a solid bullet shows that they squeeze. For example, a square (closed fist, 'S' hand) with double solid bullets is the sign for 'milk' (iconically squeezing an udder).

A downward-pointing chevron represents flexing at the knuckles, while an upward-pointing chevron (^) shows that the knuckles straighten. That is, a 'U' hand with a down chevron becomes an 'N' hand, while and 'N' hand with an up chevron becomes a 'U' hand.

A zigzag like two chevrons (^^) joined together means that the fingers flex repeatedly and in sync. A double-line zigzag means that the fingers wriggle or flutter out of sync.

Hundreds of arrows of various sorts are used to indicate movement of the hands through space. Movement notation gets quite complex, and because it is more exact than it needs to be for any one sign language, different people may choose to write the same sign in different ways.

For movement with the left hand, the Δ-shaped arrowhead is hollow (white); for movement with the right hand, it is solid (black). When both hands move as one, an open (Λ-shaped) arrowhead is used.

As with orientation, movement arrows distinguish two planes: Movement in the vertical plane (up & down) is represented by arrows with double stems, as at the bottom of the diagram at left, while single-stemmed arrows represent movement parallel to the floor (to & fro). In addition, movement in a diagonal plane uses modified double-stemmed arrows: A cross bar on the stem indicates that the motion is away as well up or down, and a solid dot indicates approaching motion. To & fro movement that also goes over or under something uses modified single-stemmed arrows, with the part of the arrow representing near motion thicker than the rest. These are iconic, but conventionalized, and so need to be learned individually.

Straight movements are in one of eight directions for either plane, as in the eight principal directions of a compass. A long straight arrow indicates movement from the elbow, a short arrow with a cross bar behind it indicates motion from the wrist, and a simple short arrow indicates a small movement. (Doubled, in opposite directions, these can show nodding from the wrist.) A secondary curved arrow crossing the main arrow shows that the arm twists while it moves. (Doubled, in opposite directions, these can show shaking of the hand.) Arrows can turn, curve, zigzag, and loop-the-loop.

Arrows on the face at the eyes show the direction of gaze.

Six contact glyphs show hand contact with the location of the sign. That is, a handshape glyph located at the side of the face, together with a contact glyph, indicates that the hand touches the side of the face. The choice of the contact glyph indicates the manner of the contact:

If the signing hand is located at the other hand, the symbol for it is one of the hand shapes above. In practice, only a subset of the more simple hand shapes occurs.

Additional symbols are used to represent sign locations at the face or body parts other than the hands. A circle shows the head.

There are symbols to represent facial movements that are used in various sign languages, including eyes, eyebrows, nose movements, cheeks, mouth movements, and breathing changes. The direction of head movement and eyegaze can also be shown.

Shoulders are shown with a horizontal line. Small arrows can be added to show shoulder and torso movement. Arms and even legs can be added if necessary.

There are also symbols that indicate speed of movement, whether movement is simultaneous or alternating, and punctuation.

Various punctuation symbols exist that correspond to commas, periods, question and exclamation marks, and other punctuation symbols of other scripts. These are written between signs, and lines do not break between a sign and its following punctuation symbol.

One of the unusual characteristics of SignWriting is its use of two-dimensional layout within an invisible 'sign box'. The relative positions of the symbols within the box iconically represent the locations of the hands and other parts of the body involved in the sign being represented. As such, there is no obvious linear relationship between the symbols within each sign box, unlike the sequence of characters within each word in most scripts for spoken languages. This is also unlike other sign language scripts which arrange symbols linearly as in spoken languages. However, since in sign languages many phonetic parameters are articulated simultaneously, these other scripts require arbitrary conventions for specifying the order of different parameters of handshape, location, motion, etc. Although SignWriting does have conventions for how symbols are to be arranged relative to each other within a sign, the two-dimensional layout results in less arbitrariness and more iconicity than other sign language scripts.

Outside of each sign, however, the script is linear, reflecting the temporal order of signs. Signs are most commonly now written in vertical columns (although formerly they were written horizontally). Sign boxes are arranged from top to bottom within the column, interspersed with punctuation symbols, and the columns progress left to right across the page. Within a column, signs may be written down the center or shifted left or right in 'lanes' to indicate side-to-side shifts of the body.

Sutton orders signs in ten groups based on which fingers are extended on the dominant hand. These are equivalent to the numerals one through ten in ASL. Each group is then subdivided according to the actual hand shape, and then subdivided again according to the plane the hand is in (vertical, then horizontal), then again according to the basic orientation of the hand (palm, side, back). An ordering system has been proposed using this beginning and examples from both American Sign Language and Brazilian Sign Language (LIBRAS). The current system of ordering for SignWriting is called the Sign Symbol Sequence which is parsed by the creator of each sign as recorded into the on-line dictionary. This system allows for internal ordering by features including handshape, orientation, speed, location, and other clustered features not found in spoken dictionaries.

Some of the advantages of SignWriting, compared to other writing systems for sign languages, are:
However, it has a few disadvantages as well.

SignWriting is the first writing system for sign languages to be included in the Unicode Standard. 672 characters were added in the Sutton SignWriting (Unicode block) of Unicode version 8.0 released in June 2015. This set of characters is based on SignWriting's standardized symbol set and defined character encoding model.

The Unicode Standard only covers the symbol set. It does not address layout, the positioning of the symbols in two dimensions. Historically, software has recorded position using Cartesian (X-Y) coordinates for each symbol. Since Unicode focuses on symbols that make sense in a one-dimensional plain-text context, the number characters required for 2-dimensional placement were not included in the Unicode proposal.

The Unicode block for Sutton SignWriting is U+1D800–U+1DAAF:

Current software records each sign as a string of characters in either ASCII or Unicode. Older software may use XML or a custom binary format to represent a sign. Formal SignWriting uses ASCII characters to define the 2-dimensional layout within a sign and other simple structures. It would be possible to fully define a sign in Unicode with seventeen additional characters. With either character set (Unicode or ASCII), the spelling of a sign produces a word that the can be efficiently processed with regular expressions. These sets are isomorphic.

Sutton has released the International SignWriting Alphabet 2010 under the SIL Open Font License. The symbols of ISWA 2010 are available as individual SVG or as TrueType Fonts.

SignWriting is enabled on with “The Javascript-based SignWriting Keyboard for Use on Wikimedia and throughout the Web” by Yair Rand. Test wikis include the and the other .





</doc>
<doc id="29323" url="https://en.wikipedia.org/wiki?curid=29323" title="Suez Canal">
Suez Canal

The Suez Canal ( "") is an artificial sea-level waterway in Egypt, connecting the Mediterranean Sea to the Red Sea through the Isthmus of Suez. Constructed by the Suez Canal Company between 1859 and 1869, it was officially opened on 17 November 1869. The canal offers watercraft a shorter journey between the North Atlantic and northern Indian Oceans via the Mediterranean and Red Seas by avoiding the South Atlantic and southern Indian Oceans, reducing the journey by approximately . It extends from the northern terminus of Port Said to the southern terminus of Port Tewfik at the city of Suez. Its length is , including its northern and southern access channels. In 2012, 17,225 vessels traversed the canal (average 47 per day).

The original canal was a single-lane waterway with passing locations in the Ballah Bypass and the Great Bitter Lake. It contains no locks system, with seawater flowing freely through it. In general, the canal north of the Bitter Lakes flows north in winter and south in summer. South of the lakes, the current changes with the tide at Suez.

The canal is owned and maintained by the Suez Canal Authority (SCA) of Egypt. Under the Convention of Constantinople, it may be used "in time of war as in time of peace, by every vessel of commerce or of war, without distinction of flag".

In August 2014, construction was launched to expand and widen the Ballah Bypass for to speed the canal's transit time. The expansion was planned to double the capacity of the Suez Canal from 49 to 97 ships a day. At a cost of $8.4 billion, this project was funded with interest-bearing investment certificates issued exclusively to Egyptian entities and individuals. The "New Suez Canal", as the expansion was dubbed, was opened with great fanfare in a ceremony on 6 August 2015.

On 24 February 2016, the Suez Canal Authority officially opened the new side channel. This side channel, located at the northern side of the east extension of the Suez Canal, serves the East Terminal for berthing and unberthing vessels from the terminal. As the East Container Terminal is located on the Canal itself, before the construction of the new side channel it was not possible to berth or unberth vessels at the terminal while the convoy was running.

Ancient west–east canals were built to facilitate travel from the Nile River to the Red Sea. One smaller canal is believed to have been constructed under the auspices of Senusret II or Ramesses II. Another canal, probably incorporating a portion of the first, was constructed under the reign of Necho II, but the only fully functional canal was engineered and completed by Darius I.

The legendary Sesostris (likely either Pharaoh Senusret II or Senusret III of the Twelfth dynasty of Egypt) may have started work on an ancient canal joining the Nile with the Red Sea (1897 BC – 1839 BC), when an irrigation channel was constructed around 1850 BC that was navigable during the flood season, leading into a dry river valley east of the Nile River Delta named Wadi Tumelat. (It is said that in ancient times the Red Sea reached northward to the Bitter Lakes and Lake Timsah.)

In his "Meteorology", Aristotle wrote:
One of their kings tried to make a canal to it (for it would have been of no little advantage to them for the whole region to have become navigable; Sesostris is said to have been the first of the ancient kings to try), but he found that the sea was higher than the land. So he first, and Darius afterwards, stopped making the canal, lest the sea should mix with the river water and spoil it.

Strabo wrote that Sesostris started to build a canal, and Pliny the Elder wrote:
165. Next comes the Tyro tribe and, the harbour of the Daneoi, from which Sesostris, king of Egypt, intended to carry a ship-canal to where the Nile flows into what is known as the Delta; this is a distance of over 60 miles. Later the Persian king Darius had the same idea, and yet again Ptolemy II, who made a trench 100 feet wide, 30 feet deep and about 35 miles long, as far as the Bitter Lakes.
In the second half of the 19th century, French cartographers discovered the remnants of an ancient north–south canal past the east side of Lake Timsah and ending near the north end of the Great Bitter Lake. This proved to be the celebrated canal made by the Persian king Darius I, as his stele commemorating its construction was found at the site. (This ancient, second canal may have followed a course along the shoreline of the Red Sea when it once extended north to Lake Timsah.) In the 20th century the northward extension of this ancient canal was discovered, extending from Lake Timsah to the Ballah Lakes. This was dated to the Middle Kingdom of Egypt by extrapolating the dates of ancient sites along its course.

The reliefs of the Punt expedition under Hatshepsut, 1470 BC, depict seagoing vessels carrying the expeditionary force returning from Punt. This suggests that a navigable link existed between the Red Sea and the Nile. Recent excavations in Wadi Gawasis may indicate that Egypt's maritime trade started from the Red Sea and did not require a canal. Evidence seems to indicate its existence by the 13th century BC during the time of Ramesses II.

Remnants of an ancient west–east canal through the ancient Egyptian cities of Bubastis, Pi-Ramesses, and Pithom were discovered by Napoleon Bonaparte and his engineers and cartographers in 1799.

According to the "Histories" of the Greek historian Herodotus, about 600 BC, Necho II undertook to dig a west–east canal through the Wadi Tumilat between Bubastis and Heroopolis, and perhaps continued it to the Heroopolite Gulf and the Red Sea. Regardless, Necho is reported as having never completed his project.

Herodotus was told that 120,000 men perished in this undertaking, but this figure is doubtless exaggerated. According to Pliny the Elder, Necho's extension to the canal was about 57 English miles, equal to the total distance between Bubastis and the Great Bitter Lake, allowing for winding through valleys. The length that Herodotus tells, of over 1000 stadia (i.e., over ), must be understood to include the entire distance between the Nile and the Red Sea at that time.

With Necho's death, work was discontinued. Herodotus tells that the reason the project was abandoned was because of a warning received from an oracle that others would benefit from its successful completion. Necho's war with Nebuchadnezzar II most probably prevented the canal's continuation.

Necho's project was completed by Darius I of Persia, who ruled over Ancient Egypt after it had been conquered by his predecessor Cambyses II. It may be that by Darius's time a natural waterway passage which had existed between the Heroopolite Gulf and the Red Sea in the vicinity of the Egyptian town of Shaluf (alt. "Chalouf" or "Shaloof"), located just south of the Great Bitter Lake, had become so blocked with silt that Darius needed to clear it out so as to allow navigation once again. According to Herodotus, Darius's canal was wide enough that two triremes could pass each other with oars extended, and required four days to traverse. Darius commemorated his achievement with a number of granite stelae that he set up on the Nile bank, including one near Kabret, and a further one a few miles north of Suez. The Darius Inscriptions read:

The canal left the Nile at Bubastis. An inscription on a pillar at Pithom records that in 270 or 269 BC, it was again reopened, by Ptolemy II Philadelphus. In Arsinoe, Ptolemy constructed a navigable lock, with sluices, at the Heroopolite Gulf of the Red Sea, which allowed the passage of vessels but prevented salt water from the Red Sea from mingling with the fresh water in the canal.

The Red Sea is believed by some historians to have gradually receded over the centuries, its coastline slowly moving southward away from Lake Timsah and the Great Bitter Lake. Coupled with persistent accumulations of Nile silt, maintenance and repair of Ptolemy's canal became increasingly cumbersome over each passing century.

Two hundred years after the construction of Ptolemy's canal, Cleopatra seems to have had no west–east waterway passage, because the Pelusiac branch of the Nile, which fed Ptolemy's west–east canal, had by that time dwindled, being choked with silt.

By the 8th century, a navigable canal existed between Old Cairo and the Red Sea, but accounts vary as to who ordered its construction—either Trajan or 'Amr ibn al-'As, or Omar the Great. This canal was reportedly linked to the River Nile at Old Cairo and ended near modern Suez. A geography treatise by Dicuil reports a conversation with an English monk, Fidelis, who had sailed on the canal from the Nile to the Red Sea during a pilgrimage to the Holy Land in the first half of the 8th century

The Abbasid Caliph al-Mansur is said to have ordered this canal closed in 767 to prevent supplies from reaching Arabian detractors.

Al-Hakim bi-Amr Allah is claimed to have repaired the Cairo to Red Sea passageway, but only briefly, circa 1000 AD, as it soon "became choked with sand." However, we are told that parts of this canal still continued to fill in during the Nile's annual inundations.

The successful 1488 navigation of southern Africa by Bartolomeu Dias opened a direct maritime trading route to India and the spice islands, and forever changed the balance of Mediterranean trade. One of the most prominent losers in the new order, as former middlemen, was the former spice trading center of Venice.

Despite entering negotiations with Egypt's ruling Mamelukes, the Venetian plan to build the canal was quickly put to rest by the Ottoman conquest of Egypt in 1517, led by Sultan Selim I

During the French campaign in Egypt and Syria in late 1798, Napoleon showed an interest in finding the remnants of an ancient waterway passage. This culminated in a cadre of archaeologists, scientists, cartographers and engineers scouring northern Egypt. Their findings, recorded in the "Description de l'Égypte", include detailed maps that depict the discovery of an ancient canal extending northward from the Red Sea and then westward toward the Nile.

Later, Napoleon, who would become French Emperor in 1804, contemplated the construction of a north–south canal to connect the Mediterranean with the Red Sea. But the plan was abandoned because it wrongly concluded that the waterway would require locks to operate. These would be very expensive and take a long time to construct. This decision was based on an erroneous belief that the Red Sea was higher than the Mediterranean. The error was the result of using fragmentary survey measurements taken in wartime during Napoleon's Egyptian Expedition. In 1819 the Pacha of Egypt undertook some canal work.

However, as late as 1861, the unnavigable ancient route discovered by Napoleon from Bubastis to the Red Sea still channeled water in spots as far east as Kassassin.

Although the alleged difference in sea levels could be problematic for construction, the idea of finding a shorter route to the east remained alive. In 1830, F. R. Chesney submitted a report to the British government that stated that there was no difference in elevation and that the Suez Canal was feasible, but his report received no further attention. Lieutenant Waghorn established his "Overland Route", which transported post and passengers to India via Egypt. Linant de Bellefonds, a French explorer of Egypt, became chief engineer of Egypt's Public Works. In addition to his normal duties, he surveyed the Isthmus of Suez and made plans for the Suez Canal. French Saint-Simonianists showed an interest in the canal and in 1833, Barthélemy Prosper Enfantin tried to draw Muhammad Ali's attention to the canal but was unsuccessful. Alois Negrelli, the Austrian railroad pioneer, became interested in the idea in 1836. In 1846, Prosper Enfantin's Société d'Études du Canal de Suez invited a number of experts, among them Robert Stephenson, Negrelli and Paul-Adrien Bourdaloue to study the feasibility of the Suez Canal (with the assistance of Linant de Bellefonds). Bourdaloue's survey of the isthmus was the first generally accepted evidence that there was no practical difference in altitude between the two seas. Britain, however, feared that a canal open to everyone might interfere with its India trade and therefore preferred a connection by train from Alexandria via Cairo to Suez, which was eventually built by Stephenson.

In 1854 and 1856, Ferdinand de Lesseps obtained a concession from Sa'id Pasha, the Khedive of Egypt and Sudan, to create a company to construct a canal open to ships of all nations. The company was to operate the canal for 99 years from its opening. De Lesseps had used his friendly relationship with Sa'id, which he had developed while he was a French diplomat in the 1830s. As stipulated in the concessions, Ferdinand convened the International Commission for the piercing of the isthmus of Suez ("Commission Internationale pour le percement de l'isthme des Suez") consisting of 13 experts from seven countries, among them John Robinson McClean, later President of the Institution of Civil Engineers in London, and again Negrelli, to examine the plans developed by Linant de Bellefonds, and to advise on the feasibility of and the best route for the canal. After surveys and analyses in Egypt and discussions in Paris on various aspects of the canal, where many of Negrelli's ideas prevailed, the commission produced a unanimous report in December 1856 containing a detailed description of the canal complete with plans and profiles. The Suez Canal Company ("Compagnie universelle du canal maritime de Suez") came into being on 15 December 1858 and work started on the shore of the future Port Said on 25 April 1859.

The excavation took some 10 years using forced labour (corvée) of Egyptian workers during the first years. Some sources estimate that over 30,000 people were working on the canal at any given period, that more than 1.5 million people from various countries were employed, and that thousands of labourers died, many of them from cholera and similar epidemics.

The British government had opposed the project from the outset to its completion. As one of the diplomatic moves against the canal, it disapproved of the use of "slave labour" of forced workers. The British Empire was the major global naval force and officially condemned the forced work and sent armed Bedouins to start a revolt among workers. Involuntary labour on the project ceased, and the viceroy condemned the corvée, halting the project.

Angered by the British opportunism, de Lesseps sent a letter to the British government remarking on the British lack of remorse a few years earlier when forced workers died in similar conditions building the British railway in Egypt.

Initially international opinion was skeptical and Suez Canal Company shares did not sell well overseas. Britain, Austria, and Russia did not buy a significant number of shares. However, with assistance from the Cattaui banking family, and their relationship with James de Rothschild of the French House of Rothschild bonds and shares were successfully promoted in France and other parts of Europe. All French shares were quickly sold in France. A contemporary British skeptic claimed "One thing is sure... our local merchant community doesn't pay practical attention at all to this grand work, and it is legitimate to doubt that the canal's receipts... could ever be sufficient to recover its maintenance fee. It will never become a large ship's accessible way in any case."

The canal opened under French control on 17 November 1869. Although numerous technical, political, and financial problems had been overcome, the final cost was more than double the original estimate. The opening was performed by Khedive Isma'il Pasha of Egypt and Sudan, and at Ismail's invitation French Empress Eugenie in the Imperial yacht "L'Aigle" piloted by Napoléon Coste, upon whom the Khedive bestowed the Ottoman Order of the Medjidie. The Khedive, in particular, was able to overcome initial reservations held by both British and French creditors by enlisting the help of the Sursock Family, whose deep connections proved invaluable in securing much international support for the project. 

The first ship to follow "L'Aigle" through the canal was the British P&O liner "Delta". Fourth ship through the canal was the Swedish steam frigate "Vanadis". Although "L'Aigle" was officially the first vessel through the canal, HMS "Newport", captained by George Nares, passed through it first. On the night before the canal was due to open, Captain Nares navigated his vessel, in total darkness and without lights, through the mass of waiting ships until it was in front of "L'Aigle". When dawn broke, the French were horrified to find that the Royal Navy was first in line and that it would be impossible to pass them. Nares received both an official reprimand and an unofficial vote of thanks from the Admiralty for his actions in promoting British interests and for demonstrating such superb seamanship. An Anchor Line ship, the S.S. "Dido", became the first to pass through the Canal from South to North.

After the opening, the Suez Canal Company was in financial difficulties. The remaining works were completed only in 1871, and traffic was below expectations in the first two years. De Lesseps therefore tried to increase revenues by interpreting the kind of net ton referred to in the second concession ("tonneau de capacité") as meaning a ship's cargo capacity and not only the theoretical net tonnage of the "Moorsom System" introduced in Britain by the Merchant Shipping Act in 1854. The ensuing commercial and diplomatic activities resulted in the International Commission of Constantinople establishing a specific kind of net tonnage and settling the question of tariffs in its protocol of 18 December 1873. This was the origin of the Suez Canal Net Tonnage and the Suez Canal Special Tonnage Certificate, both of which are still in use today.

The canal had an immediate and dramatic effect on world trade. Combined with the American transcontinental railroad completed six months earlier, it allowed the world to be circled in record time. It played an important role in increasing European colonization of Africa. The construction of the canal was one of the reasons for the Panic of 1873, because goods from the Far East were carried in sailing vessels around the Cape of Good Hope and were stored in British warehouses. An inability to pay his bank debts led Said Pasha's successor, Isma'il Pasha, to sell his 44% share in the canal for £4,000,000 (about £ million in 2017) to the government of Great Britain in 1875. French shareholders still held the majority. Local unrest caused the British to invade in 1882 and take full control, although nominally Egypt remained part of the Ottoman Empire. The British representative 1883 to 1907 was Evelyn Baring, 1st Earl of Cromer, who reorganized and modernized the government and suppressed rebellions and corruption. thereby facilitating increased traffic on the canal.

The Convention of Constantinople in 1888 declared the canal a neutral zone under the protection of the British, who had occupied Egypt and Sudan at the request of Khedive Tewfiq to suppress the Urabi Revolt against his rule. The revolt went on from 1879 to 1882. As a result of British involvement on the side of Khedive Tewfiq, Britain gained control of the canal in 1882. The British defended the strategically important passage against a major Ottoman attack in 1915, during the First World War. Under the Anglo-Egyptian Treaty of 1936, the UK retained control over the canal. The canal was again strategically important in the 1939–1945 Second World War, and Italo-German attempts to capture it were repulsed during the North Africa Campaign, during which the canal was closed to Axis shipping. In 1951 Egypt repudiated the treaty and in October 1954 the UK agreed to remove its troops. Withdrawal was completed on 18 July 1956.

Because of Egyptian overtures towards the Soviet Union, the United Kingdom and the United States withdrew their pledge to support the construction of the Aswan Dam. Egyptian President Gamal Abdel Nasser responded by nationalizing the canal on 26 July 1956 and transferring it to the Suez Canal Authority, intending to finance the dam project using revenue from the canal. On the same day that the canal was nationalized Nasser also closed the Straits of Tiran to all Israeli ships. This led to the Suez Crisis in which the UK, France, and Israel invaded Egypt. According to the pre-agreed war plans under the Protocol of Sèvres, the Israelis invaded the Sinai Peninsula, forcing Egypt to engage them militarily, and allowing the Anglo-French partnership to declare the resultant fighting a threat to stability in the Middle East and enter the war - officially to divide the two forces but in reality to regain the Canal and bring down the Nasser government.

To save the British from what he thought was a disastrous action and to stop the war from a possible escalation, Canadian Secretary of State for External Affairs Lester B. Pearson proposed the creation of the first United Nations peacekeeping force to ensure access to the canal for all and an Israeli withdrawal from the Sinai Peninsula. On 4 November 1956, a majority at the United Nations voted for Pearson's peacekeeping resolution, which mandated the UN peacekeepers to stay in Sinai unless both Egypt and Israel agreed to their withdrawal. The United States backed this proposal by putting pressure on the British government through the selling of sterling, which would cause it to depreciate. Britain then called a ceasefire, and later agreed to withdraw its troops by the end of the year. Pearson was later awarded the Nobel Peace Prize. As a result of damage and ships sunk under orders from Nasser the canal was closed until April 1957, when it was cleared with UN assistance. A UN force (UNEF) was established to maintain the free navigability of the canal, and peace in the Sinai Peninsula.

According to the historian Abd aI-Azim Ramadan, Nasser's decision to nationalize the Suez Canal was his alone, made without political or military consultation. The events leading up to the nationalization of the Suez Canal Company, as other events during Nasser’s rule, showed Nasser’s inclination to solitary decision making. Ramadan considered Nasser to be far from a rational, responsible leader.

In May 1967, Nasser ordered the UN peacekeeping forces out of Sinai, including the Suez Canal area. Israel objected to the closing of the Straits of Tiran to Israeli shipping. The canal had been closed to Israeli shipping since 1949, except for a short period in 1951–1952.

After the 1967 Six-Day War, Israeli forces occupied the Sinai peninsula, including the entire east bank of the Suez Canal. Unwilling to allow the Israelis to use the canal, Egypt immediately imposed a blockade which closed the canal to all shipping until 5 June 1975. As a result, 15 cargo ships, known as the "Yellow Fleet", were trapped in the canal for over eight years.

In 1973, during the Yom Kippur War, the canal was the scene of a major crossing by the Egyptian army into Israeli-occupied Sinai and a counter-crossing by the Israeli army to Egypt. Much wreckage from this conflict remains visible along the canal's edges.
After the Yom Kippur War the United States initiated Operation Nimbus Moon. The amphibious assault ship USS "Inchon (LPH-12)" was sent to the Canal, carrying 12 RH-53D minesweeping helicopters of HM-12. These partly cleared the canal between May and December 1974. She was relieved by the LST USS "Barnstable County" (LST1197). The British Royal Navy initiated Operation Rheostat and Task Group 65.2 provided for Operation Rheostat One (six months in 1974), the minehunters HMS "Maxton", HMS "Bossington", and HMS "Wilton", the Fleet Clearance Diving Team (FCDT) and HMS "Abdiel", a practice minelayer/MCMV support ship; and for Operation Rheostat Two (six months in 1975) the minehunters HMS Hubberston and HMS Sheraton, and HMS Abdiel. When the Canal Clearance Operations were completed, the canal and its lakes were considered 99% clear of mines. The canal was then reopened by Egyptian President Anwar Sadat aboard an Egyptian destroyer, which led the first convoy northbound to Port Said in 1975. At his side stood the Iranian Crown Prince Reza Pahlavi, delegated to represent his father, Mohammed Reza Pahlavi, the Shah of Iran. The cruiser USS "Little Rock" was the only American naval ship in the convoy.

The UNEF mandate expired in 1979. Despite the efforts of the United States, Israel, Egypt, and others to obtain an extension of the UN role in observing the peace between Israel and Egypt, as called for under the Egypt–Israel Peace Treaty of 1979, the mandate could not be extended because of the veto by the Soviet Union in the UN Security Council, at the request of Syria. Accordingly, negotiations for a new observer force in the Sinai produced the Multinational Force and Observers (MFO), stationed in Sinai in 1981 in coordination with a phased Israeli withdrawal. It is there under agreements between the United States, Israel, Egypt, and other nations.

In the summer of 2014, months after taking office as President of Egypt, Abdel Fattah el-Sisi ordered the expansion of the Ballah Bypass from 61 metres wide to 312 metres wide for 35 kilometers. The project was called the New Suez Canal, as it would allow ships to transit the canal in both directions simultaneously. The project cost more than $8 billion and was completed within one year. Sisi declared the expanded channel open for business in a ceremony on 6 August 2015.


Presidents of the Suez Canal Company (1858–1956):

Chairmen of the Suez Canal Authority (1956–present):

When built, the canal was long and deep. After several enlargements, it is long, deep and wide. It consists of the northern access channel of , the canal itself of and the southern access channel of .

The so-called "New Suez Canal", functional since 6 August 2015, currently has a new parallel canal in the middle part, with its length over . The current parameters of the Suez Canal, including both individual canals of the parallel section are: depth and width at least (that width measured at of depth).

The canal allows passage of ships up to draft or 240,000 deadweight tons and up to a height of above water level and a maximum beam of under certain conditions. The canal can handle more traffic and larger ships than the Panama Canal, as Suezmax dimensions are greater than both Panamax and New Panamax. Some supertankers are too large to traverse the canal. Others can offload part of their cargo onto a canal-owned boat to reduce their draft, transit, and reload at the other end of the canal.

The canal has no locks because of the flat terrain, and the minor sea level difference between each end is inconsequential for shipping. As the canal has no sea surge gates, the ports at the ends would be subject to the sudden impact of tsunamis from the Mediterranean Sea and Red Sea, according to a 2012 article in the "Journal of Coastal Research".

There is one shipping lane with passing areas in Ballah-Bypass near El Qantara and in the Great Bitter Lake. On a typical day, three convoys transit the canal, two southbound and one northbound. The passage takes between 11 and 16 hours at a speed of around . The low speed helps prevent erosion of the banks by ships' wakes.

By 1955, about two-thirds of Europe's oil passed through the canal. Around 8% of world sea trade is carried via the canal. In 2008, 21,415 vessels passed through the canal and the receipts totaled $5.381 billion, with an average cost per ship of $251,000.

New Rules of Navigation came into force on 1 January 2008, passed by the board of directors of the Suez Canal Authority (SCA) to organise vessels' transit. The most important amendments include allowing vessels with draught to pass, increasing the allowed breadth from to (following improvement operations), and imposing a fine on vessels using divers from outside the SCA inside the canal boundaries without permission. The amendments allow vessels loaded with dangerous cargo (such as radioactive or flammable materials) to pass if they conform with the latest amendments provided by international conventions.

The SCA has the right to determine the number of tugs required to assist warships traversing the canal, to achieve the highest degree of safety during transit.

Before August 2015, the canal was too narrow for free two-way traffic, so ships would pass in convoys and use bypasses. The by-passes were out of (40%). From north to south, they are: Port Said by-pass (entrances) , Ballah by-pass & anchorage, , Timsah by-pass , and the Deversoir by-pass (northern end of the Great Bitter Lake) . The bypasses were completed in 1980.

Typically, it would take a ship 12 to 16 hours to transit the canal. The canal's 24-hour capacity was about 76 standard ships.

In August 2014, Egypt chose a consortium that includes the Egyptian army and global engineering firm Dar Al-Handasah to develop an international industrial and logistics hub in the Suez Canal area, and began the construction of a new canal section from km 60 to km 95 combined with expansion and deep digging of the other 37 km of the canal. This will allow navigation in both directions simultaneously in the 72 km long central section of the canal. These extensions were formally opened on 6 August 2015 by President Al-Sisi.

Since the canal does not cater to unregulated two-way traffic, all ships transit in convoys on regular times, scheduled on a 24-hour basis. Each day, a single northbound convoy starts at 04:00 from Suez. At dulka lane sections, the convoy uses the eastern route. Synchronised with this convoy's passage is the southbound convoy. It starts at 03:30 from Port Said and so passes the Northbound convoy in the two-lane section.

From north to south, the crossings are:

A railway on the west bank runs parallel to the canal for its entire length.

Six new tunnels for cars and trains are also planned across the canal. Currently the Ahmed Hamdi is the only tunnel connecting Suez to the Sinai.

The main alternative is around Cape Agulhas, the southernmost point of Africa, commonly referred as the Cape of Good Hope route. This was the only sea route before the canal was constructed, and when the canal was closed. It is still the only route for ships that are too large for the canal. In the early 21st century, the Suez Canal has suffered from diminished traffic due to piracy in Somalia, with many shipping companies choosing to take the long route instead. Between 2008 and 2010, it is estimated that the canal lost 10% of traffic due to the threat of piracy, and another 10% due to the financial crisis. An oil tanker going from Saudi Arabia to the United States has longer to go when taking the route south of Africa rather than the canal.

Before the canal's opening in 1869, goods were sometimes offloaded from ships and carried overland between the Mediterranean and the Red Sea.

In recent years, the shrinking Arctic sea ice has made the Northern Sea Route feasible for commercial cargo ships between Europe and East Asia during a six-to-eight-week window in the summer months, shortening the voyage by thousands of miles compared to that through the Suez Canal. According to polar climate researchers, as the extent of the Arctic summer ice pack recedes the route will become passable without the help of icebreakers for a greater period each summer.

The Bremen-based Beluga Group claimed in 2009 to be the first Western company to attempt using the Northern Sea Route without assistance from icebreakers, cutting 4000 nautical miles off the journey between Ulsan, Korea and Rotterdam, the Netherlands.

Israel has declared that it will construct a railroad through the Negev desert to compete with the canal, with construction partly financed by China.

The opening of the canal created the first salt-water passage between the Mediterranean and the Red Sea. Although the Red Sea is about higher than the eastern Mediterranean, the current between the Mediterranean and the middle of the canal at the Bitter Lakes flows north in winter and south in summer. The current south of the Bitter Lakes is tidal, varying with the tide at Suez. The Bitter Lakes, which were hypersaline natural lakes, blocked the migration of Red Sea species into the Mediterranean for many decades, but as the salinity of the lakes gradually equalised with that of the Red Sea the barrier to migration was removed, and plants and animals from the Red Sea have begun to colonise the eastern Mediterranean. The Red Sea is generally saltier and more nutrient-poor than the Atlantic, so the Red Sea species have advantages over Atlantic species in the less salty and nutrient-rich eastern Mediterranean. Accordingly, most Red Sea species invade the Mediterranean biota, and only few do the opposite. This migratory phenomenon is called Lessepsian migration (after Ferdinand de Lesseps) or "Erythrean invasion". Also impacting the eastern Mediterranean, starting in 1968, was the operation of Aswan High Dam across the Nile. While providing for increased human development, the project reduced the inflow of freshwater and ended all natural nutrient-rich silt entering the eastern Mediterranean at the Nile Delta. This provided less natural dilution of Mediterranean salinity and ended the higher levels of natural turbidity, additionally making conditions more like those in the Red Sea.

Invasive species originating from the Red Sea and introduced into the Mediterranean by the canal have become a major component of the Mediterranean ecosystem and have serious impacts on the ecology, endangering many local and endemic species. About 300 species from the Red Sea have been identified in the Mediterranean, and there are probably others yet unidentified. The Egyptian government's intent to enlarge the canal has raised concerns from marine biologists, fearing that this will worsen the invasion of Red Sea species.

Construction of the canal was preceded by cutting a small fresh-water canal called Sweet Water Canal from the Nile delta along Wadi Tumilat to the future canal, with a southern branch to Suez and a northern branch to Port Said. Completed in 1863, these brought fresh water to a previously arid area, initially for canal construction, and subsequently facilitating growth of agriculture and settlements along the canal.

The Suez Canal Economic Zone, sometimes shortened to the Suez Canal Zone, describes the set of locations neighbouring the canal where customs rates have been reduced to zero in order to attract investment. The zone comprises over 600km² within the governorates of Port Said, Ismailia and Suez. Projects in the zone are collectively described as the Suez Canal Area Development Project (SCADP).

The plan focuses on development of East Port Said and the port of Ain Sokhna, and hopes to extend to four more ports at West Port Said, El-Adabiya, Arish and El Tor.

The zone incorporates the three "Qualifying Industrial Zones" at Port Said, Ismailia and Suez, a 1996 American initiative to encourage economic ties between Israel and its neighbours.




</doc>
<doc id="29324" url="https://en.wikipedia.org/wiki?curid=29324" title="Signal processing">
Signal processing

Signal processing concerns the analysis, synthesis, and modification of signals, which are broadly defined as functions conveying "information about the behavior or attributes of some phenomenon", such as sound, images, and biological measurements. For example, signal processing techniques are used to improve signal transmission fidelity, storage efficiency, and subjective quality, and to emphasize or detect components of interest in a measured signal.

According to Alan V. Oppenheim and Ronald W. Schafer, the principles of signal processing can be found in the classical numerical analysis techniques of the 17th century. Oppenheim and Schafer further state that the digital refinement of these techniques can be found in the digital control systems of the 1940s and 1950s.


In communication systems, signal processing may occur at:



Analog signal processing is for signals that have not been digitized, as in legacy radio, telephone, radar, and television systems. This involves linear electronic circuits as well as non-linear ones. The former are, for instance, passive filters, active filters, additive mixers, integrators and delay lines. Non-linear circuits include compandors, multiplicators (frequency mixers and voltage-controlled amplifiers), voltage-controlled filters, voltage-controlled oscillators and phase-locked loops.

Continuous-time signal processing is for signals that vary with the change of continuous domain(without considering some individual interrupted points).

The methods of signal processing include time domain, frequency domain, and complex frequency domain. This technology mainly discusses the modeling of linear time-invariant continuous system, integral of the system's zero-state response, setting up system function and the continuous time filtering of deterministic signals

Discrete-time signal processing is for sampled signals, defined only at discrete points in time, and as such are quantized in time, but not in magnitude.

"Analog discrete-time signal processing" is a technology based on electronic devices such as sample and hold circuits, analog time-division multiplexers, analog delay lines and analog feedback shift registers. This technology was a predecessor of digital signal processing (see below), and is still used in advanced processing of gigahertz signals.

The concept of discrete-time signal processing also refers to a theoretical discipline that establishes a mathematical basis for digital signal processing, without taking quantization error into consideration.

Digital signal processing is the processing of digitized discrete-time sampled signals. Processing is done by general-purpose computers or by digital circuits such as ASICs, field-programmable gate arrays or specialized digital signal processors (DSP chips). Typical arithmetical operations include fixed-point and floating-point, real-valued and complex-valued, multiplication and addition. Other typical operations supported by the hardware are circular buffers and lookup tables. Examples of algorithms are the Fast Fourier transform (FFT), finite impulse response (FIR) filter, Infinite impulse response (IIR) filter, and adaptive filters such as the Wiener and Kalman filters.

Nonlinear signal processing involves the analysis and processing of signals produced from nonlinear systems and can be in the time, frequency, or spatio-temporal domains. Nonlinear systems can produce highly complex behaviors including bifurcations, chaos, harmonics, and subharmonics which cannot be produced or analyzed using linear methods.

Statistical signal processing is an approach which treats signals as stochastic processes, utilizing their statistical properties to perform signal processing tasks. Statistical techniques are widely used in signal processing applications. For example, one can model the probability distribution of noise incurred when photographing an image, and construct techniques based on this model to reduce the noise in the resulting image.




</doc>
<doc id="29328" url="https://en.wikipedia.org/wiki?curid=29328" title="Six-Day War">
Six-Day War

The Six-Day War (Hebrew: , "Milhemet Sheshet Ha Yamim"; Arabic: , "an-Naksah", "The Setback" or , "Ḥarb 1967", "War of 1967"), also known as the June War, 1967 Arab–Israeli War, or Third Arab–Israeli War, was fought between 5 and 10 June 1967 by Israel and the neighboring states of Egypt (known at the time as the United Arab Republic), Jordan, and Syria.

Relations between Israel and its neighbours had never fully normalised following the 1948 Arab–Israeli War. In 1956 Israel invaded the Egyptian Sinai, with one of its objectives being the reopening of the Straits of Tiran which Egypt had blocked to Israeli shipping since 1950. Israel was subsequently forced to withdraw, but won a guarantee that the Straits of Tiran would remain open. While the United Nations Emergency Force was deployed along the border, there was no demilitarisation agreement.

In the period leading up to June 1967, tensions became dangerously heightened. Israel reiterated its post-1956 position that the closure of the straits of Tiran to its shipping would be a "casus belli". In May Egyptian President Gamal Abdel Nasser announced that the straits would be closed to Israeli vessels and then mobilised its Egyptian forces along its border with Israel. On 5 June, Israel launched what it claimed were a series of preemptive airstrikes against Egyptian airfields. Claims and counterclaims relating to this series of events are one of a number of controversies relating to the conflict.

The Egyptians were caught by surprise, and nearly the entire Egyptian air force was destroyed with few Israeli losses, giving the Israelis air supremacy. Simultaneously, the Israelis launched a ground offensive into the Gaza Strip and the Sinai, which again caught the Egyptians by surprise. After some initial resistance, Egyptian leader Gamal Abdel Nasser ordered the evacuation of the Sinai. Israeli forces rushed westward in pursuit of the Egyptians, inflicted heavy losses, and conquered the Sinai.

Nasser induced Syria and Jordan to begin attacks on Israel by using the initially confused situation to claim that Egypt had repelled the Israeli air strike. Israeli counterattacks resulted in the seizure of East Jerusalem as well as the West Bank from the Jordanians, while Israel's retaliation against Syria resulted in its occupation of the Golan Heights.

A ceasefire was signed on 11 June. In the aftermath of the war, Israel had crippled the Egyptian, Syrian and Jordanian militaries, having killed over 20,000 troops while only losing fewer than 1,000 of its own. The Israeli success was the result of a well-prepared and -enacted strategy, the poor leadership of the Arab states and their poor military leadership and strategy. Israel seized the Gaza Strip and the Sinai Peninsula from Egypt, the West Bank from Jordan and the Golan Heights from Syria. Israel's international standing greatly improved in the following years. Its victory humiliated Egypt, Jordan and Syria, leading Nasser to resign in shame; he was later reinstated after protests in Egypt against his resignation occurred. The speed and ease of Israel's victory would later lead to a dangerous overconfidence within the ranks of the Israel Defense Forces (IDF), contributing to initial Arab successes in the subsequent 1973 Yom Kippur War, although ultimately Israeli forces were successful and defeated the Arab militaries. The displacement of civilian populations resulting from the war would have long-term consequences, as 300,000 Palestinians fled the West Bank and about 100,000 Syrians left the Golan Heights to become refugees. Across the Arab world, Jewish minority communities fled or were expelled, with refugees going mainly to Israel or Europe.

After the 1956 Suez Crisis, Egypt agreed to the stationing of a United Nations Emergency Force (UNEF) in the Sinai to ensure all parties would comply with the 1949 Armistice Agreements. In the following years there were numerous minor border clashes between Israel and its Arab neighbors, particularly Syria. In early November 1966, Syria signed a mutual defense agreement with Egypt. Soon after this, in response to Palestine Liberation Organisation (PLO) guerilla activity, including a mine attack that left three dead, the Israeli Defence Force (IDF) attacked the village of as-Samu in the Jordanian-occupied West Bank. Jordanian units that engaged the Israelis were quickly beaten back. King Hussein of Jordan criticized Egyptian President Gamal Abdel Nasser for failing to come to Jordan's aid, and "hiding behind UNEF skirts".

In May 1967, Nasser received false reports from the Soviet Union that Israel was massing on the Syrian border. Nasser began massing his troops in two defensive lines in the Sinai Peninsula on Israel's border (16 May), expelled the UNEF force from Gaza and Sinai (19 May) and took over UNEF positions at Sharm el-Sheikh, overlooking the Straits of Tiran. Israel repeated declarations it had made in 1957 that any closure of the Straits would be considered an act of war, or justification for war, but Nasser closed the Straits to Israeli shipping on 22–23 May. After the war, U.S. President Lyndon Johnson commented:

On 30 May, Jordan and Egypt signed a defense pact. The following day, at Jordan's invitation, the Iraqi army began deploying troops and armoured units in Jordan. They were later reinforced by an Egyptian contingent. On 1 June, Israel formed a National Unity Government by widening its cabinet, and on 4 June the decision was made to go to war. The next morning, Israel launched Operation Focus, a large-scale surprise air strike that was the opening of the Six-Day War.

Before the war, Israeli pilots and ground crews had trained extensively in rapid refitting of aircraft returning from sorties, enabling a single aircraft to sortie up to four times a day (as opposed to the norm in Arab air forces of one or two sorties per day). This enabled the Israeli Air Force (IAF) to send several attack waves against Egyptian airfields on the first day of the war, overwhelming the Egyptian Air Force, and allowed it to knock out other Arab air forces on the same day. This has contributed to the Arab belief that the IAF was helped by foreign air forces (see Controversies relating to the Six-Day War). Pilots were extensively schooled about their targets, and were forced to memorize every single detail, and rehearsed the operation multiple times on dummy runways in total secrecy.

The Egyptians had constructed fortified defenses in the Sinai. These designs were based on the assumption that an attack would come along the few roads leading through the desert, rather than through the difficult desert terrain. The Israelis chose not to risk attacking the Egyptian defenses head-on, and instead surprised them from an unexpected direction.

James Reston, writing in "The New York Times" on 23 May 1967, noted, "In discipline, training, morale, equipment and general competence his [Nasser's] army and the other Arab forces, without the direct assistance of the Soviet Union, are no match for the Israelis. ... Even with 50,000 troops and the best of his generals and air force in Yemen, he has not been able to work his way in that small and primitive country, and even his effort to help the Congo rebels was a flop."

On the eve of the war, Israel believed it could win a war in 3–4 days. The United States estimated Israel would need 7–10 days to win, with British estimates supporting the U.S. view.

The Israeli army had a total strength, including reservists, of 264,000, though this number could not be sustained, as the reservists were vital to civilian life.

Against Jordan's forces on the West Bank, Israel deployed about 40,000 troops and 200 tanks (eight brigades). Israeli Central Command forces consisted of five brigades. The first two were permanently stationed near Jerusalem and were the Jerusalem Brigade and the mechanized Harel Brigade. Mordechai Gur's 55th Paratroopers Brigade was summoned from the Sinai front. The 10th Armored Brigade was stationed north of the West Bank. The Israeli Northern Command comprised a division of three brigades led by Major General Elad Peled which was stationed in the Jezreel Valley to the north of the West Bank.

On the eve of the war, Egypt massed approximately 100,000 of its 160,000 troops in the Sinai, including all seven of its divisions (four infantry, two armoured and one mechanized), four independent infantry brigades and four independent armoured brigades. Over a third of these soldiers were veterans of Egypt's continuing intervention into the North Yemen Civil War and another third were reservists. These forces had 950 tanks, 1,100 APCs, and more than 1,000 artillery pieces.

Syria's army had a total strength of 75,000 and was deployed along the border with Israel.

The Jordanian Armed Forces included 11 brigades, totalling 55,000 troops. Nine brigades (45,000 troops, 270 tanks, 200 artillery pieces) were deployed in the West Bank, including the elite armoured 40th, and two in the Jordan Valley. They possessed sizable numbers of M113 APCs and were equipped with some 300 modern Western tanks, 250 of which were U.S. M48 Pattons. They also had 12 battalions of artillery, six batteries of 81 mm and 120 mm mortars, a paratrooper battalion trained in the new U.S.-built school and a new battalion of mechanized infantry. The Jordanian Army, then known as the Arab Legion, was a long-term-service, professional army, relatively well-equipped and well-trained. Israeli post-war briefings said that the Jordanian staff acted professionally, but was always left "half a step" behind by the Israeli moves. The small Royal Jordanian Air Force consisted of only 24 British-made Hawker Hunter fighters, six transports, and two helicopters. According to the Israelis, the Hawker Hunter was essentially on par with the French-built Dassault Mirage III – the IAF's best plane.

100 Iraqi tanks and an infantry division were readied near the Jordanian border. Two squadrons of Iraqi fighter-aircraft, Hawker Hunters and MiG 21s, were rebased adjacent to the Jordanian border.

The Arab air forces were reinforced by some aircraft from Libya, Algeria, Morocco, Kuwait, and Saudi Arabia to make up for the massive losses suffered on the first day of the war. They were also aided by volunteer pilots from the Pakistan Air Force acting in an independent capacity. PAF pilots shot down several Israeli planes.

With the exception of Jordan, the Arabs relied principally on Soviet weaponry. Jordan's army was equipped with American weaponry, and its air force was composed of British aircraft.

Egypt had by far the largest and the most modern of all the Arab air forces, consisting of about 420 combat aircraft, all of them Soviet-built and with a heavy quota of top-of-the-line MiG-21s. Of particular concern to the Israelis were the 30 Tu-16 "Badger" medium bombers, capable of inflicting heavy damage on Israeli military and civilian centers.

Israeli weapons were mainly of Western origin. Its air force was composed principally of French aircraft, while its armoured units were mostly of British and American design and manufacture. Some infantry weapons, including the ubiquitous Uzi, were of Israeli origin.

Israel's first and most critical move was a surprise attack on the Egyptian Air Force. Initially, both Egypt and Israel announced that they had been attacked by the other country.

On 5 June at 7:45 Israeli time, as civil defense sirens sounded all over Israel, the IAF launched Operation Focus ("Moked"). All but 12 of its nearly 200 operational jets launched a mass attack against Egypt's airfields. The Egyptian defensive infrastructure was extremely poor, and no airfields were yet equipped with hardened aircraft shelters capable of protecting Egypt's warplanes. Most of the Israeli warplanes headed out over the Mediterranean Sea, flying low to avoid radar detection, before turning toward Egypt. Others flew over the Red Sea.

Meanwhile, the Egyptians hindered their own defense by effectively shutting down their entire air defense system: they were worried that rebel Egyptian forces would shoot down the plane carrying Field Marshal Abdel Hakim Amer and Lt-Gen. Sidqi Mahmoud, who were en route from al Maza to Bir Tamada in the Sinai to meet the commanders of the troops stationed there. In any event, it did not make a great deal of difference as the Israeli pilots came in below Egyptian radar cover and well below the lowest point at which its SA-2 surface-to-air missile batteries could bring down an aircraft.

Although the powerful Jordanian radar facility at Ajloun detected waves of aircraft approaching Egypt and reported the code word for "war" up the Egyptian command chain, Egyptian command and communications problems prevented the warning from reaching the targeted airfields. The Israelis employed a mixed-attack strategy: bombing and strafing runs against planes parked on the ground, and bombing to disable runways with special tarmac-shredding penetration bombs developed jointly with France, leaving surviving aircraft unable to take off. The runway at the Arish airfield was spared, as the Israelis expected to turn it into a military airport for their transports after the war. Surviving aircraft were taken out by later attack waves. The operation was more successful than expected, catching the Egyptians by surprise and destroying virtually all of the Egyptian Air Force on the ground, with few Israeli losses. Only four unarmed Egyptian training flights were in the air when the strike began. A total of 338 Egyptian aircraft were destroyed and 100 pilots were killed, although the number of aircraft lost by the Egyptians is disputed.

Among the Egyptian planes lost were all 30 Tu-16 bombers, 27 out of 40 Il-28 bombers, 12 Su-7 fighter-bombers, over 90 MiG-21s, 20 MiG-19s, 25 MiG-17 fighters, and around 32 assorted transport planes and helicopters. In addition, Egyptian radars and SAM missiles were also attacked and destroyed. The Israelis lost 19 planes, including two destroyed in air-to-air combat and 13 downed by anti-aircraft artillery. One Israeli plane, which was damaged and unable to break radio silence, was shot down by Israeli Hawk missiles after it strayed over the Negev Nuclear Research Center. Another was destroyed by an exploding Egyptian bomber.

The attack guaranteed Israeli air supremacy for the rest of the war. Attacks on other Arab air forces by Israel took place later in the day as hostilities broke out on other fronts.

The large numbers of Arab aircraft claimed destroyed by Israel on that day were at first regarded as "greatly exaggerated" by the Western press. However, the fact that the Egyptian Air Force, along with other Arab air forces attacked by Israel, made practically no appearance for the remaining days of the conflict proved that the numbers were most likely authentic. Throughout the war, Israeli aircraft continued strafing Arab airfield runways to prevent their return to usability. Meanwhile, Egyptian state-run radio had reported an Egyptian victory, falsely claiming that 70 Israeli planes had been downed on the first day of fighting.

The Egyptian forces consisted of seven divisions: four armoured, two infantry, and one mechanized infantry. Overall, Egypt had around 100,000 troops and 900–950 tanks in the Sinai, backed by 1,100 APCs and 1,000 artillery pieces. This arrangement was thought to be based on the Soviet doctrine, where mobile armour units at strategic depth provide a dynamic defense while infantry units engage in defensive battles.

Israeli forces concentrated on the border with Egypt included six armoured brigades, one infantry brigade, one mechanized infantry brigade, three paratrooper brigades, giving a total of around 70,000 men and 700 tanks, who were organized in three armoured divisions. They had massed on the border the night before the war, camouflaging themselves and observing radio silence before being ordered to advance.

The Israeli plan was to surprise the Egyptian forces in both timing (the attack exactly coinciding with the IAF strike on Egyptian airfields), location (attacking via northern and central Sinai routes, as opposed to the Egyptian expectations of a repeat of the 1956 war, when the IDF attacked via the central and southern routes) and method (using a combined-force flanking approach, rather than direct tank assaults).

On 5 June, at 7:50 a.m., the northernmost Israeli division, consisting of three brigades and commanded by Major General Israel Tal, one of Israel's most prominent armour commanders, crossed the border at two points, opposite Nahal Oz and south of Khan Yunis. They advanced swiftly, holding fire to prolong the element of surprise. Tal's forces assaulted the "Rafah Gap", a seven-mile stretch containing the shortest of three main routes through the Sinai towards El-Qantarah el-Sharqiyya and the Suez Canal. The Egyptians had four divisions in the area, backed by minefields, pillboxes, underground bunkers, hidden gun emplacements and trenches. The terrain on either side of the route was impassable. The Israeli plan was to hit the Egyptians at selected key points with concentrated armour.

Tal's advance was led by the 7th Armored Brigade under Colonel Shmuel Gonen. The Israeli plan called for the 7th Brigade to outflank Khan Yunis from the north and the 60th Armored Brigade under Colonel Menachem Aviram would advance from the south. The two brigades would link up and surround Khan Yunis, while the paratroopers would take Rafah. Gonen entrusted the breakthrough to a single battalion of his brigade.

Initially, the advance was met with light resistance, as Egyptian intelligence had concluded that it was a diversion for the main attack. However, as Gonen's lead battalion advanced, it suddenly came under intense fire and took heavy losses. A second battalion was brought up, but was also pinned down. Meanwhile, the 60th Brigade became bogged down in the sand, while the paratroopers had trouble navigating through the dunes. The Israelis continued to press their attack, and despite heavy losses, cleared the Egyptian positions and reached the Khan Yunis railway junction in little over four hours.

Gonen's brigade then advanced nine miles to Rafah in twin columns. Rafah itself was circumvented, and the Israelis attacked Sheikh Zuweid, eight miles to the southwest, which was defended by two brigades. Though inferior in numbers and equipment, the Egyptians were deeply entrenched and camouflaged. The Israelis were pinned down by fierce Egyptian resistance, and called in air and artillery support to enable their lead elements to advance. Many Egyptians abandoned their positions after their commander and several of his staff were killed.

The Israelis broke through with tank-led assaults. However, Aviram's forces misjudged the Egyptians' flank, and were pinned between strongholds before they were extracted after several hours. By nightfall, the Israelis had finished mopping up resistance. Israeli forces had taken significant losses, with Colonel Gonen later telling reporters that "we left many of our dead soldiers in Rafah, and many burnt-out tanks." The Egyptians suffered some 2,000 casualties and lost 40 tanks.

On 5 June, with the road open, Israeli forces continued advancing towards Arish. Already by late afternoon, elements of the 79th Armored Battalion had charged through the seven-mile long Jiradi defile, a narrow pass defended by well-emplaced troops of the Egyptian 112th Infantry Brigade. In fierce fighting, which saw the pass change hands several times, the Israelis charged through the position. The Egyptians suffered heavy casualties and tank losses, while Israeli losses stood at 66 dead, 93 wounded and 28 tanks. Emerging at the western end, Israeli forces advanced to the outskirts of Arish. As it reached the outskirts of Arish, Tal's division also consolidated its hold on Rafah and Khan Yunis.

The following day, 6 June, the Israeli forces on the outskirts of Arish were reinforced by the 7th Brigade, which fought its way through the Jiradi pass. After receiving supplies via an airdrop, the Israelis entered the city and captured the airport at 7:50 am. The Israelis entered the city at 8:00 am. Company commander Yossi Peled recounted that "Al-Arish was totally quiet, desolate. Suddenly, the city turned into a madhouse. Shots came at us from every alley, every corner, every window and house." An IDF record stated that "clearing the city was hard fighting. The Egyptians fired from the rooftops, from balconies and windows. They dropped grenades into our half-tracks and blocked the streets with trucks. Our men threw the grenades back and crushed the trucks with their tanks." Gonen sent additional units to Arish, and the city was eventually taken.

Brigadier-General Avraham Yoffe's assignment was to penetrate Sinai south of Tal's forces and north or Sharon's. Yoffe's attack allowed Tal to complete the capture of the Jiradi defile, Khan Yunis. All of them were taken after fierce fighting. Gonen subsequently dispatched a force of tanks, infantry and engineers under Colonel Yisrael Granit to continue down the Mediterranean coast towards the Suez Canal, while a second force led by Gonen himself turned south and captured Bir Lahfan and Jabal Libni.

Further south, on 6 June, the Israeli 38th Armored Division under Major-General Ariel Sharon assaulted Um-Katef, a heavily fortified area defended by the Egyptian 2nd Infantry Division under Major-General Sa'adi Nagib, and consisting of some 16,000 troops. The Egyptians also had a battalion of tank destroyers and a tank regiment, formed of Soviet World War II armour, which included 90 T-34-85 tanks, 22 SU-100 tank destroyers, and about 16,000 men. The Israelis had about 14,000 men and 150 post-World War II tanks including the AMX-13, Centurions, and M50 Super Shermans (modified M-4 Sherman tanks).

Two armoured brigades in the meantime, under Avraham Yoffe, slipped across the border through sandy wastes that Egypt had left undefended because they were considered impassable. Simultaneously, Sharon's tanks from the west were to engage Egyptian forces on Um-Katef ridge and block any reinforcements. Israeli infantry would clear the three trenches, while heliborne paratroopers would land behind Egyptian lines and silence their artillery. An armoured thrust would be made at al-Qusmaya to unnerve and isolate its garrison.
As Sharon's division advanced into the Sinai, Egyptian forces staged successful delaying actions at Tarat Umm, Umm Tarfa, and Hill 181. An Israeli jet was downed by anti-aircraft fire, and Sharon's forces came under heavy shelling as they advanced from the north and west. The Israeli advance, which had to cope with extensive minefields, took a large number of casualties. A column of Israeli tanks managed to penetrate the northern flank of Abu Ageila, and by dusk, all units were in position. The Israelis then brought up ninety 105 mm and 155 mm artillery guns for a preparatory barrage, while civilian buses brought reserve infantrymen under Colonel Yekutiel Adam and helicopters arrived to ferry the paratroopers. These movements were unobserved by the Egyptians, who were preoccupied with Israeli probes against their perimeter.

As night fell, the Israeli assault troops lit flashlights, each battalion a different color, to prevent friendly fire incidents. At 10:00 pm, Israeli artillery began a barrage on Um-Katef, firing some 6,000 shells in less than twenty minutes, the most concentrated artillery barrage in Israel's history. Israeli tanks assaulted the northernmost Egyptian defenses and were largely successful, though an entire armoured brigade was stalled by mines, and had only one mine-clearance tank. Israeli infantrymen assaulted the triple line of trenches in the east. To the west, paratroopers commanded by Colonel Danny Matt landed behind Egyptian lines, though half the helicopters got lost and never found the battlefield, while others were unable to land due to mortar fire. Those that successfully landed on target destroyed Egyptian artillery and ammunition dumps and separated gun crews from their batteries, sowing enough confusion to significantly reduce Egyptian artillery fire. Egyptian reinforcements from Jabal Libni advanced towards Um-Katef to counterattack, but failed to reach their objective, being subjected to heavy air attacks and encountering Israeli lodgements on the roads. Egyptian commanders then called in artillery attacks on their own positions. The Israelis accomplished and sometimes exceeded their overall plan, and had largely succeeded by the following day. The Egyptians took heavy casualties, while the Israelis lost 40 dead and 140 wounded.

Yoffe's attack allowed Sharon to complete the capture of the Um-Katef, after fierce fighting. The main thrust at Um-Katef was stalled due to mines and craters. After IDF engineers had cleared a path by 4:00 pm, Israeli and Egyptian tanks engaged in fierce combat, often at ranges as close as ten yards. The battle ended in an Israeli victory, with 40 Egyptian and 19 Israeli tanks destroyed. Meanwhile, Israeli infantry finished clearing out the Egyptian trenches, with Israeli casualties standing at 14 dead and 41 wounded and Egyptian casualties at 300 dead and 100 taken prisoner.

Further south, on 5 June, the 8th Armored Brigade under Colonel Albert Mandler, initially positioned as a ruse to draw off Egyptian forces from the real invasion routes, attacked the fortified bunkers at Kuntilla, a strategically valuable position whose capture would enable Mandler to block reinforcements from reaching Um-Katef and to join Sharon's upcoming attack on Nakhl. The defending Egyptian battalion, outnumbered and outgunned, fiercely resisted the attack, hitting a number of Israeli tanks. However, most of the defenders were killed, and only three Egyptian tanks, one of them damaged, survived. By nightfall, Mendler's forces had taken Kuntilla.

With the exceptions of Rafah and Khan Yunis, Israeli forces had initially avoided entering the Gaza Strip. Israeli Defense Minister Moshe Dayan had expressly forbidden entry into the area. After Palestinian positions in Gaza opened fire on the Negev settlements of Nirim and Kissufim, IDF Chief of Staff Yitzhak Rabin overrode Dayan's instructions and ordered the 11th Mechanized Brigade under Colonel Yehuda Reshef to enter the Strip. The force was immediately met with heavy artillery fire and fierce resistance from Palestinian forces and remnants of the Egyptian forces from Rafah.

By sunset, the Israelis had taken the strategically vital Ali Muntar ridge, overlooking Gaza City, but were beaten back from the city itself. Some 70 Israelis were killed, along with Israeli journalist Ben Oyserman and American journalist Paul Schutzer. Twelve members of UNEF were also killed. On the war's second day, 6 June, the Israelis were bolstered by the 35th Paratroopers Brigade under Colonel Rafael Eitan, and took Gaza City along with the entire Strip. The fighting was fierce, and accounted for nearly half of all Israeli casualties on the southern front. However, Gaza rapidly fell to the Israelis.

Meanwhile, on 6 June, two Israeli reserve brigades under Yoffe, each equipped with 100 tanks, penetrated the Sinai south of Tal's division and north of Sharon's, capturing the road junctions of Abu Ageila, Bir Lahfan, and Arish, taking all of them before midnight. Two Egyptian armoured brigades counterattacked, and a fierce battle took place until the following morning. The Egyptians were beaten back by fierce resistance coupled with airstrikes, sustaining heavy tank losses. They fled west towards Jabal Libni.

During the ground fighting, remnants of the Egyptian Air Force attacked Israeli ground forces, but took losses from the Israeli Air Force and from Israeli anti-aircraft units. Throughout the last four days, Egyptian aircraft flew 150 sorties against Israeli units in the Sinai.

Many of the Egyptian units remained intact and could have tried to prevent the Israelis from reaching the Suez Canal, or engaged in combat in the attempt to reach the canal. However, when the Egyptian Field Marshal Abdel Hakim Amer heard about the fall of Abu-Ageila, he panicked and ordered all units in the Sinai to retreat. This order effectively meant the defeat of Egypt.

Meanwhile, President Nasser, having learned of the results of the Israeli air strikes, decided together with Field Marshal Amer to order a general retreat from the Sinai within 24 hours. No detailed instructions were given concerning the manner and sequence of withdrawal.

As Egyptian columns retreated, Israeli aircraft and artillery attacked them. Israeli jets used napalm bombs during their sorties. The attacks destroyed hundreds of vehicles and caused heavy casualties. At Jabal Libni, retreating Egyptian soldiers were fired upon by their own artillery. At Bir Gafgafa, the Egyptians fiercely resisted advancing Israeli forces, knocking out three tanks and eight half-tracks, and killing 20 soldiers. Due to the Egyptians' retreat, the Israeli High Command decided not to pursue the Egyptian units but rather to bypass and destroy them in the mountainous passes of West Sinai.

Therefore, in the following two days ( 6 and 7 June), all three Israeli divisions (Sharon and Tal were reinforced by an armoured brigade each) rushed westwards and reached the passes. Sharon's division first went southward then westward, via An-Nakhl, to Mitla Pass with air support. It was joined there by parts of Yoffe's division, while its other units blocked the Gidi Pass. These passes became killing grounds for the Egyptians, who ran right into waiting Israeli positions and suffered heavy losses. According to Egyptian diplomat Mahmoud Riad, 10,000 men were killed in one day alone, and many others died from hunger and thirst. Tal's units stopped at various points to the length of the Suez Canal.

Israel's blocking action was partially successful. Only the Gidi pass was captured before the Egyptians approached it, but at other places, Egyptian units managed to pass through and cross the canal to safety. Due to the haste of the Egyptian retreat, soldiers often abandoned weapons, military equipment, and hundreds of vehicles. Many Egyptian soldiers were cut off from their units had to walk about 200 kilometers on foot before reaching the Suez Canal with limited supplies of food and water and were exposed to intense heat. Thousands of soldiers died as a result. Many Egyptian soldiers chose instead to surrender to the Israelis. However, the Israelis eventually exceeded their capabilities to provide for prisoners. As a result, they began directing soldiers towards the Suez Canal and only taking prisoner high-ranking officers, who were expected to be exchanged for captured Israeli pilots.

According to some accounts, during the Egyptian retreat from the Sinai, a unit of Soviet Marines based on a Soviet warship in Port Said at the time came ashore and attempted to cross the Suez Canal eastward. The Soviet force was reportedly decimated by an Israeli air attack and lost 17 dead and 34 wounded. Among the wounded was the commander, Lt. Col. Victor Shevchenko.

During the offensive, the Israeli Navy landed six combat divers from the Shayetet 13 naval commando unit to infiltrate Alexandria harbour. The divers sank an Egyptian minesweeper before being taken prisoner. Shayetet 13 commandos also infiltrated into Port Said harbour, but found no ships there. A planned commando raid against the Syrian Navy never materialized. Both Egyptian and Israeli warships made movements at sea to intimidate the other side throughout the war, but did not engage each other. However, Israeli warships and aircraft did hunt for Egyptian submarines throughout the war.

On 7 June, Israel began the conquest of Sharm el-Sheikh. The Israeli Navy started the operation with a probe of Egyptian naval defenses. An aerial reconnaissance flight found that the area was less defended than originally thought. At about 4:30 am, three Israeli missile boats opened fire on Egyptian shore batteries, while paratroopers and commandos boarded helicopters and Nord Noratlas transport planes for an assault on Al-Tur, as Chief of Staff Rabin was convinced it was too risky to land them directly in Sharm el-Sheikh. However, the city had been largely abandoned the day before, and reports from air and naval forces finally convinced Rabin to divert the aircraft to Sharm el-Sheikh. There, the Israelis engaged in a pitched battle with the Egyptians and took the city, killing 20 Egyptian soldiers and taking 8 prisoner. At 12:15 pm, Defense Minister Dayan announced that the Straits of Tiran constituted an international waterway open to all ships without restriction.

On 8 June, Israel completed the capture of the Sinai by sending infantry units to Ras Sudar on the western coast of the peninsula.

Several tactical elements made the swift Israeli advance possible: first, the surprise attack that quickly gave the Israeli Air Force complete air superiority over the Egyptian Air Force; second, the determined implementation of an innovative battle plan; third, the lack of coordination among Egyptian troops. These factors would prove to be decisive elements on Israel's other fronts as well.

Jordan was reluctant to enter the war. Nasser used the confusion of the first hours of the conflict to convince King Hussein that he was victorious; he claimed as evidence a radar sighting of a squadron of Israeli aircraft returning from bombing raids in Egypt, which he said was an Egyptian aircraft en route to attack Israel. One of the Jordanian brigades stationed in the West Bank was sent to the Hebron area in order to link with the Egyptians. Hussein decided to attack.

The IDF's strategic plan was to remain on the defensive along the Jordanian front, to enable focus in the expected campaign against Egypt.

Intermittent machine-gun exchanges began taking place in Jerusalem at 9:30 am, and the fighting gradually escalated as the Jordanians introduced mortar and recoilless rifle fire. Under the orders from General Narkis, the Israelis responded only with small-arms fire, firing in a flat trajectory to avoid hitting civilians, holy sites or the Old City. At 10:00 am on 5 June, the Jordanian Army began shelling Israel. Two batteries of 155 mm Long Tom cannons opened fire on the suburbs of Tel Aviv and Ramat David Airbase. The commanders of these batteries were instructed to lay a two-hour barrage against military and civilian settlements in central Israel. Some shells hit the outskirts of Tel Aviv.

By 10:30 am, Eshkol had sent a message via Odd Bull to King Hussein promising not to initiate any action against Jordan if it stayed out of the war. King Hussein replied that it was too late, "the die was cast". At 11:15 am, Jordanian howitzers began a 6,000-shell barrage at Israeli Jerusalem. The Jordanians initially targeted kibbutz Ramat Rachel in the south and Mount Scopus in the north, then ranged into the city center and outlying neighborhoods. Military installations, the Prime Minister's Residence, and the Knesset compound were also targeted. Israeli civilian casualties totalled 20 dead and about 1,000 wounded. Some 900 buildings were damaged, including Hadassah Ein Kerem Hospital.

At 11:50 am, sixteen Jordanian Hawker Hunters attacked Netanya, Kfar Sirkin and Kfar Saba, killing one civilian, wounding seven and destroying a transport plane. Three Iraqi Hawker Hunters strafed civilian settlements in the Jezreel Valley, and an Iraqi Tupolev Tu-16 attacked Afula, and was shot down near the Megiddo airfield. The attack caused minimal material damage, hitting only a senior citizens' home and several chicken coops, but sixteen Israeli soldiers were killed, most of them when the Tupolev crashed.

When the Israeli cabinet convened to decide what to do, Yigal Allon and Menahem Begin argued that this was an opportunity to take the Old City of Jerusalem, but Eshkol decided to defer any decision until Moshe Dayan and Yitzhak Rabin could be consulted. Uzi Narkiss made a number of proposals for military action, including the capture of Latrun, but the cabinet turned him down.
Dayan rejected multiple requests from Narkiss for permission to mount an infantry assault towards Mount Scopus. However, Dayan sanctioned a number of more limited retaliatory actions.

Shortly before 12:30 pm, the Israeli Air Force attacked Jordan's two airbases. The Hawker Hunters were refueling at the time of the attack. The Israeli aircraft attacked in two waves, the first of which cratered the runways and knocked out the control towers, and the second wave destroyed all 21 of Jordan's Hawker Hunter fighters, along with six transport aircraft and two helicopters. One Israeli jet was shot down by ground fire.

Israeli aircraft also attacked H-3, an Iraqi Air Force base in western Iraq. During the attack, 12 MiG-21s, 2 MiG-17s, 5 Hunter F6s, and 3 Il-28 bombers were destroyed or shot down. A Pakistani pilot stationed at the base shot down an Israeli fighter and a bomber during the raid. The Jordanian radar facility at Ajloun was destroyed in an Israeli airstrike. Israeli Fouga Magister jets attacked the Jordanian 40th Brigade with rockets as it moved south from the Damiya Bridge. Dozens of tanks were knocked out, and a convoy of 26 trucks carrying ammunition was destroyed. In Jerusalem, Israel responded to Jordanian shelling with a missile strike that devastated Jordanian positions. The Israelis used the L missile, a surface-to-surface missile developed jointly with France in secret.

A Jordanian battalion advanced up Government House ridge and dug in at the perimeter of Government House, the headquarters of the United Nations observers, and opened fire on Ramat Rachel, the Allenby Barracks and the Jewish section of Abu Tor with mortars and recoilless rifles. UN observers fiercely protested the incursion into the neutral zone, and several manhandled a Jordanian machine gun out of Government House after the crew had set it up in a second-floor window. After the Jordanians occupied Jabel Mukaber, an advance patrol was sent out and approached Ramat Rachel, where they came under fire from four civilians, including the wife of the director, who were armed with old Czech-made weapons.

The immediate Israeli response was an offensive to retake Government House and its ridge. The Jerusalem Brigade's Reserve Battalion 161, under Lieutenant-Colonel Asher Dreizin, was given the task. Dreizin had two infantry companies and eight tanks under his command, several of which broke down or became stuck in the mud at Ramat Rachel, leaving three for the assault. The Jordanians mounted fierce resistance, knocking out two tanks.

The Israelis broke through the compound's western gate and began clearing the building with grenades, before General Odd Bull, commander of the UN observers, compelled the Israelis to hold their fire, telling them that the Jordanians had already fled. The Israelis proceeded to take the Antenna Hill, directly behind Government House, and clear out a series of bunkers to the west and south. The fighting, often conducted hand-to-hand, continued for nearly four hours before the surviving Jordanians fell back to trenches held by the Hittin Brigade, which were steadily overwhelmed. By 6:30 pm, the Jordanians had retreated to Bethlehem, having suffered about 100 casualties. All but ten of Dreizin's soldiers were casualties, and Dreizin himself was wounded three times.

During the late afternoon of 5 June, the Israelis launched an offensive to encircle Jerusalem, which lasted into the following day. During the night, they were supported by intense tank, artillery and mortar fire to soften up Jordanian positions. Searchlights placed atop the Labor Federation building, then the tallest in Israeli Jerusalem, exposed and blinded the Jordanians. The Jerusalem Brigade moved south of Jerusalem, while the mechanized Harel Brigade and 55th Paratroopers Brigade under Mordechai Gur encircled it from the north.

A combined force of tanks and paratroopers crossed no-man's land near the Mandelbaum Gate. One of Gur's paratroop battalions approached the fortified Police Academy. The Israelis used bangalore torpedoes to blast their way through barbed wire leading up to the position while exposed and under heavy fire. With the aid of two tanks borrowed from the Jerusalem Brigade, they captured the Police Academy. After receiving reinforcements, they moved up to attack Ammunition Hill.

The Jordanian defenders, who were heavily dug-in, fiercely resisted the attack. All of the Israeli officers except for two company commanders were killed, and the fighting was mostly led by individual soldiers. The fighting was conducted at close quarters in trenches and bunkers, and was often hand-to-hand. The Israelis captured the position after four hours of heavy fighting. During the battle, 36 Israeli and 71 Jordanian soldiers were killed.

The battalion subsequently drove east, and linked up with the Israeli enclave on Mount Scopus and its Hebrew University campus. Gur's other battalions captured the other Jordanian positions around the American Colony, despite being short on men and equipment and having come under a Jordanian mortar bombardment while waiting for the signal to advance.

At the same time, the mechanized Harel Brigade attacked the fortress at Latrun, which the Jordanians had abandoned due to heavy Israeli tank fire. The brigade attacked Har Adar, but seven tanks were knocked out by mines, forcing the infantry to mount an assault without armoured cover. The Israeli soldiers advanced under heavy fire, jumping between stones to avoid mines. The fighting was conducted at close-quarters, often with knives and bayonets.

The Jordanians fell back after a battle that left two Israeli and eight Jordanian soldiers dead, and Israeli forces advanced through Beit Horon towards Ramallah, taking four fortified villages along the way. By the evening, the brigade arrived in Ramallah. Meanwhile, the 163rd Infantry Battalion secured Abu Tor following a fierce battle, severing the Old City from Bethlehem and Hebron.

Meanwhile, 600 Egyptian commandos stationed in the West Bank moved to attack Israeli airfields. Led by Jordanian intelligence scouts, they crossed the border and began infiltrating through Israeli settlements towards Ramla and Hatzor. They were soon detected and sought shelter in nearby fields, which the Israelis set on fire. Some 450 commandos were killed, and the remainder escaped to Jordan.

From the American Colony, the paratroopers moved towards the Old City. Their plan was to approach it via the lightly defended Salah al-Din Street. However, they made a wrong turn onto the heavily defended Nablus Road. The Israelis ran into fierce resistance. Their tanks fired at point-blank range down the street, while the paratroopers mounted repeated charges. Despite repelling repeated Israeli charges, the Jordanians gradually gave way to Israeli firepower and momentum. The Israelis suffered some 30 casualties – half the original force – while the Jordanians lost 45 dead and 142 wounded.

Meanwhile, the Israeli 71st Battalion breached barbed wire and minefields and emerged near Wadi Joz, near the base of Mount Scopus, from where the Old City could be cut off from Jericho and East Jerusalem from Ramallah. Israeli artillery targeted the one remaining route from Jerusalem to the West Bank, and shellfire deterred the Jordanians from counterattacking from their positions at Augusta-Victoria. An Israeli detachment then captured the Rockefeller Museum after a brief skirmish.

Afterwards, the Israelis broke through to the Jerusalem-Ramallah road. At Tel al-Ful, the Israelis fought a running battle with up to thirty Jordanian tanks. The Jordanians stalled the advance and destroyed a number of half-tracks, but the Israelis launched air attacks and exploited the vulnerability of the external fuel tanks mounted on the Jordanian tanks. The Jordanians lost half their tanks, and retreated towards Jericho. Joining up with the 4th Brigade, the Israelis then descended through Shuafat and the site of what is now French Hill, through Jordanian defenses at Mivtar, emerging at Ammunition Hill.
With Jordanian defenses in Jerusalem crumbling, elements of the Jordanian 60th Brigade and an infantry battalion were sent from Jericho to reinforce Jerusalem. Its original orders were to repel the Israelis from the Latrun corridor, but due to the worsening situation in Jerusalem, the brigade was ordered to proceed to Jerusalem's Arab suburbs and attack Mount Scopus. Parallel to the brigade were infantrymen from the Imam Ali Brigade, who were approaching Issawiya. The brigades were spotted by Israeli aircraft and decimated by rocket and cannon fire. Other Jordanian attempts to reinforce Jerusalem were beaten back, either by armoured ambushes or airstrikes.

Fearing damage to holy sites and the prospect of having to fight in built-up areas, Dayan ordered his troops not to enter the Old City. He also feared that Israel would be subjected to a fierce international backlash and the outrage of Christians worldwide if it forced its way into the Old City. Privately, he told David Ben-Gurion that he was also concerned over the prospect of Israel capturing Jerusalem's holy sites, only to be forced to give them up under the threat of international sanctions.

On 7 June, heavy fighting ensued. Dayan had ordered his troops not to enter the Old City; however, upon hearing that the UN was about to declare a ceasefire, he changed his mind, and without cabinet clearance, decided to capture it. Two paratroop battalions attacked Augusta-Victoria Hill, high ground overlooking the Old City from the east. One battalion attacked from Mount Scopus, and another attacked from the valley between it and the Old City. Another paratroop battalion, personally led by Gur, broke into the Old City, and was joined by the other two battalions after their missions were complete. The paratroopers met little resistance. The fighting was conducted solely by the paratroopers; the Israelis did not use armour during the battle out of fear of severe damage to the Old City.

In the north, one battalion from Peled's division was sent to check Jordanian defenses in the Jordan Valley. A brigade belonging to Peled's division captured the western part of the West Bank. One brigade attacked Jordanian artillery positions around Jenin, which were shelling Ramat David Airbase. The Jordanian 12th Armored Battalion, which outnumbered the Israelis, held off repeated attempts to capture Jenin. However, Israeli air attacks took their toll, and the Jordanian M48 Pattons, with their external fuel tanks, proved vulnerable at short distances, even to the Israeli-modified Shermans. Twelve Jordanian tanks were destroyed, and only six remained operational.
Just after dusk, Israeli reinforcements arrived. The Jordanians continued to fiercely resist, and the Israelis were unable to advance without artillery and air support. One Israeli jet attacked the Jordanian commander's tank, wounding him and killing his radio operator and intelligence officer. The surviving Jordanian forces then withdrew to Jenin, where they were reinforced by the 25th Infantry Brigade. The Jordanians were effectively surrounded in Jenin.

Jordanian infantry and their three remaining tanks managed to hold off the Israelis until 4:00 am, when three battalions arrived to reinforce them in the afternoon. The Jordanian tanks charged, and knocked out multiple Israeli vehicles, and the tide began to shift. After sunrise, Israeli jets and artillery conducted a two-hour bombardment against the Jordanians. The Jordanians lost 10 dead and 250 wounded, and had only seven tanks left, including two without gas, and sixteen APCs. The Israelis then fought their way into Jenin, and captured the city after fierce fighting.

After the Old City fell, the Jerusalem Brigade reinforced the paratroopers, and continued to the south, capturing Judea and Gush Etzion. Hebron was taken without any resistance. Fearful that Israeli soldiers would exact retribution for the 1929 massacre of the city's Jewish community, Hebron's residents flew white sheets from their windows and rooftops, and voluntarily gave up their weapons. The Harel Brigade proceeded eastward, descending to the Jordan River.

On 7 June, Israeli forces seized Bethlehem, taking the city after a brief battle that left some 40 Jordanian soldiers dead, with the remainder fleeing. On the same day, one of Peled's brigades seized Nablus; then it joined one of Central Command's armoured brigades to fight the Jordanian forces; as the Jordanians held the advantage of superior equipment and were equal in numbers to the Israelis.

Again, the air superiority of the IAF proved paramount as it immobilized the Jordanians, leading to their defeat. One of Peled's brigades joined with its Central Command counterparts coming from Ramallah, and the remaining two blocked the Jordan river crossings together with the Central Command's 10th. Engineering Corps sappers blew up the Abdullah and Hussein bridges with captured Jordanian mortar shells, while elements of the Harel Brigade crossed the river and occupied positions along the east bank to cover them, but quickly pulled back due to American pressure. The Jordanians, anticipating an Israeli offensive deep into Jordan, assembled the remnants of their army and Iraqi units in Jordan to protect the western approaches to Amman and the southern slopes of the Golan Heights.

No specific decision had been made to capture any other territories controlled by Jordan. After the Old City was captured, Dayan told his troops to dig in to hold it. When an armoured brigade commander entered the West Bank on his own initiative, and stated that he could see Jericho, Dayan ordered him back. It was only after intelligence reports indicated that Hussein had withdrawn his forces across the Jordan River that Dayan ordered his troops to capture the West Bank. According to Narkis:
First, the Israeli government had no intention of capturing the West Bank. On the contrary, it was opposed to it. Second, there was not any provocation on the part of the IDF. Third, the rein was only loosened when a real threat to Jerusalem's security emerged. This is truly how things happened on June 5, although it is difficult to believe. The end result was something that no one had planned.

In May–June 1967, the Israeli government did everything in its power to confine the confrontation to the Egyptian front. Eshkol and his colleagues took into account the possibility of some fighting on the Syrian front.

False Egyptian reports of a crushing victory against the Israeli army and forecasts that Egyptian forces would soon be attacking Tel Aviv influenced Syria's decision to enter the war. Syrian artillery began shelling northern Israel, and twelve Syrian jets attacked Israeli settlements in the Galilee. Israeli fighter jets intercepted the Syrian aircraft, shooting down three and driving off the rest. In addition, two Lebanese Hawker Hunter jets, two of the twelve Lebanon had, crossed into Israeli airspace and began strafing Israeli positions in the Galilee. They were intercepted by Israeli fighter jets, and one was shot down.
A minor Syrian force tried to capture the water plants at Tel Dan (the subject of a fierce escalation two years earlier), Dan, and She'ar Yashuv. These attacks were repulsed with the loss of twenty soldiers and seven tanks. An Israeli officer was also killed. But a broader Syrian offensive quickly failed. Syrian reserve units were broken up by Israeli air attacks, and several tanks were reported to have sunk in the Jordan River.

Other problems included tanks being too wide for bridges, lack of radio communications between tanks and infantry, and units ignoring orders to advance. A post-war Syrian army report concluded:

Our forces did not go on the offensive either because they did not arrive or were not wholly prepared or because they could not find shelter from the enemy's planes. The reserves could not withstand the air attacks; they dispersed after their morale plummeted.

The Syrians abandoned hopes of a ground attack and began a massive bombardment of Israeli communities in the Hula Valley instead.

On the evening of 5 June, the Israeli Air Force attacked Syrian airfields. The Syrian Air Force lost some 32 MiG 21s, 23 MiG-15 and MiG-17 fighters, and two Ilyushin Il-28 bombers, two-thirds of its fighting strength. The Syrian aircraft that survived the attack retreated to distant bases and played no further role in the war. Following the attack, Syria realised that the news it had received from Egypt of the near-total destruction of the Israeli military could not have been true.

On 7 and 8 June, the Israeli leadership debated about whether to attack the Golan Heights as well. Syria had supported pre-war raids that had helped raise tensions and had routinely shelled Israel from the Heights, so some Israeli leaders wanted to see Syria punished. Military opinion was that the attack would be extremely costly, since it would entail an uphill battle against a strongly fortified enemy. The western side of the Golan Heights consists of a rock escarpment that rises 500 meters (1,700 ft) from the Sea of Galilee and the Jordan River, and then flattens to a gently sloping plateau. Dayan opposed the operation bitterly at first, believing such an undertaking would result in losses of 30,000 and might trigger Soviet intervention. Prime Minister Eshkol, on the other hand, was more open to the possibility, as was the head of the Northern Command, David Elazar, whose unbridled enthusiasm for and confidence in the operation may have eroded Dayan's reluctance.

Eventually, the situation on the Southern and Central fronts cleared up, intelligence estimated that the likelihood of Soviet intervention had been reduced, reconnaissance showed some Syrian defenses in the Golan region collapsing, and an intercepted cable revealed that Nasser was urging the President of Syria to immediately accept a cease-fire. At 3 am on 9 June, Syria announced its acceptance of the cease-fire. Despite this announcement, Dayan became more enthusiastic about the idea and four hours later at 7 am, "gave the order to go into action against Syria" without consultation or government authorisation.

The Syrian army consisted of about 75,000 men grouped in nine brigades, supported by an adequate amount of artillery and armour. Israeli forces used in combat consisted of two brigades (the 8th Armored Brigade and the Golani Brigade) in the northern part of the front at Givat HaEm, and another two (infantry and one of Peled's brigades summoned from Jenin) in the center. The Golan Heights' unique terrain (mountainous slopes crossed by parallel streams every several kilometers running east to west), and the general lack of roads in the area channeled both forces along east-west axes of movement and restricted the ability of units to support those on either flank. Thus the Syrians could move north-south on the plateau itself, and the Israelis could move north-south at the base of the Golan escarpment. An advantage Israel possessed was the excellent intelligence collected by Mossad operative Eli Cohen (who was captured and executed in Syria in 1965) regarding the Syrian battle positions. Syria had built extensive defensive fortifications in depths up to 15 kilometers, comparable to the Maginot Line.

As opposed to all the other campaigns, IAF was only partially effective in the Golan because the fixed fortifications were so effective. However, the Syrian forces proved unable to put up effective defense largely because the officers were poor leaders and treated their soldiers badly; often officers would retreat from danger, leaving their men confused and ineffective. The Israelis also had the upper hand during close combat that took place in the numerous Syrian bunkers along the Golan Heights, as they were armed with the Uzi, a submachine gun designed for close combat, while Syrian soldiers were armed with the heavier AK-47 assault rifle, designed for combat in more open areas.

On the morning of 9 June, Israeli jets began carrying out dozens of sorties against Syrian positions from Mount Hermon to Tawfiq, using rockets salvaged from captured Egyptian stocks. The airstrikes knocked out artillery batteries and storehouses and forced transport columns off the roads. The Syrians suffered heavy casualties and a drop in morale, with a number of senior officers and troops deserting. The attacks also provided time as Israeli forces cleared paths through Syrian minefields. However, the airstrikes did not seriously damage the Syrians' bunkers and trench systems, and the bulk of Syrian forces on the Golan remained in their positions.

About two hours after the airstrikes began, the 8th Armored Brigade, led by Colonel Albert Mandler, advanced into the Golan Heights from Givat HaEm. Its advance was spearheaded by Engineering Corps sappers and eight bulldozers, which cleared away barbed wire and mines. As they advanced, the force came under fire, and five bulldozers were immediately hit. The Israeli tanks, with their maneuverability sharply reduced by the terrain, advanced slowly under fire toward the fortified village of Sir al-Dib, with their ultimate objective being the fortress at Qala. Israeli casualties steadily mounted. Part of the attacking force lost its way and emerged opposite Za'ura, a redoubt manned by Syrian reservists. With the situation critical, Colonel Mandler ordered simultaneous assaults on Za'ura and Qala. Heavy and confused fighting followed, with Israeli and Syrian tanks struggling around obstacles and firing at extremely short ranges. Mandler recalled that "the Syrians fought well and bloodied us. We beat them only by crushing them under our treads and by blasting them with our cannons at very short range, from 100 to 500 meters." The first three Israeli tanks to enter Qala were stopped by a Syrian bazooka team, and a relief column of seven Syrian tanks arrived to repel the attackers. The Israelis took heavy fire from the houses, but could not turn back, as other forces were advancing behind them, and they were on a narrow path with mines on either side. The Israelis continued pressing forward, and called for air support. A pair of Israeli jets destroyed two of the Syrian tanks, and the remainder withdrew. The surviving defenders of Qala retreated after their commander was killed. Meanwhile, Za'ura fell in an Israeli assault, and the Israelis also captured the 'Ein Fit fortress.

In the central sector, the Israeli 181st Battalion captured the strongholds of Dardara and Tel Hillal after fierce fighting. Desperate fighting also broke out along the operation's northern axis, where Golani Brigade attacked thirteen Syrian positions, including the formidable Tel Fakhr position. Navigational errors placed the Israelis directly under the Syrians' guns. In the fighting that followed, both sides took heavy casualties, with the Israelis losing all nineteen of their tanks and half-tracks. The Israeli battalion commander then ordered his twenty-five remaining men to dismount, divide into two groups, and charge the northern and southern flanks of Tel Fakhr. The first Israelis to reach the perimeter of the southern approach laid bodily down on the barbed wire, allowing their comrades to vault over them. From there, they assaulted the fortified Syrian positions. The fighting was waged at extremely close quarters, often hand-to-hand.

On the northern flank, the Israelis broke through within minutes and cleared out the trenches and bunkers. During the seven-hour battle, the Israelis lost 31 dead and 82 wounded, while the Syrians lost 62 dead and 20 captured. Among the dead was the Israeli battalion commander. The Golani Brigade's 51st Battalion took Tel 'Azzaziat, and Darbashiya also fell to Israeli forces.
By the evening of 9 June, the four Israeli brigades had all broken through to the plateau, where they could be reinforced and replaced. Thousands of reinforcements began reaching the front, those tanks and half-tracks that had survived the previous day's fighting were refueled and replenished with ammunition, and the wounded were evacuated. By dawn, the Israelis had eight brigades in the sector.

Syria's first line of defense had been shattered, but the defenses beyond that remained largely intact. Mount Hermon and the Banias in the north, and the entire sector between Tawfiq and Customs House Road in the south remained in Syrian hands. In a meeting early on the night of 9 June, Syrian leaders decided to reinforce those positions as quickly as possible, and to maintain a steady barrage on Israeli civilian settlements.

Throughout the night, the Israelis continued their advance. Though it was slowed by fierce resistance, an anticipated Syrian counterattack never materialized. At the fortified village of Jalabina, a garrison of Syrian reservists, leveling their anti-aircraft guns, held off the Israeli 65th Paratroop Battalion for four hours before a small detachment managed to penetrate the village and knock out the heavy guns.

Meanwhile, the 8th Brigade's tanks moved south from Qala, advancing six miles to Wasit under heavy artillery and tank bombardment. At the Banias in the north, Syrian mortar batteries opened fire on advancing Israeli forces only after Golani Brigade sappers cleared a path through a minefield, killing sixteen Israeli soldiers and wounding four.

On the next day, 10 June, the central and northern groups joined in a pincer movement on the plateau, but that fell mainly on empty territory as the Syrian forces retreated. At 8:30 am, the Syrians began blowing up their own bunkers, burning documents and retreating. Several units joined by Elad Peled's troops climbed to the Golan from the south, only to find the positions mostly empty. When the 8th Brigade reached Mansura, five miles from Wasit, the Israelis met no opposition and found abandoned equipment, including tanks, in perfect working condition. In the fortified Banias village, Golani Brigade troops found only several Syrian soldiers chained to their positions.

During the day, the Israeli units stopped after obtaining manoeuvre room between their positions and a line of volcanic hills to the west. In some locations, Israeli troops advanced after an agreed-upon cease-fire to occupy strategically strong positions. To the east, the ground terrain is an open gently sloping plain. This position later became the cease-fire line known as the "Purple Line".

"Time" magazine reported: "In an effort to pressure the United Nations into enforcing a ceasefire, Damascus Radio undercut its own army by broadcasting the fall of the city of Quneitra three hours before it actually capitulated. That premature report of the surrender of their headquarters destroyed the morale of the Syrian troops left in the Golan area."

By 10 June, Israel had completed its final offensive in the Golan Heights, and a ceasefire was signed the day after. Israel had seized the Gaza Strip, the Sinai Peninsula, the West Bank of the Jordan River (including East Jerusalem), and the Golan Heights. About one million Arabs were placed under Israel's direct control in the newly captured territories. Israel's strategic depth grew to at least 300 kilometers in the south, 60 kilometers in the east, and 20 kilometers of extremely rugged terrain in the north, a security asset that would prove useful in the Yom Kippur War six years later.

Speaking three weeks after the war ended, as he accepted an honorary degree from Hebrew University, Yitzhak Rabin gave his reasoning behind the success of Israel:

In recognition of contributions, Rabin was given the honour of naming the war for the Israelis. From the suggestions proposed, including the "War of Daring", "War of Salvation", and "War of the Sons of Light", he "chose the least ostentatious, the Six-Day War, evoking the days of creation".

Dayan's final report on the war to the Israeli general staff listed several shortcomings in Israel's actions, including misinterpretation of Nasser's intentions, overdependence on the United States, and reluctance to act when Egypt closed the Straits. He also credited several factors for Israel's success: Egypt did not appreciate the advantage of striking first and their adversaries did not accurately gauge Israel's strength and its willingness to use it.

In Egypt, according to Heikal, Nasser had admitted his responsibility for the military defeat in June 1967. According to historian Abd al-Azim Ramadan, Nasser's mistaken decisions to expel the international peacekeeping force from the Sinai Peninsula and close the Straits of Tiran in 1967 led to a state of war with Israel, despite Egypt's lack of military preparedness.

After the 1973 Yom Kippur War, Egypt reviewed the causes of its loss of the 1967 war. Issues that were identified included "the individualistic bureaucratic leadership"; "promotions on the basis of loyalty, not expertise, and the army's fear of telling Nasser the truth"; lack of intelligence; and better Israeli weapons, command, organization, and will to fight.

Between 776 and 983 Israelis were killed and 4,517 were wounded. Fifteen Israeli soldiers were captured. Arab casualties were far greater. Between 9,800 and 15,000 Egyptian soldiers were listed as killed or missing in action. An additional 4,338 Egyptian soldiers were captured. Jordanian losses are estimated to be 700 killed in action with another 2,500 wounded. The Syrians were estimated to have sustained between 1,000 and 2,500 killed in action. Between 367 and 591 Syrians were captured.

At the commencement of hostilities, both Egypt and Israel announced that they had been attacked by the other country. The Israeli government later abandoned its initial position, acknowledging Israel had struck first, claiming that it was a preemptive strike in the face of a planned invasion by Egypt. On the other hand, the Arab view was that it was unjustified to attack Egypt. Many commentators consider the war as the classic case of anticipatory attack in self-defense.

It has been alleged that Nasser did not want Egypt to learn of the true extent of his defeat and so ordered the killing of Egyptian army stragglers making their way back to the Suez canal zone. There have also been allegations from both Israeli and Egyptian sources that Israeli troops killed unarmed Egyptian prisoners.

There have been a number of allegations of direct military support of Israel during the war by the US and the UK, including the supply of equipment (despite an embargo) and the participation of US forces in the conflict. Many of these allegations and conspiracy theories have been disputed and it has been claimed that some were given currency in the Arab world to explain the Arab defeat.
It has also been claimed that the Soviet Union, in support of its Arab allies, used its naval strength in the Mediterranean to act as a major restraint on the US Navy.

America features prominently in Arab conspiracy theories purporting to explain the June 1967 defeat. Mohamed Hassanein Heikal, a confidant of Nasser, claims that President Lyndon B. Johnson was obsessed with Nasser and that Johnson conspired with Israel to bring him down. The reported Israeli troop movements seemed all the more threatening because they were perceived in the context of a US conspiracy against Egypt. Salah Bassiouny of the Foreign ministry, claims that Foreign Ministry saw the reported Israeli troop movements as credible because Israel had reached the level at which it could find strategic alliance with the United States. During the war, Cairo announced that American and British planes were participating in the Israeli attack. Nasser broke off diplomatic relations following this allegation. Nasser's image of the United States was such that he might well have believed the worst. However Anwar Sadat implied that Nasser used this deliberate conspiracy in order to accuse the United States as a political cover-up for domestic consumption. Lutfi Abd al-Qadir, the director of Radio Cairo during the late 1960s, who accompanied Nasser to his visits in Moscow, had his conspiracy theory that both the Soviets and the Western powers wanted to topple Nasser or to reduce his influence.

On 8 June 1967, USS "Liberty", a United States Navy electronic intelligence vessel sailing off Arish (just outside Egypt's territorial waters), was attacked by Israeli jets and torpedo boats, nearly sinking the ship, killing 34 sailors and wounding 171. Israel said the attack was a case of mistaken identity, and that the ship had been misidentified as the Egyptian vessel "El Quseir". Israel apologized for the mistake, and paid compensation to the victims or their families, and to the United States for damage to the ship. After an investigation, the U.S. accepted the explanation that the incident was friendly fire and the issue was closed by the exchange of diplomatic notes in 1987. Others however, including the then United States Secretary of State Dean Rusk, Chief of Naval Operations at the time, Admiral Thomas Moorer, some survivors of the attack and intelligence officials familiar with transcripts of intercepted signals on the day, have rejected these conclusions as unsatisfactory and maintain that the attack was made in the knowledge that the ship was American.

The political importance of the 1967 War was immense; Israel demonstrated that it was able and willing to initiate strategic strikes that could change the regional balance. Egypt and Syria learned tactical lessons and would launch an attack in 1973 in an attempt to reclaim their lost territory.

After following other Arab nations in declaring war, Mauritania remained in a declared state of war with Israel until about 1999. The United States imposed an embargo on new arms agreements to all Middle East countries, including Israel. The embargo remained in force until the end of the year, despite urgent Israeli requests to lift it.

Following the war, Israel experienced a wave of national euphoria, and the press praised the military's performance for weeks afterward. New "victory coins" were minted to celebrate. In addition, the world's interest in Israel grew, and the country's economy, which had been in crisis before the war, flourished due to an influx of tourists and donations, as well as the extraction of oil from the Sinai's wells. The aftermath of the war also saw a baby boom, which lasted for four years.

The aftermath of the war is also of religious significance. Under Jordanian rule, Jews were expelled from Jerusalem and were effectively barred from visiting the Western Wall, despite Article VIII of the 1949 Armistice Agreement demanded Israeli Jewish access to the Western Wall. Jewish holy sites were not maintained, and Jewish cemeteries had been desecrated. After the annexation to Israel, each religious group was granted administration over its holy sites. For the first time since 1948, Jews could visit the Old City of Jerusalem and pray at the Western Wall, the holiest site where Jews are permitted to pray, an event celebrated every year during Yom Yerushalayim. Despite the Temple Mount being the most important holy site in Jewish tradition, the al-Aqsa Mosque has been under sole administration of the Jordanian Muslim Waqf, and Jews are barred from praying on the Temple Mount, although they are allowed to visit it. In Hebron, Jews gained access to the Cave of the Patriarchs – the second most holy site in Judaism, after the Temple Mount – for the first time since the 14th century (previously Jews were allowed to pray only at the entrance). Other Jewish holy sites, such as Rachel's Tomb in Bethlehem and Joseph's Tomb in Nablus, also became accessible.

The war inspired the Jewish diaspora, which was swept up in overwhelming support for Israel. According to Michael Oren, the war enabled American Jews to "walk with their backs straight and flex their political muscle as never before. American Jewish organizations which had previously kept Israel at arms length suddenly proclaimed their Zionism." Thousands of Jewish immigrants arrived from Western countries such as the United States, United Kingdom, Canada, France, and South Africa after the war. Many of them returned to their countries of origin after a few years; one survey found that 58% of American Jews who immigrated to Israel between 1961 and 1972 returned to the US. Nevertheless, this immigration to Israel of Jews from Western countries, which was previously only a trickle, was a significant force for the first time. Most notably, the war stirred Zionist passions among Jews in the Soviet Union, who had by that time been forcibly assimilated. Many Soviet Jews subsequently applied for exit visas and began protesting for their right to immigrate to Israel. Following diplomatic pressure from the West, the Soviet government began granting exit visas to Jews in growing numbers. From 1970 to 1988, some 291,000 Soviet Jews were granted exit visas, of whom 165,000 immigrated to Israel and 126,000 immigrated to the United States. The great rise in Jewish pride in the wake of Israel's victory also fueled the beginnings of the baal teshuva movement. The war gave impetus to a Chabad campaign in which the Lubavitcher Rebbe directed his followers to put tefillin on Jewish men around world.

In the Arab nations, populations of minority Jews faced persecution and expulsion following the Israeli victory. According to historian and ambassador Michael B. Oren:
Mobs attacked Jewish neighborhoods in Egypt, Yemen, Lebanon, Tunisia, and Morocco, burning synagogues and assaulting residents. A pogrom in Tripoli, Libya, left 18 Jews dead and 25 injured; the survivors were herded into detention centers. Of Egypt's 4,000 Jews, 800 were arrested, including the chief rabbis of both Cairo and Alexandria, and their property sequestered by the government. The ancient communities of Damascus and Baghdad were placed under house arrest, their leaders imprisoned and fined. A total of 7,000 Jews were expelled, many with merely a satchel.

Following the war, a series of antisemitic purges began in Communist countries. Some 11,200 Jews from Poland immigrated to Israel during the 1968 Polish political crisis and the following year.

Following the war, Israel made an offer for peace that included the return of most of the recently captured territories. According to Chaim Herzog:

The 19 June Israeli cabinet decision did not include the Gaza Strip, and left open the possibility of Israel permanently acquiring parts of the West Bank. On 25–27 June, Israel incorporated East Jerusalem together with areas of the West Bank to the north and south into Jerusalem's new municipal boundaries.

The Israeli decision was to be conveyed to the Arab nations by the United States. The U.S. was informed of the decision, but not that it was to transmit it. There is no evidence of receipt from Egypt or Syria, and some historians claim that they may never have received the offer.

In September, the Khartoum Arab Summit resolved that there would be "no peace, no recognition and no negotiation with Israel". However, as Avraham Sela notes, the Khartoum conference effectively marked a shift in the perception of the conflict by the Arab states away from one centered on the question of Israel's legitimacy, toward one focusing on territories and boundaries. This was shown on 22 November when Egypt and Jordan accepted United Nations Security Council Resolution 242. Nasser forestalled any movement toward direct negotiations with Israel. In dozens of speeches and statements, Nasser posited the equation that any direct peace talks with Israel were tantamount to surrender.

After the war, the entire Soviet bloc of Eastern Europe (with the exception of Romania) broke off diplomatic relations with Israel.

The 1967 War laid the foundation for future discord in the region, as the Arab states resented Israel's victory and did not want to give up territory.

On 22 November 1967, the United Nations Security Council adopted Resolution 242, the "land for peace" formula, which called for Israeli withdrawal "from territories occupied" in 1967 and "the termination of all claims or states of belligerency". Resolution 242 recognized the right of "every state in the area to live in peace within secure and recognized boundaries free from threats or acts of force." Israel returned the Sinai to Egypt in 1978, after the Camp David Accords, and disengaged from the Gaza Strip in the summer of 2005. Its army frequently re-enters Gaza for military operations and still retains control of the seaports, airports and most of the border crossings.

There was extensive displacement of populations in the captured territories: of about one million Palestinians in the West Bank and Gaza, 300,000 (according to the United States Department of State) either fled, or were displaced from their homes, to Jordan, where they contributed to the growing unrest. The other 700,000 remained. In the Golan Heights, an estimated 80,000 Syrians fled. Israel allowed only the inhabitants of East Jerusalem and the Golan Heights to receive full Israeli citizenship, applying its law, administration and jurisdiction to these territories in 1967 and 1981, respectively. The vast majority of the populations in both territories declined to take citizenship. See also Israeli–Palestinian conflict and Golan Heights.

In his book "Righteous Victims" (1999), Israeli "New Historian" Benny Morris writes:
In addition, between 80,000 and 110,000 Syrians fled the Golan Heights, of which about 20,000 were from the city of Quneitra. According to more recent research by the Israeli daily "Haaretz", a total of 130,000 Syrian inhabitants fled or were expelled from the territory, most of them pushed out by the Israeli army.

Israel made peace with Egypt following the Camp David Accords of 1978 and completed a staged withdrawal from the Sinai in 1982. However, the position of the other occupied territories has been a long-standing and bitter cause of conflict for decades between Israel and the Palestinians, and the Arab world in general. Jordan and Egypt eventually withdrew their claims to sovereignty over the West Bank and Gaza, respectively. Israel and Jordan signed a peace treaty in 1994.

After the Israeli conquest of these newly acquired territories, the Gush Emunim movement launched a large settlement effort in these areas to secure a permanent foothold. There are now hundreds of thousands of Israeli settlers in the West Bank. They are a matter of controversy within Israel, both among the general population and within different political administrations, supporting them to varying degrees. Palestinians consider them a provocation. The Israeli settlements in Gaza were evacuated in August 2005 as a part of Israel's disengagement from Gaza.


1. 

3.
4. Lenczowski 1990, pp. 105–15, Citing Moshe Dayan, "Story of My Life", and Nadav Safran, "From War to War: The Arab–Israeli Confrontation, 1948–1967", p. 375 Israel clearly did not want the US government to know too much about its dispositions for attacking Syria, initially planned for June 8, but postponed for 24 hours. It should be pointed out that the attack on the Liberty occurred on June 8, whereas on June 9 at 3 am, Syria announced its acceptance of the cease-fire. Despite this, at 7 am, that is, four hours later, Israel's minister of defense, Moshe Dayan, "gave the order to go into action against Syria."





</doc>
<doc id="29329" url="https://en.wikipedia.org/wiki?curid=29329" title="Spectrum">
Spectrum

A spectrum (plural "spectra" or "spectrums") is a condition that is not limited to a specific set of values but can vary, without steps, across a continuum. The word was first used scientifically in optics to describe the rainbow of colors in visible light after passing through a prism. As scientific understanding of light advanced, it came to apply to the entire electromagnetic spectrum.

Spectrum has since been applied by analogy to topics outside optics. Thus, one might talk about the "spectrum of political opinion", or the "spectrum of activity" of a drug, or the "autism spectrum". In these uses, values within a spectrum may not be associated with precisely quantifiable numbers or definitions. Such uses imply a broad range of conditions or behaviors grouped together and studied under a single title for ease of discussion. Nonscientific uses of the term "spectrum" are sometimes misleading. For instance, a single left–right spectrum of political opinion does not capture the full range of people's political beliefs. Political scientists use a variety of biaxial and multiaxial systems to more accurately characterize political opinion.

In most modern usages of "spectrum" there is a unifying theme between the extremes at either end. This was not always true in older usage.

In Latin, "spectrum" means "image" or "apparition", including the meaning "spectre". Spectral evidence is testimony about what was done by spectres of persons not present physically, or hearsay evidence about what ghosts or apparitions of Satan said. It was used to convict a number of persons of witchcraft at Salem, Massachusetts in the late 17th century. The word "spectrum" [Spektrum] was strictly used to designate a ghostly optical afterimage by Goethe in his "Theory of Colors" and Schopenhauer in "On Vision and Colors".

The prefix "spectro-" is used to form words relating to spectra. For example, a spectrometer is a device used to record spectra and spectroscopy is the use of a spectrometer for chemical analysis.

In the 17th century, the word "spectrum" was introduced into optics by Isaac Newton, referring to the range of colors observed when white light was dispersed through a prism. Soon the term referred to a plot of light intensity or power as a function of frequency or wavelength, also known as a "spectral density plot".

The term "spectrum" was expanded to apply to other waves, such as sound waves that could also be measured as a function of frequency, frequency spectrum and power spectrum of a signal. The term now applies to any signal that can be measured or decomposed along a continuous variable such as energy in electron spectroscopy or mass-to-charge ratio in mass spectrometry. Spectrum is also used to refer to a graphical representation of the signal as a function of the dependent variable.

Electromagnetic spectrum refers to the full range of all frequencies of electromagnetic radiation and also to the characteristic distribution of electromagnetic radiation emitted or absorbed by that particular object. Devices used to measure an electromagnetic spectrum are called spectrograph or spectrometer. The visible spectrum is the part of the electromagnetic spectrum that can be seen by the human eye. The wavelength of visible light ranges from 390 to 700 nm. The absorption spectrum of a chemical element or chemical compound is the spectrum of frequencies or wavelengths of incident radiation that are absorbed by the compound due to electron transitions from a lower to a higher energy state. The emission spectrum refers to the spectrum of radiation emitted by the compound due to electron transitions from a higher to a lower energy state.

Light from many different sources contains various colors, each with its own brightness or intensity. A rainbow, or prism, sends these component colors in different directions, making them individually visible at different angles. A graph of the intensity plotted against the frequency (showing the brightness of each color) is the frequency spectrum of the light. When all the visible frequencies are present equally, the perceived color of the light is white, and the spectrum is a flat line. Therefore, flat-line spectra in general are often referred to as "white", whether they represent light or another type of wave phenomenon (sound, for example, or vibration in a structure).

In radio and telecommunications, the frequency spectrum can be shared among many different broadcasters. The radio spectrum is the part of the electromagnetic spectrum corresponding to frequencies lower below 300 GHz, which corresponds to wavelengths longer than about 1 mm. The microwave spectrum corresponds to frequencies between 300 MHz (0.3 GHz) and 300 GHz and wavelengths between one meter and one millimeter. Each broadcast radio and TV station transmits a wave on an assigned frequency range, called a "channel". When many broadcasters are present, the radio spectrum consists of the sum of all the individual channels, each carrying separate information, spread across a wide frequency spectrum. Any particular radio receiver will detect a single function of amplitude (voltage) vs. time. The radio then uses a tuned circuit or tuner to select a single channel or frequency band and demodulate or decode the information from that broadcaster. If we made a graph of the strength of each channel vs. the frequency of the tuner, it would be the frequency spectrum of the antenna signal.

In astronomical spectroscopy, the strength, shape, and position of absorption and emission lines, as well as the overall spectral energy distribution of the continuum, reveal many properties of astronomical objects. Stellar classification is the categorisation of stars based on their characteristic electromagnetic spectra. The spectral flux density is used to represent the spectrum of a light-source, such as a star. 

In radiometry and colorimetry (or color science more generally), the spectral power distribution (SPD) of a light source is a measure of the power contributed by each frequency or color in a light source. The light spectrum is usually measured at points (often 31) along the visible spectrum, in wavelength space instead of frequency space, which makes it not strictly a spectral density. Some spectrophotometers can measure increments as fine as one to two nanometers. the values are used to calculate other specifications and then plotted to show the spectral attributes of the source. This can be helpful in analyzing the color characteristics of a particular source.

A mass spectrum is a plot of ion abundance as a function of mass-to-charge ratio that is obtained by a mass spectrometer instrument. The mass spectrum can be used to determine the quantity and mass of atoms and molecules. Tandem mass spectrometry spectra are used to determine molecular structure.

In physics, the energy spectrum of a particle is the number of particles or intensity of a particle beam as a function of particle energy. Examples of techniques that produce an energy spectrum are alpha-particle spectroscopy, electron energy loss spectroscopy, and mass-analyzed ion-kinetic-energy spectrometry.

In physics, particularly in quantum mechanics, some differential operators have discrete spectra, with gaps between values. Common cases include the Hamiltonian and the angular momentum operator.

In acoustics, a spectrogram is a visual representation of the frequency spectrum of sound as a function of time or another variable.

A source of sound can have many different frequencies mixed. A Musical tone's timbre is characterized by its harmonic spectrum. Sound in our environment that we refer to as "noise" includes many different frequencies. When a sound signal contains a mixture of all audible frequencies, distributed equally over the audio spectrum, it is called white noise.

The spectrum analyzer is an instrument which can be used to convert the sound wave of the musical note into a visual display of the constituent frequencies. This visual display is referred to as an acoustic spectrogram. Software based audio spectrum analyzers are available at low cost, providing easy access not only to industry professionals, but also to academics, students and the hobbyist. The acoustic spectrogram generated by the spectrum analyzer provides an acoustic signature of the musical note. In addition to revealing the fundamental frequency and its overtones, the spectrogram is also useful for analysis of the temporal attack, decay, sustain, and release of the musical note.

Antibiotic spectrum of activity is a component of antibiotic classification. A broad-spectrum antibiotic is active against a wide range of bacteria, whereas a narrow-spectrum antibiotic is effective against specific families of bacteria. An example of a commonly used broad-spectrum antibiotic is ampicillin. An example of a narrow spectrum antibiotic is Dicloxacillin, which acts on beta-lactamase-producing Gram-positive bacteria such as "Staphylococcus aureus".

In psychiatry, the spectrum approach uses the term spectrum to describe a range of linked conditions, sometimes also extending to include singular symptoms and traits. For example, the autism spectrum describes a range of conditions classified as neurodevelopmental disorders.

In mathematics, the spectrum of a matrix is the multiset of the eigenvalues of the matrix.

In functional analysis, the concept of the spectrum of a bounded operator is a generalization of the eigenvalue concept for matrices.

In algebraic topology, a spectrum is an object representing a generalized cohomology theory.

In social science, economic spectrum is used to indicate the range of social class along some indicator of wealth or income. In political science, the term political spectrum refers to a system of classifying political positions in one or more dimensions, for example in a range including right wing and left wing.


</doc>
<doc id="29330" url="https://en.wikipedia.org/wiki?curid=29330" title="Social dynamics">
Social dynamics

Social dynamics can refer to the behavior of groups that results from the interactions of individual group members as well to the study of the relationship between individual interactions and group level behaviors. The field of social dynamics brings together ideas from Economics, Sociology, Social Psychology, and other disciplines, and is a sub-field of complex adaptive systems or complexity science. The fundamental assumption of the field is that individuals are influenced by one another's behavior. The field is closely related to system dynamics. Like system dynamics, social dynamics is concerned with changes over time and emphasizes the role of feedbacks. However, in social dynamics individual choices and interactions are typically viewed as the source of aggregate level behavior, while system dynamics posits that the structure of feedbacks and accumulations are responsible for system level dynamics. Research in the field typically takes a behavioral approach, assuming that individuals are boundedly rational and act on local information. Mathematical and computational modeling are important tools for studying social dynamics. Because social dynamics focuses on individual level behavior, and recognizes the importance of heterogeneity across individuals, strict analytic results are often impossible. Instead, approximation techniques, such as mean field approximations from statistical physics, or computer simulations are used to understand the behaviors of the system. In contrast to more traditional approaches in economics, scholars of social dynamics are often interested in non-equilibrium, or dynamic, behavior. That is, behavior that changes over time.


Weidlich, W. (1997) "Sociodynamics applied to the evolution of urban and regional structures". "Discrete Dynamics in Nature and Society", Vol. 1, pp. 85–98.
Available on line: http://www.hindawi.com/GetArticle.aspx?doi=10.1155/S1026022697000101




</doc>
<doc id="29333" url="https://en.wikipedia.org/wiki?curid=29333" title="Social evolution">
Social evolution

Social evolution is a subdiscipline of evolutionary biology that is concerned with social behaviors that have fitness consequences for individuals other than the actor. Social behaviors can be categorized according to the fitness consequences they entail for the actor and recipient.


This classification was proposed by W. D. Hamilton, arguing that natural selection favors mutually beneficial or selfish behaviors. Hamilton's insight was to show how kin selection could explain altruism and spite.

Social evolution is also often regarded (especially, in the field of social anthropology) as evolution of social systems and structures.

In 2010, Harvard biologist E. O. Wilson, a founder of modern sociobiology, proposed a new theory of social evolution. He argued that the traditional approach of focusing on eusociality had limitations, which he illustrated primarily with examples from the insect world.




</doc>
<doc id="29336" url="https://en.wikipedia.org/wiki?curid=29336" title="Systemic functional grammar">
Systemic functional grammar

Systemic functional grammar (SFG) is a form of grammatical description originated by Michael Halliday. It is part of a social semiotic approach to language called "systemic functional linguistics". In these two terms, "systemic" refers to the view of language as "a network of systems, or interrelated sets of options for making meaning"; "functional" refers to Halliday's view that language is as it is because of what it has evolved to do (see Metafunction). Thus, what he refers to as the "multidimensional architecture of language" "reflects the multidimensional nature of human experience and interpersonal relations."

Halliday describes his grammar as built on the work of Saussure, Louis Hjelmslev, Malinowski, J.R. Firth, and the Prague school linguists. In addition, he drew on the work of the American anthropological linguists Boas, Sapir and Whorf. His "main inspiration" was Firth, to whom he owes, among other things, the notion of language as system. Among American linguists, Whorf had "the most profound effect on my own thinking". Whorf "showed how it is that human beings do not all mean alike, and how their unconscious ways of meaning are among the most significant manifestations of their culture" 

From his studies in China, he lists Luo Changpei and Wang Li as two scholars from whom he gained "new and exciting insights into language". He credits Luo for giving him a diachronic perspective and insights into a non-Indo-European language family. From Wang Li he learnt "many things, including research methods in dialectology, the semantic basis of grammar, and the history of linguistics in China".

Some interrelated key terms underpin Halliday's approach to grammar, which forms part of his account of how language works. These concepts are: system, (meta)function, and rank. Another key term is lexicogrammar. In this view, grammar and lexis are two ends of the same continuum.

Analysis of the grammar is taken from a trinocular perspective, meaning from three different levels. So to look at lexicogrammar, we can analyze it from two more levels, 'above'(semantic) and 'below' (phonology). This grammar gives emphasis to the view from above.

For Halliday, grammar is described as systems not as rules, on the basis that every grammatical structure involves a choice from a describable set of options. Language is thus a "meaning potential". Grammarians in SF tradition use system networks to map the available options in a language. In relation to English, for instance, Halliday has described systems such as "mood", "agency", "theme", etc. Halliday describes grammatical systems as closed, i.e. as having a finite set of options. By contrast, lexical sets are open systems, since new words come into a language all the time.

These grammatical systems play a role in the construal of meanings of different kinds. This is the basis of Halliday's claim that language is "metafunctionally" organised. He argues that the raison d'être of language is meaning in social life, and for this reason all languages have three kinds of semantic components. All languages have resources for construing experience (the "ideational" component), resources for enacting humans' diverse and complex social relations (the "interpersonal" component), and resources for enabling these two kinds of meanings to come together in coherent text (the "textual" function). Each of the grammatical systems proposed by Halliday are related to these metafunctions. For instance, the grammatical system of 'mood' is considered to be centrally related to the expression of interpersonal meanings, 'process type' to the expression of experiential meanings, and 'theme' to the expression of textual meanings.

Traditionally the "choices" are viewed in terms of either the content or the structure of the language used. In SFG, language is analysed in three ways (strata): semantics, phonology, and lexicogrammar. SFG presents a view of language in terms of both structure (grammar) and words (lexis). The term "lexicogrammar" describes this combined approach.

From early on in his account of language, Halliday has argued that it is inherently functional. His early papers on the grammar of English make reference to the "functional components" of language, as "generalized uses of language, which, since they seem to determine the nature of the language system, require to be incorporated into our account of that system." Halliday argues that this functional organization of language "determines the form taken by grammatical structure".

Halliday refers to his functions of language as metafunctions. He proposes three general functions: the "ideational", the "interpersonal" and the "textual".

The ideational metafunction is the function for construing human experience. It is the means by which we make sense of "reality". Halliday divides the ideational into the logical and the experiential metafunctions. The logical metafunction refers to the grammatical resources for building up grammatical units into complexes, for instance, for combining two or more clauses into a clause complex. The experiential function refers to the grammatical resources involved in construing the flux of experience through the unit of the clause.

The ideational metafunction reflects the contextual value of "field", that is, the nature of the social process in which the language is implicated. An analysis of a text from the perspective of the ideational function involves inquiring into the choices in the grammatical system of "transitivity": that is, process types, participant types, circumstance types, combined with an analysis of the resources through which clauses are combined. Halliday's "An Introduction to Functional Grammar" (in the third edition, with revisions by Christian Matthiessen) sets out the description of these grammatical systems.

The interpersonal metafunction relates to a text's aspects of "tenor" or interactivity. Like field, tenor comprises three component areas: the speaker/writer persona, social distance, and relative social status. Social distance and relative social status are applicable only to spoken texts, although a case has been made that these two factors can also apply to written text.

The speaker/writer persona concerns the stance, personalisation and standing of the speaker or writer. This involves looking at whether the writer or speaker has a neutral attitude, which can be seen through the use of positive or negative language. Social distance means how close the speakers are, e.g. how the use of nicknames shows the degree to which they are intimate. Relative social status asks whether they are equal in terms of power and knowledge on a subject, for example, the relationship between a mother and child would be considered unequal. Focuses here are on speech acts (e.g. whether one person tends to ask questions and the other speaker tends to answer), who chooses the topic, turn management, and how capable both speakers are of evaluating the subject.

The textual metafunction relates to "mode"; the internal organisation and communicative nature of a text. This comprises textual interactivity, spontaneity and communicative distance.

Textual interactivity is examined with reference to disfluencies such as hesitators, pauses and repetitions.

Spontaneity is determined through a focus on lexical density, grammatical complexity, coordination (how clauses are linked together) and the use of nominal groups. The study of communicative distance involves looking at a text’s cohesion—that is, how it hangs together, as well as any abstract language it uses.

Cohesion is analysed in the context of both lexical and grammatical as well as intonational aspects with reference to lexical chains and, in the speech register, tonality, tonicity, and tone. The lexical aspect focuses on sense relations and lexical repetitions, while the grammatical aspect looks at repetition of meaning shown through reference, substitution and ellipsis, as well as the role of linking adverbials.

Systemic functional grammar deals with all of these areas of meaning equally within the grammatical system itself.

Michael Halliday (1973) outlined seven functions of language with regard to the grammar used by children:

Halliday's theory sets out to explain how spoken and written texts construe meanings and how the resources of language are organised in open systems and functionally bound to meanings. It is a theory of language in use, creating systematic relations between choices and forms within the less abstract strata of grammar and phonology, on the one hand, and more abstract strata such as context of situation and context of culture on the other. It is a radically different theory of language from others which explore less abstract strata as autonomous systems, the most notable being Noam Chomsky's. Since the principal aim of systemic functional grammar is to represent the grammatical system as a resource for making meaning, it addresses different concerns. For example, it does not try to address Chomsky's thesis that there is a "finite rule system which generates all and only the grammatical sentences in a language". Halliday's theory encourages a more open approach to the definition of language as a resource; rather than focus on grammaticality as such, a systemic functional grammatical treatment focuses instead on the relative frequencies of choices made in uses of language and assumes that these relative frequencies reflect the probability that particular paths through the available resources will be chosen rather than others. Thus, SFG does not describe language as a finite rule system, but rather as a system, realised by instantiations, that is continuously expanded by the very instantiations that realise it and that is continuously reproduced and recreated with use.

Another way to understand the difference in concerns between systemic functional grammar and most variants of generative grammar is through Chomsky's claim that "linguistics is a sub-branch of psychology". Halliday investigates linguistics more as a sub-branch of "sociology". SFG therefore pays much more attention to pragmatics and discourse semantics than is traditionally the case in formalism.

The orientation of systemic functional grammar has served to encourage several further grammatical accounts that deal with some perceived weaknesses of the theory and similarly orient to issues not seen to be addressed in more structural accounts. Examples include the model of Richard Hudson called "word grammar".


Other significant systemic functional grammarians:

Linguists also involved with the early development of the approach:



</doc>
<doc id="29340" url="https://en.wikipedia.org/wiki?curid=29340" title="Starfleet">
Starfleet

Starfleet is a fictional organization in the "Star Trek" media franchise. Within this fictional universe, Starfleet is a service maintained by the United Federation of Planets ("the Federation") as the principal means for conducting deep-space exploration, research, defense, peacekeeping, and diplomacy. While the majority of Starfleet's members are human and it is headquartered on Earth, hundreds of other species are also represented. The majority of the franchise's protagonists are Starfleet officers.

During production of early episodes of the , several details of the makeup of the "Star Trek" universe had yet to be worked out, including the operating authority for the USS "Enterprise". The terms "Star Service" (""), "Spacefleet Command" ("The Squire of Gothos"), "United Earth Space Probe Agency" ("Charlie X" and "Tomorrow Is Yesterday"), and "Space Central" ("") were all used to refer to the "Enterprise"s operating authority, before the term "Starfleet" became widespread from the episode "" onwards.

However, references to the United Earth Space Probe Agency, and its abbreviation UESPA, are to be found in episodes of later series. For example, the "Friendship One" probe (launched, on the fictional timeline, in 2067) is marked with the letters UESPA-1 in the "" episode "". Other background props included additional UESPA references, such as Captain Jean-Luc Picard's family album in "Star Trek Generations". During the production of "", some larger Starfleet insignia designs included the name "United Earth Space Probe Agency".

Many "" episodes refer to Starfleet having already been in operation in 2119, when it funded research begun by Cochrane and Henry Archer leading to the first successful flight of Warp 3 vessels in the 2140s. This research is said to have evolved into the NX Program, which led to Starfleet launching its first Warp 5-capable starship, "Enterprise" (NX-01), in 2151, followed by "Columbia" (NX-02), in 2155, as well as other vessels.

However, the Starfleet that is in existence before the Federation is a different organization (the "Earth Starfleet") than that of the Federation Starfleet. Earth Starfleet is a purely scientific and exploratory organization, without any of the military functions that the Federation Starfleet encompasses; all military operations aboard Earth Starfleet vessels are handled by Military Assault Command Operations (MACO) troops.

Starfleet acts under a Prime Directive of non-interference with developing worlds or their internal politics. This is said not to be a Human construct, but stems from policies originally implemented by the Vulcans, who regarded an alien civilization's attainment of warp speed as the sign of their importance and reason for making first contact with them. The Prime Directive and Starfleet's first-contact policies are at the center of several episodes in each "Star Trek" series and the film "".

Starfleet Headquarters is shown to be located on Earth, northeast of the Golden Gate Bridge in the present-day Fort Baker area. Starfleet Academy is located in the same general area. Additionally, various episodes show Starfleet operating a series of starbases throughout Federation territory, as ground facilities, or as space stations in planetary orbit or in deep space (notably the eponymous station in the "" series).

Starfleet has been shown to handle scientific, defense, and diplomatic missions, although its primary mandate seems to be peaceful exploration in the search for sentient life, as seen in the mission statements of different incarnations of the USS "Enterprise". The flagship of Starfleet is often considered to be the starship USS "Enterprise".

In the early years of Starfleet, as seen in "", Starfleet's mission is purely exploration and is not military in any sense (except for weapons designed for defensive capabilities) until the retrofitting of the "Enterprise" (NX-01) and the incorporation of Military Assault Command Operations (MACO), after the Xindi attack on Earth. It is assumed this trend continues as Starfleet adopts a more traditional military role and assumes its regular place as both the exploratory and the defensive arm of the United Federation of Planets. (During "", David Marcus derisively refers to Starfleet when stating scientists are always pawns of "the military".)

Starfleet has many components, including:

As early as the original "", characters refer to attending Starfleet Academy. Later series establish it as an officer training facility with a four-year educational program. The main campus is located near Starfleet Headquarters in what is now Fort Baker, California.

Starfleet Command is the headquarters/command center of Starfleet. The term "Starfleet Command" is first used in episode "Court Martial". Its headquarters are depicted as being in Fort Baker, across the Golden Gate from San Francisco, in "" and "". Overlooking the Command from the other side of the Golden Gate is the permanent site of the Council of the United Federation of Planets in what is now the Presidio of San Francisco. Throughout the "Star Trek" franchise, the main characters' isolation from Starfleet Command compels them to make and act upon decisions without Starfleet Command's orders or information, particularly in "" when the main protagonists have no means of contacting Earth for several years.

StarTrek.com notes that many of Starfleet's ships are built on Mare Island near San Francisco. It states:

The "Enterprise-D" and USS "Voyager" are depicted to have been constructed at a shipyard named Utopia Planitia in Mars orbit. Utopia Planitia served as Starfleet's main ship yards throughout a large portion of Starfleet's existence.

After the "Enterprise-D" encountered the Borg in the episode "Q Who" the size of the Utopia Planitia shipyards was doubled out of fear of a Borg strike. They were once again doubled after the Dominion threat became more evident.

In the 2009 film, Jim Kirk arrives at a shipyard near his home in Iowa and boards a shuttle to enlist in Starfleet; as the shuttle leaves, we see that the ship under construction there is the "Enterprise".

In the 2013 sequel, Montgomery "Scotty" Scott discovers a covert Starfleet facility, near Jupiter, that has built a much larger Federation warship, USS "Vengeance".

The Starfleet Engineering Corps (also called the Starfleet Corps of Engineers) is mentioned in several episodes in conjunction with projects such as hollowing out the underground laboratory complex inside the Regula I asteroid in "", the design of the "Yellowstone"-class Runabout in the alternate timeline in the "" episode "", and devising a defense against the Breen energy-dampening weapon in the "" episode "When It Rains…" As a result of these successes, Starfleet engineers gained a reputation as the undisputed masters of technological adaptation and modification. As one minion of the Dominion in the "" episode, "" notes, Starfleet engineers are reputed to be able to "Turn rocks into replicators."

Additionally, Pocket Books has published a series of eBooks and novels in the "Starfleet Corps of Engineers" series.

Starfleet Intelligence is an intelligence agency of the United Federation of Planets. It is entrusted with foreign and domestic espionage, counter-espionage, and state security.

The Starfleet Judge Advocate General (or "JAG") is the branch charged with overseeing legal matters within Starfleet. Several episodes revolve around or involve JAG officers and procedures:

Dialog in "Court Martial" reveals that a court-martial may be convened in the absence of any JAG officers by three presiding command-level officers. Additionally, dialog in "The Measure of a Man" indicates that the loss of a starship automatically leads to a JAG court-martial. Courts-martial were held following the loss of the USS "Pegasus" and USS "Stargazer". In the "Voyager" episode "", Tuvok states that the Captain has the authority to conduct a court-martial on the ship, given the circumstance of the ship being isolated from the Federation.

The Starfleet Marine Corps is the branch of Starfleet that is responsible for ground-based military engagements. The existence of this marine corps has been revealed only once (within the canon), as part of the Operation Retrieve briefing in "". Ground troops have been mentioned elsewhere in Trek, most notably in ""; but these were not referred to as Marines. The sixth film is the SFMC's only official appearance so far.

Starfleet Medical is the medical branch of Starfleet.

Gates McFadden, who played Dr. Beverly Crusher, left "" during its second season. The character is described during this season, and after her return, as having been assigned to Starfleet Medical.

Numerous star ship dedication plaques identify other personnel associated with Starfleet Operations. Rear Admiral James T. Kirk served 18 months as Starfleet's Chief of Operations.

Starfleet Security is an agency of Starfleet referred to in several episodes of "" and "". Security is a branch of Starfleet first introduced in the . Main characters in subsequent series have been security officers.

Starfleet Tactical is a rarely-mentioned department in Starfleet that is responsible for planning defensive strategies, as well as engaging in weapons research and development.

Although Humans are the most-often-seen crew members onscreen, Starfleet is shown to be composed of individuals from over 150 races, with Vulcans perhaps being the most common aliens seen.

Already in "", the USS "Enterprise" and other ships have a mixed-species crew, although this does not appear to be an absolute rule; for instance, the episode "" refers to the USS "Intrepid" as having an all-Vulcan crew. The "" episode "Take Me Out to the Holosuite" also features such a crew, serving aboard the USS "T'Kumbra".

In keeping with this idea, "", in its first two seasons, was the only show to have an entirely human crew, as it was set before the formation of the Federation, although the vessel did carry Phlox, a Denobulan serving in a medical exchange program, and T'Pol, then serving as an observer from the Vulcan High Command.

"" saw the introduction of Starfleet's first Klingon officer. Other races—such as Bolians, Betazoids, and Trill—were seen, and given more central roles, in later series; some of these, notably Klingons, had been shown as enemies in earlier episodes.

Various episodes show that Earth/Federation citizenship is not a necessary pre-condition for joining Starfleet. T'Pol of Vulcan is shown to be the first non-human Starfleet officer, receiving a commission as a commander following the Xindi mission and her resignation from the Vulcan High Command. Even after the Federation's formation citizenship was not required; several officers are from planets that are not part of the Federation. For example, "Star Trek: TNG"s Ensign Ro Laren, a Bajoran aboard the USS "Enterprise"-D; her fellow Bajoran Kira Nerys, who was field-commissioned as a Starfleet commander so that she could aid the Cardassian resistance during the Dominion War; and Ferengi Nog, who enters Starfleet Academy in season four of Deep Space Nine; all were from non-member planets. In addition, Quinn and Icheb from "" both spoke of joining Starfleet.

An example of the process imagined by the writers is given when the character Nog attempts to apply to the Academy. He is told that since he is from a non-member world (Ferenginar), he requires a letter of recommendation from a command-level officer before his application can be considered, with the implication that this is the standard procedure for all non-Federation applicants to Starfleet.

In the "Star Trek" Expanded Universe, an example of what typically becomes of a new Federation member world's military is depicted when the Bajoran Militia is integrated into Starfleet upon Bajor's entry into the Federation.



</doc>
<doc id="29341" url="https://en.wikipedia.org/wiki?curid=29341" title="Superheterodyne receiver">
Superheterodyne receiver

A superheterodyne receiver, often shortened to superhet, is a type of radio receiver that uses frequency mixing to convert a received signal to a fixed intermediate frequency (IF) which can be more conveniently processed than the original carrier frequency. It was invented by US engineer Edwin Armstrong in 1918 during World War I. Virtually all modern radio receivers use the superheterodyne principle.

"Superheterodyne" is a contraction of "supersonic heterodyne", where "supersonic" indicates frequencies above the range of human hearing. The word "heterodyne" is derived from the Greek roots "hetero-" "different", and "-dyne" "power". In radio applications the term derives from the "heterodyne detector" pioneered by Canadian inventor Reginald Fessenden in 1905, describing his proposed method of producing an audible signal from the Morse code transmissions of the new continuous wave transmitters. With the older spark gap transmitters then in use, the Morse code signal consisted of short bursts of a carrier wave. Since these burst were derived from the output of an alternator, they modulated the carrier at a frequency within the audio range, and thus could be heard as a chirp or a buzz in the receiver's headphones. However, the signal from a continuous wave transmitter was at a single frequency well above the audio range, and Morse Code from one of these would only be heard as a series of clicks or thumps. Fessenden's idea was to run two Alexanderson alternators, one producing a carrier frequency 3 kHz higher than the other. In the receiver's detector the two carriers would beat together to produce a 3 kHz tone thus in the headphones the Morse signals would then be heard as a series of 3 kHz beeps. For this he coined the term "heterodyne" meaning "generated by a difference" (in frequency).

The French engineer Lucien Lévy filed a patent application for the superheterodyne principle in August 1917 with brevet n° 493660.
The American Edwin Howard Armstrong also filed a patent in 1917. 
Levy filed his original disclosure about seven months before Armstrong's.
The German inventor Walter H. Schottky also filed a patent in 1918.
At first the US recognised Armstrong as the inventor, and his US Patent 1,342,885 was issued on 8 June 1920.
After various changes and court hearings Lévy was awarded a US patent No 1,734,938 that included seven of the nine claims in Armstrong's application, while the two remaining claims were granted to Alexanderson of GE and Kendall of AT&T.
Armstrong invented his receiver as a means of overcoming the deficiencies of early vacuum tube triodes used as high-frequency amplifiers in radio direction finding equipment. Unlike simple radio communication, which only needs to make transmitted signals audible, direction-finders measure the received signal strength, which necessitates linear amplification of the actual carrier wave.

In a triode radio-frequency (RF) amplifier, if both the plate (anode) and grid are connected to resonant circuits tuned to the same frequency, stray capacitive coupling between the grid and the plate will cause the amplifier to go into oscillation if the stage gain is much more than unity. In early designs, dozens (in some cases over 100) low-gain triode stages had to be connected in cascade to make workable equipment, which drew enormous amounts of power in operation and required a team of maintenance engineers. The strategic value was so high, however, that the British Admiralty felt the high cost was justified.

Armstrong realized that if radio direction-finding (RDF) receivers could be operated at a higher frequency, this would allow better detection of enemy shipping. However, at that time, no practical "short wave" (defined then as any frequency above 500 kHz) amplifier existed, due to the limitations of existing triodes.

It had been noticed that when a regenerative receiver went into oscillation, other nearby receivers would suddenly start picking up stations on frequencies different from the stations' transmission frequency. Armstrong (and others) eventually deduced that this was caused by a "supersonic heterodyne" between the station's carrier frequency and the regenerative receiver's oscillation frequency. Thus if a station was transmitting on 300 kHz and the oscillating receiver was set to 400 kHz, the station would be heard not only at the original 300 kHz, but also at 100 kHz and 700 kHz.

Armstrong realized that this was a potential solution to the "short wave" amplification problem, since the beat frequency still retained its original modulation, but on a lower carrier frequency. To monitor a frequency of 1500 kHz for example, he could set up an oscillator at, for example, 1560 kHz, which would produce a heterodyne difference frequency of 60 kHz, a frequency that could then be more conveniently amplified by the triodes of the day. He termed this the "intermediate frequency" often abbreviated to "IF".

In December 1919, Major E. H. Armstrong gave publicity to an indirect method of obtaining short-wave amplification, called the super-heterodyne. The idea is to reduce the incoming frequency, which may be, say 1,500,000 cycles (200 meters), to some suitable super-audible frequency that can be amplified efficiently, then passing this current through an intermediate frequency amplifier, and finally rectifying and carrying on to one or two stages of audio frequency amplification.

Armstrong was able to put his ideas into practice, and the technique was soon adopted by the military. However, it was less popular when commercial radio broadcasting began in the 1920s, mostly due to the need for an extra tube (for the oscillator), the generally higher cost of the receiver, and the level of technical skill required to operate it. For early domestic radios, tuned radio frequency receivers (TRF) were more popular because they were cheaper, easier for a non-technical owner to use, and less costly to operate. Armstrong eventually sold his superheterodyne patent to Westinghouse, who then sold it to RCA, the latter monopolizing the market for superheterodyne receivers until 1930.

Early superheterodyne receivers used IFs as low as 20 kHz, often based on the self-resonance of iron-cored transformers. This made them extremely susceptible to image frequency interference, but at the time, the main objective was sensitivity rather than selectivity. Using this technique, a small number of triodes could be made to do the work that formerly required dozens of triodes.

In the 1920s, commercial IF filters looked very similar to 1920s audio interstage coupling transformers, had very similar construction and were wired up in an almost identical manner, and so they were referred to as "IF transformers". By the mid-1930s however, superheterodynes were using much higher intermediate frequencies, (typically around 440–470 kHz), with tuned coils similar in construction to the aerial and oscillator coils. However, the name "IF transformer" was retained and is still used today. Modern receivers typically use a mixture of ceramic resonator or SAW (surface-acoustic wave) resonators as well as traditional tuned-inductor IF transformers.

By the 1930s, improvements in vacuum tube technology rapidly eroded the TRF receiver's cost advantages, and the explosion in the number of broadcasting stations created a demand for cheaper, higher-performance receivers.

The development of the tetrode vacuum tube containing a screen grid led to a multi-element tube in which the mixer and oscillator functions could be combined, first used in the so-called autodyne mixer. This was rapidly followed by the introduction of tubes specifically designed for superheterodyne operation, most notably the pentagrid converter. By reducing the tube count, this further reduced the advantage of preceding receiver designs.

By the mid-1930s, commercial production of TRF receivers was largely replaced by superheterodyne receivers. By the 1940s the vacuum-tube superheterodyne AM broadcast receiver was refined into a cheap-to-manufacture design called the "All American Five", because it only used five vacuum tubes: usually a converter (mixer/local oscillator), an IF amplifier, a detector/audio amp, audio power amp, and a rectifier. From this time, the superheterodyne design was used for virtually all commercial radio and TV receivers.

The diagram at right shows the block diagram of a typical single-conversion superheterodyne receiver. The diagram has blocks that are common to superheterodyne receivers. The antenna collects the radio signal. The tuned RF stage with optional RF amplifier provides some initial selectivity; it is necessary to suppress the "image frequency" (see below), and may also serve to prevent strong out-of-passband signals from saturating the initial amplifier. A local oscillator provides the mixing frequency; it is usually a variable frequency oscillator which is used to tune the receiver to different stations. The frequency mixer does the actual heterodyning that gives the superheterodyne its name; it changes the incoming radio frequency signal to a higher or lower, fixed, intermediate frequency (IF). The IF band-pass filter and amplifier supply most of the gain and the narrowband filtering for the radio. The demodulator extracts the audio or other modulation from the IF radio frequency; the extracted signal is then amplified by the audio amplifier.

To receive a radio signal, a suitable antenna is required. The output of the antenna may be very small, often only a few microvolts. The signal from the antenna is tuned and may be amplified in a so-called radio frequency (RF) amplifier, although this stage is often omitted. One or more tuned circuits at this stage block frequencies that are far removed from the intended reception frequency. In order to tune the receiver to a particular station, the frequency of the local oscillator is controlled by the tuning knob (for instance). Tuning of the local oscillator and the RF stage may use a variable capacitor, or varicap diode. The tuning of one (or more) tuned circuits in the RF stage must track the tuning of the local oscillator.

The signal is then fed into a circuit where it is mixed with a sine wave from a variable frequency oscillator known as the local oscillator (LO). The mixer uses a non-linear component to produce both sum and difference beat frequencies signals, each one containing the modulation contained in the desired signal. The output of the mixer may include the original RF signal at "f", the local oscillator signal at "f", and the two new heterodyne frequencies "f" + "f" and "f" − "f". The mixer may inadvertently produce additional frequencies such as third- and higher-order intermodulation products. Ideally, the IF bandpass filter removes all but the desired IF signal at "f". The IF signal contains the original modulation (transmitted information) that the received radio signal had at "f".

Historically, vacuum tubes were expensive, so broadcast AM receivers would save costs by employing a single tube as both a mixer and also as the local oscillator. The pentagrid converter tube would oscillate and also provide signal amplification as well as frequency shifting.

The frequency of the local oscillator "f" is set so the desired reception radio frequency "f" mixes to "f". There are two choices for the local oscillator frequency because the dominant mixer products are at "f" ± "f". If the local oscillator frequency is less than the desired reception frequency, it is called low-side injection ("f" = "f" − "f"); if the local oscillator is higher, then it is called high-side injection ("f" = "f" − "f").

The mixer will process not only the desired input signal at f, but also all signals present at its inputs. There will be many mixer products (heterodynes). Most other signals produced by the mixer (such as due to stations at nearby frequencies) can be filtered out in the IF amplifier; that gives the superheterodyne receiver its superior performance. However, if "f" is set to "f" + "f", then an incoming radio signal at "f" + "f" will "also" produce a heterodyne at "f"; the frequency "f" + "f" is called the "image frequency" and must be rejected by the tuned circuits in the RF stage. The image frequency is 2 "f" higher (or lower) than the desired frequency "f", so employing a higher IF frequency "f" increases the receiver's "image rejection" without requiring additional selectivity in the RF stage.

To suppress the unwanted image, the tuning of the RF stage and the LO may need to "track" each other. In some cases, a narrow-band receiver can have a fixed tuned RF amplifier. In that case, only the local oscillator frequency is changed. In most cases, a receiver's input band is wider than its IF center frequency. For example, a typical AM broadcast band receiver covers 510 kHz to 1655 kHz (a roughly 1160 kHz input band) with a 455 kHz IF frequency; an FM broadcast band receiver covers 88 MHz to 108 MHz band with a 10.7 MHz IF frequency. In that situation, the RF amplifier must be tuned so the IF amplifier does not see two stations at the same time. If the AM broadcast band receiver LO were set at 1200 kHz, it would see stations at both 745 kHz (1200−455 kHz) and 1655 kHz. Consequently, the RF stage must be designed so that any stations that are twice the IF frequency away are significantly attenuated. The tracking can be done with a multi-section variable capacitor or some varactors driven by a common control voltage. An RF amplifier may have tuned circuits at both its input and its output, so three or more tuned circuits may be tracked. In practice, the RF and LO frequencies need to track closely but not perfectly.

The stages of an intermediate frequency amplifier ("IF amplifier" or "IF strip") are tuned to a fixed frequency that does not change as the receiving frequency changes. The fixed frequency simplifies optimization of the IF amplifier. The IF amplifier is selective around its center frequency "f". The fixed center frequency allows the stages of the IF amplifier to be carefully tuned for best performance (this tuning is called "aligning" the IF amplifier). If the center frequency changed with the receiving frequency, then the IF stages would have had to track their tuning. That is not the case with the superheterodyne.

Typically, the IF center frequency "f" is chosen to be less than the desired reception frequency "f". The choice has some performance advantages. First, it is easier and less expensive to get high selectivity at a lower frequency. For the same bandwidth, a tuned circuit at a lower frequency needs a lower Q. Stated another way, for the same filter technology, a higher center frequency will take more IF filter stages to achieve the same selectivity bandwidth. Second, it is easier and less expensive to get high gain at a lower frequency. When used at high frequencies, many amplifiers show a constant gain–bandwidth product (dominant pole) characteristic. If an amplifier has a gain–bandwidth product of 100 MHz, then it would have a voltage gain of 100 at 1 MHz but only 10 at 10 MHz. If the IF amplifier needed a voltage gain of 10,000, then it would need only two stages with an IF at 1 MHz but four stages at 10 MHz.

Usually the intermediate frequency is lower than the reception frequency "f", but in some modern receivers (e.g. scanners and spectrum analyzers) a higher IF frequency is used to minimize problems with image rejection or gain the benefits of fixed-tuned stages. The Rohde & Schwarz EK-070 VLF/HF receiver covers 10 kHz to 30 MHz. It has a band switched RF filter and mixes the input to a first IF of 81.4 MHz. The first LO frequency is 81.4 to 111.4 MHz, so the primary images are far away. The first IF stage uses a crystal filter with a 12 kHz bandwidth. There is a second frequency conversion (making a triple-conversion receiver) that mixes the 81.4 MHz first IF with 80 MHz to create a 1.4 MHz second IF. Image rejection for the second IF is not a major problem because the first IF provides adequate image rejection and the second mixer is fixed tuned.

In order to avoid interference to receivers, licensing authorities will avoid assigning common IF frequencies to transmitting stations. Standard intermediate frequencies used are 455 kHz for medium-wave AM radio, 10.7 MHz for broadcast FM receivers, 38.9 MHz (Europe) or 45 MHz (US) for television, and 70 MHz for satellite and terrestrial microwave equipment. To avoid tooling costs associated with these components, most manufacturers then tended to design their receivers around a fixed range of frequencies offered, which resulted in a worldwide "de facto" standardization of intermediate frequencies.

In early superhets, the IF stage was often a regenerative stage providing the sensitivity and selectivity with fewer components. Such superhets were called super-gainers or regenerodynes. Another circuit added to the intermediate frequency chain is the Q multiplier.

The IF stage includes a filter and/or multiple tuned circuits in order to achieve the desired selectivity. This filtering must therefore have a band pass equal to or less than the frequency spacing between adjacent broadcast channels. Ideally a filter would have a high attenuation to adjacent channels, but maintain a flat response across the desired signal spectrum in order to retain the quality of the received signal. This may be obtained using one or more dual tuned IF transformers, a quartz crystal filter, or a multipole ceramic crystal filter.

The received signal is now processed by the demodulator stage where the audio signal (or other baseband signal) is recovered and then further amplified. AM demodulation requires the simple rectification of the RF signal (so-called envelope detection), and a simple RC low pass filter to remove remnants of the intermediate frequency. FM signals may be detected using a discriminator, ratio detector, or phase-locked loop. Continuous wave]) and single sideband signals require a product detector using a so-called beat frequency oscillator, and there are other techniques used for different types of modulation. The resulting audio signal (for instance) is then amplified and drives a loudspeaker.

When so-called high-side injection has been used, where the local oscillator is at a "higher" frequency than the received signal (as is common), then the frequency spectrum of the original signal will be reversed. This must be taken into account by the demodulator (and in the IF filtering) in the case of certain types of modulation such as single sideband.

To overcome obstacles such as image response, in some cases multiple stages with two or more IFs of different values are used. For example, for a receiver that can tune from 500 kHz to 30 MHz, three frequency converters might be used, and the radio would be referred to as a "triple conversion superheterodyne";

The reason that this is done is the difficulty in obtaining sufficient selectivity in the front-end tuning with higher shortwave frequencies.

With a 455 kHz IF it is easy to get adequate front end selectivity with broadcast band (under 1600 kHz) signals. For example, if the station being received is on 600 kHz, the local oscillator will be set to 600 + 455 = 1055 kHz. But a station on 1510 kHz could also potentially produce an IF of 455 kHz and so cause image interference. However, because 600 kHz and 1510 kHz are so far apart, it is easy to design the front end tuning to reject the 1510 kHz frequency.

However at 30 MHz, things are different. The oscillator would be set to 30.455 MHz to produce a 455 kHz IF, but a station on 30.910 would also produce a 455 kHz beat, so both stations would be heard at the same time. But it is virtually impossible to design an RF tuned circuit that can adequately discriminate between 30 MHz and 30.91 MHz, so one approach is to "bulk downconvert" whole sections of the shortwave bands to a lower frequency, where adequate front-end tuning is easier to arrange.

For example, the ranges 29 MHz to 30 MHz; 28 MHz to 29 MHz etc. might be converted down to 2 MHz to 3 MHz, there they can be tuned more conveniently. This is often done by first converting each "block" up to a higher frequency (typically 40 MHz) and then using a second mixer to convert it down to the 2 MHz to 3 MHz range. The 2 MHz to 3 MHz "IF" is basically another self-contained superheterodyne receiver, most likely with a standard IF of 455 kHz.

In the case of modern television receivers, no other technique was able to produce the precise bandpass characteristic needed for vestigial sideband reception, similar to that used in the NTSC system first approved by the U.S. in 1941. By the 1980s these had been replaced with precision electromechanical surface acoustic wave (SAW) filters. Fabricated by precision laser milling techniques, SAW filters are cheaper to produce, can be made to extremely close tolerances, and are very stable in operation.

Microprocessor technology allows replacing the superheterodyne receiver design by a software defined radio architecture, where the IF processing after the initial IF filter is implemented in software. This technique is already in use in certain designs, such as very low-cost FM radios incorporated into mobile phones, since the system already has the necessary microprocessor.

Radio transmitters may also use a mixer stage to produce an output frequency, working more or less as the reverse of a superheterodyne receiver.

Superheterodyne receivers have essentially replaced all previous receiver designs. The development of modern semiconductor electronics negated the advantages of designs (such as the regenerative receiver) that used fewer vacuum tubes. The superheterodyne receiver offers superior sensitivity, frequency stability and selectivity. Compared with the tuned radio frequency receiver (TRF) design, superhets offer better stability because a tuneable oscillator is more easily realized than a tuneable amplifier. Operating at a lower frequency, IF filters can give narrower passbands at the same Q factor than an equivalent RF filter. A fixed IF also allows the use of a crystal filter or similar technologies that cannot be tuned. Regenerative and super-regenerative receivers offered a high sensitivity, but often suffer from stability problems making them difficult to operate.

Although the advantages of the superhet design are overwhelming, we note a few drawbacks that need to be tackled in practice.

One major disadvantage to the superheterodyne receiver is the problem of "image frequency". In heterodyne receivers, an image frequency is an undesired input frequency equal to the station frequency plus (or minus) twice the intermediate frequency. The image frequency results in two stations being received at the same time, thus producing interference. Image frequencies can be eliminated by sufficient attenuation on the incoming signal by the RF amplifier filter of the superheterodyne receiver.

For example, an AM broadcast station at 580 kHz is tuned on a receiver with a 455 kHz IF. The local oscillator is tuned to 1035 kHz. But a signal at 1490 kHz is also 455 kHz away from the local oscillator; so both the desired signal and the image, when mixed with the local oscillator, will also appear at the intermediate frequency. This image frequency is within the AM broadcast band. Practical receivers have a tuning stage before the converter, to greatly reduce the amplitude of image frequency signals; additionally, broadcasting stations in the same area have their frequencies assigned to avoid such images.

The unwanted frequency is called the "image" of the wanted frequency, because it is the "mirror image" of the desired frequency reflected formula_2. A receiver with inadequate filtering at its input will pick up signals at two different frequencies simultaneously: the desired frequency and the image frequency. Any noise or random radio station at the image frequency can interfere with reception of the desired signal.

Early Autodyne receivers typically used IFs of only 150 kHz or so, as it was difficult to maintain reliable oscillation if higher frequencies were used. As a consequence, most Autodyne receivers needed quite elaborate antenna tuning networks, often involving double-tuned coils, to avoid image interference. Later superhets used tubes especially designed for oscillator/mixer use, which were able to work reliably with much higher IFs, reducing the problem of image interference and so allowing simpler and cheaper aerial tuning circuitry.

Sensitivity to the image frequency can be minimised only by (1) a filter that precedes the mixer or (2) a more complex mixer circuit that suppresses the image. In most receivers this is accomplished by a bandpass filter in the RF front end. In many tunable receivers, the bandpass filter is tuned in tandem with the local oscillator.

Image rejection is an important factor in choosing the intermediate frequency of a receiver. The farther apart the bandpass frequency and the image frequency are, the more the bandpass filter will attenuate any interfering image signal. Since the frequency separation between the bandpass and the image frequency is formula_3, a higher intermediate frequency improves image rejection. It may be possible to use a high enough first IF that a fixed-tuned RF stage can reject any image signals.

The ability of a receiver to reject interfering signals at the image frequency is measured by the image rejection ratio. This is the ratio (in decibels) of the output of the receiver from a signal at the received frequency, to its output for an equal-strength signal at the image frequency.

It is difficult to keep stray radiation from the local oscillator below the level that a nearby receiver can detect. The receiver's local oscillator can act like a low-power CW transmitter. Consequently, there can be mutual interference in the operation of two or more superheterodyne receivers in close proximity.

In intelligence operations, local oscillator radiation gives a means to detect a covert receiver and its operating frequency. The method was used by MI-5 during Operation RAFTER. This same technique is also used in radar detector detectors used by traffic police in jurisdictions where radar detectors are illegal.

A method of significantly reducing the local oscillator radiation from the receiver's antenna is to use an RF amplifier between the receiver's antenna and its mixer stage.

Local oscillators typically generate a single frequency signal that has negligible amplitude modulation but some random phase modulation. Either of these impurities spreads some of the signal's energy into sideband frequencies. That causes a corresponding widening of the receiver's frequency response, which would defeat the aim to make a very narrow bandwidth receiver such as to receive low-rate digital signals. Care needs to be taken to minimize oscillator phase noise, usually by ensuring that the oscillator never enters a non-linear mode.

As the superheterodyne is the most developed and widely used radio circuit, a terminology has grown up around it:






</doc>
<doc id="29344" url="https://en.wikipedia.org/wiki?curid=29344" title="Seventh Day Baptists">
Seventh Day Baptists

Seventh Day Baptists (SDBs) are a Baptist denomination which observes the Sabbath on the seventh-day of the week—Saturday—in accordance with the Biblical Sabbath of the Ten Commandments (Exodus 20:8, Deuteronomy 5:12). The movement originated in mid-17th century England and spread within a few years to the British colonies in North America. Today, the Seventh Day Baptist World Federation represents over 50,000 members in 22 countries worldwide, of whom over 20,000 reside in India and almost 5,000 reside in the United States.

Seventh Day Baptists trace the beginning of their movement to coalescing factors during the decade of the 1650s in England. These factors included the continuing Baptist movement in England, English language publications about the Sabbath in the early 1600s, and a relative freedom of religion from state interference in Oliver Cromwell's commonwealth. Once the factors had coalesced, individuals associated with the movement chose to accept punishment meted out by the State rather than renounce their Sabbath conviction.

The first recorded SDB meeting was held at The Mill Yard Church in London in 1651 under the leadership of Dr. Peter Chamberlen. However many SDBs believe that their origins date to 1617 with John Trask and his wife, but the records for this were lost in a fire.
Stephen Mumford, a SDB from England, arrived in Rhode Island in 1665 and is mentioned as an advocate for seventh-day Sabbath in many records of the time. The first SDB church in America was at Newport, Rhode Island, established December 1671. In that month, two members of the First Baptist Church of Newport, pastored by John Clarke—namely, Samuel and Tacy Hubbard—withdrew from that church and joined with Mumford. Along with four others, they covenanted to meet together for worship, calling themselves Sabbatarian Baptists.

Other SDB churches arose in Pennsylvania and New Jersey, and soon spread north into Connecticut and New York, and south into Virginia and the Carolinas. Seventh-day Sabbatarianism also emerged among the Germans at Ephrata, Pennsylvania, founded in 1735. Ephrata was incorporated as the German Religious Society of Seventh Day Baptists in 1814, and the site where their community was founded came to be known at the Ephrata Cloister. The Seventh Day Baptist General Conference was organized in 1801. Throughout the 18th and early 19th centuries, Seventh-day Sabbatarianism was one of several controversial doctrines—including pedobaptism, Arianism, and anti-missionism—that roiled the newly established Baptist churches on the American frontier.

Alfred University, in Allegany County, New York, was founded in 1836 as the "Select School" by SDBs on a non-sectarian basis. Unusual for the time, the school was co-educational. Moreover, Alfred was racially integrated and enrolled its first African-American student (along with two Native American students) in the 1850s, becoming the second college in the nation (after Berea College) to do so. (Alfred's affiliation with the SDB church later lapsed.)

It is not the case that the Seventh-day Adventists (SDAs), established in 1863, are a "splinter group" of the SDBs. (At least not in the sense that former SDBs broke with their church and formed the SDAs.) But there was a connection, and an influence. It was an SDB—Rachel Oakes Preston (1809–1868)—who brought the seventh-day Sabbath understanding to the small Millerite group which became the SDAs in Washington, New Hampshire. Through her influence, Frederick Wheeler became the first Sabbath-keeping Adventist preacher. One family, the Cottrells, looked favorably upon William Miller's Second Advent message, but did not join the movement prior to 1844 because it did not acknowledge the seventh-day Sabbath. After a group of Adventists accepted the Sabbath, the Cottrells joined them. Later on, in the 1860s and '70s, the leadership of the two organizations associated with each other. They recognized their common interest in promoting Sabbath observance. Adventist pioneer James Springer White went so far as to advise Adventist preachers not to conduct evangelistic campaigns in the small towns with an SDB presence.

Salem College—renamed Salem International University in 2000—was established by SDBs in Salem, West Virginia, in 1888, about a century after pioneering SDBs had founded the settlement of "New Salem" there.

The Seventh Day Baptist World Federation was founded in 1964–65, and it now represents over 50,000 Baptists in 17 member organizations in 22 countries. In 1995, the SDBs had 253 churches (and over 20,000 members) in India, 78 churches with 4,885 members in the United States, two churches with 55 members in England, and one church of 40 members in Canada. Conferences and associations exist in many other countries including Australia, Brazil, India, Jamaica, the Netherlands, New Zealand and amongst the Seventh Day Christians of Poland. Some conferences have sent missionaries to other nations including Malawi, Fiji, and Argentina.

Other than the belief that Christian Sabbath is Saturday rather than Sunday, SDBs are very similar to other Baptists. However, due to the Baptist tradition of freedom of conscience, even within and among Baptists, there are many variations of doctrine—and the SDBs are no exception. SDBs do not hold to a binding creed, their belief system is relatively more flexible than mainstream Christianity, and the teachings SDBs hold may also vary from member to member. Some of the basic beliefs are baptism of believers by immersion; the practice of a non-liturgical form of worship, and belief in principles of religious freedom and separation of church and state. In the days before Emancipation, the SDB church officially denounced slavery in several resolutions.

Each church and association of Seventh Day Baptist churches may have a statement of belief. A representative statement, from the conference of the USA and Canada, is as follows:

Introduction<br>
Seventh Day Baptists consider liberty of thought under the guidance of the Holy Spirit to be essential to Christian belief and practice. Therefore we encourage the unhindered study and open discussion of Scripture. We uphold the individual's freedom of conscience in seeking to determine and obey the will of God.

The following statement is not intended to be exhaustive, but is an expression of our common belief, which is derived from our understanding of Scripture.

I. God<br>
We believe in one God, infinite and perfect, the Creator and Sustainer of the universe who exists eternally in three persons—Father, Son, and Holy Spirit—and desires to share His love in a personal relationship with everyone.

II. The Bible<br>
We believe that the Bible is the inspired Word of God and is our final authority in matters of faith and practice. We believe that Jesus Christ, in His life and teachings as recorded in the Bible, is the supreme interpreter of God's will for mankind.

III. Mankind<br>
We believe that mankind was created in the image of God and is therefore the noblest work of creation. We believe that human beings have moral responsibility and are created to enjoy both divine and human fellowship as children of God.

IV. Sin and Salvation<br>
We believe that sin is disobedience to God and failure to live according to His will. Because of sin all people have separated themselves from God. We believe that because we are sinners, we are in need of a Savior.

We believe that salvation from sin and death is the gift of God by redeeming love accomplished by Christ's death and resurrection, and is received only by repentance and faith in Him. We believe that all who repent of their sin and receive Christ as Savior will not be punished at the final judgment but enjoy eternal life.

V. Eternal Life<br>
We believe that Jesus rose from the dead and lives eternally with the Father, and that He will come again with power and great glory. We believe that eternal life begins in knowing God through a commitment to Jesus Christ. We believe that because He died and lives again, resurrection with spiritual and imperishable bodies is the gift of God to believers.

VI. The Church<br>
We believe that the church of God is all believers gathered by the Holy Spirit and joined into one body, of which Christ is the Head. We believe that the local church is a community of believers organized in covenant relationship for worship, fellowship and service, practicing and proclaiming common convictions, while growing in grace and in the knowledge of our Lord and Savior Jesus Christ.

We believe in the priesthood of all believers and practice the autonomy of the local congregation, as we seek to work in association with others for more effective witness.

VII. Baptism<br>
We believe that baptism of believers in obedience to Christ's command is a witness to the acceptance of Jesus Christ as Savior and Lord. We believe in baptism by immersion as a symbol of death to sin, a pledge to a new life in Him.

VIII. The Lord's Supper<br>
We believe that the Lord's Supper commemorates the suffering and death of our Redeemer until He comes, and is a symbol of union in Christ and a pledge of renewed allegiance to our risen Lord.

IX. Sabbath<br>
We believe that the Sabbath of the Bible, the seventh day of the week, is sacred time, a gift of God to all people, instituted at creation, affirmed in the Ten Commandments and reaffirmed in the teaching and example of Jesus and the apostles.

We believe that the gift of Sabbath rest is an experience of God's eternal presence with His people.

We believe that in obedience to God and in loving response to His grace in Christ, the Sabbath should be faithfully observed as a day of rest, worship, and celebration.

X. Evangelism<br>
We believe that Jesus Christ commissions us to proclaim the Gospel, to make disciples, to baptize and to teach observance of all that He has commanded. We are called to be witnesses for Christ throughout the world and in all human relationships.

Offices of the General Conference for the USA and Canada are maintained in Janesville, Wisconsin. The Missionary Society offices are in Westerly, Rhode Island, and the Board of Christian Education has offices in Alfred Station, New York. The Seventh Day Baptist General Conference (USA and Canada) is a member of the Baptist World Alliance and is officially recognized by the Covenant Christian Coalition. The current General Secretary of the Seventh Day Baptist World Federation (founded in 1965) is Pastor Andrew Samuels, of the Miami Seventh Day Baptist Church.





</doc>
<doc id="29345" url="https://en.wikipedia.org/wiki?curid=29345" title="Shem">
Shem

Shem (; "Šēm"; "Sēm"; Ge'ez: ሴም, "Sēm"; "renown; prosperity; name"; Arabic: "Sām") was one of the sons of Noah in the Hebrew Bible as well as in Islamic literature. Genesis 10:21 refers to relative ages of Shem and his brother Japheth, but with sufficient ambiguity to have yielded different English translations. The verse is translated in the KJV as "Unto Shem also, the father of all the children of Eber, the brother of Japheth the elder, even to him were children born.". However, the New American Standard Bible gives, "Also to Shem, the father of all the children of Eber, and the older brother of Japheth, children were born."

Genesis 11:10 records that Shem was 100 years old at the birth of Arphaxad, two years after the flood; and that he lived for another 500 years after this, making his age at death 600 years.

The children of Shem were Elam, Asshur, Arphaxad, Lud and Aram, in addition to daughters. Abraham, the patriarch of the Hebrews and Arabs, was one of the descendants of Arphaxad.

Islamic literature describes Shem as one of the believing sons of Noah. Some sources even identify Shem as a 
prophet in his own right and that he was the next prophet after his father. In one Muslim legend, Shem was one of the people whom God made Jesus resurrect as a sign to the Children of Israel.

The 1st-century historian Flavius Josephus, among many others, recounted the tradition that these five sons were the progenitors of the nations of Elam, Assyria, Chaldea, Lydia, and Levantine, respectively.

The associated term "Semitic" is still a commonly used term for the Semitic languages, as a subset of the Afro-Asiatic languages, denoting the common linguistic heritage of Arabic, Aramaic, Akkadian, Ethiopic, Hebrew and Canaanite-Phoenician languages.

According to some Jewish traditions (e.g., B. Talmud Nedarim 32b; Genesis Rabbah 46:7; Genesis Rabbah 56:10; Leviticus Rabbah 25:6; Numbers Rabbah 4:8.), Shem is believed to have been Melchizedek, King of Salem whom Abraham is recorded to have met after the battle of the four kings.

Shem is mentioned several times in Genesis 5-11 as well as 1 Chronicles 1:4.

According to Genesis 10:22-31 ("Jewish Publication Society Translation" of 1917):

Excerpts from Genesis 11:10-27— ("Jewish Publication Society" translation of 1917):

A rabbinic document that surfaced in the 17th century, claiming to be the lost Book of Jasher provides some names not found in any other source.

According to Jesus is a descendant of Shem.

Early Islamic historians like Ibn Ishaq and Ibn Hisham always included Shem's name in the genealogy of Muhammad.

The following family tree contains information from the Hebrew Bible, without data from any other sources. According to Luke 3, an additional figure named Cainan is the son of Arpachshad and the father of Shelah.



</doc>
<doc id="29346" url="https://en.wikipedia.org/wiki?curid=29346" title="Sambuca">
Sambuca

Sambuca () is an Italian anise-flavoured, usually colourless, liqueur. Its most common variety is often referred to as "white sambuca" to differentiate it from other varieties that are deep blue in colour ("black sambuca") or bright red ("red sambuca"). Like other anise-flavoured liqueurs, the ouzo effect is sometimes observed when combined with water.

Sambuca is flavoured with essential oils obtained from star anise, or less commonly, green anise. Other spices such as elderflower, liquorice and others may be included, but are not required as per the legal definition. It is bottled at a minimum of 38% alcohol by volume. The oils are added to pure alcohol, a concentrated solution of sugar, and other flavouring.

The "Oxford English Dictionary" states that the term comes from the Latin word "sambucus", meaning "elderberry".

The Greek word "Sambuca" was first used as the name of another elderberry liquor that was created in Civitavecchia about 130 years ago.

The first commercial version of such a drink started at the end of 1800 in Civitavecchia, where Luigi Manzi sold "Sambuca Manzi". In 1945, soon after the end of Second World War, commendatore Angelo Molinari started producing "Sambuca Extra Molinari", which helped popularise Sambuca throughout Italy.

Both having originated as anise-based spirits containing elderberry, Sambuca shares some commonality with the Basque drink Patxaran.

Sambuca may be served neat. It may also be served on the rocks or with water, resulting in the ouzo effect from the anethole in the anise.

Sambuca is considered to go particularly well with coffee. Like other anise liqueurs, it may be drunk after coffee as a ammazzacaffè or added directly to coffee in place of sugar to produce a "caffè corretto".

A serving of sambuca can be a shot with seven coffee beans, representing the Seven hills of Rome. Likewise, a shot with one coffee bean, called "con la mosca", which means "with the fly", is as common. The traditional serving is with three coffee beans, each representing health, happiness and prosperity. The shot may be ignited to toast the coffee beans with the flame extinguished immediately before drinking.




</doc>
<doc id="29349" url="https://en.wikipedia.org/wiki?curid=29349" title="Sweeney Todd">
Sweeney Todd

Sweeney Todd is a fictional character who first appeared as the villain of the Victorian penny dreadful serial "The String of Pearls" (1846–47).

The tale became a staple of Victorian melodrama and London urban legend, and has been retold many times since, most notably in the Tony award–winning by Stephen Sondheim and Hugh Wheeler.

Claims that Sweeney Todd was a historical person are strongly disputed by scholars, although possible legendary prototypes exist.

In the original version of the tale, Todd is a barber who dispatches his victims by pulling a lever as they sit in his barber chair. His victims fall backward down a revolving trap door into the basement of his shop, generally causing them to break their necks or skulls. In case they are alive, Todd goes to the basement and "polishes them off" (slitting their throats with his straight razor). In some adaptations, the murdering process is reversed, with Todd slitting his customers' throats before dispatching them into the basement through the revolving trap door. After Todd has robbed his dead victims of their goods, Mrs. Lovett, his partner in crime (in some later versions, his friend and/or lover), assists him in disposing of the bodies by baking their flesh into meat pies and selling them to the unsuspecting customers of her pie shop. Todd's barber shop is situated at 152 Fleet Street, London, next to St. Dunstan's church, and is connected to Mrs. Lovett's pie shop in nearby Bell Yard by means of an underground passage. In most versions of the story, he and Mrs. Lovett hire an unwitting orphan boy, Tobias Ragg, to serve the pies to customers.

Sweeney Todd first appeared in a story titled "The String of Pearls: A Romance". This penny dreadful was published in 18 weekly parts, in Edward Lloyd's "The People's Periodical and Family Library", issues 7–24, 21 November 1846 to 20 March 1847. It was probably written by James Malcolm Rymer, though Thomas Peckett Prest has also been credited with it; possibly each worked on the serial from part to part. Other attributions include Edward P. Hingston, George Macfarren, and Albert Richard Smith. In February/March 1847, before the serial was even completed, George Dibdin Pitt adapted "The String of Pearls" as a melodrama for the Britannia Theatre in Hoxton. It was in this alternative version of the tale, rather than the original, that Todd acquired his catchphrase: "I'll polish him off".

Lloyd published another, lengthier, penny part serial from 1847–48, with 92 episodes. It was then published in book form in 1850 as "The String of Pearls", subtitled "The Barber of Fleet Street. A Domestic Romance". This expanded version of the story was 732 pages long. A plagiarised version of this book appeared in the United States c. 1852–53 as "Sweeney Todd: or the Ruffian Barber. A Tale of Terror of the Seas and the Mysteries of the City" by "Captain Merry" (a pseudonym for American author Harry Hazel, 1814–89).

In 1865 the French novelist Paul H.C. Féval (1816–1887), famous as a writer of horror and crime novels and short stories, referred to what he called "L'Affaire de la Rue des Marmousets", in the introductory chapter to his book "La Vampire". A version of this story is related by the author Jacques Yonnet in his book Rue des maléfices (1954). This version is set in late medieval (1387) Paris, at the corner of the Rue des Marmousets and the Rue des Deux-Hermites. The familiar plot of the barber and the pastrycook who sell pies made with human flesh is followed, the "dénouement" following one of the victims' dogs alerting neighbors and the gendarmes. The two confess, and are summarily burned alive; the houses where the crimes took place are then razed. Whether this version of the story is based on "The String of Pearls" or its dramatisation, or a much older tale alluded to by Féval is unclear. In any case, it may well be the source for some recent versions that move the tale from London to Paris.

In 1875, Frederick Hazleton's c. 1865 dramatic adaptation "Sweeney Todd, the Barber of Fleet Street: or the String of Pearls" (see below) was published as Vol 102 of "Lacy's Acting Edition of Plays".

A scholarly, annotated edition of the original 1846–47 serial was published in volume form in 2007 by the Oxford University Press under the title of "Sweeney Todd: The Demon Barber of Fleet Street", edited by Robert Mack.

The original story of Sweeney Todd quite possibly stems from an older urban legend, originally based on dubious pie-fillings. In Charles Dickens' "Pickwick Papers" (1836–37), the servant Sam Weller says that a pieman used cats "for beefsteak, veal and kidney, 'cording to the demand", and recommends that people should buy pies only "when you know the lady as made it, and is quite sure it ain't kitten." Dickens then developed this in "Martin Chuzzlewit" (1843–44), published two years before the appearance of Sweeney Todd in "The String of Pearls" (1846–47), with a character called Tom Pinch who is grateful that his own "evil genius did not lead him into the dens of any of those preparers of cannibalic pastry, who are represented in many country legends as doing a lively retail business in the metropolis".

Claims that Sweeney Todd was a real person were first made in the introduction to the 1850 (expanded) edition of "The String of Pearls" and have persisted to the present day. In two books, Peter Haining argued that Sweeney Todd was a historical figure who committed his crimes around 1800. Nevertheless, other researchers who have tried to verify his citations find nothing in these sources to back Haining's claims.

A late (1890s) reference to the urban legend of the murdering barber can be found in the poem by the Australian bush poet Banjo Paterson—"The Man from Ironbark".

In his 2012 novel" Dodger", Terry Pratchett portrays Sweeney Todd as a tragic figure, having lost his mind after being exposed to the horrors of the Napoleonic Wars as a barber surgeon.








In rhyming slang, Sweeney Todd is the Flying Squad (a branch of the UK's Metropolitan Police), which inspired the television series "The Sweeney".




</doc>
<doc id="29352" url="https://en.wikipedia.org/wiki?curid=29352" title="Selection sort">
Selection sort

In computer science, selection sort is a sorting algorithm, specifically an in-place comparison sort. It has O("n") time complexity, making it inefficient on large lists, and generally performs worse than the similar insertion sort. Selection sort is noted for its simplicity, and it has performance advantages over more complicated algorithms in certain situations, particularly where auxiliary memory is limited.

The algorithm divides the input list into two parts: the sublist of items already sorted, which is built up from left to right at the front (left) of the list, and the sublist of items remaining to be sorted that occupy the rest of the list. Initially, the sorted sublist is empty and the unsorted sublist is the entire input list. The algorithm proceeds by finding the smallest (or largest, depending on sorting order) element in the unsorted sublist, exchanging (swapping) it with the leftmost unsorted element (putting it in sorted order), and moving the sublist boundaries one element to the right.

Here is an example of this sort algorithm sorting five elements:

Selection sort can also be used on list structures that make add and remove efficient, such as a linked list. In this case it is more common to "remove" the minimum element from the remainder of the list, and then "insert" it at the end of the values sorted so far. For example:

Selection sort is not difficult to analyze compared to other sorting algorithms since none of the loops depend on the data in the array. Selecting the minimum requires scanning formula_1 elements (taking formula_2 comparisons) and then swapping it into the first position. Finding the next lowest element requires scanning the remaining formula_2 elements and so on. Therefore, the total number of comparisons is

formula_4

By the hockey-stick identity,

formula_5

which is of complexity formula_6 in terms of number of comparisons. Each of these scans requires one swap for formula_2 elements (the final element is already in place).

Among simple average-case Θ("n") algorithms, selection sort almost always outperforms bubble sort and gnome sort. Insertion sort is very similar in that after the "k"th iteration, the first "k" elements in the array are in sorted order. Insertion sort's advantage is that it only scans as many elements as it needs in order to place the "k" + 1st element, while selection sort must scan all remaining elements to find the "k" + 1st element.

Simple calculation shows that insertion sort will therefore usually perform about half as many comparisons as selection sort, although it can perform just as many or far fewer depending on the order the array was in prior to sorting. It can be seen as an advantage for some real-time applications that selection sort will perform identically regardless of the order of the array, while insertion sort's running time can vary considerably. However, this is more often an advantage for insertion sort in that it runs much more efficiently if the array is already sorted or "close to sorted."

While selection sort is preferable to insertion sort in terms of number of writes (Θ("n") swaps versus Ο("n") swaps), it almost always far exceeds (and never beats) the number of writes that cycle sort makes, as cycle sort is theoretically optimal in the number of writes. This can be important if writes are significantly more expensive than reads, such as with EEPROM or Flash memory, where every write lessens the lifespan of the memory.

Finally, selection sort is greatly outperformed on larger arrays by Θ("n" log "n") divide-and-conquer algorithms such as mergesort. However, insertion sort or selection sort are both typically faster for small arrays (i.e. fewer than 10–20 elements). A useful optimization in practice for the recursive algorithms is to switch to insertion sort or selection sort for "small enough" sublists.

Heapsort greatly improves the basic algorithm by using an implicit heap data structure to speed up finding and removing the lowest datum. If implemented correctly, the heap will allow finding the next lowest element in Θ(log "n") time instead of Θ("n") for the inner loop in normal selection sort, reducing the total running time to Θ("n" log "n").

A bidirectional variant of selection sort, called cocktail sort, is an algorithm which finds both the minimum and maximum values in the list in every pass. This reduces the number of scans of the list by a factor of 2, eliminating some loop overhead but not actually decreasing the number of comparisons or swaps. Note, however, that cocktail sort more often refers to a bidirectional variant of bubble sort. Sometimes this is double selection sort.

Selection sort can be implemented as a stable sort. If, rather than swapping in step 2, the minimum value is inserted into the first position (that is, all intervening items moved down), the algorithm is stable. However, this modification either requires a data structure that supports efficient insertions or deletions, such as a linked list, or it leads to performing Θ("n") writes.

In the bingo sort variant, items are ordered by repeatedly looking through the remaining items to find the greatest value and moving all items with that value to their final location. Like counting sort, this is an efficient variant if there are many duplicate values. Indeed, selection sort does one pass through the remaining items for each item moved. Bingo sort does one pass for each value (not item): after an initial pass to find the biggest value, the next passes can move every item with that value to its final location while finding the next value as in the following pseudocode (arrays are zero-based and the for-loop includes both the top and bottom limits, as in Pascal):

Thus, if on average there are more than two items with the same value, bingo sort can be expected to be faster because it executes the inner loop fewer times than selection sort.



</doc>
<doc id="29353" url="https://en.wikipedia.org/wiki?curid=29353" title="Syracuse University">
Syracuse University

Syracuse University (commonly referred to as Syracuse, 'Cuse, or SU) is a private research university in Syracuse, New York, United States. The institution's roots can be traced to the Genesee Wesleyan Seminary (later becoming Genesee College), founded in 1831 by the Methodist Episcopal Church in Lima, New York. After several years of debate over relocating the college to Syracuse, the university was established in 1870, independent of the college. Since 1920, the university has identified itself as nonsectarian, although it maintains a relationship with The United Methodist Church.

The campus is in the University Hill neighborhood of Syracuse, east and southeast of downtown, on one of the larger hills. Its large campus features an eclectic mix of buildings, ranging from nineteenth-century Romanesque Revival structures to contemporary buildings. SU is organized into 13 schools and colleges, with nationally recognized programs in information studies and library science, architecture, communications, business administration, inclusive education and wellness, sport management, public administration, engineering and the College of Arts and Sciences.

Syracuse University athletic teams, known as the Orange, participate in 20 intercollegiate sports. SU is a member of the Atlantic Coast Conference for all NCAA Division I athletics, except for the men's rowing and women's ice hockey teams. SU is also a member of the Eastern College Athletic Conference.

The Genesee Wesleyan Seminary was founded in 1831 by the Genesee Annual Conference of the Methodist Episcopal Church in Lima, New York, south of Rochester. In 1850, it was resolved to enlarge the institution from a seminary into a college, or to connect a college with the seminary, becoming Genesee College. However, the location was soon thought by many to be insufficiently central. Its difficulties were compounded by the next set of technological changes: the railroad that displaced the Erie Canal as the region's economic engine bypassed Lima completely. The trustees of the struggling college then decided to seek a locale whose economic and transportation advantages could provide a better base of support.
The college began looking for a new home at the same time Syracuse, ninety miles to the east, was engaged in a search to bring a university to the city, having failed to convince Ezra Cornell and Andrew Dickson White to locate Cornell University there rather than in Ithaca. Syracuse resident White pressed that the new university should locate on the hill in Syracuse (the current location of Syracuse University) due to the city's attractive transportation hub, which would ease the recruitment of faculty, students, and other persons of note. However, as a young carpenter working in Syracuse, Cornell had been twice robbed of his wages, and thereafter considered Syracuse a Sodom and Gomorrah insisting the university be in Ithaca on his large farm on East Hill, overlooking the town and Cayuga Lake.
Meanwhile, there were several years of dispute between the Methodist ministers, Lima, and contending cities across the state, over proposals to move Genesee College to Syracuse. At the time, the ministers wanted a share of the funds from the Morrill Land Grant Act for Genesee College. They agreed to a "quid pro quo" donation of $25,000 from Senator Cornell in exchange for their (Methodist) support for his bill. Cornell insisted the bargain be written into the bill and Cornell became New York State's Land Grant University in 1865. In 1869, Genesee College obtained New York State approval to move to Syracuse, but Lima got a court injunction to block the move, and Genesee stayed in Lima until it was dissolved in 1875. By that time, however, the court injunction had been made moot by the founding of a new university on March 24, 1870. On that date the State of New York granted the new Syracuse University its own charter, independent of Genesee College. The City of Syracuse had offered $100,000 to establish the school. Bishop Jesse Truesdell Peck had donated $25,000 to the proposed school and was elected the first president of the Board of Trustees.

Rev. Daniel Steele, a former Genesee College president, served as the first administrative leader of Syracuse until its Chancellor was appointed. The university opened in September 1871 in rented space downtown. George F. Comstock, a member of the new University's Board of Trustees, had offered the school of farmland on a hillside to the southeast of the city center. Comstock intended Syracuse University and the hill to develop as an integrated whole; a contemporary account described the latter as "a beautiful town ... springing up on the hillside and a community of refined and cultivated membership ... established near the spot which will soon be the center of a great and beneficent educational institution."

The university was founded as coeducational. President Peck stated at the opening ceremonies, "The conditions of admission shall be equal to all persons... there shall be no invidious discrimination here against woman... brains and heart shall have a fair chance... " Syracuse implemented this policy with a high proportion of women students. In the College of Liberal Arts, the ratio between male and female students during the 19th century was approximately even. The College of Fine Arts was predominantly female, and a low ratio of women enrolled in the College of Medicine and the College of Law. Men and women were taught together in the same courses, and many extra-curricular activities were coeducational as well. Syracuse also developed "women-only" organizations and clubs.

Coeducation at Syracuse traced its roots to the early days of Genesee College where educators and students like Frances Willard and Belva Lockwood were heavily influenced by the Women's movement in nearby Seneca Falls, NY. However, the progressive "co-ed" policies practiced at Genesee would soon find controversy at the new university in Syracuse. Colleges and universities admitted few women students in the 1870s. Administrators and faculty argued women had inferior minds and could not master mathematics and the classics. Dr. Erastus Otis Haven, Syracuse University chancellor and former president of the University of Michigan and Northwestern University, maintained that women should receive the advantages of higher education. He enrolled his daughter, Frances, at Syracuse where she joined the other newly admitted female students in founding the Gamma Phi Beta sorority. The inclusion of women in the early days of the university led to the proliferation of various women's clubs and societies. In fact, it was a Syracuse professor who coined the term "sorority" specifically for Gamma Phi Beta.

In the late 1880s the university engaged in a rapid building spree. Holden Observatory (1887) was followed by two Romanesque Revival buildings – von Ranke Library (1889), now Tolley Humanities Building, and Crouse College (1889). Together with the Hall of Languages, these first buildings formed the basis for the "Old Row," a grouping which, along with its companion Lawn, established one of Syracuse's most enduring images. The emphatically linear organization of these buildings along the brow of the hill follows a tradition of American campus planning which dates to the construction of the "Yale Row" in the 1790s. At Syracuse, the Old Row continued to provide the framework for growth well into the twentieth century.

From its founding until through early 1920s, the university grew rapidly. It offered programs in the physical sciences and modern languages, and in 1873, Syracuse added one of the first architecture programs in the U.S. In 1874, Syracuse created the nation's first bachelor of fine arts degree, and in 1876, the school offered its first post-graduate courses in the College of Arts and Sciences. SU created its first doctoral program in 1911. In 1919, Syracuse added its business school which contains multiple MBA programs. SU's school of journalism, now the S.I. Newhouse School of Public Communications, was established at Syracuse in 1934.

The growth of Syracuse University from a small liberal arts college into a major comprehensive university were due to the efforts of two men, Chancellor James Day and John Archbold. James Roscoe Day was serving the Calvary Church in New York City where he befriended Archbold. Together, the two dynamic figures would oversee the first of two great periods of campus renewal in Syracuse's history.
John Dustin Archbold was a capitalist, philanthropist, and President of the Board of Trustees at Syracuse University. He was known as John D. Rockefeller's right-hand man and successor at the Standard Oil Company. He was a close friend of Syracuse University Chancellor James R. Day, and gave almost $6 million to the university over his lifetime. Said a journalist in 1917:
Mr. Archbold's ... is the president of the board of trustees of Syracuse University, an institution which has prospered so remarkably since his connection with it that its student roll has increased from hundreds to over 4,000, including 1,500 young women, placing it in the ranks of the foremost institutions of learning in the United States.
In addition to keeping the university financially solvent during its early years, he also contributed funds for eight buildings, including the full cost of Archbold Stadium (opened 1907, demolished 1978), Sims Hall (men's dormitory, 1907), the Archbold Gymnasium (1909, nearly destroyed by fire in 1947, but still in use), and the oval athletic field.

After World War II, Syracuse University began to transform into a major research institution. Enrollment increased in the four years after the war due to the G.I. Bill, which paid tuition, room, board, and a small allowance for veterans returning from World War II. In 1946, SU admitted 9,464 freshmen, nearly four times greater than the previous incoming class. Branch campuses were established in Endicott, New York and Utica, New York.
The velocity with which the university sped through its change into a major research institution was astounding. By the end of the 1950s, Syracuse ranked twelfth nationally in terms of the amount of its sponsored research, and it had over four hundred professors and graduate students engaging in that investigation.

From the early 1950s through the 1960s, Syracuse University added programs and staff that continued the transformation of the school into a research university. In 1954, Arthur Phillips was recruited from MIT and started the first pathogen-free animal research laboratory. The lab focused on studying medical problems using animal models. The School of Social Work, which eventually merged into the College of Human Ecology, was founded in 1956. Syracuse's College of Engineering also founded the nation's second oldest computer engineering and bioengineering programs. In 1962, Samuel Irving Newhouse, Sr. donated $15 million to begin construction of a school of communications, eventually known as the SI Newhouse School of Public Communications. In 1966, Syracuse University was admitted to the Association of American Universities, an organization of leading research universities devoted to maintaining a strong system of academic research and education.

On December 21, 1988, 35 Syracuse University students were killed in the terrorist bombing of Pan Am Flight 103 over Lockerbie, Scotland. The students were returning from a study-abroad program in Europe.

That evening, Syracuse University went on with a basketball game just hours after the attack, for which it was severely criticized. The conduct of university officials in making the decision was also brought to the attention of the NCAA. The day after the bombing, the university's chancellor, Melvin A. Eggers, said on nationwide television that he should have cancelled the event. After the attacks on September 11, 2001, the NCAA left it up to the conferences to decide what to do about their sports events; many cancelled them. The bombing of Flight 103 was the deadliest terrorist attack against the United States prior to the attacks on September 11, 2001.

In April 1990, Syracuse University dedicated a memorial wall to the students killed on Flight 103, constructed at the entrance to the main campus in front of the Hall of Languages. Every year the university holds "Remembrance Week" during the fall semester to commemorate the students. On December 21 a service in the university's chapel at 2:03 p.m. (19:03 UTC) marks the exact minute on that date in 1988 when the plane exploded. The university also maintains a link to the tragedy with the "Remembrance Scholars" program, when 35 senior students receive scholarships during their final year at the university. With the "Lockerbie Scholars" program, two graduating students from Lockerbie Academy study at Syracuse for one year.

The university is set on a campus that features an eclectic mix of buildings, ranging from nineteenth-century Romanesque Revival structures to contemporary buildings designed by renowned architects such as I.M. Pei. The center of campus, with its grass quadrangle, landscaped walkways, and outdoor sculptures, offers students the amenities of a traditional college experience. The university overlooks downtown Syracuse, a medium-sized city (140,600 residents in 2008). The school also owns a Sheraton Hotel, the Drumlins Country Club — a nearby, 36-hole golf course, the Fisher Center and Joseph I. Lubin House in New York City, the Paul Greenberg House in Washington, D.C., and the Minnowbrook Conference Center, a 30-acre (121,000 m²) retreat in the Adirondack Mountains of Upstate New York.

Also called "North Campus," the Main Campus contains nearly all academic buildings and residence halls. Its centerpiece is The Kenneth A. Shaw Quadrangle, more affectionately known as "The Quad", which is surrounded by academic and administrative buildings. The North Campus represents a large portion of the University Hill neighborhood. Buses run to South Campus, as well as downtown Syracuse and other locations in the city. About 70 percent of students live in university housing. First- and second-year students are required to live on campus. All 22 residence halls are coeducational and each contain a lounge, laundry facility, and various social/study spaces. Residence halls are secured with a card access system. Residence halls are located on both Main Campus and South Campus, the latter of which is a five-minute ride via bus. Learning communities and interest housing options are also available. Food facilities include six residential dining centers, two food courts, and several cafes.

The Comstock Tract Buildings, a historic district of older buildings on the campus, was listed on the National Register of Historic Places in 1980. Three buildings on campus—the Crouse Memorial College and the Hall of Languages, and the Pi Chapter House of Psi Upsilon Fraternity—are individually listed on the National Register.

A few blocks walk from Main Campus on East Genesee St, the Syracuse Stage building includes two proscenium theatres. The Storch is used primarily by the Drama Department and the Archbold is used primarily by Syracuse Stage, a professional regional theatre.

After World War II, a large, undeveloped hill owned by the university was used to house returning veterans in military-style campus housing. During the 1970s, this housing was replaced by permanent two-level townhouses for two or three students each, or for graduate family housing. There are also three small residence halls which feature open doubles. South Campus is also home to the Institute for Sensory Research, Tennity Ice Pavilion, Goldstein Student Center, Skytop Office Building and 621 Skytop Road (for administration), and the InnComplete Pub, a graduate student bar. Just north is the headquarters of SU Athletics, Manley Field House, located in the Manley Athletics Complex. Approximately 2,500 students live on the South Campus, which is connected to the main campus by frequent bus service.

In December 2004, the university announced that it had purchased or leased twelve buildings in downtown Syracuse. Five design programs—Communication, Advertising, Environmental and Interior Design, Industrial and Interactive Design, and Fashion—reside permanently in the newly renovated facilities, fittingly called The Warehouse, which was renovated by Gluckman Mayner Architects. Both programs were chosen to be located in the downtown area because of their history of working on projects directly with the community. The Warehouse also houses a contemporary art space that commissions, exhibits, and promotes the work of local and international artists in a variety of media. Hundreds of students and faculty have also been affected by the temporary move of the School of Architecture downtown for the $12 million renovation of its campus facility, Slocum Hall.

Since 2009, the Syracuse Center of Excellence in Environmental and Energy Systems, led by Syracuse University in partnership with Clarkson University and the College Environmental Science and Forestry, creates innovations in environmental and energy technologies that improve human health and productivity, security, and sustainability in urban and built environments. The Paul Robeson Performing Arts Company and the Community Folk Art Center will also be located downtown. On March 31, 2006, the university and the city announced an initiative to connect the main campus of the university with the arts and culture areas of downtown Syracuse and The Warehouse. Using natural gas, the Green Data Center generates its own electricity on site, providing cooling for servers and for a neighboring building.

The Connective Corridor project, supported by of public and private funds, will be a strip of cultural development that will connect the main campus of the university to downtown Syracuse, NY. In 2008, an engineering firm is studying traffic patterns and lighting to commence the project. A design competition was held to determine the best design for the project.

SU has established an admissions presence in Los Angeles, California that will enhance the university's visibility on the West Coast and will join the University's West Coast offices of alumni relations, institutional advancement, and the LA semester program in the same location. Syracuse University has also established an admissions presence in New York City and Atlanta, Georgia.

Syracuse is home to the SU Art Galleries, whose mission is to enhance the cultural environment of its community and surrounding area. The main gallery space is located in the Shaffer Art Building on the main campus.

The Warehouse Gallery is a new contemporary art space exhibiting that is operated under the umbrella of the SU Art Galleries. Housed in a former furniture warehouse off campus, the Warehouse Gallery features works from international artists in a variety of media. Its mission is to engage the community in a dialogue regarding the role the arts can play in illuminating the critical issues of our times.

Also on campus is the Louise and Bernard Palitz Gallery. Located on the second floor of the Lubin House, the Palitz gallery has a rotation of exhibitions, including two annual public shows, local and regional artists, featured items from the university's art collection, and professional artists.

There are many other venues for student work at Syracuse University. In the Shaffer Art Building is the Lowe Art Gallery, which features student work. Gallery spaces are also available for reservation on the fourth floor of the Bird Library.

Within the Schine Student Center is home to three gallery spaces. The Robert B Menschel Photography Gallery features work from professional photographers as well as students and local artists. On the third floor is the Panasci Lounge Art Hanging space for two dimensional spaces. This space can be reserved by students. The White Cube Gallery, also on the third floor is a student gallery that showcases work for the student body outside of the school of art and design.

Students can also research primary sources through the Special Collections Research Center (SCRC) which is composed of rare books, manuscripts, works of architecture and design, and popular culture (cartoons, science fiction, and pulp literature), photography, the history of recorded sound, and more.

SU has a permanent art collection of over 45,000 objects from artists including Picasso, Rembrandt, Hopper, Tiffany and Wyeth. More than 100 important paintings, sculptures, and murals are displayed in public places around campus. Notable sculptures on campus include Sol LeWitt's "Six Curved Walls", Anna Hyatt Huntington's "Diana", Jean-Antoine Houdon's "George Washington", Antoine Bourdelle's "Herakles", James Earle Fraser's "Lincoln", Malvina Hoffman's "The Struggle of Elemental Man," and Ivan Meštrović's "Moses", "Job" and "Supplicant Persephone".

Syracuse is governed by a 70-member Board of Trustees, with 64 trustees elected by the board to four-year terms, and six elected by the alumni to four-year terms. Of the 64 Board elected Trustees, three must represent specified conferences of the United Methodist Church. In addition, the chancellor and the President of the Syracuse Alumni Association serve as ex officio voting Trustees. Two students and one faculty member serve as non-voting representatives to the Board of Trustees. The Board of Trustees selects, and sets the salary of, the chancellor. The Syracuse University Bylaws also establish a University Senate with "general supervision over all educational matters concerning the University as a whole". The Senate consists of administrators, faculty, students and staff.

For the Class of 2018, there were approximately 34,614 applicants for 3,350 seats in the Freshman class. In fall 2006, the university had over 12,000 full-time undergraduate students and over 1,000 part-time undergraduate students, as well as almost 4,000 full-time graduate and law students and 2,000 part-time graduate and law students. In 2005–06, the university granted over 2,600 bachelor's degrees; nearly 2,000 master's degrees; over 300 law degrees; and more than 160 doctoral degrees. "U.S. News & World Report" ranked SU 53rd among national universities in the United States for 2009, 58th for 2013 and 61st in 2016. Syracuse participates in the National Association of Independent Colleges and Universities and University and College Accountability Network (U-CAN).

SU offers undergraduate degrees in over 200 majors in the 9 undergraduate schools and colleges. Bachelor's degrees are offered through the Syracuse University School of Architecture, the College of Arts and Sciences, the School of Education, the David B. Falk College of Sport and Human Dynamics, the College of Engineering and Computer Science, the School of Information Studies, Martin J. Whitman School of Management, S.I. Newhouse School of Public Communications, and the College of Visual and Performing Arts. Also offered are Master's and doctoral degrees online and in person from the Graduate School and from specialized programs in the Martin J. Whitman School of Management, Maxwell School of Citizenship and Public Affairs, College of Law, among others. Additionally, SU offers 24 Certificates of Advanced Study Programs for specialized programs for education, counseling, and other academic areas.

The university has offered multiple international study programs since 1911. SU Abroad, formerly known as the Division of International Programs Abroad (DIPA), currently offers joint programs with universities in over 40 countries. The university operates eight international centers, called SU Abroad Centers, that offer structured programs in a variety of academic disciplines. The centers are located Beijing, Istanbul, Florence, Hong Kong, London, Madrid, Strasbourg, and Santiago.

In its 2018 ranking of U.S. colleges, "U.S. News & World Report" ranked Syracuse tied for 61st among undergraduate national universities. In 2015, Syracuse University was ranked 24th in New York State by average professor salaries. Some of SU's programs have been nationally recognized for excellence. A 2008 survey in the Academic Ranking of World Universities places Syracuse University in the top 100 world universities in social sciences. In the 2015 'Design Intelligence' national rankings, the Environmental and Interior Design program is ranked 9th. The School of Architecture's Bachelor of Architecture program was ranked second nationally in 2010 by the journal "DesignIntelligence" in its annual edition of "America's Best Architecture & Design Schools." Syracuse was ranked 5th in "The Princeton Review"'s 2014 and 1st in the 2015 list of top party schools.

The S.I. Newhouse School of Public Communications is one of the top ranked in the country and has produced alumni in many fields of broadcasting. The School of Information Studies offers information management and technology courses at the undergraduate and graduate levels at Syracuse University. Within the School of Information Studies, "U.S. News & World Report" has ranked the graduate program as the third best Library and Information Studies graduate school in the United States. It also has the top-ranked graduate Information Systems program, the second ranked graduate program in Digital Librarianship, and the fourth ranked graduate program in School Library Media. The School of Management was renamed the Martin J. Whitman School of Management in 2003, in honor of SU alumnus and benefactor Martin J. Whitman. The school is home to about 2,000 undergraduate and graduate students.

The undergraduate program was ranked No. 43 among business schools nationwide by "U.S. News & World Report" in 2014 while the graduate school was ranked No. 88. The entrepreneurship program was ranked No. 9 by the "U.S. News & World Report" in 2014, and No. 13 by both "Entrepreneur Magazine" and "The Princeton Review" in 2007. The supply chain management program was ranked No. 10 in the nation by "Supply Chain Management Review". Also, the Joseph I. Lubin School of Accounting was named No. 10 in the nation by "The Chronicle of Higher Education".

The College of Law is ranked 92nd nationally by "U.S. News & World Report". It is an emerging leader in the relatively novel field of National Security Law. In 2007 the Law School started the Cold Case Justice Initiative, investigating cold cases from the civil rights era in the South. Its professors and students have identified 196 cases, of which more than 100 are in Georgia, and will give information to the US Department of Justice in order to have cases prosecuted. The FBI has identified 122 cold cases that it is trying to resolve.

The Maxwell School of Citizenship and Public Affairs combines social sciences with public administration and international relations. It is ranked as the top graduate school for public affairs in the US.

The graduate program of the College of Visual and Performing Art is considered one of the top 50 programs in the US. VPA ranked No. 14 in multimedia/visual communications, a specialty that includes disciplines found in the college's Department of Transmedia, which offers M.F.A. programs in art photography, art video, computer art and film. VPA also ranked No. 16 in ceramics, No. 19 in printmaking and No. 20 in sculpture, which are M.F.A. programs based in the Department of Art. Project Advance (or SUPA) is a nationally recognized concurrent enrollment program honored by the American Association for Higher Education, the Carnegie Foundation for the Advancement of Teaching, the National Commission on Excellence in Education, and the National Institute of Education.

Syracuse University has 1013 full-time instructional faculty, 96 part-time faculty, and 454 adjunct faculty. Approximately 86% of the full-time faculty have earned Ph.D.s or professional degrees. The current faculty includes scholars such as United States National Academy of Sciences member Jozef J. Zwislocki, Professor of Psychology, who developed mathematical models on the mechanics of the inner and middle ear, MacArthur Fellow Don Mitchell, Professor of Geography, who has developed studies in cultural geography, Bruce Kingma, Associate Provost and Kauffman Professor of Entrepreneurship, a pioneer in the field of information economics and online learning, Catherine Bertini, Professor of Practice in Public Administration, who has worked on the role of women in food distribution, Frederick C. Beiser, Professor of Philosophy, one of leading scholars of German idealism, Mary Karr, the Jesse Truesdell Peck Professor of Literature, who has received a Guggenheim Fellowship in poetry, John Caputo, the Thomas J. Watson Professor of Humanities, who founded weak theology, and Gustav Niebuhr Associate Professor of Religion and Media who is the former New York Times National Religion Correspondent.

Syracuse University Press is a university press that is part of Syracuse University. The areas of focus for the Press include Middle East studies, Native American studies, peace and conflict resolution, Irish studies and Jewish studies, New York State, television and popular culture, sports and entertainment. The Press was founded on August 2, 1943 by Chancellor William Pearson Tolley and benefactor Thomas Watson, Sr.. It is a member of the Association of American University Presses.

Every year as a tradition, the university invites speakers from around the world, leading thinkers and practitioners in sustainability, advertising, redevelopment, human rights, journalism, and the environment. The lecturers are selected for their academic and public service excellence. The university lectures are supported by the university trustees, alumni, and friends. Previous university lecturers have included Ishmael Beah, author of ""; 45th vice president of the United States Al Gore; economist and Nobel Prize winner Muhammad Yunus; author and columnist William Safire; environmental justice advocate Majora Carter; and environmental law attorney Robert Kennedy Jr.

Syracuse University's main library is the Ernest S. Bird Library, which opened in 1972. Its seven levels contain 2.3 million books, 11,500 periodicals, of manuscripts and rare books, 3.6 million microforms, and a café. There are also several departmental libraries on campus. Many of the landmarks in the history of recorded communication between people are in the university's Special Collections Research Center, from cuneiform tablets and papyri to several codices dating from the 11th century, to the invention of printing. The collection also includes works by Galileo, Luther, John Calvin, Voltaire, Sir Isaac Newton, Descartes, Sir Francis Bacon, Samuel Johnson, Thomas Hobbes, Goethe, and others. In addition, the collection includes the personal library of Leopold Von Ranke.

Making sensational headlines at the time, the university outbid the Prussian government for all 19 tons of Von Ranke's prized personal library. Other collections of note include Rudyard Kipling first editions and an original second leaf of the Gutenberg Bible.

Bird Library is also home to the largest collection of national archives of Kenya and Tanzania. In July 2008, Syracuse University became the owner of the second largest collection of 78 rpm records in the United States after the Library of Congress after a donation of more than 200,000 records. The donation is valued at $1 million and more than doubles the university's collection of 78 rpm records to about 400,000. It also has a special Harriet Tubman Research Collection and an Environmental Justice and Gender collection housed in the Martin Luther King Jr. Memorial Library. The MLK library holds over 15,000 acquisitions in African, African-American, Afro-Latino, and Caribbean studies.

The university is also home to the Belfer Audio Laboratory and Archive, whose holdings total approximately 540,000 recordings in all formats, primarily cylinders, discs, and magnetic tapes. Some of the voices to be found include Thomas Edison, Amelia Earhart, Albert Einstein, and Oscar Wilde.

According to the Carnegie Classification of Institutions of Higher Education, Syracuse University is a research university with "highest level of research activity." Through the university's Office of Research, which promotes research, technology transfer, and scholarship, and its Office of Sponsored Programs, which assists faculty in seeking and obtaining external research support, SU supports research in the fields of management and business, sciences, engineering, education, information studies, energy, environment, communications, computer science, public and international affairs, and other specialized areas. Syracuse became a member of the Association of American Universities (AAU) in 1966, an organization of leading research universities devoted to maintaining a strong system of research and education. In 2011, however, the university's board of trustees voted to pull out of the research consortium.

SU has established 29 research centers and institutes that focuses research, often across disciplines, in a variety of areas. The Burton Blatt Institute advances research in economic and social issues for individuals with disabilities, and it has international projects in the field. The Martin J Whitman School of Management supports the largest number of research centers, including The Ballentine Investment Institute, the George E. Bennett Center for Accounting and Tax Research, the Robert H. Brethren Operations Management Institute, Michael J. Falcone Center for Entrepreneurship, The H. H. Franklin Center for Supply Chain Management, Olivia and Walter Kiebach Center for International Business Studies, and the Earl V. Snyder Innovation Management Program. In 2010, the University launched SURFACE, an online, open-access institutional repository for research, which is ran by the Syracuse University Library System. 

Other research programs include The Syracuse Biomaterials Institute, the Alan K. Campbell Public Affairs Institute through the Maxwell School, and the Center for the Study of Popular Television through the Newhouse School of Public Communications.

Syracuse University also has collaborations with CERN and Fermi National Accelerator Laboratory, among other institutes. Syracuse also has a comparatively large number of collaborators on the LIGO Scientific project and is actively involved with the search for gravitational waves using data from the gravitational-wave detectors.

Syracuse University has a diverse student population, representing all 50 US states and over 115 countries. Approximately 10 percent of students are from outside of the US, and are supported by an international services department within the University's Division of Student Affairs. Approximately 37% of students in the fall 2010 undergraduate full-time class are from New York State. Approximately 56% of that class are women. In 2014, 8.8% of the students were black or African-American. In 2015, black students made up 14.7% of all US college students.

CitrusTV (formerly UUTV, HillTV and Synapse) is the university's entirely student-run television studio, and one of the largest student-run TV studios in the country with over 300 active members. There are also multiple student-run magazines and other print publications, including: "The Onondagan Yearbook, the Daily Orange, Student Voice, Perception, Jerk Magazine, What the Health, 360, Baked Magazine, The Out Crowd", and "Equal Time."

Founded in 1957, the Student Association (SA) represents the undergraduate students of both SU and ESF. SA, elects a President and Vice President (on a unified ticket) each academic year. They also each year elect a Comptroller, who, with the assembly, oversees the allocation and designation of the Student Activity Fee that was first collected in the 1968–69 school year. The goals of SA are to participate through a unified student voice in the formulation of Syracuse University rules and regulations. The SA-SGA Alumni Organization maintains the history and an organizational timeline on its website.

The graduate students at Syracuse University are represented by the Graduate Student Organization (GSO) while the law students at Syracuse University are represented by the Law Student Senate. Each of the three organizations elects students to serve in the Syracuse University Senate, which also includes faculty, staff, and administrators.

The Syracuse University fraternity and sorority system offers organizations that are members of the Panhellenic Council (NPC), the Interfraternity Council (IFC), the National Association of Latino Fraternal Organizations, the National Multicultural Greek Council, the Professional Fraternity Council (PFC), and the National Pan-Hellenic Council (NPHC). In addition to SU students, ESF students are permitted to join the university's fraternity and sorority system.

The oldest fraternity at SU is Delta Kappa Epsilon, which established a chapter in 1871 soon after the founding of the university, followed by Psi Upsilon in 1875 and Phi Kappa Psi in 1884. Sororities were also a part of the early history of SU. Alpha Phi was founded at SU in 1872, followed by Gamma Phi Beta in 1874 and Alpha Gamma Delta in 1904. Alpha Phi Alpha established a chapter at SU in 1910, and was reorganized in 1949 and 1973. The first NPHC fraternity, Omega Psi Phi, was established at SU in 1922, and the first NPHC sorority, Delta Sigma Theta in 1973. Alpha Phi Delta, the only historically Italian-American heritage fraternity, was founded at SU in 1914. University policy prohibits fraternities and sororities from discriminating "on the basis of race, creed, color, gender, national origin, religion, marital status, age, disability, sexual orientation, or status as a disabled veteran or a veteran of the Vietnam era."

Syracuse University Ambulance, commonly referred to as SUA, is a SU Health Services-based student organization that responds to over 1,500 medical emergencies each year. Providing intermediate life support (ILS), rapid cardiac defibrillation, emergency and nonemergency transportation, and special event standby services, SUA operates two full-time transporting ambulances, a supervisor's fly car, and a MCI trailer for mass-casualty incidents. Additionally, SUA operates four transport vans for non-emergency transports. Advanced life support (ALS) mutual aid is provided by the City of Syracuse's private EMS provider, Rural/Metro Medical Services. SUA was formed in 1973 by a group of students out of a need for emergency medical services on campus. Starting with only a few members and meager equipment, the Syracuse University Medical Crisis Unit was formed. The organization has evolved greatly over time but, with 70+ volunteer students, remains a student-run organization to this day. SUA provides emergency and non-emergency services 24 hours a day, 7 days a week during the academic school year and is funded by a portion of the student health fee.

Hendricks Chapel is an interfaith chapel located on the Quad, and services as the spiritual center of Syracuse University. The Chapel, headed by Dean Tiffany Steinwert, is home to ten chaplaincies, including Baptist, Buddhist, Evangelical Christian, Historically Black Churches, Islamic, Jewish, Lutheran, Pagan, Methodist, and Roman Catholic. In addition, there are a number of student religious groups, including groups associated with the chaplaincies as well as Adventist, Christian Science, Hindu, Mormon, Muslim, Orthodox Christian, Pentecostal, and more.

Additional buildings located on campus support specific religious groups, including the Alibrandi Catholic Center and the Winnick Hillel Center for Jewish Life. Off campus, the Chabad House and Islamic Center of CNY also support student religious life.

Syracuse University's sports teams have "the Orange" nickname since 2004, although the former names of Orangemen and Orangewomen are still used. The school's mascot is Otto the Orange. SU fields intercollegiate teams in eight men's sports and 12 women's sports.

Most of Syracuse University's intercollegiate teams participate in NCAA Division I in the Atlantic Coast Conference. The Syracuse Orange women's ice hockey team participates in College Hockey America. Crew participates in the Eastern Association of Rowing Colleges. The men's and women's basketball teams, the football team, and both the men's and women's lacrosse teams play in the Carrier Dome. Other sports are located at the nearby Manley Field House, except ice hockey which takes place in the Tennity Ice Skating Pavilion.

SU has reached 28 team national championships, including 14 men's lacrosse, six men's crew, two cross country running, and one each in boxing, football, and women's lacrosse. Under long-time head coach Jim Boeheim, men's basketball team won seven Big East regular season championships, five Big East Tournament championships, and 25 NCAA Tournament appearances, including the 2003 NCAA championship. The men's basketball team holds the largest on campus attendance record of 35,446 attendees. The record was set in the Carrier Dome playing Duke on Saturday February 1, 2014.

In 1959, Syracuse earned its first National Championship following an undefeated football season and a Cotton Bowl victory over Texas. The team featured sophomore running back Ernie Davis who, in 1961, became the first African-American to win the Heisman Trophy. Davis was slated to play for the Cleveland Browns in the same backfield as Jim Brown, but died of leukemia before being able to play professionally.

Syracuse played its first intercollegiate lacrosse game in 1916, and captured its first USILA championship in 1920. It won USILA championships in 1922, 1924, and 1925. In the modern NCAA era, Syracuse is the first school to capture 11 National Championships, the most of any team in college lacrosse history. Most recently, Syracuse reached the men's Division I championship game in 2013 after winning two championships in 2008 & 2009 seasons and reaching the quarterfinals in 2011. However, the Orange lost 16-10 to Duke University after leading 5-0 early in the game. The women's lacrosse team reached the NCAA Division I National Championship game for the first time in school history in 2012, which they lost to Northwestern.

Toward the end of the 1970s, Syracuse University was under pressure to improve its football facilities in order to remain a NCAA Division I football school. Its small concrete stadium, Archbold Stadium, was seventy years old and not up to the standards of other schools. The stadium could not be expanded; it had been reduced from 40,000 seats to 26,000 due to the fire codes. Syracuse University decided to build a new stadium. In 1978, Archbold Stadium was demolished to make way for the Carrier Dome, which was to have a domed Teflon-coated, fiberglass inflatable roof. It would also serve as the home for the men's basketball team, as a replacement for Manley Field House. The Carrier Dome was constructed between April 1979 and September 1980. The total construction cost was $26.85 million, including a $2.75 million naming gift from the Carrier Corporation.

Among the individuals who have attended or graduated from Syracuse University include writers George Saunders, Stephen Crane, Joyce Carol Oates, John D. MacDonald, Cheryl Strayed, Shirley Jackson, and Alice Sebold; William Safire, Pulitzer Prize winning commentator; Pierre Ramond, string theorist; Cambridge University historian Sir Moses I. Finley; Sir John Stanley, British Member of Parliament; Arthur Rock, legendary venture capitalist and cofounder of Intel; Vishal Sikka, Former CEO and MD of Infosys; Donna Shalala, CEO of the Clinton Foundation; Joe Biden, former Vice President of the United States; Robert Jarvik, inventor of the first artificial heart implanted into human beings; Eileen Collins, first female commander of a Space Shuttle; Prince Sultan bin Salman, first Arab, first Muslim and the youngest person to travel to space; Robert Menschel, legendary partner/director at Goldman Sachs; Marilyn Loden, who coined the phrase "glass ceiling"; Samuel Irving Newhouse, Jr., owner of Conde Nast publications; Lowell Paxson, founder of Home Shopping Network; musician Lou Reed; Betsey Johnson fashion designer; David P. Weber, lawyer and certified fraud examiner, who reported misconduct in the Bernard L. Madoff and R. Allen Stanford frauds; Abramoff scandal lawyer Kevin Ring, and Prince Al-Waleed bin Talal, a prominent investor and member of the Saudi royal family. Emily C. Gorman, former director of the United States Women's Army Corps, completed her graduate studies at Syracuse.

Alumni in journalism and broadcasting include Ted Koppel, Megyn Kelly, Michael Barkann, Bob Costas, Marv Albert, Len Berman, Marc S. Ellenbogen, Marty Glickman, Dorothy Thompson, Beth Mowins, Dave Pasch, Sean McDonough, Ian Eagle, Dave O'Brien, Dick Stockton, Arun Shourie, Mike Tirico, Brian Higgins, Adam Zucker, Lakshmi Singh, Larry Hryb (an employee at Microsoft, former radio broadcaster for Clear Channel Communications), Steve Kroft of "60 Minutes", Pulitzer Prize winner Eugene Payne and Adam Schein of Mad Dog Sports Radio, NY Times columnist and war correspondent Drew Middletown, Jeff Glor, CBS News anchor, Vijay Kumar Pandey, Kantipur Newspaper columnist and Television icon.

Notable SU alumni in the performing arts include Dick Clark, Taye Diggs, Rob Edwards, Peter Falk, Vera Farmiga, Peter Guber, Peter Hyams, Frank Langella, Jessie Mueller, Lou Reed, Tom Everett Scott, Aaron Sorkin, Jerry Stiller, Lexington Steele, Bill Viola, Vanessa Williams, and Pete Yorn.

Prominent athletes include Kathrine Switzer, the first woman to officially run the Boston Marathon, Jim Brown, actor and NFL Hall of Famer with the Cleveland Browns, arguably the greatest running back of all time; Ernie Davis, the first African-American Heisman Trophy winner immortalized in the motion picture "The Express"; Donovan McNabb, former NFL quarterback; former Indianapolis Colts wide receiver Marvin Harrison; Dwight Freeney, defensive end for the San Diego Chargers; Larry Csonka, former Miami Dolphins running back, Pro Football Hall of Famer and television host, Carmelo Anthony, forward for the Oklahoma City Thunder; 7-time NBA All Star, pro basketball Hall of Famer and former Mayor of Detroit Dave Bing; Tim Green, former Atlanta Falcons player, author, lawyer, and National Public Radio commentator; Darryl Johnston, three-time Super Bowl winner with the Dallas Cowboys in the 1990s; Mikey Powell, who formerly played lacrosse for the Boston Cannons; Floyd Little, who played for the Denver Broncos; Kyle Johnson, who played the majority of his NFL career with the Denver Broncos; John Mackey a member of the NFL Hall of Fame played for the legendary Baltimore Colts (1963–71); and Tom Coughlin, former New York Giants head coach and executive VP of football operation at Jacksonville Jaguars.

The College of Environmental Science and Forestry (ESF) has a long affiliation with Syracuse University, shares many campus resources, and operates its main academic campus immediately adjacent to Syracuse University. ESF was founded in 1911 as the New York State College of Forestry at Syracuse University, under the leadership of Syracuse University Trustee Louis Marshall, with the active support of Syracuse University Chancellor Day. Its founding followed the Governor's veto of annual appropriations to a separate New York State College of Forestry at Cornell.

ESF is an autonomous institution, administratively separate from SU, while resources, facilities, and some infrastructure are shared. The two schools share a common Schedule of Classes; students at both institutions may take courses at the other, and degrees from ESF bear the Syracuse University seal along with the State University of New York. A number of concurrent degree programs and certificates are offered between the schools, as well. The college receives an annual appropriation as part of the SUNY budget and the state builds and maintains all of the college's educational facilities. The state has similar relationships with five statutory colleges that are at Alfred University and Cornell University.

ESF faculty, students, and students' families join those from SU to take part in a joint convocation ceremony at the beginning of the academic year in August, and joint commencement exercises in May. ESF and SU students share access to libraries, recreational facilities, student clubs, and other activities at both institutions, except for the schools' intercollegiate sports teams, affiliated with the NCAA and USCAA, respectively. First-year ESF students live in Centennial Hall on ESF's campus.

The medical school was formerly a college within SU, known as the Syracuse University Medical School. In 1950, SU sold the medical school to the State University of New York system. A joint Master of Public Health degree program is offered by the two institutions; the program is the first of its kind in Central New York.

Binghamton University was established in 1946 as Triple Cities College, to serve the needs of local veterans of the Binghamton, New York area, who were returning from World War II. Established in Endicott, New York, the college was a branch of Syracuse University. Triple Cities College offered local students the first two years of their education, while the following two were spent at Syracuse University. In 1946, students could earn their degrees entirely at the Binghamton campus. In 1950, it was absorbed by the State University of New York and renamed Harpur College.

Utica College, an independent private university located in Utica, New York, was founded by Syracuse University in 1946. Utica College became independent from SU in 1995, but still offers its students the option to receive a specialized bachelor's degree from Syracuse University through a mutual relationship between the two schools.




</doc>
<doc id="29354" url="https://en.wikipedia.org/wiki?curid=29354" title="Snake oil">
Snake oil

Snake oil is a traditional Chinese medicament utilizing fat extracted from the Chinese water snake ("Enhydris chinensis.") It is a rubefacient and/or ointment, and is applied topically to relieve minor physical pain. It has been used in traditional Chinese medicine for many centuries, and is a relatively common medication prescribed by doctors ascribing the practice of traditional Chinese medicine. Its effectiveness as medicine has been a historical source of controversy in the Western world, where there is much confusion over its origin and constitution due to a U.S. District Court judgment against Clark Stanley.

In Western culture, snake oil is most commonly associated with a placebo, panacea and/or deceptive marketing. Its association in Western culture lies in the fact that many 19th-century United States and 18th-century European entrepreneurs advertised and sold mineral oil (often mixed with various active and inactive household herbs, spices, and compounds, but containing no properties of snakes,) as "snake oil liniment", making frivolous claims about its efficacy as a panacea. Patent medicines that claimed to be a cure-all panacea were extremely common from the 18th until the 20th century, particularly among vendors masking addictive drugs such as cocaine, amphetamine, alcohol and opium-based concoctions and/or elixirs, to be sold as medication and/or products promoting health at medicine shows.
The use of snake oil long predates the 18th and 19th centuries in China and the Eastern world, where oil made from fat extracted from the Chinese water snake ("Enhydris chinensis") is a traditional liniment used for treating joint pain. Chinese water-snake oil contains 20 percent eicosapentaenoic acid (EPA), which has strong analgetic and anti-inflammatory properties.

The marketing concept for snake oil was likely transferred to the US from trade, immigration, and exposure to 18th-century British culture. However, the actual source of its use as a folk remedy was likely introduced, similarly to its introduction in the UK, by Chinese laborers involved in building the First Transcontinental Railroad in the US, and were undoubtedly familiar with Traditional Chinese Medicine, using snake oil to treat joint pain such as arthritis and bursitis, while introducing it to fellow American workers. When rubbed on the skin at the painful site, snake oil was claimed to bring relief. This claim was ridiculed by 19th-century rival medicine salespeople, who competed with snake oil entrepreneurs in peddling other medicines for pain, often offering more hazardous alternatives such as alcohol and/or opium.

Patent medicines originated in England, where a patent was granted to Richard Stoughton's elixir in 1712. There were no federal regulations in the United States concerning safety and effectiveness of drugs until the 1906 Food and Drugs Act. Thus, the widespread marketing and availability of dubiously advertised patent medicines without known properties or origin persisted in the US for a much greater number of years than in Europe.

In 18th-century Europe, especially in the UK, viper oil had been commonly recommended for many afflictions, including the ones for which oil from the rattlesnake (pit viper,) a type of viper native to America, was subsequently favored to treat rheumatism and skin diseases. Though there are accounts of oil obtained from the fat of various vipers in the Western world, the claims of its effectiveness as a medicine have never been thoroughly examined, and its efficacy is unknown.
It is also likely that much of the snake oil sold by Western entrepreneurs was illegitimate, and did not contain ingredients derived from any kind of snake. Snake oil in the United Kingdom and United States probably contained modified mineral oil.

In popular culture within the United States, snake oil is particularly renowned to be a commodity peddled at American Old West-themed medicine shows, although the judgment condemning snake oil as medicine took place in Rhode Island, and involved snake oil manufactured in Massachusetts. The snake oil peddler is a stock character in Western movies, depicted as a traveling "doctor" with dubious credentials, selling fake medicines with boisterous marketing hype, often supported by pseudo-scientific evidence. To increase sales, an accomplice in the crowd (a shill) will often attest to the value of the product in an effort to provoke buying enthusiasm. The "doctor" will leave town before his customers realize they have been cheated. This practice has wide ranging implications, and is known as a confidence trick, a type of fraud. This particular confidence trick is purported to have been a common mechanism utilized by peddlers in order to sell various counterfeit and generic medications at medicine shows.

The drastic amount of fraud extending to the drug epidemic was unfolded, and exposed with a judgment against Clark Stanley, which condemned the patented Clark Stanley's Snake Oil Liniment in US District Court. This minor ruling, much like the process that unfolded in the UK during the previous century, set a precedent for government bureaucracies to exert greater authority over traditional practices in health and medicine. Snake oil has grown to epitomize patent medicine, and represents a healthy act of scapegoating that allowed for government controlled bureaucracy to effectively seize authority over the means to control a drug epidemic involving alcohol and opium during the 19th century in the US. This increased authority led to the evolution and expansion of bureaucracies such as the Food and Drug Administration in the US.

The composition of snake oil medicines varies markedly among products.

Clark Stanley's Snake Oil Liniment – produced by Clark Stanley, the "Rattlesnake King" – was tested by the United States government's Bureau of Chemistry, the precursor to the Food and Drug Administration (FDA,) in 1916. It was found to contain:

Although most snake oil in the Western world was drastically overpriced and falsely advertised it is arguable whether or not it is actually representative of a placebo given that Clark Stanley's Snake Oil Liniment, the only Western produced snake oil known to have been examined, is similar in composition to modern-day capsaicin-based liniments or chest rubs. None of the oil content was found to have been extracted from actual snakes. Nonetheless, the composition of most snake oil is essentially the same as Vicks VapoRub, which contains camphor. Snake oil, and many chest rubs, utilize camphor as an active ingredient. Clark Stanley, the most renowned peddler of snake oil who is popularly known as "The Rattlesnake King," marketed a brand of snake oil containing capsaicin as an active ingredient in addition to camphor. Capsaicin also continues to be commonly used in many non-narcotic pain patches, and is found in many competing brands of chest rubs as well as in pepper spray. A critique of the historical revision giving rise to such a negative connotation for snake oil may argue that its place in English is the product of a cultural dissociation adopted from popular culture.

In 1916, subsequent to the passage of the Pure Food and Drug Act in 1906, Clark Stanley's Snake Oil Liniment was examined by the Bureau of Chemistry, and found to be drastically overpriced and of limited value. As a result, Stanley faced federal prosecution for peddling mineral oil in a fraudulent manner as snake oil. In his 1916 civil hearing instigated by federal prosecutors in the U.S. District Court for Rhode Island, Stanley plead no contest to the allegations against him, giving no admission of guilt. His plea of nolo contendere was accepted, and as a result, Stanley was fined $20.00. This amount of money corresponds to roughly $457 in 2018. The term "snake oil" has since been established in popular culture as a reference to any worthless concoction sold as medicine, and has been extended to describe a widely ranging degree of fraudulent goods, services, ideas, and activities such as worthless rhetoric in politics. By further extension, a snake oil salesman is commonly used in English to describe a quack, huckster, or charlatan. It is also used in a de facto manner to describe the general nature of many modern professions such as a politician or religious leader, most especially Islamic Imams and Christian ministers. It is also commonly used in a quackery sense to describe many present day physicians and doctors associated with medical malpractice, such as an internist, as well as many attorneys filing frivolous lawsuits, and is often used as a broad term to describe anyone in the profession of sales, most commonly car salespeople and pharmaceutical sales representatives.

Fraudulent marketing techniques employed by Western businesspersons producing snake oil are not dissimilar from most advertising campaigns employed in accordance with entrepreneurial business practices today. Such deception is prevalent in storefronts, among retail stores, as well as among peddlers who sell a wide array of products, and is particularly common in services marketing. Examples of modern products alleged to be marketed similarly to snake oil are intoxicating drugs such as marijuana, alcohol, opium, and amphetamines in addition to products of herbalism, dietary supplements, and religious or spiritual items such as a crucifix (used to ward away evil), a crystal (when used spiritually for the Christian crucifixion purpose), or a Tibetan singing bowl (used for healing.) Common indictments of false advertising for these, and other products marketed similarly to snake oil often materialize in allegations of dubious advertising claims that these products are holy/sacred, scientific, healthy, or natural.

Quite unlike snake oil in traditional Chinese medicine, there are quasi-justifiable means to codify snake oil in Western culture as a fraudulent panacea given that there are no known accounts of snake oil peddled in the United States or Europe containing any trace of actual snake extract. Thus, it is generally assumed that any variety of snake oil is in line with most other patent medicine available in the 18th and 19th centuries, although it is generally noted that snake oil is less dangerous than many other patent medicines containing intoxicating, or hazardous ingredients. Nonetheless, snake oil represents a concept for a particular type of fraud that may be extended to many of the same intoxicating drugs once sold at medicine shows that remain widely prescribed and available today. Most of these drugs are now manufactured by pharmaceutical companies, or fall under government control in some form or fashion.



</doc>
<doc id="29355" url="https://en.wikipedia.org/wiki?curid=29355" title="Stanley Elkin">
Stanley Elkin

Stanley Lawrence Elkin (May 11, 1930 – May 31, 1995) was an American novelist, short story writer, and essayist. His extravagant, satirical fiction revolves around American consumerism, popular culture, and male–female relationships.

Elkin was born to a Jewish family in Brooklyn, New York, and grew up in Chicago from age three onwards. He did both his undergraduate and graduate work at the University of Illinois at Urbana–Champaign, receiving a bachelor's degree in English in 1952 and a Ph.D. in 1961 for his dissertation on William Faulkner. (During this period he was drafted and served in the U.S. Army from 1955–57.) In 1953 Elkin married Joan Marion Jacobson. He was a member of the English faculty at Washington University in St. Louis from 1960 until his death, and battled multiple sclerosis for most of his adult life. In 1968, he signed the "Writers and Editors War Tax Protest" pledge, vowing to refuse tax payments in protest against the Vietnam War.

During his career, Elkin published ten novels, two volumes of novellas, two books of short stories, a collection of essays, and one (unproduced) screenplay. Elkin's work revolves about American pop culture, which it portrays in innumerable darkly comic variations. Characters and especially prose style take full precedence over plot. His language is extravagant and exuberant, baroque and flowery, taking fantastic flight from his characters' endless patter. "He was like a jazz artist who would go off on riffs," said critic William Gass. In a review of "George Mills", Ralph B. Sipper wrote, "Elkin's trademark is to tightrope his way from comedy to tragedy with hardly a slip." About the influence of ethnicity on his work Elkin said he admired most "the writers who are stylists, Jewish or not. Bellow is a stylist, and he is Jewish. William Gass is a stylist, and he is not Jewish. What I go for in my work is language."

Although living in the Midwest, Elkin spent his childhood and teenage summers in a bungalow colony called West Oakland, on the Ramapo River in northern New Jersey not far from Mahwah, the home of Joyce Kilmer. This was a refuge for a close-knit group of several score families, mostly Jewish, from the summer heat of New York City and urban New Jersey. Elkin’s writings placed in New Jersey were informed by this experience.

Elkin won the National Book Critics Circle Award on two occasions: for "George Mills" in 1982 and for "Mrs. Ted Bliss", his last novel, in 1995. "The MacGuffin" was a finalist for the 1991 National Book Award for Fiction. However, although he enjoyed high critical praise, his books have never enjoyed popular success. The 1976 Jack Lemmon film "Alex & the Gypsy" was based on Elkin's novella "The Bailbondsman".

Elkin died May 31, 1995 of a heart attack. His manuscripts and correspondence are archived in Olin Library at Washington University in St. Louis. Elkin's literary legacy is represented by the literary agency headed by Georges Borchardt.

He has a star on the St. Louis Walk of Fame.











</doc>
<doc id="29356" url="https://en.wikipedia.org/wiki?curid=29356" title="International Society of Cryptozoology">
International Society of Cryptozoology

The International Society of Cryptozoology (ISC) was an organization dedicated to the pseudoscience of cryptozoology founded in 1982 in Washington, D.C. It ceased to exist in 1998.

It was founded to serve as a center for documenting and evaluating topics of interest to cryptozoologists. The study of such animals is known as cryptozoology, and "Cryptozoology" was also the title of its journal. The President was Bernard Heuvelmans, and the Vice-President Roy Mackal. The Secretary was J. Richard Greenwell (died 2005), of the University of Arizona. Loren Coleman, John Willison Green, and several other prominent cryptozoologists were either Life Members, Honorary Members, or Board Members.

The official emblem of the society was the okapi, which was chosen because, although it was well known to the inhabitants of its region, it was unknown to the European scientific community until the English explorer Harry Johnston sent to London an okapi skin which received international attention in 1901.

The journal "Cryptozoology" was published from 1982 to 1996. The Society also published a newsletter "ISC News".

The ISC ended its activities in 1998 due to financial problems, though a website continued until 2005.

According to the journal "Cryptozoology", the ISC served "as a focal point for the investigation, analysis, publication, and discussion of all matters related to animals of unexpected form or size, or unexpected occurrence in time or space."


</doc>
<doc id="29357" url="https://en.wikipedia.org/wiki?curid=29357" title="Send In the Clowns">
Send In the Clowns

"Send In the Clowns" is a song written by Stephen Sondheim for the 1973 musical "A Little Night Music", an adaptation of Ingmar Bergman's film "Smiles of a Summer Night". It is a ballad from Act Two, in which the character Desirée reflects on the ironies and disappointments of her life. Among other things, she looks back on an affair years earlier with the lawyer Fredrik, who was deeply in love with her but whose marriage proposals she had rejected. Meeting him after so long, she realizes she is in love with him and finally ready to marry him, but now it is he who rejects her: he is in an unconsummated marriage with a much younger woman. Desirée proposes marriage to rescue him from this situation, but he declines, citing his dedication to his bride. Reacting to his rejection, Desirée sings this song. The song is later reprised as a coda after Fredrik's young wife runs away with his son, and Fredrik is finally free to accept Desirée's offer.

Sondheim wrote the song specifically for the actress Glynis Johns, who created the role of Desirée on Broadway. The song is structured with four verses and a bridge, and uses a complex compound meter. It became Sondheim's most popular song after Frank Sinatra recorded it in 1973 and Judy Collins' version charted in 1975 and 1977. Subsequently, numerous other artists recorded the song, and it has become a jazz standard.

The "clowns" in the title do not refer to circus clowns. Instead, they symbolize fools, as Sondheim explained in a 1990 interview:

In a 2008 interview, Sondheim further clarified:

Judi Dench, who performed the role of Desirée in London, commented on the context of the song during an interview with Alan Titchmarsh. The play is "a dark play about people who, at the beginning, are with wrong partners and in the end it is hopefully going to become right, and she (Desirée) mistimes her life in a way and realizes when she re-meets the man she had an affair with and had a child by (though he does not know that), that she loves him and he is the man she wants."

Some years before the play begins, Desirée was a young, attractive actress, whose passions were the theater and romance. She lived her life dramatically, flitting from man to man. Fredrik was one of her many lovers and fell deeply in love with Desirée, but she declined to marry him. The play implies that when they parted Desirée may have been pregnant with his child.

A few months before the play begins, Fredrik married a beautiful young woman who at 18 years old was much younger than he. In Act One, Fredrik meets Desirée again, and is introduced to her daughter, a precocious adolescent suggestively named Fredrika. Fredrik explains to Desirée that he is now married to a young woman he loves very much, but that she is still a virgin, continuing to refuse to have sex with him. Desirée and Fredrik then make love.

Act Two begins days later, and Desirée realizes that she truly loves Fredrik. She tells Fredrik that he needs to be rescued from his marriage, and she proposes to him. Fredrik explains to Desirée that he has been swept off the ground and is "in the air" in love with his beautiful, young wife, and apologizes for having misled her. Desirée remains sitting on the bed; depending on the production, Fredrik walks across the room or stays seated on the bed next to her. Desirée – feeling both intense sadness and anger, at herself, her life and her choices – sings "Send in the Clowns". She is, in effect, using the song "to cover over a moment when something has gone wrong on stage. Midway through the second Act she has deviated from her usual script by suggesting to Fredrik the possibility of being together seriously and permanently, and, having been rejected, she falters "as" a show-person, finds herself bereft of the capacity to improvise and wittily cover. If Desirée could perform at this moment – revert to the innuendos, one-liners and blithe self-referential humour that constitutes her normal character – all would be well. She cannot, and what follows is an exemplary manifestation of Sondheim’s musico-dramatic complexity, his inclination to write music that performs drama. That is, what needs to be covered over (by the clowns sung about in the song) is the very intensity, ragged emotion and utter vulnerability that comes forward through the music and singing itself, a display protracted to six minutes, wrought with exposed silences, a shocked Fredrik sitting so uncomfortably before Desirée while something much too real emerges in a realm where he – and his audience – felt assured of performance."

Not long thereafter, Fredrik's young wife runs away with his son, so he is free to accept Desirée's proposal, and the song is reprised as a coda.

Sondheim wrote the lyrics and music over a two-day period during rehearsals for the play's Broadway debut, specifically for the actress Glynis Johns, who created the role of Desirée. According to Sondheim, "Glynis had a lovely, crystal voice, but sustaining notes was not her thing. I wanted to write short phrases, so I wrote a song full of questions" and the song's melody is within a small music range:

The lyrics of the song are written in four verses and a bridge and sung by Desirée. As Sondheim explains, Desirée experiences both deep regret and furious anger:

The song was originally performed in the key of D flat major.

The song uses an unusual and complex meter, which alternates between 12/8 and 9/8. These are two complex compound meters that evoke the sense of a waltz used throughout the score of the show. Sondheim tells the story:

"Send in the Clowns" is performed in two completely different styles: dramatic and lyric. The dramatic style is the theatrical performance by Desirée, and this style emphasizes Desirée's feelings of anger and regret, and the dramatic style acts as a cohesive part of the play. The lyric style is the concert performance, and this style emphasizes the sweetness of the melody and the poetry of the lyrics. Most performances are in concert, so they emphasize the beauty of the melody and lyrics.

Sondheim teaches both dramatic and lyric performers several important elements for an accurate rendition:

The dramatic performer must take on the character of Desirée: a woman who finally realizes that she has misspent her youth on the shallow life. She is both angry and sad, and both must be seen in the performance. Two important examples are the contrast between the lines, "Quick, send in the clowns" and "Well, maybe next year." Sondheim teaches that the former should be steeped in self-loathing, while the latter should emphasize regret. Thus, the former is clipped, with a break between "quick" and "send," while the latter "well" is held pensively.

Sondheim himself apologizes for flaws in his composition. For example, in the line, "Well, maybe next year," the melodic emphasis is on the word "year" but the dramatic emphasis must be on the word "next":

Another example arises from Sondheim's roots as a speaker of American rather than British English: The line "Don't you love farce?" features two juxtaposed labiodental fricative sounds (the former ["v"] voiced, the latter ["f"] devoiced). American concert and stage performers will often fail to "breathe" and/or "voice" between the two fricatives, leading audiences familiar with British slang to hear "Don't you love arse?," misinterpreting the lyric or at the least perceiving an unintended double entendre. Sondheim agrees that "[i]t's an awkward moment in the lyric, but that "v" and that "f" should be separated."

In the line of the fourth verse, "I thought that you'd want what I want. Sorry, my dear," the performer must communicate the connection between the "want" and the "sorry". Similarly, Sondheim insists that performers separately enunciate the adjacent "t"'s in the line, "There ought to be clowns."

The musical, with the song, debuted on Broadway in 1973. The song became popular with theater audiences but had not become a pop hit. Sondheim explained how the song became a hit:

Frank Sinatra recorded "Send in the Clowns" in 1973 for his comeback album "Ol' Blue Eyes Is Back", which attained gold status. Gordon Jenkins arranged the song. It was also released as a single, with "Let Me Try Again" on side B.

Two years later, in 1975, Judy Collins recorded "Send in the Clowns" and included it on her album "Judith".
The song was released as a single, which soon became a major pop hit. It remained on the "Billboard" Hot 100 for 11 weeks in 1975, reaching Number 36.
Then, in 1977, the song again reached the Billboard Hot 100, where it remained for 16 weeks and reached Number 19.
At the Grammy Awards of 1976, the Judy Collins performance of the song was named "Song of the Year".

After Sinatra and Collins recorded the song, it was recorded by Bing Crosby (for his album "That's What Life Is All About"), Kenny Rogers, Lou Rawls and many others.

In 1985, Sondheim added a verse for Barbra Streisand to use in her concert performances
and recording, which was featured on "The Broadway Album". In 1986, her version became a Number 25 Billboard Hot Adult Contemporary hit.

The song has become a jazz standard with performances by Count Basie, Sarah Vaughan, the Stan Kenton Orchestra and many others. The song appears on over 900 records by hundreds of performers in a wide variety of arrangements.

The highly successful drum corps, Santa Clara Vanguard, first performed an arrangement of this song as part of their musical program in 1974, when the corps won its second DCI World Championship. Originally arranged by Gail Royer, the song is still played by the brass on special occasions.




</doc>
<doc id="29359" url="https://en.wikipedia.org/wiki?curid=29359" title="Sinhalese people">
Sinhalese people

The Sinhalese (Sinhala: සිංහල ජාතිය "Sinhala Jathiya", also known as "Hela") are an Indo-Aryan-speaking ethnic group native to the island of Sri Lanka. They constitute about 75% of the Sri Lankan population and number greater than 16.2 million. The Sinhalese identity is based on language, historical heritage and religion. The Sinhalese people speak the Sinhalese language, an Indo-Aryan language, and are predominantly Theravada Buddhists, although a small percentage of Sinhalese follow branches of Christianity. The Sinhalese are mostly found in North Central, Central, South, and West Sri Lanka. According to the 5th century epic poem Mahavamsa, and the Dipavamsa, a 3rd–5th century treatise written in Pali by Buddhist monks of the Anuradhapura Maha Viharaya in Sri Lanka, the Sinhalese are descendants of settlers who came to the island in 543 BCE from Sinhapura, in India, led by Prince Vijaya.

From the Sanskrit word Sinhala, meaning literally "of lions". Other Sanskrit meaning is 'Sinha' (lion) + 'la' (blood or heart).

The Mahavamsa records the origin of the Sinhalese people and related historical events. It traces the historical origin of the Sinhalese people back to the first king of Sri Lanka, Vijaya, who is the son of Sinhabahu (Sanskrit meaning 'Sinha' (lion) + 'bahu' (hands, feet), the ruler of Sinhapura. According to the Mahavamsa, Sinhabahu was the son of princess Suppadevi of the Vanga, who copulated with the king of the beast, a lion (there is no clear reference in the original text whether it was a lion or a man with lion-like features), and gave birth to a daughter called Sinhasivali and to a son, Sinhabahu, whose hands and feet were like the paws of a lion and who had the strength of a lion. King Vijaya, lineage of Sinhabahu, according to the Mahavamsa and other historical sources, arrived to the island of Tambapanni (Sri Lanka), and gave origin to the lion people, Sinhalese.

The story of the arrival of Prince Vijaya to Sri Lanka, and the origin of the Sinhalese people is also depicted in the Ajanta caves, in a mural of cave number 17.

Early recorded history of the Sinhalese is chronicled in two documents, the Mahavamsa, written in Pāli around the 4th century CE, and the much later Culavamsa (probably penned in the 13th century CE by the Buddhist monk Dhammakitti). These are ancient sources which cover the histories of the powerful ancient Sinhalese kingdoms of Anuradhapura and Polonnaruwa which lasted for 1500 years. The Mahavamsa describes the existence of fields of rice and reservoirs, indicating a well-developed agrarian society.

Prince Vijaya and his 700 followers left Suppāraka, landed on the island at a site believed to be in the district of Chilaw, near modern-day Mannar, and founded the Kingdom of Tambapanni. It is recorded the Vijaya made his landing on the day of Buddha's death. Vijaya claimed Tambapanni his capital and soon the whole island come under this name. Tambapanni was originally inhabited and governed by Yakkhas, having their capital at Sirīsavatthu and their queen Kuveni. According to the Samyutta Commentary, Tambapanni was one hundred leagues in extent.

After landing in Tambapanni Vijaya met Kuveni the queen of the Yakkhas, who was disguised as a beautiful woman but was really a 'yakkini' (devil) named Sesapathi.

At the end of his reign, Vijaya, having trouble choosing a successor, sent a letter to the city of his ancestors, Sinhapura, in order to invite his brother Sumitta to take over the throne. However, Vijaya had died before the letter had reached its destination, so the elected minister of the people Upatissa, the Chief government minister or prime minister and leading chief among the Sinhalese became regent and acted as regent for a year. After his coronation, which was held in the Kingdom of Tambapanni, he left it, building another one, bearing his own name. While he was king, Upatissa established the new capital Upatissa, in which the kingdom was moved to from the Kingdom of Tambapanni. When Vijaya's letter arrived, Sumitta had already succeeded his father as king of his country, and so he sent his son Panduvasdeva to rule Upatissa Nuwara.

Upatissa Nuwara was seven or eight miles further north of the Kingdom of Tambapanni.
It was named after the regent king Upatissa, who was the prime minister of Vijaya, and was founded in 505 BC after the death of Vijaya and the end of the Kingdom of Tambapanni.

In 377 BC, King Pandukabhaya (437–367 BC) moved the capital to Anuradhapura and developed it into a prosperous city. Anuradhapura (Anurapura) was named after the minister who first established the village and after a grandfather of Pandukabhaya who lived there. The name was also derived from the city's establishment on the auspicious asterism called Anura. Anuradhapura was the capital of all the monarchs who ruled from the dynasty.

Rulers such as Dutthagamani, Valagamba, and Dhatusena are noted for defeating the South Indians and regaining control of the kingdom. Other rulers who are notable for military achievements include Gajabahu I, who launched an invasion against the invaders, and Sena II, who sent his armies to assist a Pandyan prince.

During the middle ages Sri Lanka was well known for its agricultural prosperity under the Parakramabahu in Polonnaruwa during which period the island was famous around the world as the rice mill of the east. Later in the 13th century the country's administrative provinces were divided into three independent kingdoms: Kingdom of Sitawaka, Kingdom of Kotte and the Kandyan kingdom. The invasion by Magha in the 13th century led to migrations by the Sinhalese to areas not under his control. This migration was followed by a period of conflict among the Sinhalese chiefs who tried to exert political supremacy. Parakramabahu VI in the 15th century was the only Sinhalese king during this time who could bring back the unity of the whole island. Trade also increased during this period, as Sri Lanka began to trade Cinnamon and a large number of Muslim traders were bought into the island.

In the 15th century a Kandyan Kingdom formed which divided the Sinhalese politically into low-country and up-country.

The Sinhalese have a stable birth rate and a population that has been growing at a slow pace relative to India and other Asian countries.

Sinhalese culture is a unique one dating as far back as 2600 years and has been nourished by Theravada Buddhism. Its main domains are sculpture, fine arts, literature, dancing, poetry and a wide variety of folk beliefs and rituals traditionally. Ancient Sinhalese stone sculpture and inscriptions are known worldwide and is a main foreign attraction in modern tourism. Sigirirya is famous for its frescoes. Folk poems were sung by workers to accompany their work and narrate the story of their lives. Ideally these poems consisted of four lines and, in the composition of these poems, special attention had been paid to the rhyming patterns. Buddhist festivals are dotted by unique music using traditionally Sinhala instruments. More ancient rituals like tovils (devil exorcism) continue to enthral audiences today and often praised and admired the good and the power of Buddha and gods in order to exorcise the demons.

Traditionally during recreation the Sinhalese wear a sarong ("sarama" in Sinhala). Men may wear a long-sleeved shirt with the sarong, while women wear a tight-fitting, short-sleeved jacket with a wrap-around called the "cheeththaya". In the more populated areas, Sinhalese men also wear Western-style clothing — wearing suits while the women wear skirts and blouses. For formal and ceremonial occasions women wear the traditional Kandyan (Osaria) style, which consists of a full blouse which covers the midriff completely, and is partially tucked in at the front. However, modern intermingling of styles has led to most wearers baring the midriff. The Kandyan style is considered as the national dress of Sinhalese women. In many occasions and functions, even the "saree" plays an important role in women's clothing and has become the de facto clothing for female office workers especially in government sector. An example of its use is the uniform of air hostesses of Sri Lankan Airlines.

Sinhalese cuisine is one of the most complex cuisines of South Asia. Due to its proximity to South India, Sinhalese cuisine shows some influence, yet is in many ways quite distinct. As a major trade hub, it draws influence from colonial powers that were involved in Sri Lanka and by foreign traders. Rice, which is consumed daily, can be found at any occasion, while spicy curries are favourite dishes for lunch and dinner. Some of the Sri Lankan dishes have striking resemblance to Kerala cuisine, which could be due to the similar geographic and agricultural features with Kerala. A well-known rice dish with Sinhalese is Kiribath, meaning "Milk Rice." In addition to sambols, Sinhalese eat "Mallung"- chopped leaves mixed with grated coconut and red onions. Coconut milk is found in most Sri Lankan dishes to give the cuisine its unique flavour.

Sri Lanka has long been renowned for its spices. The best known is cinnamon which is native to Sri Lanka. In the 15th and 16th centuries, spice and ivory traders from all over the world who came to Sri Lanka brought their native cuisines to the island, resulting in a rich diversity of cooking styles and techniques. Lamprais rice boiled in stock with a special curry, accompanied by "frikkadels" (meatballs), all of which is then wrapped in a banana leaf and baked as a Dutch-influenced Sri Lankan dish. Dutch and Portuguese sweets also continue to be popular. British influences include roast beef and roast chicken. Also, the influence of the Indian cooking methods and food have played a major role in what Sri Lankans eat.

The island nation's cuisine mainly consists of boiled or steamed rice served with curry. This usually consists of a "main curry" of fish or chicken, as well as several other curries made with vegetables, lentils and even fruit curries. Side-dishes include pickles, chutneys and "sambols". The most famous of these is the coconut sambol, made of ground coconut mixed with chili peppers, dried Maldive fish and lime juice. This is ground to a paste and eaten with rice, as it gives zest to the meal and is believed to increase appetite.

The Sinhalese speak Sinhala, also known as "Helabasa"; this language has two varieties, spoken and written. Sinhala is an Indo-Aryan language within the broader group of Indo-European languages. The language was brought to Sri Lanka by the ancestors of the Sinhalese from northern India who settled on the island in the 6th century BCE. Sinhala developed in a way different from the other Indo-Aryan languages because of the geographic separation from its Indo-Aryan sister languages. Sinhala was influenced by many languages, prominently Pali, the sacred language of Southern Buddhism, and Sanskrit. Many early Sinhala texts such as the "Hela Atuwa" were lost after their translation into Pali. Other significant Sinhala texts include "Amāvatura", "Kavu Silumina", "Jathaka Potha" and "Sala Liheeniya". Sinhala has also adopted many , including from many Indian languages and colonial languages Portuguese, Dutch, and English.

Sandesha Kavyas written by Buddhist priests of Sri Lanka are regarded as some of the most sophisticated and versatile works of literature in the world. The Sinhala language was mainly inspired by Sanskrit and Pali, and many words of the Sinhala language derive from these languages. Today some English words too have come in as a result of the British occupation during colonial times, and the exposure to foreign cultures through television and Hollywood movies. Additionally many Dutch and Portuguese words can be seen in the coastal areas.

Folk tales like "Mahadana Muttha saha Golayo" and "Kawate Andare" continue to entertain children today. "Mahadana Muttha" tells the tale of a fool cum Pundit who travels around the country with his followers ("Golayo") creating mischief through his ignorance. "Kawate Andare" tells the tale of a witty court jester and his interactions with the royal court and his son.

In the modern period, Sinhala writers such as Martin Wickremasinghe and G. B. Senanayake have drawn widespread acclaim. Other writers of repute include Mahagama Sekera and Madewela S. Ratnayake. Martin Wickramasinghe wrote the immensely popular children's novel "Madol Duwa". Munadasa Cumaratunga's "Hath Pana" is also widely known.

Many forms of Sri Lankan arts and crafts take inspiration from the island's long and lasting Buddhist culture which in turn has absorbed and adopted countless regional and local traditions. In most instances Sri Lankan art originates from religious beliefs, and is represented in many forms such as painting, sculpture, and architecture. One of the most notable aspects of Sri Lankan art are caves and temple paintings, such as the frescoes found at Sigiriya, and religious paintings found in temples in Dambulla and Temple of the Tooth Relic in Kandy. Other popular forms of art have been influenced by both natives as well as outside settlers. For example, traditional wooden handicrafts and clay pottery are found around the hill country while Portuguese-inspired lacework and Indonesian-inspired Batik have become notable. It has many different and beautiful drawings.

Developed upon Indo-Aryan architectural skills in the late 6th century BCE Sinhalese people who lived upon greater kingdoms such as Anuradhapura and Polonnaruwa have built so many architectural examples such as Ruwanwelisaya, Jetavanaramaya - second tallest brick building in the ancient world after Great Pyramid of Giza, and Abayagiriya - third tallest brick building in the ancient world. And also with the ancient hydraulic technology which is also unique to Sinhalese people to build ancient tanks, systematic ponds with fountains moats and Irrigational reservoirs such as Parakrama Samudra, Kawdulla and Kandalama. Sigirya which consider as the 8th wonder of the world is a combination of natural and man made fortress, which consists so many architectural aspects.

Concerning popular music, Ananda Samarakoon developed the reflective and poignant Sarala gee style with his work in the late 1930s/early 1940s. He has been followed by artists of repute such as Sunil Shantha, W. D. Amaradeva, Premasiri Khemadasa, Nanda Malini, Victor Ratnayake, Austin Munasinghe, T. M. Jayaratne, Sanath Nandasiri, Sunil Edirisinghe, Neela Wickremasinghe, Gunadasa Kapuge, Malini Bulathsinghala and Edward Jayakody.

Dramatist Ediriweera Sarachchandra revitalised the drama form with "Maname" in 1956. The same year, film director Lester James Peries created the artistic masterwork "Rekava" which sought to create a uniquely Sinhala cinema with artistic integrity. Since then, Peries and other directors like Vasantha Obeysekera, Dharmasena Pathiraja, Mahagama Sekera, W. A. B. de Silva, Dharmasiri Bandaranayake, Sunil Ariyaratne, Siri Gunasinghe, G. D. L. Perera, Piyasiri Gunaratne, Titus Thotawatte, D. B. Nihalsinghe, Ranjith Lal, Dayananda Gunawardena, Mudalinayake Somaratne, Asoka Handagama, and Prasanna Vithanage have developed an artistic Sinhala cinema. Sinhala cinema is often made colourful with the incorporation of songs and dance adding more uniqueness to the industry.

In the recent years high budget films like Aloko Udapadi, Aba (film) and Maharaja Gemunu based on Sinhalese epic historical stories gain huge success.

Performing arts of the Sinhalese people can be categorised into few groups:


Angampora is the traditional martial art of the Sinhalese people. It combines combat techniques, self-defence, sport, exercise and meditation. Key techniques observed in "Angampora" are: "Angam", which incorporates hand-to-hand fighting, and "Illangam", which uses indigenous weapons such as "Velayudaya", staves, knives and swords. Its most distinct feature is the use of pressure point attacks to inflict pain or permanently paralyse the opponent. Fighters usually make use of both striking and grappling techniques, and fight until the opponent is caught in a submission lock that they cannot escape. Usage of weapons is discretionary. Perimeters of fighting are defined in advance, and in some of the cases is a pit. "Angampora" became nearly extinct after the country came under British rule in 1815, but survived in a few families until the country regained independence.

The Sinhalese have a long history of literacy and formal learning. Instruction in basic fields like writing and reading by Buddhist Monks pre-date the birth of Christ. This traditional system followed religious rule and was meant to foster Buddhist understanding. Training of officials in such skills as keeping track of revenue and other records for administrative purposes occurred under this institution.

Technical education such as the building of reservoirs and canals was passed down from generation to generation through home training and outside craft apprenticeships.

The arrival of the Portuguese and Dutch and the subsequent colonisation maintained religion as the centre of education though in certain communities under Catholic and Presbyterian hierarchy. The British in the 1800s initially followed the same course. Following 1870 however they began a campaign for better education facilities in the region. Christian missionary groups were at the forefront of this development contributing to a high literacy among Christians.

By 1901 schools in the South and the North were well tended. The inner regions lagged behind however. Also, English education facilities presented hurdles for the general populace through fees and lack of access.

Traditional Sinhalese villages in early days had at least one chief Medical personnel called Weda Mahaththaya (Doctor). These people practice their clinical activities by inheritance. The Sinhala Medicine resembles some of Ayurvedic practices in contrast for some treatments they use Buddhist Chantings (Pirith) in order to strengthen the effectiveness.

According to the Mahavamsa, the ancient chronicle, Pandukabhaya of Sri Lanka (437 BC-367 BC) had lying-in-homes and Ayurvedic hospitals (Sivikasotthi-Sala) built in various parts of the country. This is the earliest documentary evidence we have of institutions specifically dedicated to the care of the sick anywhere in the world. Mihintale Hospital is the oldest in the world.

The form of Buddhism in Sri Lanka is known as Theravada (school of elders). The Pali chronicles (e.g., the Mahavansa) claim that the Sinhalese as an ethnic group are destined to preserve and protect Buddhism. In 1988 almost 93% of the Sinhalese speaking population in Sri Lanka were Buddhist. Observations of current religious beliefs and practices demonstrate that Sinhalese as a religious community have complex worldview as Buddhists. Due to the proximity and on some occasions similarity of certain doctrines, there are many areas where Buddhists and Hindus share religious views and practices. This can lead to the opinion that Buddhists have adopted religious elements from Hindu traditions in their religious practices. Some of these practices may relate to ancient indigenous beliefs and traditions on spirits, worship of deities and godlings and some figures appear to demons. Some of these demonic figures are used in healing rituals and may be native to the island.

Prominent Sri Lankan anthropologists Gananath Obeyesekere and Kitsiri Malalgoda used the term "Protestant Buddhism" to describe a type of Buddhism that appeared among the Sinhalese in Sri Lanka as a response to Protestant Christian missionaries and their evangelical activities during the British colonial period. This kind of Buddhism involved emulating the Protestant strategies of organising religious practices. They saw the need to establish Buddhist schools for educating Buddhist youth and organising Buddhists with new organisations such as the Young Men's Buddhist Association, as well as printing pamphlets to encourage people to participate in debates and religious controversies to defend Buddhism.

There is a significant Sinhalese Christian community, in the maritime provinces of Sri Lanka. Christianity was brought to the Sinhalese by Portuguese, Dutch, and British missionary groups during their respective periods of rule. Most Sinhala Christians are Roman Catholic; a minority are Protestant. Their cultural centre is Negombo.

Religion is considered very important among the Sinhalese. According to a 2008 Gallup poll, 99% of Sri Lankans considered religion an important aspect of their daily lives.

Within Sri Lanka the majority of the Sinhalese reside in the South, Central, Sabaragamuwa and Western parts of the country. This coincides with the largest Sinhalese populations areas in Sri Lanka. Cities with a > 90% population include Hambantota, Galle, Gampaha, Kurunegala, Monaragala, Anuradhapura and Polonnaruwa.

Sinhalese people have emigrated out to many countries for a variety of reasons. The larger diaspora communities are situated in the United Kingdom, Australia, United States and Canada among others. In addition to this there are many Sinhalese, who reside in the Middle East, Southeast Asia and Europe, temporarily in connection with employment and/or education. They are often employed as guest workers in the Middle East and professionals in the other regions.

The largest population centres of the Sinhalese diaspora are mainly situated in Europe, North America and Australia. The city of Melbourne contains just under half of the Sri Lankan Australians. The 2011 census recorded 86,412 Sri Lanka born in Australia. There are 73,849 Australians (0.4 of the population) who reported having Sinhalese ancestry in 2006. The Sinhalese language was also reported to be the 29th-fastest-growing language in Australia (ranking above Somali but behind Hindi and Belarusian). Sinhalese Australians have an exceptionally low rate of return migration to Sri Lanka. In the 2011 Canadian Census, 7,220 people identified themselves as of Sinhalese ancestry, out of 139,415 Sri Lankans. There are a small amount of Sinhalese people in India, scattered around the country, but mainly living in and around the northern and southern regions. Sri Lankan New Zealanders comprised 3% of the Asian population of New Zealand in 2001. The numbers arriving continued to increase, and at the 2006 census there were over 7,000 Sri Lankans living in New Zealand. The Sinhalese number about 12,000 in the U.S. The New York City Metropolitan Area contains the largest Sri Lankan community in the United States, receiving the highest legal permanent resident Sri Lankan immigrant population, followed by Central New Jersey and the Los Angeles metropolitan area. Many Sinhalese have migrated to Italy since the 1970s. Italy was attractive to the Sinhalese due to perceived easier employment opportunities and entry, compared to other European countries. It is estimated that there are 30,000-33,000 Sinhalese in Italy. The major Sinhalese communities in Italy are located in Lombardia (In the districts Loreto and Lazzaretto), Milan, Lazio, Rome, Naples, and Southern Italy (Particularly Palermo, Messina and Catania). Though Sinhala people in particular and Sri Lankans in general have migrated to the UK over the centuries beginning from the colonial times, the number of Sinhalese people in the UK cannot be estimated accurately due to inadequacies of census in the UK. The UK government does not record statistics on the basis of language or ethnicity and all Sri Lankans are classified into one group as Asian British or Asian Other.

According to the Mahavamsa, the Sinhalese are descended from the exiled Prince Vijaya and his party of seven hundred followers who arrived on the island in 543 BCE. Vijaya and his followers were said to have arrived in Sri Lanka after being exiled from the city of Sinhapura in Bengal. The modern Sinhalese people as said in the Mahavamsa were found to be most closely related to the people of North-East India (Bengal). It is thought throughout Sri Lanka's history, since the founding of the Sinhalese in the 5th century BC that an influx of Indians from North India came to the island. This is further supported from the Sinhalese language being part of the Indo-Aryan language group. Sinhalese derives from the Maharashtri Prakrit, along with Marathi, Konkani and Dhivehi.

Modern studies point towards a predominantly Bengali contribution and a minor Tamil and Western Indian (Gujarati) contribution. In relation to the former, studies also show the Sinhalese possess a genetic relationship with East Asian and Southeast Asian populations due to their close genetic links to Northeast India. Certain Y-DNA and mtDNA haplogroups and genetic markers of immunoglobulin among the Sinhalese, for example, show East and Southeast Asian genetic influences many of which are also found among certain Northeast Indian populations of whom the Sinhalese are genetically related to.





</doc>
<doc id="29364" url="https://en.wikipedia.org/wiki?curid=29364" title="Spiel des Jahres">
Spiel des Jahres

The Spiel des Jahres (, "Game of the Year") is an award for board and card games, created in 1978 with the stated purpose of rewarding excellence in game design, and promoting top-quality games in the German market. It is thought that the existence and popularity of the award is one of the major drivers of the quality of games coming out of Germany. A Spiel des Jahres nomination can increase the typical sales of a game from 500–3000 copies to around 10,000; and the winner can usually expect to sell 300,000 to 500,000 copies.

The award is given by a jury of German-speaking board game critics (from Germany, Austria, Switzerland), who review games released in Germany in the preceding twelve months. The games considered for the award are family-style games. War games, role-playing games, collectible card games, and other complicated, highly competitive, or hobbyist games are outside the scope of the award. Since 1989, there has been a separate award for children's games.

On occasion, the jury has awarded a special prize for more complex games, such as Agricola in 2008 or World Without End in 2010. Prior to 2011, this award was an exceptional award, not necessarily awarded annually. In 2011, however, this practice was formalized when the jury created a new category for more complex games entitled "Kennerspiel des Jahres" (roughly "Connoisseur-Enthusiast Game of the Year"). Along with the nominations, the jury also gives a list of recommended games, and occasionally gives out special prizes for games which will not be considered for the main award.

The criteria on which a game is evaluated are,:

The nominations and the special prize for the 2018 award were announced on May 14, 2018. The winner for Children's Game of the Year was announced on June 11, 2018. The winners for Game of the Year and Connoisseur-gamer Game of the Year were announced on July 23, 2018. 

The nominations for the 2017 award were announced on May 22, 2017. The winner for Children's Game of the Year was announced on June 19th, 2017. The winners for Game of the Year and Connoisseur-gamer Game of the Year were announced on July 17, 2017. 

The nominations for the 2016 awards were announced on May 23, 2016. The winners were announced on Monday July 18, 2016.

The nominations for the 2015 awards were announced on May 18, 2015. The Kinderspiel des Jahres winner were announced on Monday, June 8, 2015 while the Sdj and KdJ winners were announced on Monday, July 6, 2015.

The nominations for the 2014 awards were announced on May 19, 2014. The Children's Game of the Year was announced on June 23, and the Game of the Year and Connoisseur's Game of the Year were announced on July 14.

The nominations for the 2013 awards were announced on May 21, 2013 and the Spiel and Kennerspiel winners were announced on July 8, 2013. The Kinderspiel (Children's) Game of the Year was announced on June 12, 2013.

The nominations for the 2012 awards were announced on May 21, 2012 and the winners on July 9, 2012.

The nominations for the 2011 awards were announced on May 23, 2011 and the winners on June 27, 2011. This was the first year the Connoisseur-gamer Game of the Year award was given, an award for more complex games.

The nominations for the 2010 award were announced on May 31, 2010 and the winner on June 28, 2010.
The nominations for the 2009 award were announced on May 24, 2009 and the winner on June 29, 2009.

The nominations for the 2008 award were announced on May 25, 2008 and the winner on June 30, 2008.

The nominations for the 2007 award were announced on May 20, 2007, and the winner on June 25, 2007.

The nominations for the 2006 award were announced on May 28, 2006 and winner on July 17, 2006.

Along with the nominations, the jury also assigned two special prizes for games which it felt were too demanding to count as 'family style' games.

The nominations for the 2005 award were announced on May 8, 2005 and the winner on June 27, 2005.




</doc>
<doc id="29365" url="https://en.wikipedia.org/wiki?curid=29365" title="Synthetic element">
Synthetic element

In chemistry, a synthetic element is a chemical element that does not occur naturally on Earth, and can only be created artificially. So far, 24 synthetic elements have been created (those with atomic numbers 95–118). All are unstable, decaying with half-lives ranging from 15.6 million years to a few hundred microseconds.

Seven other elements were first created artificially and thus considered synthetic, but later discovered to exist naturally (in trace quantities) as well; among them plutonium—first synthesized in 1940—the one best known to laypeople, because of its use in atomic bombs and nuclear reactors.

Synthetic elements are radioactive and decay rapidly into lighter elements—possessing half-lives so short, relative to the age of Earth (which formed approximately 4.6 billion years ago), that any atoms of these elements that may have existed when the Earth formed have long since decayed. Atoms of synthetic elements only occur on Earth as the product of atomic bombs or experiments that involve nuclear reactors or particle accelerators, via nuclear fusion or neutron absorption.

Atomic mass for natural elements is based on weighted average abundance of natural isotopes that occur in Earth's crust and atmosphere. For "synthetic" elements, the isotope depends on the means of synthesis, so the concept of natural isotope abundance has no meaning. Therefore, for synthetic elements the total nucleon count (protons plus neutrons) of the most stable isotope, i.e. the isotope with the longest half-life—is listed in brackets as the atomic mass.

The first element discovered through synthesis was technetium—its discovery being definitely confirmed in 1936. This discovery filled a gap in the periodic table, and the fact that no stable isotopes of technetium exist explains its natural absence on Earth (and the gap). With the longest-lived isotope of technetium, Tc-98, having a 4.2-million-year half-life, no technetium remains from the formation of the Earth. Only minute traces of technetium occur naturally in the Earth's crust—as a spontaneous fission product of uranium-238 or by neutron capture in molybdenum ores—but technetium is present naturally in red giant stars.

The first discovered synthetic element was curium, synthesized in 1944 by Glenn T. Seaborg, Ralph A. James, and Albert Ghiorso by bombarding plutonium with alpha particles. The discoveries of americium, berkelium, and californium followed soon. Einsteinium and fermium were discovered by a team of scientists led by Albert Ghiorso in 1952 while studying the radioactive debris from the detonation of the first hydrogen bomb. The isotopes discovered were einsteinium-253, with a half-life of 20.5 days, and fermium-255, with a half-life of about 20 hours.

The discoveries of mendelevium, nobelium, lawrencium followed. During the height of the Cold War, the Soviet Union and United States independently discovered rutherfordium and dubnium. The naming and credit for discovery of those elements remained unresolved for many years but eventually shared credit was recognized by IUPAC/IUPAP in 1992. In 1997, IUPAC decided to give dubnium its current name honoring the city of Dubna where the Russian team made their discoveries since American-chosen names had already been used for many existing synthetic elements, while the name "rutherfordium" (chosen by the American team) was accepted for element 104.

No element with an atomic number greater than 99 has any use outside of scientific research, as they have extremely short half-lives.

The following elements do not occur naturally on Earth. All are transuranium elements and have atomic numbers of 95 and higher.

All elements with atomic numbers 1 through 94 are naturally occurring at least in trace quantities, but the following elements are often produced through synthesis. Except for polonium, francium, actinium, and protactinium, they were all discovered through synthesis before being found in nature.



</doc>
<doc id="29366" url="https://en.wikipedia.org/wiki?curid=29366" title="Shoghi Effendi">
Shoghi Effendi

Shoghí Effendí Rabbání (1 March 1897 – 4 November 1957), better known as Shoghi Effendi (), was the Guardian and appointed head of the Bahá'í Faith from 1921 until his death in 1957.

Shoghi Effendi spent his early life in ʿAkkā (Acre). His education was directed to serving as secretary and translator to his grandfather, `Abdu'l-Bahá, then leader of the Bahá'í Faith and son of the religion's founder, Bahá'u'lláh.

After the death of `Abdu'l-Bahá in 1921, the leadership of the Bahá'í community changed from that of a single individual to an administrative order with executive and legislative branches, the head of each being the Guardianship and the Universal House of Justice, respectively. Shoghi Effendi was referred to as the "Guardian", and had the authority to interpret the writings of the three central figures of the religion and define the sphere of legislative authority. His writings are effectively limited to commentaries on the works of the central figures, and broad directives for the future.

Future hereditary Guardians were permitted in the Bahá'í scripture by appointment from one to the next with the prerequisite that appointees be male descendants of Bahá'u'lláh. At the time of Shoghi Effendi's death, all living male descendants of Bahá'u'lláh had been declared Covenant-breakers by either `Abdu'l-Bahá or Shoghi Effendi, leaving no suitable living candidates. Shoghi Effendi died without appointing a successor Guardian, and the Universal House of Justice, the only institution authorized to adjudicate on situations not covered in scripture, later announced that it could not legislate to make possible the appointment of a successor to Shoghi Effendi. Shoghi Effendi was the first and last person acknowledged as Guardian of the Bahá'í Faith.

Born in ʿAkkā in the Acre Sanjak of the Ottoman Empire in March 1897, Shoghi Effendi was related to the Báb through his father, Mírzá Hádí Shírází, and to Bahá'u'lláh through his mother, Ḍíyá'íyyih Khánum, the eldest daughter of `Abdu'l-Bahá. `Abdu'l-Bahá, who provided much of his initial training, greatly influenced Shoghi Effendi from the early years of his life. Shoghi Effendi learned prayers from his grandfather, who encouraged him to chant. `Abdu'l-Bahá also insisted that people address the child as "Shoghi Effendi", ("Effendi" signifies "Sir"), rather than simply as "Shoghi", as a mark of respect towards him.

From his early years, Shoghi Effendi was introduced to the suffering which accompanied the Bahá'ís in Akká, including the attacks by Mírzá Muhammad `Alí against `Abdu'l-Bahá. As a young boy, he was aware of the desire of Sultan Abdul Hamid II (reigned 1876-1909) to banish `Abdu'l-Bahá to the deserts of North Africa where he was expected to perish. At one point, Shoghi Effendi was warned not to drink coffee in the homes of any of the Bahá'ís in the fear that he would be poisoned.

As the eldest grandson of `Abdu'l-Bahá, Shoghi Effendi from his earliest childhood had a special relationship with his grandfather. According to one account, when Shoghi Effendi was only 5 years old, he pestered his grandfather to write a tablet for him, which was common practice for `Abdu'l-Bahá. He wrote the following for his grandson:

Shoghi Effendi then set out to memorize a number of prayers, and chanted them as loud as he could. This caused family members to ask `Abdu'l-Bahá to quieten him down, a request which he apparently refused.

Shoghi Effendi received his early education at home with the other children in the household, then attended a French Christian Brothers school in Haifa, and later boarded at another Catholic school in Beirut. Shoghi Effendi later attended the Syrian Protestant College (later known as the American University of Beirut) for his final years of high school and first years of university, where he earned an arts degree in 1918. He reports being very unhappy in school and often returned on vacations to Haifa to spend time with `Abdu'l-Bahá.

During his studies, he dedicated himself to mastering English—adding this language to the Persian, Turkish, Arabic and French languages in which he was already fluent—so that he could translate the letters of `Abdu'l-Bahá and serve as his secretary. After studying at the American University of Beirut he later went to Balliol College, Oxford in England, where he matriculated in "Economics and Social Sciences", while still perfecting his translation skills.

The issue of successorship to `Abdu'l-Bahá was in the minds of early Bahá'ís, and although the Universal House of Justice was an institution mentioned by Bahá'u'lláh, the institution of the Guardianship was not clearly introduced until the Will and Testament of `Abdu'l-Bahá was publicly read after his death.

While studying in England, on 29 November 1921, the news of `Abdu'l-Bahá's death reached Shoghi Effendi, which, according to Wellesley Tudor Pole, the deliverer of the cable, left him "in a state of collapse". After spending a couple of days with John Esslemont, and after some passport difficulties, he sailed from England accompanied with Sara Blomfield and his sister Ruhangiz on December 16 and arrived in Haifa on 29 December. A few days later he opened `Abdu'l-Bahá's Will and Testament, which was addressed to Shoghi Effendi.

In the will Shoghi Effendi found that he had been designated as "the Sign of God, the chosen branch, the Guardian of the Cause of God". He also learned that he had been designated as this when he was still a small child. As Guardian he was appointed as head of the religion, someone whom the Bahá'ís had to look to for guidance. `Abdu'l-Bahá's Will and Testament is considered one of the three charters of the Bahá'í administrative order, and in it `Abdu'l-Bahá laid down the authority of the Guardian and the Universal House of Justice, the elected governing body of the Bahá'í Faith that had been written about by Bahá'u'lláh, and had not yet been established:

Shoghi Effendi later expressed to his wife and others that he had no foreknowledge of the existence of the Institution of Guardianship, least of all that he was appointed as Guardian. The most he expected was perhaps, because he was the eldest grandson, `Abdu'l-Bahá might have left instructions as to how the Universal House of Justice was to be elected and he might have been designated as Convener of the gathering which would elect it.

From the time of his appointment as Guardian until his death the Bahá'í Faith grew from 100,000 to 400,000 members, capitalizing on prior growth and setting the stage for more, and the countries and territories in which Bahá'ís had representation went from 35 to 250. As Guardian and head of the religion, Shoghi Effendi communicated his vision to the Bahá'ís of the world through his numerous letters and his meetings with pilgrims to Palestine. During the 1920s he first started to systematize and extend the Bahá'í administration throughout the world; the Bahá'í community was relatively small and undeveloped when he assumed leadership of the religion, and he strengthened and developed it over many years to support the administrative structure envisioned by `Abdu'l-Bahá.

Under Shoghi Effendi's direction, National Spiritual Assemblies were formed, and many thousands of Local Spiritual Assemblies were created. During the 1930s he worked on projects translating the works of Bahá'u'lláh into English. Starting in 1937, he set into motion a series of systematic plans to establish Bahá'í communities in all countries. A Ten Year Crusade was carried out from 1953 to 1963 with the aim of electing the Universal House of Justice as its paramount aim. Starting in the late 1940s, after the establishment of the State of Israel, he started to develop the Bahá'í World Centre in Haifa, including the construction of the superstructure of the Shrine of the Báb and the building of the International Archives as well as beautifying the gardens at Bahji, where the Shrine of Bahá'u'lláh is located, as well as developing plans and resources to raise several of the continental Bahá'í Houses of Worship around the world; these plans continued through the 1950s.

In the 1950s he also continued building the Bahá'í administration, establishing in 1951 the International Bahá'í Council to act as a precursor to the Universal House of Justice, as well as appointing 32 living Hands of the Cause — Bahá'ís appointed to the highest rank of service available, whose main function was to propagate and protect the religion. He also acted as the official representative of the religion to legal authorities in Israel as well as designated other representatives to work with the UN. In a more secular cause, prior to World War II he supported the work of restoration-forester Richard St. Barbe Baker to reforest Palestine, introducing him to religious leaders from the major faiths of the region, from whom backing was secured for reforestation.

In his lifetime, Shoghi Effendi translated into English many of the writings of the Báb, Bahá'u'lláh and `Abdu'l-Bahá, including the "Hidden Words" in 1929, the "Kitáb-i-Íqán" in 1931, "Gleanings" in 1935 and "Epistle to the Son of the Wolf" in 1941. He also translated such historical texts as "The Dawn-breakers". His significance is not just that of a translator, but he was also the designated and authoritative interpreter of the Bahá'í writings. His translations therefore are a guideline for all future translations of the Bahá'í writings. The vast majority of his writings were in the style of letters with Bahá'ís from all parts of the globe.

These letters, of which 17,500 have been collected thus far and are believed to number a total of 30,000, ranged from routine correspondence regarding the affairs of Bahá'ís around the world to lengthy letters to the Bahá'ís of the world addressing specific themes. Some of his longer letters include "World Order of Bahá'u'lláh", regarding the nature of Bahá'í administration, "Advent of Divine Justice", regarding teaching the religion, and "Promised Day is Come" regarding Bahá'u'lláh's letters to world leaders.

Other letters included statements on Bahá'í beliefs, history, morality, principles, administration and law. He also wrote obituaries of some distinguished Bahá'ís. Many of his letters to individuals and assemblies have been compiled into several books which stand out as significant sources of literature for Bahá'ís around the world. The only actual book he ever wrote was "God Passes By" in 1944 to commemorate the centennial anniversary of the religion. The book, which is in English, is an interpretive history of the first century of the Bábí and Bahá'í Faiths. A shorter Persian language version was also written.

As a young student of twenty-four, Shoghi Effendi was initially shocked at the appointment as Guardian. He was also mourning the death of his grandfather to whom he had great attachment. The trauma of this culminated in him making retreats to the Swiss Alps. However, despite his youth, Shoghi Effendi had a clear idea of the goal he had for the religion. Oxford educated and Western in his style of dress, Shoghi Effendi was a stark contrast to his grandfather `Abdu'l-Bahá. He distanced himself from the local clergy and notability, and travelled little to visit Bahá’ís unlike his grandfather. Correspondence and pilgrims were the way that Shoghi Effendi conveyed his messages. His talks are the subject to a great number of "pilgrim notes".

He also was concerned with matters dealing with Bahá'í belief and practice — as Guardian he was empowered to interpret the writings of Bahá'u'lláh and `Abdu'l-Bahá, and these were authoritative and binding, as specified in `Abdu'l-Bahá's will. His leadership style was however, quite different from that of `Abdu'l-Bahá, in that he signed his letters to the Bahá'ís as "your true brother", and he did not refer to his own personal role, but instead to the institution of the guardianship. He requested that he be referred in letters and verbal addresses always as Shoghi Effendi, as opposed to any other appellation. He also distanced himself as a local notable. He was critical of the Bahá'ís referring to him as a holy personage, asking them not to celebrate his birthday or have his picture on display.

Shoghi Effendi's personal life was largely subordinate to his work as Guardian of the religion. His lack of secretarial support with the mass of correspondence had left a pattern of hard work in Haifa interspersed with occasional summer breaks to Europe—in the early years often to the Swiss Alps. In 1929 and 1940 he also travelled through Africa from south to north.

Shoghi Effendi had a great love for the English language. He was an avid fan of English literature, and enjoyed reading the King James Bible. He was noted for speaking English in subtle received pronunciation, and Persian in an Isfahani dialect, inherited from his grandmother. Shoghi Effendi held Iranian (Persian) nationality throughout his life and travelled on an Iranian passport, although he never visited Iran.

In March 1937, Shoghi Effendi married Mary Maxwell, entitled Rúhíyyih Khánum, a Canadian. She was the only child of May Maxwell, a disciple of `Abdu'l-Bahá, and William Sutherland Maxwell, a Canadian architect. Shoghi Effendi had first met Mary as a girl when she came on pilgrimage with her mother in 1923. Mary was an active Bahá'í teacher and youth worker, and a letter written to Shoghi Effendi described her as "a beautiful and most refreshing girl to know". Whilst on her third pilgrimage in 1937 the two began a discreet courtship. Then herself 26 years old, Mary was a tall, athletic woman. The couple married in the room of Bahíyyih Khánum in the House of `Abdu'l-Bahá in Haifa. The ceremony was a short, simple and quiet one in which Rúhíyyih Khánum wore black. Very few knew the wedding was taking place apart from the witnesses and a small group of residents of Haifa. Therefore the marriage came as a great surprise to the world-wide Bahá'í community when the mother of Shoghi Effendi cabled the Bahá'ís:

While Shoghi Effendi and Rúhíyyih Khánum never had children, Rúhíyyih Khánum became his constant companion and helpmate; in 1941, she became Shoghi Effendi's principal secretary in English.

Mírzá Muhammad `Alí was `Abdu'l-Bahá's half brother and was mentioned by Bahá'u'lláh as having a station "beneath" that of `Abdu'l-Bahá. Muhammad `Ali later fought `Abdu'l-Bahá for leadership and was ultimately excommunicated, along with several others in the Haifa/Akka area who supported him. When Shoghi Effendi was appointed Guardian Muhammad `Ali tried to revive his claim to leadership, suggesting that Bahá'u'lláh's mention of him in the Kitáb-i-'Ahd amounted to a succession of leadership.

After Shoghi Effendi's death, Rúhíyyih Khánum published parts of her personal diaries to show glimpses of Shoghi Effendi's life. She recalls a great deal of pain and suffering caused by his immediate family, and Bahá'ís in Haifa.

Throughout Shoghi Effendi's life, nearly all remaining family members and descendants of `Abdu'l-Bahá were expelled by him as covenant-breakers when they didn't abide by Shoghi Effendi's request to cut contact with covenant-breakers, as specified by `Abdu'l-Bahá. Other branches of Bahá'u'lláh's family had already been declared Covenant-breakers in `Abdu'l-Bahá's Will and Testament. At the time of his death, there were no living descendants of Bahá'u'lláh that remained loyal to him.

Shoghi Effendi's death came unexpectedly in London, on 4 November 1957, as he was travelling to Britain and caught the Asian Flu, during the pandemic which killed two million worldwide, and he is buried there in New Southgate Cemetery. His wife sent the following cable:

According to the framework of the Will and Testament of `Abdu'l-Bahá, it was not possible to appoint a successor, and the legislative body "possessing the exclusive right to legislate on matters not explicitly revealed" was not yet established in the world. Furthermore, Shoghi Effendi had left no will as attested to by the Hands of the Cause, who were required to ratify his selection. All of the 27 living Hands of the Cause unanimously signed a statement shortly after the death of Shoghi Effendi stating that he had died "without having appointed his successor..." 

In Shoghi Effendi's final message to the Baha'i World, dated October 1957, he named the Hands of the Cause of God, "the Chief Stewards of Bahá'u'lláh's embryonic World Commonwealth." Consequently, following the death of Shoghi Effendi, the Bahá'í Faith was temporarily stewarded by the Hands of the Cause, who elected among themselves 9 "Custodians" to serve in Haifa as the head of the Faith. They reserved to the "entire body of the Hands of the Cause" the responsibility to determine the transition of the International Bahá'í Council into the Universal House of Justice, and that the Custodians reserved to themselves the authority to determine and expel Covenant-breakers. This stewardship oversaw the execution of the final years of Shoghi Effendi's ordinances of the ten year crusade (which lasted until 1963) culminating and transitioning to the election and establishment of the Universal House of Justice, at the first Baha'i World Congress in 1963.

At the end of the Ten Year Crusade, planned by Shoghi Effendi and concluding in 1963, the Universal House of Justice was first elected. As its first order of business, the Universal House of Justice evaluated the situation caused by the fact that the Guardian had not appointed a successor. It determined that under the circumstances, given the criteria for succession described in the Will and Testament of `Abdu'l-Bahá, there was no legitimate way for another Guardian to be appointed. Therefore, although the Will and Testament of `Abdu'l-Bahá leaves provisions for a succession of Guardians, Shoghi Effendi remains the first and last occupant of this office.





</doc>
<doc id="29368" url="https://en.wikipedia.org/wiki?curid=29368" title="Slope">
Slope

In mathematics, the slope or gradient of a line is a number that describes both the "direction" and the "steepness" of the line. Slope is often denoted by the letter "m"; there is no clear answer to the question why the letter "m" is used for slope, but it might be from the "m for multiple" in the equation of a straight line "y = mx + b" or "y = mx + c".

Slope is calculated by finding the ratio of the "vertical change" to the "horizontal change" between (any) two distinct points on a line. Sometimes the ratio is expressed as a quotient ("rise over run"), giving the same number for every two distinct points on the same line. A line that is decreasing has a negative "rise". The line may be practical - as set by a road surveyor, or in a diagram that models a road or a roof either as a description or as a plan.

The "steepness", incline, or grade of a line is measured by the absolute value of the slope. A slope with a greater absolute value indicates a steeper line. The "direction" of a line is either increasing, decreasing, horizontal or vertical. 

The rise of a road between two points is the difference between the altitude of the road at those two points, say "y" and "y", or in other words, the rise is ("y" − "y") = Δ"y". For relatively short distances - where the earth's curvature may be neglected, the run is the difference in distance from a fixed point measured along a level, horizontal line, or in other words, the run is ("x" − "x") = Δ"x". Here the slope of the road between the two points is simply described as the ratio of the altitude change to the horizontal distance between any two points on the line.

In mathematical language, the slope "m" of the line is

The concept of slope applies directly to grades or gradients in geography and civil engineering. Through trigonometry, the slope "m" of a line is related to its angle of incline "θ" by the tangent function

Thus, a 45° rising line has a slope of +1 and a 45° falling line has a slope of −1.

As a generalization of this practical description, the mathematics of differential calculus defines the slope of a curve at a point as the slope of the tangent line at that point. When the curve is given by a series of points in a diagram or in a list of the coordinates of points, the slope may be calculated not at a point but between any two given points. When the curve is given as a continuous function, perhaps as an algebraic formula, then the differential calculus provides rules giving a formula for the slope of the curve at any point in the middle of the curve.

This generalization of the concept of slope allows very complex constructions to be planned and built that go well beyond static structures that are either horizontals or verticals, but can change in time, move in curves, and change depending on the rate of change of other factors. Thereby, the simple idea of slope becomes one of the main basis of the modern world in terms of both technology and the built environment.

The slope of a line in the plane containing the "x" and "y" axes is generally represented by the letter "m", and is defined as the change in the "y" coordinate divided by the corresponding change in the "x" coordinate, between two distinct points on the line. This is described by the following equation:

Given two points ("x","y") and ("x","y"), the change in "x" from one to the other is ("run"), while the change in "y" is ("rise"). Substituting both quantities into the above equation generates the formula:
The formula fails for a vertical line, parallel to the "y" axis (see Division by zero), where the slope can be taken as infinite, so the slope of a vertical line is considered undefined.

Suppose a line runs through two points: "P" = (1, 2) and "Q" = (13, 8). By dividing the difference in "y"-coordinates by the difference in "x"-coordinates, one can obtain the slope of the line:

As another example, consider a line which runs through the points (4, 15) and (3, 21). Then, the slope of the line is 





For example, consider a line running through the points (2,8) and (3,20). This line has a slope, , of 
One can then write the line's equation, in point-slope form:
or: 
The angle θ between -90° and 90° that this line makes with the -axis is 

Consider the two lines: and . Both lines have slope . They are not the same line. So they are parallel lines.

Consider the two lines and . The slope of the first line is . The slope of the second line is . The product of these two slopes is −1. So these two lines are perpendicular.

In statistical mathematics, the gradient of the line of best fit for a given distribution of data which is linear, numerical, and free of outliers, is usually written as formula_19, where formula_20 is defined as the gradient (in statistics), formula_21 is Pearson's correlation coefficient, formula_22 is the standard deviation of the y-values and formula_23 is the standard deviation of the x-values.

In this equation formula_24 for the least-squares regression line, formula_20 is the slope and formula_26 is the intercept.

There are two common ways to describe the steepness of a road or railroad. One is by the angle between 0° and 90° (in degrees), and the other is by the slope in a percentage. See also steep grade railway and rack railway.

The formulae for converting a slope given as a percentage into an angle in degrees and vice versa are: 
where "angle" is in degrees and the trigonometric functions operate in degrees. For example, a slope of 100% or 1000‰ is an angle of 45°.

A third way is to give one unit of rise in say 10, 20, 50 or 100 horizontal units, e.g. 1:10. 1:20, 1:50 or 1:100 (or ""1 in 10"", ""1 in 20"" etc.) Note that 1:10 is steeper than 1:20. For example, steepness of 20% means 1:5 or an incline with angle 11,3°.

Roads and railways have both longitudinal slopes and cross slopes.

The concept of a slope is central to differential calculus. For non-linear functions, the rate of change varies along the curve. The derivative of the function at a point is the slope of the line tangent to the curve at the point, and is thus equal to the rate of change of the function at that point.

If we let Δ"x" and Δ"y" be the distances (along the "x" and "y" axes, respectively) between two points on a curve, then the slope given by the above definition,

is the slope of a secant line to the curve. For a line, the secant between any two points is the line itself, but this is not the case for any other type of curve.

For example, the slope of the secant intersecting "y" = "x" at (0,0) and (3,9) is 3. (The slope of the tangent at is also 3—"a" consequence of the mean value theorem.)

By moving the two points closer together so that Δ"y" and Δ"x" decrease, the secant line more closely approximates a tangent line to the curve, and as such the slope of the secant approaches that of the tangent. Using differential calculus, we can determine the limit, or the value that Δ"y"/Δ"x" approaches as Δ"y" and Δ"x" get closer to zero; it follows that this limit is the exact slope of the tangent. If "y" is dependent on "x", then it is sufficient to take the limit where only Δ"x" approaches zero. Therefore, the slope of the tangent is the limit of Δ"y"/Δ"x" as Δ"x" approaches zero, or "dy"/"dx". We call this limit the derivative.

Its value at a point on the function gives us the slope of the tangent at that point. For example, let "y"="x". A point on this function is (-2,4). The derivative of this function is /=2"x". So the slope of the line tangent to "y" at (-2,4) is 2·(-2) = -4. The equation of this tangent line is: "y"-4=(-4)("x"-(-2)) or "y" = -4"x" - 4.

The concept of slope can be generalized to functions of more than one variable and is more often referred to as gradient.




</doc>
<doc id="29369" url="https://en.wikipedia.org/wiki?curid=29369" title="Sex organ">
Sex organ

A sex organ (or reproductive organ) is any part of an animal's body that is involved in sexual reproduction. The reproductive organs together constitute the reproductive system. The testis in the male, and the ovary in the female, are called the "primary sex organs". The external sex organs – the genitals or genitalia, visible at birth in both sexes, and the internal sex organs are called the secondary sex organs. 

Mosses, ferns, and some similar plants have gametangia for reproductive organs, which are part of the gametophyte. The flowers of flowering plants produce pollen and egg cells, but the sex organs themselves are inside the gametophytes within the pollen and the ovule. Coniferous plants likewise produce their sexually reproductive structures within the gametophytes contained within the cones and pollen. The cones and pollen are not themselves sexual organs.

The Latin term "genitalia", sometimes anglicized as "genitals", is used to describe the externally visible sex organs: in male mammals, the penis and scrotum; and in female mammals, the vulva and its organs.

The genitals and the internal sex organs are referred to as the "secondary sex organs". The primary sex organs are the gonads, a pair of sex organs, specifically the testes in the male or the ovaries in the female. Gonads as primary sex organs, generate reproductive gametes containing inheritable DNA. They also produce most of the primary hormones that affect sexual development, and regulate other sexual organs and sexually differentiated behaviors.

In general zoology, given the great variety in organs, physiologies, and behaviors involved in copulation, male genitalia are more strictly defined as "all male structures that are inserted in the female or that hold her near her gonopore during sperm transfer"; female genitalia are defined as "those parts of the female reproductive tract that make direct contact with male genitalia or male products (sperm, spermatophores) during or immediately after copulation".

The visible portion of the mammalian genitals for males consists of the scrotum and penis; for females, it consists of the vulva (labia, clitoris, etc.) and vagina.

In placental mammals, females have two genital orifices, the vagina and urethra, while males have only one, the urethra. Male and female genitals have many nerve endings, resulting in pleasurable and highly sensitive touch. In most human societies, particularly in conservative ones, exposure of the genitals is considered a public indecency.

In mammals, sex organs include:

In typical prenatal development, sex organs originate from a common primordium during early gestation and differentiate into male or female sexes. The SRY gene, usually located on the Y chromosome and encoding the testis determining factor, determines the direction of this differentiation. The absence of it allows the gonads to continue to develop into ovaries.

Thereafter, the development of the internal, and external reproductive organs is determined by hormones produced by certain fetal gonads (ovaries or testes) and the cells' response to them. The initial appearance of the fetal genitalia looks basically feminine: a pair of "urogenital folds" with a small protuberance in the middle, and the urethra behind the protuberance. If the fetus has testes, and if the testes produce testosterone, and if the cells of the genitals respond to the testosterone, the outer urogenital folds swell and fuse in the midline to produce the scrotum; the protuberance grows larger and straighter to form the penis; the inner urogenital swellings grow, wrap around the penis, and fuse in the midline to form the penile urethra.

Each sex organ in one sex has a homologous counterpart in the other one. See a list of homologues of the human reproductive system. In a larger perspective, the whole process of sexual differentiation also includes development of secondary sexual characteristics such as patterns of pubic and facial hair and female breasts that emerge at puberty. Furthermore, differences in brain structure arise, affecting, but not absolutely determining, behavior.

Intersex is the development of genitalia somewhere between typical male and female genitalia. Once the child is born, the parents are faced with decisions that are often difficult to make, such as whether or not to modify the genitalia, assign the child as male or female, or leave the genitalia as is. Some parents allow their doctors to choose. If they do decide to modify the genitalia, they have approximately a 50% chance of getting genitalia that will match the child's gender identity. If they pick the wrong one, their child may begin to show symptoms of transsexualism, which can lead them to a life of discomfort until they are able to remedy the issue.

Because of the strong sexual selection affecting the structure and function of genitalia, they form an organ system that evolves faster than any other. A great variety of genital form and function may therefore be found among animals.

In many other animals a single posterior orifice, called the cloaca, serves as the only opening for the reproductive, digestive, and urinary tracts (if present). All amphibians, birds, reptiles, some fish, and a few mammals (monotremes, tenrecs, golden moles, and marsupial moles) have this orifice, from which they excrete both urine and feces in addition to serving reproductive functions. Excretory systems with analogous purpose in certain invertebrates are also sometimes referred to as cloacae.

The organs concerned with insect mating and the deposition of eggs are known collectively as the external genitalia, although they may be largely internal; their components are very diverse in form.

The reproductive system of gastropods (slugs and snails) varies greatly from one group to another.

Planaria are flat worms widely used in biological research. There are sexual and asexual planaria. Sexual planaria are hermaphrodites, possessing both testicles and ovaries. Each planarian transports its excretion to the other planarian, giving and receiving sperm.

The life cycle of land plants involves alternation of generations between a sporophyte and a haploid gametophyte. The gametophyte produces sperm or egg cells by mitosis. The sporophyte produces spores by meiosis which in turn develop into gametophytes. Any sex organs that are produced by the plant will develop on the gametophyte. The seed plants, which include conifers and flowering plants have small gametophytes that develop inside the pollen grains (male) and the ovule (female).

Sexual reproduction in flowering plants involves the union of the male and female germ cells, sperm and egg cells respectively. Pollen is produced in stamens, and is carried to the pistil, which has the ovary at its base where fertilization can take place. Within each pollen grain is a male gametophyte which consists of only three cells. In most flowering plants the female gametophyte within the ovule consists of only seven cells. Thus there are no sex organs as such.




</doc>
<doc id="29370" url="https://en.wikipedia.org/wiki?curid=29370" title="Snake">
Snake

Snakes are elongated, legless, carnivorous reptiles of the suborder Serpentes. Like all squamates, snakes are ectothermic, amniote vertebrates covered in overlapping scales. Many species of snakes have skulls with several more joints than their lizard ancestors, enabling them to swallow prey much larger than their heads with their highly mobile jaws. To accommodate their narrow bodies, snakes' paired organs (such as kidneys) appear one in front of the other instead of side by side, and most have only one functional lung. Some species retain a pelvic girdle with a pair of vestigial claws on either side of the cloaca. Lizards have evolved elongate bodies without limbs or with greatly reduced limbs about twenty five times independently via convergent evolution, leading to many lineages of legless lizards. Legless lizards resemble snakes, but several common groups of legless lizards have eyelids and external ears, which snakes lack, although this rule is not universal (see Amphisbaenia, Dibamidae, and Pygopodidae).

Living snakes are found on every continent except Antarctica, and on most smaller land masses; exceptions include some large islands, such as Ireland, Iceland, Greenland, the Hawaiian archipelago, and the islands of New Zealand, and many small islands of the Atlantic and central Pacific oceans. Additionally, sea snakes are widespread throughout the Indian and Pacific Oceans. More than 20 families are currently recognized, comprising about 520 genera and about 3,600 species. They range in size from the tiny, -long thread snake to the reticulated python of in length. The fossil species "Titanoboa cerrejonensis" was long. Snakes are thought to have evolved from either burrowing or aquatic lizards, perhaps during the Jurassic period, with the earliest known fossils dating to between 143 and 167 Ma ago. The diversity of modern snakes appeared during the Paleocene period ("c" 66 to 56 Ma ago). The oldest preserved descriptions of snakes can be found in the Brooklyn Papyrus.

Most species are nonvenomous and those that have venom use it primarily to kill and subdue prey rather than for self-defense. Some possess venom potent enough to cause painful injury or death to humans. Nonvenomous snakes either swallow prey alive or kill by constriction.

The English word "snake" comes from Old English "snaca", itself from Proto-Germanic "*snak-an-" (cf. Germanic "Schnake" "ring snake", Swedish "snok" "grass snake"), from Proto-Indo-European root "*(s)nēg-o-" "to crawl", "to creep", which also gave "sneak" as well as Sanskrit "nāgá" "snake". The word ousted "adder", as "adder" went on to narrow in meaning, though in Old English "næddre" was the general word for snake. The other term, "serpent", is from French, ultimately from Indo-European "*serp-" (to creep), which also gave Ancient Greek "hérpō" (ἕρπω) "I crawl".

The fossil record of snakes is relatively poor because snake skeletons are typically small and fragile making fossilization uncommon. Fossils readily identifiable as snakes (though often retaining hind limbs) first appear in the fossil record during the Cretaceous period. The earliest known true snake fossils (members of the crown group Serpentes) come from the marine simoliophiids, the oldest of which is the Late Cretaceous (Cenomanian age) "Haasiophis terrasanctus", dated to between 112 and 94 million years old.

Based on comparative anatomy, there is consensus that snakes descended from lizards. Pythons and boas—primitive groups among modern snakes—have vestigial hind limbs: tiny, clawed digits known as anal spurs, which are used to grasp during mating. The families Leptotyphlopidae and Typhlopidae also possess remnants of the pelvic girdle, appearing as horny projections when visible.

Front limbs are nonexistent in all known snakes. This is caused by the evolution of their Hox genes, controlling limb morphogenesis. The axial skeleton of the snakes’ common ancestor, like most other tetrapods, had regional specializations consisting of cervical (neck), thoracic (chest), lumbar (lower back), sacral (pelvic), and caudal (tail) vertebrae. Early in snake evolution, the Hox gene expression in the axial skeleton responsible for the development of the thorax became dominant. As a result, the vertebrae anterior to the hindlimb buds (when present) all have the same thoracic-like identity (except from the atlas, axis, and 1–3 neck vertebrae). In other words, most of a snake's skeleton is an extremely extended thorax. Ribs are found exclusively on the thoracic vertebrae. Neck, lumbar and pelvic vertebrae are very reduced in number (only 2–10 lumbar and pelvic vertebrae are present), while only a short tail remains of the caudal vertebrae. However, the tail is still long enough to be of important use in many species, and is modified in some aquatic and tree-dwelling species.

Many modern snake groups originated during the Paleocene, alongside the adaptive radiation of mammals following the extinction of (non-avian) dinosaurs. The expansion of grasslands in North America also led to an explosive radiation among snakes. Previously, snakes were a minor component of the North American fauna, but during the Miocene, the number of species and their prevalence increased dramatically with the first appearances of vipers and elapids in North America and the significant diversification of Colubridae (including the origin of many modern genera such as Nerodia, Lampropeltis, Pituophis, and Pantherophis).

There is fossil evidence to suggest that snakes may have evolved from burrowing lizards, such as the varanids (or a similar group) during the Cretaceous Period. An early fossil snake relative, "Najash rionegrina", was a two-legged burrowing animal with a sacrum, and was fully terrestrial. One extant analog of these putative ancestors is the earless monitor "Lanthanotus" of Borneo (though it also is semiaquatic). Subterranean species evolved bodies streamlined for burrowing, and eventually lost their limbs. According to this hypothesis, features such as the transparent, fused eyelids (brille) and loss of external ears evolved to cope with fossorial difficulties, such as scratched corneas and dirt in the ears. Some primitive snakes are known to have possessed hindlimbs, but their pelvic bones lacked a direct connection to the vertebrae. These include fossil species like "Haasiophis", "Pachyrhachis" and "Eupodophis", which are slightly older than "Najash".
This hypothesis was strengthened in 2015 by the discovery of a 113m year-old fossil of a four-legged snake in Brazil that has been named "Tetrapodophis amplectus". It has many snake-like features, is adapted for burrowing and its stomach indicates that it was preying on other animals. It is currently uncertain if "Tetrapodophis" is a snake or another species, in the squamate order, as a snake-like body has independently evolved at least 26 times. "Tetrapodophis" does not have distinctive snake features in its spine and skull.

An alternative hypothesis, based on morphology, suggests the ancestors of snakes were related to mosasaurs—extinct aquatic reptiles from the Cretaceous—which in turn are thought to have derived from varanid lizards. According to this hypothesis, the fused, transparent eyelids of snakes are thought to have evolved to combat marine conditions (corneal water loss through osmosis), and the external ears were lost through disuse in an aquatic environment. This ultimately led to an animal similar to today's sea snakes. In the Late Cretaceous, snakes recolonized land, and continued to diversify into today's snakes. Fossilized snake remains are known from early Late Cretaceous marine sediments, which is consistent with this hypothesis; particularly so, as they are older than the terrestrial "Najash rionegrina". Similar skull structure, reduced or absent limbs, and other anatomical features found in both mosasaurs and snakes lead to a positive cladistical correlation, although some of these features are shared with varanids.

Genetic studies in recent years have indicated snakes are not as closely related to monitor lizards as was once believed—and therefore not to mosasaurs, the proposed ancestor in the aquatic scenario of their evolution. However, more evidence links mosasaurs to snakes than to varanids. Fragmented remains found from the Jurassic and Early Cretaceous indicate deeper fossil records for these groups, which may potentially refute either hypothesis.

In 2016 two studies reported that limb loss in snakes is associated with DNA mutations in the Zone of Polarizing Activity Regulatory Sequence (ZRS), a regulatory region of the sonic hedgehog gene which is critically required for limb development. More advanced snakes have no remnants of limbs, but basal snakes such as pythons and boas do have traces of highly reduced, vestigial hind limbs. Python embryos even have fully developed hind limb buds, but their later development is stopped by the DNA mutations in the ZRS.

There are over 2,900 species of snakes ranging as far northward as the Arctic Circle in Scandinavia and southward through Australia. Snakes can be found on every continent except Antarctica, in the sea, and as high as in the Himalayan Mountains of Asia. There are numerous islands from which snakes are absent, such as Ireland, Iceland, and New Zealand (although New Zealand's waters are infrequently visited by the yellow-bellied sea snake and the banded sea krait).

All modern snakes are grouped within the suborder Serpentes in Linnean taxonomy, part of the order Squamata, though their precise placement within squamates remains controversial.

The two infraorders of Serpentes are: Alethinophidia and Scolecophidia. This separation is based on morphological characteristics and mitochondrial DNA sequence similarity. Alethinophidia is sometimes split into Henophidia and Caenophidia, with the latter consisting of "colubroid" snakes (colubrids, vipers, elapids, hydrophiids, and atractaspids) and acrochordids, while the other alethinophidian families comprise Henophidia. While not extant today, the Madtsoiidae, a family of giant, primitive, python-like snakes, was around until 50,000 years ago in Australia, represented by genera such as "Wonambi".

There are numerous debates in the systematics within the group. For instance, many sources classify Boidae and Pythonidae as one family, while some keep the Elapidae and Hydrophiidae (sea snakes) separate for practical reasons despite their extremely close relation.

Recent molecular studies support the monophyly of the clades of modern snakes, scolecophidians, typhlopids + anomalepidids, alethinophidians, core alethinophidians, uropeltids ("Cylindrophis", "Anomochilus", uropeltines), macrostomatans, booids, boids, pythonids and caenophidians.

While snakes are limbless reptiles, which evolved from (and are grouped with) lizards, there are many other species of lizards which have lost their limbs independently and superficially look similar to snakes. These include the slowworm and glass snake.

The now extinct "Titanoboa cerrejonensis" snakes found were in length. By comparison, the largest extant snakes are the reticulated python, which measures about long, and the anaconda, which measures about long and is considered the heaviest snake on Earth at .

At the other end of the scale, the smallest extant snake is "Leptotyphlops carlae", with a length of about . Most snakes are fairly small animals, approximately in length.

Pit vipers, pythons, and some boas have infrared-sensitive receptors in deep grooves on the snout, which allow them to "see" the radiated heat of warm-blooded prey. In pit vipers, the grooves are located between the nostril and the eye in a large "pit" on each side of the head. Other infrared-sensitive snakes have multiple, smaller labial pits lining the upper lip, just below the nostrils.

Snakes use smell to track their prey. They smell by using their forked tongues to collect airborne particles, then passing them to the vomeronasal organ or "Jacobson's organ" in the mouth for examination. The fork in the tongue gives snakes a sort of directional sense of smell and taste simultaneously. They keep their tongues constantly in motion, sampling particles from the air, ground, and water, analyzing the chemicals found, and determining the presence of prey or predators in the local environment. In water-dwelling snakes, such as the anaconda, the tongue functions efficiently underwater.
The underside is very sensitive to vibration. This allows snakes to be able to sense approaching animals by detecting faint vibrations in the ground.

Snake vision varies greatly, from only being able to distinguish light from dark to keen eyesight, but the main trend is that their vision is adequate although not sharp, and allows them to track movements. Generally, vision is best in arboreal snakes and weakest in burrowing snakes. Some snakes, such as the Asian vine snake (genus "Ahaetulla"), have binocular vision, with both eyes capable of focusing on the same point. Most snakes focus by moving the lens back and forth in relation to the retina, while in the other amniote groups, the lens is stretched. Many nocturnal snakes have slit pupils while diurnal snakes have round pupils.

The skin of a snake is covered in scales. Contrary to the popular notion of snakes being slimy because of possible confusion of snakes with worms, snakeskin has a smooth, dry texture. Most snakes use specialized belly scales to travel, gripping surfaces. The body scales may be smooth, keeled, or granular. The eyelids of a snake are transparent "spectacle" scales, which remain permanently closed, also known as brille.

The shedding of scales is called "ecdysis" (or in normal usage, "molting" or "sloughing"). In the case of snakes, the complete outer layer of skin is shed in one layer. Snake scales are not discrete, but extensions of the epidermis—hence they are not shed separately but as a complete outer layer during each molt, akin to a sock being turned inside out.

Snakes have a wide diversity of skin coloration patterns. These patterns are often related to behavior, such as a tendency to have to flee from predators. Snakes that are plain or have longitudinal stripes often have to escape from predators, with the pattern (or lack thereof) not providing reference points to predators, thus allowing the snake to escape without being notice. Plain snakes usually adopt active hunting strategies, as their pattern allows them to send little information to prey about motion. Blotched snakes, on the other hand, usually use ambush-based strategies, likely because it helps them blend into an environment with irregularly shaped objects, like sticks or rocks. Spotted patterning can similarly help snakes to blend into their environment.

The shape and number of scales on the head, back, and belly are often characteristic and used for taxonomic purposes. Scales are named mainly according to their positions on the body. In "advanced" (Caenophidian) snakes, the broad belly scales and rows of dorsal scales correspond to the vertebrae, allowing scientists to count the vertebrae without dissection.

Molting, or ecdysis, serves a number of functions. Firstly, the old and worn skin is replaced; secondly, it helps get rid of parasites such as mites and ticks. Renewal of the skin by molting is supposed to allow growth in some animals such as insects; however, this has been disputed in the case of snakes.

Molting occurs periodically throughout the snake's life. Before a molt, the snake stops eating and often hides or moves to a safe place. Just before shedding, the skin becomes dull and dry looking and the eyes become cloudy or blue-colored. The inner surface of the old skin liquefies. This causes the old skin to separate from the new skin beneath it. After a few days, the eyes clear and the snake "crawls" out of its old skin. The old skin breaks near the mouth and the snake wriggles out, aided by rubbing against rough surfaces. In many cases, the cast skin peels backward over the body from head to tail in one piece, like pulling a sock off inside-out. A new, larger, brighter layer of skin has formed underneath.

An older snake may shed its skin only once or twice a year. But a younger snake, still growing, may shed up to four times a year. The discarded skin gives a perfect imprint of the scale pattern, and it is usually possible to identify the snake if the discarded skin is reasonably intact. This periodic renewal has led to the snake being a symbol of healing and medicine, as pictured in the Rod of Asclepius.

Scale counts can sometimes be used to tell the sex of a snake when the species is not distinctly sexually dimorphic. A probe is inserted into the cloaca until it can go no further. The probe is marked at the point where it stops, removed, and compared to the subcaudal depth by laying it alongside the scales. The scalation count determines whether the snake is a male or female as hemipenes of a male will probe to a different depth (usually longer) than the cloaca of a female.

The skeleton of most snakes consists solely of the skull, hyoid, vertebral column, and ribs, though henophidian snakes retain vestiges of the pelvis and rear limbs.

The skull of the snake consists of a solid and complete neurocranium, to which many of the other bones are only loosely attached, particularly the highly mobile jaw bones, which facilitate manipulation and ingestion of large prey items. The left and right sides of the lower jaw are joined only by a flexible ligament at the anterior tips, allowing them to separate widely, while the posterior end of the lower jaw bones articulate with a quadrate bone, allowing further mobility. The bones of the mandible and quadrate bones can also pick up ground borne vibrations. Because the sides of the jaw can move independently of one another, snakes resting their jaws on a surface have sensitive stereo hearing which can detect the position of prey. The jaw-quadrate-stapes pathway is capable of detecting vibrations on the angstrom scale, despite the absence of an outer ear and the ossicle mechanism of impedance matching used in other vertebrates to receive vibrations from the air.

The hyoid is a small bone located posterior and ventral to the skull, in the 'neck' region, which serves as an attachment for muscles of the snake's tongue, as it does in all other tetrapods.

The vertebral column consists of anywhere between 200 and 400 (or more) vertebrae. Tail vertebrae are comparatively few in number (often less than 20% of the total) and lack ribs, while body vertebrae each have two ribs articulating with them. The vertebrae have projections that allow for strong muscle attachment enabling locomotion without limbs.

Autotomy of the tail, a feature found in some lizards is absent in most snakes. Caudal autotomy in snakes is rare and is intervertebral, unlike that in lizards, which is intravertebral—that is, the break happens along a predefined fracture plane present on a vertebra.

In some snakes, most notably boas and pythons, there are vestiges of the hindlimbs in the form of a pair of pelvic spurs. These small, claw-like protrusions on each side of the cloaca are the external portion of the vestigial hindlimb skeleton, which includes the remains of an ilium and femur.

Snakes are polyphyodonts with teeth that are continuously replaced.

The snake's heart is encased in a sac, called the "pericardium", located at the bifurcation of the bronchi. The heart is able to move around, however, owing to the lack of a diaphragm. This adjustment protects the heart from potential damage when large ingested prey is passed through the esophagus. The spleen is attached to the gall bladder and pancreas and filters the blood. The thymus is located in fatty tissue above the heart and is responsible for the generation of immune cells in the blood. The cardiovascular system of snakes is also unique for the presence of a renal portal system in which the blood from the snake's tail passes through the kidneys before returning to the heart.

The vestigial left lung is often small or sometimes even absent, as snakes' tubular bodies require all of their organs to be long and thin. In the majority of species, only one lung is functional. This lung contains a vascularized anterior portion and a posterior portion that does not function in gas exchange. This 'saccular lung' is used for hydrostatic purposes to adjust buoyancy in some aquatic snakes and its function remains unknown in terrestrial species. Many organs that are paired, such as kidneys or reproductive organs, are staggered within the body, with one located ahead of the other.

Snakes have no lymph nodes.

Cobras, vipers, and closely related species use venom to immobilize or kill their prey. The venom is modified saliva, delivered through fangs. The fangs of 'advanced' venomous snakes like viperids and elapids are hollow to inject venom more effectively, while the fangs of rear-fanged snakes such as the boomslang merely have a groove on the posterior edge to channel venom into the wound. Snake venoms are often prey specific—their role in self-defense is secondary.

Venom, like all salivary secretions, is a predigestant that initiates the breakdown of food into soluble compounds, facilitating proper digestion. Even nonvenomous snake bites (like any animal bite) will cause tissue damage.

Certain birds, mammals, and other snakes (such as kingsnakes) that prey on venomous snakes have developed resistance and even immunity to certain venoms. Venomous snakes include three families of snakes, and do not constitute a formal classification group used in taxonomy.

The colloquial term "poisonous snake" is generally an incorrect label for snakes. A poison is inhaled or ingested, whereas venom produced by snakes is injected into its victim via fangs. There are, however, two exceptions: "Rhabdophis" sequesters toxins from the toads it eats, then secretes them from nuchal glands to ward off predators, and a small unusual population of garter snakes in the U.S. state of Oregon retains enough toxins in their livers from the newts they eat to be effectively poisonous to small local predators (such as crows and foxes).

Snake venoms are complex mixtures of proteins, and are stored in venom glands at the back of the head. In all venomous snakes, these glands open through ducts into grooved or hollow teeth in the upper jaw. These proteins can potentially be a mix of neurotoxins (which attack the nervous system), hemotoxins (which attack the circulatory system), cytotoxins, bungarotoxins and many other toxins that affect the body in different ways. Almost all snake venom contains "hyaluronidase", an enzyme that ensures rapid diffusion of the venom.

Venomous snakes that use hemotoxins usually have fangs in the front of their mouths, making it easier for them to inject the venom into their victims. Some snakes that use neurotoxins (such as the mangrove snake) have fangs in the back of their mouths, with the fangs curled backwards. This makes it difficult both for the snake to use its venom and for scientists to milk them. "Elapids", however, such as cobras and kraits are "proteroglyphous"—they possess hollow fangs that cannot be erected toward the front of their mouths, and cannot "stab" like a viper. They must actually bite the victim.

It has recently been suggested that all snakes may be venomous to a certain degree, with harmless snakes having weak venom and no fangs. Most snakes currently labelled "nonvenomous" would still be considered harmless according to this theory, as they either lack a venom delivery method or are incapable of delivering enough to endanger a human. This theory postulates that snakes may have evolved from a common lizard ancestor that was venomous—and that venomous lizards like the gila monster, beaded lizard, monitor lizards, and the now-extinct mosasaurs may also have derived from it. They share this venom clade with various other saurian species.

Venomous snakes are classified in two taxonomic families:


There is a third family containing the "opistoglyphous" (rear-fanged) snakes (as well as the majority of other snake species):


Although a wide range of reproductive modes are used by snakes, all snakes employ internal fertilization. This is accomplished by means of paired, forked hemipenes, which are stored, inverted, in the male's tail. The hemipenes are often grooved, hooked, or spined in order to grip the walls of the female's cloaca.

Most species of snakes lay eggs which they abandon shortly after laying. However, a few species (such as the king cobra) actually construct nests and stay in the vicinity of the hatchlings after incubation. Most pythons coil around their egg-clutches and remain with them until they hatch. A female python will not leave the eggs, except to occasionally bask in the sun or drink water. She will even "shiver" to generate heat to incubate the eggs.

Some species of snake are ovoviviparous and retain the eggs within their bodies until they are almost ready to hatch. Recently, it has been confirmed that several species of snake are fully viviparous, such as the boa constrictor and green anaconda, nourishing their young through a placenta as well as a yolk sac, which is highly unusual among reptiles, or anything else outside of requiem sharks or placental mammals. Retention of eggs and live birth are most often associated with colder environments.
Sexual selection in snakes is demonstrated by the three thousand species that each use different tactics in acquiring mates. Ritual combat between males for the females they want to mate with includes topping, a behavior exhibited by most viperids in which one male will twist around the vertically elevated fore body of its opponent and forcing it downward. It is common for neck biting to occur while the snakes are entwined.

Parthenogenesis is a natural form of reproduction in which growth and development of embryos occur without fertilization. "Agkistrodon contortrix" (copperhead) and "Agkistrodon piscivorus" (cotton mouth) can reproduce by facultative parthenogenesis. That is, they are capable of switching from a sexual mode of reproduction to an asexual mode. The type of parthenogenesis that likely occurs is automixis with terminal fusion, a process in which two terminal products from the same meiosis fuse to form a diploid zygote. This process leads to genome wide homozygosity, expression of deleterious recessive alleles and often to developmental abnormalities. Both captive-born and wild-born "A. contortrix" and "A. piscivorus" appear to be capable of this form of parthenogenesis.

Reproduction in squamate reptiles is almost exclusively sexual. Males ordinarily have a ZZ pair of sex determining chromosomes, and females a ZW pair. However, the Colombian Rainbow boa, "Epicrates maurus" can also reproduce by facultative parthenogenesis resulting in production of WW female progeny. The WW females are likely produced by terminal automixis.

In regions where winters are colder than snakes can tolerate while remaining active, local species will brumate. Unlike hibernation, in which mammals are actually asleep, brumating reptiles are awake but inactive. Individual snakes may brumate in burrows, under rock piles, or inside fallen trees, or snakes may aggregate in large numbers at hibernacula.

All snakes are strictly carnivorous, eating small animals including lizards, frogs, other snakes, small mammals, birds, eggs, fish, snails or insects. Because snakes cannot bite or tear their food to pieces, they must swallow prey whole. The body size of a snake has a major influence on its eating habits. Smaller snakes eat smaller prey. Juvenile pythons might start out feeding on lizards or mice and graduate to small deer or antelope as an adult, for example.

The snake's jaw is a complex structure. Contrary to the popular belief that snakes can dislocate their jaws, snakes have a very flexible lower jaw, the two halves of which are not rigidly attached, and numerous other joints in their skull (see snake skull), allowing them to open their mouths wide enough to swallow their prey whole, even if it is larger in diameter than the snake itself. For example, the African egg-eating snake has flexible jaws adapted for eating eggs much larger than the diameter of its head. This snake has no teeth, but does have bony protrusions on the inside edge of its spine, which it uses to break shells when it eats eggs.

While the majority of snakes eat a variety of prey animals, there is some specialization by some species. King cobras and the Australian bandy-bandy consume other snakes. Snakes of the family Pareidae have more teeth on the right side of their mouths than on the left, as the shells of their prey usually spiral clockwise.

Some snakes have a venomous bite, which they use to kill their prey before eating it. Other snakes kill their prey by constriction. Still others swallow their prey whole and alive.
After eating, snakes become dormant while the process of digestion takes place. Digestion is an intense activity, especially after consumption of large prey. In species that feed only sporadically, the entire intestine enters a reduced state between meals to conserve energy. The digestive system is then 'up-regulated' to full capacity within 48 hours of prey consumption. Being ectothermic ("cold-blooded"), the surrounding temperature plays a large role in snake digestion. The ideal temperature for snakes to digest is . So much metabolic energy is involved in a snake's digestion that in the Mexican rattlesnake ("Crotalus durissus"), surface body temperature increases by as much as during the digestive process. Because of this, a snake disturbed after having eaten recently will often regurgitate its prey to be able to escape the perceived threat. When undisturbed, the digestive process is highly efficient, with the snake's digestive enzymes dissolving and absorbing everything but the prey's hair (or feathers) and claws, which are excreted along with waste.

The lack of limbs does not impede the movement of snakes. They have developed several different modes of locomotion to deal with particular environments. Unlike the gaits of limbed animals, which form a continuum, each mode of snake locomotion is discrete and distinct from the others; transitions between modes are abrupt.

Lateral undulation is the sole mode of aquatic locomotion, and the most common mode of terrestrial locomotion. In this mode, the body of the snake alternately flexes to the left and right, resulting in a series of rearward-moving "waves". While this movement appears rapid, snakes have rarely been documented moving faster than two body-lengths per second, often much less. This mode of movement has the same net cost of transport (calories burned per meter moved) as running in lizards of the same mass.

Terrestrial lateral undulation is the most common mode of terrestrial locomotion for most snake species. In this mode, the posteriorly moving waves push against contact points in the environment, such as rocks, twigs, irregularities in the soil, etc. Each of these environmental objects, in turn, generates a reaction force directed forward and towards the midline of the snake, resulting in forward thrust while the lateral components cancel out. The speed of this movement depends upon the density of push-points in the environment, with a medium density of about 8 along the snake's length being ideal. The wave speed is precisely the same as the snake speed, and as a result, every point on the snake's body follows the path of the point ahead of it, allowing snakes to move through very dense vegetation and small openings.

When swimming, the waves become larger as they move down the snake's body, and the wave travels backwards faster than the snake moves forwards. Thrust is generated by pushing their body against the water, resulting in the observed slip. In spite of overall similarities, studies show that the pattern of muscle activation is different in aquatic versus terrestrial lateral undulation, which justifies calling them separate modes. All snakes can laterally undulate forward (with backward-moving waves), but only sea snakes have been observed reversing the motion (moving backwards with forward-moving waves).

Most often employed by colubroid snakes (colubrids, elapids, and vipers) when the snake must move in an environment that lacks irregularities to push against (rendering lateral undulation impossible), such as a slick mud flat, or a sand dune, sidewinding is a modified form of lateral undulation in which all of the body segments oriented in one direction remain in contact with the ground, while the other segments are lifted up, resulting in a peculiar "rolling" motion. This mode of locomotion overcomes the slippery nature of sand or mud by pushing off with only static portions on the body, thereby minimizing slipping. The static nature of the contact points can be shown from the tracks of a sidewinding snake, which show each belly scale imprint, without any smearing. This mode of locomotion has very low caloric cost, less than ⅓ of the cost for a lizard to move the same distance. Contrary to popular belief, there is no evidence that sidewinding is associated with the sand being hot.

When push-points are absent, but there is not enough space to use sidewinding because of lateral constraints, such as in tunnels, snakes rely on concertina locomotion. In this mode, the snake braces the posterior portion of its body against the tunnel wall while the front of the snake extends and straightens. The front portion then flexes and forms an anchor point, and the posterior is straightened and pulled forwards. This mode of locomotion is slow and very demanding, up to seven times the cost of laterally undulating over the same distance. This high cost is due to the repeated stops and starts of portions of the body as well as the necessity of using active muscular effort to brace against the tunnel walls.

The movement of snakes in arboreal habitats has only recently been studied. While on tree branches, snakes use several modes of locomotion depending on species and bark texture. In general, snakes will use a modified form of concertina locomotion on smooth branches, but will laterally undulate if contact points are available. Snakes move faster on small branches and when contact points are present, in contrast to limbed animals, which do better on large branches with little 'clutter'.

Gliding snakes ("Chrysopelea") of Southeast Asia launch themselves from branch tips, spreading their ribs and laterally undulating as they glide between trees. These snakes can perform a controlled glide for hundreds of feet depending upon launch altitude and can even turn in midair.

The slowest mode of snake locomotion is rectilinear locomotion, which is also the only one where the snake does not need to bend its body laterally, though it may do so when turning. In this mode, the belly scales are lifted and pulled forward before being placed down and the body pulled over them. Waves of movement and stasis pass posteriorly, resulting in a series of ripples in the skin. The ribs of the snake do not move in this mode of locomotion and this method is most often used by large pythons, boas, and vipers when stalking prey across open ground as the snake's movements are subtle and harder to detect by their prey in this manner.

Snakes do not ordinarily prey on humans. Unless startled or injured, most snakes prefer to avoid contact and will not attack humans. With the exception of large constrictors, nonvenomous snakes are not a threat to humans. The bite of a nonvenomous snake is usually harmless; their teeth are not adapted for tearing or inflicting a deep puncture wound, but rather grabbing and holding. Although the possibility of infection and tissue damage is present in the bite of a nonvenomous snake, venomous snakes present far greater hazard to humans. The World Health Organisation (WHO) lists snakebite under the "other neglected conditions" category.

Documented deaths resulting from snake bites are uncommon. Nonfatal bites from venomous snakes may result in the need for amputation of a limb or part thereof. Of the roughly 725 species of venomous snakes worldwide, only 250 are able to kill a human with one bite. Australia averages only one fatal snake bite per year. In India, 250,000 snakebites are recorded in a single year, with as many as 50,000 recorded initial deaths. The WHO estimates that on the order of 100 000 people die each year as a result of snake bites, and around three times as many amputations and other permanent disabilities are caused by snakebites annually.

The treatment for a snakebite is as variable as the bite itself. The most common and effective method is through antivenom (or antivenin), a serum made from the venom of the snake. Some antivenom is species-specific (monovalent) while some is made for use with multiple species in mind (polyvalent). In the United States for example, all species of venomous snakes are pit vipers, with the exception of the coral snake. To produce antivenom, a mixture of the venoms of the different species of rattlesnakes, copperheads, and cottonmouths is injected into the body of a horse in ever-increasing dosages until the horse is immunized. Blood is then extracted from the immunized horse. The serum is separated and further purified and freeze-dried. It is reconstituted with sterile water and becomes antivenom. For this reason, people who are allergic to horses are more likely to suffer an allergic reaction to antivenom. Antivenom for the more dangerous species (such as mambas, taipans, and cobras) is made in a similar manner in India, South Africa, and Australia, although these antivenoms are species-specific.

In some parts of the world, especially in India, snake charming is a roadside show performed by a charmer. In such a show, the snake charmer carries a basket that contains a snake that he seemingly charms by playing tunes from his flutelike musical instrument, to which the snake responds. Snakes lack external ears, though they do have internal ears, and respond to the movement of the flute, not the actual noise.

The Wildlife Protection Act of 1972 in India technically proscribes snake charming on grounds of reducing animal cruelty. Other snake charmers also have a snake and mongoose show, where both the animals have a mock fight; however, this is not very common, as the snakes, as well as the mongooses, may be seriously injured or killed. Snake charming as a profession is dying out in India because of competition from modern forms of entertainment and environment laws proscribing the practice.

The "Irulas" tribe of Andhra Pradesh and Tamil Nadu in India have been hunter-gatherers in the hot, dry plains forests, and have practiced the art of snake catching for generations. They have a vast knowledge of snakes in the field. They generally catch the snakes with the help of a simple stick. Earlier, the "Irulas" caught thousands of snakes for the snake-skin industry. After the complete ban of the snake-skin industry in India and protection of all snakes under the Indian Wildlife (Protection) Act 1972, they formed the Irula Snake Catcher's Cooperative and switched to catching snakes for removal of venom, releasing them in the wild after four extractions. The venom so collected is used for producing life-saving antivenom, biomedical research and for other medicinal products. The "Irulas" are also known to eat some of the snakes they catch and are very useful in rat extermination in the villages.

Despite the existence of snake charmers, there have also been professional snake catchers or wranglers. Modern-day snake trapping involves a herpetologist using a long stick with a V- shaped end. Some television show hosts, like Bill Haast, Austin Stevens, Steve Irwin, and Jeff Corwin, prefer to catch them using bare hands.

While not commonly thought of as food in most cultures, in some cultures, the consumption of snakes is acceptable, or even considered a delicacy, prized for its alleged pharmaceutical effect of warming the heart. Snake soup of Cantonese cuisine is consumed by local people in autumn, to warm up their body. Western cultures document the consumption of snakes under extreme circumstances of hunger. Cooked rattlesnake meat is an exception, which is commonly consumed in parts of the Midwestern United States. In Asian countries such as China, Taiwan, Thailand, Indonesia, Vietnam and Cambodia, drinking the blood of snakes—particularly the cobra—is believed to increase sexual virility. The blood is drained while the cobra is still alive when possible, and is usually mixed with some form of liquor to improve the taste.

In some Asian countries, the use of snakes in alcohol is also accepted. In such cases, the body of a snake or several snakes is left to steep in a jar or container of liquor. It is claimed that this makes the liquor stronger (as well as more expensive). One example of this is the Habu snake sometimes placed in the Okinawan liquor Awamori also known as "Habu Sake".

Snake wine (蛇酒) is an alcoholic beverage produced by infusing whole snakes in rice wine or grain alcohol. The drink was first recorded to have been consumed in China during the Western Zhou dynasty and considered an important curative and believed to reinvigorate a person according to Traditional Chinese medicine.

In the Western world, some snakes (especially docile species such as the ball python and corn snake) are kept as pets. To meet this demand a captive breeding industry has developed. Snakes bred in captivity tend to make better pets and are considered preferable to wild caught specimens. Snakes can be very low maintenance pets, especially compared to more traditional species. They require minimal space, as most common species do not exceed in length. Pet snakes can be fed relatively infrequently, usually once every 5 to 14 days. Certain snakes have a lifespan of more than 40 years if given proper care.

In ancient Mesopotamia, Nirah, the messenger god of Ištaran, was represented as a serpent on "kudurrus", or boundary stones. Representations of two intertwined serpents are common in Sumerian art and Neo-Sumerian artwork and still appear sporadically on cylinder seals and amulets until as late as the thirteenth century BC. The horned viper ("Cerastes cerastes") appears in Kassite and Neo-Assyrian kudurrus and is invoked in Assyrian texts as a magical protective entity. A dragon-like creature with horns, the body and neck of a snake, the forelegs of a lion, and the hind-legs of a bird appears in Mesopotamian art from the Akkadian Period until the Hellenistic Period (323 BC–31 BC). This creature, known in Akkadian as the "mušḫuššu", meaning "furious serpent", was used as a symbol for particular deities and also as a general protective emblem. It seems to have originally been the attendant of the Underworld god Ninazu, but later became the attendant to the Hurrian storm-god Tishpak, as well as, later, Ninazu's son Ningishzida, the Babylonian national god Marduk, the scribal god Nabu, and the Assyrian national god Ashur.

In Egyptian history, the snake occupies a primary role with the Nile cobra adorning the crown of the pharaoh in ancient times. It was worshipped as one of the gods and was also used for sinister purposes: murder of an adversary and ritual suicide (Cleopatra). The ouroboros was a well-known ancient Egyptian symbol of a serpent swallowing its own tail. The precursor to the ouroboros was the "Many-Faced", a serpent with five heads, who, according to the Amduat, the oldest surviving Book of the Afterlife, was said to coil around the corpse of the sun god Ra protectively. The earliest surviving depiction of a "true" ouroboros comes from the gilded shrines in the tomb of Tutankhamun. In the early centuries AD, the ouroboros was adopted as a symbol by Gnostic Christians and chapter 136 of the "Pistis Sophia", an early Gnostic text, describes "a great dragon whose tail is in its mouth". In medieval alchemy, the ouroboros became a typical western dragon with wings, legs, and a tail.

The ancient Greeks used the Gorgoneion, a depiction of a hideous face with serpents for hair, as an apotropaic symbol to ward off evil. In a Greek myth described by Pseudo-Apollodorus in his "Bibliotheca", Medusa was a Gorgon with serpents for hair whose gaze turned all those who looked at her to stone and was slain by the hero Perseus. In the Roman poet Ovid's "Metamorphoses", Medusa is said to have once been a beautiful priestess of Athena, whom Athena turned into a serpent-haired monster after she was raped by the god Poseidon in Athena's temple. In another myth referenced by the Boeotian poet Hesiod and described in detail by Pseudo-Apollodorus, the hero Heracles is said to have slain the Lernaean Hydra, a multiple-headed serpent which dwelt in the swamps of Lerna.

The legendary account of the foundation of Thebes mentioned a monster snake guarding the spring from which the new settlement was to draw its water. In fighting and killing the snake, the companions of the founder Cadmus all perished – leading to the term "Cadmean victory" (i.e. a victory involving one's own ruin).
Three medical symbols involving snakes that are still used today are Bowl of Hygieia, symbolizing pharmacy, and the Caduceus and Rod of Asclepius, which are symbols denoting medicine in general.

India is often called the land of snakes and is steeped in tradition regarding snakes. Snakes are worshipped as gods even today with many women pouring milk on snake pits (despite snakes' aversion for milk). The cobra is seen on the neck of Shiva and Vishnu is depicted often as sleeping on a seven-headed snake or within the coils of a serpent. There are also several temples in India solely for cobras sometimes called "Nagraj" (King of Snakes) and it is believed that snakes are symbols of fertility. There is a Hindu festival called Nag Panchami each year on which day snakes are venerated and prayed to. See also "Nāga".

In India there is another mythology about snakes. Commonly known in Hindi as "Ichchhadhari" snakes. Such snakes can take the form of any living creature, but prefer human form. These mythical snakes possess a valuable gem called "Mani", which is more brilliant than diamond. There are many stories in India about greedy people trying to possess this gem and ending up getting killed.

The snake is one of the 12 celestial animals of Chinese Zodiac, in the Chinese calendar.

Many ancient Peruvian cultures worshipped nature. They emphasized animals and often depicted snakes in their art.

Snakes are a part of Hindu worship. A festival, Nag Panchami, in which participants worship either images of or live Nāgas (cobras) is celebrated every year. Most images of Lord Shiva depict snake around his neck. Puranas have various stories associated with snakes. In the Puranas, Shesha is said to hold all the planets of the Universe on his hoods and to constantly sing the glories of Vishnu from all his mouths. He is sometimes referred to as "Ananta-Shesha", which means "Endless Shesha". Other notable snakes in Hinduism are Ananta, Vasuki, Taxak, Karkotaka and Pingala. The term Nāga is used to refer to entities that take the form of large snakes in Hinduism and Buddhism.

Snakes have also been widely revered, such as in ancient Greece, where the serpent was seen as a healer. Asclepius carried a serpent wound around his wand, a symbol seen today on many ambulances.

In religious terms, the snake and jaguar are arguably the most important animals in ancient Mesoamerica. "In states of ecstasy, lords dance a serpent dance; great descending snakes adorn and support buildings from Chichen Itza to Tenochtitlan, and the Nahuatl word "coatl" meaning serpent or twin, forms part of primary deities such as Mixcoatl, Quetzalcoatl, and Coatlicue." In both Maya and Aztec calendars, the fifth day of the week was known as Snake Day.

In Judaism, the snake of brass is also a symbol of healing, of one's life being saved from imminent death.

In some parts of Christianity, Christ's redemptive work is compared to saving one's life through beholding the Nehushtan (serpent of brass). Snake handlers use snakes as an integral part of church worship in order to exhibit their faith in divine protection. However, more commonly in Christianity, the serpent has been seen as a representative of evil and sly plotting, which can be seen in the description in Genesis chapter 3 of a snake in the Garden of Eden tempting Eve. Saint Patrick is reputed to have expelled all snakes from Ireland while converting the country to Christianity in the 5th century, thus explaining the absence of snakes there.

In Christianity and Judaism, the snake makes its infamous appearance in the first book of the Bible when a serpent appears before the first couple Adam and Eve and tempts them with the forbidden fruit from the Tree of Knowledge. The snake returns in Exodus when Moses, as a sign of God's power, turns his staff into a snake and when Moses made the Nehushtan, a bronze snake on a pole that when looked at cured the people of bites from the snakes that plagued them in the desert. The serpent makes its final appearance symbolizing Satan in the Book of Revelation: "And he laid hold on the dragon the old serpent, which is the devil and Satan, and bound him for a thousand years."

In Neo-Paganism and Wicca, the snake is seen as a symbol of wisdom and knowledge.
Several compounds from snake venoms are being researched as potential treatments or preventatives for pain, cancers, arthritis, stroke, heart disease, hemophilia, and hypertension, and to control bleeding (e.g. during surgery).





</doc>
