<doc id="24654" url="https://en.wikipedia.org/wiki?curid=24654" title="Premier of New South Wales">
Premier of New South Wales

The Premier of New South Wales is the head of government in the state of New South Wales, Australia. The Government of New South Wales follows the Westminster system, with a Parliament of New South Wales acting as the legislature. The Premier is appointed by the Governor of New South Wales, and by modern convention holds office by virtue of his or her ability to command the support of a majority of members of the lower house of Parliament, the Legislative Assembly.

Prior to Federation in 1901 the term "Prime Minister of New South Wales" was also used. "Premier" has been used more or less exclusively from 1901, to avoid confusion with the federal Prime Minister of Australia.

The current Premier is Gladys Berejiklian, the Leader of the New South Wales Liberal Party, who assumed office on 23 January 2017. Berejiklian replaced Mike Baird on 23 January 2017, after Baird resigned as Premier.

Nine former premiers are alive, the oldest being Barrie Unsworth (1986-1988, born 1934). The most recent premier to die was Tom Lewis on 25 April 2016.



</doc>
<doc id="24655" url="https://en.wikipedia.org/wiki?curid=24655" title="Premier of Victoria">
Premier of Victoria

The Premier of Victoria is the Head of government in the Australian state of Victoria. The Premier is appointed by the Governor of Victoria, and is the leader of the political party able to secure a majority in the Legislative Assembly.

Responsible government came to the colony of Victoria in 1855. Between 1856 and 1892, the head of the government was commonly called the Premier or the Prime Minister, but neither title had any legal basis. The head of government always held another portfolio, usually Chief Secretary or Treasurer, for which they were paid a salary. The first head of government to hold the title of Premier without holding another portfolio was William Shiels in 1892.

The incumbent Premier of Victoria since the 2014 election is Daniel Andrews of the Australian Labor Party.

As of , six former premiers are alive, the oldest being John Cain Jr. (1982–1990, born 1931). The most recent premier to die was Joan Kirner (1990–92), on 1 June 2015.




</doc>
<doc id="24657" url="https://en.wikipedia.org/wiki?curid=24657" title="Standard Chinese">
Standard Chinese

Standard Chinese, also known as Modern Standard Mandarin, Standard Mandarin, or simply Mandarin, is a standard variety of Chinese that is the sole official language of both China and Taiwan ("de facto"), and also one of the four official languages of Singapore. Its pronunciation is based on the Beijing dialect, its vocabulary on the Mandarin dialects, and its grammar is based on written vernacular Chinese.

Like other varieties of Chinese, Standard Chinese is a tonal language with topic-prominent organization and subject–verb–object word order. It has more initial consonants but fewer vowels, final consonants and tones than southern varieties. Standard Chinese is an analytic language, though with many compound words.

There exist two standardised forms of the language, namely Putonghua in Mainland China and Guoyu in Taiwan. Aside from a number of differences in pronunciation and vocabulary, Putonghua is written using simplified Chinese characters (plus Hanyu Pinyin romanization for teaching), while Guoyu is written using traditional Chinese characters (plus Zhuyin for teaching). There are many characters that are identical between the two systems.

In Chinese, the standard variety is known as:


Standard Chinese is also commonly referred to by generic names for "Chinese", notably and (compare for English, and ). In total, there have been known over 20 various names for the language.

The term "Guoyu" had previously been used by non-Han rulers of China to refer to their languages, but in 1909 the Qing education ministry officially applied it to Mandarin, a lingua franca based on northern Chinese varieties, proclaiming it as the new "national language".

The name "Putonghua" also has a long, albeit unofficial, history. It was used as early as 1906 in writings by Zhu Wenxiong to differentiate a modern, standard Chinese from classical Chinese and other varieties of Chinese.

For some linguists of the early 20th century, the "Putonghua", or "common tongue/speech", was conceptually different from the "Guoyu", or "national language". The former was a national prestige variety, while the latter was the "legal" standard.

Based on common understandings of the time, the two were, in fact, different. "Guoyu" was understood as formal vernacular Chinese, which is close to classical Chinese. By contrast, "Putonghua" was called "the common speech of the modern man", which is the spoken language adopted as a national lingua franca by conventional usage.

The use of the term "Putonghua" by left-leaning intellectuals such as Qu Qiubai and Lu Xun influenced the People's Republic of China government to adopt that term to describe Mandarin in 1956. Prior to this, the government used both terms interchangeably.

In Taiwan, "Guoyu" (national language) continues to be the official term for Standard Chinese. The term "Guoyu" however, is less used in the PRC, because declaring a Beijing dialect-based standard to be the national language would be deemed unfair to speakers of other varieties and to the ethnic minorities. The term "Putonghua" (common speech), on the contrary, implies nothing more than the notion of a lingua franca.

During the government of a pro-Taiwan independence coalition (2000–2008), Taiwan officials promoted a different reading of "Guoyu" as all of the "national languages", meaning Hokkien, Hakka and Formosan as well as Standard Chinese.

"Huayu", or "language of the Chinese nation", originally simply meant "Chinese language", and was used in overseas communities to contrast Chinese with foreign languages. Over time, the desire to standardise the variety of Chinese spoken in these communities led to the adoption of the name "Huayu" to refer to Mandarin.

This name also avoids choosing a side between the alternative names of "Putonghua" and "Guoyu", which came to have political significance after their usages diverged along political lines between the PRC and the ROC. It also incorporates the notion that Mandarin is usually not the national or common language of the areas in which overseas Chinese live.

"Hanyu", or "language of the Han people", is another umbrella term used for Chinese. However, it has confusingly two different meanings:

This term, as well as "Hànzú" (), is a relatively modern concept; it came into being with the rise of Chinese nationalism in the 19th and 20th centuries. A related concept is "Hànzì" ().

The term "Mandarin" is a translation of "Guānhuà" (, literally "official's speech"), which referred to the lingua franca of the late Chinese empire. The Chinese term is obsolete as a name for the standard language, but is used by linguists to refer to the major group of Mandarin dialects spoken natively across most of northern and southwestern China.

In English, "Mandarin" may refer to the standard language, the dialect group as a whole, or to historic forms such as the late Imperial lingua franca. The name "Modern Standard Mandarin" is sometimes used by linguists who wish to distinguish the current state of the shared language from other northern and historic dialects.

Chinese has long had considerable dialectal variation, hence prestige dialects have always existed, and linguae francae have always been needed. Confucius, for example, used "yǎyán" () rather than colloquial regional dialects; text during the Han dynasty also referred to "tōngyǔ" (). Rime books, which were written since the Northern and Southern dynasties, may also have reflected one or more systems of standard pronunciation during those times. However, all of these standard dialects were probably unknown outside the educated elite; even among the elite, pronunciations may have been very different, as the unifying factor of all Chinese dialects, Classical Chinese, was a written standard, not a spoken one.

The Ming dynasty (1368–1644) and the Qing dynasty (1644–1912) began to use the term "guānhuà" (官话/官話), or "official speech", to refer to the speech used at the courts. The term "Mandarin" is borrowed directly from Portuguese. The Portuguese word "mandarim", derived from the Sanskrit word "mantrin" "counselor or minister", was first used to refer to the Chinese bureaucratic officials.
The Portuguese then translated "guānhuà" as "the language of the mandarins" or "the mandarin language".

In the 17th century, the Empire had set up Orthoepy Academies (正音书院/正音書院 "Zhèngyīn Shūyuàn") in an attempt to make pronunciation conform to the standard. But these attempts had little success, since as late as the 19th century the emperor had difficulty understanding some of his own ministers in court, who did not always try to follow any standard pronunciation.

Before the 19th century, the standard was based on the Nanjing dialect, but later the Beijing dialect became increasingly influential, despite the mix of officials and commoners speaking various dialects in the capital, Beijing. By some accounts, as late as the early 20th century, the position of Nanjing Mandarin was considered to be higher than that of Beijing by some and the postal romanization standards set in 1906 included spellings with elements of Nanjing pronunciation. Nevertheless, by 1909, the dying Qing dynasty had established the Beijing dialect as "guóyǔ" (国语/國語), or the "national language".

As the island of Taiwan had fallen under Japanese rule per the 1895 Treaty of Shimonoseki, the term referred to the Japanese language until the handover to the ROC in 1945.

After the Republic of China was established in 1912, there was more success in promoting a common national language. A Commission on the Unification of Pronunciation was convened with delegates from the entire country. A "Dictionary of National Pronunciation" (国音字典/國音字典) was published in 1919, defining a hybrid pronunciation that did not match any existing speech. Meanwhile, despite the lack of a workable standardized pronunciation, colloquial literature in written vernacular Chinese continued to develop apace.

Gradually, the members of the National Language Commission came to settle upon the Beijing dialect, which became the major source of standard national pronunciation due to its prestigious status. In 1932, the commission published the "Vocabulary of National Pronunciation for Everyday Use" (国音常用字汇/國音常用字彙), with little fanfare or official announcement. This dictionary was similar to the previous published one except that it normalized the pronunciations for all characters into the pronunciation of the Beijing dialect. Elements from other dialects continue to exist in the standard language, but as exceptions rather than the rule.

After the Chinese Civil War, the People's Republic of China continued the effort, and in 1955, officially renamed "guóyǔ" as "pǔtōnghuà" (普通话/普通話), or "common speech". By contrast, the name "guóyǔ" continued to be used by the Republic of China which, after its 1949 loss in the Chinese Civil War, was left with a territory consisting only of Taiwan and some smaller islands. Since then, the standards used in the PRC and Taiwan have diverged somewhat, especially in newer vocabulary terms, and a little in pronunciation.

In 1956, the standard language of the People's Republic of China was officially defined as: ""Pǔtōnghuà" is the standard form of Modern Chinese with the Beijing phonological system as its norm of pronunciation, and Northern dialects as its base dialect, and looking to exemplary modern works in "báihuà" 'vernacular literary language' for its grammatical norms."
By the official definition, Standard Chinese uses:

In the early 1950s, this standard language was understood by 41% of the population of the country, including 54% of speakers of Mandarin dialects, but only 11% of people in the rest of the country. In 1984, the proportion understanding the standard language nationally rose to 90% and the proportion understanding the standard language among the speakers of Mandarin dialects rose to 91%. A survey conducted by the China's Education Ministry in 2007 indicated that 53.06% of the population were able to effectively communicate orally in Standard Chinese.

From an official point of view, Standard Chinese serves the purpose of a lingua franca—a way for speakers of the several mutually unintelligible varieties of Chinese, as well as the Chinese minorities, to communicate with each other. The very name "Putonghua," or "common speech," reinforces this idea. In practice, however, due to Standard Chinese being a "public" lingua franca, other Chinese varieties and even non-Sinitic languages, have shown signs of losing ground to the standard.

China's Education Ministry published research on September, 2014, that only 70% percent of people of the PRC had good understanding and speaking skill of Putonghua despite the Chinese government promoting Putonghua on TV, radio and public services like buses to develop Putonghua as PRC official language to ease communication between all people of the PRC, because many ethnic groups had their own dialects, so it was problem to understand each other. To develop the Putonghua as the official common language of the PRC is difficult sometimes because some ethnic groups that are using other dialects don't like using the Putonghua because they think they are losing their own native dialect and cultural identity, for example, when in the summer of 2010 appeared some reports of increasing the using of the Putonghua on a local TV broadcasting in Cantonese dialect in the province of Guangdong, then thousands of Cantonese-speaking citizens were protesting on the demonstration against the plan.

In both China and Taiwan, the use of Mandarin as the medium of instruction in the educational system and in the media has contributed to the spread of Mandarin. As a result, Mandarin is now spoken fluently, though often with some regional or personal variation from the standard in terms of pronunciation or lexicon, by most people in mainland China and Taiwan. 
In 2014, the Ministry of Education estimated that about 70% of the population of China spoke Standard Mandarin to some degree, but only one tenth of those could speak it "fluently and articulately".
However, there is a 20% difference in penetration between eastern and western parts of China and a 50% difference between urban and rural areas. In addition, there are still 400 million Chinese who are only able to listen and understand Mandarin and not able to speak it. Therefore, in China's 13th Five Year Plan, the general goal is to raise the penetration rate to over 80% by 2020.

Both mainland China and Taiwan use Standard Chinese in the official context and the governments are keen to promote its use as a national lingua franca. The PRC in particular has enacted a law (the "National Common Language and Writing Law") which states that the government must "promote" Standard Mandarin. There is no explicit official intent to have Standard Chinese replace the regional varieties, but local governments have enacted regulations (such as the "Guangdong National Language Regulations") which "implement" the national law by way of coercive measures to control the public use of regional spoken varieties and traditional characters in writing. In practice, some elderly or rural Chinese-language speakers do not speak Standard Chinese fluently, if at all, though most are able to understand it. But urban residents and the younger generations, who received their education with Standard Mandarin as the primary medium of education, are almost all fluent in a version of Standard Chinese, some to the extent of being unable to speak their local dialect.
In the predominantly Han areas in mainland China, while the use of Standard Chinese is encouraged as the common working language, the PRC has been somewhat sensitive to the status of minority languages and, outside the education context, has generally not discouraged their social use. Standard Chinese is commonly used for practical reasons, as, in many parts of southern China, the linguistic diversity is so large that neighboring city dwellers may have difficulties communicating with each other without a "lingua franca".

In Taiwan, the relationship between Standard Chinese and other varieties, particularly Taiwanese Hokkien, has been more politically heated. During the martial law period under the Kuomintang (KMT) between 1949 and 1987, the KMT government revived the Mandarin Promotion Council and discouraged or, in some cases, forbade the use of Hokkien and other non-standard varieties. This produced a political backlash in the 1990s. Under the administration of Chen Shui-Bian, other Taiwanese varieties were taught in schools. The former President, Chen Shui-Bian, often spoke in Hokkien during speeches, while after the late 1990s, former President Lee Teng-hui, also speaks Hokkien openly.

In Hong Kong and Macau, which are now special administrative regions of the People's Republic of China, Cantonese is the primary language spoken by the majority of the population. Cantonese remains the official government language of Hong Kong and Macau. After Hong Kong's handover from the United Kingdom and Macau's handover from Portugal, Putonghua is the language used by the governments of the two territories to communicate with the Central People's Government of the PRC. There have been widespread efforts to promote usage of Putonghua in Hong Kong since the handover, with specific efforts to train police and teachers.

In Singapore, the government has heavily promoted a "Speak Mandarin Campaign" since the late 1970s, with the use of other Chinese varieties in broadcast media being prohibited and their use in any context officially discouraged until recently. This has led to some resentment amongst the older generations, as Singapore's migrant Chinese community is made up almost entirely of people of south Chinese descent. Lee Kuan Yew, the initiator of the campaign, admitted that to most Chinese Singaporeans, Mandarin was a "stepmother tongue" rather than a true mother language. Nevertheless, he saw the need for a unified language among the Chinese community not biased in favor of any existing group.

Mandarin is now spreading overseas beyond East Asia and Southeast Asia as well. In New York City, the use of Cantonese that dominated the Manhattan Chinatown for decades is being rapidly swept aside by Mandarin, the lingua franca of most of the latest Chinese immigrants.

In both the PRC and Taiwan, Standard Chinese is taught by immersion starting in elementary school. After the second grade, the entire educational system is in Standard Chinese, except for local language classes that have been taught for a few hours each week in Taiwan starting in the mid-1990s.

In December 2004, the first survey of language use in the People's Republic of China revealed that only 53% of its population, about 700 million people, could communicate in Standard Chinese. This 53% is defined as a passing grade above 3-B (a score above 60%) of the Evaluation Exam.

With the fast development of the country and the massive internal migration in China, the standard Putonghua Proficiency Test has quickly become popular. Many university graduates in mainland China and Hong Kong take this exam before looking for a job. Employers often require varying proficiency in Standard Chinese from applicants depending on the nature of the positions. Applicants of some positions, e.g. telephone operators, may be required to obtain a certificate. People raised in Beijing are sometimes considered inherently 1-A (A score of at least 97%) and exempted from this requirement. As for the rest, the score of 1-A is rare. According to the official definition of proficiency levels, people who get 1-B (A score of at least 92%) are considered qualified to work as television correspondents or in broadcasting stations. 2-A (A score of at least 87%) can work as Chinese Literature Course teachers in public schools. Other levels include: 2-B (A score of at least 80%), 3-A (A score of at least 70%) and 3-B (A score of at least 60%). In China, a proficiency of level 3-B usually cannot be achieved unless special training is received. Even though many Chinese do not speak with standard pronunciation, spoken Standard Chinese is widely understood to some degree.

The China National Language And Character Working Committee was founded in 1985. One of its important responsibilities is to promote Standard Chinese proficiency for Chinese native speakers.

The usual unit of analysis is the syllable, consisting of an optional initial consonant, an optional medial glide, a main vowel and an optional coda, and further distinguished by a tone.

The palatal initials , and pose a classic problem of phonemic analysis. Since they occur only before high front vowels, they are in complementary distribution with three other series, the dental sibilants, retroflexes and velars, which never occur in this position.

The final, which occurs only after dental sibilant and retroflex initials, is a syllabic approximant, prolonging the initial.
The rhotacized vowel forms a complete syllable.
A reduced form of this syllable occurs as a sub-syllabic suffix, spelled "-r" in pinyin and often with a diminutive connotation. The suffix modifies the coda of the base syllable in a rhotacizing process called "erhua".

Each full syllable is pronounced with a phonemically distinctive pitch contour. There are four tonal categories, marked in pinyin with iconic diacritic symbols, as in the words "mā" (妈/媽 "mother"), "má" (麻 "hemp"), "mǎ" (马/馬 "horse") and "mà" (骂/罵 "curse"). The tonal categories also have secondary characteristics. For example, the third tone is long and murmured, whereas the fourth tone is relatively short. Statistically, vowels and tones are of similar importance in the language.

There are also weak syllables, including grammatical particles such as the interrogative "ma" (吗/嗎) and certain syllables in polysyllabic words. These syllables are short, with their pitch determined by the preceding syllable.

It is common for Standard Chinese to be spoken with the speaker's regional accent, depending on factors such as age, level of education, and the need and frequency to speak in official or formal situations. This appears to be changing, though, in large urban areas, as social changes, migrations, and urbanization take place.

Due to evolution and standardization, Mandarin, although based on the Beijing dialect, is no longer synonymous with it. Part of this was due to the standardization to reflect a greater vocabulary scheme and a more archaic and "proper-sounding" pronunciation and vocabulary.

Distinctive features of the Beijing dialect are more extensive use of "erhua" in vocabulary items that are left unadorned in descriptions of the standard such as the "Xiandai Hanyu Cidian", as well as more neutral tones. An example of standard versus Beijing dialect would be the standard "mén" (door) and Beijing "ménr".

Most Standard Chinese as spoken on Taiwan differs mostly in the tones of some words as well as some vocabulary. Minimal use of the neutral tone and "erhua", and technical vocabulary constitute the greatest divergences between the two forms.

The stereotypical "southern Chinese" accent does not distinguish between retroflex and alveolar consonants, pronouncing pinyin "zh" [tʂ], "ch" [tʂʰ], and "sh" [ʂ] in the same way as "z" [ts], "c" [tsʰ], and "s" [s] respectively. Southern-accented Standard Chinese may also interchange "l" and "n", final "n" and "ng", and vowels "i" and "ü" [y]. Attitudes towards southern accents, particularly the Cantonese accent, range from disdain to admiration.

Chinese is a very analytic or isolating language, having almost no inflectional morphemes. It follows a similar sentence structure to English, frequently forming sentences in the order subject-predicate. The predicate can be an intransitive verb, a transitive verb followed by a direct object, a linking verb followed by a predicate nominative, etc.

Chinese differs from English in distinguishing between names of things, which can stand as predicate nominatives, and names of characteristics. Names of characteristics (e.g., green) cannot follow linking verbs. There is not an equivalent to the English predicate adjective. Instead, abstract characterizations such as "green", "angry", "hot", etc., stand as complete predicates in their own right. For example, 我不累。"Wǒ bú lèi". A word-for-word version in English might be "I not tired." Another common phrase, 你好 (nǐ hăo), demonstrates this feature; while it translates into English as "hello", the literal translation is "You good".

Chinese additionally differs from English in that it forms another kind of sentence by stating a topic and following it by a comment. To do this in English, speakers generally flag the topic of a sentence by prefacing it with "as for." For instance, one might say, "As for the money that Mom gave us, I have already bought candy with it." Note that the comment in this case is itself a complete sentence with subject, verb, and object. The Chinese version is simply, 妈妈给我们的钱,我已经买了糖果。"Māma gěi wǒmen de qián, wǒ yǐjīng mǎile tángguǒ(r)". This might be directly translated as "The money Mom gave us, I already bought candy," lacking a preface as in English.

Chinese does not inflect verbs for tense like English and other European languages. Instead it uses a combination of aspect markers for aspect and modality. In other words, it employs single syllables that indicate such things as (1) an action being expected or anticipated, (2) that the subject of the sentence has gone through some experience within a stated or implicit time period, (3) that a statement that was formerly not the case has now become true, i.e., that there has been a change of status, (4) that there still has not been a change in a condition previously noted, etc.

The time when something happens can be given by an explicit term such as "yesterday," by relative terms such as "formerly," etc.

Another major difference between the syntax of Chinese and languages like English lies in the stacking order of modifying clauses. 昨天发脾气的外交警察取消了沒有交钱的那些人的入境证。"Zuótiān fāpíqì de wàijiāo jǐngchá qǔxiāole méiyǒu jiāoqián de nàxiē rén de rùjìngzhèng". Using the Chinese order in English, that sentence would be:
In more ordinary English order, that would be:

There are a few other features of Chinese that would be unfamiliar to speakers of English, but the features mentioned above are generally the most noticeable.

Many formal, polite and humble words that were in use in imperial China have not been used in daily conversation in modern-day Mandarin, such as "jiàn" (贱/賤 "my humble") and "guì" (贵/貴 "your honorable").

Although Chinese speakers make a clear distinction between Standard Chinese and the Beijing dialect, there are aspects of Beijing dialect that have made it into the official standard. Standard Chinese has a T–V distinction between the polite and informal "you" that comes from the Beijing dialect, although its use is quite diminished in daily speech. In addition, it also distinguishes between ""zánmen"" ("we" including the listener) and ""wǒmen"" ("we" not including the listener). In practice, neither distinction is commonly used by most Chinese, at least outside the Beijing area.

The following samples are some phrases from the Beijing dialect which are not yet accepted into Standard Chinese:

The following samples are some phrases from Beijing dialect which have become accepted as Standard Chinese:

Standard Chinese is written with characters corresponding to syllables of the language, most of which represent a morpheme.
In most cases, these characters come from those used in Classical Chinese to write cognate morphemes of late Old Chinese, though their pronunciation, and often meaning, has shifted dramatically over two millennia.
However, there are several words, many of them heavily used, which have no classical counterpart or whose etymology is obscure.
Two strategies have been used to write such words:

The government of the PRC (as well as some other governments and institutions) has promulgated a set of simplified forms. Under this system, the forms of the words "zhèlǐ" ("here") and "nàlǐ" ("there") changed from 這裏/這裡 and 那裏/那裡 to 这里 and 那里.

Chinese characters were traditionally read from top to bottom, right to left, but in modern usage it is more common to read from left to right.





</doc>
<doc id="24658" url="https://en.wikipedia.org/wiki?curid=24658" title="Premier of Tasmania">
Premier of Tasmania

The Premier of Tasmania is the head of the executive government in the Australian state of Tasmania. By convention, the leader of the party or political grouping which has majority support in the House of Assembly is invited by the Governor of Tasmania to be Premier and principal adviser.

Since the 2014 election, the Premier of Tasmania has been Will Hodgman, leader of the Liberal Party. Hodgman won a second term at the 2018 election, and now holds 13 of the 25 seats in the House of Assembly.

Before the 1890s, there was no formal party system in Tasmania. Party labels before that time indicate a general tendency only. The current convention of appointing the Premier from the House of Assembly was not generally applied prior to 1920, with Premiers often appointed from the Legislative Council.

As of 24 January 2011, eight former premiers are alive, the oldest being Tony Rundle (1996–98, born 1939). The most recent premier to die was Sir Angus Bethune (1969–72), on 27 August 2004. The most recently serving premier to die was Jim Bacon (1998–2004), on 20 June 2004.




</doc>
<doc id="24659" url="https://en.wikipedia.org/wiki?curid=24659" title="Perihelion and aphelion">
Perihelion and aphelion

The perihelion () of any orbit of a celestial body about the Sun is the point where the body comes closest to the Sun. It is the opposite of aphelion (), which is the point in the orbit where the celestial body is farthest from the Sun.

The words perihelion and aphelion were coined by Johannes Kepler to describe the orbital motion of the planets.
The words are formed from the prefixes "peri-" (Greek: "περί", near) and "apo-" (Greek: "ἀπό", away from) affixed to the Greek word for the sun, ἥλιος.

Perihelion and aphelion are sometimes incorrectly used for the orbits of objects about bodies other than the Sun. The correct terms are:

According to Kepler's first law of planetary motion, all planets, comets, and asteroids in the Solar System have approximately elliptical orbits around the Sun. Newton's and Einstein's laws of gravity imply that the orbits are only approximately elliptical because of perturbations due to the gravitational attraction of other bodies. Every ellipse has two focus points, and the Sun is at one of these focus points for the elliptical orbits of its satellites. Hence, an orbiting body has a closest and a farthest point from its parent object, that is, a perihelion and an aphelion. Each extreme is known as an apsis. 

Orbital eccentricity measures the flatness (departure from a perfect circle) of the orbit.

Earth is about 147.1 million kilometers (91.4 million miles) from the Sun at perihelion around January 3, in contrast to about 152.1 million kilometers (94.5 million miles) at aphelion around July 4 — a difference of about 5.0 million kilometers (3.1 million miles). (These dates change over time due to precession and other orbital factors, which follow cyclical patterns known as Milankovitch cycles. For a table of these dates for various years, see Apsis.)

Because of the increased distance at aphelion, only 93.55% of the solar radiation from the Sun falls on a given area of land as does at perihelion. However, this fluctuation does not account for the seasons, as it is summer in the northern hemisphere when it is winter in the southern hemisphere and "vice versa." Instead, seasons result from the tilt of Earth's axis, which is 23.4 degrees away from perpendicular to the plane of Earth's orbit around the sun. Winter falls on the hemisphere where sunlight strikes least directly, and summer falls where sunlight strikes most directly, regardless of the Earth's distance from the Sun.

In the northern hemisphere, summer occurs at the same time as aphelion. Despite this, there are larger land masses in the northern hemisphere, which are easier to heat than the seas. Consequently, summers are warmer in the northern hemisphere than in the southern hemisphere under similar conditions.




</doc>
<doc id="24661" url="https://en.wikipedia.org/wiki?curid=24661" title="Privatization">
Privatization

Privatization (also spelled privatisation) can mean different things including moving something from the public sphere into the private sphere. It is also sometimes used as a synonym for deregulation when a heavily regulated private company or industry becomes less regulated. Government functions and services may also be privatized; in this case, private entities are tasked with the implementation of government programs or performance of government services that had previously been the purview of state-run agencies. Some examples include revenue collection, law enforcement, and prison management.

Another definition is the purchase of all outstanding shares of a publicly traded company by private investors, or the sale of a state-owned enterprise to private investors. In the case of a for-profit company, the shares are then no longer traded at a stock exchange, as the company became private through private equity; in the case the partial or full sale of a state-owned enterprise to private owners shares may be traded in the public market for the first time, or for the first time since an enterprise's previous nationalization. The second such type of privatization is the demutualization of a mutual organization or cooperative in order to form a joint-stock company.

"The Economist" magazine introduced the term "privatization" (or "privatisation") during the 1930s when it covered Nazi Germany's economic policy.

"The Economist" magazine introduced the term "privatization" (or "privatisation") during the 1930s when it covered Nazi Germany's economic policy.

The word privatization may mean different things depending on the context in which it is used. It can mean moving something from the public sphere into the private sphere, but it may also be used to describe something that was always private, but heavily regulated, which becomes less regulated through a process of deregulation. The term may also be used descriptively for something that has always been private, but could be public in other jurisdictions.

There are also private entities that may perform public functions. These entities could also be described as privatized. Privatization may mean the government sells state-owned businesses to private interests, but it may also be discussed in the context of the privatization of services or government functions, where private entities are tasked with the implementation of government programs or performance of government services. Gillian E. Metzger has written that: "Private entities [in the US] provide a vast array of social services for the government; administer core aspects of government programs; and perform tasks that appear quintessentially governmental, such as promulgating standards or regulating third-party activities." Metzger mentions an expansion of privatization that includes health and welfare programs, public education, and prisons.

The history of privatization dates from Ancient Greece, when governments contracted out almost everything to the private sector. In the Roman Republic private individuals and companies performed the majority of services including tax collection (tax farming), army supplies (military contractors), religious sacrifices and construction. However, the Roman Empire also created state-owned enterprises—for example, much of the grain was eventually produced on estates owned by the Emperor. Some scholars suggest that the cost of bureaucracy was one of the reasons for the fall of the Roman Empire.

Perhaps one of the first ideological movements towards privatization came during China's golden age of the Han Dynasty. Taoism came into prominence for the first time at a state level, and it advocated the laissez-faire principle of Wu wei (無為), literally meaning "do nothing". The rulers were counseled by the Taoist clergy that a strong ruler was virtually invisible.

During the Renaissance, most of Europe was still by and large following the feudal economic model. By contrast, the Ming dynasty in China began once more to practice privatization, especially with regards to their manufacturing industries. This was a reversal of the earlier Song dynasty policies, which had themselves overturned earlier policies in favor of more rigorous state control.

In Britain, the privatization of common lands is referred to as enclosure (in Scotland as the Lowland Clearances and the Highland Clearances). Significant privatizations of this nature occurred from 1760 to 1820, preceding the industrial revolution in that country.

The first mass privatization of state property occurred in Nazi Germany between 1933-37: "It is a fact that the government of the National Socialist Party sold off public ownership in several state-owned firms in the middle of the 1930s. The firms belonged to a wide range of sectors: steel, mining, banking, local public utilities, shipyard, ship-lines, railways, etc. In addition to this, delivery of some public services produced by public administrations prior to the 1930s, especially social services and services related to work, was transferred to the private sector, mainly to several organizations within the Nazi Party."

Great Britain privatized its steel industry in the 1950s, and the West German government embarked on large-scale privatization, including sale of the majority stake in Volkswagen to small investors in public share offerings in 1961. However, it was in the 1980s under Margaret Thatcher in the United Kingdom and Ronald Reagan in the United States that privatization gained worldwide momentum. Notable privatization attempts in the UK included privatization of Britoil (1982), Amersham International PLC (1982), British Telecom (1984), Sealink ferries (1984), British Petroleum (gradually privatized between 1979 and 1987), British Aerospace (1985 to 1987), British Gas (1986), Rolls-Royce (1987), Rover Group (formerly British Leyland, 1988), British Steel Corporation (1988), and the regional water authorities (mostly in 1989). After 1979, council house tenants in the UK were given the right to buy their homes (at a heavily discounted rate). One million purchased their residences by 1986.

Such efforts culminated in 1993 when British Rail was privatized under Thatcher's successor, John Major. British Rail had been formed by prior nationalization of private rail companies. The privatization was controversial, and the its impact is still debated today, as doubling of passenger numbers and investment was balanced by an increase in rail subsidy.

Privatization in Latin America flourished in the 1980s and 1990s as a result of a Western liberal economic policy. Companies providing public services such as water management, transportation, and telecommunication were rapidly sold off to the private sector. In the 1990s, privatization revenue from 18 Latin American countries totaled 6% of gross domestic product. Private investment in infrastructure from 1990 and 2001 reached $360.5 billion, $150 billion more than in the next emerging economy.

While economists generally give favorable evaluations of the impact of privatization in Latin America, opinion polls and public protests across the countries suggest that a large segment of the public is dissatisfied with or have negative views of privatization in the region.

In the 1990s, the governments in Eastern and Central Europe engaged in extensive privatization of state-owned enterprises in Eastern and Central Europe and Russia, with assistance from the World Bank, the U.S. Agency for International Development, the German Treuhand, and other governmental and nongovernmental organizations.

Ongoing privatization of Japan Post relates to that of the national postal service and one of the largest banks in the world. After years of debate, the privatization of Japan Post spearheaded by Junichiro Koizumi finally started in 2007. The privatization process is expected to last until 2017. Japan Post was one of the nation's largest employers, as one-third of Japanese state employees worked for it. It was also said to be the largest holder of personal savings in the world. Criticisms against Japan Post were that it served as a channel of corruption and was inefficient. In September 2003, Koizumi's cabinet proposed splitting Japan Post into four separate companies: a bank, an insurance company, a postal service company, and a fourth company to handle the post offices and retail storefronts of the other three.

After the Upper House rejected privatization, Koizumi scheduled nationwide elections for September 11, 2005. He declared the election to be a referendum on postal privatization. Koizumi subsequently won the election, gaining the necessary supermajority and a mandate for reform, and in October 2005, the bill was passed to privatize Japan Post in 2007.

Nippon Telegraph and Telephone's privatization in 1987 involved the largest share offering in financial history at the time. 15 of the world's 20 largest public share offerings have been privatizations of telecoms.

In 1988, the perestroika policy of Mikhail Gorbachev started allowing privatization of the centrally planned economy. Large privatization of the Soviet economy occurred over the next few years as the country dissolved. Other Eastern Bloc countries followed suit after the Revolutions of 1989 introduced non-communist governments.

The United Kingdom's largest public share offerings were privatizations of British Telecom and British Gas during the 1980s under the Conservative government of Margaret Thatcher, when many state-run firms were sold off to the private sector. The privatization received very mixed views from the public and the parliament. Even former Conservative prime minister Harold Macmillan was critical of the policy, likening it to "selling the family silver". There were around 3 million shareholders in Britain when Thatcher took office in 1979, but the subsequent sale of state-run firms saw the number of shareholders double by 1985. By the time of her resignation in 1990, there were more than 10 million shareholders in Britain.

The largest public shares offering in France involved France Télécom.

Egypt undertook widespread privatization under Hosni Mubarak. He was later overthrown in the 2011 revolution, the public called for re-nationalization as the privatized firms were accused of practicing crony capitalism with the old regime.

Under the Medicare managed care the government pays a managed care organization (MCO) a fixed amount called the "capitated rate" for all medical services received by a beneficiary in a given period. Enrollment in the programs has increased substantially since 1990; in 2002 60% of Medicaid beneficiaries and 12% of Medicare beneficiaries were being treated by MCOs. Private sector involvement in Medicare and Medicaid is not limited to MCOs; private doctors, hospitals, nursing homes provide medical care; reimbursement claims are processed by private intermediaries; and peer review organizations, utilization review committees and accreditation organizations like JCAHO are staffed by private medical personnel.

Homeless shelters and food banks are run by private organizations, who also provide treatment services, operate Head Start progrms and work with child welfare agencies. Privatization of welfare system expanded in 1996, when the Aid to Families with Dependent Child (AFDC) program was replaced with the Temporary Aid to Needy Families (TANF) program. Welfare services that are often privatized include workforce development, job training and job placement are often privatized.

There is also some private sector involvement in the public education system including charter schools, [{Educational Management Organizations]] (EMOs), and school voucher programs. EMOs are usually for-profit and manage charter schools and sometimes traditional public schools as well. The United States Supreme Court upheld school voucher programs against an Establishment Clause challenge in "Zelman v. Simmons-Harris".

In the US in 2001, private prison facilities housed 12.3% of all federal prisoners and 5.8% of state prisoners. Contracts for these private prisons regulate prison conditions and operation, but the nature of running a prison requires a substantial exercise of discretion. Private prisons are more exposed to liability than state run prisons.

Both for-profit and non-profit entities are tasked with various responsibilities related to the US foreign aid budget such as providing emergency humanitarian relief, development assistance, as well as post-conflict reconstruction efforts. Similarly, private entities have started to perform tasks that have traditionally been regarded as falling within the government's diplomatic and military authority like participating in peace negotiations, military training, intelligence gathering and other security services or combat-related missions. Many of the military interrogators at Abu Ghraib prison were provided by a private contractor and lacked formal military training; this was subsequently identified as a contributing factor to detainee abuse at the prison by the Fay report.

The United Nations uses private subcontractors as well, and in some cases, "failed states" have relied on private entities extensively for a range of tasks including building critical infrastructure, managing social services programs and using private military companies during the course of armed conflicts.

The United States Constitution only constrains state action and, with few exceptions, "erects no shield against merely private conduct, however discriminatory or wrongful". Gillian Metzger writes:
Adequately guarding against abuse of public power requires application of constitutional principles to every exercise of state authority, regardless of the formal public or private status of the actor involved: 'It surely cannot be that government, state or federal, is able to evade the most solemn obligations imposed in the Constitution by simply resorting to the corporate form' and thereby transferring operation of government programs to private hands"

Even if private actors can't be held accountable through the traditional constitutional mechanism, they may be bound by other regulatory or contractual requirements. Tort law might be another avenue of protection, and some may argue that this protection could be even more effective as public agencies and employees usually enjoy some degree of immunity from civil liability.

There are five main methods of privatization:


The choice of sale method is influenced by the capital market and the political and firm-specific factors. Privatization through the stock market is more likely to be the method used when there is an established capital market capable of absorbing the shares. A market with high liquidity can facilitate the privatization. If the capital markets are insufficiently developed, however, it would be difficult to find enough buyers. The shares may have to be underpriced, and the sales may not raise as much capital as would be justified by the fair value of the company being privatized. Many governments, therefore, elect for listings in more sophisticated markets, for example, Euronext, and the London, New York and Hong Kong stock exchanges.

Governments in developing countries and transition countries more often resort to direct asset sales to a few investors, partly because those countries do not yet have a stock market with high capital.

Voucher privatization occurred mainly in the transition economies in Central and Eastern Europe, such as Russia, Poland, the Czech Republic, and Slovakia. Additionally, privatization from below had made important contribution to economic growth in transition economies.

In one study assimilating some of the literature on "privatization" that occurred in Russian and Czech Republic transition economies, the authors identified three methods of privatization: "privatization by sale", "mass privatization", and "mixed privatization". Their calculations showed that "mass privatization" was the most effective method.

However, in economies "characterized by shortages" and maintained by the state bureaucracy, wealth was accumulated and concentrated by "gray/black market" operators. Privatizing industries by sale to these individuals did not mean a transition to "effective private sector owners [of former] state assets". Rather than mainly participating in a market economy, these individuals could prefer elevating their personal status or prefer accumulating political power. Instead, outside foreign investment led to the efficient conduct of former state assets in the private sector and market economy.

Through privatization by direct asset sale or the stock market, bidders compete to offer higher prices, generating more revenue for the state. Voucher privatization, on the other hand, could represent a genuine transfer of assets to the general population, creating a sense of participation and inclusion. A market could be created if the government permits transfer of vouchers among voucher holders.

Some privatization transactions can be interpreted as a form of a secured loan and are criticized as a "particularly noxious form of governmental debt". In this interpretation, the upfront payment from the privatization sale corresponds to the principal amount of the loan, while the proceeds from the underlying asset correspond to secured interest payments – the transaction can be considered substantively the same as a secured loan, though it is structured as a sale. This interpretation is particularly argued to apply to recent municipal transactions in the United States, particularly for fixed term, such as the 2008 sale of the proceeds from Chicago parking meters for 75 years. It is argued that this is motivated by "politicians' desires to borrow money surreptitiously", due to legal restrictions on and political resistance to alternative sources of revenue, viz, raising taxes or issuing debt.

Literature reviews find that in competitive industries with well-informed consumers, privatization consistently improves efficiency. The more competitive the industry, the greater the improvement in output, profitability, and efficiency. Such efficiency gains mean a one-off increase in GDP, but through improved incentives to innovate and reduce costs also tend to raise the rate of economic growth. Although typically there are many costs associated with these efficiency gains,
many economists argue that these can be dealt with by appropriate government support through redistribution and perhaps retraining. Yet, some empirical literature suggests that privatization could also have very modest effects on efficiency and quite regressive distributive impact. In the first attempt at a social welfare analysis of the British privatization program under the Conservative governments of Margaret Thatcher and John Major during the 1980s and 1990s, Massimo Florio points to the absence of any productivity shock resulting strictly from ownership change. Instead, the impact on the previously nationalized companies of the UK productivity leap under the Conservatives varied in different industries. In some cases, it occurred prior to privatization, and in other cases, it occurred upon privatization or several years afterward.

A study by the European Commission found that the UK rail network (which was privatized from 1994–97) was most improved out of all the 27 EU nations from 1997–2012. The report examined a range of 14 different factors and the UK came top in four of the factors, second and third in another two and fourth in three, coming top overall.

Privatizations in Russia and Latin America were accompanied by large-scale corruption during the sale of the state-owned companies. Those with political connections unfairly gained large wealth, which has discredited privatization in these regions. While media have widely reported the grand corruption that accompanied those sales, studies have argued that in addition to increased operating efficiency, daily petty corruption is, or would be, larger without privatization, and that corruption is more prevalent in non-privatized sectors. Furthermore, there is evidence to suggest that extralegal and unofficial activities are more prevalent in countries that privatized less.

A 2009 study published in "The Lancet" medical journal initially claimed to have found that as many as a million working men died as a result of economic shocks associated with mass privatization in the former Soviet Union and in Eastern Europe during the 1990s, although a further study revealed that there were errors in their method and "correlations reported in the original article are simply not robust." Historian Walter Scheidel, a specialist in ancient history, posits that economic inequality and wealth concentration in the top percentile "had been made possible by the transfer of state assets to private owners."

In Latin America, there is a discrepancy between the economic efficiency of privatization and the political/social ramifications that occur. On the one hand, economic indicators, including firm profitability, productivity, and growth, project positive microeconomic results. On the other hand, however, these results have largely been met with a negative criticism and citizen coalitions. This neoliberal criticism highlights the ongoing conflict between varying visions of economic development. Karl Polanyi emphasizes the societal concerns of self-regulating markets through a concept known as a "double movement". In essence, whenever societies move towards increasingly unrestrained, free-market rule, a natural and inevitable societal correction emerges to undermine the contradictions of capitalism. This was the case in the 2000 Cochabamba protests.

Privatization in Latin America has invariably experienced increasing push-back from the public. Some suggest that implementing a less efficient but more politically mindful approach could be more sustainable.

In India, a survey by the National Commission for Protection of Child Rights (NCPCR) —Utilization of Free Medical Services by Children Belonging to the Economically Weaker Section (EWS) in Private Hospitals in New Delhi, 2011-12: A Rapid Appraisal—indicates under-utilization of the free beds available for EWS category in private hospitals in Delhi, though they were allotted land at subsidized rates.

Arguments for and against the controversial subject of privatization are presented here.

Studies show that private market factors can more efficiently deliver many goods or service than governments due to free market competition. Over time this tends to lead to lower prices, improved quality, more choices, less corruption, less red tape, and/or quicker delivery. Many proponents do not argue that everything should be privatized. According to them, market failures and natural monopolies could be problematic. However, anarcho-capitalists prefer that every function of the state be privatized, including defense and dispute resolution.

Proponents of privatization make the following arguments:

Opponents of certain privatizations believe that certain public goods and services should remain primarily in the hands of government in order to ensure that everyone in society has access to them (such as law enforcement, basic health care, and basic education). There is a positive externality when the government provides society at large with public goods and services such as defense and disease control. Some national constitutions in effect define their governments' "core businesses" as being the provision of such things as justice, tranquility, defense, and general welfare. These governments' direct provision of security, stability, and safety, is intended to be done for the common good (in the public interest) with a long-term (for posterity) perspective. As for natural monopolies, opponents of privatization claim that they aren't subject to fair competition, and better administrated by the state.

Although private companies will provide a similar good or service alongside the government, opponents of privatization are careful about completely transferring the provision of public goods, services and assets into private hands for the following reasons:

In economic theory, privatization has been studied in the field of contract theory. When contracts are complete, institutions such as (private or public) property are difficult to explain, since every desired incentive structure can be achieved with sufficiently complex contractual arrangements, regardless of the institutional structure (all that matters is who are the decision makers and what is their available information). In contrast, when contracts are incomplete, institutions matter. A leading application of the incomplete contract paradigm in the context of privatization is the model by Hart, Shleifer, and Vishny (1997). In their model, a manager can make investments to increase quality (but they may also increase costs) and investments to decrease costs (but they may also reduce quality). It turns out that it depends on the particular situation whether private ownership or public ownership is desirable. The Hart-Shleifer-Vishny model has been further developed in various directions, e.g. to allow for mixed public-private ownership and endogenous assignments of the investment tasks.






</doc>
<doc id="24663" url="https://en.wikipedia.org/wiki?curid=24663" title="Passage grave">
Passage grave

A passage grave (sometimes hyphenated) or passage tomb consists of a narrow passage made of large stones and one or multiple burial chambers covered in earth or stone. The building of passage tombs was normally carried out with megaliths and smaller stones; they usually date from the Neolithic Age. Those with more than one chamber may have multiple sub-chambers leading off from the main burial chamber. One common layout, the cruciform passage grave, is cross-shaped. Sometimes passage tombs are covered with a cairn, especially those dating from later times. Not all passage graves have been found to contain evidence of human remains. One such example is Maeshowe. The Passage Tomb tradition is believed to have originated in the French region of Brittany. It was introduced to other regions such as Ireland by colonists from Brittany.

Passage tombs of the cairn type often have elaborate corbelled roofs rather than simple slabs. Megalithic art has been identified carved into the stones at some sites. The passage itself, in a number of notable instances, is aligned in such a way that the sun shines into the passage at a significant point in the year, for example at sunrise on the winter solstice or at sunset on the equinox.

In a 1961 survey of megalithic tombs in Ireland, Irish scholars Seán Ó Nualláin and Rúaidhrí de Valera describe four categories of megalithic tombs: court cairns, portal dolmens, wedge-shaped gallery graves, and passage tombs. This appears to be one of the first uses of the term passage tomb. It is likely that the writers borrowed from the Spanish term "tumbas de corredor", which is used for tombs in Cantabria, Galicia and the Basque Country. Of their list, only passage tombs appear to have widespread distribution throughout Europe.

Passage graves are distributed extensively in lands along the Atlantic seaboard of Europe. They are found in Ireland, Britain, Scandinavia, northern Germany and the Drenthe area of the Netherlands. They are also found in Iberia, some parts of the Mediterranean, and along the northern coast of Africa. The earliest passage tombs seem to take the form of small dolmens. In Ireland and Britain, passage tombs are often found in large clusters, giving rise to the term passage tomb cemeteries. Many later passage tombs were constructed at the tops of hills or mountains, indicating that their builders intended them to be seen from a great distance.



</doc>
<doc id="24664" url="https://en.wikipedia.org/wiki?curid=24664" title="P-group">
P-group

In mathematical group theory, given a prime number "p", a "p"-group is a group in which each element has a power of "p" as its order. That is, for each element "g" of a "p"-group, there exists a nonnegative integer "n" such that the product of "p" copies of "g", and not fewer, is equal to the identity element. The orders of different elements may be different powers of "p".

Abelian "p"-groups are also called "p"-primary or simply primary.

A finite group is a "p"-group if and only if its order (the number of its elements) is a power of "p". Given a finite group "G", the Sylow theorems guarantee for every prime power "p" that divides the order of "G" the existence of a subgroup of "G" of order "p".

The remainder of this article deals with finite "p"-groups. For an example of an infinite abelian "p"-group, see Prüfer group, and for an example of an infinite simple "p"-group, see Tarski monster group.

Every "p"-group is periodic since by definition every element has finite order.

If "p" is prime and "G" is a group of order "p", then "G" has a normal subgroup of order "p" for every 1≤"m"≤"k". This follows by induction, using Cauchy's theorem and the Correspondence Theorem for groups. A proof sketch is as follows: by Cauchy's Theorem, "G" has a subgroup "H" of order "p". If the normalizer of "H" in "G" is "G" itself, then we may apply the inductive hypothesis to "G/H", and the result follows from the Correspondence Theorem. Otherwise, we apply the same logic to "G/N(H)", where "N(H)" is the normalizer of "H" in "G".

One of the first standard results using the class equation is that the center of a non-trivial finite "p"-group cannot be the trivial subgroup.

This forms the basis for many inductive methods in "p"-groups.

For instance, the normalizer "N" of a proper subgroup "H" of a finite "p"-group "G" properly contains "H", because for any counterexample with "H"="N", the center "Z" is contained in "N", and so also in "H", but then there is a smaller example "H"/"Z" whose normalizer in "G"/"Z" is "N"/"Z"="H"/"Z", creating an infinite descent. As a corollary, every finite "p"-group is nilpotent.

In another direction, every normal subgroup of a finite "p"-group intersects the center nontrivially as may be proved by considering the elements of "N" which are fixed when "G" acts on "N" by conjugation. Since every central subgroup is normal, it follows that every minimal normal subgroup of a finite "p"-group is central and has order "p". Indeed, the socle of a finite "p"-group is the subgroup of the center consisting of the central elements of order "p".

If "G" is a "p"-group, then so is "G"/"Z", and so it too has a nontrivial center. The preimage in "G" of the center of "G"/"Z" is called the second center and these groups begin the upper central series. Generalizing the earlier comments about the socle, a finite "p"-group with order "p" contains normal subgroups of order "p" with 0 ≤ "i" ≤ "n", and any normal subgroup of order "p" is contained in the "i"th center "Z". If a normal subgroup is not contained in "Z", then its intersection with "Z" has size at least "p".

The automorphism groups of "p"-groups are well studied. Just as every finite "p"-group has a nontrivial center so that the inner automorphism group is a proper quotient of the group, every finite "p"-group has a nontrivial outer automorphism group. Every automorphism of "G" induces an automorphism on "G"/Φ("G"), where Φ("G") is the Frattini subgroup of "G". The quotient G/Φ("G") is an elementary abelian group and its automorphism group is a general linear group, so very well understood. The map from the automorphism group of "G" into this general linear group has been studied by Burnside, who showed that the kernel of this map is a "p"-group. 

"p"-groups of the same order are not necessarily isomorphic; for example, the cyclic group "C" and the Klein four-group "V" are both 2-groups of order 4, but they are not isomorphic.

Nor need a "p"-group be abelian; the dihedral group Dih of order 8 is a non-abelian 2-group. However, every group of order "p" is abelian.

The dihedral groups are both very similar to and very dissimilar from the quaternion groups and the semidihedral groups. Together the dihedral, semidihedral, and quaternion groups form the 2-groups of maximal class, that is those groups of order 2 and nilpotency class "n".

The iterated wreath products of cyclic groups of order "p" are very important examples of "p"-groups. Denote the cyclic group of order "p" as "W"(1), and the wreath product of "W"("n") with "W"(1) as "W"("n" + 1). Then "W"("n") is the Sylow "p"-subgroup of the symmetric group Sym("p"). Maximal "p"-subgroups of the general linear group GL("n",Q) are direct products of various "W"("n"). It has order "p" where "k" = ("p" − 1)/("p" − 1). It has nilpotency class "p", and its lower central series, upper central series, lower exponent-"p" central series, and upper exponent-"p" central series are equal. It is generated by its elements of order "p", but its exponent is "p". The second such group, "W"(2), is also a "p"-group of maximal class, since it has order "p" and nilpotency class "p", but is not a regular "p"-group. Since groups of order "p" are always regular groups, it is also a minimal such example.

When "p" = 2 and "n" = 2, "W"("n") is the dihedral group of order 8, so in some sense "W"("n") provides an analogue for the dihedral group for all primes "p" when "n" = 2. However, for higher "n" the analogy becomes strained. There is a different family of examples that more closely mimics the dihedral groups of order 2, but that requires a bit more setup. Let ζ denote a primitive "p"th root of unity in the complex numbers, let Z[ζ] be the ring of cyclotomic integers generated by it, and let "P" be the prime ideal generated by 1−ζ. Let "G" be a cyclic group of order "p" generated by an element "z". Form the semidirect product "E"("p") of Z[ζ] and "G" where "z" acts as multiplication by ζ. The powers "P" are normal subgroups of "E"("p"), and the example groups are "E"("p","n") = "E"("p")/"P". "E"("p","n") has order "p" and nilpotency class "n", so is a "p"-group of maximal class. When "p" = 2, "E"(2,"n") is the dihedral group of order 2. When "p" is odd, both "W"(2) and "E"("p","p") are irregular groups of maximal class and order "p", but are not isomorphic.

The Sylow subgroups of general linear groups are another fundamental family of examples. Let "V" be a vector space of dimension "n" with basis { "e", "e", …, "e" } and define "V" to be the vector space generated by { "e", "e", …, "e" } for 1 ≤ "i" ≤ "n", and define "V" = 0 when "i" > "n". For each 1 ≤ "m" ≤ "n", the set of invertible linear transformations of "V" which take each "V" to "V" form a subgroup of Aut("V") denoted "U". If "V" is a vector space over Z/"p"Z, then "U" is a Sylow "p"-subgroup of Aut("V") = GL("n", "p"), and the terms of its lower central series are just the "U". In terms of matrices, "U" are those upper triangular matrices with 1s one the diagonal and 0s on the first "m"−1 superdiagonals. The group "U" has order "p", nilpotency class "n", and exponent "p" where "k" is the least integer at least as large as the base "p" logarithm of "n".

The groups of order "p" for 0 ≤ "n" ≤ 4 were classified early in the history of group theory, and modern work has extended these classifications to groups whose order divides "p", though the sheer number of families of such groups grows so quickly that further classifications along these lines are judged difficult for the human mind to comprehend. For example, Marshall Hall Jr. and James K. Senior classified groups of order 2 for "n" ≤ 6 in 1964.

Rather than classify the groups by order, Philip Hall proposed using a notion of isoclinism of groups which gathered finite "p"-groups into families based on large quotient and subgroups.

An entirely different method classifies finite "p"-groups by their coclass, that is, the difference between their composition length and their nilpotency class. The so-called coclass conjectures described the set of all finite "p"-groups of fixed coclass as perturbations of finitely many pro-p groups. The coclass conjectures were proven in the 1980s using techniques related to Lie algebras and powerful p-groups. The final proofs of the coclass theorems are due to A. Shalev and independently to C. R. Leedham-Green, both in 1994. They admit a classification of finite "p"-groups in directed coclass graphs consisting of only finitely many coclass trees whose (infinitely many) members are characterized by finitely many parametrized presentations.

Every group of order "p" is metabelian.

The trivial group is the only group of order one, and the cyclic group "C" is the only group of order "p". There are exactly two groups of order "p", both abelian, namely "C" and "C" × "C". For example, the cyclic group "C" and the Klein four-group "V" which is "C" × "C" are both 2-groups of order 4.

There are three abelian groups of order "p", namely "C", "C"×"C", and "C"×"C"×"C". There are also two non-abelian groups.

For "p" ≠ 2, one is a semi-direct product of "C"×"C" with "C", and the other is a semi-direct product of "C" with "C". The first one can be described in other terms as group UT(3,"p") of unitriangular matrices over finite field with "p" elements, also called the Heisenberg group mod "p".

For "p" = 2, both the semi-direct products mentioned above are isomorphic to the dihedral group Dih of order 8. The other non-abelian group of order 8 is the quaternion group "Q".

The number of isomorphism classes of groups of order "p" grows as formula_1, and these are dominated by the classes that are two-step nilpotent. Because of this rapid growth, there is a folklore conjecture asserting that almost all finite groups are 2-groups: the fraction of isomorphism classes of 2-groups among isomorphism classes of groups of order at most "n" is thought to tend to 1 as "n" tends to infinity. For instance, of the 49 910 529 484 different groups of order at most 2000, 49 487 365 422, or just over 99%, are 2-groups of order 1024.

Every finite group whose order is divisible by "p" contains a subgroup which is a non-trivial "p"-group, namely a cyclic group of order "p" generated by an element of order "p" obtained from Cauchy's theorem. In fact, it contains a "p"-group of maximal possible order: if formula_2 where "p" does not divide "m," then "G" has a subgroup "P" of order formula_3 called a Sylow "p"-subgroup. This subgroup need not be unique, but any subgroups of this order are conjugate, and any "p"-subgroup of "G" is contained in a Sylow "p"-subgroup. This and other properties are proved in the Sylow theorems.

"p"-groups are fundamental tools in understanding the structure of groups and in the classification of finite simple groups. "p"-groups arise both as subgroups and as quotient groups. As subgroups, for a given prime "p" one has the Sylow "p"-subgroups "P" (largest "p"-subgroup not unique but all conjugate) and the "p"-core formula_4 (the unique largest "normal" "p"-subgroup), and various others. As quotients, the largest "p"-group quotient is the quotient of "G" by the "p"-residual subgroup formula_5 These groups are related (for different primes), possess important properties such as the focal subgroup theorem, and allow one to determine many aspects of the structure of the group.

Much of the structure of a finite group is carried in the structure of its so-called local subgroups, the normalizers of non-identity "p"-subgroups.

The large elementary abelian subgroups of a finite group exert control over the group that was used in the proof of the Feit–Thompson theorem. Certain central extensions of elementary abelian groups called extraspecial groups help describe the structure of groups as acting on symplectic vector spaces.

Brauer classified all groups whose Sylow 2-subgroups are the direct product of two cyclic groups of order 4, and Walter, Gorenstein, Bender, Suzuki, Glauberman, and others classified those simple groups whose Sylow 2-subgroups were abelian, dihedral, semidihedral, or quaternion.





</doc>
<doc id="24666" url="https://en.wikipedia.org/wiki?curid=24666" title="Pope Innocent XII">
Pope Innocent XII

Pope Innocent XII (; 13 March 1615 – 27 September 1700), born Antonio Pignatelli, was Pope from 12 July 1691 to his death in 1700.

He took a hard stance against nepotism in the church, continuing the policies of Pope Innocent XI, who started the battle against nepotism. To that end, he issued a papal bull strictly forbidding it.

Antonio Pignatelli was born on 13 March 1615 in Spinazzola (now in Apulia) to one of the most aristocratic families of the Kingdom of Naples, which had included several Viceroys and ministers of the crown. He was the fourth of five children of Francesco Pignatelli and Porzia Carafa. His siblings were Marzio, Ludovico, Fabrizio and Paola Maria.

He was educated at the Collegio Romano in Rome where he earned a doctorate in both canon and civil law.

At the age of 20 he became an official of the court of Pope Urban VIII. Pignatelli was the Referendary of the Apostolic Signatura and served as the Governor of Fano and Viterbo. Later he went to Malta where he served as an inquisitor from 1646 to 1649. Shortly after this, he received his priestly ordination.

Pignatelli was made Titular Archbishop of Larissa in 1652 and received episcopal consecration in Rome. Pignatelli served as the Apostolic Nuncio to Poland from 1660 to 1668 and later in Austria from 1668 to 1671. He was transferred to Lecce in 1671. Pope Innocent XI appointed him as the Cardinal-Priest of San Pancrazio in 1681 and then moved him to the see of Faenza in 1682. He was moved to his final post as Archbishop of Naples in 1686.

Pope Alexander VIII died in 1691 and the College of Cardinals assembled to hold a conclave to select his successor. Factions loyal to the Kingdom of France, Kingdom of Spain and the broader Holy Roman Empire failed to agree on a consensus candidate.

After five months, Cardinal Pignatelli emerged as a compromise candidate between the cardinals of France and those of the Holy Roman Empire. Pignatelli took his new name in honour of Pope Innocent XI and was crowned on 15 July 1691 by the protodeacon, Cardinal Urbano Sacchetti. He took possession of the Basilica of Saint John Lateran on 13 April 1692.

Immediately after his election on 12 July 1691, Innocent XII declared his opposition to the nepotism which had afflicted the reigns of previous popes. The following year he issued the papal bull, "Romanum decet Pontificem", banning the curial office of the Cardinal-Nephew and prohibiting popes from bestowing estates, offices, or revenues on any relative. Further, only one relative (and only "if otherwise suitable") was to be raised to the cardinalate.

At the same time he sought to check the simony in the practices of the Apostolic Chamber and to that end introduced a simpler and more economical manner of life into his court. Innocent XII said that "the poor were his nephews" and compared his public beneficence to the nepotism of many predecessors.

Innocent XII also introduced various reforms into the States of the Church including the "Forum Innocentianum", designed to improve the administration of justice dispensed by the Church. In 1693 he compelled French bishops to retract the four propositions relating to the Gallican Liberties which had been formulated by the assembly of 1682.

In 1699, he decided in favour of Jacques-Benigne Bossuet in that prelate's controversy with Fénelon about the "Explication des Maximes des Saints sur la Vie Intérieure" of the latter. Innocent XII's pontificate also differed greatly from his predecessors' because of his leanings towards France instead of the Habsburg Monarchy; the first in the 20 years following France's failure to have its candidate elected in 1644 and 1655.

Innocent XII created 30 cardinals in four consistories.

He canonized Saint Zita of Lucca on 5 September 1696. Innocent XII beatified Augustin Kažotić on 17 July 1700 and approved the cultus of Angela of Foligno in 1693. He also beatified Osanna Andreasi on 24 November 1694, Mary de Cerevellon on 13 February 1692, Jane of Portugal on 31 December 1692, Humiliana de Cerchi on 24 July 1694, Helen Enselmini on 29 October 1695 and Delphine in 1694.

Innocent XII died on 27 September 1700 and was succeeded by Pope Clement XI (1700–1721). His tomb at St. Peter's Basilica was sculpted by Filippo della Valle.

Innocent XII appears as one of the narrators in Robert Browning's long poem "The Ring and the Book" (1869), based on the true story of the pope's intervention in a historical murder trial in Rome during his papacy.

Innocent is notable for being the last pope to have facial hair to date.



</doc>
<doc id="24667" url="https://en.wikipedia.org/wiki?curid=24667" title="Protein phosphatase">
Protein phosphatase

A protein phosphatase is a phosphatase enzyme that removes a phosphate group from the phosphorylated amino acid residue of its substrate protein. Protein phosphorylation is one of the most common forms of reversible protein posttranslational modification (PTM), with up to 30% of all proteins being phosphorylated at any given time. Protein kinases (PKs) are the effectors of phosphorylation and catalyse the transfer of a γ-phosphate from ATP to specific amino acids on proteins. Several hundred PKs exist in mammals and are classified into distinct super-families. Proteins are phosphorylated predominantly on Ser, Thr and Tyr residues, which account for 79.3, 16.9 and 3.8% respectively of the phosphoproteome, at least in mammals. In contrast, protein phosphatases (PPs) are the primary effectors of dephosphorylation and can be grouped into three main classes based on sequence, structure and catalytic function. The largest class of PPs is the phosphoprotein phosphatase (PPP) family comprising PP1, PP2A, PP2B, PP4, PP5, PP6 and PP7, and the protein phosphatase Mg- or Mn-dependent (PPM) family, composed primarily of PP2C. The protein Tyr phosphatase (PTP) super-family forms the second group, and the aspartate-based protein phosphatases the third. The protein pseudophosphatases form part of the larger phosphatase family, and in most cases are thought to be catalytically inert, instead functioning as phosphate-binding proteins, integrators of signalling or subcellular traps. Examples of membrane-spanning protein phosphatases containing both active (phosphatase) and inactive (pseudophosphatase) domains linked in tandem are known, conceptually similar to the kinase and pseudokinase domain polypeptide structure of the JAK pseudokinases. A complete comparative analysis of human phosphatases and pseudophosphatases has been completed by Manning and colleagues, forming a companion piece to the ground-breaking analysis of the human kinome, which encodes the complete set of ~536 human protein kinases.

Phosphorylation involves the transfer of phosphate groups from ATP to the enzyme, the energy for which comes from hydrolysing ATP into ADP or AMP. However, dephosphorylation releases phosphates into solution as free ions, because attaching them back to ATP would require energy input.

Cysteine-dependent phosphatases (CDPs) catalyse the hydrolysis of a phosphoester bond via a phospho-cysteine intermediate.

The free cysteine nucleophile forms a bond with the phosphorus atom of the phosphate moiety, and the P-O bond linking the phosphate group to the tyrosine is protonated, either by a suitably positioned acidic amino acid residue (Asp in the diagram below) or a water molecule. The phospho-cysteine intermediate is then hydrolysed by another water molecule, thus regenerating the active site for another dephosphorylation reaction.

Metallo-phosphatases (e.g. PP2C) co-ordinate 2 catalytically essential metal ions within their active site. There is currently some confusion of the identity of these metal ions, as successive attempts to identify them yield different answers. There is currently evidence that these metals could be Magnesium, Manganese, Iron, Zinc, or any combination thereof. It is thought that a hydroxyl ion bridging the two metal ions takes part in nucleophilic attack on the phosphorus ion.

Phosphatases can be subdivided based upon their substrate specificity. 

Protein Ser/Thr phosphatases were originally classified using biochemical assays as either, type 1 (PP1) or type 2 (PP2), and were further subdivided based on metal-ion requirement (PP2A, no metal ion; PP2B, Ca stimulated; PP2C, Mg dependent) (Moorhead et al., 2007). The protein Ser/Thr phosphatases PP1, PP2A and PP2B of the PPP family, together with PP2C of the PPM family, account for the majority of Ser/Thr PP activity in vivo (Barford et al., 1998). In the brain, they are present in different subcellular compartments in neuronal and glial cells, and contribute to different neuronal functions.

The PPM family, which includes PP2C and pyruvate dehydrogenase phosphatase, are enzymes with Mn/Mg metal ions that are resistant to classic inhibitors and toxins of the PPP family. Unlike most PPPs, PP2C exists in only one subunit but, like PTPs, it displays a wide variety of structural domains that confer unique functions. In addition, PP2C does not seem to be evolutionarily related to the major family of Ser/Thr PPs and has no sequence homology to ancient PPP enzymes. The current assumption is that PPMs evolved separately from PPPs but converged during evolutionary development.

Class I PTPs constitute the largest family. They contain the well-known classical receptor (a) and non-receptor PTPs (b), which are strictly tyrosine-specific, and the DSPs (c) which target Ser/Thr as well as Tyr and are the most diverse in terms of substrate specificity.

The third class of PTPs contains three cell cycle regulators, CDC25A, CDC25B and CDC25C, which dephosphorylate CDKs at their N-terminal, a reaction required to drive progression of the cell cycle. They are themselves regulated by phosphorylation and are degraded in response to DNA damage to prevent chromosomal abnormalities.

The haloacid dehalogenase (HAD) superfamily is a further PP group that uses Asp as a nucleophile and was recently shown to have dual-specificity. These PPs can target both Ser and Tyr, but are thought to have greater specificity towards Tyr. A subfamily of HADs, the Eyes Absent Family (Eya), are also transcription factors and can therefore regulate their own phosphorylation and that of transcriptional cofactor/s, and contribute to the control of gene transcription. The combination of these two functions in Eya reveals a greater complexity of transcriptional gene control than previously thought . A further member of this class is the RNA polymerase II C-terminal domain phosphatase. While this family remains poorly understood, it is known to play important roles in development and nuclear morphology.

Many phosphatases are promiscuous with respect to substrate type, or can evolve quickly to change substrate. An alternative structural classification notes that 20 distinct protein folds have phosphatase activity, and 10 of these contain protein phosphatases.

Phosphatases act in opposition to kinases/phosphorylases, which add phosphate groups to proteins. The addition of a phosphate group may activate or de-activate an enzyme (e.g., kinase signalling pathways) or enable a protein-protein interaction to occur (e.g., SH2 domains ); therefore phosphatases are integral to many signal transduction pathways. Phosphate addition and removal do not necessarily correspond to enzyme activation or inhibition, and that several enzymes have separate phosphorylation sites for activating or inhibiting functional regulation. CDK, for example, can be either activated or deactivated depending on the specific amino acid residue being phosphorylated. Phosphates are important in signal transduction because they regulate the proteins to which they are attached. To reverse the regulatory effect, the phosphate is removed. This occurs on its own by hydrolysis, or is mediated by protein phosphatases.

Protein phosphorylation plays a crucial role in biological functions and controls nearly every cellular process, including metabolism, gene transcription and translation, cell-cycle progression, cytoskeletal rearrangement, protein-protein interactions, protein stability, cell movement, and apoptosis. These processes depend on the highly regulated and opposing actions of PKs and PPs, through changes in the phosphorylation of key proteins. Histone phosphorylation, along with methylation, ubiquitination, sumoylation and acetylation, also regulates access to DNA through chromatin reorganisation.

One of the major switches for neuronal activity is the activation of PKs and PPs by elevated intracellular calcium. The degree of activation of the various isoforms of PKs and PPs is controlled by their individual sensitivities to calcium. Furthermore, a wide range of specific inhibitors and targeting partners such as scaffolding, anchoring, and adaptor proteins also contribute to the control of PKs and PPs and recruit them into signalling complexes in neuronal cells. Such signalling complexes typically act to bring PKs and PPs in close proximity with target substrates and signalling molecules as well as enhance their selectivity by restricting accessibility to these substrate proteins. Phosphorylation events, therefore, are controlled not only by the balanced activity of PKs and PPs but also by their restricted localisation. Regulatory subunits and domains serve to restrict specific proteins to particular subcellular compartments and to modulate protein specificity. These regulators are essential for maintaining the coordinated action of signalling cascades, which in neuronal cells include short-term (synaptic) and long-term (nuclear) signalling. These functions are, in part, controlled by allosteric modification by secondary messengers and reversible protein phosphorylation.

It is thought that around 30% of known PPs are present in all tissues, with the rest showing some level of tissue restriction. While protein phosphorylation is a cell-wide regulatory mechanism, recent quantitative proteomics studies have shown that phosphorylation preferentially targets nuclear proteins. Many PPs that regulate nuclear events, are often enriched or exclusively present in the nucleus. In neuronal cells, PPs are present in multiple cellular compartments and play a critical role at both pre- and post-synapses, in the cytoplasm and in the nucleus where they regulate gene expression.

Phosphoprotein phosphatase is activated by the hormone insulin, which indicates that there is a high concentration of glucose in the blood. The enzyme then acts to dephosphorylate other enzymes, such as phosphorylase kinase, glycogen phosphorylase, and glycogen synthase. This leads to phosphorylase kinase and glycogen phosphorylase's becoming inactive, while glycogen synthase is activated. As a result, glycogen synthesis is increased and glycogenolysis is decreased, and the net effect is for energy to enter and be stored inside the cell.

In the adult brain, PPs are essential for synaptic functions and are involved in the negative regulation of higher-order brain functions such as learning and memory. Dysregulation of their activity has been linked to several disorders including cognitive ageing and neurodegeneration, as well as cancer, diabetes and obesity.

Human genes that encode proteins with phosphoprotein phosphatase activity include:






</doc>
<doc id="24668" url="https://en.wikipedia.org/wiki?curid=24668" title="P5 (microarchitecture)">
P5 (microarchitecture)

The first Pentium microprocessor was introduced by Intel on March 22, 1993. Dubbed P5, its microarchitecture was the fifth generation for Intel, and the first superscalar IA-32 microarchitecture. As a direct extension of the 80486 architecture, it included dual integer pipelines, a faster floating-point unit, wider data bus, separate code and data caches and features for further reduced address calculation latency. In 1996, the "Pentium with MMX Technology" (often simply referred to as "Pentium MMX") was introduced with the same basic microarchitecture complemented with an MMX instruction set, larger caches, and some other enhancements.

The P5 Pentium competitors included the Motorola 68060 and the PowerPC 601 as well as the SPARC, MIPS, and Alpha microprocessor families, most of which also used a superscalar in-order dual instruction pipeline configuration at some time.

Intel's Larrabee multicore architecture project uses a processor core derived from a P5 core (P54C), augmented by multithreading, 64-bit instructions, and a 16-wide vector processing unit. Intel's low-powered Bonnell microarchitecture employed in early Atom processor cores also uses an in-order dual pipeline similar to P5.

The P5 microarchitecture was designed by the same Santa Clara team which designed the 386 and 486. Design work started in 1989; the team decided to use a superscalar architecture, with on-chip cache, floating-point, and branch prediction. The preliminary design was first successfully simulated in 1990, followed by the laying-out of the design. By this time, the team had several dozen engineers. The design was taped out, or transferred to silicon, in April 1992, at which point beta-testing began. By mid-1992, the P5 team had 200 engineers. Intel at first planned to demonstrate the P5 in June 1992 at the trade show PC Expo, and to formally announce the processor in September 1992, but design problems forced the demo to be cancelled, and the official introduction of the chip was delayed until the spring of 1993.

John H. Crawford, chief architect of the original 386, co-managed the design of the P5, along with Donald Alpert, who managed the architectural team. Dror Avnon managed the design of the FPU. Vinod K. Dham was general manager of the P5 group.

The P5 microarchitecture brings several important advancements over the preceding i486 architecture.


The Pentium was designed to execute over 100 million instructions per second (MIPS), and the 75 MHz model was able to reach 126.5 MIPS in certain benchmarks. The Pentium architecture typically offered just under twice the performance of a 486 processor per clock cycle in common benchmarks. The fastest 80486 parts (with slightly improved microarchitecture and 100 MHz operation) were almost as powerful as the first-generation Pentiums, and the AMD Am5x86 was roughly equal to the Pentium 75 regarding pure ALU performance.

The early versions of 60–100 MHz P5 Pentiums had a problem in the floating point unit that resulted in incorrect (but predictable) results from some division operations. This bug, discovered in 1994 by professor Thomas Nicely at Lynchburg College, Virginia, became known as the Pentium FDIV bug and caused embarrassment for Intel, which created an exchange program to replace the faulty processors. Soon afterwards, a bug was discovered which could allow a malicious program to crash a system without any special privileges (the "F00F bug"); fortunately, operating systems were able to implement workarounds to prevent crashes.

The 60 and 66 MHz 0.8 µm versions of the P5 Pentium processors also had (for the time) high heat production due to their 5 V operation. The P54C used 3.3 V and had significantly lower power draw by about 51% (a quadratic relationship). P5 Pentiums used Socket 4, while P54C started out on Socket 5 before moving to Socket 7 in later revisions. All desktop Pentiums from P54CS onwards used Socket 7.

The Pentium was Intel's primary microprocessor for personal computers during the mid-1990s. The original design was reimplemented in newer processes and new features were added to maintain its competitiveness as well as to address specific markets such as portable computers. As a result, there were several variants of the P5 microarchitecture.

The first Pentium microprocessor core was code-named "P5". Its product code was 80501 (80500 for the earliest steppings Q0399). There were two versions, specified to operate at 60 MHz and 66 MHz respectively. This first implementation of the Pentium used a traditional 5 Volt power supply (descended from the usual TTL logic compatibility requirements). It contained 3.1 million transistors and measured 16.7 mm by 17.6 mm for an area of 293.92 mm. It was fabricated in a 0.8 µm BiCMOS process. The five-volt design resulted in relatively high energy consumption for its operating frequency, when compared to the later models.

The P5 was followed by the P54C (80502), also known as Pentium-S; there were versions specified to operate at 75, 90, or 100 MHz using a 3.3 volt power supply. This was the first Pentium processor to operate at 3.3 volts, reducing energy consumption. It employed an internal clock multiplier to let the internal circuitry work at a higher frequency than the external address and data buses, as it is more complicated and cumbersome to increase the external frequency, due to physical constraints. It also allowed two-way multiprocessing and had an integrated local APIC as well as new power management features. It contained 3.3 million transistors and measured 163 mm. It was fabricated in a BiCMOS process which has been described as both 0.5 µm and 0.6 µm due to differing definitions.

The P54C was followed by the P54CQS which operated at 120 MHz. It was fabricated in a 0.35 µm BiCMOS process and was the first commercial microprocessor to be fabricated in a 0.35 µm process. Its transistor count is identical to the P54C and, despite the newer process, it had an identical die area as well. The chip was connected to the package using wire bonding, which only allows connections along the edges of the chip. A smaller chip would have required a redesign of the package, as there is a limit on the length of the wires and the edges of the chip would be further away from the pads on the package. The solution was to keep the chip the same size, retain the existing pad-ring, and only reduce the size of the Pentium's logic circuitry to enable it to achieve higher clock frequencies.

The P54CQS was followed by the P54CS, which operated at 133, 150, 166 and 200 MHz. It contained 3.3 million transistors, measured 90 mm and was fabricated in a 0.35 µm BiCMOS process with four levels of interconnect.

The P24T Pentium OverDrive for 486 systems were released in 1995, which were based on 3.3 V 0.6 µm versions using a 63 or 83 MHz clock. Since these used Socket 2/3, some modifications had to be made to compensate for the 32-bit data bus and slower on-board L2 cache of 486 motherboards. They were therefore equipped with a 32 KB L1 cache (double that of pre-P55C Pentium CPUs).

The P55C (or 80503) was developed by Intel's Research & Development Center in Haifa, Israel. It was sold as Pentium with MMX Technology (usually just called Pentium MMX); although it was based on the P5 core, it featured a new set of 57 "MMX" instructions intended to improve performance on multimedia tasks, such as encoding and decoding digital media data. The Pentium MMX line was introduced on 22 October 1996.

The new instructions worked on new data types: 64-bit packed vectors of either eight 8-bit integers, four 16-bit integers, two 32-bit integers, or one 64-bit integer. So, for example, the PADDUSB (Packed ADD Unsigned Saturated Byte) instruction adds two vectors, each containing eight 8-bit unsigned integers together, pairwise; each addition that would overflow "saturates", yielding 255, the maximum unsigned value that can be represented in a byte. These rather specialized instructions generally require special coding by the programmer for them to be used.

Other changes to the core include a 6-stage pipeline (vs. 5 on P5) with a return stack (first done on Cyrix 6x86) and better parallelism, an improved instruction decoder, 32 KB L1 cache with 4-way associativity (vs. 16 KB with 2-way on P5), 4 write buffers that could now be used by either pipeline (vs. one corresponding to each pipeline on P5) and an improved branch predictor taken from the Pentium Pro, with a 512 entry buffer (vs. 256 on P5).

It contained 4.5 million transistors and had an area of 140 mm. It was fabricated in a 0.28 µm CMOS process with the same metal pitches as the previous 0.35 µm BiCMOS process, so Intel described it as "0.35 µm" because of its similar transistor density. The process has four levels of interconnect.

While the P55C is compatible with the common Socket 7 motherboard configuration, the voltage requirements for powering the chip differ from the standard Socket 7 specifications. Most motherboards manufactured for Socket 7 prior to the establishment of the P55C standard are not compliant with the dual intensity required for proper operation of this chip. Intel temporarily manufactured an upgrade kit called the OverDrive that was designed to correct this lack of planning on the motherboard makers' part.

Pentium MMX notebook CPUs used a "mobile module" that held the CPU. This module was a PCB with the CPU directly attached to it in a smaller form factor. The module snapped to the notebook motherboard and typically a heat spreader was installed and made contact with the module. However, with the 0.25 µm "Tillamook" Mobile Pentium MMX (named after a city in Oregon), the module also held the 430TX chipset along with the system's 512 KB SRAM cache memory.

After the introduction of the Pentium, competitors such as Nexgen, AMD, Cyrix, and Texas Instruments announced Pentium-compatible processors in 1994. "CIO magazine" identified NexGen's Nx586 as the first Pentium-compatible CPU, while "PC Magazine" described the Cyrix 6x86 as the first. These were followed by the AMD K5, which was delayed due to design difficulties. AMD later bought NexGen in order to help design the AMD K6, and Cyrix was purchased by National Semiconductor. Later processors from AMD and Intel retain compatibility with the original Pentium.



These Manuals do provide an overview of the Pentium Processor and its features:


</doc>
<doc id="24669" url="https://en.wikipedia.org/wiki?curid=24669" title="Pauli exclusion principle">
Pauli exclusion principle

The Pauli exclusion principle is the quantum mechanical principle which states that two or more identical fermions (particles with half-integer spin) cannot occupy the same quantum state within a quantum system simultaneously. In the case of electrons in atoms, it can be stated as follows: it is impossible for two electrons of a poly-electron atom to have the same values of the four quantum numbers: "n", the principal quantum number, ', the angular momentum quantum number, "m", the magnetic quantum number, and "m", the spin quantum number. For example, if two electrons reside in the same orbital, and if their "n", ', and "m" values are the same, then their "m" must be different, and thus the electrons must have opposite half-integer spin projections of 1/2 and −1/2. This principle was formulated by Austrian physicist Wolfgang Pauli in 1925 for electrons, and later extended to all fermions with his spin–statistics theorem of 1940.

Particles with an integer spin, or bosons, are not subject to the Pauli exclusion principle: any number of identical bosons can occupy the same quantum state, as with, for instance, photons produced by a laser and Bose–Einstein condensate.

A more rigorous statement is that with respect to exchange of two identical particles the total wave function is antisymmetric for fermions, and symmetric for bosons. This means that if the space "and" spin co-ordinates of two identical particles are interchanged, then the wave function changes its sign for fermions and does not change for bosons.

The Pauli exclusion principle describes the behavior of all fermions (particles with "half-integer spin"), while bosons (particles with "integer spin") are subject to other principles. Fermions include elementary particles such as quarks, electrons and neutrinos. Additionally, baryons such as protons and neutrons (subatomic particles composed from three quarks) and some atoms (such as helium-3) are fermions, and are therefore described by the Pauli exclusion principle as well. Atoms can have different overall "spin", which determines whether they are fermions or bosons — for example helium-3 has spin 1/2 and is therefore a fermion, in contrast to helium-4 which has spin 0 and is a boson. As such, the Pauli exclusion principle underpins many properties of everyday matter, from its large-scale stability, to the chemical behavior of atoms.

"Half-integer spin" means that the intrinsic angular momentum value of fermions is formula_1 (reduced Planck's constant) times a half-integer (1/2, 3/2, 5/2, etc.). In the theory of quantum mechanics fermions are described by antisymmetric states. In contrast, particles with integer spin (called bosons) have symmetric wave functions; unlike fermions they may share the same quantum states. Bosons include the photon, the Cooper pairs which are responsible for superconductivity, and the W and Z bosons. (Fermions take their name from the Fermi–Dirac statistical distribution that they obey, and bosons from their Bose–Einstein distribution.)

In the early 20th century it became evident that atoms and molecules with even numbers of electrons are more chemically stable than those with odd numbers of electrons. In the 1916 article "The Atom and the Molecule" by Gilbert N. Lewis, for example, the third of his six postulates of chemical behavior states that the atom tends to hold an even number of electrons in any given shell, and especially to hold eight electrons which are normally arranged symmetrically at the eight corners of a cube (see: cubical atom). In 1919 chemist Irving Langmuir suggested that the periodic table could be explained if the electrons in an atom were connected or clustered in some manner. Groups of electrons were thought to occupy a set of electron shells around the nucleus. In 1922, Niels Bohr updated his model of the atom by assuming that certain numbers of electrons (for example 2, 8 and 18) corresponded to stable "closed shells".

Pauli looked for an explanation for these numbers, which were at first only empirical. At the same time he was trying to explain experimental results of the Zeeman effect in atomic spectroscopy and in ferromagnetism. He found an essential clue in a 1924 paper by Edmund C. Stoner, which pointed out that, for a given value of the principal quantum number ("n"), the number of energy levels of a single electron in the alkali metal spectra in an external magnetic field, where all degenerate energy levels are separated, is equal to the number of electrons in the closed shell of the noble gases for the same value of "n". This led Pauli to realize that the complicated numbers of electrons in closed shells can be reduced to the simple rule of "one" electron per state, if the electron states are defined using four quantum numbers. For this purpose he introduced a new two-valued quantum number, identified by Samuel Goudsmit and George Uhlenbeck as electron spin.

The Pauli exclusion principle with a single-valued many-particle wavefunction is equivalent to requiring the wavefunction to be antisymmetric with respect to exchange. An antisymmetric two-particle state is represented as a sum of states in which one particle is in state formula_2 and the other in state formula_3, and is given by:

and antisymmetry under exchange means that . This implies when , which is Pauli exclusion. It is true in any basis since local changes of basis keep antisymmetric matrices antisymmetric.

Conversely, if the diagonal quantities are zero "in every basis", then the wavefunction component

is necessarily antisymmetric. To prove it, consider the matrix element

This is zero, because the two particles have zero probability to both be in the superposition state formula_7. But this is equal to

The first and last terms are diagonal elements and are zero, and the whole sum is equal to zero. So the wavefunction matrix elements obey:

or

According to the spin–statistics theorem, particles with integer spin occupy symmetric quantum states, and particles with half-integer spin occupy antisymmetric states; furthermore, only integer or half-integer values of spin are allowed by the principles of quantum mechanics.
In relativistic quantum field theory, the Pauli principle follows from applying a rotation operator in imaginary time to particles of half-integer spin.

In one dimension, bosons, as well as fermions, can obey the exclusion principle. A one-dimensional Bose gas with delta-function repulsive interactions of infinite strength is equivalent to a gas of free fermions. The reason for this is that, in one dimension, exchange of particles requires that they pass through each other; for infinitely strong repulsion this cannot happen. This model is described by a quantum nonlinear Schrödinger equation. In momentum space the exclusion principle is valid also for finite repulsion in a Bose gas with delta-function interactions, as well as for interacting spins and Hubbard model in one dimension, and for other models solvable by Bethe ansatz. The ground state in models solvable by Bethe ansatz is a Fermi sphere.

The Pauli exclusion principle helps explain a wide variety of physical phenomena. One particularly important consequence of the principle is the elaborate electron shell structure of atoms and the way atoms share electrons, explaining the variety of chemical elements and their chemical combinations. An electrically neutral atom contains bound electrons equal in number to the protons in the nucleus. Electrons, being fermions, cannot occupy the same quantum state as other electrons, so electrons have to "stack" within an atom, i.e. have different spins while at the same electron orbital as described below.

An example is the neutral helium atom, which has two bound electrons, both of which can occupy the lowest-energy ("1s") states by acquiring opposite spin; as spin is part of the quantum state of the electron, the two electrons are in different quantum states and do not violate the Pauli principle. However, the spin can take only two different values (eigenvalues). In a lithium atom, with three bound electrons, the third electron cannot reside in a 1s state, and must occupy one of the higher-energy 2s states instead. Similarly, successively larger elements must have shells of successively higher energy. The chemical properties of an element largely depend on the number of electrons in the outermost shell; atoms with different numbers of occupied electron shells but the same number of electrons in the outermost shell have similar properties, which gives rise to the periodic table of the elements.

In conductors and semiconductors, there are very large numbers of molecular orbitals which effectively form a continuous band structure of energy levels. In strong conductors (metals) electrons are so degenerate that they cannot even contribute much to the thermal capacity of a metal. Many mechanical, electrical, magnetic, optical and chemical properties of solids are the direct consequence of Pauli exclusion.

The stability of the electrons in an atom itself is unrelated to the exclusion principle, but is described by the quantum theory of the atom. The underlying idea is that close approach of an electron to the nucleus of the atom necessarily increases its kinetic energy, an application of the uncertainty principle of Heisenberg. However, stability of large systems with many electrons and many nucleons is a different matter, and requires the Pauli exclusion principle.

It has been shown that the Pauli exclusion principle is responsible for the fact that ordinary bulk matter is stable and occupies volume. This suggestion was first made in 1931 by Paul Ehrenfest, who pointed out that the electrons of each atom cannot all fall into the lowest-energy orbital and must occupy successively larger shells. Atoms therefore occupy a volume and cannot be squeezed too closely together.

A more rigorous proof was provided in 1967 by Freeman Dyson and Andrew Lenard, who considered the balance of attractive (electron–nuclear) and repulsive (electron–electron and nuclear–nuclear) forces and showed that ordinary matter would collapse and occupy a much smaller volume without the Pauli principle.

The consequence of the Pauli principle here is that electrons of the same spin are kept apart by a repulsive exchange interaction, which is a short-range effect, acting simultaneously with the long-range electrostatic or Coulombic force. This effect is partly responsible for the everyday observation in the macroscopic world that two solid objects cannot be in the same place at the same time.

Freeman Dyson and Andrew Lenard did not consider the extreme magnetic or gravitational forces that occur in some astronomical objects. In 1995 Elliott Lieb and coworkers showed that the Pauli principle still leads to stability in intense magnetic fields such as in neutron stars, although at a much higher density than in ordinary matter. It is a consequence of general relativity that, in sufficiently intense gravitational fields, matter collapses to form a black hole.

Astronomy provides a spectacular demonstration of the effect of the Pauli principle, in the form of white dwarf and neutron stars. In both bodies, atomic structure is disrupted by extreme pressure, but the stars are held in hydrostatic equilibrium by "degeneracy pressure", also known as Fermi pressure. This exotic form of matter is known as degenerate matter. The immense gravitational force of a star's mass is normally held in equilibrium by thermal pressure caused by heat produced in thermonuclear fusion in the star's core. In white dwarfs, which do not undergo nuclear fusion, an opposing force to gravity is provided by electron degeneracy pressure. In neutron stars, subject to even stronger gravitational forces, electrons have merged with protons to form neutrons. Neutrons are capable of producing an even higher degeneracy pressure, neutron degeneracy pressure, albeit over a shorter range. This can stabilize neutron stars from further collapse, but at a smaller size and higher density than a white dwarf. Neutron stars are the most "rigid" objects known; their Young modulus (or more accurately, bulk modulus) is 20 orders of magnitude larger than that of diamond. However, even this enormous rigidity can be overcome by the gravitational field of a massive star or by the pressure of a supernova, leading to the formation of a black hole.






</doc>
<doc id="24670" url="https://en.wikipedia.org/wiki?curid=24670" title="Pasiphaë">
Pasiphaë

In Greek mythology, Pasiphaë (; "Pasipháē", "wide-shining" derived from "pas" "all, for all, of all" and "phaos" "light") was a queen of Crete.

Pasiphae was the daughter of Helios, the Sun, and Perse, the eldest of the Oceanids. Like her doublet Europa, her origins were in the East, in her case at Colchis; she was the sister of Circe, and she was given in marriage to King Minos of Crete. With Minos, she was the mother of Acacallis, Ariadne, Androgeus, Glaucus, Deucalion, Phaedra, Xenodice, and Catreus. She was also the mother of "starlike" Asterion, called by the Greeks the Minotaur.

After a curse from Poseidon, Pasiphae experienced lust for and mated with a white bull sent by Poseidon. "The Bull was the old pre-Olympian Poseidon," Ruck and Staples remark. 

In the Greek literalistic understanding of a Minoan myth, in order to actually copulate with the bull, she had the Athenian artificer Daedalus construct a portable wooden cow with a cowhide covering, within which she was able to satisfy her strong desire. The effect of the Greek interpretation was to reduce a more-than-human female, daughter of the Sun itself, to a stereotyped emblem of grotesque bestiality and the shocking excesses of female sensuality and deceit. Pasiphaë appeared in Virgil's "Eclogue VI" (45–60), in Silenus' list of suitable mythological subjects, on which Virgil lingers in such detail that he gives the sixteen-line episode the weight of a brief inset myth. In Ovid's "Ars Amatoria" Pasiphaë is reduced to unflattering human terms: "Pasiphae fieri gaudebat adultera tauri"—"Pasiphaë took pleasure in becoming an adulteress with a bull."

In other aspects, Pasiphaë, like her niece Medea, was a mistress of magical herbal arts in the Greek imagination. The author of "Bibliotheke" (3.197-198) records the fidelity charm she placed upon Minos, who would ejaculate serpents, scorpions, and centipedes killing any unlawful concubine; but Procris, with a protective herb, lay with Minos with impunity. 

In mainland Greece, Pasiphaë was worshipped as an oracular goddess at Thalamae, one of the original "koine" of Sparta. The geographer Pausanias describes the shrine as small, situated near a clear stream, and flanked by bronze statues of Helios and Pasiphaë. His account also equates Pasiphaë with Ino and the lunar goddess Selene.

Cicero writes in "De Divinatione" 1.96 that the Spartan ephors would sleep at the shrine of Pasiphaë, seeking prophetic dreams to aid them in governance. According to Plutarch, Spartan society twice underwent major upheavals sparked by ephors' dreams at the shrine during the Hellenistic era. In one case, an ephor dreamed that some of his colleagues' chairs were removed from the agora, and that a voice called out "this is better for Sparta"; inspired by this, King Cleomenes acted to consolidate royal power. Again during the reign of King Agis, several ephors brought the people into revolt with oracles from Pasiphaë's shrine promising remission of debts and redistribution of land.

In "Description of Greece", Pausanias equates Pasiphaë with Selene, implying that the figure was worshipped as a lunar deity. However, further studies on Minoan religion indicate that the sun was a female figure, suggesting instead that Pasiphaë was originally a solar goddess, an interpretation consistent with her depiction as Helios' daughter. Poseidon's bull may in turn be vestigial of the lunar bull prevalent in Middle Eastern religions.






</doc>
<doc id="24672" url="https://en.wikipedia.org/wiki?curid=24672" title="Primate (bishop)">
Primate (bishop)

Primate () is a title or rank bestowed on some archbishops in certain Christian churches. Depending on the particular tradition, it can denote either jurisdictional authority (title of authority) or (usually) ceremonial precedence (title of honour).

In the Western Church, a Primate is an Archbishop—or rarely a suffragan or exempt bishop—of a specific (mostly Metropolitan) episcopal see (called a "primatial see") who has precedence over the bishoprics of one or more ecclesiastical provinces of a particular historical, political or cultural area. Historically, Primates of particular sees were granted privileges including the authority to call and preside at national synods, jurisdiction to hear appeals from metropolitan tribunals, the right to crown the sovereign of the nation, and presiding at the investiture (installation) of archbishops in their sees.
The office is generally found only in older Catholic countries, and is now purely honorific, enjoying no effective powers under canon law—except for the Archbishop of Esztergom (Gran) in Hungary. Thus, e.g., the Primate of Poland holds no jurisdictional authority over other Polish bishops or their dioceses, but is "durante munere" a member of the standing committee of the episcopal conference and has honorary precedence among Polish bishops (e.g., in liturgical ceremonies). The Holy See has also granted Polish primates the privilege of wearing cardinal's crimson attire, except for the skullcap and biretta, even if they have not been made cardinals.

Where the title of primate exists, it may be vested in one of the oldest archdioceses in a country, often based in a city other than the present capital, but which was the capital when the country was first Christianized. The city may no longer have the prominence it had when the title was granted. The political area over which primacy was originally granted may no longer exist: for example, the Archbishop of Toledo was designated "Primate of the Visigothic Kingdom", and the Archbishop of Lyon is the "Primate of the Gauls".

Some of the leadership functions once exercised by Primates, specifically presiding at meetings of the bishops of a nation or region, are now exercised by the president of the conference of bishops: "The president of the Conference or, when he is lawfully impeded, the vice-president, presides not only over the general meetings of the Conference but also over the permanent committee." The president is generally elected by the conference, but by exception the President of the Italian Episcopal Conference is appointed by the Pope, and the Irish Catholic Bishops' Conference has the Primate of All Ireland as President and the Primate of Ireland as Vice-President. Other former functions of primates, such as hearing appeals from metropolitan tribunals, were reserved to the Holy See by the early 20th century. Soon after, by the norm of the Code of Canon Law of 1917, confirmed in the 1983 Code, the tribunal of second instance for appeals from a metropolitan tribunal is "the tribunal which the metropolitan has designated in a stable manner with the approval of the Apostolic See".

The closest equivalent position in the Eastern Churches in 1911 was an Exarch.

The Holy See has continued in modern times to grant the title of Primate. With the papal decree "Sollicitae Romanis Pontificibus" of 24 January 1956 it granted the title of Primate of Canada to the Archbishop of Quebec. As stated above, this is merely an honorary title involving no additional power.

A right of precedence over other bishops and similar privileges can be granted even to a bishop who is not a Primate. Thus, in 1858, the Holy See granted the Archbishop of Baltimore precedence in meetings of the United States bishops. The Archbishop of Westminster has not been granted the title of Primate of England and Wales, which is sometimes applied to him, but his position has been described as that of "Chief Metropolitan" and as "similar to" that of the Archbishop of Canterbury.

The title of Primate is sometimes applied loosely to the Archbishop of a country's capital, as in the case of the Archbishops of Seoul in South Korea and of Edinburgh in Scotland. Functions can sometimes be exercised in practice ("de facto"), as by a "de facto" government, without having been granted by law; but since "Primate" is today a title, not a function, there is no such thing as a ""de facto"" primate.

The pre-reformation Metropolitan Archbishop of Nidaros was sometimes referred to as Primate of Norway, even though it is unlikely that this title ever was officially granted to him by the Holy See.

The heads of certain sees have at times been referred to, at least by themselves, as primates: 



In the modern confederation of the Benedictine Order, all the Black Monks of St. Benedict were united under the presidency of an Abbot Primate (Leo XIII, "Summum semper", 12 July 1893); but the unification, fraternal in its nature, brought no modification to the abbatial dignity, and the various congregations preserved their autonomy intact. The loose structure of the Benedictine Confederation is claimed to have made Pope Leo XIII exclaim that the Benedictines were "ordo sine ordine" ("an order without order"). The powers of the Abbot Primate are specified, and his position defined, in a decree of the Sacred Congregation of Bishops and Regulars dated 16 September 1893. The primacy is attached to the global Benedictine Confederation whose Primate resides at Sant'Anselmo in Rome. He takes precedence of all other abbots, is empowered to pronounce on all doubtful matters of discipline, to settle difficulties arising between monasteries, to hold a canonical visitation, if necessary, in any congregation of the order, and to exercise a general supervision for the regular observance of monastic discipline. The Primatial powers are only vested in the Abbot Primate to act by virtue of the proper law of its autonomous Benedictine congregation, which at the present is minimal to none. However, certain branches of the Benedictine Order seem to have lost their original autonomy to some extent.
In a similar way the Confederation of Canons Regular of St. Augustine, elects an Abbot Primate as figurehead of the Confederation and indeed the whole Canonical Order. The Abbots and Superiors General of the nine congregations of confederated congregations of Canons Regular elect a new Abbot Primate for a term of office lasting six years. The Current Abbot General is Rt. Rev. Fr Maurice Bitz, Abbot of St. Pierre, and Abbot General of the Canons Regular of St. Victor.

Anglican usage styles the bishop who heads an independent church as its "primate", though commonly they hold some other title (e.g. archbishop, presiding bishop, or moderator). The primates' authority within their churches varies considerably: some churches give the primate some executive authority, while in others they may do no more than preside over church councils and represent the church ceremonially.

In the context of the Anglican Communion Primates' Meeting, the chief bishop of each of the thirty-nine churches (also known as provinces) that compose the Anglican Communion acts as its primate, though this title may not necessarily be used within their own provinces. Thus the United Churches of Bangladesh, of North India, of Pakistan and of South India, which are united with other originally non-Anglican churches, are represented at the meetings by their moderators.

In both the Church of England and the Church of Ireland, two bishops have the title of primate: the archbishops of Canterbury and York in England and of Armagh and Dublin in Ireland. Only the bishop of the senior primatial see of each of these two churches participates in the meetings.

The Archbishop of Canterbury, who is considered "primus inter pares" of all the participants, convokes the meetings and issues the invitations.

Primates and archbishops are styled "The Most Reverend". All other bishops are styled "The Right Reverend".

The head of the Traditional Anglican Communion's College of Bishops takes the title of Primate.



</doc>
<doc id="24673" url="https://en.wikipedia.org/wiki?curid=24673" title="Penny Arcade">
Penny Arcade

Penny Arcade is a webcomic focused on video games and video game culture, written by Jerry Holkins and illustrated by Mike Krahulik. The comic debuted in 1998 on the website "loonygames.com". Since then, Holkins and Krahulik have established their own site, which is typically updated with a new comic strip each Monday, Wednesday, and Friday. The comics are accompanied by regular updates on the site's blog.

"Penny Arcade" is among the most popular and longest running webcomics currently online, listed in 2010 as having 3.5 million readers. Holkins and Krahulik are among the first webcomic creators successful enough to make a living from their work. In addition to the comic, Holkins and Krahulik also created Child's Play, a children's charity; PAX, a gaming convention; Penny Arcade TV, a YouTube channel; Pinny Arcade, a pin exchange; and the episodic video game "" with Hothead Games and Zeboyd Games.

The strip features Krahulik and Holkins' cartoon alter egos, John "Gabe" Gabriel and Tycho Brahe, respectively. While often borrowing from the authors' experiences, Holkins and Krahulik do not treat them as literal avatars or caricatures of themselves. The two characters spend much of their time playing and commenting on computer and video games, which forms the basis of the humor in the strip. Most of the time Gabe serves the purpose of the comic and Tycho the comic foil. The strip can feature in-jokes that are explained in the news posts accompanying each comic, written by the authors.

Both Krahulik and Holkins make a living from "Penny Arcade", placing them in a small group of professional webcomic artists devoted to their creations full-time. Originally, like many webcomics, "Penny Arcade" was supported solely by donations. A graph on the main page indicated how much people had donated that month. After hiring Robert Khoo as their business manager, Holkins and Krahulik switched to a different income stream based on advertising and merchandise revenue alone. According to Holkins, the website in 2006 handled more than two million pageviews daily (excluding forum traffic). On November 13, 2005, the website was given a facelift in celebration of their seventh year running and to match the designs of the Child's Play Charity and Penny Arcade Expo websites. Afterwards, the site has been redesigned multiple times.

As a (primarily) topical video gaming news comic, there is little plot or general continuity in "Penny Arcade" strips. Any story sustained for longer than a single strip is referred to as "dreaded continuity", something of a running gag in the newsposts. A character who dies a violent death in one strip will come back in the next, perfectly whole, though occasionally these deaths have an effect on later comics. For example, often, when Gabe kills Tycho or vice versa, the killer takes a certain Pac-Man watch off the dead character, but only if he currently has the watch. Profanity and violence are common in "Penny Arcade" and the strip is known for its surrealism; zombies, a talking alcoholic DIVX player called Div, Santa Claus, a robotic juicer called the "Fruit Fucker 2000", and Jesus, among others, are known to drop in often and for petty reasons. Other such occurrences are implied, if not shown, such as mentioning Dante from "Devil May Cry" living in the building next door. However, the comic does occasionally expand into more serious issues; one even had Krahulik, in the guise of the character Gabe, proposing to his girlfriend of two years, while another had both Gabe and Tycho praising Casey Heynes for standing up to bullying.

Some of the strips are drawn from the perspective of fictional characters within a game or movie. Occasionally, Gabe and Tycho are featured as they would be as characters or players in the game themselves, often having some sarcastic remark to make about some feature or bug in the game. At times the comic also depicts meetings between game developers or business people, and features or mocks the reporters of a news article that is commented on in Holkins' newspost.

"Penny Arcade" has a theme song, "Penny Arcade Theme", written and performed by nerdcore artist MC Frontalot. It was written as a thank-you by Frontalot for the creators of the webcomic linking his website to their front page and declaring him their "rapper laureate" in 2002. The song appears in the dance game "In the Groove".

Mike Krahulik's comic alter ego is energetic and free-spirited, but has a propensity to become extremely angry. He has a Pac-Man tattoo on his right arm, as well as a tattoo in honor of the demise of SNK on his back. His eyes are a shade of slate blue. He almost always wears a yellow Pac-Man shirt, and in one comic he mentioned having a glass eye as a result of an incident after Tycho beat him at "Warcraft II", although no other references to it have been made. He has a fascination with unicorns, a secret love of Barbies, is a dedicated fan of Spider-Man and "Star Wars", and has proclaimed "Jessie's Girl" to be the greatest song of all time. He practices line dancing with the Kansas City Hotsteppers. He is a diabetic, though he continues to consume large quantities of sugar products. He has an odd affinity for a cardboard tube which he had fantasies of wielding as a wandering samurai, often in feudal Japan. He was for a short time addicted to "Tribes" but soon grew out of it. He also has an obsession with his own genitalia and possible latent homosexual tendencies. This theory can be supported by a recent recurrence of Gabriel's "personal" interest in actor Patrick Swayze. Despite this, his "son" is also present in the strip and appears alongside Gabe's wife. As a contrast to Tycho's expansive vocabulary, Gabe usually speaks using only simple, common words. Krahulik named his son "Gabriel" in honor of the character.
Jerry Holkins' comic alter ego (named after the astronomer Tycho Brahe) is bitter and sarcastic. His eyes are burnt sienna, and he's almost invariably clad in a blue-striped sweater. Tycho enjoys books, role-playing video games, using large and uncommon words in conversation, and deflating Gabe's ego. He is a rabid fan of "Harry Potter" and "Doctor Who". He also plays "Dungeons & Dragons" often (the website's previous banner illustrated him holding a 20-sided die), and adopts a wildly theatrical style when acting as a dungeon master. He occasionally makes reference to his scarring childhood, during which his mother physically abused him and blamed him for the family's abandonment by his father due to his body, "swelling with evil" (in fact, his puberty). It has been mentioned that one of his aunts, believing him to be gay, regularly sends him homo-erotic material. Tycho also has a drinking problem. In one strip, after a dream, Tycho is shown to be host to an evil spirit, the presence of which is indicated by his eyes glowing with pink light; this theme is repeated over the course of the strip. Some strips appear to indicate that he has an unhealthy sexual obsession with long-necked animals such as giraffes and ostriches, or even with inhuman alien creatures. In "Poker Night at the Inventory", Tycho is voiced by Kid Beyond.

Krahulik and Holkins began to record and release audio content on March 20, 2006, titled "Downloadable Content." The podcasts specifically captured the creative process that goes into the creation of a "Penny Arcade" comic, usually starting with a perusal of recent gaming news, with conversational tangents and digressions to follow. As well as being a behind-the-scenes look at the creation of "Penny Arcade", Krahulik and Holkins discuss possible subjects for the comic.

The format of the show was mostly "fly-on-the-wall" style, in that the hosts rarely acknowledged the existence of the microphone. There was no theme music, intro, or outro. The podcasts were of varying lengths, beginning abruptly and ending with the idea for the current comic. New episodes were released irregularly, with six month gaps not uncommon.

Although the shows were initially published weekly, Holkins stated in a May 2006 blog post that they have found difficulties when trying to produce the podcasts on a regular basis. The duo planned to keep recording podcasts occasionally.

Since airing the first episode of the new PATV in February 2010, the podcast has not been updated. A new segment has since appeared on PATV called "The Fourth Panel," which presents a fly-on-the-wall look at comics creation much as the podcast did.

On May 8, 2013 Penny Arcade launched a Kickstarter campaign to fund the continuation of "Downloadable Content". The kickstarter was successful, with new Podcasts being added each Wednesday.

"" is an episodic video game based on the strip. The first two episodes were developed by Hothead Games, and were built on a version of the Torque Game Engine. The first episode was released worldwide on May 21, 2008, and the second on October 29, 2008. They were self-published via the PlayStation Network and Xbox Live as well as the PlayGreenhouse.com service created by "Penny Arcade" to distribute independent games. The game features many elements of the "Penny Arcade" universe in a 1920s steampunk setting. In 2010, Krahulik and Holkins announced that the remainder of the series had been cancelled, to allow Hothead to focus on other projects. At PAX Prime 2011, however, it was announced that the series would be revived and developed by Zeboyd Games, with a retro style similar to Zeboyd's past titles. The third episode was released on Steam and on Penny Arcade's web store June 25, 2012. The fourth and final episode was announced in January 2013, and released to Steam and Xbox Live in June 2013.

A teaser trailer released by Telltale Games on August 28, 2010, revealed that Tycho would appear in an upcoming game alongside "Team Fortress 2's" Heavy, Strong Bad and Max. The game, called "Poker Night at the Inventory", was officially revealed on September 2, 2010.

"The Last Christmas" and "The Hawk and the Hare", two stories that were published on the site, were released as motion comics for iOS developed by SRRN Games.

The North American release of "Tekken 6" has a skin for Yoshimitsu based on the Cardboard Tube Samurai. An official DLC skin pack was released for Dungeon Defenders featuring Tycho, Cardboard Tube Samurai Gabe, Annarchy and Jim Darkmagic skins.

Cryptozoic Entertainment released the licensed deck-building card game "Penny Arcade The Game: Gamers Vs. Evil" in 2011, and followed it with the expansion pack "Penny Arcade The Game: Rumble in R'lyeh" in 2012. Playdek released a digital conversion of "Penny Arcade The Game: Gamers Vs. Evil" for iOS in 2012.

"Penny Arcade: The Series" first aired online on February 20, 2010. It is a multi-season documentary series based on the exploits of the Penny Arcade company and its founders Krahulik and Holkins.

Under the banner of "Penny Arcade Presents", Krahulik and Holkins are sometimes commissioned to create promotional artwork/comic strips for new video games, with their signature artistic style and humor. They are usually credited simply as "Penny Arcade" rather than by their actual names. Some of these works have been included with the distribution of the game, and others have appeared on pre-launch official websites. An official list can be found on the Penny Arcade website.

On August 8, 2005, Krahulik announced that "Penny Arcade", in partnership with Sabertooth Games, would be producing a collectible card game based on the "Penny Arcade" franchise. The resulting "Penny Arcade" "battle box" was released in February 2006 as part of the Universal Fighting System.

There are also a few spinoffs from the main comic that have gained independent existences. An example is "" (ELotH:TES), a parody of the written-by-committee fantasy fiction used as back-story for a wide variety of games: originally a one-off gag in the "Penny Arcade" comic, in late 2005 this was expanded into a complete fantasy universe, documented on a hoax "fan-wiki". ELotH:TES first appeared in the webcomic of February 7, 2005, and has subsequently been featured in the comics of November 7, 2005 and November 30, 2005. Several elements of the ELotH:TES universe are featured on the cover of their second comics collection, "Epic Legends of the Magic Sword Kings".

On May 31, 2006 Krahulik announced a new advertising campaign for the Entertainment Software Rating Board. According to Krahulik, the ESRB "wanted a campaign that would communicate to gamers why the ESRB is important even if they don't think it directly affects them." Among the reasons he listed for "Penny Arcade"<nowiki>'</nowiki>s accepting the job was that he and Holkins are both fathers and are concerned about the games their children might play. The ad campaign was rolled out in the summer and fall of 2006 and a second campaign was released in 2012 featuring a mother, a father and a gamer describing the tools employed by the ESRB.

Announced on June 2, 2011, Paramount Pictures had acquired the rights to produce an animated film, via Paramount Animation to make this, of the one-off strip "The New Kid" which was published on October 29, 2010. The strip was one of three mini-strips which featured a cinematic opening to a larger story left unexplored. "The New Kid" is about a boy who's moving to a new planet with his family because of his father's career. The script was written by Gary Whitta and would have been produced by Mary Parent and Cale Boyter.

At PAX Australia in 2016, during a Q&A session, Holkins revealed that changes at Paramount resulted in the movie rights being returned to Penny Arcade and the project canceled. He did note, however, that Whitta's script was complete and the project could move forward with another production company in the future.

The Trenches was a comic series by Krahulik and Holkins in collaboration with webcomic "PvP"'s creator Scott Kurtz. The comic followed a man named Issac and his life as a game tester. The series was launched on August 9, 2011 and featured new strips every Tuesday and Thursday, usually accompanied by a "Tale from the Trenches", which was a short piece submitted by a reader detailing their own experiences in the game industry.

In September 2012, Kurtz stopped illustrating the webcomic, due to lack of time, and was replaced by Mary Cagle, a former intern of his, and the creator of the webcomic Kiwi Blitz. Kurtz still continued to collaborate with Krahulik and Holkins in writing the comic. In late August 2013, illustration was taken over by Ty Halley ("Secret Life of a Journal Writer") and Monica Ray ("Phuzzy Comics"), former contestants of the Penny Arcade series "Strip Search".

"The Trenches" was ultimately abandoned. The last comic was posted January 5, 2016, while the last "Tales" is from September 10, 2015.

Krahulik and Holkins have also released an application for iOS devices called "The Decide-o-tron", presented by Eedar and developed by The Binary Mill. The app works as a recommendation engine for video games; users input games they've enjoyed and the app attempts to predict their ratings of titles they haven't yet played. Holkins described it as "Pandora for games".

Penny Arcade has created two Kickstarter projects. The first was the "Penny Arcade's Paint the Line" card game which was used as an alternative to pre-ordering it and came with an exclusive comic. The second was entitled "Penny Arcade Sells Out" and was intended to replace advertising revenue with crowd funding. The leaderboard ad on the home page of Penny Arcade would be removed if the minimum goal of $250,000 were reached, whereas the entire site would become completely ad-free for a year at $999,999. The reality web series described as "our version of America's Next Top Webcomic" titled "Strip Search" arose from the $450,000 stretch goal.

Krahulik and Holkins created a comic strip which compares the 7th generation consoles that appears in the December 2006 issue of "Wired" magazine.

Every Christmas since 2003, "Penny Arcade" hosts a charity called Child's Play to buy new toys for children's hospitals. They have also sponsored a three-day gaming festival called the Penny Arcade Expo every August since 2004.

Krahulik and Holkins received a cease-and-desist letter from American Greetings Corporation over the use of American Greetings' Strawberry Shortcake and Plum Puddin' characters in the April 14, 2003 "Penny Arcade" strip entitled "Tart as a Double Entendre". The strip was intended as a parody of the works of both American McGee (especially the computer game "Alice") and McFarlane Toys. At the time, McFarlane toys and American McGee made separate toy lines, each portraying a dark, frightening interpretation of the characters and situations from "The Wonderful Wizard of Oz". Krahulik and Holkins' portrayal of Strawberry Shortcake parodied McFarlane Toys' depiction of Dorothy as bound and blindfolded by a pair of munchkins.

Krahulik and Holkins chose not to enter into a legal battle over whether or not the strip was a protected form of parody, and they complied with the cease-and-desist by replacing it with an image directing their audience to send a letter to a lawyer for American Greetings. They later lampooned the incident by portraying an American Greetings employee as a Nazi.

On June 15, 2011, a strip entitled "Reprise" revisited the issue, due to the release of "", another American McGee game. In the strip, Gabe suggests that he and Tycho parody a brand not "under constant surveillance", resulting in a spoof of the "Rainbow Brite" franchise. Holkins stated in the accompanying news post that "it seemed like an incredible opportunity to relive the days of yore."

On October 17, 2005 Krahulik and Holkins donated US$10,000 to the Entertainment Software Association foundation in the name of Jack Thompson, an activist against violence in video games. Earlier, Thompson himself had promised to donate $10,000 if a video game was created in which the player kills video game developers ("A Modest Video Game Proposal"), but after a mod to the game "Grand Theft Auto" was pointed out to already exist, Thompson called his challenge satire (referring to the title of the letter as a reference to "A Modest Proposal") and refused to donate the money. He claimed these games were not going to be manufactured, distributed, or sold like retail games, as his Modest Proposal stated, and therefore, the deal went unfulfilled. His refusal was met with disdain, given that multiple games were created or in the process of being created under Thompson's criteria. Krahulik and Holkins donated the money in his place, with a check containing the memo: "For Jack Thompson, Because Jack Thompson Won't".

Thompson proceeded to phone Krahulik, as related by Holkins in the corresponding news post.

On October 18, 2005 it was reported that Jack Thompson had faxed a letter to Seattle Police Chief Gil Kerlikowske claiming that "Penny Arcade" "employs certain personnel who have decided to commence and orchestrate criminal harassment of me by various means". Holkins defended the site by saying that the "harassment" Thompson referred to was simply "the natural result of a public figure making statements that people disagree with, and letting him know their thoughts on the matter via his publicly available contact information".

On October 21, 2005 Thompson claimed to have sent a letter to John McKay, U.S. Attorney for the Western District of Washington, in an attempt to get the FBI involved. Thompson re-iterated his claims of "extortion" and accused "Penny Arcade" of using "their Internet site and various other means to encourage and solicit criminal harassment". Penny Arcade denied the charge of "extortion", noting that they paid the $10,000 to charity, and asked nothing in return.

Thompson claimed the harassment of him is a direct result of Mike Krahulik's posts, which listed links to the Florida Bar Association. Thompson accused "Penny Arcade" of soliciting complaints to the Bar against him, even though Krahulik actually posted the opposite, asking fans to cease sending letters to the Bar, as the Bar acknowledged that it is aware of Thompson's actions, thanks to previous letters.

The Seattle PD eventually acknowledged receiving a complaint from Thompson, but have commented that they believe the issue to be a civil, rather than criminal, matter. They noted that this was from initial impressions of the letter they received, and their criminal investigations bureau is reviewing the letter to make sure that there were not any criminal matters that they missed.

On the same day, Scott Kurtz, creator of the webcomic "PvP" and a longtime friend of Krahulik and Holkins, used the image of the letter Thompson sent to the Seattle PD to create a parody letter in which Jack attempts to enlist the aid of the Justice League of America by claiming Gabe and Tycho to be villains of some description.

The "Penny Arcade" shop had at the time sold an "I hate Jack Thompson" T-shirt, claiming that every living creature, including Thompson's own mother, hates Jack Thompson.

On March 21, 2007 Thompson filed a countersuit to the lawsuit brought against him by Take Two Interactive claiming that they are at the center of a RICO conspiracy. "Penny Arcade" was named as one of the co-conspirators. At Sakura-Con 2007, Krahulik announced that the suit had been dropped.

An August 11, 2010 comic entitled "The Sixth Slave" wherein an NPC pleads with a player to save him from being raped nightly by monsters called "dickwolves", drew criticism from many commentators, including from "The American Prospect" and "The Boston Phoenix". Krahulik and Holkins dismissed these criticisms, later selling "Team Dickwolves" T-shirts based on the strip. They later removed the "Team Dickwolves" shirt from their store due to complaints that it made potential PAX attendees uncomfortable. After the removal, Krahulik posted online that removing the shirts was only partly caving to pressure but mainly due to people who had personally emailed him and were reasonable with their concerns. Krahulik also stated that anyone still hesitant about going to PAX even after removal of the shirts should not come to PAX. In September 2013, on the last day of PAX, Krahulik told a panel that he thought that "pulling the dickwolves merchandise was a mistake", to cheers from the crowd. However, Krahulik later apologized on the "Penny Arcade" website, stating that he regretted contributing to the furor that had followed the original comic.

Both critics of the comic strip and Krahulik and Holkins, made claims of receiving verbal abuse through social media and death threats.

"John Gabriel's Greater Internet Fuckwad Theory" was posted in the "Penny Arcade" strip published March 19, 2004. It regards the online disinhibition effect, in which Internet users exhibit unsociable tendencies while interacting with other Internet users. Krahulik and Holkins suggest that, given both anonymity and an audience, an otherwise regular person becomes aggressively antisocial. In 2013, Holkins gave the corollary that "Normal Person - "Consequences" + Audience = Total Fuckwad".

Clay Shirky, an adjunct professor at New York University who studies social and economic effects of Internet technologies, explains: "There’s a large crowd and you can act out in front of it without paying any personal price to your reputation,” which "creates conditions most likely to draw out the typical Internet user’s worst impulses." In an "Advocate" article about online homophobia, this theory was used to account for behavior on online forums where one can remain anonymous in front of an audience: for instance, posting comments on popular YouTube videos.


On December 13, 2006, "Next Generation Magazine" rated Krahulik and Holkins among its "Top 25 People of the Year". Also appearing on the list were Nintendo of America President Reggie Fils-Aime and former Xbox corporate vice-president Peter Moore. Krahulik made a post about the honor, in which he explained that "Penny Arcade" was created only because Next Gen rejected the duo's entry to a comic contest many years before. "Entertainment Weekly" listed "Penny Arcade" on their "100 Sites to Bookmark Now," calling it "a hilarious and smart webcomic for gamers." MTV Online named Holkins and Krahulik two of the world's most influential gamers, saying "they have become the closest the medium has to leaders of a gamers' movement." Time.com named "Penny Arcade" as one of its "50 Best Websites" for 2008 "...for the way it pokes fun at the high-tech industry and the people who love it."
1UP.com described it as "the One True Gaming Webcomic." "Penny Arcade" was used along with "American Elf", "Fetus-X", and "Questionable Content" as an example of comics using the web to create "an explosion of diverse genres and styles" in Scott McCloud's 2006 book "Making Comics".

On March 5, 2009, the Washington State Senate honored Holkins and Krahulik, both originally from Spokane, for the contribution that they had made to the state, the video game industry, and to children's charities from around the world courtesy of their Child's Play initiative. Later in March, "Penny Arcade" won the category "Best Webcomic" in the fan voted Project Fanboy Awards for 2008.

In 2010, Holkins, Krahulik, and Khoo were awarded the annual "Ambassador Award" at GDC's Game Developers Choice Awards for contributions they had made to the industry. The same year, "Time" included Holkins and Krahulik in the annual "Time 100", the magazine's listing of the world's 100 most influential people.

In July 2015, Holkins and Krahulik were recognized as "Multimedia Empire Builders" in Ad Week's 10 Visual Artists Changing the Way We See Advertising issue.




</doc>
<doc id="24675" url="https://en.wikipedia.org/wiki?curid=24675" title="Permanent Way Institution">
Permanent Way Institution

The Permanent Way Institution is a technical Institution which aims to provide technical knowledge, advice and support to all those engaged in rail infrastructure systems worldwide.

Permanent Way is used to describe the course of a railway line, including the components that form the track, aggregate that supports the track and the civil engineering assets covering bridges, tunnels, viaducts and earthworks.

The Permanent Way Institution is split up into a number of sections throughout the United Kingdom and also has internationally located sections across the world.

Membership is open to anyone who is either actively involved in the rail industry, retired or just has a general interest in rail infrastructure engineering.

Home Sections are:

Ashford, 
Croydon & Brighton, 
Glasgow, 
London, 
North Wales, 
Wessex, 
Birmingham, 
Darlington & NE, 
Manchester & Liverpool, 
Nottingham & Derby, 
South & West Wales, 
West Yorkshire, 
Bristol & West of England, 
Edinburgh, 
Lancaster, Barrow & Carlisle, 
Milton Keynes, 
Sheffield & Doncaster, 
Thames Valley, 
York,

Student/Apprentice

Member

Fellow


The Journal (technical journal published quarterly)

Understanding Track Engineering - An essential introduction to the theory and practice of railway track engineering in the UK

Design of Railway Switches & Crossings in Flat Bottom Rail

Design of Railway Track in Bull Head Rail

Plain Line Maintenance of Track

Switch & Crossing Track Maintenance

Track Terminology



</doc>
<doc id="24676" url="https://en.wikipedia.org/wiki?curid=24676" title="President of Ireland">
President of Ireland

The President of Ireland () is the head of state of Ireland and the Supreme Commander of the Irish Defence Forces.

The President holds office for seven years, and can be elected for a maximum of two terms. The President is directly elected by the people, although there is no poll if only one candidate is nominated, which has occurred on six occasions to date. The presidency is largely a ceremonial office, but the President does exercise certain limited powers with absolute discretion. The President acts as a representative of the Irish state and guardian of the constitution. The President's official residence is in Phoenix Park, Dublin. The office was established by the Constitution of Ireland in 1937, the first president took office in 1938, and became internationally recognised as head of state in 1949 following the coming into force of the Republic of Ireland Act.

The current President is Michael D. Higgins, who was elected on 29 October 2011. His inauguration was held on 11 November 2011. President Higgins is a veteran left-wing politician and human rights campaigner. He had served in both houses of the as a member of the Labour Party. President Higgins is also a poet and speaks the Irish language fluently.

The Constitution of Ireland provides for a parliamentary system of government, under which the role of the head of state is largely a ceremonial one. The President is formally one of three parts of the Oireachtas (national parliament), which also comprises Dáil Éireann (the house of representatives or lower house) and Seanad Éireann (the Senate or upper house).

As a parliamentary republic, executive authority in Ireland is expressly vested in the Government (cabinet), rather than the president. The Government is obliged, however, to keep the President generally informed on matters of domestic and foreign policy. Most of the functions of the President may be carried out only in accordance with the strict instructions of the Constitution, or the binding 'advice' of the Government. The President does, however, possess certain personal powers that may be exercised at their discretion.

The main functions are prescribed by the Constitution:

Other functions specified by statute or otherwise include:


The President possesses the following powers exercised "in his absolute discretion" according to the English version of the Constitution. The Irish version states that these powers are exercised "as a chomhairle féin" which is usually translated as "under his own counsel." Lawyers have suggested that a conflict may exist in this case between both versions of the constitution. In the event of a clash between the Irish and English versions of the constitution, the Irish one is given supremacy. While "absolute discretion" appears to leave some freedom for manoeuvre for a president in deciding whether to initiate contact with the opposition, "own counsel" has been interpreted by some lawyers as suggesting that "no" contact whatsoever can take place. As a result, it is considered controversial for the president to be contacted by the leaders of any political parties in an effort to influence a decision made using the discretionary powers. It is required that, before exercising certain reserve powers, the President consult the Council of State. However, the President is not compelled to act in accordance with the council's advice.

The Taoiseach is required to resign if he has "ceased to retain the support of a majority in Dáil Eireann," unless he asks the President to dissolve the Dáil. The President has the right to refuse such a request, in which case the Taoiseach must resign immediately. This power has never been invoked. However, the necessary circumstances existed in 1944, 1982 and 1994. The apparent discrepancy, referred to above, between the Irish and English versions of the Constitution has discouraged Presidents from contemplating the use of the power. On the three occasions when the necessary circumstances existed, presidents have adopted an ultra-strict policy of non-contact with the opposition. The most notable instance of this was in January 1982, when Patrick Hillery instructed an aide, Captain Anthony Barber, to ensure that no telephone calls from the opposition were to be passed on to him. Nevertheless, three opposition figures, including Fianna Fáil leader Charles Haughey, demanded to be connected to Hillery, with Haughey threatening to end Barber's career if the calls weren't put through. Hillery, as Supreme Commander of the Defence Forces, recorded the threat in Barber's file and recorded that Barber had been acting on his instructions in refusing the call. Even without this consideration, refusing such a request would arguably create a constitutional crisis, as it is considered a fairly strong constitutional convention that the head of state always grants a parliamentary dissolution.

If requested to do so by a petition signed by a majority of the membership of the Seanad, and one-third of the membership of the Dáil, the President may, after consultation with the Council of State, decline to sign into law a bill (other than a bill to amend the constitution) they consider to be of great "national importance" until it has been approved by either the people in a referendum or the Dáil reassembling after a general election, held within eighteen months. This power has never been used, and no such petition has been invoked. Of the 60 Senators, 11 are nominated by the Taoiseach, so there is rarely a majority opposed to a government bill.

The President may appoint up to seven members of the Council of State, and remove or replace such appointed members. (See list of presidential appointees to the Council of State.) The following powers all require prior consultation with the Council of State, although the President need not take its advice:

The President is directly elected by secret ballot using the instant-runoff voting, the single-winner analogue of the Single Transferable Vote. Under the Presidential Elections Act, 1993 a candidate's election formally takes place in the form of a 'declaration' by the returning officer. Where more than one candidate is nominated, the election is 'adjourned' so that a ballot can take place, allowing the electors to choose between candidates. A Presidential election is held in time for the winner to take office the day after the end of the incumbent's seven-year term. In the event of premature vacancy, an election must be held within sixty days.

Only resident Irish citizens aged eighteen or more may vote; a 1983 bill to extend the right to resident British citizens was ruled unconstitutional.

Candidates must be Irish citizens and over 35 years old. However, there is a discrepancy between the English- and Irish-language texts of Article 12.4.1º. According to the English text, an eligible candidate "has reached his thirty-fifth year of age", whereas the Irish text has this as "ag a bhfuil cúig bliana tríochad slán" ("has completed his thirty-five years"). Because a person's thirty-fifth year of life begins on their thirty-fourth birthday, this means there is a year's difference between the minimum ages as stated in the two texts. Various proposals have been made to amend the Constitution so as to eliminate this discrepancy. At present, however, the Irish version of the subsection prevails in accordance with the rule stated in Article 25.5.4º. The current government has introduced the Thirty-fifth Amendment of the Constitution (Age of Eligibility for Election to the Office of President) Bill 2015 to reduce the age of candidacy from 35 to 21, which was put to referendum in May 2015, but the bill was heavily defeated, with approximately 73% of voters voting against reducing the age of eligibility.

Presidents can serve a maximum of two terms, consecutive or otherwise. They must be nominated by one of the following:
Where only one candidate is nominated, he or she is deemed elected without the need for a ballot. For this reason, where there is a consensus among political parties not to have a contest, the President may be 'elected' without the occurrence of an actual ballot. Since the establishment of the office this has occurred on six occasions.

The most recent presidential election was held on 27 October 2011.

There is no office of Vice President of Ireland. In the event of a premature vacancy a successor must be elected within sixty days. In a vacancy or where the President is unavailable, the duties and functions of the office are carried out by a Presidential Commission, consisting of the Chief Justice, the Ceann Comhairle (speaker) of the Dáil, and the Cathaoirleach (chairperson) of the Seanad. Routine functions, such as signing bills into law, have often been fulfilled by the Presidential Commission when the President is abroad on a state visit. The government's power to prevent the President leaving the state is relevant in aligning the diplomatic and legislative calendars.

Technically each president's term of office expires at midnight on the day before the new president's inauguration. Therefore, between midnight and the inauguration the following day the presidential duties and functions are carried out by the Presidential Commission. The constitution also empowers the Council of State, acting by a majority of its members, to "make such provision as to them may seem meet" for the exercise of the duties of the president in any contingency the constitution does not foresee. However, to date, it has never been necessary for the council to take up this role. Though an outgoing President of Ireland who has been re-elected is usually described in the media as "president" before the taking of the Declaration of Office, that is actually incorrect. The Irish Constitution makes it clear that a president's term of office expires on the day before the inauguration of their successor. In the interregnum period, the Presidential Commission acts as president, though given that it is usually for less than 11 hours no Presidential Commission has ever been called on to do anything in that period. Technically for that period the outgoing president is a "former" president and, if re-elected, "President-elect".

Vacancies in the presidency have occurred three times: on the death of Erskine Hamilton Childers in 1974, and on the resignations of Cearbhall Ó Dálaigh in 1976 and Mary Robinson in 1997.

The official residence of the President is Áras an Uachtaráin, located in the Phoenix Park in Dublin. The ninety-two room building formerly served as the 'out-of-season' residence of the Irish Lord Lieutenant and the residence of two of the three Irish Governors-General: Tim Healy and James McNeill. The President is normally referred to as 'President' or 'Uachtarán', rather than 'Mr/Madam President' or similar forms. The style used is normally "His Excellency/Her Excellency" (); sometimes people may orally address the President as 'Your Excellency' ( ), or simply 'President' ( (vocative case)). The Presidential Salute is taken from the National Anthem, "Amhrán na bhFiann". It consists of the first four bars followed by the last five, without lyrics.

The Constitution provides that the President of Ireland is inaugurated in a major public ceremony. The ceremony takes place on the day following the expiry of the term of office of the preceding President. No location is specified in the constitution, but all inaugurations have taken place in Saint Patrick's Hall in the State Apartments in Dublin Castle. The ceremony is transmitted live by national broadcaster RTÉ on its principal television and radio channels, typically from around 11 am. To highlight the significance of the event, all key figures in the executive (the Government of Ireland), the legislature (Oireachtas) and the judiciary attend, as do members of the diplomatic corps and other invited guests.

During the period of the Irish Free State (1922 to 1937), the Governor-General had been installed into office as the representative of the Crown in a low-key ceremony, twice in Leinster House (the seat of the Oireachtas), but in the case of the last Governor-General, Domhnall Ua Buachalla, in his brother's drawing room. By contrast, the Constitution of Ireland adopted in 1937, provided that the President of Ireland would be inaugurated in state in a major public ceremony.

Under the Constitution, in assuming office the President must subscribe to a formal declaration, made publicly and in the presence of members of both Houses of the Oireachtas, judges of the Supreme Court and the High Court, and other "public personages". The inauguration of the President takes place in St Patrick's Hall in Dublin Castle. The declaration is specified in Article 12.8:

To date every President has subscribed to the declaration in Irish. Erskine H. Childers, who never learnt Irish and spoke with a distinctive Oxbridge accent that made pronouncing Irish quite difficult, opted with some reluctance for the Irish version in 1973. Pictures of the event show Childers reading from an exceptionally large board where it had been written down phonetically for him.

In 1993 the United Nations Human Rights Committee expressed concern that, because of its religious language, the declaration amounts to a religious test for office. The Oireachtas Committee in 1998 recommended that the religious references be made optional.
Having taken the Declaration of Office, the new President traditionally delivers an address to the guests. Constitutionally all addresses or messages to 'the Nation' or to 'the Oireachtas' are supposed to have prior government approval. Some lawyers have questioned whether the speech at the inauguration should fall into the category requiring government approval. However, as it is impractical to get approval given that the new president is only president for a matter of moments before delivering the speech and so has not had a time to submit it, any constitutional questions as to its status are ignored.

Inauguration Day involves a lot of ritual and ceremonial. Until 1983 the morning saw the President-elect, accompanied by his spouse, escorted by the Presidential Motorcycle Escort to one of Dublin's cathedrals. If they were Catholic they were brought to St Mary's Pro-Cathedral for a Pontifical High Mass. If they were Church of Ireland, they were brought to St Patrick's Cathedral for a Divine Service. In the 1970s instead of separate denominational ceremonies a single ecumenical multi-faith service was held in the Cathedral of the faith of the President-elect. Some additional religious ceremonies also featured: President-elect Cearbhall Ó Dálaigh attended a prayer ceremony in a synagogue in Dublin to reflect his longstanding relationship with the Jewish Community in Ireland.
In 1983, to reduce the costs of the day in a period of economic retrenchment, the separate religious blessing ceremony was incorporated into the inauguration ceremony itself, with the President-elect blessed by representatives of the Roman Catholic Church, the Church of Ireland, the Presbyterian Church, Methodism, the Society of Friends, and the Jewish and Islamic faiths. This inter-faith service has featured in the inaugurations since 1983.

For the first inauguration in 1938 President-elect Douglas Hyde wore a morning suit, with black silk top hat. Morning suits continued to be a standard feature of Irish presidential inaugurations until 1997 when Mary McAleese, whose husband disliked wearing formal suits, abolished their use for inaugurations (and for all other presidential ceremonial). From then, guests were required to wear plain business suits, and judges were prohibited from wearing their distinctive wigs and gowns. Ambassadors were also discouraged from wearing national dress.

The President-elect (unless they are already a serving president, in which case they will already be living in the presidential residence) are usually driven to the inauguration from their private home. After the ceremony they are driven through the streets of Dublin to Áras an Uachtaráin, the official presidential residence, where they are welcomed by the Secretary-General to the President, the head of the presidential secretariat.

That evening, the Irish government hosts a reception in their honour in the State Apartments (the former Royal Apartments) in Dublin Castle. Whereas the dress code was formerly white tie affair, it is now more usually black tie.

The President can be removed from office in two ways, neither of which has ever been invoked. The Supreme Court, in a sitting of at least five judges, may find the President "permanently incapacitated", while the Oireachtas may remove the President for "stated misbehaviour". Either house of the Oireachtas may instigate the latter process by passing an impeachment resolution, provided at least thirty members move it and at least two thirds support it. The other house will then either investigate the stated charges or commission a body to do so; following which at least two thirds of members must agree both that the President is guilty and that the charges warrant removal.

As head of state of Ireland, the President receives the highest level of protection in the state. Áras an Uachtaráin is protected by armed guards from the Garda Síochána and Defence Forces at all times, and is encircled by security fencing and intrusion detection systems. At all times the President travels with an armed security detail in Ireland and overseas, which is provided by the Special Detective Unit (SDU), an elite wing of the Irish police force. Protection is increased if there is a known threat. The Presidential limousine is a Mercedes-Benz S-Class LWB. The Presidential Limousine is dark navy blue and carries the Presidential standard on the left front wing and the tricolour on the right front wing. When travelling the Presidential limousine is always accompanied by support cars (normally BMW 5 Series, Audi A6 and Volvo S60 driven by trained drivers from the SDU) and several Garda motorcycle outriders from the Garda Traffic Corps which form a protective convoy around the car.

The President-elect is usually escorted to and from the ceremony by the Presidential Motorcycle Escort ceremonial outriders. Until 1947 they were a cavalry mounted escort, wearing light blue hussar-style uniforms. However to save money the first Inter-Party Government replaced the Irish horses by Japanese motorbikes, which the then Minister for Defence believed would be "much more impressive."

At the presidential inauguration in 1945, alongside the mounted escort on horseback, President-elect Seán T. O'Kelly rode in the old state landau of Queen Alexandra the Queen Mother. The use of the state carriage was highly popular with crowds. However an accident with a later presidential carriage at the Royal Dublin Society Horse show led to the abolition of the carriage and its replacement by a Rolls-Royce Silver Wraith in 1947. The distinctive 1947 Rolls-Royce is still used to bring the President to and from the inauguration today.

The Presidential State Car is a 1947 Rolls-Royce Silver Wraith landaulette, which is used only for ceremonial occasions.

The President also has the full use of all Irish Air Corps aircraft at his/her disposal if so needed, including helicopters and private jets.

The office of President was established in 1937, in part as a replacement for the office of Governor-General that existed during the 1922–37 Irish Free State. The seven-year term of office of the President was inspired by that of the presidents of Weimar Germany. At the time the office was established critics warned that the post might lead to the emergence of a dictatorship. However, these fears were not borne out as successive Presidents played a limited, largely apolitical role in national affairs.

During the period of 1937 to 1949 it was unclear whether the Irish head of state was actually the President of Ireland or George VI, the king of Ireland. This period of confusion ended in 1949 when the state was declared to be a republic. The 1937 constitution did not mention the king; but, nor did it state that the president was head of state, saying rather that the president "shall take precedence over all other persons in the State". The president exercised some powers that could be exercised by heads of state, but, which could also be exercised by governors or governors-general, such as appointing the government and promulgating the law.

However, in 1936, George VI had been declared "King of Ireland" and, under the External Relations Act of the same year, it was this king who represented the state in its foreign affairs. Treaties, therefore, were signed in the name of the King of Ireland, who also accredited ambassadors and received the letters of credence of foreign diplomats. This role meant, in any case, that George VI was the Irish head of state in the eyes of foreign nations. The Republic of Ireland Act 1948, which came into force in April 1949, proclaimed a republic and transferred the role of representing the state abroad from the monarch to the president. No change was made to the constitution.

After the inaugural presidency of Douglas Hyde, who was an interparty nominee for the office, the nominees of the Fianna Fáil political party won every presidential election until 1990. The party traditionally used the nomination as a reward for its most senior and prominent members, such as party founder and longtime Taoiseach Éamon de Valera and European Commissioner Patrick Hillery. Most of its occupants to that time followed Hyde's precedent-setting conception of the presidency as a conservative, low-key institution that used its ceremonial prestige and few discretionary powers sparingly. In fact, the presidency was such a quiet position that Irish politicians sought to avoid contested presidential elections as often as possible, feeling that the attention such elections would bring to the office was an unnecessary distraction, and office-seekers facing economic austerity would often suggest the elimination of the office as a money-saving measure.

Despite the historical meekness of the presidency, however, it has been at the centre of some high-profile controversies. In particular, the fifth President, Cearbhall Ó Dálaigh, faced a contentious dispute with the government in 1976 over the signing of a bill declaring a state of emergency, which ended in Ó Dálaigh's resignation. His successor, Patrick Hillery, was also involved in a controversy in 1982, when then Taoiseach Garret FitzGerald requested a dissolution of the Dáil Éireann. Hillery was bombarded with phone calls from opposition members urging him to refuse the request, an action that Hillery saw as highly inappropriate interference with the President's constitutional role and resisted the political pressure.

The presidency began to be transformed in the 1990s. Hillery's conduct regarding the dissolution affair in 1982 came to light in 1990, imbuing the office with a new sense of dignity and stability. However, it was Hillery's successor, seventh President Mary Robinson, who ultimately revolutionized the presidency. The winner of an upset victory in the highly controversial election of 1990, Robinson was the Labour nominee, the first President to defeat Fianna Fáil in an election and the first female President. Upon election, however, Robinson took steps to de-politicize the office. She also sought to widen the scope of the presidency, developing new economic, political and cultural links between the state and other countries and cultures, especially those of the Irish diaspora. Robinson used the prestige of the office to activist ends, placing emphasis during her presidency on the needs of developing countries, linking the history of the Great Irish Famine to today's nutrition, poverty and policy issues, attempting to create a bridge of partnership between developed and developing countries.

After the 2018 presidential election the official salary or "personal remuneration" of the President will be €249,014. The incumbent, Michael D. Higgins, chooses to receive the same salary although he is entitled to a higher figure of €325,507. The President's total "emoluments and allowances" includes an additional €317,434 for expenses. The Office of the President's total budget estimate for 2017 was €3.9 million, of which €2.6 million was for pay and running costs, and the balance for the "President's Bounty" paid to centenarians on their hundredth birthday.

The salary was fixed at IR£5000 from 1938 to 1973, since when it has been calculated as 10% greater than that of the Chief Justice. After the post-2008 Irish economic downturn most public-sector workers took significant pay cuts, but the Constitution prohibited a reduction in the salary of the President and the judiciary during their terms of office, in order to prevent such a reduction being used by the government to apply political pressure on them. While a 2011 Constitutional amendment allows judges' pay to be cut, it did not extend to the President, although incumbent Mary McAleese offered to take a voluntary cut in solidarity.

The text of the Constitution of Ireland, as originally enacted in 1937, made reference in its Articles 2 and 3 to two geopolitical entities: a thirty-two county 'national territory' (i.e., the island of Ireland), and a twenty-six county 'state' formerly known as the Irish Free State. The implication behind the title 'President of Ireland' was that the President would function as the head of all Ireland. However, this implication was challenged by the Ulster Unionists and the United Kingdom of Great Britain and Northern Ireland which was the state internationally acknowledged as having jurisdiction over Northern Ireland. Articles 2 and 3 were substantially amended in consequence of the 1998 Good Friday Agreement.

Ireland in turn challenged the proclamation in the United Kingdom of Queen Elizabeth II in 1952 as '[Queen] of the United Kingdom of Great Britain and Northern Ireland'. The Irish government refused to attend royal functions as a result; for example, Patrick Hillery declined on Government advice to attend the wedding of the Prince of Wales to Lady Diana Spencer in 1981, to which he had been invited by Queen Elizabeth, just as Seán T. O'Kelly had declined on government advice to attend the 1953 Coronation Garden Party at the British Embassy in Dublin. Britain in turn insisted on referring to the President as 'President of the Republic of Ireland' or 'President of the Irish Republic'. Letters of Credence from Queen Elizabeth, on the British government's advice, appointing United Kingdom ambassadors to Ireland were not addressed to the 'President of Ireland' but to the President personally (for example: 'President Hillery').

The naming dispute and consequent avoidance of contact at head of state level has gradually thawed since 1990. President Robinson (1990–97) chose unilaterally to break the taboo by regularly visiting the United Kingdom for public functions, frequently in connection with Anglo-Irish Relations or to visit the Irish emigrant community in Great Britain. In another breaking of precedent, she accepted an invitation to Buckingham Palace by Queen Elizabeth II. Palace accreditation supplied to journalists referred to the "visit of the President of Ireland". Between 1990 and 2010, both Robinson and her successor President McAleese (1997–2011) visited the Palace on numerous occasions, while senior members of the British royal family – The Prince of Wales, The Duke of York, The Earl of Wessex and The Duke of Edinburgh - all visited both Presidents of Ireland at Áras an Uachtaráin. The Presidents also attended functions with The Princess Royal. President Robinson jointly hosted a reception with the Queen at St. James's Palace, London, in 1995, to commemorate the one hundred and fiftieth anniversary of the foundation of the Queen's Colleges in 1845 (the Queen's Colleges are now known as The Queen's University of Belfast, University College, Cork, and National University of Ireland, Galway). These contacts eventually led to a state visit of Queen Elizabeth to Ireland in 2011.

Though the President's title implicitly asserted authority in Northern Ireland, in reality the Irish President needed government permission to visit there. (The Constitution of Ireland in Article 3 explicitly stated that "[p]ending the re-integration of the national territory" the authority of the Irish state did not extend to Northern Ireland. Presidents prior to the presidency of Mary Robinson were regularly refused permission by the Irish government to visit Northern Ireland.)

However, since the 1990s and in particular since the Good Friday Agreement of 1998, the president has regularly visited Northern Ireland. President McAleese, who was the first President to have been born in Northern Ireland, continued on from President Robinson in this regard. In a sign of the warmth of modern British-Irish relations, she has even been warmly welcomed by most leading unionists. At the funeral for a child murdered by the Real IRA in Omagh she symbolically walked up the main aisle of the church hand-in-hand with the Ulster Unionist Party leader and then First Minister of Northern Ireland, David Trimble. But in other instances, Mary McAleese had been criticised for certain comments, such as a reference to the way in which Protestant children in Northern Ireland had been brought up to hate Catholics just as German children had been encouraged to hate Jews under the Nazi regime, on 27 January 2005, following her attendance at the ceremony commemorating the sixtieth anniversary of the liberation of Auschwitz concentration camp. These remarks caused outrage among Northern Ireland's unionist politicians, and McAleese later apologised and conceded that her statement had been unbalanced.

There have been many suggestions for reforming the office of President over the years. In 1996, the Constitutional Review Group recommended that the office of President should remain largely unchanged. However, it suggested that the Constitution should be amended to explicitly declare the President to be head of state (at present that term does not appear in the text), and that consideration be given to the introduction of a constructive vote of no confidence system in the Dáil, along the lines of that in Germany. If this system were introduced then the power of the President to refuse a Dáil dissolution would be largely redundant and could be taken away. The All-party Oireachtas Committee on the Constitution's 1998 Report made similar recommendations.

In an October 2009 poll, concerning support for various potential candidates in the 2011 presidential election conducted by the "Sunday Independent", a "significant number" of people were said to feel that the presidency is a waste of money and should be abolished.

The functions of the President were exercised by the Presidential Commission from the coming into force of the Constitution on 29 December 1937 until the election of Douglas Hyde in 1938, and during the vacancies of 1974, 1976, and 1997.

Currently, there are two living former presidents: Mary Robinson and Mary McAleese. Former presidents who are able and willing to act are members of the Council of State.






</doc>
<doc id="24677" url="https://en.wikipedia.org/wiki?curid=24677" title="Premier of Queensland">
Premier of Queensland

The Premier of Queensland is the head of government in the Australian state of Queensland.

By convention the Premier is the leader of the party with a parliamentary majority in the unicameral Legislative Assembly of Queensland. The Premier is appointed by the Governor of Queensland.

The incumbent Premier of Queensland since the 2015 election is Annastacia Palaszczuk of the Labor Party.

Under section 42 of the Constitution of Queensland the Premier and other members of Cabinet are appointed by the Governor and are collectively responsible to Parliament. The text of the Constitution assigns to the Premier certain powers, such as the power to assign roles (s. 25) to Assistant Ministers (formerly known as Parliamentary Secretaries), and to appoint Ministers as acting Ministers (s. 45) for a period of 14 days.

In practice, under the conventions of the Westminster System followed in Queensland, the Premier's power is derived from two sources: command of a majority in the Legislative Assembly, and the Premier's role as chair of Cabinet, determining the appointment and roles of Ministers. Although ministerial appointments are the prerogative of the Governor of Queensland, in normal circumstances the Governor will make these appointments under the "advice" (in reality, direction) of the Premier.

Immediately following an election for the Legislative Assembly, the Governor will call on the leader of the party which commands a majority in the Legislative Assembly, and ask them to commission a government. A re-elected government will be resworn, with adjustments to the ministry as determined by the Premier.

The Premier has an office in the Executive Annexe of Parliament House, Brisbane, which is normally used while Parliament is sitting. At other times the Premier's ministerial office is in 1 William Street, which is across the road from the Executive Annexe.

Before the 1890s, there was no developed party system in Queensland. Political affiliation labels before that time indicate a general tendency only. Before the end of the first decade of the twentieth century, political parties were more akin to parliamentary factions, and were fluid, informal and disorganised by modern standards.

, six former premiers are alive, the oldest being Russell Cooper (1989, born 1941). The most recent premier to die was Wayne Goss (1951–2014), on 10 November 2014.



</doc>
<doc id="24678" url="https://en.wikipedia.org/wiki?curid=24678" title="Premier of South Australia">
Premier of South Australia

The Premier of South Australia is the head of government in the state of South Australia, Australia. The Government of South Australia follows the Westminster system, with a Parliament of South Australia acting as the legislature. The Premier is appointed by the Governor of South Australia, and by modern convention holds office by virtue of his or her ability to command the support of a majority of members of the lower house of Parliament, the House of Assembly.

Steven Marshall is the current Premier, having served since 19 March 2018.

Before the 1890s when there was no formal party system in South Australia, MPs tended to have historical liberal or conservative beliefs. The liberals dominated government from the 1893 election to 1905 election with the support of the South Australian United Labor Party, with the conservatives mostly in opposition. Labor took government with the support of eight dissident liberals in 1905 when Labor won the most seats for the first time. The rise of Labor saw non-Labor politics start to merge into various party incarnations.

The two independent conservative parties, the Australasian National League (formerly National Defence League) and the Farmers and Producers Political Union merged with the Liberal and Democratic Union to become the Liberal Union in 1910. Labor formed South Australia's first majority government after winning the 1910 state election, triggering the merger. The 1910 election came two weeks after federal Labor formed Australia's first elected majority government at the 1910 federal election.

No "Country" or rural conservative parties emerged as serious long-term forces in South Australian state politics, often folding into the main non-Labor party.

The first six Governors of South Australia oversaw governance from proclamation in 1836 until self-government and an elected Parliament of South Australia was enacted in the year prior to the inaugural 1857 election.

There are seven living former premiers, the oldest being Steele Hall (1968–70, born 1928). The most recent premier to die was John Bannon (Premier 1982–1992) on 13 December 2015.

In the following timeline, the legend includes the Liberal and Democratic Union, the Liberal Union and the Liberal Federation represented as "Liberal (pre-1979)". The Liberal Party is represented as "Liberal (post-1979)" only. The grey area represents the duration of Playmander electoral malapportionment, beginning in 1936, in effect until the 1970 election.





</doc>
<doc id="24680" url="https://en.wikipedia.org/wiki?curid=24680" title="Premier of Western Australia">
Premier of Western Australia

The Premier of Western Australia is the head of the executive branch of government in the Australian state of Western Australia. The Premier has similar functions in Western Australia to those performed by the Prime Minister of Australia at the national level, subject to the different Constitutions.

The incumbent Premier of Western Australia is Mark McGowan who won the 2017 state election and was sworn in on 17 March 2017 by Governor Kerry Sanderson as the 30th Premier of Western Australia.

The premier must be a member of one of the two Houses of the Parliament of Western Australia; and by convention the premier is a member of the lower house, the Legislative Assembly. He or she is appointed by the governor on the advice of the lower house, and must resign if he or she loses the support of the majority of that house. Consequently, the premier is almost always the leader of the political party or coalition of parties with the majority of seats in the lower house.

The office of premier of Western Australia was first formed in 1890, after Western Australia was officially granted responsible government by Britain in 1889. The Constitution of Western Australia, does not explicitly provide for a premier, and the office was not formally listed as one of the executive offices until the appointment of Ross McLarty in 1947. Nonetheless, John Forrest immediately adopted the title on taking office as first premier of Western Australia in 1890, and it has been used ever since.

John Forrest was the only premier of Western Australia as a self-governing colony. Following the Federation of Australia in 1901, Western Australia became an Australian state and the responsibilities of the office of premier were diminished.

Party politics began in Western Australia with the rise of the Labor party in 1901. By 1904, the party system was entrenched in Western Australian politics. Since then the premiers have been associated with political parties.

Western Australia's constitution contains nothing to preclude the premier being a member of the upper house, the Western Australian Legislative Council. Historically and by convention, however, the premier is a member of the Assembly. The only exception has been Hal Colebatch, a member of the Legislative Council who accepted the premiership in April 1919 on the understanding that an Assembly seat would be found for him, only to resign a month later when no seat could be found.

During the economic boom of the 1980s, the Western Australian government became closely involved with a number of large businesses. A succession of deals were made between the government and businesses, and these ultimately caused great losses for the state. A subsequent royal commission found evidence of widespread corruption. Three former premiers were found to have acted improperly and two of them, Ray O'Connor and Brian Burke, were jailed. This scandal became popularly known as WA Inc.

As of , seven former premiers are alive, the oldest being Peter Dowding (born 1943), who served from 1988 to 1990. The most recent premier to die was Ray O'Connor, on 25 February 2013, aged 86.


 The only premier to serve in the upper house while premier was Sir Hal Colebatch, who was elected by the Nationalist Party to fill the vacancy presented by the resignation of Henry Lefroy, on the condition that a seat in the lower house would be found for him. He served as premier for a month before resigning after no seat could be found.<br>



</doc>
<doc id="24681" url="https://en.wikipedia.org/wiki?curid=24681" title="Pigeonhole sort">
Pigeonhole sort

Pigeonhole sorting is a sorting algorithm that is suitable for sorting lists of elements where the number of elements ("n") and the length of the range of possible key values ("N") are approximately the same. It requires O("n" + "N") time. It is similar to counting sort, but differs in that it "moves items twice: once to the bucket array and again to the final destination [whereas] counting sort builds an auxiliary array then uses the array to compute each item's final destination and move the item there."

The pigeonhole algorithm works as follows:

Suppose one were sorting these value pairs by their first element:


For each value between 3 and 8 we set up a pigeonhole, then move each element to its pigeonhole:


The pigeonhole array is then iterated over in order, and the elements are moved back to the original list.

The difference between pigeonhole sort and counting sort is that in counting sort, the auxiliary array does not contain lists of input elements, only counts:


Using this information, one could perform a series of exchanges on the input array that would put it in order, moving items only once.

For arrays where "N" is much larger than "n", bucket sort is a generalization that is more efficient in space and time.



</doc>
<doc id="24683" url="https://en.wikipedia.org/wiki?curid=24683" title="Pope Innocent XIII">
Pope Innocent XIII

Pope Innocent XIII (; 13 May 1655 – 7 March 1724), born as Michelangelo dei Conti, was head of the Catholic Church and ruler of the Papal States from 8 May 1721 to his death in 1724. He is the last pope to date to take the pontifical name of "Innocent" upon his election.

Pope Innocent XIII was reform-oriented, and he imposed new standards of frugality, abolishing excessive spending. He took steps to finally end the practice of nepotism by issuing a decree which forbade his successors from granting land, offices or income to any relatives - something opposed by many cardinals who hoped that they might become pope and benefit their families.

Michelangelo dei Conti was born on 13 May 1655 in Poli, near Rome as the son of Carlo II, Duke of Poli, and Isabella d'Monti. Like Pope Innocent III (1198–1216), Pope Gregory IX (1227–1241) and Pope Alexander IV (1254–1261), he was a member of the land-owning family of the Conti, who held the titles of counts and dukes of Segni. He included the family crest in his pontifical coats of arms.

Conti commenced his studies in Ancona and then with the Jesuits in Rome at the Collegio Romano and then later at La Sapienza University. After he received his doctorate in canon law and civil law, he was ordained to the priesthood. Conti also served as the Referendary of the Apostolic Signatura in 1691, later to be appointed as the Governor of Ascoli until 1692. Conti was also the Governor of Campagna and Marittima from 1692 to 1693 and the Governor of Viterbo from 1693 to 1695.

Pope Innocent XII selected Conti as the Titular Archbishop of Tarso on 13 June 1695 and he received his episcopal consecration on 16 June 1695 in Rome. Conti was also the nuncio to both Switzerland and Portugal.

On 7 June 1706, Conti was elevated to the cardinalate and was made the Cardinal-Priest of Santi Quirico e Giulitta under Pope Clement XI (1700–21). His appointment came about as the replacement of Gabriele Filippucci who declined the cardinalate. He would receive his titular church on 23 February 1711. From 1697 to 1710 he acted as papal nuncio to the Kingdom of Portugal, where he is believed to have formed those unfavourable impressions of the Jesuits which afterwards influenced his conduct towards them. While in Portugal, he was witness to Father Bartolomeu de Gusmão's early aerostat experiments.

He was also transferred to Osimo as its archbishop in 1709 and was later translated one last time to Viterbo e Toscanella in 1712. He also served as Camerlengo of the Sacred College of Cardinals from 1716 to 1717 and resigned his position in his diocese due to illness in 1719.

After the death of Pope Clement XI in 1721, a conclave was called to choose a new pope. It took 75 ballots just to reach a decision and choose Conti as the successor of Clement XI. After all candidates seemed to slip, support turned to Conti. The curial factions also turned their attention to him. In the morning of 8 May 1721, he was elected. He chose the name of Innocent XIII in honour of Pope Innocent III. On the following 18 May, he was solemnly crowned by the protodeacon, Cardinal Benedetto Pamphili.

In 1721 his high reputation for ability, learning, purity, and a kindly disposition secured his election to succeed Clement XI as Pope Innocent XIII. His pontificate was prosperous, but comparatively uneventful. He held two consistories that saw three new cardinals elevated on 16 June 1721 and 16 July 1721.

The Chinese Rites controversy that started under his predecessor continued during his reign. Innocent XIII prohibited the Jesuits from prosecuting their mission in China, and ordered that no new members should be received into the order. This indication of his sympathies encouraged some French bishops to approach him with a petition for the recall of the bull "Unigenitus" by which Jansenism had been condemned; the request, however, was peremptorily denied.

The pope also assisted the Venetians in their struggles and also assisted Malta in its struggles against the Turks.

Innocent XIII, like his predecessor, showed much favour to James Francis Edward Stuart, the "Old Pretender" to the British throne and liberally supported him. The pope's cousin, Francesco Maria Conti, from Siena, became chamberlain of James' little court in the Roman Muti Palace.

Innocent XIII held two consistories in which he named three cardinals. One of those new cardinals was his own brother, Bernardo Maria.

Innocent XIII beatified three individuals during his pontificate: John of Nepomuk (31 May 1721), Dalmazio Moner (13 August 1721), and Andrea dei Conti (11 December 1723).

In 1722, he named Saint Isidore of Seville as a Doctor of the Church.

Innocent XIII fell ill in 1724. He was tormented by a hernia of which he spoke to nobody but his valet. At one point, it had burst and caused inflammation and fever. Innocent XIII asked for the last rites, made his profession of faith, and died on 7 March 1724, at the age of 68. His pontificate was unremarkable, given that he was hampered by physical suffering. He was interred in the grottoes at Saint Peter's Basilica.

In 2005 upon the occasion of the 350 years since the birth of the late pontiff, the citizens in the late pope's village of birth asked the Holy See to introduce the cause of beatification for Innocent XIII.



</doc>
<doc id="24684" url="https://en.wikipedia.org/wiki?curid=24684" title="Pope Julius I">
Pope Julius I

Pope Julius I (died 12 April 352) was Pope of the Catholic Church from 6 February 337 to his death in 352. He was notable for asserting the authority of the pope over the Arian Eastern bishops, and also for setting the date of 25 December for celebrating the Nativity.

Julius I was a native of Rome and was chosen as successor of Pope Mark after the Roman see had been vacant for four months. He is chiefly known by the part he took in the Arian controversy. After the followers of Eusebius of Nicomedia, who had become the archbishop of Constantinople, renewed their deposition of Athanasius at a synod held in Antioch in 341, they resolved to send delegates to Constans, Emperor of the West, and also to Julius, setting forth the grounds on which they had proceeded. Julius, after expressing an opinion favourable to Athanasius, adroitly invited both parties to lay the case before a synod to be presided over by himself. This proposal, however, the Arian Eastern bishops declined to accept.

On this second banishment from Alexandria, Athanasius came to Rome, and was recognised as a regular bishop by the synod presided over by Julius in 342. Julius sent a letter to the Eastern bishops that is an early instance of the claims of primacy for the bishop of Rome. Even if Athanasius and his companions were somewhat to blame, the letter runs, the Alexandrian Church should first have written to the pope. "Can you be ignorant," writes Julius, "that this is the custom, that we should be written to first, so that from here what is just may be defined" (Epistle of Julius to Antioch, c. xxii).

It was through the influence of Julius that, at a later date, the council of Sardica in Illyria was held, which was attended only by seventy-six Eastern bishops, who speedily withdrew to Philippopolis and deposed Julius at the council of Philippopolis, along with Athanasius and others. The three hundred Western bishops who remained, confirmed the previous decisions of the Roman synod and issues a number of decrees regarding church discipline. The first canon forbid the transfer of bishops from one see to another, for if frequently made, it was seen to encourage covetousness and ambition.

By its 3rd, 4th, and 5th decrees relating to the rights of revision claimed by Julius, the council of Sardica perceptibly helped forward the claims of the Bishop of Rome. Julius built several basilicas and churches in Rome and died there 12 April 352. He was succeeded by Liberius.

Julius is considered a saint in the Catholic Church, with his feast day on 12 April.

Julius is also credited with splitting the birth of Jesus into two distinct celebrations in 345: Epiphany stayed on the traditional date, and Nativity was added on 25th of December.




</doc>
<doc id="24685" url="https://en.wikipedia.org/wiki?curid=24685" title="Pope Julius III">
Pope Julius III

Pope Julius III (; 10 September 1487 – 23 March 1555), born Giovanni Maria Ciocchi del Monte, was head of the Catholic Church and ruler of the Papal States from 7 February 1550 to his death in 1555.

After a career as a distinguished and effective diplomat, he was elected to the papacy as a compromise candidate after the death of Paul III. As pope he made only reluctant and short-lived attempts at reform, mostly devoting himself to a life of personal pleasure. His reputation, and that of the Catholic Church, were greatly harmed by his scandal-ridden relationship with his adopted nephew.

Giovanni Maria Ciocchi del Monte was born in Monte San Savino. He was educated by the humanist Raffaele Brandolini Lippo, and later studied law at Perugia and Siena. During his career, he distinguished himself as a brilliant canonist rather than as a theologian.

Del Monte was the nephew of Antonio Maria Ciocchi del Monte, Archbishop of Manfredonia (1506–1511). When his uncle exchanged this see for a position as a Cardinal in 1511, Giovanni Maria Ciocchi del Monte succeeded in Manfredonia in 1512. In 1520, del Monte also became Bishop of Pavia. Popular for his affable manner and respected for his administrative skills, he was twice Governor of Rome and was entrusted by the papal curia with several duties. At the Sack of Rome (1527) he was one of the hostages given by Pope Clement VII to the Emperor's forces, and barely escaped execution. Pope Paul III made him Cardinal-bishop of Palestrina in 1536 and employed him in several important legations, notably as papal legate and first president of the Council of Trent (1545/47) and then at Bologna (1547/48).

Paul III died on 10 November 1549, and in the ensuing conclave the forty-eight cardinals were divided into three factions: of the primary factions, the Imperial faction wished to see the Council of Trent reconvened, the French faction wished to see it dropped. The Farnese faction, loyal to the family of the previous Pope, supported the election of Paul III's grandson, Cardinal Alessandro Farnese, and also the family's claim to the Duchy of Parma, which was contested by Emperor Charles V.

Neither the French nor the Germans favoured del Monte, and the Emperor had expressly excluded him from the list of acceptable candidates, but the French were able to block the other two factions, allowing del Monte to promote himself as a compromise candidate and be elected on 7 February 1550. Ottavio Farnese, whose support had been crucial to the election, was immediately confirmed as Duke of Parma.

At the start of his reign Julius had seriously desired to bring about a reform of the Catholic Church and to reconvene the Council of Trent, but very little was actually achieved during his five years in office. In 1551, at the request of Emperor Charles V, he consented to the reopening of the council of Trent and entered into a league against the duke of Parma and Henry II of France (1547–59), causing the War of Parma. However, Julius soon came to terms with the duke and France and in 1553 suspended the meetings of the council.

Julius increasingly contented himself with Italian politics and retired to his luxurious palace at the Villa Giulia, which he had built for himself close to the Porta del Popolo. From there he passed the time in comfort, emerging from time to time to make timid efforts to reform the Church through the reestablishment of the reform commissions. He was a friend of the Jesuits, to whom he granted a fresh confirmation in 1550; and through the Papal bull, "Dum sollicita" of August 1552, he founded the Collegium Germanicum, and granted an annual income.

During his pontificate, Catholicism was restored in England under Queen Mary in 1553. Julius sent Cardinal Reginald Pole as legate with powers that he could use at his discretion to help the restoration succeed. In February 1555, an envoy was dispatched from the English parliament to Julius to inform him of the country's formal submission, but the pope died before the envoy reached Rome.

Shortly before his death, Julius dispatched Cardinal Giovanni Morone to represent the interests of the Holy See at the Peace of Augsburg.

Julius' papacy was marked by scandals, the most notable of which is centered around the pope's adoptive nephew, Innocenzo Ciocchi Del Monte. Innocenzo del Monte was a teenaged beggar found in the streets of Parma who was hired by the family as a lowly hall boy in their primary residence, the boy's age being variously given as 14, 15 or 17 years. After the elevation of Julius to the papacy, Innocenzo Del Monte was adopted into the family by the pope's brother and, by Julius, was then promptly created cardinal-nephew. Julius showered his favourite with benefices, including the "commendatario" of the abbeys of Mont Saint-Michel in Normandy and Saint Zeno in Verona, and, later, of the abbeys of Saint Saba, Miramondo, Grottaferrata and Frascati, among others. As rumours began to circle about the particular relationship between the pope and his adoptive nephew, Julius refused to take advice. The cardinals Reginald Pole and Giovanni Carafa warned the pope of the "evil suppositions to which the elevation of a fatherless young man would give rise".

Poet Joachim du Bellay, who lived in Rome through this period in the retinue of his relative, Cardinal Jean du Bellay, expressed his scandalized opinion of Julius in two sonnets in his series Les regrets (1558), hating to see, he wrote, "a Ganymede with the red hat on his head". The courtier and poet Girolamo Muzio in a letter of 1550 to Ferrante Gonzaga, governor of Milan, wrote: "They write many bad things about this new pope; that he is vicious, proud, and odd in the head", and the Pope's enemies made capital of the scandal, Thomas Beard, in the "Theatre of God's judgement" (1597) saying it was Julius' "custome ... to promote none to ecclesiastical livings, save only his buggerers”. In Italy it was said that Julius showed the impatience of a "lover awaiting a mistress" while awaiting Innocenzo's arrival in Rome and boasted of the boy's prowess in bed, while the Venetian ambassador reported that Innocenzo Del Monte shared the pope's bed "as if he [Innocenzo] were his [Julius'] own son or grandson." "The charitably-disposed told themselves the boy might after all be simply his bastard son."

Despite the damage which the scandal was inflicting on the church, it was not until after Julius' death in 1555 that anything could be done to curb Innocenzo's visibility. He underwent temporary banishment following the murder of two men who had insulted him, and then again following the rape of two women. He tried to use his connections in the College of Cardinals to plead his cause but his influence waned and he died in obscurity. He was buried in Rome in the Del Monte family chapel. One outcome of the cardinal-nephew scandal, however, was the upgrading of the position of Papal Secretary of State, as the incumbent had to take over the duties Innocenzo Del Monte was unfit to perform: the Secretary of State eventually replaced the cardinal-nephew as the most important official of the Holy See.

The pope's lack of interest in political or ecclesiastical affairs caused dismay among his contemporaries. He spent the bulk of his time, and a great deal of papal money, on entertainments at the Villa Giulia, created for him by Vignola, but more significant and lasting was his patronage of the great Renaissance composer Giovanni Pierluigi da Palestrina, whom he brought to Rome as his "maestro di cappella", Giorgio Vasari, who supervised the design of the Villa Giulia, and Michelangelo, who worked there.

In the novel "Q" by Luther Blissett, Julius appears toward the end of the book as a moderate cardinal favouring religious tolerance, in the upheavals caused by the Reformation and the Roman Church's response during the 16th century. His election as pope and the subsequent unleashing of the Inquisition form the last chapters of the novel.






</doc>
<doc id="24686" url="https://en.wikipedia.org/wiki?curid=24686" title="Pope Eugene I">
Pope Eugene I

Pope Eugene I (d. 2 June 657), also known as Eugenius I, was Pope from 10 August 654 to his death in 657. He was a native of Rome, born to one Rufinianus.

In June 653, in the midst of a dispute with Byzantine Emperor Constans II over Monothelitism (the belief that Jesus had that only a single, divine will), Pope Martin I was seized and carried to Constantinople and subsequently exiled to Cherson in the Crimea. Initially, in the pontiff's absence, the church was probably governed by the archpriest, archdeacon and the primicerius of the notaries. Over a year later, and with no sign of Martin's return, Eugene was chosen to succeed. If the emperor expected Eugene to take a different approach from that of his predecessor, he was disappointed. 

Little is known of Pope Eugene's early life other than that he was a Roman from the Aventine and was known for his holiness, gentleness, and charity. He had been a cleric from his youth and held various positions within the Church of Rome.

On the banishment of Pope Martin I by Byzantine Emperor Constans II, he showed greater deference than his predecessor to the emperor's wishes and made no public stand against the Monothelitism of the patriarchs of Constantinople.

Martin I was carried off from Rome on 18 June 653 and was kept in exile until his death in September 655. Little is known about what happened in Rome after Pope Martin's departure, but it was typical in those days for the Holy See to be governed by the archpriest and archdeacon.

After a year and two months, a successor was found to Martin in Eugene.

Almost immediately after his election, Eugene was forced to deal with the heresy of Monothelitism, i.e., that Christ had only one will.

One of the first acts of the new pope was to send papal legates to Constantinople with letters to Emperor Constans II informing him of his election and professing his faith. The legates unfortunately allowed themselves to be deceived, or bribed, and brought back a synodical letter from Patriarch Peter of Constantinople (656–666), while the emperor's envoy, who accompanied them, brought offerings for St. Peter and a request from the emperor that the pope would enter into communion with the Patriarch of Constantinople. Peter's letter proved to be written in a difficult and obscure style and avoided making any specific declaration as to the number of "wills or operations" in Christ. When its contents were read to the clergy and people in the church of St. Mary Major in 656, they not only rejected the letter with indignation, but would not allow the pope to leave the basilica until he had promised that he would not on any account accept it.

So furious were the Byzantine officials at this harsh rejection of the wishes of their emperor and patriarch that they threatened to roast Eugene, just as they had roasted Pope Martin I. Eugene's persecution was averted by the ensuing conquest of the Muslims, who took Rhodes in 654 and defeated Constans himself in the naval battle of Phoenix (655).

It was almost certainly this pope who received the youthful St. Wilfrid on the occasion of his first visit to Rome (c. 654). At Rome he gained the affection of Archdeacon Boniface, a counsellor of the apostolic pope, who presented him to his master. Eugene "placed his blessed hand on the head of the youthful servant of God, prayed for him, and blessed him." Nothing more is known of Eugene except that he consecrated twenty-one bishops for different parts of the world, and that he was buried in St. Peter's Basilica.

He died in 657 and was acclaimed a saint, his day being the 2nd of June, although, according to Anastasius, he died on the 1st of that month.



Attribution



</doc>
<doc id="24687" url="https://en.wikipedia.org/wiki?curid=24687" title="Pope Eugene II">
Pope Eugene II

Pope Eugene II (; died 27 August 827) was Pope from June 6, 824 to his death in 827. A native of Rome, he was chosen to succeed Paschal I. Another candidate, Zinzinnus, was proposed by the plebeian faction, and the presence of Lothair I, son of the Frankish emperor Louis the Pious, was necessary in order to maintain the authority of the new pope. Lothair took advantage of this opportunity to redress many abuses in the papal administration, to vest the election of the pope in the nobles, and to confirm the statute that no pope should be consecrated until his election had the approval of the Frankish emperor.

Pope Eugene convened a council at Rome in 826 to address matters of church discipline. The practice of simony was condemned and untrained clergy were to be suspended until they had improved their knowledge to carry out their sacred duties. It was decreed that schools were to be established at cathedral churches and other places to give instruction in sacred and secular literature. 

He was elected pope on 6 June 824, after the death of Paschal I. The late pope had attempted to curb the rapidly increasing power of the Roman nobility, who had turned for support to the Franks to strengthen their positions against him. When Paschal died, these nobles made strenuous efforts to replace him with a candidate of their own. The clergy put forward a candidate likely to continue the policy of Paschal. However, even though the Roman Council of 769 under Stephen IV had decreed that the nobles had no right to a real share in a papal election, the nobles were successful in securing the consecration of Eugene, who was archpriest of St Sabina on the Aventine. Eugene candidacy was endorsed by Abbot Walla, who was then in Rome and served as a councilor to both the current emperor and his late father.

In earlier editions of the "Liber Pontificalis" Eugene is said to have been the son of Boemund, but in the more recent and more accurate editions, his father's name is not given. While archpriest of the Roman Church, he is credited with having fulfilled most conscientiously the duties of his position. After he became pope, he beautified his ancient church of St. Sabina with mosaics and metalwork bearing his name that were still intact as late as the 16th century. Eugene is described by his biographer as simple and humble, learned and eloquent, handsome and generous, a lover of peace, and wholly occupied with the thought of doing what was pleasing to God.

The election of Eugene II was a triumph for the Franks, and they subsequently resolved to improve their position. Emperor Louis the Pious accordingly sent his son Lothair to Rome to strengthen the Frankish influence. The Roman nobles who had been banished during the preceding reign and fled to France were recalled, and their property was restored to them. A "Constitutio Romana" was then agreed upon between the pope and the emperor in 824 which advanced the imperial pretensions in the city of Rome, but also checked the power of the nobles. This constitution included the statute that no pope should be consecrated until his election had the approval of the Frankish emperor. It decreed that those who were under the special protection of the pope or emperor were to be inviolable, and that church property not be plundered after the death of a pope.

Seemingly before Lothair left Rome, there arrived ambassadors from Emperor Louis and from the Greeks concerning the image question. At first the Eastern Roman Emperor Michael II showed himself tolerant towards the image-worshippers, and their great champion, Theodore the Studite, wrote to him to exhort him "to unite us [the Church of Constantinople] to the head of the Churches of God, Rome, and through it with the three Patriarchs" and to refer any doubtful points to the decision of Old Rome in accordance with ancient custom. But Michael soon forgot his tolerance, bitterly persecuted the image worshippers, and endeavoured to secure the co-operation of Louis the Pious. He also sent envoys to the pope to consult him on certain points connected with the worship of images. Before taking any steps to meet the wishes of Michael, Louis asked the pope's permission for a number of his bishops to assemble and make a selection of passages from the Fathers to elucidate the question that the Greeks had put before them. The leave was granted, but the bishops who met at Paris in 825 were incompetent for the task. Their collection of extracts from the Fathers was a mass of confused and ill-digested lore, and both their conclusions and the letters they wished the pope to forward to the Greeks were based on a complete misunderstanding of the decrees of the Second Council of Nicaea. Their labours do not appear to have accomplished much; nothing is known of the result of their researches.

In 826 Eugene held an important council at Rome of 62 bishops, in which 38 disciplinary decrees were issued. The council passed several enactments for the restoration of church discipline, and took measures for the foundation of schools or chapters. The decrees are noteworthy as showing that Eugene had at heart the advancement of learning. Not only were ignorant bishops and priests to be suspended till they had acquired sufficient learning to perform their sacred duties, but it was decreed that, as in some localities there were neither masters nor zeal for learning, masters were to be attached to the episcopal palaces, cathedral churches and other places to give instruction in sacred and polite literature. It also ruled against priests wearing secular dress or engaging in secular occupations. Simony was forbidden. Eugene also adopted various provisions for the care of the poor, widows and orphans, and on that account received the name of "father of the people". 

To help in the work of the conversion of the North, Eugene wrote commending St. Ansgar, the Apostle of the Scandinavians, and his companions "to all the sons of the Catholic Church". Coins of this pope are extant bearing his name and that of Emperor Louis.

He died on 27 August 827. It is supposed that he was buried in St. Peter's in accordance with the custom of the time, even though there is no documentary record to confirm it.




</doc>
<doc id="24688" url="https://en.wikipedia.org/wiki?curid=24688" title="Pope Eugene III">
Pope Eugene III

Pope Eugene III (; c. 1080 – 8 July 1153), born Bernardo Pignatelli, called Bernardo da Pisa, was Pope from 15 February 1145 to his death in 1153. He was the first Cistercian to become Pope. In response to the fall of Edessa to the Muslims in 1144, Eugene proclaimed the Second Crusade. The crusade failed to recapture Edessa, which was the first of many failures by the Christians in the crusades to recapture lands won in the First Crusade.

He was beatified on 28 December 1872 by Pope Pius IX on the account of his sanctity.

Bernardo was born in the vicinity of Pisa. Little is known about his origins and family except that he was son of a certain Godius. From the 16th century he is commonly identified as member of the family of Paganelli di Montemagno, which belonged to the Pisan aristocracy, but this has not been proven and contradicts earlier testimonies that suggest he was a man of rather humble origins. In 1106 he was a canon of the cathedral chapter in Pisa and from 1115 is attested as subdeacon. 1133–1138 he acted as "vicedominus" of the archdiocese of Pisa.

Between May 1134 and February 1137 he was ordained to the priesthood by Pope Innocent II, who resided at that time in Pisa. Under the influence of Bernard of Clairvaux he entered the Cistercian Order in the monastery of Clairvaux in 1138. A year later he returned to Italy as leader of the Cistercian community in Scandriglia. In Autumn 1140, Pope Innocent II named him abbot of the monastery of S. Anastasio alle Tre Fontane outside Rome. Some chronicles indicate that he was also elevated to the College of Cardinals, but these testimonies probably resulted from a confusion because Bernardo is not attested as cardinal in any document and from the letter of Bernard of Clairvaux addressed to the cardinals shortly after his election clearly appears that he was not a cardinal.

Bernardo was elected pope on 15 February 1145, the same day as the death of his predecessor Lucius III who had unwisely decided to take the offensive against the Roman Senate and was killed by a "heavy stone" thrown at him during an attack on the Capitol. He took the pontifical name of "Eugene III". He was "a simple character, gentle and retiring - not at all, men thought, the material of which Popes are made". He owed his elevation partly to the fact that no one was eager to accept an office the duties of which were at the time so difficult and dangerous and because the election was "held on safe Frangipani territory".

His election was assisted by being a friend and pupil of Bernard of Clairvaux, the most influential ecclesiastic of the Western Church and a strong assertor of the pope's temporal authority. The choice did not have the approval of Bernard, however, who remonstrated against the election, writing to the entire Curia:"May God forgive you what you have done! ... What reason or counsel, when the Supreme Pontiff was dead, made you rush upon a mere rustic, lay hands on him in his refuge, wrest from his hands the axe, pick or hoe, and lift him to a throne?"Bernard was equally forthright in his views directly to Eugene, writing:"Thus does the finger of God raise up the poor out of the dust and lift up the beggar from the dunghill that he may sit with princes and inherit the throne of glory."Despite these criticisms, Eugene seems to have borne no resentment to Bernard and notwithstanding these criticisms, after the choice was made, Bernard took advantage of the qualities in Eugene III which he objected to, so as to virtually rule in his name.

During nearly the whole of his pontificate, Eugene III was unable to reside in Rome. Hardly had he left the city to be consecrated in the monastery of Farfa (about 40 km north of Rome), when the citizens, under the influence of Arnold of Brescia, the great opponent of the Pope's temporal power, established the old Roman constitution, the Commune of Rome and elected Giordano Pierleoni to be "Patrician". Eugene III appealed for help to Tivoli, Italy, to other cities at feud with Rome, and to King Roger II of Sicily (who sent his general Robert of Selby), and with their aid was successful in making such conditions with the Roman citizens as enabled him for a time to hold the semblance of authority in his capital. But as he would not agree to a treacherous compact against Tivoli, he was compelled to leave the city in March 1146. He stayed for some time at Viterbo, and then at Siena, but went ultimately to France.

On hearing of the fall of Edessa (now the modern day city of Urfa, the first of the Crusader states established in the Levant) to the Turks, which occurred in 1144, he had, in December 1145, addressed the bull "Quantum praedecessores" to Louis VII of France, calling on him to take part in another crusade. At a great diet held at Speyer in 1146, King of the Romans Conrad III and many of his nobles were also incited to dedicate themselves to the crusade by the eloquence of Bernard who preached to an enormous crowd at Vézelay.

In the end, the Second Crusade was "an ignominous fiasco" and, after travelling for a year, the army abandoned their campaign after just five days of siege "having regained not one inch of Muslim territory." The crusaders suffered immense losses in both men and materiel and suffered, in the view of one modern historian, "the ultimate humiliation which neither they, nor their enemies, would forget".

Eugene III held synods in northern Europe at Paris, Rheims (March 1148), and Trier in 1147 that were devoted to the reform of clerical life. He also considered and approved the works of Hildegard of Bingen.

In June 1148, Eugene III returned to Italy and took up his residence at Viterbo. He was unable to return to Rome due to the popularity of Arnold of Brescia, who opposed Papal temporal authority, in the city. He established himself at Prince Ptolemy's fortress in Tusculum, the closest town to Rome at which he could safely install himself, on 8 April 1149.

There her met the returning Crusader king Louis VII of France and his wife Eleanor of Aquitaine who were by then barely on speaking terms given the strains of the failed Crusade and the suggestion that Eleanor may have entered until a relationship with her uncle Raymond during the Crusade. Eugene, "a gentle, kind-hearted man who hated to see people unhappy" attempted to assuage the pain of the failed Crusade and their failing marriage by insisting that they slept in the same bed and "by daily converse to restore the love between them". His efforts were unsuccessful, and two years later Eugene agreed to annul the marriage on the grounds of consanguinity. Eleanor went on to remarry and become the wife of a King of England, and the mother of two.

Eugent stayed at Tusculum until 7 November. At the end of November 1149, through the aid of the King of Sicily, he was again able to enter Rome, but the atmosphere of open hostility from the Comune soon compelled him to retire (June 1150).
The Emperor Frederick I Barbarossa had promised to aid him against his revolted subjects, but this was not to be: Eugene III died at Tivoli on 8 July 1153. Though the citizens of Rome were jealous of the efforts of Eugene III to assert his temporal authority, they were always ready to recognize him as their spiritual lord. Besides that, they deeply reverenced his personal character. Until the day of his death he continued to wear, under his robes, the coarse habit of a Cistercian monk. Accordingly, he was buried in the Vatican with every mark of respect, and his tomb soon acquired an extraordinary fame for miraculous cures.

The people of Rome were quick to recognize Eugene III as a pious figure who was meek and spiritual. His tomb acquired considerable fame due to the miracle purported to have occurred there and his cause for sainthood commenced. Pope Pius IX beatified him in 1872.




</doc>
<doc id="24689" url="https://en.wikipedia.org/wiki?curid=24689" title="Persistence">
Persistence

Persistence may refer to:






</doc>
<doc id="24690" url="https://en.wikipedia.org/wiki?curid=24690" title="Plaintiff">
Plaintiff

A plaintiff (Π in legal shorthand) is the party who initiates a lawsuit (also known as an "action") before a court. By doing so, the plaintiff seeks a legal remedy; if this search is successful, the court will issue judgment in favor of the plaintiff and make the appropriate court order (e.g., an order for damages). "Plaintiff" is the term used in civil cases in most English-speaking jurisdictions, the notable exception being England and Wales, where a plaintiff has, since the introduction of the Civil Procedure Rules in 1999, been known as a "claimant", but that term also has other meanings. In criminal cases, the prosecutor brings the case against the defendant, but the key complaining party is often called the "complainant".

In some jurisdictions, a lawsuit is commenced by filing a summons, claim form or a complaint. These documents are known as pleadings, that set forth the alleged wrongs committed by the defendant or defendants with a demand for relief. In other jurisdictions, the action is commenced by service of legal process by delivery of these documents on the defendant by a process server; they are only filed with the court subsequently with an affidavit from the process server that they had been given to the defendant according to the rules of civil procedure.

In most English-speaking jurisdictions, including Hong Kong, Nigeria, Australia, Canada and the United States, as well as in both Northern Ireland and the Republic of Ireland, the legal term "plaintiff" is used as a general term for the party taking action in a civil case.

The word "plaintiff" can be traced to the year 1278, and stems from the Anglo-French word "pleintif" meaning "complaining". It was identical to "plaintive" at first and receded into legal usage with the -iff spelling in the 15th century.

A plaintiff identified by name in a class action is called a named plaintiff.

In most common-law jurisdictions, the term "claimant" used in England and Wales since 1999 (see below) is used only in specific, often non-judicial contexts. In particular, in American usage, terms such as "claimant" and "claim form" are limited to extrajudicial process in insurance and administrative law. After exhausting remedies available through an insurer or government agency, an American claimant in need of further relief would turn to the courts, file a complaint (thus establishing a real court case under judicial supervision) and become a plaintiff.

In England and Wales, the term "claimant" replaced "plaintiff" after the Civil Procedure Rules 1998 came into force on 26 April 1999. The move, which brings England and Wales out of line with general usage in English-speaking jurisdictions, was reportedly based on an assessment that the word "claimant" is more acceptable as "plain English" than the word "plaintiff". In Scottish law a plaintiff is referred to as a "pursuer" and a defendant as a "defender".

The party against whom the complaint is made is the defendant; or, in the case of a petition, a respondent. Case names are usually given with the plaintiff first, as in "Plaintiff v. Defendant".

The similar term "complainant" denotes the complaining witness in a criminal proceeding.



</doc>
<doc id="24694" url="https://en.wikipedia.org/wiki?curid=24694" title="Philosophy of law">
Philosophy of law

Philosophy of law is a branch of philosophy and jurisprudence that seeks to answer basic questions about law and legal systems, such as "What is law?", "What are the criteria for legal validity?", "What is the relationship between law and morality?", and many other similar questions.

"The principal objective of analytical jurisprudence has traditionally been to provide an account of what distinguishes law as a system of norms from other systems of norms, such as ethical norms." The question that has received the most attention from philosophers of law is "What is law?" Several schools of thought have provided rival answers to this question, the most influential of which are:

In recent years, debates about the nature of law have become increasingly fine-grained. One important debate is within legal positivism. One school is sometimes called "exclusive legal positivism", and it is associated with the view that the legal validity of a norm can never depend on its moral correctness. A second school is labeled "inclusive legal positivism", and it is associated with the view that moral considerations "may" determine the legal validity of a norm, but that it is not necessary that this is the case. Some philosophers used to contend that positivism was the theory that there is "no necessary connection" between law and morality; but influential contemporary positivists, including Joseph Raz, John Gardner, and Leslie Green, reject that view. As Raz points out, it is a necessary truth that there are vices that a legal system cannot possibly have (for example, it cannot commit rape or murder). In fact, it is even unclear whether Hart himself held this view in its broad form, for he insisted both that to be a legal system rules must have a certain minimum content, which content overlaps with moral concerns, and that it must attain at least some degree of justice in the administration of laws.

A second important debate in recent years concerns interpretivism, a view that is associated mainly with Ronald Dworkin. An interpretivist theory of law holds that legal rights and duties are determined by the best interpretation of the political practices of a particular community. Interpretation, according to Dworkin's law as integrity theory, has two dimensions. To count as an interpretation, the reading of a text must meet the criterion of "fit". But of those interpretations that fit, Dworkin maintains that the correct interpretation is the one that puts the political practices of the community in their best light, or makes of them "the best that they can be". But many writers have doubted whether there "is" a single best justification for the complex practices of any given community, and others have doubted whether, even if there are, they should be counted as part of the law of that community.

In addition to analytic jurisprudence, legal philosophy is also concerned with normative theories of law. "Normative jurisprudence involves normative, evaluative, and otherwise prescriptive questions about the law." For example, What is the goal or purpose of law? What moral or political theories provide a foundation for the law? Three approaches have been influential in contemporary moral and political philosophy, and these approaches are reflected in normative theories of law:
There are many other normative approaches to the philosophy of law, including critical legal studies and libertarian theories of law.

Philosophers of law are also concerned with a variety of philosophical problems that arise in particular legal subjects, such as constitutional law, Contract law, Criminal law, and Tort law. Thus, philosophy of law addresses such diverse topics as theories of contract law, theories of criminal punishment, theories of tort liability, and the question of whether judicial review is justified.





</doc>
<doc id="24695" url="https://en.wikipedia.org/wiki?curid=24695" title="Personal property">
Personal property

Personal property is generally considered property that is movable, as opposed to real property or real estate. In common law systems, personal property may also be called chattels or personalty. In civil law systems, personal property is often called movable property or movables – any property that can be moved from one location to another.

Personal property is movable and can be understood in comparison to immovable property or real property, such as land and buildings. Movable property on land, for example, larger livestock, was not automatically sold with the land, it was "personal" to the owner and moved with the owner. The word "cattle" is the Old Norman variant of Old French "chatel", chattel (derived from Latin "capitalis", “of the head”), which was once synonymous with general movable personal property. 

Personal property may be classified in a variety of ways.

Tangible personal property refers to any type of property that can generally be moved (i.e., it is not attached to real property or land), touched or felt. These generally include items such as furniture, clothing, jewelry, art, writings, or household goods. In some cases, there can be formal title documents that show the ownership and transfer rights of that property after a person's death (for example, motor vehicles, boats, etc.) In many cases, however, tangible personal property will not be "titled" in an owner's name and is presumed to be whatever property he or she was in possession of at the time of his or her death.

Intangible personal property or "intangibles" refers to personal property that cannot actually be moved, touched or felt, but instead represents something of value such as negotiable instruments, securities, service (economics), and intangible assets including chose in action.

Accountants also distinguish personal property from real property because personal property can be depreciated faster than improvements (while land is not depreciable at all). It is an owner's right to get tax benefits for chattel, and there are businesses that specialize in appraising personal property, or chattel.

The distinction between these types of property is significant for a variety of reasons. Usually one's rights on movables are more attenuated than one's rights on immovables (or real property). The statutes of limitations or prescriptive periods are usually shorter when dealing with personal or movable property. Real property rights are usually enforceable for a much longer period of time and in most jurisdictions real estate and immovables are registered in government-sanctioned land registers. In some jurisdictions, rights (such as a lien or other security interest) can be registered against personal or movable property.

In the common law it is possible to place a mortgage upon real property. Such mortgage requires payment or the owner of the mortgage can seek foreclosure. Personal property can often be secured with similar kind of device, variously called a chattel mortgage, trust receipt, or security interest. In the United States, Article 9 of the Uniform Commercial Code governs the creation and enforcement of security interests in most (but not all) types of personal property.

There is no similar institution to the mortgage in the civil law, however a hypothec is a device to secure real rights against property. These real rights follow the property along with the ownership. In the common law a lien also remains on the property and it is not extinguished by alienation of the property; liens may be real or equitable.

Many jurisdictions levy a personal property tax, an annual tax on the privilege of owning or possessing personal property within the boundaries of the jurisdiction. Automobile and boat registration fees are a subset of this tax. Most household goods are exempt as long as they are kept or used within the household; the tax usually becomes a problem when the taxing authority discovers that expensive personal property like art is being regularly stored outside of the household.

The distinction between tangible and intangible personal property is also significant in some of the jurisdictions which impose sales taxes. In Canada, for example, provincial and federal sales taxes were imposed primarily on sales of tangible personal property whereas sales of intangibles tended to be exempt. The move to value added taxes, under which almost all transactions are taxable, has diminished the significance of the distinction.

In political/economic theory, notably socialist, Marxist, and most anarchist philosophies, the distinction between private and personal property is extremely important. Which items of property constitute which is open to debate. In some philosophies, such as capitalism, private and personal property are considered to be exactly equivalent.





</doc>
<doc id="24696" url="https://en.wikipedia.org/wiki?curid=24696" title="Prima facie">
Prima facie

Prima facie (; ) is a Latin expression meaning "on its first encounter" or "at first sight". The literal translation would be "at first face" or "at first appearance", from the feminine forms of "primus" ("first") and "facies" ("face"), both in the ablative case. In modern, colloquial and conversational English, a common translation would be "on the face of it". The term "prima facie" is used in modern legal English (including both civil law and criminal law) to signify that upon initial examination, sufficient corroborating evidence appears to exist to support a case. In common law jurisdictions, "prima facie" denotes evidence that, unless rebutted, would be sufficient to prove a particular proposition or fact. The term is used similarly in academic philosophy. Most legal proceedings, in most jurisdictions, require a "prima facie" case to exist, following which proceedings may then commence to test it, and create a ruling.

In most legal proceedings, one party has a burden of proof, which requires it to present "prima facie" evidence for all of the essential facts in its case. If it cannot, its claim may be dismissed without any need for a response by other parties. A "prima facie" case might not stand or fall on its own; if an opposing party introduces other evidence or asserts an affirmative defense it can only be reconciled with a full trial. Sometimes the introduction of "prima facie" evidence is informally called "making a case" or "building a case".

For example, in a trial under criminal law the prosecution has the burden of presenting "prima facie" evidence of each element of the crime charged against the defendant. In a murder case, this would include evidence that the victim was in fact dead, that the defendant's act caused the death, and evidence that the defendant acted with malice aforethought. If no party introduces new evidence, the case stands or falls just by the "prima facie" evidence or lack thereof.

"Prima facie" evidence does not need to be conclusive or irrefutable: at this stage, evidence rebutting the case is not considered, only whether any party's case has enough merit to take it to a full trial.

In common law jurisdictions such as the United Kingdom and the United States, the prosecution in a criminal trial must disclose all evidence to the defense. This includes the "prima facie" evidence.

An aim of the doctrine of "prima facie" is to prevent litigants from bringing spurious charges which simply waste all other parties' time.

"Prima facie" is often confused with "res ipsa loquitur" ("the thing speaks for itself", or literally "the thing itself speaks"), the common law doctrine that when the facts make it self-evident that negligence or other responsibility lies with a party, it is not necessary to provide extraneous details, since any reasonable person would immediately find the facts of the case.

The difference between the two is that "prima facie" is a term meaning there is enough evidence for there to be a case to answer, while "Res ipsa loquitur" means that the facts are so obvious a party does not need to explain any more. For example: "There is a "prima facie" case that the defendant is liable. They controlled the pump. The pump was left on and flooded the plaintiff's house. The plaintiff was away and had left the house in the control of the defendant. "Res ipsa loquitur"."

This doctrine has been subsumed by general negligence law in Canadian tort law.

The phrase is also used in academic philosophy. Among its most notable uses is in the theory of ethics first proposed by W. D. Ross, often called the "Ethic of Prima Facie Duties", as well as in epistemology, as used, for example, by Robert Audi. It is generally used in reference to an obligation. "I have a "prima facie" obligation to keep my promise and meet my friend" means that I am under an obligation, but this may yield to a more pressing duty. A more modern usage prefers the title "pro tanto obligation": an obligation that may be later overruled by another more pressing one; it exists only "pro tempore".

The phrase "prima facie" is sometimes misspelled ' in the mistaken belief that ' is the actual Latin word; however, "faciē" is in fact the ablative case of "faciēs", a fifth declension Latin noun.

In policy debate theory, "prima facie" is used to describe the mandates or planks of an affirmative case, or, in some rare cases, a negative counterplan. When the negative team appeals to "prima facie", it appeals to the fact that the affirmative team cannot add or amend anything in its plan after being stated in the first affirmative constructive.

A common usage of the phrase is the concept of a ""prima facie" speed limit" which has been used in Australia and the United States. A "prima facie" speed limit is a default speed limit that applies when no other specific speed limit is posted, and may be exceeded by a driver. However, if the driver is detected, and cited by police for exceeding the limit, the onus of proof is on the driver, to show that the speed at which the driver was travelling was safe under the circumstances. In most jurisdictions, this type of speed limit has been replaced by absolute speed limits.




</doc>
<doc id="24697" url="https://en.wikipedia.org/wiki?curid=24697" title="Product liability">
Product liability

Product liability is the area of law in which manufacturers, distributors, suppliers, retailers, and others who make products available to the public are held responsible for the injuries those products cause. Although the word "product" has broad connotations, product liability as an area of law is traditionally limited to products in the form of tangible personal property.

In the United States, the claims most commonly associated with product liability are negligence, strict liability, breach of warranty, and various consumer protection claims. The majority of product liability laws are determined at the state level and vary widely from state to state. Each type of product liability claim requires proof of different elements in order to present a valid claim.

Section 2 of the "Restatement (Third) of Torts: Products Liability" distinguishes between three major types of product liability claims:


However, in most states, these are not legal claims in and of themselves, but are pleaded in terms of the theories mentioned above. For example, a plaintiff might plead negligent failure to warn or strict liability for defective design.

Warranties are statements by a manufacturer or seller concerning a product during a commercial transaction. Warranty claims commonly require privity between the injured party and the manufacturer or seller; in plain English, this means they must be dealing with each other directly. Breach of warranty-based product liability claims usually focus on one of three types: (1) breach of an express warranty, (2) breach of an implied warranty of merchantability, and (3) breach of an implied warranty of fitness for a particular purpose. Additionally, claims involving real estate may also take the form of an implied warranty of habitability. Express warranty claims focus on express statements by the manufacturer or the seller concerning the product (e.g., "This chainsaw is useful to cut turkeys"). The various implied warranties cover those expectations common to all products (e.g., that a tool is not unreasonably dangerous when used for its proper purpose), unless specifically disclaimed by the manufacturer or the seller.

A basic negligence claim consists of proof of


As demonstrated in cases such as "Winterbottom v. Wright", the scope of the duty of care was limited to those with whom one was in privity. Later cases like "MacPherson v. Buick Motor Co." broadened the duty of care to all who could be foreseeably injured by one's conduct.

Over time, negligence concepts have arisen to deal with certain specific situations, including negligence "per se" (using a manufacturer's violation of a law or regulation, in place of proof of a duty and a breach) and res ipsa loquitur (an inference of negligence under certain conditions).

Rather than focus on the behavior of the manufacturer (as in negligence), strict liability claims focus on the product itself. Under strict liability, the manufacturer is liable if the product is defective, even if the manufacturer was not negligent in making that product defective.

The difficulty with negligence is that it still requires the plaintiff to prove that the defendant's conduct fell below the relevant standard of care. However, if an entire industry tacitly settles on a somewhat careless standard of conduct (that is, as analyzed from the perspective of a layperson), then the plaintiff may not be able to recover even though he or she is severely injured, because although the defendant's conduct "caused" his or her injuries, such conduct was not negligent in the legal sense (if everyone within the trade would inevitably testify that the defendant's conduct conformed to that of a reasonable tradeperson in such circumstances). As a practical matter, with the increasing complexity of products, injuries, and medical care (which made many formerly fatal injuries survivable), it is quite a difficult and expensive task to find and retain good expert witnesses who can establish the standard of care, breach, and causation.

Therefore, in the 1940s and 1950s, many American courts departed from the "MacPherson" standard and decided that it was too harsh to require seriously injured consumer plaintiffs to prove negligence claims against manufacturers or retailers. To avoid having to deny such plaintiffs any relief, these courts began to look for facts in their cases which they could characterize as an express or implied warranty from the manufacturer to the consumer. The "res ipsa loquitur" doctrine was also stretched to reduce the plaintiff's burden of proof. Over time, the resulting legal fictions became increasingly strained.

Of the various U.S. states, California was the first to throw away the fiction of a warranty and to boldly assert the doctrine of strict liability in tort for defective products, in the Supreme Court of California's decision in "Greenman v. Yuba Power Products", 59 Cal. 2d 57 (1963) (in which the majority opinion was authored by then-Associate Justice Roger J. Traynor). The importance of "Greenman" cannot be overstated: in 1996, the Association of Trial Lawyers of America (now known as the American Association of Justice) celebrated its 50th anniversary by polling lawyers and law professors on the top ten developments in tort law during the past half-century, and "Greenman" topped the list.

In "Greenman", Traynor cited to his own earlier concurring opinion in "Escola v. Coca-Cola Bottling Co.", 24 Cal. 2d 453, 462 (1944) (Traynor, J., concurring). In "Escola", now widely recognized as a landmark case in American law, Justice Traynor laid the foundation for "Greenman" with these words:

Even if there is no negligence, however, public policy demands that responsibility be fixed wherever it will most effectively reduce the hazards to life and health inherent in defective products that reach the market. It is evident that the manufacturer can anticipate some hazards and guard against the recurrence of others, as the public cannot. Those who suffer injury from defective products are unprepared to meet its consequences. The cost of an injury and the loss of time or health may be an overwhelming misfortune to the person injured, and a needless one, for the risk of injury can be insured by the manufacturer and distributed among the public as a cost of doing business. It is to the public interest to discourage the marketing of products having defects that are a menace to the public. If such products nevertheless find their way into the market it is to the public interest to place the responsibility for whatever injury they may cause upon the manufacturer, who, even if he is not negligent in the manufacture of the product, is responsible for its reaching the market. However intermittently such injuries may occur and however haphazardly they may strike, the risk of their occurrence is a constant risk and a general one. Against such a risk there should be general and constant protection and the manufacturer is best situated to afford such protection.

The year after "Greenman", the Supreme Court of California proceeded to extend strict liability to "all" parties involved in the manufacturing, distribution, and sale of defective products (including retailers) and in 1969 made it clear that such defendants were liable not only to direct customers and users, but also to any innocent bystanders randomly injured by defective products.

Since then, many jurisdictions have been swayed by Justice Traynor's arguments on behalf of the strict liability rule in "Escola", "Greenman", and subsequent cases. In the 40 years after "Greenman", the highest courts of nearly all U.S. states and territories followed California's example in imposing strict liability on manufacturers, distributors, and retailers for defective products. In a landmark 1986 decision, the U.S. Supreme Court embraced strict liability for defective products by adopting it as part of federal admiralty law.

Meanwhile, although the "Greenman" rule was transmitted to most other states via Section 402A of the Restatement of Torts, Second (published in 1964 after "Greenman"), the Supreme Court of California refused to adopt Section 402A's "unreasonably dangerous" limitation upon strict liability in 1972. Thus, strict liability in California is truly strict, in that the plaintiff need not show that the defect was unreasonable or dangerous. On the other hand, in California, the defendant is allowed to introduce evidence in a strict products liability action that the plaintiff contributed to his or her own injuries.

Although the Supreme Court of California has since become more conservative, it continues to endorse and expand the doctrine. In 2002 it held that strict liability for defective products even applies to makers of component products that are installed into and sold as part of real property. However, strict liability is not limitless. In 2012, the Court held that manufacturers are liable under strict liability and negligence only for defects in "their" products, as distinguished from other products that could potentially be used with their products.

In addition to the above common law claims, many states have enacted consumer protection statutes providing for specific remedies for a variety of product defects. Statutory remedies are often provided for defects which merely render the product unusable (and hence cause economic injury) but do not cause physical injury or damage to other property; the "economic loss rule" means that strict liability is generally unavailable for products that damage only themselves. The best known examples of consumer protection laws for product defects are lemon laws, which became widespread because automobiles are often an American citizen's second-largest investment after buying a home.

In the rest of the world, legislatures took the lead in imposing strict liability for defective products. The judiciaries of several countries rejected attempts by creative lawyers to persuade them to adopt the "Greenman" holding, including Canada and South Africa.

In Europe, a movement towards strict liability began with the Council of Europe Convention on Products Liability in regard to Personal Injury and Death (the Strasbourg Convention) in 1977. On July 25, 1985, the European Economic Community adopted the Product Liability Directive. In language similar to Traynor's, the Directive stated that "liability without fault on the part of the producer is the sole means of adequately solving the problem, peculiar to our age of increasing technicality, of a fair apportionment of the risks inherent in modern technological production." However, the Directive also gave each member state the option of imposing a liability cap of 70 million euros per defect. The Directive only imposed strict liability upon manufacturers or importers, and deviated significantly from the U.S. model by refusing to impose strict liability on purely domestic distributors or retailers.

The legislatures of many other countries outside the EEC subsequently enacted strict liability regimes based on the European model (that is, generally applying only to manufacturers and importers), including Israel (March 1980, based on an early proposed draft of the Directive), Brazil (September 1990), Peru (November 1991), Australia (July 1992), Russia (February 1992), Switzerland (December 1992), Argentina (October 1993), Japan (June 1994), Taiwan (June 1994), Malaysia (August 1999), South Korea (January 2000), Thailand (December 2007), and South Africa (April 2009).

China first enacted a Product Quality Law in October 1993 in an attempt to impose strict liability, but the law was badly drafted and was quite weak. After numerous product scandals throughout the 2000s, China finally enacted a much stronger Tort Liability Act in December 2009, followed by a Statute on the Choice of Substantive Law in Foreign-Related Civil Relationships in April 2011, which enables Chinese consumers injured by foreign-made products to request that Chinese courts apply the law of the defendant's place of business. While these two laws are still relatively ineffective against large Chinese manufacturers who are state-owned enterprises (as the defendant can simply have the product defect declared a state secret and then have the plaintiff prosecuted for revealing state secrets), they will enable Chinese consumers to seek some compensation from non-state companies as well as foreign manufacturers.

Strict products liability causes manufacturers to internalize costs they would normally externalize. Strict liability thus requires manufacturers to evaluate the full costs of their products. In this way, strict liability provides a mechanism for ensuring that a product's absolute good outweighs its absolute harm.

Between two parties who are not negligent (manufacturer and consumer), one will necessarily shoulder the costs of product defects. Proponents say it is preferable to place the economic costs on the manufacturer because it can better absorb them and pass them on to other consumers. The manufacturer thus becomes a de facto insurer against its defective products, with premiums built into the product's price.

Strict liability also seeks to diminish the impact of information asymmetry between manufacturers and consumers. Manufacturers have better knowledge of their own products' dangers than do consumers. Therefore, manufacturers properly bear the burden of finding, correcting, and warning consumers of those dangers.

Strict liability reduces litigation costs, because a plaintiff need only prove causation, not imprudence. Where causation is easy to establish, parties to a strict liability suit will most likely settle, because only damages are in dispute.

Critics charge that strict liability creates risk of moral hazard. They claim that strict liability causes consumers to under invest in care even when they are the least-cost avoiders. This, they say, results in a lower aggregate level of care than under a negligence standard. Proponents counter that people have enough natural incentive to avoid inflicting serious harm on themselves to mitigate this concern.

Critics charge that the requiring manufacturers to internalize costs they would otherwise externalize increases the price of goods. Critics claim that in elastic, price-sensitive markets, price increases cause some consumers to seek substitutes for that product. As a result, they say, manufacturers may not produce the socially optimal level of goods. Proponents respond that these consumer opt outs reflect a product whose absolute harm outweighs its absolute value; products that do more harm than good ought not be produced.

In the law and economics literature, there is a debate about whether liability and regulation are substitutes or complements. If they are substitutes, then either liability or regulation should be used. If they are complements, then the joint use of liability and regulation is optimal.




</doc>
<doc id="24698" url="https://en.wikipedia.org/wiki?curid=24698" title="Proximate cause">
Proximate cause

In the law, a proximate cause is an event sufficiently related to an injury that the courts deem the event to be the cause of that injury. There are two types of causation in the law: cause-in-fact, and proximate (or legal) cause. Cause-in-fact is determined by the "but for" test: But for the action, the result would not have happened. For example, but for running the red light, the collision would not have occurred. The action is a necessary condition, but may not be a sufficient condition, for the resulting injury. For an act to cause a harm, both tests must be met; proximate cause is a legal limitation on cause-in-fact.

The formal Latin term for "but for" (cause-in-fact) causation, is sine qua non causation.

A few circumstances exist where the "but for" test is complicated, or the test is ineffective. The primary examples are:

Since but-for causation is very easy to show and does not assign culpability (but for the rain, you would not have crashed your carthe rain is not morally or legally culpable but still constitutes a cause), there is a second test used to determine if an action is close enough to a harm in a "chain of events" to be a legally culpable cause of the harm. This test is called proximate cause, from the Latin "proxima causa".

There are several competing theories of proximate cause.

The most common test of proximate cause under the American legal system is foreseeability. It determines if the harm resulting from an action could reasonably have been predicted. The test is used in most cases only in respect to the type of harm. It is foreseeable, for example, that throwing a baseball at someone could cause them a blunt-force injury. But proximate cause is still met if a thrown baseball misses the target and knocks a heavy object off a shelf behind them, which causes a blunt-force injury. Evident in Corrigan v HSE (2011 IEHC 305).

This is also known as the "extraordinary in hindsight" rule.

Direct causation is a minority test, which addresses only the metaphysical concept of causation. It does not matter how foreseeable the result as long as what the negligent party's physical action can be tied to what actually happened. The main thrust of direct causation is that there are no intervening causes between an act and the resulting harm. An intervening cause has several requirements: it must 1) be independent of the original act, 2) be a voluntary human act or an abnormal natural event, and 3) occur in time between the original act and the harm.

Direct causation is the only theory that addresses only causation, and does not take into account the culpability of the original actor.

The plaintiff must demonstrate that the defendant's action increased the risk that the particular harm suffered by the plaintiff would occur. If the action were repeated, the likelihood of the harm would correspondingly increase. This is also called foreseeable risk.

The harm within the risk (HWR) test determines whether the victim was among the class of persons who could foreseeably be harmed, and whether the harm was foreseeable within the class of risks. It is the strictest test of causation, made famous by Benjamin Cardozo in "Palsgraf v. Long Island Railroad Co." case under New York state law.

The first element of the test is met if the injured person was a member of a class of people who could be expected to be put at risk of injury by the action. For example, a pedestrian, as an expected user of sidewalks, is among the class of people put at risk by driving on a sidewalk, whereas a driver who is distracted by another driver driving on the sidewalk, and consequently crashes into a utility pole, is not.

The HWR test is no longer much used, outside of New York law. When it is used, it is used to consider the class of people injured, not the type of harm. The main criticism of this test is that it is preeminently concerned with culpability, rather than actual causation.

Referred to by the Reporters of the Second and Third Restatements of the Law of Torts as the "scope-of-the-risk" test, the term "Risk Rule" was coined by the University of Texas School of Law's Dean Robert Keeton. The rule is that “[a]n actor’s liability is limited to those physical harms that result from the risks that made the actor’s conduct tortious.” Thus, the operative question is "what were the particular risks that made an actor's conduct negligent?" If the injury suffered is not the result of one of those risks, there can be no recovery. Two examples will illustrate this principle:


The most obvious objection to this approach is that it requires courts to consider an arguably endless possibility of hypothetical situations. Not only can such an undertaking be an exercise in futility, but this approach lacks even a minimal amount of precision such that parties might be able to predict outcomes and results during litigation. Notwithstanding the already-complex nature of this and other questions relating to proximate or legal cause, this fluid standard could be misused by plaintiff-friendly or defense-favoring judges in attempts to vindicate their own personal philosophies regarding the appropriate reach of tort law.

The doctrine of proximate cause is notoriously confusing. The doctrine is phrased in the language of causation, but in most of the cases in which proximate cause is actively litigated, there is not much real dispute that the defendant but-for caused the plaintiff's injury. The doctrine is actually used by judges in a somewhat arbitrary fashion to limit the scope of the defendant's liability to a subset of the total class of potential plaintiffs who may have suffered some harm from the defendant's actions. For an understanding of the broader view of causation which proximate cause circumscribes, see butterfly effect.

For example, in the two famous "Kinsman Transit" cases from the 2nd Circuit (exercising admiralty jurisdiction over a New York incident), it was clear that mooring a boat improperly could lead to the risk of that boat drifting away and crashing into another boat, and that both boats could crash into a bridge, which collapsed and blocked the river, and in turn, the wreckage could flood the land adjacent to the river, as well as prevent any traffic from traversing the river until it had been cleared. But under proximate cause, the property owners adjacent to the river could sue ("Kinsman I"), but not the owners of the boats or cargoes which could not move until the river was reopened ("Kinsman II").

Therefore, in the final version of the "Restatement (Third), Torts: Liability for Physical and Emotional Harm", published in 2010, the American Law Institute argued that proximate cause should be replaced with scope of liability. Chapter 6 of the Restatement is titled "Scope of Liability (Proximate Cause)." It begins with a special note explaining the Institute's decision to reframe the concept in terms of "scope of liability" because it does not involve true causation, and to also include "proximate cause" in the chapter title in parentheses to help judges and lawyers understand the connection between the old and new terminology. The Institute added that it "fervently hopes" the parenthetical will be unnecessary in a future fourth Restatement of Torts.

A related doctrine is the insurance law doctrine of efficient proximate cause. Under this rule, in order to determine whether a loss resulted from a cause covered under an insurance policy, a court looks for the predominant cause which sets into motion the chain of events producing the loss, which may not necessarily be the "last" event that immediately preceded the loss. Many insurers have attempted to contract around efficient proximate cause through the use of "anti-concurrent causation" (ACC) clauses, under which if a covered cause and a noncovered cause join together to cause a loss, the loss is not covered.

ACC clauses frequently come into play in jurisdictions where property insurance does not normally include flood insurance and expressly excludes coverage for floods. The classic example of how ACC clauses work is where a hurricane hits a building with wind and flood hazards "at the same time." If the evidence later shows that the wind blew off a building's roof and then water damage resulted only because there was no roof to prevent rain from entering, there would be coverage, but if the building was simultaneously flooded (i.e., because the rain caused a nearby body of water to rise or simply overwhelmed local sewers), an ACC clause would completely block coverage for the "entire" loss (even if the building owner could otherwise attribute damage to wind v. flood).

A minority of jurisdictions have ruled ACC clauses to be unenforceable as against public policy, but they are generally enforceable in the majority of jurisdictions.




</doc>
<doc id="24702" url="https://en.wikipedia.org/wiki?curid=24702" title="Peace">
Peace

Peace is the concept of harmony and the absence of hostility. In a behavioral sense, peace is a lack of conflict and freedom from fear of violence between individuals and heterogeneous social groups. Throughout history some of the most extraordinary and benevolent leaders have used peace talks to establish a certain type of behavioral restraint that has resulted in the establishment of regional peace or economic growth through various forms of agreements or peace treaties. Such behavioral restraint has often resulted in de-escalation of rhetorical and physical conflicts, greater economic interactivity, and consequently substantial prosperity. The avoidance of war or violent hostility can be the result of thoughtful active listening and communication that enables greater genuine mutual understanding and therefore compromise. Leaders often benefit tremendously from the prestige of peace talks and treaties that can result in substantially enhanced popularity.

“Psychological peace” (such as a peaceful thinking and emotions) is perhaps less well defined yet often a necessary precursor to establishing "behavioral peace." Peaceful behavior sometimes results from a "peaceful inner disposition." Some have expressed the belief that peace can be initiated with a certain quality of inner tranquility that does not depend upon the uncertainties of daily life for its existence. The acquisition of such a "peaceful internal disposition" for oneself and others can contribute to resolving of otherwise seemingly irreconcilable competing interests.

Because psychological peace can be important to Behavioral peace, leaders sometimes de-escalate conflicts through compliments and generosity. Small gestures of rhetorical and actual generosity have been shown in psychological research to often result in larger levels of reciprocal generosity (and even virtuous circles of generosity). Such benevolent selfless behavior can eventually become a pattern that may become a lasting basis for improved relations between individuals and groups of people. Peace talks often start without preconditions and preconceived notions, because they are more than just negotiating opportunities. They place attention on peace itself over and above what may have been previously perceived as the competing needs or interests of separate individuals or parties to elicit peaceful feelings and therefore produce benevolent behavioral results. Peace talks are sometimes also uniquely important learning opportunities for the individuals or parties involved.

The term-'peace' originates most recently from the Anglo-French "pes," and the Old French "pais", meaning "peace, reconciliation, silence, agreement" (11th century). But, "Pes" itself comes from the Latin "pax", meaning "peace, compact, agreement, treaty of peace, tranquility, absence of hostility, harmony." The English word came into use in various personal greetings from c.1300 as a translation of the Hebrew word shalom, which, according to Jewish theology, comes from a Hebrew verb meaning 'to be complete, whole'. Although 'peace' is the usual translation, however, it is an incomplete one, because 'shalom,' which is also cognate with the Arabic "salaam", has multiple other meanings in addition to peace, including justice, good health, safety, well-being, prosperity, equity, security, good fortune, and friendliness, as well as simply the greetings, "hello" and "goodbye". At a personal level, peaceful behaviors are kind, considerate, respectful, just, and tolerant of others' beliefs and behaviors — tending to manifest goodwill.

This latter understanding of peace can also pertain to an individual's introspective sense or concept of her/himself, as in being "at peace" in one's own mind, as found in European references from c.1200. The early English term is also used in the sense of "quiet", reflecting calm, serene, and meditative approaches to family or group relationships that avoid quarreling and seek tranquility — an absence of disturbance or agitation.

In many languages, the word for peace is also used as a greeting or a farewell, for example the Hawaiian word aloha, as well as the Arabic word "salaam". In English the word peace is occasionally used as a farewell, especially for the dead, as in the phrase "rest in peace".

Wolfgang Dietrich in his research project which led to the book "The Palgrave International Handbook of Peace Studies" (2011) maps the different meanings of peace in different languages and from different regions across the world. Later, in his "Interpretations of Peace in History and Culture" (2012), he groups the different meanings of peace into five peace families: Energetic/Harmony, Moral/Justice, Modern/Security, Postmodern/Truth, and Transrational, a synthesis of the positive sides of the four previous families and the society.

Religious beliefs often seek to identify and address the basic problems of human life, including the conflicts between, among, and within persons and societies. In ancient Greek-speaking areas the virtue of peace was personified as the goddess Eirene, and in Latin-speaking areas as the goddess Pax. Her image was typically represented by ancient sculptors as that of a full-grown woman, usually with a horn of plenty and scepter and sometimes with a torch or olive leaves.

Christians, who believe Jesus of Nazareth to be the Jewish Messiah called Christ (meaning Anointed One), interpret Isaiah 9:6 as a messianic prophecy of Jesus in which he is called the "Prince of Peace." In the Gospel of Luke, Zechariah celebrates his son John: And you, child, will be called prophet of the Most High, for you will go before the Lord to prepare his ways, to give his people knowledge of salvation through the forgiveness of their sins, because of the tender mercy of our God by which the daybreak from on high will visit us to shine on those who sit in darkness and death's shadow, to guide our feet into the path of peace.

Numerous pontifical documents on the Holy Rosary document a continuity of views of the Popes to have confidence in the Holy Rosary as a means to foster peace. Subsequently, to the Encyclical Mense maio,1965, in which he urged the practice of the Holy Rosary, "the prayer so dear to the Virgin and so much recommended by the Supreme Pontiffs," and as reaffirmed in the encyclical Christi Matri, 1966, to implore peace, Pope Paul VI stated in the apostolic Recurrens mensis, October 1969, that the Rosary is a prayer that favors the great gift of peace.

Islam derived from the root word salam which literally means peace. Muslims are called followers of Islam. Quran clearly stated "Those who have believed and whose hearts are assured by the remembrance of Allah. Unquestionably, by the remembrance of Allah, hearts are assured" and stated "O you who have believed, when you are told, "Space yourselves" in assemblies, then make space; Allah will make space for you. And when you are told, "Arise," then arise; Allah will raise those who have believed among you and those who were given knowledge, by degrees. And Allah is Acquainted with what you do." 

Buddhists believe that peace can be attained once all suffering ends. They regard all suffering as stemming from cravings (in the extreme, greed), aversions (fears), or delusions. To eliminate such suffering and achieve personal peace, followers in the path of the Buddha adhere to a set of teachings called the Four Noble Truths — a central tenet in Buddhist philosophy.

Hindu texts contain the following passages:

Psychological or inner peace (i.e. peace of mind) refers to a state of being internally or spiritually at peace, with sufficient knowledge and understanding to keep oneself calm in the face of apparent discord or stress. Being internally "at peace" is considered by many to be a healthy mental state, or homeostasis and to be the opposite of feeling stressful, mentally anxious, or emotionally unstable. Within the meditative traditions, the psychological or inward achievement of "peace of mind" is often associated with bliss and happiness.

Peace of mind, serenity, and calmness are descriptions of a disposition free from the effects of stress. In some meditative traditions, inner peace is believed to be a state of consciousness or enlightenment that may be cultivated by various types of meditation, prayer, t'ai chi ch'uan (太极拳, tàijíquán), yoga, or other various types of mental or physical disciplines. Many such practices refer to this peace as an experience of knowing oneself. An emphasis on finding one's inner peace is often associated with traditions such as Buddhism, Hinduism, and some traditional Christian contemplative practices such as monasticism, as well as with the New Age movement.

Satyagraha ( ) is a philosophy and practice of nonviolent resistance developed by Mohandas Karamchand Gandhi. He deployed satyagraha techniques in campaigns for Indian independence and also during his earlier struggles in South Africa.

The word "satyagraha" itself was coined through a public contest that Gandhi sponsored through the newspaper he published in South Africa, 'Indian Opinion', when he realized that neither the common, contemporary Hindu language nor the English language contained a word which fully expressed his own meanings and intentions when he talked about his nonviolent approaches to conflict. According to Gandhi's autobiography, the contest winner was Maganlal Gandhi (presumably no relation), who submitted the entry 'sadagraha', which Gandhi then modified to 'satyagraha'. Etymologically, this Hindic word means 'truth-firmness', and is commonly translated as 'steadfastness in the truth' or 'truth-force'.
Satyagraha theory also influenced Martin Luther King Jr. during the campaigns he led during the civil rights movement in the United States. The theory of satyagraha sees means and ends as inseparable. Therefore, it is contradictory to try to use violence to obtain peace. As Gandhi wrote: "They say, 'means are, after all, means'. I would say, 'means are, after all, everything'. As the means so the end..." A contemporary quote sometimes attributed to Gandhi, but also to A. J. Muste, sums it up: 'There is no way to peace; peace is the way.'

Since classical times, it has been noted that peace has sometimes been achieved by the victor over the vanquished by the imposition of ruthless measures. In his book "Agricola" the Roman historian Tacitus includes eloquent and vicious polemics against the rapacity and greed of Rome. One, that Tacitus says is by the Caledonian chieftain Calgacus, ends "Auferre trucidare rapere falsis nominibus imperium, atque ubi solitudinem faciunt, pacem appellant." (To ravage, to slaughter, to usurp under false titles, they call empire; and where they make a desert, they call it peace. — Oxford Revised Translation).

Discussion of peace is therefore at the same time a discussion on the form of such peace. Is it simple absence of mass organized killing (war) or does peace require a particular morality and justice? ("just peace").
A peace must be seen at least in two forms: 

More recently, advocates for radical reform in justice systems have called for a public policy adoption of non-punitive, non-violent Restorative Justice methods, and many of those studying the success of these methods, including a United Nations working group on Restorative Justice, have attempted to re-define justice in terms related to peace. From the late 2000s on, a Theory of Active Peace has been proposed which conceptually integrates justice into a larger peace theory.

The longest continuing period of neutrality among currently existing states is observed in Switzerland, which has had an official policy of neutrality and general peace since 1815 (for years as of 20). This was made possible partly by the periods of relative peace in Europe and the world known as Pax Britannica (1815-1914), Pax Europaea/Pax Americana (since 1950s), and Pax Atomica (also since the 1950s).

Other examples of long periods of peace are:

Pacifism is the categorical opposition to the behaviors of war or violence as a means of settling disputes or of gaining advantage. Pacifism covers a spectrum of views ranging from the belief that international disputes can and should all be resolved via peaceful behaviors; to calls for the abolition of various organizations which tend to institutionalize aggressive behaviors, such as the military, or arms manufacturers; to opposition to any organization of society that might rely in any way upon governmental force. Such groups which sometimes oppose the governmental use of force include anarchists and libertarians. Absolute pacifism opposes violent behavior under all circumstance, including defense of self and others.

Pacifism may be based on moral principles (a deontological view) or pragmatism (a consequentialist view). Principled pacifism holds that all forms of violent behavior are inappropriate responses to conflict, and are morally wrong. Pragmatic pacifism holds that the costs of war and inter-personal violence are so substantial that better ways of resolving disputes must be found. Pacifists in general reject theories of Just War. Pacifism tends to place its initial focus on the need for a "peaceful behavior" ahead of any focus on the need for a "peaceful inner disposition."

The United Nations (UN) is an international organization whose stated aims are to facilitate cooperation in international law, international security, economic development, social progress, human rights, and achieving world peace. The UN was founded in 1945 after World War II to replace the League of Nations, to stop wars between countries, and to provide a platform for dialogue.

The UN, after approval by the Security Council, sends peacekeepers to regions where armed conflict has recently ceased or paused to enforce the terms of peace agreements and to discourage combatants from resuming hostilities. Since the UN does not maintain its own military, peacekeeping forces are voluntarily provided by member states of the UN. The forces, also called the "Blue Helmets", who enforce UN accords are awarded United Nations Medals, which are considered international decorations instead of military decorations. The peacekeeping force as a whole received the Nobel Peace Prize in 1988.

The principal forerunner of the United Nations was the League of Nations. It was created at the Paris Peace Conference of 1919, and emerged from the advocacy of Woodrow Wilson and other idealists during World War I. The Covenant of the League of Nations was included in the Treaty of Versailles in 1919, and the League was based in Geneva until its dissolution as a result of World War II and replacement by the United Nations. The high hopes widely held for the League in the 1920s, for example amongst members of the League of Nations Union, gave way to widespread disillusion in the 1930s as the League struggled to respond to challenges from Nazi Germany, Fascist Italy, and Japan.

One of the most important scholars of the League of Nations was Sir Alfred Zimmern. Like many of the other British enthusiasts for the League, such as Gilbert Murray and Florence Stawell - the so-called "Greece and peace" set - he came to this from the study of the classics.

The creation of the League of Nations, and the hope for informed public opinion on international issues (expressed for example by the Union for Democratic Control during World War I), also saw the creation after World War I of bodies dedicated to understanding international affairs, such as the Council on Foreign Relations in New York and the Royal Institute of International Affairs at Chatham House in London. At the same time, the academic study of international relations started to professionalize, with the creation of the first professorship of international politics, named for Woodrow Wilson, at Aberystwyth, Wales, in 1919.

The late 19th century idealist advocacy of peace which led to the creation of the Nobel Peace Prize, the Rhodes Scholarships, the Carnegie Endowment for International Peace, and ultimately the League of Nations, also saw the re-emergence of the ancient Olympic ideal. Led by Pierre de Coubertin, this culminated in the holding in 1896 of the first of the modern Olympic Games.

The highest honour awarded to peace maker is the Nobel Prize in Peace, awarded since 1901 by the Norwegian Nobel Committee. It is awarded annually to internationally notable persons following the prize's creation in the will of Alfred Nobel. According to Nobel's will, the Peace Prize shall be awarded to the person who "...shall have done the most or the best work for fraternity between nations, for the abolition or reduction of standing armies and for the holding and promotion of peace congresses."

In creating the Rhodes Scholarships for outstanding students from the United States, Germany and much of the British Empire, Cecil Rhodes wrote in 1901 that 'the object is that an understanding between the three great powers will render war impossible and educational relations make the strongest tie'. This peace purpose of the Rhodes Scholarships was very prominent in the first half of the 20th century, and became prominent again in recent years under Warden of the Rhodes House Donald Markwell, a historian of thought about the causes of war and peace. This vision greatly influenced Senator J. William Fulbright in the goal of the Fulbright fellowships to promote international understanding and peace, and has guided many other international fellowship programs, including the Schwarzman Scholars to China created by Stephen A. Schwarzman in 2013.

The International Gandhi Peace Prize, named after Mahatma Gandhi, is awarded annually by the Government of India. It is launched as a tribute to the ideals espoused by Gandhi in 1995 on the occasion of the 125th anniversary of his birth. This is an annual award given to individuals and institutions for their contributions towards social, economic and political transformation through non-violence and other Gandhian methods. The award carries Rs. 10 million in cash, convertible in any currency in the world, a plaque and a citation. It is open to all persons regardless of nationality, race, creed or sex.

The Student Peace Prize is awarded biennially to a student or a student organization that has made a significant contribution to promoting peace and human rights.

The Culture of Peace News Network, otherwise known simply as CPNN, is a UN authorized interactive online news network, committed to supporting the global movement for a culture of peace.

Every year in the first week of November, the Sydney Peace Foundation presents the Sydney Peace Prize. The Sydney Peace Prize is awarded to an organization or an individual whose life and work has demonstrated significant contributions to:
The achievement of peace with justice locally, nationally or internationally
The promotion and attainment of human rights
The philosophy, language and practice of non violence

A peace museum is a museum that documents historical peace initiatives. Many peace museums also provide advocacy programs for nonviolent conflict resolution. This may include conflicts at the personal, regional or international level.

Smaller institutions:

The following are monuments to peace:

Many different theories of "peace" exist in the world of peace studies, which involves the study of de-escalation, conflict transformation, disarmament, and cessation of violence. The definition of "peace" can vary with religion, culture, or subject of study.

One definition is that peace is a state of balance and understanding in yourself and between others, where respect is gained by the acceptance of differences, tolerance persists, conflicts are resolved through dialog, people's rights are respected and their voices are heard, and everyone is at their highest point of serenity without social tension.

The "Peace & War Game" is an approach in game theory to understand the relationship between peace and conflicts.

The iterated game hypotheses was originally used by academic groups and computer simulations to study possible strategies of cooperation and aggression.

As peace makers became richer over time, it became clear that making war had greater costs than initially anticipated. One of the well studied strategies that acquired wealth more rapidly was based on Genghis Khan, i.e. a constant aggressor making war continually to gain resources. This led, in contrast, to the development of what's known as the "provokable nice guy strategy", a peace-maker until attacked, improved upon merely to win by occasional forgiveness even when attacked.

There exists a strategy of multiple players who can continue to gain wealth cooperating with each other while bleeding a constantly aggressive player. 

The classical "realist" position is that the key to promoting order between states, and so of increasing the chances of peace, is the maintenance of a balance of power between states - a situation where no state is so dominant that it can "lay down the law to the rest". Exponents of this view have included Metternich, Bismarck, Hans Morgenthau, and Henry Kissinger. A related approach - more in the tradition of Hugo Grotius than Thomas Hobbes - was articulated by the so-called "English school of international relations theory" such as Martin Wight in his book "Power Politics" (1946, 1978) and Hedley Bull in "The Anarchical Society" (1977).

As the maintenance of a balance of power could in some circumstances require a willingness to go to war, some critics saw the idea of a balance of power as promoting war rather than promoting peace. This was a radical critique of those supporters of the Allied and Associated Powers who justified entry into World War I on the grounds that it was necessary to preserve the balance of power in Europe from a German bid for hegemony.

In the second half of the 20th century, and especially during the cold war, a particular form of balance of power - mutual nuclear deterrence - emerged as a widely held doctrine on the key to peace between the great powers. Critics argued that the development of nuclear stockpiles increased the chances of war rather than peace, and that the "nuclear umbrella" made it "safe" for smaller wars (e.g. the Vietnam war and the Soviet invasion of Czechoslovakia to end the Prague Spring), so making such wars more likely.

The democratic peace theory holds that democracies will never go to war with one another.

It was a central tenet of classical liberalism, for example among English liberal thinkers of the late 19th and early 20th century, that free trade promoted peace. For example, the Cambridge economist John Maynard Keynes (1883-1946) said that he was "brought up" on this idea and held it unquestioned until at least the 1920s. During the economic globalization in the decades leading up to World War I, writers such as Norman Angell argued that the growth 
of economic interdependence between the great powers made war between them futile and therefore unlikely. He made this argument in 1914.

These ideas have again come to prominence among liberal internationalists during the globalization of the late 20th and early 21st century. These ideas have seen capitalism as consistent with, even conducive to, peace.

Socialist, communist, and left-wing liberal writers of the 19th and 20th centuries (e.g., Lenin, J.A. Hobson, John Strachey) argued that capitalism caused war (e.g. through promoting imperial or other economic rivalries that lead to international conflict). This led some to argue that international socialism was the key to peace.

However, in response to such writers in the 1930s who argued that capitalism caused war, the economist John Maynard Keynes (1883-1946) argued that managed capitalism could promote peace. This involved international coordination of fiscal/monetary policies, an international monetary system that did not pit the interests of countries against each other, and a high degree of freedom of trade. These ideas underlay Keynes's work during World War II that led to the creation of the International Monetary Fund and the World Bank at Bretton Woods in 1944, and later of the General Agreement on Tariffs and Trade (subsequently the World Trade Organization).

Borrowing from the teachings of Norwegian theorist Johan Galtung, one of the pioneers of the field of Peace Research, on 'Positive Peace', and on the writings of Maine Quaker Gray Cox, a consortium of theorists, activists, and practitioners in the experimental John Woolman College initiative have arrived at a theory of "active peace". This theory posits in part that peace is part of a triad, which also includes justice and wholeness (or well-being), an interpretation consonant with scriptural scholarly interpretations of the meaning of the early Hebrew word "shalom". Furthermore, the consortium have integrated Galtung's teaching of the meanings of the terms peacemaking, peacekeeping, and peacebuilding, to also fit into a triadic and interdependent formulation or structure. Vermont Quaker John V. Wilmerding posits five stages of growth applicable to individuals, communities, and societies, whereby one transcends first the 'surface' awareness that most people have of these kinds of issues, emerging successively into acquiescence, pacifism, passive resistance, active resistance, and finally into "active peace", dedicating themselves to peacemaking, peacekeeping or peace building.

One of the most influential theories of peace, especially since Woodrow Wilson led the creation of the League of Nations at the Paris Peace Conference of 1919, is that peace will be advanced if the intentional anarchy of states is replaced through the growth of international law promoted and enforced through international organizations such as the League of Nations, the United Nations, and other functional international organizations. One of the most important early exponents of this view was Sir Alfred Zimmern, for example in his 1936 book "The League of Nations and the Rule of Law".

Many "idealist" thinkers about international relations - e.g. in the traditions of Kant and Karl Marx - have argued that the key to peace is the growth of some form of solidarity between peoples (or classes of people) spanning the lines of cleavage between nations or states that lead to war.

One version of this is the idea of promoting international understanding between nations through the international mobility of students - an idea most powerfully advanced by Cecil Rhodes in the creation of the Rhodes Scholarships, and his successors such as J. William Fulbright.

Another theory is that peace can be developed among countries on the basis of active management of water resources.

Following Wolfgang Dietrich, Wolfgang Sützl and the Innsbruck School of Peace Studies, some peace thinkers have abandoned any single and all-encompassing definition of peace. Rather, they promote the idea of "many peaces". They argue that since no singular, correct definition of peace can exist, peace should be perceived as a plurality. This post-modern understanding of peace(s) was based on the philosophy of Jean Francois Lyotard. It served as a fundament for the more recent concept of trans-rational peace(s) and elicitive conflict transformation.

In 2008 Dietrich enlarged his approach of the "many peaces" to the so-called "five families" of peace interpretations: the energetic, moral, modern, post-modern and trans-rational approach. Trans-rationality unites the rational and mechanistic understanding of modern peace in a relational and culture-based manner with spiritual narratives and energetic interpretations. The systemic understanding of trans-rational peaces advocates a client-centred method of conflict transformation, the so-called elicitive approach.

The theory of peace without weapons is as old as philosophy and human consciousness. This theory holds that weapons in and of themselves are causative of violence, aggression, and other non-peaceful activities, and the removal of all weapons and the military, would therefore be a means of preventing such activities, thereby inducing peace. 
Some philosophical and legal manifests have been written and distributed on this theme in several languages, for select and privileged groups of highly respected and experienced experts in philosophy and law, in many countries in all continents, worldwide.
These philosophical peace manifests would be suitable for public lectures at universities in many countries in all continents, worldwide.
Some pacifist religious denominations, such as the Quakers, the Amish, and the Mennonites traditionally renounce the ownership of weapons, and routinely lobby against their manufacture and distributuon.

Peace and conflict studies is an academic field which identifies and analyses violent and nonviolent behaviours, as well as the structural mechanisms attending violent and non violent social conflicts. This is to better understand the processes leading to a more desirable human condition. One variation,
Peace studies (irenology), is an interdisciplinary effort aiming at the prevention, de-escalation, and solution of conflicts. This contrasts with war studies (polemology), directed at the efficient attainment of victory in conflicts. Disciplines involved may include political science, geography, economics, psychology, sociology, international relations, history, anthropology, religious studies, and gender studies, as well as a variety of other disciplines.

Although peace is widely perceived as something intangible, various organizations have been making efforts to quantify and measure it. The Global Peace Index produced by the Institute for Economics and Peace is a known effort to evaluate peacefulness in countries based on 23 indicators of the absence of violence and absence of the fear of violence.

The last edition of the Index ranks 163 countries on their internal and external levels of peace. According to the 2017 Global Peace Index, Iceland is the most peaceful country in the world while Syria is the least peaceful one. Fragile States Index (formerly known as the Failed States Index) created by the Fund for Peace focuses on risk for instability or violence in 178 nations. This index measures how fragile a state is by 12 indicators and subindicators that evaluate aspects of politics, social economy, and military facets in countries. The 2015 Failed State Index reports that the most fragile nation is South Sudan, and the least fragile one is Finland. University of Maryland publishes the Peace and Conflict Instability Ledger in order to measure peace. It grades 163 countries with 5 indicators, and pays the most attention to risk of political instability or armed conflict over a three-year period. The most recent ledger shows that the most peaceful country is Slovenia on the contrary Afghanistan is the most conflicted nation. Besides indicated above reports from the Institute for Economics and Peace, Fund for Peace, and University of Maryland, other organizations including George Mason University release indexes that rank countries in terms of peacefulness.



</doc>
<doc id="24703" url="https://en.wikipedia.org/wiki?curid=24703" title="Portland Vase">
Portland Vase

The Portland Vase is a Roman cameo glass vase, which is dated to between AD 1 and AD 25, though low BC dates have some scholarly support. It is the best known piece of Roman cameo glass and has served as an inspiration to many glass and porcelain makers from about the beginning of the 18th century onwards. It is first recorded in Rome in 1600–1601, and since 1810 has been in the British Museum in London. It was bought by the museum in 1945 (GR 1945,0927.1) and is normally on display in Room 70.

The vase is about high and in circumference. It is made of violet-blue glass, and surrounded with a single continuous white glass cameo making two distinct scenes, depicting seven human figures, plus a large snake, and two bearded and horned heads below the handles, marking the break between the scenes.

The bottom of the vase was a cameo glass disc, also in blue and white, showing a head, presumed to be of Paris or Priam on the basis of the Phrygian cap it wears. This roundel clearly does not belong to the vase, and has been displayed separately since 1845. It may have been added to mend a break in antiquity or after, or the result of a conversion from an original amphora form (paralleled by a similar blue-glass cameo vessel from Pompeii) – it was attached to the bottom from at least 1826.

The meaning of the images on the vase is unclear, and none of the many theories put forward has been found generally satisfactory. They fall into two main groups: mythological and historical, though a historical interpretation of a myth is also a possibility. Historical interpretations focus on Augustus, his family and his rivals, especially given the quality and expense of the object, and the somewhat remote neo-classicism of the style, which compares with some Imperial gemstone cameos featuring Augustus and his family with divine attributes, such as the Gemma Augustea, the Great Cameo of France and the Blacas Cameo (the last also in the British Museum). Interpretations of the portrayals have included that of a marine setting (due to the presence of a ketos or sea-snake), and of a marriage theme/context, as the vase may have been a wedding gift. Many scholars (including Charles Towneley) have concluded that the figures do not fit into a single iconographic set.

Interpretations include:

Interpretations include:

Another variant theory is that the vase dates back to circa 32 BC, and was commissioned by Octavian (later Caesar Augustus), as an attempt to promote his case against his fellow-consuls, Mark Antony and Marcus Lepidus in the period after the death of Julius Caesar. It is based on the skill of the famous Greek carver of engraved gems Dioskourides, who is recorded as active and at his peak circa 40–15 BC and three of whose attributed cameos bear a close resemblance in line and quality to the Portland vase figures. This theory proposes that the first two figures are Gaius Octavius, father of the future emperor, and Attia Julia Balboa, his mother (hence Cupid with the arrow) who had a dream of being impregnated by Apollo in the form of a sea serpent (ketos), note the snake's prominent teeth. The onlooker with his staff, could be Aeneas, a hero of the Trojan Wars who saved his father by carrying over his back (hence his hunched position, and his Trojan beard) and who is believed to have founded Rome, and from whom the Julian gens, including Julius Caesar and Attia, claimed descent, witnessing the conception of Rome's future savior as an Empire, and the greatest of all the Emperors.

On the reverse is Octavian, Octavia his sister, widow of Mark Anthony (downcast flambeau, broken tablets) and Livia, Octavian's third wife who outlived him. These two are looking directly at each other. Octavian commanded she divorce her then husband and marry him with a few weeks of meeting, she was mother to the future Emperor Tiberius.

This vase suggests Octavian was descended partly from Apollo (thus partly divine, shades of Achilles), whom he worshiped as a God, gave private parties in his honor together with Minerva, Roman Goddess of War, from the founder of Rome, and his connection to his uncle Julius Caesar, for whom as a young man he gave a remarkable funeral oratory, and who adopted him on his father's death, when he was only four. All the pieces and people fit in this theory and it explains most mysteries (apart from who actually made it). It would have been a fabulously expensive piece to commission, so that few men of the period could have afforded it. Several attempts at creating the vase must have been made, as modern reproduction trials show today (see below). Historians and archeologists dismiss this modern theory as gods and goddesses with mythical allegories were usually portrayed, but could this remarkable vase have broken convention, and shown realism in portraiture, known solely on coins of the period, before it, in turn, was broken?

Cameo-glass vessels were probably all made within about two generations, as experiments when the blowing technique (discovered in about 50 BC) was still in its infancy. Recent research suggests that the Portland vase, like the majority of cameo-glass vessels, was made by the dip-overlay method, whereby an elongated bubble of glass was partially dipped into a crucible of white glass, before the two were blown together. After cooling the white layer was cut away to form the design.

The work in making a 19th-century copy proved to be incredibly painstaking, and based on this it is believed that the Portland Vase must have taken its original artisan no less than two years to produce. The cutting was probably performed by a skilled gem-cutter. It is believed that the cutter may have been Dioskourides, as engraved gems thought to be cut by him of a similar period and signed by him (Vollenweider 1966, see Gem in the collection of the Duke of Devonshire "Diomedes stealing the Palladium") are extant. This is confirmed by the Corning Museum in their 190-page study of the vase – see above.

According to a controversial theory by Rosemarie Lierke, the vase, along with the rest of Roman cameo glass, was moulded rather than cold-cut, probably using white glass powder for the white layer.

Jerome Eisenberg has argued in "Minerva" that the vase was produced in the 16th century AD and not antiquity, because the iconography is incoherent, but this theory has not been widely accepted.

One story suggests that it was discovered by Fabrizio Lazzaro in what was then thought to be the sarcophagus of the Emperor Alexander Severus (died 235) and his mother, at Monte del Grano near Rome, and excavated some time around 1582.

The first historical reference to the vase is in a letter of 1601 from the French scholar Nicolas Claude Fabri de Peiresc to the painter Peter Paul Rubens, where it is recorded as in the collection of Cardinal Francesco Maria Del Monte in Italy. In 1626 it passed into the Barberini family collection (which also included sculptures such as the Barberini Faun and Barberini Apollo) where it remained for some two hundred years, being one of the treasures of Maffeo Barberini, later Pope Urban VIII (1623–1644). It was at this point that the Severan connection is first recorded. The vase was known as the "Barberini Vase" in this period.

Between 1778 and 1780, Sir William Hamilton, British ambassador in Naples, bought the vase from James Byres, a Scottish art dealer, who had acquired it after it was sold by Cornelia Barberini-Colonna, Princess of Palestrina. She had inherited the vase from the Barberini family. Hamilton brought it to England on his next leave, after the death of his first wife, Catherine. In 1784, with the assistance of his niece, Mary, he arranged a private sale of the vase to Margaret Cavendish-Harley, widow of William Bentinck, 2nd Duke of Portland and dowager Duchess of Portland. It was sold at auction in 1786 and passed into the possession of the duchess's son, William Cavendish-Bentinck, 3rd Duke of Portland.

The 3rd Duke lent the original vase to Josiah Wedgwood (see below) and then to the British Museum for safe-keeping, by which point it was known as the "Portland Vase". It was deposited there permanently by the fourth Duke in 1810, after a friend of his broke its base. The original Roman vase has remained in the British Museum ever since 1810, apart from three years in 1929–32 when the 6th Duke put it up for sale at Christie's where it failed to reach its reserve. It was finally purchased by the museum from the 7th Duke in 1945 with the aid of a bequest from James Rose Vallentin.

The 3rd Duke lent the vase to Josiah Wedgwood, who had already had it described to him as "the finest production of Art that has been brought to England and seems to be the very apex of perfection to which you are endeavoring" by the sculptor John Flaxman. Wedgwood devoted four years of painstaking trials at duplicating the vase – not in glass but in black and white jasperware. He had problems with his copies ranging from cracking and blistering (clearly visible on the example at the Victoria and Albert Museum) to the sprigged reliefs 'lifting' during the firing, and in 1786 he feared that he could never apply the Jasper relief thinly enough to match the glass original's subtlety and delicacy. He finally managed to perfect it in 1790, with the issue of the "first-edition" of copies (with some of this edition, including the V&A one, copying the cameo's delicacy by a combination of undercutting and shading the reliefs in grey), and it marks his last major achievement.

Wedgwood put the first edition on private show between April and May 1790, with that exhibition proving so popular that visitor numbers had to be restricted by only printing 1,900 tickets, before going on show in his public London showrooms. (One ticket to the private exhibition, illustrated by Samuel Alkin and printed with 'Admission to see Mr Wedgwood's copy of The Portland Vase, Greek Street, Soho, between 12 o'clock and 5', was bound into the Wedgwood catalogue on view in the Victoria and Albert Museum's British Galleries.) As well as the V&A copy (said to have come from the collection of Wedgwood's grandson, the naturalist Charles Darwin)
, others are held at the Fitzwilliam Museum (this is the copy sent by Wedgwood to Erasmus Darwin which his descendants lent to the Museum in 1963 and later sold to them); the Indianapolis Museum of Art and the Department of Prehistory and Europe at the British Museum.

The vase also inspired a 19th-century competition to duplicate its cameo-work in glass, with Benjamin Richardson offering a £1,000 prize to anyone who could achieve that feat. Taking three years, glass maker Philip Pargeter made a copy and John Northwood engraved it, to win the prize. This copy is in the Corning Museum of Glass in Corning, New York.

The Wedgwood Museum, in Barlaston, near Stoke-on-Trent, contains a display describing the trials of replicating the vase, and several examples of the early experiments are shown.

On 7 February 1845, the vase was shattered by William Lloyd, who, after drinking all the previous week, threw a nearby sculpture on top of the case, smashing both it and the vase. He was arrested and charged with the crime of wilful damage. When his lawyer pointed out an error in the wording of the act which seemed to limit its application to the destruction of objects worth no more than five pounds, he was convicted instead of the destruction of the glass case in which the vase had sat. He was ordered to pay a fine of three pounds or spend two months in prison. He remained in prison until an anonymous benefactor paid the fine by mail. The name William Lloyd is thought to be a pseudonym. Investigators hired by the British Museum concluded that he was actually William Mulcahy, a student who had gone missing from Trinity College. Detectives reported that the Mulcahy family was impoverished. The owner of the vase declined to bring a civil action against William Mulcahy because he did not want his family to suffer for "an act of folly or madness which they could not control".

The vase was pieced together with fair success, though the restorer was unable to replace all of the pieces and thirty-seven small fragments were left when he was done. It appears they had been put into a box and forgotten. In 1948, the keeper Bernard Ashmole received thirty-seven fragments in a box from Mr Croker of Putney, who did not know what they were. In 1845 John Doubleday, the first restorer, had not been able to determine where these fragments went. A colleague took them to Mr Gabb, a box maker, who was asked to make a box with thirty seven compartments, one for each fragment. The colleague died, the box was never collected, Mr Gabb died and his executrix Miss Revees asked Croker to ask the museum if they could identify them.

By 1948, the restoration appeared aged and it was decided to restore the vase again, but the restorer was successful in replacing only three fragments. The adhesive from this weakened: by 1986 the joints rattled when the vase was gently tapped.

The third and current reconstruction took place from 1 June 1988 and was completed on 1 October 1989 by Nigel Williams and Sandra Smith, and overseen by David Akehurst (CCO of Glass and Ceramics) who had assessed the vase's condition during its appearance as the focal piece of an international exhibition of Roman glass and, at the conclusion of the exhibition, it was decided to go ahead with reconstruction and stabilization. The treatment had scholarly attention and press coverage. The vase was photographed and drawn to record the position of fragments before dismantling; the BBC filmed the conservation process. All the adhesives used in previous restorations had deteriorated, so to find one that would last, conservation scientists at the museum tested many adhesives for long-term stability. Finally, an epoxy resin with excellent ageing properties was chosen. Reassembly of the vase was made more difficult as the edges of some fragments were found to have been filed down during the restorations. Nevertheless, all of the fragments were replaced except for a few small splinters. Areas that were still missing were gap-filled with a blue or white resin.

The newly conserved Portland Vase was returned to display. Little sign of the original damage is visible and, except for light cleaning, the vase should not require major conservation work for many years.





</doc>
<doc id="24705" url="https://en.wikipedia.org/wiki?curid=24705" title="Patrimony">
Patrimony

Patrimony may refer to:





</doc>
<doc id="24707" url="https://en.wikipedia.org/wiki?curid=24707" title="Pyrenees">
Pyrenees

The Pyrenees (; , , , , , ) is a range of mountains in southwest Europe that forms a natural border between Spain and France. Reaching a height of altitude at the peak of Aneto, the range separates the Iberian Peninsula from the rest of continental Europe, and extends for about from the Bay of Biscay (Cap Higuer) to the Mediterranean Sea (Cap de Creus).

For the most part, the main crest forms a divide between Spain and France, with the microstate of Andorra sandwiched in between. The Principality of Catalonia alongside with the Kingdom of Aragon in the Crown of Aragon, Occitania and the Kingdom of Navarre have historically extended on both sides of the mountain range, with smaller northern portions now in France and larger southern parts now in Spain.

The demonym for the noun "Pyrenees" in English is "Pyrenean".

In Greek mythology, Pyrene is a princess who gave her name to the Pyrenees. The Greek historian Herodotus says Pyrene is the name of a town in Celtic Europe. According to Silius Italicus, she was the virgin daughter of Bebryx, a king in Mediterranean Gaul by whom the hero Hercules was given hospitality during his quest to steal the cattle of Geryon during his famous Labors. Hercules, characteristically drunk and lustful, violates the sacred code of hospitality and rapes his host's daughter. Pyrene gives birth to a serpent and runs away to the woods, afraid that her father will be angry. Alone, she pours out her story to the trees, attracting the attention of wild beasts who tear her to pieces.

After his victory over Geryon, Hercules passes through the kingdom of Bebryx again, finding the girl's lacerated remains. As is often the case in stories of this hero, the sober Hercules responds with heartbroken grief and remorse at the actions of his darker self, and lays Pyrene to rest tenderly, demanding that the surrounding geography join in mourning and preserve her name: "struck by Herculean voice, the mountaintops shudder at the ridges; he kept crying out with a sorrowful noise 'Pyrene!' and all the rock-cliffs and wild-beast haunts echo back 'Pyrene!' … The mountains hold on to the wept-over name through the ages." Pliny the Elder connects the story of Hercules and Pyrene to Lusitania, but rejects it as "fabulosa", highly fictional.

Other classical sources derived the name from the Greek word for fire, (IPA: /pŷːr/). According to Greek historian Diodorus Siculus "..in ancient times, we are told, certain herdsmen left a fire and the whole area of the mountains was entirely consumed; and due to this fire, since it raged continuously day after day, the surface of the earth was also burned and the mountains, because of what had taken place, were called the Pyrenees."

The Spanish Pyrenees are part of the following provinces, from east to west: Girona, Barcelona, Lleida (all in Catalonia), Huesca (in Aragon), Navarra (in Navarre) and Gipuzkoa (in the Basque Country).

The French Pyrenees are part of the following "départements", from east to west: Pyrénées-Orientales (North Catalonia and Fenolheda), Aude, Ariège, Haute-Garonne, Hautes-Pyrénées, and Pyrénées-Atlantiques (the latter two of which include the Pyrenees National Park).

The independent principality of Andorra is sandwiched in the eastern portion of the mountain range between the Spanish Pyrenees and French Pyrenees.

Physiographically, the Pyrenees may be divided into three sections: the Atlantic (or Western), the Central, and the Eastern Pyrenees. Together, they form a distinct physiographic province of the larger Alpine System division.

In the Western Pyrenees, from the Basque mountains near the Bay of Biscay of the Atlantic Ocean, the average elevation gradually increases from west to east.

The Central Pyrenees extend eastward from the Somport pass to the Aran Valley, and they include the highest summits of this range:

In the Eastern Pyrenees, with the exception of one break at the eastern extremity of the "Pyrénées Ariègeoises" in the Ariège area, the mean elevation is remarkably uniform until a sudden decline occurs in the easternmost portion of the chain known as the Albères.

Most foothills of the Pyrenees are on the Spanish side, where there is a large and complex system of ranges stretching from Spanish Navarre, across northern Aragon and into Catalonia, almost reaching the Mediterranean coast with summits reaching . At the eastern end on the southern side lies a distinct area known as the Sub-Pyrenees.

On the French side the slopes of the main range descend abruptly and there are no foothills except in the Corbières Massif in the northeastern corner of the mountain system.

The Pyrenees are older than the Alps: their sediments were first deposited in coastal basins during the Paleozoic and Mesozoic eras. Between 100 and 150 million years ago, during the Lower Cretaceous Period, the Bay of Biscay fanned out, pushing present-day Spain against France and applying intense compressional pressure to large layers of sedimentary rock. The intense pressure and uplifting of the Earth's crust first affected the eastern part and moved progressively to the entire chain, culminating in the Eocene Epoch.

The eastern part of the Pyrenees consists largely of granite and gneissose rocks, while in the western part the granite peaks are flanked by layers of limestone. The massive and unworn character of the chain comes from its abundance of granite, which is particularly resistant to erosion, as well as weak glacial development.

The upper parts of the Pyrenees contain low-relief surfaces forming a peneplain. This peneplain originated no earlier than in Late Miocene times. Presumably it formed at height as extensive sedimentation raised the local base level considerably.

Conspicuous features of Pyrenean scenery are:

The highest waterfall is Gavarnie (462 m or 1,515 ft), at the head of the Gave de Pau; the Cirque de Gavarnie, in the same valley, together with the nearby Cirque de Troumouse and Cirque d'Estaubé, are notable examples of the cirque formation. 

Low passes are lacking, and the principal roads and the railroads between France and Spain run only in the lowlands at the western and eastern ends of the Pyrenees, near sea level. The main passes of note are:
Because of the lack of low passes a number of tunnels have been created, beneath the passes at Somport, Envalira, and Puymorens and new routes in the center of the range at Bielsa and Vielha.

A notable visual feature of this mountain range is La Brèche de Roland, a gap in the ridge line, whichaccording to legendwas created by Roland.

The metallic ores of the Pyrenees are not in general of much importance now, though there were iron mines at several locations in Andorra, as well as at Vicdessos in Ariège, and the foot of Canigou in Pyrénées-Orientales long ago. Coal deposits capable of being profitably worked are situated chiefly on the Spanish slopes, but the French side has beds of lignite. The open pit of Trimoun near the commune of Luzenac (Ariège) is one of the greatest sources of talc in Europe.

Mineral springs are abundant and remarkable, and especially noteworthy are the hot springs. The hot springs, among which those of Les Escaldes in Andorra, Panticosa and Lles in Spain, Ax-les-Thermes, Bagnères-de-Luchon and Eaux-Chaudes in France may be mentioned, are sulfurous and mostly situated high, near the contact of the granite with the stratified rocks. The lower springs, such as those of Bagnères-de-Bigorre (Hautes-Pyrénées), Rennes-les-Bains (Aude), and Campagne-sur-Aude (Aude), are mostly selenitic and not hot.

The amount of precipitation the range receives, including rain and snow, is much greater in the western than in the eastern Pyrenees because of the moist air that blows in from the Atlantic Ocean over the Bay of Biscay. After dropping its moisture over the western and central Pyrenees, the air is left dry over the eastern Pyrenees. The winter average temperature is -2 °C (28.4 °F).

Sections of the mountain range vary in more than one respect. There are some glaciers in the western and snowy central Pyrenees, but there are no glaciers in the eastern Pyrenees because there is insufficient snowfall to cause their development. Glaciers are confined to the northern slopes of the central Pyrenees, and do not descend, like those of the Alps, far down into the valleys but rather have their greatest lengths along the direction of the mountain chain. They form, in fact, in a narrow zone near the crest of the highest mountains. Here, as in the other great mountain ranges of central Europe, there is substantial evidence of a much wider expanse of glaciation during the glacial periods. The best evidence of this is in the valley of Argeles Gazost, between Lourdes and Gavarnie, in the "" of Hautes-Pyrénées.

The annual snow-line varies in different parts of the Pyrenees from about 2,700 to 2,800 metres above sea level. In average the seasonal snow is observed at least 50% of the time above 1,600 metres between December and April.

A still more marked effect of the preponderance of rainfall in the western half of the chain is seen in the vegetation. The lower mountains in the extreme west are wooded, but the extent of forest declines as one moves eastwards. The eastern Pyrenees are peculiarly wild and barren, all the more since it is in this part of the chain that granitic masses prevail. Also moving from west to east, there is a change in the composition of the flora, with the change becoming most evident as one passes the centre of the mountain chain from which point the Corbières stretch north-eastwards towards the central plateau of France. Though the difference in latitude is only about 1°, in the west the flora resembles that of central Europe while in the east it is distinctly Mediterranean in character. The Pyrenees are nearly as rich in endemic species as the Alps, and among the most remarkable instances of that endemism is the occurrence of the monotypic genus "Xatardia" (family Apiaceae), which grows only on a high alpine pass between the Val d'Eynes and Catalonia. Other examples include "Arenaria montana", "Bulbocodium vernum", and "Ranunculus glacialis". The genus most abundantly represented in the range is that of the saxifrages, several species of which are endemic here.

In their fauna the Pyrenees present some striking instances of endemism. The Pyrenean desman is found only in some of the streams of the northern slopes of these mountains; the only other desmans are confined to the rivers of the Caucasus in southern Russia. The Pyrenean euprocte ("Euproctus pyrenaicus"), an endemic relative of the salamander, also lives in streams and lakes located at high altitudes. Among other peculiarities of Pyrenean fauna are blind insects in the caverns of Ariège, the principal genera of which are "Anophthalmus" and "Adelops".

The Pyrenean ibex mysteriously became extinct in January 2000; the native Pyrenean brown bear was hunted to near-extinction in the 1990s, but it was re-introduced in 1996 when three bears were brought from Slovenia. The bear population has bred successfully, and there are now believed to be about 15 brown bears in the central region around Fos, but only four native ones are still living in the Aspe Valley.

Principal nature reserves and national parks:

The Pyrenean region possesses a varied ethnology, folklore and history: see Andorra; Aragon; Ariège; Basque Country; Béarn; Catalonia; Navarre; Roussillon. For their history, see also Almogavars, Marca Hispanica.

The principal languages spoken in the area are Spanish, French, Aragonese, Catalan (in Catalonia and Andorra), and Basque.
Also spoken, to a lesser degree, are the Occitan language (the Gascon and Languedocien dialects in France and the Aranese dialect in the Aran Valley).

An important feature of rural life in the Pyrenees is 'transhumance', the moving of livestock from the farms in the valleys up to the higher grounds of the mountains for the summer. In this way the farming communities could keep larger herds than the lowland farms could support on their own. The principal animals moved were cows and sheep, but historically most members of farming families also moved to the higher pastures along with their animals, so they also took with them pigs, horses and chickens. Transhumance thus took the form of a mass biannual migration, moving uphill in May or June and returning to the farms in September or October. During the summer period, the families would live in basic stone cabins in the high mountains. Nowadays, industrialisation and changing agriculture practices have diminished the custom. However, the importance of transhumance continues to be recognised through its celebration in popular festivals.

The following is the complete list of the summits of the Pyrenees above three-thousand meters:

Both sides of the Pyrenees are popular spots for winter sports such as alpine skiing and mountaineering. The Pyrenees are also a good place for athletes to do high-altitude training in the summertime, such as by bicycling and cross-country running.

In the summer and the autumn, the Pyrenees are usually featured in two of cycling's grand tours, the Tour de France held annually in July and the Vuelta a España held in September. The stages held in the Pyrenees are often crucial legs of both tours, drawing hundreds of thousands of spectators to the region.

Three main long-distance footpaths run the length of the mountain range: the GR 10 across the northern slopes, the GR 11 across the southern slopes, and the HRP which traverses peaks and ridges along a high altitude route. In addition, there are numerous marked and unmarked trails throughout the region.

"Pirena" is a dog-mushing competition held in the Pyrenees.

Ski resorts in the Pyrenees include:





</doc>
<doc id="24709" url="https://en.wikipedia.org/wiki?curid=24709" title="Planetary nomenclature">
Planetary nomenclature

Planetary nomenclature, like terrestrial nomenclature, is a system of uniquely identifying features on the surface of a planet or natural satellite so that the features can be easily located, described, and discussed. Since the invention of the telescope, astronomers have given names to the surface features they have discerned, especially on the Moon and Mars. To standardize planetary nomenclature, the International Astronomical Union (IAU) was assigned in 1919 the task of selecting official names for features on solar system bodies.

When images are first obtained of the surface of a planet or satellite, a theme for naming features is chosen and a few important features are named, usually by members of the appropriate IAU task group (a commonly accepted planet-naming group). Later, as higher resolution images and maps become available, additional features are named at the request of investigators mapping or describing specific surfaces, features, or geologic formations. Anyone may suggest that a specific name be considered by a task group. If the members of the task group agree that the name is appropriate, it can be retained for use when there is a request from a member of the scientific community that a specific feature be named. Names successfully reviewed by a task group are submitted to the IAU Working Group for Planetary System Nomenclature (WGPSN). Upon successful review by the members of the WGPSN, names are considered provisionally approved and can be used on maps and in publications as long as the provisional status is clearly stated. Provisional names are then presented for adoption to the IAU's General Assembly, which met triennially in the past, and which now adopts nomenclature for planetary surface features as required. A name is not considered to be official — that is, "adopted" — until the General Assembly has given its approval.

Names adopted by the IAU must follow various rules and conventions established and amended through the years by the Union. These include:


In addition to these general rules, each task group develops additional conventions as it formulates an interesting and meaningful nomenclature for individual planetary bodies.

Names for all planetary features include a descriptor term, with the exception of two feature types. For craters, the descriptor term is implicit. Some features named on Io and Triton do not carry a descriptor term because they are ephemeral.

In general, the naming convention for a feature type remains the same regardless of its size. Exceptions to this rule are valleys and craters on Mars and Venus; naming conventions for these features differ according to size.

One feature classification, "regio", was originally used on early maps of the Moon and Mercury (drawn from telescopic observations) to describe vague albedo features. It is now used to delineate a broad geographic region.

Named features on bodies so small that coordinates have not yet been determined are identified on drawings of the body that are included in the IAU Transactions volume of the year when the names were adopted. Satellite rings and gaps in the rings are named for scientists who have studied these features; drawings that show these names are also included in the pertinent Transactions volume. Names for atmospheric features are informal at present; a formal system will be chosen in the future.

The boundaries of many large features (such as "terrae, regiones, planitiae" and "plana") are not topographically or geomorphically distinct; the coordinates of these features are identified from an arbitrarily chosen center point. Boundaries (and thus coordinates) may be determined more accurately from geochemical and geophysical data obtained by future missions.

During active missions, small surface features are often given informal names. These may include landing sites, spacecraft impact sites, and small topographic features, such as craters, hills, and rocks. Such names will not be given official status by the IAU, except as provided for by Rule 2 above. As for the larger objects, official names for any such small features would have to conform to established IAU rules and categories.

All but three features on Venus are named after females. These three exceptions were named before the convention was adopted, being respectively Alpha Regio, Beta Regio, and Maxwell Montes which is named after James Clerk Maxwell.

When space probes have landed on Mars, individual small features such as rocks, dunes, and hollows have often been given informal names. Many of these are frivolous: features have been named after ice cream (such as Cookies N Cream); cartoon characters (such as SpongeBob SquarePants and Patrick); and '70s music acts (such as ABBA and the Bee Gees).

Features on Deimos are named after authors who wrote about Martian satellites. There are currently two named features on Deimos - Swift crater and Voltaire crater - after Jonathan Swift and Voltaire who predicted the presence of Martian moons.

All features on Phobos are named after scientists involved with the discovery, dynamics, or properties of the Martian satellites or people and places from Jonathan Swift's "Gulliver's Travels".

People and places associated with the Amalthea myth

Features on Thebe are named after people and places associated with the Thebe myth. There is only one named feature on Thebe - Zethus Crater.

People from myth of Castor and Pollux (twins)

People from myth of Castor and Pollux (twins)

People and places from Malory's "Le Morte d'Arthur" legends (Baines translation)

People and places from Burton's "Arabian Nights"

People and places from Homer's "Odyssey"

People and places from Virgil's "Aeneid"

People and places from creation myths

Sun and Moon deities

People and places from Sayers' translation of "Chanson de Roland", the only exception is Cassini Regio, which is named after its discoverer, Giovanni Cassini.

Satellites of Uranus are named for characters from the works of William Shakespeare.

Mischievous (Pucklike) spirits (class)

Characters, places from Shakespeare's plays

Light spirits (individual and class)

Dark spirits (individual)

Female Shakespearean characters, places

Shakespearean tragic heroes and places

There are currently no named features on Uranian small satellites, however the naming convention is heroines from plays by Shakespeare and Pope.

Features on Proteus are to be named after water-related spirits, gods or goddesses who are neither Greek nor Roman. The only named feature on Proteus is crater Pharos.

Geological features on Triton should be assigned aquatic names, excluding those which are Roman and Greek in origin. Possible themes for individual descriptor terms include worldwide aquatic spirits, famous terrestrial fountains or fountain locations, terrestrial aquatic features, famous terrestrial geysers or geyser locations and terrestrial islands.

There are currently no named features on Nereid. When features are discovered, they are to be named after individual nereids.

Features on other satellites of Neptune, once discovered, should be named after gods and goddesses associated with Neptune/Poseidon mythology or generic mythological aquatic beings.

In February 2017, the IAU approved the following themes for surface features on Pluto and its satellites:










</doc>
<doc id="24710" url="https://en.wikipedia.org/wiki?curid=24710" title="North American P-51 Mustang">
North American P-51 Mustang

The North American Aviation P-51 Mustang is an American long-range, single-seat fighter and fighter-bomber used during World War II and the Korean War, among other conflicts. The Mustang was designed in 1940 by North American Aviation (NAA) in response to a requirement of the British Purchasing Commission. The Purchasing Commission approached North American Aviation to build Curtiss P-40 fighters under license for the Royal Air Force (RAF). Rather than build an old design from another company, North American Aviation proposed the design and production of a more modern fighter. The prototype NA-73X airframe was rolled out on 9 September 1940, 102 days after the contract was signed, and first flew on 26 October.

The Mustang was originally designed to use the Allison V-1710 engine, which, in its earlier variants, had limited high-altitude performance. It was first flown operationally by the RAF as a tactical-reconnaissance aircraft and fighter-bomber (Mustang Mk I). The replacement of the Allison with a Rolls-Royce Merlin resulted in the P-51B/C (Mustang Mk III) model and transformed the Mustang's performance at altitudes above 15,000 ft, allowing the aircraft to compete with the Luftwaffe's fighters. The definitive version, the P-51D, was powered by the Packard V-1650-7, a license-built version of the Rolls-Royce Merlin 66 two-stage two-speed supercharged engine and was armed with six .50 caliber (12.7 mm) M2/AN Browning machine guns.

From late 1943, P-51Bs and Cs (supplemented by P-51Ds from mid-1944) were used by the USAAF's Eighth Air Force to escort bombers in raids over Germany, while the RAF's Second Tactical Air Force and the USAAF's Ninth Air Force used the Merlin-powered Mustangs as fighter-bombers, roles in which the Mustang helped ensure Allied air superiority in 1944. The P-51 was also used by Allied air forces in the North African, Mediterranean, Italian and Pacific theaters. During World War II, Mustang pilots claimed to have destroyed 4,950 enemy aircraft.

At the start of the Korean War, the Mustang, by then redesignated F-51, was the main fighter of the United Nations until jet fighters, including North American's F-86, took over this role; the Mustang then became a specialized fighter-bomber. Despite the advent of jet fighters, the Mustang remained in service with some air forces until the early 1980s. After the Korean War, Mustangs became popular civilian warbirds and air racing aircraft.

In April 1940 the British government established a purchasing commission in the United States, headed by Sir Henry Self. Self was given overall responsibility for Royal Air Force (RAF) production and research and development, and also served with Sir Wilfrid Freeman, the Air Member for Development and Production. Self also sat on the British Air Council Sub-committee on Supply (or "Supply Committee") and one of his tasks was to organize the manufacturing and supply of American fighter aircraft for the RAF. At the time, the choice was very limited, as no U.S. aircraft then in production or flying met European standards, with only the Curtiss P-40 Tomahawk coming close. The Curtiss-Wright plant was running at capacity, so P-40s were in short supply.

North American Aviation (NAA) was already supplying its Harvard trainer to the RAF, but was otherwise underused. NAA President "Dutch" Kindelberger approached Self to sell a new medium bomber, the B-25 Mitchell. Instead, Self asked if NAA could manufacture P-40s under license from Curtiss. Kindelberger said NAA could have a better aircraft with the same Allison V-1710 engine in the air sooner than establishing a production line for the P-40. The Commission stipulated armament of four .303 in (7.7 mm) machine guns (as used on the Tomahawk), a unit cost of no more than $40,000 and delivery of the first production aircraft by January 1941. In March 1940, 320 aircraft were ordered by Freeman, who had become the executive head of the Ministry of Aircraft Production and the contract was promulgated on 24 April.

The NA-73X, which was designed by a team led by lead engineer Edgar Schmued, followed the best conventional practice of the era, but included several new features. One was a wing designed using laminar flow airfoils, which were developed co-operatively by North American Aviation and the National Advisory Committee for Aeronautics (NACA). These airfoils generated very low drag at high speeds. During the development of the NA-73X, a wind tunnel test of two wings, one using NACA five-digit airfoils and the other using the new NAA/NACA 45–100 airfoils, was performed in the University of Washington Kirsten Wind Tunnel. The results of this test showed the superiority of the wing designed with the NAA/NACA 45–100 airfoils.
The other feature was a new cooling arrangement (aft positioned, single ducted water and oil radiators assembly) that reduced the cooling drag. Later they discovered that, after much development, the cooling assembly could take advantage of the "Meredith effect", in which heated air exited the radiator with a slight amount of jet thrust. Because NAA lacked a suitable wind tunnel to test this feature, it used the GALCIT wind tunnel at the California Institute of Technology. This led to some controversy over whether the Mustang's cooling system aerodynamics were developed by NAA's engineer Edgar Schmued or by Curtiss, although NAA had purchased the complete set of P-40 and XP-46 wind tunnel data and flight test reports for US$56,000. The NA-73X was also one of the first aircraft to have a fuselage lofted mathematically using conic sections; this resulted in smooth, low drag surfaces. To aid production, the airframe was divided into five main sections—forward, center, rear fuselage, and two wing halves—all of which were fitted with wiring and piping before being joined.

The prototype NA-73X was rolled out in September 1940, just 102 days after the order had been placed; it first flew on 26 October 1940, 149 days into the contract, an uncommonly short development period, even during the war. With test pilot Vance Breese at the controls, the prototype handled well and accommodated an impressive fuel load. The aircraft's three-section, semimonocoque fuselage was constructed entirely of aluminum to save weight. It was armed with four .30 caliber (7.62 mm) M1919 Browning machine guns in the wings and two .50 caliber (12.7 mm) M2 Browning machine guns mounted under the engine and firing through the propeller arc using gun-synchronizing gear.

While the United States Army Air Corps could block any sales it considered detrimental to the interests of the US, the NA-73 was considered to be a special case because it had been designed at the behest of the British. In September 1940, a further 300 NA-73s were ordered by the MAP. To ensure uninterrupted delivery, Colonel Oliver P. Echols arranged with the Anglo-French Purchasing Commission to deliver the aircraft and NAA gave two examples (41-038 and 41-039) to the USAAC for evaluation.

The Mustang was initially developed for the RAF, which was its first user. As the first Mustangs were built to British requirements, these aircraft used factory numbers and were not P-51s; the order comprised 320 NA-73s, followed by 300 NA-83s, all of which were designated North American Mustang Mark I by the RAF. The first RAF Mustangs supplied under Lend-Lease were 93 P-51s, designated Mk Ia, followed by 50 P-51As used as Mustang Mk IIs. Aircraft supplied to Britain under Lend-Lease were required for accounting purposes to be on the USAAC's books before they could be supplied to Britain. Lend-Lease aircraft destined for the RAF were first ordered and paid for on Britain's behalf by the USAAC.

After the arrival of the initial aircraft in the UK in October 1941, the first Mustang Mk Is entered service in January 1942, the first unit being 26 Squadron RAF. Due to poor high-altitude performance, the Mustangs were used by Army Co-operation Command, rather than Fighter Command, and were used for tactical reconnaissance and ground-attack duties. On 10 May 1942, Mustangs first flew over France, near Berck-sur-Mer. On 27 July 1942, 16 RAF Mustangs undertook their first long-range reconnaissance mission over Germany. During the amphibious Dieppe Raid on the French coast (19 August 1942), four British and Canadian Mustang squadrons, including 26 Squadron, saw action covering the assault on the ground. By 1943–1944, British Mustangs were used extensively to seek out V-1 flying bomb sites. The last RAF Mustang Mk I and Mustang Mk II aircraft were struck off charge in 1945.
The RAF also operated 308 P-51Bs and 636 P-51Cs, which were known in RAF service as Mustang Mk IIIs; the first units converted to the type in late 1943 and early 1944. Mustang Mk III units were operational until the end of World War II, though many units had already converted to the Mustang Mk IV (P-51D) and Mk IVa (P-51K) (828 in total, comprising 282 Mk IV and 600 Mk IVa). As all except the earliest aircraft were obtained under Lend-Lease, all Mustang aircraft still on RAF charge at the end of the war were either returned to the USAAF "on paper" or retained by the RAF for scrapping. The last RAF Mustangs were retired from service in 1947.

Prewar doctrine was based on the idea "the bomber will always get through". Despite RAF and Luftwaffe experience with daylight bombing, the USAAC still believed in 1942 that tightly packed formations of bombers would have so much firepower that they could fend off fighters on their own. Fighter escort was low-priority and when an escort fighter was planned in 1941, a heavy fighter with twin engines, such as the Lockheed P-38 Lightning, was considered to be most appropriate. Another school of thought favored a heavily up-armed "gunship" conversion of a strategic bomber. A single-engined, high-speed fighter with the range of a bomber was thought to be an engineering impossibility.

The 8th Air Force started operations from Britain in August 1942. At first, because of the limited scale of operations, no conclusive evidence showed American doctrine was failing. In the 26 operations flown to the end of 1942, the loss rate had been under 2%.

In January 1943, at the Casablanca Conference, the Allies formulated the Combined Bomber Offensive (CBO) plan for "round-the-clock" bombing – USAAF daytime operations complementing the RAF nighttime raids on industrial centers. In June 1943, the Combined Chiefs of Staff issued the Pointblank Directive to destroy the Luftwaffe's capacity before the planned invasion of Europe, putting the CBO into full implementation. German daytime fighter efforts were, at that time, focused on the Eastern Front and several other distant locations. Initial efforts by the 8th met limited and unorganized resistance, but with every mission, the Luftwaffe moved more aircraft to the west and quickly improved their battle direction. In fall 1943, the 8th Air Force's heavy bombers conducted a series of deep-penetration raids into Germany, beyond the range of escort fighters. The Schweinfurt–Regensburg mission in August lost 60 B-17s of a force of 376, the 14 October attack lost 77 of a force of 291—26% of the attacking force. Losses were so severe that long-range missions were called off for a time until an effective escort could be found.

For the US, the very concept of self-defending bombers was called into question, but instead of abandoning daylight raids and turning to night bombing, as the RAF suggested, they chose other paths; at first, a bomber with more guns (the Boeing YB-40) was believed to be able to escort the bomber formations, but when the concept proved to be unsuccessful, thoughts then turned to the Lockheed P-38 Lightning. In early 1943, the USAAF also decided that the Republic P-47 Thunderbolt and P-51B be considered for the role of a smaller escort fighter, and in July, a report stated that the P-51B was "the most promising plane" with an endurance of 4 hours 45 minutes with the standard internal fuel of 184 gallons plus 150 gallons carried externally. In August, a P-51B was fitted with an extra internal 85-gallon tank, and although problems with longitudinal stability occurred and some compromises in performance with the tank full were made, and because the fuel from the fuselage tank would be used during the initial stages of a mission, the fuel tank would be fitted in all Mustangs destined for VIII Fighter Command.

The P-51 Mustang was a solution to the need for an effective bomber escort. It used a common, reliable engine and had internal space for a large fuel load. With external fuel tanks, it could accompany the bombers from England to Germany and back.

However, the Allison engine in the P-51A had a single-stage supercharger that caused power to drop off rapidly above 15,000 ft. This made it unsuitable for combat at the altitudes where USAAF bombers planned to fly. Following the RAF's initial disappointing experience with the Mustang I (P-51A) Ronald Harker, a test pilot for Rolls-Royce, suggested fitting a Merlin 61, as fitted to the Spitfire Mk IX. The Merlin 61 had a two-speed, two-stage, intercooled supercharger, designed by Stanley Hooker of Rolls-Royce, and this gave an increase in horsepower from the Allison's 1,200 hp (895 kW) to 1,620 hp (1,208 kW) (1,720 hp in War Emergency Power) delivering an increase of top speed from , as well as raising the service ceiling to almost 42,000 ft (12,800 m). Initial flights of what was known to Rolls-Royce as the Mustang Mk X were completed at Rolls-Royce's airfield at Hucknall in October 1942.
At the same time, the possibility of combining the P-51 airframe with the US license-built Packard version of the Merlin engine was being explored on the other side of the Atlantic. In July 1942 a contract was let for two prototypes, briefly designated XP-78 but soon to become the XP-51B. The first flight of the XP-51B took place in November 1942, but the USAAF was so interested in the possibility that an initial contract for 400 aircraft was placed three months beforehand in August. The conversion led to production of the P-51B beginning at North American's Inglewood, California, plant in June 1943, and P-51s started to become available to the 8th and 9th Air Forces in the winter of 1943–1944. During the conversion to the two-stage, supercharged Merlin engine, which was slightly heavier than the single-stage Allison, so moved the aircraft's centre-of-gravity forward, North American's engineers took the opportunity to add a large additional fuselage fuel tank behind the pilot, greatly increasing the aircraft's range over that of the earlier P-51A.

By the time the "Pointblank" offensive resumed in early 1944, matters had changed. Bomber escort defences were initially layered, using the shorter-range P-38s and P-47s to escort the bombers during the initial stages of the raid before handing over to the P-51s when they were forced to turn for home. This provided continuous coverage during the raid. The Mustang was so clearly superior to earlier US designs that the 8th Air Force began to steadily switch its fighter groups to the Mustang, first swapping arriving P-47 groups to the 9th Air Force in exchange for those that were using P-51s, then gradually converting its Thunderbolt and Lightning groups. By the end of 1944, 14 of its 15 groups flew the Mustang.

The Luftwaffe's twin-engined Messerschmitt Bf 110 heavy fighters brought up to deal with the bombers proved to be easy prey for the Mustangs, and had to be quickly withdrawn from combat. The Focke-Wulf Fw 190A, already suffering from poor high-altitude performance, was outperformed by the Mustang at the B-17's altitude, and when laden with heavy bomber-hunting weapons as a replacement for the more vulnerable twin-engined "Zerstörer" heavy fighters, it suffered heavy losses. The Messerschmitt Bf 109 had comparable performance at high altitudes, but its lightweight airframe was even more greatly affected by increases in armament. The Mustang's much lighter armament, tuned for antifighter combat, allowed it to overcome these single-engined opponents.

At the start of 1944, Major General James Doolittle, the new commander of the 8th Air Force, ordered many fighter pilots to stop flying in formation with the bombers and instead attack the "Luftwaffe" wherever it could be found. The aim was to achieve air supremacy. Mustang groups were sent far ahead of the bombers in a "fighter sweep" in order to intercept attacking German fighters.

The Luftwaffe answered with the "Gefechtsverband" ("battle formation"). This consisted of a "Sturmgruppe" of heavily armed and armored Fw 190As escorted by two "Begleitgruppen" of Messerschmitt Bf 109s, whose task was to keep the Mustangs away from the Fw 190As attacking the bombers. This strategy proved to be problematic, as the large German formation took a long time to assemble and was difficult to maneuver. It was often intercepted by the P-51 "fighter sweeps" before it could attack the bombers. However, German attacks against bombers could be effective when they did occur; the bomber-destroyer Fw 190As swept in from astern and often pressed their attacks to within .
While not always able to avoid contact with the escorts, the threat of mass attacks and later the "company front" (eight abreast) assaults by armored "Sturmgruppe" Fw 190As brought an urgency to attacking the Luftwaffe wherever it could be found, either in the air or on the ground. Beginning in late February 1944, 8th Air Force fighter units began systematic strafing attacks on German airfields with increasing frequency and intensity throughout the spring, with the objective of gaining air supremacy over the Normandy battlefield. In general these were conducted by units returning from escort missions but, beginning in March, many groups also were assigned airfield attacks instead of bomber support. The P-51, particularly with the advent of the K-14 Gyro gunsight and the development of "Clobber Colleges" for the training of fighter pilots in fall 1944, was a decisive element in Allied countermeasures against the "Jagdverbände".

The numerical superiority of the USAAF fighters, superb flying characteristics of the P-51, and pilot proficiency helped cripple the Luftwaffe's fighter force. As a result, the fighter threat to US, and later British, bombers was greatly diminished by July 1944. The RAF, long proponents of night bombing for protection, were able to reopen daylight bombing in 1944 as a result of the crippling of the Luftwaffe fighter arm. Reichsmarschall Hermann Göring, commander of the German Luftwaffe during the war, was quoted as saying, "When I saw Mustangs over Berlin, I knew the jig was up."

On 15 April 1944, VIII Fighter Command began "Operation Jackpot", attacks on Luftwaffe fighter airfields. As the efficacy of these missions increased, the number of fighters at the German airbases fell to the point where they were no longer considered worthwhile targets. On 21 May, targets were expanded to include railways, locomotives, and rolling stock used by the Germans to transport materiel and troops, in missions dubbed "Chattanooga". The P-51 excelled at this mission, although losses were much higher on strafing missions than in air-to-air combat, partially because the Mustang's liquid-cooled engine (particularly its coolant system) was vulnerable to small-arms fire, unlike the air-cooled Double Wasp radials of its Republic P-47 Thunderbolt stablemates based in England, regularly tasked with ground-strafing missions.
Given the overwhelming Allied air superiority, the Luftwaffe put its effort into the development of aircraft of such high performance that they could operate with impunity, but which also made bomber attack much more difficult, merely from the flight velocities they achieved. Foremost among these were the Messerschmitt Me 163B point-defense rocket interceptors, which started their operations with JG 400 near the end of July 1944, and the longer-endurance Messerschmitt Me 262A jet fighter, first flying with the "Gruppe"-strength Kommando Nowotny unit by the end of September 1944. In action, the Me 163 proved to be more dangerous to the Luftwaffe than to the Allies, and was never a serious threat. The Me 262A was a serious threat, but attacks on their airfields neutralized them. The pioneering Junkers Jumo 004 axial-flow jet engines of the Me 262As needed careful nursing by their pilots, and these aircraft were particularly vulnerable during takeoff and landing. Lt. Chuck Yeager of the 357th Fighter Group was one of the first American pilots to shoot down an Me 262, which he caught during its landing approach. On 7 October 1944, Lt. Urban L. Drew of the 361st Fighter Group shot down two Me 262s that were taking off, while on the same day Lt. Col. Hubert Zemke, who had transferred to the Mustang-equipped 479th Fighter Group, shot down what he thought was a Bf 109, only to have his gun camera film reveal that it may have been an Me 262. On 25 February 1945, Mustangs of the 55th Fighter Group surprised an entire "Staffel" of Me 262As at takeoff and destroyed six jets.

The Mustang also proved useful against the V-1s launched toward London. P-51B/Cs using 150-octane fuel were fast enough to catch the V-1 and operated in concert with shorter-range aircraft such as advanced marks of the Supermarine Spitfire and Hawker Tempest.

By 8 May 1945, the 8th, 9th, and 15th Air Force's P-51 groups claimed some 4,950 aircraft shot down (about half of all USAAF claims in the European theater, the most claimed by any Allied fighter in air-to-air combat) and 4,131 destroyed on the ground. Losses were about 2,520 aircraft. The 8th Air Force's 4th Fighter Group was the top-scoring fighter group in Europe, with 1,016 enemy aircraft claimed destroyed. This included 550 claimed in aerial combat and 466 on the ground.

In air combat, the top-scoring P-51 units (both of which exclusively flew Mustangs) were the 357th Fighter Group of the 8th Air Force with 565 air-to-air combat victories and the 9th Air Force's 354th Fighter Group with 664, which made it one of the top-scoring fighter groups. The top Mustang ace was the USAAF's George Preddy, whose final tally stood at 26.83 victories, 23 of which were scored with the P-51, when he was shot down and killed by friendly fire on Christmas Day 1944 during the Battle of the Bulge.

In early 1945, P-51C, D, and K variants also joined the Chinese Nationalist Air Force. These Mustangs were provided to the 3rd, 4th, and 5th Fighter Groups and used to attack Japanese targets in occupied areas of China. The P-51 became the most capable fighter in China, while the Imperial Japanese Army Air Force used the Nakajima Ki-84 "Hayate" against it.

The P-51 was a relative latecomer to the Pacific Theater, due largely to the need for the aircraft in Europe, although the P-38's twin-engined design was considered a safety advantage for long, over-water flights. The first P-51s were deployed in the Far East later in 1944, operating in close-support and escort missions, as well as tactical photo reconnaissance. As the war in Europe wound down, the P-51 became more common; eventually, with the capture of Iwo Jima, it was able to be used as a bomber escort during Boeing B-29 Superfortress missions against the Japanese homeland.

The P-51 was often mistaken for the Japanese Kawasaki Ki-61 "Hien" in both China and Pacific because of its similar appearance.

Chief Naval Test Pilot and C.O. Captured Enemy Aircraft Flight Capt. Eric Brown, CBE, DSC, AFC, RN, tested the Mustang at RAE Farnborough in March 1944 and noted, "The Mustang was a good fighter and the best escort due to its incredible range, make no mistake about it. It was also the best American dogfighter. But the laminar-flow wing fitted to the Mustang could be a little tricky. It could not by any means out-turn a Spitfire. No way. It had a good rate-of-roll, better than the Spitfire, so I would say the plusses to the Spitfire and the Mustang just about equate. If I were in a dogfight, I'd prefer to be flying the Spitfire. The problem was I wouldn't like to be in a dogfight near Berlin, because I could never get home to Britain in a Spitfire!"

The U.S. Air Forces, Flight Test Engineering, assessed the Mustang B on 24 April 1944 "The rate of climb is good and the high speed in level flight is exceptionally good at all altitudes, from sea level to 40,000 feet. The airplane is very maneuverable with good controllability at indicated speeds to 400 MPH. The stability about all axes is good and the rate of roll is excellent; however, the radius of turn is fairly large for a fighter. The cockpit layout is excellent, but visibility is poor on the ground and only fair in level flight."

Kurt Bühligen, the third-highest scoring German fighter pilot of World War II's Western Front (with 112 confirmed victories, three against Mustangs), later stated, "We would out-turn the P-51 and the other American fighters, with the Bf 109 or the Fw 190. Their turn rate was about the same. The P-51 was faster than us, but our munitions and cannon were better." Heinz Bär said that the P-51 "was perhaps the most difficult of all Allied aircraft to meet in combat. It was fast, maneuverable, hard to see, and difficult to identify because it resembled the Me 109".

In the aftermath of World War II, the USAAF consolidated much of its wartime combat force and selected the P-51 as a "standard" piston-engined fighter, while other types, such as the P-38 and P-47, were withdrawn or given substantially reduced roles. As the more advanced (P-80 and P-84) jet fighters were introduced, the P-51 was also relegated to secondary duties.

In 1947, the newly formed USAF Strategic Air Command employed Mustangs alongside F-6 Mustangs and F-82 Twin Mustangs, due to their range capabilities. In 1948, the designation P-51 (P for pursuit) was changed to F-51 (F for fighter) and the existing F designator for photographic reconnaissance aircraft was dropped because of a new designation scheme throughout the USAF. Aircraft still in service in the USAF or Air National Guard (ANG) when the system was changed included: F-51B, F-51D, F-51K, RF-51D (formerly F-6D), RF-51K (formerly F-6K) and TRF-51D (two-seat trainer conversions of F-6Ds). They remained in service from 1946 through 1951. By 1950, although Mustangs continued in service with the USAF after the war, the majority of the USAF's Mustangs had become surplus to requirements and placed in storage, while some were transferred to the Air Force Reserve and the ANG.
From the start of the Korean War, the Mustang once again proved useful. A substantial number of stored or in-service F-51Ds were shipped, via aircraft carriers, to the combat zone, and were used by the USAF, the South African Air Force, and the Republic of Korea Air Force (ROKAF). The F-51 was used for ground attack, fitted with rockets and bombs, and photo reconnaissance, rather than being as interceptors or "pure" fighters. After the first North Korean invasion, USAF units were forced to fly from bases in Japan and the F-51Ds, with their long range and endurance, could attack targets in Korea that short-ranged F-80 jets could not. Because of the vulnerable liquid cooling system, however, the F-51s sustained heavy losses to ground fire. Due to its lighter structure and a shortage of spare parts, the newer, faster F-51H was not used in Korea.

Mustangs continued flying with USAF and ROKAF fighter-bomber units on close support and interdiction missions in Korea until 1953, when they were largely replaced as fighter-bombers by USAF F-84s and by United States Navy (USN) Grumman F9F Panthers. Other air forces and units using the Mustang included the Royal Australian Air Force's 77 Squadron, which flew Australian-built Mustangs as part of British Commonwealth Forces Korea. The Mustangs were replaced by Gloster Meteor F8s in 1951. The South African Air Force's 2 Squadron used U.S.-built Mustangs as part of the U.S. 18th Fighter Bomber Wing and had suffered heavy losses by 1953, after which 2 Squadron converted to the F-86 Sabre.

F-51s flew in the Air Force Reserve and ANG throughout the 1950s. The last American USAF Mustang was F-51D-30-NA AF serial no. 44-74936, which was finally withdrawn from service with the West Virginia Air National Guard's 167th Fighter Interceptor Squadron in January 1957 and retired to what was then called the Air Force Central Museum, although it was briefly reactivated to fly at the 50th anniversary of the Air Force Aerial Firepower Demonstration at the Air Proving Ground, Eglin AFB, Florida, on 6 May 1957. This aircraft, painted as P-51D-15-NA serial no. 44-15174, is on display at the National Museum of the United States Air Force, Wright-Patterson AFB, in Dayton, Ohio.

The final withdrawal of the Mustang from USAF dumped hundreds of P-51s onto the civilian market. The rights to the Mustang design were purchased from North American by the Cavalier Aircraft Corporation, which attempted to market the surplus Mustang aircraft in the U.S. and overseas. In 1967 and again in 1972, the USAF procured batches of remanufactured Mustangs from Cavalier, most of them destined for air forces in South America and Asia that were participating in the Military Assistance Program (MAP). These aircraft were remanufactured from existing original F-51D airframes fitted with new V-1650-7 engines, a new radio, tall F-51H-type vertical tails, and a stronger wing that could carry six machine guns and a total of eight underwing hardpoints. Two bombs and six rockets could be carried. They all had an original F-51D-type canopy, but carried a second seat for an observer behind the pilot. One additional Mustang was a two-seat, dual-control TF-51D (67-14866) with an enlarged canopy and only four wing guns. Although these remanufactured Mustangs were intended for sale to South American and Asian nations through the MAP, they were delivered to the USAF with full USAF markings. They were, however, allocated new serial numbers (67-14862/14866, 67-22579/22582 and 72-1526/1541).

The last U.S. military use of the F-51 was in 1968, when the U. S. Army employed a vintage F-51D (44-72990) as a chase aircraft for the Lockheed YAH-56 Cheyenne armed helicopter project. This aircraft was so successful that the Army ordered two F-51Ds from Cavalier in 1968 for use at Fort Rucker as chase planes. They were assigned the serials 68-15795 and 68-15796. These F-51s had wingtip fuel tanks and were unarmed. Following the end of the Cheyenne program, these two chase aircraft were used for other projects. One of them (68-15795) was fitted with a 106 mm recoilless rifle for evaluation of the weapon's value in attacking fortified ground targets. Cavalier Mustang 68-15796 survives at the Air Force Armament Museum, Eglin AFB, Florida, displayed indoors in World War II markings.

The F-51 was adopted by many foreign air forces and continued to be an effective fighter into the mid-1980s with smaller air arms. The last Mustang ever downed in battle occurred during Operation Power Pack in the Dominican Republic in 1965, with the last aircraft finally being retired by the Dominican Air Force in 1984.

After World War II, the P-51 Mustang served in the air arms of more than 25 nations. During the war, a Mustang cost about $51,000, while many hundreds were sold postwar for the nominal price of one dollar to signatories of the Inter-American Treaty of Reciprocal Assistance, ratified in Rio de Janeiro in 1947.

These countries used the P-51 Mustang:




Many P-51s were sold as surplus after the war, often for as little as $1,500. Some were sold to former wartime fliers or other aficionados for personal use, while others were modified for air racing.
One of the most significant Mustangs involved in air racing was a surplus P-51C-10-NT (44-10947) purchased by film stunt pilot Paul Mantz. The aircraft was modified by creating a "wet wing", sealing the wing to create a giant fuel tank in each wing, which eliminated the need for fuel stops or drag-inducing drop tanks. This Mustang, named "Blaze of Noon" after the film "Blaze of Noon", came in first in the 1946 and 1947 Bendix Air Races, second in the 1948 Bendix, and third in the 1949 Bendix. He also set a U.S. coast-to-coast record in 1947. The Mantz Mustang was sold to Charles F. Blair Jr (future husband of Maureen O'Hara) and renamed "Excalibur III". Blair used it to set a New York-to-London ("circa" 3,460 mi/5,568 km) record in 1951: 7 hr 48 min from takeoff at Idlewild to overhead London Airport. Later that same year, he flew from Norway to Fairbanks, Alaska, via the North Pole ("circa" 3,130 mi/5,037 km), proving that navigation via sun sights was possible over the magnetic north pole region. For this feat, he was awarded the Harmon Trophy and the Air Force was forced to change its thoughts on a possible Soviet air strike from the north. This Mustang now resides in the National Air and Space Museum at the Steven F. Udvar-Hazy Center.
The most prominent firm to convert Mustangs to civilian use was Trans-Florida Aviation, later renamed Cavalier Aircraft Corporation, which produced the Cavalier Mustang. Modifications included a taller tailfin and wingtip tanks. A number of conversions included a Cavalier Mustang specialty: a "tight" second seat added in the space formerly occupied by the military radio and fuselage fuel tank.

In 1958, 78 surviving RCAF Mustangs were retired from service's inventory and were ferried by Lynn Garrison, an RCAF pilot, from their varied storage locations to Canastota, New York, where the American buyers were based. In effect, Garrison flew each of the surviving aircraft at least once. These aircraft make up a large percentage of the aircraft presently flying worldwide.

In the late 1960s and early 1970s, when the United States Department of Defense wished to supply aircraft to South American countries and later Indonesia for close air support and counter insurgency, it turned to Cavalier to return some of their civilian conversions back to updated military specifications.

In the 21st century, a P-51 can command a price of more than $1 million, even for only partially restored aircraft. There were 204 privately owned P-51s in the U.S. on the FAA registry in 2011, most of which are still flying, often associated with organizations such as the Commemorative Air Force (formerly the Confederate Air Force).

In May 2013, Doug Matthews set an altitude record of in a P 51 named "The Rebel", for piston-powered aircraft weighing . Mathews departed from a grass runway at Florida's Indiantown airport and flew "The Rebel" over Lake Okeechobee. He set world records for time to reach altitudes of , 18 minutes and , 31 minutes. He achieved a new height record of in level flight and a maximum altitude. The previous record of had stood since 1954.


Over 20 variants of the P-51 Mustang were produced from 1940 to after the war.

Except for the small numbers assembled or produced in Australia, all Mustangs were built by North American initially at Inglewood, California, but then additionally in Dallas, Texas.


As indicative of the iconic nature of the P-51, manufacturers within the hobby industry have created scale plastic model kits of the P-51 Mustang, with varying degrees of detail and skill levels. The aircraft have also been the subject of numerous scale flying replicas. Aside from the popular radio-controlled aircraft, several kitplane manufacturers offer ½, ⅔, and ¾-scale replicas capable of comfortably seating one (or even two) and offering high performance combined with more forgiving flight characteristics. Such aircraft include the Titan T-51 Mustang, W.A.R. P-51 Mustang, Linn Mini Mustang, Jurca Gnatsum, Thunder Mustang, Stewart S-51D Mustang, and Loehle 5151 Mustang.



</doc>
<doc id="24714" url="https://en.wikipedia.org/wiki?curid=24714" title="Precession">
Precession

Precession is a change in the orientation of the rotational axis of a rotating body. In an appropriate reference frame it can be defined as a change in the first Euler angle, whereas the third Euler angle defines the rotation itself. In other words, if the axis of rotation of a body is itself rotating about a second axis, that body is said to be precessing about the second axis. A motion in which the second Euler angle changes is called "nutation". In physics, there are two types of precession: torque-free and torque-induced.

In astronomy, "precession" refers to any of several slow changes in an astronomical body's rotational or orbital parameters. An important example is the steady change in the orientation of the axis of rotation of the Earth, known as the precession of the equinoxes.

Torque-free precession implies that no external moment (torque) is applied to the body. In torque-free precession, the angular momentum is a constant, but the angular velocity vector changes orientation with time. What makes this possible is a time-varying moment of inertia, or more precisely, a time-varying inertia matrix. The inertia matrix is composed of the moments of inertia of a body calculated with respect to separate coordinate axes (e.g. , , ). If an object is asymmetric about its principal axis of rotation, the moment of inertia with respect to each coordinate direction will change with time, while preserving angular momentum. The result is that the component of the angular velocities of the body about each axis will vary inversely with each axis' moment of inertia.

The torque-free precession rate of an object with an axis of symmetry, such as a disk, spinning about an axis not aligned with that axis of symmetry can be calculated as follows:

where is the precession rate, is the spin rate about the axis of symmetry, is the moment of inertia about the axis of symmetry, is moment of inertia about either of the other two equal perpendicular principal axes, and is the angle between the moment of inertia direction and the symmetry axis.

When an object is not perfectly solid, internal vortices will tend to damp torque-free precession, and the rotation axis will align itself with one of the inertia axes of the body.

For a generic solid object without any axis of symmetry, the evolution of the object's orientation, represented (for example) by a rotation matrix that transforms internal to external coordinates, may be numerically simulated. Given the object's fixed internal moment of inertia tensor and fixed external angular momentum , the instantaneous angular velocity is
Precession occurs by repeatedly recalculating and applying a small rotation vector for the short time ; e.g.:
for the skew-symmetric matrix . The errors induced by finite time steps tend to increase the rotational kinetic energy:
this unphysical tendency can be counteracted by repeatedly applying a small rotation vector perpendicular to both and , noting that

Another type of torque-free precession can occur when there are multiple reference frames at work. For example, Earth is subject to local torque induced precession due to the gravity of the sun and moon acting on Earth's axis, but at the same time the solar system is moving around the galactic center. As a consequence, an accurate measurement of Earth's axial reorientation relative to objects outside the frame of the moving galaxy (such as distant quasars commonly used as precession measurement reference points) must account for a minor amount of non-local torque-free precession, due to the solar system’s motion.

Torque-induced precession (gyroscopic precession) is the phenomenon in which the axis of a spinning object (e.g., a gyroscope) describes a cone in space when an external torque is applied to it. The phenomenon is commonly seen in a spinning toy top, but all rotating objects can undergo precession. If the speed of the rotation and the magnitude of the external torque are constant, the spin axis will move at right angles to the direction that would intuitively result from the external torque. In the case of a toy top, its weight is acting downwards from its center of mass and the normal force (reaction) of the ground is pushing up on it at the point of contact with the support. These two opposite forces produce a torque which causes the top to precess.
The device depicted on the right (or above on mobile devices) is gimbal mounted. From inside to outside there are three axes of rotation: the hub of the wheel, the gimbal axis, and the vertical pivot.

To distinguish between the two horizontal axes, rotation around the wheel hub will be called "spinning", and rotation around the gimbal axis will be called "pitching". Rotation around the vertical pivot axis is called "rotation".

First, imagine that the entire device is rotating around the (vertical) pivot axis. Then, spinning of the wheel (around the wheelhub) is added. Imagine the gimbal axis to be locked, so that the wheel cannot pitch. The gimbal axis has sensors, that measure whether there is a torque around the gimbal axis.

In the picture, a section of the wheel has been named . At the depicted moment in time, section is at the perimeter of the rotating motion around the (vertical) pivot axis. Section , therefore, has a lot of angular rotating velocity with respect to the rotation around the pivot axis, and as is forced closer to the pivot axis of the rotation (by the wheel spinning further), because of the Coriolis effect, with respect to the vertical pivot axis, tends to move in the direction of the top-left arrow in the diagram (shown at 45°) in the direction of rotation around the pivot axis. Section of the wheel is moving away from the pivot axis, and so a force (again, a Coriolis force) acts in the same direction as in the case of . Note that both arrows point in the same direction.

The same reasoning applies for the bottom half of the wheel, but there the arrows point in the opposite direction to that of the top arrows. Combined over the entire wheel, there is a torque around the gimbal axis when some spinning is added to rotation around a vertical axis.

It is important to note that the torque around the gimbal axis arises without any delay; the response is instantaneous.

In the discussion above, the setup was kept unchanging by preventing pitching around the gimbal axis. In the case of a spinning toy top, when the spinning top starts tilting, gravity exerts a torque. However, instead of rolling over, the spinning top just pitches a little. This pitching motion reorients the spinning top with respect to the torque that is being exerted. The result is that the torque exerted by gravity – via the pitching motion – elicits gyroscopic precession (which in turn yields a counter torque against the gravity torque) rather than causing the spinning top to fall to its side.

Precession or gyroscopic considerations have an effect on bicycle performance at high speed. Precession is also the mechanism behind gyrocompasses.

Precession is the change of angular velocity and angular momentum produced by a torque. The general equation that relates the torque to the rate of change of angular momentum is:

where formula_7 and formula_8 are the torque and angular momentum vectors respectively.

Due to the way the torque vectors are defined, it is a vector that is perpendicular to the plane of the forces that create it. Thus it may be seen that the angular momentum vector will change perpendicular to those forces. Depending on how the forces are created, they will often rotate with the angular momentum vector, and then circular precession is created.

Under these circumstances the angular velocity of precession is given by:

where is the moment of inertia, is the angular velocity of spin about the spin axis, is the mass, is the acceleration due to gravity and is the perpendicular distance of the spin axis about the axis of precession. The torque vector originates at the center of mass. Using , we find that the period of precession is given by:

Where is the moment of inertia, is the period of spin about the spin axis, and is the torque. In general, the problem is more complicated than this, however.

There is an easy way to understand why gyroscopic precession occurs without using any mathematics. The behavior of a spinning object simply obeys laws of inertia by resisting any change in direction. A spinning object possesses a property known as rigidity in space, meaning the spin axis resists any change in orientation. It is the inertia of matter comprising the object as it resists any change in direction that provides this property. Of course, the direction this matter travels constantly changes as the object spins, but any further change in direction is resisted. If a force is applied to the surface of a spinning disc, for example, matter experiences no change in direction at the place the force was applied (or 180 degrees from that place). But 90 degrees before and 90 degrees after that place, matter is forced to change direction. This causes the object to behave as if the force was applied at those places instead. When a force is applied to anything, the object exerts an equal force back but in the opposite direction. Since no actual force was applied 90 degrees before or after, nothing prevents the reaction from taking place, and the object causes itself to move in response. A good way to visualize why this happens is to imagine the spinning object to be a large hollow doughnut filled with water, as described in the book "Thinking Physics" by Lewis Epstein. The doughnut is held still while water circulates inside it. As the force is applied, the water inside is caused to change direction 90 degrees before and after that point. The water then exerts its own force against the inner wall of the doughnut and causes the doughnut to rotate as if the force was applied 90 degrees ahead in the direction of rotation. Epstein exaggerates the vertical and horizontal motion of the water by changing the shape of the doughnut from round to square with rounded corners. 

Now imagine the object to be a spinning bicycle wheel, held at both ends of its axle in the hands of a subject. The wheel is spinning clock-wise as seen from a viewer to the subject’s right. Clock positions on the wheel are given relative to this viewer. As the wheel spins, the molecules comprising it are traveling exactly horizontal and to the right the instant they pass the 12-o'clock position, vertically downward the instant they pass 3 o'clock, horizontally to the left at 6 o'clock, vertically upward at 9 o’clock and horizontally to the right again at 12 o'clock. Between these positions, each molecule travels components of these directions. Now imagine the viewer applying a force to the rim of the wheel at 12 o’clock. For this example’s sake, imagine the wheel tilting over when this force is applied; it tilts to the left as seen from the subject holding it at its axle. As the wheel tilts to its new position, molecules at 12 o’clock (where the force was applied) and those at 6 o’clock still travel horizontally; their direction did not change as the wheel was tilting. Nor is their direction different after the wheel settles in its new position; they still move horizontally the instant they pass 12 and 6 o’clock. BUT, molecules passing 3 and 9 o’clock were forced to change direction. Those at 3 o’clock were forced to change from moving straight downward, to downward and to the right as viewed from the subject holding the wheel. Molecules passing 9 o’clock were forced to change from moving straight upward, to upward and to the left. This change in direction is resisted by the inertia of those molecules. And when they experience this change in direction, they exert an equal and opposite force in response AT THOSE LOCATIONS-3 AND 9 O’CLOCK. At 3 o’clock, where they were forced to change from moving straight down to downward and to the right, they exert their own equal and opposite reactive force to the left. At 9 o’clock, they exert their own reactive force to the right, as viewed from the subject holding the wheel. This makes the wheel as a whole rotate counter-clockwise as viewed from directly above. Thus, as the force was applied at 12 o’clock, the wheel behaved as if that force was applied at 3 o’clock, which is 90 degrees ahead in the direction of rotation. Or, you can say a force from the opposite direction was applied at 9 o'clock, 90 degrees prior to the actual force.

In summary, when you apply a force to a spinning object to change the direction of its spin axis, you are not changing the direction of the matter comprising the object at the place you applied the force (nor at 180 degrees from it); matter experiences zero change in direction at those places. Matter experiences the maximum change in direction 90 degrees before and after that place, and lesser amounts closer to that place. The equal and opposite reaction that occurs 90 degrees before and after then causes the object to behave as it does. This principle is demonstrated in helicopters. Helicopter controls are rigged so that inputs to them are transmitted to the rotor blades at points 90 degrees prior to and 90 degrees after the point at which the change in aircraft attitude is desired. The effect is dramatically felt on motorcycles. A motorcycle will suddenly lean and turn in the opposite direction the handle bars are turned. 

Precession causes another phenomenon for spinning objects such as the bicycle wheel in this scenario. If the subject holding the wheel removes a hand from one end of its axle, the wheel will not topple over, but will remain upright, supported at just the other end. However, it will immediately take on an additional motion; it will begin to rotate about a vertical axis, pivoting at the point of support as it continues spinning. If you allowed the wheel to continue rotating, you would have to turn your body in the same direction. If the wheel was not spinning, it would topple over and fall when one hand is removed. The initial action of the wheel beginning to topple over is equivalent to applying a force to it at 12 o'clock in the direction toward the unsupported side (or a force at 6 o’clock toward the supported side). When the wheel is spinning, the sudden lack of support at one end of its axle is equivalent to this same force. So, instead of toppling over, the wheel behaves as if a continuous force is being applied to it at 3 or 9 o’clock, depending on the direction of spin and which hand was removed. This causes the wheel to begin pivoting at the one supported end of its axle while remaining upright. Although it pivots at that point, it does so only because of the fact that it is supported there; the actual axis of precessional rotation is located vertically through the wheel, passing through its center of mass. Also, this explanation does not account for the effect of variation in the speed of the spinning object; it only illustrates how the spin axis behaves due to precession. More correctly, the object behaves according to the balance of all forces based on the magnitude of the applied force, mass and rotational speed of the object. Once it is visualized why the wheel remains upright and rotates, it can easily be seen why the axis of a spinning top slowly rotates while the top spins as shown in the above illustration. A top behaves exactly like the bicycle wheel due to the force of gravity pulling downward. The point of contact with the surface it spins on is equivalent to the end of the wheel axle that is supported.

The special and general theories of relativity give three types of corrections to the Newtonian precession, of a gyroscope near a large mass such as Earth, described above. They are:

In astronomy, precession refers to any of several gravity-induced, slow and continuous changes in an astronomical body's rotational axis or orbital path. Precession of the equinoxes, perihelion precession, changes in the tilt of Earth's axis to its orbit, and the eccentricity of its orbit over tens of thousands of years are all important parts of the astronomical theory of ice ages. "(See Milankovitch cycles.)"

Axial precession is the movement of the rotational axis of an astronomical body, whereby the axis slowly traces out a cone. In the case of Earth, this type of precession is also known as the "precession of the equinoxes", "lunisolar precession", or "precession of the equator". Earth goes through one such complete precessional cycle in a period of approximately 26,000 years or 1° every 72 years, during which the positions of stars will slowly change in both equatorial coordinates and ecliptic longitude. Over this cycle, Earth's north axial pole moves from where it is now, within 1° of Polaris, in a circle around the ecliptic pole, with an angular radius of about 23.5°.

The ancient Greek astronomer Hipparchus (c. 190-120 BC) is claimed to be the earliest known astronomer to recognize and assess the precession of the equinoxes at about 1° per century (which is not far from the actual value for antiquity, 1.38°). Caltech's Swerdlow disputes Hipparchus's knowledge of precession because Hipparchus apparently did not necessarily indicate anything like a motion of the entire sphere of the fixed stars with respect to the equinoxes. In ancient China, the Jin-dynasty scholar-official Yu Xi (fl. 307-345 AD) made a similar discovery centuries later, noting that the position of the Sun during the winter solstice had drifted roughly one degree over the course of fifty years relative to the position of the stars. The precession of Earth's axis was later explained by Newtonian physics. Being an oblate spheroid, Earth has a non-spherical shape, bulging outward at the equator. The gravitational tidal forces of the Moon and Sun apply torque to the equator, attempting to pull the equatorial bulge into the plane of the ecliptic, but instead causing it to precess. The torque exerted by the planets, particularly Jupiter, also plays a role.

The orbits of planets around the Sun do not really follow an identical ellipse each time, but actually trace out a flower-petal shape because the major axis of each planet's elliptical orbit also precesses within its orbital plane, partly in response to perturbations in the form of the changing gravitational forces exerted by other planets. This is called perihelion precession or apsidal precession.

In the adjunct image, Earth's apsidal precession is illustrated. As the Earth travels around the Sun, its elliptical orbit rotates gradually over time. The eccentricity of its ellipse and the precession rate of its orbit are exaggerated for visualization. Most orbits in the Solar System have a much smaller eccentricity and precess at a much slower rate, making them nearly circular and stationary.

Discrepancies between the observed perihelion precession rate of the planet Mercury and that predicted by classical mechanics were prominent among the forms of experimental evidence leading to the acceptance of Einstein's Theory of Relativity (in particular, his General Theory of Relativity), which accurately predicted the anomalies. Deviating from Newton's law, Einstein's theory of gravitation predicts an extra term of , which accurately gives the observed excess turning rate of 43″ every 100 years.

The gravitational force between the Sun and moon induces the precession in Earth's orbit, which is the major cause of the climate oscillation of Earth that has a period of 19,000 to 23,000 years. It follows that changes in Earth's orbital parameters (e.g., orbital inclination, the angle between Earth's rotation axis and its plane of orbit) is important to the study of Earth's climate, in particular to the study of past ice ages.

Orbital nodes also precess over time.




</doc>
<doc id="24717" url="https://en.wikipedia.org/wiki?curid=24717" title="Punjab">
Punjab

The Punjab (, , , ), also spelled Panjab ("land of "five rivers""; Punjabi: ; , "Pentapotamia") is a geographical and cultural region in the northern part of the Indian subcontinent, comprising areas of eastern Pakistan and northern India. Not being a political unit, the boundaries of the region are ill-defined and focus on historical accounts.

Until the Partition of Punjab in 1947, the British Punjab Province encompassed the present-day Indian states of Punjab, Haryana, Himachal Pradesh, Chandigarh, and Delhi, and the Pakistani provinces of Punjab and Islamabad Capital Territory. It bordered the Balochistan and Pashtunistan regions to the west, Kashmir to the north, the Hindi Belt to the east, and Rajasthan and Sindh to the south.

The people of the Punjab today are called Punjabis, and their principal language is Punjabi. The main religions of the Punjab region are Islam, Sikhism, and Hinduism. Other religious groups are Christianity, Jainism, Zoroastrianism, Buddhism, and Ravidassia. The Punjab region has been inhabited by the Indus Valley Civilisation, Indo-Aryan peoples, and Indo-Scythians, and has seen numerous invasions by the Persians, Greeks, Kushans, Ghaznavids, Timurids, Mughals, Pashtuns, British, and others. Historic foreign invasions mainly targeted the most productive central region of the Punjab known as the Majha region, which is also the bedrock of Punjabi culture and traditions.

The region was originally called Sapta Sindhu, the Vedic land of the seven rivers flowing into the ocean. The Sanskrit name for the region, as mentioned in the Ramayana and Mahabharata for example, was "Panchanada" which means "Land of the Five Rivers", and was translated to Persian as "Punjab" after the Muslim conquests. The later name of the region, "Punjab", is a compound of two Persian words, Panj (five) and āb (water), introduced to the region by the Turko-Persian conquerors of India, and more formally popularised during the Mughal Empire. Punjab thus means "The Land of Five Waters", referring to the rivers Jhelum, Chenab, Ravi, Sutlej, and Beas. All are tributaries of the Indus River, the Chenab being the largest.

There are two main definitions of the Punjab region: the 1947 definition and the older 1846–1849 definition. A third definition incorporates both the 1947 and the older definitions but also includes northern Rajasthan on a linguistic basis and ancient river movements.
The 1947 definition defines the Punjab region with reference to the dissolution of British India whereby the then British Punjab Province was partitioned between India and Pakistan. In Pakistan, the region now includes the Punjab province and Islamabad Capital Territory. In India, it includes the Punjab state, Chandigarh, Haryana, and Himachal Pradesh.

Using the 1947 definition, the Punjab borders the Balochistan and Pashtunistan regions to the west, Kashmir to the north, the Hindi Belt to the east, and Rajasthan and Sindh to the south. Accordingly, the Punjab region is very diverse and stretches from the hills of the Kangra Valley to the plains and to the Cholistan Desert.

Using the 1947 definition of the Punjab region, some of the major cities of the area include Lahore, Faisalabad and Ludhiana.

The older definition of the Punjab region focuses on the collapse of the Sikh Empire and the creation of the British Punjab province between 1846 and 1849. According to this definition, the Punjab region incorporates, in Pakistan, Azad Kashmir including Bhimber and Mirpur and parts of Khyber Pakhtunkhwa (especially Peshawar known in the Punjab region as Pishore). In India the wider definition includes parts of Delhi and Jammu Division.

Using the older definition of the Punjab region, the Punjab region covers a large territory and can be divided into five natural areas:

The formation of the Himalayan Range of mountains to the east and north-east of the Punjab is the result of a collision between the north-moving Indo-Australian Plate and the Eurasian Plate. The plates are still moving together, and the Himalayas are rising by about per year.

The upper regions are snow-covered the whole year. Lower ranges of hills run parallel to the mountains. The Lower Himalayan Range runs from north of Rawalpindi through Jammu and Kashmir, Himachal Pradesh and further south. The mountains are relatively young, and are eroding rapidly. The Indus and the five rivers of the Punjab have their sources in the mountain range and carry loam, minerals and silt down to the rich alluvial plains, which consequently are very fertile.

According to the older definition, some of the major cities include Jammu, Peshawar and parts of Delhi.
The third definition of the Punjab region adds to the definitions cited above and includes parts of Rajasthan on linguistic lines and takes into consideration the location of the Punjab rivers in ancient times. In particular, the Sri Ganganagar and Hanumangarh districts are included in the Punjab region.
The climate is a factor contributing to the economy of the Punjab. It is not uniform over the whole region, with the sections adjacent to the Himalayas receiving heavier rainfall than those at a distance.

There are three main seasons and two transitional periods. During the hot season, from about mid April to the end of June, the temperature may reach . The monsoon season, from July to September, is a period of heavy rainfall, providing water for crops in addition to the supply from canals and irrigation systems. The transitional period after the monsoon is cool and mild, leading to the winter season, when the temperature in January falls to at night and by day. During the transitional period from winter to the hot season, sudden hailstorms and heavy showers may occur, causing damage to crops.

The Punjab region of India and Pakistan has a historical and cultural link to Indo-Aryan peoples as well as partially to various indigenous communities. As a result of several invasions from Central Asia and the Middle East, many ethnic groups and religions make up the cultural heritage of the Punjab.

In prehistoric times, one of the earliest known cultures of South Asia, the Indus Valley civilisation was located in the region.

The epic battles described in the "Mahabharata" are described as being fought in what is now the State of Haryana and historic Punjab. The Gandharas, Kambojas, Trigartas, Andhra, Pauravas, Bahlikas (Bactrian settlers of the Punjab), Yaudheyas and others sided with the Kauravas in the great battle fought at Kurukshetra. According to DrFauja Singh and DrL.M. Joshi: "There is no doubt that the Kambojas, Daradas, Kaikayas, Andhra, Pauravas, Yaudheyas, Malavas, Saindhavas and Kurus had jointly contributed to the heroic tradition and composite culture of ancient Punjab".

In 326 BCE, Alexander the Great invaded Pauravas and defeated King Porus. His armies entered the region via the Hindu Kush in northwest Pakistan and his rule extended up to the city of Sagala (present-day Sialkot in northeast Pakistan). In 305BCE the area was ruled by the Maurya Empire. In a long line of succeeding rulers of the area, Chandragupta Maurya and Ashoka stand out as the most renowned. The Maurya presence in the area was then consolidated in the Indo-Greek Kingdom in 180BCE. Menander I Soter "The Saviour" (known as Milinda in Indian sources) is the most renowned leader of the era, he conquered the Punjab and made Sagala the capital of his Empire. Menander carved out a Greek kingdom in the Punjab and ruled the region till his death in 130BCE. The neighbouring Seleucid Empire rule came to an end around 12BCE, after several invasions by the Yuezhi and the Scythian people.

In 711–713 CE, the 18-year-old Arab general Muhammad bin Qasim of Taif, a city in what is now Saudi Arabia, came by way of the Arabian Sea with Arab troops to defeat Raja Dahir. BinQasim then led his troops to conquer the Sindh and Punjab regions for the Islamic Umayyad Caliphate, making him the first to bring Islam to the region.

During the establishment and consolidation of the Muslim Turkic Mughal Empire prosperity, growth, and relative peace were established, particularly under the reign of Jahangir. Muslim empires ruled the Punjab for approximately 1,000 years. The period was also notable for the emergence of Guru Nanak (1469–1539), the founder of Sikhism.

In 1758, Punjab came under the rule of Marathas, who captured the region by defeating the Afghan forces of Ahmad Shah Abdali. Abdali's Indian invasion weakened the Maratha influence, but he could not defeat the Sikhs. After the death of Ahmad Shah, the Punjab was freed from the Afghan yoke by Sikhs between 1773 and 1818. At the time of the formation of the Dal Khalsa in 1748 at Amritsar, the Punjab had been divided into 36 areas and 12 separate Sikh principalities, called misl. From this point onward, the beginnings of a Punjabi Sikh Empire emerged. Out of the 36 areas, 22 were united by Maharaja Ranjit Singh. The other 14 accepted British sovereignty. After Ranjit Singh's death, assassinations and internal divisions severely weakened the empire. Six years later the British East India Company was given an excuse to declare war, and in 1849, after two Anglo-Sikh wars, the Punjab was annexed by the British.

In the Indian Rebellion of 1857 the Sikh rulers backed the East India Company, providing troops and support, but in Jhelum 35 British soldiers of HMXXIV regiment were killed by the local resistance, and in Ludhiana a rebellion was crushed with the assistance of the Punjab chiefs of Nabha and Malerkotla.

The British Raj had political, cultural, philosophical, and literary consequences in the Punjab, including the establishment of a new system of education. During the independence movement, many Punjabis played a significant role, including Madan Lal Dhingra, Sukhdev Thapar, Ajit Singh Sandhu, Bhagat Singh, Udham Singh, Kartar Singh Sarabha, Bhai Parmanand, Muhammad Iqbal, Chaudhary Rehmat Ali, and Lala Lajpat Rai.

At the time of partition in 1947, the province was split into East and West Punjab. East Punjab (48%) became part of India, while West Punjab (52%) became part of Pakistan. The Punjab bore the brunt of the civil unrest following the end of the British Raj, with casualties estimated to be in the millions.


Ethnic ancestries of modern Punjabis include a mixture of Indo-Aryan and Indo-Scythian. Semitic ancestries can also be found in lesser numbers. With the advent of Islam, settlers from Turkestan, Afghanistan, and Kashmir have also integrated into the Muslim Punjabi society. However, the majority of Punjab is still made up of the Arains, Dalits, Gujjars, Jats, Khatris, Tarkhans, Brahmins, Bhats, Awans, Kambojs, Rajputs Sainis, Kumhars, and others. In the past, the most densely populated area has been the Majha region of Punjab. 
 The major language spoken in the Punjab is Punjabi. In the Indian Punjab this is written in the Gurmukhi script. Pakistan uses the Shahmukhi script, that is closer to Urdu script. Hindi, written in the Devanagri script, is used widely in the Indian states of Himanchal Pradesh and Haryana. Several dialects of Punjabi are spoken in the different regions. The Majhi dialect is considered to be textbook Punjabi and is shared by both countries.

The vast majority of Pakistani Punjabis are Sunni Muslim by faith, but also include large minority faiths mostly Shia Muslim, Ahmadi Muslim and Christians.

The Indian states of Haryana and Himachal Pradesh are mostly Hindu-majority. Sikhism, founded in the late 15thcentury, is the main religion practised in the post-1966 Indian Punjab state. About 60% of the population of Punjab state is Sikh, 37% is Hindu, and the rest are Muslims, Christians, and Jains. However, due to large scale migration from Uttar Pradesh, Rajasthan, Bihar, Bengal and Odisha the demographics have become more skewed than reported earlier. Punjab state contains the holy Sikh cities of Amritsar, Anandpur Sahib, Tarn Taran Sahib, Fatehgarh Sahib and Chamkaur Sahib.

The Punjab was home to several Sufi saints, and Sufism is well established in the region. Also, Kirpal Singh revered the Sikh Gurus as saints.

Punjabis celebrate the following cultural, seasonal and religious festivals:

Traditional Punjabi clothing includes the following:

The historical region of Punjab is considered to be one of the most fertile regions on Earth. Both east and west Punjab produce a relatively high proportion of India and Pakistan's food output respectively.

The region has been used for extensive wheat farming, in addition rice, cotton, sugarcane, fruit, and vegetables are also grown.

The agricultural output of the Punjab region in Pakistan contributes significantly to Pakistan's GDP. Both Indian and Pakistani Punjab are considered to have the best infrastructure of their respective countries. Indian Punjab has been estimated to be the second richest state in India. Pakistani Punjab produces 68% of Pakistan's food grain production. Its share of Pakistan's GDP has historically ranged from 51.8% to 54.7%.

Called "The Granary of India" or "The Bread Basket of India", Indian Punjab produces 1% of the world's rice, 2% of its wheat, and 2% of its cotton. In 2001, it was recorded that farmers made up 39% of Indian Punjab's workforce.





</doc>
<doc id="24718" url="https://en.wikipedia.org/wiki?curid=24718" title="Ring system">
Ring system

A ring system is a disc or ring orbiting an astronomical object that is composed of solid material such as dust and moonlets, and is a common component of satellite systems around giant planets. A ring system around a planet is also known as a planetary ring system.

The most prominent and most famous planetary rings in the Solar System are those around Saturn, but the other three giant planets (Jupiter, Uranus, and Neptune) also have ring systems. Recent evidence suggests that ring systems may also be found around other types of astronomical objects, including minor planets, moons, and brown dwarfs.

There are three ways that thicker planetary rings (the rings around planets) have been proposed to have formed: from material of the protoplanetary disk that was within the Roche limit of the planet and thus could not coalesce to form moons, from the debris of a moon that was disrupted by a large impact, or from the debris of a moon that was disrupted by tidal stresses when it passed within the planet's Roche limit. Most rings were thought to be unstable and to dissipate over the course of tens or hundreds of millions of years, but it now appears that Saturn's rings might be quite old, dating to the early days of the Solar System.

Fainter planetary rings can form as a result of meteoroid impacts with moons orbiting around the planet or, in case of Saturn's E-ring, the ejecta of cryovolcanic material.

The composition of ring particles varies; they may be silicate or icy dust. Larger rocks and boulders may also be present, and in 2007 tidal effects from eight 'moonlets' only a few hundred meters across were detected within Saturn's rings. The maximum size of a ring particle is determined by the specific strength of the material it is made of, its density, and the tidal force at its altitude. The tidal force is proportional to the average density inside the radius of the ring, or to the mass of the planet divided by the radius of the ring cubed. It is also inversely proportional to the square of the orbital period of the ring.

Sometimes rings will have "shepherd" moons, small moons that orbit near the inner or outer edges of rings or within gaps in the rings. The gravity of shepherd moons serves to maintain a sharply defined edge to the ring; material that drifts closer to the shepherd moon's orbit is either deflected back into the body of the ring, ejected from the system, or accreted onto the moon itself.

It is also predicted that Phobos, a moon of Mars, will break up and form into a planetary ring in about 50 million years, because its low orbit with an orbital period that is shorter than a Martian day is decaying due to tidal deceleration.

Jupiter's ring system was the third to be discovered, when it was first observed by the "Voyager 1" probe in 1979, and was observed more thoroughly by the "Galileo" orbiter in the 1990s. Its four main parts are a faint thick torus known as the "halo"; a thin, relatively bright main ring; and two wide, faint "gossamer rings". The system consists mostly of dust.

Saturn's rings are the most extensive ring system of any planet in the Solar System, and thus have been known to exist for quite some time. Galileo Galilei first observed them in 1610, but they were not accurately described as a disk around Saturn until Christiaan Huygens did so in 1655. With help from the NASA/ESA/ASI Cassini mission, a further understanding of the ring formation and active movement was understood. The rings are not a series of tiny ringlets as many think, but are more of a disk with varying density. They consist mostly of water ice and trace amounts of rock, and the particles range in size from micrometers to meters.

Uranus' ring system lies between the level of complexity of Saturn's vast system and the simpler systems around Jupiter and Neptune. They were discovered in 1977 by James L. Elliot, Edward W. Dunham, and Jessica Mink. In the time between then and 2005, observations by "Voyager 2" and the Hubble Space Telescope led to a total of 13 distinct rings being identified, most of which are opaque and only a few kilometers wide. They are dark and likely consist of water ice and some radiation-processed organics. The relative lack of dust is due to aerodynamic drag from the extended exosphere-corona of Uranus.

The system around Neptune consists of five principal rings that, at their densest, are comparable to the low-density regions of Saturn's rings. However, they are faint and dusty, much more similar in structure to those of Jupiter. The very dark material that makes up the rings are likely organics processed by radiation, like in the rings of Uranus. 20 to 70 percent of the rings are dust, a relatively high proportion. Hints of the rings were seen for decades prior to their conclusive discovery by "Voyager 2" in 1989.

Reports in March 2008 suggested that Saturn's moon Rhea may have its own tenuous ring system, which would make it the only moon known to have a ring system. A later study published in 2010 revealed that imaging of Rhea by the "Cassini" spacecraft was inconsistent with the predicted properties of the rings, suggesting that some other mechanism is responsible for the magnetic effects that had led to the ring hypothesis.

10199 Chariklo, a centaur, was the first minor planet discovered to have rings. It has two rings, perhaps due to a collision that caused a chain of debris to orbit it. The rings were discovered when astronomers observed Chariklo passing in front of the star UCAC4 248-108672 on June 3, 2013 from seven locations in South America. While watching, they saw two dips in the star's apparent brightness just before and after the occultation. Because this event was observed at multiple locations, the conclusion that the dip in brightness was in fact due to rings is unanimously the leading hypothesis. The observations revealed what is likely a -wide ring system that is about 1,000 times closer than the Moon is to Earth. In addition, astronomers suspect there could be a moon orbiting amidst the ring debris. If these rings are the leftovers of a collision as astronomers suspect, this would give fodder to the idea that moons (such as the Moon) form through collisions of smaller bits of material. Chariklo's rings have not been officially named, but the discoverers have nicknamed them Oiapoque and Chuí, after two rivers near the northern and southern ends of Brazil.

A second centaur, 2060 Chiron, is also suspected to have a pair of rings. Based on stellar-occultation data that were initially interpreted as resulting from jets associated with Chiron's comet-like activity, the rings are proposed to be 324 (± 10) km in radius. Their changing appearance at different viewing angles can explain the long-term variation in Chiron's brightness over time.

Ring systems may form around centaurs when they are tidally disrupted in a close encounter (within 0.4 to 0.8 times the Roche limit) with a giant planet. (By definition, a centaur is a minor planet whose orbit crosses the orbit(s) of one or more giant planets.) For a differentiated body approaching a giant planet at an initial relative velocity of 3−6 km/s with an initial rotational period of 8 hours, a ring mass of 0.1%−10% of the centaur's mass is predicted. Ring formation from an undifferentiated body is less likely. The rings would be composed mostly or entirely of material from the parent body's icy mantle. After forming, the ring would spread laterally, leading to satellite formation from whatever portion of it spreads beyond the centaur's Roche Limit. Satellites could also form directly from the disrupted icy mantle. This formation mechanism predicts that roughly 10% of centaurs will have experienced potentially ring-forming encounters with giant planets.

A ring around Haumea, a dwarf planet and resonant Kuiper belt member, was revealed by a stellar occultation observed on 21 January 2017. This makes it the first trans-Neptunian object found to have a ring system. The ring has a radius of about 2,287 km, a width of ~70 km and an opacity of 0.5. The ring plane coincides with Haumea’s equator and the orbit of its larger, outer moon Hi’iaka (which has a semimajor axis of ~25,657 km). The ring is close to the 3:1 resonance with Haumea's rotation, which is located at a radius of 2,285 ± 8 km. It is well within Haumea's Roche limit, which would lie at a radius of about 4,400 km if Haumea were spherical (being nonspherical pushes the limit out farther).

It had previously been theorized by some astronomers that Pluto might have a ring system. However, this possibility has been ruled out by "New Horizons", which would have detected any such ring system.

Because all giant planets of the Solar System have rings, the existence of exoplanets with rings is plausible. Although particles of ice, the material that is predominant in the rings of Saturn, can only exist around planets beyond the frost line, within this line rings consisting of rocky material can be stable in the long term. Such ring systems can be detected for planets observed by the transit method by additional reduction of the light of the central star if their opacity is sufficient. As of January 2015, no such observations are known.

A sequence of occultations of the star 1SWASP J140747.93-394542.6 observed in 2007 over 56 days was interpreted as a transit of a ring system of a (not directly observed) substellar companion dubbed “J1407b”. This ring system is attributed a radius of about 90 million km (about 200 times that of Saturn's rings). In press releases, the term super-Saturn was dubbed. However, the age of this stellar system is only about 16 million years, which suggests that this structure, if real, is more like a protoplanetary disk rather than a stable ring system in an evolved planetary system.

Fomalhaut b was found to be large and unclearly defined when detected in 2008. This may either be due to a cloud of dust attracted from the dust disc of the star, or a possible ring system.



</doc>
<doc id="24721" url="https://en.wikipedia.org/wiki?curid=24721" title="Phoebe">
Phoebe

Phoebe may refer to:







</doc>
<doc id="24722" url="https://en.wikipedia.org/wiki?curid=24722" title="P-code machine">
P-code machine

In computer programming, a p-code machine, or portable code machine is a virtual machine designed to execute p-code (the assembly language of a hypothetical CPU). This term is applied both generically to all such machines (such as the Java Virtual Machine and MATLAB precompiled code), and to specific implementations, the most famous being the p-Machine of the Pascal-P system, particularly the UCSD Pascal implementation (among whose developers the "p" in "p-code" was construed to mean "pseudo" more often than "portable", "pseudo-code" thus meaning instructions for a pseudo-machine) .

Although the concept was first implemented circa 1966 (as O-code for BCPL and P a code for the Euler Language), the term p-code first appeared in the early 1970s. Two early compilers generating p-code were the Pascal-P compiler in 1973, by Nori, Ammann, Jensen, Hageli, and Jacobi,
and the Pascal-S compiler in 1975, by Niklaus Wirth.

Programs that have been translated to p-code can either be interpreted by a software program that emulates the behavior of the hypothetical CPU, or translated into the machine code of the CPU on which the program is to run and then executed. If there is sufficient commercial interest, a hardware implementation of the CPU specification may be built (e.g., the Pascal MicroEngine or a version of the Java processor).

Compared to direct translation into native machine code, a two-stage approach involving translation into p-code and execution by an interpreter or just-in-time compiler offers several advantages.


One of the significant disadvantages of p-code is execution speed, which can sometimes be remedied through the use of a JIT compiler. P-code is often also easier to reverse-engineer than native code.

In the early 1980s, at least two operating systems achieved machine independence through extensive use of p-code. The Business Operating System (BOS) was a cross-platform operating system designed to run p-code programs exclusively. The UCSD p-System, developed at The University of California, San Diego, was a self-compiling and self-hosted operating system based on p-code optimized for generation by the Pascal programming language.

In the 1990s, translation into p-code became a popular strategy for implementations of languages such as Python, Microsoft P-Code in Visual Basic and Java bytecode in Java.

The Go programming language uses a generic, portable assembly as a form of p-code, implemented by Ken Thompson as an extension of the work on Plan 9 from Bell Labs. Unlike CLR bytecode or JVM bytecode, there is no stable specification, and the Go build tools do not emit a bytecode format to be used at a later time. The Go assembler uses the generic assembly language as an intermediate representation, and Go executables are machine-specific statically linked binaries.

Like many other p-code machines, the UCSD p-Machine is a stack machine, which means that most instructions take their operands from the stack, and place results back on the stack. Thus, the "add" instruction replaces the two topmost elements of the stack with their sum. A few instructions take an immediate argument. Like Pascal, the p-code is strongly typed, supporting boolean (b), character (c), integer (i), real (r), set (s), and pointer (a) types natively.

Some simple instructions:

Unlike other stack-based environments (such as Forth and the Java Virtual Machine) but very similar to a real target CPU, the p-System has only one stack shared by procedure stack frames (providing return address, etc.) and the arguments to local instructions. Three of the machine's registers point into the stack (which grows upwards):


Also present is a constant area, and, below that, the heap growing down towards the stack. The NP (the new pointer) register points to the top (lowest used address) of the heap. When EP gets greater than NP, the machine's memory is exhausted.

The fifth register, PC, points at the current instruction in the code area.

Stack frames look like this:

The procedure calling sequence works as follows: The call is introduced with

where codice_1 specifies the difference in nesting levels (remember that Pascal supports nested procedures). This instruction will "mark" the stack, i.e. reserve the first five cells of the above stack frame, and initialise previous EP, dynamic, and static link. The caller then computes and pushes any parameters for the procedure, and then issues

to call a user procedure (codice_1 being the number of parameters, codice_3 the procedure's address). This will save the PC in the return address cell, and set the procedure's address as the new PC.

User procedures begin with the two instructions

The first sets SP to MP + codice_4, the second sets EP to SP + codice_5. So codice_4 essentially specifies the space reserved for locals (plus the number of parameters plus 5), and codice_5 gives the number of entries needed locally for the stack. Memory exhaustion is checked at this point.

Returning to the caller is accomplished via

with codice_8 giving the return type (i, r, c, b, a as above, and p for no return value). The return value has to be stored in the appropriate cell previously. On all types except p, returning will leave this value on the stack.

Instead of calling a user procedure (cup), standard procedure codice_9 can be called with

These standard procedures are Pascal procedures like codice_10 (codice_11), codice_12 (codice_13), etc. Peculiarly codice_14 is a p-Code instruction instead.

Niklaus Wirth specified a simple p-code machine in the 1976 book "Algorithms + Data Structures = Programs". The machine had 3 registers - a program counter "p", a base register "b", and a top-of-stack register "t". There were 8 instructions:

This is the code for the machine, written in Pascal:

This machine was used to run Wirth's PL/0, which was a Pascal subset compiler used to teach compiler development.




</doc>
<doc id="24723" url="https://en.wikipedia.org/wiki?curid=24723" title="Proton-pump inhibitor">
Proton-pump inhibitor

Proton-pump inhibitors (PPIs) are a group of drugs whose main action is a pronounced and long-lasting reduction of stomach acid production. Within the class of medications, there is no clear evidence that one agent works better than another.

They are the most potent inhibitors of acid secretion available. This group of drugs followed and largely superseded another group of medications with similar effects, but a different mode of action, called H-receptor antagonists.
PPIs are among the most widely sold drugs in the world, and the first one, omeprazole, is on the WHO Model List of Essential Medicines. The cost between different agents varies significantly.

These drugs are used in the treatment of many conditions, such as:

Specialty professional organizations recommend that people take the lowest effective PPI dose to achieve the desired therapeutic result when used to treat gastroesophageal reflux disease long-term. In the United States, the Food and Drug Administration has advised that no more than three 14-day treatment courses should be used in one year.

Despite their extensive use, the quality of the evidence supporting their use in some of these conditions is variable. The effectiveness of PPIs has not been demonstrated for every case. For example, although they reduce the incidence of esophageal adenocarcinoma in Barrett's oesophagus, they do not change the length affected.

PPIs are often used longer than necessary. In about half of people who are hospitalized or seen at a primary care clinic there is no documented reason for their long long-term PPIs use. Some researchers believe that given the little evidence of long-term effectiveness, the costs of the medication, and the potential for harm means that clinicians should consider stopping PPIs in many people.

After four weeks, if symptoms have resolved, the PPI may be stopped in those who were using them for heartburn, gastroesophageal reflux disease, or inflammation of the esophagus if these last two were not severe. Stopping is not recommended in those with Barrett esophagus or a bleeding stomach ulcer. Stopping may be carried out by first decreasing the amount of medication taken or having the person take the medication only when symptoms are present.

In general, proton pump inhibitors are well tolerated, and the incidence of short-term adverse effects is relatively low. The range and occurrence of adverse effects are similar for all of the PPIs, though they have been reported more frequently with omeprazole. This may be due to its longer availability and, hence, clinical experience.

Common adverse effects include headache, nausea, diarrhea, abdominal pain, fatigue, and dizziness. Infrequent adverse effects include rash, itch, flatulence, constipation, anxiety, and depression. Also infrequently, PPI use may be associated with occurrence of myopathies, including the serious reaction rhabdomyolysis.

Long-term use of PPIs requires assessment of the balance of the benefits and risks of the therapy. Various adverse outcomes have been associated with long-term PPI use in several primary reports, but reviews assess the overall quality of evidence in these studies as "low" or "very low". They describe inadequate evidence to establish causal relationships between PPI therapy and many of the proposed associations, due to study design and small estimates of effect size. Benefits outweigh risks when PPIs are used appropriately, but when used inappropriately, modest risks become important. They recommend that PPIs should be used at the lowest effective dose in people with a proven indication, but discourage dose escalation and continued chronic therapy in people unresponsive to initial empiric therapy.

Gastric acid is important for breakdown of food and release of micronutrients, and some studies have shown possibilities for interference with absorption of iron, calcium, magnesium, and vitamin B. With regard to iron and vitamin B, the data are weak and several confounding factors have been identified.

Low levels of magnesium can be found in people on PPI therapy and these can be reversed when they are switched to H2-receptor antagonist drugs.

High dose and/or long-term use of PPIs carries a possible increased risk of bone fractures which was not found with short-term, low dose use; the FDA included a warning regarding this on PPI drug labels in 2010.

Some studies have shown a correlation between use of PPIs and "Clostridium difficile" infections. While the data are contradictory and controversial, the FDA had sufficient concern to include a warning about this adverse effect on the label of PPI drugs. Concerns have also been raised about spontaneous bacterial peritonitis in older people taking PPIs and in people with irritable bowel syndrome taking PPIs; both types of infections arise in these populations due to underlying conditions and it is not clear if this is a class effect of PPIs. PPIs may predispose an individual to developing small intestinal bacterial overgrowth or fungal overgrowth.

Long-term use of PPIs is associated with the development of benign polyps from fundic glands (which is distinct from fundic gland polyposis); these polyps do not cause cancer and resolve when PPIs are discontinued. There is no association between PPI use and cancer or pre-cancer. There is concern that use of PPIs may mask gastric cancers or other serious gastric problems and physicians should be aware of this effect.

PPI use has also been associated with the development of microscopic colitis.

There is also evidence that PPI use alters the composition of the bacterial populations inhabiting the gut. Although the mechanisms by which PPIs cause these changes are yet to be determined they may have a role in the increased risk of bacterial infections with PPI use.

Associations of PPI use and cardiovascular events have also been widely studied but clear conclusions have not been made as these relative risks are confounded by other factors. PPIs are commonly used in cardiovascular patients for gastric protection when aspirin is given for its antiplatelet actions. An interaction between PPIs and the metabolism of the platelet inhibitor clopidogrel is known and this drug is also often used in patients with cardiac disease.

One suggested mechanism for cardiovascular effects is because PPIs bind and inhibit dimethylargininase, the enzyme that degrades asymmetric dimethylarginine (ADMA), resulting in higher ADMA levels and a decrease in bioavailable nitric oxide.

Associations have been shown between PPI use and an increased risk of pneumonia, particularly in the 30 days after starting therapy, where it was found to be 50% higher in community use. Other very weak associations of PPI use have been found, such as with chronic kidney disease and dementia. As these results were derived from observational studies, it remains uncertain whether such associations are causal relationships.

Proton pump inhibitors act by irreversibly blocking the hydrogen/potassium adenosine triphosphatase enzyme system (the H/K ATPase, or, more commonly, the gastric proton pump) of the gastric parietal cells. The proton pump is the terminal stage in gastric acid secretion, being directly responsible for secreting H ions into the gastric lumen, making it an ideal target for inhibiting acid secretion.

Targeting the terminal step in acid production, as well as the irreversible nature of the inhibition, results in a class of drugs that are significantly more effective than H antagonists and reduce gastric acid secretion by up to 99%.

Decreasing the acid in the stomach can aid the healing of duodenal ulcers and reduce the pain from indigestion and heartburn. However, stomach acids are needed to digest proteins, vitamin B, calcium, and other nutrients, and too little stomach acid causes the condition hypochlorhydria.

The PPIs are given in an inactive form, which is neutrally charged (lipophilic) and readily crosses cell membranes into intracellular compartments (like the parietal cell canaliculus) with acidic environments. In an acid environment, the inactive drug is protonated and rearranges into its active form. As described above, the active form will covalently and irreversibly bind to the gastric proton pump, deactivating it.

The rate of omeprazole absorption is decreased by concomitant food intake. In addition, the absorption of lansoprazole and esomeprazole is decreased and delayed by food. It has been reported, however, that these pharmacokinetic effects have no significant impact on efficacy.

PPIs have a half-life in human blood plasma of only 60–90 minutes, but because they covalently bind to the pump, the half-life of their inhibition of gastric acid secretion lasts an estimated 24 hours. Dissociation of the inhibitory complex is probably due to the effect of the endogenous antioxidant glutathione which leads to the release of omeprazole sulfide and reactivation of the enzyme.

Medically used proton pump inhibitors:

PPIs were developed in the 1980s with omeprazole being launched in 1988. Most of these drugs are benzimidazole derivatives, related to omeprazole, but imidazopyridine derivatives such as tenatoprazole have also been developed. Potassium-competitive inhibitors such as revaprazan reversibly block the potassium-binding site of the proton pump, acting more quickly, but are not available in most countries.

In British Columbia, Canada the cost of the PPIs varies significantly from 0.20 CAD to 2.38 CAD per dose while all agents in the class appear more or less equally effective.

A comparative table of FDA-approved indications for PPIs is shown below.


</doc>
<doc id="24724" url="https://en.wikipedia.org/wiki?curid=24724" title="Pan-Slavism">
Pan-Slavism

Pan-Slavism, a movement which crystallized in the mid-19th century, is the political ideology concerned with the advancement of integrity and unity for the Slavic-speaking peoples. Its main impact occurred in the Balkans, where non-Slavic empires had ruled the South Slavs for centuries. These were mainly the Byzantine Empire, Austria-Hungary (both as separate entities for most of the period), the Ottoman Empire, and Venice.

Extensive pan-Slavism began much like Pan-Germanism, both of which grew from the sense of unity and nationalism experienced within ethnic groups after the French Revolution and the consequent Napoleonic Wars against European monarchies. Like other Romantic nationalist movements, Slavic intellectuals and scholars in the developing fields of history, philology, and folklore actively encouraged the passion of their shared identity and ancestry. Pan-Slavism also co-existed with the Southern Slavic independence.

Commonly used symbols of the Pan-Slavic movement were the Pan-Slavic colours (blue, white and red) and the Pan-Slavic anthem, "Hey, Slavs".

The first pan-Slavists were the 16th-century Croatian writer Vinko Pribojević and the 17th-century Aleksandar Komulović, Bartol Kašić, Gundulić and Croatian Catholic missionary Juraj Križanić. Some of the earliest manifestations of Pan-Slavic thought within the Habsburg Monarchy have been attributed to Adam Franz Kollár and Pavel Jozef Šafárik. The movement began following the end of the Napoleonic Wars in 1815. In the aftermath, the leaders of Europe sought to restore the pre-war status quo. At the Congress of Vienna, Austria's representative, Prince von Metternich, felt the threat to this status quo in Austria was the nationalists demanding independence from the empire. While their subjects were composed of numerous ethnic groups (such as Italians, Romanians, Hungarians, etc.), most of the subjects were Slavs.

The First Pan-Slav congress was held in Prague, Bohemia in June, 1848, during the revolutionary movement of 1848. The Czechs had refused to send representatives to the Frankfurt Assembly feeling that Slavs had a distinct interest from the Germans. The Austroslav, František Palacký, presided over the event. Most of the delegates were Czech. Palacký called for the co-operation of the Habsburgs and had also endorsed the Habsburg monarchy as the political formation most likely to protect the peoples of central Europe. When the Germans asked him to declare himself in favour of their desire for national unity, he replied that he would not as this would weaken the Habsburg state: “Truly, if it were not that Austria had long existed, it would be necessary, in the interest of Europe, in the interest of humanity itself, to create it.”

The Pan-Slav congress met during the revolutionary turmoil of 1848. Young inhabitants of Prague had taken to the streets and in the confrontation, a stray bullet had killed the wife of Field Marshal Alfred I, Prince of Windisch-Grätz, the commander of the Austrian forces in Prague. Enraged, Windischgrätz seized the city, disbanded the congress, and established martial law throughout Bohemia.

The first Pan-Slavic convention was held in Prague on June 2 through 16, 1848. The delegates at the Congress were specifically both anti-Austrian and anti-Russian. Still "the Right"—the moderately liberal wing of the Congress—under the leadership of František Palacký (1798–1876), a Czech historian and politician, and Pavol Jozef Šafárik (1795–1861), a Slovak philologist, historian and archaeologist, favored autonomy of the Slav lands within the framework of Austrian (Habsburg) monarchy. In contrast "the Left"—the radical wing of the Congress—under the leadership of Karel Sabina (1813–1877), a Czech writer and journalist, Josef Václav Frič, a Czech nationalist, Karol Libelt (1817–1861), a Polish writer and politician, and others, pressed for a close alliance with the revolutionary-democratic movement going on in Germany and Hungary in 1848.

A national rebirth in the Hungarian "Upper Land" (now Slovakia) awoken in a completely new light, both before the Slovak Uprising in 1848 and after. The driving force of this rebirth movement were Slovak writers and politicians who called themselves Štúrovci, the followers of Ľudovít Štúr. As the Slovak nobility was Magyarized and most of Slovaks were merely farmers or priests, this movement failed to attract much attention. Nonetheless, the campaign was successful as a brotherly cooperation between the Croats and the Slovaks brought its fruit throughout the war. Most of the battles between Slovaks and Hungarians however, did not turn out in favor for the Slovaks who were logistically supported by the Austrians, but not sufficiently. The shortage of manpower proved to be decisive as well.

During the war, the Slovak National Council brought its demands to the young Austrian emperor, Franz Joseph I, who seemed to take a note of it and promised support for the Slovaks against the revolutionary radical Hungarians. However the moment the revolution was over, Slovak demands were forgotten. These demands included an autonomous land within the Austrian Empire called "Slovenský kraj" which would be eventually led by a Serbian prince. This act of ignorance from the Emperor convinced the Slovak and the Czech elite who proclaimed the concept of Austroslavism as dead. 

Disgusted by the Emperor's policy, in the year of 1849, Ľudovít Štúr, the person who codified the first official Slovak language, wrote a book he would name "Slavdom and the World of the Future". This book served him as a manifesto where he noted that Austroslavism was not the way to go anymore. He also wrote a sentence that often serves as a quote until this day: "Every nation has its time under the God's sun. And tilia (the symbol of Slavs) blooms, when oak (symbol of the Germanic people) had already died long ago." 

He expressed confidence in the Russian Empire however, as it was the only country of Slavs that was not dominated by anybody else, yet it was one of the most powerful nations in the world. He often symbolized Slavs as being a tree, with "minor" Slavic nations being branches while the trunk of the tree was Russian. His Pan-Slavic views were unleashed in this book, where he stated that the land of Slovaks should be annexed by the Tsar's empire and that eventually the population could be not only Russified, but also converted into the rite of Orthodoxy, religion originally spread by Cyril and Methodius during the times of Great Moravia, which served as an opposition to the Catholic missionaries from the Franks. After the Hungarian invasion of Pannonia, Hungarians converted into Catholicism, which effectively influenced the Slavs living in Pannonia and in the land south of the Lechs.

However, the Russian Empire often claimed Pan-Slavism as a justification for its aggressive moves in the Balkan Peninsula of Europe against the Ottoman Empire, which conquered and held the land of Slavs for centuries. This eventually led to the Balkan campaign of the Russian Empire, which resulted in the entire Balkan being liberated from the Ottoman Empire, with the help and the initiative of the Russian Empire. Pan-Slavism has some supporters among Czech and Slovak politicians, especially among the nationalistic and far-right ones, such as People's Party - Our Slovakia.

During World War I, captured Slavic soldiers were asked to fight against "oppression in the Austrian Empire". Consequently, some did. (see Czechoslovak Legions)

The creation of an independent Czechoslovakia made the old ideals of Pan-Slavism anachronistic. Relations with other Slavic states varied, sometimes being so tense it escalated into an armed conflict, such as with the Second Polish Republic where border clashes over Silesia resulted in a short hostile conflict, the Polish–Czechoslovak War. Even tensions between Czechs and Slovaks had appeared before and during the World War II.

The capital city of Slovakia is Bratislava, a name that is a conjunction of the word Brother (Brat) and Glory (Slava), a name which is generally considered as a symbol of Slavic identity, brotherhood and values.

A paramilitary branch called Slovenskí branci also actively promotes the idea of Slavic unity, identity and values while training their members in war-like simulations, in case "Slovak integrity is threatened by outside forces."

Pan-Slavism in the south would often turn to Russia for support. The Southern Slavic movement advocated the independence of the Slavic peoples in the Austro-Hungarian Empire, Republic of Venice and the Ottoman Empire. Some Serbian intellectuals sought to unite all of the Southern, Balkan Slavs, whether Catholic (Croats, Slovenes), Muslim (Bosniaks), or Orthodox (Serbs, Montenegrins, Bulgarians) as a "Southern-Slavic nation of three faiths".

Austria feared that Pan-Slavists would endanger the empire. In Austria-Hungary Southern Slavs were distributed among several entities: Slovenes in the Austrian part (Carniola, Styria, Carinthia, Gorizia and Gradisca, Trieste, Istria (also Croats)), Croats and Serbs in the Hungarian part within the autonomous Kingdom of Croatia-Slavonia and in the Austrian part within the autonomous Kingdom of Dalmatia, and in Bosnia and Herzegovina, under direct control from Vienna. Due to a different position within Austria-Hungary several different goals were prominent among the Southern Slavs of Austria-Hungary. A strong alternative to Pan-Slavism was Austroslavism, especially among the Croats and Slovenes. Because the Serbs were dispersed among several regions, and the fact that they had ties to the independent nation state of Kingdom of Serbia, they were among the strongest supporters of independence of South-Slavs from Austria-Hungary and uniting into a common state under Serbian monarchy.

In 1863, the Association of Serbian Philology commemorated the death of Cyril a thousand years earlier, its president Dimitrije Matić, talked of the creation of an ethnically "pure" Slavonic people: "with God’s help, there should be a whole Slavonic people with purely Slavonic faces and of purely Slavonic character"

After World War I the creation of the Kingdom of Yugoslavia, under Serbian royalty of the Karađorđević dynasty, united most Southern Slavic-speaking nations regardless of religion and cultural background. The only ones they did not unite with were the Bulgarians. Still, in the years after the Second World War, there were proposals to incorporate Bulgaria into a Greater Yugoslavia thus uniting all south Slavic-speaking nations into one state. The idea was abandoned after the split between Josip Broz Tito and Joseph Stalin in 1948. This led to some bitter sentiment between the people of Yugoslavia and Bulgaria in the aftermath.

At the end of Second World War, the Partisans leader Josip Broz Tito, a Croat, became Yugoslav president, and the country become a socialist republic. Tito advocated Brotherhood and unity which meant equality among the ethnic groups, including non-Slav minorities. This led to relatively peaceful co-existence and prosperity until the breakup of the federation.

Although early Pan-Slavism had found support among some Poles, it soon lost its appeal as the movement became dominated by Russia. While Russian Pan-Slavists spoke of liberation of other Slavs through Russian actions, parts of Poland had been ruled by the Russian Empire since the Partitions of Poland. At different points in history, Poland often saw itself in partnership with non-Slavic nations, such as Hungary, Saxony, Sweden and Lithuania under the Polish–Lithuanian Commonwealth. Especially after 1795, Revolutionary and Napoleonic France was held in high regard by most Poles, and seen as the main champion of reconstitution of their country, particularly since it was a mutual enemy of Austria, Prussia and Russia. The influence of 19th century Pan-Slavism had little impact in Poland except for creating sympathy towards the other oppressed Slavic nations and their aspirations to independence. At the same time while Pan-Slavism worked against Austro-Hungary with South Slavs, Poles enjoyed a wide autonomy within the state and assumed a loyalist position towards the Hapsburgs. Within the Austro-Hungarian polity, they were able to develop their national culture and preserve Polish language, both of which were under threat in both German and Russian Empires. A Pan-Slavic federation was proposed, but on the condition that the Russian Empire would be excluded from such an entity. After Poland regained its independence (from Germany, Austria and Russia) in 1918 no major force considered Pan-Slavism as a serious alternative, viewing Pan-Slavism as little more than a code word for Russification. During Poland's communist era, the USSR used Pan-Slavism as propaganda tool to justify its control over the country. The issue of the Pan-Slavism was not part of current mainstream politics, and is widely seen as an ideology of Russian imperialism.

Joseph Conrad in Notes on Life and Letters.:
""... between Polonism and Slavonism there is not so much hatred as a complete and ineradicable incompatibility."" ... Conrad argues that "nothing is more foreign than what in the literary world is called Slavonism to his "individual" sensibility and "the whole Polish mentality""

Pan-Slavism is popular in the large immigration from the former USSR to Slavic countries of the European Union. It expresses fierce populism, nostalgia for the Soviet era, and strong anti-Western sentiments.

The authentic idea of unity of the Slavic people was all but gone after World War I when the maxim "Versailles and Trianon have put an end to all Slavisms" and was finally put to rest with the fall of communism in Central and Eastern Europe in late 1980s. With the breakup of federal states such as Czechoslovakia and Yugoslavia and the problem of Russian and Serbian dominance in any proposed all-Slavic organisation, the idea of Pan-Slavic unity is mostly considered dead in the western world. Varying relations between the Slavic countries exist nowadays; they range from mutual respect on equal footing and sympathy towards one another through traditional dislike and enmity, to indifference. None, other than culture and heritage oriented organizations, are currently considered as a form of rapprochement among the countries with Slavic origins. The political parties which include panslavism as part of their program usually live on the fringe of the political spectrum (e.g. in Poland candidates from Związek Słowiański got no more than few thousands votes). In modern times, the appeals to Pan-Slavism are often made in Belarus, Russia, Serbia and Slovakia.

The similarity of Slavic languages inspired many people to create Pan-Slavic languages, i.e., zonal constructed languages for all Slavic people to communicate with one another. Several of these languages were created in the past, but due to the Internet, many more Pan-Slavic languages were created in the Digital Age. The most popular modern Pan-Slavic language is Interslavic.





</doc>
<doc id="24727" url="https://en.wikipedia.org/wiki?curid=24727" title="Pan-Germanism">
Pan-Germanism

Pan-Germanism ( or '), also occasionally known as Pan-Germanicism"', is a pan-nationalist political idea. Pan-Germanists originally sought to unify all the German and possibly also Germanic-speaking peoples in a single nation-state known as "Großdeutschland".

Pan-Germanism was highly influential in German politics in the 19th century during the unification of Germany when the German Empire was proclaimed as a nation-state in 1871 but without Austria (Kleindeutsche Lösung/Lesser Germany), and the first half of the 20th century in the Austro-Hungarian Empire and the German Empire. From the late 19th century, many Pan-Germanist thinkers, since 1891 organized in the Pan-German League, had adopted openly ethnocentric and racist ideologies, and ultimately gave rise to the foreign policy "Heim ins Reich" pursued by Nazi Germany under Austrian-born Adolf Hitler from 1938, one of the primary factors leading to the outbreak of World War II.
As a result of the disaster of World War II, Pan-Germanism was mostly seen as a taboo ideology in the postwar period in both West and East Germany. Today, Pan-Germanism is mainly limited to some nationalist groups in Germany and Austria.

The word "pan" is a Greek word element meaning "all, every, whole, all-inclusive". The word "German" in this context derives from Latin "Germani" originally used by Julius Caesar referring to tribes or a single tribe in northeastern Gaul. In the Late Middle Ages, it acquired a loose meaning referring to the speakers of Germanic languages (alongside 'Almain' and 'Teuton') most of whom spoke dialects ancestral to modern German. In English, "Pan-German" was first attested in 1892. In German, there exists a synonym ""Alldeutsche Bewegung"" which is a calque using German instead of Latin and Greek roots.

Pan-Germanism's origins began with the birth of Romantic nationalism during the Napoleonic Wars, with Friedrich Ludwig Jahn and Ernst Moritz Arndt being early proponents. Germans, for the most part, had been a loose and disunited people since the Reformation, when the Holy Roman Empire was shattered into a patchwork of states following the end of the Thirty Years' War with the Peace of Westphalia.

Advocates of the "Großdeutschland" (Greater Germany) solution sought to unite all the German-speaking people in Europe, under the leadership of the German Austrians from the Austrian Empire. Pan-Germanism was widespread among the revolutionaries of 1848, notably among Richard Wagner and the Brothers Grimm. Writers such as Friedrich List and Paul Anton Lagarde argued for German hegemony in Central and Eastern Europe, where German domination in some areas had begun as early as the 9th century AD with the Ostsiedlung, Germanic expansion into Slavic and Baltic lands. For the Pan-Germanists, this movement was seen as a Drang nach Osten, in which Germans would be naturally inclined to seek Lebensraum by moving eastwards to reunite with the German minorities there.

The "Deutschlandlied" ("Song of Germany"), written in 1841 by Hoffmann von Fallersleben, in its first stanza defines "Deutschland" as reaching "From the Meuse to the Memel / From the Adige to the Belt", i.e. as including East Prussia and South Tyrol.

Reflecting upon the First Schleswig War in 1848, Karl Marx noted that "by quarrelling amongst themselves, instead of confederating, Germans and Scandinavians, both of them belonging to the same great race, only prepare the way for their hereditary enemy, the Slav."

 
By the 1860s the Kingdom of Prussia and the Austrian Empire had become the two most powerful states dominated by German-speaking élites. Both sought to expand their influence and territory. The Austrian Empire—like the Holy Roman Empire—was a multi-ethnic state, but the German-speaking people there did not have an absolute numerical majority; its re-shaping into the Austro-Hungarian Empire was one result of the growing nationalism of other ethnicities—especially the Hungarians. Under Prussian leadership, Otto von Bismarck would ride on the coat-tails of nationalism to unite all of the northern German lands. After Bismarck excluded Austria and the German Austrians from Germany in the German war of 1866 and (following a few other events over the next few years), the unification of Germany, established the Prussian-dominated German Empire ("Second Reich") in 1871 with the proclamation of Wilhelm I as head of a union of German-speaking states, while disregarding millions of its non-German subjects who desired self-determination from German rule. After World War I the Pan-Germanist philosophy changed drastically during the ascendancy of Adolf Hitler. Pan-Germanists originally sought to unify all the German-speaking populations of Europe in a single nation-state known as "Großdeutschland" (Greater Germany), where "German-speaking" was sometimes taken as synonymous with Germanic-speaking, to the inclusion of the Frisian- and Dutch-speaking populations of the Low Countries, and Scandinavia.

Although Bismarck had excluded Austria and the German Austrians from his creation of the Kleindeutschland state in 1871, integrating the German Austrians nevertheless remained a strong desire for many people of both Austria and Germany. The most radical Austrian pan-German Georg Schönerer (1842–1921) and (1862–1941) articulated Pan-Germanist sentiments in the Austro-Hungarian Empire. There was also a rejection of Roman Catholicism with the Away from Rome! movement (ca 1900 onwards) calling for German-speakers to identify with Lutheran or Old Catholic churches. The Pan-German Movement gained an institutional format in 1891, when , a professor at the University of Leipzig and a member of the Reichstag, organized the Pan-German League, an ultra-nationalist political-interest organization which promoted imperialism, anti-semitism, and support for ethnic German minorities in other countries.
The organization achieved great support among the educated middle and upper class; it promoted German nationalist consciousness, especially among ethnic Germans outside Germany. In his three-volume work, "Deutsche Politik" (1905–07), Hasse called for German imperialist expansion in Europe. The Munich professor Karl Haushofer, , and Hans Grimm (author of the novel "Volk ohne Raum") preached similar expansionist policies.

After the Revolutions of 1848/49, in which the liberal nationalistic revolutionaries advocated the Greater German solution, the Austrian defeat in the Austro-Prussian War (1866) with the effect that Austria was now excluded from Germany, and increasing ethnic conflicts in the multinational Habsburg Monarchy, a German national movement evolved in Austria. Led by the radical German nationalist and anti-semite Georg von Schönerer, organisations such as the "Pan-German Society" demanded the annexation of all German-speaking territories of the Danube Monarchy to the German Empire, and fervently rejected Austrian patriotism and a pan-Austrian identity. Schönerer's völkisch and racist German nationalism was an inspiration to Hitler's Nazi ideology.

In 1933, Austrian Nazis and the national-liberal Greater German People's Party formed an action group, fighting together against the Austrofascist regime which imposed a distinct Austrian national identity and in accordance said that Austrians were "better Germans", while Kurt Schuschnigg adopted a policy of appeasement towards Austrian-born Hitler's annexing of Austria to Nazi Germany and called Austria the "better German state", but he still struggled to keep Austria independent. With "Anschluss" of Austria in 1938, the historic aim of Austria's German nationalists was achieved.

After the end of Nazi Germany and the events of World War II in 1945, the ideas of pan-Germanism and an "Anschluss" fell out of favour due to their association with Nazism and allowed Austrians to develop their own national identity. Nevertheless, such notions were revived with the German national camp in the Federation of Independents and the early Freedom Party of Austria.

The idea of including the North Germanic-speaking Scandinavians into a Pan-German state, sometimes referred to as Pan-Germanicism, was promoted alongside mainstream pan-German ideas. Jacob Grimm adopted Munch's anti-Danish Pan-Germanism and argued that the entire peninsula of Jutland had been populated by Germans before the arrival of the Danes and that thus it could justifiably be reclaimed by Germany, whereas the rest of Denmark should be incorporated into Sweden. This line of thinking was countered by Jens Jacob Asmussen Worsaae, an archaeologist who had excavated parts of Danevirke, who argued that there was no way of knowing the language of the earliest inhabitants of Danish territory. He also pointed out that Germany had more solid historical claims to large parts of France and England, and that Slavs—by the same reasoning—could annex parts of Eastern Germany. Regardless of the strength of Worsaae's arguments, pan-Germanism spurred on the German nationalists of Schleswig and Holstein and led to the First Schleswig War in 1848. In turn, this likely contributed to the fact that Pan-Germanism never caught on in Denmark as much as it did in Norway. Pan-Germanic tendencies were particularly widespread among the Norwegian independence movement. Prominent supporters included Peter Andreas Munch, Christopher Bruun, Knut Hamsun, Henrik Ibsen and Bjørnstjerne Bjørnson. Bjørnson, who wrote the lyrics for the Norwegian national anthem, proclaimed in 1901:

Anti-German Scandinavism surged in Denmark in the 1930s and 1940s in response to the pan-Germanic ambitions of Nazi Germany.

World War I became the first attempt to carry out the Pan-German ideology in practice, and the Pan-German movement argued forcefully for expansionist imperialism.

Following the defeat in World War I, the influence of German-speaking elites over Central and Eastern Europe was greatly limited. At the Treaty of Versailles, Germany was substantially reduced in size. Austria-Hungary was split up. A Rump-Austria, which to a certain extent corresponded to the German-speaking areas of Austria-Hungary (a complete split into language groups was impossible due to multi-lingual areas and language-exclaves) adopted the name "German Austria" () in hope for union with Germany. Union with Germany and the name "German Austria" was forbidden by the Treaty of St. Germain and the name had to be changed back to Austria.

It was in the post-World War I period that the Austrian-born Adolf Hitler, under the influence of the stab-in-the-back myth, first took up German nationalist ideas in his "Mein Kampf". Hitler met Heinrich Class in 1918, and Class provided Hitler with support for the 1923 Beer Hall Putsch. Hitler and his National Socialist friends shared most of the basic pan-German visions with the Pan-German League, but differences in political style led the two groups to open rivalry. The German Workers Party of Bohemia cut its ties to the pan-German movement, which was seen as being too dominated by the upper classes, and joined forces with the German Workers Party led by Anton Drexler, which later became the National Socialist German Workers Party (Nazi party) that was to be headed by Adolf Hitler from 1921.

Nazi propaganda also used the political slogan "Ein Volk, ein Reich, ein Führer" ("One people, one Reich, one leader"), to enforce pan-German sentiment in Austria for an "Anschluss".

The "Heim ins Reich" ("Back Home to the Reich") initiative was a policy pursued by the Nazis which attempted to convince the ethnic Germans living outside of Nazi Germany (such as in Austria and Sudetenland) that they should strive to bring these regions "home" into a Greater Germany. This notion also led the way for an even more expansive state to be envisioned, the Greater Germanic Reich, which Nazi Germany tried to establish. This pan-Germanic empire was expected to assimilate practically all of Germanic Europe into an enormously expanded Greater Germanic Reich. Territorially speaking, this encompassed the already-enlarged Reich itself (consisting of pre-1938 Germany plus the areas annexed into the "Großdeutsche Reich"), the Netherlands, Belgium, areas in north-eastern France considered to be historically and ethnically Germanic, Denmark, Norway, Sweden, Iceland, at least the German-speaking Switzerland, and Liechtenstein. The most notable exception was the predominantly Anglo-Saxon United Kingdom, which was not projected as having to be reduced to a German province but to instead become an allied seafaring partner of the Germans.

The eastern "Reichskommissariats" in the vast stretches of Ukraine and Russia were also intended for future integration, with plans for them stretching to the Volga or even beyond the Urals. They were deemed of vital interest for the survival of the German nation, as it was a core tenet of national-socialist ideology that it needed "living space" ("Lebensraum"), creating a "pull towards the East" ("Drang nach Osten") where that could be found and colonized, in a model that the Nazis explicitly derived from the American Manifest Destiny in the Far West and its clearing of native inhabitants.

The defeat of Germany in World War II brought about the decline of Pan-Germanism, much as World War I had led to the demise of Pan-Slavism. Parts of Germany itself were devastated, and the country was divided, firstly into Soviet, French, American, and British zones and then into West Germany and East Germany. To add to the disaster, Germany suffered even larger territorial losses than it did in the First World War, with vast portions of eastern Germany directly annexed by the Soviet Union and Poland. The scale of the Germans' defeat was unprecedented; Pan-Germanism became taboo because it had been tied to racist concepts of the "master race" and "Nordicism" by the Nazi party. However, the reunification of Germany in 1990 revived the old debates.

Up to and during 18th century 

19th century 

20th century 



</doc>
<doc id="24730" url="https://en.wikipedia.org/wiki?curid=24730" title="Patrick Abercromby">
Patrick Abercromby

Patrick Abercromby (1656) was a Scottish physician and antiquarian, noted for being physician to King James VII (II of England) and his fervent opposition to the Act of Union between Scotland and England.

Patrick Abercromby was the third son of Alexander Abercromby of Fetterneir in Aberdeenshire, and brother of Francis Abercromby, who was created Lord Glasford by King James II. He was born at Forfar in 1656 apparently of a Roman Catholic family.

Intending to become a doctor of medicine he entered the University of St Andrews, where he took his degree of M.D. in 1685, but apparently he spent most of his youthful years abroad. It has been stated that he attended the university of Paris, France. The Discourse of Wit (1685), sometimes assigned to him, belongs to Dr David Abercromby.

On his return to Scotland, he is found practising as a physician in Edinburgh, where, besides his professional duties, he gave himself with characteristic zeal to the study of antiquities. He was appointed physician to James II in 1685, but the revolution deprived him of the post. Living during the agitations for the union of England and Scotland, he took part as a Jacobite in the war of pamphlets inaugurated and sustained by prominent men on both sides of the Border, and he crossed swords with no less redoubtable a foe than Daniel Defoe in his "Advantages of the Act of Security compared with those of the intended Union" (Edinburgh, 1707), and "A Vindication of the Same against Mr De Foe" (ibid.).

A minor literary work of Abercromby's was a translation of Jean de Beaugué's "Histoire de la guerre d'Écosse" (1556) which appeared in 1707. But the work with which his name is permanently associated is his "Martial Atchievements "[sic]" of the Scots Nation", issued in two large folios, vol. i. 1711, vol. ii. 1716. In the title-page and preface to vol. i. he disclaims the ambition of being an historian, but in vol. ii., in title-page and preface alike, he is no longer a simple biographer, but an historian. Even though, read in the light of later research, much of the first volume must necessarily be relegated to the region of the mythical, nonetheless, the historian was a laborious and accomplished reader and investigator of all available authorities, as well manuscript as printed; while the roll of names of those who aided him includes every man of note in Scotland at the time, from Sir Thomas Craig and Sir George Mackenzie to Alexander Nisbet and Thomas Ruddiman.

The date of Abercromby's death is uncertain. It has been variously assigned to 1715, 1716, 1720, and 1726, and it is usually added that he left a widow in great poverty. The Memoirs of the Abercrombys, commonly attributed to him, do not appear to have been published.




</doc>
<doc id="24731" url="https://en.wikipedia.org/wiki?curid=24731" title="Positron">
Positron

The positron or antielectron is the antiparticle or the antimatter counterpart of the electron. The positron has an electric charge of +1 "e", a spin of 1/2 (same as electron), and has the same mass as an electron. When a positron collides with an electron, annihilation occurs. If this collision occurs at low energies, it results in the production of two or more gamma ray photons (see electron–positron annihilation).

Positrons may be generated by positron emission radioactive decay (through weak interactions), or by pair production from a sufficiently energetic photon which is interacting with an atom in a material.

In 1928, Paul Dirac published a paper proposing that electrons can have both a positive and negative charge. This paper introduced the Dirac equation, a unification of quantum mechanics, special relativity, and the then-new concept of electron spin to explain the Zeeman effect. The paper did not explicitly predict a new particle but did allow for electrons having either positive or negative energy as solutions. Hermann Weyl then published a paper discussing the mathematical implications of the negative energy solution. The positive-energy solution explained experimental results, but Dirac was puzzled by the equally valid negative-energy solution that the mathematical model allowed. Quantum mechanics did not allow the negative energy solution to simply be ignored, as classical mechanics often did in such equations; the dual solution implied the possibility of an electron spontaneously jumping between positive and negative energy states. However, no such transition had yet been observed experimentally. He referred to the issues raised by this conflict between theory and observation as "difficulties" that were "unresolved".

Dirac wrote a follow-up paper in December 1929 that attempted to explain the unavoidable negative-energy solution for the relativistic electron. He argued that "... an electron with negative energy moves in an external [electromagnetic] field as though it carries a positive charge." He further asserted that all of space could be regarded as a "sea" of negative energy states that were filled, so as to prevent electrons jumping between positive energy states (negative electric charge) and negative energy states (positive charge). The paper also explored the possibility of the proton being an island in this sea, and that it might actually be a negative-energy electron. Dirac acknowledged that the proton having a much greater mass than the electron was a problem, but expressed "hope" that a future theory would resolve the issue.

Robert Oppenheimer argued strongly against the proton being the negative-energy electron solution to Dirac's equation. He asserted that if it were, the hydrogen atom would rapidly self-destruct. Persuaded by Oppenheimer's argument, Dirac published a paper in 1931 that predicted the existence of an as-yet-unobserved particle that he called an "anti-electron" that would have the same mass as an electron and that would mutually annihilate upon contact with an electron.

Feynman, and earlier Stueckelberg, proposed an interpretation of the positron as an electron moving backward in time, reinterpreting the negative-energy solutions of the Dirac equation. Electrons moving backward in time would have a positive electric charge. Wheeler invoked this concept to explain the identical properties shared by all electrons, suggesting that "they are all the same electron" with a complex, self-intersecting worldline. Yoichiro Nambu later applied it to all production and annihilation of particle-antiparticle pairs, stating that "the eventual creation and annihilation of pairs that may occur now and then is no creation or annihilation, but only a change of direction of moving particles, from the past to the future, or from the future to the past." The backwards in time point of view is nowadays accepted as completely equivalent to other pictures, but it does not have anything to do with the macroscopic terms "cause" and "effect", which do not appear in a microscopic physical description.

Dmitri Skobeltsyn first observed the positron in 1929. While using a Wilson cloud chamber to try to detect gamma radiation in cosmic rays, Skobeltsyn detected particles that acted like electrons but curved in the opposite direction in an applied magnetic field.

Likewise, in 1929 Chung-Yao Chao, a graduate student at Caltech, noticed some anomalous results that indicated particles behaving like electrons, but with a positive charge, though the results were inconclusive and the phenomenon was not pursued.

Carl David Anderson discovered the positron on 2 August 1932, for which he won the Nobel Prize for Physics in 1936. Anderson did not coin the term "positron", but allowed it at the suggestion of the "Physical Review" journal editor to which he submitted his discovery paper in late 1932. The positron was the first evidence of antimatter and was discovered when Anderson allowed cosmic rays to pass through a cloud chamber and a lead plate. A magnet surrounded this apparatus, causing particles to bend in different directions based on their electric charge. The ion trail left by each positron appeared on the photographic plate with a curvature matching the mass-to-charge ratio of an electron, but in a direction that showed its charge was positive.

Anderson wrote in retrospect that the positron could have been discovered earlier based on Chung-Yao Chao's work, if only it had been followed up on. Frédéric and Irène Joliot-Curie in Paris had evidence of positrons in old photographs when Anderson's results came out, but they had dismissed them as protons.

The positron had also been contemporaneously discovered by Patrick Blackett and Giuseppe Occhialini at the Cavendish Laboratory in 1932. Blackett and Occhialini had delayed publication to obtain more solid evidence, so Anderson was able to publish the discovery first.

Positrons are produced naturally in β decays of naturally occurring radioactive isotopes (for example, potassium-40) and in interactions of gamma quanta (emitted by radioactive nuclei) with matter. Antineutrinos are another kind of antiparticle produced by natural radioactivity (β decay). Many different kinds of antiparticles are also produced by (and contained in) cosmic rays. Recent (as of January 2011) research by the American Astronomical Society has discovered antimatter (positrons) originating above thunderstorm clouds; positrons are produced in gamma-ray flashes created by electrons accelerated by strong electric fields in the clouds. Antiprotons have also been found to exist in the Van Allen Belts around the Earth by the PAMELA module.

Antiparticles, of which the most common are positrons due to their low mass, are also produced in any environment with a sufficiently high temperature (mean particle energy greater than the pair production threshold). During the period of baryogenesis, when the universe was extremely hot and dense, matter and antimatter were continually produced and annihilated. The presence of remaining matter, and absence of detectable remaining antimatter, also called baryon asymmetry, is attributed to CP-violation: a violation of the CP-symmetry relating matter to antimatter. The exact mechanism of this violation during baryogenesis remains a mystery.

Positron production from radioactive decay can be considered both artificial and natural production, as the generation of the radioisotope can be natural or artificial. Perhaps the best known naturally-occurring radioisotope which produces positrons is potassium-40, a long-lived isotope of potassium which occurs as a primordial isotope of potassium. Even though a small percent of potassium (0.0117%) it is the single most abundant radioisotope in the human body. In a human body of 70 kg mass, about 4,400 nuclei of K decay per second. The activity of natural potassium is 31 Bq/g. About 0.001% of these K decays produce about 4000 natural positrons per day in the human body. These positrons soon find an electron, undergo annihilation, and produce pairs of 511 keV gamma rays, in a process similar (but much lower intensity) to that which happens during a PET scan nuclear medicine procedure. 

Recent observations indicate black holes and neutron stars produce vast amounts of positron-electron plasma via the jets. Large clouds of positron-electron plasma have also been associated with neutron stars.

Satellite experiments have found evidence of positrons (as well as a few antiprotons) in primary cosmic rays, amounting to less than 1% of the particles in primary cosmic rays. These do not appear to be the products of large amounts of antimatter from the Big Bang, or indeed complex antimatter in the universe (evidence for which is lacking, see below). Rather, the antimatter in cosmic rays appear to consist of only these two elementary particles, probably made in energetic processes long after the Big Bang. 

Preliminary results from the presently operating Alpha Magnetic Spectrometer ("AMS-02") on board the International Space Station show that positrons in the cosmic rays arrive with no directionality, and with energies that range from 10 to 250 GeV. In September 2014, new results with almost twice as much data were presented in a talk at CERN and published in Physical Review Letters. A new measurement of positron fraction up to 500 GeV was reported, showing that positron fraction peaks at a maximum of about 16% of total electron+positron events, around an energy of 275 ± 32 GeV. At higher energies, up to 500 GeV, the ratio of positrons to electrons begins to fall again. The absolute flux of positrons also begins to fall before 500 GeV, but peaks at energies far higher than electron energies, which peak about 10 GeV. These results on interpretation have been suggested to be due to positron production in annihilation events of massive dark matter particles.

Positrons, like anti-protons, do not appear to originate from any hypothetical "antimatter" regions of the universe. On the contrary, there is no evidence of complex antimatter atomic nuclei, such as antihelium nuclei (i.e., anti-alpha particles), in cosmic rays. These are actively being searched for. A prototype of the "AMS-02" designated "AMS-01", was flown into space aboard the on STS-91 in June 1998. By not detecting any antihelium at all, the "AMS-01" established an upper limit of 1.1×10 for the antihelium to helium flux ratio.

Physicists at the Lawrence Livermore National Laboratory in California have used a short, ultra-intense laser to irradiate a millimeter-thick gold target and produce more than 100 billion positrons. Presently significant lab production of 5 MeV positron-electron beams allows investigation of multiple characteristics such as how different elements react to 5 MeV positron interactions or impacts, how energy is transferred to particles, and the shock effect of gamma-ray bursts (GRBs).

Certain kinds of particle accelerator experiments involve colliding positrons and electrons at relativistic speeds. The high impact energy and the mutual annihilation of these matter/antimatter opposites create a fountain of diverse subatomic particles. Physicists study the results of these collisions to test theoretical predictions and to search for new kinds of particles.

The ALPHA experiment combines positrons with antiprotons to study properties of antihydrogen.

Gamma rays, emitted indirectly by a positron-emitting radionuclide (tracer), are detected in positron emission tomography (PET) scanners used in hospitals. PET scanners create detailed three-dimensional images of metabolic activity within the human body.

An experimental tool called positron annihilation spectroscopy (PAS) is used in materials research to detect variations in density, defects, displacements, or even voids, within a solid material.




</doc>
<doc id="24733" url="https://en.wikipedia.org/wiki?curid=24733" title="Phencyclidine">
Phencyclidine

Phencyclidine (PCP), also known as angel dust among other names, is a drug used for its mind-altering effects. PCP may cause hallucinations, distorted perceptions of sounds, and violent behavior. As a recreational drug, it is typically smoked, but may be taken by mouth, snorted, or injected. It may also be mixed with cannabis or tobacco.
Adverse effects may include seizures, coma, addiction, and an increased risk of suicide. Flashbacks may occur despite stopping usage. Chemically, PCP is a member of the arylcyclohexylamine class, and pharmacologically, it is a dissociative anesthetic. PCP works primarily as an NMDA receptor antagonist.
PCP is most commonly used in the United States. While usage peaked there in the 1970s, between 2005 and 2011 an increase in visits to emergency departments as a result of the drug occurred. As of 2017 in the United States about 1% of people in grade twelve reported using PCP in the prior year while 2.9% of those over the age of 25 reported using it at some point in their life.
PCP was initially made in 1926 and brought to market as an anesthetic medication in the 1950s. Its use in humans was disallowed in the United States in 1965 due to the high rates of side effects while its use in other animals was disallowed in 1978. Moreover, ketamine was discovered and was better tolerated as an anesthetic. PCP is currently illegal in the United States where it is classified as a schedule II drug. A number of derivatives of PCP have been sold for recreational and non-medical use.
Behavioral effects can vary by dosage. Low doses produce a numbness in the extremities and intoxication, characterized by staggering, unsteady gait, slurred speech, bloodshot eyes, and loss of balance. Moderate doses (5–10 mg intranasal, or 0.01–0.02 mg/kg intramuscular or intravenous) will produce analgesia and anesthesia. High doses may lead to convulsions. The drug is often illegally produced under poorly-controlled conditions; this means that users may be unaware of the actual dose they are taking.

Psychological effects include severe changes in body image, loss of ego boundaries, paranoia, and depersonalization. Hallucinations, euphoria, and suicidal impulses are also reported, as well as occasional aggressive behavior. Like many other drugs, PCP has been known to alter mood states in an unpredictable fashion, causing some individuals to become detached, and others to become animated. PCP may induce feelings of strength, power, and invulnerability as well as a numbing effect on the mind.

Studies by the Drug Abuse Warning Network in the 1970s show that media reports of PCP-induced violence are greatly exaggerated and that incidents of violence are unusual and often limited to individuals with reputations for aggression regardless of drug use. Although uncommon, events of PCP-intoxicated individuals acting in an unpredictable fashion, possibly driven by their delusions or hallucinations, have been publicized. One example is the case of Big Lurch, a former rapper with a history of violent crime, who was convicted of murdering and cannibalizing his roommate while under the influence of PCP. Other commonly cited types of incidents include inflicting property damage and self-mutilation of various types, such as pulling one's own teeth. These effects were not noted in its medicinal use in the 1950s and 1960s however, and reports of physical violence on PCP have often been shown to be unfounded.

Recreational doses of the drug also occasionally appear to induce a psychotic state that resembles a schizophrenic episode, sometimes lasting for months at a time. Users generally report feeling detached from reality.

Symptoms are summarized by the mnemonic device RED DANES: rage, erythema (redness of skin), dilated pupils, delusions, amnesia, nystagmus (oscillation of the eyeball when moving laterally), excitation, and skin dryness.

PCP is self-administered and induces ΔFosB expression in the D1-type medium spiny neurons of the nucleus accumbens, and accordingly, excessive PCP use is known to cause addiction. PCP's rewarding and reinforcing effects are at least partly mediated by blocking the NMDA receptors in the glutamatergic inputs to D1-type medium spiny neurons in the nucleus accumbens. PCP has been shown to produce conditioned place aversion and conditioned place preference in animal studies.

PCP comes in both powder and liquid forms (PCP base is dissolved most often in ether), but typically it is sprayed onto leafy material such as cannabis, mint, oregano, tobacco, parsley, or ginger leaves, then smoked.

Management of PCP intoxication mostly consists of supportive care – controlling breathing, circulation, and body temperature – and, in the early stages, treating psychiatric symptoms. Benzodiazepines, such as lorazepam, are the drugs of choice to control agitation and seizures (when present). Typical antipsychotics such as phenothiazines and haloperidol have been used to control psychotic symptoms, but may produce many undesirable side effects – such as dystonia – and their use is therefore no longer preferred; phenothiazines are particularly risky, as they may lower the seizure threshold, worsen hyperthermia, and boost the anticholinergic effects of PCP. If an antipsychotic is given, intramuscular haloperidol has been recommended.

Forced acid diuresis (with ammonium chloride or, more safely, ascorbic acid) may increase clearance of PCP from the body, and was somewhat controversially recommended in the past as a decontamination measure. However, it is now known that only around 10% of a dose of PCP is removed by the kidneys, which would make increased urinary clearance of little consequence; furthermore, urinary acidification is dangerous, as it may induce acidosis and worsen rhabdomyolysis (muscle breakdown), which is not an unusual manifestation of PCP toxicity.

PCP is well known for its primary action on the NMDA receptor, an ionotropic glutamate receptor, in rats and in rat brain homogenate. As such, PCP is an NMDA receptor antagonist. The role of NMDAR antagonism in the effect of PCP, ketamine, and related dissociative agents was first published in the early 1980s by David Lodge and colleagues. Other NMDA receptor antagonists include ketamine, tiletamine, dextromethorphan, nitrous oxide, and dizocilpine (MK-801).

Research also indicates that PCP inhibits nicotinic acetylcholine receptors (nAChRs) among other mechanisms. Analogues of PCP exhibit varying potency at nACh receptors and NMDA receptors. Findings demonstrate that presynaptic nAChRs and NMDA receptor interactions influence postsynaptic maturation of glutamatergic synapses and consequently impact synaptic development and plasticity in the brain. These effects can lead to inhibition of excitatory glutamate activity in certain brain regions such as the hippocampus and cerebellum thus potentially leading to memory loss as one of the effects of prolonged use. Acute effects on the cerebellum manifest as changes in blood pressure, breathing rate, pulse rate, and loss of muscular coordination during intoxication.

PCP, like ketamine, also acts as a potent dopamine D receptor partial agonist in rat brain homogenate and has affinity for the human cloned D receptor. This activity may be associated with some of the other more psychotic features of PCP intoxication, which is evidenced by the successful use of D receptor antagonists (such as haloperidol) in the treatment of PCP psychosis.

In addition to its well explored interactions with NMDA receptors, PCP has also been shown to inhibit dopamine reuptake, and thereby leads to increased extracellular levels of dopamine and hence increased dopaminergic neurotransmission. However, PCP has little affinity for the human monoamine transporters, including the dopamine transporter (DAT). Instead, its inhibition of monoamine reuptake may be mediated by interactions with allosteric sites on the monoamine transporters. PCP is notably a high-affinity ligand of the PCP site 2 (K = 154 nM), a not-well-characterized site associated with monoamine reuptake inhibition.

Studies on rats indicate that PCP interacts indirectly with opioid receptors (endorphin and enkephalin) to produce analgesia.

A binding study assessed PCP at 56 sites including neurotransmitter receptors and transporters and found that PCP had K values of >10,000 nM at all sites except the dizocilpine (MK-801) site of the NMDA receptor (K = 59 nM), the σ receptor (PC12) (K = 136 nM), and the serotonin transporter (K = 2,234 nM). The study notably found K values of >10,000 nM for the D receptor, the opioid receptors, the σ receptor, and the dopamine and norepinephrine transporters. These results suggest that PCP is a highly selective ligand of the NMDAR and σ receptor. However, PCP may also interact with allosteric sites on the monoamine transporters to produce inhibition of monoamine reuptake.

Some studies found that, like other NMDA receptor antagonists, PCP can cause a kind of brain damage called Olney's lesions in rats. Studies conducted on rats showed that high doses of the NMDA receptor antagonist dizocilpine caused reversible vacuoles to form in certain regions of the rats' brains. All studies of Olney's lesions have only been performed on non-human animals and may not apply to humans. One unpublished study by Frank Sharp reportedly showed no damage by the NDMA antagonist, ketamine, a similar drug, far beyond recreational doses, but due to the study never having been published, its validity is controversial.

PCP has also been shown to cause schizophrenia-like changes in "N"-acetylaspartate and "N"-acetylaspartylglutamate levels in the rat brain, which are detectable both in living rats and upon necropsy examination of brain tissue. It also induces symptoms in humans that mimic schizophrenia. PCP not only produced symptoms similar to schizophrenia, it also yielded electroencephalogram changes in the thalamocortical pathway (increased delta decreased alpha) and in the hippocampus (increase theta bursts) that were similar to those in schizophrenia. PCP induced augmentation of dopamine release may link the NMDA and DA hypothesis of schizophrenia.

PCP is metabolized into PCHP, PPC and PCAA.

When smoked, some of the compound is broken down by heat into 1-phenylcyclohexene (PC) and piperidine.

PCP is an arylcyclohexylamine.

Fewer than 30 different analogues of PCP were reported as being used on the street during the 1970s and 1980s, mainly in the United States. The best known of these are rolicyclidine (PCPy or 1-(1-phenylcyclohexyl)pyrrolidine); eticyclidine (PCE or "N"-ethyl-1-phenylcyclohexylamine); and tenocyclidine (TCP or 1-(1-(2-thienyl)cyclohexyl)piperidine). Only of a few of these compounds were widely used.

The generalized structural motif required for PCP-like activity is derived from structure-activity relationship studies of PCP derivatives, and summarized in the illustration (right). All of these derivatives are likely to share some of their psychoactive effects with PCP itself, although a range of potencies and varying mixtures of anesthetic, dissociative and stimulant effects are known, depending on the particular drug and its substituents. In some countries such as the United States, Australia, and New Zealand, all of these compounds would be considered controlled substance analogues of PCP, and are hence illegal drugs if sold for human consumption, even though many of them have never been made or tested.

Other analogues of PCP include 3-HO-PCP, 3-MeO-PCMo, and 3-MeO-PCP.

PCP began to emerge as a recreational drug in major cities in the United States in 1960s. In 1978, "People" magazine and Mike Wallace of "60 Minutes" called PCP the country's "number one" drug problem. Although recreational use of the drug had always been relatively low, it began declining significantly in the 1980s. In surveys, the number of high school students admitting to trying PCP at least once fell from 13% in 1979 to less than 3% in 1990.

It is commonly mistakenly reported that PCP was first synthesized in 1926. This early synthesis, in fact, refers to the PCP intermediate PCC. PCP was actually discovered by Victor Maddox, a chemist at Parke-Davis in Michigan, while investigating synthetic analgesic agents. Although unexpected, PCP was identified as potentially interesting, and as such, was submitted for pharmacological testing. The promising results of these pharmacological investigations led to the rapid development of PCP. It was approved for use as an investigational drug under the brand names Sernyl and Sernylan in the 1950s as an anesthetic, but because of its long terminal half-life and adverse side effects, such as hallucinations, mania, delirium, and disorientation, it was removed from the market in 1965 and limited to veterinary use.

PCP is a Schedule II substance in the United States and its ACSCN is 7471. Its manufacturing quota for 2014 was 19 grams.

It is a Schedule I drug by the Controlled Drugs and Substances act in Canada, a List I drug of the Opium Law in the Netherlands, and a Class A substance in the United Kingdom.



</doc>
<doc id="24734" url="https://en.wikipedia.org/wiki?curid=24734" title="Product of group subsets">
Product of group subsets

In mathematics, one can define a product of group subsets in a natural way. If "S" and "T" are subsets of a group "G", then their product is the subset of "G" defined by
The subsets "S" and "T" need not be subgroups for this product to be well defined. The associativity of this product follows from that of the group product. The product of group subsets therefore defines a natural monoid structure on the power set of "G".

A lot more can be said in the case where "S" and "T" are subgroups. The product of two subgroups "S" and "T" of a group "G" is itself a subgroup of "G" if and only if "ST" = "TS".

If "S" and "T" are subgroups of "G" their product need not be a subgroup (consider, for example, two distinct subgroups of order two in the symmetric group on 3 symbols). This product is sometimes called the "Frobenius product". In general, the product of two subgroups "S" and "T" is a subgroup if and only if "ST" = "TS", and the two subgroups are said to permute. (Walter Ledermann has called this fact the "Product Theorem", but this name, just like "Frobenius product" is by no means standard.) In this case, "ST" is the group generated by "S" and "T"; i.e., "ST" = "TS" = ⟨"S" ∪ "T"⟩.

If either "S" or "T" is normal then the condition "ST" = "TS" is satisfied and the product is a subgroup. If both "S" and "T" are normal, then the product is normal as well.

If "G" is a finite group and "S" and "T" are subgroups of "G", then "ST" is a subset of "G" of size "|ST|" given by the "product formula":
Note that this applies even if neither "S" nor "T" is normal.

The following modular law (for groups) holds for any "Q" a subgroup of "S", where "T" is any other arbitrary subgroup (and both "S" and "T" are subgroups of some group "G"):
The two products that appear in this equality are not necessarily subgroups.

If "QT" is a subgroup (equivalently, as noted above, if "Q" and "T" permute) then "QT" = ⟨"Q" ∪ "T"⟩ = "Q" ∨ "T"; i.e., "QT" is the join of "Q" and "T" in the lattice of subgroups of "G", and the modular law for such a pair may also be written as "Q" ∨ ("S" ∩ "T") = "S" ∩ ("Q ∨ T"), which is the equation that defines a modular lattice if it holds for any three elements of the lattice with "Q" ≤ "S". In particular, since normal subgroups permute with each other, they form a modular sublattice.

A group in which every subgroup permutes is called an Iwasawa group. The subgroup lattice of an Iwasawa group is thus a modular lattice, so these groups are sometimes called "modular groups" (although this latter term may have other meanings.)

The assumption in the modular law for groups (as formulated above) that "Q" is a subgroup of "S" is essential. If "Q" is "not" a subgroup of "S", then the tentative, more general distributive property that one may consider "S" ∩ ("QT") = ("S" ∩ "Q")("S" ∩ "T") is "false".

In particular, if "S" and "T" intersect only in the identity, then every element of "ST" has a unique expression as a product "st" with "s" in "S" and "t" in "T". If "S" and "T" also commute, then "ST" is a group, and is called a Zappa–Szép product. Even further, if "S" or "T" is normal in "ST", then "ST" coincides with the semidirect product of "S" and "T". Finally, if both "S" and "T" are normal in "ST", then "ST" coincides with the direct product of "S" and "T".

If "S" and "T" are subgroups whose intersection is the trivial subgroup (identity element) and additionally "ST" = "G", then "S" is called a complement of "T" and vice versa.

By a (locally unambiguous) abuse of terminology, two subgroups that intersect only on the (otherwise obligatory) identity are sometimes called disjoint.

A question that arises in the case of a non-trivial intersection between a normal subgroup "N" and a subgroup "K" is what is the structure of the quotient "NK"/"N". Although one might be tempted to just "cancel out" "N" and say the answer is "K", that is not correct because a homomorphism with kernel "N" will also "collapse" (map to 1) all elements of "K" that happen to be in "N". Thus the correct answer is that "NK"/"N" is isomorphic with "K"/("N"∩"K"). This fact is sometimes called the second isomorphism theorem, (although the numbering of these theorems sees some variation between authors); it has also been called the "diamond theorem" by I. Martin Isaacs because of the shape of subgroup lattice involved, and has also been called the "parallelogram rule" by Paul Moritz Cohn, who thus emphasized analogy with the parallelogram rule for vectors because in the resulting subgroup lattice the two sides assumed to represent the quotient groups ("SN") / "N" and "S" / ("S" ∩ "N") are "equal" in the sense of isomorphism.

Frattini's argument guarantees the existence of a product of subgroups (giving rise to the whole group) in a case where the intersection is not necessarily trivial (and for this latter reason the two subgroups are not complements). More specifically, if "G" is a finite group with normal subgroup "N", and if "P" is a Sylow "p"-subgroup of "N", then "G" = "N"("P")"N", where "N"("P") denotes the normalizer of "P" in "G". (Note that the normalizer of "P" includes "P", so the intersection between "N" and "N"("P") is at least "P".)

In a semigroup, the product of two subsets is always a subsemigroup; furthermore the power set of subsemigroups is a semiring with addition as union (of subsets) and multiplication as product of subsets.



</doc>
<doc id="24736" url="https://en.wikipedia.org/wiki?curid=24736" title="PCHP">
PCHP

1-(1-Phenylcyclohexyl)-4-hydroxypiperidine (PCHP) is a metabolite of phencyclidine (PCP). PCHP can be detected in the hair, urine, stool, sweat, and saliva of PCP users.



</doc>
<doc id="24737" url="https://en.wikipedia.org/wiki?curid=24737" title="4-Phenyl-4-(1-piperidinyl)cyclohexanol">
4-Phenyl-4-(1-piperidinyl)cyclohexanol

4-Phenyl-4-(1-piperidinyl)cyclohexanol, also known as PPC, is an organic chemical which is a metabolite of phencyclidine (PCP). It can be detected in the hair of PCP users.

PPC has been shown to cause increases in locomotor activity in lab mice.



</doc>
<doc id="24738" url="https://en.wikipedia.org/wiki?curid=24738" title="PCAA">
PCAA

PCAA, or 5-[N-(1-phenylcyclohexyl)]-aminopentanoic acid, is a metabolite of phencyclidine (PCP). It can be detected in the urine of PCP users by mass spectrometry as means of drug screening.


</doc>
<doc id="24739" url="https://en.wikipedia.org/wiki?curid=24739" title="Piperidine">
Piperidine

Piperidine is an organic compound with the molecular formula (CH)NH. This heterocyclic amine consists of a six-membered ring containing five methylene bridges (–CH–) and one amine bridge (–NH–). It is a colorless liquid with an odor described as objectionable, and typical of amines. The name comes from the genus name "Piper", which is the Latin word for pepper. Although piperidine is a common organic compound, it is best known as a representative structure element within many pharmaceuticals and alkaloids.

Piperidine was first reported in 1850 by the Scottish chemist Thomas Anderson and again, independently, in 1852 by the French chemist Auguste Cahours, who named it. Both men obtained piperidine by reacting piperine with nitric acid.

Industrially, piperidine is produced by the hydrogenation of pyridine, usually over a molybdenum disulfide catalyst:

Pyridine can also be reduced to piperidine via a modified Birch reduction using sodium in ethanol.

Piperidine itself has been obtained from black pepper, from "Psilocaulon absimile" (Aizoaceae), and in "Petrosimonia monandra".

The piperidine structural motif is present in numerous natural alkaloids. These include piperine, which gives black pepper its spicy taste. This gave the compound its name. Other examples are the fire ant toxin solenopsin, the nicotine analog anabasine of tree tobacco ("Nicotiana glauca"), lobeline of Indian tobacco, and the toxic alkaloid coniine from poison hemlock, which was used to put Socrates to death.

Piperidine prefers a chair conformation, similar to cyclohexane. Unlike cyclohexane, piperidine has two distinguishable chair conformations: one with the N–H bond in an axial position, and the other in an equatorial position. After much controversy during the 1950s–1970s, the equatorial conformation was found to be more stable by 0.72 kcal/mol in the gas phase. In nonpolar solvents, a range between 0.2 and 0.6 kcal/mol has been estimated, but in polar solvents the axial conformer may be more stable. The two conformers interconvert rapidly through nitrogen inversion; the free energy activation barrier for this process, estimated at 6.1 kcal/mol, is substantially lower than the 10.4 kcal/mol for ring inversion. In the case of "N"-methylpiperidine, the equatorial conformation is preferred by 3.16 kcal/mol, which is much larger than the preference in methylcyclohexane, 1.74 kcal/mol.

Piperidine is a widely used secondary amine. It is widely used to convert ketones to enamines. Enamines derived from piperidine can be used in the Stork enamine alkylation reaction.

Piperidine can be converted to the chloramine CHNCl with calcium hypochlorite. The resulting chloramine undergoes dehydrohalogenation to afford the cyclic imine.


Piperidine is used as a solvent and as a base. The same is true for certain derivatives: "N"-formylpiperidine is a polar aprotic solvent with better hydrocarbon solubility than other amide solvents, and 2,2,6,6-tetramethylpiperidine is a highly sterically hindered base, useful because of its low nucleophilicity and high solubility in organic solvents.

A significant industrial application of piperidine is for the production of dipiperidinyl dithiuram tetrasulfide, which is used as an accelerator of the sulfur vulcanization of rubber.

Piperidine and its derivatives are ubiquitous building blocks in the synthesis of pharmaceuticals and fine chemicals. The piperidine structure is found in, for example:
Piperidine is also commonly used in chemical degradation reactions, such as the sequencing of DNA in the cleavage of particular modified nucleotides. Piperidine is also commonly used as a base for the deprotection of Fmoc-amino acids used in solid-phase peptide synthesis.

Piperidine is listed as a Table II precursor under the United Nations Convention Against Illicit Traffic in Narcotic Drugs and Psychotropic Substances due to its use (peaking in the 1970s) in the clandestine manufacture of PCP (1-(1-phenylcyclohexyl)piperidine, also known as angel dust, sherms, wet, etc.).


</doc>
<doc id="24740" url="https://en.wikipedia.org/wiki?curid=24740" title="Political question">
Political question

In American Constitutional law, the political question doctrine is closely linked to the concept of justiciability, as it comes down to a question of whether or not the court system is an appropriate forum in which to hear the case. This is because the court system only has authority to hear and decide a legal question, not a political question. Legal questions are deemed to be justiciable, while political questions are nonjusticiable. One scholar explained:

A ruling of nonjusticiability will ultimately prohibit the issue that is bringing the case before the court from being able to be heard in a court of law. In the typical case where there is a finding of nonjusticiability due to the political question doctrine, the issue presented before the court is usually so specific that the Constitution gives all power to one of the coordinate political branches, or at the opposite end of the spectrum, the issue presented is so vague that the United States Constitution does not even consider it. A court can only decide issues based on law. The Constitution dictates the different legal responsibilities of each respective branch of government. If there is an issue where the court does not have the Constitution as a guide, there are no legal criteria to use. When there are no specific constitutional duties involved, the issue is to be decided through the democratic process. The court will not engage in political disputes.

A constitutional dispute that requires knowledge of a non-legal character or the use of techniques not suitable for a court or explicitly assigned by the Constitution to the U.S. Congress, or the President of the United States, is a political question, which judges customarily refuse to address.

The doctrine has its roots in the historic Supreme Court case of "Marbury v. Madison" (1803). In that case, Chief Justice John Marshall drew a distinction between two different functions of the U.S. Secretary of State. Marshall stated that when the Secretary of State was performing a purely discretionary matter, such as advising the President on matters of policy, he was not held to any legally identifiable standards. Therefore, some of the Secretary's actions are unable to be reviewed by a court of law.

The doctrine is grounded in the federal judiciary's desire to avoid inserting itself into conflicts between branches of the federal government. It is justified by the notion that there exist some questions best resolved through the political process, voters approving or correcting the challenged action by voting for or against those involved in the decision.

The leading Supreme Court case in the area of political question doctrine is "Baker v. Carr" (1962). In the opinion written for Baker, the Court outlined six characteristics of a political question. These include:

While this is a still rather unsettled doctrine, its application has been settled in a few decided areas. These areas are:

The Guarantee Clause, Article IV, section 4, requires the federal government to "guarantee to every State in this Union a Republican Form of Government". The Supreme Court has declared that this Clause does not imply any set of "judicially manageable standards which a court could utilize independently in order to identify a State's lawful government".

Article I, section 2 of the Constitution states that the House "shall have the sole power of Impeachment", and Article I, section 3 provides that the "Senate shall have the sole Power to try all Impeachments". Since the Constitution placed the sole power of impeachment in two political bodies, it is qualified as a political question. As a result, neither the decision of the House to impeach nor a vote of the Senate to remove a President or any other official can be appealed to any court. 




Important cases discussing the political question doctrine:



</doc>
<doc id="24742" url="https://en.wikipedia.org/wiki?curid=24742" title="Paul Dirac">
Paul Dirac

Paul Adrien Maurice Dirac (; 8 August 1902 – 20 October 1984) was an English theoretical physicist who is regarded as one of the most significant physicists of the 20th century.

Dirac made fundamental contributions to the early development of both quantum mechanics and quantum electrodynamics. Among other discoveries, he formulated the Dirac equation which describes the behaviour of fermions and predicted the existence of antimatter. Dirac shared the 1933 Nobel Prize in Physics with Erwin Schrödinger "for the discovery of new productive forms of atomic theory". He also made significant contributions to the reconciliation of general relativity with quantum mechanics.

Dirac was regarded by his friends and colleagues as unusual in character. In a 1926 letter to Paul Ehrenfest, Albert Einstein wrote of Dirac, "This balancing on the dizzying path between genius and madness is awful".

He was the Lucasian Professor of Mathematics at the University of Cambridge, a member of the Center for Theoretical Studies, University of Miami, and spent the last decade of his life at Florida State University.

Paul Adrien Maurice Dirac was born at his parents' home in Bristol, England, on 8 August 1902, and grew up in the Bishopston area of the city. His father, Charles Adrien Ladislas Dirac, was an immigrant from Saint-Maurice, Switzerland, who worked in Bristol as a French teacher. His mother, Florence Hannah Dirac, Holten, the daughter of a ship's captain, was born in Cornwall, England, and worked as a librarian at the Bristol Central Library. Paul had a younger sister, Béatrice Isabelle Marguerite, known as Betty, and an older brother, Reginald Charles Félix, known as Felix, who committed suicide in March 1925. Dirac later recalled: "My parents were terribly distressed. I didn't know they cared so much [...] I never knew that parents were supposed to care for their children, but from then on I knew."

Charles and the children were officially Swiss nationals until they became naturalised on 22 October 1919. Dirac's father was strict and authoritarian, although he disapproved of corporal punishment. Dirac had a strained relationship with his father, so much so that after his father's death, Dirac wrote, "I feel much freer now, and I am my own man." Charles forced his children to speak to him only in French, in order that they learn the language. When Dirac found that he could not express what he wanted to say in French, he chose to remain silent.

Dirac was educated first at Bishop Road Primary School and then at the all-boys Merchant Venturers' Technical College (later Cotham School), where his father was a French teacher. The school was an institution attached to the University of Bristol, which shared grounds and staff. It emphasised technical subjects like bricklaying, shoemaking and metal work, and modern languages. This was unusual at a time when secondary education in Britain was still dedicated largely to the classics, and something for which Dirac would later express his gratitude.

Dirac studied electrical engineering on a City of Bristol University Scholarship at the University of Bristol's engineering faculty, which was co-located with the Merchant Venturers' Technical College. Shortly before he completed his degree in 1921, he sat the entrance examination for St John's College, Cambridge. He passed, and was awarded a £70 scholarship, but this fell short of the amount of money required to live and study at Cambridge. Despite his having graduated with a first class honours Bachelor of Science degree in engineering, the economic climate of the post-war depression was such that he was unable to find work as an engineer. Instead he took up an offer to study for a Bachelor of Arts degree in mathematics at the University of Bristol free of charge. He was permitted to skip the first year of the course owing to his engineering degree.

In 1923, Dirac graduated, once again with first class honours, and received a £140 scholarship from the Department of Scientific and Industrial Research. Along with his £70 scholarship from St John's College, this was enough to live at Cambridge. There, Dirac pursued his interests in the theory of general relativity, an interest he had gained earlier as a student in Bristol, and in the nascent field of quantum physics, under the supervision of Ralph Fowler. From 1925 to 1928 he held an 1851 Research Fellowship from the Royal Commission for the Exhibition of 1851. He completed his PhD in June 1926 with the first thesis on quantum mechanics to be submitted anywhere. He then continued his research in Copenhagen and Göttingen.

Dirac married Margit Wigner (Eugene Wigner's sister), in 1937. He adopted Margit's two children, Judith and Gabriel. Paul and Margit Dirac had two children together, both daughters, Mary Elizabeth and Florence Monica.

Margit, known as Manci, visited her brother in 1934 in Princeton, New Jersey, from her native Hungary and, while at dinner at the Annex Restaurant met the "lonely-looking man at the next table." This account from a Korean physicist, Y. S. Kim, who met and was influenced by Dirac, also says: "It is quite fortunate for the physics community that Manci took good care of our respected Paul A. M. Dirac. Dirac published eleven papers during the period 1939–46... Dirac was able to maintain his normal research productivity only because Manci was in charge of everything else."

Dirac was known among his colleagues for his precise and taciturn nature. His colleagues in Cambridge jokingly defined a unit called a "dirac", which was one word per hour. When Niels Bohr complained that he did not know how to finish a sentence in a scientific article he was writing, Dirac replied, "I was taught at school never to start a sentence without knowing the end of it." He criticised the physicist J. Robert Oppenheimer's interest in poetry: "The aim of science is to make difficult things understandable in a simpler way; the aim of poetry is to state simple things in an incomprehensible way. The two are incompatible."

Dirac himself wrote in his diary during his postgraduate years that he concentrated solely on his research, and stopped only on Sunday, when he took long strolls alone.

An anecdote recounted in a review of the 2009 biography tells of Werner Heisenberg and Dirac sailing on an ocean liner to a conference in Japan in August 1929. "Both still in their twenties, and unmarried, they made an odd couple. Heisenberg was a ladies' man who constantly flirted and danced, while Dirac—'an Edwardian geek', as biographer Graham Farmelo puts it—suffered agonies if forced into any kind of socialising or small talk. 'Why do you dance?' Dirac asked his companion. 'When there are nice girls, it is a pleasure,' Heisenberg replied. Dirac pondered this notion, then blurted out: 'But, Heisenberg, how do you know beforehand that the girls are nice?

According to a story told in different versions, a friend or student visited Dirac, not knowing of his marriage. Noticing the visitor's surprise at seeing an attractive woman in the house, Dirac said, "This is... this is Wigner's sister". Margit Dirac told both George Gamow and Anton Capri in the 1960s that her husband had actually said, "Allow me to present Wigner's sister, who is now my wife."

Another story told of Dirac is that when he first met the young Richard Feynman at a conference, he said after a long silence, "I have an equation. Do you have one too?"

After he presented a lecture at a conference, one colleague raised his hand and said "I don't understand the equation on the top-right-hand corner of the blackboard". After a long silence, the moderator asked Dirac if he wanted to answer the question, to which Dirac replied "That was not a question, it was a comment."

Dirac was also noted for his personal modesty. He called the equation for the time evolution of a quantum-mechanical operator, which he was the first to write down, the "Heisenberg equation of motion". Most physicists speak of Fermi–Dirac statistics for half-integer-spin particles and Bose–Einstein statistics for integer-spin particles. While lecturing later in life, Dirac always insisted on calling the former "Fermi statistics". He referred to the latter as "Einstein statistics" for reasons, he explained, of "symmetry".

Heisenberg recollected a conversation among young participants at the 1927 Solvay Conference about Einstein and Planck's views on religion between Wolfgang Pauli, Heisenberg and Dirac. Dirac's contribution was a criticism of the political purpose of religion, which was much appreciated for its lucidity by Bohr when Heisenberg reported it to him later. Among other things, Dirac said:
I cannot understand why we idle discussing religion. If we are honest—and scientists have to be—we must admit that religion is a jumble of false assertions, with no basis in reality. The very idea of God is a product of the human imagination. It is quite understandable why primitive people, who were so much more exposed to the overpowering forces of nature than we are today, should have personified these forces in fear and trembling. But nowadays, when we understand so many natural processes, we have no need for such solutions. I can't for the life of me see how the postulate of an Almighty God helps us in any way. What I do see is that this assumption leads to such unproductive questions as why God allows so much misery and injustice, the exploitation of the poor by the rich and all the other horrors He might have prevented. If religion is still being taught, it is by no means because its ideas still convince us, but simply because some of us want to keep the lower classes quiet. Quiet people are much easier to govern than clamorous and dissatisfied ones. They are also much easier to exploit. Religion is a kind of opium that allows a nation to lull itself into wishful dreams and so forget the injustices that are being perpetrated against the people. Hence the close alliance between those two great political forces, the State and the Church. Both need the illusion that a kindly God rewards—in heaven if not on earth—all those who have not risen up against injustice, who have done their duty quietly and uncomplainingly. That is precisely why the honest assertion that God is a mere product of the human imagination is branded as the worst of all mortal sins.

Heisenberg's view was tolerant. Pauli, raised as a Catholic, had kept silent after some initial remarks, but when finally he was asked for his opinion, said: "Well, our friend Dirac has got a religion and its guiding principle is 'There is no God and Paul Dirac is His prophet. Everybody, including Dirac, burst into laughter.

Later in life, Dirac's views towards the idea of God were less acerbic. As an author of an article appearing in the May 1963 edition of "Scientific American", Dirac wrote:
It seems to be one of the fundamental features of nature that fundamental physical laws are described in terms of a mathematical theory of great beauty and power, needing quite a high standard of mathematics for one to understand it. You may wonder: Why is nature constructed along these lines? One can only answer that our present knowledge seems to show that nature is so constructed. We simply have to accept it. One could perhaps describe the situation by saying that God is a mathematician of a very high order, and He used very advanced mathematics in constructing the universe. Our feeble attempts at mathematics enable us to understand a bit of the universe, and as we proceed to develop higher and higher mathematics we can hope to understand the universe better.

In 1971, at a conference meeting, Dirac expressed his views on the existence of God. Dirac explained that the existence of God could only be justified if an improbable event were to have taken place in the past:

It could be that it is extremely difficult to start life. It might be that it is so difficult to start life that it has happened only once among all the planets... Let us consider, just as a conjecture, that the chance life starting when we have got suitable physical conditions is 10. I don't have any logical reason for proposing this figure, I just want you to consider it as a possibility. Under those conditions ... it is almost certain that life would not have started. And I feel that under those conditions it will be necessary to assume the existence of a god to start off life. I would like, therefore, to set up this connexion between the existence of a god and the physical laws: if physical laws are such that to start off life involves an excessively small chance, so that it will not be reasonable to suppose that life would have started just by blind chance, then there must be a god, and such a god would probably be showing his influence in the quantum jumps which are taking place later on. On the other hand, if life can start very easily and does not need any divine influence, then I will say that there is no god.

Dirac did not commit himself to any definite view, but he described the possibilities for answering the question of God in a scientific manner.

Dirac shared the 1933 Nobel Prize for physics with Erwin Schrödinger "for the discovery of new productive forms of atomic theory". Dirac was also awarded the Royal Medal in 1939 and both the Copley Medal and the Max Planck Medal in 1952. He was elected a Fellow of the Royal Society in 1930, an Honorary Fellow of the American Physical Society in 1948, and an Honorary Fellow of the Institute of Physics, London in 1971. He received the inaugural J. Robert Oppenheimer Memorial Prize in 1969. Dirac became a member of the Order of Merit in 1973, having previously turned down a knighthood as he did not want to be addressed by his first name.

In 1984, Dirac died in Tallahassee, Florida, and was buried at Tallahassee's Roselawn Cemetery. Dirac's childhood home in Bristol is commemorated with a blue plaque and the nearby Dirac Road is named in recognition of his links with the city. A commemorative stone was erected in a garden in Saint-Maurice, Switzerland, the town of origin of his father's family, on 1 August 1991. On 13 November 1995 a commemorative marker, made from Burlington green slate and inscribed with the Dirac equation, was unveiled in Westminster Abbey. The Dean of Westminster, Edward Carpenter, had initially refused permission for the memorial, thinking Dirac to be anti-Christian, but was eventually (over a five-year period) persuaded to relent.

Dirac established the most general theory of quantum mechanics and discovered the relativistic equation for the electron, which now bears his name. The remarkable notion of an antiparticle to each fermion particle – e.g. the positron as antiparticle to the electron – stems from his equation. He was the first to develop quantum field theory, which underlies all theoretical work on sub-atomic or "elementary" particles today, work that is fundamental to our understanding of the forces of nature. He proposed and investigated the concept of a magnetic monopole, an object not yet known empirically, as a means of bringing even greater symmetry to James Clerk Maxwell's equations of electromagnetism.

He quantised the gravitational field, and developed a general theory of quantum field theories with dynamical constraints, which forms the basis of the gauge theories and superstring theories of today. The influence and importance of his work has increased with the decades, and physicists use the concepts and equations that he developed daily.

Dirac's first step into a new quantum theory was taken late in September 1925. Ralph Fowler, his research supervisor, had received a proof copy of an exploratory paper by Werner Heisenberg in the framework of the old quantum theory of Bohr and Sommerfeld. Heisenberg leaned heavily on Bohr's correspondence principle but changed the equations so that they involved directly observable quantities, leading to the matrix formulation of quantum mechanics. Fowler sent Heisenberg's paper on to Dirac, who was on vacation in Bristol, asking him to look into this paper carefully.

Dirac's attention was drawn to a mysterious mathematical relationship, at first sight unintelligible, that Heisenberg had reached. Several weeks later, back in Cambridge, Dirac suddenly recognised that this mathematical form had the same structure as the Poisson brackets that occur in the classical dynamics of particle motion. From this thought he quickly developed a quantum theory that was based on non-commuting dynamical variables. This led him to a more profound and significant general formulation of quantum mechanics than was achieved by any other worker in this field. Dirac's formulation allowed him to obtain the quantisation rules in a novel and more illuminating manner. For this work, published in 1926, Dirac received a PhD from Cambridge. This formed the basis for Fermi-Dirac statistics that applies to systems consisting of many identical spin 1/2 particles (i.e. that obey the Pauli exclusion principle), e.g. electrons in solids and liquids, and importantly to the field of conduction in semi-conductors.

Dirac was famously not bothered by issues of interpretation in quantum theory. In fact, in a paper published in a book in his honour, he wrote: "The interpretation of quantum mechanics has been dealt with by many authors, and I do not want to discuss it here. I want to deal with more fundamental things."

In 1928, building on 2×2 spin matrices which he purported to have discovered independently of Wolfgang Pauli's work on non-relativistic spin systems (Dirac told Abraham Pais, "I believe I got these [matrices] independently of Pauli and possibly Pauli got these independently of me."), he proposed the Dirac equation as a relativistic equation of motion for the wave function of the electron. This work led Dirac to predict the existence of the positron, the electron's antiparticle, which he interpreted in terms of what came to be called the "Dirac sea". The positron was observed by Carl Anderson in 1932. Dirac's equation also contributed to explaining the origin of quantum spin as a relativistic phenomenon.

The necessity of fermions (matter) being created and destroyed in Enrico Fermi's 1934 theory of beta decay led to a reinterpretation of Dirac's equation as a "classical" field equation for any point particle of spin "ħ"/2, itself subject to quantisation conditions involving anti-commutators. Thus reinterpreted, in 1934 by Werner Heisenberg, as a (quantum) field equation accurately describing all elementary matter particles – today quarks and leptons – this Dirac field equation is as central to theoretical physics as the Maxwell, Yang–Mills and Einstein field equations. Dirac is regarded as the founder of quantum electrodynamics, being the first to use that term. He also introduced the idea of vacuum polarisation in the early 1930s. This work was key to the development of quantum mechanics by the next generation of theorists, in particular Schwinger, Feynman, Sin-Itiro Tomonaga and Dyson in their formulation of quantum electrodynamics.

Dirac's "The" "Principles of Quantum Mechanics", published in 1930, is a landmark in the history of science. It quickly became one of the standard textbooks on the subject and is still used today. In that book, Dirac incorporated the previous work of Werner Heisenberg on matrix mechanics and of Erwin Schrödinger on wave mechanics into a single mathematical formalism that associates measurable quantities to operators acting on the Hilbert space of vectors that describe the state of a physical system. The book also introduced the delta function. Following his 1939 article, he also included the bra–ket notation in the third edition of his book, thereby contributing to its universal use nowadays.

In 1931, Dirac proposed that the existence of a single magnetic monopole in the universe would suffice to explain the quantisation of electrical charge. In 1975, 1982, and 2009 intriguing results suggested the possible detection of magnetic monopoles, but there is, to date, no direct evidence for their existence (see also Magnetic monopole#Searches for magnetic monopoles).

Dirac was the Lucasian Professor of Mathematics at Cambridge from 1932 to 1969. In 1937, he proposed a speculative cosmological model based on the so-called large numbers hypothesis. During World War II, he conducted important theoretical and experimental research on uranium enrichment by gas centrifuge.

Dirac's quantum electrodynamics (QED) made predictions that were – more often than not – infinite and therefore unacceptable. A workaround known as renormalisation was developed, but Dirac never accepted this. "I must say that I am very dissatisfied with the situation", he said in 1975, "because this so-called 'good theory' does involve neglecting infinities which appear in its equations, neglecting them in an arbitrary way. This is just not sensible mathematics. Sensible mathematics involves neglecting a quantity when it is small – not neglecting it just because it is infinitely great and you do not want it!" His refusal to accept renormalisation resulted in his work on the subject moving increasingly out of the mainstream.

However, from his once rejected notes he managed to work on putting quantum electrodynamics on "logical foundations" based on Hamiltonian formalism that he formulated. He found a rather novel way of deriving the anomalous magnetic moment "Schwinger term" and also the Lamb shift, afresh in 1963, using the Heisenberg picture and without using the joining method used by Weisskopf and French, and by the two pioneers of modern QED, Schwinger and Feynman. That was two years before the Tomonaga–Schwinger–Feynman QED was given formal recognition by an award of the Nobel Prize for physics.

Weisskopf and French (FW) were the first to obtain the correct result for the Lamb shift and the anomalous magnetic moment of the electron. At first FW results did not agree with the incorrect but independent results of Feynman and Schwinger. The 1963–1964 lectures Dirac gave on quantum field theory at Yeshiva University were published in 1966 as the Belfer Graduate School of Science, Monograph Series Number, 3. After having relocated to Florida to be near his elder daughter, Mary, Dirac spent his last fourteen years (of both life and physics research) at the University of Miami in Coral Gables, Florida, and Florida State University in Tallahassee, Florida.

In the 1950s in his search for a better QED, Paul Dirac developed the Hamiltonian theory of constraints based on lectures that he delivered at the 1949 International Mathematical Congress in Canada. Dirac had also solved the problem of putting the Tomonaga–Schwinger equation into the Schrödinger representation and given explicit expressions for the scalar meson field (spin zero pion or pseudoscalar meson), the vector meson field (spin one rho meson), and the electromagnetic field (spin one massless boson, photon).

The Hamiltonian of constrained systems is one of Dirac's many masterpieces. It is a powerful generalisation of Hamiltonian theory that remains valid for curved spacetime. The equations for the Hamiltonian involve only six degrees of freedom described by formula_1,formula_2 for each point of the surface on which the state is considered. The formula_3 ("m" = 0, 1, 2, 3) appear in the theory only through the variables formula_4, formula_5 which occur as arbitrary coefficients in the equations of motion.
There are four constraints or weak equations for each point of the surface formula_6 = constant. Three of them formula_7 form the four vector density in the surface. The fourth formula_8 is a 3-dimensional scalar density in the surface "H" ≈ 0; "H" ≈ 0 ("r" = 1, 2, 3)

In the late 1950s, he applied the Hamiltonian methods he had developed to cast Einstein's general relativity in Hamiltonian form and to bring to a technical completion the quantisation problem of gravitation and bring it also closer to the rest of physics according to Salam and DeWitt. In 1959 he also gave an invited talk on "Energy of the Gravitational Field" at the New York Meeting of the American Physical Society later published in 1959 Phys Rev Lett 2, 368. In 1964 he published his "Lectures on Quantum Mechanics" (London:Academic) which deals with constrained dynamics of nonlinear dynamical systems including quantisation of curved spacetime. He also published a paper entitled "Quantization of the Gravitational Field" in the 1967 ICTP/IAEA Trieste Symposium on Contemporary Physics.

From September 1970 to January 1971, Dirac was Visiting Professor at Florida State University in Tallahassee. During that time he was offered a permanent position there, which he accepted, becoming a full professor in 1972. Contemporary accounts of his time there describe it as happy except that he apparently found the summer heat oppressive and liked to escape from it to Cambridge.

He would walk about a mile to work each day and was fond of swimming in one of the two nearby lakes (Silver Lake and Lost Lake), and was also more sociable than he had been at Cambridge, where he mostly worked at home apart from giving classes and seminars; at FSU he would usually eat lunch with his colleagues before taking a nap.

Dirac published over 60 papers in those last twelve years of his life, including a short book on general relativity. His last paper (1984), entitled "The inadequacies of quantum field theory," contains his final judgment on quantum field theory;

"These rules of renormalisation give surprisingly, excessively good agreement with experiments. Most physicists say that these working rules are, therefore, correct. I feel that is not an adequate reason. Just because the results happen to be in agreement with observation does not prove that one's theory is correct."

The paper ends with these words;

"I have spent many years searching for a Hamiltonian to bring into the theory and have not yet found it. I shall continue to work on it as long as I can and other people, I hope, will follow along such lines."

Amongst his many students were Homi J. Bhabha, Fred Hoyle and John Polkinghorne. Polkinghorne recalls that Dirac "was once asked what was his fundamental belief. He strode to a blackboard and wrote that the laws of nature should be expressed in beautiful equations."

In 1975, Dirac gave a series of five lectures at the University of New South Wales which were subsequently published as a book, "Directions in Physics" (1978). He donated the royalties from this book to the university for the establishment of the Dirac Lecture Series. The Silver Dirac Medal for the Advancement of Theoretical Physics is awarded by the University of New South Wales to commemorate the lecture.

Immediately after his death, two organisations of professional physicists established annual awards in Dirac's memory. The Institute of Physics, the United Kingdom's professional body for physicists, awards the Paul Dirac Medal for "outstanding contributions to theoretical (including mathematical and computational) physics". The first three recipients were Stephen Hawking (1987), John Stewart Bell (1988), and Roger Penrose (1989). The International Centre for Theoretical Physics awards the Dirac Medal of the ICTP each year on Dirac's birthday (8 August).

The Dirac-Hellman Award at Florida State University was endowed by Dr Bruce P. Hellman in 1997 to reward outstanding work in theoretical physics by FSU researchers. The Paul A.M. Dirac Science Library at Florida State University, which Manci opened in December 1989, is named in his honour, and his papers are held there. Outside is a statue of him by Gabriella Bollobás. The street on which the National High Magnetic Field Laboratory in Innovation Park of Tallahassee, Florida, is located is named Paul Dirac Drive. As well as in his home town of Bristol, there is also a road named after him in Didcot Oxfordshire, Dirac Place. The BBC named a video codec, Dirac, in his honour.
An asteroid discovered in 1983 was named after Dirac. The Distributed Research utilising Advanced Computing (DiRAC) and Dirac software are named in his honour.





</doc>
<doc id="24743" url="https://en.wikipedia.org/wiki?curid=24743" title="Pessimism">
Pessimism

Pessimism is a mental attitude. Pessimists anticipate undesirable outcomes from a given situation, which is generally referred to as situational pessimism, or believe that undesirable outcomes are going to happen to them in life more frequently than desirable ones. Pessimists also tend to focus on the negatives of life in general or a given situation. The most common example of this phenomenon is the "Is the glass half empty or half full?" situation. In this situation a pessimist is said to see the glass as half empty while an optimist is said to see the glass as half full. Throughout history, the pessimistic disposition has had effects on all major areas of thinking.

Philosophical pessimism is the related idea that views the world in a strictly anti-optimistic fashion. This form of pessimism is not an emotional disposition as the term commonly connotes. Instead, it is a philosophy or worldview that directly challenges the notion of progress and what may be considered the faith-based claims of optimism. Philosophical pessimists are often existential nihilists believing that life has no intrinsic meaning or value. Their responses to this condition, however, are widely varied and often life-affirming.

The term pessimism derives from the Latin word "pessimus" meaning 'the worst'. It was first used by Jesuit critics of Voltaire's 1759 novel 'Candide, ou l'Optimisme'. Voltaire was satirizing the philosophy of Leibniz who maintained that this was the 'best (optimum) of all possible worlds'. In their attacks on Voltaire, the Jesuits of the "Revue de Trévoux" accused him of "pessimisme".

Philosophical pessimism is not a state of mind or a psychological disposition, but rather it is a worldview or ethic that seeks to face up to the distasteful realities of the world and eliminate irrational hopes and expectations (such as the Idea of Progress and religious faith) which may lead to undesirable outcomes. Ideas which prefigure philosophical pessimism can be seen in ancient texts such as the Dialogue of Pessimism and Ecclesiastes (which maintains that everything is "hevel", literally 'vapor' or 'breath', but could also mean 'senseless' and 'absurd'.)

In Western philosophy, philosophical pessimism is not a single coherent movement, but rather a loosely associated group of thinkers with similar ideas and a family resemblance to each other. In "Pessimism: Philosophy, Ethic, Spirit", Joshua Foa Dienstag outlines the main propositions shared by most philosophical pessimists as "that time is a burden; that the course of history is in some sense ironic; that freedom and happiness are incompatible; and that human existence is absurd."

Philosophical pessimists see the self-consciousness of man as bound up with his consciousness of time and that this leads to greater suffering than mere physical pain. While many organisms live in the present, humans and certain species of animals can contemplate the past and future, and this is an important difference. Human beings have foreknowledge of their own eventual fate and this "terror" is present in every moment of our lives as a reminder of the impermanent nature of life and of our inability to control this change.

The philosophical pessimistic view of the effect of historical progress tends to be more negative than positive. The philosophical pessimist does not deny that certain areas like science can "progress" but they deny that this has resulted in an overall improvement of the human condition. In this sense it could be said that the pessimist views history as ironic; while seemingly getting better, it is mostly in fact not improving at all, or getting worse. This is most clearly seen in Rousseau's critique of enlightenment civil society and his preference for man in the primitive and natural state. For Rousseau, "our souls have become corrupted to the extent that our sciences and our arts have advanced towards perfection".

The pessimistic view of the human condition is that it is in a sense "absurd". Absurdity is seen as an ontological mismatch between our desire for meaning and fulfillment and our inability to find or sustain those things in the world, or as Camus puts it: "a divorce between man and his life, the actor and his setting". The idea that rational thought would lead to human flourishing can be traced to Socrates and is at the root of most forms of western optimistic philosophies. Pessimism turns the idea on its head, it faults the human freedom to reason as the feature that misaligned humanity from our world and sees it as the root of human unhappiness.

The responses to this predicament of the human condition by pessimists are varied. Some philosophers, mainly Schopenhauer, recommend a form of resignation and self-denial (which he saw exemplified in Indian religions). Some followers tend to believe that "expecting the worst leads to the best." Rene Descartes even believed that life was better if emotional reactions to "negative" events were removed. Others like Nietzsche, Leopardi and Camus respond with a more life-affirming view, what Nietzsche called a "Dionysian pessimism", an embrace of life as it is in all of its constant change and suffering, without appeal to progress or hedonistic calculus. Albert Camus indicated that the common responses to the absurdity of life are often: Suicide, a leap of faith (as per Kierkegaard's knight of faith), or recognition/rebellion. Camus rejected all but the last option as unacceptable and inauthentic responses.

Philosophical pessimism has often been tied to the arts and literature. Schopenhauer's philosophy was very popular with composers (Wagner, Brahms and Mahler). Several philosophical pessimists also wrote novels or poetry (Camus and Leopardi respectively). A distinctive literary form which has been associated with pessimism is aphoristic writing, and this can be seen in Leopardi, Nietzsche and Cioran. Writers which could be said to express pessimistic views in their works or to be influenced by pessimistic philosophers include Miguel de Cervantes, Lord Byron, Charles Baudelaire, Gottfried Benn, Sadegh Hedayat, Fyodor Dostoyevsky, Joseph Conrad, Charles Bukowski, Thomas Mann, Louis-Ferdinand Céline, Mihai Eminescu, Friedrich Dürrenmatt, Cormac McCarthy, Samuel Beckett, Dino Buzzati, Jorge Luis Borges, H. P. Lovecraft, Michel Houellebecq, Thomas Ligotti, Thomas Bernhard and Camilo Pessanha.

In "Philosophy in the Tragic Age of the Greeks", Friedrich Nietzsche argued that the pre-Socratic philosophers such as Anaximander, Heraclitus (called "the Weeping Philosopher") and Parmenides represented a classical form of pessimism. Nietzsche saw Anaximander's philosophy as the "enigmatic proclamation of a true pessimist". Similarly, of Heraclitus' philosophy of flux and strife he wrote:
Heraclitus denied the duality of totally diverse worlds—a position which Anaximander had been compelled to assume. He no longer distinguished a physical world from a metaphysical one, a realm of definite qualities from an undefinable "indefinite." And after this first step, nothing could hold him back from a second, far bolder negation: he altogether denied being. For this one world which he retained [...] nowhere shows a tarrying, an indestructibility, a bulwark in the stream. Louder than Anaximander, Heraclitus proclaimed: "I see nothing other than becoming. Be not deceived. It is the fault of your short-sightedness, not of the essence of things, if you believe you see land somewhere in the ocean of becoming and passing-away. You use names for things as though they rigidly, persistently endured; yet even the stream into which you step a second time is not the one you stepped into before." "The Birth of Tragedy. 5, pp. 51–52" 
Another Greek expressed a form of pessimism in his philosophy: the ancient Cyrenaic philosopher Hegesias (290 BCE). Like later pessimists, Hegesias argued that lasting happiness is impossible to achieve and that all we can do is to try to avoid pain as much as possible.
Complete happiness cannot possibly exist; for that the body is full of many sensations, and that the mind sympathizes with the body, and is troubled when that is troubled, and also that fortune prevents many things which we cherished in anticipation; so that for all these reasons, perfect happiness eludes our grasp.
Hegesias held that all external objects, events and actions are indifferent to the wise man, even death: "for the foolish person it is expedient to live, but to the wise person it is a matter of indifference". According to Cicero, Hegesias wrote a book called "Death by Starvation", which supposedly persuaded many people that death was more desirable than life. Because of this, Ptolemy II Philadelphus banned Hegesias from teaching in Alexandria.

From the 3rd century BCE, Stoicism propounded as an exercise "the premeditation of evils"—concentration on worst possible outcomes.

Baltasar Gracián (1601–1658) was Schopenhauer's favorite author and Gracián's novel "El Criticón" was his favorite book. Schopenhauer's pessimistic outlook was influenced by Gracián, and he translated Gracián's "The Pocket Oracle and Art of Prudence" into German. He praised Gracián for his aphoristic writing style (conceptismo) and often quoted him in his works. Gracian's novel "El Criticón" (The Critic) is an extended allegory of the human search for happiness which turns out to be fruitless on this Earth. "The Critic" paints a bleak and desolate picture of the human condition. His "Pocket Oracle" was a book of aphorisms on how to live in what he saw as a world filled with deception, duplicity and disillusionment.

Voltaire was the first European to be labeled as a pessimist due to his critique of Alexander Pope's optimistic "An Essay on Man", and Leibniz' affirmation that "we live in the best of all possible worlds." Voltaire's novel Candide is an extended criticism of theistic optimism and his Poem on the Lisbon Disaster is especially pessimistic about the state of mankind and the nature of God. Though himself a Deist, Voltaire argued against the existence of a compassionate personal God through his interpretation of the problem of evil.

The major themes of philosophical pessimism were first presented by Rousseau and he has been called "the patriarch of pessimism". For Rousseau, humans in their "natural goodness" have no sense of self-consciousness in time and thus are happier than humans corrupted by society. Rousseau saw the movement out of the state of nature as the origin of inequality and mankind's lack of freedom. The wholesome qualities of man in his natural state, a non-destructive love of self and compassion are gradually replaced by "amour propre", a self-love driven by pride and jealousy of his fellow man. Because of this, modern man lives "always outside himself", concerned with other men, the future and external objects. Rousseau also blames the human faculty of "perfectibility" and human language for tearing us away from our natural state by allowing us to imagine a future in which we are different than what we are now and therefore making us appear inadequate to ourselves (and thus 'perfectible').

Rousseau saw the evolution of modern society as the replacement of natural egalitarianism by alienation and class distinction enforced by institutions of power. Thus "The Social Contract" opens with the famous phrase "Man is born free, and everywhere he is in chains." Even the ruling classes are not free, in fact for Rousseau they are "greater slaves" because they require more esteem from others to rule and must therefore constantly live "outside themselves".

Though a lesser known figure outside Italy, Giacomo Leopardi was highly influential in the 19th century, especially for Schopenhauer and Nietzsche. In Leopardi's darkly comic essays, aphorisms, fables and parables, life is often described as a sort of divine joke or mistake. According to Leopardi, because of our conscious sense of time and our endless search for truth, the human desire for happiness can never be truly satiated and joy cannot last. Leopardi claims that "Therefore they greatly deceive themselves, [those] who declare and preach that the perfection of man consists in knowledge of the truth and that all his woes proceed from false opinions and ignorance, and that the human race will at last be happy, when all or most people come to know the truth, and solely on the grounds of that arrange and govern their lives." Furthermore, Leopardi believes that for man it is not possible to forget truth and that "it is easier to rid oneself of any habit before that of philosophizing."

Leopardi's response to this condition is to face up to these realities and try to live a vibrant and great life, to be risky and take up uncertain tasks. This uncertainty makes life valuable and exciting but does not free us from suffering, it is rather an abandonment of the futile pursuit of happiness. He uses the example of Christopher Columbus who went on a dangerous and uncertain voyage and because of this grew to appreciate life more fully. Leopardi also sees the capacity of humans to laugh at their condition as a laudable quality that is able to help us deal with our predicament. For Leopardi: "He who has the courage to laugh is master of the world, much like him who is prepared to die."

Arthur Schopenhauer's pessimism comes from his elevating of Will above reason as the mainspring of human thought and behavior. The Will is the ultimate metaphysical animating noumenon and it is futile, illogical and directionless striving. Schopenhauer sees reason as weak and insignificant compared to Will; in one metaphor, Schopenhauer compares the human intellect to a lame man who can see, but who rides on the shoulder of the blind giant of Will. Schopenhauer saw human desires as impossible to satisfy. 
He pointed to motivators such as hunger, thirst and sexuality as the fundamental features of the Will in action, which are always by nature unsatisfactory.

All satisfaction, or what is commonly called happiness, is really and essentially always negative only, and never positive. It is not a gratification which comes to us originally and of itself, but it must always be the satisfaction of a wish. For desire, that is to say, want [or will], is the precedent condition of every pleasure; but with the satisfaction, the desire and therefore the pleasure cease; and so the satisfaction or gratification can never be more than deliverance from a pain, from a want. — "The world as will and representation, pg 319" 

Schopenhauer notes that once satiated, the feeling of satisfaction rarely lasts and we spend most of our lives in a state of endless striving, in this sense, we are, deep down nothing but Will. Even the moments of satisfaction, when repeated often enough, only lead to boredom and thus human existence is constantly swinging "like a pendulum to and fro between pain and boredom, and these two are in fact its ultimate constituents". This ironic cycle eventually allows us to see the inherent vanity at the truth of existence ("nichtigkeit") and to realize that "the purpose of our existence is not to be happy".

Moreover, the business of biological life is a war of all against all filled with constant physical pain and distress, not merely unsatisfied desires. There is also the constant dread of death on the horizon to consider, which makes human life worse than animals. Reason only compounds our suffering by allowing us to realize that biology's agenda is not something we would have chosen had we been given a choice, but it is ultimately helpless to prevent us from serving it.

Schopenhauer saw in artistic contemplation a temporary escape from the act of willing. He believed that through "losing yourself" in art one could sublimate the Will. However, he believed that only a resignation from the pointless striving of the will to life through a form of asceticism (as those practiced by eastern monastics and by "saintly persons") could free oneself from the Will altogether.

Friedrich Nietzsche could be said to be a philosophical pessimist even though unlike Schopenhauer (whom he read avidly) his response to the 'tragic' pessimistic view is neither resigned nor self-denying, but a life-affirming form of pessimism. For Nietzsche this was a "pessimism of the future", a "Dionysian pessimism." Nietzsche identified his Dionysian pessimism with what he saw as the pessimism of the Greek pre-socratics and also saw it at the core of ancient Greek tragedy. He saw tragedy as laying bare the terrible nature of human existence, bound by constant flux. In contrast to this Nietzsche saw Socratic philosophy as an optimistic refuge of those who could not bear the tragic any longer. Since Socrates posited that wisdom could lead to happiness, Nietzsche saw this as "morally speaking, a sort of cowardice...amorally, a ruse". Nietzsche was also critical of Schopenhauer's pessimism because in judging the world negatively, it turned to moral judgements about the world and therefore led to weakness and nihilism. Nietzsche's response was a total embracing of the nature of the world, a "great liberation" through a "pessimism of strength" which "does not sit in judgement of this condition". Nietzsche believed that the task of the philosopher was to wield this pessimism like a hammer, to first attack the basis of old moralities and beliefs and then to "make oneself a new pair of wings", i.e. to re-evaluate all values and create new ones. A key feature of this Dionysian pessimism was 'saying yes' to the changing nature of the world, this entailed embracing destruction and suffering joyfully, forever (hence the ideas of amor fati and eternal recurrence). Pessimism for Nietzsche is an art of living that is "good for one's health" as a "remedy and an aid in the service of growing and struggling life".

In a 1945 article, Albert Camus wrote "the idea that a pessimistic philosophy is necessarily one of discouragement is a puerile idea." Camus helped popularize the idea of "the absurd", a key term in his famous essay "The Myth of Sisyphus". Like previous philosophical pessimists, Camus sees human consciousness and reason as that which "sets me in opposition to all creation". For Camus, this clash between a reasoning mind which craves meaning and a 'silent' world is what produces the most important philosophical problem, the 'problem of suicide'. Camus believed that people often escape facing the absurd through "eluding" ("l'esquive"), a 'trickery' for "those who live not for life itself but some great idea that will transcend it, refine it, give it a meaning, and betray it". He considered suicide and religion as inauthentic forms of eluding or escaping the problem of existence. For Camus, the only choice was to rebelliously accept and live with the absurd, for "there is no fate that cannot be surmounted by scorn." Camus' response to the absurd problem is illustrated by using the Greek mythic character of Sisyphus, who was condemned by the gods to push a boulder up a hill for eternity. Camus imagines Sisyphus while pushing the rock, realizing the futility of his task, but doing it anyway out of rebellion: "One must imagine Sisyphus happy."

There are several theories of epistemology which could arguably be said to be pessimistic in the sense that they consider it difficult or even impossible to obtain knowledge about the world. These ideas are generally related to nihilism, philosophical skepticism and relativism.

Friedrich Heinrich Jacobi (1743–1819), analyzed rationalism, and in particular Immanuel Kant's "critical" philosophy in order to carry out a reductio ad absurdum according to which all rationalism reduces to nihilism, and thus it should be avoided and replaced with a return to some type of faith and revelation.

Richard Rorty, Michel Foucault, and Ludwig Wittgenstein questioned whether our particular concepts could relate to the world in any absolute way and whether we can justify our ways of describing the world as compared with other ways. In general, these philosophers argue that truth was not about getting it right or representing reality, but was part of subjective social relations of power, or language-games that served our purposes in a particular time. Therefore, these forms of anti-foundationalism, while not being pessimistic per se, rejects any definitions that claims to have discovered absolute 'truths' or foundational facts about the world as valid.

Philosophical pessimism stands opposed to the optimism or even utopianism of Hegelian philosophies. Emil Cioran claimed "Hegel is chiefly responsible for modern optimism. How could he have failed to see that consciousness changes only its forms and modalities, but never progresses?" Philosophical pessimism is differentiated from other political philosophies by having no ideal governmental structure or political project, rather pessimism generally tends to be an anti-systematic philosophy of individual action. This is because philosophical pessimists tend to be skeptical that any politics of social progress can actually improve the human condition. As Cioran states, "every step forward is followed by a step back: this is the unfruitful oscillation of history". Cioran also attacks political optimism because it creates an "idolatry of tomorrow" which can be used to authorize anything in its name. This does not mean however, that the pessimist cannot be politically involved, as Camus argued in The Rebel.

There is another strain of thought generally associated with a pessimistic worldview, this is the pessimism of cultural criticism and social decline which is seen in Oswald Spengler's 'The Decline of the West'. Spengler promoted a cyclic model of history similar to the theories of Giambattista Vico. Spengler believed modern western civilization was in the 'winter' age of decline ("untergang"). Spenglerian theory was immensely influential in interwar Europe, especially in Weimar Germany. Similarly, traditionalist Julius Evola thought that the world was in the Kali Yuga, a dark age of moral decline.

Intellectuals like Oliver James correlate economic progress with economic inequality, the stimulation of artificial needs, and affluenza. Anti-consumerists identify rising trends of conspicuous consumption and self-interested, image-conscious behavior in culture. Post-modernists like Jean Baudrillard have even argued that culture (and therefore our lives) now has no basis in reality whatsoever.

Conservative thinkers, especially social conservatives, often perceive politics in a generally pessimistic way. William F. Buckley famously remarked that he was "standing athwart history yelling 'stop!'" and Whittaker Chambers was convinced that capitalism was bound to fall to communism, though he was himself violently anti-communist. Social conservatives often see the West as a decadent and nihilistic civilization which has abandoned its roots in Christianity and/or Greek philosophy, leaving it doomed to fall into moral and political decay. Robert Bork's "Slouching Toward Gomorrah" and Allan Bloom's "The Closing of the American Mind" are famous expressions of this point of view.

Many economic conservatives and libertarians believe that the expansion of the state and the role of government in society is inevitable, and they are at best fighting a holding action against it. They hold that the natural tendency of people is to be ruled and that freedom is an exceptional state of affairs which is now being abandoned in favor of social and economic security provided by the welfare state. Political pessimism has sometimes found expression in dystopian novels such as George Orwell's "Nineteen Eighty-Four". Political pessimism about one's country often correlates with a desire to emigrate.

During the financial crisis of 2007–08 in the United States, the neologism "pessimism porn" was coined to describe the alleged eschatological and survivalist thrill some people derive from predicting, reading and fantasizing about the collapse of civil society through the destruction of the world's economic system.

Technological pessimism is the belief that advances in science and technology do not lead to an improvement in the human condition. Technological pessimism can be said to have originated during the industrial revolution with the Luddite movement. Luddites blamed the rise of industrial mills and advanced factory machinery for the loss of their jobs and set out to destroy them. The Romantic movement was also pessimistic towards the rise of technology and longed for simpler and more natural times. Poets like William Wordsworth and William Blake believed that industrialization was polluting the purity of nature.

Some social critics and environmentalists believe that globalization, overpopulation and the economic practices of modern capitalist states over-stress the planet's ecological equilibrium. They warn that unless something is done to slow this, climate change will worsen eventually leading to some form of social and ecological collapse. James Lovelock believes that the ecology of the Earth has already been irretrievably damaged, and even an unrealistic shift in politics would not be enough to save it. According to Lovelock, the Earth’s climate regulation system is being overwhelmed by pollution and the Earth will soon jump from its current state into a dramatically hotter climate. Lovelock blames this state of affairs on what he calls “polyanthroponemia”, which is when: “humans overpopulate until they do more harm than good.” Lovelock states:

The presence of 7 billion people aiming for first-world comforts…is clearly incompatible with the homeostasis of climate but also with chemistry, biological diversity and the economy of the system.

Some radical environmentalists, anti-globalization activists, and Neo-luddites can be said to hold to this type of pessimism about the effects of modern "progress". A more radical form of environmental pessimism is anarcho-primitivism which faults the agricultural revolution with giving rise to social stratification, coercion, and alienation. Some anarcho-primitivists promote deindustrialization, abandonment of modern technology and rewilding.

An infamous anarcho-primitivist is Theodore Kaczynski, also known as the Unabomber who engaged in a nationwide mail bombing campaign. In his 1995 manifesto, "Industrial Society and Its Future" he called attention to the erosion of human freedom by the rise of the modern "industrial-technological system". The manifesto begins thus: The Industrial Revolution and its consequences have been a disaster for the human race. They have greatly increased the life-expectancy of those of us who live in “advanced” countries, but they have destabilized society, have made life unfulfilling, have subjected human beings to indignities, have led to widespread psychological suffering (in the Third World to physical suffering as well) and have inflicted severe damage on the natural world. The continued development of technology will worsen the situation. It will certainly subject human beings to greater indignities and inflict greater damage on the natural world, it will probably lead to greater social disruption and psychological suffering, and it may lead to increased physical suffering even in “advanced” countries.

One of the most radical pessimist organizations is the voluntary human extinction movement which argues for the extinction of the human race through antinatalism.

Pope Francis' controversial 2015 encyclical on ecological issues is ripe with pessimistic assessments of the role of technology in the modern world.

'Entropy pessimism' represents a special case of technological and environmental pessimism, based on thermodynamic principles. According to the first law of thermodynamics, matter and energy is neither created nor destroyed in the economy. According to the second law of thermodynamics — also known as the entropy law — what happens in the economy is that all matter and energy is transformed from states available for human purposes (valuable natural resources) to states unavailable for human purposes (valueless waste and pollution). In effect, all of man's technologies and activities are only speeding up the general march against a future planetary 'heat death' of degraded energy, exhausted natural resources and a deteriorated environment — a state of maximum entropy locally on Earth; 'locally' on Earth, that is, when compared to the heat death of the universe, taken as a whole.

The term 'entropy pessimism' was coined to describe the work of Romanian American economist Nicholas Georgescu-Roegen, a progenitor in economics and the paradigm founder of ecological economics. Georgescu-Roegen made extensive use of the entropy concept in his magnum opus on "The Entropy Law and the Economic Process". Since the 1990s, leading ecological economist and steady-state theorist Herman Daly — a student of Georgescu-Roegen — has been the economists profession's most influential proponent of entropy pessimism. 

Among other matters, the entropy pessimism position is concerned with the existential impossibility of distributing Earth's finite stock of mineral resources evenly among an unknown number of present and future generations. This number of generations is likely to remain unknown to us, as there is little way of knowing in advance if or when mankind will eventually face extinction. In effect, "any" conceivable intertemporal distribution of the stock will inevitably end up with universal economic decline at some future point. 

Entropy pessimism is a widespread view in ecological economics and in the degrowth movement.

Bibas writes that some criminal defense attorneys prefer to err on the side of pessimism: "Optimistic forecasts risk being proven disastrously wrong at trial, an embarrassing result that makes clients angry. On the other hand, if clients plead based on their lawyers' overly pessimistic advice, the cases do not go to trial and the clients are none the wiser."

In the ancient world, psychological pessimism was associated with melancholy, and was believed to be caused by an excess of black bile in the body. 
The study of pessimism has parallels with the study of depression. Psychologists trace pessimistic attitudes to emotional pain or even biology. Aaron Beck argues that depression is due to unrealistic negative views about the world. Beck starts treatment by engaging in conversation with clients about their unhelpful thoughts. Pessimists, however, are often able to provide arguments that suggest that their understanding of reality is justified; as in Depressive realism or (pessimistic realism). Deflection is a common method used by those who are depressed. They let people assume they are revealing everything which proves to be an effective way of hiding. The pessimism item on the Beck Depression Inventory has been judged useful in predicting suicides. The Beck Hopelessness Scale has also been described as a measurement of pessimism.

Wender and Klein point out that pessimism can be useful in some circumstances: "If one is subject to a series of defeats, it pays to adopt a conservative game plan of sitting back and waiting and letting others take the risks. Such waiting would be fostered by a pessimistic outlook. Similarly if one is raking in the chips of life, it pays to adopt an expansive risk taking approach, and thus maximize access to scarce resources."

Through history, some have concluded that a pessimistic attitude, although justified, must be avoided in order to endure. Optimistic attitudes are favored and of emotional consideration. Al-Ghazali and William James rejected their pessimism after suffering psychological, or even psychosomatic illness. Criticisms of this sort however assume that pessimism leads inevitably to a mood of darkness and utter depression. Many philosophers would disagree, claiming that the term "pessimism" is being abused. The link between pessimism and nihilism is present, but the former does not necessarily lead to the latter, as philosophers such as Albert Camus believed. Happiness is not inextricably linked to optimism, nor is pessimism inextricably linked to unhappiness. One could easily imagine an unhappy optimist, and a happy pessimist. Accusations of pessimism may be used to silence legitimate criticism. The economist Nouriel Roubini was largely dismissed as a pessimist, for his dire but accurate predictions of a coming global financial crisis, in 2006. "Personality Plus" opines that pessimistic temperaments (e.g. melancholy and phlegmatic) can be useful inasmuch as pessimists' focus on the negative helps them spot problems that people with more optimistic temperaments (e.g. choleric and sanguine) miss.




</doc>
<doc id="24744" url="https://en.wikipedia.org/wiki?curid=24744" title="Peter Wessel Zapffe">
Peter Wessel Zapffe

Peter Wessel Zapffe (December 18, 1899 – October 12, 1990) was a Norwegian metaphysician, author, lawyer and mountaineer. He is often noted for his philosophically pessimistic and fatalistic view of human existence—his system of philosophy in line with the work of the earlier philosopher Arthur Schopenhauer, by whom he was inspired—as well as his firm advocacy of antinatalism. His thoughts regarding the error of human life are presented in the essay "The Last Messiah" (Norwegian: "Den sidste Messias", 1933). This essay is a shorter version of his best-known work, the philosophical treatise "On the Tragic" ("Om det tragiske", 1941).

Zapffe's view is that humans are born with an overdeveloped skill (understanding, self-knowledge) which does not fit into nature's design. The human craving for justification on matters such as life and death cannot be satisfied, hence humanity has a need that nature cannot satisfy. The tragedy, following this theory, is that humans spend all their time trying not to be human. The human being, therefore, is a paradox.

In "The Last Messiah" Zapffe described four principal defense mechanisms that humankind uses to avoid facing this paradox:


Zapffe was a prolific mountaineer and took a very early interest in environmentalism. This form of nature conservationism sprung from the intent, not of protecting nature, but to avoid human culturalization of nature. He is the author of many humorous short stories about climbing and other adventures in nature.

Zapffe married twice. He remained married to his second wife Berit Zapffe until his death in 1990. Berit died in May 2008. Zapffe remained childless by choice.







</doc>
<doc id="24745" url="https://en.wikipedia.org/wiki?curid=24745" title="Franc Poincaré">
Franc Poincaré

The Franc Poincaré is a unit of account that was used in the international regulation of liability. It is defined as 65.5 milligrams of gold of millesimal fineness .900. Formerly it was identical to the French franc, although it has not been so since the 1920s.

Practice on its conversion to national currencies varies from state to state; in most states the conversion factor is based not on the market price of gold, but on an official price (a remnant of the gold standard, frequently far below its market price today). The Franc Poincaré has been replaced for most purposes by special drawing rights.

Conventions which used the Franc Poincaré included the Convention for the Unification of Certain Rules Relating to International Carriage by Air, the International Convention on Civil Liability for Oil Pollution Damage and the International Convention on the Establishment of an International Fund for Compensation for Oil Pollution Damage.


</doc>
<doc id="24746" url="https://en.wikipedia.org/wiki?curid=24746" title="PCX">
PCX

PCX, standing for "PiCture eXchange", is an image file format developed by the now-defunct ZSoft Corporation of Marietta, Georgia, United States. It was the native file format for PC Paintbrush and became one of the first widely accepted DOS imaging standards, although it has since been succeeded by more sophisticated image formats, such as BMP, JPEG, and PNG. PCX files commonly stored palette-indexed images ranging from 2 or 4 colors to 16 and 256 colors, although the format has been extended to record true-color (24-bit) images as well.

PCX was designed during the early development of PC display hardware and most of the formats it supported are no longer used, Table A shows a list of the most commonly used PCX formats. Contemporary image editing programs may not read PCX files that match older hardware.

PCX is supported by common image processing software including ACDSee, GIMP, ImageMagick, IrfanView, LView, Netpbm, PaintShop Pro, Photoshop, Visio, PMview, XnView and GraphicConverter. In version 2.1.4 FFmpeg could encode and decode the PCX pixel formats "rgb24, rgb8, bgr8, rgb4_byte, bgr4_byte, gray, pal8," and "monob".

There is a multi-page version of PCX, used by some computer fax and document management programs, with file extension codice_1. A DCX file consists of a header introducing a set of following PCX files.

PCX files were designed for use on IBM-compatible PCs and always use little endian byte ordering. A PCX file has three main sections, in the following order

The PCX file header contains an identifier byte (value 10), a version number, image dimensions, 16 palette colors, number color planes, bit depth of each plane, and a value for compression method. PCX version numbers range from 0 to 5, this originally denoted the version of the PC Paintbrush program used to create the PCX file. The header always has space for 16 colors though the number of colors used depends upon the bit depth of the image. The header is 74 bytes long and the image data begins 128 bytes after the start of the file, the 54 bytes between are not used.

All PCX files use the same compression scheme and the compression value is always 1. No other values have been defined and there are no uncompressed PCX files. One source claims that 0 (uncompressed) is "allowed, but not much software supports it".

PCX image data is stored in rows or scan lines in top-down order. If the image has multiple planes, these are stored by plane within row, such that all the red data for row 0 are followed by all the green data for row 0, then all the blue data, then alpha data. This pattern is repeated for each line as shown in Table B.

When an image is less than 8 bits per pixel, each line is padded to the next byte boundary. For example, if an image has 1 plane of 1-bit data (monochrome) with a width of 22 pixels, each row will be 3 bytes long, having 24 bits per row with 2 bits unused.

PCX image data are compressed using run-length encoding (RLE), a simple lossless compression algorithm that collapses a series of three or more consecutive bytes with identical values into a two-byte pair. The two most-significant bits of a byte are used to determine whether the given data represent a single pixel of a given palette index or color value, or an RLE pair representing a series of several pixels of a single value:
Compared to the maximum run length of 128, possible with TGA RLE compression, the PCX run-length encoding offers a larger single-pixel value range, while the maximum run length is restricted to 63.

Due to the use of the two most-significant bits as flags, pixel values from 192 to 255 (with their most-significant bit already set) must be stored in an RLE byte pair, even when they only occur one or two pixels in succession, whereas color indexes 0 to 191 can be stored directly "or" in RLE byte pairs (whichever is more space-efficient); therefore, the actual compression ratio could be optimized with proper sorting of palette entries, though this is not feasible where the file must share its color palette with other images. For example, a palette could be optimized with the most commonly used colors occurring in palette positions 0 to 191 and the least common colors allocated to the remaining quarter of the palette.

Another inefficiency with the RLE algorithm is that it is possible to store chunks with a length of 0, which allows whitespace in the file. This allowed PCX files to be decompressed slightly faster on the processors it was originally intended for. This quirk could be used for steganography.

The PCX compression algorithm requires very little processor power or memory to apply, a significant concern with the computer systems when it was designed. As computers and display hardware grow more sophisticated, the PCX algorithm becomes less space-efficient. Compression algorithms used by newer image formats are more efficient when compressing images such as photographs, and dithered or otherwise complex graphics.

A PCX file has space in its header for a 16 color palette. When 256-color VGA hardware became available there was not enough space for the palette in a PCX file; even the 54 unused bytes after the header would not be enough. The solution chosen was to put the palette at the end of the file, along with a marker byte to confirm its existence.

If a PCX file has a 256-color palette, it is found 768 bytes from the end of the file. In this case the value in the byte preceding the palette should be 12 (0x0C). The palette is stored as a sequence of RGB triples; its usable length is defined by the number of colors in the image. Colors values in a PCX palette always use 8 bits, regardless of the bit depth of the image.


</doc>
<doc id="24749" url="https://en.wikipedia.org/wiki?curid=24749" title="Permian–Triassic extinction event">
Permian–Triassic extinction event

The Permian–Triassic (P–Tr or P–T) extinction event, colloquially known as the Great Dying, the End-Permian Extinction or the Great Permian Extinction, occurred about 252 Ma (million years) ago, forming the boundary between the Permian and Triassic geologic periods, as well as the Paleozoic and Mesozoic eras. It is the Earth's most severe known extinction event, with up to 96% of all marine species and 70% of terrestrial vertebrate species becoming extinct. It is the only known mass extinction of insects. Some 57% of all biological families and 83% of all genera became extinct. Because so much biodiversity was lost, the recovery of land-dwelling life took significantly longer than after any other extinction event, possibly up to 10 million years. Studies in Bear Lake County near Paris, Idaho showed a quick and dynamic rebound in a marine ecosystem, illustrating the remarkable resilience of life.

There is evidence for one to three distinct pulses, or phases, of extinction. Suggested mechanisms for the latter include one or more large meteor impact events, massive volcanism such as that of the Siberian Traps, and the ensuing coal or gas fires and explosions,<ref name="lava/coal fires"> </ref> and a runaway greenhouse effect triggered by sudden release of methane from the sea floor due to methane clathrate dissociation according to the clathrate gun hypothesis or methane-producing microbes known as methanogens. Possible contributing gradual changes include sea-level change, increasing anoxia, increasing aridity, and a shift in ocean circulation driven by climate change.

Until 2000, it was thought that rock sequences spanning the Permian–Triassic boundary were too few and contained too many gaps for scientists to reliably determine its details. However, it is now possible to date the extinction with millennial precision. U–Pb zircon dates from five volcanic ash beds from the Global Stratotype Section and Point for the Permian–Triassic boundary at Meishan, China, establish a high-resolution age model for the extinction – allowing exploration of the links between global environmental perturbation, carbon cycle disruption, mass extinction, and recovery at millennial timescales. The extinction occurred between 251.941 ± 0.037 and 251.880 ± 0.031 Ma, a duration of 60 ± 48 ka. A large (approximately 0.9%), abrupt global decrease in the ratio of the stable isotope to that of , coincides with this extinction, and is sometimes used to identify the Permian–Triassic boundary in rocks that are unsuitable for radiometric dating. Further evidence for environmental change around the P–Tr boundary suggests an rise in temperature, and an increase in levels by (for comparison, the concentration immediately before the industrial revolution was , and the amount today is about 410 ppm). There is also evidence of increased ultraviolet radiation reaching the earth, causing the mutation of plant spores.

It has been suggested that the Permian–Triassic boundary is associated with a sharp increase in the abundance of marine and terrestrial fungi, caused by the sharp increase in the amount of dead plants and animals fed upon by the fungi. For a while this "fungal spike" was used by some paleontologists to identify the Permian–Triassic boundary in rocks that are unsuitable for radiometric dating or lack suitable index fossils, but even the proposers of the fungal spike hypothesis pointed out that "fungal spikes" may have been a repeating phenomenon created by the post-extinction ecosystem in the earliest Triassic. The very idea of a fungal spike has been criticized on several grounds, including: "Reduviasporonites", the most common supposed fungal spore, was actually a fossilized alga; the spike did not appear worldwide; and in many places it did not fall on the Permian–Triassic boundary. The algae, which were misidentified as fungal spores, may even represent a transition to a lake-dominated Triassic world rather than an earliest Triassic zone of death and decay in some terrestrial fossil beds. Newer chemical evidence agrees better with a fungal origin for "Reduviasporonites", diluting these critiques.

Uncertainty exists regarding the duration of the overall extinction and about the timing and duration of various groups' extinctions within the greater process. Some evidence suggests that there were multiple extinction pulses or that the extinction was spread out over a few million years, with a sharp peak in the last million years of the Permian. Statistical analyses of some highly fossiliferous strata in Meishan, Zhejiang Province in southeastern China, suggest that the main extinction was clustered around one peak. Recent research shows that different groups became extinct at different times; for example, while difficult to date absolutely, ostracod and brachiopod extinctions were separated by 670 to 1 170 thousand years. In a well-preserved sequence in east Greenland, the decline of animals is concentrated in a period 10 to long, with plants taking an additional several hundred thousand years to show the full impact of the event. An older theory, still supported in some recent papers, is that there were two major extinction pulses 9.4 million years apart, separated by a period of extinctions well above the background level, and that the final extinction killed off only about 80% of marine species alive at that time while the other losses occurred during the first pulse or the interval between pulses. According to this theory one of these extinction pulses occurred at the end of the Guadalupian epoch of the Permian.
For example, all but one of the surviving dinocephalian genera died out at the end of the Guadalupian, as did the Verbeekinidae, a family of large-size fusuline foraminifera.
The impact of the end-Guadalupian extinction on marine organisms appears to have varied between locations and between taxonomic groups — brachiopods and corals had severe losses.
Marine invertebrates suffered the greatest losses during the P–Tr extinction. Evidence of this was found in samples from south China sections at the P–Tr boundary. Here, 286 out of 329 marine invertebrate genera disappear within the final 2 sedimentary zones containing conodonts from the Permian. The decrease in diversity was probably caused by a sharp increase in extinctions, rather than a decrease in speciation.

The extinction primarily affected organisms with calcium carbonate skeletons, especially those reliant on stable CO levels to produce their skeletons. These organisms were susceptible to the effects of the ocean acidification that resulted from increased atmospheric CO.

Among benthic organisms the extinction event multiplied background extinction rates, and therefore caused maximum species loss to taxa that had a high background extinction rate (by implication, taxa with a high turnover). The extinction rate of marine organisms was catastrophic.

Surviving marine invertebrate groups include: articulate brachiopods (those with a hinge), which have undergone a slow decline in numbers since the P–Tr extinction; the Ceratitida order of ammonites; and crinoids ("sea lilies"), which very nearly became extinct but later became abundant and diverse.

The groups with the highest survival rates generally had active control of circulation, elaborate gas exchange mechanisms, and light calcification; more heavily calcified organisms with simpler breathing apparatuses suffered the greatest loss of species diversity. In the case of the brachiopods, at least, surviving taxa were generally small, rare members of a formerly diverse community.

The ammonoids, which had been in a long-term decline for the 30 million years since the Roadian (middle Permian), suffered a selective extinction pulse 10 million years before the main event, at the end of the Capitanian stage. In this preliminary extinction, which greatly reduced disparity, or the range of different ecological guilds, environmental factors were apparently responsible. Diversity and disparity fell further until the P–Tr boundary; the extinction here (P–Tr) was non-selective, consistent with a catastrophic initiator. During the Triassic, diversity rose rapidly, but disparity remained low.

The range of morphospace occupied by the ammonoids, that is, their range of possible forms, shapes or structures, became more restricted as the Permian progressed. A few million years into the Triassic, the original range of ammonoid structures was once again reoccupied, but the parameters were now shared differently among clades.

The Permian had great diversity in insect and other invertebrate species, including the largest insects ever to have existed. The end-Permian is the only known mass extinction of insects, with eight or nine insect orders becoming extinct and ten more greatly reduced in diversity. Palaeodictyopteroids (insects with piercing and sucking mouthparts) began to decline during the mid-Permian; these extinctions have been linked to a change in flora. The greatest decline occurred in the Late Permian and was probably not directly caused by weather-related floral transitions.

Most fossil insect groups found after the Permian–Triassic boundary differ significantly from those before. Of Paleozoic insect groups, only the Glosselytrodea, Miomoptera, and Protorthoptera have been discovered in deposits from after the extinction. The caloneurodeans, monurans, paleodictyopteroids, protelytropterans, and protodonates became extinct by the end of the Permian. In well-documented Late Triassic deposits, fossils overwhelmingly consist of modern fossil insect groups.

The geological record of terrestrial plants is sparse and based mostly on pollen and spore studies. Plants are relatively immune to mass extinction, with the impact of all the major mass extinctions "insignificant" at a family level. Even the reduction observed in species diversity (of 50%) may be mostly due to taphonomic processes. However, a massive rearrangement of ecosystems does occur, with plant abundances and distributions changing profoundly and all the forests virtually disappearing; the Palaeozoic flora scarcely survived this extinction.

At the P–Tr boundary, the dominant floral groups changed, with many groups of land plants entering abrupt decline, such as "Cordaites" (gymnosperms) and "Glossopteris" (seed ferns). Dominant gymnosperm genera were replaced post-boundary by lycophytes—extant lycophytes are recolonizers of disturbed areas.

Palynological or pollen studies from East Greenland of sedimentary rock strata laid down during the extinction period indicate dense gymnosperm woodlands before the event. At the same time that marine invertebrate macrofauna declined, these large woodlands died out and were followed by a rise in diversity of smaller herbaceous plants including Lycopodiophyta, both "Selaginellales" and "Isoetales". Later, other groups of gymnosperms again become dominant but again suffered major die offs. These cyclical flora shifts occurred a few times over the course of the extinction period and afterwards. These fluctuations of the dominant flora between woody and herbaceous taxa indicate chronic environmental stress resulting in a loss of most large woodland plant species. The successions and extinctions of plant communities do not coincide with the shift in values, but occurred many years after. The recovery of gymnosperm forests took 4–5 million years.

No coal deposits are known from the Early Triassic, and those in the Middle Triassic are thin and low-grade. This "coal gap" has been explained in many ways. It has been suggested that new, more aggressive fungi, insects and vertebrates evolved, and killed vast numbers of trees. These decomposers themselves suffered heavy losses of species during the extinction, and are not considered a likely cause of the coal gap. It could simply be that all coal forming plants were rendered extinct by the P–Tr extinction, and that it took 10 million years for a new suite of plants to adapt to the moist, acid conditions of peat bogs. Abiotic factors (factors not caused by organisms), such as decreased rainfall or increased input of clastic sediments, may also be to blame.

On the other hand, the lack of coal may simply reflect the scarcity of all known sediments from the Early Triassic. Coal-producing ecosystems, rather than disappearing, may have moved to areas where we have no sedimentary record for the Early Triassic. For example, in eastern Australia a cold climate had been the norm for a long period, with a peat mire ecosystem adapted to these conditions. Approximately 95% of these peat-producing plants went "locally" extinct at the P–Tr boundary; Coal deposits in Australia and Antarctica disappear significantly "before" the P–Tr boundary.

There is enough evidence to indicate that over two-thirds of terrestrial labyrinthodont amphibians, sauropsid ("reptile") and therapsid ("proto-mammal") families became extinct. Large herbivores suffered the heaviest losses.

All Permian anapsid reptiles died out except the procolophonids (although testudines have "morphologically" anapsid skulls, they are now thought to have separately evolved from diapsid ancestors). Pelycosaurs died out before the end of the Permian. Too few Permian diapsid fossils have been found to support any conclusion about the effect of the Permian extinction on diapsids (the "reptile" group from which lizards, snakes, crocodilians, and dinosaurs (including birds) evolved).

The groups that survived suffered extremely heavy losses of species, and some terrestrial vertebrate groups very nearly became extinct at the end-Permian. Some of the surviving groups did not persist for long past this period, while others that barely survived went on to produce diverse and long-lasting lineages. Yet it took 30million years for the terrestrial vertebrate fauna to fully recover both numerically and ecologically.

An analysis of marine fossils from the Permian's final Changhsingian stage found that marine organisms with low tolerance for hypercapnia (high concentration of carbon dioxide) had high extinction rates, while the most tolerant organisms had very slight losses.

The most vulnerable marine organisms were those that produced calcareous hard parts (i.e., from calcium carbonate) and had low metabolic rates and weak respiratory systems—notably calcareous sponges, rugose and tabulate corals, calcite-depositing brachiopods, bryozoans, and echinoderms; about 81% of such genera became extinct. Close relatives without calcareous hard parts suffered only minor losses, for example sea anemones, from which modern corals evolved. Animals with high metabolic rates, well-developed respiratory systems, and non-calcareous hard parts had negligible losses—except for conodonts, in which 33% of genera died out.

This pattern is consistent with what is known about the effects of hypoxia, a shortage but not a total absence of oxygen. However, hypoxia cannot have been the only killing mechanism for marine organisms. Nearly all of the continental shelf waters would have had to become severely hypoxic to account for the magnitude of the extinction, but such a catastrophe would make it difficult to explain the very selective pattern of the extinction. Models of the Late Permian and Early Triassic atmospheres show a significant but protracted decline in atmospheric oxygen levels, with no acceleration near the P–Tr boundary. Minimum atmospheric oxygen levels in the Early Triassic are never less than present day levels—the decline in oxygen levels does not match the temporal pattern of the extinction.

Marine organisms are more sensitive to changes in (carbon dioxide) levels than are terrestrial organisms for a variety of reasons. is 28 times more soluble in water than is oxygen. Marine animals normally function with lower concentrations of in their bodies than land animals, as the removal of in air-breathing animals is impeded by the need for the gas to pass through the respiratory system's membranes (lungs' alveolus, tracheae, and the like), even when diffuses more easily than oxygen. In marine organisms, relatively modest but sustained increases in concentrations hamper the synthesis of proteins, reduce fertilization rates, and produce deformities in calcareous hard parts. In addition, an increase in concentration is inevitably linked to ocean acidification, consistent with the preferential extinction of heavily calcified taxa and other signals in the rock record that suggest a more acidic ocean. The decrease in ocean pH is calculated to be up to 0.7 units.

It is difficult to analyze extinction and survival rates of land organisms in detail, because few terrestrial fossil beds span the Permian–Triassic boundary. Triassic insects are very different from those of the Permian, but a gap in the insect fossil record spans approximately 15 million years from the late Permian to early Triassic. The best-known record of vertebrate changes across the Permian–Triassic boundary occurs in the Karoo Supergroup of South Africa, but statistical analyses have so far not produced clear conclusions. However, analysis of the fossil river deposits of the floodplains indicate a shift from meandering to braided river patterns, indicating an abrupt drying of the climate. The climate change may have taken as little as 100,000 years, prompting the extinction of the unique "Glossopteris" flora and its herbivores, followed by the carnivorous guild. End-Permian extinctions did not occur at an instantaneous time horizon; particularly, floral extinction was delayed in time.

Earlier analyses indicated that life on Earth recovered quickly after the Permian extinctions, but this was mostly in the form of disaster taxa, opportunist organisms such as the hardy "Lystrosaurus". Research published in 2006 indicates that the specialized animals that formed complex ecosystems, with high biodiversity, complex food webs and a variety of niches, took much longer to recover. It is thought that this long recovery was due to the successive waves of extinction, which inhibited recovery, and prolonged environmental stress to organisms, which continued into the Early Triassic. Research indicates that recovery did not begin until the start of the mid-Triassic, 4 to 6 million years after the extinction; and some writers estimate that the recovery was not complete until after the P–Tr extinction, i.e. in the late Triassic.

A study published in the journal "Science" found that during the Great Extinction, ocean surface temperatures reached in some places. This explains why recovery took so long: it was too hot for life to survive. Anoxic waters may have also delayed the recovery.
During the early Triassic (4 to 6 million years after the P–Tr extinction), the plant biomass was insufficient to form coal deposits, which implies a limited food mass for herbivores. River patterns in the Karoo changed from meandering to braided, indicating that vegetation there was very sparse for a long time.

Each major segment of the early Triassic ecosystem—plant and animal, marine and terrestrial—was dominated by a small number of genera, which appeared virtually worldwide, for example: the herbivorous therapsid "Lystrosaurus" (which accounted for about 90% of early Triassic land vertebrates) and the bivalves "Claraia", "Eumorphotis", "Unionites" and "Promylina". A healthy ecosystem has a much larger number of genera, each living in a few preferred types of habitat.

Disaster taxa took advantage of the devastated ecosystems and enjoyed a temporary population boom and increase in their territory. Microconchids are the dominant component of otherwise impoverished Early Triassic encrusting assemblages. For example: "Lingula" (a brachiopod); stromatolites, which had been confined to marginal environments since the Ordovician; "Pleuromeia" (a small, weedy plant); "Dicroidium" (a seed fern).

Prior to the extinction, about two-thirds of marine animals were sessile and attached to the sea floor. During the Mesozoic, only about half of the marine animals were sessile while the rest were free-living. Analysis of marine fossils from the period indicated a decrease in the abundance of sessile epifaunal suspension feeders such as brachiopods and sea lilies and an increase in more complex mobile species such as snails, sea urchins and crabs.

Before the Permian mass extinction event, both complex and simple marine ecosystems were equally common; after the recovery from the mass extinction, the complex communities outnumbered the simple communities by nearly three to one, and the increase in predation pressure led to the Mesozoic Marine Revolution.

Bivalves were fairly rare before the P–Tr extinction but became numerous and diverse in the Triassic, and one group, the rudist clams, became the Mesozoic's main reef-builders. Some researchers think much of this change happened in the 5 million years between the two major extinction pulses.

Crinoids ("sea lilies") suffered a selective extinction, resulting in a decrease in the variety of their forms. Their ensuing adaptive radiation was brisk, and resulted in forms possessing flexible arms becoming widespread; motility, predominantly a response to predation pressure, also became far more prevalent.

"Lystrosaurus", a pig-sized herbivorous dicynodont therapsid, constituted as much as 90% of some earliest Triassic land vertebrate fauna. Smaller carnivorous cynodont therapsids also survived, including the ancestors of mammals. In the Karoo region of southern Africa, the therocephalians "Tetracynodon", "Moschorhinus" and "Ictidosuchoides" survived, but do not appear to have been abundant in the Triassic.

Archosaurs (which included the ancestors of dinosaurs and crocodilians) were initially rarer than therapsids, but they began to displace therapsids in the mid-Triassic. In the mid to late Triassic, the dinosaurs evolved from one group of archosaurs, and went on to dominate terrestrial ecosystems during the Jurassic and Cretaceous. This "Triassic Takeover" may have contributed to the evolution of mammals by forcing the surviving therapsids and their mammaliform successors to live as small, mainly nocturnal insectivores; nocturnal life probably forced at least the mammaliforms to develop fur and higher metabolic rates, while losing part of the differential color-sensitive retinal receptors reptilians and birds preserved.

Some temnospondyl amphibians made a relatively quick recovery, in spite of nearly becoming extinct. "Mastodonsaurus" and trematosaurians were the main aquatic and semiaquatic predators during most of the Triassic, some preying on tetrapods and others on fish.

Land vertebrates took an unusually long time to recover from the P–Tr extinction; Palaeontologist Michael Benton estimated the recovery was not complete until after the extinction, i.e. not until the Late Triassic, in which dinosaurs, pterosaurs, crocodiles, archosaurs, amphibians, and mammaliforms were abundant and diverse.

Pinpointing the exact cause or causes of the Permian–Triassic extinction event is difficult, mostly because the catastrophe occurred over 250 million years ago, and since then much of the evidence that would have pointed to the cause has been destroyed or is concealed deep within the Earth under many layers of rock. The sea floor is also completely recycled every 200 million years by the ongoing process of plate tectonics and seafloor spreading, leaving no useful indications beneath the ocean.

Scientists have accumulated a fairly significant amount of evidence for causes, and several mechanisms have been proposed for the extinction event. The proposals include both catastrophic and gradual processes (similar to those theorized for the Cretaceous–Paleogene extinction event).

Any hypothesis about the cause must explain the selectivity of the event, which affected organisms with calcium carbonate skeletons most severely; the long period (4 to 6 million years) before recovery started, and the minimal extent of biological mineralization (despite inorganic carbonates being deposited) once the recovery began.

Evidence that an impact event may have caused the Cretaceous–Paleogene extinction event (Cretaceous–Tertiary) has led to speculation that similar impacts may have been the cause of other extinction events, including the P–Tr extinction, and thus to a search for evidence of impacts at the times of other extinctions and for large impact craters of the appropriate age.

Reported evidence for an impact event from the P–Tr boundary level includes rare grains of shocked quartz in Australia and Antarctica; fullerenes trapping extraterrestrial noble gases; meteorite fragments in Antarctica; and grains rich in iron, nickel and silicon, which may have been created by an impact. However, the accuracy of most of these claims has been challenged. For example, quartz from Graphite Peak in Antarctica, once considered "shocked", has been re-examined by optical and transmission electron microscopy. The observed features were concluded to be not due to shock, but rather to plastic deformation, consistent with formation in a tectonic environment such as volcanism.

An impact crater on the sea floor would be evidence of a possible cause of the P–Tr extinction, but such a crater would by now have disappeared. As 70% of the Earth's surface is currently sea, an asteroid or comet fragment is now perhaps more than twice as likely to hit ocean as it is to hit land. However, Earth's oldest ocean-floor crust is 200 million years old because it is continually destroyed and renewed by spreading and subduction. Thus, craters produced by very large impacts may be masked by extensive flood basalting from below after the crust is punctured or weakened. Yet, subduction should not be entirely accepted as an explanation of why no firm evidence can be found: as with the K-T event, an ejecta blanket stratum rich in siderophilic elements (such as iridium) would be expected to be seen in formations from the time.

A large impact might have triggered other mechanisms of extinction described below, such as the Siberian Traps eruptions at either an impact site or the antipode of an impact site. The abruptness of an impact also explains why more species did not rapidly evolve to survive, as would be expected if the Permian-Triassic event had been slower and less global than a meteorite impact.

Several possible impact craters have been proposed as the site of an impact causing the P–Tr extinction, including the Bedout structure off the northwest coast of Australia and the hypothesized Wilkes Land crater of East Antarctica. In each case, the idea that an impact was responsible has not been proven and has been widely criticized. In the case of Wilkes Land, the age of this sub-ice geophysical feature is very uncertain – it may be later than the Permian–Triassic extinction.

The Araguainha crater in Brazil has been most recently dated to 254.7 ± 2.5 million years ago, overlapping with estimates for the Permo-Triassic boundary. Much of the local rock was oil shale. The estimated energy released by the Araguainha impact is insufficient to be a direct cause of the global mass extinction, but the colossal local earth tremors would have released huge amounts of oil and gas from the shattered rock. The resulting sudden global warming might have precipitated the Permian–Triassic extinction event.

In May 1992, Michael R. Rampino published an abstract for the American Geophysical Union noting the discovery of a circular gravity anomaly near the Falkland Islands. He suggested this structure might correspond to an impact crater with a diameter of . In August 2017, Rampino, Maximilliano Rocca and Jaime Baez Presser followed up with a paper providing further seismic and magnetic evidence that the structure is an impact crater. Estimates for the age of the structure range up to 250 millions years old. If, in fact, this is an impact crater, it would be substantially larger than the well-known Chicxulub impact crater associated with a later extinction event.

The final stages of the Permian had two flood basalt events. A small one, the Emeishan Traps in China, occurred at the same time as the end-Guadalupian extinction pulse, in an area close to the equator at the time. The flood basalt eruptions that produced the Siberian Traps constituted one of the largest known volcanic events on Earth and covered over with lava. The date of the Siberian Traps eruptions and the extinction event are in good agreement.

The Emeishan and Siberian Traps eruptions may have caused dust clouds and acid aerosols, which would have blocked out sunlight and thus disrupted photosynthesis both on land and in the photic zone of the ocean, causing food chains to collapse. The eruptions may also have caused acid rain when the aerosols washed out of the atmosphere. That may have killed land plants and molluscs and planktonic organisms which had calcium carbonate shells. The eruptions would also have emitted carbon dioxide, causing global warming. When all of the dust clouds and aerosols washed out of the atmosphere, the excess carbon dioxide would have remained and the warming would have proceeded without any mitigating effects.

The Siberian Traps had unusual features that made them even more dangerous. Pure flood basalts produce fluid, low-viscosity lava and do not hurl debris into the atmosphere. It appears, however, that 20% of the output of the Siberian Traps eruptions was pyroclastic (consisted of ash and other debris thrown high into the atmosphere), increasing the short-term cooling effect. The basalt lava erupted or intruded into carbonate rocks and into sediments that were in the process of forming large coal beds, both of which would have emitted large amounts of carbon dioxide, leading to stronger global warming after the dust and aerosols settled.

In January 2011, a team, led by Stephen Grasby of the Geological Survey of Canada—Calgary, reported evidence that volcanism caused massive coal beds to ignite, possibly releasing more than 3 trillion tons of carbon. The team found ash deposits in deep rock layers near what is now Buchanan Lake. According to their article, "coal ash dispersed by the explosive Siberian Trap eruption would be expected to have an associated release of toxic elements in impacted water bodies where fly ash slurries developed... Mafic megascale eruptions are long-lived events that would allow significant build-up of global ash clouds." In a statement, Grasby said, "In addition to these volcanoes causing fires through coal, the ash it spewed was highly toxic and was released in the land and water, potentially contributing to the worst extinction event in earth history." In 2013, a team led by Q. Y. Yang reported the total amounts of important volatiles emitted from the Siberian Traps are 8.5 × 10 Tg CO, 4.4 × 10 Tg CO, 7.0 × 10 Tg HS and 6.8 × 10 Tg SO, the data support a popular notion that the end-Permian mass extinction on the Earth was caused by the emission of enormous amounts of volatiles from the Siberian Traps into the atmosphere.

In 2015, evidence and a timeline indicated the extinction was caused by events in the Large igneous province of the Siberian Traps.

Scientists have found worldwide evidence of a swift decrease of about 1% in the C/C isotope ratio in carbonate rocks from the end-Permian. This is the first, largest, and most rapid of a series of negative and positive excursions (decreases and increases in C/C ratio) that continues until the isotope ratio abruptly stabilised in the middle Triassic, followed soon afterwards by the recovery of calcifying life forms (organisms that use calcium carbonate to build hard parts such as shells).

A variety of factors may have contributed to this drop in the C/C ratio, but most turn out to be insufficient to account fully for the observed amount:

Other hypotheses include mass oceanic poisoning releasing vast amounts of and a long-term reorganisation of the global carbon cycle.

Prior to consideration of the inclusion of roasting carbonate sediments by volcanism, the only proposed mechanism sufficient to cause a global 1% reduction in the C/C ratio was the release of methane from methane clathrates. Carbon-cycle models confirm that it would have had enough effect to produce the observed reduction. Methane clathrates, also known as methane hydrates, consist of methane molecules trapped in cages of water molecules. The methane, produced by methanogens (microscopic single-celled organisms), has a C/C ratio about 6.0% below normal ( −6.0%). At the right combination of pressure and temperature, it gets trapped in clathrates fairly close to the surface of permafrost and in much larger quantities at continental margins (continental shelves and the deeper seabed close to them). Oceanic methane hydrates are usually found buried in sediments where the seawater is at least deep. They can be found up to about below the sea floor, but usually only about below the sea floor.

The area covered by lava from the Siberian Traps eruptions is about twice as large as was originally thought, and most of the additional area was shallow sea at the time. The seabed probably contained methane hydrate deposits, and the lava caused the deposits to dissociate, releasing vast quantities of methane.
A vast release of methane might cause significant global warming since methane is a very powerful greenhouse gas. Strong evidence suggests the global temperatures increased by about 6 °C (10.8 °F) near the equator and therefore by more at higher latitudes: a sharp decrease in oxygen isotope ratios (O/O); the extinction of "Glossopteris" flora ("Glossopteris" and plants that grew in the same areas), which needed a cold climate, with its replacement by floras typical of lower paleolatitudes.

However, the pattern of isotope shifts expected to result from a massive release of methane does not match the patterns seen throughout the early Triassic. Not only would such a cause require the release of five times as much methane as postulated for the PETM, but would it also have to be reburied at an unrealistically high rate to account for the rapid increases in the C/C ratio (episodes of high positive ) throughout the early Triassic before it was released again several times.

Evidence for widespread ocean anoxia (severe deficiency of oxygen) and euxinia (presence of hydrogen sulfide) is found from the Late Permian to the Early Triassic. Throughout most of the Tethys and Panthalassic Oceans, evidence for anoxia, including fine laminations in sediments, small pyrite framboids, high uranium/thorium ratios, and biomarkers for green sulfur bacteria, appear at the extinction event.
However, in some sites, including Meishan, China, and eastern Greenland, evidence for anoxia precedes the extinction.
Biomarkers for green sulfur bacteria, such as isorenieratane, the diagenetic product of isorenieratene, are widely used as indicators of photic zone euxinia because green sulfur bacteria require both sunlight and hydrogen sulfide to survive. Their abundance in sediments from the P-T boundary indicates hydrogen sulfide was present even in shallow waters.

This spread of toxic, oxygen-depleted water would have been devastating for marine life, producing widespread die-offs. Models of ocean chemistry show that anoxia and euxinia would have been closely associated with hypercapnia (high levels of carbon dioxide).
This suggests that poisoning from hydrogen sulfide, anoxia, and hypercapnia acted together as a killing mechanism. Hypercapnia best explains the selectivity of the extinction, but anoxia and euxinia probably contributed to the high mortality of the event. The persistence of anoxia through the Early Triassic may explain the slow recovery of marine life after the extinction. Models also show that anoxic events can cause catastrophic hydrogen sulfide emissions into the atmosphere (see below).

The sequence of events leading to anoxic oceans may have been triggered by carbon dioxide emissions from the eruption of the Siberian Traps. In that scenario, warming from the enhanced greenhouse effect would reduce the solubility of oxygen in seawater, causing the concentration of oxygen to decline. Increased weathering of the continents due to warming and the acceleration of the water cycle would increase the riverine flux of phosphate to the ocean. The phosphate would have supported greater primary productivity in the surface oceans. The increase in organic matter production would have caused more organic matter to sink into the deep ocean, where its respiration would further decrease oxygen concentrations. Once anoxia became established, it would have been sustained by a positive feedback loop because deep water anoxia tends to increase the recycling efficiency of phosphate, leading to even higher productivity.

A severe anoxic event at the end of the Permian would have allowed sulfate-reducing bacteria to thrive, causing the production of large amounts of hydrogen sulfide in the anoxic ocean. Upwelling of this water may have released massive hydrogen sulfide emissions into the atmosphere and would poison terrestrial plants and animals and severely weaken the ozone layer, exposing much of the life that remained to fatal levels of UV radiation.
Indeed, biomarker evidence for anaerobic photosynthesis by Chlorobiaceae (green sulfur bacteria) from the Late-Permian into the Early Triassic indicates that hydrogen sulfide did upwell into shallow waters because these bacteria are restricted to the photic zone and use sulfide as an electron donor.

The hypothesis has the advantage of explaining the mass extinction of plants, which would have added to the methane levels and should otherwise have thrived in an atmosphere with a high level of carbon dioxide. Fossil spores from the end-Permian further support the theory: many show deformities that could have been caused by ultraviolet radiation, which would have been more intense after hydrogen sulfide emissions weakened the ozone layer.

In the mid-Permian (during the Kungurian age of the Permian's Cisuralian epoch), the earth’s major continental plates were joined, forming a supercontinent called Pangaea, which was surrounded by the superocean, Panthalassa.

Oceanic circulation and atmospheric weather patterns during the mid-Permian produced seasonal monsoons near the coasts and an arid climate in the vast continental interior of Pangaea.

The extent of biologically diverse and ecologically productive coastal areas shrank as the supercontinent formed. The elimination of shallow aquatic environments exposed formerly protected organisms of the rich continental shelves to increased environmental volatility.

After the formation of Pangaea (see the diagram "Marine genus biodiversity" at the top of this article), the rate of marine life depletion approached catastrophic levels; however, marine life extinction never reached the rate of the "Big Five" mass extinctions.

Pangaea’s effect on extinctions on land is thought to have been less significant. In fact, the advance of the therapsids and increase in their diversity is attributed to the late Permian, when Pangaea’s global effect was thought to have peaked.

While Pangaea’s formation is known to have initiated a long period of marine life extinction, the significance of its impact on the "Great Dying" and the end of the Permian is uncertain.

A hypothesis published in 2014 posits that a genus of anaerobic methanogenic archaea known as "Methanosarcina" was responsible for the event. Three lines of evidence suggest that these microbes acquired a new metabolic pathway via gene transfer at about that time, enabling them to efficiently metabolize acetate into methane. That would have led to their exponential reproduction, allowing them to rapidly consume vast deposits of organic carbon that had accumulated in the marine sediment. The result would have been a sharp buildup of methane and carbon dioxide in the Earth's oceans and atmosphere, in a manner that may be consistent with the C/C isotopic record. Massive volcanism facilitated this process by releasing large amounts of nickel, a scarce metal which is a cofactor for an enzymes involved in producing methane. On the other hand, in the canonical Meishan sections, the nickel concentration increases somewhat after the concentrations have begun to fall.

Possible causes supported by strong evidence appear to describe a sequence of catastrophes, each worse than the last: the Siberian Traps eruptions were bad enough alone, but because they occurred near coal beds and the continental shelf, they also triggered very large releases of carbon dioxide and methane. The resultant global warming may have caused perhaps the most severe anoxic event in the oceans' history: according to this theory, the oceans became so anoxic, anaerobic sulfur-reducing organisms dominated the chemistry of the oceans and caused massive emissions of toxic hydrogen sulfide.

However, there may be some weak links in this chain of events: the changes in the C/C ratio expected to result from a massive release of methane do not match the patterns seen throughout the early Triassic; and the types of oceanic thermohaline circulation that may have existed at the end of the Permian are not likely to have supported deep-sea anoxia.




</doc>
<doc id="24750" url="https://en.wikipedia.org/wiki?curid=24750" title="Porter Blanchard">
Porter Blanchard

Porter George Blanchard (1886–1973) was an American silversmith living and working in Pacoima, California. He is considered to be part of the Arts and Crafts Movement.

Blanchard learned the trade of the silversmith from his father, George Porter Blanchard in Gardner, Massachusetts. In 1923, Blanchard moved to Burbank, California, where he established a studio for silversmithing. Between the 1930s and 1950, he operated a shop in Hollywood. He then worked from his home in Pacoima from the 1940s until his death in 1973.

His daughter Alice Blanchard married Lewis Wise, who conducted business as Porter Blanchard Silversmiths in Calabasas, California. After 1955, all Porter Blanchard flatware was made at the Calabasas shop, while the holloware was made at Blanchard's Pacoima home. His daughter Rebecca married Allan Adler, who continued designing as a silversmith in the Arts and Crafts tradition.

Blanchard was a member of the Boston Society of Arts and Crafts and was awarded their title of medalist in 1944.

Many of his papers, including photographs of his shop, are collected in the Archives of American Art at the Smithsonian Institution in Washington, D.C. They were donated to the Archives by his daughters, Rebecca Adler and Alice E. Wise.

Blanchard's works are in the collections of various museums, including the Cooper-Hewitt National Design Museum, the Los Angeles County Museum of Art, and the Oakland Museum of California.




</doc>
<doc id="24751" url="https://en.wikipedia.org/wiki?curid=24751" title="Punjab, Pakistan">
Punjab, Pakistan

Punjab (Urdu, Punjabi: , "panj-āb", "five waters": ) is Pakistan's second largest province by area, after Balochistan, and its most populous province, with an estimated population of 110,012,442 as of 2017. It is bordered by the Pakistan provinces of Sindh, Balochistan, and Khyber Pakhtunkhwa, the enclave of Islamabad, and Azad Kashmir. It also shares borders with the Indian states of Punjab, Rajasthan and Jammu and Kashmir. The provincial capital of Punjab is the city Lahore, a cultural, historical, economic and cosmopolitan centre of Pakistan where the country's cinema industry, and much of its fashion industry, are based.

Punjab has been inhabited since ancient times. The Indus Valley Civilization, dating to 2600 BCE, was first discovered at Harappa. Punjab features heavily in the Hindu epic poem, the Mahabharata, and is home to Taxila, site of what is considered by many to be the oldest university in the world. In 326 BCE, Alexander the Great defeated King Porus at the Battle of the Hydaspes near Mong, Punjab. The Umayyad empire conquered Punjab in the 8th century CE. Punjab was later invaded by Tamerlane, Babur, and Nader Shah. Punjab reached the height of its splendour during the reign of the Mughal Empire, which for a time ruled from Lahore. Following a successful rebellion, Sikh-led armies claimed Lahore in 1759. The administration of the Sikh Empire was based out of Lahore, until its defeat by the British. Punjab was central to the independence movements of both India and Pakistan, with Lahore being site of both the Declaration of Indian Independence, and the resolution calling for the establishment of Pakistan. The province was formed when the Punjab province of British India was divided along religious boundaries in 1947 by the Radcliffe Line after Partition.

Punjab is Pakistan's most industrialised province with the industrial sector making up 24% of the province's gross domestic product. Punjab is known in Pakistan for its relative prosperity, and has the lowest rate of poverty amongst all Pakistani provinces. A clear divide is present between the northern and southern portions of the province; with poverty rates in prosperous northern Punjab amongst the lowest in Pakistan, while some in south Punjab are amongst the most impoverished. Punjab is also one of South Asia's most urbanized regions with approximately 40% of people living in urban areas. Its human development index rankings are high relative to the rest of Pakistan.
Punjab is known in Pakistan for its relatively liberal social attitudes. The province has been strongly influenced by Sufism, with numerous Sufi shrines spread across Punjab which attract millions of devotees annually. The founder of the Sikh faith, Guru Nanak, was born in the Punjab town of Nankana Sahib near Lahore. Punjab is also the site of the Katasraj Temple, which features prominently in Hindu mythology. Several UNESCO World Heritage Sites are located in Punjab, including the Shalimar Gardens, the Lahore Fort, the archeological excavations at Taxila, and the Rohtas Fort.

The region was originally called Sapta Sindhu, the Vedic land of the seven rivers flowing into the ocean. The Sanskrit name for the region, as mentioned in the Ramayana and Mahabharata for example, was "Panchanada" which means "Land of the Five Rivers", and was translated to Persian as "Punjab" after the Muslim conquests. The region was known to the Greeks as "Pentapotamia", meaning the region of five rivers. The word "Punjab" was formally introduced in the early 17th century CE as an elision of the Persian words "panj" ("five") and "āb" ("water"), thus meaning the (land of) "five rivers", similar in meaning to the Sanskrit and Greek name for the region. The five rivers, namely Chenab, Jhelum, Ravi, Beas and Sutlej, flow via the Panjnad River into the Indus River and eventually into the Arabian Sea. Of the five great rivers of Punjab, four course through Pakistan's Punjab province.

Due to its location, the Punjab region came under constant attack and witnessed centuries of foreign invasions by the Persians, Greeks, Kushans, Scythians, Turks and Afghans. The northwestern part of South Asia, including Punjab, was repeatedly invaded or conquered by various foreign empires, including those of Tamerlane, Alexander the Great, and Genghis Khan.

Soanian culture first flourished in the soan valley of northern Punjab.Tools up to two million years old have been recovered in potohar plateau. In the Soan River, many fossil bearing rocks are exposed on the surface. 14 million year old fossils of gazelle, rhinoceros, crocodile, giraffe and rodents have been found there.
Punjab during Mahabharata times was known as Panchanada. Punjab was part of the Indus Valley Civilization, more than 4000 years ago.
The main site in Punjab was the city of Harrapa. The Indus Valley Civilization spanned much of what is today Pakistan and eventually evolved into the Indo-Aryan civilization. The Vedic civilisation flourished along the length of the Indus River. This civilization shaped subsequent cultures in South Asia and Afghanistan. Although the archaeological site at Harappa was partially damaged in 1857 when engineers constructing the Lahore-Multan railroad used brick from the Harappa ruins for track ballast, an abundance of artefacts have nevertheless been found. Punjab was part of the great ancient empires including the Gandhara Mahajanapadas, Achaemenids, Macedonians, Mauryas, Kushans, Guptas and Hindu Shahi. It also comprised the Gujar empire for a period of time, otherwise known as the Gurjara-Pratihara empire. Agriculture flourished and trading cities (such as Multan and Lahore) grew in wealth.
The city of Taxila, founded by son of Taksh the son Bharat who was the brother of Ram. It was reputed to house the oldest university in the world, Takshashila University. One of the teachers was the great Vedic thinker and politician Chanakya. Taxila was a great centre of learning and intellectual discussion during the Maurya Empire. It is a UN World Heritage site, valued for its archaeological and religious history.

Gandhāra was an ancient kingdom situated in the northwestern region of Pakistan, in the Peshawar valley and Potohar plateau with its capital at Taxila.Gandhara existed since the time of the Rigveda (c. 1500–1200 BC), as well as the Zoroastrian Avesta, which mentions it as "Vaēkərəta", the sixth most beautiful place on earth, created by Ahura Mazda. Gandhara was conquered by the Achaemenid Empire in the 6th century BC. Conquered by Alexander the Great in 327 BC, it subsequently became part of the Maurya Empire and then the Indo-Greek Kingdom.The name of the Gandhāris is attested in the Rigveda (RV 1.126.7) and in ancient inscriptions dating back to Achaemenid Persia.The primary cities of Gandhara were Puruṣapura (Peshawar), Takṣaśilā (Taxila), and Pushkalavati (Charsadda).
Gandhara's language was a Prakrit or "Middle Indo-Aryan" dialect, usually called Gāndhārī. The language used the Kharosthi script, which died out about the 4th century. However, Punjabi, Kohistani, and Hindko are derived from the Indo-Aryan Prakrits that were spoken in Gandhara and surrounding areas.

The Parthian dynasty fell about 75 to another group from Central Asia. The Kushans, moved from Central Asia to Bactria, where they stayed for a century. Around 75, one of their tribes, the Kushan (Kuṣāṇa), under the leadership of Kujula Kadphises gained control of Gandhara and other parts of what is now Pakistan.The Kushan period is considered the Golden Period of Gandhara. Gandhara's culture peaked during the reign of the great Kushan king Kanishka the Great (128–151). The cities of Taxila (Takṣaśilā) at Sirsukh and Peshawar were built.Kanishka was a great patron of the Buddhist faith; Buddhism spread to Central Asia and the Far East across Bactria and Sogdia, where his empire met the Han Empire of China. Buddhist art spread from Gandhara to other parts of Asia. Under Kanishka, Gandhara became a holy land of Buddhism and attracted Chinese pilgrims eager to view the monuments associated with many Jatakas.The Hephthalite Huns captured Gandhara around 451, and did not adopt Buddhism, but in fact "perpetrated frightful massacres." Mihirakula became a "terrible persecutor" of the Buddhist religion. During their rule, Hinduism revived itself and the Buddhist Gandharan civilization declined.

The Achaemenid Persian empire included Pujab west of the Indus.

Having conquered Drangiana, Arachosia, Gedrosia and Seistan in ten days, Alexander the Great (locally known as 'Iskander') crossed the Hindu Kush and was thus fully informed of the magnificence of the country and its riches in gold, gems and pearls. However, Alexander had to encounter and reduce the tribes on the border of Punjab before entering the luxuriant plains. Having taken a northeasterly direction, he marched against the Aspii (mountaineers), who offered vigorous resistance, but were subdued. Alexander then marched through Ghazni, blockaded Magassa, and then marched to Ora and Bazira. Turning to the northeast, Alexander marched to Pucela, the capital of the district now known as Pakhli. He entered Western Punjab, where the ancient city of Nysa (at the site of modern-day Mong) was situated. A coalition was formed against Alexander by the Cathians, the people of Multan, who were very skilful in war. Alexander invested many troops, eventually killing seventeen thousand Cathians in this battle, and the city of Sagala (present-day Sialkot) was razed to the ground. Alexander left Punjab in 326 B.C. and took his army to the heartlands of his empire.

The Indo-Greek Kingdom or Graeco-Indian Kingdom was a Hellenistic kingdom covering most of the Punjab.The kingdom was founded when the Graeco-Bactrian king Demetrius invaded the subcontinent early in the 2nd century BC.The city of Sirkap founded by Demetrius combines Greek and Indian influences without signs of segregation between the two cultures.
The most famous Indo-Greek ruler was Menander (Milinda).He had his capital at Sakala in the Punjab (present-day Sialkot).The Indo-Greeks were involved with local faiths, particularly with Buddhism, but also with Hinduism'.Buddhism flourished under the Indo-Greek kings, and their rule, especially that of Menander, has been remembered as benevolent.

The Indo-Scythian king Maues invaded Indo-Greek territories in Punjab and established an Indo-Scythian empire. Maues first conquered Gandhara and Taxila around 80 BCE, but his kingdom disintegrated after his death. The Indo-Scythians ultimately established a kingdom in the northwest south Asia, based near Taxila, with two great Satraps, one in Mathura in the east, and one in Surastrene (Gujarat) in the southwest. The Indo-Scythians seem to have been followers of Buddhism, and many of their practices apparently continued those of the Indo-Greeks.

The Indo-Parthian Kingdom was ruled by the Gondopharid dynasty with its capital at Taxila ,Punjab.
Gondophares, founder of Indo Parthia kingdom, was a ruler of Seistan in what is today eastern Iran, probably a vassal or relative of the Apracarajas. Around 20–10 BCE, he made conquests in the former Indo-Scythian kingdom, perhaps after the death of the important ruler Azes. Gondophares became the ruler of areas comprising Arachosia, Seistan, Sindh, Punjab, and the Kabul valley.
The temple of Jandial, Taxila is usually interpreted as a Zoroastrian fire temple from the period of the Indo-Parthians.

The Punjabis followed a diverse plethora of faiths, mainly comprising Hinduism, when the Muslim Umayyad army led by Muhammad bin Qasim conquered Sindh and Southern Punjab in 712, by defeating Raja Dahir. The Umayyad Caliphate was the second Arab, Islamic caliphate established after the death of Muhammad. It was ruled by the Umayyad dynasty, whose name derives from Umayya ibn Abd Shams, the great-grandfather of the first Umayyad caliph. Although the Umayyad family originally came from the city of Mecca, their capital was Damascus. Muhammad bin Qasim was the first to bring message of Islam to the population of Punjab.
Punjab was part of different Muslim Empires consisting of Afghans and Turkic peoples in co-operation with local Punjabi tribes and others. In the 11th century, during the reign of Mahmud of Ghazni, the province became an important centre, with Lahore as its second capital of the Ghaznavid Empire based out of Afghanistan. The Punjab region became predominantly Muslim due to missionary Sufi saints whose dargahs dot the landscape of Punjab region.

The area subsequently came under various other Muslim rulers until finally becoming part of the Mughal Empire in 1526.

The Punjab region rose to significance in the Hindustani empire when Lahore became a seat for royal family in 1584, the legacy of which is seen today in its rich display of Mughal architecture.

The Mughals controlled the region from 1524 until around 1739 and implemented building projects such as the Shalimar Gardens and the Badshahi Mosque, both situated in Lahore. Padshah (emperor) Akbar established two of his original twelve subahs (imperial top-level provinces) in Punjab : 
Muslim soldiers, traders, architects, theologians and Sufis (Muslim mystics) came from the rest of the Muslim world to the Islamic Sultanate in South Asia.

Swaths of what is now Punjab were annexed by the Afghan conqueror Ahmad Shah Durrani in 1747 as he made the Punjab a part of his Durrani Empire, lasting until 1762.

In 1758 Raghunath Rao, the general of the Hindu Maratha Empire, conquered Lahore and Attock. Timur Shah Durrani, the son and viceroy of Duranni Monarch Ahmad Shah Abdali, was driven out of Punjab. Lahore, Multan, Dera Ghazi Khan, Kashmir and other subahs (ex-Mughal provinces) on the south and eastern side of Peshawar were under the Maratha rule for the most part. In Punjab and Kashmir, the Marathas were now major players. The Third Battle of Panipat took place on 1761, Ahmad Shah Abdali invaded the Maratha territory of Punjab and captured remnants of the Maratha Empire in Punjab and Kashmir regions and re-consolidated control over them.

In the mid-fifteenth century, the religion of Sikhism was born. During the Mughal empire, many Hindus increasingly adopted Sikhism. These became a formidable military force against the Mughals and later against the Afghan Empire. After fighting Ahmad Shah Durrani in the later eighteenth century, the Sikhs took control of Punjab and managed to establish the Sikh Empire under Maharaja Ranjit Singh, which lasted from 1799 to 1849. The capital of Ranjit Singh's empire was Lahore, and the empire also extended into Afghanistan and Kashmir. Bhangi Misl was the first Sikh band to conquer Lahore and other towns of Punjab. Syed Ahmad Barelvi a Muslim, waged jihad and attempted to create an Islamic state with strict enforcement of Islamic law. Syed Ahmad Barelvi in 1821 with many supporters and spent two years organising popular and material support for his Punjab campaign. He carefully developed a network of people through the length and breadth of India to collect funds and encourage volunteers, travelling widely throughout India attracting a following among pious Muslims. In December 1826 Sayyid Ahmad and his followers clashed with Sikh troops at Akora Khattak, but with no decisive result. In a major battle near the town of Balakot in 1831, Sayyid Ahmad and Shah Ismail Shaheed with volunteer Muslims were defeated by the professional Sikh Army.

Maharaja Ranjit Singh's death in the summer of 1839 brought political chaos and the subsequent battles of succession and the bloody infighting between the factions at court weakened the state. Relationships with neighbouring British territories then broke down, starting the First Anglo-Sikh War; this led to a British official being resident in Lahore and the annexation in 1849 of territory south of the Satluj to British India. After the Second Anglo-Sikh War in 1849, the Sikh Empire became the last territory to be merged into British India. In Jhelum 35 British soldiers of the HM XXIV regiment were killed by the local resistance during the Indian Rebellion of 1857.

In 1947 the Punjab province of British India was divided along religious lines into West Punjab and East Punjab. Western Punjab was assimilated into the new country of Pakistan, while East Punjab became a part of modern-day India. This led to massive rioting as both sides committed atrocities against fleeing refugees.

The part of the Punjab now in Pakistan once formed a major region of British Punjab, and was home to a large minority population of Punjabi Sikhs and Hindus up to 1947 apart from the Muslim majority.

Migration between Eastern and Western Punjab was continuous before independence. By the 1900s Western Punjab was predominantly Muslim and supported the Muslim League and Pakistan Movement. After independence, the minority Hindus and Sikhs migrated to India while Muslim refugees from India settled in the Western Punjab and across Pakistan.

Since the 1950s, Punjab industrialised rapidly. New factories were established in Lahore, Sargodha, Multan, Gujrat, Gujranwala, Sialkot and Wah. In the 1960s the new city of Islamabad north of Rawalpindi.

Agriculture continues to be the largest sector of Punjab's economy. The province is the breadbasket of the country as well as home to the largest ethnic group in Pakistan, the Punjabis. Unlike neighbouring India, there was no large-scale redistribution of agricultural land. As a result, most rural areas are dominated by a small set of feudalistic land-owning families.

In the 1950s there was tension between the eastern and western halves of Pakistan. To address the situation, a new formula resulted in the abolition of the province status for Punjab in 1955. It was merged into a single province West Pakistan. In 1972, after East Pakistan seceded and became Bangladesh, Punjab again became a province.

Punjab witnessed major battles between the armies of India and Pakistan in the wars of 1965 and 1971. Since the 1990s Punjab hosted several key sites of Pakistan's nuclear program such as Kahuta. It also hosts major military bases such as at Sargodha and Rawalpindi. The peace process between India and Pakistan, which began in earnest in 2004, has helped pacify the situation. Trade and people-to-people contacts through the Wagah border are now starting to become common. Indian Sikh pilgrims visit holy sites such as Nankana Sahib.

Starting in the 1980s, large numbers of Punjabis migrated to the Middle East, Britain, Spain, Canada and the United States for economic opportunities, forming the large Punjabi diaspora. Business and cultural ties between the United States and Punjab are growing.

Punjab is Pakistan's second largest province by area after Balochistan with an area of . It occupies 25.8% of the total landmass of Pakistan. Punjab province is bordered by Sindh to the south, the province of Balochistan to the southwest, the province of Khyber Pakhtunkhwa to the west, and the Islamabad Capital Territory and Azad Kashmir in the north. Punjab borders Jammu and Kashmir in the north, and the Indian states of Punjab and Rajasthan to the east.

The capital and largest city is Lahore which was the historical capital of the wider Punjab region. Other important cities include Faisalabad, Rawalpindi, Gujranwala, Sargodha, Multan, Sialkot, Bahawalpur, Gujrat, Sheikhupura, Jhelum and Sahiwal. The undivided Punjab region was home to six rivers, of which five flow through Pakistan's Punjab province. From west to east, the rivers are: the Indus, Jhelum, Beas, Chenab, Ravi and Sutlej. Nearly 60% of Pakistan's population lives in the Punjab. It is the nation's only province that touches every other province; it also surrounds the federal enclave of the national capital city at Islamabad. In the acronym "P-A-K-I-S-T-A-N", the P is for "Punjab".

Punjab's landscape consists mostly consists of fertile alluvial plains of the Indus River and its four major tributaries in Pakistan, the Jhelum, Chenab, Ravi, and Sutlej rivers which traverse Punjab north to south – the fifth of the "five waters" of Punjab, the Beas River, lies exclusively in the Indian state of Punjab. The landscape is amongst the most heavily irrigated on earth and canals can be found throughout the province. Punjab also includes several mountainous regions, including the Sulaiman Mountains in the southwest part of the province, the Margalla Hills in the north near Islamabad, and the Salt Range which divides the most northerly portion of Punjab, the Pothohar Plateau, from the rest of the province. Sparse deserts can be found in southern Punjab near the border with Rajasthan and near the Sulaiman Range. Punjab also contains part of the Thal and Cholistan deserts. In the South, Punjab's elevation reaches near the hill station of Fort Munro in Dera Ghazi Khan.

Most areas in Punjab experience extreme weather with foggy winters, often accompanied by rain. By mid-February the temperature begins to rise; springtime weather continues until mid-April, when the summer heat sets in.

The onset of the southwest monsoon is anticipated to reach Punjab by May, but since the early 1970s the weather pattern has been irregular. The spring monsoon has either skipped over the area or has caused it to rain so hard that floods have resulted. June and July are oppressively hot. Although official estimates rarely place the temperature above 46 °C, newspaper sources claim that it reaches 51 °C and regularly carry reports about people who have succumbed to the heat. Heat records were broken in Multan in June 1993, when the mercury was reported to have risen to 54 °C. In August the oppressive heat is punctuated by the rainy season, referred to as "barsat", which brings relief in its wake. The hardest part of the summer is then over, but cooler weather does not come until late October.

Recently the province experienced one of the coldest winters in the last 70 years.

Punjab's region temperature ranges from −2° to 45 °C, but can reach 50 °C (122 °F) in summer and can touch down to −10 °C in winter.

Climatically, Punjab has three major seasons:


Weather extremes are notable from the hot and barren south to the cool hills of the north. The foothills of the Himalayas are found in the extreme north as well, and feature a much cooler and wetter climate, with snowfall common at higher altitudes.

The province is home to over half the population of Pakistan. Punjabis are a heterogeneous group comprising different tribes, clans () and communities. In Pakistani Punjab, non-tribal social distinctions are primarily based on traditional occupations such as blacksmiths or artisans, as opposed to rigid social stratifications.

Punjab has the lowest poverty rates in Pakistan, although a divide is present between the northern and southern parts of the province. Sialkot District in the prosperous northern part of the province has a poverty rate of 5.63%, while Rajanpur District in the poorer south has a poverty rate of 60.05%.

The major and native language spoken in the Punjab is Punjabi (which is written in a Shahmukhi script in Pakistan) and Punjabis comprise the largest ethnic group in country. Punjabi is the provincial language of Punjab, but is not given any official recognition in the Constitution of Pakistan at the national level.

Saraiki is mostly spoken in south Punjab, and Pashto, spoken in some parts of north west Punjab, especially in Attock District and Mianwali District near Khyber Pakhtunkhwa province.
The use of Urdu and English as the near exclusive languages of broadcasting, the public sector, and formal education have led some to fear that Punjabi in Pakistan is being relegated to a low-status language and that it is being denied an environment where it can flourish. Several prominent educational leaders, researchers, and social commentators have echoed the opinion that the intentional promotion of Urdu and the continued denial of any official sanction or recognition of the Punjabi language amounts to a process of "Urdu-isation" that is detrimental to the health of the Punjabi language In August 2015, the Pakistan Academy of Letters, International Writer’s Council (IWC) and World Punjabi Congress (WPC) organised the "Khawaja Farid Conference" and demanded that a Punjabi-language university should be established in Lahore and that Punjabi language should be declared as the medium of instruction at the primary level. In September 2015, a case was filed in Supreme Court of Pakistan against Government of Punjab, Pakistan as it did not take any step to implement the Punjabi language in the province. Additionally, several thousand Punjabis gather in Lahore every year on International Mother Language Day.

Hafiz Saeed, chief of Jama'at-ud-Da'wah (JuD) has questioned Pakistan's decision to adopt Urdu as its national language in a country where majority of people speak Punjabi language, citing his interpretation of Islamic doctrine as encouraging education in the mother-tongue. The list of thinktanks, political organisations, cultural projects, and individuals that demand authorities at the national and provincial level to promote the use of the language in the public and official spheres includes:

The population of Punjab (Pakistan) is estimated to be 97.21% Muslim with a Sunni Hanafi majority and Shia Ithna 'ashariyah minority. The largest non-Muslim minority is Christians and make up 2.31% of the population. The other minorities include Ahmadiyya, Hindus, Sikhs, Parsis and Bahá'í.

The Government of Punjab is a provincial government in the federal structure of Pakistan, is based in Lahore, the capital of the Punjab Province. The Chief Minister of Punjab (CM) is elected by the Provincial Assembly of the Punjab to serve as the head of the provincial government in Punjab, Pakistan. The current Chief Minister is Shahbaz Sharif, who became the Chief Minister of Punjab as being restored after Governor's rule starting from 25 February 2009 to 30 March 2009. Thereafter got re-elected as a result of 11 May 2013 elections. The Provincial Assembly of the Punjab is a unicameral legislature of elected representatives of the province of Punjab, which is located in Lahore in eastern Pakistan. The Assembly was established under Article 106 of the Constitution of Pakistan as having a total of 371 seats, with 66 seats reserved for women and eight reserved for non-Muslims.

There are 48 departments in Punjab government. Each Department is headed by a Provincial Minister (Politician) and a Provincial Secretary (A civil servant of usually BPS-20 or BPS-21). All Ministers report to the Chief Minister, who is the Chief Executive. All Secretaries report to the Chief Secretary of Punjab, who is usually a BPS-22 Civil Servant. The Chief Secretary in turn reports to the Chief Minister. In addition to these departments, there are several Autonomous Bodies and Attached Departments that report directly to either the Secretaries or the Chief Secretary.

When the divisions were restored as a tier of government in 2008, a tenth division – Sheikhupura Division – was created from part of Lahore Division.

Punjab has the largest economy in Pakistan, contributing most to the national GDP. The province's economy has quadrupled since 1972. Its share of Pakistan's GDP was 54.7% in 2000 and 59% as of 2010. It is especially dominant in the service and agriculture sectors of Pakistan's economy. With its contribution ranging from 52.1% to 64.5% in the Service Sector and 56.1% to 61.5% in the agriculture sector. It is also major manpower contributor because it has largest pool of professionals and highly skilled (technically trained) manpower in Pakistan. It is also dominant in the manufacturing sector, though the dominance is not as huge, with historical contributions raging from a low of 44% to a high of 52.6%. In 2007, Punjab achieved a growth rate of 7.8% and during the period 2002–03 to 2007–08, its economy grew at a rate of between 7% to 8% per year. and during 2008–09 grew at 6% against the total GDP growth of Pakistan at 4%.

Despite the lack of a coastline, Punjab is the most industrialised province of Pakistan; its manufacturing industries produce textiles, sports goods, heavy machinery, electrical appliances, surgical instruments, vehicles, auto parts, metals, sugar mill plants, aircraft, cement, agricultural machinery, bicycles and rickshaws, floor coverings, and processed foods. In 2003, the province manufactured 90% of the paper and paper boards, 71% of the fertilizers, 69% of the sugar and 40% of the cement of Pakistan.

Despite its tropical wet and dry climate, extensive irrigation makes it a rich agricultural region. Its canal-irrigation system established by the British is the largest in the world. Wheat and cotton are the largest crops. Other crops include rice, sugarcane, millet, corn, oilseeds, pulses, vegetables, and fruits such as kinoo. Livestock and poultry production are also important. Despite past animosities, the rural masses in Punjab's farms continue to use the Hindu calendar for planting and harvesting.

Punjab contributes about 76% to annual food grain production in the country. Cotton and rice are important crops. They are the cash crops that contribute substantially to the national exchequer. Attaining self-sufficiency in agriculture has shifted the focus of the strategies towards small and medium farming, stress on barani areas, farms-to-market roads, electrification for tube-wells and control of water logging and salinity.

Punjab has also more than 68 thousand industrial units. There are 39,033 small and cottage industrial units. The number of textile units is 14,820. The ginning industries are 6,778. There are 7,355 units for processing of agricultural raw materials including food and feed industries.

Lahore and Gujranwala Divisions have the largest concentration of small light engineering units. The district of Sialkot excels in sports goods, surgical instruments and cutlery goods.

Punjab is also a mineral-rich province with extensive mineral deposits of coal, iron, gas, petrol, rock salt (with the second largest salt mine in the world), dolomite, gypsum, and silica-sand. The Punjab Mineral Development Corporation is running over a hundred economically viable projects. Manufacturing includes machine products, cement, plastics, and various other goods.

The incidence of poverty differs between the different regions of Punjab. With Northern and Central Punjab facing much lower levels of poverty than Western and Southern Punjab. Those living in Southern and Western Punjab are also a lot more dependent on agriculture due to lower levels of industrialisation in those regions.

, Pakistan's electricity problems were so severe that violent riots were taking place across Punjab. According to protesters, load shedding was depriving the cities of electricity 20–22 hours a day, causing businesses to go bust and making living extremely hard. Gujranwala, Toba Tek Singh, Faisalabad, Sialkot, Bahawalnagar and communities across Khanewal District saw widespread rioting and violence on Sunday 17 June 2012, with the houses of several members of parliament being attacked as well as the offices of regional energy suppliers Fesco, Gepco and Mepco being ransacked or attacked.

The literacy rate has increased greatly over the last 40 years (see the table below). Punjab has the highest Human Development Index out of all of Pakistan's provinces at 0.670.

Sources:

This is a chart of the education market of Punjab estimated by the government in 1998.



Punjab has been the cradle of civilisation since times immemorial. The ruins of Harappa show an advanced urban culture that flourished over 8000 years ago. Ancient Taxila, another historic landmark also stands out as a proof of the achievements of the area in learning, arts and crafts. The ancient Hindu Katasraj temple and the Salt Range temples are regaining attention and much-needed repair.

The structure of a mosque is simple and it expresses openness. Calligraphic inscriptions from the Quran decorate mosques and mausoleums in Punjab. The inscriptions on bricks and tiles of the mausoleum of Shah Rukn-e-Alam (1320 AD) at Multan are outstanding specimens of architectural calligraphy. The earliest existing building in South Asia with enamelled tile-work is the tomb of Shah Yusuf Gardezi (1150 AD) at Multan. A specimen of the sixteenth century tile-work at Lahore is the tomb of Sheikh Musa Ahangar, with its brilliant blue dome. The tile-work of Emperor Shah Jahan is of a richer and more elaborate nature. The pictured wall of Lahore Fort is the last line in the tile-work in the entire world.

The culture of Punjab derives its basis from the institution of Sufi saints, who spread Islam and preached and lived the Muslim way of life. People have festivities to commemorate these traditions. The fairs and festivals of Punjab reflect the entire gamut of its folk life and cultural traditions. These mainly fall in the following categories:

Religious fairs are held on special days of Islamic significance like Eid ul-Adha, Eid-ul-Fitr, Eid-e-Milad-un-Nabi, Shahb-e-Barat, Ashura, Laylat al-Qadr and Jumu'ah-tul-Wida. The main activities on these special occasions are confined to congregational prayers and rituals. Melas are also held to mark these occasions.

The fairs held at the shrines of Sufi saints are called urs. They generally mark the death anniversary of the saint. On these occasions devotees assemble in large numbers and pay homage to the memory of the saint. Soul inspiring music is played and devotees dance in ecstasy. The music on these occasions is essentially folk and appealing. It forms a part of the folk music through mystic messages. The most important urs are: urs of Data Ganj Buksh at Lahore, urs of Hazrat Sultan Bahu at Jhang, urs of Hazrat Shah Jewna at Jhang, urs of Hazrat Mian Mir at Lahore, urs of Baba Farid Ganj Shakar at Pakpattan, urs of Hazrat Bahaudin Zakria at Multan, urs of Sakhi Sarwar Sultan at Dera Ghazi Khan, urs of Shah Hussain at Lahore, urs of Hazrat Bulleh Shah at Kasur, urs of Hazrat Imam Bari (Bari Shah Latif) at Rawalpindi-Islamabad and urs of Shah Inayat Qadri (the murrshad of Bulleh Shah) in Lahore.

A big fair/mela is organised at Jandiala Sher Khan in district Sheikhupura on the mausoleum of Syed Waris Shah who is the most loved Sufi poet of Punjab due to his classic work, Heer Ranjha. The shrine of Heer Ranjha in Jhang is one of the most visited shrines in Punjab.
Exhibitions and annual horse shows in all districts and a national horse and cattle show at Lahore are held with the official patronage. The national horse and cattle show at Lahore is the biggest festival where sports, exhibitions, and livestock competitions are held. It not only encourages and patronises agricultural products and livestock through the exhibitions of agricultural products and cattle but is also a colourful documentary on the rich cultural heritage of the province with its strong rural roots.

Vaisakhi, also called Besakhi, is a harvest festival to celebrate harvesting the wheat crop. Colourful festivals are held at the time of Besakhi when farmers are free to enjoy their leisure time. Various literary festivals and fairs are organised in many places. 
Basant is a seasonal festival and is celebrated as a spring festival of kites. The day is marked by wearing yellow, eating food with yellow colouring such as potatoes with turmeric and saffron rice, and holding parties.

The crafts in the Punjab are of two types: the crafts produced in the rural areas and the royal crafts.

The province is home to several historical sites, including the Shalimar Gardens, the Lahore Fort, the Badshahi Mosque, the Rohtas Fort and the ruins of the ancient city of Harrapa. The Anarkali Market and Jahangir's Tomb are prominent in the city of Lahore as is the Lahore Museum, while the ancient city of Taxila in the northwest was once a major centre of Buddhist and Hindu influence. Several important Sikh shrines are in the province, including the birthplace of the first Guru, Guru Nanak. (born at Nankana Sahib). There are a few famous hill stations, including Murree, Bhurban, Patriata and Fort Munro.

Katasraj Mandir is a Hindu temple complex situated in Katas village near Choa Saidanshah in the Chakwal district. Dedicated to Shiva, the temple has, according to Hindu legend, existed since the days of Mahābhārata and the Pandava brothers spent a substantial part of their exile at the site and later Krishna himself laid the foundation of this temple.

The Khewra Salt Mine is a tourist attraction. Tours are accompanied by guides as the mine itself is very large and the complex interconnected passages are like a maze. There is a small but beautiful mosque inside the mine made from salt stone. A clinical ward with 20 beds was established in 2007 for the treatment of asthma and other respiratory diseases using salt therapy.

Classical music forms, such as Pakistani classical music, are an important part of the cultural wealth of the Punjab. The Muslim musicians have contributed a large number of ragas to the repository of classical music. The most common instruments used are the tabla and harmonium.

Among the Punjabi poets, the names of Sultan Bahu, Bulleh Shah, Mian Muhammad Baksh, and Waris Shah and folk singers like Inayat Hussain Bhatti and Tufail Niazi, Alam Lohar, Sain Marna, Mansoor Malangi, Allah Ditta Lonawala, Talib Hussain Dard, Attaullah Khan Essa Khailwi, Gamoo Tahliwala, Mamzoo Gha-lla, Akbar Jat, Arif Lohar, Ahmad Nawaz Cheena and Hamid Ali Bela are well-known. In the composition of classical ragas, there are such masters as "Malika-i-Mauseequi" (Queen of Music) Roshan Ara Begum, Ustad Amanat Ali Khan, Salamat Ali Khan and Ustad Fateh Ali Khan. Alam Lohar has made significant contributions to folklore and Punjabi literature, by being a very influential Punjabi folk singer from 1930 until 1979.

For the popular taste however, light music, particularly Ghazals and folk songs, which have an appeal of their own, the names of Mehdi Hassan, Ghulam Ali, Nur Jehan, Malika Pukhraj, Farida Khanum, Roshen Ara Begum, and Nusrat Fateh Ali Khan are well-known. Folk songs and dances of the Punjab reflect a wide range of moods: the rains, sowing and harvesting seasons. Luddi, Bhangra and Sammi depict the joy of living. Love legends of Heer Ranjha, Mirza Sahiban, Sohni Mahenwal and Saiful Mulk are sung in different styles.

For the most popular music from the region, bhangra, the names of Abrar-Ul-Haq, Arif Lohar, Attaullah Khan Essa Khailwi, Jawad Ahmed, Sajjad Ali, Legacy, and Malkoo are renowned.

Folklore songs, ballads, epics and romances are generally written and sung in the various Punjabi dialects.

There are a number of folk tales that are popular in different parts of the Punjab. These are the folk tales of Mirza Sahiban, Sayful Muluk, Yusuf Zulekha, Heer Ranjha, Sohni Mahiwal, Dulla Bhatti, and Sassi Punnun.
The mystic folk songs include the "Kafees" of Khwaja Farid in Saraiki, Punjabi and the "Shalooks" by Baba Farid. They also include "Baits", "Dohas", "Lohris", "Sehra", and "Jugni".

The most famous of the romantic love songs are "Mayhiah", "Dhola" and "Boliyan". Punjabi romantic dances include Dharees, Dhamaal, Bhangra, Giddha, Dhola, and Sammi.

One social/educational issue is the status of Punjabi language. According to Manzur Ejaz, "In Central Punjab, Punjabi is neither an official language of the province nor it is used as medium of education at any level. There are only two daily newspapers published in Punjabi in the Central areas of Punjab. Only a few monthly literary magazines constitute Punjabi press in Pakistan".





</doc>
<doc id="24752" url="https://en.wikipedia.org/wiki?curid=24752" title="Politburo">
Politburo

A politburo () or political bureau is the executive committee for communist parties.

The term "politburo" in English comes from the Russian "Politbyuro" (), itself a contraction of "Politicheskoye Byuro" (, "Political Bureau"). The Spanish term "Politburó" is directly loaned from Russian, as is the German "Politbüro". Chinese uses a calque (), from which the Vietnamese (), and Korean ( "Jeongchiguk") terms derive.

The first politburo was created in Russia by the Bolshevik Party in 1917 to provide strong and continuous leadership during the Russian Revolution occurring during the same year. The first Politburo had seven members: Lenin, Zinoviev, Kamenev, Trotsky, Stalin, Sokolnikov, and Bubnov. During the 20th century, nations that had a politburo included the USSR, East Germany, Afghanistan, Czechoslovakia and China, amongst others. Today, there are five countries that have a politburo system (China, North Korea, Laos, Vietnam, and Cuba).

In socialist states, the party is seen as the vanguard of the people and from that legitimizes itself to lead the state. In that way, the party officials in the Politburo informally lead the state.

Officially, the Party Congress elects a Central Committee which, in turn, elects the Politburo and General Secretary in a process termed democratic centralism. The Politburo was theoretically answerable to the Central Committee. Under Stalin this model was reversed, and it was the General Secretary who determined the composition of the Politburo and Central Committee. This tendency decreased to some extent after Stalin's death, though in practice the Politburo remained a self-perpetuating body whose decisions de facto had the force of law.

In Trotskyist parties, the Politburo is a bureau of the Central Committee tasked with making day-to-day political decisions, which must later be ratified by the Central Committee. It is appointed by the Central Committee from among its members. The post of General Secretary carries far less weight in this model. See, for example, the Lanka Sama Samaja Party.



</doc>
<doc id="24755" url="https://en.wikipedia.org/wiki?curid=24755" title="Pope Julius II">
Pope Julius II

Pope Julius II (; ) (5 December 1443 – 21 February 1513), born Giuliano della Rovere, and nicknamed "The Fearsome Pope" and "The Warrior Pope". During his nine-year pontificate his military and diplomatic interventions averted a take-over by France of the Italian States (including the Papal States). He also proved a bulwark against Venetian expansionism. His spiritual leadership was less impressive. The quintessential "Renaissance pope", Julius' rule from 1 November 1503 to his death in 1513 was marked by an active foreign policy, ambitious building projects, and patronage of the arts. He commissioned the rebuilding of St. Peter's Basilica, and Michelangelo's decoration of the ceiling of the Sistine Chapel. His discerning eye in hiring the artist Raphael as a young man brought numerous improvements to the Vatican.

Giuliano della Rovere was born at Albisola, near Savona in the Republic of Genoa. He was of a noble but impoverished family, the son of Raffaelo della Rovere. and Theodora Manerola, a lady of Greek ancestry. He had three brothers: Bartolomeo, a Franciscan friar who then became Bishop of Ferrara (1474–1494); Leonardo; and Giovanni, Prefect of the City of Rome (1475–1501) and Prince of Sorea and Senigallia. He also had a sister, Lucina (later the mother of Cardinal Sisto Gara della Rovere). Giuliano was educated by his uncle, Fr. Francesco della Rovere, O.F.M. among the Franciscans, who took him under his special charge. He was later sent by this same uncle (who by that time had become Minister General of the Franciscans (1464–1469)), to the Franciscan friary in Perugia, where he could study the sciences at the University.

Della Rovere, as a young man, showed traits of being rough, coarse and given to bad language. During the late 1490s he became more closely acquainted with Cardinal Medici and nephew (both relatives), and the two dynasties became uneasy allies in the context of papal politics. Both houses desired an end to the occupation of Italian lands by the armies of France. He seemed less enthused by theology; rather Strathern argues his imagined heroes were military leaders such as Frederic Colonna.

After his uncle was elected Pope Sixtus IV on 10 August 1471, Giuliano was appointed Bishop of Carpentras in the Comtat Venaissin on 16 October 1471. In an act of literal nepotism he was immediately raised to the cardinalate on 16 December 1471, and assigned the same titular church as that formerly held by his uncle, San Pietro in Vincoli. Guilty of serial simony and pluralism he held several powerful offices at once: in addition to the archbishopric of Avignon he held no fewer than eight bishoprics, including Lausanne from 1472, and Coutances (1476–1477).

In 1474, Giuliano led an army to Todi, Spoleto, and Città di Castello as papal legate. He returned to Rome in May, in the company of Duke Federigo of Urbino, who promised his daughter in marriage to Giuliano's brother Giovanni, who was subsequently named Lord of Senigallia and of Mondovì. On 22 December 1475, Pope Sixtus IV created the new Archdiocese of Avignon, assigning to it as suffragan dioceses the Sees of Vaison, Cavaillon, and Carpentras. He appointed Giuliano as the first archbishop. Giuliano held the archdiocese until his later election to the papacy. In 1476 the office of Legate was added, and he left Rome for France in February. On 22 August 1476 he founded the "Collegium de Ruvere" in Avignon. He returned to Rome on 4 October 1476.

In 1479, Cardinal Giuliano served his one-year term as Chamberlain of the College of Cardinals. In this office he was responsible for collecting all the revenues owed to the cardinals as a group (from "ad limina" visits, for example) and for the proper disbursements of appropriate shares to cardinals who were in service in the Roman Curia.

Giuliano was again named Papal Legate to France on 28 April 1480, and left Rome on June 9. As Legate, his mission was threefold: to make peace between King Louis XI and the Emperor Maximilian of Austria; to raise funds for a war against the Ottoman Turks; and to negotiate the release of Cardinal Jean Balue and Bishop Guillaume d'Harancourt (who by then had been imprisoned by Louis for eleven years on charges of treason). He reached Paris in September, and finally, on 20 December 1480, Louis gave orders that Balue be handed over to the Archpriest of Loudun, who had been commissioned by the Legate to receive him in the name of the Pope. He returned to Rome on 3 February 1482. Shortly thereafter the sum of 300,000 ecus of gold was received from the French in subsidy of the war.

On 31 January 1483 Cardinal della Rovere was promoted suburbicarian Bishop of Ostia, in succession to Cardinal Guillaume d'Estouteville who had died on January 22. It was the privilege of the Bishop of Ostia to consecrate an elected pope a bishop, if he were not already a bishop. This actually occurred in the case of Pius III (Francesco Todeschini-Piccolomini), who was ordained a priest on 30 September 1503 and consecrated a bishop on 1 October 1503 by Cardinal Giuliano della Rovere.

Around this time, in 1483, an illegitimate daughter was born, Felice della Rovere.

On 3 November 1483, Cardinal della Rovere was named Bishop of Bologna and Papal Legate, succeeding Cardinal Francesco Gonzaga, who had died on 21 October. He held the diocese until 1502. On 28 December 1484, Giuliano participated in the investiture of his brother Giovanni as Captain-General of the Papal Armies by Pope Innocent VIII.

By 1484 Giuliano was living in the new palazzo which he had constructed next to the Basilica of the Twelve Apostles, which he had also restored. Pope Sixtus IV paid a formal visit to the newly restored building on 1 May 1482, and it may be that Giuliano was already in residence then.

Sixtus IV died on 12 August 1484 and was succeeded by Innocent VIII. After the ceremonies of the election of Pope Innocent were completed, the cardinals were dismissed to their own homes, but Cardinal della Rovere accompanied the new Pope to the Vatican Palace, and was the only one to remain with him. Ludwig Pastor quotes the Florentine ambassador as remarking, "[Pope Innocent] gives the impression of a man who is guided rather by the advice of others than by his own lights." The ambassador of Ferrara stated, "While with his uncle [Della Rovere] had not the slightest influence, he now obtains whatever he likes from the new Pope." Della Rovere was one of the five cardinals named to the committee to make the arrangements for the Coronation.

In 1485 Pope Innocent and Cardinal della Rovere (as the Pope's new principal advisor), decided to involve themselves in the political affairs of the Kingdom of Naples, in what was called the "Conspiracy of the Barons". On Palm Sunday, 20 March, Cardinal della Rovere, concealing his activities from his principal rival, Cardinal Rodrigo Borgia (later Pope Alexander VI), rode out of Rome and took ship at Ostia, intending to head for Genoa and Avignon to prepare to wage war between the Church and the King of Naples, Ferdinand I (Ferrante). On 28 June the Pope sent back to Naples the token gift of a palfrey which symbolized the King of Naples' submission, and demanded the full feudal submission of the Kingdom of Naples to the Roman Church according to long-standing tradition. In a second attempt to overthrow the Aragonese monarchy, the Prince of Salerno Antonello II dei Sanseverino, on the advice of Antonello Petrucci and Francesco Coppola, gathered together several feudal families belonging to the Guelph faction and supporting the Angevin claim to Naples. Antonello de Sanseverino was the brother-in-law of Cardinal della Rovere's brother Giovanni, who was a noble of Naples because of his fief of Sora. The principal complaints of the barons were the heavy taxation imposed by Ferdinand to finance his war against the Saracens, who had occupied Bari in 1480; and the vigorous efforts of Ferrante to centralize the administrative apparatus of the kingdom, moving it away from a feudal to a bureaucratic system. The barons seized L'Aquila, and appealed to the Pope for assistance as their feudal overlord. Genoa and Venice supported the Papacy, while Florence and Milan opted for Naples. In Rome the Orsini allied themselves with Ferrante's son Alfonso, and therefore the Colonna supported the Pope in the street fighting that ensued. Ferrante reacted by seizing the fiefs of the barons, and, when the two parties met to negotiate a settlement, Ferrante had them arrested, and eventually executed. The prestige of the della Rovere family was seriously damaged, and in an attempt to exculpate himself Pope Innocent began to withdraw his support for them. Peace was restored in 1487, but Innocent VIII's papacy was discredited.

On 23 March 1486, the pope sent Giuliano as Papal Legate to the Court of King Charles VIII of France to ask for help. A French entourage arrived in Rome on 31 May, but immediately relations broke down with the Pro-Spanish Cardinal Rodrigo. But Ferrante's army decided the pope's humiliation, Innocent backed down and on 10 August signed a treaty. Innocent looked for new allies and settled on the Republic of Florence.

On 2 March 1487, Giuliano was appointed legate in the March of Ancona and to the Republic of Venice. He encouraged trade with the sizeable Turkish community at these ports. But urgent reports arrived from the King of Hungary that the Ottoman Sultan was threatening Italy. He returned on 8 April 1488, and again took up his residence in the Palazzo Colonna next to the Basilica of the XII Apostles.

In the Conclave of 1492, following the death of Innocent VIII, Cardinal della Rovere was supported for election by both King Charles VIII of France and by Charles' enemy King Ferrante of Naples. It was reported that France had deposited 200,000 ducats into a bank account to promote della Rovere's candidature, while the Republic of Genoa had deposited 100,000 ducats to the same end. Della Rovere, however, had enemies, both because of the influence he had exercised over Pope Sixtus IV, and because of his French sympathies. His rivals included Cardinal Ardicio della Porta and Cardinal Ascanio Sforza, both patronised by the Milanese. Kellogg, Baynes & Smith, continue, a "rivalry had, however, gradually grown up between [della Rovere] and [then-Cardinal] Rodrigo Borgia, and on the death of Innocent VIII in 1492 Borgia by means of a secret agreement and simony with Ascanio Sforza succeeded in being elected by a large majority, under the name of Pope Alexander VI." Della Rovere, jealous and angry, accused Borgia of being elected over him.

On 31 August 1492 the new Pope, Alexander VI, held a consistory in which he named six cardinal legates, one of whom was Giuliano della Rovere, who was appointed Legate in Avignon. Cardinal Giuliano was increasingly alarmed by the powerful position assumed by Cardinal Ascanio Sforza and the Milanese faction in the Court of Alexander VI, and after Christmas Day in December 1492 chose to withdraw to his fortress in the town and diocese of Ostia, at the mouth of the Tiber River. In that same month, Federico of Altamura, the second son of King Ferdinando (Ferrante) of Naples was in Rome to pay homage to the new pope, and he reported back to his father that Alexander and Cardinal Sforza were working on establishing new alliances, which would upset Ferrante's security arrangements. Ferrante therefore decided to use Della Rovere as the center of an anti-Sforza party at the papal court, a prospect made easier since Ferrante had prudently repaired his relations with Cardinal Giuliano after the War of the Barons. He also warned King Ferdinand and Queen Isabella of Spain that Alexander was intriguing with the French, which brought an immediate visit of a Spanish ambassador to the Pope. In June Federico of Altamura was back in Rome, and held conversations with Della Rovere, assuring him of Neapolitan protection. On 24 July 1493, Cardinal della Rovere returned to Rome (despite the warnings of Virginius Orsini) and dined with the Pope.

Della Rovere at once determined to take refuge from Borgia's wrath at Ostia. On 23 April 1494, the Cardinal took ship, having placed his fortress at Ostia in the hands of his brother Giovanni della Rovere, and travelled to Genoa and then to Avignon. He was summoned by King Charles VIII to Lyons, where the two met on 1 June 1494. He joined Charles VIII of France who undertook to take Italy back from the Borgias by military force. The King entered Rome with his army on 31 December 1495, with Giuliano della Rovere riding on one side and Cardinal Ascanio Sforza riding on the other. The King made several demands of Pope Alexander, one of which was that the Castel S. Angelo be turned over to French forces. This Pope Alexander refused to do, claiming that Cardinal della Rovere would occupy it and become master of Rome. Charles soon conquered Naples, making his triumphal entry on 22 February 1495, but he was forced to remove most of his army. As he was returning to the north, his army was defeated at the Battle of Foronovo on 5 July 1495, and his Italian adventure came to an end. The last remnants of the French invasion were gone by November 1496. Ostia, however, remained in French hands until March 1497, making difficulties in the provisioning of the city of Rome.

Back in Lyon in 1496, Charles VIII and Giuliano della Rovere were planning another war. Giuliano was travelling back and forth from Lyon to Avignon, raising troops. It was being reported in France by June 1496, moreover, that King Charles intended to have a papal election in France and to have Cardinal della Rovere elected pope.

In March 1497 Pope Alexander deprived Cardinal della Rovere of his benefices as an enemy of the Apostolic See, and Giovanni della Rovere of the Prefecture of Rome. His action against the Cardinal was done not only without the consent of the cardinals in consistory, but in fact over their vigorous objections. By June, however, the Pope was in negotiations with the Cardinal for a reconciliation and return to Rome. His benefices were restored to him after an apparent reconciliation with the Pope in August 1498.

King Charles VIII of France, the last of the senior branch of the House of Valois, died on 7 April 1498 of a self-inflicted blow to the head. When Cesare Borgia passed through southern France in October 1498 on his way to meet King Louis XII for his investiture as Duke of Valentinois, he stopped in Avignon and was magnificently entertained by Cardinal della Rovere. They then moved on to meet the King at Chinon, where Cesare Borgia fulfilled one of the terms of the treaty between Louis and Alexander by producing the red hat of a cardinal, which had been promised for the Archbishop of Rouen, Georges d'Amboise. It was Cardinal della Rovere, the Papal Legate, who placed the hat on Amboise's head. Della Rovere, who was trying to repair his relations with the House of Borgia, was also involved in another clause of the treaty, the marriage between Cesare Borgia and Carlotta, the daughter of the King of Naples, who had been brought up at the French Court. Della Rovere was in favor of the marriage, but, according to Pope Alexander, King Louis XII was not, and, most especially, Carlotta was stubbornly refusing her consent. Alexander's plan of securing a royal throne for his son fell through, and he was very angry.

The marriage produced a complete "volta facie" in Pope Alexander. He became an open partisan of the French and Venice, and accepted their goal, the destruction of the Sforza hold on Milan. On 14 July, Cardinal Ascanio Sforza, della Rovere's sworn enemy, fled Rome with all his property and friends. Meanwhile, the French army crossed the Alps and captured Alessandria in the Piedmont. On 1 September 1499 Lodovico "Il Moro" fled Milan, and on 6 September the city surrendered to the French. Cardinal Giuliano was in the King's entourage when he entered Milan on 6 October.

Pope Alexander then turned his attention, stimulated by the Venetians, to the threat of the Osmanli Turks. In the autumn of 1499 he called for a crusade, and sought aid and money from all Christendom. The rulers of Europe paid little attention, but to show his sincerity Alexander imposed a tithe on all the residents of the Papal States and a tithe on the clergy of the entire world. A list of cardinals and their incomes, drawn up for the occasion, shows that Cardinal della Rovere was the second-richest cardinal, with an annual income of 20,000 ducats.

Another break in relations between Pope Alexander and Cardinal Giuliano came at the end of 1501 or the beginning of 1502, when Giuliano was transferred from the Bishopric of Bologna to the diocese of Vercelli.

On 21 June 1502, Pope Alexander sent his secretary, Francesco Troche (Trochia), and Cardinal Amanieu d'Albret (brother-in-law of Cesare Borgia) to Savona to seize Cardinal della Rovere by stealth and bring him back to Rome as quickly as possible and turn him over to the Pope. The kidnapping party returned to Rome on 12 July, without having accomplished its mission. On 20 July 1502, Cardinal Giovanni Battista Ferrari died in his rooms at the Vatican Palace; he had been poisoned, and his property was claimed by the Borgia. On 3 January 1503, Cardinal Orsini was arrested and sent to the Castel S. Angelo; on 22 February he died there, poisoned on orders of Alexander VI.

A veteran of the Sacred College, della Rovere had won influence for the election of Pope Pius III with the help of Florentine Ambassador to Naples, Lorenzo de' Medici. In spite of a violent temper della Rovere succeeded by dexterous diplomacy in winning the support of Cesare Borgia, whom he won over by his promise of money and continued papal backing for Borgia policies in the Romagna. This election was, in Ludwig von Pastor's view, was certainly achieved by means of bribery with money, but also with promises. "Giuliano, whom the popular voice seemed to indicate as the only possible pope, was as unscrupulous as any of his colleagues in the means which he employed. Where promises and persuasions were unavailing, he did not hesitate to have recourse to bribery." Indeed, his election on 1 November 1503 took only a few hours, and the only two votes he did not receive were his own and the one of Georges d'Amboise, his most vigorous opponent and the favourite of the French monarchy. In the end, as in all papal elections, the vote is made unanimous after the leading candidate has achieved the required number of votes for election.

Giuliano Della Rovere thenceforth took the name of his fourth century predecessor, Julius I, and was pope for nine years, from 1503 to 1513. From the beginning, Julius II set out to defeat the various powers that challenged his temporal authority; in a series of complicated stratagems he first succeeded in rendering it impossible for the Borgias to retain their power over the Papal States. Indeed, on the day of his election, he declared: Others indicate that his decision was taken on 26 November 1507, not in 1503. The Borgia Apartments were turned to other uses. The "Sala dei Papi" was redecorated by two pupils of Raphael by order of Pope Leo X. The rooms were used to accommodate the Emperor Charles V on his visit to the Vatican after the Sack of Rome, and subsequently they became the residence of the Cardinal nephew and then the Secretary of State.

Julius used his influence to reconcile two powerful Roman families, the Orsini and Colonna. Decrees were made in the interests of the Roman nobility, in whose shoes the new pope now stepped. Being thus secure in Rome and the surrounding country, he set himself the task to expel the Republic of Venice from Faenza, Rimini, and the other towns and fortresses of Italy which it occupied after the death of Pope Alexander. In 1504, finding it impossible to succeed with the Doge of Venice by remonstrance, he brought about a union of the conflicting interests of France and the Holy Roman Empire, and sacrificed temporarily to some extent the independence of Italy to conclude with them an offensive and defensive alliance against Venice. The combination was, however, at first little more than nominal, and was not immediately effective in compelling the Venetians to deliver up more than a few unimportant places in the Romagna. With a campaign in 1506, he personally led an army to Perugia and Bologna, freeing the two papal cities from their despots, Giampolo Baglioni and Giovanni II Bentivoglio.

In December 1503, Julius issued a dispensation allowing the future Henry VIII of England to marry Catherine of Aragon; Catherine had previously been briefly married to Henry's older brother Prince Arthur, who had died, but Henry later argued that she had remained a virgin for the five months of the marriage. Some twenty years later, when Henry was attempting to wed Anne Boleyn (since his son by Catherine of Aragon survived only a few days, and two of her sons were stillborn, and therefore he had no male heir), he sought to have his marriage annulled, claiming that the dispensation of Pope Julius should never have been issued. The retractation of the dispensation was refused by Pope Clement VII.

The Bull entitled "Ea quae pro bono pacis" issued on January 24, 1506, confirmed papal approval of the "mare clausum" policy being pursued by Spain and Portugal amid their explorations, and approved the changes of the 1494 Treaty of Tordesillas to previous papal bulls. In the same year, the Pope founded the Swiss Guard to provide a constant corps of soldiers to protect the Vatican City. As part of the Renaissance programme of reestablishing the glory of antiquity for the Christian capital, Rome, Julius II took considerable effort to present himself as a sort of emperor-pope, capable of leading a Latin-Christian empire. On Palm Sunday, 1507, "Julius II entered Rome . . . both as a second Julius Caesar, heir to the majesty of Rome's imperial glory, and in the likeness of Christ, whose vicar the pope was, and who in that capacity governed the universal Roman Church." Julius, who modelled himself after his namesake Caesar, would personally lead his army across the Italian peninsula under the imperial war-cry, "Drive out the barbarians." Yet, despite the imperial rhetoric, the campaigns were highly localised. Perugia voluntarily surrendered in March 1507 to direct control, as it had always been within the Papal States; it was in these endeavors he had enlisted French mercenaries. Urbino's magnificent court palace was infiltrated by French soldiers in the pay of the Duke of Gonzaga; the Montefeltro Conspiracy against his loyal cousins earned the occupying armies the Pope's undying hatred. Julius relied upon Guidobaldo's help to raise his nephew and heir Francesco Maria della Rovere; the intricate web of nepotism helped secure the Italian Papacy. Moreover, the Pope's interest in Urbino was widely known in the French court. Julius left a spy at the Urbino Palace, possibly Galeotto Franciotti della Rovere, Cardinal San Pietro, to watch the Mantua stables in total secret; the secular progress of the Papal Curia was growing in authority and significance. In Rome, the Pope watched from his private chapel to see how his court behaved. This was age of Renaissance conspiracy.

In addition to an active military policy, the new pope personally led troops into battle on at least two occasions, the first to expel Giovanni Bentivoglio from Bologna (17 August 1506 – 23 March 1507), which was achieved successfully with the assistance of the Duchy of Urbino. The second was an attempt to recover Ferrara for the Papal States (1 September 1510 – 29 June 1512). In 1508, Julius was fortuitously able to form the League of Cambrai with Louis XII, King of France, Maximilian I, Holy Roman Emperor, and Ferdinand II, King of Aragon. The League fought against the Republic of Venice. Among other things, Julius wanted possession of Venetian Romagna; Emperor Maximilian I wanted Friuli and Veneto; Louis XII wanted Cremona; and Ferdinand II desired the Apulian ports. This war was a conflict in what was collectively known as the "Italian Wars". In the spring of 1509, the Republic of Venice was placed under an interdict by Julius, In May 1509 Julius sent troops to fight against the Venetians who had occupied parts of the Romagna winning back the Papal States in a decisive battle near Cremona. During the War of the Holy League alliances kept changing: in 1510 Venice and France switched places, and by 1513, Venice had joined France. The achievements of the League soon outstripped the primary intention of Julius. In one single battle, the Battle of Agnadello on 14 May 1509, the dominion of Venice in Italy was practically lost to His Holiness. Yet neither the King of France nor the Holy Roman Emperor were satisfied with merely effecting the purposes of the Pope, the latter found it necessary to enter into an arrangement with the Venetians to defend himself from those who immediately before had been his allies. The Venetians, on making humble submission, were absolved at the beginning of 1510, and shortly afterward France was placed under papal interdict.
Attempts to cause a rupture between France and England proved unsuccessful; on the other hand, at a synod convened by Louis at Tours in September 1510, the French bishops withdrew from papal obedience, and resolved, with the Emperor's co-operation, to seek dethronement of the pope. With some courage Julius marched his army to Bologna and then against the French to Mirandola. In November 1511, a council met at Pisa, called by rebel cardinals with support from the French king and the Empire, they demanded the deposition of Charles II at Pisa. Despite being seriously he refused to shave showing utter contempt for the hated French occupation. "per vendicarsi et diceva...anco fuora scazato el re Ludovico Franza d'Italia."
Whereupon Julius entered into another Holy League of 1511: in alliance with Ferdinand II of Aragon and the Venetians he conspired against the Gallican liberties. In short time, both Henry VIII, King of England (1509–47), and Maximilian I also joined the Holy League of 1511 against France. Louis XII defeated the alliance at Battle of Ravenna on 11 April 1512. When a desperate battle felled over 20,000 men in a bloodbath the Pope commanded his protege, a newly-released young Cardinal Medici to re-take Florence with his Spanish army. The rescue of the city on 1 September 1512 saved Rome from another invasion, ousting Soderini, and returning the dynastic rule of the Medici. Julius had seemingly restored "fortuna" or control by exercising his manly "vertu", just as Machiavelli wrote. This re-asserted strong relations between Florence and Rome; a lasting legacy of Julius II. Yet Machiavelli and his methods would not outlast Julius' Papacy. Julius hired Swiss mercenaries to fight against the French in Milan in May 1512.

When Swiss mercenaries came to the Pope's aid, the French army withdrew across the Alps into Savoy. The papacy gained control of Parma and Piacenza in central Italy, but now Spain took an interest in occupying troops on the peninsula. During the last months of his life, Julius II engaged in negotiations with Ferdinand's diplomats, who obtained from him the ideological back-up necessary for Ferdinand II of Aragon's invasion of Navarre in the form of a number of papal bulls. In 1512 the French were driven across the Alps, but it was at the cost of the occupation of the peninsula by the Pope's enemies. Although Julius had securely established papal authority in the region immediately around Rome, he was as far as ever from realizing his dream of an independent Italian kingdom.

In May 1512 a general or ecumenical council, the Fifth Council of the Lateran, was held in Rome. According to an oath taken on his election to observe the Electoral Capitulations of the Conclave of October 1513, Julius had sworn to summon a general council, but it had been delayed, he affirmed, because of the occupation of Italy by his enemies. The real stimulus came from a false council which took place in 1511, called the "Conciliabulum Pisanum", inspired by Louis XII and Maximilian I as a tactic to weaken Julius, and which threatened Julius II with deposition. Julius' reply was the issuing of the bull "Non sini gravi" of 18 July 1511, which fixed the date of 19 April 1512 for the opening of his own council. The Council actually convened on 3 May, and Paris de Grassis reports that the crowd at the basilica was estimated at 50,000. It held its first working session on 10 May. In the third plenary session, on 3 December 1512, Julius attended, though he was ill; but he wanted to witness and receive the formal adhesion of the Emperor Maximilian to the Lateran Council and his repudiation of the "Conciliabulum Pisanum". This was one of Julius' great triumphs. The Pope was again in attendance at the fourth session on 10 December, this time to hear the accrediting of the Venetian Ambassador as the Serene Republic's representative at the Council; he then had the letter of King Louis XI (of 27 November 1461), in which he announced the revocation of the Pragmatic Sanction, read out to the assembly, and demanded that all persons who accepted the Pragmatic Sanction appear before the Council within sixty days to justify their conduct. This was directed against King Louis XII.

The fifth session was held on 16 February, but Pope Julius was too ill to attend. Cardinal Raffaele Riario, the Dean of the College of Cardinals and Bishop of Ostia, presided. The Bishop of Como, Scaramuccia Trivulzio, then read from the pulpit a bull of Pope Julius, "Si summus rerum", dated that very day and containing within its text the complete bull of 14 January 1505, "Cum tam divino". The bull was submitted to the Council fathers for their consideration and ratification. Julius wanted to remind everyone of his legislation on papal conclaves, in particular against Simony, and to fix his regulations firmly in canon law so that they could not be dispensed or ignored. Julius was fully aware that his death was imminent, and though he had been a witness to a good deal of Simony at papal conclaves and had been a practitioner himself, he was determined to stamp out the abuse. The reading of the bull "Cum tam divino" became a regular feature of the first day of every conclave.

On the Vigil of Pentecost in May 1512, Pope Julius, aware that he was seriously ill and that his health was failing, despite comments on the part of some cardinals about how well he looked, remarked to Paris de Grassis, "They are flattering me; I know better; my strength diminishes from day to day and I cannot live much longer. Therefore I beg you not to expect me at Vespers or at Mass from henceforth." Nonetheless he continued his restless activities, including Masses, visits to churches, and audiences. On 24 June, in the morning Paris found the Pope "debilem et semifebricantem". On Christmas Eve, Julius ordered Paris to summon the College of Cardinals and the Sacristan of the Apostolic Palace, "quia erat sic infirmus, quod non speraret posse diu supravivere." From then until 6 January he was confined to bed, and most of the time with a fever; he had lost his appetite, but the doctors were unable to diagnose his languor. On 4 February he had an extensive conversation with Paris concerning the arrangements for his funeral.

Pope Julius was reported to be seriously ill in a dispatch received in Venice on 10 February 1513. He received Holy Communion and was granted the plenary indulgence on the morning of 19 February, according to the Venetian Ambassador. On the 20th, according to Paris de Grassis, he received Holy Communion from the hands of Cardinal Raffaele Riario, the Camerlengo. He died of a fever in the night of 20–21 February 1513.

In the evening of 21 February, Paris de Grassis conducted the funeral of Julius II, even though the Canons of the Vatican Basilica and the beneficiati refused to cooperate. The body was placed for a time at the Altar of Saint Andrew in the Basilica, and was then carried by the Imperial Ambassador, the papal Datary, and two of Paris' assistants to the altar of the Chapel of Pope Sixtus, where the Vicar of the Vatican Basilica performed the final absolution. At the third hour of the evening the body was laid in a sepulcher between the altar and the wall of the tribune.

Despite the fact that the so-called "Tomb of Julius" by Michelangelo is in San Pietro in Vincoli in Rome, Julius is in fact buried in the Vatican. Michelangelo's tomb was not completed until 1545 and represents a much abbreviated version of the planned original, which was initially intended for the new St. Peter's Basilica. His remains lay alongside his uncle, Pope Sixtus IV, but were later desecrated during the Sack of Rome in 1527. Today both men lie in St. Peter's Basilica in the floor in front of the monument to Pope Clement X. A simple marble tombstone marks the site. Julius II was succeeded by Pope Leo X.

In 1484 Cardinal Giuliano della Rovere had begun negotiations to persuade Marquis Francesco Gonzaga of Mantua to allow Andrea Mantegna to come to Rome, which finally bore fruit in 1488; Mantegna was given the commission to decorate the chapel of the Belvedere for Pope Innocent VIII, on which he spent two years.

Beyond Julius II's political and military achievements, he enjoys a title to honor in his patronage of art, architecture, and literature. He did much to improve and beautify the city.

Early in his papacy, Julius decided to revive the plan for replacing the dilpidated Constantianian basilica of St. Peter's. The idea was not his, but originally that of Nicholas V, who had commissioned designs from Bernardo Rossellino. Other more pressing problems distracted the attention of Nicholas and subsequent popes, but Julius was not the sort of person to be distracted once he had settled on an idea, in this case, for the greatest building on earth, for the glory of Saint Peter and himself. In the competition for a building plan, the design of Rossellino was immediately rejected as being out of date. A second design was submitted by Giuliano da Sangallo, an old friend of Julius, who had worked on several projects for him before, including the palazzo at S. Pietro in Vincoli, and who had left Rome with Julius when he fled the wrath of Alexander VI in 1495. Through Cardinal della Rovere, Sangallo had presented Charles VIII a plan for a palace, and in 1496 he had made a tour of the architectural monuments of Provence, returning to his native Florence in 1497. His proposals for S. Peter's, however, were not accepted despite what he believed to be a promise, and he retired in anger to Florence.

On 18 April 1506 Pope Julius II laid the foundation stone of the new St. Peter's Basilica for the successful architect, Donato Bramante. However, he also began the demolition of the old St. Peter's Basilica, which had stood for more than 1,100 years. He was a friend and patron of Bramante and Raphael, and a patron of Michelangelo. Several of Michelangelo's greatest works (including the painting of the ceiling of the Sistine Chapel) were commissioned by Julius.

Pope Julius long before he became pope had a violent temper. He often treated subordinates and people who worked for him very badly. His manner was gruff and coarse, just as his peasant-like sense of humour. Others suggest that Julius had little sense of humor. Ludwig von Pastor wrote, "Paris de Grassis, his Master of Ceremonies, who has handed on to us so many characteristic features of his master's life, says that he hardly ever jested. He was generally absorbed in deep and silent thought..."

To most historians Julius was manly and virile, an energetic man of action, whose courage saved the Papacy. There was a sense that war caused him serious illness, exhaustion and fatigue, that most popes could not have withstood. To many Julius II has been described as the best in an era of exceptionally bad popes: Alexander VI was evil and despotic, exposing the future Julius II to a number of assassination attempts that required tremendous fortitude.

Julius II is usually depicted with a beard, after his appearance in the celebrated portrait by Raphael, the artist whom he first met in 1509. However, the pope only wore his beard from 27 June 1511 to March 1512, as a sign of mourning at the loss of the city of Bologna by the Papal States. He was nevertheless the first pope since antiquity to grow facial hair, a practice otherwise forbidden by canon law since the 13th century. The pope's hirsute chin may have raised severe, even vulgar criticism, as at one Bologna banquet held on 1510 at which papal legate Marco Cornaro was present. In overturning the ban on beards Pope Julius challenged Gregorian conventional wisdom in dangerous times. Julius shaved his beard again before his death, and his immediate successors were clean-shaven; nonetheless Pope Clement VII sported a beard when mourning the sack of Rome. Thenceforward, all popes were bearded until the death of Pope Innocent XII in 1700.

The frescoes on the ceiling of Stanza d'Eliodoro in the stanze of Raphael depict the traumatic events in 1510-11, when the Papacy regained its freedom. Although Raphael's original was lost, it was thought to relate closely to the personal iconography of Stanza della Segnatura, commissioned by Pope Julius himself. The Lateran Council that formed the Holy League marked a high point in his personal success. Saved by an allegory to the Expulsion of Helidorus, the French gone, Julius collapsed once again in late 1512, very seriously ill once more.

Julius was not the first pope to have fathered children before being elevated to high office, and is believed to have had a daughter born to Lucrezia Normanni in 1483 - after he had been made a cardinal. Felice della Rovere survived into adulthood. Shortly after Felice was born, Julius arranged for Lucrezia to marry Bernardino de Cupis, Chamberlain to Julius's cousin, Cardinal Girolamo Basso della Rovere.

Despite producing an illegitimate daughter (and having at least one mistress), it was suggested that Julius may have had homosexual lovers - although there is little evidence that the pope was ever sexually active. His confrontational style inevitably created enemies and sodomy was the "common currency of insult and innuendo". Such accusations were made to discredit him, but perhaps in so doing his accusers were attacking a perceived weakness. The Venetians, who were implacably opposed to the pope's new military policy, were among the most vociferous opponents; notable among them was diarist Girolamo Priuli, and the historian Marino Sanudo. Erasmus also impropriated sexual misconduct in his 1514 dialogues ""Julius Excluded from Heaven""; a theme picked up in the denunciation made at the conciliabulum of Pisa. Criticism was furthermore made of the sinister influence exerted by his advisor, Francesco Alidosi, whom Julius had made a cardinal in 1505. However, it is likely that the closeness was down to the fact that he simply knew how to handle him well. This sexual reputation survived Julius, and the accusation continued to be made without reservation by Protestant opponents in their polemics against "papism" and Catholic decadence. The French writer Philippe de Mornay (1549-1623) accused all Italians of being sodomites, but added specifically: "This horror is ascribed to good Julius."





 

 


</doc>
<doc id="24759" url="https://en.wikipedia.org/wiki?curid=24759" title="Proteus">
Proteus

In Greek mythology, Proteus (; Ancient Greek: Πρωτεύς) is an early sea-god or god of rivers and oceanic bodies of water, one of several deities whom Homer calls the "Old Man of the Sea". Some who ascribe to him a specific domain call him the god of "elusive sea change", which suggests the constantly changing nature of the sea or the liquid quality of water in general. He can foretell the future, but, in a mytheme familiar to several cultures, will change his shape to avoid having to; he will answer only to someone who is capable of capturing the beast. From this feature of Proteus comes the adjective protean, with the general meaning of "versatile", "mutable", "capable of assuming many forms". "Protean" has positive connotations of flexibility, versatility and adaptability.

Proteus' name suggests the "first" (from Greek "πρῶτος" "protos", "first"), as "protogonos" (πρωτόγονος) is the "primordial" or the "firstborn". It is not certain to what this refers, but in myths where he is the son of Poseidon, it possibly refers to his being Poseidon's eldest son, older than Poseidon's other son, the sea-god Triton. The first attestation of the name, although it is not certain whether it refers to the god or just a person, is in Mycenaean Greek; the attested form, in Linear B, is , "po-ro-te-u".

According to Homer ("Odyssey" iv:412), the sandy island of Pharos situated off the coast of the Nile Delta was the home of Proteus, the oracular Old Man of the Sea and herdsman of the sea-beasts. In the "Odyssey", Menelaus relates to Telemachus that he had been becalmed here on his journey home from the Trojan War. He learned from Proteus' daughter Eidothea ("the very image of the Goddess"), that if he could capture her father, he could force him to reveal which of the gods he had offended and how he could propitiate them and return home. Proteus emerged from the sea to sleep among his colony of seals, but Menelaus was successful in holding him, though Proteus took the forms of a lion, a serpent, a leopard, a pig, even of water or a tree. Proteus then answered truthfully, further informing Menelaus that his brother Agamemnon had been murdered on his return home, that Ajax the Lesser had been shipwrecked and killed, and that Odysseus was stranded on Calypso's Isle Ogygia.

According to Virgil in the fourth Georgic, at one time the bees of Aristaeus, son of Apollo, all died of a disease. Aristaeus went to his mother, Cyrene, for help; she told him that Proteus could tell him how to prevent another such disaster, but would do so only if compelled. Aristaeus had to seize Proteus and hold him, no matter what he would change into. Aristaeus did so, and Proteus eventually gave up and told him that the bees' death was a punishment for causing the death of Eurydice. To make amends, Aristaeus needed to sacrifice 12 animals to the gods, leave the carcasses in the place of sacrifice, and return three days later. He followed these instructions, and upon returning, he found in one of the carcasses a swarm of bees which he took to his apiary. The bees were never again troubled by disease.

The children of Proteus, besides Eidothea, include Polygonus and Telegonus, who both challenged Heracles at the behest of Hera and were killed, one of Heracles' many successful encounters with representatives of the pre-Olympian world order.

Another Proteus occurs in Greek myth as one of the fifty sons of King Aegyptus. There are also legends concerning Apollonius of Tyana that say Proteus incarnated himself as the 1st century philosopher. These legends are mentioned in the 3rd century biographical work "Life of Apollonius of Tyana".

In the "Odyssey" (iv.430ff) Menelaus wrestles with "Proteus of Egypt, the immortal old man of the sea who never lies, who sounds the deep in all its depths, Poseidon's servant" (Robert Fagles's translation). Proteus of Egypt is mentioned in an alternative version of the story of Helen of Troy in the tragedy "Helen" of Euripides (produced in 412 BC). The often unconventional playwright introduces a "real" Helen and a "phantom" Helen (who caused the Trojan War), and gives a backstory that makes the father of his character Theoclymenus, Proteus, a king in Egypt who had been wed to a Nereid Psamathe. In keeping with one of his themes in "Helen", Euripides mentions in passing "Eido" ("image"), a daughter of the king and therefore sister of Theoclymenus who underwent a name-change after her adolescence and became "Theonoë," "god-minded," since she was as it turned out capable of foreseeing the future--as such, she is a prophet who appears as a crucial character in the play. The play's king Proteus is already dead at the start of the action, and his tomb is present onstage. It appears that he is only marginally related to the "Old Man of the Sea" and should not be confused with the sea god Proteus, although it is tempting to see Euripides as playing a complex literary game with the sea god's history--both Proteuses, for example, are protectors of the house of Menelaus, both are connected with the sea, both dwell in Egypt, and both are "grandfatherly" or "ancient" figures.

At Pharos a king of Egypt named Proteus welcomed the young god Dionysus in his wanderings. In Hellenistic times, Pharos was the site of the Lighthouse of Alexandria, one of the seven wonders of the ancient world.

The German mystical alchemist Heinrich Khunrath wrote of the shape-changing sea-god who, because of his relationship to the sea, is both a symbol of the unconscious as well as the perfection of the art. Alluding to the "scintilla", the spark from ‘the light of nature’ and symbol of the "anima mundi", Khunrath in Gnostic vein stated of the Protean element Mercury:
In modern times, the Swiss psychologist Carl Jung defined the mythological figure of Proteus as a personification of the unconscious, who, because of his gift of prophecy and shape-changing, has much in common with the central but elusive figure of alchemy, Mercurius.

The poet John Milton, aware of the association of Proteus with the Hermetic art of alchemy, wrote in "Paradise Lost" of alchemists who sought the philosopher's stone:
In his 1658 discourse "The Garden of Cyrus", Sir Thomas Browne, pursuing the figure of the quincunx, queried:
"Why Proteus in Homer the Symbole of the first matter, before he settled himself in the midst of his Sea-Monsters, doth place them out by fives?"

Shakespeare uses the image of Proteus to establish the character of his great royal villain Richard III in the play "Henry VI, Part Three", in which the future usurper boasts:
Shakespeare also names one of the main characters of his play "The Two Gentlemen of Verona" Proteus. Inconsistent with his affections, his deceptions have unraveled at the finale of the play as he is brought face-to-face with his friend Valentine and original love Julia:
In 1807, William Wordsworth finished his sonnet on the theme of a modernity deadened to Nature, which opens "The world is too much with us", with a sense of nostalgia for the lost richness of a world numinous with deities: 
In James Joyce's "Ulysses", uses Protean transformations of matter in time for self exploration. "Proteus" is the title provided for the third chapter in the Linati schema for Ulysses.

The protagonist of Kurt Vonnegut's 1952 novel "Player Piano" is an engineer named Paul Proteus.

"Proteus" is the name of the submarine in the original story by Otto Klement and Jay Lewis Bixby, which became the basis for the 1966 film "Fantastic Voyage" and Isaac Asimov's novelization.

John Barth's novelette "Menelaiad" in "Lost in the Funhouse" is built around a battle between Proteus and Menelaus. It is told as a multiply-nested frame tale, and the narrators bleed into each other as the battle undermines their identities.

"Proteus: The City" is the title of Book Four of Thomas Wolfe's autobiographical novel "Of Time and the River".

As a concept and as a word, Proteus is not a commonly used term today, but has been adopted by some companies to be an interesting concept for the basis of their business names, ranging from healthcare to industrial supplies all the way to sports nutrition and supplementation.

In medicine, Proteus syndrome refers to a rare genetic condition characterized by symmetric overgrowth of the bones, skin, and other tissues. Organs and tissues affected by the disease grow out of proportion to the rest of the body. This condition is associated with mutations of the PTEN gene. Proteus also refers to a genus of Gram-negative Proteobacteria, some of which are opportunistic human pathogens known to cause urinary tract infections, most notably. "Proteus mirabilis" is one of these and is most referenced in its tendency to produce "stag-horn" calculi composed of struvite (magnesium ammonium phosphate) that fill the human renal pelvis.





</doc>
<doc id="24760" url="https://en.wikipedia.org/wiki?curid=24760" title="Pope Eusebius">
Pope Eusebius

Pope Eusebius (from Greek Εὐσέβιος "pious"; died 17 August 310) was the Bishop of Rome from 18 April to his death in 309 or 310.

His pontificate lasted four months, after which, in consequence of disturbances within the Church which led to acts of violence, he was banished by the emperor Maxentius, who had been the ruler of Rome since 306, and had at first shown himself friendly to the Christians. The difficulty arose, as in the case of his predecessor Pope Marcellus I, out of his attitude toward the lapsi.

Eusebius maintained the attitude of the Roman Church, adopted after the Decian persecutions (250-51), that the apostates should not be forever debarred from ecclesiastical communion, but on the other hand, should be readmitted only after doing proper penance. This view was opposed by a faction of Christians in Rome under the leadership of one Heraclius. Johann Peter Kirsch believes it likely that Heraclius was the chief of a party made up of apostates and their followers, who demanded immediate restoration to the Church. Maxentius exiled them both.

Eusebius died in exile in Sicily and was buried in the catacomb of Callixtus. Pope Damasus I placed an epitaph of eight hexameters over his tomb because of his firm defense of ecclesiastical discipline and the banishment which he suffered thereby.

His feast is celebrated on 26 September.




</doc>
<doc id="24761" url="https://en.wikipedia.org/wiki?curid=24761" title="Persian Gulf">
Persian Gulf

The Persian Gulf (), () is a mediterranean sea in Western Asia. The body of water is an extension of the Indian Ocean (Gulf of Oman) through the Strait of Hormuz and lies between Iran to the northeast and the Arabian Peninsula to the southwest. The Shatt al-Arab river delta forms the northwest shoreline.

The Persian Gulf was a battlefield of the 1980–1988 Iran–Iraq War, in which each side attacked the other's oil tankers. It is the namesake of the 1991 Gulf War, the largely air- and land-based conflict that followed Iraq's invasion of Kuwait.

The gulf has many fishing grounds, extensive reefs (mostly rocky, but also coral), and abundant pearl oysters, but its ecology has been damaged by industrialization and oil spills.

The body of water is historically and internationally known as the "Persian Gulf". Some Arab governments refer to it as the "Arabian Gulf" () or "The Gulf", but neither term is recognized internationally. The name "Gulf of Iran (Persian Gulf)" is used by the International Hydrographic Organization.

The Persian Gulf is geologically very young, having been formed around 15,000 years ago.

This inland sea of some is connected to the Gulf of Oman in the east by the Strait of Hormuz; and its western end is marked by the major river delta of the Shatt al-Arab, which carries the waters of the Euphrates and the Tigris. Its length is , with Iran covering most of the northern coast and Saudi Arabia most of the southern coast. The Persian Gulf is about wide at its narrowest, in the Strait of Hormuz. The waters are overall very shallow, with a maximum depth of and an average depth of .

Countries with a coastline on the Persian Gulf are (clockwise, from the north): Iran; Oman's Musandam exclave; the United Arab Emirates; Saudi Arabia (in Iran this is called "Arvand Rood", where "Rood" means "river"); Qatar, on a peninsula off the Saudi coast; Bahrain, on an island; Kuwait; and Iraq in the northwest. Various small islands also lie within the Persian Gulf, some of which are the subject of territorial disputes between the states of the region.

The International Hydrographic Organization defines the Persian Gulf's southern limit as "The Northwestern limit of Gulf of Oman". This limit is defined as "A line joining Ràs Limah (25°57'N) on the coast of Arabia and Ràs al Kuh (25°48'N) on the coast of Iran (Persia)".

The gulf is connected to Indian Ocean through Strait of Hormuz. Writing the water balance budget for the Persian Gulf, the inputs are river discharges from Iran and Iraq (estimated to be 2000 cubic meters per second), as well as precipitation over the sea which is around 180mm/year in Qeshm Island. The evaporation of the sea is high, so that after considering river discharge and rain contributions, there is still a deficit of 416 cubic kilometers per year. This difference is supplied by currents at the Strait of Hormuz. The water from the Gulf has a higher salinity, and therefore exits from the bottom of the Strait, while ocean water with less salinity flows in through the top. Another study revealed the following numbers for water exchanges for the Gulf: evaporation = -1.84m/year, precipitation = 0.08m/year, inflow from the Strait = 33.66m/year, outflow from the Strait = -32.11m/year, and the balance is 0m/year. Data from different 3D computational fluid mechanics models, typically with spatial resolution of 3 kilometers and depth each element equal to 1–10 meters are predominantly used in computer models.

The Persian Gulf and its coastal areas are the world's largest single source of crude oil, and related industries dominate the region. Safaniya Oil Field, the world's largest offshore oilfield, is located in the Persian Gulf. Large gas finds have also been made, with Qatar and Iran sharing a giant field across the territorial median line (North Field in the Qatari sector; South Pars Field in the Iranian sector). Using this gas, Qatar has built up a substantial liquefied natural gas (LNG) and petrochemical industry.

In 2002, the Persian Gulf nations of Bahrain, Iran, Iraq, Kuwait, Qatar, Saudi Arabia, and the UAE produced about 25% of the world's oil, held nearly two-thirds of the world's crude oil reserves, and about 35% of the world's natural gas reserves. The oil-rich countries (excluding Iraq) that have a coastline on the Persian Gulf are referred to as the "Persian Gulf States". Iraq's egress to the gulf is narrow and easily blockaded consisting of the marshy river delta of the Shatt al-Arab, which carries the waters of the Euphrates and the Tigris rivers, where the east bank is held by Iran.

In 550 BC, the Achaemenid Empire established the first ancient empire in Persis ("Pars", or modern "Fars"), in the southwestern region of the Iranian plateau. Consequently, in the Greek sources, the body of water that bordered this province came to be known as the "Persian Gulf".

During the years 550 to 330 BC, coinciding with the sovereignty of the Achaemenid Persian Empire over the Middle East area, especially the whole part of the Persian Gulf and some parts of the Arabian Peninsula, the name of "Pars Sea" is widely found in the compiled written texts.

In the travel account of Pythagoras, several chapters are related to description of his travels accompanied by the Achaemenid king Darius the Great, to Susa and Persepolis, and the area is described. From among the writings of others in the same period, there is the inscription and engraving of Darius the Great, installed at junction of waters of Red Sea and the Nile river and the Rome river (current Mediterranean) which belongs to the 5th century BC where Darius the Great has named the Persian Gulf Water Channel: "Pars Sea" ("Persian Sea").

Considering the historical background of the name Persian Gulf, Sir Arnold Wilson mentions in a book published in 1928 that "no water channel has been so significant as Persian Gulf to the geologists, archaeologists, geographers, merchants, politicians, excursionists, and scholars whether in past or in present. This water channel which separates the Iran Plateau from the Arabia Plate, has enjoyed an Iranian Identity since at least 2200 years ago."

Before being given its present name, the Persian Gulf was called many different names. The classical Greek writers, like Herodotus, called it "the Red Sea". In Babylonian texts, it was known as "the sea above Akkad".

The name of the gulf, historically and internationally known as the Persian Gulf after the land of Persia (Iran), has been disputed by some Arab countries since the 1960s. Rivalry between Iran and some Arab states, along with the emergence of pan-Arabism and Arab nationalism, has seen the name "Arabian Gulf" become predominant in most Arab countries. Names beyond these two have also been applied to or proposed for this body of water.

Earliest evidence of human presence on Persian Gulf islands dates back to Middle Paleolithic and consist of stone tools discovered at Qeshm Island.The world's oldest known civilization (Sumer) developed along the Persian Gulf and southern Mesopotamia. The shallow basin that now underlies the Gulf was an extensive region of river valley and wetlands during the transition between the end of the Last Glacial Maximum and the start of the Holocene, which, according to University of Birmingham archaeologist Jeffrey Rose, served as an environmental refuge for early humans during periodic hyperarid climate oscillations, laying the foundations for the legend of Dilmun.

For most of the early history of the settlements in the Persian Gulf, the southern shores were ruled by a series of nomadic tribes. During the end of the fourth millennium BC, the southern part of the Persian Gulf was dominated by the Dilmun civilization. For a long time the most important settlement on the southern coast of the Persian Gulf was Gerrha. In the 2nd century the Lakhum tribe, who lived in what is now Yemen, migrated north and founded the Lakhmid Kingdom along the southern coast. Occasional ancient battles took place along the Persian Gulf coastlines, between the Sassanid Persian empire and the Lakhmid Kingdom, the most prominent of which was the invasion led by Shapur II against the Lakhmids, leading to Lakhmids' defeat, and advancement into Arabia, along the southern shore lines. During the 7th century the Sassanid Persian empire conquered the whole of the Persian Gulf, including southern and northern shores.

Between 625 BC and 226 AD, the northern side was dominated by a succession of Persian empires including the Median, Achaemenid, Seleucid and Parthian empires. Under the leadership of the Achaemenid king Darius the Great (Darius I), Persian ships found their way to the Persian Gulf. Persian naval forces laid the foundation for a strong Persian maritime presence in Persian Gulf, that started with Darius I and existed until the arrival of the British East India Company, and the Royal Navy by mid-19th century AD. Persians were not only stationed on islands of the Persian Gulf, but also had ships often of 100 to 200 capacity patrolling empire's various rivers including Shatt-al-Arab, Tigris, and the Nile in the west, as well as Sind waterway, in India.

The Achaemenid high naval command had established major naval bases located along Shatt al-Arab river, Bahrain, Oman, and Yemen. The Persian fleet would soon not only be used for peacekeeping purposes along the Shatt al-Arab but would also open the door to trade with India via Persian Gulf.

Following the fall of Achaemenid Empire, and after the fall of the Parthian Empire, the Sassanid empire ruled the northern half and at times the southern half of the Persian Gulf. The Persian Gulf, along with the Silk Road, were important trade routes in the Sassanid empire. Many of the trading ports of the Persian empires were located in or around Persian Gulf. Siraf, an ancient Sassanid port that was located on the northern shore of the gulf, located in what is now the Iranian province of Bushehr, is an example of such commercial port. Siraf, was also significant in that it had a flourishing commercial trade with China by the 4th century, having first established connection with the far east in 185 AD.

Portuguese expansion into the Indian Ocean in the early 16th century following Vasco da Gama's voyages of exploration saw them battle the Ottomans up the coast of the Persian Gulf. In 1521, a Portuguese force led by commander Antonio Correia invaded Bahrain to take control of the wealth created by its pearl industry. On April 29, 1602, Shāh Abbās, the Persian emperor of the Safavid Persian Empire expelled the Portuguese from Bahrain, and that date is commemorated as National Persian Gulf day in Iran. With the support of the British fleet, in 1622 'Abbās took the island of Hormuz from the Portuguese; much of the trade was diverted to the town of Bandar 'Abbās, which he had taken from the Portuguese in 1615 and had named after himself. The Persian Gulf was therefore opened by Persians to a flourishing commerce with the Portuguese, Dutch, French, Spanish and the British merchants, who were granted particular privileges.
The Ottoman Empire reasserted itself into Eastern Arabia in 1871. Under military and political pressure from the governor of the Ottoman Vilayet of Baghdad, Midhat Pasha, the ruling Al Thani tribe submitted peacefully to Ottoman rule. The Ottomans were forced to withdraw from the area with the start of World War I and the need for troops in various other frontiers.

In World War II, the Western Allies used Iran as a conduit to transport military and industrial supply to the USSR, through a pathway known historically as the "Persian Corridor". Britain utilized the Persian Gulf as the entry point for the supply chain in order to make use of the Trans-Iranian Railway. The Persian Gulf therefore became a critical maritime path through which the Allies transported equipment to Russia against the Nazi invasion.

From 1763 until 1971, the British Empire maintained varying degrees of political control over some of the Persian Gulf states, including the United Arab Emirates (originally called the Trucial States) and at various times Bahrain, Kuwait, Oman, and Qatar through the British Residency of the Persian Gulf.

The United Kingdom maintains a high profile in the region to date; in 2006 alone, over 1 million British nationals visited Dubai. In 2014, the UK announced it will reestablish a permanent military base, HMS Jufair, in the Persian Gulf, the first since it withdrew from East of Suez in 1971.

The Persian Gulf is home to many small islands. Bahrain, an island in the Persian Gulf, is itself a Persian Gulf Arab state. Geographically the biggest island in the Persian Gulf is Qeshm island located in the Strait of Hormuz and belonging to Iran. Other significant islands in the Persian Gulf include Greater Tunb, Lesser Tunb and Kish administered by Iran, Bubiyan administered by Kuwait, Tarout administered by Saudi Arabia, and Dalma administered by UAE. In recent years, there has also been addition of artificial islands, often created by Arab states such as UAE for commercial reasons or as tourist resorts. Persian Gulf islands are often also historically significant, having been used in the past by colonial powers such as the Portuguese and the British in their trade or as acquisitions for their empires.

Eight nations have coasts along the Persian Gulf: Bahrain, Iran, Iraq, Kuwait, Oman, Qatar, Saudi Arabia, and the United Arab Emirates. The gulf's strategic location has made it an ideal place for human development over time. Today, many major cities of the Middle East are located in this region.

The wildlife of the Persian Gulf is diverse, and entirely unique due to the gulf's geographic distribution and its isolation from the international waters only breached by the narrow Strait of Hormuz. The Persian Gulf has hosted some of the most magnificent marine fauna and flora, some of which are near extirpation or at serious environmental risk. From corals, to dugongs, Persian Gulf is a diverse cradle for many species who depend on each other for survival. However, the gulf is not as biologically diverse as the Red Sea.

Overall, the wild life of the Persian Gulf is endangered from both global factors, and regional, local negligence. Most pollution is from ships; land generated pollution counts as the second most common source of pollution.

Along the mediterranean regions of the Arabian Sea, including the Persian Gulf, the Red Sea, the Gulf of Kutch, the Gulf of Suez, the Gulf of Aqaba, the Gulf of Aden, and the Gulf of Oman, dolphins and finless porpoises are the most common marine mammals in the waters, while larger whales and orcas are rarer today. Historically, whales had been abundant in the gulf before commercial hunts wiped them out. Whales were reduced even further by illegal mass hunts by the Soviet Union and Japan in the 1960s and 70s. Along with Bryde's whales, the most common and possible resident and still can be seen in deeper marginal seas such as Gulf of Aden, Israel coasts, and in Strait of Hormuz. Other species such as the critically endangered Arabian humpback whale (also historically common in Gulf of Aden, and sighting records increased in Red Sea since in 2006 including in Gulf of Aqaba), omura's whale, minke whale, and orca also swim into the gulf, while many other large species such as blue whale, sei, and sperm whales were once migrants into the Gulf of Oman and off the coasts in deeper waters, and still migrate in Red Sea, but mainly in deeper waters of outer seas. In 2017, waters of Persian Gulf along Abu Dhabi was revealed to hold world's largest population of Indo-Pacific humpbacked dolphins.

One of the more unusual marine mammals living in the Persian Gulf is the dugong ("Dugong dugon"). Also called "sea cows" for their grazing habits, their mild manner and resemblance to the livestock, dugongs have a life expectancy similar to that of humans and can reach lengths of up to . These gentle mammals feed on the sea grass and closer relatives of certain land mammals than the dolphins and the whales. Despite the simplicity of their grass diet, new developments along the Persian Gulf coastline, particularly artificial island development in Arab states, pollution particularly by oil spills caused during the "Persian Gulf war" and also due to occasional oil spills, and uncontrolled hunting has had a negative impact on the survival of the dugongs. After Australian waters with some 80,000 dugong inhabitants, the waters off Qatar, Bahrain, UAE, and Saudi Arabia have some 7,500 dugongs remaining, making the Persian Gulf the second most important habitat for the species. Dugong's current number is dwindling and it is not clear how many are currently alive or what their reproductive trend is. Unfortunately, ambitious and uncalculated construction schemes, political unrest and an ever-present international conflict, and presence of the most lucrative world supply of oil, along with lack of cooperation between Arab states and Iran, has had a negative impact on the survival of many marine species, including dugongs.

The Persian Gulf is also home to many migratory and local birds. There is great variation in color, size, and type of the bird species that call the gulf home. One bird in particular, the "kalbaensis" subspecies of the collared kingfishers is at the brink of extinction due to real state development by cities such as Dubai and countries such as Oman. Estimates from 2006 showed that only three viable nesting sites were available for this ancient bird, one located from Dubai, and two smaller sites in Oman, all of which are in the process of becoming real estate developments. Such expansion would prove devastating and could cause this species to become extinct. Unfortunately for the kingfisher, a U.N. plan to protect the mangroves as a biological reserve was blatantly ignored by the emirate of Sharjah, which allowed the dredging of a channel that bisects the wetland and construction of an adjacent concrete walkway. Environmental watchdogs in Arabia are few, and those that do advocate the wildlife are often silenced or ignored by developers of real estate, most of whom have royal family connections and huge energy profits to invest. The end result has been sacrifice of a beautiful yet delicate ecology that has been in harmony for hundreds of years, for structures that are erected only a few years, yet will have a lasting detrimental effect.

Almost no species in the Persian Gulf is spared from the real estate development of UAE and Oman, including the hawksbill turtle, greater flamingo, and booted warbler, mainly due to destruction of the mangrove habitats to make way for towers, hotels, and luxury resorts. Even dolphins that frequent the gulf in northern waters, around Iran are at serious risk. Recent statistics and observations show that dolphins are at danger of entrapment in purse seine fishing nets and exposure to chemical pollutants; perhaps the most alarming sign is the "mass suicides" committed by dolphins off Iran's Hormozgan province, which are not well understood, but are suspected to be linked with a deteriorating marine environment from water pollution from oil, sewage, and industrial run offs.

The Persian Gulf is home to over 700 species of fish, most of which are native. Of these 700 species, more than 80% are reef associated. These reefs are primarily rocky, but there are also a few coral reefs. Compared to the Red Sea, the coral reefs in the Persian Gulf are relatively few and far between. This is primarily connected to the influx of major rivers, especially the Shatt al-Arab (Euphrates and Tigris), which carry large amounts of sediment (most reef-building corals require strong light) and causes relatively large variations in temperature and salinity (corals in general are poorly suited to large variations). Nevertheless, coral reefs have been found along sections of coast of all countries in the Gulf. Corals are vital ecosystems that support multitude of marine species, and whose health directly reflects the health of the gulf. Recent years have seen a drastic decline in the coral population in the gulf, partially owing to global warming but majorly due to irresponsible dumping by Arab states like the UAE and Bahrain. Construction garbage such as tires, cement, and chemical by products have found their way to the Persian Gulf in recent years. Aside from direct damage to the coral, the construction waste creates "traps" for marine life in which they are trapped and die. The end result has been a dwindling population of the coral, and as a result a decrease in number of species that rely on the corals for their survival.

A great example of this symbiosis are the mangroves in the gulf, which require tidal flow and a combination of fresh and salt water for growth, and act as nurseries for many crabs, small fish, and insects; these fish and insects are the source of food for many of the marine birds that feed on them. Mangroves are a diverse group of shrubs and trees belonging to the genus "Avicennia" or "Rhizophora" that flourish in the salt water shallows of the gulf, and are the most important habitats for small crustaceans that dwell in them. They are as crucial an indicator of biological health on the surface of the water, as the corals are to biological health of the gulf in deeper waters. Mangroves' ability to survive the salt water through intricate molecular mechanisms, their unique reproductive cycle, and their ability to grow in the most oxygen-deprived waters have allowed them extensive growth in hostile areas of the gulf. Unfortunately, however, with the advent of artificial island development, most of their habitat is destroyed, or occupied by man-made structures. This has had a negative impact on the crustaceans that rely on the mangrove, and in turn on the species that feed on them.




</doc>
<doc id="24762" url="https://en.wikipedia.org/wiki?curid=24762" title="P53">
P53

Tumor protein p53, also known as p53, cellular tumor antigen p53 (UniProt name), phosphoprotein p53, tumor suppressor p53, antigen NY-CO-13, or transformation-related protein 53 (TRP53), is any isoform of a protein encoded by homologous genes in various organisms, such as "TP53" (humans) and "Trp53" (mice). This homolog (originally thought to be, and often spoken of as, a single protein) is crucial in multicellular organisms, where it prevents cancer formation, thus, functions as a tumor suppressor. As such, p53 has been described as "the guardian of the genome" because of its role in conserving stability by preventing genome mutation. Hence "TP53" is classified as a tumor suppressor gene. ("Italics" are used to denote the "TP53" gene name and distinguish it from the protein it encodes.)

The name p53 was given in 1979 describing the apparent molecular mass; SDS-PAGE analysis indicates that it is a 53-kilodalton (kDa) protein. However, the actual mass of the full-length p53 protein (p53α) based on the sum of masses of the amino acid residues is only 43.7 kDa. This difference is due to the high number of proline residues in the protein, which slow its migration on SDS-PAGE, thus making it appear heavier than it actually is. In addition to the full-length protein, the human "TP53" gene encodes at least 15 protein isoforms, ranging in size from 3.5 to 43.7 kDa. All these p53 proteins are called the p53 isoforms. The TP53 gene is the most frequently mutated gene (>50%) in human cancer, indicating that the "TP53" gene plays a crucial role in preventing cancer formation. "TP53" gene encodes proteins that bind to DNA and regulate gene expression to prevent mutations of the genome.

In humans, the "TP53" gene is located on the short arm of chromosome 17 (17p13.1). The gene spans 20 kb, with a non-coding exon 1 and a very long first intron of 10 kb. The coding sequence contains five regions showing a high degree of conservation in vertebrates, predominantly in exons 2, 5, 6, 7 and 8, but the sequences found in invertebrates show only distant resemblance to mammalian TP53. "TP53" orthologs have been identified in most mammals for which complete genome data are available.

In humans, a common polymorphism involves the substitution of an arginine for a proline at codon position 72. Many studies have investigated a genetic link between this variation and cancer susceptibility; however, the results have been controversial. For instance, a meta-analysis from 2009 failed to show a link for cervical cancer. A 2011 study found that the "TP53" proline mutation did have a profound effect on pancreatic cancer risk among males. A study of Arab women found that proline homozygosity at "TP53" codon 72 is associated with a decreased risk for breast cancer. One study suggested that "TP53" codon 72 polymorphisms, MDM2 SNP309, and A2164G may collectively be associated with non-oropharyngeal cancer susceptibility and that MDM2 SNP309 in combination with "TP53" codon 72 may accelerate the development of non-oropharyngeal cancer in women. A 2011 study found that "TP53" codon 72 polymorphism was associated with an increased risk of lung cancer.

Meta-analyses from 2011 found no significant associations between "TP53" codon 72 polymorphisms and both colorectal cancer risk and endometrial cancer risk. A 2011 study of a Brazilian birth cohort found an association between the non mutant arginine "TP53" and individuals without a family history of cancer. Another 2011 study found that the p53 homozygous (Pro/Pro) genotype was associated with a significantly increased risk for renal cell carcinoma.

A tandem of nine-amino-acid transactivation domains (9aaTAD) was identified in the AD1 and AD2 regions of transcription factor p53.
KO mutations and position for p53 interaction with TFIID are listed below: The competence of the p53 transactivation domains 9aaTAD to activate transcription as small peptides was reported.

9aaTADs mediate p53 interaction with general coactivators – TAF9, CBP/p300 (all four domains KIX, TAZ1, TAZ2 and IBiD), GCN5 and PC4, regulatory protein MDM2 and replication protein A (RPA).

Mutations that deactivate p53 in cancer usually occur in the DBD. Most of these mutations destroy the ability of the protein to bind to its target DNA sequences, and thus prevents transcriptional activation of these genes. As such, mutations in the DBD are recessive loss-of-function mutations. Molecules of p53 with mutations in the OD dimerise with wild-type p53, and prevent them from activating transcription. Therefore, OD mutations have a dominant negative effect on the function of p53.

Wild-type p53 is a labile protein, comprising folded and unstructured regions that function in a synergistic manner.

p53 has many mechanisms of anticancer function and plays a role in apoptosis, genomic stability, and inhibition of angiogenesis. In its anti-cancer role, p53 works through several mechanisms:

Activated p53 binds DNA and activates expression of several genes including microRNA miR-34a, WAF1/CIP1 encoding for p21 and hundreds of other down-stream genes. p21 (WAF1) binds to the G1-S/CDK (CDK4/CDK6, CDK2, and CDK1) complexes (molecules important for the G1/S transition in the cell cycle) inhibiting their activity.

When p21(WAF1) is complexed with CDK2, the cell cannot continue to the next stage of cell division. A mutant p53 will no longer bind DNA in an effective way, and, as a consequence, the p21 protein will not be available to act as the "stop signal" for cell division. Studies of human embryonic stem cells (hESCs) commonly describe the nonfunctional p53-p21 axis of the G1/S checkpoint pathway with subsequent relevance for cell cycle regulation and the DNA damage response (DDR). Importantly, p21 mRNA is clearly present and upregulated after the DDR in hESCs, but p21 protein is not detectable. In this cell type, p53 activates numerous microRNAs (like miR-302a, miR-302b, miR-302c, and miR-302d) that directly inhibit the p21 expression in hESCs.

Research has also linked the p53 and RB1 pathways, via p14ARF, raising the possibility that the pathways may regulate each other.

p53 by regulating LIF has been shown to facilitate implantation in the mouse model and possibly in humans.

p53 expression can be stimulated by UV light, which also causes DNA damage. In this case, p53 can initiate events leading to tanning.

The p21 protein binds directly to cyclin-CDK complexes that drive forward the cell cycle and inhibits their kinase activity thereby causing cell cycle arrest to allow repair to take place. p21 can also mediate growth arrest associated with differentiation and a more permanent growth arrest associated with cellular senescence. The p21 gene contains several p53 response elements that mediate direct binding of the p53 protein, resulting in transcriptional activation of the gene encoding the p21 protein.

Levels of p53 play an important role in the maintenance of stem cells throughout development and the rest of human life.

p53 is maintained at low inactive levels in human embryonic stem cells (hESCs). This is because activation of p53 leads to rapid differentiation of hESCs. Studies have shown that knocking out p53 delays differentiation and that adding p53 causes spontaneous differentiation, showing how p53 promotes differentiation of hESCs and plays a key role in cell cycle as a differentiation regulator. When p53 becomes stabilized and activated in hESCs, it increases p21 to establish a longer G1. This typically leads to abolition of S-phase entry, which stops the cell cycle in G1, leading to differentiation. p53 also activates miR-34a and miR-145, which then repress the hESCs pluripotency factors, further instigating differentiation.

Studies of human embryonic stem cells (hESCs) commonly describe the nonfunctional p53-p21 axis of the G1/S checkpoint pathway. This has subsequent relevance for cell cycle regulation and the DNA damage response (DDR). Importantly, p21 mRNA is clearly present and upregulated after the DDR in hESCs, but p21 protein is not detectable. In this cell type, p53 activates numerous microRNAs (like miR-302a, miR-302b, miR-302c, and miR-302d) that directly inhibit the p21 expression in hESCs.

In adult stem cells, p53 regulation is important for maintenance of stemness in adult stem cell niches. Mechanical signals such as hypoxia affect levels of p53 in these niche cells through the hypoxia inducible factors, HIF-1α and HIF-2α. While HIF-1α stabilizes p53, HIF-2α suppresses it. Suppression of p53 plays important roles in cancer stem cell phenotype, induced pluripotent stem cells and other stem cell roles and behaviors, such as blastema formation. Cells with decreased levels of p53 have been shown to reprogram into stem cells with a much greater efficiency than normal cells. Papers suggest that the lack of cell cycle arrest and apoptosis gives more cells the chance to be reprogrammed. Decreased levels of p53 were also shown to be a crucial aspect of blastema formation in the legs of salamanders. p53 regulation is very important in acting as a barrier between stem cells and a differentiated stem cell state, as well as a barrier between stem cells being functional and being cancerous.

p53 becomes activated in response to myriad stressors, including but not limited to DNA damage (induced by either UV, IR, or chemical agents such as hydrogen peroxide), oxidative stress, osmotic shock, ribonucleotide depletion, and deregulated oncogene expression. This activation is marked by two major events. First, the half-life of the p53 protein is increased drastically, leading to a quick accumulation of p53 in stressed cells. Second, a conformational change forces p53 to be activated as a transcription regulator in these cells. The critical event leading to the activation of p53 is the phosphorylation of its N-terminal domain. The N-terminal transcriptional activation domain contains a large number of phosphorylation sites and can be considered as the primary target for protein kinases transducing stress signals.

The protein kinases that are known to target this transcriptional activation domain of p53 can be roughly divided into two groups. A first group of protein kinases belongs to the MAPK family (JNK1-3, ERK1-2, p38 MAPK), which is known to respond to several types of stress, such as membrane damage, oxidative stress, osmotic shock, heat shock, etc. A second group of protein kinases (ATR, ATM, CHK1 and CHK2, DNA-PK, CAK, TP53RK) is implicated in the genome integrity checkpoint, a molecular cascade that detects and responds to several forms of DNA damage caused by genotoxic stress. Oncogenes also stimulate p53 activation, mediated by the protein p14ARF.

In unstressed cells, p53 levels are kept low through a continuous degradation of p53. A protein called Mdm2 (also called HDM2 in humans), binds to p53, preventing its action and transports it from the nucleus to the cytosol. Also Mdm2 acts as ubiquitin ligase and covalently attaches ubiquitin to p53 and thus marks p53 for degradation by the proteasome. However, ubiquitylation of p53 is reversible.

MI-63 binds to MDM2 making the action of p53 again possible in situations were p53's function has become inhibited.

A ubiquitin specific protease, USP7 (or HAUSP), can cleave ubiquitin off p53, thereby protecting it from proteasome-dependent degradation via the ubiquitin ligase pathway. This is one means by which p53 is stabilized in response to oncogenic insults. USP42 has also been shown to deubiquitinate p53 and may be required for the ability of p53 to respond to stress.

Recent research has shown that HAUSP is mainly localized in the nucleus, though a fraction of it can be found in the cytoplasm and mitochondria. Overexpression of HAUSP results in p53 stabilization. However, depletion of HAUSP does not result to a decrease in p53 levels but rather increases p53 levels due to the fact that HAUSP binds and deubiquitinates Mdm2. It has been shown that HAUSP is a better binding partner to Mdm2 than p53 in unstressed cells.

USP10 however has been shown to be located in the cytoplasm in unstressed cells and deubiquitinates cytoplasmic p53, reversing Mdm2 ubiquitination. Following DNA damage, USP10 translocates to the nucleus and contributes to p53 stability. Also USP10 does not interact with Mdm2.

Phosphorylation of the N-terminal end of p53 by the above-mentioned protein kinases disrupts Mdm2-binding. Other proteins, such as Pin1, are then recruited to p53 and induce a conformational change in p53, which prevents Mdm2-binding even more. Phosphorylation also allows for binding of transcriptional coactivators, like p300 and PCAF, which then acetylate the carboxy-terminal end of p53, exposing the DNA binding domain of p53, allowing it to activate or repress specific genes. Deacetylase enzymes, such as Sirt1 and Sirt7, can deacetylate p53, leading to an inhibition of apoptosis. Some oncogenes can also stimulate the transcription of proteins that bind to MDM2 and inhibit its activity.

If the "TP53" gene is damaged, tumor suppression is severely compromised. People who inherit only one functional copy of the "TP53" gene will most likely develop tumors in early adulthood, a disorder known as Li-Fraumeni syndrome.

The "TP53" gene can also be modified by mutagens (chemicals, radiation, or viruses), increasing the likelihood for uncontrolled cell division. More than 50 percent of human tumors contain a mutation or deletion of the "TP53" gene. Loss of p53 creates genomic instability that most often results in an aneuploidy phenotype.

Increasing the amount of p53 may seem a solution for treatment of tumors or prevention of their spreading. This, however, is not a usable method of treatment, since it can cause premature aging. Restoring endogenous normal p53 function holds some promise. Research has shown that this restoration can lead to regression of certain cancer cells without damaging other cells in the process. The ways by which tumor regression occurs depends mainly on the tumor type. For example, restoration of endogenous p53 function in lymphomas may induce apoptosis, while cell growth may be reduced to normal levels. Thus, pharmacological reactivation of p53 presents itself as a viable cancer treatment option. The first commercial gene therapy, Gendicine, was approved in China in 2003 for the treatment of head and neck squamous cell carcinoma. It delivers a functional copy of the p53 gene using an engineered adenovirus.

Certain pathogens can also affect the p53 protein that the "TP53" gene expresses. One such example, human papillomavirus (HPV), encodes a protein, E6, which binds to the p53 protein and inactivates it. This mechanism, in synergy with the inactivation of the cell cycle regulator pRb by the HPV protein E7, allows for repeated cell division manifested clinically as warts. Certain HPV types, in particular types 16 and 18, can also lead to progression from a benign wart to low or high-grade cervical dysplasia, which are reversible forms of precancerous lesions. Persistent infection of the cervix over the years can cause irreversible changes leading to carcinoma in situ and eventually invasive cervical cancer. This results from the effects of HPV genes, particularly those encoding E6 and E7, which are the two viral oncoproteins that are preferentially retained and expressed in cervical cancers by integration of the viral DNA into the host genome.

The p53 protein is continually produced and degraded in cells of healthy people, resulting in damped oscillation. The degradation of the p53 protein is associated with binding of MDM2. In a negative feedback loop, MDM2 itself is induced by the p53 protein. Mutant p53 proteins often fail to induce MDM2, causing p53 to accumulate at very high levels. Moreover, the mutant p53 protein itself can inhibit normal p53 protein levels. In some cases, single missense mutations in p53 have been shown to disrupt p53 stability and function.

Suppression of p53 in human breast cancer cells is shown to lead to increased CXCR5 chemokine receptor gene expression and activated cell migration in response to chemokine CXCL13.

One study found that p53 and Myc proteins were key to the survival of Chronic Myeloid Leukaemia (CML) cells. Targeting p53 and Myc proteins with drugs gave positive results on mice with CML.

Most p53 mutations are detected by DNA sequencing. However, it is known that single missense mutations can have a large spectrum from rather mild to very severe functional affects.

The large spectrum of cancer phenotypes due to mutations in the "TP53" gene is also supported by the fact that different isoforms of p53 proteins have different cellular mechanisms for prevention against cancer. Mutations in "TP53" can give rise to different isoforms, preventing their overall functionality in different cellular mechanisms and thereby extending the cancer phenotype from mild to severe. Recents studies show that p53 isoforms are differentially expressed in different human tissues, and the loss-of-function or gain-of-function mutations within the isoforms can cause tissue-specific cancer or provides cancer stem cell potential in different tissues. TP53 mutation also hits energy metabolism and increases glycolysis in breast cancer cells.

The dynamics of p53 proteins, along with its antagonist Mdm2, indicate that the levels of p53, in units of concentration, oscillate as a function of time. This "damped" oscillation is both clinically documented and mathematically modelled. Mathematical models also indicate that the p53 concentration oscillates much faster once teratogens, such as double-stranded breaks (DSB) or UV radiation, are introduced to the system. This supports and models the current understanding of p53 dynamics, where DNA damage induces p53 activation (see p53 regulation for more information). Current models can also be useful for modelling the mutations in p53 isoforms and their effects on p53 oscillation, thereby promoting "de novo" tissue-specific pharmacological drug discovery.

p53 was identified in 1979 by Lionel Crawford, David P. Lane, Arnold Levine, and Lloyd Old, working at Imperial Cancer Research Fund (UK) Princeton University/UMDNJ (Cancer Institute of New Jersey), and Memorial Sloan-Kettering Cancer Center, respectively. It had been hypothesized to exist before as the target of the SV40 virus, a strain that induced development of tumors. The "TP53" gene from the mouse was first cloned by Peter Chumakov of the Russian Academy of Sciences in 1982, and independently in 1983 by Moshe Oren in collaboration with David Givol (Weizmann Institute of Science). The human "TP53" gene was cloned in 1984 and the full length clone in 1985.

It was initially presumed to be an oncogene due to the use of mutated cDNA following purification of tumor cell mRNA. Its role as a tumor suppressor gene was revealed in 1989 by Bert Vogelstein at the Johns Hopkins School of Medicine and Arnold Levine at Princeton University.

Warren Maltzman, of the Waksman Institute of Rutgers University first demonstrated that TP53 was responsive to DNA damage in the form of ultraviolet radiation. In a series of publications in 1991–92, Michael Kastan of Johns Hopkins University, reported that TP53 was a critical part of a signal transduction pathway that helped cells respond to DNA damage.

In 1993, p53 was voted "molecule of the year" by Science magazine.

As with 95% of human genes, TP53 encodes more than one protein. In 2005 several isoforms were discovered and until now, 12 human p53 isoforms were identified (p53α, p53β, p53γ, ∆40p53α, ∆40p53β, ∆40p53γ, ∆133p53α, ∆133p53β, ∆133p53γ, ∆160p53α, ∆160p53β, ∆160p53γ). Furthermore, p53 isoforms are expressed in a tissue dependent manner and p53α is never expressed alone.

The full length p53 isoform proteins can be subdivided into different protein domains. Starting from the N-terminus, there are first the amino-terminal transactivation domains (TAD 1, TAD 2), which are needed to induce a subset of p53 target genes. This domain is followed by the Proline rich domain (PXXP), whereby the motif PXXP is repeated (P is a Proline and X can be any amino acid). It is required among others for p53 mediated apoptosis. Some isoforms lack the Proline rich domain, such as Δ133p53β,γ and Δ160p53α,β,γ; hence some isoforms of p53 are not mediating apoptosis, emphasizing the diversifying roles of the "TP53" gene. Afterwards there is the DNA binding domain (DBD), which enables the proteins to sequence specific binding. The carboxyl terminal domain completes the protein. It includes the nuclear localization signal (NLS), the nuclear export signal (NES) and the oligomerisation domain (OD). The NLS and NES are responsible for the subcellular regulation of p53. Through the OD, p53 can form a tetramer and then bind to DNA. Among the isoforms, some domains can be missing, but all of them share most of the highly conserved DNA-binding domain.

The isoforms are formed by different mechanisms. The beta and the gamma isoforms are generated by multiple splicing of intron 9, which leads to a different C-terminus. Furthermore, the usage of an internal promoter in intron 4 causes the ∆133 and ∆160 isoforms, which lack the TAD domain and a part of the DBD. Moreover, alternative initiation of translation at codon 40 or 160 bear the ∆40p53 and ∆160p53 isoforms.

Due to the isoformic nature of p53 proteins, there have been several sources of evidence showing that mutations within the "TP53" gene giving rise to mutated isoforms are causative agents of various cancer phenotypes, from mild to severe, due to single mutation in the "TP53" gene (refer to section Experimental analysis of p53 mutations for more details).

p53 has been shown to interact with:

Peto's paradox is the observation, due to Richard Peto, that at the species level, the incidence of cancer does not appear to correlate with the number of cells in an organism. For example, the incidence of cancer in humans is much higher than the incidence of cancer in whales. This is despite the fact that a whale has many more cells than a human. If the probability of carcinogenesis were constant across cells, one would expect whales to have a higher incidence of cancer than humans. The same is true of elephants. In October 2015, two independent studies showed that elephants have 20 copies of a tumor suppressor gene TP53 in their genome, where humans and other mammals have only one, thus providing a possible solution to the paradox.



</doc>
<doc id="24764" url="https://en.wikipedia.org/wiki?curid=24764" title="Pointless topology">
Pointless topology

In mathematics, pointless topology (also called point-free or pointfree topology, or locale theory) is an approach to topology that avoids mentioning points.

Traditionally, a topological space consists of a set of points together with a "topology", a system of subsets called open sets that with the operations of intersection and union forms a lattice with certain properties. Point-free topology is based on the concept of a "realistic spot" instead of a point without extent. Spots can be joined (forming a complete lattice) and if a spot meets a join of others it has to meet some of the constituents, which, roughly speaking, leads to the distributive law

formula_1.

The basic concept is that of a frame, a complete lattice satisfying the distributive law above; frame homomorphisms respect all joins (in particular, the least element of the lattice) and finite meets (in particular, the greatest element of the lattice).

Frames, together with frame homomorphisms, form a category.

In classical topology, represented on a set formula_2 by the system formula_3 of open sets, formula_3 (partially ordered by inclusion) is a frame, and if formula_5 is a continuous map, formula_6 defined by formula_7 is a frame homomorphism. For sober spaces such formula_8 are precisely the frame homomorphisms formula_9. Hence formula_10 is a full embedding of the category of sober spaces into the dual of the category of frames (usually called of the category of locales). This justifies thinking of frames (locales) as of generalized topological spaces. A frame is "spatial" if it is isomorphic to a formula_3. There is plenty of non-spatial ones and this fact turned out to be helpful in several problems.

The theory of frames and locales in the contemporary sense initiated in late fifties (Charles Ehresmann, Jean Bénabou, Hugh Dowker, Dona Papert) and developed through the following decades (John Isbell, Peter Johnstone, Harold Simmons, , , Till Plewe, Japie Vermeulen, Steve Vickers) into a lively branch of topology, with application in various fields, in particular also in theoretical computer science. For more on the history of locale theory see.

It is possible to translate most concepts of point-set topology into the context of locales, and prove analogous theorems. From the advantages of the point-free approach let us point out, e.g. the fact that some important facts of classical topology depending on choice principles become choice-free (that is, constructive, which is, a.o. appealing for computer science). Thus for instance, products of compact locales are compact constructively, or completions of uniform locales are constructive. This can be useful if one works in a topos that does not have the axiom of choice. From among other facts of advantage let us name the much better behavior of paracompactness, or the fact that subgroups of localic groups are always closed.

Another point where locale theory and topology diverge strongly is the concept of subspaces vs. sublocales: by Isbell's density theorem, every locale has a smallest dense sublocale.This has absolutely no equivalent in the realm of topological spaces.


A general introduction to pointless topology is

This is, in its own words, to be read as the trailer for Johnstone's excellent monograph (which appeared already in 1982 and can still be used for basic reference):


There is a recent monograph


where one also finds a more extensive bibliography.

For relations with logic:


For a faster information see the respective chapters in:



</doc>
<doc id="24767" url="https://en.wikipedia.org/wiki?curid=24767" title="Phobos">
Phobos

Phobos may refer to:








</doc>
<doc id="24768" url="https://en.wikipedia.org/wiki?curid=24768" title="Pizza">
Pizza

Pizza is a traditional Italian dish consisting of a yeasted flatbread typically topped with tomato sauce and cheese and baked in an oven. It can also be topped with additional vegetables, meats, and condiments, and can be made without cheese. 

The term "pizza" was first recorded in the 10th century, in a Latin manuscript from the Southern Italian town of Gaeta in Lazio, on the border with Campania. Modern pizza was invented in Naples, and the dish and its variants have since become popular and common in many areas of the world. In 2009, upon Italy's request, Neapolitan pizza was registered with the European Union as a Traditional Speciality Guaranteed dish. 
The "Associazione Verace Pizza Napoletana" (True Neapolitan Pizza Association), a non-profit organization founded in 1984 with headquarters in Naples, aims to "promote and protect... the true Neapolitan pizza".

Pizza is one of the most popular foods in the world and a common fast food item in Europe and North America. Many independent or chain restaurants, cafes, and fast food outlets offer pizza. Restaurants or chains specializing in pizza are pizzerias. Pizza delivery is common in some parts of the world.

Pizza is sold fresh or frozen, either whole or in portions. Various types of ovens are used to cook them and many varieties exist. Several similar dishes are prepared from ingredients commonly used in pizza preparation, such as calzone and stromboli. In the United States, pizza is usually eaten out of hand after dividing into slices from a large pizza or small pizzetta as a whole. In Italy, pizza is eaten with a fork and knife in restaurants, but is also sold to take away and eaten out of hand. Pre-made pizza sold and stored frozen became popular in the late 20th century.

The word "pizza" () first appeared in a Latin text from the central Italian town of Gaeta, then still part of the Byzantine Empire, in 997 AD; the text states that a tenant of certain property is to give the bishop of Gaeta "duodecim pizze" ("twelve pizzas") every Christmas Day, and another twelve every Easter Sunday".

Suggested etymologies include:

Foods similar to pizza have been made since the neolithic age. Records of people adding other ingredients to bread to make it more flavorful can be found throughout ancient history. The ancient Greeks supplemented their bread with oils, herbs, and cheese, and in the 6th century BC, the Persian soldiers of Achaemenid Empire during the rule King Darius I baked flatbreads with cheese and dates on top of their battle shields. An early reference to a pizza-like food occurs in the Aeneid, when Celaeno, queen of the Harpies, foretells that the Trojans would not find peace until they are forced by hunger to eat their tables (Book III). In Book VII, Aeneas and his men are served a meal that includes round cakes (like pita bread) topped with cooked vegetables. When they eat the bread, they realize that these are the "tables" prophesied by Celaeno.

Modern pizza evolved from similar flatbread dishes in Naples in the 18th or early 19th century. Prior to that time, flatbread was often topped with ingredients such as garlic, salt, lard, cheese, and basil. It is uncertain when tomatoes were first added and there are many conflicting claims. Until about 1830, pizza was sold from open-air stands and out of pizza bakeries, and pizzerias keep this old tradition alive today. 

A popular contemporary legend holds that the archetypal pizza, "pizza Margherita", was invented in 1889, when the Royal Palace of Capodimonte commissioned the Neapolitan pizzaiolo (pizza maker) Raffaele Esposito to create a pizza in honor of the visiting Queen Margherita. Of the three different pizzas he created, the Queen strongly preferred a pizza swathed in the colors of the Italian flag: red (tomato), green (basil), and white (mozzarella). Supposedly, this kind of pizza was then named after the Queen, although recent research casts doubt on this legend. An official letter of recognition from the Queen's "head of service" remains on display in Esposito's shop, now called the Pizzeria Brandi.

Pizza was brought to the United States with Italian immigrants in the late nineteenth century, and first appeared in areas where Italian immigrants concentrated. The country's first pizzeria, Lombardi's, opened in 1905. Following World War II, veterans returning from the Italian Campaign after being introduced to Italy's native cuisine proved a ready market for pizza in particular. Since then pizza consumption has exploded in the U.S. Pizza chains such as Domino's, Pizza Hut, and Papa John's, pizzas from take and bake pizzerias, and chilled or frozen pizzas from supermarkets make pizza readily available nationwide. 13% of the US population consumes pizza on any given day.

Pizza is prepared fresh, frozen, and as portion-size slices or pieces. Methods have been developed to overcome challenges such as preventing the sauce from combining with the dough and producing a crust that can be frozen and reheated without becoming rigid. There are frozen pizzas with raw ingredients and self-rising crusts.

Another form of uncooked pizza is available from take and bake pizzerias. This pizza is assembled in the store, then sold to customers to bake in their own ovens. Some grocery stores sell fresh dough along with sauce and basic ingredients, to complete at home before baking in an oven.

In restaurants, pizza can be baked in an oven with stone bricks above the heat source, an electric deck oven, a conveyor belt oven or, in the case of more expensive restaurants, a wood or coal-fired brick oven. On deck ovens, pizza can be slid into the oven on a long paddle, called a peel, and baked directly on the hot bricks or baked on a screen (a round metal grate, typically aluminum). Prior to use, a peel may be sprinkled with cornmeal to allow pizza to easily slide onto and off of it. When made at home, it can be baked on a pizza stone in a regular oven to reproduce the effect of a brick oven. Cooking directly in a metal oven results in too rapid heat transfer to the crust, burning it. Aficionado home-chefs sometimes use a specialty wood-fired pizza oven, usually installed outdoors. Dome-shaped pizza ovens have been used for centuries, which is one way to achieve true heat distribution in a wood-fired pizza oven. Another option is grilled pizza, in which the crust is baked directly on a barbecue grill. Greek pizza, like Chicago-style pizza, is baked in a pan rather than directly on the bricks of the pizza oven.

When it comes to preparation, the dough and ingredients can be combined on any kind of table. With mass production of pizza, the process can be completely automated. Most restaurants still use standard and purpose-built pizza preparation tables. Pizzerias nowadays can even opt for hi tech pizza preparation tables that combine mass production elements with traditional techniques.

The bottom of the pizza, called the 'crust', may vary widely according to style; thin as in a typical hand-tossed Neapolitan pizza, or thick as in a deep-dish Chicago-style. It is traditionally plain, but may also be seasoned with garlic or herbs, or stuffed with cheese. The outer edge of the pizza is sometimes referred to as the "cornicione". Pizza dough often contains sugar, both to help its yeast rise and enhance browning of the crust.
Dipping sauce specifically for pizza was invented by American pizza chain Papa John's Pizza in 1984, and has since become popular when eating pizza, especially the crust.

Mozzarella is commonly used on pizza, with the highest quality buffalo mozzarella produced in the surroundings of Naples. Today, other cheeses have been used as pizza ingredients (particularly Italian cheeses), including provolone, pecorino romano, ricotta, and scamorza. Less expensive processed cheeses or cheese analogues have been developed for mass-market pizzas to produce desirable qualities like browning, melting, stretchiness, consistent fat and moisture content, and stable shelf life. This quest to create the ideal and economical pizza cheese has involved many studies and experiments analyzing the impact of vegetable oil, manufacturing and culture processes, denatured whey proteins and other changes in manufacture. In 1997 it was estimated that annual production of pizza cheese was in the U.S. and in Europe.

Authentic Neapolitan pizza ("pizza napoletana") is typically made with San Marzano tomatoes, grown on the volcanic plains south of Mount Vesuvius, and mozzarella di bufala Campana, made with milk from water buffalo raised in the marshlands of Campania and Lazio. This mozzarella is protected with its own European protected designation of origin. Other traditional pizzas include "pizza alla marinara", which is topped with marinara sauce and is supposedly the most ancient tomato-topped pizza,
pizza capricciosa, which is prepared with mozzarella cheese, baked ham, mushroom, artichoke and tomato, and pizza pugliese, prepared with tomato, mozzarella and onions.

A popular variant of pizza in Italy is Sicilian pizza (locally called "sfincione" or "sfinciuni"), a thick-crust or deep-dish pizza originating during the 17th century in Sicily: it is essentially a focaccia that is typically topped with tomato sauce and other ingredients. Until the 1860s, "sfincione" was the type of pizza usually consumed in Sicily, especially in the Western portion of the island. Other variations of pizzas are also found in other regions of Italy, for example "pizza al padellino" or "pizza al tegamino", a small-sized, thick-crust and deep-dish pizza typically served in Turin, Piedmont.

Common toppings for pizza in the United States include ground beef, mushrooms, onions, pepperoni, pineapple, garlic, olives, peppers, carrots, tomatoes, spinach, anchovies, chicken, bacon, ham and sausage. Distinct regional types developed in the 20th century, including California, Chicago, Greek, New Haven, Detroit, St. Louis, and New York styles. The first pizzeria in the U.S. was opened in New York's Little Italy in 1905 and since then regions throughout the U.S. offer variations, including deep-dish, stuffed, pockets, turnovers, rolled and pizza-on-a-stick, each with seemingly limitless combinations of sauce and toppings.

Another variation is grilled pizza, created by taking a fairly thin, round (more typically, irregularly shaped) sheet of yeasted pizza dough, placing it directly over the fire of a grill and then turning it over once the bottom has baked and placing a thin layer of toppings on the baked side. Toppings may be sliced thin to ensure that they heat through, and chunkier toppings such as sausage or peppers may be precooked before being placed on the pizza. Garlic, herbs, or other ingredients are sometimes added to the pizza or the crust to maximize the flavor of the dish.

Grilled pizza was offered in the United States at the Al Forno restaurant in Providence, Rhode Island by owners Johanne Killeen and George Germon in 1980. Although it was inspired by a misunderstanding that confused a wood-fired brick oven with a grill, grilled pizza did exist prior to 1980, both in Italy, and in Argentina where it is known as "pizza a la parrilla". It has become a popular cookout dish, and there are even some pizza restaurants that specialize in the style. The traditional style of grilled pizza employed at Al Forno restaurant uses a dough coated with olive oil, strained tomato sauce, thin slices of fresh mozzarella, and a garnish made from shaved scallions, and is served uncut. The final product can be likened to flatbread with pizza toppings. Another Providence establishment, Bob & Timmy's Grilled Pizza, was featured in a Providence-themed episode of the Travel Channel's "Man v. Food Nation" in 2011.

The world's largest pizza was prepared in Rome in December 2012, and measured . The pizza was named "Ottavia" in homage to the first Roman emperor Octavian Augustus, and was made with a gluten-free base. The world's longest pizza was made in Naples in 2016. It was baked using a series of wheeled ovens which moved along its length, and measured .

The world's most expensive pizza listed by "Guinness World Records" is a commercially available thin-crust pizza at Maze restaurant in London, United Kingdom, which costs . The pizza is wood fire-baked, and is topped with onion puree, white truffle paste, fontina cheese, baby mozzarella, pancetta, cep mushrooms, freshly picked wild mizuna lettuce, and fresh shavings of a rare Italian white truffle.

There are several instances of more expensive pizzas, such as the "Pizza Royale 007" at Haggis restaurant in Glasgow, Scotland, which has caviar, lobster and is topped with 24-carat gold dust, and the caviar pizza made by Nino's Bellissima pizzeria in New York City, New York. However, these are not officially recognized by "Guinness World Records". Additionally, a pizza was made by the restaurateur Domenico Crolla that included toppings such as sunblush-tomato sauce, Scottish smoked salmon, medallions of venison, edible gold, lobster marinated in cognac, and champagne-soaked caviar. The pizza was auctioned for charity in 2007, raising .

In 2017, the world pizza market was $128 billion and in the US it was $44 billion spread over 76,000 pizzerias. Overall, 13% of the U.S. population aged 2 years and over, consumed pizza on any given day.

Some mass-produced pizzas by fast food chains have been criticized as having an unhealthy balance of ingredients. Pizza can be high in salt, fat and calories (food energy). The USDA reports an average sodium content of 5,101 mg per pizza in fast food chains. There are concerns about negative health effects. Food chains have come under criticism at various times for the high salt content of some of their meals.

Frequent pizza eaters in Italy have been found to have a relatively low incidence of cardiovascular disease and digestive tract cancers relative to infrequent pizza eaters, although the nature of the correlation between pizza and such perceived benefits is unclear. Pizza consumption in Italy might only indicate adherence to traditional Mediterranean dietary patterns, which have been shown to have various health benefits.

Some attribute the apparent health benefits of pizza to the lycopene content in pizza sauce, which research indicates likely plays a role in protecting against cardiovascular disease and various cancers.

National Pizza Month is an annual observance that occurs for the month of October in the United States and some areas of Canada. This observance began in October 1984, and was created by Gerry Durnell, the publisher of "Pizza Today" magazine. During this time, some people observe National Pizza Month by consuming various types of pizzas or pizza slices, or going to various pizzerias.




</doc>
<doc id="24772" url="https://en.wikipedia.org/wiki?curid=24772" title="Phase modulation">
Phase modulation

Phase modulation (PM) is a modulation pattern for conditioning communication signals for transmission. It encodes a message signal as variations in the instantaneous phase of a carrier wave. Phase modulation is one of the two principal forms of angle modulation, together with frequency modulation.

The phase of a carrier signal is modulated to follow the changing signal level (amplitude) of the message signal. The peak amplitude and the frequency of the carrier signal are maintained constant, but as the amplitude of the message signal changes, the phase of the carrier changes correspondingly.

Phase modulation is widely used for transmitting radio waves and is an integral part of many digital transmission coding schemes that underlie a wide range of technologies like Wi-Fi, GSM and satellite television.

PM is used for signal and waveform generation in digital synthesizers, such as the Yamaha DX7 to implement FM synthesis. A related type of sound synthesis called phase distortion is used in the Casio CZ synthesizers. 

PM changes the phase angle of the complex envelope in direct proportion to the message signal.

If "m(t)" is the message signal to be transmitted and the carrier onto which the signal is modulated is

then the modulated signal is

This shows how formula_3 modulates the phase - the greater m(t) is at a point in time, the greater the phase shift of the modulated signal at that point. It can also be viewed as a change of the frequency of the carrier signal, and phase modulation can thus be considered a special case of FM in which the carrier frequency modulation is given by the time derivative of the phase modulation.

The modulation signal could here be

The mathematics of the spectral behavior reveals that there are two regions of particular interest:

As with other modulation indices, this quantity indicates by how much the modulated variable varies around its unmodulated level. It relates to the variations in the phase of the carrier signal:
where formula_9 is the peak phase deviation. Compare to the modulation index for frequency modulation.



</doc>
<doc id="24774" url="https://en.wikipedia.org/wiki?curid=24774" title="Phosphodiesterase inhibitor">
Phosphodiesterase inhibitor

A phosphodiesterase inhibitor is a drug that blocks one or more of the five subtypes of the enzyme phosphodiesterase (PDE), thereby preventing the inactivation of the intracellular second messengers cyclic adenosine monophosphate (cAMP) and cyclic guanosine monophosphate (cGMP) by the respective PDE subtype(s). The ubiquitous presence of this enzyme means that non-specific inhibitors have a wide range of actions, the actions in the heart, lungs and penis being some of the first to find a therapeutic use.

The different forms or subtypes of phosphodiesterase were initially isolated from rat brains in the early 1970s and were soon afterward shown to be selectively inhibited in the brain and in other tissues by a variety of drugs. The potential for selective phosphodiesterase inhibitors as therapeutic agents was predicted as early as 1977 by Weiss and Hait. This prediction meanwhile has proved to be true in a variety of fields.

Methylated xanthines and derivatives:
Methylated xanthines act as both
But different analogues show varying potency at the numerous subtypes, and a wide range of synthetic xanthine derivatives (some nonmethylated) have been developed in the search for compounds with greater selectivity for phosphodiesterase enzyme or adenosine receptor subtypes.




PDE3 is sometimes referred to as cGMP-inhibited phosphodiesterase.


PDE4 is the major cAMP-metabolizing enzyme found in inflammatory and immune cells. PDE4 inhibitors have proven potential as anti-inflammatory drugs, especially in inflammatory pulmonary diseases such as asthma, COPD, and rhinitis. They suppress the release of cytokines and other inflammatory signals, and inhibit the production of reactive oxygen species. PDE4 inhibitors may have antidepressive effects and have also recently been proposed for use as antipsychotics.

On October 26, 2009, The University of Pennsylvania reported that researchers at their institution had discovered a link between elevated levels of PDE4 (and therefore decreased levels of cAMP) in sleep deprived mice. Treatment with a PDE4 inhibitor raised the deficient cAMP levels and restored some functionality to Hippocampus-based memory functions.


Recent studies have shown Quinazoline type PDE7 inhibitor to be potent anti-inflammatory and neuroprotective agents.

Papaverine, an opium alkaloid, has been reported to act as a PDE10 inhibitor. 
PDE10A is almost exclusively expressed in the striatum and subsequent increase in cAMP and cGMP after PDE10A inhibition (e.g. by papaverine) is "a novel therapeutic avenue in the discovery of antipsychotics".


</doc>
<doc id="24776" url="https://en.wikipedia.org/wiki?curid=24776" title="Piston">
Piston

A piston is a component of reciprocating engines, reciprocating pumps, gas compressors and pneumatic cylinders, among other similar mechanisms. It is the moving component that is contained by a cylinder and is made gas-tight by piston rings. In an engine, its purpose is to transfer force from expanding gas in the cylinder to the crankshaft via a piston rod and/or connecting rod. In a pump, the function is reversed and force is transferred from the crankshaft to the piston for the purpose of compressing or ejecting the fluid in the cylinder. In some engines, the piston also acts as a valve by covering and uncovering ports in the cylinder.

An internal combustion engine is acted upon by the pressure of the expanding combustion gases in the combustion chamber space at the top of the cylinder. This force then acts downwards through the connecting rod and onto the crankshaft. The connecting rod is attached to the piston by a swivelling gudgeon pin (US: wrist pin). This pin is mounted within the piston: unlike the steam engine, there is no piston rod or crosshead (except big two stroke engines).

The pin itself is of hardened steel and is fixed in the piston, but free to move in the connecting rod. A few designs use a 'fully floating' design that is loose in both components. All pins must be prevented from moving sideways and the ends of the pin digging into the cylinder wall, usually by circlips.

Gas sealing is achieved by the use of piston rings. These are a number of narrow iron rings, fitted loosely into grooves in the piston, just below the crown. The rings are split at a point in the rim, allowing them to press against the cylinder with a light spring pressure. Two types of ring are used: the upper rings have solid faces and provide gas sealing; lower rings have narrow edges and a U-shaped profile, to act as oil scrapers. There are many proprietary and detail design features associated with piston rings.

Pistons are cast from aluminium alloys. For better strength and fatigue life, some racing pistons may be forged instead. Billet pistons are also used in racing engines because they do not rely on the size and architecture of available forgings, allowing for last-minute design changes. Although not commonly visible to the naked eye, pistons themselves are designed with a certain level of ovality and profile taper, meaning they are not perfectly round, and their diameter is larger near the bottom of the skirt than at the crown. 

Early pistons were of cast iron, but there were obvious benefits for engine balancing if a lighter alloy could be used. To produce pistons that could survive engine combustion temperatures, it was necessary to develop new alloys such as Y alloy and Hiduminium, specifically for use as pistons.

A few early gas engines had double-acting cylinders, but otherwise effectively all internal combustion engine pistons are single-acting. During World War II, the US submarine "Pompano" was fitted with a prototype of the infamously unreliable H.O.R. double-acting two-stroke diesel engine. Although compact, for use in a cramped submarine, this design of engine was not repeated.

Trunk pistons are long relative to their diameter. They act both as a piston and cylindrical crosshead. As the connecting rod is angled for much of its rotation, there is also a side force that reacts along the side of the piston against the cylinder wall. A longer piston helps to support this.

Trunk pistons have been a common design of piston since the early days of the reciprocating internal combustion engine. They were used for both petrol and diesel engines, although high speed engines have now adopted the lighter weight slipper piston.

A characteristic of most trunk pistons, particularly for diesel engines, is that they have a groove for an oil ring below the gudgeon pin, in addition to the rings between the gudgeon pin and crown.

The name 'trunk piston' derives from the 'trunk engine', an early design of marine steam engine. To make these more compact, they avoided the steam engine's usual piston rod with separate crosshead and were instead the first engine design to place the gudgeon pin directly within the piston. Otherwise these trunk engine pistons bore little resemblance to the trunk piston; they were extremely large diameter and double-acting. Their 'trunk' was a narrow cylinder mounted in the centre of the piston.

Large slow-speed Diesel engines may require additional support for the side forces on the piston. These engines typically use crosshead pistons. The main piston has a large piston rod extending downwards from the piston to what is effectively a second smaller-diameter piston. The main piston is responsible for gas sealing and carries the piston rings. The smaller piston is purely a mechanical guide. It runs within a small cylinder as a trunk guide and also carries the gudgeon pin.

Lubrication of the crosshead has advantages over the trunk piston as its lubricating oil is not subject to the heat of combustion: the oil is not contaminated by combustion soot particles, it does not break down owing to the heat and a thinner, less viscous oil may be used. The friction of both piston and crosshead may be only half of that for a trunk piston.

Because of the additional weight of these pistons, they are not used for high-speed engines.

A slipper piston is a piston for a petrol engine that has been reduced in size and weight as much as possible. In the extreme case, they are reduced to the piston crown, support for the piston rings, and just enough of the piston skirt remaining to leave two lands so as to stop the piston rocking in the bore. The sides of the piston skirt around the gudgeon pin are reduced away from the cylinder wall. The purpose is mostly to reduce the reciprocating mass, thus making it easier to balance the engine and so permit high speeds. In racing applications, slipper piston skirts can be configured to yield extremely light weight while maintaining the rigidity and strength of a full skirt. Reduced inertia also improves mechanical efficiency of the engine: the forces required to accelerate and decelerate the reciprocating parts cause more piston friction with the cylinder wall than the fluid pressure on the piston head. A secondary benefit may be some reduction in friction with the cylinder wall, since the area of the skirt, which slides up and down in the cylinder is reduced by half. However, most friction is due to the piston rings, which are the parts which actually fit the tightest in the bore and the bearing surfaces of the wrist pin, and thus the benefit is reduced.

Deflector pistons are used in two-stroke engines with crankcase compression, where the gas flow within the cylinder must be carefully directed in order to provide efficient scavenging. With cross scavenging, the transfer (inlet to the cylinder) and exhaust ports are on directly facing sides of the cylinder wall. To prevent the incoming mixture passing straight across from one port to the other, the piston has a raised rib on its crown. This is intended to deflect the incoming mixture upwards, around the combustion chamber.

Much effort, and many different designs of piston crown, went into developing improved scavenging. The crowns developed from a simple rib to a large asymmetric bulge, usually with a steep face on the inlet side and a gentle curve on the exhaust. Despite this, cross scavenging was never as effective as hoped. Most engines today use Schnuerle porting instead. This places a pair of transfer ports in the sides of the cylinder and encourages gas flow to rotate around a vertical axis, rather than a horizontal axis.

In racing engines, piston strength and stiffness is typically much higher than that of a passenger car engine, while the weight is much less, to achieve the high engine RPM necessary in racing. 

Steam engines are usually double-acting (i.e. steam pressure acts alternately on each side of the piston) and the admission and release of steam is controlled by slide valves, piston valves or poppet valves. Consequently, steam engine pistons are nearly always comparatively thin discs: their diameter is several times their thickness. (One exception is the trunk engine piston, shaped more like those in a modern internal-combustion engine.) Another factor is that since almost all steam engines use crossheads to translate the force to the drive rod, there are few lateral forces acting to try and "rock" the piston, so a cylinder-shaped piston skirt isn't necessary.

Piston pumps can be used to move liquids or compress gases.

There are two special type of pistons used in air cannons: close tolerance pistons and double pistons. In close tolerance pistons O-rings serve as a valve, but O-rings are not used in double piston types.





</doc>
<doc id="24778" url="https://en.wikipedia.org/wiki?curid=24778" title="PK">
PK

PK or pk may refer to:












</doc>
<doc id="24779" url="https://en.wikipedia.org/wiki?curid=24779" title="Psi">
Psi

Psi or the initials PSI or Ψ may refer to:














</doc>
<doc id="24780" url="https://en.wikipedia.org/wiki?curid=24780" title="Five precepts">
Five precepts

The five precepts (; ) or rules of training (; ) constitute the basic code of ethics undertaken by upāsaka and upāsikā (lay followers) of Buddhism. The precepts in all the traditions are essentially identical and are commitments to abstain from harming living beings, stealing, sexual misconduct, lying and intoxication.

Undertaking the five precepts is part of both lay Buddhist initiation and regular lay Buddhist devotional practices. They are not formulated as imperatives, but as training rules that lay people undertake voluntarily to facilitate practice.

"Śīla" (Sanskrit; ) is used to refer to Buddhist precepts, including the five. But the word also refers to the virtue and morality which lies at the foundation of the spiritual path to enlightenment, which is the first of the three forms of training on the path. Thus, the precepts are rules or guidelines to develop mind and character to make progress on the path to enlightenment. The five precepts are part of the right speech, action and livelihood aspects of the eight-fold path, the core teaching of Buddhism. Moreover, the practice of the five precepts and other parts of "śīla" are forms of merit-making, means to create good karma.

The five precepts also form the basis of the eight precepts, which are a stricter level of precepts for laypeople, similar to monastic precepts. Secondly, the five precepts form the first half of the ten or eleven Mahāyāna precepts, as mentioned in the Brahmajala Sutra, a text believed to have been composed in China.

The following are the five precepts, rendered in English and Pāli:

In the fifth precept sura, meraya and majja are kinds of alcoholic beverages. In some modern translations, "Surāmerayamajjapamādaṭṭhānā", is rendered more broadly, variously, as, "intoxicants", "liquor and drugs", etc. The monastic discipline allows the use of alcohol when taken as part of medicinal treatments.

The format of the ceremony for taking the precepts occurs several times in the Chinese texts, in slightly different forms, and each temple or tradition has different ordination ceremonies.

One ceremonial version of the precepts can be found in the Treatise on Taking Refuge and the Precepts ().


The same treatise outlines the option of undertaking fewer than all five precepts, though nearly all modern ceremonies involve undertaking all five precepts. Some modern teachers, such as the Taiwanese teacher Yin-Shun, have used simplified formulas for the five precepts.

Buddhist scriptures explain the five precepts as the minimal standards of Buddhist morality. They are regarded as means to building good character, or as an expression of such character. The texts also describe the precepts as ways for devotees to avoid harm to themselves and others. In the Pāli Canon, the five precepts are described as gifts toward oneself and others. Moreover, the Buddha mentions the consequences of breaking the precepts.

The precepts are normative rules, but are usually not understood as commandments enforced by a moral authority, according to the voluntary and gradualist standards of Buddhist ethics. The precepts are forms of restraint, but are also accompanied by virtues. There are several virtues and principles which are fundamental to the precepts, and are cultivated through them. The most important of these is non-harming (Pāli and ), which underlies all of the five precepts.

In the upholding or violation of the precepts, intention is crucial. In the Pāli scriptures, an example is mentioned of a person stealing an animal only to set it free, which was not seen as an offense of theft. In the Pāli commentaries, a precept is understood to be violated when the person violating it finds the object of the transgression (e.g. things to be stolen), is aware of the violation, has the intention to violate it, does actually act on that intention, and does so successfully.

The first precept prohibits the taking of life of a sentient being. It is violated when someone intentionally kills such a sentient being, having understood it to be sentient. This includes taking the lives of animals, even small insects. Nevertheless, it has also been pointed out that the seriousness of taking life depends on the size, intelligence and the spiritual attainments of that living being. Killing a large animal is worse than killing a small animal (because it costs more effort); killing a spiritually accomplished master is regarded as more severe than the killing of another "more average" human being; and killing a human being is more severe than the killing an animal. But all killing is condemned. The first precept is not motivated by a principle of preserving life, but rather by respect for dignity of life. Other virtues that accompany this precept are kindness and compassion.

The second precept prohibits theft, and involves the intention to steal what one perceives as not belonging to oneself ("what is not given") and acting successfully upon that intention. The severity of the act of theft is judged by the worth of the owner and the worth of that which is stolen. Underhand dealings are also included in theft. Accompanying virtues are generosity and renunciation. The third precept involves bad sexual behavior against women that are "protected", "claimed" or "acquired". The transgression is regarded as more severe if the other person is a good person. A virtue that goes hand-in-hand with the third precept is contentment with one's partner. The fourth precept involves falsehood spoken or committed to by action, which is considered more serious if the falsehood is motivated by a serious ulterior motive (rather than, for example, spoken as a joke). The accompanying virtue is honesty. The fifth precept prohibits intoxication through alcohol, drugs or other means, and its virtue is mindfulness and responsibility. The importance of awareness, meditation and heedfulness in Buddhist doctrine is clarified by the last words ascribed to the Buddha, in which awareness of mind has a central role.

Upholding the precepts is sometimes distinguished in three levels: to uphold them without having formally undertaken them, to uphold them formally, willing to sacrifice our own life for it, and finally, to spontaneously uphold them. The latter refers to enlightened disciples of the Buddha, who are understood to be morally incapable of violating the first four precepts.

The most serious violations of the precepts are the five actions of immediate retribution, which are believed to lead the perpetrator to an unavoidable rebirth in hell. These consist of injuring a Buddha, killing an enlightened disciple, killing one's father or mother, and causing the monastic community to have a schism.

Lay followers often undertake these training rules in the same ceremony as they take the refuges. In Mahāyāna schools, a lay practitioner who has taken the precepts is called an upāsaka or upāsikā (layman or laywoman). In Theravāda Buddhism, any lay follower is in theory called an upāsaka or upāsikā; in practice, everyone is expected to take the precepts. Additionally, traditional Theravāda lay devotional practice () includes daily rituals taking refuge and undertaking to observe the five precepts. Thus, the five precepts are at the core of Buddhist morality. Nevertheless, Buddhists do not all follow them with the same strictness. Devotees who have just started keeping the precepts, will typically have to exercise considerable restraint. When they become used to the precepts, they start to embody them more naturally.

A 1966 survey in Cambodia showed that Buddhists considered the first precept the most important. In some traditional communities, such as in Kandal Province in Cambodia, it was uncommon for Buddhists to slaughter animals, to the extent that meat had to be bought from not-Buddhists. The prohibition on killing has motivated early Buddhists to form a stance against animal sacrifice, a common ritual practice in ancient India. It did not, at least according to the Pāli Canon, lead them to adopt a vegetarian lifestyle, however. Indeed, in several Pāli texts vegetarianism is described as irrelevant in the spiritual purification of the mind. There are prohibitions on certain types of meat, however, especially those which are condemned by society. The idea of abstaining from killing animal life has also led to a prohibition on professions that involve trade in flesh or living beings, but not to a full prohibition of all agriculture that involves cattle. In modern times, however, referring to the law of supply and demand, some Theravādin Buddhists have attempted to promote vegetarianism as part of the five precepts. Furthermore, among some schools of Buddhism, there has been some debate with regard to a principle in the monastic discipline. This principle states that a Buddhist monk cannot accept meat if it comes from animals especially slaughtered for him. Some teachers have interpreted this to mean that when the recipient has no knowledge on whether the animal has been killed for him, he cannot accept the food either. Similarly, there has been debate as to whether laypeople should be vegetarian when adhering to the five precepts. Vegetarianism as part of the precepts has mostly been practiced in East Asian countries, as some later Mahāyāna texts, such as the Mahāparanirvana Sūtra and the Laṅkāvatāra Sūtra, condemn the eating of meat. Nevertheless, even among Mahāyāna Buddhistsand East Asian Buddhiststhere is disagreement on whether vegetarianism should be practiced. In the Laṅkāvatāra Sūtra, biological, social and hygienic reasons are given for a vegetarian diet; however, historically, a major factor in the development of a vegetarian lifestyle among Mahāyāna communities may have been that they cultivated their own crops for food, rather than living from alms.

There is some debate and controversy surrounding the problem whether a person can commit suicide, such as self-immolation, to reduce other people's suffering in the long run, such as in political protest to improve a political situation in a country. Teachers like the Dalai Lama and Shengyan have rejected forms of protest like self-immolation, as well as fasting or other acts of self-harming.

The first precept does not include an absolute prohibition of termination of pregnancy, but this is considered very much unwanted.

The second precept includes different ways of stealing and fraud. Borrowing without permission is sometimes included. 

The third precept is interpreted as harming another by using sensuality in the wrong way. It involves engaging with inappropriate partners, but also respecting one's commitment to a relationship. In modern times, adherence to the precepts among Buddhists is less strict than it traditionally was. This is especially true for the third precept. For example, in Cambodia in the 1990s and 2000s, standards with regard to sexual restraint were greatly relaxed. Finally, the third precept is not connected with a stance against contraception.

The fourth precept includes avoidance of lying and harmful speech. Some practitioners view it as refraining from not just lying, but also idle chat and gossip. 

As for the fifth precept, this is regarded as important, because drinking alcohol is condemned for the lack of self-control it leads to. Nevertheless, in practice it is often disregarded.

Several modern teachers such as Thich Nhat Hanh and Sulak Sivaraksa have written about the five precepts in a wider scope, with regard to social and institutional relations. In these perspectives, mass production of weapons or spreading untruth through media and education also violate the precepts. On a similar note, human rights organizations in Southeast Asia have attempted to advocate respect for human rights by referring to the five precepts as a guiding principle.

The five precepts were part of early Buddhism and are common to nearly all schools of Buddhism. In Early Buddhism, the five precepts were regarded as an ethic of restraint, to restraint unwholesome tendencies and thereby purify one's being.

Sometimes the five precepts were adapted in difficult circumstances. E.g. the Chinese Buddhist monk Wŏn'gwang (630?) developed a new interpretation of the five precepts, in which killing of certain people was allowed, and which included gratitude to parents and loyalty to authorities.

Some Buddhist movements and communities have tried to go against the modern trend of less strict adherence to the precepts. In Cambodia, a millenarian movement led by Chan Yipon promoted the revival of the five precepts. And in the 2010s, the Supreme Sangha Council in Thailand ran a nationwide program called "The Villages Practicing the Five Precepts", aiming to encourage keeping the precepts, with an extensive classification and reward system.

Studying lay and monastic ethical practice in traditional Buddhist societies, anthropologist Melford Spiro argued ethical guidelines such as the five precepts are adhered to as a means to a higher end, that is, a better rebirth or enlightenment. He therefore concluded that Buddhist ethical principles like the five precepts are similar to Western utilitarianism. Bioethicist Damien Keown, however, has observed that the five precepts are regarded as rules that cannot be violated, and therefore may indicate a deontological perspective in Buddhist ethics. On the other hand, he has suggested that Aristoteles' virtue ethics could apply as well, since the precepts are considered good in themselves, and mutually dependent on other aspects of the Buddhist path of practice. Philosopher William Edelglass points out that the precepts are based on virtues.




</doc>
<doc id="24782" url="https://en.wikipedia.org/wiki?curid=24782" title="Pente">
Pente

Pente is a strategy board game for two or more players, created in 1977 by Gary Gabrel, a dishwasher at Hideaway Pizza, in Stillwater, Oklahoma. Customers played Pente at Hideaway Pizza on checkerboard tablecloths while waiting for their orders to arrive. Thirty years later, patrons are still playing Pente at Hideaway Pizza, although now with roll-up Pente boards. Pente is based on the Japanese game ninuki-renju, a variant of renju or gomoku that is played on a Go board of 19x19 intersections with white and black stones. Like "ninuki-renju," Pente allows captures, but Pente added a new opening rule. In the nineteenth century, "gomoku" was introduced to Britain where it was known as "Go Bang." (borrowed from Japanese "goban" 碁盤 meaning "go board")

Pente is a registered trademark of Hasbro for strategy game equipment. Pente (πέντε) is the number five in Greek.

Hasbro ceased distribution of Pente in 1993. It later licensed the name to Winning Moves, a classic games publisher that resurrected the game in 2004. The 2004 version includes 4 extra stones, called power stones, that can be played in the Pente Plus version.

The players alternate in placing stones of their color on free intersections, with White always assuming the opening move. The players aim to align five stones of the same color in vertical, horizontal or diagonal lines. Captures are obtained by flanking pairs of an opponent's stones in any same direction. Captures must consist of exactly two stones; flanking a single stone or three stones does not result in a capture. For example, if the stones are X O O _ and you place your stone so it becomes X O O X, then your opponent's stones are removed from the board, leaving X _ _ X. A stone may legally be placed on any empty intersection, even if it forms a pair between two enemy stones. For example, if the stones are X O _ X you may place your stone so it becomes X O O X. Your stones are NOT captured in this case. When playing with multiple players the inside stones can be different colors, but the two stones on the outside must be the same colors. For example, X O Y X. It must be a pair in order to capture. 

A player wins by scoring five stones in a row. It can be horizontal, vertical, or diagonal. A player can also win by capturing five pairs of opponent stones. Pente can also be played by four people, with pairs of two acting as partners. It can also be played with multiple independent players when each player has their own different colored stones. 

In this common variation, the first player's second move is restricted — it must be at least three intersections away from the center of the board. The tournament rule was created by Tom Braunlich to reduce the advantage held by the first player.



</doc>
<doc id="24783" url="https://en.wikipedia.org/wiki?curid=24783" title="Pompatus">
Pompatus

Pompatus () is a nonsense word coined by Steve Miller and most famously used in his 1973 hit single "The Joker". The word was inspired by a similar nonsense word, sometimes transliterated as "puppetutes," in the 1954 song "The Letter" by The Medallions. The oddness and unknown meaning of the word occasioned some attention and further use, including being used in the title of a movie.

The lyrics of "The Joker" include the quatrain:

Each line references a track on a previous Miller album: "Space Cowboy" on "Brave New World" (1969); "Gangster of Love" on "Sailor" (1968); and "Enter Maurice" on "Recall the Beginning...A Journey from Eden" (1972), which includes the lines:

Although Miller claims he invented the words "epismetology" (a metathesis of the word epistemology) and "pompatus", both are variants of words which Miller most likely heard in a song by Vernon Green called "The Letter," which was recorded by the Los Angeles Doo-Wop group The Medallions in 1954.

Green's "The Letter" as performed by the Medallions had the lines:

Green describes the lyrics as a description of his dream woman. ""Pizmotality" described words of such secrecy that they could only be spoken to the one you loved", Green explained. He coined the term "puppetutes" "to mean a secret paper-doll fantasy figure who would be my everything and bear my children".

Because of its peculiarity, the word "pompatus" has secured a niche in 20th century pop culture. Wolfman Jack frequently referenced the phrase and there is a sound clip of him using the line within the song "Clap for the Wolfman" by The Guess Who. "The Pompatus of Love", a 1996 film starring Jon Cryer, featured four men discussing a number of assorted topics, including attempts to determine the meaning of the phrase. Jon Cryer was also a writer of the film, and describes finding out the meaning of the phrase during a phone call with Vernon Green in his autobiography "so that happened" in chapter 22, page 217. The line has been mentioned in various television show gags, including "The Simpsons" and "South Park".

Humor columnist Dave Barry frequently refers to the song line as a source of comedic value, particularly in his 1997 book "Dave Barry's Book of Bad Songs". 'Pompatus' is used by Michael Ondaatje in his 2001 book "Anil's Ghost". Stephen King uses the word in his 2006 novel "Lisey's Story". Tim Dorsey uses the word in his 2010 novel, "Gator a-Go-Go". It was the subject of the October 9, 2011 "Over the Hedge" comic strip.



</doc>
<doc id="24787" url="https://en.wikipedia.org/wiki?curid=24787" title="UGM-27 Polaris">
UGM-27 Polaris

The UGM-27 Polaris missile was a two-stage solid-fueled nuclear-armed submarine-launched ballistic missile. The United States Navy's first SLBM, it served from 1961 to 1996.

The Polaris project was created to replace the solid-fueled Jupiter S project, which had been approved in 1956 to replace the liquid-fueled SM-78 and PGM-19 Jupiter missiles. In December 1956, the United States Navy awarded Polaris development contracts to Lockheed Corporation and Aerojet Rocketdyne.

The Polaris missile was designed to be used for second strike countervalue (CEP not good enough for first strike counterforce) as part of the Navy's contribution to the United States arsenal of nuclear weapons, replacing the Regulus cruise missile. Known as a Fleet Ballistic Missile (FBM), the Polaris was first launched from the Cape Canaveral, Florida, missile test base on January 7, 1960.

Following the Polaris Sales Agreement in 1963, Polaris missiles were also carried on British Royal Navy submarines between 1968 and the mid-1990s.

Plans to equip the Italian Navy with the missile ended in the mid-60s, after several successful test launches carried out on board the . Despite the successful launching tests, the plan was abandoned due to the completion of initial SSBN vessels. Nonetheless, the Italian government set out to develop an indigenous missile, called Alfa. The program was successful, but was halted by Italy's ratification of the Nuclear Non-Proliferation Treaty and the failure of the NATO Multilateral Force.

The Polaris missile was gradually replaced on 31 of the 41 original SSBNs in the U.S. Navy by the MIRV-capable Poseidon missile beginning in 1972. During the 1980s, these missiles were replaced on 12 of these submarines by the Trident I missile. The 10 - and SSBNs retained Polaris A-3 until 1980 because their missile tubes were not large enough to accommodate Poseidon. With beginning sea trials in 1980, these submarines were disarmed and redesignated as attack submarines to avoid exceeding the SALT II strategic arms treaty limits.

The Polaris missile program's complexity led to the development of new project management techniques, including the Program Evaluation and Review Technique (PERT) to replace the simpler Gantt chart methodology.

At the start of the second World War, nearly every major world military force that was involved in the war had at least developed rough ideas of a rocket program. It is important to note that at this time the distinction between rockets and missiles was simply this: rockets traveled over a fixed trajectory and missiles could be guided to their destination. Rockets of all shapes and sizes were being implemented in war-zones around the globe. The Soviets deployed rockets such as the Stalin Organ, which were fired from a mobile launcher in waves of up to nearly 50 small, unguided rockets, and the Japanese were implementing rockets that would be used on the front lines. Rockets such as the Stalin Organ could fire at targets within three miles, while the first Japanese rockets were only valuable for targets less than five-hundred feet away. The initial version of the Japanese Kamikaze planes were made of wood and powered by rockets. These wooden suicide planes did not provide the Japanese forces with a reliable weapon, and by 1945 the Kamikaze gliders were being used in combat, no matter how ineffective they may have been. British forces, too, had begun developments on anti-aircraft rockets of their own, which proved effective as early as 1941. Soon after the attacks on Pearl Harbor, the United States also joined arms in the race for rockets borrowing much of its initial products from the British armed forces. The United States rocket program began regularly testing both rockets and missiles, and by 1945, the Army was investing roughly $150 million a year, while the Navy was spending $1.2 billion. Despite these efforts from the major contributing forces in the war, German scientists excelled quickly at mastering the largest and most advanced weapons. One of which, the German V-2 rocket, would become the blueprint for all of the serious global missile programs to come.

As the United States Army continued to make steady advancements in its rocket and missile programs it quickly became apparent that if the program wished to keep up with its own rapid growth, as well as with the rest of the world, it would certainly need more space than what was available. On October 28, 1949, Huntsville, Alabama, was chosen based on its promising location and easy access to resources to be the new home to the American program. By the end of 1950, the Redstone Arsenal was operational and took on the new designation as the Ordnance Guided Missile Center.

The Polaris missile replaced an earlier plan to create a submarine-based missile force based on a derivative of the U.S. Army Jupiter Intermediate-range ballistic missile. Chief of Naval Operations Admiral Arleigh Burke appointed Rear Admiral W. F. "Red" Raborn as head of a Special Project Office to develop Jupiter for the Navy in late 1955. The Jupiter missile's large diameter was a product of the need to keep the length short enough to fit in a reasonably-sized submarine. At the seminal Project Nobska conference in 1956, with Admiral Burke present, nuclear physicist Edward Teller stated that a physically small one-megaton warhead could be produced for Polaris within a few years, and this prompted Burke to leave the Jupiter program and concentrate on Polaris in December of that year. Polaris was spearheaded by the Special Project Office's Missile Branch under Rear Admiral Roderick Osgood Middleton, and is still under the Special Project Office. Admiral Burke later was instrumental in determining the size of the Polaris submarine force, suggesting that 40-45 submarines with 16 missiles each would be sufficient. Eventually, the number of Polaris submarines was fixed at 41.

The was the first submarine that was capable of deploying a submarine-launched ballistic missiles (SLBM) the US developed. The responsibility of the development of SLBMs was given to the Navy and the Army. The Air Force was charged with developing a land-based intermediate range ballistic missile (IRBM), while an IRBM which could be launched by land or by sea was tasked to the Navy and Army. The Navy Special Projects (SP) office was at the head of the project. It was led by Rear Admiral William Raborn.

On September 13, 1955, James R. Killian, head of a special committee organized by President Eisenhower, recommended that both the Army and Navy come together under a program aimed at developing an Intermediate Range Ballistic Missile (IRBM). The missile, later known as Jupiter, would be developed under the Joint Army-Navy Ballistic Missile Committee approved by Secretary of Defense Charles E. Wilson in early November of that year. The first IRBM boasted a liquid-fueled design. Liquid fuel is compatible with aircraft; it is less compatible with submarines. Solid fuels, on the other hand, make logistics and storage simpler and are safer. Not only was the Jupiter a liquid fuel design, it was also very large; even after it was designed for solid fuel, it was still a whopping 160,000 pounds. A smaller, new design would weigh much less, estimated at 30,000 pounds. The Navy would rather develop a smaller, more easily manipulated design. Edward Teller was one of the scientists encouraging the progress of smaller rockets. He argued that the technology needed to be discovered, rather than apply technology that is already created. Raborn was also convinced he could develop smaller rockets. He sent officers to make independent estimates of size to determine the plausibility of a small missile; while none of the officers could agree on a size, their findings were encouraging nonetheless.

The US Navy began work on nuclear-powered submarines in 1946. They launched the first one, the in 1955. Nuclear powered submarines were the least vulnerable to a first strike from the Soviet Union.The next question that led to further development was what kind of arms the nuclear-powered submarines should be equipped with. In the summer of 1956, the navy sponsored a study by the National Academy of Sciences on anti-submarine warfare at Nobska Point in Woods Hole, Massachusetts, known as Project NOBSKA. The navy’s intention was to have a new missile developed that would be lighter than existing missiles and cover a range up to fifteen hundred miles. A problem that needed to be solved was that this design would not be able to carry the desired one-megaton thermonuclear warhead.

This study brought Edward Teller from the recently formed nuclear weapons laboratory at Livermore and J. Carson Mark, representing the Los Alamos nuclear weapons laboratory. Teller was already known as a nuclear salesman, but this became the first instance where there was a big betting battle where he outbid his Los Alamos counterpart. The two knew each other well: Mark was named head of the theoretical division of Los Alamos in 1947, a job that was originally offered for Teller. Mark was a cautious physicist and no match for Teller in a bidding war.

At the NOBSKA summer study, Edward Teller made his famous contribution to the FBM program. Teller offered to develop a lightweight warhead of one-megaton strength within a prescribed five years. He suggested that nuclear-armed torpedoes could be substituted for conventional ones to provide a new anti-submarine weapon. Livermore received the project. When Teller returned to Livermore, people were astonished by the boldness of Teller’s promise. It seemed inconceivable with the current size of nuclear warheads, and Teller was challenged to support his assertion. He pointed out the trend in warhead technology, which indicated reduced weight to yield ratios in each succeeding generation. When Teller was questioned about the application of this to the FBM program, he asked, ‘Why use a 1958 warhead in a 1965 weapon system?’

Mark disagreed with Teller’s prediction that the desired one-megaton warhead could be made to fit the missile envelope within the timescale envisioned. Instead, Mark suggested that half a megaton would be more realistic and he quoted a higher price and a longer deadline. This simply confirmed the validity of Teller’s prediction in the Navy’s eyes. Whether the warhead was half or one megaton mattered little so long as it fitted the missile and would be ready by the deadline. Almost four decades later, Teller said, referring to Mark’s performance, that it was “an occasion when I was happy about the other person being bashful.”
When the Atomic Energy Commission backed up Teller’s estimate in early September, Admiral Burke and the Navy Secretariat decided to support SPO in heavily pushing for the new missile, now named Polaris by Admiral Raborn.

There is a contention that the Navy's "Jupiter" missile program was unrelated to the Army program. The Navy also expressed an interest in Jupiter as an SLBM, but left the collaboration to work on their Polaris. At first, the newly assembled SPO team had the problem of making the large, liquid-fuel Jupiter IRBM to work properly. Jupiter retained the short, squat shape intended to fit in naval submarines. Its sheer size and volatility of its fuel made it very unsuited to submarine launching and was only slightly more attractive for deployment on ships. The missile continued to be developed by the Army’s German team in collaboration with their main contractor, Chrysler Corporation. SPO’s responsibility was to develop a sea-launching platform with necessary fire control and stabilization systems for that very purpose. The original schedule was to have a ship-based IRBM system ready for operation evaluation by January 1, 1960, and a submarine-based one by January 1, 1965.
However, the Navy was deeply dissatisfied with the liquid fuel IRBM. The first concern was that the cryogenic liquid fuel was not only extremely dangerous to handle, but launch-preparations were also very time-consuming. Second, an argument was made that liquid-fueled rockets gave relatively low initial acceleration, which is disadvantageous in launching a missile from a moving platform in certain sea states. By mid-July 1956, the Secretary of Defense’s Scientific Advisory Committee had recommended that a solid-propellant missile program be fully instigated but not using the unsuitable Jupiter payload and guidance system.
By October 1956, a study group comprising key figures from Navy, industry and academic organizations considered various design parameters of the Polaris system and trade-offs between different sub-sections. The estimate that a 30,000-pound missile could deliver a suitable warhead over 1500 nautical miles was endorsed. With this optimistic assessment, the Navy now decided to scrap the Jupiter program altogether and sought out the Department of Defense to back a separate Navy missile.
A huge surfaced submarine would carry four "Jupiter" missiles, which would be carried and launched horizontally. This was probably the never-built SSM-N-2 Triton program. However, a history of the Army's Jupiter program states that the Navy was involved in the Army program, but withdrew at an early stage.

Originally, the Navy favored cruise missile systems in a strategic role, such as the Regulus missile deployed on the earlier and a few other submarines, but a major drawback of these early cruise missile launch systems (and the Jupiter proposals) was the need to surface, and remain surfaced for some time, to launch. Submarines were very vulnerable to attack during launch, and a fully or partially fueled missile on deck was a serious hazard. The difficulty of preparing a launch in rough weather was another major drawback for these designs, but rough sea conditions did not unduly affect Polaris' submerged launches.

It quickly became apparent that solid-fueled ballistic missiles had advantages over cruise missiles in range and accuracy, and could be launched from a submerged submarine, improving submarine survivability.

The prime contractor for all three versions of Polaris was Lockheed Missiles and Space Company, now Lockheed Martin.

The Polaris program started development in 1956. , the first US missile submarine, successfully launched the first Polaris missile from a submerged submarine on July 20, 1960. The A-2 version of the Polaris missile was essentially an upgraded A-1, and it entered service in late 1961. It was fitted on a total of 13 submarines and served until June 1974.(1). Ongoing problems with the W-47 warhead, especially with its mechanical arming and safing equipment, led to large numbers of the missiles being recalled for modifications, and the U.S. Navy sought a replacement with either a larger yield or equivalent destructive power. The result was the W-58 warhead used in a "cluster" of three warheads for the Polaris A-3, the final model of the Polaris missile.

One of the initial problems the Navy faced in creating an SLBM was that the sea moves, while a launch platform on land does not. Waves and swells rocking the boat or submarine, as well as possible flexing of the ship’s hull had to be taken into account to properly aim the missile.

The Polaris development was kept on a tight schedule and the only influence that changed this was the USSR’s launching of SPUTNIK on October 4, 1957. This caused many working on the project to want to accelerate development. The launch of a second Russian satellite and pressing public and government opinions cause Secretary Wilson to move the project along quicker.

The Navy favored an underwater launch of an IRBM, although the project began with an above-water launch goal. They decided to continue the development of an underwater launch, and developed two ideas for this launch: wet and dry. Dry launch meant encasing the missile in a shell that would peel away when the missile reached the water’s surface. Wet launch meant shooting the missile through the water without a casing. While they Navy was in favor of a wet launch, they developed both methods as a failsafe. They did this with the development of gas and air propulsion of the missile out of the submerged tube as well.

The first Polaris missile tests were given the names “AX-#” and later renamed “A1X-#”. Testing of the missiles occurred:

Sept 24, 1958: AX-1, at Cape Canaveral from a launch pad; the missile was destroyed, after it failed to turn into the correct trajectory following a programming-error.

October 1958: AX-2, at Cape Canaveral from a launch pad; exploded on the launch pad.

December 30, 1958: AX-3, at Cape Canaveral from a launch pad; launched correctly, but was destroyed because of the fuel overheating.

January 19, 1959: AX-4, at Cape Canaveral from launch pad: launched correctly but began to behave erratically and was destroyed.

February 27, 1959: AX-5, at Cape Canaveral from launch pad: launched correctly but began to behave erratically and was destroyed.

April 20, 1959: AX-6, at Cape Canaveral from launch pad: this test was a success. The missile launched, separated, and splashed into the Atlantic 300 miles off shore.

It was in between these two tests that the inertial guidance system was developed and implemented for testing.

July 1, 1959: AX-11 at Cape Canaveral from a launch pad: this launch was successful, but pieces of the missile detached causing failure. It did show that the new guidance systems worked.

At the time that the Polaris project went live, submarine navigation systems were and at this time that standard was sufficient enough to sustain effective military efforts given the existing weapons systems in use by the Army, Air Force and Navy. Initially, developers of Polaris were set to utilize the existing 'Stable Platform' configuration of the inertial guidance system. Created at the MIT Instrumentation Laboratory, this Ships Inertial Navigation System (SINS) was supplied to the Navy in 1954. The developers of Polaris encountered many issues from the birth of the project, however, perhaps the most unsettling for them was the outdated technology of the gyroscopes they would be implementing.
This 'Stable Platform' configuration did not account for the change in gravitational fields that the submarine would experience while it was in motion, nor did it account for the ever-altering position of the Earth. This problem raised many concerns, as this would make it nearly impossible for navigational read outs to remain accurate and reliable. A submarine hauling several hundred-thousand pounds of Fleet Ballistic Missiles was of little to no use if operators had no way to direct them. Polaris was thus forced to seek elsewhere and quickly found hope in a guidance system that had been abandoned by the US Air Force. A company by the name of Autonetics Division of North American Aviation had previously been faced with the task of developing a guidance system for the US Air Force Navaho known as the XN6 Autonavigator. The XN6 was a system designed for air-breathing Cruise missiles, but by 1958 had proved useful for installment on submarines.

A predecessor to the GPS satellite navigation system, the Transit system (later called NAVSAT), was developed because the submarines needed to know their position at launch in order for the missiles to hit their targets. Two American physicists, William Guier and George Weiffenbach, at Johns Hopkins's Applied Physics Laboratory (APL), began this work in 1958. A computer small enough to fit through a submarine hatch was developed in 1958, the AN/UYK-1. It was used to interpret the Transit satellite data and send guidance information to the Polaris, which had its own guidance computer made with ultra miniaturized electronics, very advanced for its time, because there wasn't much room in a Polaris—there were 16 on each submarine. The Ship's Inertial Navigation System (SINS) was developed earlier to provide a continuous dead reckoning update of the submarine's position between position fixes via other methods, such as LORAN. This was especially important in the first few years of Polaris, because Transit was not operational until 1964. By 1965 microchips similar to the Texas Instruments units made for the Minuteman II were being purchased by the Navy for the Polaris. The Minuteman guidance systems each required 2000 of these, so the Polaris guidance system may have used a similar number. To keep the price under control, the design was standardized and shared with Westinghouse Electric Company and RCA. In 1962, the price for each Minuteman chip was $50, the price dropped to $2 in 1968.

This missile replaced the earlier A-1 and A-2 models in the US Navy, and also equipped the British Polaris force. The A-3 had a range extended to and a new weapon bay housing three Mk 2 re-entry vehicles (ReB or Re-Entry Body in US Navy and British usage); and the new W-58 warhead of 200 kt yield. This arrangement was originally described as a "cluster warhead" but was replaced with the term Multiple Re-Entry Vehicle (MRV). The three warheads were spread about a common target and were not independently targeted (such as a MIRV missile is). The three warheads were stated to be equivalent in destructive power to a single one-megaton warhead. Later the Polaris A-3 missiles (but not the ReBs) were also given limited hardening to protect the missile electronics against nuclear electromagnetic pulse effects while in the boost phase. This was known as the A-3T ("Topsy") and was the final production model.

The initial test model of the Polaris was referred to as the AX series and made its maiden flight from Cape Canaveral on September 24, 1958. The missile failed to perform its pitch and roll maneuver and instead just flew straight up, however the flight was considered a partial success (at that time, "partial success" was used for any missile test that returned usable data). The next flight on October 15 failed spectacularly when the second stage ignited on the pad and took off by itself. Range Safety blew up the errant rocket while the first stage sat on the pad and burned. The third and fourth tests (December 30 and January 9) had problems due to overheating in the boattail section. This necessitated adding extra shielding and insulation to wiring and other components. When the final AX flight was conducted a year after the program began, 17 Polaris missiles had been flown of which five met all of their test objectives.

The first operational version, the Polaris A-1, had a range of and a single Mk 1 re-entry vehicle, carrying a single W-47-Y1 600 kt nuclear warhead, with an inertial guidance system which provided a circular error probable (CEP) of . The two-stage solid propellant missile had a length of , a body diameter of , and a launch weight of .

Work on its W47 nuclear warhead began in 1957 at the facility that is now called the Lawrence Livermore National Laboratory by a team headed by John Foster and Harold Brown. The Navy accepted delivery of the first 16 warheads in July 1960. On May 6, 1962, a Polaris A-2 missile with a live W47 warhead was tested in the "Frigate Bird" test of Operation Dominic by in the central Pacific Ocean, the only American test of a live strategic nuclear missile.

The two stages were both steered by thrust vectoring. Inertial navigation guided the missile to about a 900 m (3,000-foot) CEP, insufficient for use against hardened targets. They were mostly useful for attacking dispersed military surface targets (airfields or radar sites), clearing a pathway for heavy bombers, although in the general public perception Polaris was a strategic second-strike retaliatory weapon.

The Polaris A-1 missile was developed to complement the limited number of medium-range systems deployed throughout Europe. As those systems lacked the range to attack major Soviet targets, Polaris was developed to increase the level of nuclear deterrence. At this time there was little threat of counterforce strikes, as few systems had the accuracy to destroy missile systems. The primary advantages of ballistic missile submarines was their ability to launch submerged, which offered improved survivability for the submarine while also (like their Regulus predecessors) keeping shorter ranged systems within range.

The USN had forward-basing arrangements for its Atlantic-based Polaris fleet with both the United Kingdom and Spain, permitting the use of bases at the Holy Loch in Scotland (established in 1961) and at Naval Station Rota (Polaris base established 1964) in the Bay of Cadiz. The forward deployment bases were much closer to patrol areas than U.S. East Coast bases, avoiding the necessity for lengthy transit times. In the Pacific, a Polaris base was also established at Guam in 1964. The Regulus missile program was deactivated with the advent of Polaris in the Pacific. The forward-basing arrangement was continued when Poseidon replaced Polaris, starting in 1972, in what by then were the 31 Atlantic Fleet SSBNs. The 10 older SSBNs that could not use Poseidon were assigned to the Pacific Fleet in the 1970s. Polaris was not accurate enough to destroy hardened targets, but would have been effective against dispersed surface targets, such as airfields, radar and SAM sites, as well as military and industrial centers of strategic importance. The military authorities, however, regarded Polaris as but one part of a nuclear triad including ICBMs and bombers, each with its own function. The task allotted to Polaris of 'taking out' peripheral defenses was well-suited to its characteristics and limitations.

The forward deployment strategy required some infrastructure. To allow quick establishment of bases and to minimize the impact on the host country, each base was centered around a submarine tender and a floating drydock, with minimal facilities on shore, mostly family support for the tender's crew. The first Polaris submarine tender was , a World War II tender that was refitted in 1959–60 with the insertion of a midships missile storage compartment and handling crane. "Proteus" established each of the three forward deployment bases. Four additional Polaris tenders (, , , and ) were commissioned 1962–65.

A two-crew concept was established for SSBNs, combined with forward deployment to maximize the time each submarine would spend on patrol. The crews were named Blue and Gold after the US Naval Academy colors. The crews were deployed for 105 days and at their home bases for 95 days, with a 3-day turnover period on each end of the deployed period. Crews were flown from their home bases to and from the forward deployment bases. After taking over the boat, the crew would perform a 30-day refit assisted by the tender, followed by a 70-day deterrent patrol. Sometimes a port visit would be arranged in the middle of the patrol. The home bases for Atlantic Fleet crews were Groton, Connecticut and Charleston, South Carolina. Pacific Fleet crews were based at Pearl Harbor, Hawaii.

Two Polaris missile depots were established in the United States, Polaris Missile Facility Atlantic (POMFLANT) at Charleston, South Carolina in 1960 and later Strategic Weapons Facility Pacific (SWFPAC) at Bangor, Washington. To transport missiles and other supplies from the missile depots to the forward deployment bases, several cargo ships were converted to carry missiles and were designated as T-AKs, operated by the Military Sealift Command with a mostly-civilian crew.

The advent of the Trident I missile, refitted to 12 Atlantic Fleet SSBNs starting in 1979 and with a much greater range than Polaris or Poseidon, meant that SSBNs could be based in the United States. The 18 s, slated to replace the 41 older SSBNs, also started commissioning in 1981, initially carrying 24 Trident I missiles but later refitted with the much larger and more capable Trident II missile. In the late 1970s it was decided that Pacific Fleet "Ohio"-class SSBNs would be based at Bangor, WA, collocated with SWFPAC, and that the refitted Trident I SSBNs and additional "Ohio"-class SSBNs would be based at a new facility in King's Bay, Georgia. Also, a new missile depot, Strategic Weapons Facility Atlantic (SWFLANT), was constructed at King's Bay to replace POMFLANT. The SSBN facility at Rota was closed in 1979 as King's Bay began refitting submarines. As commenced sea trials in 1980, the 10 remaining Polaris submarines in the Pacific Fleet were disarmed and reclassified as SSNs to avoid exceeding SALT II treaty limits. The SSBN base at Guam was closed at this time. By 1992, the Soviet Union had collapsed, 12 "Ohio"-class SSBNs had been commissioned, and the START I treaty had gone into effect, so Holy Loch was closed and the remaining 31 original SSBNs disarmed. Most of these were decommissioned and later scrapped in the Ship-Submarine Recycling Program, but a few were converted to other roles. Two remain in service but decommissioned as nuclear power training vessels attached to Naval Nuclear Power School at Charleston, SC, and .

To meet the need for greater accuracy over the longer ranges the Lockheed designers included a reentry vehicle concept, improved guidance, fire control, and navigation systems to achieve their goals. To obtain the major gains in performance of the Polaris A3 in comparison to early models, there were many improvements, including propellants and material used in the construction of the burn chambers. The later versions (the A-2, A-3, and B-3) were larger, weighed more, and had longer ranges than the A-1. The range increase was most important: The A-2 range was , the A-3 , and the B-3 . The A-3 featured multiple re-entry vehicles (MRVs) which spread the warheads about a common target, and the B-3 was to have penetration aids to counter Soviet Anti-Ballistic Missile defenses.

The US Navy began to replace Polaris with Poseidon in 1972. The B-3 missile evolved into the C-3 Poseidon missile, which abandoned the decoy concept in favor of using the C3's greater throw-weight for larger numbers (10–14) of new hardened high-re-entry-speed reentry vehicles that could overwhelm Soviet defenses by sheer weight of numbers, and its high speed after re-entry. This turned out to be a less than reliable system and soon after both systems were replaced by the Trident. A proposed Undersea Long-Range Missile System (ULMS) program outlined a long-term plan which proposed the development of a longer-range missile designated as ULMS II, which was to achieve twice the range of the existing Poseidon (ULMS I) missile. In addition to a longer-range missile, a larger submarine (Ohio-class) was proposed to replace the submarines currently being used with Poseidon. The ULMS II missile system was designed to be retrofitted to the existing SSBNs, while also being fitted to the proposed Ohio-class submarine.

In May 1972, the term ULMS II was replaced with Trident. The Trident was to be a larger, higher-performance missile with a range capacity greater than 6000 miles. Under the agreement, the United Kingdom paid an additional 5% of their total procurement cost of 2.5 billion dollars to the US government as a research and development contribution.
In 2002, the United States Navy announced plans to extend the life of the submarines and the D5 missiles to the year 2040. This requires a D5 Life Extension Program (D5LEP), which is currently underway. The main aim is to replace obsolete components at minimal cost by using commercial off the shelf (COTS) hardware; all the while maintaining the demonstrated performance of the existing Trident II missiles.

STARS, a strategic targeting system, is a BMDO program managed by the U. S. Army Space and Strategic Defense Command (SSDC). It began in 1985 in response to concerns that the supply of surplus Minuteman I boosters used to launch targets and other experiments on intercontinental ballistic missile flight trajectories in support of the Strategic Defense Initiative would be depleted by 1988. SSDC tasked Sandia National Laboratories, a Department of Energy laboratory, to develop an alternative launch vehicle using surplus Polaris boosters. The Sandia National Laboratories developed two STARS booster configurations: STARS I and STARS II.

STARS I consisted of refurbished Polaris first and second stages and a
commercially procured Orbis I third stage. It can deploy single or multiple payloads, but the multiple payloads cannot be deployed in a manner that simulates the operation of a post-boost vehicle. To meet this specific need, Sandia developed an Operations and Deployment
Experiments Simulator (ODES), which functions as a PBV. When ODES was added to STARS I, the configuration is became known as STARS II. The development phase of the STARS program was completed in year 1994, and BMDO provided about $192.1 million for this effort. The operational phase began in year 1995. The first STARS I flight, a hardware check-out flight, was launched in February 1993, and the second flight, a STARS I reentry vehicle experiment, was launched in August 1993.

The third flight, a STARS II development mission, was launched in July 1994, with all three flights considered to be successful by BMDO. The Secretary of Defense conducted a comprehensive review in 1993 of the nation’s defense strategy, which drastically reduced the number of STARS launches required to support National Missile Defense (NMD)2 and BMDO funding. Due to the launch and budget reductions, the STARS office developed a draft long-range plan for the STARS program. The study examined three options:
When the STARS program was started in 1985 it was perceived that there would be four launches per year. Because of the large number of anticipated launches and an unknown defect rate for surplus Polaris motors, the STARS office acquired 117 first-stage and 102 second-stage surplus motors. As of December 1994, seven first-stage and five second-stage refurbished motors were available for future launches. BMDO is currently evaluating STARS as a potential long-range system for launching targets for development tests of future Theater Missile Defense 3 systems. STARS I was first launched in 1993, and from 2004 onwards has served as the standard booster for trials of the Ground-Based Interceptor.

From the early days of the Polaris program, American senators and naval officers suggested that the United Kingdom might use Polaris. In 1957 Chief of Naval Operations Arleigh Burke and First Sea Lord Louis Mountbatten began corresponding on the project. After the cancellations of the Blue Streak and Skybolt missiles in the 1960s, under the 1962 Nassau Agreement that emerged from meetings between Harold Macmillan and John F. Kennedy, the United States would supply Britain with Polaris missiles, launch tubes, ReBs, and the fire-control systems. Britain would make its own warheads and initially proposed to build five ballistic missile submarines, later reduced to four by the incoming Labour government of Harold Wilson, with 16 missiles to be carried on each boat. The Nassau Agreement also featured very specific wording. The intention of wording the agreement in this manner was to make it intentionally opaque. The sale of the Polaris was malleable in how an individual country could interpret it due to the diction choices taken in the Nassau Agreement. For the United States of America, the wording allowed for the sale to fall under the scope of NATO's deterrence powers. On the other hand, for the British, the sale could be viewed as a solely British deterrent. The Polaris Sales Agreement was signed on April 6, 1963.

In return, the British agreed to assign control over their Polaris missile targeting to the SACEUR (Supreme Allied Commander, Europe), with the provision that in a national emergency when unsupported by the NATO allies, the targeting, permission to fire, and firing of those Polaris missiles would reside with the British national authorities. Nevertheless, the consent of the British Prime Minister is and has been always required for the use of British nuclear weapons, including SLBMs.

The operational control of the Polaris submarines was assigned to another NATO Supreme Commander, the SACLANT (Supreme Allied Commander, Atlantic), who is based near Norfolk, Virginia, although the SACLANT routinely delegated control of the missiles to his deputy commander in the Eastern Atlantic area, COMEASTLANT, who was always a British admiral.

Polaris was the largest project in the Royal Navy's peacetime history. Although in 1964 the new Labour government considered cancelling Polaris and turning the submarines into conventionally armed hunter-killers, it continued the program as Polaris gave Britain a global nuclear capacity—perhaps east of Suez—at a cost £150 million less than that of the V bomber force. By adopting many established, American, methodologies and components Polaris was finished on time and within budget. On 15 February 1968, , the lead ship of her class, became the first British vessel to fire a Polaris. All Royal Navy SSBNs have been based at Faslane, only a few miles from Holy Loch. Although one submarine of the four was always in a shipyard undergoing a refit, recent declassifications of archived files disclose that the Royal Navy deployed four boatloads of reentry vehicles and warheads, plus spare warheads for the Polaris A3T, retaining a limited ability to re-arm and put to sea the submarine that was in refit. When replaced by the Chevaline warhead, the sum total of deployed RVs and warheads was reduced to three boatloads.

The original U.S. Navy Polaris had not been designed to penetrate anti-ballistic missile (ABM) defenses, but the Royal Navy had to ensure that its small Polaris force operating alone, and often with only one submarine on deterrent patrol, could penetrate the ABM screen around Moscow. Britain’s submarines featured the Polaris A3T missiles, a modification to the model of the Polaris used by the U.S. from 1968 to 1972. Similar concerns were present in the U.S. as well, resulting in a new American defense program.

The program became known as Antelope, and its purpose was to alter the Polaris. Various aspects of the Polaris, such as increasing deployment efficiency and creating ways to improve the penetrative power were specific items considered in the tests conducted during the Antelope program. The British's uncertainty with their missiles led to the examination of the Antelope program. The assessments of Antelope occurred at Aldermaston. Evidence from the evaluation of Antelope led to the British decision to undertake their program following that of the United States.

The result was a programme called "Chevaline" that added multiple decoys, chaff, and other defensive countermeasures. Its existence was only revealed in 1980, partly because of the cost overruns of the project, which had almost quadrupled the original estimate given when the project was finally approved in January 1975.The program also ran into trouble when dealing with the British Labour Party. Their Chief Scientific Adviser, Solly Zuckerman, believed that Britain no longer needed new designs for nuclear weapons and no more nuclear warhead tests would be necessary. Though the Labour party provided a clear platform on nuclear weapons, the Chevaline program found supporters. One such individual who supported modification to the Polaris was the Secretary of state for Defense, Denis Healey.

Despite the approval of the program, the expenses caused hurdles that augmented the time it took for the system to come to fruition. The cost of the project led to Britain’s revisit of disbanding the program in 1977. The system became operational in mid-1982 on , and the last British SSBN submarine was equipped with it in mid-1987. Withdrawn from service in 1996.

Though Britain adopted the Antelope program methods, no input on the design came from the United States. Aldermaston was solely responsible for the Chevaline warheads.

The British did not ask to extend the Polaris Sales Agreement to cover the Polaris successor Poseidon due to its cost. The Ministry of Defence upgraded its nuclear missiles to the longer-ranged Trident after much political wrangling within the Callaghan Labour Party government over its cost and whether it was necessary. The outgoing Prime Minister James Callaghan made his government's papers on Trident available to Margaret Thatcher's new incoming Conservative Party government, which took the decision to acquire the Trident C4 missile.

A subsequent decision to upgrade the missile purchase to the even larger, longer-ranged Trident D5 missile was possibly taken to ensure that there was missile commonality between the U.S. Navy and the Royal Navy, which was considerably important when the Royal Navy Trident submarines were also to use the Naval Submarine Base Kings Bay.

Even though the U.S. Navy initially deployed the Trident C4 missile in the original set of its "Ohio"-class submarines, it was always planned to upgrade all of these submarines to the larger and longer-ranged Trident D5 missile—and that eventually, all of the C4 missiles would be eliminated from the U.S. Navy. This change-over has been completely carried out, and no Trident C4 missiles remain in service.

The Polaris missile remained in Royal Navy service long after it had been completely retired and scrapped by the U.S. Navy in 1980–1981. Consequently, many spare parts and repair facilities for the Polaris that were located in the U.S. ceased to be available (such as at Lockheed, which had moved on first to the Poseidon and then to the Trident missile).

As of 2014, there were four Trident D-5 missiles present at the Faslane Naval Base in Scotland. Another one always remains at sea as a means of constant deterrence. Though the Trident missiles stay in use, it is expected for the warheads to reach termination in the 2020s, around two decades after it was first commissioned in 1994.

Steps were taken toward this new missile development as early as 2006 under Tony Blair’s Labour Party. Blair passed a plan for actions to be made toward moving away from the Trident missile as well as the introduction of a newer British submarine fleet. However, the British Liberal Democratic Party shared power with the Conservatives from 2010 and sought to move toward a different nuclear policy. The government budget for defence spending was high, leading them to find an alternative to the nuclear program the party inherited from its predecessors. The Liberal Democrats have since moved to pursue a new policy including the reduction of patrols, submarines, and warhead stockpiles.

During its reconstruction program in 1957–1961, the was fitted with four Polaris missile launchers located in the aft part of the ship. The Italian usage of Polaris missiles was partially the result of the Kennedy administration. Prior to 1961, the Italian and Turkish fleets were outfitted with Jupiter missiles. Three factors were instrumental in the movement away from the Jupiter project in Italy and Turkey: the president’s view of the project, new understanding about weapons systems and the diminished necessity of the Jupiter missile. The Joint Congressional Committee report on Atomic Energy accentuated the three previous factors in Italy's decision to switch to the Polaris missiles.Successful tests held in 1961–1962 induced the United States to study a NATO Multilateral Nuclear Force (MLF), consisting of 25 international surface vessels from the US, United Kingdom, France, Italy, and West Germany, equipped with 200 Polaris nuclear missiles, enabling European allies to participate in the management of the NATO nuclear deterrent.

The report advocated a change from the outdated Jupiter missiles, already housed by the Italians, to the newer missile, Polaris. The report resulted in Secretary of State Dean Rusk and Assistant Secretary of Defense Paul Nitze discussing the possibility of changing the warheads in the Mediterranean. The Italians were not swayed by the American’s interest in modernizing their warheads. However, after the Cuban Missile Crisis, Kennedy met the Italian leader Amitore Fanfani in Washington. Fanfani conceded and went along with Kennedy’s Polaris plan, despite the Italians hoping to stick with the Jupiter missile.

The MLF plan, as well as the Italian Polaris Program, were abandoned, both for political reasons (in consequence of the Cuban Missile Crisis) and the initial operational availability of the first SSBN , which was capable of launching SLBMs while submerged, a solution preferable to surface-launched missiles.

Italy developed a new domestic version of the missile, the SLBM-designated Alfa. That program was cancelled in 1975 after Italy ratified the Nuclear Non-Proliferation Treaty, with the final launch of the third prototype in 1976.

Two Italian Navy cruisers, commissioned in 1963–1964, were "fitted for but not with" two Polaris missile launchers per ship. All four launchers were built but never installed, and were stored at the La Spezia naval facility.

The , launched in 1969, was also "fitted for but not with" four Polaris missile launchers. During refit periods in 1980–1983, these facilities were removed and used for other weapons and systems.


Notes
Bibliography




</doc>
<doc id="24788" url="https://en.wikipedia.org/wiki?curid=24788" title="UGM-73 Poseidon">
UGM-73 Poseidon

The UGM-73 Poseidon missile was the second US Navy nuclear-armed submarine-launched ballistic missile (SLBM) system, powered by a two-stage solid-fuel rocket. It succeeded the UGM-27 Polaris beginning in 1972, bringing major advances in warheads and accuracy. It was followed by Trident I in 1979, and Trident II in 1990.

A development study for a longer range version of the Polaris missile achieved by enlarging it to the maximum possible size allowed by existing launch tubes started in 1963. Tests had already shown that Polaris missiles could be operated without problems in launch tubes that had their fiberglass liners and locating rings removed.

The project was given the title Polaris B3 in November, but the missile was eventually named Poseidon C3 to emphasize the technical advances over its predecessor. The C3 was the only version of the missile produced, and it was also given the designation UGM-73A.

Slightly longer and considerably wider and heavier than Polaris A3, Poseidon had the same range, greater payload capacity, improved accuracy, and multiple independently targetable reentry vehicle (MIRV) capability. MIRV capacity has been given as up to either ten or fourteen W68 thermonuclear warheads contained in Mark 3 reentry vehicles to multiple targets.

As with Polaris, starting a rocket motor when the missile was still in the submarine was considered very dangerous. Therefore, the missile was ejected from its launch tube using high pressure steam produced by a solid-fueled boiler. The main rocket motor ignited automatically when the missile had risen approximately above the submarine.

The first test launch took place on 16 August 1968, the first successful at-sea launch was from a surface ship, the (from July 1 to December 16, 1969), earning the ship the Meritorious Unit Commendation, and the first test launch from a submarine took place on the on 3 August 1970. The weapon officially entered service on 31 March 1971. It eventually equipped 31 -, -, and -class submarines.

The Royal Navy also considered adopting Poseidon in the 1970s as an upgrade to its Polaris A3T boats, and like the US this would have kept the existing hulls. Although the Navy's favoured option, the British government instead adopted Chevaline, a two warhead MRV system with decoys, on the existing Polaris airframes and later moved to the Trident D5 in new boats.

Beginning in 1979, 12 Poseidon-equipped SSBNs were refitted with Trident I. By 1992, the Soviet Union had collapsed, 12 Ohio-class submarines had been commissioned, and the START I treaty had gone into effect, so the 31 older Poseidon- and Trident I-armed SSBNs were disarmed, withdrawing Poseidon from service.




</doc>
<doc id="24789" url="https://en.wikipedia.org/wiki?curid=24789" title="Portuguese">
Portuguese

Portuguese may refer to:



</doc>
<doc id="24793" url="https://en.wikipedia.org/wiki?curid=24793" title="POTS">
POTS

Pots most commonly refers to pottery, the ceramic ware made by potters

POTS or Pots may also refer to:



</doc>
<doc id="24795" url="https://en.wikipedia.org/wiki?curid=24795" title="Private (rank)">
Private (rank)

A private is a soldier of the lowest military rank (equivalent to NATO Rank Grades OR-1 to OR-3 depending on the force served in).

In modern military writing, "private" is shortened to "Pte" in the United Kingdom and other (Commonwealth of Nations) countries and to "Pvt." in the United States.

The term derives from the medieval term "private soldiers" (a term still used in the British Army), denoting individuals who were either hired, conscripted, or mustered into service by a feudal nobleman commanding a battle group of an army. The usage of "private" dates from the 18th century.

In the Israel Defense Forces, טוראי "Turai" ("private") refers to the lowest enlisted rank. After 7–10 months of service (7 for combatants, 8 for combat support and 10 for non-combatants) soldiers are promoted from private to corporal ("rav-turai" or "rabat"), if they performed their duties appropriately during this time. Soldiers who take a commander's course, are prisoner instructors or practical engineers become corporals earlier. An IDF private wears no uniform insignia and is sometimes described as having a "slick sleeve" for this reason.

The equivalent ranks to privates within the North and South Korean armies are "il-byong" (private first class) and "e-byong" (private second class). The symbol for this rank is 1 line ( | ) or 2 lines ( || ). Private second class is known by 1 line, while private first class is 2 lines.

Once recruits complete their Basic Military Training (BMT) or Basic Rescue Training (BRT), they attain the rank of private (PTE). Privates (列兵) do not wear ranks on their rank holder. PTEs who performed well are promoted to the rank of Private First Class (PFC). The PFC rank insignia is a single chevron pointing downward.

In Indonesia, this rank is referred to as (specifically "Prajurit"), which is the lowest rank in the Indonesian Armed Forces and special Police Force. In the Indonesian Army, "Private" has three levels, which are: Private ("Prajurit Dua"), Private First Class ("Prajurit Satu"), and Master Private ("Prajurit Kepala"). After this rank, it is promoted the rank: Corporal.

In the Australian Army, a soldier of private rank wears no insignia. Like its British Army counterpart, the Australian Army rank of private (PTE) has other titles, depending on the corps and specification of that service member.

The following alternative ranks are available for privates in the Australian Army:


"Private" is the lowest rank in the Canadian Army. There are three levels of private: private (recruit), private (basic), and private (trained). All persons holding the rank of private are referred to as such and the qualifier shown in brackets is used on employment records only. A private is considered an "apprentice" in their trade, and there are no pay raises between the various levels of private except for time in rank raise.

Army privates may be known by other titles, depending on unit and personnel branch:

In the Indian Army and Pakistan Army the lowest enlisted rank is sepoy (/ˈsiːpɔɪ/), literally meaning "soldier" derived from Persian. A sepoy does not wear any rank insignia on his uniform.

In the British Army, a private (Pte) equates to both OR-1 and OR-2 on the NATO scale, although there is no difference in rank. Privates wear no insignia. Many regiments and corps use other distinctive and descriptive names instead of private, some of these ranks have been used for centuries, others are less than 100 years old. In the contemporary British Armed Forces, the army rank of private is broadly equivalent to able seaman in the Royal Navy, aircraftman, leading aircraftman and senior aircraftman in the Royal Air Force, and marine (Mne) or bandsman, as appropriate equivalent rank in the Royal Marines. Outwith the Armed Forces, in the Boys Brigade the rank of private is used when a boy moves from the junior section to the company section.

Notably, both Sir Fitzroy Maclean and Enoch Powell are examples of rare, rapid career progression with the British Army, both rising from the rank of private to at least brigadier during World War II.

Distinctive equivalents for private include:

The lowest rank in the Austrian Armed Forces is the "Rekrut" (literally "Recruit"). For recruits in training to become non-commissioned or commissioned officers the rank bears an additional silver crossbar.

Up until 1998 the rank was called "Wehrmann". In 2017 the silver crossbar was removed, as the system of the 'officers career' changed.

The equivalent rank to private in the Spanish, Mexican, Colombian, Dominican and Argentinian army is the "soldado raso" meaning "rankless soldier" or simply "soldado".

On enlistment in the Belgian army one is given the rank of (Dutch) or (French), whether one wishes to be a volunteer, non-commissioned officer or officer. Subsequent rank depends on the branch of the service: for example, at the Royal Military Academy (for officer training) one is soon promoted to the rank of (Dutch) or (French) i.e. "corporal". The insignia is a simple black mark.

"Soldado" is the rank equivalent to private in the Brazilian and Portuguese Armed Forces. "Soldado" means "soldier" in Portuguese.

The Finnish equivalent rank is "sotamies" (literally "war man"), although since 1973 this has been purely a paper term as all infantry troopers were renamed as "jääkäri" troops, previously reserved only to mobile light infantry. As in the British army, the various branches use different names:


In the Finnish Air Force, the basic rank is "lentosotamies" ("flight war man"). In the Finnish Navy, the basic rank is "matruusi" ("seaman").

Special corps troopers may be referred by their function or unit, such as "kaartinjääkäri" (Guards jaeger), "panssarijääkäri" (panzerjäger), "laskuvarjojääkäri" (paratroop jaeger), "rajajääkäri" (border jaeger) or "rannikkojääkäri" (coastal jaeger).

In the French army "soldat de seconde classe" is the lowest military rank. This rank is also referred to as "recrue" ("recruit").

The German "Bundeswehr" modern-day equivalent of the private rank (NATO-standard code OR-2) is Gefreiter.

The equivalent of the lowest rank (NATO-standard code OR-1) is either "Schütze" (rifleman), "Kanonier" (gunner) or "Jäger" (light-infantryman otherwise ranger), and sometimes in general simply "Soldat" (soldier), as well as other unit-specific distinctions. Up until 1918 it was "Gemeine" (Ordinary [soldier]) as well as unit-specific distinctions such as "Musketier" (musketeer), "Infanterist" (infantryman), "Kürassier" (cuirassier), "Jäger" (light-infantryman otherwise ranger), "Füsilier" (fusilier) etc., until 1945 "Soldat" (soldier) and unit-specific distinctions such as "Schütze" (rifleman), "Grenadier" (grenadier) etc. The navy equivalent of the OR-1 rank is known as "Matrose" (sailor or seaman), and the German Air Force equivalent is "Flieger" (aviator or airman) which is also used by army aviators.

The name of the lowest rank in the Hungarian army ("Magyar Honvédség") is the "honvéd" which means "homeland defender". The word is also used informally for a soldier in general of any rank (i.e. "our "honvéds"" or an officer referred as a "honvédtiszt", "honvéd" officer). This is because Hungarian military traditions are strictly defensive, despite the Hungarian army participating in offensives on foreign soil in both world wars. The word "honvéd" has been in use since the Hungarian Revolution of 1848.

Private (Pte) ("saighdiúr singil" in Irish), is the lowest enlisted rank in the Irish Army. Soldiers enlist as recruits then undergo a basic course of instruction. There are three grades of private in the army. After basic training the soldier is upgraded (rather than promoted) from recruit to private 2 star (Pte 2*) ("saighdiúr singil, 2 réalta"). After more corps-specific training (usually lasting eight weeks) the soldier is upgraded to private 3 star (Pte 3*) ("saighdiúr singil, 3 réalta"). All are usually just addressed as "private", although before being upgraded, recruits may be addressed as "recruit".

In corps units, the rank designation changes. In the artillery, the rank is known as gunner (Gnr), but usually only after the completion of a gunners' course, and in the cavalry it is known as trooper (Tpr). Communications and Information Services privates are known as signalman or signalwoman. Medical orderlies are sometimes referred to as medic, although this can apply to privates and corporals.

In the Italian Army is the lowest military rank. This rank is also referred to as (meaning recruit).

In the Royal Netherlands Army, the "Landmacht", the equivalent ranks are "soldaat" (soldier), similar to the original French, with different classes:


Depending on where the "soldaat" serves, he may be deemed a "kanonnier" (gunner in the artillery), "huzaar" (hussar in the cavalry) or "fuselier" (rifleman in the rifles) as well as "commando", "jager" or "rijder". There is less differentiation than in other countries between different armed forces. A "soldaat" can be promoted to "korporaal" (corporal).

In the Swedish Armed Forces a recruit is given the rank of in the army and in the navy.

After basic training which is roughly 3 months other terms can be used such as ’’soldat’’ (soldier), ’’jägare’’, etc.

In the Swiss Armed Forces a recruit is given the rank of when he finishes basic training, mostly after 13 weeks.

In the Turkish Land Forces, Turkish Air Force and Turkish Naval Forces; "Er" (Private) is the lowest rank possible. This rank does not have any insignia.
In the U.S. Army, private is used for the two lowest enlisted ranks, just below private first class (E-3) or PFC. The lowest rank is "Private (E-1)" or PV1, and sometimes referred to as recruit, but also held by some soldiers after punishment through the Uniform Code of Military Justice or prisoners after conviction until they are discharged. A PV1 wears no uniform rank insignia; since the advent of the Army Combat Uniform, the term "fuzzy" has come into vogue, referring to the blank velcro patch on the ACU where the rank would normally be placed. The second rank, "Private (E-2)" or PV2, wears a single chevron, known colloquially as "mosquito wings". Advancement to the PV2 is automatic after six months' time in service, but may get shortened to four months if given a waiver. A person who earned the Eagle Scout award, the Gold Award, or completed at least two years of JROTC may enlist at any time at the rank of PV2. The term of address, "Private," may be properly applied to any Army soldier E-1 (PV1) to E-3 (PFC). The abbreviation "PVT" may be used whenever the specific grade of private, including both/either/or PV1 and PV2, is immaterial (such as in Tables of Organization and Equipment). It should also be noted that while a soldier is currently in Initial Enlistment Training, he or she will often be referred to as "Private" by the training cadre, regardless of actual rank, even if the soldier enlisted as a Specialist (E-4).

In the U.S. Marine Corps, "private" (Pvt) refers only to the lowest enlisted rank, just below private first class. A Marine Corps private wears no uniform insignia and is sometimes described as having a "slick sleeve" for this reason. Most new, non-officer Marines begin their military career as a private. In the Marine Corps, privates first class are not referred to as "private"; it is more appropriate to use either "private first class" or "PFC".




</doc>
<doc id="24797" url="https://en.wikipedia.org/wiki?curid=24797" title="Proclus">
Proclus

Proclus Lycaeus (; 8 February 412 – 17 April 485 AD), called the Successor (Greek , "Próklos ho Diádokhos"), was a Greek Neoplatonist philosopher, one of the last major classical philosophers (see Damascius). He set forth one of the most elaborate and fully developed systems of Neoplatonism. He stands near the end of the classical development of philosophy, and was very influential on Western medieval philosophy (Greek and Latin).

Proclus was born on February 8, 412 AD (his birth date is deduced from a horoscope cast by a disciple, Marinus) in Constantinople to a family of high social status in Lycia (his father Patricius was a high legal official, very important in the Byzantine Empire's court system) and raised in Xanthus. He studied rhetoric, philosophy and mathematics in Alexandria, with the intent of pursuing a judicial position like his father. Before completing his studies, he returned to Constantinople when his rector, his principal instructor (one Leonas), had business there.

Proclus became a successful practicing lawyer. However, the experience of the practice of law made Proclus realize that he truly preferred philosophy. He returned to Alexandria, and began determinedly studying the works of Aristotle under Olympiodorus the Elder. He also began studying mathematics during this period as well with a teacher named Heron (no relation to Hero of Alexandria, who was also known as Heron). As a gifted student, he eventually became dissatisfied with the level of philosophical instruction available in Alexandria, and went to Athens, the pre-eminent philosophical center of the day, in 431 to study at the Neoplatonic successor of the famous Academy founded 800 years earlier (in 387 BC) by Plato; there he was taught by Plutarch of Athens (not to be confused with Plutarch of Chaeronea), Syrianus, and Asclepigenia; he succeeded Syrianus as head of the Academy, and would in turn be succeeded on his death by Marinus of Neapolis.

He lived in Athens as a vegetarian bachelor, prosperous and generous to his friends, until the end of his life, except for a voluntary one-year exile, which was designed to lessen the pressure put on him by his political-philosophical activity, little appreciated by the Christian rulers; he spent the exile traveling and being initiated into various mystery cults. He was also instructed in the "theurgic" Neoplatonism, as derived from the Orphic and Chaldean Oracles. His house has been discovered recently in Athens, under the pavement of Dionysiou Areopagitou Street, south of Acropolis, opposite the theater of Dionysus. He had a great devotion to the goddess Athena, who he believed guided him at key moments in his life. Marinus reports that when Christians removed the statue of the goddess from the Parthenon, a beautiful woman appeared to Proclus in a dream and announced that the "Athenian Lady" wished to stay at his home. Proclus died aged 73, and was buried near Mount Lycabettus in a tomb. It is reported that he was writing 700 lines each day.

The majority of Proclus's works are commentaries on dialogues of Plato ("Alcibiades", "Cratylus", "Parmenides", "Republic", "Timaeus"). In these commentaries he presents his own philosophical system as a faithful interpretation of Plato, and in this he did not differ from other Neoplatonists, as he considered the Platonic texts to be divinely inspired (ὁ θεῖος Πλάτων "ho theios Platon"—the divine Plato, inspired by the gods) and therefore that they spoke often of things under a veil, hiding the truth from the philosophically uninitiate. Proclus was however a close reader of Plato, and quite often makes very astute points about his Platonic sources. A number of his Platonic commentaries are lost.

Proclus, the scholiast to Euclid, knew Eudemus of Rhodes' "History of Geometry" well, and gave a short sketch of the early history of geometry, which appeared to be founded on the older, lost book of Eudemus. The passage has been referred to as "the Eudemian summary," and determines some approximate dates, which otherwise might have remained unknown. The influential commentary on the first book of Euclid's "Elements of Geometry" is one of the most valuable sources we have for the history of ancient mathematics, and its Platonic account of the status of mathematical objects was influential. In this work, Proclus also listed the first mathematicians associated with Plato: a mature set of mathematicians (Leodamas of Thasos, Archytas of Taras, and Theaetetus), a second set of younger mathematicians (Neoclides, Eudoxus of Cnidus), and a third yet younger set (Amyntas, Menaechmus and his brother Dinostratus, Theudius of Magnesia, Hermotimus of Colophon and Philip of Opus). Some of these mathematicians were influential in arranging the Elements that Euclid later published.

In addition to his commentaries, Proclus wrote two major systematic works. The "Elements of Theology" (Στοιχείωσις θεολογική) consists of 211 propositions, each followed by a proof, beginning from the existence of the One (divine Unity) and ending with the descent of individual souls into the material world. The "Platonic Theology" (Περὶ τῆς κατὰ Πλάτωνα θεολογίας) is a systematisation of material from Platonic dialogues, showing from them the characteristics of the divine orders, the part of the universe which is closest to the One.

We also have three essays, extant only in Latin translation: "Ten doubts concerning providence" ("De decem dubitationibus circa providentiam"); "On providence and fate" ("De providentia et fato"); "On the existence of evils" ("De malorum subsistentia").

He also wrote a number of minor works, which are listed in the bibliography below.

Proclus's system, like that of the other Neoplatonists, is a combination of Platonic, Aristotelian, and Stoic elements. In its broad outlines, Proclus's system agrees with that of Plotinus. However, following Iamblichus, Plutarch of Athens, and his master Syrianus, Proclus presents a much more elaborate universe than Plotinus, subdividing the elements of Plotinus's system into their logically distinct parts, and positing these parts as individual things. This multiplication of entities is balanced by the monism which is common to all Neoplatonists. What this means is that, on the one hand the universe is composed of hierarchically distinct things, but on the other all things are part of a single continuous emanation of power from the One. From this latter perspective, the many distinctions to be found in the universe are a result of the divided perspective of the human soul, which needs to make distinctions in its own thought in order to understand unified realities. The idealist tendency is taken further in John Scotus Eriugena.

There is a double motivation found in Neoplatonic systems. The first is a need to account for the origin and character of all things in the universe. The second is a need to account for how we can know this origin and character of things. These two aims are related: they begin from the assumption that we can know reality, and then ask the question of what reality must be like, in its origin and unfolding, so that we can know it. An important element in the Neoplatonic answer to these questions is its reaction to Scepticism. In response to the sceptical position that we only know the appearances presented by our senses, and not the world as it is, Plotinus placed the object of knowledge inside the soul itself, and accounted for this interior truth through the soul's kinship with its own productive principles.

The first principle in Neoplatonism is the One (Greek: "to Hen"). Being proceeds from the One. The One cannot itself be a being. If it were a being, it would have a particular nature, and so could not be universally productive. Because it is "beyond being" ("epekeina tes ousias", a phrase from Plato's "Republic" 509b), it is also beyond thought, because thinking requires the determinations which belong to being: the division between subject and object, and the distinction of one thing from another. For this reason, even the name "The One" isn't a positive name, but rather the most non-multiple name possible, a name derived from our own inadequate conception of the simplicity of the first principle. The One causes all things by conferring unity, in the form of individuality, on them, and in Neoplatonism existence, unity, and form tend to become equivalent. The One causes things to exist by donating unity, and the particular manner in which a thing is one is its form (a dog and a house are individual in different manners, for example). Because the One makes things exist by giving them the individuality which makes them what they are as distinct and separate beings, the Neoplatonists thought of it also as the source of the good of everything. So the other name for the One is the Good. Despite appearances, the first principle is not double; all things have a double relation to it, as coming from them (One) and then being oriented back towards them to receive their perfection or completion (Good).

The particular characteristic of Proclus's system is his elaboration of a level of individual ones, called "henads," between the One which is before being and intelligible divinity. The henads exist "superabundantly", also beyond being, but they stand at the head of chains of causation ("seirai") and in some manner give to these chains their particular character. He identifies them with the Greek gods, so one henad might be Apollo and be the cause of all things apollonian, while another might be Helios and be the cause of all "sunny" things. Each henad participates in every other henad, according to its character. What appears to be multiplicity is not multiplicity at all, because any henad may rightly be considered the center of the polycentric system.

The principle which is produced below the level of the One and the Henads is the divine Intellect ("Nous"). The One cannot have a determinate nature if it is to be the source of all determinate natures, so what it produces is the totality of all determinate natures, or Being. By determination is meant existence within boundaries, a being "this" and not "that". The most important determinate natures are the "Greatest Kinds" from Plato's "Sophist" (Being, Same, Other, Rest, Motion) and Aristotle's ten categories (Quantity, Quality, etc.). In other words, the One produces what Plato called the Forms, and the Forms are understood to be the first determinations into which all things fall. The One produces the Forms through the activity of thinking. The One itself does not think, but instead produces a divine mind, Intellect, whose thoughts are themselves the Forms. Intellect is both Thinking and Being. It is a mind which has its own contents as its object. All things relate to the first principle as both One and Good. As Being, Intellect is the product of the One. But it also seeks to return to its cause, and so in Thinking it attempts to grasp the One as its Good. But because the simplicity of the One/Good does not allow Intellect to grasp it, what Intellect does is generate a succession of perspectives around its simple source. Each of these perspectives is itself a Form, and is how Intellect generates for itself its own content.

Plotinus speaks about the generation of Intellect from the One, and Intellect's attempt to return to the One in a thinking which is also a desiring. Proclus systematises this production through a threefold movement of remaining, procession, and return ("mone, proodos, epistrophe"). Intellect remains in the One, which means that it has the One as its origin. It proceeds from the One, which means that it comes to be as a separate entity. But it returns to the One, which means that it doesn't cut itself off from its source, but receives the good which is its identity from the One. This threefold motion is used by Proclus to structure all levels of his system below the One and above material reality, so that all things except those mentioned remain, proceed, and return.

Proclus also gives a much more elaborate account of Intellect than does Plotinus. In Plotinus we find the distinction between Being and Thinking in Intellect. Proclus, in keeping with his triadic structure of remaining, procession, and return, distinguishes three moments in Intellect: Intelligible, Intelligible-Intellectual, and Intellectual. They correspond to the object of thought, the power of the object to be grasped by the subject, and the thinking subject. These three divisions are elaborated further, so that the intelligible moment consists of three triads (Being, Eternity, and the Living Being or Paradigm from Plato's "Timaeus"). The intelligible-intellectual moment also consists of three triads, and the intellectual moment is a hebdomad (seven elements), among which is numbered the Demiurge from Plato's "Timaeus" and also the monad of Time (which is before temporal things). In this elaboration of Intellect as a whole, Proclus is attempting to give a hierarchical ordering to the various metaphysical elements and principles that other philosophers have discussed, by containing them within a single triadic logic of unfolding.

Proclus's universe unfolds according to the smallest steps possible, from unity to multiplicity. With Intellect emerges the multiplicity which allows one being to be different from another being. But as a divine mind, Intellect has a complete grasp of all its moments in one act of thought. For this reason, Intellect is outside of Time.

Intellect as the second principle also gives rise to individual intellects, which hold various places within Proclus's cosmos.

In terms of his sources, Intellect is like taking the Platonic Forms and placing them in the self-thinking thought which is Aristotle's Unmoved Mover.

Soul ("Psyche") is produced by Intellect, and so is the third principle in the Neoplatonic system. It is a mind, like Intellect, but it does not grasp all of its own content as one. Therefore with Soul, Time comes to be, as a measure of Soul's movement from one object of thought to another. Intellect tries to grasp the One, and ends up producing its own ideas as its content. Soul attempts to grasp Intellect in its return, and ends up producing its own secondary unfoldings of the Forms in Intellect. Soul, in turn, produces Body, the material world.

In his commentary on Plato's "Timaeus" Proclus explains the role the Soul as a principle has in mediating the Forms in Intellect to the body of the material world as a whole. The Soul is constructed through certain proportions, described mathematically in the "Timaeus", which allow it to make Body as a divided image of its own arithmetical and geometrical ideas.

Individual souls have the same overall structure as the principle of Soul, but they are weaker. They have a tendency to be fascinated with the material world, and be overpowered by it. It is at this point that individual souls are united with a material body (i.e. when they are born). Once in the body, our passions have a tendency to overwhelm our reason. According to Proclus, philosophy is the activity which can liberate the soul from a subjection to bodily passions, remind it of its origin in Soul, Intellect, and the One, and prepare it not only to ascend to the higher levels while still in this life, but to avoid falling immediately back into a new body after death.

Because the soul's attention, while inhabiting a body, is turned so far away from its origin in the intelligible world, Proclus thinks that we need to make use of bodily reminders of our spiritual origin. In this he agrees with the doctrines of theurgy put forward by Iamblichus. Theurgy is possible because the powers of the gods (the "henads") extend through their series of causation even down to the material world. And by certain power-laden words, acts, and objects, the soul can be drawn back up the series, so to speak. Proclus himself was a devotee of many of the religions in Athens, considering that the power of the gods could be present in these various approaches.

For Proclus, philosophy is important because it is one of the primary ways to rescue the soul from a fascination with the body and restore it to its station. However, beyond its own station, the soul has Intellect as its goal, and ultimately has unification with the One as its goal. So higher than philosophy is the non-discursive reason of Intellect, and the pre-intellectual unity of the One. Philosophy is therefore a means of its own overcoming, in that it points the soul beyond itself.

Proclus can be considered as the spokesman of mature Neoplatonism. His works had a great influence on the history of western philosophy. The extent of this influence, however, is obscured by the channels through which it was exercised. An important source of Procline ideas was through the Pseudo-Dionysius. This late-5th- or early-6th-century Christian Greek author wrote under the pseudonym Dionysius the Areopagite, the figure converted by St. Paul in Athens. Because of this fiction, his writings were taken to have almost apostolic authority. He is an original Christian writer, and in his works can be found a great number of Proclus's metaphysical principles.

Another important source for the influence of Proclus on the Middle Ages is Boethius's "Consolation of Philosophy", which has a number of Proclus principles and motifs. The central poem of Book III is a summary of Proclus's "Commentary on the Timaeus", and Book V contains the important principle of Proclus that things are known not according to their own nature, but according to the character of the knowing subject.

A summary of Proclus's "Elements of Theology" circulated under the name "Liber de Causis" (the "Book of Causes"). This book is of uncertain origin, but circulated in the Arabic world as a work of Aristotle, and was translated into Latin as such. It had great authority because of its supposed Aristotelian origin, and it was only when Proclus's "Elements" were translated into Latin that Thomas Aquinas realised its true origin.

Proclus's works also exercised an influence during the Renaissance through figures such as Georgius Gemistus Pletho and Marsilio Ficino. Before the contemporary period, the most significant scholar of Proclus in the English-speaking world was Thomas Taylor, who produced English translations of most of his works, with commentaries.

His work inspired the New England Transcendentalists, including Ralph Waldo Emerson, who declared in 1843 that, in reading Proclus, "I am filled with hilarity & spring, my heart dances, my sight is quickened, I behold shining relations between all beings, and am impelled to write and almost to sing."

Modern scholarship on Proclus essentially begins with E.R. Dodd's edition of the "Elements of Theology" in 1933. Since then he has attracted considerable attention, especially in the French-speaking world. Procline scholarship, however, still (2006) falls far short of the attention paid to Plotinus.

The following epigram is engraved on the tomb which houses Proclus and his master Syrianus:

The crater Proclus on the Moon is named after him.


A number of other minor works or fragments of works survive. A number of major commentaries have been lost.

The "Liber de Causis" (Book of Causes) is not a work by Proclus, but a summary of his work the "Elements of Theology", likely written by an Arabic interpreter. It was mistakenly thought in the Middle Ages to be a work of Aristotle, but was recognised by Aquinas not to be so.

A list of modern editions and translations of his surviving works is available at:

Monographs

Collections of essays

Bibliographic resources




</doc>
<doc id="24799" url="https://en.wikipedia.org/wiki?curid=24799" title="Production team">
Production team

A production team is the group of technical staff who produce a play, television show, recording, or film. Generally the term refers to all individuals responsible for the technical aspects of creating of a particular product, regardless of where in the process their expertize is required, or how long they are involved in the project. For example, in a theatrical performance, the production team includes not only the running crew, but also the theatrical producer, designers and theatre direction.

A production company in filmmaking is composed of a film crew and a television crew in video production.

In music, the term "production team" typically refers to a group of individuals filling the role of "record producer" usually reserved for one individual. Some examples of musical production teams include Matmos and D-Influence.



</doc>
<doc id="24801" url="https://en.wikipedia.org/wiki?curid=24801" title="Pinconning cheese">
Pinconning cheese

Pinconning Cheese is an aged semi-hard whole cow's milk, Colby style cheese named after Pinconning, Michigan, where it was first developed and produced by Dan Horn in 1915. Since then and currently, Pinconning Cheese is made and distributed based on the original family traditional recipe by the originator's related companies, Pinconning Cheese Company and Wilson's (Horn) Cheese Shoppe in Pinconning, Michigan. It is available in mild and then aged many years to sharpness levels of medium mild, medium sharp, sharp, extra sharp, and super sharp (7 plus years old). Its hardness and texture change and sharpness increase with aging. Pinconning's flavor and texture are rich, creamy and open. It is unusual and a different experience than eating traditional Colby Cheese. It is often used as a replacement for Cheddar and Colby cheeses in dishes such as macaroni and soufflés." Pinconning was chosen as the ‘Cheese Capital of Michigan’ after the Pinconning brand of cheese where it was originated and still sold today.


</doc>
<doc id="24805" url="https://en.wikipedia.org/wiki?curid=24805" title="Prophet">
Prophet

In religion, a prophet is an individual regarded as being in contact with a divine being and said to speak on that entity's behalf, serving as an intermediary with humanity by delivering messages or teachings from the supernatural source to other people. The message that the prophet conveys is called a prophecy.

Claims of prophethood have existed in many cultures through history, including Judaism, Christianity, Islam, in ancient Greek religion, Zoroastrianism, Manichaeism, and many others.

In Hebrew, the word נָבִיא ("nāvî"), "spokesperson", traditionally translates as "prophet". The second subdivision of the Hebrew Bible, TaNaKh (for "Torah, Nevi'im, Ketuvim"), is devoted to the Hebrew prophets. The meaning of "navi" is perhaps described in Deuteronomy 18:18, where God said, "...and I will put My words in his mouth, and he shall speak unto them all that I shall command him." Thus, the "navi" was thought to be the "mouth" of God. The root nun-bet-alef ("navi") is based on the two-letter root nun-bet which denotes hollowness or openness; to receive transcendental wisdom, one must make oneself "open". Cf. Rashbam's comment to Genesis 20:7.

In addition to writing and speaking messages from God, Israelite or Jewish nevi'im ("spokespersons", "prophets") often acted out prophetic parables in their life. For example, in order to contrast the people’s disobedience with the obedience of the Rechabites, God has Jeremiah invite the Rechabites to drink wine, in disobedience to their ancestor’s command. The Rechabites refuse, wherefore God commends them. Other prophetic parables acted out by Jeremiah include burying a linen belt so that it gets ruined to illustrate how God intends to ruin Judah's pride. Likewise, Jeremiah buys a clay jar and smashes it in the Valley of Ben Hinnom in front of elders and priests to illustrate that God will smash the nation of Judah and the city of Judah beyond repair. God instructs Jeremiah to make a yoke from wood and leather straps and to put it on his own neck to demonstrate how God will put the nation under the yoke of Nebuchadnezzar, king of Babylon. In a similar way, the prophet Isaiah had to walk stripped and barefoot for three years to illustrate the coming captivity, and the prophet Ezekiel had to lie on his side for 390 days and eat measured food to illustrate the coming siege.

The prophetic assignment is not always portrayed as positive in the Hebrew Bible, and prophets were often the target of persecution and opposition. God’s personal prediction for Jeremiah, "Attack you they will, overcome you they can't," was performed many times in the biblical narrative as Jeremiah warned of destruction of those who continued to refuse repentance and accept more moderate consequences. In return for his adherence to God’s discipline and speaking God’s words, Jeremiah was attacked by his own brothers, beaten and put into the stocks by a priest and false prophet, imprisoned by the king, threatened with death, thrown into a cistern by Judah’s officials, and opposed by a false prophet. Likewise, Isaiah was told by his hearers who rejected his message, "Leave the way! Get off the path! Let us hear no more about the Holy One of Israel!" The life of Moses being threatened by Pharaoh is another example.

According to I Samuel 9:9, the old name for navi is "ro'eh", רֹאֶה, which literally means "Seer". That could document an ancient shift, from viewing prophets as seers for hire to viewing them as moral teachers. Allen (1971) comments that in the First Temple Era, there were essentially seer-priests, who formed a guild, divined, performed rituals and sacrifices, and were scribes, and then there were canonical prophets, who did none of these (and were against divination) and had instead a message to deliver. The seer-priests were usually attached to a local shrine or temple, such as Shiloh, and initiated others as priests in that priesthood: it was a mystical craft-guild with apprentices and recruitment. Canonical prophets were not organised this way. The similar term "ben-navi" ("son of the prophet") means "member of a seer-priest guild".

Some examples of prophets in the Tanakh include Abraham, Moses, Miriam, Isaiah, Samuel, Ezekiel, Malachi, and Job. In Jewish tradition Daniel is not counted in the list of prophets.

A Jewish tradition suggests that there were twice as many prophets as the number which left Egypt, which would make 1,200,000 prophets. The Talmud recognizes the existence of 48 male prophets who bequeathed permanent messages to mankind. According to the Talmud there were also seven women who are counted as prophets whose message bears relevance for all generations: Sarah, Miriam, Devorah, Hannah (mother of the prophet Samuel), Abigail (a wife of King David), Huldah (from the time of Jeremiah), and Esther. Rashi points out that Rebecca, Rachel, and Leah were also prophets.

Prophets in Judaism are not always Jews. The story of Balaam in Numbers 22 describes a non-Jewish prophet. According to the Talmud, Obadiah is said to have been a convert to Judaism.

The last nevi'im ("spokespersons", "prophets") mentioned in the Jewish Bible are Haggai, Zechariah, and Malachi, all of whom lived at the end of the 70-year Babylonian exile. The Talmud (Sanhedrin 11a) states that Haggai, Zachariah, and Malachi were the last prophets, and nowadays only the "Bath Kol" (בת קול, lit. "daughter of a voice", "voice of God") exists.

In Christianity a prophet (or seer) is one inspired by God through the Holy Spirit to deliver a message for a specific purpose. God's calling as a prophet is not to elevate an individual for their own glory, but for the glory of God and to turn people to him. Some Christian denominations limit a prophet's message to those only to the entire church congregation and exclude personal messages not intended for the body of believers, but in the Bible on a number of occasions prophets were called to deliver personal messages. The reception of a message is termed revelation and the delivery of the message is termed prophecy.

The term prophet is applied to those who receive public or private revelation. Public Revelation, in Catholicism, is part of the Deposit of faith, the revelation of which was completed by Jesus; whereas Private Revelation does not add to the Deposit. The term "deposit of faith" refers to the entirety of Jesus Christ's revelation, and is passed to successive generations in two different forms, sacred scripture (the Bible) and sacred tradition.

Anyone who claims to speak God's words or teach in his name and is not a prophet the Bible terms a false prophet. One test given in the Old Testament in Deuteronomy contains a warning of those who prophecy events which do not come to pass and said they should be put to death. Elsewhere a false prophet may be someone who is purposely trying to deceive, is delusional, under the influence of Satan or is speaking from his own spirit.
Some Christians who believe in dispensationalism believe prophecy ended along with the rest of the sign gifts shortly after the coming of Jesus, who delivered the "fullness of the law". Within this group, many Protestants believe that prophecy ended with the last of the Hebrew prophets of the Hebrew Bible, leaving a gap of about 400 years between then and the life of Jesus. The majority, including the Eastern Orthodox, allow an exception for John the Baptist as a prophet contemporary with Jesus.

New Testament passages that explicitly discuss prophets existing after the death and resurrection of Christ include Revelation 11:10, Matthew 10:40–41 and 23:34, John 13:20 and 15:20 and Acts 11:25–30, 13:1 and 15:32. Christians believe that the Holy Spirit leads people to faith in Jesus and gives them the ability to lead a Christian life and to give gifts (i.e. abilities) to Christians. These may include the charismatic gifts such as prophecy, tongues, miraculous healing ability, and clairsentience. Christians holding a view known as cessationism believe these gifts were given only in New Testament times and ceased after the last apostle died.

The Didache gives extensive instruction in how to distinguish between true and false prophets, as well as commands regarding tithes to prophets in the church. Irenaeus, wrote of 2nd-century believers with the gift of prophecy, while Justin Martyr argued in his "Dialogue with Trypho" that prophets were not found among the Jews in his time, but that the church had prophets. The Shepherd of Hermas describes revelation in a vision regarding the proper operation of prophecy in the church. Eusebius mentions that Quadratus and Ammia of Philadelphia were both prominent prophets following the age of the Twelve Apostles. Tertullian, writing of the church meetings of the Montanists (to whom he belonged), described in detail the practice of prophecy in the 2nd-century church.

A number of later Christian saints were claimed to have powers of prophecy, such as Columba of Iona, Saint Malachy or Padre Pio. Marian apparitions like those at Fatima or Kibeho often included prophecies regarding the future of the world as well as of the local areas they occurred in 

Prophetic movements in particular can be traced throughout the Christian Church's history, in expressions such as Montanism, Novatianism, Donatism, Franciscanism, Anabaptism, Camisard enthusiasm, Puritanism, Quakerism, Quietism, Lutheranism and Pietism. Modern Pentecostals and Charismatics, movements which together make up approximately half a billion people, believe in the contemporary function of the gift of prophecy, and some in these movements allow for idea that God may continue to gift the church with some individuals who are prophets. 

Some Christians also believe that the title "prophet" encompasses others than those who receive visions from God. A more modern definition of prophet is someone who spreads God's truths. These can be revealed in a number of ways, not only visions.

Some Christian sects recognize the existence of a "modern-day" prophet. One such denomination is The Church of Jesus Christ of Latter-day Saints (LDS Church), which teaches that God still communicates with mankind through prophecy.

The Quran identifies a number of men as "Prophets of Islam" ( "nabī"; pl. "anbiyāʾ"). Muslims believe such individuals were assigned a special mission by God to guide humanity. Besides Muhammad, this includes prophets such as Abraham ("Ibrāhīm"), Moses ("Mūsā") () and Jesus ("ʿĪsā").
Although only twenty-five prophets are mentioned by name in the Qur'an, a hadith (no. 21257 in "Musnad Ahmad ibn Hanbal") mentions that there were (more or less) 124,000 prophets in total throughout history. Other traditions place the number of prophets at 224,000. Some scholars hold that there are an even greater number in the history of mankind, and only God knows. The Qur'an says that God has sent a prophet to every group of people throughout time, and that Muhammad is the last of the prophets, sent for the whole of humankind. The message of all the prophets is believed to be the same. In Islam, all prophetic messengers are prophets (such as Adam, Noah, Abraham, Moses, Jesus, and Muhammad) though not all prophets are prophetic messengers. The primary distinction is that a prophet is required to demonstrate God's law through his actions, character, and behavior without necessarily calling people to follow him, while a prophetic messenger is required to pronounce God's law (i.e. revelation) and call his people to submit and follow him. Muhammad is distinguished from the rest of the prophetic messengers and prophets in that he was commissioned by God to be the prophetic messenger to all of mankind. Many of these prophets are also found in the texts of Judaism (The Torah, the Prophets, and the Writings) and Christianity.

Muslims often refer to Muhammad as "the Prophet", in the form of a noun. Jesus is the result of a virgin birth in Islam as in Christianity, and is regarded as a prophet.

Traditionally, four prophets are believed to have been sent holy books: the Torah ("Tawrat") to Moses, the Psalms ("Zābūr") to David, the Gospel to Jesus, and the Qur'an to Muhammad; those prophets are considered "Messengers" or "rasūl". Other main prophets are considered messengers or "nabī", even if they didn't receive a Book from God. Examples include the messenger-prophet Aaron| ("Hārūn"), the messenger-prophet Ishmael ("Ismāʿīl")) and the messenger-prophet Joseph ("Yūsuf").

Although it offers many incidents from the lives of many prophets, the Qur'an focuses with special narrative and rhetorical emphasis on the careers of the first four of these five major prophets. Of all the figures before Muhammad, Moses is referred to most frequently in the Qur'an. As for the fifth, the Qur'an is frequently addressed directly to Muhammad, and it often discusses situations encountered by him. Direct use of his name in the text, however, is rare. Rarer still is the mention of Muhammad's contemporaries.

The Bahá'í Faith refers to what are commonly called prophets as "Manifestations of God" who are directly linked with the concept of Progressive revelation. Bahá'ís believe that God expresses this will at all times and in many ways, including through a series of divine messengers referred to as "Manifestations of God" or "divine educators". In expressing God's intent, these Manifestations are seen to establish religion in the world. Thus they are seen as an intermediary between God and humanity.

The Manifestations of God are not seen as incarnations of God, and are also not seen as ordinary mortals. Instead, the Bahá'í concept of the Manifestation of God emphasizes simultaneously the humanity of that intermediary and the divinity in the way they show forth the will, knowledge and attributes of God; thus they have both human and divine stations.

In addition to the Manifestations of God, there are also minor prophets. While the Manifestations of God, or major prophets, are compared to the Sun (which produces its own heat and light), minor prophets are compared to the Moon (which receives its light from the sun). Moses, for example, is taught as having been a Manifestation of God and his brother Aaron a minor prophet. Moses spoke on behalf of God, and Aaron spoke on behalf of Moses (Exodus 4:14–17). Other Jewish prophets are considered minor prophets, as they are considered to have come in the shadow of the dispensation of Moses to develop and consolidate the process he set in motion.

In modern times the term "prophet" can be somewhat controversial. Many Christians with Pentecostal or charismatic beliefs believe in the continuation of the gift of prophecy and the continuation of the role of prophet as taught in Ephesians 4. The content of prophecies can vary widely. Prophecies are often spoken as quotes from God. They may contain quotes from scripture, statements about the past or current situation, or predictions of the future. Prophecies can also 'make manifest the secrets' of the hearts of other people, telling about the details of their lives. Sometimes, more than one person in a congregation will receive the same message in prophecy, with one giving it before another.

Other movements claim to have prophets. In France, Michel Potay says he received a revelation, called "The Revelation of Arès", dictated by Jesus in 1974, then by God in 1977. He is considered a prophet by his followers, the Pilgrims of Arès.

A number of modern catholic saints have been claimed to have powers of prophecy, such as Padre Pio and Alexandrina Maria da Costa.

In addition to this many modern Marian apparitions included prophecies in them about the world and about the local areas. The Fátima apparition in 1917 included a prophecy given by Mary to three children, that on October 13, 1917 there would be a great miracle for all to see at Fátima, Portugal, and on that day tens of thousands of people headed to Fátima to see what would happen including newspaper journalists. Many witnesses, including journalists, claimed to see the sun "dance" in the sky in the afternoon of that day, exactly as the visionaries had predicted several months before. The Kibeho apparition in Rwanda in the 1980s included many prophecies about great violence and destruction that was coming, and the Rwandan genocide only ten years later was interpreted by the visionaries as the fulfilment of these prophecies 

Several miracles and a vision of the identity of the last 112 Popes were attributed to Saint Malachy, the Archbishop of Armagh (1095–1148).

Jehovah's Witnesses do not consider any single person in their modern-day organization to be a prophet. Their literature has referred to their organization collectively as God's "prophet" on earth; this is understood, however, in the sense of declaring their interpretation of God's judgments from the Bible along with God's guidance of His Holy Spirit. Their publishing company, Watch Tower, and official position magazine, "The Watchtower", have asserted: "Ever since "The Watchtower" began to be published in July 1879 it has looked ahead into the future... No, "The Watchtower" is no inspired prophet, but it follows and explains a Book of prophecy the predictions in which have proved to be unerring and unfailing till now. "The Watchtower" is therefore under safe guidance. It may be read with confidence, for its statements may be checked against that prophetic Book." They also claim that they are God's one and only true channel to mankind on earth, and used by God for this purpose.

They have made many eschatological forecasts, some of which have led people (including followers) to incorrect assumptions. One example is "The Watchtower's" assertions that the end of the "Gentile times" or "times of the nations" would occur in 1914; even prominent Watch Tower representatives such as A. H. Macmillan incorrectly concluded and overstated their expectations. As a result, "The Watchtower" has acknowledged that Jehovah's Witnesses "have made mistakes in their understanding of what would occur at the end of certain time periods." Concurrently with these exceptions, Jehovah's Witnesses in their literature and assemblies have taught their leadership was personally chosen by Jesus Christ in 1919 (a prophetic year in Jehovah's Witnesses eschatology) and that they are "God's sole channel on earth," and "Jehovah's spirit directed organization".

Joseph Smith, who established the Church of Christ in 1830, is considered a prophet by members of the Latter Day Saint movement, of which The Church of Jesus Christ of Latter-day Saints (LDS Church) is the largest denomination. Additionally, many churches within the movement believe in a succession of modern prophets (accepted by Latter Day Saints as "prophets, seers, and revelators") since the time of Joseph Smith. Russell M. Nelson is the current president and prophet of The Church of Jesus Christ of Latter-day Saints.

Baptist preacher William Miller is credited with beginning the mid-19th century North American religious movement now known as Adventism. He announced a Second Coming, resulting in the Great Disappointment.

The Seventh-day Adventist Church, established in 1863, believes Ellen G. White, one of the church's founders, was given the spiritual gift of prophecy.

The Branch Davidians sect evolved from the Seventh-Day Adventists Church. David Koresh, who died in the well-known Waco Siege in 1993, in 1983 claimed to be their final prophet and "the Son of God, the Lamb".


The Ahmadiyya movement in Islam believes that Mirza Ghulam Ahmad was a non law-bearing Prophet, who claimed to be a fulfillment of the various Islamic prophecies regarding the spiritual second advent of Jesus of Nazareth near the end times.

Nathan of Gaza was a theologian and author who became famous as a prophet for the alleged messiah, Sabbatai Zevi.

The Hindu concept of rishis is similar to the concept of prophets. The Sanskrit word "rishi" is loosely translated into English as "seer" (a prophet, a man who can foresee the future). Hinduism recognizes and reveres thousands of rishis, who can be thought of as the collective founders of the Hindu religion over many millennia. Of these, special importance is given to the Saptarshi (the Seven Sages), widely regarded as patriarchs of the Hindu religion, whose listing is different according to different texts. The Saptarshi and their clans are believed to have composed the hymns of the four Vedas by entering into communion with the Supreme Cosmic Spirit through meditation. For instance, Rigveda 1.1 is attributed to Rishi Madhucchandā Vaishwāmitra (i.e. Madhucchandā of the clan of Vishwamitra). Most rishikās were male, but some were female too. Lopamudra is the author of one hymn in the Rigveda, and Gargi Vachaknavi is described in the Brihadaranyaka Upanishad as a highly respected woman in the field of Brahmajñāna. Apart from the Vedas, various rishis are also credited with composing the several Smriti texts, like Veda Vyasa who composed the "Mahābhārata".

Divination remains an important aspect of the lives of the people of contemporary Africa, especially amongst the usually rural, socially traditionalistic segments of its population. In arguably its most influential manifestation, the system of prophecy practiced by the Babalawos and Iyanifas of the historically Yoruba regions of West Africa have bequeathed to the world a corpus of fortune-telling poetic methodologies so intricate that they have been added by UNESCO to its official "intangible cultural heritage of the World list".

Tenrikyo's prophet, Nakayama Miki, is believed by Tenrikyoans to have been a messenger of God.


Native American Great Peacemaker (Deganawidah) co-founded the Haudenosaunee league in pre-Columbian times. In retrospect, his prophecy of the boy seer could appear to refer to the conflict between natives and Europeans (white serpent).

From 1805 until the Battle of Tippecanoe that falsified his predictions in 1811, the "Shawnee prophet" Tenskwatawa lead an Indian alliance to stop Europeans to take more and more land going west. He reported visions he had. He is said to have accurately predicted a solar eclipse. His brother Tecumseh re-established the alliance for Tecumseh's War, that ended with the latter's death in 1813. Tecumseh fought together with British forces that, in the area of the Great Lakes, occupied essentially today's territory of Canada.

Francis the Prophet, influenced by Tecumseh and Tenskwatawa, was a leader of the Red Stick faction of the Creek Indians. He traveled to England in 1815 as a representative of the "four Indian nations" in an unsuccessful attempt to get Great Britain to help them resist the expansionism of the white settlers.

20 years later (1832), Wabokieshiek, the "Winnebago Prophet", after whom Prophetstown has been named, (also called "White Cloud") claimed that British forces would support the Indians in the Black Hawk War against the United States as 20 years earlier (based on "visions"). They did not, and no longer he was considered a "prophet".

In 1869, the Paiute Wodziwob founded the Ghost Dance movement. The dance rituals were an occasion to announce his visions of an earthquake that would swallow the whites. He seems to have died in 1872.

The Northern Paiute Wovoka claimed he had a vision during the solar eclipse of January 1, 1889, that the Paiute dead would come back and the whites would vanish from America, provided the natives performed Ghost Dances. This idea spread among other Native American peoples. The government were worried about a rebellion and sent troops, which lead to the death of Sitting Bull and to the Wounded Knee massacre in 1890.

Other people throughout history have been described as prophets in the sense of foretelling the future (as opposed to relaying a religious message). Examples of such prophets include:

In the late 20th century the appellation of "prophet" has been used to refer to individuals particularly successful at analysis in the field of economics, such as in the derogatory "prophet of greed". Alternatively, social commentators who suggest escalating crisis are often called "prophets of doom."





</doc>
<doc id="24807" url="https://en.wikipedia.org/wiki?curid=24807" title="Pleading">
Pleading

In law as practiced in countries that follow the English models, a pleading is a formal written statement of a party's claims or defenses to another party's claims in a civil action. The parties' pleadings in a case define the issues to be adjudicated in the action.

The Civil Procedure Rules (CPR) govern pleading in England and Wales. Federal Rules of Civil Procedure govern pleading in United States federal courts. Each state in the United States has its own statutes and rules that govern pleading in the courts of that state.

In the United States, a "complaint" is the first pleading filed by a plaintiff which initiates a lawsuit. A complaint sets forth the relevant allegations of fact that give rise to one or more legal causes of action along with a prayer for relief and sometimes a statement of damages claimed (an ad quod damnum clause). In some situations, a complaint is called a "petition", in which case the party filing it is called the petitioner and the other party is the respondent. In equity, sometimes called chancery, the initial pleading may be called either a "petition" or a "bill of complaint in chancery".

In England and Wales, the first pleading is a Claim Form, issued under either Part 7 or Part 8 of the Civil Procedure Rules, which sets out the nature of the action and the relief sought, and may give brief particulars of the claim. The Claimant also has the option, under Practice Direction 7A.61 to serve Particulars of Claim (a document setting out the allegations which found the cause of action) within 14 days of issue of the Claim Form.

When used in civil proceedings in England and Wales, the term "complaint" refers to the mechanism by which civil proceedings are instituted in the magistrates' court and may be either written or oral.

A "demurrer" is a pleading (usually filed by a defendant) which objects to the legal sufficiency of the opponent's pleading (usually a complaint) and demands that the court rule immediately about whether the pleading is legally adequate before the party must plead on the merits in response. Since demurrer procedure required an immediate ruling like a motion, many common law jurisdictions therefore went to a narrower understanding of pleadings as framing the issues in a case but not being motions in and of themselves, and replaced the demurrer with the motion to dismiss for failure to state a cause of action or the application to strike out particulars of claim.

An "answer" is a pleading filed by a defendant which admits or denies the specific allegations set forth in a complaint and constitutes a general appearance by a defendant. In England and Wales, the equivalent pleading is called a Defence.

A defendant may also file a cross-complaint against another defendant named by the plaintiff, and may also file a "third-party complaint" bring other parties into a case by the process of impleader.

A defendant may file a "counter-claim" to raise a cause of action to defend, reduce or set off the claim of the plaintiff.

Common law pleading was the system of civil procedure used in England, which early on developed a strong emphasis on the form of action rather than the cause of action (as a result of the Provisions of Oxford, which severely limited the evolution of the common law writ system). The emphasis was on procedure over substance.

Law and equity evolved as separate judicial systems, each with its own procedures and remedies. Because the types of claims eligible for consideration was capped early during the development of the English legal system, claims that might have been acceptable to the courts' evolving sense of justice often did not match up perfectly with any of the established forms of action. Lawyers had to engage in great ingenuity to shoehorn their clients' claims into existing forms of action. The result was that at common law, pleadings were stuffed full of awkward legal fictions that had little to do with the actual "real-world" facts of the case. The placeholder name John Doe (still commonly used in American pleading to name unknown parties) is a remnant of this period.

In its final form in the 19th century, common law pleading was terribly complex and slow by modern standards. The parties would normally go through several rounds of pleadings before the parties were deemed to have clearly stated their controversy, so that the case was "at issue" and could proceed to trial. A case would begin with a complaint in which the plaintiff alleged the facts entitling him to relief, then the defendant would file any one of a variety of pleas as an answer, followed by a replication from the plaintiff, a rejoinder from the defendant, a surrejoinder from the plaintiff, a rebutter from the defendant, and a surrebutter from the plaintiff. At each stage, a party could file a demurrer to the other's pleading (essentially a request that the court immediately rule on whether the pleading was legally adequate before they had to file a pleading in response) or simply file another pleading in response.

Generally, a plea could be dilatory or peremptory. There were three kinds of dilatory plea: to the jurisdiction, in suspension, or in abatement. The first challenged the court's jurisdiction, the second asked the court to stay the action, and the third asked the court to dismiss the action without prejudice to the other side's right to bring the claims in another action or another court. A peremptory plea had only one kind: a plea in bar. A party making a plea in bar could either traverse the other side's pleading (i.e., deny all or some of the facts pleaded) or confess and avoid it (i.e., admit the facts pleaded but plead new ones that would dispel their effect). A traverse could be general (deny everything) or specific. Either side could plead imparlance in order to get more time to plead on the merits. Once the case was at issue, the defendant could reopen the pleadings in order to plead a newly discovered defense (and start the whole sequence again) by filing a plea puis darrein.

The result of all this complexity was that to ascertain what was "at issue" in a case, a stranger to the case (i.e., such as a newly appointed judge) would have to sift through a huge pile of pleadings to figure out what had happened to the original averments of the complaint and whether there was anything left to be actually adjudicated by the court.

Code pleading was first introduced in 1850 in New York and in 1872 in California, and eventually spread to 22 other states. Code pleading sought to abolish the distinction between law and equity. It unified civil procedure for all types of actions as much as possible. The focus shifted from pleading the right form of action (that is, the right procedure) to pleading the right cause of action (that is, a substantive right to be enforced by the law). Under code pleading, the required elements of each action are supposed to be set out in carefully codified statutes.

Code pleading stripped out most of the legal fictions that had encrusted common law pleading by requiring parties to plead "ultimate facts." This means that to plead a cause of action, the pleader has to plead each element and also allege specific facts which, if proven with evidence at trial, would constitute proof of that element. Failure to provide such detail could lead to dismissal of the case if the defendant successfully demurred to the complaint on the basis that it merely stated "legal conclusions" or "evidentiary facts."

Code pleading also drastically shortened the pleading process. Most of the old common law pleadings were abolished. From now on, a case required only a complaint and an answer, with an optional cross-complaint and cross-answer, and with the demurrer kept as the standard attack on improper pleadings. Instead of piling layers and layers of pleadings and averments on top of each other, a pleading that was attacked by demurrer would either be completely superseded by an amended pleading or would proceed immediately "at issue" as to the validly pleaded parts. This meant that to determine what the parties were currently fighting about, a stranger to a case would no longer have to read the entire case file from scratch, but could (in theory) look "only" at the most recent version of the complaint filed by the plaintiff, the defendant's most recent answer to that complaint, and any court orders on demurrers to either pleading.

Code pleading was criticized because many lawyers felt that it was too difficult to fully research all the facts needed to bring a complaint "before" one had even initiated the action, and thus meritorious plaintiffs could not bring their complaints in time before the statute of limitations expired. Code pleading has also been criticized as promoting "hypertechnical reading of legal papers".

Notice pleading is the dominant form of pleading used in the United States today. In 1938, the Federal Rules of Civil Procedure were adopted to govern civil procedure in United States federal courts. One goal of the Federal Rules of Civil Procedure was to relax the strict rules of code pleading. However, each state also has its own rules of civil procedure, which may require different, looser, or stricter rules in state court.

Louisiana, a state that derives its legal tradition from the Spanish and French (as opposed to English common law), employs a system of fact pleading wherein it is only necessary to plead the facts that give rise to a cause of action. It is not necessary even for the petitioner to identify the cause of action being pleaded. Mere conclusory allegations such as "the defendant was negligent" are not, by themselves, sufficient to sustain a cause of action.

Other states are also fact-pleading jurisdictions. Illinois, for example, requires that a complaint "must assert a legally recognized cause of action and it must plead facts which bring the particular case within that cause of action."

In alternative pleading, legal fiction is employed to permit a party to argue two mutually exclusive possibilities, for example, submitting an injury complaint alleging that the harm to the plaintiff caused by the defendant was so outrageous that it must have either been intended as a malicious attack or, if not, must have been due to gross negligence.




</doc>
<doc id="24808" url="https://en.wikipedia.org/wiki?curid=24808" title="Personal Communications Service">
Personal Communications Service

At the most basic level, Personal Communications Service (PCS) describes a set of communications capabilities which allows some combination of terminal mobility, personal mobility, and service profile management. More specifically, PCS refers to any of several types of wireless voice or wireless data communications systems, typically incorporating digital technology, providing services similar to advanced cellular mobile or paging services. In addition, PCS can also be used to provide other wireless communications services, including services which allow people to place and receive communications while away from their home or office, as well as wireless communications to homes, office buildings and other fixed havelocations. Described in more commercial terms, PCS is a generation of wireless-phone technology that combines a range of features and services surpassing those available in analog- and digital-cellular phone systems, providing a user with an all-in-one wireless phone, paging, messaging, and data service.

The International Telecommunication Union describes Personal Communications Services as a component of the IMT-2000 (3G) standard. PCS and the IMT-2000 standard of which PCS is a part do not specify a particular air interface and channel access method. Wireless service providers may deploy equipment using any of several air interface and channel access methods, as long as the network meets the service description characteristics described in the standard.

In Canada, Mexico and the United States, PCS are provided in the "1900 MHz band" (specifically 1850–1990 MHz). This frequency band was designated by the United States FCC and Industry Canada to be used for new wireless services to alleviate capacity caps inherent in the original AMPS and D-AMPS cellular networks in the "850 MHz band" (specifically 800–894 MHz). These frequency bands are particular to North America and other frequency bands may be designated in other regions.

In the United States, Sprint PCS was the first company to build and operate a PCS network, launching service in November 1995 under the "Sprint Spectrum" brand in the Baltimore-Washington metropolitan area. Sprint originally built out the network using GSM radio interface equipment. Sprint PCS later selected CDMA as the radio interface for its nationwide network and built out a parallel CDMA network in the Baltimore-Washington area, launching service in 1997. Sprint operated the two networks in parallel until finishing a migration of its area customers to the CDMA network. After completing the customer migration, Sprint PCS sold the GSM radio interface network equipment to Omnipoint Communications in January 2000. Omnipoint was later purchased by VoiceStream Wireless which subsequently became T-Mobile USA.




</doc>
<doc id="24809" url="https://en.wikipedia.org/wiki?curid=24809" title="PCS">
PCS

PCS may refer to:







</doc>
<doc id="24811" url="https://en.wikipedia.org/wiki?curid=24811" title="Puck">
Puck

Puck may refer to:








</doc>
<doc id="24815" url="https://en.wikipedia.org/wiki?curid=24815" title="Polaris Sales Agreement">
Polaris Sales Agreement

The Polaris Sales Agreement was a treaty between the United States and the United Kingdom which began the UK Polaris programme. The agreement was signed on 6 April 1963. It formally arranged the terms and conditions under which the Polaris missile system was provided to the United Kingdom.

The United Kingdom had been planning to buy the air-launched Skybolt missile to extend the operational life of the British V bombers, but the United States decided to cancel the Skybolt program in 1962 as it no longer needed the missile. The crisis created by the cancellation prompted an emergency meeting between the President of the United States, John F. Kennedy, and the Prime Minister of the United Kingdom, Harold Macmillan, which resulted in the Nassau Agreement, under which the United States agreed to provide Polaris missiles to the United Kingdom instead.

The Polaris Sales Agreement provided for the implementation of the Nassau Agreement. The United States would supply the United Kingdom with Polaris missiles, launch tubes, and the fire control system. The United Kingdom would manufacture the warheads and submarines. In return, the US was given certain assurances by the United Kingdom regarding the use of the missile, but not a veto on the use of British nuclear weapons. The British Polaris ballistic missile submarines were built on time and under budget, and came to be seen as a credible deterrent that enhanced Britain's international status.

Along with the 1958 US–UK Mutual Defence Agreement, the Polaris Sales Agreement became a pillar of the nuclear Special Relationship between Britain and the United States. The agreement was amended in 1982 to provide for the sale of the Trident missile system.

During the early part of the Second World War, Britain had a nuclear weapons project, codenamed Tube Alloys. In August 1943, the Prime Minister of the United Kingdom, Winston Churchill and the President of the United States, Franklin Roosevelt, signed the Quebec Agreement, which merged Tube Alloys with the American Manhattan Project. The British government trusted that the United States would continue to share nuclear technology, which it regarded as a joint discovery, but the 1946 McMahon Act ended cooperation. Fearing a resurgence of United States isolationism, and Britain losing its great power status, the British government restarted its own development effort, now codenamed High Explosive Research. The first British atomic bomb was tested in Operation Hurricane on 3 October 1952. The subsequent British development of the hydrogen bomb, and a favourable international relations climate created by the Sputnik crisis, led to the McMahon Act being amended in 1958, and the restoration of the nuclear Special Relationship in the form of the 1958 US–UK Mutual Defence Agreement (MDA), which allowed Britain to acquire nuclear weapons systems from the United States.

Britain's nuclear weapons armament was initially based on free-fall bombs delivered by the V bombers of the Royal Air Force (RAF), but the possibility of the manned bomber becoming obsolete by the late 1960s due to improvements in anti-aircraft defences was foreseen. In 1953, work began on a medium-range ballistic missile (MRBM) called Blue Streak, but by 1958, there were concerns about its vulnerability to a pre-emptive nuclear strike. To extend the effectiveness and operational life of the V bombers, an air-launched, rocket-propelled standoff missile called Blue Steel was developed, but it was anticipated that the air defences of the Soviet Union would improve to the extent that V bombers might still find it difficult to attack their targets. A solution appeared to be the American Skybolt missile, which combined the range of Blue Streak with the mobile basing of the Blue Steel, and was small enough that two could be carried on an Avro Vulcan bomber.

An institutional challenge to Skybolt came from the United States Navy, which was developing a submarine-launched ballistic missile (SLBM), the UGM-27 Polaris. The US Chief of Naval Operations, Admiral Arleigh Burke, kept the First Sea Lord, Lord Mountbatten, apprised of its development. By moving the deterrent out to sea, Polaris offered the prospect of a deterrent that was invulnerable to a first strike, and reduced the risk of a nuclear strike on the British Isles. The British Nuclear Deterrent Study Group (BNDSG) produced a study that argued that SLBM technology was as yet unproven, that Polaris would be expensive, and that given the time it would take to build the boats, it could not be deployed before the early 1970s. The Cabinet Defence Committee therefore approved the acquisition of Skybolt in February 1960. The Prime Minister, Harold Macmillan, met with the President, Dwight D. Eisenhower, in March 1960, and secured permission to buy Skybolt. In return, the Americans could base the US Navy's Polaris ballistic missile submarines in the Holy Loch in Scotland. The financial arrangement was particularly favourable to Britain, as the US was charging only the unit cost of Skybolt, absorbing all the research and development costs. With this agreement in hand, the cancellation of Blue Streak was announced in the House of Commons on 13 April 1960.

The subsequent American decision to cancel Skybolt created a political crisis in the UK, and an emergency meeting between Macmillan and President John F. Kennedy was called in Nassau, Bahamas. Macmillan rejected the US offers of paying half the cost of developing Skybolt, and of supplying the AGM-28 Hound Dog missile instead. This brought options down to Polaris, but the Americans would only supply it on condition that it be used as part of a proposed Multilateral Force (MLF). Kennedy ultimately relented, and agreed to supply Britain with Polaris missiles, while "the Prime Minister made it clear that except where Her Majesty's Government may decide that supreme national interests are at stake, these British forces will be used for the purposes of international defence of the Western Alliance in all circumstances." A joint statement to this effect, the Nassau Agreement, was issued on 21 December 1962.

With the Nassau Agreement in hand, it remained to work out the details. Vice Admiral Michael Le Fanu had a meeting with the United States Secretary of Defense, Robert S. McNamara, on 21 December 1962, the final day of the Nassau conference. He found McNamara eager to help, and enthusiastic about the idea of Polaris costing as little as possible. The first issue identified was how many Polaris boats should be built. While the Vulcans to carry Skybolt were already in service, the submarines to carry Polaris were not, and there was no provision in the defence budget for them. Some naval officers feared that their construction would adversely impact the hunter-killer submarine programme. The First Sea Lord, Admiral of the Fleet Sir Caspar John, denounced the "millstone of Polaris hung around our necks" as "potential wreckers of the real navy".

The number of missiles required was based on substituting for Skybolt. To achieve the same capability, the BNDSG calculated that this would require eight Polaris submarines, each of which would have 16 missiles, for a total of 128 missiles, with 128 one-megaton warheads. It was subsequently decided to halve this, based on the decision that the ability to destroy twenty Soviet cities would have nearly as great a deterrent effect as the ability to destroy forty. The Admiralty considered the possibility of hybrid submarines that could operate as hunter-killers while carrying eight Polaris missiles, but McNamara noted that this would be inefficient, as twice as many submarines would need to be on station to maintain the deterrent, and cautioned that the effect of tinkering with the US Navy's 16-missile layout was unpredictable. The Treasury costed a four-boat Polaris fleet at £314 million by 1972/73. A Cabinet Defence Committee meeting on 23 January 1963 approved the plan for four boats, with Thorneycroft noting that four boats would be cheaper and faster to build.

A mission led by Sir Solly Zuckerman, the Chief Scientific Adviser to the Ministry of Defence, left for the United States to discuss Polaris on 8 January 1963. It included the Vice Chief of the Naval Staff, Vice Admiral Sir Varyl Begg; the Deputy Secretary of the Admiralty, James Mackay; Rear Admiral Hugh Mackenzie; and physicist Sir Robert Cockburn and F. J. Doggett from the Ministry of Aviation. That the involvement of the Ministry of Aviation might be a complicating factor was foreseen, but it had experience with nuclear weapons development. Mackenzie had been the Flag Officer Submarines until 31 December 1962, when Le Fanu had appointed him the Chief Polaris Executive (CPE). As such, he was directly answerable to Le Fanu as Controller of the Navy. His CPE staff was divided between London and Foxhill, near Bath, Somerset, where Royal Navy had its ship design, logistics and weapons groups. It was intended as a counterpart to the United States Navy Special Projects Office (SPO), with whom it would have to deal.

The principal finding of the Zuckerman mission was that the Americans had developed a new version of the Polaris missile, the A3. With a range extended of , it had a new weapons bay housing three re-entry vehicles (REBs or Re-Entry Bodies in US Navy parlance) and a new W58 warhead to penetrate improved Soviet anti-missile defences expected to become available around 1970. A decision was therefore required on whether to purchase the old A2 missile or the new A3. The Zuckerman mission came out in favour of the new A3 missile, although it was still under development and not expected to enter service until August 1964, as the deterrent would remain credible for much longer. The decision was endorsed by the First Lord of the Admiralty, Lord Carrington, in May 1963, and was officially made by Thorneycroft on 10 June 1963.

The choice of the A3 created a problem for the Atomic Weapons Research Establishment (AWRE) at Aldermaston, for the Skybolt warhead that had recently been tested in the Tendrac nuclear test at the Nevada Test Site in the United States would require a redesigned Re-Entry System (RES) in order to be fitted to a Polaris missile, at an estimated cost of between £30 million and £40 million. The alternative was to make a British copy of the W58. While the AWRE was familiar with the W47 warhead used in the A2, it knew nothing of the W58. A presidential determination was required to release information on the W58 under the MDA, but with this in hand, a mission led by John Challens, the Chief of Warhead Development at the AWRE, visited the Lawrence Livermore Laboratory from 22 to 24 January 1963, and was shown details of the W58.
The Zuckerman mission found the SPO helpful and forthcoming, but there was one major shock. The British were expected to contribute to the research and development costs of the A3, backdated to 1 January 1963. These were expected to top $700 million by 1968. Skybolt had been offered to the UK at unit cost, with the US absorbing the research and development costs, but no such agreement had been reached at Nassau for Polaris. Thorneycroft baulked at the prospect of paying research and development costs, but McNamara pointed out that the United States Congress would not stand for an agreement that placed all the burden on the United States. Macmillan instructed the British Ambassador to the United States, Sir David Ormsby-Gore, to inform Kennedy that Britain was not willing to commit to an open-ended sharing of research and development costs, but, as a compromise, would pay an additional five per cent for each missile. He asked that Kennedy be informed that a breakdown of the Nassau Agreement would likely cause the fall of his government. Ormsby-Gore met with Kennedy that very day, and while Kennedy noted that the five per cent offer "was not the most generous offer he had ever heard of", he accepted it. McNamara, certain that the United States was being ripped off, calculated the five percent on top of not just the missiles, but their fire control and navigation systems as well, adding around £2 million to the bill. On Ormsby-Gore's advice, this formulation was accepted.

An American mission now visited the United Kingdom. This was led by Paul H. Nitze, the Assistant Secretary of Defense for International Security Affairs, and included Walt W. Rostow, the Director of Policy Planning at the State Department, and Admiral Ignatius J. Galantin, the head of the SPO. The Americans had ideas about how the programme should be organised. They foresaw the UK Polaris programme having project officers from both countries, with a Joint Steering Task Group that met regularly to provide advice. This was accepted, and would become part of the final agreement. However, a follow-up British mission under Leslie Williams, the Director General Atomic Weapons at the Ministry of Aviation, whose members included Challens and Rear Admiral Frederick Dossor, was given a letter by the SPO with a list of subjects that were off limits. These included penetration aids, which were held to be outside the scope of the Nassau Agreement.

One remaining obstacle in the path of the programme was how it would be integrated with the MLF. The British response to the MLF concept "ranged from unenthusiastic to hostile throughout the military establishment and in the two principal political parties". Apart from anything else, it was estimated to cost as much as £100 million over ten years. Nonetheless, the Foreign Office argued that Britain must support the MLF. The Nassau Agreement had invigorated the MLF effort in the United States. Kennedy appointed Livingston T. Merchant to negotiate the MLF with the European governments, which he did in February and March 1963. While reaffirming support for those parts of the Nassau Agreement concerning the MLF, the British were successful in getting them omitted from the Polaris Sales Agreement.
The British team completed drafting the agreement in March 1963, and copies were circulated for discussion. The contracts for their construction were announced that month. The Polaris boats would be the largest submarines built in Britain up to that time, and would be built by Vickers Armstrong Shipbuilders in Barrow-in-Furness and Cammell Laird in Birkenhead. For similar reasons to the US Navy, the Royal Navy decided to base the boats at Faslane, on the Gareloch, not far from the US Navy's base on the Holy Loch. The drawback of the site was that it isolated the Polaris boats from the rest of the navy. The Polaris Sales Agreement was signed in Washington, DC, on 6 April 1963 by Ormsby-Gore and Dean Rusk, the United States Secretary of State.

The two liaison officers were appointed in April; Captain Peter la Niece became the Royal Navy project officer in Washington, DC, while Captain Phil Rollings became the US Navy project officer in London. The Joint Steering Task Group held its first meeting in Washington on 26 June 1963. The shipbuilding programme would prove to be a remarkable achievement, with the four submarines built on time and within the budget. The first boat, was launched in September 1966, and commenced its first deterrent patrol in June 1968. The annual running costs of the Polaris boats came to around two per cent of the defence budget, and they came to be seen as a credible deterrent that enhanced Britain's international status. Along with the more celebrated 1958 US–UK Mutual Defence Agreement, the Polaris Sales Agreement became a pillar of the nuclear Special Relationship between Britain and the United States.

The Polaris Sales Agreement provided an established framework for negotiations over missiles and re-entry systems. The legal agreement took the form of amending the Polaris Sales Agreement through an exchange of notes between the two governments so that "Polaris" in the original now also covered the purchase of Trident. There were also some amendments to the classified annexes of the Polaris Sales Agreement to delete the exclusion of penetrating aids. Under the Polaris Sales Agreement, the United Kingdom paid a five per cent levy on the cost of equipment supplied in recognition of US research and development costs already incurred. For Trident, a payment of $116 million was substituted. The United Kingdom procured the Trident system from America and fitted them to their own submarines, which had only 16 missile tubes like Polaris rather than the 24 in the American . The first , , entered operational service in December 1994, by which time the Cold War had ended.



</doc>
<doc id="24818" url="https://en.wikipedia.org/wiki?curid=24818" title="Proto-Indo-Europeans">
Proto-Indo-Europeans

The Proto-Indo-Europeans were the prehistoric people of Eurasia who spoke Proto-Indo-European (PIE), the ancestor of the Indo-European languages according to linguistic reconstruction.

Knowledge of them comes chiefly from that reconstruction, along with material evidence from archaeology and archaeogenetics. The Proto-Indo-Europeans likely lived during the late Neolithic, or roughly the 4th millennium BC. Mainstream scholarship places them in the forest-steppe zone immediately to the north of the western end of the Pontic-Caspian steppe in Eastern Europe. Some archaeologists would extend the time depth of PIE to the middle Neolithic (5500 to 4500 BC) or even the early Neolithic (7500 to 5500 BC), and suggest alternative location hypotheses.

By the early second millennium BC, offshoots of the Proto-Indo-Europeans had reached far and wide across Eurasia, including Anatolia (Hittites), the Aegean (the ancestors of Mycenaean Greece), the north of Europe (Corded Ware culture), the edges of Central Asia (Yamna culture), and southern Siberia (Afanasievo culture).

The following basic traits of the Proto-Indo-Europeans and their environment are widely agreed upon but still hypothetical due to their reconstructed nature:

The Proto-Indo-Europeans had domesticated horses – ' (cf. Latin "equus"). The cow (') played a central role, in religion and mythology as well as in daily life. A man's wealth would have been measured by the number of his animals (small livestock), "" (cf. English "fee", Latin "pecunia").

As for technology, reconstruction indicates a culture of the late Neolithic bordering on the early Bronze Age, with tools and weapons very likely composed of "natural bronze" (i.e., made from copper ore naturally rich in silicon or arsenic). Silver and gold were known, but not silver smelting (as PIE has no word for lead, a by-product of silver smelting), thus suggesting that silver was imported. Sheep were kept for wool, and textiles were woven.

Burials in barrows or tomb chambers apply to the Kurgan culture, in accordance with the original version of the Kurgan hypothesis, but not to the previous Sredny Stog culture, which is also generally associated with PIE. Important leaders would have been buried with their belongings in kurgans.

Many Indo-European societies know a threefold division of priests, a warrior class, and a class of peasants or husbandmen. Georges Dumézil has suggested such a division for Proto-Indo-European society.

If there was a separate class of warriors, traces of initiation rites in several Indo-European societies suggest that this group would have identified with wolves (see also Berserker, werewolf).

Researchers have made many attempts to identify particular prehistoric cultures with the Proto-Indo-European-speaking peoples, but all such theories remain speculative. 

The scholars of the 19th century who first tackled the question of the Indo-Europeans' original homeland (also called "Urheimat", from German), had essentially only linguistic evidence. They attempted a rough localization by reconstructing the names of plants and animals (importantly the beech and the salmon) as well as the culture and technology (a Bronze Age culture centered on animal husbandry and having domesticated the horse). The scholarly opinions became basically divided between a European hypothesis, positing migration from Europe to Asia, and an Asian hypothesis, holding that the migration took place in the opposite direction.

In the early 20th century, the question became associated with the expansion of a supposed "Aryan race," a fallacy promoted during the expansion of European empires and the rise of "scientific racism." The question remains contentious within some flavours of ethnic nationalism (see also Indigenous Aryans).

A series of major advances occurred in the 1970s due to the convergence of several factors. First, the radiocarbon dating method (invented in 1949) had become sufficiently inexpensive to be applied on a mass scale. Through dendrochronology (tree-ring dating), pre-historians could calibrate radiocarbon dates to a much higher degree of accuracy. And finally, before the 1970s, parts of Eastern Europe and Central Asia had been off limits to Western scholars, while non-Western archaeologists did not have access to publication in Western peer-reviewed journals. The pioneering work of Marija Gimbutas, assisted by Colin Renfrew, at least partly addressed this problem by organizing expeditions and arranging for more academic collaboration between Western and non-Western scholars.

The Kurgan hypothesis, the most widely held theory, depends on linguistic and archaeological evidence, but is not universally accepted. It suggests PIE origin in the Pontic-Caspian steppe during the Chalcolithic. A minority of scholars prefer the Anatolian hypothesis, suggesting an origin in Anatolia during the Neolithic. Other theories (Armenian hypothesis, Out of India theory, Paleolithic Continuity Theory, Balkan hypothesis) have only marginal scholarly support.

In regard to terminology, in the 19th and early 20th centuries, the term "Aryan" was used to refer to the Proto-Indo-Europeans and their descendants. However, "Aryan" more properly applies to the Indo-Iranians, the Indo-European branch that settled parts of the Middle East and South Asia, as only Indic and Iranian languages explicitly affirm the term as a self-designation referring to the entirety of their people, whereas the same Proto-Indo-European root (*aryo-) is the basis for Greek and Germanic word forms which seem only to denote the ruling elite of Proto-Indo-European (PIE) society. In fact, the most accessible evidence available confirms only the existence of a common, but vague, socio-cultural designation of "nobility" associated with PIE society, such that Greek socio-cultural lexicon and Germanic proper names derived from this root remain insufficient to determine whether the concept was limited to the designation of an exclusive, socio-political elite, or whether it could possibly have been applied in the most inclusive sense to an inherent and ancestral "noble" quality which allegedly characterized all ethnic members of PIE society. Only the latter could have served as a true and universal self-designation for the Proto-Indo-European people.

By the early twentieth century this term had come to be widely used in a racist context referring to a hypothesized white, blonde and blue eyed "master race", culminating with the pogroms of the Nazis in Europe. Subsequently, the term "Aryan" as a general term for Indo-Europeans has been largely abandoned by scholars (though the term "Indo-Aryan" is still used to refer to the branch that settled in Southern Asia).

According to some archaeologists, PIE speakers cannot be assumed to have been a single, identifiable people or tribe, but were a group of loosely related populations ancestral to the later, still partially prehistoric, Bronze Age Indo-Europeans. This view is held especially by those archaeologists who posit an original homeland of vast extent and immense time depth. However, this view is not shared by linguists, as proto-languages, like all languages before modern transport and communication, occupied small geographical areas over a limited time span, and were spoken by a set of close-knit communities—a tribe in the broad sense.

Researchers have put forward a great variety of proposed locations for the first speakers of Proto-Indo-European. Few of these hypotheses have survived scrutiny by academic specialists in Indo-European studies sufficiently well to be included in modern academic debate.

In 1956 Marija Gimbutas (1921–1994) first proposed the Kurgan hypothesis. The name originates from the "kurgans" (burial mounds) of the Eurasian steppes. The hypothesis suggests that the Indo-Europeans, a nomadic culture of the Pontic-Caspian steppe (now part of Eastern Ukraine and Southern Russia), expanded in several waves during the 3rd millennium BCE. Their expansion coincided with the taming of the horse. Leaving archaeological signs of their presence (see battle-axe people), they subjugated the peaceful European neolithic farmers of Gimbutas' Old Europe. As Gimbutas' beliefs evolved, she put increasing emphasis on the patriarchal, patrilinear nature of the invading culture, sharply contrasting it with the supposedly egalitarian, if not matrilinear culture of the invaded, to a point of formulating essentially feminist archaeology. A modified form of this theory by JP Mallory (1945- ), dating the migrations earlier (to around 3500 BCE) and putting less insistence on their violent or quasi-military nature, remains the most widely accepted view of the Proto-Indo-European expansion.

The Armenian hypothesis, based on the glottalic theory, suggests that the Proto-Indo-European language was spoken during the 4th millennium BCE in the Armenian Highland. It is an Indo-Hittite model and does not include the Anatolian languages in its scenario. The phonological peculiarities of PIE proposed in the Glottalic theory would be best preserved in the Armenian language and the Germanic languages, the former assuming the role of the dialect which remained "in situ", implied to be particularly archaic in spite of its late attestation. Proto-Greek would be practically equivalent to Mycenean Greek and would date to the 17th century BCE, closely associating Greek migration to Greece with the Indo-Aryan migration to India at about the same time (viz., Indo-European expansion at the transition to the Late Bronze Age, including the possibility of Indo-European Kassites). The Armenian hypothesis argues for the latest possible date of Proto-Indo-European ("sans" Anatolian), a full millennium later than the mainstream Kurgan hypothesis. In this, it figures as an opposite to the Anatolian hypothesis, in spite of the geographical proximity of the respective "Urheimaten" suggested, diverging from the time-frame suggested there by a full three millennia.

Bernard Sergent associates the Indo-European language family with certain archaeological cultures in Southern Russia, and he reconstructs an Indo-European religion (relying on the method of Georges Dumézil). He writes that the lithic assemblage of the first Kurgan culture in Ukraine (Sredni Stog II), originated from the Volga and South Urals, recalls that of the Mesolithic-Neolithic sites to the east of the Caspian sea, Dam Dam Chesme II and the cave of Djebel. Thus, he places the roots of the Gimbutas' Kurgan cradle of Indo-Europeans in a more southern cradle, and adds that the Djebel material is related to a Paleolithic material of Northwestern Iran, the Zarzian culture, dated 10,000-8,500 BCE, and in the more ancient Kebarian of the Near East. He concludes that more than 10,000 years ago the Indo-Europeans were a small people grammatically, phonetically and lexically close to Semitic-Hamitic populations of the Near East.

The Anatolian hypothesis proposes that the Indo-European languages spread peacefully into Europe from Asia Minor from around 7000 BCE with the advance of farming ("wave of advance"). The leading propagator of the theory is Colin Renfrew. The culture of the Indo-Europeans as inferred by linguistic reconstruction raises difficulties for this theory, since early neolithic cultures had neither the horse, nor the wheel, nor metal, terms for all of which are securely reconstructed for Proto-Indo-European. Renfrew dismisses this argument, comparing such reconstructions to a theory that the presence of the word "café" in all modern Romance languages implies that the ancient Romans had cafés too. The linguistic counter-argument to this might state that whereas there can be no clear Proto-Romance reconstruction of the word "café" according to historical linguistic methodology, words such as "wheel" in the Indo-European languages clearly point to an archaic form of the protolanguage. Another argument against Renfrew is the fact that ancient Anatolia is known to have been inhabited by non-Indo-European Caucasian-speaking peoples, namely the Hattians, the Chalybes, and the Hurrians.

The rise of archaeogenetic evidence which uses genetic analysis to trace migration patterns also added new elements to the origins puzzle.

According to three autosomal DNA studies, haplogroups R1b and R1a, now the most common in Europe (R1a is also very common in South Asia) would have expanded from the Russian steppes, along with the Indo European languages; they also detected an autosomal component present in modern Europeans which was not present in Neolithic Europeans, which would have been introduced with paternal lineages R1b and R1a, as well as Indo European Languages. Studies which analysed ancient human remains in Ireland and Portugal suggest that R1b was introduced in these places along with autosomal DNA from the Eastern European steppes.

The subclade R1a1a (R-M17 or R-M198) is most commonly associated with Indo-European speakers, although the subclade R1b1a (P-297) has also been linked to the Centum branch of Indo-European. Data so far collected indicate that there are two widely separated areas of high frequency, one in Eastern Europe, around Poland and the Russian core, and the other in South Asia, around Indo-Gangetic Plain. The historical and prehistoric possible reasons for this are the subject of on-going discussion and attention amongst population geneticists and genetic genealogists, and are considered to be of potential interest to linguists and archaeologists also.

A large, 2014 study by Underhill et al., using 16,244 individuals from over 126 populations from across Eurasia, concluded there was compelling evidence, that R1a-M420 originated in the vicinity of Iran. The mutations that characterize haplogroup R1a occurred ~10,000 years BP. Its defining mutation (M17) occurred about 10,000 to 14,000 years ago.

Ornella Semino et al. propose a postglacial (Holocene) spread of the R1a1 haplogroup from north of the Black Sea during the time of the Late Glacial Maximum, which was subsequently magnified by the expansion of the Kurgan culture into Europe and eastward.

According to Jones et al. (2015) and Haak et al. (2015), Yamna culture was exclusively R1b, autosomic tests indicate that the Yamnaya-people were the result of admixture between two different hunter-gatherer populations: distinctive "Eastern European hunter-gatherers" with high affinity to the Mal'ta-Buret' culture or other, closely related Ancient North Eurasian (ANE) people from Siberia and to Western Hunter Gatherers(WHG) and a population of "Caucasus hunter-gatherers" who probably arrived from somewhere in the Near East, probably the Caucasus or Iran. Each of those two populations contributed about half the Yamnaya DNA. According to co-author Dr. Andrea Manica of the University of Cambridge: 
According to Haak et al. (2015), "Eastern European hunter-gatherers" who inhabited Russia were a distinctive population of hunter-gatherers with high affinity to a ~24,000-year-old Siberian from Mal'ta-Buret' culture, or other, closely related Ancient North Eurasian (ANE) people from Siberia and to the Western Hunter Gatherers (WHG). Remains of the "Eastern European hunter-gatherers" have been found in Mesolithic or early Neolithic sites in Karelia and Samara Oblast, Russia, and put under analysis. Three such hunter-gathering individuals of the male sex have had their DNA results published. Each was found to belong to a different Y-DNA haplogroup: R1a, R1b, and J. R1b is also the most common Y-DNA haplogroup found among both the Yamnaya and modern-day Western Europeans.

The Near East population were most likely hunter-gatherers from the Caucasus (CHG) c.q. Iran Chalcolithic related people with a CHG-component.

Jones et al. (2015) analyzed genomes from males from western Georgia, in the Caucasus, from the Late Upper Palaeolithic (13,300 years old) and the Mesolithic (9,700 years old). These two males carried Y-DNA haplogroup: J* and J2a. The researchers found that these Caucasus hunters were probably the source of the farmer-like DNA in the Yamnaya, as the Caucasians were distantly related to the Middle Eastern people who introduced farming in Europe. Their genomes showed that a continued mixture of the Caucasians with Middle Eastern took place up to 25,000 years ago, when the coldest period in the last Ice Age started.

According to Lazaridis et al. (2016), "a population related to the people of the Iran Chalcolithic contributed ~43% of the ancestry of early Bronze Age populations of the steppe." According to Lazaridis et al. (2016), these Iranian Chalcolithic people were a mixture of "the Neolithic people of western Iran, the Levant, and Caucasus Hunter Gatherers." Lazaridis et al. (2016) also note that farming spread at two places in the Near East, namely the Levant and Iran, from where it spread, Iranian people spreading to the steppe and south Asia.

Haak et al. (2015) studied DNA from 94 skeletons from Europe and Russia aged between 3,000 and 8,000 years old. They concluded that about 4,500 years ago there was a major influx into Europe of Yamna culture people originating from the Pontic-Caspian steppe north of the Black Sea and that the DNA of copper-age Europeans matched that of the Yamnaya. The genetic basis of a number of features of the Yamnaya people were ascertained: they were genetically tall (phenotypic height is determined by both genetics and environmental factors), overwhelmingly dark-eyed (brown), dark-haired and had a skin colour that was moderately light, though somewhat darker than that of the average modern European:
From the Corded Ware culture the Indo-Europeans spread eastward again, forming the Andronovo culture. Most researchers associate the Andronovo horizon with early Indo-Iranian languages, though it may have overlapped the early Uralic-speaking area at its northern fringe. According to Allentoft et al. (2015), the Sintashta culture and Andronovo culture are derived from the Corded Ware culture. According to Keyser et al. (2009), out of 10 human male remains assigned to the Andronovo horizon from the Krasnoyarsk region, nine possessed the R1a Y-chromosome haplogroup and one had the C-M130 haplogroup (xC3). Furthermore, 90% of the Bronze Age period mtDNA haplogroups were of west Eurasian origin, and the study determined that at least 60% of the individuals overall (out of the 26 Bronze and Iron Age human-remains samples from the study that could be tested) had light hair and blue or green eyes.

A 2004 study also established that during the Bronze Age/Iron Age period, the majority of the population of Kazakhstan (part of the Andronovo culture during Bronze Age), was of west Eurasian origin (with mtDNA haplogroups such as U, H, HV, T, I and W), and that prior to the 13th–7th centuries BCE, all samples from Kazakhstan belonged to European lineages.

Luigi Luca Cavalli-Sforza and Alberto Piazza argue that Renfrew and Gimbutas reinforce rather than contradict each other. states that "It is clear that, genetically speaking, peoples of the Kurgan steppe descended at least in part from people of the Middle Eastern Neolithic who immigrated there from Turkey." Piazza and Cavalli-Sforza (2006) state that:
Spencer Wells suggests in a 2001 study that the origin, distribution and age of the R1a1 haplotype points to an ancient migration, possibly corresponding to the spread by the Kurgan people in their expansion across the Eurasian steppe around 3000 BCE.

About his old teacher Cavalli-Sforza's proposal, states that "there is nothing to contradict this model, although the genetic patterns do not provide clear support either", and instead argues that the evidence is much stronger for Gimbutas' model:
David Reich argues that the most likely location of the Proto-Indo-European homeland is south of the Caucasus, because "ancient DNA from people who lived there matches what we would expect for a source population both for the Yamnaya and for ancient Anatolians". 





</doc>
<doc id="24820" url="https://en.wikipedia.org/wiki?curid=24820" title="Peter Mark Roget">
Peter Mark Roget

Peter Mark Roget FRS (, ; 18 January 1779 – 12 September 1869) was a British physician, natural theologian and lexicographer. He is best known for publishing, in 1852, the "Thesaurus of English Words and Phrases" (Roget's Thesaurus), a classified collection of related words.

Peter Mark Roget was born in London. His obsession with list-making as a coping mechanism was well established by the time he was eight years old. The son of a Swiss clergyman, Roget studied medicine at the University of Edinburgh, graduating in 1798. His life was marked by several depressing incidents. His father and his wife died young; while his beloved maternal uncle Samuel Romilly committed suicide in his presence. Roget struggled with depression for most of his life; his work on the thesaurus arose partly from an effort to battle it.

Roget retired from professional life in 1840, and in about 1848 began preparing for publication the one work that was to perpetuate his memory. This was the catalogue of words organized by their meanings, the compilation of which had been an avocation since 1805. Its first printed edition, in 1852, was called "Thesaurus of English Words and Phrases Classified and Arranged so as to Facilitate the Expression of Ideas and Assist in Literary Composition". During his lifetime the work had twenty-eight printings; after his death it was revised and expanded by his son, John Lewis Roget (1828–1908), and later by John's son, Samuel Romilly Roget (1875–?). Peter Roget was a secretary of the Portico Library in Manchester and it was there that he began to compile his Thesaurus.

Roget died while on holiday in West Malvern, Worcestershire, aged 90, and is buried there in the cemetery of St James's Church.

Roget was much concerned with medical education but the School of Medicine at the University of Manchester was only established in 1874. He was also one of the founders of the Medical and Chirurgical Society of London, which later became the Royal Society of Medicine, and he was a secretary of the Royal Society. In 1815, he invented the log-log slide rule, allowing a person to perform exponential and root calculations simply. This was especially helpful for calculations involving fractional powers and roots. In 1834 he became the first Fullerian Professor of Physiology at the Royal Institution. He was examiner in physiology in the University of London.

On 9 December 1824, Roget presented a paper entitled "Explanation of an optical deception in the appearance of the spokes of a wheel when seen through vertical apertures." This article is often incorrectly referenced as either "On the Persistence of Vision with Regard to Human Motion" or "Persistence of Vision with regard to Moving Objects", likely due to erroneous citations by film historians Terry Ramsaye and Arthur Knight (see Anderson and Anderson below). While Roget's explanation of the illusion was probably wrong, his consideration of the illusion of motion is seen as an important point in the history of film, and possibly influenced the development of the Thaumatrope, the Phenakistiscope and the Zoetrope.

He wrote numerous papers on physiology and health, among them the fifth "Bridgewater Treatise", "Animal and Vegetable Physiology considered with reference to Natural Theology" (1834), a two-volume work on phrenology (1838), and articles for several editions of "Encyclopædia Britannica".

He played an important role in the establishment of the University of London; he was a founder of the Society for the Diffusion of Useful Knowledge and wrote for it a series of popular manuals. He showed remarkable ingenuity in inventing and solving chess problems and designed an inexpensive pocket chessboard.


Canadian writer Keath Fraser published a story, "Roget's Thesaurus," in 1982, which is narrated in Roget's voice. Minimalist in style, Fraser's story manages to capture both the associative power of language and many of the salient facts of Roget's life in a text that occupies less than two full pages. 

A picture book biography of Roget entitled "The Right Word: Roget and His Thesaurus" was published by Eerdmans Books in 2014. It was named a Caldecott Honor book for excellence in illustration, and won the Sibert Medal for excellence in children's nonfiction.

Peter Roget is mentioned in Philip Roth's book "Operation Shylock" as a fake name that the author made up to introduce himself while speaking by phone with his counterpart ("the other Philip Roth"). The choice of Roget's name as a pseudonym was motivated by the coincidence between the initials of both names (P.R)

Roget was the focus of Randy Wyatt's "Synonymy", which premiered at Minnesota State University's Department of Theatre and Dance in December, 2005. In the play, Gordon, a graduate student, rents Roget's last known residence to inspire himself as he writes his dissertation on the English language and Roget's "Thesaurus". The building, soon to be torn down, creates a gateway through which Gordon finds himself traveling back in time and meeting Roget and his daughter, Kate.

Roget also appears in Shelagh Stephenson's "An Experiment with an Air Pump", which concerns scientific ethics. The play takes place in the household of Joseph Fenwick in 1799, and Roget is one of Fenwick's assistants. Roget was elected a Fellow of the Royal Society (FRS) in 1815. 

Dr. Jack Lynch, professor English at Rutgers, is of the opinion that Roget's thesaurus was influenced by Amarasimha's Amarakosha.



 


</doc>
<doc id="24823" url="https://en.wikipedia.org/wiki?curid=24823" title="Pterodactylus">
Pterodactylus

Pterodactylus ( , from the , ', meaning "winged finger") is an extinct flying reptile genus of pterosaurs, whose members are popularly known as pterodactyls ( ). It is currently thought to contain only a single species, Pterodactylus antiquus, the first pterosaur species to be named and identified as a flying reptile.

The fossil remains of this species have been found primarily in the Solnhofen limestone of Bavaria, Germany, dated to the late Jurassic Period (early Tithonian), about 150.8–148.5 million years ago, though more fragmentary remains have been tentatively identified from elsewhere in Europe and in Africa.

It was a carnivore and probably preyed upon fish and other small animals. Like all pterosaurs, "Pterodactylus" had wings formed by a skin and muscle membrane stretching from its elongated fourth finger to its hind limbs. It was supported internally by collagen fibres and externally by keratinous ridges.

"Pterodactylus" is known from over 30 fossil specimens, and though most of those are juveniles, many preserve complete skeletons. "Pterodactylus antiquus" was a relatively small pterosaur, with an estimated adult wingspan of about (the only known adult specimen is represented by an isolated skull). Other "species" were once thought to be smaller. However, these smaller specimens have been shown to represent juveniles of "Pterodactylus", as well as its contemporary relatives including "Ctenochasma", "Germanodactylus", "Aerodactylus", "Aurorazhdarcho", and "Gnathosaurus".

The skulls of adult "Pterodactylus" were long and thin with about 90 narrow, conical teeth. The teeth extended back from the tips of both jaws, and became smaller farther away from the jaw tips (unlike some relatives, where teeth were absent in the upper jaw tip and were relatively uniform in size). The teeth extended farther back into the jaw than in close relatives, as some were present below the front of the "nasoantorbital fenestra", the largest opening in the skull. Unlike related species, the skull and jaws were straight, not curved upwards.
"Pterodactylus", like related pterosaurs, had a crest on its skull composed mainly of soft tissues. In adult "Pterodactylus", this crest extended between the back edge of the antorbital fenestra (the largest opening in the skull) and the back of the skull. In at least one specimen, the crest had a short bony base, also seen in related pterosaurs like "Germanodactylus". Solid crests have only been found on large, fully adult specimens of "Pterodactylus", indicating that this was a display structure that became larger and more well developed as individuals reached maturity. Bennett (2013) noted that other authors claimed that the soft tissue crest of "Pterodactylus" extended backward behind the skull; Bennett himself, however, didn't find any evidence for the crest extending past the back of the skull. Two specimens of "P. antiquus" (the holotype specimen BSP AS I 739 and the incomplete skull BMMS 7, the largest known skull of "P. antiquus") have a low bony crest on their skulls; in BMMS 7 it is 47.5 mm long (more or less 24% of the estimated total length of its skull) and has a maximum height of 0.9 mm above the orbit. Several specimens previously referred to "P. antiquus" preserved evidence of the soft tissue extensions of these crests, including an "occipital lappet", a flexible, tab-like structure extending from the back of the skull. However, most of these specimens have since been reclassified in the related species "Aerodactylus scolopaciceps". At least one specimen with these features is still considered to belong to "Pterodactylus". This is BSP 1929 I 18, which has an occipital lappet similar to "Aerodactylus". This specimen also has a small triangular soft tissue crest with the peak of the Crest positioned above the eyes.

Like other pterosaurs (notably "Rhamphorhynchus"), "Pterodactylus" specimens can vary considerably based on age or level of maturity. Both the proportions of the limb bones, size and shape of the skull, and size and number of teeth changed as the animals grew. Historically, this has led to various growth stages (including growth stages of related pterosaurs) being mistaken for new species of "Pterodactylus". Several detailed studies using various methods to measure growth curves among known specimens have suggested that there is actually only one valid "Pterodactylus" species, "P. antiquus".

The youngest immature "Pterodactylus antiquus" specimens (alternately interpreted as young specimens of the distinct species "P. kochi") have a small number of teeth (as few as 15), and the teeth have a relatively broad base. The teeth of other "P. antiquus" specimens are both narrower and more numerous (up to 90 teeth are present in some specimens).

"Pterodactylus" specimens can be divided into two distinct year classes. In the first year class, the skulls are only 15-45mm in length. The second year class is characterized by skulls 55-95mm long, but still immature. These first two size groups were once classified as juveniles and adults of the species "P. kochi", until further study showed that even the supposed "adults" were immature, and possibly belong to a distinct genus. A third year class is represented by specimens of the "traditional" "P. antiquus", as well as a few isolated, large specimens once assigned to "P. kochi" that overlap "P. antiquus" in size. However, all specimens in this third year class also show sign of immaturity. Fully mature "Pterodactylus" specimens remain unknown, or may have been mistakenly classified as a different genus.

The distinct year classes of "Pterodactylus antiquus" specimens show that this species, like the contemporary "Rhamphorhynchus muensteri", likely bred seasonally and grew consistently during its lifetime. A new generation of 1st year class "P. antiquus" would have been produced seasonally, and reached 2nd-year size by the time the next generation hatched, creating distinct 'clumps' of similarly-sized and aged individuals in the fossil record. The smallest size class probably consisted of individuals that had just begun to fly and were less than one year old. The second year class represents individuals one to two years old, and the rare third year class is composed of specimens over two years old. This growth pattern is similar to modern crocodilians, rather than the rapid growth of modern birds.

Comparisons between the scleral rings of "Pterodactylus antiquus" and modern birds and reptiles suggest that it may have been diurnal. This may also indicate niche partitioning with contemporary pterosaurs inferred to be nocturnal, such as "Ctenochasma" and "Rhamphorhynchus".

The type specimen of the animal now known as "Pterodactylus antiquus" was one of the first pterosaur fossils ever to be identified. The first "Pterodactylus" specimen was described by the Italian scientist Cosimo Alessandro Collini in 1784, based on a fossil skeleton that had been unearthed from the Solnhofen limestone of Bavaria. Collini was the curator of the "Naturalienkabinett", or nature cabinet (a precursor to the modern concept of the natural history museum), in the palace of Charles Theodore, Elector of Bavaria at Mannheim. The specimen had been given to the collection by Count Friedrich Ferdinand zu Pappenheim, probably around 1780, having been recovered from a lithographic limestone quarry in Eichstätt. The actual date of the specimen's discovery and entry into the collection is unknown. It was not mentioned in a catalogue of the collection taken in 1767 and so must have been acquired at some point between that date and its 1784 description by Collini. This makes it potentially the earliest documented pterosaur find; the "Pester Exemplar" of "Pterodactylus micronyx" was described in 1779 and possibly discovered earlier than the Mannheim specimen, but it was at first considered to be a fossil crustacean.
Collini, in his first description of the Mannheim specimen, did not conclude that it was a flying animal. In fact, Collini could not fathom what kind of animal it might have been, rejecting affinities with the birds or the bats. He speculated that it may have been a sea creature, not for any anatomical reason, but because he thought the ocean depths were more likely to have housed unknown types of animals. The idea that pterosaurs were aquatic animals persisted among a minority of scientists as late as 1830, when the German zoologist Johann Georg Wagler published a text on "amphibians" which included an illustration of "Pterodactylus" using its wings as flippers. Wagler went so far as to classify "Pterodactylus", along with other aquatic vertebrates (namely plesiosaurs, ichthyosaurs, and monotremes), in the class Gryphi, between birds and mammals.

It was the German/French scientist Johann Hermann who first stated that "Pterodactylus" used its long fourth finger to support a wing membrane. In March 1800, Hermann alerted the French scientist George Cuvier to the existence of Collini's fossil, believing that it had been captured by the occupying armies of Napoleon and sent to the French collections in Paris (and perhaps to Cuvier himself) as war booty; at the time special French political commissars systematically seized art treasures and objects of scientific interest. Hermann sent Cuvier a letter containing his own interpretation of the specimen (though he had not examined it personally), which he believed to be a mammal, including the first known life restoration of a pterosaur. Hermann restored the animal with wing membranes extending from the long fourth finger to the ankle and a covering of fur (neither wing membranes nor fur had been preserved in the specimen). Hermann also added a membrane between the neck and wrist, as is the condition in bats. Cuvier agreed with this interpretation, and at Hermann's suggestion, Cuvier became the first to publish these ideas in December 1800 in a very short description. Cuvier remarked, "[It is not possible to doubt that the long finger served to support a membrane that, by lengthening the anterior extremity of this animal, formed a good wing.]" However, contrary to Hermann, Cuvier was convinced the animal was a reptile.

The specimen had not in fact been seized by the French. Rather, in 1802, following the death of Charles Theodore, it was brought to Munich, where Baron Johann Paul Carl von Moll had obtained a general exemption of confiscation for the Bavarian collections. Cuvier asked von Moll to study the fossil but was informed it could not be found. In 1809 Cuvier published a somewhat longer description, in which he named the animal a "ptero-dactyle" and refuted a hypothesis by Johann Friedrich Blumenbach that it would have been a shore bird.

Contrary to von Moll's report, the fossil was not missing; it was being studied by Samuel Thomas von Sömmerring, who gave a public lecture about it on 27 December 1810. In January 1811, von Sömmerring wrote a letter to Cuvier deploring the fact that he had only recently been informed of Cuvier's request for information. His lecture was published in 1812, and in it von Sömmerring named the species "Ornithocephalus antiquus". The animal was described as being both a mammal, a bat, and a form in between mammals and birds, i.e. not intermediate in descent but in "affinity" or archetype. Cuvier disagreed, and the same year in his "Ossemens fossiles" provided a lengthy description in which he restated that the animal was a reptile. It was not until 1817 that a second specimen of "Pterodactylus" came to light, again from Solnhofen. This tiny specimen was that year described by von Soemmerring as "Ornithocephalus brevirostris", named for its short snout, now understood to be a juvenile character (this specimen is now thought to represent a juvenile specimen of a different genus, probably "Ctenochasma"). He provided a restoration of the skeleton, the first one published for any pterosaur. This restoration was very inaccurate, von Soemmerring mistaking the long metacarpals for the bones of the lower arm, the lower arm for the humerus, this upper arm for the breast bone and this sternum again for the shoulder blades. Soemmerring did not change his opinion that these forms were bats and this "bat model" for interpreting pterosaurs would remain influential long after a consensus had been reached around 1860 that they were reptiles. The standard assumptions were that pterosaurs were quadrupedal, clumsy on the ground, furred, warmblooded and had a wing membrane reaching the ankle. Some of these elements have been confirmed, some refuted by modern research, while others remain disputed.

The genus now known as "Pterodactylus" was originally named "Petro-Dactyle" by Cuvier in 1809, though this was a typographical error, later corrected by him to "Ptéro-Dactyle". In 1812, Samuel Thomas von Sömmerring named the same specimen "Ornithocephalus antiquus". The genus name was emended to the current "Pterodactylus" by Constantine Samuel Rafinesque in 1815. Unaware of Rafinesque's publication, Cuvier himself in 1819 again emended the genus name, but the specific name he then gave, "longirostris", has to give precedence to von Soemmerring's "antiquus". In 1888 Richard Lydekker designated "Pterodactylus antiquus" the type species. The original specimen is the holotype of the genus, BSP No. AS.I.739.

Hermann von Meyer, in 1830, used the name Pterodactyli to contain "Pterodactylus" and other pterosaurs known at the time. This was emended to the family Pterodactylidae by Prince Charles Lucien Bonaparte in 1838. This group has more recently been given several competing definitions.

Below is a cladogram showing the results of a phylogenetic analysis presented by Andres, Clark & Xu, 2014.

Numerous species have been assigned to "Pterodactylus" in the years since its discovery. In the first half of the nineteenth century any new pterosaur species would be named "Pterodactylus", which thus became a typical "wastebasket taxon". Even after clearly different forms had later been given their own generic name, new species would be created from the very productive late Jurassic German sites, often based on only slightly different material.

Around 1980, subsequent revisions by Peter Wellnhofer had reduced the number of recognized species to about half a dozen. Many species assigned to "Pterodactylus" had been based on juvenile specimens, and subsequently been recognized as immature individuals of other species or genera. By the 1990s it was understood that this was even true for part of the remaining species. "P. elegans", for example, was found by numerous studies to be an immature "Ctenochasma". Another species of "Pterodactylus" originally based on small, immature specimens was "P. micronyx". However, it has been difficult to determine exactly of what genus and species "P. micronyx" might be the juvenile form. Stéphane Jouve, Christopher Bennett and others had once suggested that it probably belonged either to "Gnathosaurus subulatus" or one of the "Ctenochasma" species, though after additional research Bennett assigned it to the genus "Aurorazhdarcho". Another species with a complex history is "P. longicollum", named by von Meyer in 1854, based on a large specimen with a long neck and fewer teeth. Many researchers, including David Unwin, have found "P. longicollum" to be distinct from "P. kochi" and "P. antiquus". Unwin found "P. longicollum" to be closer to "Germanodactylus" and therefore requiring a new genus name. It has sometimes been placed in the genus "Diopecephalus" because Harry Govier Seeley based this genus partly on the "P. longicollum" material. However, it was shown by Bennett that the type specimen later designated for "Diopecephalus" was a fossil belonging to "P. kochi", and no longer thought to be separate from "Pterodactylus". "Diopecephalus" is therefore a synonym of "Pterodactylus", and as such is unavailable for use as a new genus for "P." "longicollum". ""P." longicollum" was eventually made the type species of a separate genus "Ardeadactylus".
The only well-known and well-supported species left by the first decades of the 21st century were "P. antiquus" and "P. kochi". However, most studies between 1995 and 2010 found little reason to separate even these two species, and treated them as synonymous. In 1996, Bennett suggested that the differences between specimens of "P. kochi" and "P. antiquus" could be explained by differences in age, with "P. kochi" (including specimens alternately classified in the species "P. scolopaciceps") representing an immature growth stage of "P. antiquus". In a 2004 paper, Jouve used a different method of analysis and recovered the same result, showing that the "distinctive" features of "P. kochi" were age-related, and using mathematical comparison to show that the two forms are different growth stages of the same species. An additional review of the specimens published in 2013 demonstrated that some of the supposed differences between "P. kochi" and "P. antiquus" were due to measurement errors, further supporting their synonymy.

By the 2010s, a large body of research had been developed based on the idea that "P. kochi" and "P. scolopaciceps" were early growth stages of "P. antiquus". However, in 2014, two scientists began publishing research that challenged this paradigm. Steven Vidovic and David Martill concluded that differences between specimens of "P. kochi", "P. scolopaciceps", and "P. antiquus", such as different lengths of neck vertebrae, thinner or thicker teeth, more rounded skulls, and how far the teeth extended back in the jaws, were significant enough to separate them into three distinct species. Vidovic and Martill also performed a phylogenetic analysis which treated all relevant specimens as distinct units, and found that the "P. kochi" type specimen did not form a natural group with that of "P. antiquus". They concluded that the genus "Diopecephalus" could be returned to use to distinguish "P". "kochi" from "P. antiquus". They named the new genus "Aerodactylus" for "P. scolopaciceps" as well. So, what Bennett considered early growth stages of one species, Vidovic and Martill considered representatives of new species.

In 2017, Bennett challenged this hypothesis. He claimed that while Vidovic and Martill had identified real differences between the these three groups of specimens, they had not provided any rationale that the differences were enough to distinguish them as species, rather than just individual variation, growth changes, or simply due to crushing and distortion during the fossilization process. Bennett pointed in particular to the data used to distinguish ""Aerodactylus"", which was so different from the data for related species, it might be due to an unnatural assemblage of specimens. As a result, Bennett continued to consider "Diopecephalus" and "Aerodactylus" simply as year-classes of immature "Pterodactylus antiquus".

During its over-200-year history, the various species of "Pterodactylus" have gone through a number of changes in classification, and thus have acquired a large number of synonyms. Additionally, a number of species assigned to "Pterodactylus" are based on poor remains that have proven difficult to assign to one species or another, and are therefore considered "nomina dubia" ("doubtful names"). The following list includes names that are based on German material presently, or until recently, thought to be pertaining to "Pterodactylus" proper and names based on other material that has as yet not been assigned to other genera.



</doc>
<doc id="24824" url="https://en.wikipedia.org/wiki?curid=24824" title="Pterosaur">
Pterosaur

Pterosaurs (; from the Greek , ', meaning "winged lizard") were flying reptiles of the extinct clade or order Pterosauria. They existed during most of the Mesozoic: from the late Triassic to the end of the Cretaceous (228 to 66 million years ago). Pterosaurs are the earliest vertebrates known to have evolved powered flight. Their wings were formed by a membrane of skin, muscle, and other tissues stretching from the ankles to a dramatically lengthened fourth finger.

Early species had long, fully toothed jaws and long tails, while later forms had a highly reduced tail, and some lacked teeth. Many sported furry coats made up of hair-like filaments known as pycnofibers, which covered their bodies and parts of their wings. Pterosaurs spanned a wide range of adult sizes, from the very small anurognathids to the largest known flying creatures of all time, including "Quetzalcoatlus" and "Hatzegopteryx".

Pterosaurs are often referred to in the popular media and by the general public as "flying dinosaurs", but this is scientifically incorrect. The term "dinosaur" is restricted to just those reptiles descended from the last common ancestor of the groups Saurischia and Ornithischia (clade Dinosauria, which includes birds), and current scientific consensus is that this group excludes the pterosaurs, as well as the various groups of extinct marine reptiles, such as ichthyosaurs, plesiosaurs, and mosasaurs.

Like the dinosaurs, and unlike these other reptiles, pterosaurs are more closely related to birds than to crocodiles or any other living reptile. Pterosaurs are also colloquially referred to as pterodactyls, particularly in fiction and by journalists. However, technically, "pterodactyl" only refers to members of the genus "Pterodactylus", and more broadly to members of the suborder Pterodactyloidea of the pterosaurs.

The anatomy of pterosaurs was highly modified from their reptilian ancestors by the adaption to flight. Pterosaur bones were hollow and air-filled, like the bones of birds. They had a keeled breastbone that was developed for the attachment of flight muscles and an enlarged brain that shows specialised features associated with flight. In some later pterosaurs, the backbone over the shoulders fused into a structure known as a notarium, which served to stiffen the torso during flight, and provide a stable support for the shoulder blade.

Pterosaur wings were formed by membranes of skin and other tissues. The primary membranes attached to the extremely long fourth finger of each arm and extended along the sides of the body to the ankles.

While historically thought of as simple leathery structures composed of skin, research has since shown that the wing membranes of pterosaurs were highly complex dynamic structures suited to an active style of flight. The outer wings (from the tip to the elbow) were strengthened by closely spaced fibers called "actinofibrils". The actinofibrils themselves consisted of three distinct layers in the wing, forming a crisscross pattern when superimposed on one another. The function of the actinofibrils is unknown, as is the exact material from which they were made. Depending on their exact composition (keratin, muscle, elastic structures, etc.), they may have been stiffening or strengthening agents in the outer part of the wing. The wing membranes also contained a thin layer of muscle, fibrous tissue, and a unique, complex circulatory system of looping blood vessels.

As shown by cavities in the wing bones of larger species and soft tissue preserved in at least one specimen, some pterosaurs extended their system of respiratory air sacs (see Paleobiology section below) into the wing membrane.

The pterosaur wing membrane is divided into three basic units. The first, called the "propatagium" ("first membrane"), was the forward-most part of the wing and attached between the wrist and shoulder, creating the "leading edge" during flight. This membrane may have incorporated the first three fingers of the hand, as evidenced in some specimens. The "brachiopatagium" ("arm membrane") was the primary component of the wing, stretching from the highly elongated fourth finger of the hand to the hind limbs (though where exactly on the hind limbs it anchored is controversial and may have varied between species, see below). Finally, at least some pterosaur groups had a membrane that stretched between the legs, possibly connecting to or incorporating the tail, called the uropatagium; the extent of this membrane is not certain, as studies on "Sordes" seem to suggest that it simply connected the legs but did not involve the tail (rendering it a cruropatagium). It is generally agreed though that non-pterodactyloid pterosaurs had a broader uro/cruropatagium, with pterodactyloids only having membranes running along the legs.

A bone unique to pterosaurs, known as the pteroid, connected to the wrist and helped to support a forward membrane (the propatagium) between the wrist and shoulder. Evidence of webbing between the three free fingers of the pterosaur forelimb suggests that this forward membrane may have been more extensive than the simple pteroid-to-shoulder connection traditionally depicted in life restorations. The position of the pteroid bone itself has been controversial. Some scientists, notably Matthew Wilkinson, have argued that the pteroid pointed forward, extending the forward membrane. This view was contradicted in a 2007 paper by Chris Bennett, who showed that the pteroid did not articulate as previously thought and could not have pointed forward, but rather inward toward the body as traditionally thought. Peters (2009) proposed that the pteroid articulated with the ‘saddle' of the radiale (proximal syncarpal) and both the pteroid and preaxial carpal were migrated centralia. This view of the articulation of the pteroid has since been supported by specimens of "Changchengopterus pani" and "Darwinopterus linglongtaensis", both of which show the pteroid in articulation with the proximal syncarpal.

The pterosaur wrist consists of two inner (proximal) and four outer (distal) carpals (wrist bones), excluding the pteroid bone, which may itself be a modified distal carpal. The proximal carpals are fused together into a "syncarpal" in mature specimens, while three of the distal carpals fuse to form a distal syncarpal. The remaining distal carpal, referred to here as the medial carpal, but which has also been termed the distal lateral, or pre-axial carpal, articulates on a vertically elongate biconvex facet on the anterior surface of the distal syncarpal. The medial carpal bears a deep concave fovea that opens anteriorly, ventrally and somewhat medially, within which the pteroid articulates. In derived pterodactyloids like pteranodontians and azhdarchoids, metacarpals I-III are small and do not connect to the carpus, instead hanging in contact with the fourth metacarpal; in nyctosaurids the forelimb digits besides the wingfinger have been lost altogether.

There has been considerable argument among paleontologists about whether the main wing membranes (brachiopatagia) attached to the hind limbs, and if so, where. Fossils of the rhamphorhynchoid "Sordes", the anurognathid "Jeholopterus", and a pterodactyloid from the Santana Formation seem to demonstrate that the wing membrane did attach to the hindlimbs, at least in some species. However, modern bats and flying squirrels show considerable variation in the extent of their wing membranes and it is possible that, like these groups, different species of pterosaur had different wing designs. Indeed, analysis of pterosaur limb proportions shows that there was considerable variation, possibly reflecting a variety of wing-plans.

Many, if not all, pterosaurs also had webbed feet.

Most pterosaur skulls had elongated jaws with a full complement of needle-like teeth. In some cases, fossilized keratinous beak tissue has been preserved, though in toothed forms, the beak is small and restricted to the jaw tips and does not involve the teeth. Some advanced beaked forms were toothless, such as the pteranodonts and azhdarchids, and had larger, more extensive, and more bird-like beaks.

Unlike most archosaurs, the nasal and antorbital openings of pterodactyloid pterosaurs merged into a single large opening, called the "nasoantorbital fenestra". This feature likely evolved to lighten the skull for flight.

Some species of pterosaurs featured elaborate crests. The first and perhaps best known of these is the distinctive backward-pointing crest of some "Pteranodon" species, though a few pterosaurs, such as the tapejarids and "Nyctosaurus", sported extremely large crests that often incorporated keratinous or other soft tissue extensions of the bony crest base.

Since the 1990s, new discoveries and more thorough study of old specimens have shown that crests are far more widespread among pterosaurs than previously thought, due mainly to the fact that they were frequently extended by or composed completely of keratin, which does not fossilize as often as bone. In the case of pterosaurs like "Pterorhynchus" and "Pterodactylus", the true extent of these crests has only been uncovered using ultraviolet photography. The discovery of "Pterorynchus" and "Austriadactylus", both crested "rhamphorhynchoids", showed that even primitive pterosaurs had crests (previously, crests were thought to be restricted to the more advanced pterodactyloids).

At least some pterosaurs had hair-like filaments known as pycnofibers on the head and body, similar to, but not homologous (sharing a common origin) with, mammalian hair. A fuzzy integument was first reported from a specimen of "Scaphognathus crassirostris" in 1831 by Goldfuss, and recent pterosaur finds and the technology for histological and ultraviolet examination of pterosaur specimens have provided incontrovertible proof: pterosaurs had pycnofiber coats. Pycnofibers were not true hair as seen in mammals, but a unique structure that developed a similar appearance. Although, in some cases, actinofibrils (internal structural fibers) in the wing membrane have been mistaken for pycnofibers or true hair, some fossils, such as those of "Sordes pilosus" (which translates as "hairy demon") and "Jeholopterus ninchengensis", do show the unmistakable imprints of pycnofibers on the head and body, not unlike modern-day bats, another example of convergent evolution. The head-coats do not cover the pterosaur's large jaws in many of the specimens found so far.

Some (Czerkas and Ji, 2002) have speculated that pycnofibers were an antecedent of proto-feathers, but the available impressions of pterosaur integuments are not like the "quills" found on many of the bird-like maniraptoran specimens in the fossil record. Pterosaur pycnofibers were structured similarly to theropod proto-feathers. Pycnofibers were flexible, short filaments, "only 5-7mm in some specimens" and rather simple, "apparently lacking any internal detail aside from a central canal". Pterosaur "pelts" found "preserved in concentrated, dense mats of fibers, similar to those found surrounding fossilized mammals" suggest coats with a thickness comparable to many Mesozoic mammals, at least on the parts of the pterosaur covered in pycnofibers. The coat thickness, and surface area covered, definitely varied by pterosaur species.

The presence of pycnofibers (and the demands of flight) imply that pterosaurs were endothermic (warm-blooded). The absence of pycnofibers on pterosaur wings suggests that the coat did not have an aerodynamic function, lending support to the idea that pycnofibers evolved to aid pterosaur thermoregulation, as is common in warm-blooded animals, insulation being necessary to conserve the heat created by an endothermic metabolism.

Pterosaur "hair" was so obviously distinct from mammalian fur and other animal integuments, it required a new, separate name. The term "pycnofiber", meaning "dense filament", was first coined in a paper on the soft tissue impressions of "Jeholopterus" by palaeontologist Alexander W.A. Kellner and colleagues in 2009. Research into the genetic code of American alligator embryos could suggest that pycnofibres, crocodile scutes and avian feathers are developmentally homologous, based on the construction of their beta-keratin.

The first pterosaur fossil was described by the Italian naturalist Cosimo Alessandro Collini in 1784. Collini misinterpreted his specimen as a seagoing creature that used its long front limbs as paddles. A few scientists continued to support the aquatic interpretation even until 1830, when the German zoologist Johann Georg Wagler suggested that "Pterodactylus" used its wings as flippers. Georges Cuvier first suggested that pterosaurs were flying creatures in 1801, and coined the name ""Ptero-dactyle"" in 1809 for the specimen recovered in Germany. However, due to the standardization of scientific names, the official name for this genus became "Pterodactylus", though the name "pterodactyl" continued to be popularly and incorrectly applied to all members of Pterosauria. Paleontologists now avoid using "pterodactyl" and prefer the term "pterosaur". They relegate the term "pterodactyl" specifically for members of the genus "Pterodactylus" or more broadly for members of the suborder Pterodactyloidea.

The mechanics of pterosaur flight are not completely understood or modeled at this time.

Katsufumi Sato, a Japanese scientist, did calculations using modern birds and concluded that it was impossible for a pterosaur to stay aloft. In the book "Posture, Locomotion, and Paleoecology of Pterosaurs" it is theorized that they were able to fly due to the oxygen-rich, dense atmosphere of the Late Cretaceous period. However, both Sato and the authors of "Posture, Locomotion, and Paleoecology of Pterosaurs" based their research on the now outdated theories of pterosaurs being seabird-like, and the size limit does not apply to terrestrial pterosaurs, such as azhdarchids and tapejarids. Furthermore, Darren Naish concluded that atmospheric differences between the present and the Mesozoic were not needed for the giant size of pterosaurs.
Another issue that has been difficult to understand is how they took off. Earlier suggestions were that pterosaurs were largely cold-blooded gliding animals, deriving warmth from the environment like modern lizards, rather than burning calories. In this case, it was unclear how the larger ones of enormous size, with an inefficient cold-blooded metabolism, could manage a bird-like takeoff strategy, using only the hind limbs to generate thrust for getting airborne. Later research shows them instead as being warm-blooded and having powerful flight muscles, and using the flight muscles for walking as quadrupeds. Mark Witton of the University of Portsmouth and Mike Habib of Johns Hopkins University suggested that pterosaurs used a vaulting mechanism to obtain flight. The tremendous power of their winged forelimbs would enable them to take off with ease. Once aloft, pterosaurs could reach speeds of up to and travel thousands of kilometres.

In 1985, the Smithsonian Institution commissioned aeronautical engineer Paul MacCready to build a half-scale working model of "Quetzalcoatlus northropi". The replica was launched with a ground-based winch. It flew several times in 1986 and was filmed as part of the Smithsonian's IMAX film "On the Wing". However, the model was not anatomically correct and embodied vertical and horizontal tail stabilizers that pterosaurs did not have. It also had a longer tail, changing the weight distribution.

Pterosaurs had a wide range of sizes, with wingspans ranging from at their smallest, to at their largest.

A 2009 study showed that pterosaurs had a lung-air sac system and a precisely controlled skeletal breathing pump, which supports a flow-through pulmonary ventilation model in pterosaurs, analogous to that of birds. The presence of a subcutaneous air sac system in at least some pterodactyloids would have further reduced the density of the living animal. Like modern crocodilians, pterosaurs appeared to have had a hepatic piston, seeing as their shoulder-pectoral girdles were too inflexible to move the sternum as in birds, and they possessed strong gastralia. Thus, their respiratory system had characteristics comparable to both modern archosaur clades.

An X-ray study of pterosaur brain cavities revealed that the animals ("Rhamphorhynchus muensteri" and "Anhanguera santanae") had massive flocculi. The flocculus is a brain region that integrates signals from joints, muscles, skin and balance organs. The pterosaurs' flocculi occupied 7.5% of the animals' total brain mass, more than in any other vertebrate. Birds have unusually large flocculi compared with other animals, but these only occupy between 1 and 2% of total brain mass.

The flocculus sends out neural signals that produce small, automatic movements in the eye muscles. These keep the image on an animal's retina steady. Pterosaurs may have had such a large flocculus because of their large wing size, which would mean that there was a great deal more sensory information to process. The low relative mass of the flocculi in birds is also a result of birds having a much larger brain overall; though this has been considered an indication that pterosaurs lived in a structurally simpler environment or had less complex behaviour compared to birds, recent studies of crocodilians and other reptiles show that it is common for sauropsids to achieve high intelligence levels with small brains. Studies on the endocast of "Allkaruen" show that brain evolution in pterodactyloids was a modular process.

Pterosaurs' hip sockets are oriented facing slightly upwards, and the head of the femur (thigh bone) is only moderately inward facing, suggesting that pterosaurs had an erect stance. It would have been possible to lift the thigh into a horizontal position during flight, as gliding lizards do.

There was considerable debate whether pterosaurs ambulated as quadrupeds or as bipeds. In the 1980s, paleontologist Kevin Padian suggested that smaller pterosaurs with longer hindlimbs, such as "Dimorphodon", might have walked or even run bipedally, in addition to flying, like road runners. However, a large number of pterosaur trackways were later found with a distinctive four-toed hind foot and three-toed front foot; these are the unmistakable prints of pterosaurs walking on all fours.

Fossil footprints show that pterosaurs stood with the entire foot in contact with the ground (plantigrade), in a manner similar to many mammals like humans and bears. Footprints from azhdarchids and several unidentified species show that pterosaurs walked with an erect posture with their four limbs held almost vertically beneath the body, an energy-efficient stance used by most modern birds and mammals, rather than the sprawled limbs of modern reptiles. Indeed, erect-limbs may be omnipresent in pterosaurs.
Though traditionally depicted as ungainly and awkward when on the ground, the anatomy of some pterosaurs (particularly pterodactyloids) suggests that they were competent walkers and runners. Early pterosaurs have long been considered particularly cumbersome locomotors due to the presence of large cruropatagia, but they too appear to have been generally efficient on the ground.

The forelimb bones of azhdarchids and ornithocheirids were unusually long compared to other pterosaurs, and, in azhdarchids, the bones of the arm and hand (metacarpals) were particularly elongated. Furthermore, as a whole, azhdarchid front limbs were proportioned similarly to fast-running ungulate mammals. Their hind limbs, on the other hand, were not built for speed, but they were long compared with most pterosaurs, and allowed for a long stride length. While azhdarchid pterosaurs probably could not run, they would have been relatively fast and energy efficient.

The relative size of the hands and feet in pterosaurs (by comparison with modern animals such as birds) may indicate the type of lifestyle pterosaurs led on the ground. Azhdarchid pterosaurs had relatively small feet compared to their body size and leg length, with foot length only about 25%–30% the length of the lower leg. This suggests that azhdarchids were better adapted to walking on dry, relatively solid ground. "Pteranodon" had slightly larger feet (47% the length of the tibia), while filter-feeding pterosaurs like the ctenochasmatoids had very large feet (69% of tibial length in "Pterodactylus", 84% in "Pterodaustro"), adapted to walking in soft muddy soil, similar to modern wading birds. Though clearly forelimb-based launchers, basal pterosaurs have hindlimbs well adapted for hopping, suggesting a connection with archosaurs such as "Scleromochlus".

Tracks made by ctenochasmatoids indicate that these pterosaurs swam using their hindlimbs. In general, these have large hindfeet and long torsos, indicating that they were probably more adapted for swimming than other pterosaurs. Pteranodontians conversely have several speciations in their humeri interpreted to have been suggestive of a water-based version of the typical quadrupedal launch, and several like boreopterids must have foraged while swimming, as they seem incapable of frigatebird-like aerial hawking. These adaptations are also seen in terrestrial pterosaurs like azhdarchids, which presumably still needed to launch from water in case they found themselves in it. The nyctosaurid "Alcione" may display adaptations for wing-propelled diving like modern gannets and tropicbirds.

Traditionally, almost all pterosaurs were seen as surface-feeding piscivores, a view that still dominates popular culture. In reality, however, the majority of pterosaurs are now thought to have been terrestrial carnivores or insectivores.

One of the few groups that were never thought to be piscivores are the anurognathids; these were instead thought to be nocturnal, aerial insectivores, a view still maintained today. With highly flexible joints on the wing finger, a broad, triangular wing shape, large eyes and short tail, these pterosaurs were likely analogous to some of today's insectivorous bats, being capable of high manoeuvrability at relatively low speeds.

"Dimorphodon" has been envisioned as a puffin analogue in the past, but its jaw structure and gait, combined with its poor flight capabilities, indicate that it was a terrestrial/semiarboreal feeder. It seems to have been a predator of small mammals and squamates, and likely also preyed on large insects.

"Campylognathoides" is often seen either as a generalist or a terrestrial predator of small vertebrates, based on its robust dentition.. The highly robust, "gorilla-like" humerus and a high-aspect wing morphology, similar to that of falcons, suggest it may have been capable of grabbing prey on the wing.

Eudimorphodonts can be divided into two major categories: those with long, robust wings similar to "Campylognathoides", and those with long, slender wings. Species in the former category, including "Carniadactylus" and "Eudimorphodon" itself, were highly aerial animals and fast, agile flyers. The former was almost certainly insectivorous due to its small size; "Eudimorphodon" has been found with fish remains in its stomach, but its dentition suggests an opportunistic diet. Slender-winged species, such as "Austriadactylus" and "Caviramus", were likely terrestrial/semiarboreal in habits, and potentially generalists. "Caviramus" likely had a strong bite force, indicating an adaptation towards hard foods. All eudimorphodonts possessed well-developed molariform teeth and could chew their food, as indicated by the tooth wear on "Caviramus" and "Eudimorphodon" teeth. "Austriadactylus" and "Eudimorphodon" had a pair of these molariform teeth developed into enlarged fangs.

Rhamphorhynchids can be roughly classified into two categories. One is the longirostrine bauplan, with long, slender wings, needle-like dentition and long, thin jaws, represented by species akin to "Rhamphorhynchus" itself or "Dorygnathus". These taxa were piscivores. The other group is the "robust-jawed" bauplan, represented by species such as "Sericipterus", "Scaphognathus" and "Harpactognathus", which have more robust jaws and teeth (which were ziphont in " Sericipterus"), and shorter, broader wings. These were either terrestrial/aerial predators of vertebrates or corvid-like generalists.

Wukongopterids like "Darwinopterus" were first seen as aerial predators; however, as they lack the robust jaw structure or powerful flying muscles of "Campylognathoides" or the "robust-jawed" rhamphorhynchids, they are now seen as arboreal or semiterrestrial insectivores. "Darwinopterus robustidens", in particular, seems to have been a beetle specialist.

Among pterodactyloids, a greater variation in diet is present. Pteranodontia contained many piscivorous taxa, such as ornithocheirans, boreopterids, pteranodontids and nyctosaurids. Some amount of niche partitioning seems to have been present: ornithocheirans and the later nyctosaurs were likely aerial dip-feeders like today's frigatebirds, while boreopterids were likely freshwater diving animals similar to cormorants or Platanista river dolphins, and pteranodonts were likely pelagic plunge-divers akin to boobies and gannets. The biggest exception among this group are the istiodactylids, which were likely primarily scavengers.

Archaeopterodactyloidea contained many pterosaurs that obtained food in coastal or freshwater habitats. "Germanodactylus" and "Pterodactylus" were likely piscivores, while the Ctenochasmatidae were suspension feeders, their numerous fine teeth to filter small organisms from shallow water. "Pterodaustro" in particular has been noted for its adaptations for flamingo-like filter-feeding. The diet of "Cycnorhamphus", on the other hand, is an enigma - its unusually curved jaws show little indication of one diet over another. Hypothesized prey items include shellfish and jellyfish.

In contrast, Azhdarchoidea mostly contained terrestrial pterosaurs. Tapejarids are considered arboreal omnivores, feeding heavily on vegetation, but possibly also on small insects and vertebrates. Dsungaripterids are traditionally thought of as being specialist molluscivores, using their powerful jaws to crush the shells of molluscs and crustaceans. While this remains the dominant view of dsungaripterid paleobiology today, some have suggested that they were generalistic omnivores eating a variety of hard foods, as dsungaripterids are better adapted to terrestrial movement rather than wading and are found in inland deposits. Thalassodromids were likely terrestrial carnivores. "Thalassodromeus" itself was named after a fishing method known as "skim-feeding", which it (and every other known pterosaur) was physically incapable of. Instead, it seems to have been an unusually predatory pterosaur, pursuing relatively large prey, similar in ecology to phorusrhacids.

Azhdarchids are now well known as being terrestrial predators akin to ground hornbills or some storks, eating any prey item they could swallow whole. Two major exceptions to this are "Hatzegopteryx", which was a robustly built raptorial predator of relatively large prey, including medium-sized dinosaurs; and "Alanqa", which may have been a specialist molluscivore.

Lonchodectids are known to have had bodily proportions similar to those of azhdarchoids, and were probably similarly terrestrial. They are noted for rather unusual dentitions, however, and the possible member "Prejanopterus" possesses a bizarrely curved upper jaw that might indicate some specialized lifestyle.

Pterosaurs are known to have been eaten by theropods. In the 1 July 2004 edition of "Nature", paleontologist Eric Buffetaut discusses an early Cretaceous fossil of three cervical vertebrae of a pterosaur with the broken tooth of a spinosaur, most likely "Irritator", embedded in it. The vertebrae are known not to have been eaten and exposed to digestion, as the joints are still articulated.

Very little is known about pterosaur reproduction, and pterosaur eggs are very rare. The first known pterosaur egg was found in the quarries of Liaoning, the same place that yielded feathered dinosaurs. The egg was squashed flat with no signs of cracking, so evidently the eggs had leathery shells, as in modern lizards. This was supported by the description of an additional pterosaur egg belonging to the genus "Darwinopterus", described in 2011, which also had a leathery shell and, also like modern reptiles but unlike birds, was fairly small compared to the size of the mother. In 2014 five unflattened eggs from the species "Hamipterus tianshanensis" were found in an Early Cretaceous deposit in northwest China. Examination of the shells by scanning electron microscopy showed the presence of a thin calcareous eggshell layer with a membrane underneath. A study of pterosaur eggshell structure and chemistry published in 2007 indicated that it is likely pterosaurs buried their eggs, like modern crocodiles and turtles. Egg-burying would have been beneficial to the early evolution of pterosaurs, as it allows for more weight-reducing adaptations, but this method of reproduction would also have put limits on the variety of environments pterosaurs could live in, and may have disadvantaged them when they began to face ecological competition from birds.

A "Darwinopterus" specimen showcases that at least some pterosaurs had a pair of functional ovaries, as opposed to the single functional ovary in birds, dismissing the reduction of functional ovaries as a requirement for powered flight.

Wing membranes preserved in pterosaur embryos are well developed, suggesting that pterosaurs were ready to fly soon after birth. Fossils of pterosaurs only a few days to a week old (called "flaplings") have been found, representing several pterosaur families, including pterodactylids, rhamphorhinchids, ctenochasmatids and azhdarchids. All preserve bones that show a relatively high degree of hardening ("ossification") for their age, and wing proportions similar to adults. In fact, many pterosaur flaplings have been considered adults and placed in separate species in the past. Additionally, flaplings are normally found in the same sediments as adults and juveniles of the same species, such as the "Pterodactylus" and "Rhamphorhynchus" flaplings found in the Solnhofen limestone of Germany, and "Pterodaustro" flaplings from Brazil. All are found in deep aquatic environment far from shore.

It is not known whether pterosaurs practiced any form of parental care, but their ability to fly as soon as they emerged from the egg and the numerous flaplings found in environments far from nests and alongside adults has led most researchers, including Christopher Bennett and David Unwin, to conclude that the young were dependent on their parents for a relatively short period of time, during a period of rapid growth while the wings grew long enough to fly, and then left the nest to fend for themselves, possibly within days of hatching. Alternatively, they may have used stored yolk products for nourishment during their first few days of life, as in modern reptiles, rather than depend on parents for food.

Growth rates of pterosaurs once they hatched varied across different groups. In more primitive, long-tailed pterosaurs ("rhamphorhynchoids"), such as "Rhamphorhynchus", the average growth rate during the first year of life was 130% to 173%, slightly faster than the growth rate of alligators. Growth in these species slowed after sexual maturity, and it would have taken more than three years for "Rhamphorhynchus" to attain maximum size. In contrast, the more advanced, large pterodactyloid pterosaurs, such as "Pteranodon", grew to adult size within the first year of life. Additionally, pterodactyloids had "determinate growth", meaning that the animals reached a fixed maximum adult size and stopped growing.

Comparisons between the scleral rings of pterosaurs and modern birds and reptiles have been used to infer daily activity patterns of pterosaurs. The pterosaur genera "Pterodactylus", "Scaphognathus", and "Tupuxuara" have been inferred to be diurnal, "Ctenochasma", "Pterodaustro", and "Rhamphorhynchus" have been inferred to be nocturnal, and "Tapejara" has been inferred to be cathemeral, being active throughout the day for short intervals. As a result, the possibly fish-eating "Ctenochasma" and "Rhamphorhynchus" may have had similar activity patterns to modern nocturnal seabirds, and the filter-feeding "Pterodaustro" may have had similar activity patterns to modern anseriform birds that feed at night. The differences between activity patterns of the Solnhofen pterosaurs "Ctenochasma", "Rhamphorhynchus", "Scaphognathus", and "Pterodactylus" may also indicate niche partitioning between these genera.

Because pterosaur anatomy has been so heavily modified for flight, and immediate transitional fossil predecessors have not so far been described, the ancestry of pterosaurs is not fully understood. Several hypotheses have been advanced, including links to the avemetatarsalian-like "Scleromochlus", an ancestry among the basal archosauriforms, like "Euparkeria", or among the protorosaurs.

Two researchers, Chris Bennett (1996) and David Peters (2000), have found pterosaurs to be protorosaurs or closely related to them. Peters used a technique called DGS, which involves applying the digital tracing features of photo editing software to images of pterosaur fossils. Bennett only recovered pterosaurs as close relatives of the protorosaurs after removing characteristics of the hind limb from his analysis, in an attempt to test the idea that these characters are the result of convergent evolution between pterosaurs and dinosaurs. However, subsequent analysis by Dave Hone and Michael Benton (2007) could not reproduce this result. Hone and Benton found pterosaurs to be closely related to dinosaurs even without hind limb characters. They also criticized previous studies by David Peters, raising questions about whether conclusions reached without access to the primary evidence, that is, pterosaur fossils, can be held to have the same weight as conclusions based strictly on first-hand interpretation. Hone and Benton concluded that, although more primitive pterosauromorphs are needed to clarify their relationships, pterosaurs are best considered archosaurs, and specifically ornithodirans, given current evidence. In Hone and Benton's analysis, pterosaurs are either the sister group of "Scleromochlus" or fall between it and "Lagosuchus" on the ornithodiran family tree. Sterling Nesbitt (2011) found strong support for a clade composed of "Scleromochlus" and pterosaurs. More recent studies on basal pterosaur hindlimb morphology seem to vindicate a connection to "Scleromochlus". Like this archosaur, basal pterosaur lineages have plantigrade hindlimbs that show adaptations for saltation.

In phylogenetic taxonomy, the clade Pterosauria has usually been defined as node-based and anchored to several extensively studied taxa as well as those thought to be primitive. One 2003 study defined Pterosauria as "The most recent common ancestor of the Anurognathidae, "Preondactylus" and "Quetzalcoatlus" and all their descendants." However, these types of definition would inevitably leave any related species that are slightly more primitive out of the Pterosauria. To remedy this, a new definition was proposed that would anchor the name not to any particular species but to an anatomical feature, the presence of an enlarged fourth finger that supports a wing membrane. A broader clade, Pterosauromorpha, has been defined as all ornithodirans more closely related to pterosaurs than to dinosaurs.

The internal classification of pterosaurs has historically been difficult, because there were many gaps in the fossil record. Starting from the 21st century, new discoveries are now filling in these gaps and giving a better picture of the evolution of pterosaurs. Traditionally, they were organized into two suborders: the Rhamphorhynchoidea, a "primitive" group of long-tailed pterosaurs, and the Pterodactyloidea, "advanced" pterosaurs with short tails. However, this traditional division has been largely abandoned. Rhamphorhynchoidea is a paraphyletic (unnatural) group, since the pterodactyloids evolved directly from them and not from a common ancestor, so, with the increasing use of cladistics, it has fallen out of favor among most scientists.

The precise relationships between pterosaurs is still unsettled. Many studies of pterosaur relationships in the past have included limited data and were highly contradictory. However, newer studies using larger data sets are beginning to make things clearer. The cladogram (family tree) below follows a phylogenetic analysis presented by Andres & Myers in 2013.

It was once thought that competition with early bird species might have resulted in the extinction of many of the pterosaurs. By the end of the Cretaceous, only large species of pterosaurs are known (but see below). The smaller species were thought to have become extinct, their niche filled by birds. However, pterosaur decline (if actually present) seems unrelated to bird diversity, as ecological overlap between the two groups appears to be minimal. In fact, at least some avian niches were reclaimed by pterosaurs prior to the KT event. At the end of the Cretaceous period, the Cretaceous–Paleogene extinction event, which wiped out all non-avian dinosaurs and most avian dinosaurs as well, and many other animals, seems also to have taken the pterosaurs.

In the early 2010s, several new pterosaur taxa were discovered dating to the Campanian/Maastrichtian, such as the ornithocheirids "Piksi" and "Ornithocheirus", possible pteranodontids and nyctosaurids, several tapejarids and the indeterminate non-azhdarchid "Navajodactylus". Small azhdarchoid pterosaurs were also present in the Campanian. This suggests that late Cretaceous pterosaur faunas were far more diverse than previously thought, possibly not even having declined significantly from the early Cretaceous. However, "Piksi" is no longer considered to be a pterosaur.

Small sized pterosaur species apparently were present in the Csehbánya Formation, indicating a higher diversity of Late Cretaceous pterosaurs than previously accounted for. The recent findings of a small cat-sized adult azhdarchid further indicate that small pterosaurs from the Late Cretaceous might actually have simply been rarely preserved in the fossil record, helped by the fact that there is a strong bias against terrestrial small sized vertebrates such as juvenile dinosaurs, and that their diversity might actually had been much larger than previously thought.

At least some non-pterodactylod pterosaurs survived into the Late Cretaceous, postulating a lazarus taxa situation for late Cretaceous pterosaur faunas.

Pterosaurs have been a staple of popular culture for as long as their cousins the dinosaurs, though they are usually not featured as prominently in films, literature or other art. Additionally, while the depiction of dinosaurs in popular media has changed radically in response to advances in paleontology, a mainly outdated picture of pterosaurs has persisted since the mid 20th century.

While the generic term "pterodactyl" is often used to describe these creatures, the animals depicted frequently represent either "Pteranodon" or "Rhamphorhynchus", or a fictionalized hybrid of the two. Many children's toys and cartoons feature "pterodactyls" with "Pteranodon"-like crests and long, "Rhamphorhynchus"-like tails and teeth, a combination that never existed in nature. However, at least one type of pterosaur "did" have the "Pteranodon"-like crest and teeth—for example, the "Ludodactylus", a name that means "toy finger" for its resemblance to old, inaccurate children's toys. Also, some depictions of pterosaurs incorrectly identify them as "birds", when in real life they were flying reptiles, and birds are actually theropod dinosaurs.

Pterosaurs were used in fiction in Arthur Conan Doyle's 1912 novel "The Lost World", and subsequent 1925 film adaptation. They have been used in a number of films and television programs since, including the 1933 film "King Kong", and 1966's "One Million Years B.C.". In the latter, animator Ray Harryhausen had to add inaccurate bat-like wing fingers to his stop motion models in order to keep the membranes from falling apart, though this particular error was common in art even before the film was made. Pterosaurs were mainly absent from notable film appearances until 2001, with "Jurassic Park III". However, paleontologist Dave Hone has noted that, even after the 40 intervening years, the pterosaurs in this film had not been significantly updated to reflect modern research. Among the errors he noted as persisting from the 1960s to the 2000s, were teeth even in toothless species (the "Jurassic Park III" pterosaurs were intended to be "Pteranodon", which translates as "toothless wing"), nesting behavior that was known to be inaccurate by 2001, and leathery wings, rather than the taut membranes of muscle fiber that was actually present and required for pterosaur flight.

In most media appearances, pterosaurs are most often depicted as piscivores, a behaviour only a few groups actually had in reality. They are also often shown as aerial predators similar to birds of prey, grasping human victims with their taloned feet. No pterosaur species known so far possesses prehensile feet; all known pterosaurs have flat, plantigrade feet with no opposable toes, often poorly muscled and, in the case of pteranodontians, generally proportionally small. However, some pterosaurs might have had raptorial tendencies; "Thalassodromeus" possesses powerful jaws akin to those of phorusrhacids, and "Hatzegopteryx"'s short neck and more powerful jaws have been interpreted as a speciation on larger prey.



</doc>
