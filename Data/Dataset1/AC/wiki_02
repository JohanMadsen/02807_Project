<doc id="24968" url="https://en.wikipedia.org/wiki?curid=24968" title="Peter Stuyvesant">
Peter Stuyvesant

Peter Stuyvesant (English pronunciation /ˈstaɪv.ə.sənt/; in Dutch also "Pieter" and "Petrus" Stuyvesant; (1610–1672) served as the last Dutch director-general of the colony of New Netherland from 1647 until it was ceded provisionally to the English in 1664, after which it was renamed New York. He was a major figure in the early history of New York City and his name has been given to various landmarks and points of interest throughout the city (e.g. Stuyvesant High School, Stuyvesant Town–Peter Cooper Village, Stuyvesant Plaza, Bedford–Stuyvesant neighborhood, etc.).

Stuyvesant's accomplishments as director-general included a great expansion for the settlement of New Amsterdam beyond the southern tip of Manhattan. Among the projects built by Stuyvesant's administration were the protective wall on Wall Street, the canal that became Broad Street, and Broadway. Stuyvesant, himself a member of the Dutch Reformed Church, opposed religious pluralism and came into conflict with Lutherans, Jews, Roman Catholics and Quakers as they attempted to build places of worship in the city and practice their faiths.

Pieter Stuyvesant was born in 1610 in Peperga, Friesland, in the Netherlands, to Balthasar Stuyvesant, a Reformed Calvinist minister, and Margaretha Hardenstein. He grew up in Peperga, Scherpenzeel, and Berlikum.

At the age of 20, Stuyvesant went to the University of Franeker, where he studied languages and philosophy, but several years later he was expelled from the school after he seduced the daughter of his landlord. He was then sent to Amsterdam by his father, where Stuyvesant – now using the Latinized version of his first name, "Petrus", to indicate that he had university schooling – joined the Dutch West India Company. In 1630, the company assigned him to be their commercial agent on a small island just off of Brazil, Fernando de Noronha, and then five years later transferred him to the nearby Brazilian state of Pernambuco. In 1638, he was moved again, this time to the colony of Curaçao, the main Dutch naval base in the West Indies, where, just four years later, at barely 30 years old, he became the acting governor of that colony, as well as Aruba and Bonaire, a position he held until 1644.

In April 1644, he coordinated and led an attack on the island of Saint Martin – which the Spanish had taken from the Dutch, and had almost been recaptured by them in 1625 – with an armada of 12 ships carrying more than a thousand men. He invested the island when the Spanish would not surrender, but was not successful in preventing them from getting supplies from Puerto Rico. A cannonball crushed Stuyvesants's right leg, and it was amputated just below the knee. Still in severe pain, he called off the siege a month later.

Stuyvesant returned to the Netherlands for convalescence, where his right leg was replaced with a wooden peg. Stuyvesant was given the nicknames "Peg Leg Pete" and "Old Silver Nails" because he used a wooden stick studded with silver nails as a prosthesis. The West India Company saw the loss of Stuyvesant's leg as a "Roman" sacrifice, while Stuyvesant himself saw the fact that he did not die from his injury as a sign that God was saving him to do great things. A year later, in May 1645, he was selected by the Company to replace Willem Kieft as Director-General of the New Netherland colony, including New Amsterdam, the site of present-day New York City.

Stuyvesant had to wait for his appointment to be confirmed by the Dutch States-General, and during that time he married Judith Bayard, who was the daughter of a Huguenot minister, and hailed from Breda. Together, they left Amsterdam in December 1646, and, after stopping at Curaçao, arrived in New Amsterdam in August 1647.

Kieft's administration of the colony had left the colony in terrible condition. Only a small number of villages remained after Kieft's wars, and many of the inhabitants had been driven away to return home, leave only 250 to 300 men able to carry arms. Kieft himself had accumulated over 4,000 guilders during his term in office, and had become an alcoholic.

With certainty that putting New Netherland to rights was the work which God had saved him for, Stuyvesant began the task of rebuilding the physical and moral state of the colony, returning it to being the kind of well-run place that the Dutch preferred. He told the people "I shall govern you as a father his children."

In September 1647, Stuyvesant appointed an advisory council of nine men as representatives of the colonists.

In 1648, a conflict started between him and Brant Aertzsz van Slechtenhorst, the commissary of the patroonship Rensselaerwijck, which surrounded Fort Orange (present-day Albany). Stuyvesant claimed he had power over Rensselaerwijck, despite special privileges granted to Kiliaen van Rensselaer in the patroonship regulations of 1629. In 1649, Stuyvesant marched to Fort Orange with a military escort and ordered bordering settlement houses to be razed to permit a better defense of the fort in case of an attack from the Native Americans. When Van Slechtenhorst refused, Stuyvesant sent a group of soldiers to enforce his orders. The controversy that followed resulted in the founding of the new settlement, Beverwijck.

Stuyvesant became involved in a dispute with Theophilus Eaton, the governor of English New Haven Colony, over the border of the two colonies. In September 1650, a meeting of the commissioners on boundaries took place in Hartford, Connecticut, called the Treaty of Hartford, to settle the border between New Amsterdam and the English colonies to the north and east. The border was arranged to the dissatisfaction of the Nine Men, who declared that "the governor had ceded away enough territory to found fifty colonies each fifty miles square." Stuyvesant then threatened to dissolve the council. A new plan of municipal government was arranged in the Netherlands, and the name "New Amsterdam" was officially declared on 2 February 1653. Stuyvesant made a speech for the occasion, saying that his authority would remain undiminished.

Stuyvesant was then ordered to the Netherlands, but the order was soon revoked under pressure from the States of Holland and the city of Amsterdam. Stuyvesant prepared against an attack by ordering the citizens to dig a ditch from the North River to the East River and to erect a fortification.

In 1653, a convention of two deputies from each village in New Netherland demanded reforms, and Stuyvesant commanded that assembly to disperse, saying: "We derive our authority from God and the company, not from a few ignorant subjects."

In the summer of 1655, he sailed down the Delaware River with a fleet of seven vessels and about 700 men and took possession of the colony of New Sweden, which was renamed "New Amstel." In his absence, Pavonia was attacked by Native Americans, during the "Peach War" on September 15, 1655.

In 1657, the directors of the Dutch West India Company wrote to Stuyvesant to tell him that they were not going to be able to send him all the tradesmen that he requested and that he would have to purchase slaves in addition to the tradesmen he would receive.

In 1660, Stuyvesant was quoted as saying that "Nothing is of greater importance than the early instruction of youth." In 1661, New Amsterdam had one grammar school, two free elementary schools, and had licensed 28 schoolmasters.

In 1657, Stuyvesant, who did not tolerate full religious freedom in the colony, and was strongly committed to the supremacy of the Dutch Reformed Church, refused to allow Lutherans the right to organize a church. When he also issued an ordinance forbidding them from worshiping in their own homes, the directors of the Dutch West Indies Company, three of whom were Lutherans, told him to rescind the order and allow private gatherings of Lutherans.

Freedom of religion was further tested when Stuyvesant refused to allow Jewish refugees, from Dutch Brazil, to settle permanently in New Amsterdam (without passports) and join the existing community of Jews (with passports from Amsterdam). Stuyvesant attempted to have Jews "in a friendly way to depart" the colony. As he wrote to the Amsterdam Chamber of the Dutch West India Company in 1654, he hoped that "the deceitful race, — such hateful enemies and blasphemers of the name of Christ, — be not allowed to further infect and trouble this new colony." He referred to Jews as a "repugnant race" and "usurers", and was concerned that "Jewish settlers should not be granted the same liberties enjoyed by Jews in Holland, lest members of other persecuted minority groups, such as Roman Catholics, be attracted to the colony."

Stuyvesant's decision was again rescinded after pressure from the directors of the Company. As a result, Jewish immigrants were allowed to stay in the colony as long as their community was self-supporting, however, Stuyvesant and the company would not allow them to build a synagogue, forcing them to worship instead in a private house.

In 1657, the Quakers, who were newly arrived in the colony, drew his attention. He ordered the public torture of Robert Hodgson, a 23-year-old Quaker convert who had become an influential preacher. Stuyvesant then made an ordinance, punishable by fine and imprisonment, against anyone found guilty of harboring Quakers. That action led to a protest from the citizens of Flushing, which came to be known as the Flushing Remonstrance, considered by some a precursor to the United States Constitution's provision on freedom of religion in the Bill of Rights.

In 1664, King Charles II of England ceded to his brother, the Duke of York, later King James II, a large tract of land that included all of New Netherland. Four English ships bearing 450 men, commanded by Richard Nicolls, seized the Dutch colony. On 30 August 1664, George Cartwright sent the governor a letter demanding surrender. He promised "life, estate, and liberty to all who would submit to the king's authority."

On 6 September 1664, Stuyvesant sent Johannes de Decker, a lawyer for the West India Company, and five others to sign the Articles of Capitulation. Nicolls was declared governor, and the city was renamed New York. Stuyvesant obtained civil rights and freedom of religion in the Articles of Capitulation. The Dutch settlers mainly belonged to the Dutch Reformed church, a Calvinist denomination, holding to the Three Forms of Unity (Belgic Confession, Heidelberg Catechism, Canons of Dordt). The English were Anglicans, holding to the 39 Articles, a Protestant confession, with bishops.

In 1665, Stuyvesant went to the Netherlands to report on his term as governor. On his return to the colony, he spent the remainder of his life on his farm of sixty-two acres outside the city, called the Great Bouwerie, beyond which stretched the woods and swamps of the village of Nieuw Haarlem. A pear tree that he reputedly brought from the Netherlands in 1647 remained at the corner of Thirteenth Street and Third Avenue until 1867 when it was destroyed by a storm, bearing fruit almost to the last. The house was destroyed by fire in 1777. He also built an executive mansion of stone called Whitehall.

In 1645, Stuyvesant married Judith Bayard (–1687) of the Bayard family. Her brother, Samuel Bayard, was the husband of Stuyvesant's sister, Anna Stuyvesant. Petrus and Judith had two sons together.


He died in August 1672 and his body was entombed in the east wall of St. Mark's Church in-the-Bowery, which sits on the site of Stuyvesant’s family chapel.

Stuyvesant and his family were large landowners in the northeastern portion of New Amsterdam, and the Stuyvesant name is currently associated with three places in Manhattan's East Side, near present-day Gramercy Park: the Stuyvesant Town housing complex; Stuyvesant Square, a park in the area; and the Stuyvesant Apartments on East 18th Street. His farm, called the "Bouwerij" – the seventeenth-century Dutch word for "farm" – was the source for the name of the Manhattan street and surrounding neighborhood named "The Bowery". The contemporary neighborhood of Bedford–Stuyvesant, Brooklyn includes Stuyvesant Heights and retains its name. Also named after him are the hamlets of Stuyvesant and Stuyvesant Falls in Columbia County, New York, where descendants of the early Dutch settlers still live and where the Dutch Reformed Church remains an important part of the community, as well as shopping centers, yacht clubs and other buildings and facilities throughout the area where the Dutch colony once was.

A statue of Stuyvesant by J. Massey Rhind situated at Bergen Square in Jersey City was dedicated in 1915 to mark the 250th anniversary of the Dutch settlement there

The last acknowledged direct descendant of Peter Stuyvesant to bear his surname was Augustus van Horne Stuyvesant, Jr., who died a bachelor in 1953 at the age of 83 in his mansion at 2 East 79th Street. Rutherfurd Stuyvesant, the 19th-century New York developer, and his descendants are also descended from Peter Stuyvesant; however, Ruthford Stuyvesant's name was changed from Stuyvesant Rutherford in 1863 to satisfy the terms of the 1847 will of Peter Gerard Stuyvesant.

His descendants include:



Notes
Bibliography



</doc>
<doc id="24969" url="https://en.wikipedia.org/wiki?curid=24969" title="Phish">
Phish

Phish is an American rock band that was founded at the University of Vermont in Burlington, Vermont in 1983. It is known for musical improvisation, extended jams, blending of genres, and a dedicated fan base. The current line-up—guitarist and lead vocalist Trey Anastasio, bassist and vocalist Mike Gordon, drummer and vocalist Jon Fishman, and keyboardist and vocalist Page McConnell—performed together for 15 years before going on hiatus from October 7, 2000, to December 30, 2002. They resumed touring from December 31, 2002, until August 15, 2004, when they announced that the Coventry Festival would be their last show. They reunited in March 2009 for a series of three consecutive concerts played in the Hampton Coliseum in Hampton, Virginia, and have since resumed performing regularly.

Phish's music blends elements of a wide variety of genres, including funk, progressive rock, psychedelic rock, folk, country, jazz, blues, bluegrass, and pop. Although the band has received little radio play or mainstream exposure, Phish has developed a large and dedicated following by word of mouth, the exchange of live recordings, and selling over 8 million albums and DVDs in the United States. "Rolling Stone" stated that the band helped to "...spawn a new wave of bands oriented around group improvisation and extended instrumental grooves".

Phish was formed at the University of Vermont (UVM) in 1983 by guitarists Trey Anastasio and Jeff Holdsworth, bassist Mike Gordon, and drummer Jon Fishman. For their first gig, at Harris Millis Cafeteria at the University of Vermont on December 2, 1983, the band was billed as "Blackwood Convention". ("Blackwood convention" is a term from the card game contract bridge.) The band would collaborate with percussionist Marc Daubert in the fall of 1984, a time during which they promoted themselves as playing Grateful Dead songs. Page McConnell then joined the group on keyboards and made his debut on May 3, 1985, at a show at Wilks/Davis/Wing Dormitory on Redstone Campus at UVM. Holdsworth left the group after graduating in 1986, solidifying the band's lineup of "Trey, Page, Mike, and Fish"—the lineup to this day.

Following a prank at UVM with his friend and former bandmate Steve Pollak—also known as "The Dude of Life"—Anastasio decided to leave the college. With the encouragement of McConnell (who received $50 for each transferee), Anastasio and Fishman relocated in mid-1986 to Goddard College, a small school in the hills of Plainfield, Vermont. Phish distributed at least six different experimental self-titled cassettes during this era, including "The White Tape". This first studio recording was circulated in two variations: the first, mixed in a dorm room as late as 1985, received a higher distribution than the second studio remix of the original four tracks, c. 1987. The older version was officially released under the title "Phish" in August 1998.

Jesse Jarnow's book "" details much of the band's early years at Goddard College, including their early relationship with fellow Goddard students Richard "Nancy" Wright and Jim Pollock. Pollock and Wright were musical collaborators, experimenting with multi-track cassette records to be broadcast on local radio. Phish adopted a number of Nancy's songs into their own set, including "Halley's Comet", "I Didn't Know", and "Dear Mrs. Reagan", the latter song being written by Nancy and Pollock. Jarnow argues that despite an eventual falling out between the members of Phish and Nancy, Nancy and his music were highly influential to Phish's early style and experimental sound. Pollock continued to collaborate with Phish over the years, designing some of their most iconic concert posters.

The band's actions demonstrate an identity with their "hometown" of Burlington, Vermont. By 1985, the group had encountered Burlington luthier Paul Languedoc, who would eventually design four guitars for Anastasio and two basses for Gordon. In October 1986, he began working as their sound engineer. Since then, Languedoc has built exclusively for the two, and his designs and traditional wood choices have given Phish a unique instrumental identity. Also during the late 1980s, Phish played regularly at Nectar's restaurant and bar in Burlington. In 1992 the album "A Picture of Nectar", named as a tribute to the owner, featured a large orange with Nectar's photo superimposed subtly within the orange.

As his senior project, Anastasio penned "The Man Who Stepped into Yesterday", a nine-song concept album that would become Phish's second studio experiment. Recorded between 1987 and 1988, it was submitted in July of that year, accompanied by a written thesis. Elements of the story—known as "Gamehendge"—grew to include an additional eight songs. The band performed the suite in concert on five different occasions: in 1988, 1991, 1993, and twice in 1994 without replicating the song list.

Beginning in the spring of 1988, members of the band began practicing in earnest, sometimes locking themselves in a room and jamming for hours on end. One such jam took place at Anastasio's apartment, with a second at Paul Languedoc's house in August 1989. They called these jam sessions "Oh Kee Pa Ceremonies", saying the name was chosen by Anastasio after seeing the films "A Man Called Horse" and "Modern Primitives," which depict fictional and misappropriated versions of a Mandan Indian ceremony. The product of one of these jam sessions was included in the band's first mass-released recording, a double album called "Junta", later that year.

On January 26, 1989, Phish played the Paradise Rock Club in Boston. The owners of the club had never heard of Phish and refused to book them, so the band rented the club for the night. The show sold out due to the caravan of fans that had traveled to see the band.

By late 1990, Phish's concerts were becoming more and more intricate, often making a consistent effort to involve the audience in the performance. In a special "secret language", the audience would react in a certain manner based on a particular musical cue from the band. For instance, if Anastasio "teased" a motif from "The Simpsons" theme song, the audience would yell, "D'oh!" in imitation of . In 1992, Phish introduced a collaboration between audience and band called the "Big Ball Jam" in which each band member would throw a large beach ball into the audience and play a note each time his ball was hit. In so doing, the audience was helping to create an original composition.

In an experiment known as "The Rotation Jam", each member would switch instruments with the musician on his left. On occasion, a performance of "You Enjoy Myself" involved Gordon and Anastasio performing synchronized maneuvers, jumping on mini-trampolines while simultaneously playing their instruments.

Phish, along with Bob Dylan, the Grateful Dead, and the Beatles, was one of the first bands to have a Usenet newsgroup, rec.music.phish, which launched in 1991. Aware of the band's growing popularity, Elektra Records signed them that year. The following year "A Picture of Nectar" was complete: their first major studio release, enjoying far more extensive production than either 1988's "Junta" or 1990's "Lawn Boy". These albums were eventually re-released on Elektra, as well.

The first annual H.O.R.D.E. festival in 1992 provided Phish with their first national tour of major amphitheaters. The lineup, among others, included Phish, Blues Traveler, the Spin Doctors, and Widespread Panic. That summer, the band toured Europe with the Violent Femmes and later toured Europe and the U.S. with Carlos Santana.

Phish began headlining major amphitheaters in the summer of 1993. That year, the group released "Rift" packaged as a concept album and with heavy promotion from Elektra including artwork by David Welker. In 1994, the band released "Hoist." To promote the album, the band made their only video for MTV, "Down with Disease", airing in June of that year. Foreshadowing their future tradition of festivals, Phish coupled camping with their summer tour finale at Sugarbush North in Warren, Vermont, in July 1994, that show eventually being released as "Live Phish Volume 2". On Halloween of that year, the group promised to don a fan-selected "musical costume" by playing an entire album from another band. After an extensive mail-based poll, Phish performed the Beatles' White Album as the second of their three sets at the Glens Falls Civic Center in upstate New York. For their 1994 New Years Run, Phish played the Civic Centers in Philadelphia and Providence as well as sold-out shows at Madison Square Garden and Boston Garden, which were their debuts at each venue. Following the death of Grateful Dead frontman Jerry Garcia in the summer of 1995 and the appearance of "Down with Disease" on "Beavis and Butt-Head", the band experienced a surge in the growth of their fan base and an increased awareness in popular culture.

In their tradition of playing a well-known album by another band for Halloween, Phish contracted a full horn section for their performance of The Who's "Quadrophenia" in 1995. Their first live album—"A Live One"—which was released during the summer of 1995, became Phish's first RIAA-certified gold album in November 1995.

Phish retreated to their Vermont recording studio and recorded hours and hours of improvisations, sometimes overlaying them on one another, and included some of the result on the second half of "Billy Breathes", which they released in the fall of 1996. Alongside traditional rock-based crescendos, the album has more acoustic guitar than their previous records, and was regarded by the band and some fans as their crowning studio achievement. The album's first single, "Free", peaked at No. 24 on the Billboard Hot Modern Rock Tracks chart and No. 11 on the Mainstream Rock Tracks chart, becoming the band's most successful chart single of their career.

By 1997, their improvisational ventures were developing into a new funk-inspired jamming style. Vermont-based ice cream conglomerate Ben & Jerry's launched "Phish Food" that year, and proceeds from the flavor are donated to the Lake Champlain Initiative. Part of Phish's new non-profit foundation, The WaterWheel Foundation, was also composed of two other now-defunct branches: The Touring Branch and the Vermont Giving Program.

To celebrate the new millennium, Phish hosted a two-day outdoor festival at the Big Cypress Seminole Indian Reservation in Florida. The highlight of this festival began when Phish took the stage at 11:35 p.m. on December 31, 1999, and continued to play until sunrise on January 1, 2000, approximately eight hours later. This concert has been referred to as a peak musical experience by the band.

2000 saw no Halloween show, no summer festival and no new full-band compositions: May's "Farmhouse" contained material dating from 1997 and original material from Anastasio's 1999 solo acoustic/electric club tour. That summer, the band announced that they would take their first "extended time-out" following their upcoming fall tour. During the tour's last concert on October 7, 2000, at the Shoreline Amphitheatre in Mountain View, California, they played a regular show and left without saying a word as The Beatles' "Let It Be" played over the sound system.

Over two years after the hiatus began, Phish announced that they were getting back on the road with a New Year's Eve 2002 concert at Madison Square Garden. They also recorded "Round Room" in only three days. In their return concert, McConnell's brother was introduced as actor Tom Hanks. The impostor sang a line of the song "Wilson", prompting several media outlets to report that the actor had "jammed with Phish".

At the end of the 2003 summer tour, Phish held their first summer festival in four years, returning to Limestone, Maine, for It. The festival drew crowds of over 60,000 fans, once again making Limestone one of the largest cities in Maine for a weekend. In November - December, the band celebrated its 20th anniversary with a four-show mini-tour of shows in New York, Pennsylvania, and Massachusetts.

In order to avoid the exhaustion and pitfalls of previous years' high-paced touring, Phish played sporadically after the reunion, with tours lasting about two weeks. After an April 2004 run of shows in Las Vegas, Anastasio announced on the band's website that the band was breaking up after a small summer tour.

Their final album (at the time), "Undermind", was released in late spring. In the summer of 2004, the band jammed with rapper Jay-Z at one show, shot a video called "Live in Brooklyn" for broadcast in movie theaters, and performed a seven-song set atop the marquee of the Ed Sullivan Theater during the "Late Show with David Letterman" to fans who had gathered on the street, a move reminiscent of The Beatles' final performance on the rooftop of the Apple building in London.

Their final show of 2004—Coventry—was named for the town in Vermont that hosted the event. 100,000 people were expected to attend. After a week of rain that prompted fears of a sinking stage, Gordon announced on local radio that no more cars would be allowed in, though only about 20,000 people had arrived. Many concert-goers parked their vehicles on roadsides and hiked to the site; an estimated 65,000 attended the emotional finale.

Phish received the Jammys Lifetime Achievement Award on May 7, 2008, in The Theater at Madison Square Garden. After performing three songs together at the September 2008 wedding of their former tour-road manager, Phish announced that they would perform three reunion shows on March 6, 7, and 8, 2009, at the Hampton Coliseum in Hampton, Virginia. Following the reunion weekend, the band played thirteen shows of a summer tour, including an inaugural concert at Fenway Park and headlining Bonnaroo 2009 in June with Bruce Springsteen and the E Street Band, Beastie Boys, and Nine Inch Nails. During their first set of the second day, Phish was joined by Springsteen on guitar for "Mustang Sally", "Bobby Jean", and "Glory Days". Twelve additional dates in July and August were announced as a Late Summer Tour, including four nights at Red Rocks, two nights at The Gorge, a stop in Chicago, and several nights in the Northeast.

Phish's fourteenth studio album, "Joy", produced by Steve Lillywhite, was released September 8, 2009. A single from the album, "Time Turns Elastic", was released on iTunes in late May. The band announced a "save-the-date" for a three-day festival on October 30 & 31 and November 1. Phish.com contained an animated map of the United States, and individual states were slowly removed from the map, leaving California. Confirming several rumors, the band announced that "Festival 8" would take place in Indio, California. Footage from Festival 8 was released in April 2010 as a 3D movie titled "Phish 3D". In the late spring and summer of 2010, the band completed a two-legged, 29-show tour. The August Alpine Valley shows have been released as a DVD and CD. Phish made their Hollywood Bowl debut and headlined the Outside Lands Music and Arts Festival in August. They played a show in Essex Junction, Vermont, on September 14, and the more than $1.2 million in proceeds were donated to Vermont flood victim relief in the aftermath of Hurricane Irene.

Phish's next festival, Super Ball IX, took place at the Watkins Glen International in Watkins Glen, New York on July 1–3, 2011. It was the first concert to take place at Watkins Glen International since Summer Jam at Watkins Glen in 1973.

In June 2012, Phish headlined Bonnaroo 2012 with the Red Hot Chili Peppers and Radiohead. Phish also performed for the first time ever a show in Oklahoma at the Zoo Amphitheater in August. For the fourth consecutive year, Phish performed a set of sold-out New Year's shows at New York City's Madison Square Garden, which culminated with a three-set show to ring in 2013. Phish went back on tour in the summer of 2013 to celebrate their 30th-year anniversary, which graced fan favorite venues such as Saratoga Performing Arts Center, PNC Bank Arts Center, The Gorge Amphitheatre, and Merriweather Post Pavilion, while also stopping at new destinations such as Darling's Waterfront Pavilion and FirstMerit Bank Pavilion at Northerly Island in Chicago. The band also announced a fall tour for the first time since 2010, including stops at Hampton Coliseum. The band completed a new album known as "Fuego." Phish debuted 12 potential tracks from their 2014 album, which was introduced as "Wingsuit", the working title of the album, during the second of three sets on October 31, 2013.

On July 1, 2014, Phish embarked on a 25-show tour including stops that wound a path from Massachusetts to the Midwest, and from the Mid-Atlantic to Georgia. For the third consecutive year, Phish played a three-night run of shows at Saratoga Performing Arts Center over the 4th of July holiday. Phish also made their first visit to Randall's Island in New York City. August 2014 ended with three performances at Dick's Sporting Goods Park, firmly establishing the annual Colorado pilgrimage as a Labor Day tradition for Phish fans. This tradition was upheld with three-night runs over the holiday in following years, bringing the total number of shows at this venue (and on the same weekend, to boot) to 18 as of September 4, 2016. The 2014 fall tour included stops in Oregon, Washington, and California, and ended in Las Vegas, Nevada, where Phish once again debuted new music on Halloween. The October 31, 2014, performance at MGM Grand Las Vegas featured a second set consisting of ten original songs inspired by a 1964 novelty record from Walt Disney Studios, "Chilling, Thrilling Sounds of the Haunted House." 2014 ended with a three-set show on New Year's Eve in Miami, Florida, followed by three more nights of performances to ring in 2015.
2015 included a coast-to-coast summer tour, including the aforementioned "Labor Day Run" at Dick's Sporting Goods Park in Colorado. Although there was no fall tour, Phish's 10th festival, Magnaball, was announced at the same time. The band returned to Madison Square Garden for a series of four shows, including a three-set performance on New Year's Eve. Two weeks later, Phish performed their first shows in Mexico as part of a three-night, all-inclusive resort package at Barceló Maya Beach in Riviera Maya. During the final night's performance, the band announced from the stage that they planned to record a new album following the shows in Mexico. According to comments from Fishman, the recording was completed by the following March.

The 2016 summer tour was announced on February 5, 2016, including Phish's first visit to Wrigley Field in Chicago and two headlining sets at the Lockn' Festival. A fall tour in the southeastern U.S. followed, concluding with a four-night run over Halloween in Las Vegas at MGM Grand Arena, where the band played "The Rise and Fall of Ziggy Stardust and the Spiders from Mars" as an homage to David Bowie. Separately, the band played a four-night run at Madison Square Garden for New Year's Eve.

Phish's sixteenth studio album, "Big Boat", was released on October 7, 2016, on JEMP Records.

Phish played a 13-night concert residency at New York City's Madison Square Garden from July 21 to August 6, 2017, each show featuring unique set lists, none of which repeated a single song. Named "The Baker's Dozen" as a tribute to the band's affinity to donuts (the drummer's muumuu also features donuts), these shows brought the band's total performances at the Garden to 52 since they first played there in December 1994. A special donut was served each night to the audience. Later announcing a New Year's Run at Madison Square Garden (which brought their Garden concert total to 56, Phish played 17 concerts at the venue in 2017 and named the announcement "17 in 17".

In 2018, Phish announced a 24-date summer tour with multi-night runs at The Gorge Amphitheatre, Merriweather Post Pavilion, Harveys Lake Tahoe, The Forum in Inglewood, California, and three nights at their 11th festival called Curveball.




The members of Phish have worked on various musical side projects. Anastasio continued the solo career he'd begun in 1998, formed the group Oysterhead, and began conducting an orchestral composition with the Vermont Youth Orchestra. Gordon made an album with acoustic guitar legend Leo Kottke and two films before launching his own solo career. Fishman alternated between the Jazz Mandolin Project and his band Pork Tornado, while McConnell formed the trio Vida Blue.

During their break-up, members of Phish maintained various solo projects. Anastasio continued his solo career with his own band and performed with Oysterhead in June 2006. Gordon played with Leo Kottke and the Benevento/Russo Duo. At Rothbury in 2008, he played with his newest project, Ramble Dove, which is the name of the country outfit he fronted in his directorial feature "Outside Out", and also joined Grateful Dead drummers Mickey Hart and Bill Kreutzmann along with Steve Kimock and Jen Durkin as the Rhythm Devils. Anastasio and Gordon toured as a four-piece with the Benevento/Russo Duo in the summer of 2006. McConnell debuted his new solo project at a festival in September 2006 held by jam band moe. and released his self-titled debut on April 17, 2007. Fishman has performed occasional shows with the Everyone Orchestra, The Village and the Yonder Mountain String Band.

In March 2010, Trey Anastasio was asked to pay tribute to Genesis, one of his favorite bands, at their induction into the Rock and Roll Hall of Fame. In addition to Anastasio's speech, Phish appeared and performed two Genesis songs, "Watcher of the Skies" and "No Reply at All". Genesis did not perform. On May 13, 2010, Phish played the Rolling Stones' "Loving Cup" on "Late Night with Jimmy Fallon". The band was introduced by Keith Richards.

The music of Phish is "oriented around group improvisation and superextended grooves" that draw on a range of rock-oriented influences, including psychedelic rock, funk, reggae, hard rock and various "acoustic" genres, such as folk and bluegrass. Some Phish songs use different vocal approaches, such as a cappella (unaccompanied) sections of barbershop quartet-style vocal harmonies.

Some of their original compositions tend towards a psychedelic rock and bluegrass fusion, with more rock, jazz and funk elements than the Grateful Dead and other earlier jam bands. Their more ambitious, epic compositions (such as "You Enjoy Myself" and "Guyute") are often said to resemble classical music in a rock setting, much like the music of one of their heroes, Frank Zappa.

The driving force behind Phish is the popularity of their concerts and the fan culture surrounding the event. Each a production unto itself, the band is known to consistently change set lists and details, as well as the addition of their own antics to ensure that no two shows are ever the same. With fans flocking to venues hours before they open, the concert is the centerpiece of an event that includes a temporary community in the parking lot, complete with "Shakedown Street": at times a garment district, art district, food court, or pharmacy. For many, one concert is simply a prelude to the next as the community follows the band around the country. Their image and fan devotion could be compared to that of the Grateful Dead.

Because Phish's reputation is so grounded in their live performances, concert recordings are commonly traded commodities. Official soundboard recordings can be purchased through the Live Phish website. Legal field recordings produced by tapers with boom microphones from the audience in compliance with Phish's tape trading policy are frequently traded on any number of music message boards. Although technically not allowed, live videos of Phish shows are also traded by fans and are tolerated as long as they are for non-profit, personal use. Phish fans have been noted for their extensive collections of fan-taped concert recordings; owning recordings of entire tours and years is widespread.

Phish have hosted 10 festivals; the first was The Clifford Ball in Plattsburgh, New York, in 1996; the most recent was Magnaball in 2015. Each festival has attracted upwards of 30,000 fans. Only one festival (Camp Oswego) featured performances by bands other than Phish. Phish will be performing their 11th festival and 3rd event, titled Curveball at The Watkins Glen Racetrack on August 17-19th 2018.

Phish began appearing in video games in 2009. Their song "Wilson" (December 30, 1994 at Madison Square Garden, New York, NY as released on "A Live One"), appeared in "Rock Band"'s Bonnaroo song pack, along with other songs by artists playing at the Bonnaroo Festival that year. A Phish "Live Track Pack" for "Guitar Hero World Tour" became available on June 25, 2009. Recordings of "Sample in a Jar" (December 1, 1994 at Salem Armory, Salem, Oregon), "Down With Disease" (December 1, 1995 at Hersheypark Arena, Hershey, Pennsylvania) and "Chalk Dust Torture" (November 16, 1994, Hill Auditorium, University of Michigan, Ann Arbor, Michigan, as released on "A Live One") have been released, compatible with Xbox 360, PS3, and Wii. On August 19, 2010, it was confirmed that Llama would be a playable song in Rock Band 3, released on October 26, 2010.

Seattle Seahawks fans began mimicking Phish's song "Wilson" by chanting the song's opening line when quarterback Russell Wilson took the field during games. The new tradition started after Anastasio made the suggestion at shows in Seattle. NFL Films made a short documentary on the cultural phenomenon. Tampa Bay Rays catcher Wilson Ramos also uses the song as his walk-up music.

They also have an ice cream flavor named after them, Ben & Jerry's Phish Food, in recognition of their shared Vermont heritage. All of Phish's share of the proceeds from this flavor are donated towards environmental work to restore Lake Champlain.

Phish appeared as themselves in a 2002 episode of "The Simpsons" called "Weekend at Burnsie's".

In 2017, Jon Fishman was elected to his Maine town's board of selectmen. He will fill one of two open board seats on Lincolnville's five-seat board.


</doc>
<doc id="24970" url="https://en.wikipedia.org/wiki?curid=24970" title="PA-RISC">
PA-RISC

PA-RISC is an instruction set architecture (ISA) developed by Hewlett-Packard. As the name implies, it is a reduced instruction set computer (RISC) architecture, where the PA stands for Precision Architecture. The design is also referred to as HP/PA for Hewlett Packard Precision Architecture.

The architecture was introduced on 26 February 1986, when the HP 3000 Series 930 and HP 9000 Model 840 computers were launched featuring the first implementation, the TS1.

PA-RISC has been succeeded by the Itanium (originally IA-64) ISA, jointly developed by HP and Intel. HP stopped selling PA-RISC-based HP 9000 systems at the end of 2008 but supported servers running PA-RISC chips until 2013.

In the late 1980s, HP was building four series of computers, all based on CISC CPUs. One line was the IBM PC compatible Intel i286-based Vectra Series, started in 1986. All others were non-Intel systems. One of them was the HP Series 300 of Motorola 68000-based workstations, another Series 200 line of technical workstations based on a custom silicon on sapphire (SOS) chip design, the SOS based 16-bit HP 3000 classic series, and finally the HP 9000 Series 500 minicomputers, based on their own (16 and 32-bit) FOCUS microprocessor. HP planned to use PA-RISC to move all of their non-PC compatible machines to a single RISC CPU family.

Precision Architecture is the result of what was known inside Hewlett-Packard as the Spectrum program . The first processors were introduced in 1986. It had thirty-two 32-bit integer registers and sixteen 64-bit floating-point registers. The number of floating-point registers was doubled in the 1.1 version to 32 once it became apparent that 16 were inadequate and restricted performance. The architects included Allen Baum, Hans Jeans, Michael J. Mahon, Ruby Bei-Loh Lee, Russel Kao, Steve Muchnick, Terrence C. Miller, David Fotland, and William S. Worley.

The first implementation was the TS1, a central processing unit built from discrete transistor-transistor logic (74F TTL) devices. Later implementations were multi-chip VLSI designs fabricated in NMOS processes (NS1 and NS2) and CMOS (CS1 and PCX).
They were first used in a new series of HP 3000 machines in the late 1980s – the 930 and 950, commonly known at the time as Spectrum systems, the name given to them in the development labs. These machines ran MPE-XL. The HP 9000 machines were soon upgraded with the PA-RISC processor as well, running the HP-UX version of UNIX.

Other operating systems ported to the PA-RISC architecture include Linux, OpenBSD, NetBSD and NeXTSTEP.

An interesting aspect of the PA-RISC line is that most of its generations have no Level 2 cache. Instead large Level 1 caches are used, formerly as separate chips connected by a bus, and now integrated on-chip. Only the PA-7100LC and PA-7300LC had L2 caches. Another innovation of the PA-RISC was the addition of vectorized instructions (SIMD) in the form of MAX, which were first introduced on the PA-7100LC.

Precision RISC Organization, an industry group led by HP, was founded in 1992, to promote the PA-RISC architecture. Members included Convex, Hitachi, Hughes Aircraft, Mitsubishi, NEC, OKI, Prime, Stratus, and Yokogawa. 

The ISA was extended in 1996 to 64 bits, with this revision named PA-RISC 2.0. PA-RISC 2.0 also added fused multiply–add instructions, which help certain floating-point intensive algorithms, and the MAX-2 SIMD extension, which provides instructions for accelerating multimedia applications. The first PA-RISC 2.0 implementation was the PA-8000, which was introduced in January 1996.




</doc>
<doc id="24971" url="https://en.wikipedia.org/wiki?curid=24971" title="Preacher (comics)">
Preacher (comics)

Preacher is an American comic book series published by Vertigo, an imprint of DC Comics. The series was created by writer Garth Ennis and artist Steve Dillon with painted covers by Glenn Fabry.

The series consists of 75 issues in total - 66 regular, monthly issues, five one-shot specials and a four-issue "Preacher: Saint of Killers" limited series. The entire run has been collected in nine trade paperback editions. The final monthly issue, number 66, was published in October 2000.


"Preacher" tells the story of Jesse Custer, a preacher in the small Texas town of Annville. Custer is accidentally possessed by the supernatural creature named Genesis, the infant of the unauthorized, unnatural coupling of an angel and a demon. The incident flattens Custer's church and kills his entire congregation.

Genesis has no sense of individual will, but since it is composed of both pure goodness and pure evil, its power might rival that of God Himself, making Jesse Custer, bonded to Genesis, potentially the most powerful being in the universe.

Driven by a strong sense of right and wrong, Custer journeys across the United States attempting to literally find God, who abandoned Heaven the moment Genesis was born. He also begins to discover the truth about his new powers. They allow him, when he wills it, to command the obedience of those who hear and comprehend his words. He is joined by his old girlfriend Tulip O'Hare, as well as a hard-drinking Irish vampire named Cassidy.

During the course of their journeys, the three encounter enemies and obstacles both sacred and profane, including The Saint of Killers, an invincible, quick-drawing, perfect-aiming, come-lately Angel of Death answering only to "He who sits on the throne"; a disfigured suicide attempt survivor turned rock-star named Arseface; a serial-killer called the 'Reaver-Cleaver'; The Grail, a secret organization controlling the governments of the world and protecting the bloodline of Jesus; Herr Starr, ostensible Allfather of the Grail, a megalomaniac with a penchant for prostitutes, who wishes to use Custer for his own ends; several fallen angels; and Jesse's own redneck 'family' — particularly his nasty Cajun grandmother, her mighty bodyguard Jody, and the 'animal-loving' T.C.

Garth Ennis, feeling "Preacher" would translate perfectly as a film, sold the film rights to Electric Entertainment. Rachel Talalay was hired to direct, with Ennis writing the script. Rupert Harvey and Tom Astor were set as producers. By May 1998, Ennis completed three drafts of the script, based largely on the "Gone to Texas" story arc. The filmmakers found it difficult financing "Preacher" because investors found the idea religiously controversial. Ennis approached Kevin Smith and Scott Mosier to help finance the film under their View Askew Productions banner. Ennis, Smith and Mosier pitched "Preacher" to Bob Weinstein at Miramax Films.

Weinstein was confused by the characterization of Jesse Custer. Miramax also did not want to share the box office gross with Electric Entertainment, ultimately dropping the pitch. By May 2000, Smith and Mosier were still attached to produce with Talalay directing, but Smith did not know the status of "Preacher", feeling it would languish in development hell. By then, Storm Entertainment, a UK-based production company known for their work on independent films, joined the production with Electric Entertainment. In September 2001, the two companies announced "Preacher" had been greenlighted to commence pre-production, with filming to begin in November and Talaly still directing Ennis' script. The production and start dates were pushed back because of financial issues of the $25 million projected budget.

James Marsden was cast in the lead role as Jesse Custer sometime in 2002. He explained, "It was something I never knew anything about, but once I got my hands on the comic books, I was blown away by it." In a March 2004 interview, Marsden said the filmmakers were hoping for filming to start the following August. With the full-length film adaptation eventually abandoned with budgetary concerns, HBO announced in November 2006 that they commissioned Mark Steven Johnson and Howard Deutch to produce a television pilot. Johnson was to write with Deutch directing. Impressed with Johnson's pilot script, HBO had him write the series bible for the first season. Johnson originally planned "to turn each comic book issue into a single episode" on a shot-for-shot basis. "I gave [HBO] the comics, and I said, 'Every issue is an hour'. Garth Ennis said 'You don't have to be so beholden to the comic'. And I'm like, 'No, no, no. It's got to be like the comic'."

Johnson also wanted to make sure that one-shots were included as well. Johnson changed his position, citing new storylines conceived by Ennis. "Well, there would be nothing new to add if we did that, so Garth [Ennis] and I have been creating new stories for the series," he said. "I love the book so much and I was telling Garth that he has to make the stories we are coming up with as comics because I want to see them." By August 2008, new studio executives at HBO decided to abandon the idea, finding it too stylistically dark and religiously controversial. Columbia Pictures then purchased the film rights in October 2008 with Sam Mendes planned to direct. Neal H. Moritz and Jason Netter would have produced the film. The previous scripts written by Ennis would not have been used.

On November 16, 2013, it was announced that AMC would be shooting a pilot for "Preacher". On November 18, 2013, "BleedingCool" confirmed that Seth Rogen and Evan Goldberg had developed the series pilot with Sam Catlin, and that it would be distributed by Sony Pictures Television. On February 7, 2014 it was made public that AMC was officially developing the series to television based on the pilot written by Seth Rogen and Evan Goldberg. Rogen has no plans to co-star in the series. On May 9, 2014, AMC announced that "Preacher" was picked up to series. "Preacher" was slated to premiere mid to late 2015, as announced by Seth Rogen, with the script for the series complete and the pilot ordered by the studio. Comic creators Steve Dillon and Garth Ennis will work on this project as co-executive producer. On April 17, 2015, Seth Rogen tweeted that Dominic Cooper was cast in the role of Jesse Custer, Joseph Gilgun as Cassidy, Ruth Negga as Tulip O'Hare, Ian Colletti as Arseface, and W. Earl Brown as Sheriff Hugo Root. On September 9, 2015, Seth Rogen announced via Twitter that the series ordered to a 10-episode season and was due to premiere in mid-2016. The series premiered on AMC on Sunday, May 22, 2016. In 2017 a second season, with thirteen episodes, aired. In 2018 a third season aired, planned to consist of ten episodes.

Stephen King has said that his comic book series "" was influenced by "Preacher".

The character Yorick from "", has a Zippo lighter with the words "Fuck Communism" engraved, identical to the one owned by Jesse Custer in "Preacher". When asked about it he says it's "from this book I read once... a graphic novel. You know, like a comic book." The phrase originated as a 1963 satirical poster produced by "The Realist" magazine's Paul Krassner. This lighter appears later in the series when Yorick and Agent 355 are being held by Russian agents at gunpoint, who find the lighter and take offense to it. Also, in volume 4 "Safeword", Yorick says "pardners", which is used several times in "Preacher", in lieu of "partners".

IGN declared Preacher the third-greatest Vertigo comic, after "Saga of the Swamp Thing" and "Sandman".

Jesse Custer was ranked the 11th Greatest Comic Book Character by "Empire" magazine. The Saint of Killers was ranked at number 42 on the same list.



</doc>
<doc id="24972" url="https://en.wikipedia.org/wiki?curid=24972" title="Preacher">
Preacher

A preacher is a person who delivers sermons or homilies on religious topics to an assembly of people. Less common are preachers who preach on the street, or those whose message is not necessarily religious, but who preach components such as a moral or social worldview or philosophy.

Preachers are common throughout most cultures. They can take the form of a Christian minister on a Sunday morning, or an Islamic Imam. A Muslim preacher in general is referred to as a "dā‘ī", while one giving sermons on a Friday afternoon is called a "khatib". 

The sermon or homily has been an important part of Christian services since Early Christianity, and remains prominent in both Roman Catholicism and Protestantism. Lay preachers sometimes figure in these traditions of worship, for example the Methodist local preachers, but in general preaching has usually been a function of the clergy. The Dominican Order is officially known as the "Order of Preachers" ("Ordo Praedicatorum" in Latin); friars of this order were trained to publicly preach in vernacular languages, and the order was created by Saint Dominic to preach to the Cathars of southern France in the early thirteenth century. The Franciscans are another important preaching order; Travelling preachers, usually friars, were an important feature of late medieval Catholicism.

In most denominations, modern preaching is kept below about 40 minutes, but historic preachers of all denominations could at times speak for well over an hour, sometimes for two or three hours, and use techniques of rhetoric and theatre that are today somewhat out of fashion in mainline churches. 

In many churches in the United States, the title "Preacher" is synonymous with "pastor" or "minister", and the church's minister is often referred to simply as "our/the preacher" or by name such as "Preacher Smith". However, among some Chinese churches, preacher (Chinese: 傳道) is different from pastor (Chinese: 牧師). A preacher in the Protestant church is one of the younger clergy, but they are not officially recognised as pastors until they can prove their capability of leading the church.





</doc>
<doc id="24973" url="https://en.wikipedia.org/wiki?curid=24973" title="Prime time">
Prime time

The prime time or the peak time is the block of broadcast programming taking place during the middle of the evening for television programming.

The term "prime time" is often defined in terms of a fixed time period – for example (in the United States), from 8:00p.m. to 11:00p.m. (Eastern and Pacific Time) or 7:00p.m. to 10:00p.m. (Central and Mountain Time).

In Bangladeshi Television Channels, the 19:00-to-22:00 time slot is known as Prime Time. Several National Broadcasters like Maasranga Television, Gazi TV, Channel 9, Channel i broadcast their prime time shows from 20.00 to 23.00 after their Primetime news at 19.00. 
During Eid Season, most of the TV Stations broadcast their especially produced shows and World Television Premiers starting from 15.00 to 24.00.
In Ramadan, the broadcasters also air special Religious and Cooking shows starting from 14.00 to 20.00 affecting the primetime hours. Besides, Late Night Talkshows are also aired from 01.00 to 04.00 with Ramadan being exception. Religious shows are also broadcast simultaneously from 01.00 along with Talkshows and News Analysis.

In Chinese television, the 19:00-to-22:00 time slot is known as Golden Time (Traditional Chinese: 黄金時間; Simplified Chinese: 黄金时间; Pinyin: Huángjīn shíjiān). The term also influenced a nickname of a strip of holidays in known as Golden Week.

Prime time usually takes place from 19:00 until 22:00. After that, programs classified as “PG” (Parental Guidance) are allowed to be broadcast. Frontline dramas appear during this time slot in Cantonese, as well as movies in English.

In India, prime time occurs between 20:00 and 22:30. The main news programs are broadcast at 20:30, and the highest-rated television program is preceded by it at 20:00. Usually, programmes during prime time are domestic dramas, foreign drama series (mostly American), movies and entertainment programmes.

Prime time usually takes place from 18:00 to 23:00 WIB, preceded by a daily newscast at 17:00 (although some channels broadcast their daily evening newscasts earlier, usually at 16:00 or 16:30). After prime time, programs classified as Adult, as well as cigarette commercials, are allowed to be broadcast.

Like another Muslim-majority country, there is also a 'midnight prime time' during sahur time in a month of Ramadan. It takes place from 02:00 (or 02:30 in some channels) and ends at the Fajr prayer call, varies between 04:30 and 05:00. The time slot is usually filled with comedy and religious programming.

In Iraq, prime time runs from 20:00 to 23:00. The main news programs are broadcast at 20:00 and the highest-rated television program airs at 21:00.

In Japanese television, the 19:00-to-22:00 time slot is also known as . The term also influenced a nickname of a strip of holidays in known as Golden Week.

Malaysian prime time starts with the main news from 20:00 to 20:30 (now 20:00 to 21:00) and ends either at 23:00 or 0:30, or possibly later. Usually, programmes during prime time are domestic dramas, foreign drama series (mostly American), films and entertainment programmes. Programmes classified as 18 are not allowed to be broadcast before 10:00 p.m. but on RTM, most programmes on this slot are rated U (U means "Umum" in Malay and literally General Viewing or General Audiences in English) throughout the whole day. However, programmes broadcast after 23:00 are still considered prime time. As of December 2010, NTV7's prime time continues until 12:00 a.m. Programmes during prime time may have longer commercial breaks due to number of viewers.

Some domestic prime time productions may be affected because of certain major sporting events such as FIFA World Cup. However, only FIFA World Cup in the Americas did not affect the domestic prime time programmes.

In the Philippines, prime time blocks begin at 18:00 (now 17:50 or 17:00) and run until about 23:00 (or 23:30) on weekdays, and 19:00 to 23:00 on weekends. The weekday prime time blocks usually consists of local teleseryes (soap operas) and foreign television series. The network's highest-rated programs are usually aired right after the evening newscast at 20:00, while a foreign series usually precedes the late night newscast.

On weekends, non-scripted programming such as talent shows, reality shows and current affairs shows air in prime time. For the minor networks, prime time consists of American television series on weekdays, with encores of those shows on weekends. Prime time originally started earlier at around 19:00, but the evening newscasts were lengthened to 90 minutes and now start at 18:30, instead of the original one-hour newscast that starts at 18:00.

In Singapore, prime time begins at 18:30 on MediaCorp Channel 8 and 19:00 on MediaCorp Channel 5, MediaCorp Channel U, Channel NewsAsia, MediaCorp Suria, MediaCorp Vasantham and MediaCorp Okto. which are also the main (Free-to-air) television channels in Singapore.

On Channel 8, prime time ends at 24:00 or 0:15 on weekdays, at 0:30 on Saturday nights and at 23:30 on Sunday nights. On Channel 5, prime time ends at 0:00 on weekdays, at 1:30 (or later) on Saturday nights and at 0:30 on Sunday nights. On Suria, prime time ends at 23:30 on Monday to Thursday nights and at 23:00 on Friday to Sunday nights. On Vasantham, prime time ends at 23:00 on Mondays to Thursdays and at 24:00 (or later) on Fridays to Sundays. On Channel NewsAsia, prime time ends at 23:01, immediately after the news headlines, seven days a week. On Channel U, prime time ends at 23:00 seven days a week and on Okto, prime time ends at closedown at 24:00 or later. Generally, however, prime time is considered to be from 18:30 to 00:00.

In South Korea, prime time usually runs from 20:00 to 23:00 during the week, while on Saturdays and Sundays, it runs from 18:00 to 23:00. Family-oriented television shows are broadcast before 22:00, and adult-oriented television shows air after 22:00.

In Taiwan, prime time (called "bādiǎn dàng" - - in Mandarin Chinese) starts at 20:00 in the evening. Taiwanese drama series played then are called 8 o'clock series and are expected to have high viewer ratings.

In Thailand, prime time dramas (ละคร; la-korn) air from 20:30 to 22:30. Most dramas are soap operas. Prime time dramas are popular and influential to Thai society.

In Vietnam Prime time is also known as Golden Time (Tiếng Việt: Giờ vàng), prime time starts at 20:00 in the evening and ends at 23:00.

In Bosnia and Herzegovina, prime time starts at 20.00 and finishes at 22.00. It is preceded by a daily newscast ("Dnevnik") at 19.00 and followed by a late night newscast ("Vijesti") at 22.00.

In Croatia, prime time starts between 20.00 and 20.15. Croatian public broadcaster HRT broadcasts a daily newscast from 19.00 to 20.00. Also, many private broadcasters have daily newscasts either before or after the HTY newscast, at around 20.05, followed by the start of their own prime time. Many broadcasters without daily newscasts start their prime time at 20.00. Prime time generally ends between 22.00 and 23.00, followed by the late night edition of the network newscast and adult-oriented programming.

In Denmark, prime time starts at 20.00.

In Finland, prime time starts at 21.00. It is preceded by a daily newscast at 20.30.

In France prime time runs from 21.00 (after the main channels' evening news programmes) until around 22.30.

In Georgia, prime time starts between 18.45 and 20.00 and generallly ends at 24.00. However, on Friday night / Saturday morning prime time usually continues until 1.00.

At 20.00 each evening Das Erste (The First), Germany's oldest public television network, airs the country's most-watched news broadcast, the main edition of the "Tagesschau" – which is also simulcast on most of its other specialist and regional channels (The Third). The conclusion of the bulletin 15 minutes later marks the beginning of prime time, as it has since the 1950s. In consequence, most channels also choose to start their prime time at 20.15. In the 1990s, the commercial channel Sat.1 suffered a significant loss of audience share when it tried moving the start of its prime time to 20.00.

In Greece, prime time runs from 21.00 (usually following the news) to 24.00.

In Hungary, prime time on weekdays on the two big commercial stations (RTL Klub and TV2) starts at 19.00 with game shows, tabloid and docu-reality programmes. At 21.00, two popular soap operas air: "Barátok közt" and "Jóban Rosszban", which follows at 21.30. American and other series, movies, talk-shows and magazines run until 23.30. The prime-time lineup is preceded by daily news programmes at 18.30. At weekends prime time begins at 19.00, with blockbuster movies and television shows.

Before 15 March 2015, the public television station M1 began its prime time with a game show at 18.30, which was followed by the daily news programme "Híradó" at 19.30. After the news, the channel broadcast American and other series, talk shows, magazines, and news programmes until 22.00, after which came the daily news magazine "Este" and the late edition of "Híradó".

From 15 March 2015, Duna began broadcasting all of the entertainment programming transferred to it from that date from M1, meaning that prime time on Duna now begins at 18.00, starting with the simulcast of the 18.00 edition of Híradó from the newly re-launched news channel, M1.

In Iceland, prime time starts at 19:30. It is preceded by a daily newscast at 19:00.

In Italy, prime time (called "prima serata") is from 21:00 to 23:30. It usually follows news and, on some networks (like Rai 1 and Canale 5), a slot called “access prime time”. Shows, movies, and sport events are usually shown during prime time.

Much like in Germany, prime time in the Netherlands usually begins at 20:30 in order to not compete with NOS's flagship 20:00 newscast.

In Norway, prime time starts at 19:45. On the NRK1 channel it is preceded by the daily newscast "Dagsrevyen" at 19:00. Locally, prime time is called (lit. "best time for broadcasting").

In Poland, prime time starts around 20:00 (sometimes 20:30). On (TVP 1) It is preceded by a daily newscast at 19:30, on (TVN) the newscast is aired at 19:00 followed by the newsmagazine Uwaga at 19:50 (weekdays)/19:45 (weekends) and then the soap Na Wspólnej at 20:05 (Monday to Thursday, from Friday to Sunday (at 20:00) various: movies on Friday, show or movies (Winter and Summer) at Saturday, and programme or movies (Winter and Summer) at Sunday), on (Polsat) the news is aired at 18:50, followed by a sitcom Świat według Kiepskich at 19:30.

In Russia television prime time is between 19:00 and 23:00 on working days and from 15:00 to 01:00 on holidays.
On radio stations there are morning, day and evening prime times. The most common division:
morning — 6:30 to 10:00;
day — с 12:00 to 14:00;
evening - 16:00 to 21:00.

Public television in Slovakia consists of two channels; on the main channel (Jednotka) prime time starts at 20:10, and on the second one (Dvojka) prime time programming starts at 20:00. The two biggest private broadcasters set the start of prime time programming at 20:20 (Markíza) and 20:30 (JOJ). Generally, however, prime time is considered to be from 20:00 to 23:00.

In Slovenia, prime time, the period in which the most-watched shows are broadcast, is from 8:00pm to 11:00pm. It is preceded by daily newscasts; Dnevnik RTV SLO (7:00pm–8:00pm) on TV SLO 1, 24ur (6:55pm–8:00pm) on POP TV, Svet na Kanalu A (6:00pm–7:00pm; 7:50pm–8:0pm), and Danes (7:30pm–8:00pm) on Planet TV.

In Spain, prime time refers to the time period in which the most-watched shows are broadcast. Prime time in Spain starts quite late when compared to most nations as it runs from 22:30 till 01:00. Most news programmes in Spain air at 21:00 for an hour and prime time follows. However, due to fierce competition, especially among the private stations prime time has even been delayed until 23:00. Most channels are delaying prime time in order to protect their top shows from sporting events.

In the 1990s, prime time in Spain began at 21:00, moving to 21:30 in the latter half of the 1990s and 22:00 in the early 2000s. Commercial broadcaster laSexta and the second channel from the Public broadcasting La 2 have attempted to shift prime time back to 21:30 in 2006 and Spring 2007, but these attempts have been unsuccessful. Fellow public channel La 1 also tried to pull prime time back to 21:00 in early 2015, to no avail.

The lateness in the start of prime time in Spain is also due to Spanish culture. Spanish people generally work from 09:00-14:00 and then from 17:00-20:00 as opposed to the standard 09:00-17:00. The popular late night show "Crónicas Marcianas" during the late 1990s–2000 also helped to extend prime time well into the early hours with the show being watched by a share of 40%, despite finishing at 02:00.

Spain might also be unique in that it has a second prime time, running from 14:30-17:00 which coincides with the extended Spanish lunch break. Shows airing in the secondary prime time period on many occasions beat those prime time shows at night on a daily basis. The second prime time only occurs on weekdays, though and the slot is usually filled with The Simpsons, news, soap operas and talk shows.

In Sweden, prime time starts at 20:00. It is preceded by a daily newscast at 19:30 and local news at 19:50.

In the UK, the term used is peak time, early peak is 17:30 to 20:00 and late peak is 20:00 to 23:00.

In a great part of Latin American countries, prime time is considered to be from 6:00 or 7:00 p.m. to 10:00 or 11:00 p.m. The time slot is usually used for news, telenovelas and television series, and special time slots are used for reality shows, with great popularity, especially in Mexico and Brazil. In Mexico, Prime Time is known as "horario estelar" ("Stellar Time"). In Brazil, it is called "horário nobre" (“noble time”), which is the time the three most famous telenovelas in the country are shown each weekday and on Saturdays. There are also news programs, reality shows, and sitcoms.

In Argentina, prime time is considered to be from 8.00 p.m. until 12.00 a.m.; with the most successful series and telenovelas in the country (such as "Los Roldán" and "Valientes"), and entertainment shows, like CQC (Caiga Quien Caiga).

In Chile, prime time is considered to be from 10.30 p.m. until 01.00 a.m.; with the most successful series and telenovelas in the country (such as "Socias" and "Las Vega's"). Investigation entertainment shows (like "Informe Especial", "Contacto", "Apuesto por tí") also air.

In North America, television networks feed their prime time programming in two blocks: one for the Eastern, Central, and Mountain time zones, and one for the Pacific, Alaskan, and Hawaiian time zones, to their local network affiliates. In Atlantic Canada (including Newfoundland) as well as Alaska and Hawaii, there is no change in the interpretation or usage of “prime time” as the concept is not attached to time zones in any way. Affiliates in the Mountain, Alaskan, and Hawaii-Aleutian zones are either on their own to delay broadcast by an hour or two, or collectively form a small, regional network feed with others in the same time zone.

Prime time is commonly defined as 8:00-11:00 p.m. Eastern/Pacific and 7:00-10:00 p.m. Central/Mountain. On Sundays, the major broadcast television networks traditionally begin their primetime programming at 7:00 p.m. (Eastern/Pacific, 6:00 p.m. Central/Mountain) instead. Some networks such as Fox, The CW, and MyNetworkTV only broadcast from 8:00-10:00 p.m., a time period known as "common prime". Most networks air primetime programming nightly, but the smaller CW and MyNetworkTV only broadcast prime time programs on weekdays, leaving weekends to their affiliates. In Canada, CTV and Global both follow the same model as the larger US networks, while City and CTV Two follow a hybrid model of airing new programming only between 8 and 10 p.m. on weeknights, but acting like one of the larger US networks on weekends. The public CBC Television uses the 10 p.m. block on weeknights and Sundays for its nightly news program "The National", but otherwise programs on the same model as the major US television networks.

The major networks have come to consider Saturday prime time as a graveyard slot, and have largely abandoned scheduling of new scripted programming on that night. The major networks still maintain a prime time programming schedule on Saturdays; while live sporting events (most commonly college football in the United States and ice hockey in Canada) are generally preferred to fill the time slot, they typically air encores of programs aired earlier in the week, films, non-scripted reality programs and, occasionally, burned off episodes of low-rated or cancelled series.

Prime time can be extended or truncated if coverage of sporting events run past their allotted end time. Since the "Heidi Game" incident in 1968, in which NBC cut away from coverage of a New York Jets/Oakland Raiders football game on the east coast in order to show a movie (and, in the process, causing viewers to miss an unexpected comeback by the Raiders to win the game), the later National Football League mandated that all games be broadcast in their entirety in the markets of the teams involved. Due to this rule, game telecasts may sometimes overrun into the 7:00 p.m. ET hour. Fox previously scheduled repeats of its animated series in the 7:00 hour, allowing themselves to simply pre-empt the reruns if a game ran long. This was later replaced by a half-hour-long wrap-up show, "The OT". In contrast, CBS does not, as its weekly newsmagazine "60 Minutes" has traditionally aired as close to 7:00 p.m. ET as possible. Even if a game runs past that hour, CBS shows "60 Minutes" in its entirety after the conclusion of coverage, and the rest of the prime time schedule on the East Coast is shifted to compensate. For example, if game coverage were to end at 7:30 p.m., prime time would end at 11:30 p.m.

However, in the rare case where the NFL game runs excessively late (8 p.m. or later), the series scheduled to air at 10 p.m. is preempted, with the West Coast usually receiving a repeat of the 10 p.m. series instead. In an extreme case, CBS's prime time can be extended past midnight during broadcasts of the NCAA Division I Men's Basketball Tournament. This does not necessarily apply universally; in 2001, after an XFL game went into double overtime, causing a 45-minute delay of a highly promoted episode of "Saturday Night Live", NBC made a decision to cut off all future XFL broadcasts at 11:00 p.m. ET. NBC backed out of the XFL after the end of that season, leading to its failure. NBC similarly bumps National Hockey League broadcasts that run long to its cable network NBCSN in the event of a schedule conflict.

Until the U.S. Federal Communications Commission (FCC) regulated time slots prior to prime time with the now-defunct Prime Time Access Rule in 1971–1972, networks began programming at 7:30 p.m. Eastern and Pacific/6:30 p.m. Central and Mountain on weeknights (that is, the 1970–1971 season was the last season in which the networks began prime time at 7:30). The change helped instigate what is colloquially known as the ”rural purge”, in which rural-themed and older-skewing programs were disproportionately canceled. In the 1987-1988 season, NBC-owned stations in several cities experimented with airing a schedule of syndicated first-run sitcoms at 7:30/6:30 p.m. (known as ) to compete against syndicated reruns or game shows such as "Wheel of Fortune" on rival stations.

The vast majority of prime time programming in English-speaking North America comes from the United States, with only a limited amount produced in Canada. The Canadian Radio-television and Telecommunications Commission mandates quotas for Canadian content in prime time; these quotas indicate at least half of Canadian prime time programs must be Canadian in origin, but the majority of this is served by national and local news or localized entertainment gossip shows such as Global's "ET Canada" and CTV's "eTalk".

Likewise, the vast majority of Spanish-language programming in North America comes from Mexico. Televisa, a Mexican network, provides the majority of programming to the dominant U.S.-based Spanish broadcaster, Univision. Univision does produce a fairly large amount of unscripted Spanish-language programming, the best known being the long-running variety show "Sábado Gigante", hosted and created by Chilean national Don Francisco. Univision's distant second-place competitor, Telemundo, produces a much greater share of in-house content, including a long line of telenovelas.

In Quebec, the largest Francophone area of North America, French-language programming consists of originally produced programs (most of which are produced in Montreal, with a few produced in Quebec City) and a few French-language dubs of English language programs. On all of the Quebec networks, entertainment programming is scheduled only between 8 and 10 p.m., with the 10-11 p.m. hour given over to a network newscast or a nightly talk show.

Prime time is the daypart (a block of a day's programming schedule) with the most viewers and is generally where television networks and local stations reap much of their advertising revenues. In recent years television advertising expenditure in the US has been highest during prime-time drama shows.

The Nielsen ratings system is explicitly designed for the optimum measurement of audience viewership by dayparts with prime time being of most interest. Most people tend to watch television at prime time, as most often, based on standard working time, the end of the work day coincides with prime time viewing hours. Most viewers sit down to watch TV after dinner. This is usually the main reason for the high ratings for television programming at this time, as well as the attraction of the timeslot for advertisers.

The existence of prime time in the United States is largely an artifact of now repealed regulations of the Federal Communications Commission, which limited the number of hours that a network can require its affiliates to broadcast.

Additionally, networks may also choose to provide local affiliates the opportunity to air sporting events or other special events which may fall outside of standard designated network broadcast times. Prime time for radio is called “Drive time” and, in Eastern and Pacific Time, is 6–10 a.m. and 3–7 p.m. and, for Mountain and Central Time, is 5–9 a.m. and 2–6 p.m.

A survey by Nielsen revealed that viewers watched almost two hours worth of TV during prime time.

Prime time in Australia is officially from 6:00 p.m. to midnight, following Australian Eastern Standard Time, with the highest ratings normally achieved between 6:00 p.m. to 9:00 p.m.

Traditionally, prime time in New Zealand is considered to be 7:30pm to 10:30pm, but can be extended to cover the entire evening of television (5:30pm to 11:00pm).



</doc>
<doc id="24974" url="https://en.wikipedia.org/wiki?curid=24974" title="Pelton wheel">
Pelton wheel

The Pelton wheel is an impulse-type water turbine. It was invented by Lester Allan Pelton in the 1870s. The Pelton wheel extracts energy from the impulse of moving water, as opposed to water's dead weight like the traditional overshot water wheel. Many variations of impulse turbines existed prior to Pelton's design, but they were less efficient than Pelton's design. Water leaving those wheels typically still had high speed, carrying away much of the dynamic energy brought to the wheels. Pelton's paddle geometry was designed so that when the rim ran at half the speed of the water jet, the water left the wheel with very little speed; thus his design extracted almost all of the water's impulse energywhich allowed for a very efficient turbine.

Lester Allan Pelton was born in Vermillion, Ohio in 1829. In 1850, he travelled overland to California, to take part in the Gold Rush. Pelton worked by selling fish he caught in the Sacramento River. In 1860, he moved to Camptonville, a center of placer mining activity. At this time many mining operations were powered by steam engines which consumed vast amounts of wood as their fuel. Some water wheels were used in the larger rivers, but they were ineffective in the smaller streams that were found near the mines. Pelton worked on a design for a water wheel that would work with the relatively small flow found in these streams.

By the mid 1870's, Pelton had developed a wooden prototype of his new wheel. In 1876, approached the Miners Foundry in Nevada City to build the first commercial models in iron. The first Pelton Wheel was installed at the Mayflower Mine in Nevada City in 1878.. The efficiency advantages of Pelton's invention were quickly recognized and his product was soon in high demand. By the mid-1880s, the Miners Foundry could not meet the demand, and in 1888, Pelton sold the rights to his name and the patents to his invention to the Pelton Water Wheel Company in San Francisco. The company established a factory at 121/123 Main Street in San Francisco.

The Pelton Water Wheel Company manufactured a large number of Pelton Wheels in San Francisco which were shipped around the world. In1892, the Company added a branch on the east coast at 143 Liberty Street in New York City. By 1900, over 11,000 turbines were in use. In 1914, the company moved manufacturing to new, larger premises at 612 Alabama Street in San Francisco. In 1956, the company was acquired by the Baldwin-Lima-Hamilton Company, which ended manufacture of Pelton Wheels.

Nozzles direct forceful, high-speed streams of water against a series of spoon-shaped buckets, also known as impulse blades, which are mounted around the outer rim of a drive wheelalso called a runner (see photo, 'Old Pelton wheel..'). As the water jet hits the blades, the direction of water velocity is changed to follow the contours of the blades. The impulse energy of the water jet exerts torque on the bucket-and-wheel system, spinning the wheel; the water jet does a "u-turn" and exits at the outer sides of the bucket, decelerated to a low velocity. In the process, the water jet's momentum is transferred to the wheel and hence to a turbine. Thus, "impulse" energy does work on the turbine. Maximum power and efficiency are achieved when the velocity of the water jet is twice the velocity of the rotating buckets. A very small percentage of the water jet's original kinetic energy will remain in the water, which causes the bucket to be emptied at the same rate it is filled, (see conservation of mass) and thereby allows the high-pressure input flow to continue uninterrupted and without waste of energy. Typically two buckets are mounted side-by-side on the wheel, with the water jet split into two equal streams; this balances the side-load forces on the wheel and helps to ensure smooth, efficient transfer of momentum from the water jet to the turbine wheel.

Because water is nearly incompressible, almost all of the available energy is extracted in the first stage of the hydraulic turbine. Therefore, Pelton wheels have only one turbine stage, unlike gas turbines that operate with compressible fluid.

Pelton wheels are the preferred turbine for hydro-power where the available water source has relatively high hydraulic head at low flow rates. Pelton wheels are made in all sizes. There exist multi-ton Pelton wheels mounted on vertical oil pad bearings in hydroelectric plants. The largest units - the Bieudron Hydroelectric Power Station at the Grande Dixence Dam complex in Switzerland - are over 400 megawatts . The smallest Pelton wheels are only a few inches across, and can be used to tap power from mountain streams having flows of a few gallons per minute. Some of these systems use household plumbing fixtures for water delivery. These small units are recommended for use with or more of head, in order to generate significant power levels. Depending on water flow and design, Pelton wheels operate best with heads from , although there is no theoretical limit.

The specific speed formula_1 parameter is independent of a particular turbine's size.

Compared to other turbine designs, the relatively low specific speed of the Pelton wheel, implies that the geometry is inherently a "low gear" design. Thus it is most suitable to being fed by a hydro source with a low ratio of flow to pressure, (meaning relatively low flow and/or relatively high pressure).

The specific speed is the main criterion for matching a specific hydro-electric site with the optimal turbine type. It also allows a new turbine design to be scaled from an existing design of known performance.

formula_2 (dimensioned parameter), 

where:

The formula implies that the Pelton turbine is "geared" most suitably for applications with relatively high hydraulic head "H", due to the 5/4 exponent being greater than unity, and given the characteristically low specific speed of the Pelton.

In the ideal (frictionless) case, all of the hydraulic potential energy ("E" = "mgh") is converted into kinetic energy ("E" = "mv"/2) (see Bernoulli's principle). Equating these two equations and solving for the initial jet velocity ("V") indicates that the theoretical (maximum) jet velocity is "V" = . For simplicity, assume that all of the velocity vectors are parallel to each other. Defining the velocity of the wheel runner as: ("u"), then as the jet approaches the runner, the initial jet velocity relative to the runner is: ("V" − "u").
The initial velocity of jet is "V"

Assuming that the jet velocity is higher than the runner velocity, if the water is not to become backed-up in runner, then due to conservation of mass, the mass entering the runner must equal the mass leaving the runner. The fluid is assumed to be incompressible (an accurate assumption for most liquids). Also it is assumed that the cross-sectional area of the jet is constant. The jet "speed" remains constant relative to the runner. So as the jet recedes from the runner, the jet velocity relative to the runner is: −("V" − "u") = −"V" + "u". In the standard reference frame (relative to the earth), the final velocity is then: "V" = (−"V" + u) + "u" = −"V" + 2"u".

We know that the ideal runner speed will cause all of the kinetic energy in the jet to be transferred to the wheel. In this case the final jet velocity must be zero. If we let −"V" + 2"u" = 0, then the optimal runner speed will be "u" = "V" /2, or half the initial jet velocity.

By Newton's second and third laws, the force "F" imposed by the jet on the runner is equal but opposite to the rate of momentum change of the fluid, so
where "ρ" is the density, and "Q" is the volume rate of flow of fluid. If "D" is the wheel diameter, the torque on the runner is
The torque is maximal when the runner is stopped (i.e. when "u" = 0, "T" = "ρQDV"). When the speed of the runner is equal to the initial jet velocity, the torque is zero (i.e. when "u" = "V", then "T" = 0). On a plot of torque versus runner speed, the torque curve is straight between these two points: (0, "pQDV") and ("V", 0).
Nozzle efficiency is the ratio of the jet power to the water power at the base of nozzle

The power "P" = "Fu" = "Tω", where "ω" is the angular velocity of the wheel. Substituting for "F", we have "P" = 2"ρQ"("V" − "u")"u". To find the runner speed at maximum power, take the derivative of "P" with respect to "u" and set it equal to zero, ["dP"/"du" = 2"ρQ"("V" − 2"u")]. Maximum power occurs when "u" = "V" /2. "P" = "ρQV"/2. Substituting the initial jet power "V" = , this simplifies to "P" = "ρghQ". This quantity exactly equals the kinetic power of the jet, so in this ideal case, the efficiency is 100%, since all the energy in the jet is converted to shaft output.

A wheel power divided by the initial jet power, is the turbine efficiency, "η" = 4"u"("V" − "u")/"V". It is zero for "u" = 0 and for "u" = "V". As the equations indicate, when a real Pelton wheel is working close to maximum efficiency, the fluid flows off the wheel with very little residual velocity. In theory, the energy efficiency varies only with the efficiency of the nozzle and wheel, and does not vary with hydraulic head.
The term "efficiency" can refer to: Hydraulic, Mechanical, Volumetric, Wheel, or overall efficiency.

The conduit bringing high-pressure water to the impulse wheel is called the penstock. Originally the penstock was the name of the valve, but the term has been extended to include all of the fluid supply hydraulics. Penstock is now used as a general term for a water passage and control that is under pressure, whether it supplies an impulse turbine or not.




</doc>
<doc id="24975" url="https://en.wikipedia.org/wiki?curid=24975" title="Piezoelectricity">
Piezoelectricity

Piezoelectricity is the electric charge that accumulates in certain solid materials (such as crystals, certain ceramics, and biological matter such as bone, DNA and various proteins) in response to applied mechanical stress. The word "piezoelectricity" means electricity resulting from pressure and latent heat. It is derived from the Greek "piezein", which means to squeeze or press, and "ēlektron", which means amber, an ancient source of electric charge. French physicists Jacques and Pierre Curie discovered piezoelectricity in 1880.

The piezoelectric effect results from the linear electromechanical interaction between the mechanical and electrical states in crystalline materials with no inversion symmetry. The piezoelectric effect is a reversible process: materials exhibiting the piezoelectric effect (the internal generation of electrical charge resulting from an applied mechanical force) also exhibit the reverse piezoelectric effect, the internal generation of a mechanical strain resulting from an applied electrical field. For example, lead zirconate titanate crystals will generate measurable piezoelectricity when their static structure is deformed by about 0.1% of the original dimension. Conversely, those same crystals will change about 0.1% of their static dimension when an external electric field is applied to the material. The inverse piezoelectric effect is used in the production of ultrasonic sound waves.

Piezoelectricity is exploited in a number of useful applications, such as the production and detection of sound, piezoelectric inkjet printing, generation of high voltages, electronic frequency generation, microbalances, to drive an ultrasonic nozzle, and ultrafine focusing of optical assemblies. It forms the basis for a number of scientific instrumental techniques with atomic resolution, the scanning probe microscopies, such as STM, AFM, MTA, and SNOM. It also finds everyday uses such as acting as the ignition source for cigarette lighters, and push-start propane barbecues, as well as being used as the time reference source in quartz watches.

The pyroelectric effect, by which a material generates an electric potential in response to a temperature change, was studied by Carl Linnaeus and Franz Aepinus in the mid-18th century. Drawing on this knowledge, both René Just Haüy and Antoine César Becquerel posited a relationship between mechanical stress and electric charge; however, experiments by both proved inconclusive.

The first demonstration of the direct piezoelectric effect was in 1880 by the brothers Pierre Curie and Jacques Curie. They combined their knowledge of pyroelectricity with their understanding of the underlying crystal structures that gave rise to pyroelectricity to predict crystal behavior, and demonstrated the effect using crystals of tourmaline, quartz, topaz, cane sugar, and Rochelle salt (sodium potassium tartrate tetrahydrate). Quartz and Rochelle salt exhibited the most piezoelectricity.

The Curies, however, did not predict the converse piezoelectric effect. The converse effect was mathematically deduced from fundamental thermodynamic principles by Gabriel Lippmann in 1881. The Curies immediately confirmed the existence of the converse effect, and went on to obtain quantitative proof of the complete reversibility of electro-elasto-mechanical deformations in piezoelectric crystals.

For the next few decades, piezoelectricity remained something of a laboratory curiosity. More work was done to explore and define the crystal structures that exhibited piezoelectricity. This culminated in 1910 with the publication of Woldemar Voigt's "Lehrbuch der Kristallphysik" ("Textbook on Crystal Physics"), which described the 20 natural crystal classes capable of piezoelectricity, and rigorously defined the piezoelectric constants using tensor analysis.

The first practical application for piezoelectric devices was sonar, first developed during World War I. In France in 1917, Paul Langevin and his coworkers developed an ultrasonic submarine detector. The detector consisted of a transducer, made of thin quartz crystals carefully glued between two steel plates, and a hydrophone to detect the returned echo. By emitting a high-frequency pulse from the transducer, and measuring the amount of time it takes to hear an echo from the sound waves bouncing off an object, one can calculate the distance to that object.

The use of piezoelectricity in sonar, and the success of that project, created intense development interest in piezoelectric devices. Over the next few decades, new piezoelectric materials and new applications for those materials were explored and developed.

Piezoelectric devices found homes in many fields. Ceramic phonograph cartridges simplified player design, were cheap and accurate, and made record players cheaper to maintain and easier to build. The development of the ultrasonic transducer allowed for easy measurement of viscosity and elasticity in fluids and solids, resulting in huge advances in materials research. Ultrasonic time-domain reflectometers (which send an ultrasonic pulse through a material and measure reflections from discontinuities) could find flaws inside cast metal and stone objects, improving structural safety.

During World War II, independent research groups in the United States, Russia, and Japan discovered a new class of synthetic materials, called ferroelectrics, which exhibited piezoelectric constants many times higher than natural materials. This led to intense research to develop barium titanate and later lead zirconate titanate materials with specific properties for particular applications.

One significant example of the use of piezoelectric crystals was developed by Bell Telephone Laboratories. Following World War I, Frederick R. Lack, working in radio telephony in the engineering department, developed the “AT cut” crystal, a crystal that operated through a wide range of temperatures. Lack's crystal didn't need the heavy accessories previous crystal used, facilitating its use on aircraft. This development allowed Allied air forces to engage in coordinated mass attacks through the use of aviation radio.

Development of piezoelectric devices and materials in the United States was kept within the companies doing the development, mostly due to the wartime beginnings of the field, and in the interests of securing profitable patents. New materials were the first to be developed — quartz crystals were the first commercially exploited piezoelectric material, but scientists searched for higher-performance materials. Despite the advances in materials and the maturation of manufacturing processes, the United States market did not grow as quickly as Japan's did. Without many new applications, the growth of the United States' piezoelectric industry suffered.

In contrast, Japanese manufacturers shared their information, quickly overcoming technical and manufacturing challenges and creating new markets. In Japan, a temperature stable crystal cut was developed by Issac Koga. Japanese efforts in materials research created piezoceramic materials competitive to the United States materials but free of expensive patent restrictions. Major Japanese piezoelectric developments included new designs of piezoceramic filters for radios and televisions, piezo buzzers and audio transducers that can connect directly to electronic circuits, and the piezoelectric igniter, which generates sparks for small engine ignition systems and gas-grill lighters, by compressing a ceramic disc. Ultrasonic transducers that transmit sound waves through air had existed for quite some time but first saw major commercial use in early television remote controls. These transducers now are mounted on several car models as an echolocation device, helping the driver determine the distance from the car to any objects that may be in its path.

The nature of the piezoelectric effect is closely related to the occurrence of electric dipole moments in solids. The latter may either be induced for ions on crystal lattice sites with asymmetric charge surroundings (as in BaTiO and PZTs) or may directly be carried by molecular groups (as in cane sugar). The dipole density or polarization (dimensionality [C·m/m] ) may easily be calculated for crystals by summing up the dipole moments per volume of the crystallographic unit cell. As every dipole is a vector, the dipole density P is a vector field. Dipoles near each other tend to be aligned in regions called Weiss domains. The domains are usually randomly oriented, but can be aligned using the process of "poling" (not the same as magnetic poling), a process by which a strong electric field is applied across the material, usually at elevated temperatures. Not all piezoelectric materials can be poled.

Of decisive importance for the piezoelectric effect is the change of polarization P when applying a mechanical stress. This might either be caused by a reconfiguration of the dipole-inducing surrounding or by re-orientation of molecular dipole moments under the influence of the external stress. Piezoelectricity may then manifest in a variation of the polarization strength, its direction or both, with the details depending on: 1. the orientation of P within the crystal; 2. crystal symmetry; and 3. the applied mechanical stress. The change in P appears as a variation of surface charge density upon the crystal faces, i.e. as a variation of the electric field extending between the faces caused by a change in dipole density in the bulk. For example, a 1 cm cube of quartz with 2 kN (500 lbf) of correctly applied force can produce a voltage of 12500 V.

Piezoelectric materials also show the opposite effect, called the converse piezoelectric effect, where the application of an electrical field creates mechanical deformation in the crystal.

Linear piezoelectricity is the combined effect of

These may be combined into so-called "coupled equations", of which the strain-charge form is:
In matrix form,
where ["d"] is the matrix for the direct piezoelectric effect and ["d"] is the matrix for the converse piezoelectric effect. The superscript "E" indicates a zero, or constant, electric field; the superscript "T" indicates a zero, or constant, stress field; and the superscript t stands for transposition of a matrix.

Notice that the third order tensor formula_7 maps vectors into symmetric matrices. There are no non-trivial rotation-invariant tensors that have this property, which is why there are no isotropic piezoelectric materials.

The strain-charge for a material of the 4mm (C) crystal class (such as a poled piezoelectric ceramic such as tetragonal PZT or BaTiO) as well as the 6mm crystal class may also be written as (ANSI IEEE 176):

where the first equation represents the relationship for the converse piezoelectric effect and the latter for the direct piezoelectric effect.

Although the above equations are the most used form in literature, some comments about the notation are necessary. Generally, "D" and "E" are vectors, that is, Cartesian tensors of rank 1; and permittivity "ε" is a Cartesian tensor of rank 2. Strain and stress are, in principle, also rank-2 tensors. But conventionally, because strain and stress are all symmetric tensors, the subscript of strain and stress can be relabeled in the following fashion: 11 → 1; 22 → 2; 33 → 3; 23 → 4; 13 → 5; 12 → 6. (Different conventions may be used by different authors in literature. For example, some use 12 → 4; 23 → 5; 31 → 6 instead.) That is why "S" and "T" appear to have the "vector form" of six components. Consequently, "s" appears to be a 6-by-6 matrix instead of a rank-3 tensor. Such a relabeled notation is often called Voigt notation. Whether the shear strain components "S", "S", "S" are tensor components or engineering strains is another question. In the equation above, they must be engineering strains for the 6,6 coefficient of the compliance matrix to be written as shown, i.e., 2("s" − "s"). Engineering shear strains are double the value of the corresponding tensor shear, such as "S" = 2"S" and so on. This also means that "s" = , where "G" is the shear modulus.

In total, there are four piezoelectric coefficients, "d", "e", "g", and "h" defined as follows:

where the first set of four terms corresponds to the direct piezoelectric effect and the second set of four terms corresponds to the converse piezoelectric effect. For those piezoelectric crystals for which the polarization is of the crystal-field induced type, a formalism has been worked out that allows for the calculation of piezoelectrical coefficients "d" from electrostatic lattice constants or higher-order Madelung constants.

Of the 32 crystal classes, 21 are non-centrosymmetric (not having a centre of symmetry), and of these, 20 exhibit direct piezoelectricity (the 21st is the cubic class 432). Ten of these represent the polar crystal classes, which show a spontaneous polarization without mechanical stress due to a non-vanishing electric dipole moment associated with their unit cell, and which exhibit pyroelectricity. If the dipole moment can be reversed by applying an external electric field, the material is said to be ferroelectric.

For polar crystals, for which P ≠ 0 holds without applying a mechanical load, the piezoelectric effect manifests itself by changing the magnitude or the direction of P or both.

For the nonpolar but piezoelectric crystals, on the other hand, a polarization P different from zero is only elicited by applying a mechanical load. For them the stress can be imagined to transform the material from a nonpolar crystal class (P = 0) to a polar one, having P ≠ 0.

Many materials, both natural and synthetic, exhibit piezoelectricity:


The action of piezoelectricity in Topaz can probably be attributed to ordering of the (F,OH) in its lattice, which is otherwise centrosymmetric: orthorhombic bipyramidal (mmm). Topaz has anomalous optical properties which are attributed to such ordering.

Dry bone exhibits some piezoelectric properties. Studies of Fukada "et al." showed that these are not due to the apatite crystals, which are centrosymmetric, thus non-piezoelectric, but due to collagen. Collagen exhibits the polar uniaxial orientation of molecular dipoles in its structure and can be considered as bioelectret, a sort of dielectric material exhibiting quasipermanent space charge and dipolar charge. Potentials are thought to occur when a number of collagen molecules are stressed in the same way displacing significant numbers of the charge carriers from the inside to the surface of the specimen. Piezoelectricity of single individual collagen fibrils was measured using piezoresponse force microscopy, and it was shown that collagen fibrils behave predominantly as shear piezoelectric materials.

The piezoelectric effect is generally thought to act as a biological force sensor. This effect was exploited by research conducted at the University of Pennsylvania in the late 1970s and early 1980s, which established that sustained application of electrical potential could stimulate both resorption and growth (depending on the polarity) of bone in-vivo. Further studies in the 1990s provided the mathematical equation to confirm long bone wave propagation as to that of hexagonal (Class 6) crystals.

Biological materials exhibiting piezoelectric properties include:


Ceramics with randomly oriented grains must be ferroelectric to exhibit piezoelectricity. The macroscopic piezoelectricity is possible in textured polycrystalline non-ferroelectric piezoelectric materials, such as AlN and ZnO. 
The family of ceramics with perovskite, tungsten-bronze and related structures exhibits piezoelectricity:

More recently, there is growing concern regarding the toxicity in lead-containing devices driven by the result of restriction of hazardous substances directive regulations. To address this concern, there has been a resurgence in the compositional development of lead-free piezoelectric materials.
So far, neither the environmental effect nor the stability of supplying these substances have been measured.

A piezoelectric potential can be created in any bulk or nanostructured semiconductor crystal having non central symmetry, such as the Group III–V and II–VI materials, due to polarization of ions under applied stress and strain. This property is common to both the zincblende and wurtzite crystal structures. To first order, there is only one independent piezoelectric coefficient in zincblende, called e, coupled to shear components of the strain. In wurtzite, there are instead three independent piezoelectric coefficients: "e", "e" and "e".
The semiconductors where the strongest piezoelectricity is observed are those commonly found in the wurtzite structure, i.e. GaN, InN, AlN and ZnO. ZnO is the most used material in the recent field of piezotronics.

Since 2006, there have also been a number of reports of strong non linear piezoelectric effects in polar semiconductors.
Such effects are generally recognized to be at least important if not of the same order of magnitude as the first order approximation.


A strong shear piezoelectric activity was observed in self-assembled diphenylalanine peptide nanotubes (PNTs), indicating electric polarization directed along the tube axis. Comparison with LiNbO and lateral signal calibration yields sufficiently high effective piezoelectric coefficient values of at least 60 pm/V (shear response for tubes of ≈200 nm in diameter). PNTs demonstrate linear deformation without irreversible degradation in a broad range of driving voltages.

Currently, industrial and manufacturing is the largest application market for piezoelectric devices, followed by the automotive industry. Strong demand also comes from medical instruments as well as information and telecommunications. The global demand for piezoelectric devices was valued at approximately US$14.8 billion in 2010. The largest material group for piezoelectric devices is piezoceramics, and piezopolymer is experiencing the fastest growth due to its low weight and small size.

Piezoelectric crystals are now used in numerous ways:

Direct piezoelectricity of some substances, like quartz, can generate potential differences of thousands of volts.


The principle of operation of a piezoelectric sensor is that a physical dimension, transformed into a force, acts on two opposing faces of the sensing element. Depending on the design of a sensor, different "modes" to load the piezoelectric element can be used: longitudinal, transversal and shear.

Detection of pressure variations in the form of sound is the most common sensor application, e.g. piezoelectric microphones (sound waves bend the piezoelectric material, creating a changing voltage) and piezoelectric pickups for acoustic-electric guitars. A piezo sensor attached to the body of an instrument is known as a contact microphone.

Piezoelectric sensors especially are used with high frequency sound in ultrasonic transducers for medical imaging and also industrial nondestructive testing (NDT).

For many sensing techniques, the sensor can act as both a sensor and an actuator – often the term "transducer" is preferred when the device acts in this dual capacity, but most piezo devices have this property of reversibility whether it is used or not. Ultrasonic transducers, for example, can inject ultrasound waves into the body, receive the returned wave, and convert it to an electrical signal (a voltage). Most medical ultrasound transducers are piezoelectric.

In addition to those mentioned above, various sensor applications include:


As very high electric fields correspond to only tiny changes in the width of the crystal, this width can be changed with better-than-µm precision, making piezo crystals the most important tool for positioning objects with extreme accuracy — thus their use in actuators.
Multilayer ceramics, using layers thinner than , allow reaching high electric fields with voltage lower than . These ceramics are used within two kinds of actuators: direct piezo actuators and Amplified piezoelectric actuators. While direct actuator's stroke is generally lower than , amplified piezo actuators can reach millimeter strokes.

The piezoelectrical properties of quartz are useful as a standard of frequency.


Types of piezoelectric motor include:

Aside from the stepping stick-slip motor, all these motors work on the same principle. Driven by dual orthogonal vibration modes with a phase difference of 90°, the contact point between two surfaces vibrates in an elliptical path, producing a frictional force between the surfaces. Usually, one surface is fixed, causing the other to move. In most piezoelectric motors, the piezoelectric crystal is excited by a sine wave signal at the resonant frequency of the motor. Using the resonance effect, a much lower voltage can be used to produce a high vibration amplitude.

A stick-slip motor works using the inertia of a mass and the friction of a clamp. Such motors can be very small. Some are used for camera sensor displacement, thus allowing an anti-shake function.

Different teams of researchers have been investigating ways to reduce vibrations in materials by attaching piezo elements to the material. When the material is bent by a vibration in one direction, the vibration-reduction system responds to the bend and sends electric power to the piezo element to bend in the other direction. Future applications of this technology are expected in cars and houses to reduce noise. Further applications to flexible structures, such as shells and plates, have also been studied for nearly three decades.

In a demonstration at the Material Vision Fair in Frankfurt in November 2005, a team from TU Darmstadt in Germany showed several panels that were hit with a rubber mallet, and the panel with the piezo element immediately stopped swinging.

Piezoelectric ceramic fiber technology is being used as an electronic damping system on some HEAD tennis rackets.

In people with previous total fertilization failure, piezoelectric activation of oocytes together with intracytoplasmic sperm injection (ICSI) seems to improve fertilization outcomes.

A recent application of piezoelectric ultrasound sources is piezoelectric surgery, also known as piezosurgery. Piezosurgery is a minimally invasive technique that aims to cut a target tissue with little damage to neighboring tissues. For example, Hoigne "et al." reported its use in hand surgery for the cutting of bone, using frequencies in the range 25–29 kHz, causing microvibrations of 60–210 μm. It has the ability to cut mineralized tissue without cutting neurovascular tissue and other soft tissue, thereby maintaining a blood-free operating area, better visibility and greater precision.

In 2015, Cambridge University researchers working in conjunction with researchers from the National Physical Laboratory and Cambridge-based dielectric antenna company Antenova Ltd, using thin films of piezoelectric materials found that at a certain frequency, these materials become not only efficient resonators, but efficient radiators as well, meaning that they can potentially be used as antennas. The researchers found that by subjecting the piezoelectric thin films to an asymmetric excitation, the symmetry of the system is similarly broken, resulting in a corresponding symmetry breaking of the electric field, and the generation of electromagnetic radiation.

In recent years, several attempts at the macro-scale application of the piezoelectric technology have emerged to harvest kinetic energy from walking pedestrians. The piezoelectric floors have been trialed since the beginning of 2007 in two Japanese train stations, Tokyo and Shibuya stations. The electricity generated from the foot traffic is used to provide all the electricity needed to run the automatic ticket gates and electronic display systems. In London, a famous nightclub exploited the piezoelectric technology in its dance floor. Parts of the lighting and sound systems in the club can be powered by the energy harvesting tiles. However, the piezoelectric tile deployed on the ground usually harvests energy from low frequency strikes provided by the foot traffic. This working condition may eventually lead to low power generation efficiency.

In this case, locating high traffic areas is critical for optimization of the energy harvesting efficiency, as well as the orientation of the tile pavement significantly affects the total amount of the harvested energy. A density flow evaluation is recommended to qualitatively evaluate the piezoelectric power harvesting potential of the considered area based on the number of pedestrian crossings per unit time. In X. Li's study, the potential application of a commercial piezoelectric energy harvester in a central hub building at Macquarie University in Sydney, Australia is examined and discussed. Optimization of the piezoelectric tile deployment is presented according to the frequency of pedestrian mobility and a model is developed where 3.1% of the total floor area with the highest pedestrian mobility is paved with piezoelectric tiles. The modelling results indicate that the total annual energy harvesting potential for the proposed optimized tile pavement model is estimated at 1.1 MW h/year, which would be sufficient to meet close to 0.5% of the annual energy needs of the building. In Israel, there is a company which has installed piezoelectric materials under a busy highway. The energy generated is adequate and powers street lights, billboards and signs.

Tire company Goodyear has plans to develop an electricity generating tire which has piezoelectric material lined inside it. As the tire moves, it deforms and thus electricity is generated.

The efficiency of a hybrid photovoltaic cell that contains piezoelectric materials can be increased simply by placing it near a source of ambient noise or vibration. The effect was demonstrated with organic cells using zinc oxide nanotubes. The electricity generated by the piezoelectric effect itself is a negligible percentage of the overall output. Sound levels as low as 75 decibels improved efficiency by up to 50%. Efficiency peaked at 10 kHz, the resonant frequency of the nanotubes. The electrical field set up by the vibrating nanotubes interacts with electrons migrating from the organic polymer layer. This process decreases the likelihood of recombination, in which electrons are energized but settle back into a hole instead of migrating to the electron-accepting ZnO layer.




</doc>
<doc id="24977" url="https://en.wikipedia.org/wiki?curid=24977" title="Product (mathematics)">
Product (mathematics)

In mathematics, a product is the result of multiplying, or an expression that identifies factors to be multiplied. Thus, for instance, 6 is the product of 2 and 3 (the result of multiplication), and formula_1 is the product of formula_2 and formula_3 (indicating that the two factors should be multiplied together).

The order in which real or complex numbers are multiplied has no bearing on the product; this is known as the commutative law of multiplication. When matrices or members of various other associative algebras are multiplied, the product usually depends on the order of the factors. Matrix multiplication, for example, and multiplication in other algebras is in general non-commutative.

There are many different kinds of products in mathematics: besides being able to multiply just numbers, polynomials or matrices, one can also define products on many different algebraic structures. An overview of these different kinds of products is given here.

Placing several stones into a rectangular pattern with formula_4 rows and formula_5 columns gives

stones.

Integers allow positive and negative numbers. The two numbers are multiplied just like natural numbers, except we need an additional rule for the signs:

In words, we have:

Two fractions can be multiplied by multiplying their numerators and denominators:

For a rigorous definition of the product of two real numbers see Construction of the real numbers.

Two complex numbers can be multiplied by the distributive law and the fact that formula_9, as follows:

Complex numbers can be written in polar coordinates:
Furthermore,

The geometric meaning is that we multiply the magnitudes and add the angles.

The product of two quaternions can be found in the article on quaternions. However, it is interesting to note that in this case, formula_14 and formula_15 are in general different.

The product operator for the product of a sequence is denoted by the capital Greek letter pi ∏ (in analogy to the use of the capital Sigma ∑ as summation symbol). The product of a sequence consisting of only one number is just that number itself. The product of no factors at all is known as the empty product, and is equal to 1.

Commutative rings have a product operation.

Residue classes in the rings formula_16 can be added:

and multiplied:

Two functions from the reals to itself can be multiplied in another way, called the convolution.

If

then the integral

is well defined and is called the convolution.

Under the Fourier transform, convolution becomes point-wise function multiplication.

The product of two polynomials is given by the following:

with

There are many different kinds of products in linear algebra; some of these have confusingly similar names (outer product, exterior product) but have very different meanings. Others have very different names (outer product, tensor product, Kronecker product) but convey essentially the same idea. A brief overview of these is given here.

By the very definition of a vector space, one can form the product of any scalar with any vector, giving a map formula_23.

A scalar product is a bilinear map:

with the following conditions, that formula_25 for all formula_26.

From the scalar product, one can define a norm by letting formula_27.

The scalar product also allows one to define an angle between two vectors:

In formula_29-dimensional Euclidean space, the standard scalar product (called the dot product) is given by:

The cross product of two vectors in 3-dimensions is a vector perpendicular to the two factors, with length equal to the area of the parallelogram spanned by the two factors.

The cross product can also be expressed as the formal determinant:

A linear mapping can be defined as a function "f" between two vector spaces "V" and "W" with underlying field F, satisfying
If one only considers finite dimensional vector spaces, then
in which b andb denote the bases of "V" and "W", and "v" denotes the component of v on b, and Einstein summation convention is applied.

Now we consider the composition of two linear mappings between finite dimensional vector spaces. Let the linear mapping "f" map "V" to "W", and let the linear mapping "g" map "W" to "U". Then one can get
Or in matrix form:
in which the "i"-row, "j"-column element of F, denoted by "F", is "f", and "G=g".

The composition of more than two linear mappings can be similarly represented by a chain of matrix multiplication.

Given two matrices

their product is given by

There is a relationship between the composition of linear functions and the product of two matrices. To see this, let r = dim(U), s = dim(V) and t = dim(W) be the (finite) dimensions of vector spaces U, V and W. Let 
formula_39 be a basis of U, 
formula_40 be a basis of V and 
formula_41 be a basis of W. In terms of this basis, let
formula_42
be the matrix representing f : U → V and 
formula_43 
be the matrix representing g : V → W. Then

is the matrix representing formula_45.

In other words: the matrix product is the description in coordinates of the composition of linear functions.

Given two finite dimensional vector spaces "V" and "W", the tensor product of them can be defined as a (2,0)-tensor satisfying:
where "V" and "W" denote the dual spaces of "V" and "W".

For infinite-dimensional vector spaces, one also has the:

The tensor product, outer product and Kronecker product all convey the same general idea. The differences between these are that the Kronecker product is just a tensor product of matrices, with respect to a previously-fixed basis, whereas the tensor product is usually given in its intrinsic definition. The outer product is simply the Kronecker product, limited to vectors (instead of matrices).

In general, whenever one has two mathematical objects that can be combined in a way that behaves like a linear algebra tensor product, then this can be most generally understood as the internal product of a monoidal category. That is, the monoidal category captures precisely the meaning of a tensor product; it captures exactly the notion of why it is that tensor products behave the way they do. More precisely, a monoidal category is the class of all things (of a given type) that have a tensor product.

Other kinds of products in linear algebra include:


In set theory, a Cartesian product is a mathematical operation which returns a set (or product set) from multiple sets. That is, for sets "A" and "B", the Cartesian product is the set of all ordered pairs where and .

The class of all things (of a given type) that have Cartesian products is called a Cartesian category. Many of these are Cartesian closed categories. Sets are an example of such objects.

The empty product on numbers and most algebraic structures has the value of 1 (the identity element of multiplication) just like the empty sum has the value of 0 (the identity element of addition). However, the concept of the empty product is more general, and requires special treatment in logic, set theory, computer programming and category theory.

Products over other kinds of algebraic structures include:

A few of the above products are examples of the general notion of an internal product in a monoidal category; the rest are describable by the general notion of a product in category theory.

All of the previous examples are special cases or examples of the general notion of a product. For the general treatment of the concept of a product, see product (category theory), which describes how to combine two objects of some kind to create an object, possibly of a different kind. But also, in category theory, one has:





</doc>
<doc id="24979" url="https://en.wikipedia.org/wiki?curid=24979" title="4-polytope">
4-polytope

In geometry, a 4-polytope (sometimes also called a polychoron, polycell, or polyhedroid) is a four-dimensional polytope. It is a connected and closed figure, composed of lower-dimensional polytopal elements: vertices, edges, faces (polygons), and cells (polyhedra). Each face is shared by exactly two cells.

The two-dimensional analogue of a 4-polytope is a polygon, and the three-dimensional analogue is a polyhedron.

Topologically 4-polytopes are closely related to the uniform honeycombs, such as the cubic honeycomb, which tessellate 3-space; similarly the 3D cube is related to the infinite 2D square tiling. Convex 4-polytopes can be "cut and unfolded" as nets in 3-space.

A 4-polytope is a closed four-dimensional figure. It comprises vertices (corner points), edges, faces and cells. A cell is the three-dimensional analogue of a face, and is therefore a polyhedron. Each face must join exactly two cells, analogous to the way in which each edge of a polyhedron joins just two faces. Like any polytope, the elements of a 4-polytope cannot be subdivided into two or more sets which are also 4-polytopes, i.e. it is not a compound.

The most familiar 4-polytope is the tesseract or hypercube, the 4D analogue of the cube.
4-polytopes cannot be seen in three-dimensional space due to their extra dimension. Several techniques are used to help visualise them.

Orthogonal projections can be used to show various symmetry orientations of a 4-polytope. They can be drawn in 2D as vertex-edge graphs, and can be shown in 3D with solid faces as visible projective envelopes.
Just as a 3D shape can be projected onto a flat sheet, so a 4-D shape can be projected onto 3-space or even onto a flat sheet. One common projection is a Schlegel diagram which uses stereographic projection of points on the surface of a 3-sphere into three dimensions, connected by straight edges, faces, and cells drawn in 3-space.

Just as a slice through a polyhedron reveals a cut surface, so a slice through a 4-polytope reveals a cut "hypersurface" in three dimensions. A sequence of such sections can be used to build up an understanding of the overall shape. The extra dimension can be equated with time to produce a smooth animation of these cross sections.

A net of a 4-polytope is composed of polyhedral cells that are connected by their faces and all occupy the same three-dimensional space, just as the polygon faces of a net of a polyhedron are connected by their edges and all occupy the same plane.

The topology of any given 4-polytope is defined by its Betti numbers and torsion coefficients.

The value of the Euler characteristic used to characterise polyhedra does not generalize usefully to higher dimensions, and is zero for all 4-polytopes, whatever their underlying topology. This inadequacy of the Euler characteristic to reliably distinguish between different topologies in higher dimensions led to the discovery of the more sophisticated Betti numbers.

Similarly, the notion of orientability of a polyhedron is insufficient to characterise the surface twistings of toroidal 4-polytopes, and this led to the use of torsion coefficients.

Like all polytopes, 4-polytopes may be classified based on properties like "convexity" and "symmetry".


The following lists the various categories of 4-polytopes classified according to the criteria above:

Uniform 4-polytope (vertex-transitive):

Other convex 4-polytopes:
Infinite uniform 4-polytopes of Euclidean 3-space (uniform tessellations of convex uniform cells)

Infinite uniform 4-polytopes of hyperbolic 3-space (uniform tessellations of convex uniform cells)

Dual uniform 4-polytope (cell-transitive):

Others:

Abstract regular 4-polytopes:

These categories include only the 4-polytopes that exhibit a high degree of symmetry. Many other 4-polytopes are possible, but they have not been studied as extensively as the ones included in these categories.





</doc>
<doc id="24980" url="https://en.wikipedia.org/wiki?curid=24980" title="Punctuated equilibrium">
Punctuated equilibrium

Punctuated equilibrium (also called punctuated equilibria) is a theory in evolutionary biology which proposes that once species appear in the fossil record the population will become stable, showing little evolutionary change for most of its geological history. This state of little or no morphological change is called "stasis". When significant evolutionary change occurs, the theory proposes that it is generally restricted to rare and geologically rapid events of branching speciation called cladogenesis. Cladogenesis is the process by which a species splits into two distinct species, rather than one species gradually transforming into another.

Punctuated equilibrium is commonly contrasted against phyletic gradualism, the idea that evolution generally occurs uniformly and by the steady and gradual transformation of whole lineages (called anagenesis). In this view, evolution is seen as generally smooth and continuous.

In 1972, paleontologists Niles Eldredge and Stephen Jay Gould published a landmark paper developing their theory and called it "punctuated equilibria". Their paper built upon Ernst Mayr's model of geographic speciation, I. Michael Lerner's theories of developmental and genetic homeostasis, and their own empirical research. Eldredge and Gould proposed that the degree of gradualism commonly attributed to Charles Darwin is virtually nonexistent in the fossil record, and that stasis dominates the history of most fossil species.

Punctuated equilibrium originated as a logical consequence of Ernst Mayr's concept of genetic revolutions by allopatric and especially peripatric speciation as applied to the fossil record. Although the sudden appearance of species and its relationship to speciation was proposed and identified by Mayr in 1954, historians of science generally recognize the 1972 Eldredge and Gould paper as the basis of the new paleobiological research program. Punctuated equilibrium differs from Mayr's ideas mainly in that Eldredge and Gould placed considerably greater emphasis on stasis, whereas Mayr was concerned with explaining the morphological discontinuity (or "sudden jumps") found in the fossil record. Mayr later complimented Eldredge and Gould's paper, stating that evolutionary stasis had been "unexpected by most evolutionary biologists" and that punctuated equilibrium "had a major impact on paleontology and evolutionary biology."

A year before their 1972 Eldredge and Gould paper, Niles Eldredge published a paper in the journal "Evolution" which suggested that gradual evolution was seldom seen in the fossil record and argued that Ernst Mayr's standard mechanism of allopatric speciation might suggest a possible resolution.

The Eldredge and Gould paper was presented at the Annual Meeting of the Geological Society of America in 1971. The symposium focused its attention on how modern microevolutionary studies could revitalize various aspects of paleontology and macroevolution. Tom Schopf, who organized that year's meeting, assigned Gould the topic of speciation. Gould recalls that "Eldredge's 1971 publication [on Paleozoic trilobites] had presented the only new and interesting ideas on the paleontological implications of the subject—so I asked Schopf if we could present the paper jointly." According to Gould "the ideas came mostly from Niles, with yours truly acting as a sounding board and eventual scribe. I coined the term "punctuated equilibrium" and wrote most of our 1972 paper, but Niles is the proper first author in our pairing of Eldredge and Gould." In his book "Time Frames" Eldredge recalls that after much discussion the pair "each wrote roughly half. Some of the parts that would seem obviously the work of one of us were actually first penned by the other—I remember for example, writing the section on Gould's snails. Other parts are harder to reconstruct. Gould edited the entire manuscript for better consistency. We sent it in, and Schopf reacted strongly against it—thus signaling the tenor of the reaction it has engendered, though for shifting reasons, down to the present day."

John Wilkins and Gareth Nelson have argued that French architect Pierre Trémaux proposed an "anticipation of the theory of punctuated equilibrium of Gould and Eldredge."

The fossil record includes well documented examples of both phyletic gradualism and punctuational evolution. As such, much debate persists over the prominence of stasis in the fossil record. Before punctuated equilibrium, most evolutionists considered stasis to be rare or unimportant. The paleontologist George Gaylord Simpson, for example, believed that phyletic gradual evolution (called "horotely" in his terminology) comprised 90% of evolution. More modern studies, including a meta-analysis examining 58 published studies on speciation patterns in the fossil record showed that 71% of species exhibited stasis, and 63% were associated with punctuated patterns of evolutionary change. According to Michael Benton, "it seems clear then that stasis is common, and that had not been predicted from modern genetic studies." A paramount example of evolutionary stasis is the fern "Osmunda claytoniana". Based on paleontological evidence it has remained unchanged, even at the level of fossilized nuclei and chromosomes, for at least 180 million years.

When Eldredge and Gould published their 1972 paper, allopatric speciation was considered the "standard" model of speciation. This model was popularized by Ernst Mayr in his 1954 paper "Change of genetic environment and evolution," and his classic volume "Animal Species and Evolution" (1963).

Allopatric speciation suggests that species with large central populations are stabilized by their large volume and the process of gene flow. New and even beneficial mutations are diluted by the population's large size and are unable to reach fixation, due to such factors as constantly changing environments. If this is the case, then the transformation of whole lineages should be rare, as the fossil record indicates. Smaller populations on the other hand, which are isolated from the parental stock, are decoupled from the homogenizing effects of gene flow. In addition, pressure from natural selection is especially intense, as peripheral isolated populations exist at the outer edges of ecological tolerance. If most evolution happens in these rare instances of allopatric speciation then evidence of gradual evolution in the fossil record should be rare. This hypothesis was alluded to by Mayr in the closing paragraph of his 1954 paper:

Although punctuated equilibrium generally applies to sexually reproducing organisms, some biologists have applied the model to non-sexual species like viruses, which cannot be stabilized by conventional gene flow. As time went on biologists like Gould moved away from wedding punctuated equilibrium to allopatric speciation, particularly as evidence accumulated in support of other modes of speciation. Gould, for example, was particularly attracted to Douglas Futuyma's work on the importance of reproductive isolating mechanisms.

Many hypotheses have been proposed to explain the putative causes of stasis. Gould was initially attracted to I. Michael Lerner's theories of developmental and genetic homeostasis. However this hypothesis was rejected over time, as evidence accumulated against it. Other plausible mechanisms which have been suggested include: habitat tracking, stabilizing selection, the Stenseth-Maynard Smith stability hypothesis, constraints imposed by the nature of subdivided populations, normalizing clade selection, and koinophilia.

Evidence for the existence of stasis has also been corroborated from the genetics of sibling species, species which are morphologically indistinguishable, but whose proteins have diverged sufficiently to suggest they have been separated for millions of years.

According to Gould, "stasis may emerge as the theory's most important contribution to evolutionary science." Philosopher Kim Sterelny in clarifying the meaning of stasis adds, "In claiming that species typically undergo no further evolutionary change once speciation is complete, they are not claiming that there is no change at all between one generation and the next. Lineages do change. But the change between generations does not accumulate. Instead, over time, the species wobbles about its phenotypic mean. Jonathan Weiner's "The Beak of the Finch" describes this very process."

Punctuated equilibrium has also been cited as contributing to the hypothesis that species are Darwinian individuals, and not just classes, thereby providing a stronger framework for a hierarchical theory of evolution.

Much confusion has arisen over what proponents of punctuated equilibrium actually argued, what mechanisms they advocated, how fast the punctuations were, what taxonomic scale their theory applied to, how revolutionary their claims were intended to be, and how punctuated equilibrium related to other ideas like quantum evolution, saltationism, and mass extinction.

The punctuational nature of punctuated equilibrium has engendered perhaps the most confusion over Eldredge and Gould's theory. Gould's sympathetic treatment of Richard Goldschmidt, the controversial geneticist who advocated the idea of "hopeful monsters," led some biologists to conclude that Gould's punctuations were occurring in single-generation jumps. This interpretation has frequently been used by creationists to characterize the weakness of the paleontological record, and to portray contemporary evolutionary biology as advancing neo-saltationism. In an often quoted remark, Gould stated, "Since we proposed punctuated equilibria to explain trends, it is infuriating to be quoted again and again by creationists—whether through design or stupidity, I do not know—as admitting that the fossil record includes no transitional forms. Transitional forms are generally lacking at the species level, but they are abundant between larger groups." Although there exist some debate over how long the punctuations last, supporters of punctuated equilibrium generally place the figure between 50,000 and 100,000 years.

Quantum evolution was a controversial hypothesis advanced by Columbia University paleontologist George Gaylord Simpson, who was regarded by Gould as "the greatest and most biologically astute paleontologist of the twentieth century." Simpson's conjecture was that according to the geological record, on very rare occasions evolution would proceed very rapidly to form entirely new families, orders, and classes of organisms. This hypothesis differs from punctuated equilibrium in several respects. First, punctuated equilibrium was more modest in scope, in that it was addressing evolution specifically at the species level. Simpson's idea was principally concerned with evolution at higher taxonomic groups. Second, Eldredge and Gould relied upon a different mechanism. Where Simpson relied upon a synergistic interaction between genetic drift and a shift in the adaptive fitness landscape, Eldredge and Gould relied upon ordinary speciation, particularly Ernst Mayr's concept of allopatric speciation. Lastly, and perhaps most significantly, quantum evolution took no position on the issue of stasis. Although Simpson acknowledged the existence of stasis in what he called the bradytelic mode, he considered it (along with rapid evolution) to be unimportant in the larger scope of evolution. In his "Major Features of Evolution" Simpson stated, "Evolutionary change is so nearly the universal rule that a state of motion is, figuratively, normal in evolving populations. The state of rest, as in bradytely, is the exception and it seems that some restraint or force must be required to maintain it." Despite such differences between the two models, earlier critiques—from such eminent commentators as Sewall Wright as well as Simpson himself—have argued that punctuated equilibrium is little more than quantum evolution relabeled.

Punctuated equilibrium is often portrayed to oppose the concept of gradualism, when it is actually a form of gradualism. This is because even though evolutionary change appears instantaneous between geological sedimentary layers, change is still occurring incrementally, with no great change from one generation to the next. To this end, Gould later commented that "Most of our paleontological colleagues missed this insight because they had not studied evolutionary theory and either did not know about allopatric speciation or had not considered its translation to geological time. Our evolutionary colleagues also failed to grasp the implication(s), primarily because they did not think at geological scales".

Richard Dawkins dedicated a chapter in "The Blind Watchmaker" to correcting, in his view, the wide confusion regarding "rates of change". His first point is to argue that phyletic gradualism — understood in the sense that evolution proceeds at a single uniform rate of speed, called "constant speedism" by Dawkins — is a "caricature of Darwinism" and "does not really exist". His second argument, which follows from the first, is that once the caricature of "constant speedism" is dismissed, we are left with one logical alternative, which Dawkins terms "variable speedism". Variable speedism may also be distinguished one of two ways: ""discrete variable" speedism" and ""continuously variable" speedism". Eldredge and Gould, proposing that evolution jumps between stability and relative rapidity, are described as "discrete variable speedists", and "in this respect they are genuinely radical." They assert that evolution generally proceeds in bursts, or not at all. "Continuously variable speedists", on the other hand, advance that "evolutionary rates fluctuate continuously from very fast to very slow and stop, with all intermediates. They see no particular reason to emphasize certain speeds more than others. In particular, stasis, to them, is just an extreme case of ultra-slow evolution. To a punctuationist, there is something very special about stasis." Dawkins therefore commits himself here to an empirical claim about the geological record, in contrast to his earlier claim that "The paleontological evidence can be argued about, and I am not qualified to judge it." It is this particular commitment that Eldredge and Gould have aimed to overturn.

Richard Dawkins regards the apparent gaps represented in the fossil record to document migratory events rather than evolutionary events. According to Dawkins, evolution certainly occurred but "probably gradually" elsewhere. However, the punctuational equilibrium model may still be inferred from both the observation of stasis and examples of rapid and episodic speciation events documented in the fossil record.

Dawkins also emphasizes that punctuated equilibrium has been "oversold by some journalists", but partly due to Eldredge and Gould's "later writings". Dawkins contends that the hypothesis "does not deserve a particularly large measure of publicity". It is a "minor gloss," an "interesting but minor wrinkle on the surface of neo-Darwinian theory," and "lies firmly within the neo-Darwinian synthesis".

In his book "Darwin's Dangerous Idea", philosopher Daniel Dennett is especially critical of Gould's presentation of punctuated equilibrium. Dennett argues that Gould alternated between revolutionary and conservative claims, and that each time Gould made a revolutionary statement—or appeared to do so—he was criticized, and thus retreated to a traditional neo-Darwinian position. Gould responded to Dennett's claims in "The New York Review of Books", and in his technical volume "The Structure of Evolutionary Theory".

English professor Heidi Scott argues that Gould's talent for writing vivid prose, his use of metaphor, and his success in building a popular audience of nonspecialist readers altered the "climate of specialized scientific discourse" favorably in his promotion of punctuated equilibrium. While Gould is celebrated for the color and energy of his prose, as well as his interdisciplinary knowledge, critics such as Scott, Richard Dawkins, and Daniel Dennett have concerns that the theory has gained undeserved credence among non-scientists because of Gould's rhetorical skills. Philosopher John Lyne and biologist Henry Howe, believed punctuated equilibrium's success has much more to do with the nature of the geological record than the nature of Gould's rhetoric. They state, a "re-analysis of existing fossil data has shown, to the increasing satisfaction of the paleontological community, that Eldredge and Gould were correct in identifying periods of evolutionary stasis which are interrupted by much shorter periods of evolutionary change."

Some critics jokingly referred to the theory of punctuated equilibrium as "evolution by jerks",
which prompted Gould to describe phyletic gradualism as "evolution by creeps."

The sudden appearance of most species in the geologic record and the lack of evidence of substantial gradual change in most species—from their initial appearance until their extinction—has , including by Charles Darwin who appealed to the imperfection of the record as the favored explanation. When presenting his ideas against the prevailing influences of catastrophism and progressive creationism, which envisaged species being supernaturally created at intervals, Darwin needed to forcefully stress the gradual nature of evolution in accordance with the gradualism promoted by his friend Charles Lyell. He privately expressed concern, noting in the margin of his 1844 "Essay", "Better begin with this: If species really, after catastrophes, created in showers world over, my theory false."

It is often incorrectly assumed that he insisted that the rate of change must be constant, or nearly so, but even the first edition of "On the Origin of Species" states that "Species of different genera and classes have not changed at the same rate, or in the same degree. In the oldest tertiary beds a few living shells may still be found in the midst of a multitude of extinct forms... The Silurian "Lingula" differs but little from the living species of this genus". "Lingula" is among the few brachiopods surviving today but also known from fossils over 500 million years old. In the fourth edition (1866) of "On the Origin of Species" Darwin wrote that "the periods during which species have undergone modification, though long as measured in years, have probably been short in comparison with the periods during which they retain the same form." Thus punctuationism in general is consistent with Darwin's conception of evolution.

According to early versions of punctuated equilibrium, "peripheral isolates" are considered to be of critical importance for speciation. However, Darwin wrote, ""I can by no means agree" ... that immigration and isolation are necessary elements... Although isolation is of great importance in the production of new species, on the whole I am inclined to believe that largeness of area is still more important, especially for the production of species which shall prove capable of enduring for a long period, and of spreading widely."

The importance of isolation in forming species had played a significant part in Darwin's early thinking, as shown in his "Essay" of 1844. But by the time he wrote the "Origin" he had downplayed its importance. He explained the reasons for his revised view as follows:
Throughout a great and open area, not only will there be a greater chance of favourable variations, arising from the large number of individuals of the same species there supported, but the conditions of life are much more complex from the large number of already existing species; and if some of these species become modified and improved, others will have to be improved in a corresponding degree, or they will be exterminated. Each new form, also, as soon as it has been improved, will be able to spread over the open and continuous area, and will thus come into competition with many other forms ... the new forms produced on large areas, which have already been victorious over many competitors, will be those that will spread most widely, and will give rise to the greatest number of new varieties and species. They will thus play a more important role in the changing history of the organic world.

Thus punctuated equilibrium is incongruous with some of Darwin's ideas regarding the specific mechanisms of evolution, but generally accords with Darwin's theory of evolution by natural selection.

Recent work in developmental biology has identified dynamical and physical mechanisms of tissue morphogenesis that may underlie abrupt morphological transitions during evolution. Consequently, consideration of mechanisms of phylogenetic change that have been found in reality to be non-gradual is increasingly common in the field of evolutionary developmental biology, particularly in studies of the origin of morphological novelty. A description of such mechanisms can be found in the multi-authored volume "Origination of Organismal Form" (MIT Press; 2003).

In linguistics, R. M. W. Dixon has proposed a punctuated equilibrium model for language histories, with reference particularly to the prehistory of the indigenous languages of Australia and his objections to the proposed Pama–Nyungan language family there. Although his model has raised considerable interest, it does not command majority support within linguistics.

Separately, recent work using computational phylogenetic methods claims to show that punctuational bursts play an important factor when languages split from one another, accounting for anywhere from 10 to 33% of the total divergence in vocabulary.

Punctuational evolution has been argued to explain changes in folktales and mythology over time.



</doc>
<doc id="24981" url="https://en.wikipedia.org/wiki?curid=24981" title="Pioneer 11">
Pioneer 11

Pioneer 11 (also known as Pioneer G) is a robotic space probe launched by NASA on April 6, 1973 to study the asteroid belt, the environment around Jupiter and Saturn, solar wind and cosmic rays. It was the first probe to encounter Saturn and the second to fly through the asteroid belt and by Jupiter. Thereafter, "Pioneer 11" became the second of five artificial objects to achieve the escape velocity that will allow them to leave the Solar System. Due to power constraints and the vast distance to the probe, the last routine contact with the spacecraft was on September 30, 1995, and the last good engineering data was received on November 24, 1995.

Approved in February 1969, "Pioneer 11" and its twin probe, "Pioneer 10", were the first to be designed for exploring the outer Solar System. Yielding to multiple proposals throughout the 1960s, early mission objectives were defined as:

Subsequent planning for an encounter with Saturn added many more goals:

"Pioneer 11" was built by TRW and managed as part of the Pioneer program by NASA Ames Research Center. A backup unit, Pioneer H, is currently on display in the "Milestones of Flight" exhibit at the National Air and Space Museum in Washington, D.C.. Many elements of the mission proved to be critical in the planning of the "Voyager" program.

The "Pioneer 11" bus measured deep and with six panels forming the hexagonal structure. The bus housed propellant to control the orientation of the probe and eight of the twelve scientific instruments. The spacecraft had a mass of 260 kilograms.

The "Pioneer 11" probe was launched on April 6, 1973 at 02:11:00 UTC, by the National Aeronautics and Space Administration from Space Launch Complex 36A at Cape Canaveral, Florida aboard an Atlas-Centaur launch vehicle. Its twin probe, "Pioneer 10", had launched a year earlier on March 3, 1972. "Pioneer 11" was launched on a trajectory directly aimed at Jupiter without any prior gravitational assists. In May 1974, Pioneer was retargeted to fly past Jupiter on a north-south trajectory enabling a Saturn flyby in 1979. The maneuver used 17 pounds of propellant, lasted 42 minutes and 36 seconds and increased Pioneer 11's speed by 230 km/h. It also made two mid-course corrections, on April 11, 1973 and November 7, 1974.

"Pioneer 11" flew past Jupiter in November and December 1974. During its closest approach, on December 2, it passed above the cloud tops. The probe obtained detailed images of the Great Red Spot, transmitted the first images of the immense polar regions, and determined the mass of Jupiter's moon Callisto. Using the gravitational pull of Jupiter, a gravity assist was used to alter the trajectory of the probe towards Saturn. On April 16, 1975, following the Jupiter encounter, the micrometer detector was turned off.

"Pioneer 11" passed by Saturn on September 1, 1979, at a distance of 21,000 km from Saturn's cloud tops.

By this time "Voyager 1" and "Voyager 2" had already passed Jupiter and were also en route to Saturn, so it was decided to target "Pioneer 11" to pass through the Saturn ring plane at the same position that the soon-to-come Voyager probes would use in order to test the route before the Voyagers arrived. If there were faint ring particles that could damage a probe in that area, mission planners felt it was better to learn about it via Pioneer. Thus, "Pioneer 11" was acting as a "pioneer" in a true sense of the word; if danger were detected, then the Voyager probes could be rerouted further away from the rings, but missing the opportunity to visit Uranus and Neptune in the process.

"Pioneer 11" imaged and nearly collided with one of Saturn's small moons, passing at a distance of no more than . The object was tentatively identified as Epimetheus, a moon discovered the previous day from "Pioneer"s imaging, and suspected from earlier observations by Earth-based telescopes. After the Voyager flybys, it became known that there are two similarly-sized moons (Epimetheus and Janus) in the same orbit, so there is some uncertainty about which one was the object of Pioneer's near-miss. "Pioneer 11" encountered Janus on September 1, 1979 at 14:52 UTC at a distance of 2500 km and Mimas at 16:20 UTC the same day at 103000 km.

Besides Epimetheus, instruments located another previously undiscovered small moon and an additional ring, charted Saturn's magnetosphere and magnetic field and found its planet-size moon, Titan, to be too cold for life. Hurtling underneath the ring plane, the probe sent back pictures of Saturn's rings. The rings, which normally seem bright when observed from Earth, appeared dark in the Pioneer pictures, and the dark gaps in the rings seen from Earth appeared as bright rings.

On February 23, 1990, Pioneer 11 became the 4th man-made object to pass beyond the orbit of the planets.

By 1995, Pioneer 11 could no longer power any of its detectors, so the decision was made to shut it down. On September 29, 1995, NASA's Ames Research Center, responsible for managing the project, issued a press release that began, "After nearly 22 years of exploration out to the farthest reaches of the Solar System, one of the most durable and productive space missions in history will come to a close." It indicated NASA would use its Deep Space Network antennas to listen "once or twice a month" for the spacecraft's signal, until "some time in late 1996" when "its transmitter will fall silent altogether." NASA Administrator Daniel Goldin characterized "Pioneer 11" as "the little spacecraft that could, a venerable explorer that has taught us a great deal about the Solar System and, in the end, about our own innate drive to learn. "Pioneer 11" is what NASA is all about – exploration beyond the frontier." Besides announcing the end of operations, the dispatch provided a historical list of "Pioneer 11" mission achievements. NASA terminated routine contact with the spacecraft on September 30, 1995, but continued to make contact for about 2 hours every 2 to 4 weeks. Scientists received a few minutes of good engineering data on 24 November 1995 but then lost final contact once Earth permanently moved out of view of the spacecraft's antenna. Its signal became too faint to hear in 2002.

On July 19, 2015, Pioneer 11 was from the Earth and from the Sun; and traveling at (relative to the Sun) and traveling outward at about 2.4 AU per year. The spacecraft is heading in the direction of the constellation Scutum near the current position (August 2017) RA 18h 50m dec -8° 39.5' (J2000.0) close to Messier 26.

"Pioneer 11" has now been overtaken by the two Voyager probes, launched in 1977, and "Voyager 1" is now the most distant object built by humans.

Analysis of the radio tracking data from the "Pioneer 10" and "11" spacecraft at distances between 20–70 AU from the Sun has consistently indicated the presence of a small but anomalous Doppler frequency drift. The drift can be interpreted as due to a constant acceleration of directed towards the Sun. Although it is suspected that there is a systematic origin to the effect, none was found. As a result, there is sustained interest in the nature of this so-called "Pioneer anomaly". Extended analysis of mission data by Slava Turyshev and colleagues has determined the source of the anomaly to be asymmetric thermal radiation and the resulting thermal recoil force acting on the face of the Pioneers away from the Sun, and in July 2012 the group of researchers published their results in the "Physical Review Letters" scientific journal.

"Pioneer 10" and "11" both carry a gold-anodized aluminum plaque in the event that either spacecraft is ever found by intelligent lifeforms from other planetary systems. The plaques feature the nude figures of a human male and female along with several symbols that are designed to provide information about the origin of the spacecraft.

In 1991, Pioneer 11 was honored on one of 10 United States Postage Service stamps commemorating unmanned spacecraft exploring each of the then nine planets and the Moon. Pioneer 11 was the spacecraft featured with Jupiter. Pluto was listed as "Not yet explored".



</doc>
<doc id="24982" url="https://en.wikipedia.org/wiki?curid=24982" title="Psychometrics">
Psychometrics

Psychometrics is a field of study concerned with the theory and technique of psychological measurement. As defined by the National Council on Measurement in Education (NCME), psychometrics refers to psychological measurement. Generally, it refers to the field in psychology and education that is devoted to testing, measurement, assessment, and related activities.

The field is concerned with the objective measurement of skills and knowledge, abilities, attitudes, personality traits, and educational achievement. Some psychometric researchers focus on the construction and validation of assessment instruments such as questionnaires, tests, raters' judgments, and personality tests. Others focus on research relating to measurement theory (e.g., item response theory; intraclass correlation).

Practitioners are described as psychometricians. Psychometricians usually possess a specific qualification, and most are psychologists with advanced graduate training. In addition to traditional academic institutions, many psychometricians work for the government or in human resources departments. Others specialize as learning and development professionals.

Psychological testing has come from two streams of thought: the first, from Darwin, Galton, and Cattell on the measurement of individual differences, and the second, from Herbart, Weber, Fechner, and Wundt and their psychophysical measurements of a similar construct. The second set of individuals and their research is what has led to the development of experimental psychology, and standardized testing.

Charles Darwin was the inspiration behind Sir Francis Galton who led to the creation of psychometrics. In 1859, Darwin published his book "The Origin of Species", which pertained to individual differences in animals. This book discussed how individual members in a species differ and how they possess characteristics that are more adaptive and successful or less adaptive and less successful. Those who are adaptive and successful are the ones that survive and give way to the next generation, who would be just as or more adaptive and successful. This idea, studied previously in animals, led to Galton's interest and study of human beings and how they differ one from another, and more importantly, how to measure those differences.

Galton wrote a book entitled "Hereditary Genius" about different characteristics that people possess and how those characteristics make them more "fit" than others. Today these differences, such as sensory and motor functioning (reaction time, visual acuity, and physical strength) are important domains of scientific psychology. Much of the early theoretical and applied work in psychometrics was undertaken in an attempt to measure intelligence. Galton, often referred to as "the father of psychometrics," devised and included mental tests among his anthropometric measures. James McKeen Cattell, who is considered a pioneer of psychometrics went on to extend Galton's work. Cattell also coined the term "mental test", and is responsible for the research and knowledge which ultimately led to the development of modern tests. (Kaplan & Saccuzzo, 2010)

The origin of psychometrics also has connections to the related field of psychophysics. Around the same time that Darwin, Galton, and Cattell were making their discoveries, Herbart was also interested in "unlocking the mysteries of human consciousness" through the scientific method. (Kaplan & Saccuzzo, 2010) Herbart was responsible for creating mathematical models of the mind, which were influential in educational practices in years to come.

E.H. Weber built upon Herbart's work and tried to prove the existence of a psychological threshold, saying that a minimum stimulus was necessary to activate a sensory system. After Weber, G.T. Fechner expanded upon the knowledge he gleaned from Herbart and Weber, to devise the law that the strength of a sensation grows as the logarithm of the stimulus intensity. A follower of Weber and Fechner, Wilhelm Wundt is credited with founding the science of psychology. It is Wundt's influence that paved the way for others to develop psychological testing.

The psychometrician L. L. Thurstone, founder and first president of the Psychometric Society in 1936, developed and applied a theoretical approach to measurement referred to as the law of comparative judgment, an approach that has close connections to the psychophysical theory of Ernst Heinrich Weber and Gustav Fechner. In addition, Spearman and Thurstone both made important contributions to the theory and application of factor analysis, a statistical method developed and used extensively in psychometrics. In the late 1950s, Leopold Szondi made an historical and epistemological assessment of the impact of statistical thinking onto psychology during previous few decades: "in the last decades, the specifically psychological thinking has been almost completely suppressed and removed, and replaced by a statistical thinking. Precisely here we see the cancer of testology and testomania of today."

More recently, psychometric theory has been applied in the measurement of personality, attitudes, and beliefs, and academic achievement. Measurement of these unobservable phenomena is difficult, and much of the research and accumulated science in this discipline has been developed in an attempt to properly define and quantify such phenomena. Critics, including practitioners in the physical sciences and social activists, have argued that such definition and quantification is impossibly difficult, and that such measurements are often misused, such as with psychometric personality tests used in employment procedures:

Figures who made significant contributions to psychometrics include Karl Pearson, Henry F. Kaiser, Carl Brigham, L. L. Thurstone, Anne Anastasi, Georg Rasch, Eugene Galanter, Johnson O'Connor, Frederic M. Lord, Ledyard R Tucker, Arthur Jensen, and David Andrich.

The definition of measurement in the social sciences has a long history. A currently widespread definition, proposed by Stanley Smith Stevens (1946), is that measurement is "the assignment of numerals to objects or events according to some rule." This definition was introduced in the paper in which Stevens proposed four levels of measurement. Although widely adopted, this definition differs in important respects from the more classical definition of measurement adopted in the physical sciences, namely that scientific measurement entails "the estimation or discovery of the ratio of some magnitude of a quantitative attribute to a unit of the same attribute" (p. 358)

Indeed, Stevens's definition of measurement was put forward in response to the British Ferguson Committee, whose chair, A. Ferguson, was a physicist. The committee was appointed in 1932 by the British Association for the Advancement of Science to investigate the possibility of quantitatively estimating sensory events. Although its chair and other members were physicists, the committee also included several psychologists. The committee's report highlighted the importance of the definition of measurement. While Stevens's response was to propose a new definition, which has had considerable influence in the field, this was by no means the only response to the report. Another, notably different, response was to accept the classical definition, as reflected in the following statement:

These divergent responses are reflected in alternative approaches to measurement. For example, methods based on covariance matrices are typically employed on the premise that numbers, such as raw scores derived from assessments, are measurements. Such approaches implicitly entail Stevens's definition of measurement, which requires only that numbers are "assigned" according to some rule. The main research task, then, is generally considered to be the discovery of associations between scores, and of factors posited to underlie such associations.

On the other hand, when measurement models such as the Rasch model are employed, numbers are not assigned based on a rule. Instead, in keeping with Reese's statement above, specific criteria for measurement are stated, and the goal is to construct procedures or operations that provide data that meet the relevant criteria. Measurements are estimated based on the models, and tests are conducted to ascertain whether the relevant criteria have been met.

The firstpsychometric instruments were designed to measure the concept of intelligence. One historical approach involved the Stanford-Binet IQ test, developed originally by the French psychologist Alfred Binet. Intelligence tests are useful tools for various purposes. An alternative conception of intelligence is that cognitive capacities within individuals are a manifestation of a general component, or general intelligence factor, as well as cognitive capacity specific to a given domain.

Psychometrics is applied widely in educational assessment to measure abilities in domains such as reading, writing, and mathematics. The main approaches in applying tests in these domains have been classical test theory and the more recent Item Response Theory and Rasch measurement models. These latter approaches permit joint scaling of persons and assessment items, which provides a basis for mapping of developmental continua by allowing descriptions of the skills displayed at various points along a continuum.

Another major focus in psychometrics has been on personality testing. There have been a range of theoretical approaches to conceptualizing and measuring personality. Some of the better known instruments include the Minnesota Multiphasic Personality Inventory, the Five-Factor Model (or "Big 5") and tools such as Personality and Preference Inventory and the Myers-Briggs Type Indicator. Attitudes have also been studied extensively using psychometric approaches. A common method in the measurement of attitudes is the use of the Likert scale. An alternative method involves the application of unfolding measurement models, the most general being the Hyperbolic Cosine Model (Andrich & Luo, 1993).

Psychometricians have developed a number of different measurement theories. These include classical test theory (CTT) and item response theory (IRT). An approach which seems mathematically to be similar to IRT but also quite distinctive, in terms of its origins and features, is represented by the Rasch model for measurement. The development of the Rasch model, and the broader class of models to which it belongs, was explicitly founded on requirements of measurement in the physical sciences.

Psychometricians have also developed methods for working with large matrices of correlations and covariances. Techniques in this general tradition include: factor analysis, a method of determining the underlying dimensions of data; multidimensional scaling, a method for finding a simple representation for data with a large number of latent dimensions; and data clustering, an approach to finding objects that are like each other. All these multivariate descriptive methods try to distill large amounts of data into simpler structures. More recently, structural equation modeling and path analysis represent more sophisticated approaches to working with large covariance matrices. These methods allow statistically sophisticated models to be fitted to data and tested to determine if they are adequate fits.

One of the main deficiencies in various factor analyses is a lack of consensus in cutting points for determining the number of latent factors. A usual procedure is to stop factoring when eigenvalues drop below one because the original sphere shrinks. The lack of the cutting points concerns other multivariate methods, also.

Key concepts in classical test theory are reliability and validity. A reliable measure is one that measures a construct consistently across time, individuals, and situations. A valid measure is one that measures what it is intended to measure. Reliability is necessary, but not sufficient, for validity.

Both reliability and validity can be assessed statistically. Consistency over repeated measures of the same test can be assessed with the Pearson correlation coefficient, and is often called "test-retest reliability." Similarly, the equivalence of different versions of the same measure can be indexed by a Pearson correlation, and is called "equivalent forms reliability" or a similar term.

Internal consistency, which addresses the homogeneity of a single test form, may be assessed by correlating performance on two halves of a test, which is termed "split-half reliability"; the value of this Pearson product-moment correlation coefficient for two half-tests is adjusted with the Spearman–Brown prediction formula to correspond to the correlation between two full-length tests. Perhaps the most commonly used index of reliability is Cronbach's α, which is equivalent to the mean of all possible split-half coefficients. Other approaches include the intra-class correlation, which is the ratio of variance of measurements of a given target to the variance of all targets.

There are a number of different forms of validity. Criterion-related validity can be assessed by correlating a measure with a criterion measure theoretically expected to be related. When the criterion measure is collected at the same time as the measure being validated the goal is to establish "concurrent validity"; when the criterion is collected later the goal is to establish "predictive validity". A measure has "construct validity" if it is related to measures of other constructs as required by theory. "Content validity" is a demonstration that the items of a test do an adequate job of covering the domain being measured. In a personnel selection example, test content is based on a defined statement or set of statements of knowledge, skill, ability, or other characteristics obtained from a "job analysis".

Item response theory models the relationship between latent traits and responses to test items. Among other advantages, IRT provides a basis for obtaining an estimate of the location of a test-taker on a given latent trait as well as the standard error of measurement of that location. For example, a university student's knowledge of history can be deduced from his or her score on a university test and then be compared reliably with a high school student's knowledge deduced from a less difficult test. Scores derived by classical test theory do not have this characteristic, and assessment of actual ability (rather than ability relative to other test-takers) must be assessed by comparing scores to those of a "norm group" randomly selected from the population. In fact, all measures derived from classical test theory are dependent on the sample tested, while, in principle, those derived from item response theory are not.

Many psychometricians are also concerned with finding and eliminating test bias from their psychological tests. Test bias is a form of systematic (i.e., non-random) error which leads to examinees from one demographic group having an unwarranted advantage over examinees from another demographic group. According to leading experts, test bias may cause differences in average scores across demographic groups, but differences in group scores are not sufficient evidence that test bias is actually present because the test could be measuring real differences among groups. Psychometricians use sophisticated scientific methods to search for test bias and eliminate it. Research shows that it is usually impossible for people reading a test item to accurately determine whether it is biased or not.

The considerations of validity and reliability typically are viewed as essential elements for determining the quality of any test. However, professional and practitioner associations frequently have placed these concerns within broader contexts when developing standards and making overall judgments about the quality of any test as a whole within a given context. A consideration of concern in many applied research settings is whether or not the metric of a given psychological inventory is meaningful or arbitrary.

In 2014, the American Educational Research Association (AERA), American Psychological Association (APA), and National Council on Measurement in Education (NCME) published a revision of the "Standards for Educational and Psychological Testing", which describes standards for test development, evaluation, and use. The "Standards" cover essential topics in testing including validity, reliability/errors of measurement, and fairness in testing. The book also establishes standards related to testing operations including test design and development, scores, scales, norms, score linking, cut scores, test administration, scoring, reporting, score interpretation, test documentation, and rights and responsibilities of test takers and test users. Finally, the "Standards" cover topics related to testing applications, including psychological testing and assessment, workplace testing and credentialing, educational testing and assessment, and testing in program evaluation and public policy.

In the field of evaluation, and in particular educational evaluation, the Joint Committee on Standards for Educational Evaluation has published three sets of standards for evaluations. "The Personnel Evaluation Standards" was published in 1988, "The Program Evaluation Standards" (2nd edition) was published in 1994, and "The Student Evaluation Standards" was published in 2003.

Each publication presents and elaborates a set of standards for use in a variety of educational settings. The standards provide guidelines for designing, implementing, assessing and improving the identified form of evaluation. Each of the standards has been placed in one of four fundamental categories to promote educational evaluations that are proper, useful, feasible, and accurate. In these sets of standards, validity and reliability considerations are covered under the accuracy topic. For example, the student accuracy standards help ensure that student evaluations will provide sound, accurate, and credible information about student learning and performance.

Psychometrics addresses "human" abilities, attitudes, traits and educational evolution. Notably, the study of behavior, mental processes and abilities of non-human "animals" is usually addressed by comparative psychology, or with a continuum between non-human animals and the rest of animals by evolutionary psychology. Nonetheless there are some advocators for a more gradual transition between the approach taken for humans and the approach taken for (non-human) animals.
The evaluation of abilities, traits and learning evolution of "machines" has been mostly unrelated to the case of humans and non-human animals, with specific approaches in the area of artificial intelligence. A more integrated approach, under the name of universal psychometrics, has also been proposed.





</doc>
<doc id="24983" url="https://en.wikipedia.org/wiki?curid=24983" title="Philosophy of education">
Philosophy of education

Philosophy of education can refer either to the application of philosophy to the problem of education, examining definitions, goals and chains of meaning used in education by teachers, administrators or policymakers. It can involve the examination of particular visions or approaches by researchers and policy-makers in education that often address contemporary debates and assumptions about innovations and practices in teaching and learning by considering the profession within broader philosophical or sociocultural contexts.
As an academic field, study involves "the philosophical study of education and its problems...its central subject matter is education, and its methods are those of philosophy". "The philosophy of education may be either the philosophy of the process of education or the philosophy of the discipline of education. That is, it may be part of the discipline in the sense of being concerned with the aims, forms, methods, or results of the process of educating or being educated; or it may be metadisciplinary in the sense of being concerned with the concepts, aims, and methods of the discipline." As such, it is both part of the field of education and a field of applied philosophy, drawing from fields of metaphysics, epistemology, axiology and the philosophical approaches (speculative, prescriptive, or analytic) to address questions in and about pedagogy, education policy, and curriculum, as well as the process of learning, to name a few. For example, it might study what constitutes upbringing and education, the values and norms revealed through upbringing and educational practices, the limits and legitimization of education as an academic discipline, and the relation between educational theory and practice. One application is Transactionalism which seeks to avoid the risks of simplifying complexity in teaching and learning any subject.

Instead of being taught in philosophy departments, philosophy of education is usually housed in departments or colleges of education, similar to how philosophy of law is generally taught in law schools. The multiple ways of conceiving education coupled with the multiple fields and approaches of philosophy make philosophy of education not only a very diverse field but also one that is not easily defined. Although there is overlap, philosophy of education should not be conflated with educational theory, which is not defined specifically by the application of philosophy to questions in education. Philosophy of education also should not be confused with philosophy education, the practice of teaching and learning the subject of philosophy.

Philosophy of education can also be understood not as an academic discipline but as a normative educational theory that unifies pedagogy, curriculum, learning theory, and the purpose of education and is grounded in specific metaphysical, epistemological, and axiological assumptions. These theories are also called educational philosophies. For example, a teacher might be said to follow a perennialist educational philosophy or to follow a perennialist philosophy of education.

Date: 424/423 BC – 348/347 BC

Plato's educational philosophy was grounded in a vision of an ideal "Republic" wherein the individual was best served by being subordinated to a just society due to a shift in emphasis that departed from his predecessors. The mind and body were to be considered separate entities. In the dialogues of Phaedo, written in his "middle period" (360 B.C.E.) Plato expressed his distinctive views about the nature of knowledge, reality, and the soul:When the soul and body are united, then nature orders the soul to rule and govern, and the body to obey and serve. Now which of these two functions is akin to the divine? and which to the mortal? Does not the divine appear…to be that which naturally orders and rules, and the mortal to be that which is subject and servant?On this premise, Plato advocated removing children from their mothers' care and raising them as wards of the state, with great care being taken to differentiate children suitable to the various castes, the highest receiving the most education, so that they could act as guardians of the city and care for the less able. Education would be holistic, including facts, skills, physical discipline, and music and art, which he considered the highest form of endeavor.

Plato believed that talent was distributed non-genetically and thus must be found in children born in any social class. He built on this by insisting that those suitably gifted were to be trained by the state so that they might be qualified to assume the role of a ruling class. What this established was essentially a system of selective public education premised on the assumption that an educated minority of the population were, by virtue of their education (and inborn educability), sufficient for healthy governance.

Plato's writings contain some of the following ideas:
Elementary education would be confined to the guardian class till the age of 18, followed by two years of compulsory military training and then by higher education for those who qualified. While elementary education made the soul responsive to the environment, higher education helped the soul to search for truth which illuminated it. Both boys and girls receive the same kind of education. Elementary education consisted of music and gymnastics, designed to train and blend gentle and fierce qualities in the individual and create a harmonious person.

At the age of 20, a selection was made. The best students would take an advanced course in mathematics, geometry, astronomy and harmonics. The first course in the scheme of higher education would last for ten years. It would be for those who had a flair for science. At the age of 30 there would be another selection; those who qualified would study dialectics and metaphysics, logic and philosophy for the next five years. After accepting junior positions in the army for 15 years, a man would have completed his theoretical and practical education by the age of 50.

Date: 1724–1804

Immanuel Kant believed that education differs from training in that the former involves thinking whereas the latter does not. In addition to educating reason, of central importance to him was the development of character and teaching of moral maxims. Kant was a proponent of public education and of learning by doing.

Date: 1770–1831

Date: 384 BC – 322 BC

Only fragments of Aristotle's treatise "On Education" are still in existence. We thus know of his philosophy of education primarily through brief passages in other works. Aristotle considered human nature, habit and reason to be equally important forces to be cultivated in education. Thus, for example, he considered repetition to be a key tool to develop good habits. The teacher was to lead the student systematically; this differs, for example, from Socrates' emphasis on questioning his listeners to bring out their own ideas (though the comparison is perhaps incongruous since Socrates was dealing with adults).

Aristotle placed great emphasis on balancing the theoretical and practical aspects of subjects taught. Subjects he explicitly mentions as being important included reading, writing and mathematics; music; physical education; literature and history; and a wide range of sciences. He also mentioned the importance of play.

One of education's primary missions for Aristotle, perhaps its most important, was to produce good and virtuous citizens for the polis. "All who have meditated on the art of governing mankind have been convinced that the fate of empires depends on the education of youth."

Date: 980 AD – 1037 AD

In the medieval Islamic world, an elementary school was known as a "maktab", which dates back to at least the 10th century. Like madrasahs (which referred to higher education), a maktab was often attached to a mosque. In the 11th century, Ibn Sina (known as "Avicenna" in the West), wrote a chapter dealing with the "maktab" entitled "The Role of the Teacher in the Training and Upbringing of Children", as a guide to teachers working at "maktab" schools. He wrote that children can learn better if taught in classes instead of individual tuition from private tutors, and he gave a number of reasons for why this is the case, citing the value of competition and emulation among pupils as well as the usefulness of group discussions and debates. Ibn Sina described the curriculum of a "maktab" school in some detail, describing the curricula for two stages of education in a "maktab" school.

Ibn Sina wrote that children should be sent to a "maktab" school from the age of 6 and be taught primary education until they reach the age of 14. During which time, he wrote that they should be taught the Qur'an, Islamic metaphysics, language, literature, Islamic ethics, and manual skills (which could refer to a variety of practical skills).

Ibn Sina refers to the secondary education stage of "maktab" schooling as the period of specialization, when pupils should begin to acquire manual skills, regardless of their social status. He writes that children after the age of 14 should be given a choice to choose and specialize in subjects they have an interest in, whether it was reading, manual skills, literature, preaching, medicine, geometry, trade and commerce, craftsmanship, or any other subject or profession they would be interested in pursuing for a future career. He wrote that this was a transitional stage and that there needs to be flexibility regarding the age in which pupils graduate, as the student's emotional development and chosen subjects need to be taken into account.

The empiricist theory of 'tabula rasa' was also developed by Ibn Sina. He argued that the "human intellect at birth is rather like a "tabula rasa", a pure potentiality that is actualized through education and comes to know" and that knowledge is attained through "empirical familiarity with objects in this world from which one abstracts universal concepts" which is developed through a "syllogistic method of reasoning; observations lead to prepositional statements, which when compounded lead to further abstract concepts." He further argued that the intellect itself "possesses levels of development from the material intellect ("al-‘aql al-hayulani"), that potentiality that can acquire knowledge to the active intellect ("al-‘aql al-fa‘il"), the state of the human intellect in conjunction with the perfect source of knowledge."

Date: c. 1105 – 1185

In the 12th century, the Andalusian-Arabian philosopher and novelist Ibn Tufail (known as "Abubacer" or "Ebn Tophail" in the West) demonstrated the empiricist theory of 'tabula rasa' as a thought experiment through his Arabic philosophical novel, "Hayy ibn Yaqzan", in which he depicted the development of the mind of a feral child "from a tabula rasa to that of an adult, in complete isolation from society" on a desert island, through experience alone. The Latin translation of his philosophical novel, "Philosophus Autodidactus", published by Edward Pococke the Younger in 1671, had an influence on John Locke's formulation of tabula rasa in "An Essay Concerning Human Understanding".

Date: 1632–1704

In "Some Thoughts Concerning Education" and "Of the Conduct of the Understanding" Locke composed an outline on how to educate this mind in order to increase its powers and activity:

"The business of education is not, as I think, to make them perfect in any one of the sciences, but so to open and dispose their minds as may best make them capable of any, when they shall apply themselves to it."

"If men are for a long time accustomed only to one sort or method of thoughts, their minds grow stiff in it, and do not readily turn to another. It is therefore to give them this freedom, that I think they should be made to look into all sorts of knowledge, and exercise their understandings in so wide a variety and stock of knowledge. But I do not propose it as a variety and stock of knowledge, but a variety and freedom of thinking, as an increase of the powers and activity of the mind, not as an enlargement of its possessions." 

Locke expressed the belief that education maketh the man, or, more fundamentally, that the mind is an "empty cabinet", with the statement, "I think I may say that of all the men we meet with, nine parts of ten are what they are, good or evil, useful or not, by their education."

Locke also wrote that "the little and almost insensible impressions on our tender infancies have very important and lasting consequences." He argued that the "associations of ideas" that one makes when young are more important than those made later because they are the foundation of the self: they are, put differently, what first mark the "tabula rasa". In his "Essay", in which is introduced both of these concepts, Locke warns against, for example, letting "a foolish maid" convince a child that "goblins and sprites" are associated with the night for "darkness shall ever afterwards bring with it those frightful ideas, and they shall be so joined, that he can no more bear the one than the other."

"Associationism", as this theory would come to be called, exerted a powerful influence over eighteenth-century thought, particularly educational theory, as nearly every educational writer warned parents not to allow their children to develop negative associations. It also led to the development of psychology and other new disciplines with David Hartley's attempt to discover a biological mechanism for associationism in his "Observations on Man" (1749).

Date: 1712–1778

Rousseau, though he paid his respects to Plato's philosophy, rejected it as impractical due to the decayed state of society. Rousseau also had a different theory of human development; where Plato held that people are born with skills appropriate to different castes (though he did not regard these skills as being inherited), Rousseau held that there was one developmental process common to all humans. This was an intrinsic, natural process, of which the primary behavioral manifestation was curiosity. This differed from Locke's 'tabula rasa' in that it was an active process deriving from the child's nature, which drove the child to learn and adapt to its surroundings.

Rousseau wrote in his book "" that all children are perfectly designed organisms, ready to learn from their surroundings so as to grow into virtuous adults, but due to the malign influence of corrupt society, they often fail to do so. Rousseau advocated an educational method which consisted of removing the child from society—for example, to a country home—and alternately conditioning him through changes to his environment and setting traps and puzzles for him to solve or overcome.

Rousseau was unusual in that he recognized and addressed the potential of a problem of legitimation for teaching. He advocated that adults always be truthful with children, and in particular that they never hide the fact that the basis for their authority in teaching was purely one of physical coercion: "I'm bigger than you." Once children reached the age of reason, at about 12, they would be engaged as free individuals in the ongoing process of their own.

He once said that a child should grow up without adult interference and that the child must be guided to suffer from the experience of the natural consequences of his own acts or behaviour. When he experiences the consequences of his own acts, he advises himself.

"Rousseau divides development into five stages (a book is devoted to each). Education in the first two stages seeks to the senses: only when Émile is about 12 does the tutor begin to work to develop his mind. Later, in Book 5, Rousseau examines the education of Sophie (whom Émile is to marry). Here he sets out what he sees as the essential differences that flow from sex. 'The man should be strong and active; the woman should be weak and passive' (Everyman edn: 322). From this difference comes a contrasting education. They are not to be brought up in ignorance and kept to housework: Nature means them to think, to will, to love to cultivate their minds as well as their persons; she puts these weapons in their hands to make up for their lack of strength and to enable them to direct the strength of men. They should learn many things, but only such things as suitable' (Everyman edn.: 327)."
Émile

Date: 1902–2001

Mortimer Jerome Adler was an American philosopher, educator, and popular author. As a philosopher he worked within the Aristotelian and Thomistic traditions. He lived for the longest stretches in New York City, Chicago, San Francisco, and San Mateo, California. He worked for Columbia University, the University of Chicago, Encyclopædia Britannica, and Adler's own Institute for Philosophical Research. Adler was married twice and had four children. Adler was a proponent of educational perennialism.

Date: 1905–1998

Broudy's philosophical views were based on the tradition of classical realism, dealing with truth, goodness, and beauty. However he was also influenced by the modern philosophy existentialism and instrumentalism. In his textbook Building a Philosophy of Education he has two major ideas that are the main points to his philosophical outlook: The first is truth and the second is universal structures to be found in humanity's struggle for education and the good life. Broudy also studied issues on society's demands on school. He thought education would be a link to unify the diverse society and urged the society to put more trust and a commitment to the schools and a good education.

Date: c. 1225 – 1274

See Religious perennialism.

Date: 1608–1674

The objective of medieval education was an overtly religious one, primarily concerned with uncovering transcendental truths that would lead a person back to God through a life of moral and religious choice (Kreeft 15). The vehicle by which these truths were uncovered was dialectic:

To the medieval mind, debate was a fine art, a serious science, and a fascinating entertainment, much more than it is to the modern mind, because the medievals believed, like Socrates, that dialectic could uncover truth. Thus a 'scholastic disputation' was not a personal contest in cleverness, nor was it 'sharing opinions'; it was a shared journey of discovery (Kreeft 14–15).

Date: 1859–1952

In "Democracy and Education: An Introduction to the Philosophy of Education", Dewey stated that education, in its broadest sense, is the means of the "social continuity of life" given the "primary ineluctable facts of the birth and death of each one of the constituent members in a social group". Education is therefore a necessity, for "the life of the group goes on." Dewey was a proponent of Educational Progressivism and was a relentless campaigner for reform of education, pointing out that the authoritarian, strict, pre-ordained knowledge approach of modern traditional education was too concerned with delivering knowledge, and not enough with understanding students' actual experiences.

Date: 1842–1910

Date: 1871–1965

William Heard Kilpatrick was a US American philosopher of education and a colleague and a successor of John Dewey. He was a major figure in the progressive education movement of the early 20th century. Kilpatrick developed the Project Method for early childhood education, which was a form of Progressive Education organized curriculum and classroom activities around a subject's central theme. He believed that the role of a teacher should be that of a "guide" as opposed to an authoritarian figure. Kilpatrick believed that children should direct their own learning according to their interests and should be allowed to explore their environment, experiencing their learning through the natural senses. Proponents of Progressive Education and the Project Method reject traditional schooling that focuses on memorization, rote learning, strictly organized classrooms (desks in rows; students always seated), and typical forms of assessment.

Date: 1929–

Noddings' first sole-authored book "Caring: A Feminine Approach to Ethics and Moral Education" (1984) followed close on the 1982 publication of Carol Gilligan’s ground-breaking work in the ethics of care "In a Different Voice". While her work on ethics continued, with the publication of "Women and Evil" (1989) and later works on moral education, most of her later publications have been on the philosophy of education and educational theory. Her most significant works in these areas have been "Educating for Intelligent Belief or Unbelief" (1993) and "Philosophy of Education" (1995).

Date: 1931–2007

G.E Moore (1873–1858)

Bertrand Russell (1872–1970)

Gottlob Frege (1848–1925)

Date: 1919–

The existentialist sees the world as one's personal subjectivity, where goodness, truth, and reality are individually defined. Reality is a world of existing, truth subjectively chosen, and goodness a matter of freedom. The subject matter of existentialist classrooms should be a matter of personal choice. Teachers view the individual as an entity within a social context in which the learner must confront others' views to clarify his or her own. Character development emphasizes individual responsibility for decisions. Real answers come from within the individual, not from outside authority. Examining life through authentic thinking involves students in genuine learning experiences. Existentialists are opposed to thinking about students as objects to be measured, tracked, or standardized. Such educators want the educational experience to focus on creating opportunities for self-direction and self-actualization. They start with the student, rather than on curriculum content.

Date: 1921–1997

A Brazilian philosopher and educator committed to the cause of educating the impoverished peasants of his nation and collaborating with them in the pursuit of their liberation from what he regarded as "oppression," Freire is best known for his attack on what he called the "banking concept of education," in which the student was viewed as an empty account to be filled by the teacher. Freire also suggests that a deep reciprocity be inserted into our notions of teacher and student; he comes close to suggesting that the teacher-student dichotomy be completely abolished, instead promoting the roles of the participants in the classroom as the teacher-student (a teacher who learns) and the student-teacher (a learner who teaches). In its early, strong form this kind of classroom has sometimes been criticized on the grounds that it can mask rather than overcome the teacher's authority.

Aspects of the Freirian philosophy have been highly influential in academic debates over "participatory development" and development more generally. Freire's emphasis on what he describes as "emancipation" through interactive participation has been used as a rationale for the participatory focus of development, as it is held that 'participation' in any form can lead to empowerment of poor or marginalised groups. Freire was a proponent of critical pedagogy.
"He participated in the import of European doctrines and ideas into Brazil,
assimilated them to the needs of a specific socio-economic situation, and thus expanded and
refocused them in a thought-provoking way"

Date: 1889–1976

Heidegger's philosophizing about education was primarily related to higher education. He believed that teaching and research in the university should be unified and aim towards testing and interrogating the "ontological assumptions presuppositions which implicitly guide research in each domain of knowledge."

Date: 1900–2002

Date: 1924–1998

Date: 1926–1984

"Normative philosophies or theories of education may make use of the results of philosophical thought and of factual inquiries about human beings and the psychology of learning, but in any case they propound views about what education should be, what dispositions it should cultivate, why it ought to cultivate them, how and in whom it should do so, and what forms it should take. In a full-fledged philosophical normative theory of education, besides analysis of the sorts described, there will normally be propositions of the following kinds:

Perennialists believe that one should teach the things that one deems to be of everlasting importance to all people everywhere. They believe that the most important topics develop a person. Since details of fact change constantly, these cannot be the most important. Therefore, one should teach principles, not facts. Since people are human, one should teach first about humans, not machines or techniques. Since people are people first, and workers second if at all, one should teach liberal topics first, not vocational topics. The focus is primarily on teaching reasoning and wisdom rather than facts, the liberal arts rather than vocational training.

Date: 1930–1992

Bloom, a professor of political science at the University of Chicago, argued for a traditional Great Books-based liberal education in his lengthy essay "The Closing of the American Mind".

The Classical education movement advocates a form of education based in the traditions of Western culture, with a particular focus on education as understood and taught in the Middle Ages. The term "classical education" has been used in English for several centuries, with each era modifying the definition and adding its own selection of topics. By the end of the 18th century, in addition to the trivium and quadrivium of the Middle Ages, the definition of a classical education embraced study of literature, poetry, drama, philosophy, history, art, and languages. In the 20th and 21st centuries it is used to refer to a broad-based study of the liberal arts and sciences, as opposed to a practical or pre-professional program. Classical Education can be described as rigorous and systematic, separating children and their learning into three rigid categories, Grammar, Dialectic, and Rhetoric.

Date: 1842–1923

Mason was a British educator who invested her life in improving the quality of children's education. Her ideas led to a method used by some homeschoolers. Mason's philosophy of education is probably best summarized by the principles given at the beginning of each of her books. Two key mottos taken from those principles are "Education is an atmosphere, a discipline, a life" and "Education is the science of relations." She believed that children were born persons and should be respected as such; they should also be taught the Way of the Will and the Way of Reason. Her motto for students was "I am, I can, I ought, I will." Charlotte Mason believed that children should be introduced to subjects through living books, not through the use of "compendiums, abstracts, or selections." She used abridged books only when the content was deemed inappropriate for children. She preferred that parents or teachers read aloud those texts (such as Plutarch and the Old Testament), making omissions only where necessary.

Educational essentialism is an educational philosophy whose adherents believe that children should learn the traditional basic subjects and that these should be learned thoroughly and rigorously. An essentialist program normally teaches children progressively, from less complex skills to more complex.

Date: 1874–1946

William Chandler Bagley taught in elementary schools before becoming a professor of education at the University of Illinois, where he served as the Director of the School of Education from 1908 until 1917. He was a professor of education at Teachers College, Columbia, from 1917 to 1940. An opponent of pragmatism and progressive education, Bagley insisted on the value of knowledge for its own sake, not merely as an instrument, and he criticized his colleagues for their failure to emphasize systematic study of academic subjects. Bagley was a proponent of educational essentialism.

Critical pedagogy is an "educational movement, guided by passion and principle, to help students develop consciousness of freedom, recognize authoritarian tendencies, and connect knowledge to power and the ability to take constructive action." Based in Marxist theory, critical pedagogy draws on radical democracy, anarchism, feminism, and other movements for social justice.

Date: 1889–1974

Date: 1870–1952

The Montessori method arose from Dr. Maria Montessori's discovery of what she referred to as "the child's true normal nature" in 1907, which happened in the process of her experimental observation of young children given freedom in an environment prepared with materials designed for their self-directed learning activity. The method itself aims to duplicate this experimental observation of children to bring about, sustain and support their true natural way of being.

Waldorf education (also known as Steiner or Steiner-Waldorf education) is a humanistic approach to pedagogy based upon the educational philosophy of the Austrian philosopher Rudolf Steiner, the founder of anthroposophy. Learning is interdisciplinary, integrating practical, artistic, and conceptual elements. The approach emphasizes the role of the imagination in learning, developing thinking that includes a creative as well as an analytic component. The educational philosophy's overarching goals are to provide young people the basis on which to develop into free, morally responsible and integrated individuals, and to help every child fulfill his or her unique destiny, the existence of which anthroposophy posits. Schools and teachers are given considerable freedom to define curricula within collegial structures.

Date: 1861–1925

Steiner founded a holistic educational impulse on the basis of his spiritual philosophy (anthroposophy). Now known as Steiner or Waldorf education, his pedagogy emphasizes a balanced development of cognitive, affective/artistic, and practical skills (head, heart, and hands). Schools are normally self-administered by faculty; emphasis is placed upon giving individual teachers the freedom to develop creative methods.

Steiner's theory of child development divides education into three discrete developmental stages predating but with close similarities to the stages of development described by Piaget. Early childhood education occurs through imitation; teachers provide practical activities and a healthy environment. Steiner believed that young children should meet only goodness. Elementary education is strongly arts-based, centered on the teacher's creative authority; the elementary school-age child should meet beauty. Secondary education seeks to develop the judgment, intellect, and practical idealism; the adolescent should meet truth.

Democratic education is a theory of learning and school governance in which students and staff participate freely and equally in a school democracy. In a democratic school, there is typically shared decision-making among students and staff on matters concerning living, working, and learning together.

Date: 1883–1973

Neill founded Summerhill School, the oldest existing democratic school in Suffolk, England in 1921. He wrote a number of books that now define much of contemporary democratic education philosophy. Neill believed that the happiness of the child should be the paramount consideration in decisions about the child's upbringing, and that this happiness grew from a sense of personal freedom. He felt that deprivation of this sense of freedom during childhood, and the consequent unhappiness experienced by the repressed child, was responsible for many of the psychological disorders of adulthood.

Educational progressivism is the belief that education must be based on the principle that humans are social animals who learn best in real-life activities with other people. Progressivists, like proponents of most educational theories, claim to rely on the best available scientific theories of learning. Most progressive educators believe that children learn as if they were scientists, following a process similar to John Dewey's model of learning known as "the pattern of inquiry": 1) Become aware of the problem. 2) Define the problem. 3) Propose hypotheses to solve it. 4) Evaluate the consequences of the hypotheses from one's past experience. 5) Test the likeliest solution.

Date: 1859–1952

In 1896, Dewey opened the Laboratory School at the University of Chicago in an institutional effort to pursue together rather than apart "utility and culture, absorption and expression, theory and practice, [which] are [indispensable] elements in any educational scheme. As the unified head of the departments of Philosophy, Psychology and Pedagogy, John Dewey articulated a desire to organize an educational experience where children could be more creative than the best of progressive models of his day. Transactionalism as a pragmatic philosophy grew out of the work he did in the Laboratory School. The two most influential works that stemmed from his research and study were "The Child and the Curriculum" (1902) and "Democracy and Education" (1916). Dewey wrote of the dualisms that plagued educational philosophy in the latter book: "Instead of seeing the educative process steadily and as a whole, we see conflicting terms. We get the case of the child vs. the curriculum; of the individual nature vs. social culture." Dewey found that the preoccupation with facts as knowledge in the educative process led students to memorize "ill-understood rules and principles" and while second-hand knowledge learned in mere words is a beginning in study, mere words can never replace the ability to organize knowledge into both useful and valuable experience.

Date: 1896–1980

Jean Piaget was a Swiss developmental psychologist known for his epistemological studies with children. His theory of cognitive development and epistemological view are together called "genetic epistemology". Piaget placed great importance on the education of children. As the Director of the International Bureau of Education, he declared in 1934 that "only education is capable of saving our societies from possible collapse, whether violent, or gradual." Piaget created the International Centre for Genetic Epistemology in Geneva in 1955 and directed it until 1980. According to Ernst von Glasersfeld, Jean Piaget is "the great pioneer of the constructivist theory of knowing."

Jean Piaget described himself as an epistemologist, interested in the process of the qualitative development of knowledge. As he says in the introduction of his book "Genetic Epistemology" (): ""What the genetic epistemology proposes is discovering the roots of the different varieties of knowledge, since its elementary forms, following to the next levels, including also the scientific knowledge.""

Date: 1915–2016

Another important contributor to the inquiry method in education is Bruner. His books "The Process of Education" and "Toward a Theory of Instruction" are landmarks in conceptualizing learning and curriculum development. He argued that any subject can be taught in some intellectually honest form to any child at any stage of development. This notion was an underpinning for his concept of the "spiral" (helical) curriculum which posited the idea that a curriculum should revisit basic ideas, building on them until the student had grasped the full formal concept. He emphasized intuition as a neglected but essential feature of productive thinking. He felt that interest in the material being learned was the best stimulus for learning rather than external motivation such as grades. Bruner developed the concept of discovery learning which promoted learning as a process of constructing new ideas based on current or past knowledge. Students are encouraged to discover facts and relationships and continually build on what they already know.

Unschooling is a range of educational philosophies and practices centered on allowing children to learn through their natural life experiences, including child directed play, game play, household responsibilities, work experience, and social interaction, rather than through a more traditional school curriculum. Unschooling encourages exploration of activities led by the children themselves, facilitated by the adults. Unschooling differs from conventional schooling principally in the thesis that standard curricula and conventional grading methods, as well as other features of traditional schooling, are counterproductive to the goal of maximizing the education of each child.

In 1964 Holt published his first book, "How Children Fail", asserting that the academic failure of schoolchildren was not "despite" the efforts of the schools, but actually "because" of the schools. Not surprisingly, "How Children Fail" ignited a firestorm of controversy. Holt was catapulted into the American national consciousness to the extent that he made appearances on major TV talk shows, wrote book reviews for "Life" magazine, and was a guest on the "To Tell The Truth" TV game show. In his follow-up work, "How Children Learn", published in 1967, Holt tried to elucidate the learning process of children and why he believed school short circuits that process.

Contemplative education focuses on bringing introspective practices such as mindfulness and yoga into curricular and pedagogical processes for diverse aims grounded in secular, spiritual, religious and post-secular perspectives. Contemplative approaches may be used in the classroom, especially in tertiary or (often in modified form) in secondary education. Parker Palmer is a recent pioneer in contemplative methods. The Center for Contemplative Mind in Society founded a branch focusing on education, The Association for Contemplative Mind in Higher Education.

Contemplative methods may also be used by teachers in their preparation; Waldorf education was one of the pioneers of the latter approach. In this case, inspiration for enriching the content, format, or teaching methods may be sought through various practices, such as consciously reviewing the previous day's activities; actively holding the students in consciousness; and contemplating inspiring pedagogical texts. Zigler suggested that only through focusing on their own spiritual development could teachers positively impact the spiritual development of students.





</doc>
<doc id="24984" url="https://en.wikipedia.org/wiki?curid=24984" title="Personality psychology">
Personality psychology

Personality psychology is a branch of psychology that studies personality and its variation among individuals. It is a scientific study which aims to show how people are individually different due to psychological forces. Its areas of focus include:


"Personality" is a dynamic and organized set of characteristics possessed by a person that uniquely influences their environment, cognitions, emotions, motivations, and behaviors in various situations. The word "personality" originates from the Latin "persona", which means mask.

Personality also refers to the pattern of thoughts, feelings, social adjustments, and behaviors consistently exhibited over time that strongly influences one's expectations, self-perceptions, values, and attitudes. Personality also predicts human reactions to other people, problems, and stress. Gordon Allport (1937) described two major ways to study personality: the nomothetic and the idiographic. "Nomothetic psychology" seeks general laws that can be applied to many different people, such as the principle of self-actualization or the trait of extraversion. "Idiographic psychology" is an attempt to understand the unique aspects of a particular individual.

The study of personality has a broad and varied history in psychology with an abundance of theoretical traditions. The major theories include dispositional (trait) perspective, psychodynamic, humanistic, biological, behaviorist, evolutionary, and social learning perspective. However, many researchers and psychologists do not explicitly identify themselves with a certain perspective and instead take an eclectic approach. Research in this area is empirically driven, such as dimensional models, based on multivariate statistics, such as factor analysis, or emphasizes theory development, such as that of the psychodynamic theory. There is also a substantial emphasis on the applied field of personality testing. In psychological education and training, the study of the nature of personality and its psychological development is usually reviewed as a prerequisite to courses in abnormal psychology or clinical psychology.

Many of the ideas developed by historical and modern personality theorists stem from the basic philosophical assumptions they hold. The study of personality is not a purely empirical discipline, as it brings in elements of art, science, and philosophy to draw general conclusions. The following five categories are some of the most fundamental philosophical assumptions on which theorists disagree:


The study of personality is based on the essential insight that all people are similar in some ways, yet different in others. There have been many different definitions of personality proposed. However, many contemporary psychologists agree on the following defias differentiating the HEXACO model from other personality frameworks. Specifically, the H factor is described as sincere, honest, faithful/loyal, modest/unassuming, fair-minded, "VERSUS" sly, deceitful, greedy, pretentious, hypocritical, boastful, and pompous. The H factor has been linked to criminal, materialistic, power-seeking, and unethical tendencies.

Trait models have been criticized as being purely descriptive and offering little explanation of the underlying causes of personality. Eysenck's theory, however, proposes biological mechanisms as driving traits, and modern behavior genetics researchers have shown a clear genetic substrate to them. Another potential weakness of trait theories is that they may lead some people to accept oversimplified classifications—or worse, offer advice—based on a superficial analysis of personality. Finally, trait models often underestimate the effect of specific situations on people's behavior. Traits are considered to be statistical generalizations that do not always correspond to an individual's behavior.

The importance that genetic influences have on personality characteristics can change across a five-year period. Age differences create more variables even within a family, so the best comparisons are found using twins. Twins typically share a family environment called a shared environment because they may share other aspects like teachers, school, and friends. A non-shared environment means completely different environment for both subjects. "Biologically related children who are separated after birth and raised in different families live in non-shared environments." Identical twins separated at birth and raised in different families constitute the best cases for heredity and personality because similarities between the two are due only to genetic influences. Vulnerability was a factor in this study that was taken into consideration regarding the issue of genetic influences on vulnerability. The study concluded that the monozygotic co-twins would be more similar than dizygotic co-twins in change over time. The data concluded that there were no significant differences for either variances between the monozygotic and dizygotic co-twins.

Another current open question is whether genetic influences are important for the likeliness of co-twins to change in the same way over a period of time. A link was found between the personality trait of neuroticism and a polymorphism called 5-HTTLPR in the serotonin transporter gene, but this association was not replicated in larger studies. Other candidate gene studies have provided weak evidence that some personality traits are related to "AVPR1A" ("ruthlessness gene") and "MAOA" ("Warrior gene"). Genotypes, or the genetic make up of an organism, influence but don't fully decide the physical traits of a person. Those are also influenced by the environment and behaviors they are surrounded by. For example, a person's height is affected by genetics, but if they are malnourished growth will be stunted no matter what their genetic coding says. Environment is also not completely responsible for an outcome in personality. An example from "Psychobiology of Personality" by Marvin Zuckerman is alcoholism: Studies suggest that alcoholism is an inherited disease, but if a subject with a strong biological background of alcoholism in their family tree is never exposed to alcohol, they will not be so inclined regardless of their genome.

It is also a question open to debate whether there are genetic influences on the tendency of the "co-twins to change, without keeping in mind the direction of the change. Another factor that can be addressed is biological versus adoptive relatives and can be clearly seen in what is a real-life experiment: adoption. This creates two groups: genetic relatives (biological parents and siblings) and environmental relatives (adoptive parents and siblings). After studying hundreds of adoptive families, researchers discovered that people who grow up together, whether biologically related or not, do not much resemble one another in personality. In characteristics such as extroversion and agreeableness, adoptees are more like their biological parents than their adoptive parents. However, the minute shared-environment effects do not mean that adoptive parenting is ineffective. Even though genetics may limit the family environment's influence on personality, parents do influence their children's attitudes, values, faith, manners, and politics. In adoptive homes, child neglect and abuse and even divorce between the parents is uncommon. This noted it is not surprising, despite a somewhat greater risk of psychological disorder, that most adopted children excel, especially when they are adopted as infants. In fact, seven out of eight have reported feeling a strong connection with one or even both of their adoptive parents.
Personality type refers to the psychological classification of different types of people. Personality types are distinguished from personality traits, which come in different degrees. There are many types of theories regarding personality, but each theory contains several and sometimes many sub theories. A "theory of personality" constructed by any given psychologist will contain multiple relating theories or sub theories often expanding as more psychologist explore the theory. For example, according to type theories, there are two types of people, introverts and extroverts. According to trait theories, introversion and extroversion are part of a continuous dimension with many people in the middle. The idea of psychological types originated in the theoretical work of Carl Jung, specifically in his 1921 book "Psychologische Typen" ("Psychological Types") and William Marston.

Building on the writings and observations of Jung during World War II, Isabel Briggs Myers and her mother, Katharine C. Briggs, delineated personality types by constructing the Myers–Briggs Type Indicator. This model was later used by David Keirsey with a different understanding from Jung, Briggs and Myers. In the former Soviet Union, Lithuanian Aušra Augustinavičiūtė independently derived a model of personality type from Jung's called socionics.

Theories could also be considered an "approach" to personality or psychology and is generally referred to as a model. The model is an older and more theoretical approach to personality, accepting extroversion and introversion as basic psychological orientations in connection with two pairs of psychological functions:


Briggs and Myers also added another personality dimension to their type indicator to measure whether a person prefers to use a judging or perceiving function when interacting with the external world. Therefore, they included questions designed to indicate whether someone wishes to come to conclusions (judgment) or to keep options open (perception).

This personality typology has some aspects of a trait theory: it explains people's behavior in terms of opposite fixed characteristics. In these more traditional models, the sensing/intuition preference is considered the most basic, dividing people into "N" (intuitive) or "S" (sensing) personality types. An "N" is further assumed to be guided either by thinking or feeling and divided into the "NT" (scientist, engineer) or "NF" (author, humanitarian) temperament. An "S", in contrast, is assumed to be guided more by the judgment/perception axis and thus divided into the "SJ" (guardian, traditionalist) or "SP" (performer, artisan) temperament. These four are considered basic, with the other two factors in each case (including always extraversion/introversion) less important. Critics of this traditional view have observed that the types can be quite strongly stereotyped by professions (although neither Myers nor Keirsey engaged in such stereotyping in their type descriptions), and thus may arise more from the need to categorize people for purposes of guiding their career choice. This among other objections led to the emergence of the five-factor view, which is less concerned with behavior under work conditions and more concerned with behavior in personal and emotional circumstances. (It should be noted, however, that the MBTI is not designed to measure the "work self", but rather what Myers and McCaulley called the "shoes-off self.")

Type A and Type B personality theory: During the 1950s, Meyer Friedman and his co-workers defined what they called Type A and Type B behavior patterns. They theorized that intense, hard-driving Type A personalities had a higher risk of coronary disease because they are "stress junkies." Type B people, on the other hand, tended to be relaxed, less competitive, and lower in risk. There was also a Type AB mixed profile.

John L. Holland's "RIASEC" vocational model, commonly referred to as the "Holland Codes", stipulates that six personality types lead people to choose their career paths. In this circumplex model, the six types are represented as a hexagon, with adjacent types more closely related than those more distant. The model is widely used in vocational counseling.

Eduard Spranger's personality-model, consisting of six (or, by some revisions, 6 +1) basic types of "value attitudes", described in his book "Types of Men" ("Lebensformen"; Halle (Saale): Niemeyer, 1914; English translation by P. J. W. Pigors - New York: G. E. Stechert Company, 1928).

The Enneagram of Personality, a model of human personality which is principally used as a typology of nine interconnected personality types. It has been criticized as being subject to interpretation, making it difficult to test or validate scientifically.

Perhaps the most ancient attempt at personality psychology is the personality typology outlined by the Indian Buddhist Abhidharma schools. This typology mostly focuses on negative personal traits (greed, hatred, and delusion) and the corresponding positive meditation practices used to counter those traits.

Psychoanalytic theories explain human behavior in terms of the interaction of various components of personality. Sigmund Freud was the founder of this school of thought. Freud drew on the physics of his day (thermodynamics) to coin the term psychodynamics. Based on the idea of converting heat into mechanical energy, he proposed psychic energy could be converted into behavior. Freud's theory places central importance on dynamic, unconscious psychological conflicts.

Freud divides human personality into three significant components: the id, ego and super-ego. The id acts according to the "pleasure principle", demanding immediate gratification of its needs regardless of external environment; the ego then must emerge in order to realistically meet the wishes and demands of the id in accordance with the outside world, adhering to the "reality principle". Finally, the superego (conscience) inculcates moral judgment and societal rules upon the ego, thus forcing the demands of the id to be met not only realistically but morally. The superego is the last function of the personality to develop, and is the embodiment of parental/social ideals established during childhood. According to Freud, personality is based on the dynamic interactions of these three components.

The channeling and release of sexual (libidal) and aggressive energies, which ensues from the "Eros" (sex; instinctual self-preservation) and "Thanatos" (death; instinctual self-annihilation) drives respectively, are major components of his theory. It is important to note that Freud's broad understanding of sexuality included all kinds of pleasurable feelings experienced by the human body.

Freud proposed five psychosexual stages of personality development. He believed adult personality is dependent upon early childhood experiences and largely determined by age five. Fixations that develop during the infantile stage contribute to adult personality and behavior.

One of Sigmund Freud's earlier associates, Alfred Adler, did agree with Freud that early childhood experiences are important to development and believed birth order may influence personality development. Adler believed that the oldest child was the individual who would set high achievement goals in order to gain attention lost when the younger siblings were born. He believed the middle children were competitive and ambitious. He reasoned that this behavior was motivated by the idea of surpassing the firstborn's achievements. He added, however, that the middle children were often not as concerned about the glory attributed with their behavior. He also believed the youngest would be more dependent and sociable. Adler finished by surmising that an only child loves being the center of attention and matures quickly but in the end fails to become independent.

Heinz Kohut thought similarly to Freud's idea of transference. He used narcissism as a model of how people develop their sense of self. Narcissism is the exaggerated sense of one self in which one is believed to exist in order to protect one's low self-esteem and sense of worthlessness. Kohut had a significant impact on the field by extending Freud's theory of narcissism and introducing what he called the 'self-object transferences' of mirroring and idealization. In other words, children need to idealize and emotionally "sink into" and identify with the idealized competence of admired figures such as parents or older siblings. They also need to have their self-worth mirrored by these people. These experiences allow them to thereby learn the self-soothing and other skills that are necessary for the development of a healthy sense of self.

Another important figure in the world of personality theory is Karen Horney. She is credited with the development of the "real self" and the "ideal self". She believes all people have these two views of their own self. The "real self" is how humans act with regard to personality, values, and morals; but the "ideal self" is a construct individuals implement in order to conform to social and personal norms.

Behaviorists explain personality in terms of the effects external stimuli have on behavior. The approaches used to analyze the behavioral aspect of personality are known as behavioral theories or learning-conditioning theories. These approaches were a radical shift away from Freudian philosophy. One of the major tenets of this concentration of personality psychology is a strong emphasis on scientific thinking and experimentation. This school of thought was developed by B. F. Skinner who put forth a model which emphasized the mutual interaction of the person or "the organism" with its environment. Skinner believed children do bad things because the behavior obtains attention that serves as a reinforcer. For example: a child cries because the child's crying in the past has led to attention. These are the "response", and "consequences". The response is the child crying, and the attention that child gets is the reinforcing consequence. According to this theory, people's behavior is formed by processes such as operant conditioning. Skinner put forward a "three term contingency model" which helped promote analysis of behavior based on the "Stimulus - Response - Consequence Model" in which the critical question is: "Under which circumstances or antecedent 'stimuli' does the organism engage in a particular behavior or 'response', which in turn produces a particular 'consequence'?"

Richard Herrnstein extended this theory by accounting for attitudes and traits. An attitude develops as the response strength (the tendency to respond) in the presences of a group of stimuli become stable. Rather than describing conditionable traits in non-behavioral language, response strength in a given situation accounts for the environmental portion. Herrstein also saw traits as having a large genetic or biological component, as do most modern behaviorists.

Ivan Pavlov is another notable influence. He is well known for his classical conditioning experiments involving dogs, which led him to discover the foundation of behaviorism.

In cognitive theory, behavior is explained as guided by cognitions (e.g. expectations) about the world, especially those about other people. Cognitive theories are theories of personality that emphasize cognitive processes, such as thinking and judging.

Albert Bandura, a social learning theorist suggested the forces of memory and emotions worked in conjunction with environmental influences. Bandura was known mostly for his "Bobo doll experiment". During these experiments, Bandura video taped a college student kicking and verbally abusing a bobo doll. He then showed this video to a class of kindergarten children who were getting ready to go out to play. When they entered the play room, they saw bobo dolls, and some hammers. The people observing these children at play saw a group of children beating the doll. He called this study and his findings observational learning, or modeling.

Early examples of approaches to cognitive style are listed by Baron (1982). These include Witkin's (1965) work on field dependency, Gardner's (1953) discovering people had consistent preference for the number of categories they used to categorise heterogeneous objects, and Block and Petersen's (1955) work on confidence in line discrimination judgments. Baron relates early development of cognitive approaches of personality to ego psychology. More central to this field have been:


Various scales have been developed to assess both attributional style and locus of control. Locus of control scales include those used by Rotter and later by Duttweiler, the Nowicki and Strickland (1973) Locus of Control Scale for Children and various locus of control scales specifically in the health domain, most famously that of Kenneth Wallston and his colleagues, The Multidimensional Health Locus of Control Scale. Attributional style has been assessed by the Attributional Style Questionnaire, the Expanded Attributional Style Questionnaire, the Attributions Questionnaire, the Real Events Attributional Style Questionnaire and the Attributional Style Assessment Test.


Recognition that the tendency to believe that hard work and persistence often results in attainment of life and academic goals has influenced formal educational and counseling efforts with students of various ages and in various settings since the 1970s research about achievement. Counseling aimed toward encouraging individuals to design ambitious goals and work toward them, with recognition that there are external factors that may impact, often results in the incorporation of a more positive achievement style by students and employees, whatever the setting, to include higher education, workplace, or justice programming.

Walter Mischel (1999) has also defended a cognitive approach to personality. His work refers to "Cognitive Affective Units", and considers factors such as encoding of stimuli, affect, goal-setting, and self-regulatory beliefs. The term "Cognitive Affective Units" shows how his approach considers affect as well as cognition.

Cognitive-Experiential Self-Theory (CEST) is another cognitive personality theory. Developed by Seymour Epstein, CEST argues that humans operate by way of two independent information processing systems: experiential system and rational system. The experiential system is fast and emotion-driven. The rational system is slow and logic-driven. These two systems interact to determine our goals, thoughts, and behavior.

Personal construct psychology (PCP) is a theory of personality developed by the American psychologist George Kelly in the 1950s. Kelly's fundamental view of personality was that people are like naive scientists who see the world through a particular lens, based on their uniquely organized systems of construction, which they use to anticipate events. But because people are naive scientists, they sometimes employ systems for construing the world that are distorted by idiosyncratic experiences not applicable to their current social situation. A system of construction that chronically fails to characterize and/or predict events, and is not appropriately revised to comprehend and predict one's changing social world, is considered to underlie psychopathology (or mental illness.)
From the theory, Kelly derived a psychotherapy approach and also a technique called "The Repertory Grid Interview" that helped his patients to uncover their own "constructs" with minimal intervention or interpretation by the therapist. The repertory grid was later adapted for various uses within organizations, including decision-making and interpretation of other people's world-views.

Humanistic psychology emphasizes that people have free will and that this plays an active role in determining how they behave. Accordingly, humanistic psychology focuses on subjective experiences of persons as opposed to forced, definitive factors that determine behavior. Abraham Maslow and Carl Rogers were proponents of this view, which is based on the "phenomenal field" theory of Combs and Snygg (1949). Rogers and Maslow were among a group of psychologists that worked together for a decade to produce the "Journal of Humanistic Psychology". This journal was primarily focused on viewing individuals as a whole, rather than focusing solely on separate traits and processes within the individual.

Robert W. White wrote the book "The Abnormal Personality" that became a standard text on abnormal psychology. He also investigated the human need to strive for positive goals like competence and influence, to counterbalance the emphasis of Freud on the pathological elements of personality development.

Maslow spent much of his time studying what he called "self-actualizing persons", those who are "fulfilling themselves and doing the best they are capable of doing". Maslow believes all who are interested in growth move towards self-actualizing (growth, happiness, satisfaction) views. Many of these people demonstrate a trend in dimensions of their personalities. Characteristics of self-actualizers according to Maslow include the four key dimensions:

Maslow and Rogers emphasized a view of the person as an active, creative, experiencing human being who lives in the present and subjectively responds to current perceptions, relationships, and encounters. They disagree with the dark, pessimistic outlook of those in the Freudian psychoanalysis ranks, but rather view humanistic theories as positive and optimistic proposals which stress the tendency of the human personality toward growth and self-actualization. This progressing self will remain the center of its constantly changing world; a world that will help mold the self but not necessarily confine it. Rather, the self has opportunity for maturation based on its encounters with this world. This understanding attempts to reduce the acceptance of hopeless redundancy. Humanistic therapy typically relies on the client for information of the past and its effect on the present, therefore the client dictates the type of guidance the therapist may initiate. This allows for an individualized approach to therapy. Rogers found patients differ in how they respond to other people. Rogers tried to model a particular approach to therapy- he stressed the reflective or empathetic response. This response type takes the client's viewpoint and reflects back their feeling and the context for it. An example of a reflective response would be, "It seems you are feeling anxious about your upcoming marriage". This response type seeks to clarify the therapist's understanding while also encouraging the client to think more deeply and seek to fully understand the feelings they have expressed.

Biology plays a very important role in the development of personality. The study of the biological level in personality psychology focuses primarily on identifying the role of genetic determinants and how they mold individual personalities. Some of the earliest thinking about possible biological bases of personality grew out of the case of Phineas Gage. In an 1848 accident, a large iron rod was driven through Gage's head, and his personality apparently changed as a result, although descriptions of these psychological changes are usually exaggerated.

In general, patients with brain damage have been difficult to find and study. In the 1990s, researchers began to use electroencephalography (EEG), positron emission tomography (PET), and more recently functional magnetic resonance imaging (fMRI), which is now the most widely used imaging technique to help localize personality traits in the brain.

Ever since the Human Genome Project allowed for a much more in depth understanding of genetics, there has been an ongoing controversy involving heritability, personality traits, and environmental vs. genetic influence on personality. The human genome is known to play a role in the development of personality.
Previously, genetic personality studies focused on specific genes correlating to specific personality traits. Today's view of the gene-personality relationship focuses primarily on the activation and expression of genes related to personality and forms part of what is referred to as behavioural genetics. Genes provide numerous options for varying cells to be expressed; however, the environment determines which of these are activated. Many studies have noted this relationship in varying ways in which our bodies can develop, but the interaction between genes and the shaping of our minds and personality is also relevant to this biological relationship.
DNA-environment interactions are important in the development of personality because this relationship determines what part of the DNA code is actually made into proteins that will become part of an individual. It has been noted that while different choices are made available by the genome, in the end, the environment is the ultimate determinant of what becomes activated. Small changes in DNA in individuals are what lead to the uniqueness of every person as well as differences in looks, abilities, brain functioning, and all the factors that culminate to develop a cohesive personality.

Cattell and Eysenck have proposed that genetics have a strong influence on personality. A large part of the evidence collected linking genetics and the environment to personality have come from twin studies. This "twin method" compares levels of similarity in personality using genetically identical twins. One of the first of these twin studies measured 800 pairs of twins, studied numerous personality traits, and determined that identical twins are most similar in their general abilities. Personality similarities were found to be less related for self-concepts, goals, and interests.

Twin studies have also been important in the creation of the five factor personality model: neuroticism, extraversion, openness, agreeableness, and conscientiousness. Neuroticism and extraversion are the two most widely studied traits. A person that may fall into the extravert category can display characteristics such as impulsiveness, sociability, and activeness. A person falling into the neuroticism category may be more likely to be moody, anxious, or irritable. Identical twins, however, have higher correlations in personality traits than fraternal twins. One study measuring genetic influence on twins in five different countries found that the correlations for identical twins were .50, while for fraternal they were about .20. It is suggested that heredity and environment interact to determine one's personality.

Charles Darwin is the founder of the theory of the evolution of the species. The evolutionary approach to personality psychology is based on this theory. This theory examines how individual personality differences are based on natural selection. Through natural selection organisms change over time through adaptation and selection. Traits are developed and certain genes come into expression based on an organism's environment and how these traits aid in an organism's survival and reproduction.

Polymorphisms, such as gender and blood type, are forms of diversity which evolve to benefit a species as a whole. The theory of evolution has wide-ranging implications on personality psychology. Personality viewed through the lens of evolutionary psychology places a great deal of emphasis on specific traits that are most likely to aid in survival and reproduction, such as conscientiousness, sociability, emotional stability, and dominance. The social aspects of personality can be seen through an evolutionary perspective. Specific character traits develop and are selected for because they play an important and complex role in the social hierarchy of organisms. Such characteristics of this social hierarchy include the sharing of important resources, family and mating interactions, and the harm or help organisms can bestow upon one another.

In the 1930s, John Dollard and Neal Elgar Miller met at Yale University, and began an attempt to integrate drives (see Drive theory), into a theory of personality, basing themselves on the work of Clark Hull. They began with the premise that personality could be equated with the habitual responses exhibited by an individual – their habits. From there, they determined that these habitual responses were built on secondary, or acquired drives. 

Secondary drives are internal needs directing the behaviour of an individual that results from learning. Acquired drives are learned, by and large in the manner described by classical conditioning. When we are in a certain environment and experience a strong response to a stimulus, we internalize cues from the said environment. When we find ourselves in an environment with similar cues, we begin to act in anticipation of a similar stimulus. Thus, we are likely to experience anxiety in an environment with cues similar to one where we have experienced pain or fear – such as the dentist's office. 

Secondary drives are built on primary drives, which are biologically driven, and motivate us to act with no prior learning process – such as hunger, thirst or the need for sexual activity. However, secondary drives are thought to represent more specific elaborations of primary drives, behind which the functions of the original primary drive continue to exist. Thus, the primary drives of fear and pain exist behind the acquired drive of anxiety. Secondary drives can be based on multiple primary drives and even in other secondary drives. This is said to give them strength and persistence. Examples include the need for money, which was conceptualized as arising from multiple primary drives such as the drive for food and warmth, as well as from secondary drives such as imitativeness (the drive to do as others do) and anxiety.

Secondary drives vary based on the social conditions under which they were learned – such as culture. Dollard and Miller used the example of food, stating that the primary drive of hunger manifested itself behind the learned secondary drive of an appetite for a specific type of food, which was dependent on the culture of the individual.

Secondary drives are also explicitly social, representing a manner in which we convey our primary drives to others. Indeed, many primary drives are actively repressed by society (such as the sexual drive). Dollard and Miller believed that the acquisition of secondary drives was essential to childhood development. As children develop, they learn not to act on their primary drives, such as hunger but acquire secondary drives through reinforcement. Friedman and Schustack describe an example of such developmental changes, stating that if an infant engaging in an active orientation towards others brings about the fulfillment of primary drives, such as being fed or having their diaper changed, they will develop a secondary drive to pursue similar interactions with others – perhaps leading to an individual being more gregarious. Dollard and Miller's belief in the importance of acquired drives led them to reconceive Sigmund Freud's theory of psychosexual development. They found themselves to be in agreement with the timing Freud used but believed that these periods corresponded to the successful learning of certain secondary drives.

Dollard and Miller gave many examples of how secondary drives impact our habitual responses – and by extension our personalities, including anger, social conformity, imitativeness or anxiety, to name a few. In the case of anxiety, Dollard and Miller note that people who generalize the situation in which they experience the anxiety drive will experience anxiety far more than they should. These people are often anxious all the time, and anxiety becomes part of their personality. This example shows how drive theory can have ties with other theories of personality – many of them look at the trait of neuroticism or emotional stability in people, which is strongly linked to anxiety.

There are two major types of personality tests, projective and objective.

"Projective tests" assume personality is primarily unconscious and assess individuals by how they respond to an ambiguous stimulus, such as an ink blot. Projective tests have been in use for about 60 years and continue to be used today. Examples of such tests include the Rorschach test and the Thematic Apperception Test.

The Rorschach Test involves showing an individual a series of note cards with ambiguous ink blots on them. The individual being tested is asked to provide interpretations of the blots on the cards by stating everything that the ink blot may resemble based on their personal interpretation. The therapist then analyzes their responses. Rules for scoring the test have been covered in manuals that cover a wide variety of characteristics such as content, originality of response, location of "perceived images" and several other factors. Using these specific scoring methods, the therapist will then attempt to relate test responses to attributes of the individual's personality and their unique characteristics. The idea is that unconscious needs will come out in the person's response, e.g. an aggressive person may see images of destruction.
The Thematic Apperception Test (also known as the TAT) involves presenting individuals with vague pictures/scenes and asking them to tell a story based on what they see. Common examples of these "scenes" include images that may suggest family relationships or specific situations, such as a father and son or a man and a woman in a bedroom. Responses are analyzed for common themes. Responses unique to an individual are theoretically meant to indicate underlying thoughts, processes, and potentially conflicts present within the individual. Responses are believed to be directly linked to unconscious motives. There is very little empirical evidence available to support these methods.

"Objective tests" assume personality is consciously accessible and that it can be measured by self-report questionnaires. Research on psychological assessment has generally found objective tests to be more valid and reliable than projective tests. Critics have pointed to the Forer effect to suggest some of these appear to be more accurate and discriminating than they really are. Issues with these tests include false reporting because there is no way to tell if an individual is answering a question honestly or accurately.

The Myers-Briggs Type Indicator (also known as the MBTI) is self-reporting questionnaire based on Carl Jung's Type theory. 

Psychology has traditionally defined personality through its behavioral patterns, and more recently with neuroscientific studies of the brain. In recent years, some psychologists have turned to the study of inner experiences for insight into personality as well as individuality. Inner experiences are the thoughts and feelings to an immediate phenomenon. Another term used to define inner experiences is qualia. Being able to understand inner experiences assists in understanding how humans behave, act, and respond. Defining personality using inner experiences has been expanding due to the fact that solely relying on behavioral principles to explain one's character may seem incomplete. Behavioral methods allow the subject to be observed by an observer, whereas with inner experiences the subject is its own observer.

Descriptive experience sampling (DES), developed by psychologist Russel Hurlburt. This is an idiographic method that is used to help examine inner experiences. This method relies on an introspective technique that allows an individual's inner experiences and characteristics to be described and measured. A beep notifies the subject to record their experience at that exact moment and 24 hours later an interview is given based on all the experiences recorded. DES has been used in subjects that have been diagnosed with schizophrenia and depression. It has also been crucial to studying the inner experiences of those who have been diagnosed with common psychiatric diseases.

Articulated thoughts in stimulated situations (ATSS): ATSS is a paradigm which was created as an alternative to the TA (think aloud) method. This method assumes that people have continuous internal dialogues that can be naturally attended to. ATSS also assesses a person’s inner thoughts as they verbalize their cognitions. In this procedure, subjects listen to a scenario via a video or audio player and are asked to imagine that they are in that specific situation. Later, they are asked to articulate their thoughts as they occur in reaction to the playing scenario. This method is useful in studying emotional experience given that the scenarios used can influence specific emotions. Most importantly, the method has contributed to the study of personality. In a study conducted by Rayburn and Davison (2002), subjects’ thoughts and empathy toward anti-gay hate crimes were evaluated. The researchers found that participants showed more aggressive intentions towards the offender in scenarios which mimicked hate crimes.

Experimental method: This method is an experimental paradigm used to study human experiences involved in the studies of sensation and perception, learning and memory, motivation, and biological psychology. The experimental psychologist usually deals with intact organisms although studies are often conducted with organisms modified by surgery, radiation, drug treatment, or long-standing deprivations of various kinds or with organisms that naturally present organic abnormalities or emotional disorders. Economists and psychologists have developed a variety of experimental methodologies to elicit and assess individual attitudes where each emotion differs for each individual. The results are then gathered and quantified to conclude if specific experiences have any common factors. This method is used to seek clarity of the experience and remove any biases to help understand the meaning behind the experience to see if it can be generalized.




</doc>
<doc id="24985" url="https://en.wikipedia.org/wiki?curid=24985" title="Pronoun">
Pronoun

In linguistics and grammar, a pronoun (abbreviated ) is a word that substitutes for a noun or noun phrase. It is a particular case of a pro-form.

Pronouns have traditionally been regarded as one of the parts of speech, but some modern theorists would not consider them to form a single class, in view of the variety of functions they perform. Subtypes include personal pronouns, reflexive and reciprocal pronouns, possessive pronouns, demonstrative pronouns, relative pronouns, interrogative pronouns, and indefinite pronouns.

The use of pronouns often involves anaphora, where the meaning of the pronoun is dependent on an antecedent. This applies especially to third-person personal pronouns and relative pronouns. For example, in the sentence "That poor man looks as if he needs a new coat", the antecedent of the pronoun "he" is the noun phrase "that poor man".

The adjective associated with "pronoun" is pronominal. A pronominal is also a word or phrase that acts as a pronoun. For example, in "That's not the one I wanted", the phrase "the one" (containing the prop-word "one") is a pronominal.

Personal pronouns may be classified by person, number, gender and case. English has three persons (first, second and third) and two numbers (singular and plural); in the third person singular there are also distinct pronoun forms for male, female and neuter gender. Principal forms are shown in the adjacent table (see also English personal pronouns).

English personal pronouns have two cases, "subject" and "object". Subject pronouns are used in subject position (I like to eat chips, but she does not"). Object pronouns are used for the object of a verb or preposition ("John likes me but not her).

Other distinct forms found in some languages include:

Some special uses of personal pronouns include:

Reflexive pronouns are used when a person or thing acts on itself, for example, "John cut himself." In English they all end in "-self" or "-selves" and must refer to a noun phrase elsewhere in the same clause.

Reciprocal pronouns refer to a reciprocal relationship ("each other", "one another"). They must refer to a noun phrase in the same clause. An example in English is: "They do not like each other." In some languages, the same forms can be used as both reflexive and reciprocal pronouns.

Possessive pronouns are used to indicate possession (in a broad sense). Some occur as independent noun phrases: "mine", "yours", "hers", "ours", "yours", "theirs". An example is: "Those clothes are mine." Others act as a determiner (adjective) and must accompany a noun: "my", "your", "her", "our", "your", "their", as in: "I lost my wallet." ("His" and "its" can fall into either category, although "its" is nearly always found in the second.) Those of the second type have traditionally also been described as possessive adjectives, and in more modern terminology as possessive determiners. The term "possessive pronoun" is sometimes restricted to the first type. Both types replace possessive noun phrases. As an example, Their crusade to capture our attention" could replace The advertisers' crusade to capture our attention."

Demonstrative pronouns (in English, "this", "that" and their plurals "these", "those") often distinguish their targets by pointing or some other indication of position; for example, "I'll take these." They may also be "anaphoric", depending on an earlier expression for context, for example, "A kid actor would try to be all sweet, and who needs that?"

Indefinite pronouns, the largest group of pronouns, refer to one or more unspecified persons or things. One group in English includes compounds of "some-", "any-", "every-" and "no-" with "-thing", "-one" and "-body", for example: "Anyone can do that." Another group, including "many", "more", "both", and "most", can appear alone or followed by "of". In addition,

Relative pronouns ("who", "whom", "whose", "what", "which" and "that") refer back to people or things previously mentioned: "People who smoke should quit now." They are used in relative clauses.

Interrogative pronouns ask which person or thing is meant. In reference to a person, one may use "who" (subject), "whom" (object) or "whose" (possessive); for example, "Who did that?" In colloquial speech, "whom" is generally replaced by "who". English non-personal interrogative pronouns ("which" and "what") have only one form.

In English and many other languages (e.g. French and Czech), the sets of relative and interrogative pronouns are nearly identical. Compare English: "Who is that?" (interrogative) and "I know the woman who came" (relative). In some other languages, interrogative pronouns and indefinite pronouns are frequently identical; for example, Standard Chinese 什么 "shénme" means "what?" as well as "something" or "anything".

Though the personal pronouns described above are the "contemporary" English pronouns, older forms of "modern" English (as used by Shakespeare, for example) use a slightly different set of personal pronouns as shown in the table. The difference is entirely in the second person. Though one would rarely find these older forms used in literature from recent centuries, they are nevertheless considered "modern".

The use of pronouns often involves anaphora, where the meaning of the pronoun is dependent on another referential element. The referent of the pronoun is often the same as that of a preceding (or sometimes following) noun phrase, called the antecedent of the pronoun. The following sentences give examples of particular types of pronouns used with antecedents:

Some other types, such as indefinite pronouns, are usually used without antecedents. Relative pronouns are used without antecedents in free relative clauses. Even third-person personal pronouns are sometimes used without antecedents ("unprecursed") – this applies to special uses such as dummy pronouns and generic "they", as well as cases where the referent is implied by the context.

Pronouns "(antōnymía)" are listed as one of eight parts of speech in "The Art of Grammar", a treatise on Greek grammar attributed to Dionysius Thrax and dating from the 2nd century BC. The pronoun is described there as "a part of speech substitutable for a noun and marked for a person." Pronouns continued to be regarded as a part of speech in Latin grammar (the Latin term being "pronomen", from which the English name – through Middle French – ultimately derives), and thus in the European tradition generally.

In more modern approaches, pronouns are less likely to be considered to be a single word class, because of the many different syntactic roles that they play, as represented by the various different types of pronouns listed in the previous sections.
Certain types of pronouns are often identical or similar in form to determiners with related meaning; some English examples are given in the table on the right. This observation has led some linguists, such as Paul Postal, to regard pronouns as determiners that have had their following noun or noun phrase deleted. (Such patterning can even be claimed for certain personal pronouns; for example, "we" and "you" might be analyzed as determiners in phrases like "we Brits" and "you tennis players".) Other linguists have taken a similar view, uniting pronouns and determiners into a single class, sometimes called "determiner-pronoun", or regarding determiners as a subclass of pronouns or vice versa. The distinction may be considered to be one of subcategorization or valency, rather like the distinction between transitive and intransitive verbs – determiners take a noun phrase complement like transitive verbs do, while pronouns do not. This is consistent with the determiner phrase viewpoint, whereby a determiner, rather than the noun that follows it, is taken to be the head of the phrase.

The grammatical behavior of certain types of pronouns, and in particular their possible relationship with their antecedents, has been the focus of studies in binding, notably in the Chomskyan government and binding theory. In this context, reflexive and reciprocal pronouns (such as "himself" and "each other") are referred to as anaphors (in a specialized restricted sense) rather than as pronominal elements.





</doc>
<doc id="24986" url="https://en.wikipedia.org/wiki?curid=24986" title="Pelagianism">
Pelagianism

Pelagianism is the belief that original sin did not taint human nature and that mortal will is still capable of choosing good or evil without special divine aid. This theological theory is named after the British monk Pelagius (354–420 or 440), although he denied, at least at some point in his life, many of the doctrines associated with his name. Pelagius was identified as an Irishman by Saint Jerome. Pelagius taught that the human will, as created with its abilities by God, was sufficient to live a sinless life, although he believed that God's grace assisted every good work. Pelagianism has come to be identified with the view (whether taught by Pelagius or not) that human beings can earn salvation by their own efforts.

Pelagius rejected the Biblical concept of grace. According to his opponents, Pelagius taught that moral perfection was attainable in this life without the assistance of divine grace through human free will. Augustine contradicted this by saying that perfection was impossible without grace because we are born sinners with a sinful heart and will. The Pelagians charged Augustine with departing from the accepted teaching (e.g.: John 8:11) of the Apostles and the Bible, demonstrating that the doctrine of original sin amounted to Manichaeism, which taught that the flesh was in itself sinful (and thus denied that Jesus came in the flesh). This charge would have carried added weight since contemporaries knew that Augustine had himself been a Manichaean layman before converting to Christianity. Augustine also taught that a person's salvation comes solely through a free gift, the efficacious grace of God, but that this was a gift that one had no free choice to accept or refuse.

Pelagianism was attacked in 415 at the Council of Diospolis (also known as Lydda or Lod), which found Pelagius to be orthodox. But it was later condemned at the Council of Carthage (418) and this condemnation was ratified at the Council of Ephesus in 431. The strict moral teachings of the Pelagians were influential in southern Italy and Sicily, where they were openly preached until the death of Julian of Eclanum in 455, and in Britain until the coming of Saint Germanus of Auxerre c 429.

In "De causa Dei contra Pelagium et de virtute causarum", Thomas Bradwardine denounced Pelagianism in the 14th century, as did Gabriel Biel in the 15th century.

Little is known about the life of Pelagius, and although he is frequently referred to as a "British" monk, his origins are by no means certain. ("Pelagius" is derived from the Greek "pelagikos", meaning of the sea.) Augustine says that he lived in Rome "for a very long time" and referred to him as "Brito" to distinguish him from a different man called Pelagius of Tarentum. Bede refers to him as "Pelagius Bretto". St. Jerome suggests he was of Scottish descent which at the time would most certainly have meant he was from Ireland, since in the time of Pelagius, "Scots" referred to the Irish because Scota (source of "Scottish" or "Irish" in the early Middle Ages) was one of their matronyms; the word Irish comes from the matronym Ériu. Other sources place his origins in Brittany. He was certainly well known in the Roman province, both for the harsh asceticism of his public life, as well as the power and persuasiveness of his speech. Augustine, a pillar of the Church, referred to him as "saintly" before their falling out and John Wesley said "he was both a wise and a holy man".

The teachings of Pelagius are generally associated with the rejection of both original sin and infant baptism. Although the writings of Pelagius are no longer extant, the eight canons of the Council of Carthage (418) provided corrections to the perceived errors of the early Pelagians. These corrections include:

Some codices containing a ninth canon: Children dying without baptism do not go to a "middle place" (""), since the non-reception of baptism excludes both from the "kingdom of heaven" and from "eternal life". Pelagianism stands in contrast to the official hamartiological system of the Catholic Church that is based on the theology of Saint Augustine of Hippo. Semipelagianism is a modified form of Pelagianism that was also condemned by the Catholic Church at the Council of Orange (529).

Of far-reaching influence upon the further progress of Pelagianism was the friendship which Pelagius developed in Rome with Caelestius, a lawyer of noble (probably Italian) descent. In the capacity of a lay-monk Caelestius endeavoured to convert the practical maxims learnt from Pelagius, into theoretical principles, which he then propagated in Rome. The denial of the transmission of Original Sin seems to have been introduced into Pelagianism by Rufinus the Syrian, who influenced Pelagius' supporter Celestius. Pelagius' views were sometimes misrepresented by his followers and distorted by his opponents. Pelagianism has come to mean – unfairly to its founder – the view that human beings can earn salvation by their own efforts.

Pelagius was disturbed by the immorality he encountered in Rome and saw Christians using human frailty as an excuse for their failure to live a Christian life. He taught that the human will, as created with its abilities by God, was sufficient to live a sinless life, although he believed that God's grace assisted every good work. Pelagius did not believe that all humanity was guilty in Adam's sin, but said that Adam had condemned mankind through bad example. The value of Christ's redemption was, in his opinion, limited mainly to instruction and example.

Pelagius wrote:

"Whenever I have to speak on the subject of moral instruction and conduct of a holy life, it is my practice first to demonstrate the power and quality of human nature and to show what it is capable of achieving, and then to go on to encourage the mind of my listener to consider the idea of different kinds of virtues, in case it may be of little or no profit to him to be summoned to pursue ends which he has perhaps assumed hitherto to be beyond his reach; for we can never end upon the path of virtue unless we have hope as our guide and compassion."

"It was because God wished to bestow on the rational creature the gift of doing good of his own free will and the capacity to exercise free choice, by implanting in man the possibility of choosing either alternative. ...He could not claim to possess the good of his own volition, unless he was the kind of creature that could also have possessed evil. Our most excellent creator wished us to be able to do either but actually to do only one, that is, good, which he also commanded, giving us the capacity to do evil only so that we might do His will by exercising our own. That being so, this very capacity to do evil is also good – good, I say, because it makes the good part better by making it voluntary and independent, not bound by necessity but free to decide for itself."

"Yet we do not defend the good of nature to such an extent that we claim that it cannot do evil, since we undoubtedly declare also that it is capable of good and evil; we merely try to protect it from an unjust charge, so that we may not seem to be forced to do evil through a fault of our nature, when, in fact, we do neither good nor evil without the exercise of our will and always have the freedom to do one of the two, being always able to do either."

"Nothing impossible has been commanded by the God of justice and majesty...Why do we indulge in pointless evasions, advancing the frailty of our own nature as an objection to the one who commands us? No one knows better the true measure of our strength than he who has given it to us nor does anyone understand better how much we are able to do than he who has given us this very capacity of ours to be able; nor has he who is just wished to command anything impossible or he who is good intended to condemn a man for doing what he could not avoid doing."

A follower of Pelagius taught:

Many of the Church Fathers before Augustine taught that humans have the power of free will and the choice over good and evil.


Thomas Bradwardine (c. 1290–1349) wrote "De causa Dei contra Pelagium et de virtute causarum ad suos Mertonenses". Johann Pupper, also known as Johannes von Goch (c. 1400–1475), an Augustinian, recommended a return to the text of the Bible as a remedy for Pelagianism.

Pelagianism became a common accusation during the Protestant Reformation; Reformers often used the epithet to critique what they saw as late-medieval Catholicism's undue emphasis on doing good works. Martin Luther (1483–1546), John Calvin (1509–1564), and Cornelius Jansen (1585–1638) reacted in different ways against Pelagianism, and evaluations of Lutheran, Reformed, and Jansenist theologies have often turned on the question of what is or is not Pelagian.

In the book "Guardare Cristo: esempi di fede, speranza e carità" (Looking at Christ: Examples of faith, hope and charity) Pope Benedict XVI wrote: "the other face of the same vice is the Pelagianism of the pious. They do not want forgiveness and in general they do not want any real gift from God either. They just want to be in order. They don’t want hope they just want security. Their aim is to gain the right to salvation through a strict practice of religious exercises, through prayers and action. What they lack is humility which is essential in order to love; the humility to receive gifts not just because we deserve it or because of how we act…" 

In a June 2013 talk with the leadership of the Religious Confederation of Latin America and the Caribbean (CLAR), Pope Francis alluded to Pelagian tendencies when he referred to "restorationists", one group of whom sent him after his election 3,525 rosaries. The pope said he was "bothered" by this need to count prayers and labeled it "pelagianism." He went on to comment: "these groups return to practices and disciplines I lived – not you, none of you are old – to things that were lived in that moment, but not now, they aren't today..." The Congregation of the Doctrine of the Faith subsequently emphasised "neo-Pelagianism" in a letter of February 2018 titled "Placuit Deo", stating, "A new form of Pelagianism is spreading in our days, one in which the individual, understood to be radically autonomous, presumes to save oneself, without recognizing that, at the deepest level of being, he or she derives from God and from others."

Mormon philosopher Sterling M. McMurrin, argued that "[t]he theology of Mormonism is completely Pelagian." Mormon theology teaches that the Atonement of Jesus Christ has overcome the effects of "original sin" for all mankind. For example, the Book of Mormon, a sacred text for The Church of Jesus Christ of Latter-day Saints, teaches: "[T]he Messiah cometh in the fullness of time, that he might redeem the children of men from the fall. And because they are redeemed from the fall they have become free forever, knowing good and evil; to act for themselves and not to be acted upon, save it be by the punishment of the law at that great and last day, according to the commandments which God has given." It also teaches: "there is no flesh that can dwell in the presence of God, save it be through the merits, and mercy, and grace of the Holy Messiah". Pelagianism is not the official stance of The Church of Jesus Christ of Latter-day Saints.






</doc>
<doc id="24987" url="https://en.wikipedia.org/wiki?curid=24987" title="Patripassianism">
Patripassianism

In Christian theology, patripassianism (as it is referred to in the Western church) is a version of Sabellianism in the Eastern church (and a version of modalism, modalistic monarchianism, or modal monarchism). Modalism is the belief that God the Father, Jesus Christ, and the Holy Spirit are three different "modes" or "aspects" of one monadic God, as perceived by "the believer", rather than three distinct persons within "the Godhead" – that there are no real or substantial differences between the three, such that there is no substantial identity for the Spirit or the Son.

In the West, a version of this belief was known as "patripassianism" (from Latin "patri"- "father" and "passio" "suffering"), because the teaching required that since God the Father had become directly incarnate in Christ, that God literally sacrificed Himself on the Cross.

From the standpoint of the doctrine of the Trinity— one divine being existing in three persons— patripassianism is considered heretical since "it simply cannot make sense of the New Testament's teaching on the interpersonal relationship of Father, Son, and Spirit." In this patripassianism asserts that God the Father—rather than God the Son—became incarnate and suffered on the cross for humanity's redemption. This not only denies the personhood of God-the-Son (Jesus Christ), but is seen by trinitarians as distorting the "spiritual transaction" of atonement that was taking place at the cross, which the Apostle Paul described as follows: "God [the Father] was reconciling the world to himself in Christ [the Son], not counting people’s sins against them. . . . God [the Father] made him who had no sin [God-the-Son] to be sin for us, so that in him [the Son] we might become the righteousness of God [the Father]." (2 Corinthians 5:19, 21)

It is possible, however, to modify patripassianism so as to acknowledge the Divine Being as having feelings toward, and sharing in the experiences of, both Jesus— whom Christians regard as both human and divine— and other human beings. Full-orbed patripassianism denies Trinitarian distinctions, yet it does not contradict Christianity as defined in the Creeds to say that God feels or experiences things, including nonphysical forms of suffering. With regard to the crucifixion of Jesus, they claim it is consistent with Scriptural teaching to say that God the Father suffered—that is, felt emotional and spiritual pain as He watched His Son suffer on the Cross.

Patripassianism began in the third century AD. Patripassianism was referred to as a belief ascribed to those following Sabellianism, after its founder Sabellius, especially by the chief opponent Tertullian. Sabellius, considered a founder of an early movement, was a priest who was excommunicated from the Church by Pope Callixtus I in 220 and lived in Rome. Sabellius advanced the doctrine of one God sometimes referred to as the “economic Trinity” and he opposed the Eastern Orthodox doctrine of the “essential Trinity”. Praxeas and Noetus were some major followers.

Because the writings of Sabellius were destroyed it is hard to know if he did actually believe in Patripassianism, but one early version of the Apostles' Creed, recorded by Rufinus, explicitly states that the Father is 'impassible.' This reading dates to about 390 AD. This addition was made in response to patripassianism, which Rufinus evidently regarded as a heresy.

Cyprian and Tertullian famously accused the Modalistic Monarchians of patripassianism. The Monarchians taught the unity of the Godhead in Christ and that as the Son suffered the Father also experienced the sufferings. They did not teach that the Father died on the cross, though they were sometimes accused of this.

This term has been used by others such as F. L. Cross and E. A. Livingstone, eds., "The Oxford Dictionary of the Christian Church" (Oxford: Oxford University Press), accessed via Oxford Reference Online August 21, 2009 to describe other Oneness religions.



</doc>
<doc id="24988" url="https://en.wikipedia.org/wiki?curid=24988" title="Denial of the virgin birth of Jesus">
Denial of the virgin birth of Jesus

Denial of the virgin birth of Jesus is found among various groups and individuals throughout the history of Christianity. These groups and individuals often took an approach to Christology which understands Jesus to be human, the literal son of human parents.

During the 19th century this view was sometimes called "Psilanthropism", a term which derives from the combination of the Greek (psilós), "plain," "mere" or "bare," and (ánthrōpos) "human." Psilanthropists generally deny both the virgin birth of Jesus, and his divinity. Denial of the virgin birth is distinct from adoptionism, and may or may not be present in beliefs described as adoptionist.

The group most closely associated with denial of the virgin birth were the Ebionites. However Jerome does not say that all Ebionites denied the virgin birth, but only contrasts their view with the acceptance of the doctrine on the part of a related group, the Nazarenes.

The view was rejected by the ecumenical councils, especially in the First Council of Nicaea, which was convened to deal directly with the nature of Christ's divinity.

The turmoil of the Reformation threw up many radical groups and individuals, some of were accused of denying, or actually did deny, the virgin birth. For example during the trial of Lorenzo Tizzano before the Inquisition at Venice in 1550, it was charged that the circle of the late Juan de Valdés (died 1541) at Naples had included such individuals. Early Unitarians, often called Socinians, after Laelio Sozzini who first published the first unitarian analysis of John's "Logos" in 1550, were sometimes accused of denying the virgin birth, but mainly only denied the pre-existence of Christ in heaven. For Sozzini's better known nephew Fausto Sozzini the miraculous virgin birth was the element in their belief which removed the need for the pre-existence to which they objected. The Socinians in fact excommunicated from their number the translator of the first Bible in Belarusian, Symon Budny, for his denial of the virgin birth.

A large scale change among Unitarians to acceptance of a human father for Jesus took place only in the time of Joseph Priestley. The young Samuel Taylor Coleridge was an example of what he called "a psilanthropist, one of those who believe our Lord to have been the real son of Joseph" but later in life Coleridge decisively rejected this idea and accepted traditional Christian belief in the virgin birth.

Biblical scholars, churchmen and theologians who have notably rejected the virgin birth include:

The Korean Unification Church's textbook, the "Divine Principle" does not include the teaching that Zacharias was the father of Jesus; however, according to Ruth Tucker, some members of the Unification Church hold that belief based on the work of Leslie Weatherhead.



</doc>
<doc id="24989" url="https://en.wikipedia.org/wiki?curid=24989" title="Pendulum clock">
Pendulum clock

A pendulum clock is a clock that uses a pendulum, a swinging weight, as its timekeeping element. The advantage of a pendulum for timekeeping is that it is a harmonic oscillator; it swings back and forth in a precise time interval dependent on its length, and resists swinging at other rates. From its invention in 1656 by Christiaan Huygens until the 1930s, the pendulum clock was the world's most precise timekeeper, accounting for its widespread use. Throughout the 18th and 19th centuries pendulum clocks in homes, factories, offices and railroad stations served as primary time standards for scheduling daily life, work shifts, and public transportation, and their greater accuracy allowed the faster pace of life which was necessary for the Industrial Revolution. The home pendulum clock was replaced by cheaper synchronous electric clocks in the 1930s and '40s, and they are now kept mostly for their decorative and antique value.

Pendulum clocks must be stationary to operate; any motion or accelerations will affect the motion of the pendulum, causing inaccuracies, so other mechanisms must be used in portable timepieces.

The pendulum clock was invented in 1656 by Dutch scientist and inventor Christiaan Huygens, and patented the following year. Huygens contracted the construction of his clock designs to clockmaker Salomon Coster, who actually built the clock. Huygens was inspired by investigations of pendulums by Galileo Galilei beginning around 1602. Galileo discovered the key property that makes pendulums useful timekeepers: isochronism, which means that the period of swing of a pendulum is approximately the same for different sized swings. Galileo had the idea for a pendulum clock in 1637, which was partly constructed by his son in 1649, but neither lived to finish it. The introduction of the pendulum, the first harmonic oscillator used in timekeeping, increased the accuracy of clocks enormously, from about 15 minutes per day to 15 seconds per day leading to their rapid spread as existing 'verge and foliot' clocks were retrofitted with pendulums.

These early clocks, due to their verge escapements, had wide pendulum swings of 80–100°. In his 1673 analysis of pendulums, "Horologium Oscillatorium", Huygens showed that wide swings made the pendulum inaccurate, causing its period, and thus the rate of the clock, to vary with unavoidable variations in the driving force provided by the movement. Clockmakers' realization that only pendulums with small swings of a few degrees are isochronous motivated the invention of the anchor escapement around 1670, which reduced the pendulum's swing to 4–6°. The anchor became the standard escapement used in pendulum clocks. In addition to increased accuracy, the anchor's narrow pendulum swing allowed the clock's case to accommodate longer, slower pendulums, which needed less power and caused less wear on the movement. The seconds pendulum (also called the Royal pendulum), 0.994 m (39.1 in) long, in which each swing takes one second, became widely used in quality clocks. The long narrow clocks built around these pendulums, first made by William Clement around 1680, became known as grandfather clocks. The increased accuracy resulting from these developments caused the minute hand, previously rare, to be added to clock faces beginning around 1690.

The 18th and 19th century wave of horological innovation that followed the invention of the pendulum brought many improvements to pendulum clocks. The deadbeat escapement invented in 1675 by Richard Towneley and popularized by George Graham around 1715 in his precision "regulator" clocks gradually replaced the anchor escapement and is now used in most modern pendulum clocks. Observation that pendulum clocks slowed down in summer brought the realization that thermal expansion and contraction of the pendulum rod with changes in temperature was a source of error. This was solved by the invention of temperature-compensated pendulums; the mercury pendulum by George Graham in 1721 and the gridiron pendulum by John Harrison in 1726. With these improvements, by the mid-18th century precision pendulum clocks achieved accuracies of a few seconds per week.

Until the 19th century, clocks were handmade by individual craftsmen and were very expensive. The rich ornamentation of pendulum clocks of this period indicates their value as status symbols of the wealthy. The clockmakers of each country and region in Europe developed their own distinctive styles. By the 19th century, factory production of clock parts gradually made pendulum clocks affordable by middle-class families.

During the Industrial Revolution, daily life was organized around the home pendulum clock. More accurate pendulum clocks, called "regulators", were installed in places of business and railroad stations and used to schedule work and set other clocks. The need for extremely accurate timekeeping in celestial navigation to determine longitude drove the development of the most accurate pendulum clocks, called "astronomical regulators". These precision instruments, installed in naval observatories and kept accurate within a second by observation of star transits overhead, were used to set marine chronometers on naval and commercial vessels. Beginning in the 19th century, astronomical regulators in naval observatories served as primary standards for national time distribution services that distributed time signals over telegraph wires. From 1909, US National Bureau of Standards (now NIST) based the US time standard on Riefler pendulum clocks, accurate to about 10 milliseconds per day. In 1929 it switched to the Shortt-Synchronome free pendulum clock before phasing in quartz standards in the 1930s.

Pendulum clocks remained the world standard for accurate timekeeping for 270 years, until the invention of the quartz clock in 1927, and were used as time standards through World War 2. The French Time Service used pendulum clocks as part of their ensemble of standard clocks until 1954. The home pendulum clock began to be replaced as domestic timekeeper during the 1930s and 1940s by the synchronous electric clock, which kept more accurate time because it was synchronized to the oscillation of the electric power grid. The most accurate experimental pendulum clock ever made may be the Littlemore Clock built by Edward T. Hall in the 1990s
(donated in 2003 to the National Watch and Clock Museum, Columbia, Pennsylvania, USA).

The mechanism which runs a mechanical clock is called the movement. The movements of all mechanical pendulum clocks have these five parts:

Additional functions in clocks besides basic timekeeping are called complications. More elaborate pendulum clocks may include these complications:


In "electromechanical pendulum clocks" such as used in mechanical Master clocks the power source is replaced by an electrically powered solenoid that provides the impulses to the pendulum by magnetic force, and the escapement is replaced by a switch or photodetector that senses when the pendulum is in the right position to receive the impulse. These should not be confused with more recent quartz pendulum clocks in which an electronic quartz clock module swings a pendulum. These are not true pendulum clocks because the timekeeping is controlled by a quartz crystal in the module, and the swinging pendulum is merely a decorative simulation.

The pendulum swings with a period that varies with the square root of its effective length. For small swings the period "T", the time for one complete cycle (two swings), is

where "L" is the length of the pendulum and "g" is the local acceleration of gravity. All pendulum clocks have a means of adjusting the rate. This is usually an adjustment nut under the pendulum bob which moves the bob up or down on its rod. Moving the bob up reduces the length of the pendulum, reducing the pendulum's period so the clock gains time. In some pendulum clocks, fine adjustment is done with an auxiliary adjustment, which may be a small weight that is moved up or down the pendulum rod. In some master clocks and tower clocks, adjustment is accomplished by a small tray mounted on the rod where small weights are placed or removed to change the effective length, so the rate can be adjusted without stopping the clock.

The period of a pendulum increases slightly with the width (amplitude) of its swing. The "rate" of error increases with amplitude, so when limited to small swings of a few degrees the pendulum is nearly "isochronous"; its period is independent of changes in amplitude. Therefore, the swing of the pendulum in clocks is limited to 2° to 4°.

A major source of error in pendulum clocks is thermal expansion; the pendulum rod changes in length slightly with changes in temperature, causing changes in the rate of the clock. An increase in temperature causes the rod to expand, making the pendulum longer, so its period increases and the clock loses time. Many older quality clocks used wooden pendulum rods to reduce this error, as wood expands less than metal.

The first pendulum to correct for this error was the "mercury pendulum" invented by George Graham in 1721, which was used in precision regulator clocks into the 20th century. These had a bob consisting of a container of the liquid metal mercury. An increase in temperature would cause the pendulum rod to expand, but the mercury in the container would also expand and its level would rise slightly in the container, moving the center of gravity of the pendulum up toward the pivot. By using the correct amount of mercury, the centre of gravity of the pendulum remained at a constant height, and thus its period remained constant, despite changes in temperature.

The most widely used temperature-compensated pendulum was the gridiron pendulum invented by John Harrison around 1726. This consisted of a "grid" of parallel rods of high-thermal-expansion metal such as zinc or brass and low-thermal-expansion metal such as steel. If properly combined, the length change of the high-expansion rods compensated for the length change of the low-expansion rods, again achieving a constant period of the pendulum with temperature changes. 
This type of pendulum became so associated with quality that decorative "fake" gridirons are often seen on pendulum clocks, that have no actual temperature compensation function.

Beginning around 1900, some of the highest precision scientific clocks had pendulums made of ultra-low-expansion materials such as the nickel steel alloy Invar or fused silica, which required very little compensation for the effects of temperature.

The viscosity of the air through which the pendulum swings will vary with atmospheric pressure, humidity, and temperature. This drag also requires power that could otherwise be applied to extending the time between windings. Traditionally the pendulum bob is made with a narrow streamlined lens shape to reduce air drag, which is where most of the driving power goes in a quality clock. In the late 19th century and early 20th century, pendulums for precision regulator clocks in astronomical observatories were often operated in a chamber that had been pumped to a low pressure to reduce drag and make the pendulum's operation even more accurate by avoiding changes in atmospheric pressure. Fine adjustment of the rate of the clock could be made by slight changes to the internal pressure in the sealed housing.

To keep time accurately, pendulum clocks must be absolutely level. If they are not, the pendulum swings more to one side than the other, upsetting the symmetrical operation of the escapement. This condition can often be heard audibly in the ticking sound of the clock. The ticks or "beats" should be at precisely equally spaced intervals to give a sound of, "tick...tock...tick...tock"; if they are not, and have the sound "tick-tock...tick-tock..." the clock is "out of beat" and needs to be leveled. This problem can easily cause the clock to stop working, and is one of the most common reasons for service calls. A spirit level or watch timing machine can achieve a higher accuracy than relying on the sound of the beat; precision regulators often have a built in spirit level for the task. Older freestanding clocks often have feet with adjustable screws to level them, more recent ones have a leveling adjustment in the movement. Some modern pendulum clocks have 'auto-beat' or 'self-regulating beat adjustment' devices, and don't need this adjustment.

Since the pendulum rate will increase with an increase in gravity, and local gravity varies with latitude and elevation on Earth, precision pendulum clocks must be readjusted to keep time after a move. For example, a pendulum clock moved from sea level to will lose 16 seconds per day. With the most accurate pendulum clocks, even moving the clock to the top of a tall building would cause it to lose measurable time due to lower gravity.

Also called torsion-spring pendulum, this is a wheel-like mass (most often four spheres on cross spokes) suspended from a vertical strip (ribbon) of spring steel, used as the regulating mechanism in torsion pendulum clocks. Rotation of the mass winds and unwinds the suspension spring, with the energy impulse applied to the top of the spring. With a period of 12—15 seconds, compared to the gravity swing pendulum's period of 0.5—2s, it is possible to make clocks that need to be wound only every 30 days, or even only once a year or more. This type is independent of the local force of gravity but is more affected by temperature changes than an uncompensated gravity-swing pendulum. 

A clock requiring only annual winding is sometimes called a "400-Day clock" or "anniversary clock", the latter sometimes given as a wedding memorialisation gift. German firms Schatz and Kieninger & Obergfell (known as "Kundo", from "K und O"), were the main manufacturers of this type of clock. The "perpetual motion" clock, called the Atmos because its mechanism was kept wound by changes in atmospheric temperature, also makes use of a torsion pendulum. In this case the oscillation cycle takes a full 60 seconds.

The escapement is a mechanical linkage that converts the force from the clock's wheel train into impulses that keep the pendulum swinging back and forth. It is the part that makes the "ticking" sound in a working pendulum clock. Most escapements consist of a wheel with pointed teeth called the "escape wheel" which is turned by the clock's wheel train, and surfaces the teeth push against, called "pallets". During most of the pendulum's swing the wheel is prevented from turning because a tooth is resting against one of the pallets; this is called the "locked" state. Each swing of the pendulum a pallet releases a tooth of the escape wheel. The wheel rotates forward a fixed amount until a tooth catches on the other pallet. These releases allow the clock's wheel train to advance a fixed amount with each swing, moving the hands forward at a constant rate, controlled by the pendulum. 

Although the escapement is necessary, its force disturbs the natural motion of the pendulum, and in precision pendulum clocks this was often the limiting factor on the accuracy of the clock. Different escapements have been used in pendulum clocks over the years to try to solve this problem. In the 18th and 19th century escapement design was at the forefront of timekeeping advances. The anchor escapement (see animation) was the standard escapement used until the 1800s when an improved version, the deadbeat escapement took over in precision clocks. It is used in almost all pendulum clocks today. The remontoire, a small spring mechanism rewound at intervals which serves to isolate the escapement from the varying force of the wheel train, was used in a few precision clocks. In tower clocks the wheel train must turn the large hands on the clock face on the outside of the building, and the weight of these hands, varying with snow and ice buildup, put a varying load on the wheel train. Gravity escapements were used in tower clocks. 

By the end of the 19th century specialized escapements were used in the most accurate clocks, called "astronomical regulators", which were employed in naval observatories and for scientific research. The Riefler escapement, used in Clemens-Riefler regulator clocks was accurate to 10 milliseconds per day. Electromagnetic escapements, which used a switch or phototube to turn on a solenoid electromagnet to give the pendulum an impulse without requiring a mechanical linkage, were developed. The most accurate pendulum clock was the Shortt-Synchronome clock, a complicated electromechanical clock with two pendulums developed in 1923 by W.H. Shortt and Frank Hope-Jones, which was accurate to better than one second per year. A slave pendulum in a separate clock was linked by an electric circuit and electromagnets to a master pendulum in a vacuum tank. The slave pendulum performed the timekeeping functions, leaving the master pendulum to swing virtually undisturbed by outside influences. In the 1920s the Shortt-Synchronome briefly became the highest standard for timekeeping in observatories before quartz clocks superseded pendulum clocks as precision time standards.

The indicating system is almost always the traditional dial with moving hour and minute hands. Many clocks have a small third hand indicating seconds on a subsidiary dial. Pendulum clocks are usually designed to be set by opening the glass face cover and manually pushing the minute hand around the dial to the correct time. The minute hand is mounted on a slipping friction sleeve which allows it to be turned on its arbor. The hour hand is driven not from the wheel train but from the minute hand's shaft through a small set of gears, so rotating the minute hand manually also sets the hour hand.

Pendulum clocks were more than simply utilitarian timekeepers; they were status symbols that expressed the wealth and culture of their owners. They evolved in a number of traditional styles, specific to different countries and times as well as their intended use. Case styles somewhat reflect the furniture styles popular during the period. Experts can often pinpoint when an antique clock was made within a few decades by subtle differences in their cases and faces. These are some of the different styles of pendulum clocks:



</doc>
<doc id="24992" url="https://en.wikipedia.org/wiki?curid=24992" title="Programmable logic controller">
Programmable logic controller

A programmable logic controller (PLC), or programmable controller is an industrial digital computer which has been ruggedized and adapted for the control of manufacturing processes, such as assembly lines, or robotic devices, or any activity that requires high reliability control and ease of programming and process fault diagnosis.

They were first developed in the automobile industry to provide flexible, ruggedised and easily programmable controllers to replace hard-wired relays, timers and sequencers. Since then they have been widely adopted as high-reliability automation controllers suitable for harsh environments. A PLC is an example of a "hard" real-time system since output results must be produced in response to input conditions within a limited time, otherwise unintended operation will result.

PLCs can range from small "building brick" devices with tens of inputs and outputs (I/O), in a housing integral with the processor, to large rack-mounted modular devices with a count of thousands of I/O, and which are often networked to other PLC and SCADA systems.

They can be designed for multiple arrangements of digital and analog I/O, extended temperature ranges, immunity to electrical noise, and resistance to vibration and impact. Programs to control machine operation are typically stored in battery-backed-up or non-volatile memory.

It was from the automotive industry in the USA that the PLC was born. Before the PLC, control, sequencing, and safety interlock logic for manufacturing automobiles was mainly composed of relays, cam timers, drum sequencers, and dedicated closed-loop controllers. Since these could number in the hundreds or even thousands, the process for updating such facilities for the yearly model change-over was very time consuming and expensive, as electricians needed to individually rewire the relays to change their operational characteristics.

When digital computers became available, being general-purpose programmable devices, they were soon applied to control sequential and combinatorial logic in industrial processes. However these early computers required specialist programmers and stringent operating environmental control for temperature, cleanliness, and power quality. To meet these challenges the PLC was developed with several key attributes. It would tolerate the shop-floor environment, it would support discrete (bit-form) input and output in an easily extensible manner, it would not require years of training to use, and it would permit its operation to be monitored. Since many industrial processes have timescales easily addressed by millisecond response times, modern (fast, small, reliable) electronics greatly facilitate building reliable controllers, and performance could be traded off for reliability.

In 1968 GM Hydra-Matic (the automatic transmission division of General Motors) issued a request for proposals for an electronic replacement for hard-wired relay systems based on a white paper written by engineer Edward R. Clark. The winning proposal came from Bedford Associates of Bedford, Massachusetts. The first PLC, designated the 084 because it was Bedford Associates' eighty-fourth project, was the result. Bedford Associates started a new company dedicated to developing, manufacturing, selling, and servicing this new product: , which stood for modular digital controller. One of the people who worked on that project was Dick Morley, who is considered to be the "father" of the PLC. The Modicon brand was sold in 1977 to Gould Electronics, later acquired by German Company AEG, and then by French Schneider Electric, the current owner.

One of the very first 084 models built is now on display at Schneider Electric's facility in North Andover, Massachusetts. It was presented to Modicon by GM, when the unit was retired after nearly twenty years of uninterrupted service. Modicon used the 84 moniker at the end of its product range until the 984 made its appearance.

The automotive industry is still one of the largest users of PLCs.

In a parallel development Odo Josef Struger is sometimes known as the "father of the programmable logic controller" as well. He was involved in the invention of the Allen-Bradley programmable logic controller (PLC) during 1958 to 1960. Struger is credited with creating the PLC acronym. Rockwell (Allen-Bradley) became a major programmable logic controller device manufacturer in the United States during the tenure of Struger.

Early PLCs were designed to replace relay logic systems. These PLCs were programmed in "ladder logic", which strongly resembles a schematic diagram of relay logic. This program notation was chosen to reduce training demands for the existing technicians. Other early PLCs used a form of instruction list programming, based on a stack-based logic solver.

Modern PLCs can be programmed in a variety of ways, from the relay-derived ladder logic to programming languages such as specially adapted dialects of BASIC and C. Another method is state logic, a very high-level programming language designed to program PLCs based on state transition diagrams. The majority of PLC systems today adhere to the IEC 61131/3 control systems programming standard that defines 5 languages: Ladder Diagram (LD), Structured Text (ST), Function Block Diagram (FBD), Instruction List (IL) and Sequential Flow Chart (SFC).

Many early PLCs did not have accompanying programming terminals that were capable of graphical representation of the logic, and so the logic was instead represented as a series of logic expressions in some version of Boolean format, similar to Boolean algebra. As programming terminals evolved, it became more common for ladder logic to be used, for the aforementioned reasons and because it was a familiar format used for electromechanical control panels. Newer formats such as state logic and Function Block (which is similar to the way logic is depicted when using digital integrated logic circuits) exist, but they are still not as popular as ladder logic. A primary reason for this is that PLCs solve the logic in a predictable and repeating sequence, and ladder logic allows the programmer (the person writing the logic) to see any issues with the timing of the logic sequence more easily than would be possible in other formats.

Early PLCs, up to the mid-1990s, were programmed using proprietary programming panels or special-purpose programming terminals, which often had dedicated function keys representing the various logical elements of PLC programs. Some proprietary programming terminals displayed the elements of PLC programs as graphic symbols, but plain ASCII character representations of contacts, coils, and wires were common. Programs were stored on cassette tape cartridges. Facilities for printing and documentation were minimal due to lack of memory capacity. The oldest PLCs used non-volatile magnetic core memory.

More recently, PLCs are programmed using application software on personal computers, which now represent the logic in graphic form instead of character symbols. The computer is connected to the PLC through USB, Ethernet, RS-232, RS-485, or RS-422 cabling. The programming software allows entry and editing of the ladder-style logic. In some software packages, it is also possible to view and edit the program in function block diagrams, sequence flow charts and structured text. Generally the software provides functions for debugging and troubleshooting the PLC software, for example, by highlighting portions of the logic to show current status during operation or via simulation. The software will upload and download the PLC program, for backup and restoration purposes. In some models of programmable controller, the program is transferred from a personal computer to the PLC through a programming board which writes the program into a removable chip such as an EPROM.

The functionality of the PLC has evolved over the years to include sequential relay control, motion control, process control, distributed control systems, and networking. The data handling, storage, processing power, and communication capabilities of some modern PLCs are approximately equivalent to desktop computers. PLC-like programming combined with remote I/O hardware, allow a general-purpose desktop computer to overlap some PLCs in certain applications. Desktop computer controllers have not been generally accepted in heavy industry because the desktop computers run on less stable operating systems than do PLCs, and because the desktop computer hardware is typically not designed to the same levels of tolerance to temperature, humidity, vibration, and longevity as the processors used in PLCs. Operating systems such as Windows do not lend themselves to deterministic logic execution, with the result that the controller may not always respond to changes of input status with the consistency in timing expected from PLCs. Desktop logic applications find use in less critical situations, such as laboratory automation and use in small facilities where the application is less demanding and critical, because they are generally much less expensive than PLCs.

The most basic function of a programmable controller is to emulate the functions of electromechanical relays. Discrete inputs are given a unique address, and a PLC instruction can test if the input state is on or off. Just as a series of relay contacts perform a logical AND function, not allowing current to pass unless all the contacts are closed, so a series of "examine if on" instructions will energize its output storage bit if all the input bits are on. Similarly, a parallel set of instructions will perform a logical OR. In an electromechanical relay wiring diagram, a group of contacts controlling one coil is called a "rung" of a "ladder diagram ", and this concept is also used to describe PLC logic. Some models of PLC limit the number of series and parallel instructions in one "rung" of logic. The output of each rung sets or clears a storage bit, which may be associated with a physical output address or which may be an "internal coil" with no physical connection. Such internal coils can be used, for example, as a common element in multiple separate rungs. Unlike physical relays, there is usually no limit to the number of times an input, output or internal coil can be referenced in a PLC program.

Some PLCs enforce a strict left-to-right, top-to-bottom execution order for evaluating the rung logic. This is different from electromechanical relay contacts, which in a sufficiently complex circuit may either pass current left-to-right or right-to-left, depending on the configuration of surrounding contacts. The elimination of these "sneak paths" is either a bug or a feature, depending on programming style.

More advanced instructions of the PLC may be implemented as functional blocks, which carry out some operation when enabled by a logical input and which produce outputs to signal, for example, completion or errors, while manipulating variable internally that may not correspond to discrete logic.

The main function of a timer is to keep an output on for a specific length of time. A good example of this is a garage light, where you want power to be cut off after 2 minutes so as to give someone time to go into the house. The three different types of timers that are commonly used are a Delay-OFF, a Delay-ON, and a Delay-ON-Retentive. A Delay-OFF timer activates immediately when turned on, counts down from a programmed time before cutting off, and is cleared when the enabling input is off. A Delay-ON timer is activated by input and starts accumulating time, counts up to a programmed time before cutting off, and is cleared when the enabling input is turned off. A Delay-ON-Retentive timer is activated by input and starts accumulating time, retains the accumulated value even if the (ladder-logic) rung goes false, and can be reset only by a RESET contact.

Counters are primarily used for counting items such as cans going into a box on an assembly line. This is important because once something is filled to its max the item needs to be moved on so something else can be filled. Many companies use counters in PLC's to count boxes, count how many feet of something is covered, or to count how many pallets are on a truck. There are three types of counters, Up counters, Down counters, and Up/Down counters. Up counters count up to the preset value, turn on the CTU (CounT Up output) when the preset value is reached, and are cleared upon receiving a reset. Down counters count down from a preset value, turns on the CTD (CounT Down output) when 0 is reached, and are cleared upon reset. Up/Down counters count up on CU, count down on CD, turn on CTUD (CounT Up/Down output) when the preset value is reached, and cleared on reset.

In more recent years, small products called PLRs (programmable logic relays), and also by similar names, have become more common and accepted. These are much like PLCs, and are used in light industry where only a few points of I/O (i.e. a few signals coming in from the real world and a few going out) are needed, and low cost is desired. These small devices are typically made in a common physical size and shape by several manufacturers, and branded by the makers of larger PLCs to fill out their low end product range. Popular names include PICO Controller, NANO PLC, and other names implying very small controllers. Most of these have 8 to 12 discrete inputs, 4 to 8 discrete outputs, and up to 2 analog inputs. Size is usually about 4" wide, 3" high, and 3" deep. Most such devices include a tiny postage-stamp-sized LCD screen for viewing simplified ladder logic (only a very small portion of the program being visible at a given time) and status of I/O points, and typically these screens are accompanied by a 4-way rocker push-button plus four more separate push-buttons, similar to the key buttons on a VCR remote control, and used to navigate and edit the logic. Most have a small plug for connecting via RS-232 or RS-485 to a personal computer so that programmers can use simple Windows applications for programming instead of being forced to use the tiny LCD and push-button set for this purpose. Unlike regular PLCs that are usually modular and greatly expandable, the PLRs are usually not modular or expandable, but their price can be two orders of magnitude less than a PLC, and they still offer robust design and deterministic execution of the logics.

The main difference from most other computing devices is that PLCs are intended-for and therefore tolerant-of more severe conditions (such as dust, moisture, heat, cold), while offering extensive input/output (I/O) to connect the PLC to sensors and actuators. PLC input can include simple digital elements such as limit switches, analog variables from process sensors (such as temperature and pressure), and more complex data such as that from positioning or machine vision systems. PLC output can include elements such as indicator lamps, sirens, electric motors, pneumatic or hydraulic cylinders, magnetic relays, solenoids, or analog outputs. The input/output arrangements may be built into a simple PLC, or the PLC may have external I/O modules attached to a fieldbus or computer network that plugs into the PLC.

A PLC program generally loops i.e. executes repeatedly, as long as the controlled system is running. At the start of each execution loop, the status of all physical inputs are copied to an area of memory, sometimes called the "I/O Image Table", which is accessible to the processor. The program then runs from its first instruction rung down to the last rung. It takes some time for the processor of the PLC to evaluate all the rungs and update the I/O image table with the status of outputs. Scan times of a few milliseconds may be encountered for small programs and fast processors, but for older processors and very large programs much longer scan times (on the order of 100 ms) may be encountered. Excessively long scan times may mean the response of the PLC to changing inputs or process conditions is too slow to be useful.

As PLCs became more advanced, methods were developed to change the sequence of ladder execution, and subroutines were implemented. This simplified programming could be used to save scan time for high-speed processes; for example, parts of the program used only for setting up the machine could be segregated from those parts required to operate at higher speed. Newer PLCs now have the option to run the logic program synchronously with the IO scanning. This means that IO is updated in the background and the logic reads and writes values as it's required during the logic scanning.

Special-purpose I/O modules may be used where the scan time of the PLC is too long to allow predictable performance. Precision timing modules, or counter modules for use with shaft encoders, are used where the scan time would be too long to reliably count pulses or detect the sense of rotation of an encoder. This allows even a relatively slow PLC to still interpret the counted values to control a machine, as the accumulation of pulses is done by a dedicated module that is unaffected by the speed of program execution on the PLC.

There are 5 main steps in a scan cycle:

A small PLC will have a fixed number of connections built in for inputs and outputs. Typically, expansions are available if the base model has insufficient I/O.

Modular PLCs have a chassis (also called a rack) into which are placed modules with different functions. The processor and selection of I/O modules are customized for the particular application. Several racks can be administered by a single processor, and may have thousands of inputs and outputs. Either a special high speed serial I/O link or comparable communication method is used so that racks can be distributed away from the processor, reducing the wiring costs for large plants. Options are also available to mount I/O points directly to the machine and utilize quick disconnecting cables to sensors and valves, saving time for wiring and replacing components.

PLCs may need to interact with people for the purpose of configuration, alarm reporting, or everyday control. A human-machine interface (HMI) is employed for this purpose. HMIs are also referred to as man-machine interfaces (MMIs) and graphical user interfaces (GUIs). A simple system may use buttons and lights to interact with the user. Text displays are available as well as graphical touch screens. More complex systems use programming and monitoring software installed on a computer, with the PLC connected via a communication interface.

Many models of PLCs have built-in communications ports, using RS-232, RS-422, RS-485, or Ethernet. Various protocols are usually included. Many of these protocols are vendor specific.

Most modern PLCs can communicate over a network to some other system, such as a computer running a SCADA (Supervisory Control And Data Acquisition) system or web browser.

PLCs used in larger I/O systems may have peer-to-peer (P2P) communication between processors. This allows separate parts of a complex process to have individual control while allowing the subsystems to co-ordinate over the communication link. These communication links are also often used for HMI devices such as keypads or PC-type workstations.

Formerly, some manufacturers offered dedicated communication modules as an add-on function where the processor had no network connection built-in.

PLC programs are typically written in a special application on a personal computer, then downloaded by a direct-connection cable or over a network to the PLC. The program is stored in the PLC either in battery-backed-up RAM or some other non- volatile flash memory. Often, a single PLC can be programmed to replace thousands of relays.

Under the IEC 61131-3 standard, PLCs can be programmed using standards-based programming languages. The most commonly used programming language is Ladder diagram (LD) also known as Ladder logic. It uses Contact-Coil logic to make programs like an electrical control diagram. A graphical programming notation called Sequential Function Charts is available on certain programmable controllers. A model which emulated electromechanical control panel devices (such as the contact and coils of relays) which PLCs replaced. This model remains common today.

IEC 61131-3 currently defines five programming languages for programmable control systems: function block diagram (FBD), ladder diagram (LD), structured text (ST; similar to the Pascal programming language), instruction list (IL; similar to assembly language), and sequential function chart (SFC). These techniques emphasize logical organization of operations.

While the fundamental concepts of PLC programming are common to all manufacturers, differences in I/O addressing, memory organization, and instruction sets mean that PLC programs are never perfectly interchangeable between different makers. Even within the same product line of a single manufacturer, different models may not be directly compatible.

This is a programming example in ladder diagram which shows the control system. A ladder diagram is a method of drawing control circuits which pre-dates PLCs. The ladder diagram resembles the schematic diagram of a system built with electromechanical relays.

As an example, say a facility needs to store water in a tank. The water is drawn from the tank by another system, as needed, and our example system must manage the water level in the tank by controlling the valve that refills the tank. . Shown are:


In ladder diagram, the contact symbols represent the state of bits in processor memory, which corresponds to the state of physical inputs to the system. If a discrete input is energized, the memory bit is a 1, and a "normally open" contact controlled by that bit will pass a logic "true" signal on to the next element of the ladder. Therefore, the contacts in the PLC program that "read" or look at the physical switch contacts in this case must be "opposite" or open in order to return a TRUE for the closed physical switches. Internal status bits, corresponding to the state of discrete outputs, are also available to the program.

In the example, the physical state of the float switch contacts must be considered when choosing "normally open" or "normally closed" symbols in the ladder diagram. The PLC has two discrete inputs from float switches (Low Level and High Level). Both float switches (normally closed) open their contacts when the water level in the tank is above the physical location of the switch.

When the water level is below both switches, the float switch physical contacts are both closed, and a true (logic 1) value is passed to the Fill Valve output. Water begins to fill the tank. The internal "Fill Valve" contact latches the circuit so that even when the "Low Level" contact opens (as the water passes the lower switch), the fill valve remains on. Since the High Level is also normally closed, water continues to flow as the water level remains between the two switch levels. Once the water level rises enough so that the "High Level" switch is off (opened), the PLC will shut the inlet to stop the water from overflowing; this is an example of seal-in (latching) logic. The output is sealed in until a high level condition breaks the circuit. After that the fill valve remains off until the level drops so low that the Low Level switch is activated, and the process repeats again.
A complete program may contain thousands of rungs, evaluated in sequence. Typically the PLC processor will alternately scan all its inputs and update outputs, then evaluate the ladder logic; input changes during a program scan will not be effective until the next I/O update. A complete program scan may take only a few milliseconds, much faster than changes in the controlled process.

Programmable controllers vary in their capabilities for a "rung" of a ladder diagram. Some only allow a single output bit. There are typically limits to the number of series contacts in line, and the number of branches that can be used. Each element of the rung is evaluated sequentially. If elements change their state during evaluation of a rung, hard-to-diagnose faults can be generated, although sometimes (as above) the technique is useful. Some implementations forced evaluation from left-to-right as displayed and did not allow reverse flow of a logic signal (in multi-branched rungs) to affect the output.

Prior to the discovery of the Stuxnet computer worm in June 2010, security of PLCs received little attention. Modern PLCs generally contain a real-time operating system such as OS-9 or VxWorks, and exploits for these systems exist much as they do for desktop computer operating systems such as Microsoft Windows. PLCs can also be attacked by gaining control of a computer they communicate with.

In order to properly understand the operation of a PLC, it is necessary to spend considerable time programming, testing, and debugging PLC programs. PLC systems are inherently expensive, and down-time is often very costly. In addition, if a PLC is programmed incorrectly it can result in lost productivity and dangerous conditions. PLC simulation software such as PLCLogix can save time in the design of automated control applications and can also increase the level of safety associated with equipment since various "what if" scenarios can be tried and tested before the system is activated.

Some special processes need to work permanently with minimum unwanted down time. Therefore, it is necessary to design a system which is fault-tolerant and capable of handling the process with faulty modules. In such cases to increase the system availability in the event of hardware component failure, redundant CPU or I/O modules with the same functionality can be added to hardware configuration for preventing total or partial process shutdown due to hardware failure.

PLCs are well adapted to a range of automation tasks. These are typically industrial processes in manufacturing where the cost of developing and maintaining the automation system is high relative to the total cost of the automation, and where changes to the system would be expected during its operational life. PLCs contain input and output devices compatible with industrial pilot devices and controls; little electrical design is required, and the design problem centers on expressing the desired sequence of operations. PLC applications are typically highly customized systems, so the cost of a packaged PLC is low compared to the cost of a specific custom-built controller design. On the other hand, in the case of mass-produced goods, customized control systems are economical. This is due to the lower cost of the components, which can be optimally chosen instead of a "generic" solution, and where the non-recurring engineering charges are spread over thousands or millions of units.

For high volume or very simple fixed automation tasks, different techniques are used. For example, a cheap consumer dishwasher would be controlled by an electromechanical cam timer costing only a few dollars in production quantities.

A microcontroller-based design would be appropriate where hundreds or thousands of units will be produced and so the development cost (design of power supplies, input/output hardware, and necessary testing and certification) can be spread over many sales, and where the end-user would not need to alter the control. Automotive applications are an example; millions of units are built each year, and very few end-users alter the programming of these controllers. However, some specialty vehicles such as transit buses economically use PLCs instead of custom-designed controls, because the volumes are low and the development cost would be uneconomical.

Very complex process control, such as used in the chemical industry, may require algorithms and performance beyond the capability of even high-performance PLCs. Very high-speed or precision controls may also require customized solutions; for example, aircraft flight controls. Single-board computers using semi-customized or fully proprietary hardware may be chosen for very demanding control applications where the high development and maintenance cost can be supported. "Soft PLCs" running on desktop-type computers can interface with industrial I/O hardware while executing programs within a version of commercial operating systems adapted for process control needs.

Programmable controllers are widely used in motion, positioning, or torque control. Some manufacturers produce motion control units to be integrated with PLC so that G-code (involving a CNC machine) can be used to instruct machine movements.

PLCs may include logic for single-variable feedback analog control loop, a proportional, integral, derivative (PID) controller. A PID loop could be used to control the temperature of a manufacturing process, for example. Historically PLCs were usually configured with only a few analog control loops; where processes required hundreds or thousands of loops, a distributed control system (DCS) would instead be used. As PLCs have become more powerful, the boundary between DCS and PLC applications has been blurred.

PLCs have similar functionality as remote terminal units. An RTU, however, usually does not support control algorithms or control loops. As hardware rapidly becomes more powerful and cheaper, RTUs, PLCs, and DCSs are increasingly beginning to overlap in responsibilities, and many vendors sell RTUs with PLC-like features, and vice versa. The industry has standardized on the IEC 61131-3 functional block language for creating programs to run on RTUs and PLCs, although nearly all vendors also offer proprietary alternatives and associated development environments.

In recent years "safety" PLCs have started to become popular, either as standalone models or as functionality and safety-rated hardware added to existing controller architectures (Allen-Bradley Guardlogix, Siemens F-series etc.). These differ from conventional PLC types as being suitable for use in safety-critical applications for which PLCs have traditionally been supplemented with hard-wired safety relays. For example, a safety PLC might be used to control access to a robot cell with trapped-key access, or perhaps to manage the shutdown response to an emergency stop on a conveyor production line. Such PLCs typically have a restricted regular instruction set augmented with safety-specific instructions designed to interface with emergency stops, light screens, and so forth. The flexibility that such systems offer has resulted in rapid growth of demand for these controllers.

Discrete (digital) signals behave as binary switches, yielding simply an On or Off signal (1 or 0, True or False, respectively). Push buttons, limit switches, and photoelectric sensors are examples of devices providing a discrete signal. Discrete signals are sent using either voltage or current, where a specific range is designated as "On" and another as "Off". For example, a PLC might use 24 V DC I/O, with values above 22 V DC representing "On", values below 2VDC representing "Off", and intermediate values undefined. Initially, PLCs had only digital I/O.

Analog signals are like volume controls, with a range of values between zero and full-scale. These are typically interpreted as integer values (counts) by the PLC, with various ranges of accuracy depending on the device and the number of bits available to store the data. As PLCs typically use 16-bit signed binary processors, the integer values are limited between -32,768 and +32,767. Pressure, temperature, flow, and weight are often represented by analog signals. Analog signals can use voltage or current with a magnitude proportional to the value of the process signal. For example, an analog 0 to 10 V or 4-20 mA input would be converted into an integer value of 0 to 32767.

Current inputs are less sensitive to electrical noise (e.g. from welders or electric motor starts) than voltage inputs.

PLCs are at the forefront of manufacturing automation. An engineer working in a manufacturing environment will at least encounter some PLCs, if not use them on a regular basis. Electrical engineering students should have basic knowledge of PLCs because of their widespread use in industrial applications.




</doc>
<doc id="24994" url="https://en.wikipedia.org/wiki?curid=24994" title="Peter David">
Peter David

Peter Allen David (born September 23, 1956) often abbreviated PAD, is an American writer of comic books, novels, television, films and video games. His notable comic book work includes an award-winning 12-year run on "The Incredible Hulk", as well as runs on "Aquaman", "Young Justice", "Supergirl", "Fallen Angel", "Spider-Man 2099" and "X-Factor".

His "Star Trek" work includes both comic books and novels such as "Imzadi", and co-creating the "" series. His other novels include film adaptations, media tie-ins, and original works, such as the "Apropos of Nothing" and "Knight Life" series. His television work includes series such as "Babylon 5", "Young Justice", "" and Nickelodeon's "Space Cases", which he co-created with Bill Mumy.

David often jokingly describes his occupation as "Writer of Stuff", and is noted for his prolific writing, characterized by its mingling of real-world issues with humor and references to popular culture, as well as elements of metafiction and self-reference.

David has earned multiple awards for his work, including a 1992 Eisner Award, a 1993 "Wizard" Fan Award, a 1996 Haxtur Award, a 2007 Julie Award and a 2011 GLAAD Media Award.

Peter David's paternal grandparents, Martin and Hela David, and Peter's father, Gunter, came to the United States in the 1930s after the antisemitism in Nazi Germany progressed to the point that Martin's Berlin shoestore became the target of vandalism. David was born September 23, 1956 in Fort Meade, Maryland to Gunter David and Dalia David (née Rojansky), an Israeli-born Jewish mother who had worked with DNA mappers James Watson and Francis Crick, and to whom David credits his sense of humor. He has two siblings, a brother Wally, seven years his junior, who works as a still life photographer and musician, and a younger sister named Beth.

David first became interested in comics when he was about five years old, reading copies of Harvey Comics' "Casper" and "Wendy" in a barbershop. He became interested in superheroes through the "Adventures of Superman" TV series. Although David's parents approved of his reading Harvey Comics and comics featuring Disney characters, they did not approve of superhero books, especially those published by Marvel Comics, feeling that characters that looked like monsters, such as the Thing or the Hulk, or who wore bug-eyed costumes, like Spider-Man, did not appear heroic. As a result, David read those comics in secret, beginning with his first Marvel book, "Fantastic Four Annual" #3 (November 1965), which saw the wedding of Mister Fantastic and the Invisible Woman. His parents eventually allowed him to start reading superhero titles, his favorite of which was "Superman". He cites John Buscema as his favorite pre-1970s artist. David attended his first comic book convention around the time that Jack Kirby's "New Gods" premiered, after asking his father to take him to one of Phil Seuling's shows in New York, where David obtained Kirby's autograph, his first encounter with a comics professional.

David's earliest interest in writing came through the journalism work of his father, Gunter, who would sometimes review movies, and take young David along if it was age-appropriate. While Gunter would write his reviews back at the newspaper's office, David would write his own, portions of which would sometimes find their way into Gunter's published reviews. David began to entertain the notion of becoming a professional writer at age twelve, buying a copy of "The Guide to the Writer's Market", and subscribing to similar-themed magazines, in the hopes of becoming a reporter.

David lived in Bloomfield, New Jersey, in a small house at 11 Albert Terrace, and attended Demarest Elementary School. His family later moved to Verona, New Jersey, where he spent his adolescence. By the time he entered his teens, he had lost interest in comic books, feeling he had outgrown them. David's best friend in junior high and first year in high school, Keith, was gay, and David has described how both of them were targets of ostracism and harassment from homophobes.

Although his family eventually moved to Pennsylvania, his experiences in Verona soured him on that town, and would shape his liberal sociopolitical positions regarding LGBT issues. He would later make Verona the home location of villain Morgan le Fay in his novel "Knight Life", and has often discussed his progressive views on LGBT issues in his column and on his blog.

David's interest in comics was rekindled when he saw a copy of "Superman vs. Muhammad Ali" (1978) while passing a newsstand, and later, "X-Men" #95 (October 1975), and discovered in that latter book the "All-New, All-Different" team that had first appeared in "Giant-Size X-Men" #1 (May 1975). These two books were the first comics he had purchased in years.

A seminal moment in the course of his aspirations occurred when he met writer Stephen King at a book signing, and told him that he was an aspiring writer. King signed David's copy of "Danse Macabre" with the inscription, "Good luck with your writing career.", which David now inscribes himself onto books presented to him by fans who tell him the same thing. Other authors that David cites as influences include Harlan Ellison, Arthur Conan Doyle, Robert B. Parker, Neil Gaiman, Terry Pratchett, Robert Crais and Edgar Rice Burroughs. Specific books he has mentioned as favorites include "To Kill a Mockingbird", "Tarzan of the Apes", "The Princess Bride", "The Essential Ellison", "A Confederacy of Dunces", "Adams Versus Jefferson", and "Don Quixote". David has singled out Ellison in particular as a writer whom he has tried to emulate.

David attended New York University, where he graduated with a Bachelor of Arts degree in journalism.

David's first professional assignment was covering the World Science Fiction Convention held in Washington in 1974 for the "Philadelphia Bulletin".

David eventually gravitated towards fiction after his attempts at journalism did not meet with success. His first published fiction was in "Asimov's Science Fiction". He sold an op-ed piece to "The New York Times", but overall his submissions were met with rejection that far outnumbered those accepted.

David eventually gave up on a career in writing, and came to work in book publishing. His first publishing job was for the E.P. Dutton imprint Elsevier/Nelson, where he worked mainly as an assistant to the editor-in-chief. He later worked in sales and distribution for Playboy Paperbacks. He subsequently worked for five years in Marvel Comics' Sales Department, first as Assistant Direct Sales Manager under Carol Kalish, who hired him, and then succeeding Kalish as Sales Manager. During this time he made some cursory attempts to sell stories, including submission of some Moon Knight plots to Dennis O'Neil, but his efforts were unfruitful. 

Three years into David's tenure as Direct Sales Manager, Jim Owsley became editor of the Spider-Man titles. Although crossing over from sales into editorial was considered a conflict of interest in the Marvel offices, Owsley, whom David describes as a "maverick," was impressed with how David had not previously hesitated to work with him when Owsley was an assistant editor under Larry Hama. When Owsley became an editor, he purchased a Spider-Man story from David, which appeared in "The Spectacular Spider-Man" #103 (June 1985). Owsley subsequently purchased from David "The Death of Jean DeWolff", a violent murder mystery darker in tone than the usually lighter Spider-Man stories that ran in issues #107–110 (October 1985 – January 1986) of that title. Responding to charges of conflict of interest, David made a point of not discussing editorial matters with anyone during his 9-to-5 hours as Direct Sales Manager, and decided not to exploit his position as Sales Manager by promoting the title. Although David attributes the story's poor sales to this decision, he asserts that such crossing over from Sales to Editorial is now common. In the Marvel offices, a rumor circulated that it was actually Owsley who was writing the stories attributed to David. Nonetheless, David says he was fired from "Spectacular Spider-Man" by Owsley due to editorial pressure by Marvel's Editor-in-Chief Jim Shooter, and has commented that the resentment stirred by Owsley's purchase of his stories may have permanently damaged Owsley's career. Months later, Bob Harras offered David "The Incredible Hulk", as it was a struggling title that no one else wanted to write, which gave David free rein to do whatever he wanted with the character.

During his 12-year run on "Hulk", David explored the recurring themes of the Hulk's multiple personality disorder, his periodic changes between the more rageful and less intelligent Green Hulk and the more streetwise, cerebral Gray Hulk, and of being a journeyman hero, which were inspired by "The Incredible Hulk" #312 (October 1985), in which writer Bill Mantlo (and possibly, according to David, Barry Windsor-Smith) had first established that Banner had suffered childhood abuse at the hands of his father. These aspects of the character would later be used in the 2003 feature film adaptation by screenwriter Michael France and director Ang Lee. Comic Book Resources credits David with making the formerly poor-selling book "a must-read mega-hit". David collaborated with a number of artists who became fan-favorites on the series, including Todd McFarlane, Dale Keown and Gary Frank. Among the new characters he created during his run on the series were the Riot Squad and the Pantheon. David wrote the first appearance of the Thunderbolts, a team created by Kurt Busiek and Mark Bagley, in "The Incredible Hulk" #449 (January 1997).

It was after he had been freelancing for a year, and into his run on "Hulk", that David felt that his writing career had cemented. After putting out feelers at DC Comics, and being offered the job of writing a four-issue miniseries of The Phantom by editor Mike Gold, David quit his sales position to write full-time. David had a brief tenure writing Green Lantern, when the character was exclusive to the short-lived anthology series, "Action Comics Weekly" from issues #608–620 in 1988.

David took over "Dreadstar" during its First Comics run, with issue #41 (March 1989) after Jim Starlin left the title, and remained on it until issue #64 (March 1991), the final issue of that run. David's other Marvel Comics work in the late 1980s and 1990s includes runs on "Wolverine", the New Universe series "" and "Justice", a run on the original "X-Factor", and the futuristic series "Spider-Man 2099", about a man in the year 2099 who takes up the mantle of Spider-Man, the title character of which David co-created. David left "X-Factor" after 19 issues, and wrote the first 44 issues of "Spider-Man 2099", before quitting that book to protest the firing of editor Joey Cavalieri. The book was cancelled two issues later, along with the entire 2099 line.

In 1990, David wrote a seven-issue "Aquaman" miniseries, "The Atlantis Chronicles", for DC Comics, about the history of Aquaman's home of Atlantis, which David has referred to as among the written works of which he is most proud. He would later write a 1994 "Aquaman" miniseries, "Aquaman: Time and Tide", which would lead to a relaunched monthly "Aquaman" series, the first 46 issues of which he would write from 1994–1998. His run on "Aquaman" gained notoriety, for in the book's second issue, Aquaman lost a hand, which was then replaced with a harpoon, a feature of the character that endured for the duration of David's run on the book. More broadly, his run recast the character as an aggressive man of action, one deserving of greater respect, in contrast to the "fish-talking punch line" into which the TV series "Super Friends" had rendered him. David quit that book over creative differences. 

David wrote the "Star Trek" comic book for DC from 1988–1991, when that company held the licensing rights to the property, though he has opined that novels are better suited to "Star Trek", whose stories are not highly visual. He and Ron Marz cowrote the "DC vs. Marvel" intercompany crossover in 1996. David enjoyed considerable runs on "Supergirl" and "Young Justice", the latter eventually being canceled so that DC could use that book's characters in a relaunched "Teen Titans" monthly.

David's work for Dark Horse Comics has included the teen spy adventure "SpyBoy", which appeared in a series and a number of miniseries between 1999 and 2004, and the 2007 miniseries "The Scream".

Other 1990s work includes the 1997 miniseries "Heroes Reborn: The Return", for Marvel, and two creator-owned properties: "Soulsearchers and Company", published by Claypool Comics, and the Epic Comics title "Sachs and Violens", which he produced with co-creator/artist George Pérez.

David's early 2000s work includes runs on two volumes of "Captain Marvel", which debuted in 2000 and 2002 as well as the "Before the Fantastic Four: Reed Richards" limited series.

David and his second wife, Kathleen, wrote the final English-language text for the first four volumes of the manga series "Negima" for Del Rey Manga.

In 2003, David began writing another creator-owned comic, "Fallen Angel", for DC Comics, which he created in order to make use of plans he had devised for Supergirl after the "Many Happy Returns" storyline, but which were derailed by that series' cancellation. That same year, he wrote a "Teenage Mutant Ninja Turtles" series for Dreamwave that tied into the animated television series broadcast that year.

DC canceled "Fallen Angel" after 20 issues, but David restarted the title at IDW Publishing at the end of 2005. Other IDW work included a "" one-shot and the "Spike vs. Dracula" mini-series, both based on the character from the "Buffy the Vampire Slayer" and "Angel" television series.
In 2005, David briefly returned to "The Incredible Hulk", though he left after only 11 issues because of his workload. He started a new series, "Friendly Neighborhood Spider-Man", beginning with a twelve-part crossover storyline called "", which, along with J. Michael Straczynski's run on "The Amazing Spider-Man", and Reginald Hudlin's run on "Marvel Knights Spider-Man," depicted the webslinger as he discovered he was dying, lost an eye during a traumatic fight with Morlun, underwent a metamorphosis and emerged with new abilities and insights into his powers. As tends to be the case when fundamental changes are introduced to long-standing classic comics characters, the storyline caused some controversy among readers for its introduction of retractable stingers in Spider-Man's arms, and the establishment of a "totem" from which his powers are derived. David's final issue of that title was #23.

David wrote a "MadroX" miniseries that year, whose success led to a relaunch of a monthly "X-Factor" volume 3 written by him. This was a revamped version of the title starring both Madrox and other members of the former "X-Factor" title that David had written in the early 1990s, now working as investigators in a detective agency of that name. David's work on the title garnered praise from Ain't it Cool News, and David has stated that the opt in/opt out policy and greater planning with which Marvel now executes crossover storylines has made his second stint on the title far easier. His decision to explicitly establish male characters Shatterstar and Rictor as sharing a homosexual attraction to one another (a confirmation of clues that had been established in "X-Force" years earlier in issues such as "X-Force" #25, 34, 43, 49, 56 and "X-Force '99 Annual"), drew criticism from Shatterstar's co-creator, Rob Liefeld, though Editor-in-Chief Joe Quesada supported David's story. David would eventually win a 2011 GLAAD Media Award for Outstanding Comic Book for his work on the title.

On February 11, 2006, David announced at the WonderCon convention in California in that he had signed an exclusive contract with Marvel Comics. "Fallen Angel", "Soulsearchers and Company" and David's "Spike" miniseries were "grandfathered" into the contract, so as to not be affected by it. The first new project undertaken by David after entering into the contract, which he announced on April 5, 2006, was writing the dialogue for "", the comic book spin-off of Stephen King's "The Dark Tower" novels, which would be illustrated by Jae Lee. He would script the subsequent "Dark Tower" comics as well.

David took over Marvel's "She-Hulk" after writer Dan Slott's departure, beginning with issue #22. His run, which won praise, ended with issue #38, when the series was canceled. He wrote a 2008–09 "Sir Apropos of Nothing" miniseries, based on the character from his novels, which was published by IDW Publishing.

David's other 2000s comics based on licensed or adapted properties include "Halo: Helljumper", a 2009 miniseries based on the "Halo" video game, a 2009 "" manga book published by Del Rey, "Ben Folds Four", a "Little Mermaid" story in Jim Valentino's "Fractured Fables" anthology that was praised by Ain't It Cool News, an adaptation of the 1982 film "Tron" that was released to tie in with that film's , and a "John Carter of Mars" prequel to the 2012 feature film. In 2010, he co-wrote "The Spider-Man Vault: A Museum-in-a-Book with Rare Collectibles Spun from Marvel's Web" with Robert Greenberger. David wrote the script for "Avengers: Season One", an original graphic novel published to promote the DVD release of "The Avengers".

On November 24, 2011, David was one of the balloon handlers who pulled the Spider-Man balloon during the Macy's Thanksgiving Day Parade.
In October 2013, "X-Factor" ended its run with issue #262, concluding the X-Factor Investigations incarnation of the series. The book was then relaunched as "All-New X-Factor", a new series with artist Carmine Di Giandomenico, as a part of the All-New Marvel NOW! initiative announced at the 2013 New York Comic Con. The opening storyline, which continues events from issue #260 of the previous series, establishes the new corporate-sponsored version of the team, and includes Polaris, Quicksilver, and Gambit.

In July 2014, David returned to Spider-Man 2099, writing the second volume of "Spider-Man 2099" with artist Will Sliney. With this series, David would again be writing two series, "X-Factor" and "Spider-Man 2099", after having previously done so over decades prior, a coincidence that prompted him to joke at the June 2014 Special Edition NYC convention, "I don't know whether to be proud of that or if I'm in a rut!"

In 2014 David wrote a six-part story-arc for "The Phantom" for publishing company Hermes Press, a story that David, reportedly had wanted to write for many years.

In 2015, Simon and Schuster published Stan Lee's autobiographical graphic novel, "Amazing Fantastic Incredible", which David co-wrote, and which became a "New York Times" bestseller in its first week of release.

In April 2017, following the conclusion of the Spider-Man storyline "", which saw the return of Ben Reilly, Marvel premiered the monthly series "", with David as writer. David explained to Syfy Wire that when Marvel offered him the job, he was initially ambivalent, as Ben Reilly had never been his favorite incarnation of Spider-Man, and given Reilly's recent emergence as the villainous Jackal. However, David gave further consideration to the fact that a book whose main character had a skewed, villainous worldview was not something Marvel had historically done much of, and decided that the premise presented itself with opportunities that intrigued him enough to accept the job.

David's career as a novelist developed concurrently with his comic-book writing career. David had been working at a publisher that went out of business, and a former coworker from that publisher became his agent, through whom he sold his first novel, "Knight Life", to Ace Books. Although the sale was made before he wrote any comic books, the novel was not published until eighteen months later, in 1987. The novel depicts the reappearance of King Arthur in modern-day New York City. Another early novel of his, "Howling Mad", is about a wolf that turns into a human being after being bitten by a werewolf. Ace Books hired David to write the "Photon" and "Psi-Man" novels, though they published them under the "house name" David Peters, over David's objections. David updated "Knight Life" years later when Penguin Putnam brought it back into print in 2003, and made it a trilogy with the sequels "One Knight Only" and "Fall of Knight", which were published in 2004 and 2007, respectively. Penguin would rerelease "Howling Mad" and the "Psi-Man books" under David's actual name.

David first began writing "Star Trek" novels at the request of Pocket Books editor Dave Stern, who was a fan of David's "Star Trek" comic book work. His "Star Trek" novels are among those for which he is best known, including "Q-in-Law"; "I, Q"; "Vendetta"; "Q-Squared"; and "Imzadi", one of the best-selling Star Trek novels of all time. He created the ongoing novel series, "," a spin-off from "," with John J. Ordover in 1997. "New Frontier" continued until April 2011, with the publication of "Blind Man's Bluff", the final "New Frontier" novel on David's contract at the time, after which the series' future was unclear to David. David's other science fiction tie-in novels include written five "Babylon 5" novels, three of which were originals, and two of which were adaptations of the TV movies "" and "".

His other novel adaptations include those of the movies "The Return of Swamp Thing", "The Rocketeer", "Batman Forever", "Spider-Man", "Spider-Man 2", "Spider-Man 3", "Hulk", "The Incredible Hulk", "Fantastic Four", and "Iron Man". He wrote an original Hulk novel, "The Incredible Hulk: What Savage Beast", and an adaptation of an unused "Alien Nation" television script, "Body and Soul".

David's 2009 novel "Tigerheart" is a re-imagining of Peter Pan with a mix of new and old characters, told as a Victorian bedtime story, much like the classic tale. It was praised by Ain't It Cool News, and honored by the "School Library Journal" as one of 2008's Best Adult Books for High School Students. His "Sir Apropos of Nothing" fantasy trilogy, "Sir Apropos of Nothing", "The Woad to Wuin" and "Tong Lashing", features characters and settings completely of David's own creation, as does his 2007 fantasy novel, "Darkness of the Light", which is the first in a new trilogy of novels titled "The Hidden Earth". The second installment, "The Highness of the Low", was scheduled to be published in September 2009, but David has related on his blog that it has been delayed until the winter of 2012.

David's 2010 novel work includes "Year of the Black Rainbow", a novel cowritten with musician Claudio Sanchez of the band Coheed and Cambria, that was released with the band's album of the same name, and an "Fable" original novel "The Balverine Order", set between the events of "Fable II" and "Fable III". In April 2011, David announced that, in addition to another "Fable" novel, he and a number of other writers, including Glenn Hauman, Mike Friedman and Bob Greenberger, were assembling an electronic publishing endeavor called Crazy Eight Press, which would allow them to publish e-books directly to fans, the first of which would be David's Arthurian story, "The Camelot Papers". David explained that the second book in his "Hidden Earth" trilogy would be published through Crazy Eight. In September 2013, David acknowledged that books published through Crazy Eight are not as lucrative for him as those for publishers that pay him advances, and announced that his then-impending novel, "ARTFUL: Being the Heretofore Secret History of that Unique Individual, The Artful Dodger, Hunter of Vampyres (Amongst Other Things.)", would be published by Amazon.com.

David has stated that he tries to block out different days and different times to work on different projects. He usually works in the morning, for example, on novels, and does comics-related work in the afternoon. Having previously used Smith Corona typewriters, he writes on a Sony Vaio desktop computer, using Microsoft Word for his comics and novel work, and Final Draft for his screenplays. When writing novels, he sometimes outlines the story, and sometimes improvises it as he is writing it. Following his stroke in December 2012, David began using DragonDictate to write. Todd McFarlane's original art for the cover of "The Incredible Hulk" #340, featuring Wolverine, which McFarlane gave to David as a gift, hangs in David's office.

David previously wrote his comic book scripts using the Marvel Method, but due to his tendency to overplot, as during his collaboration with McFarlane on "The Incredible Hulk", he switched to the full script method, which he continues to use . He has stated that he prefers to plot his comics stories in six-month arcs. He has stated that when he works on a particular title, he always does so with a particular person or group of people in mind to which he dedicates it, explaining that he wrote "Supergirl" for his daughters, "Young Justice" for a son he might one day have and "The Incredible Hulk" for his first wife, Myra, who first urged him to accept the job of writing that book. David has further explained that the events of his own life are sometimes reflected in his work, as when, for example, following the breakup of his first marriage, the direction of "The Incredible Hulk" faltered, with the Hulk wandering the world aimlessly, hopelessly looking to be loved.

David has stated that his favorite female character of his own creation is Lee, the protagonist of "Fallen Angel", which he says is derived from the positive female fan reaction to that character. Characters that David has not written but which he has expressed an interest in writing for the comics medium include Batman, Tarzan, Doc Savage, the Dragonriders of Pern, the Steed/Peel Avengers, and Dracula. He has specifically mentioned interest in writing a "Tarzan vs. the Phantom" story.


David has written for several television series and video games. He wrote two scripts for "Babylon 5" (the second-season episodes "Soul Mates" and "There All the Honor Lies"), and the episode "Ruling from the Tomb" for its sequel series, "Crusade". With actor/writer Bill Mumy, he is co-creator of the television series "Space Cases", which ran for two seasons on Nickelodeon, and which proved to be his most lucrative work. David himself appeared as Ben, the father of series regular Bova, in the second-season episode "Long Distance Calls". David's oldest daughter, Shana, would later appear as Pezu, the emotionally disturbed sentient computer in the series finale "A Friend in Need". David has written and co-produced several films for Full Moon Entertainment and has made cameo appearances in some of the films as well.

David wrote an unproduced script for the fifth season of "Babylon 5" called "Gut Reactions", which he wrote with Bill Mumy.

David wrote "In Charm's Way", an episode of "". The script was recorded in early 2009, and the episode premiered November 13, 2009. He later wrote three episodes of the spinoff "", the first of which, "Reflected Glory", premiered October 15, 2010.

David wrote the script for the Xbox 360 video game "Shadow Complex", which debuted in August 2009.

David wrote several episodes of the "Young Justice" animated TV series, which premiered in 2010, and is based on the comic book series he wrote from 1998 to 2003. The first episode he penned is episode #18. The same year, he wrote a graphic novel adaptation of the video game "Epic Mickey", and a prequel digicomic, "Disney's Epic Mickey: Tales of Wasteland".

In 2011 David wrote the video game "".

At the 2012 San Diego Comic-Con International, Stan Lee announced his new YouTube channel, "Stan Lee's World of Heroes", which airs several programs created by Lee and other creators. One of them, "Head Cases", is a superhero sitcom created by David and his wife Kathleen, and produced by David M. Uslan. The series centers on Thunderhead, a would be hero whose inability to utilize his ability to produce loud thunderblasts without injury to himself leads him to become a source of comedic derision in the superhero community. The series, which explores events that occur in between the battles typically seen in comic books, was based on a concept originated by Uslan, and partly inspired by "It's Always Sunny in Philadelphia". David describes "Head Cases" as a 75-minute movie divided into 5-minute webisodes. The series will feature guest appearances by other industry personalities, including Stan Lee, who appears as himself, functioning in a similar manner to Norm Peterson from "Cheers".



On more than one occasion, editorial problems or corporate pressure to modify or re-script his plotlines have prompted David to leave books, particularly his decision to terminate his first run on Marvel's "X-Factor", due to constantly having to constrain his plots to accommodate crossover events with other books. He resigned from "Spider-Man 2099" to protest the firing of editor Joey Cavalieri, and from "Aquaman" over other creative differences. When David abruptly left his first stint on "The Incredible Hulk" due to editorial pressures, some of the plot points of the character that David established were retconned by later creative teams.

In his "But I Digress" column, which began appearing in the "Comics Buyer's Guide" on July 27, 1990, and in his blog, in operation since April 2002, David has been outspoken in many of his views pertaining to the comic book industry, and numerous other subjects. He has criticized the low regard in which writers are held, the practice of bagged comics, so-called "poster covers" that showcase a character without indicating anything about the comic's content, the meaninglessness of killing off characters to be eventually revived, the poor commitment on the part of some to maintaining continuity in shared fictional universes, and the emphasis on gearing monthly comics series toward eventual collection into trade paperbacks. David has opined that failure on the part of consumers to purchase the monthly individual issues in favor of waiting for the trade collections hurts the sales of the monthly, and its chances of being collected at all. A father of four daughters, David has worked on a number of series that feature female leads, such as "Supergirl", "Fallen Angel" and "She-Hulk", and has lamented that the American comic book market is not very supportive of such books. David has spoken out about fans who are abusive or threatening to creators, and against copyright infringement, particularly that which is committed through peer-to-peer file sharing and posting literary works in their entirety on the Internet without the permission of the copyright holder.

On many occasions, he has offered criticisms of specific publishers, as when he criticized "Wizard" magazine for ageism. He has criticized companies for not sufficiently compensating the creators of their long-standing and lucrative characters, such as Marvel Comics for its treatment of Blade creator Marv Wolfman and Archie Comics for its treatment of "Josie and the Pussycats" creator Dan DeCarlo. He has criticized publishers for various other business practices, including Marvel and Image Comics. He has defended said companies from criticism he feels is unfounded, as when he defended Marvel from a February 17, 1992 "Barron's" magazine article. He has criticized deletionists on Wikipedia on more than one occasion.

On occasion, he has disagreed publicly with specific industry personalities such as Frank Miller and Jim Shooter. Particularly publicized were his disagreements with "Spawn" creator Todd McFarlane in 1992 and 1993, in the wake of the formation of Image Comics, the company McFarlane co-founded. This came to a head during a public debate they participated in at Philadelphia's Comicfest convention in October 1993, which was moderated by artist George Pérez. McFarlane claimed that Image was not being treated fairly by the media, and by David in particular. The three judges, Maggie Thompson, editor of the "Comics Buyer's Guide", William Christensen of "Wizard Press", and John Danovich of the magazine "Hero Illustrated", voted 2–1 in favor of David, with Danovich voting the debate a tie. David has since criticized McFarlane for other business practices, and has engaged in public disagreements with "The Comics Journal" editor Gary Groth, Erik Larsen, Rob Liefeld, Marvel Editor-In-Chief Joe Quesada, writer/director Kevin Smith, DC Comics Vice President and Executive Editor Dan DiDio, and John Byrne. Despite his differences with Byrne, David has stated that he is still a fan of Byrne's, citing Byrne's work on "X-Men", "Fantastic Four", "Next Men", "Alpha Flight" and "Babe".

Politically, David identifies himself as liberal. He was critical of the George W. Bush administration in general, and the Iraq War in particular, as well as other Republicans and the religious right. He has spoken out in favor of Israel's right to defend itself from aggressors, and has opined that certain criticisms of Israel indicate bias and double standards. He favors gun control, and holds progressive or liberal views on LGBT issues, including favoring gay marriage and allowing openly homosexual individuals to serve in the military. He opposes capital punishment. He is an advocate of freedom of speech, having criticized various publicized instances of censorship in general, such as the targeting of comic book retailers for prosecution for selling certain comic books, and the Comics Code Authority in particular. He is a promoter and activist for the Comic Book Legal Defense Fund, which comes to the aid of such creators and retailers. He has criticized ideas associated with liberalism or political correctness, such as certain publicized cases of alleged sexual harassment or discrimination that he deems unfounded, and has not shied away from criticizing liberals and Democrats, including Bill Clinton, Al Gore, Hillary Clinton, Michelle Obama, Caroline Kennedy and Barack Obama.

David met his first wife, Myra Kasman, at a "Star Trek" convention. They married in June 1977, with his childhood friend Keith serving as best man. Together they had three daughters, Shana, Guinevere and Ariel. They separated in late 1996, and were divorced by 1998. David began dating Kathleen O'Shea, a bookseller, puppeteer and writer/editor in 1998. After dating for three years, David proposed to O'Shea at the Adventurers Club in Disney World on September 3, 2000. They married on May 26, 2001 in Atlanta, Georgia. Their daughter, Caroline Helen David, was born on December 5, 2002, and named after David's late friend and coworker, Carol Kalish. David and his family live in Suffolk County, New York, on the south shore of Long Island, where his favorite local comics shop is Fourth World Comics in Smithtown, New York. David's father, Gunter, died of cancer on April 20, 2015. David's mother, Dalia, died May 27, 2017.

David had been a Conservative Jew, but as of October 2003, attends a Reform synagogue. His Hebrew name in patronymic form is Jacob Ben Joachim. He has, however, expressed reservations about organized religion.

David has named "Groo the Wanderer", "Liberty Meadows", "Fables", "", "Strangers in Paradise", "Runaways", "She-Hulk", "Spider-Man Loves Mary Jane", "Knights of the Dinner Table", "The Crossovers" and J. Michael Straczynski's run on "Spider-Man" as comics that he has enjoyed. Other creators whose work he has long-admired include John Romita, Sr., John Buscema, Gene Colan, and others he has stated he presently admires or are friends that he enjoys working with include George Pérez, Andy Kubert, and Rick Leonardi. He has named Pérez as his favorite artistic collaborator, and has named Pérez, Leonard Kirk and Dale Keown as the artists whose art has mostly closely matched the visuals he conceived when writing comic book scripts.

David is an avid fan of bowling, and a bowler himself, as is his daughter Ariel. He is a fan of the New York Mets, and practices tai chi. His favorite music includes The Beatles, and his favorite albums include Harry Chapin's "Verities and Balderdash" and the soundtracks to "Amadeus" and "". His favorite movies include the James Bond films, "The Adventures of Robin Hood", "That", "Casablanca", and the early Johnny Weissmuller "Tarzan" films. His favorite TV shows have included "Doctor Who", "Hill Street Blues", "Charmed", "Carnivale", "Boston Public", "The Practice", "Friends", "Buffy the Vampire Slayer", "Angel", "Alias" and "The West Wing". He is a fan of musicals, in particular "1776", "Man of La Mancha", "Li'l Abner" and "Into the Woods", with a taste for Lerner and Loewe and Stephen Sondheim. He acts in local stage productions.

In June 2010, David's wife announced on his website that he had successfully undergone surgery to relieve serious back pain. He later explained on his site that the pain, which he had been suffering in his hips and knees for three weeks, left him unable to function, and was eventually diagnosed as a herniated disc caused by bone fragments and fluid buildup. He underwent a three-hour discectomy, and was told his full strength would return in six months.

On December 29, 2012, David suffered a stroke while on vacation in Florida. The stroke occurred in the Pons section of David's brain, from which he lost most of the use of his right arm and his right leg, and suffered from blurred vision in his right eye. While a total recovery was indicated to be unlikely, he remained in good spirits, and underwent physical therapy in order to return to his prior routine. Two and a half months later, his condition had improved. His vision problems were gone, and he was able to navigate around his house without a wheelchair, and resume bowling and practicing tai chi. He had made slow and steady progress on his right leg and arm, and was continuing his therapy. Six months after the stroke, David had completed his physical therapy, though he still suffered some pain in his shoulder, and intended to work on improving his reduced endurance. David revealed in January 2015 that he was diagnosed with Type 2 diabetes a year prior.

In March 2017, David revealed on his blog that the IRS was demanding that he pay $88,000 USD in unpaid taxes, penalty and interest, which began to accumulate when his divorce from his first wife used up his savings. He started a GoFundMe campaign to raise the money from friends and fans, which raised $68,000 by April 12. David announced that he would begin a Patreon account where he would publish new work, and which would be used to pay taxes, and asked his readers for their content requests. By May 11, having sold some original comics artwork acquired two decades earlier, the Davids' debts were paid off.


 

 


</doc>
<doc id="24998" url="https://en.wikipedia.org/wiki?curid=24998" title="Plenum">
Plenum

Plenum may refer to:




</doc>
<doc id="25002" url="https://en.wikipedia.org/wiki?curid=25002" title="Pretoria">
Pretoria

Pretoria is a city in the northern part of Gauteng province in South Africa. It straddles the Apies River and has spread eastwards into the foothills of the Magaliesberg mountains. It is one of the country's three capital cities, serving as the seat of the administrative branch of government (Cape Town is the legislative capital and Bloemfontein the judicial capital). Pretoria has a reputation for being an academic city with three universities and the Council for Scientific and Industrial Research (CSIR) located in its eastern suburbs. The city also hosts the South African Bureau of Standards making the city a hub for research. Pretoria is the central part of the Tshwane Metropolitan Municipality which was formed by the amalgamation of several former local authorities including Centurion and Soshanguve. There have been proposals to change the name of Pretoria itself to Tshwane, and the proposed name change has caused some controversy.

Pretoria is named after the Voortrekker leader Andries Pretorius, and within South Africa is popularly known as the "Jacaranda City" due to the thousands of jacaranda trees planted in its streets, parks and gardens. Being an invasive species, jacaranda trees are no longer allowed to be planted in Pretoria.

Pretoria was founded in 1855 by Marthinus Pretorius, a leader of the Voortrekkers, who named it after his father Andries Pretorius and chose a spot on the banks of the "Apies rivier" (Afrikaans for "Monkeys river") to be the new capital of the South African Republic (ZAR). The elder Pretorius had become a national hero of the "Voortrekker"s after his victory over Dingane and the Zulus in the Battle of Blood River. The elder Pretorius also negotiated the Sand River Convention (1852), in which Britain acknowledged the independence of the Transvaal. It became the capital of the South African Republic (ZAR) on 1 May 1860.

The founding of Pretoria as the capital of the South African Republic can be seen as marking the end of the Boers' settlement movements of the Great Trek.

During the First Boer War, the city was besieged by Republican forces in December 1880 and March 1881. The peace treaty which ended the war was signed in Pretoria on 3 August 1881 at the Pretoria Convention.

The Second Boer War resulted in the end of the Transvaal Republic and start of British hegemony in South Africa. The city surrendered to British forces under Frederick Roberts on 5 June 1900 and the conflict was ended in Pretoria with the signing of the Peace of Vereeniging on 31 May 1902 at Melrose House.

The Pretoria Forts were built for the defence of the city just prior to the Second Boer War. Though some of these forts are today in ruins, a number of them have been preserved as national monuments.

The Boer Republics of the ZAR and the Orange River Colony were united with the Cape Colony and Natal Colony in 1910 to become the Union of South Africa. Pretoria then became the administrative capital of the whole of South Africa, with Cape Town the legislative capital and Bloemfontein served as the judicial capital. Between 1910 and 1994, the city was also the capital of the province of Transvaal. (As the capital of the ZAR, Pretoria had superseded Potchefstroom in that role.)
On 14 October 1931, Pretoria achieved official city status. When South Africa became a republic in 1961, Pretoria remained its administrative capital.

Pretoria is situated approximately north-northeast of Johannesburg in the northeast of South Africa, in a transitional belt between the plateau of the Highveld to the south and the lower-lying Bushveld to the north. It lies at an altitude of about above sea level, in a warm, sheltered, fertile valley, surrounded by the hills of the Magaliesberg range.

Pretoria has a humid subtropical climate (Köppen: Cwa) with long hot rainy summers and short cool to cold, dry winters. The city experiences the typical winters of South Africa with cold, clear nights and mild to moderately warm days. Although the average lows during winter are mild, it can get cold due to the clear skies, with nighttime low temperatures in recent years in the range of .

The average annual temperature is . This is rather high, considering the city's relatively high altitude of about , and is due mainly to its sheltered valley position, which acts as a heat trap and cuts it off from cool southerly and south-easterly air masses for much of the year. 

Rain is chiefly concentrated in the summer months, with drought conditions prevailing over the winter months, when frosts may be sharp. Snowfall is an extremely rare event; snowflakes were spotted in 1959, 1968 and 2012 in the city, but the city has never experienced an accumulation in its history.

During a nationwide heatwave in November 2011, Pretoria experienced temperatures that reached , unusual for that time of the year. Similar record-breaking extreme heat events also occurred in January 2013, when Pretoria experienced temperatures exceeding on several days. The year 2014 was one of the wettest on record for the city. A total of fell up to the end of December, with recorded in this month alone. In 2015 Pretoria saw its worst drought since 1982; the month of November 2015 saw new records broken for high temperatures, with recorded on 11 November after three weeks of temperatures between and . January 2016 saw Pretoria reach a new record high of on 7 January 2016.

Depending on the extent of the area understood to constitute "Pretoria", the population ranges from 700,000 to 2.95 million. The main languages spoken in Pretoria are Sepedi, Sesotho, Setswana, Xitsonga, Afrikaans and English. The city of Pretoria has the largest white population in Sub-Saharan Africa. Since its founding it has been a major Afrikaner population centre, and currently there are roughly 1 million Afrikaners living in or around the city.

Even since the end of Apartheid, Pretoria itself has a white majority, albeit an ever-increasing black middle-class. However, in the townships of Soshanguve and Atteridgeville black people make up close to all of the population. The largest white ethnic group are the Afrikaners and the largest black ethnic group are the Northern Sothos.

The lower estimate for the population of Pretoria includes largely former white-designated areas and there is therefore a white majority. However, including the geographically separate townships increases Pretoria's population beyond a million and makes whites a minority.

Pretoria's Indians were ordered to move from Pretoria to Laudium on 6 June 1958.
Pretoria is known as the "Jakaranda City" due to the approximately 50 000 Jacarandas that line its streets. Purple is a colour often associated with the city and is often included on local council logos and services such as the A Re Yeng rapid bus system and the logo of the local Jacaranda FM radio station.

Pretoria has over the years had very diverse cultural influences and this is reflected in the architectural styles that can be found in the city. It ranges from 19th century Dutch, German and British Colonial Architecture to modern, postmodern, neomodern, and art deco architecture styles with a good mix of a uniquely South African style.

Some of the notable structures in Pretoria include the late 19th century Palace of Justice, the early 20th century Union Buildings, the post-war Voortrekker Monument, the diverse buildings dotting the main campuses of both the University of Pretoria and the University of South Africa, traditional Cape Dutch style Mahlamba Ndlopfu (the President's House), the more modern Reserve Bank of South Africa (Office skyscraper) and the Telkom Lukas Rand Transmission Tower. Other well-known structures and buildings include the Loftus Versfeld Stadium, The South African State Theatre and the Oliver Tambo building which is the Headquarters of the Department of International Relations and Cooperation (which is a good example of neomodern architecture in South Africa).The Lukasrand Tower is located on Muckleneuk Hill in the Lukasrand suburb on the outskitrts of the central city and is a prominent landmark in the skyline.
Despite the many corporate offices, small businesses, shops and government departments that are situated in Pretoria's sprawling suburbs, its Central Business District still retains its status as the traditional centre of government and commerce. Many banks, businesses, large corporations, shops, shopping centres and other businesses are situated in the city centre which is towered by several large skyscrapers, the tallest of which is the Poyntons Building ( tall), the ABSA Building ( tall) and the Reserve Bank of South Africa building ( tall).

The area contains a large amount of historical buildings, monuments and museums that include the Pretoria City Hall, Pretorius Square, Church Square (Along with its many historical buildings and statues) and the Ou Raadsaal. There is also the Transvaal Museum (the country's leading natural history museum, which although it has changed venues a number of times, has been around since 1892), the National Zoological Gardens of South Africa (or more colloquially known as the Pretoria Zoo), Melrose House Museum in Jacob Maré Street, the Pretoria Art Museum and the African Window Cultural History Museum.

Several National Departments also have Head Offices in the Central Business district such as the Department of Health, Basic Education, Transport, Higher Education and Training, Sport and Recreation, Justice and Constitutional Development, Public Service and Administration, Water and Environmental Affairs and the National Treasury. The district also has a high number of residential buildings which house people who primarily work in the district.

Pretoria is home to the National Zoological Gardens of South Africa as well as the Pretoria National Botanical Garden. There are also a number of smaller parks and gardens located throughout the city, including the Austin Roberts Bird Sanctuary, Pretorius Square gardens, the Pretoria Rosarium, Church Square, Pretoria Showgrounds, Springbok Park, Freedom Park, and Burgers Park, the oldest park in the city and now a national monument. In the suburbs there are also several parks that are notable: Rietondale Park, "Die Proefplaas" in the Queenswood suburb, Nelson Mandel Park and Mandela Park Peace Garden and Belgrave Square Park.

Commuter rail services around Pretoria are operated by Metrorail. The routes, originating from the city centre, extend south to Germiston and Johannesburg, west to Atteridgeville, northwest to Ga-Rankuwa, north to Soshanguve and east to Mamelodi.

The Gautrain high-speed railway line runs from the eastern suburb of Hatfield to Pretoria Station and then southwards to Centurion, Midrand, Marlboro, Sandton, OR Tambo International Airport, Rosebank and Johannesburg.

Pretoria Station is a departure point for the Blue Train luxury train. Rovos Rail, a luxury mainline train safari service operates from the colonial-style railway station at Capital Park. The South African Friends of the Rail have recently moved their vintage train trip operations from the Capital Park station to the Hercules station.

Various bus companies exist in Pretoria, of which Putco is one of the oldest and most recognised. Tshwane(Pretoria) municipality provides for the rest of the bus transport and to view the time table please visit them at Tshwane Bus Booklet.

The N1 is the major freeway that runs through Pretoria. It enters the city from the south as the Ben Schoeman Highway. At the Brakfontein Interchange with the N14 it continues as The N1 Eastern Bypass bisects the large expanse of the eastern suburbs, routing traffic from Johannesburg to Polokwane and the north of the country. The R101 is the original N1, and served the same function before the construction of the highway. It runs through the centre of town rather than the eastern suburbs.

The N4 enters the town as a highway from Witbank in the east, merging with the N1 at the Proefplaas Interchange. It begins again north of the city, branching west from the N1 as the Platinum Highway, forming the Northern Bypass, and heading to Rustenburg. The N4 runs east–west through South Africa, connecting Maputo to Gaborone. Before the Platinum Highway was built, the N4 continued passed the Proefplaas Interchange to the city centre, where it became a regular road, before again becoming a highway west of the city. These roads are now designated the M2 and M4. There is a third, original east–west road: the R104, previously named Church Street. Church Street has been renamed Helen Joseph from Nelson Mandela Church Square, WF Nkomo from Nelson Mandela to R511, Stanza Bopape from Nelson Mandela to the East and Elias Motswaledi from R511 to the West.

The N14 starts in the centre of town from the M4 (former N4). It is a normal road heading south through the centre before becoming the Ben Schoeman highway. At the Brakfontein interchange, the Ben Schoeman highway becomes the N1, but the N14 continues as the intersecting west-south-western highway towards Krugersdorp. The R114 parallels the N14 in its westward journey running just to the north of the highway.

The R21 provides a second north–south highway, further east. It starts from the Fountains Interchange south of the city centre, but is still a road until Monument Park, when it becomes a true highway. It crosses the N1 east of the Brakfontein Interchange at the Flying Saucer Interchange and runs north–south towards Ekurhuleni (specifically Kempton Park and Boksburg). Importantly it links Pretoria with the OR Tambo International Airport in Kempton Park.

A proposed third north–south highway, in the west of the city, the R80 is partially built. At present the highway begins in Soshanguve. It terminates just north of the city centre at an intersection with the M1. Plans have been in place for some time to extend this all the way past the M4 and N14 highways to the N1 in Randburg.

Pretoria is also served by many regional roads. The R55 starts at an interchange with the R80, and runs north–south west of the city to Sandton. The R50 starts from the N1 just after the Flying Saucer Interchange in the south-east of the city, and continues south-east towards Delmas. The R511 runs north–south from Randburg towards Brits and barely by-passes Pretoria to the west. The R514 starts from the M1, north of the city centre, and terminates at the R511. The R513 crosses Pretoria's northern suburbs from east to west. It links Pretoria to Cullinan and Bronkhorstspruit in the east and Hartbeespoort in the west. The R566 takes origin in Pretoria's northern suburbs, and exits the town to the west just north of the R513. It connects Pretoria to Brits. Finally the R573 starts from the R513, just east of the town and heads north-east to Siyabuswa.

Pretoria is also served internally by metropolitan routes.

For scheduled air services, Pretoria is served by Johannesburg's airports: OR Tambo International, south of central Pretoria; and Lanseria, south-west of the city. Wonderboom Airport in the suburb of Wonderboom in the north of Pretoria primarily services light commercial and private aircraft. However, as from August 2015, scheduled flights from Wonderboom Airport to Cape Town International Airport were made available by SA Airlink. There are two military air bases to the south of the city, Swartkop and Waterkloof.

Since Pretoria forms part the Tshwane Metropolitan Municipality, most radio, television and paper media is the same as the rest of the metro area.

There are many radio stations in the greater Pretoria region, some of note are:

Impact Radio, is a Christian Community Radio Station based in Pretoria, and broadcasting on 103FM in the Greater Tshwane Area.

Jacaranda FM, previously known as Jacaranda 94.2, is a commercial South African radio station, broadcasting in English and Afrikaans, with a footprint that covers Gauteng, Limpopo, Mpumalanga and the North West Province and boasts a listening audience of 2 million people a week, and a digital community of more than 1,1 million people a month. The station's format is mainstream adult contemporary with programming constructed around a playlist of hit music from the 80's, 90's and now.

Tuks FM is the radio station of the University of Pretoria and one of South Africa's community broadcasters. It was one of the first community broadcasters in South Africa to be given an FM licence. It is known for contemporary music and is operated by UP's student base.

Radio Pretoria is a community-based radio station in Pretoria, South Africa, whose programmes are aimed at Afrikaners. It broadcasts 24 hours a day in stereo on 104.2 FM in the greater Pretoria area. Various other transmitters (with their own frequencies) in South Africa broadcast the station's content further afield, while the station is also available on Sentech's digital satellite platform.

Radio Kuber Kontrei is a community-based Internet (streaming) radio station in Pretoria, South Africa, whose programmes are aimed at Afrikaans-speaking Christians worldwide.

Pretoria is serviced by eTV, SABC and MNET.

The city is serviced by a variety of printed publications namely;

Pretoria News is a daily newspaper established in Pretoria in 1898. It publishes a daily edition from Monday to Friday and a Weekend edition on Saturday and Sunday. It is an independent newspaper in the English language that serves the city and its direct environs. It is available online via the Independent online website.

Beeld is an Afrikaans-language daily newspaper that was launched on 16 September 1974. Beeld is distributed in four provinces of South Africa: Gauteng, Mpumalanga, Limpopo, North West. Die Beeld (English: The Image) was an Afrikaans-language Sunday newspaper in the late 1960s.

Wrapped is an alternative lifestyle magazine from Africa that caters for the entire LGBT community and is not gender-dominated.

Pretoria Sotho (called Sepitori by its speakers) is the urban lingua franca of Pretoria and the Tshwane metropolitan area in South Africa. It is a combination of Tswana and Northern Sotho (Pedi), with influences from Tsotsitaal and other black South African languages. It is a creole language that developed in the city during the years of Apartheid.


A number of popular South African bands and musicians are originally from Pretoria. These include Desmond and the Tutus, Bittereinder, The Black Cat Bones, Seether, popular mostwako rapper JR, Joshua na die Reën and DJ Mujava who was raised in the town of Attridgeville.

The song "Marching to Pretoria" refers to this city. Pretoria was the capital of the South African Republic (a.k.a. Republic of the Transvaal; 1852-1881 and 1884-1902) the principal battleground for the First and Second Boer War, the latter which brought both the Transvaal and the Orange Free State republic under British rule. "Marching to Pretoria" was one of the songs that British soldiers sang as they marched from the Cape Colony, under British Rule since 1814, to the capital of the Southern African Republic (or in Dutch, "Zuid-Afrikaansche Republiek"). As the song's refrain puts it: "We are marching to Pretoria, Pretoria, Pretoria/We are marching to Pretoria, Pretoria, Hurrah."

The opening line of John Lennon's Beatles' song I Am the Walrus, "I am he as you are he as you are me and we are all together," is often believed to be based on the lyric "I'm with you and you're with me and so we are all together" in "Marching to Pretoria." Lennon denied this, insisting his lyrics came from "nothing."

Pretoria is home to an extensive portfolio of public art. A diverse and evolving city, Pretoria boasts a vibrant art scene and a variety of works that range from sculptures to murals to pieces by internationally and locally renowned artists. The Pretoria Art Museum is home to a vast collection of local artworks. After a bequest of 17th century Dutch artworks by Lady Michaelis in 1932 the art collection of Pretoria City Council expanded quickly to include South African works by Henk Pierneef, Pieter Wenning, Frans Oerder, Anton van Wouw and Irma Stern. And according to the museum: "As South African museums in Cape Town and Johannesburg already had good collections of 17th, 18th and 19th century European art, it was decided to focus on compiling a representative collection of South African art" making it somewhat unusual compared to its contemporaries.

Pretoria houses several performing arts venues including:
the South African State Theatre which houses the arts of Opera, musicals, plays and comedic performances.

A 9 metre tall statue of former president Nelson Mandela was unveiled in front of the Union Buildings on 16 December 2013. Since Nelson Mandela's inauguration as South Africa's first majority elected president the Union Buildings have come to represent the new 'Rainbow Nation'. Public art in Pretoria has flourished since the 2010 FIFA World Cup with many areas receiving new public artworks.

One of the most popular sports in Pretoria is rugby union. Loftus Versfeld is home to the Blue Bulls, who compete in the domestic Currie Cup, and also to the Bulls in the international Super Rugby competition. The Bulls Super Rugby team, which is operated by the Blue Bulls, won the competition in 2007, 2009 and 2010. Loftus Versfeld also hosts the soccer side Mamelodi Sundowns.

Pretoria also hosted matches during the 1995 Rugby World Cup. Loftus Versfeld was used for matches of soccer in the 2010 FIFA World Cup.

There are three soccer teams in the city playing in South Africa's top flight football League, the Premier Soccer League. They are Mamelodi Sundowns and Supersport United. Supersport United were the 2008–09 PSL Champions. Following the 2011/2012 season the University of Pretoria F.C. gained promotion to the South African Premier Soccer League (PSL), the top domestic league.

Cricket is also a popular game in the city. As there is no international cricket stadium in the city, it does not host any top-class cricket tournaments, although the nearby situated Centurion has Supersport Park which is an international cricket stadium and has hosted many important tournaments such as 2003 Cricket World Cup, 2007 ICC World Twenty20, 2009 IPL and 2009 ICC Champions Trophy. The most local franchise team to Pretoria is the Titans, although Northerns occasionally play in the city in South Africa's provincial competitions. Many Pretoria born cricketers have gone on to play for South Africa, including current captain AB de Villiers and T20 captain Faf du Plessis.

The Pretoria Transnet Blind Cricket Club is situated in Pretoria and is currently the biggest Blind Cricket club in South Africa. Their field is at the Transnet Engineering campus on Lynette Street, home of differently disabled cricket. PTBCC has played many successful blind cricket matches with abled body team such as the South African Indoor Cricket Team and TuksCricket Junior Academy. Northerns Blind Cricket is the Provincial body that governs PTBCC and Filefelfia Secondary School. The Northern Blind Cricket team won the 40 over National Blind Cricket tournament that was held in Cape Town in April 2014.





The city is a major commercial centre and an important industrial centre. Its main industries are iron and steel works, copper casting, and the manufacture of automobiles, railway carriages and heavy machinery.

Pretoria has a number of industrial areas, business districts and small home businesses. A number of chambers of commerce exist for Pretoria and its business community including Pretoriaweb, a business networking group that meets once a month to discuss the issues of doing business in Pretoria. The members of Pretoriaweb also discuss issues in various social media environments and on the website.

The Pretoria civic arms, designed by Dr. Frans Engelenburg, were granted by the College of Arms on 7 February 1907. They were registered with the Transvaal Provincial Administration in March 1953 and at the Bureau of Heraldry in May 1968. The Bureau provided new artwork, in a more modern style, in 1989.

The arms were : "Gules, on an mimosa tree eradicated proper within an orle of eight bees volant, Or, an inescutcheon Or and thereon a Roman praetor seated proper". In layman's terms : a red shield displaying an uprooted mimosa tree surrounded by a border of eight golden bees, superimposed on the tree is a golden shield depicting a Roman praetor. The tree represented growth, the bees industry, and the praetor (judge) was an heraldic pun on the name.

The crest was a three-towered golden castle; the supporters were an eland and a kudu; and the motto "Praestantia praevaleat Pretoria".
The coat of arms have gone out of favour after the City Council amalgamated with its surrounding councils to form the City of Tshwane Metropolitan Municipality.


Schools for foreign students:

Pretoria is one of South Africa's leading academic cities and is home to both the largest residential university in South Africa, largest distance education university in South Africa and a research intensive university. The three Universities in the city in order of the year founded are as follows:

The University of South Africa (commonly referred to as Unisa), founded in 1873 as the University of the Cape of Good Hope, is the largest university on the African continent and attracts a third of all higher education students in South Africa. It spent most of its early history as an examining agency for Oxford and Cambridge universities and as an incubator from which most other universities in South Africa are descended. In 1946 it was given a new role as a distance education university and in 2012 it had a student headcount of over 300 000 students, including African and international students in 130 countries worldwide, making it one of the world's mega universities. Unisa is a dedicated open distance education institution and offers both vocational and academic programmes.

The University of Pretoria (commonly referred to as UP, Tuks, or Tukkies) is a multi campus public research university. The university was established in 1908 as the Pretoria campus of the Johannesburg based Transvaal University College and is the fourth South African institution in continuous operation to be awarded university status. Established in 1920, the University of Pretoria Faculty of Veterinary Science is the second oldest veterinary school in Africa and the only veterinary school in South Africa. In 1949 the university launched the first MBA programme outside of North America. Since 1997, the university has produced more research outputs every year than any other institution of higher learning in South Africa, as measured by the Department of Education's accreditation benchmark.

The Tshwane University of Technology (commonly referred to as TUT) is a higher education institution, offering vocational oriented diplomas and degrees, and came into being through a merger of Technikon Northern Gauteng, Technikon North-West and Technikon Pretoria. TUT caters for approximately 60,000 students and it has become the largest residential higher education institution in South Africa.

The Council for Scientific and Industrial Research (CSIR) is South Africa's central scientific research and development organisation. It was established by an act of parliament in 1945 and is situated on its own campus in the city. It is the largest research and development organisation in Africa and accounts for about 10% of the entire African R&D budget. It has a staff of approximately 3,000 technical and scientific researchers, often working in multi-disciplinary teams. In 2002, Dr. Sibusiso Sibisi was appointed as the president and CEO of the CSIR

Pretoria has earned a reputation as being the centre of South Africa's Military and is home to several military facilities of the South African National Defence Force:

This complex is the headquarters to the South African Air Force.

A military complex that houses the following:

A military complex located on the corner of Patriot Street and Koraalboom Road that houses the following military headquarters:

This base is situated in the suburb of Salvokop and is divided into two parts:

Thaba Tshwane is a large military area South-West of the Pretoria Central Business District and North of Air Force Base Swartkop. It is the Headquarters of several Army units-

The military base also houses the 1 Military Hospital and the Military Police School. Within Thaba Tshwane a facility known as "TEK Base" exists which houses its own units-

The Wonderboom Military Base is located adjacent to the Wonderboom Airport and is the headquarters of the South African Army Signals Formation. It also houses the School of Signals, 1 Signal Regiment, 2 Signal Regiment, 3 Electronic Workshop, 4 Signal Regiment and 5 Signal Regiment.

The South African Air Force College, the South African Military Health Service School for Military Health Training and the South African Army College are situated in the Thaba Tshwane Military Base and are used to train Commissioned and Non-commissioned Officers to perform effectively in combat/command roles in the various branches of the South African National Defence Force. The South African Defence Intelligence College is also located in the Sterrewag Suburb north of Air Force Base Waterkloof.

While technically not within the city limits of Pretoria, Air Force Base Swartkop and Air Force Base Waterkloof are often used for defence related matters within the city. These may include aerial military transport duties within the city, aerospace monitoring and defence as well as VIP transport to and from the city.

On 26 May 2005 the South African Geographical Names Council (SAGNC), which is linked to the Directorate of Heritage in the Department of Arts and Culture, approved changing the name of Pretoria to Tshwane, which is already the name of the Metropolitan Municipality in which Pretoria, and a number of surrounding towns are located. Although the name change was approved by the SAGNC, it has not yet been approved by the Minister of Arts and Culture. The matter is currently under consideration while he has requested further research on the matter. Should the Minister approve the name change, the name will be published in the Government Gazette, giving the public opportunity to comment on the matter. The Minister can then refer that public response back to the SAGNC, before presenting his recommendation before parliament, who will vote on the change. Various public interest groups have warned that the name change will be challenged in court, should the minister approve the renaming. The long process involved made it unlikely the name would change anytime soon, if ever, even assuming the Minister had approved the change in early 2006.

The Tshwane Metro Council has advertised "Tshwane" as "Africa's leading capital city" since the name change was approved by the SAGNC in 2005. This has led to further controversy, however, as the name of the city had not yet been changed officially, and the council was, at best, acting prematurely. Following a complaint lodged with the Advertising Standards Authority (ASA), it was ruled that such advertisements are deliberately misleading and should be withdrawn from all media. Despite the rulings of the ASA, Tshwane Metro Council failed to discontinue their "City of Tshwane" advertisements. As a result, the ASA requested that Tshwane Metro pay for advertisements in which it admits that it has misled the public. Refusing to abide by the ASA's request, the Metro Council was banned consequently from placing any advertisements in the South African media that refer to Tshwane as the capital. ASA may still place additional sanctions on the Metro Council that would prevent it from placing any advertisements in the South African media, including council notices and employment vacancies.

After the ruling, the Metro Council continued to place "Tshwane" advertisements, but placed them on council-owned advertising boards and busstops throughout the municipal area. In August 2007, an internal memo was leaked to the media in which the Tshwane mayor sought advice from the premier of Gauteng on whether the municipality could be called the "City of Tshwane" instead of just "Tshwane". This could increase confusion about the distinction between the city of Pretoria and the municipality of Tshwane.

In early 2010 it was again rumoured that the South African government would make a decision regarding the name, however, a media briefing regarding name changes, where it may have been discussed, was cancelled shortly before taking place. Rumours of the name change provoked outrage from Afrikaner civil rights and political groups. It later emerged that the registration of the municipality as a geographic place had been published in the government gazette as it had been too late to withdraw the name from the publication, but it was announced that the name had been withdrawn, pending "further work" by officials. The following week, the registration of "Tshwane" was officially withdrawn in the Government Gazette. The retraction had reportedly been ordered at the behest of the Deputy President of South Africa Kgalema Motlanthe, acting on behalf of President Jacob Zuma, as minister of Arts and Culture Lulu Xingwana had acted contrary to the position of the ANC, which is that Pretoria and the municipality are separate entities, which was subsequently articulated by ANC secretary general Gwede Mantashe.

In March 2010, the "Tshwane Royal House Committee", claiming to be descendents of Chief Tshwane, called for the name to be changed, and for the descendents of Chief Tshwane to be recognised, and to be made part of the administration of the municipality.

According to comments made by Mayor Kgosientso Ramokgopa in late 2011, the change would occur in 2012. However, there remained considerable uncertainty about the issue.

, the proposed name change has not occurred and is now unlikely to happen.

Pretoria is twinned with:


Note: Malls marked with an asterisk are malls with at least a 4-screen cinema complex. Kolonnade Centre was the only mall in the city with a public ice-skating rink. It closed due to high levels of rent and the management of the mall deciding to build shops in its place. In 2014, The Grove Shopping Centre as well as Forest Hill Mall both opened ice-skating rinks.
After undergoing a substantial refurbishment and expansion, Menlyn Park Mall is currently the largest mall in South Africa.







</doc>
<doc id="25004" url="https://en.wikipedia.org/wiki?curid=25004" title="Psychiatrist">
Psychiatrist

A psychiatrist is a physician who specializes in psychiatry, the branch of medicine devoted to the diagnosis, prevention, study, and treatment of mental disorders. Psychiatrists are medical doctors, unlike psychologists, and must evaluate patients to determine whether their symptoms are the result of a physical illness, a combination of physical and mental ailments, or strictly psychiatric.

As part of the clinical assessment process, psychiatrists may employ a mental status examination; a physical examination; brain imaging such as a computerized tomography (CT), magnetic resonance imaging (MRI), or positron emission tomography (PET) scan; and blood testing. Psychiatrists prescribe medicine, and may also use psychotherapy, although the vast majority do medical management and refer to a psychologist or other specialized therapist for weekly to bi-monthly psychotherapy.

The field of psychiatry has many subspecialties (also known as fellowships) that require additional training which are certified by the American Board of Psychiatry and Neurology (ABPN) and require Maintenance of Certification Program (MOC) to continue. These include the following: 

Further, other specialties that exist include:

The United Council for Neurologic Subspecialties in the United States offers certification and fellowship program accreditation in the subspecialty 'Behavioral Neurology and Neuropsychiatry' (BNNP) - which is open to both neurologists and psychiatrists.

Some psychiatrists specialize in helping certain age groups. Pediatric psychiatry is the area of the profession working with children in addressing psychological problems. Psychiatrists specializing in geriatric psychiatry work with the elderly and are called geriatric psychiatrists or geropsychiatrists. Those who practice psychiatry in the workplace are called occupational psychiatrists in the United States and occupational psychology is the name used for the most similar discipline in the UK. Psychiatrists working in the courtroom and reporting to the judge and jury, in both criminal and civil court cases, are called forensic psychiatrists, who also treat mentally disordered offenders and other patients whose condition is such that they have to be treated in secure units.

Other psychiatrists and mental health professionals in the field of psychiatry may also specialize in psychopharmacology, psychotherapy, psychiatric genetics, neuroimaging, dementia-related disorders such as Alzheimer's disease, attention deficit hyperactivity disorder (ADHD), sleep medicine, pain medicine, palliative medicine, eating disorders, sexual disorders, women's health, global mental health, early psychosis intervention, mood disorders, and anxiety disorders such as obsessive–compulsive disorder (OCD) and posttraumatic stress disorder (PTSD).

The (Consultant psychiatrist) supports treating patients with behavioral health problems. This role can be performed by a team of experts that include mental health specialists (specialists with Ph.D in Neuroscience,Psychiatry and/or Psychology ) who can assist the psychiatrist to relay proper recommendations to the primary care team in treatment planning. The psychiatric consultant may suggest treatment modifications for the primary team to consider, recommend or see the patient for an in-person consultation, and consult patients who are clinically challenging or who need specialty mental health services.

While requirements to become a psychiatrist differ from country to country, all require a medical degree.

In the U.S. and Canada one must first attain the degree of M.D. or D.O., followed by practice as a psychiatric resident for another four years (five years in Canada). This extended period involves comprehensive training in psychiatric diagnosis, psychopharmacology, medical care issues, and psychotherapies. All accredited psychiatry residencies in the United States require proficiency in cognitive-behavioral, brief, psychodynamic, and supportive psychotherapies. Psychiatry residents are required to complete at least four post-graduate months of internal medicine or pediatrics, plus a minimum of two months of neurology during their first year of residency, referred to as an "internship". After completing their training, psychiatrists are eligible to take a specialty board examination to become board-certified. The total amount of time required to complete educational and training requirements in the field of psychiatry in the United States is twelve years after high school. Subspecialists in child and adolescent psychiatry are required to complete a two-year fellowship program, the first year of which can run concurrently with the fourth year of the general psychiatry residency program. This adds one to two years of training.

In the United Kingdom, psychiatrists must hold a medical degree. These degrees are often abbreviated MB BChir, MB BCh, MB ChB, BM BS, or MB BS. Following this, the individual will work as a Foundation House Officer for two additional years in the UK, or one year as Intern in the Republic of Ireland to achieve registration as a basic medical practitioner. Training in psychiatry can then begin and it is taken in two parts: three years of Basic Specialist Training culminating in the MRCPsych exam followed by three years of Higher Specialist Training, referred to as "ST4-6" in the UK and "Senior Registrar Training" in the Republic of Ireland. Candidates with MRCPsych degree and complete basic training must reinterview for higher specialist training. At this stage, the development of speciality interests such as forensic, child/adolescent take place. At the end of 3 years of higher specialist training, candidates are awarded a CCT (UK) or CCST (Ireland), both meaning Certificate of Completion of (Specialist) Training. At this stage, the psychiatrist can register as a specialist and the qualification of CC(S)T is recognized in all EU/EEA states. As such, training in the UK and Ireland is considerably longer than in the US or Canada and frequently takes around 8–9 years following graduation from medical school. Those with a CC(S)T will be able to apply for Consultant posts. Those with training from outside the EU/EEA should consult local/native medical boards to review their qualifications and eligibility for equivalence recognition (for example, those with a US residency and ABPN qualification).

In the Netherlands one must complete medical school after which one is certified as a medical doctor. After a strict selection program one can specialize in psychiatry: a 4.5 year specialization. During this specialization, the resident has to do a 6-month residency in the field of social psychiatry, a 12-month residency in a field of their own choice (which can be child psychiatry, forensic psychiatry, somatic medicine or medical research). To become an adolescent psychiatrist, one has to do an extra specialization period of 2 more years. In short this means that it takes at least 10.5 years of study to become a psychiatrist which can go up to 12.5 years if one becomes a children's and adolescent psychiatrist.

In India MBBS degree is the basic qualification needed to do Psychiatry. After completing MBBS (including internship) one can attend various PG Medical Entrance Exams and take MD in psychiatry which is a 3-year course. Diploma Course in Psychiatry or DNB Psychiatry can also be taken to become a Psychiatrist.

In Pakistan one must complete basic medical education, an MBBS, then get registered with Pakistan Medical and Dental Council as a General Practitioner after one year mandatory internship, House Job. After registration with PMDC, one has to go for FCPS-I exam, after that four-year training in Psychiatry under College of Physicians and Surgeons Pakistan. Training includes rotations in General Medicine, Neurology, and Clinical Psychology for 3 months each, during first two years. There is a mid-exam IMM (Intermediate Module) and a final exam after 4 years.


Pass the Casc (2012, 2018) by Dr Seshni Moodliar for the CASC MRCPsych exam

</doc>
<doc id="25005" url="https://en.wikipedia.org/wiki?curid=25005" title="Peano axioms">
Peano axioms

In mathematical logic, the Peano axioms, also known as the Dedekind–Peano axioms or the Peano postulates, are axioms for the natural numbers presented by the 19th century Italian mathematician Giuseppe Peano. These axioms have been used nearly unchanged in a number of metamathematical investigations, including research into fundamental questions of whether number theory is consistent and complete.

The need to formalize arithmetic was not well appreciated until the work of Hermann Grassmann, who showed in the 1860s that many facts in arithmetic could be derived from more basic facts about the successor operation and induction. In 1881, Charles Sanders Peirce provided an axiomatization of natural-number arithmetic. In 1888, Richard Dedekind proposed another axiomatization of natural-number arithmetic, and in 1889, Peano published a simplified version of them as a collection of axioms in his book, "The principles of arithmetic presented by a new method" ().

The Peano axioms contain three types of statements. The first axiom asserts the existence of at least one member of the set of natural numbers. The next four are general statements about equality; in modern treatments these are often not taken as part of the Peano axioms, but rather as axioms of the "underlying logic". The next three axioms are first-order statements about natural numbers expressing the fundamental properties of the successor operation. The ninth, final axiom is a second order statement of the principle of mathematical induction over the natural numbers. A weaker first-order system called Peano arithmetic is obtained by explicitly adding the addition and multiplication operation symbols and replacing the second-order induction axiom with a first-order axiom schema.

When Peano formulated his axioms, the language of mathematical logic was in its infancy. The system of logical notation he created to present the axioms did not prove to be popular, although it was the genesis of the modern notation for set membership (∈, which comes from Peano's ε) and implication (⊃, which comes from Peano's reversed 'C'.) Peano maintained a clear distinction between mathematical and logical symbols, which was not yet common in mathematics; such a separation had first been introduced in the "Begriffsschrift" by Gottlob Frege, published in 1879. Peano was unaware of Frege's work and independently recreated his logical apparatus based on the work of Boole and Schröder.

The Peano axioms define the arithmetical properties of "natural numbers", usually represented as a set N or formula_1 The non-logical symbols for the axioms consist of a constant symbol 0 and a unary function symbol "S".

The first axiom states that the constant 0 is a natural number:

The next four axioms describe the equality relation. Since they are logically valid in first-order logic with equality, they are not considered to be part of "the Peano axioms" in modern treatments.

The remaining axioms define the arithmetical properties of the natural numbers. The naturals are assumed to be closed under a single-valued "successor" function "S".

Peano's original formulation of the axioms used 1 instead of 0 as the "first" natural number. This choice is arbitrary, as axiom 1 does not endow the constant 0 with any additional properties. However, because 0 is the additive identity in arithmetic, most modern formulations of the Peano axioms start from 0. Axioms 1, 6, 7, 8 define a unary representation of the intuitive notion of natural numbers: the number 1 can be defined as "S"(0), 2 as "S"("S"(0)), etc. However, considering the notion of natural numbers as being defined by these axioms, axioms 1, 6, 7, 8 do not imply that the successor function generates all the natural numbers different from 0. Put differently, they do not guarantee that every natural number other than zero must succeed some other natural number.

The intuitive notion that each natural number can be obtained by applying "successor" sufficiently often to zero requires an additional axiom, which is sometimes called the "axiom of induction".

The induction axiom is sometimes stated in the following form:
In Peano's original formulation, the induction axiom is a second-order axiom. It is now common to replace this second-order principle with a weaker first-order induction scheme. There are important differences between the second-order and first-order formulations, as discussed in the section below.

The Peano axioms can be augmented with the operations of addition and multiplication and the usual total (linear) ordering on N. The respective functions and relations are constructed in set theory or second-order logic, and can be shown to be unique using the Peano axioms.

Addition is a function that maps two natural numbers (two elements of N) to another one. It is defined recursively as:

For example:

The structure is a commutative monoid with identity element 0. is also a cancellative magma, and thus embeddable in a group. The smallest group embedding N is the integers.

Similarly, multiplication is a function mapping two natural numbers to another one. Given addition, it is defined recursively as:

It is easy to see that "S"(0) (or "1", in the familiar language of decimal representation) is the multiplicative right identity:

To show that "S"(0) is also the multiplicative left identity requires the induction axiom due to the way multiplication is defined:


Therefore by the induction axiom "S"(0) is the multiplicative left identity of all natural numbers. Moreover, it can be shown that multiplication distributes over addition:

Thus, is a commutative semiring.

The usual total order relation ≤ on natural numbers can be defined as follows, assuming 0 is a natural number:

This relation is stable under addition and multiplication: for formula_5, if , then:


Thus, the structure is an ordered semiring; because there is no natural number between 0 and 1, it is a discrete ordered semiring.

The axiom of induction is sometimes stated in the following form that uses a stronger hypothesis, making use of the order relation "≤":

This form of the induction axiom, called "strong induction", is a consequence of the standard formulation, but is often better suited for reasoning about the ≤ order. For example, to show that the naturals are well-ordered—every nonempty subset of N has a least element—one can reason as follows. Let a nonempty be given and assume "X" has no least element.


Thus, by the strong induction principle, for every , . Thus, , which contradicts "X" being a nonempty subset of N. Thus "X" has a least element.

All of the Peano axioms except the ninth axiom (the induction axiom) are statements in first-order logic. The arithmetical operations of addition and multiplication and the order relation can also be defined using first-order axioms. The axiom of induction is in second-order, since it quantifies over predicates (equivalently, sets of natural numbers rather than natural numbers), but it can be transformed into a first-order "axiom schema" of induction. Such a schema includes one axiom per predicate definable in the first-order language of Peano arithmetic, making it weaker than the second-order axiom.

First-order axiomatizations of Peano arithmetic have an important limitation, however. In second-order logic, it is possible to define the addition and multiplication operations from the successor operation, but this cannot be done in the more restrictive setting of first-order logic. Therefore, the addition and multiplication operations are directly included in the signature of Peano arithmetic, and axioms are included that relate the three operations to each other.

The following list of axioms (along with the usual axioms of equality), which contains six of the seven axioms of Robinson arithmetic, is sufficient for this purpose:


In addition to this list of numerical axioms, Peano arithmetic contains the induction schema, which consists of a countably infinite set of axioms. For each formula in the language of Peano arithmetic, the first-order induction axiom for "φ" is the sentence

where formula_13 is an abbreviation for "y"...,"y". The first-order induction schema includes every instance of the first-order induction axiom, that is, it includes the induction axiom for every formula "φ".

There are many different, but equivalent, axiomatizations of Peano arithmetic. While some axiomatizations, such as the one just described, use a signature that only has symbols for 0 and the successor, addition, and multiplications operations, other axiomatizations use the language of ordered semirings, including an additional order relation symbol. One such axiomatization begins with the following axioms that describe a discrete ordered semiring.

The theory defined by these axioms is known as PA; the theory PA is obtained by adding the first-order induction schema. An important property of PA is that any structure formula_29 satisfying this theory has an initial segment (ordered by formula_30) isomorphic to formula_31. Elements in that segment are called standard elements, while other elements are called nonstandard elements.

A model of the Peano axioms is a triple , where N is a (necessarily infinite) set, and satisfies the axioms above. Dedekind proved in his 1888 book, "The Nature and Meaning of Numbers" (, i.e., “What are the numbers and what should they be?”) that any two models of the Peano axioms (including the second-order induction axiom) are isomorphic. In particular, given two models and of the Peano axioms, there is a unique homomorphism satisfying

and it is a bijection. This means that the second-order Peano axioms are categorical. This is not the case with any first-order reformulation of the Peano axioms, however.

The Peano axioms can be derived from set theoretic constructions of the natural numbers and axioms of set theory such as ZF. The standard construction of the naturals, due to John von Neumann, starts from a definition of 0 as the empty set, ∅, and an operator "s" on sets defined as:

The set of natural numbers N is defined as the intersection of all sets closed under "s" that contain the empty set. Each natural number is equal (as a set) to the set of natural numbers less than it:

and so on. The set N together with 0 and the successor function satisfies the Peano axioms.

Peano arithmetic is equiconsistent with several weak systems of set theory. One such system is ZFC with the axiom of infinity replaced by its negation. Another such system consists of general set theory (extensionality, existence of the empty set, and the axiom of adjunction), augmented by an axiom schema stating that a property that holds for the empty set and holds of an adjunction whenever it holds of the adjunct must hold for all sets.

The Peano axioms can also be understood using category theory. Let "C" be a category with terminal object 1, and define the category of pointed unary systems, US("C") as follows:


Then "C" is said to satisfy the Dedekind–Peano axioms if US("C") has an initial object; this initial object is known as a natural number object in "C". If is this initial object, and is any other object, then the unique map is such that

This is precisely the recursive definition of 0 and "S".

Although the usual natural numbers satisfy the axioms of PA, there are other models as well (called non-standard models); the compactness theorem implies that the existence of nonstandard elements cannot be excluded in first-order logic. The upward Löwenheim–Skolem theorem shows that there are nonstandard models of PA of all infinite cardinalities. This is not the case for the original (second-order) Peano axioms, which have only one model, up to isomorphism. This illustrates one way the first-order system PA is weaker than the second-order Peano axioms.

When interpreted as a proof within a first-order set theory, such as ZFC, Dedekind's categoricity proof for PA shows that each model of set theory has a unique model of the Peano axioms, up to isomorphism, that embeds as an initial segment of all other models of PA contained within that model of set theory. In the standard model of set theory, this smallest model of PA is the standard model of PA; however, in a nonstandard model of set theory, it may be a nonstandard model of PA. This situation cannot be avoided with any first-order formalization of set theory.

It is natural to ask whether a countable nonstandard model can be explicitly constructed. The answer is affirmative as Skolem in 1933 provided an explicit construction of such a nonstandard model. On the other hand, Tennenbaum's theorem, proved in 1959, shows that there is no countable nonstandard model of PA in which either the addition or multiplication operation is computable. This result shows it is difficult to be completely explicit in describing the addition and multiplication operations of a countable nonstandard model of PA. However, there is only one possible order type of a countable nonstandard model. Letting "ω" be the order type of the natural numbers, "ζ" be the order type of the integers, and "η" be the order type of the rationals, the order type of any countable nonstandard model of PA is , which can be visualized as a copy of the natural numbers followed by a dense linear ordering of copies of the integers.

A cut in a nonstandard model "M" is a nonempty subset "I" of "M" so that "I" is downward closed ( "x"<"y" and "y"∈"I" implies "x"∈"I") and "I" is closed under successor. A proper cut is a cut that is a proper subset of "M". Each nonstandard model has many proper cuts, including one that corresponds to the standard natural numbers. However, the induction scheme in Peano arithmetic prevents any proper cut from being definable. The overspill lemma, first proved by Abraham Robinson, formalizes this fact. 

When the Peano axioms were first proposed, Bertrand Russell and others agreed that these axioms implicitly defined what we mean by a "natural number". Henri Poincaré was more cautious, saying they only defined natural numbers if they were "consistent"; if there is a proof that starts from just these axioms and derives a contradiction such as 0 = 1, then the axioms are inconsistent, and don't define anything. In 1900, David Hilbert posed the problem of proving their consistency using only finitistic methods as the second of his twenty-three problems. In 1931, Kurt Gödel proved his second incompleteness theorem, which shows that such a consistency proof cannot be formalized within Peano arithmetic itself.

Although it is widely claimed that Gödel's theorem rules out the possibility of a finitistic consistency proof for Peano arithmetic, this depends on exactly what one means by a finitistic proof. Gödel himself pointed out the possibility of giving a finitistic consistency proof of Peano arithmetic or stronger systems by using finitistic methods that are not formalizable in Peano arithmetic, and in 1958, Gödel published a method for proving the consistency of arithmetic using type theory. In 1936, Gerhard Gentzen gave a proof of the consistency of Peano's axioms, using transfinite induction up to an ordinal called ε. Gentzen explained: "The aim of the present paper is to prove the consistency of elementary number theory or, rather, to reduce the question of consistency to certain fundamental principles". Gentzen's proof is arguably finitistic, since the transfinite ordinal ε can be encoded in terms of finite objects (for example, as a Turing machine describing a suitable order on the integers, or more abstractly as consisting of the finite trees, suitably linearly ordered). Whether or not Gentzen's proof meets the requirements Hilbert envisioned is unclear: there is no generally accepted definition of exactly what is meant by a finitistic proof, and Hilbert himself never gave a precise definition.

The vast majority of contemporary mathematicians believe that Peano's axioms are consistent, relying either on intuition or the acceptance of a consistency proof such as Gentzen's proof. A small number of philosophers and mathematicians, some of whom also advocate ultrafinitism, reject Peano's axioms because accepting the axioms amounts to accepting the infinite collection of natural numbers. In particular, addition (including the successor function) and multiplication are assumed to be total. Curiously, there are self-verifying theories that are similar to PA but have subtraction and division instead of addition and multiplication, which are axiomatized in such a way to avoid proving sentences that correspond to the totality of addition and multiplication, but which are still able to prove all true formula_40 theorems of PA, and yet can be extended to a consistent theory that proves its own consistency (stated as the non-existence of a Hilbert-style proof of "0=1").





</doc>
<doc id="25006" url="https://en.wikipedia.org/wiki?curid=25006" title="Procyon">
Procyon

Procyon ( ), also designated Alpha Canis Minoris (α Canis Minoris, abbreviated Alpha CMi, α CMi), is the brightest star in the constellation of Canis Minor. To the naked eye, it appears to be a single star, the eighth-brightest in the night sky with a visual apparent magnitude of 0.34. It is a binary star system, consisting of a white main-sequence star of spectral type F5 IV–V, named Procyon A, and a faint white dwarf companion of spectral type DQZ, named Procyon B.

As determined by the European Space Agency Hipparcos astrometry satellite, it lies at a distance of just , and is therefore one of Earth's nearest stellar neighbours.

Procyon is the eighth-brightest star in the night sky, culminating at midnight on January 14. It forms one of the three vertices of the Winter Triangle asterism, in combination with Sirius and Betelgeuse. The prime period for evening viewing of Procyon is in late winter in the northern hemisphere.

It has a color index of 0.42, and its hue has been described as having a faint yellow tinge to it.

Procyon is a binary star system with a bright primary component, Procyon A, having an apparent magnitude of 0.34, and a faint companion, Procyon B, at magnitude 10.7. The pair orbit each other with a period of 40.82 years along an elliptical orbit with an eccentricity of 0.407. The plane of their orbit is inclined at an angle of 31.1° to the line of sight with the Earth. The average separation of the two components is 15.0 AU, a little less than the distance between Uranus and the Sun, though the eccentric orbit carries them as close as 8.9 AU and as far as 21.0 AU.

The primary has a stellar classification of F5IV–V, indicating that it is a late-stage F-type main-sequence star. Procyon A is bright for its spectral class, suggesting that it is evolving into a subgiant that has nearly fused its core hydrogen into helium, after which it will expand as the nuclear reactions move outside the core. As it continues to expand, the star will eventually swell to about 80 to 150 times its current diameter and become a red or orange color. This will probably happen within 10 to 100 million years.

The effective temperature of the stellar atmosphere is an estimated 6,530 K, giving Procyon A a white hue. It is 1.5 times the solar mass (), twice the solar radius (), and has 7 times the Sun's luminosity (). Both the core and the envelope of this star are convective; the two regions being separated by a wide radiation zone.

In late June 2004, Canada's orbital MOST satellite telescope carried out a 32-day survey of Procyon A. The continuous optical monitoring was intended to confirm solar-like oscillations in its brightness observed from Earth and to permit asteroseismology. No oscillations were detected and the authors concluded that the theory of stellar oscillations may need to be reconsidered. However, others argued that the non-detection was consistent with published ground-based radial velocity observations of solar-like oscillations.

Photometric measurements from the NASA Wide Field Infrared Explorer (WIRE) satellite from 1999 and 2000 showed evidence of granulation (convection near the surface of the star) and solar-like oscillations. Unlike the MOST result, the variation seen in the WIRE photometry was in agreement with radial velocity measurements from the ground.

Like Sirius B, Procyon's companion is a white dwarf that was inferred from astrometric data long before it was observed. Its existence had been postulated by Friedrich Bessel as early as 1844, and, although its orbital elements had been calculated by Arthur Auwers in 1862 as part of his thesis, Procyon B was not visually confirmed until 1896 when John Martin Schaeberle observed it at the predicted position using the 36-inch refractor at Lick Observatory. It is more difficult to observe from Earth than Sirius B, due to a greater apparent magnitude difference and smaller angular separation from its primary.

At , Procyon B is considerably less massive than Sirius B; however, the peculiarities of degenerate matter ensure that it is larger than its more famous neighbor, with an estimated radius of 8,600 km, versus 5,800 km for Sirius B. The radius agrees with white dwarf models that assume a carbon core. It has a stellar classification of DQZ, having a helium-dominated atmosphere with traces of heavy elements. For reasons that remain unclear, the mass of Procyon B is unusually low for a white dwarf star of its type. With a surface temperature of 7,740 K, it is also much cooler than Sirius B; this is a testament to its lesser mass and greater age. The mass of the progenitor star for Procyon B was about and it came to the end of its life some  Gyr ago, after a main-sequence lifetime of  Myr.

Attempts to detect X-ray emission from Procyon with nonimaging, soft X-ray–sensitive detectors prior to 1975 failed. Extensive observations of Procyon were carried out with the Copernicus and TD-1A satellites in the late 1970s. The X-ray source associated with Procyon A/B was observed on April 1, 1979, with the Einstein Observatory high-resolution imager (HRI). The HRI X-ray pointlike source location is ~4" south of Procyon A, on the edge of the 90% confidence error circle, indicating identification with Procyon A rather than Procyon B which was located about 5" north of Procyon A (about 9" from the X-ray source location).
"α Canis Minoris" (Latinised to "Alpha Canis Minoris") is the star's Bayer designation.

The name "Procyon" comes from the Ancient Greek (""), meaning "before the dog", since it precedes the "Dog Star" Sirius as it travels across the sky due to Earth's rotation. (Although Procyon has a greater right ascension, it also has a more northerly declination, which means it will rise above the horizon earlier than Sirius from most northerly latitudes.) In Greek mythology, Procyon is associated with Maera, a hound belonging to Erigone, daughter of Icarius of Athens. In 2016, the International Astronomical Union organized a Working Group on Star Names (WGSN) to catalog and standardize proper names for stars. The WGSN's first bulletin of July 2016 included a table of the first two batches of names approved by the WGSN; which included "Procyon" for this star.

The two dog stars are referred to in the most ancient literature and were venerated by the Babylonians and the Egyptians, In Babylonian mythology, Procyon was known as Nangar (the Carpenter), an aspect of Marduk, involved in constructing and organising the celestial sky.

The constellations in Macedonian folklore represented agricultural items and animals, reflecting their village way of life. To them, Procyon and Sirius were "Volci" "the wolves", circling hungrily around Orion which depicted a plough with oxen.

Rarer names are the Latin translation of Procyon, "Antecanis," and the Arabic-derived names "Al Shira" and "Elgomaisa." Medieval astrolabes of England and Western Europe used a variant of this, "Algomeiza/Algomeyza". "Al Shira" derives from ', "the Syrian sign" (the other sign being Sirius; "Syria" is supposedly a reference to its northern location relative to Sirius); "Elgomaisa." derives from ' "the bleary-eyed (woman)", in contrast to "the teary-eyed (woman)", which is Sirius. (See Gomeisa.) At the same time this name is synonymous with the Turkish name "Rumeysa", and it is a commonly used name in Turkey. The modern Arabic name for Procyon is "". 

In Chinese, (), meaning "South River", refers to an asterism consisting of Procyon, ε Canis Minoris and β Canis Minoris. Consequently, Procyon itself is known as (, .). It is part of the Vermilion Bird.

The Hawaiians saw Procyon as part of an asterism "Ke ka o Makali'i" ("the canoe bailer of Makali'i") that helped them navigate at sea. Called "Puana" "blossom", it formed this asterism with Capella, Sirius, Castor, and Pollux. In Tahitian lore, Procyon was one of the pillars propping up the sky, known as "Anâ-tahu'a-vahine-o-toa-te-manava" ("star-the-priestess-of-brave-heart"), the pillar for elocution. The Maori knew the star as "Puangahori".

Procyon appears on the flag of Brazil, symbolising the state of Amazonas.
The Kalapalo people of Mato Grosso state in Brazil called Procyon and Canopus "Kofongo" "Duck", with Castor and Pollux representing his hands. The asterism's appearance signified the coming of the rainy season and increase in food staple manioc, used at feasts to feed guests.

Known as "Sikuliarsiujuittuq" to the Inuit, Procyon was quite significant in their astronomy and mythology. Its eponymous name means "the one who never goes onto the newly formed sea-ice", and refers to a man who stole food from his village's hunters because he was too obese to hunt on ice. He was killed by the other hunters who convinced him to go on the sea ice. Procyon received this designation because it typically appears red (though sometimes slightly greenish) as it rises during the Arctic winter; this red color was associated with Sikuliarsiujuittuq's bloody end.

Were the Sun to be observed from this star system, it would appear to be a magnitude 2.55 star in the constellation Aquila with the exact opposite coordinates at right ascension , declination . It would be as bright as Beta Scorpii is in our sky. Canis Minor would obviously be missing its brightest star.

Procyon's closest neighboring star is Luyten's Star, about away, and the latter would appear as a visual magnitude 2.7 star in the night sky of a hypothetical planet orbiting Procyon.




</doc>
<doc id="25008" url="https://en.wikipedia.org/wiki?curid=25008" title="Prisoner of war">
Prisoner of war

A prisoner of war (POW) is a person, whether combatant or non-combatant, who is held in custody by a belligerent power during or immediately after an armed conflict. The earliest recorded usage of the phrase "prisoner of war" dates to 1660.

Belligerents hold prisoners of war in custody for a range of legitimate and illegitimate reasons, such as isolating them from enemy combatants still in the field (releasing and repatriating them in an orderly manner after hostilities), demonstrating military victory, punishing them, prosecuting them for war crimes, exploiting them for their labour, recruiting or even conscripting them as their own combatants, collecting military and political intelligence from them, or indoctrinating them in new political or religious beliefs.

For most of human history, depending on the culture of the victors, enemy combatants on the losing side in a battle who had surrendered and been taken as a prisoner of war could expect to be either slaughtered or enslaved. The first Roman gladiators were prisoners of war and were named according to their ethnic roots such as Samnite, Thracian, and the Gaul (Gallus). Homer's "Iliad" describes Greek and Trojan soldiers offering rewards of wealth to opposing forces who have defeated them on the battlefield in exchange for mercy, but their offers are not always accepted; see Lycaon for example.

Typically, little distinction was made between enemy combatants and enemy civilians, although women and children were more likely to be spared. Sometimes, the purpose of a battle, if not a war, was to capture women, a practice known as "raptio"; the Rape of the Sabines was a large mass abduction by the founders of Rome. Typically women had no rights, and were held legally as chattel.

In the fourth century AD, Bishop Acacius of Amida, touched by the plight of Persian prisoners captured in a recent war with the Roman Empire, who were held in his town under appalling conditions and destined for a life of slavery, took the initiative of ransoming them, by selling his church's precious gold and silver vessels, and letting them return to their country. For this he was eventually canonized.

During Childeric's siege and blockade of Paris in 464, the nun Geneviève (later canonised as the city's patron saint) pleaded with the Frankish king for the welfare of prisoners of war and met with a favourable response. Later, Clovis I liberated captives after Genevieve urged him to do so.

Many French prisoners of war were killed during the Battle of Agincourt in 1415. This was done in retaliation for the French killing of the boys and other non-combatants handling the baggage and equipment of the army, and because the French were attacking again and Henry was afraid that they would break through and free the prisoners to fight again.

In the later Middle Ages, a number of religious wars aimed to not only defeat but eliminate their enemies. In Christian Europe, the extermination of heretics was considered desirable. Examples include the 13th century Albigensian Crusade and the Northern Crusades. When asked by a Crusader how to distinguish between the Catholics and Cathars once they'd taken the city of Béziers, the Papal Legate Arnaud Amalric famously replied, ""Kill them all, God will know His own"".

Likewise, the inhabitants of conquered cities were frequently massacred during the Crusades against the Muslims in the 11th and 12th centuries. Noblemen could hope to be ransomed; their families would have to send to their captors large sums of wealth commensurate with the social status of the captive.

In feudal Japan there was no custom of ransoming prisoners of war, who were for the most part summarily executed.
The expanding Mongol Empire was famous for distinguishing between cities or towns that surrendered, where the population were spared but required to support the conquering Mongol army, and those that resisted, where their city was ransacked and destroyed, and all the population killed. In Termez, on the Oxus: ""all the people, both men and women, were driven out onto the plain, and divided in accordance with their usual custom, then they were all slain"".

The Aztecs were constantly at war with neighbouring tribes and groups, with the goal of this constant warfare being to collect live prisoners for sacrifice. For the re-consecration of Great Pyramid of Tenochtitlan in 1487, "between 10,000 and 80,400 persons" were sacrificed.
During the early Muslim conquests, Muslims routinely captured large number of prisoners. Aside from those who converted, most were ransomed or enslaved. Christians who were captured during the Crusades, were usually either killed or sold into slavery if they could not pay a ransom. During his lifetime, Muhammad made it the responsibility of the Islamic government to provide food and clothing, on a reasonable basis, to captives, regardless of their religion; however if the prisoners were in the custody of a person, then the responsibility was on the individual. The freeing of prisoners was highly recommended as a charitable act.

The 1648 Peace of Westphalia, which ended the Thirty Years' War, established the rule that prisoners of war should be released without ransom at the end of hostilities and that they should be allowed to return to their homelands.
There also evolved the right of "parole", French for "discourse", in which a captured officer surrendered his sword and gave his word as a gentleman in exchange for privileges. If he swore not to escape, he could gain better accommodations and the freedom of the prison. If he swore to cease hostilities against the nation who held him captive, he could be repatriated or exchanged but could not serve against his former captors in a military capacity.

Early historical narratives of captured colonial Europeans, including perspectives of literate women captured by the indigenous peoples of North America, exist in some number. The writings of Mary Rowlandson, captured in the brutal fighting of King Philip's War, are an example. Such narratives enjoyed some popularity, spawning a genre of the captivity narrative, and had lasting influence on the body of early American literature, most notably through the legacy of James Fenimore Cooper's "Last of the Mohicans". Some Native Americans continued to capture Europeans and use them both as labourers and bargaining chips into the 19th century; see for example John R. Jewitt, an Englishman who wrote a memoir about his years as a captive of the Nootka people on the Pacific Northwest coast from 1802–1805.

The earliest known purposely built prisoner-of-war camp was established at Norman Cross, England in 1797 to house the increasing number of prisoners from the French Revolutionary Wars and the Napoleonic Wars. The average prison population was about 5,500 men. The lowest number recorded was 3,300 in October 1804 and 6,272 on 10 April 1810 was the highest number of prisoners recorded in any official document. Norman Cross was intended to be a model depot providing the most humane treatment of prisoners of war. The British government went to great lengths to provide food of a quality at least equal to that available to locals. The senior officer from each quadrangle was permitted to inspect the food as it was delivered to the prison to ensure it was of sufficient quality. Despite the generous supply and quality of food, some prisoners died of starvation after gambling away their rations. Most of the men held in the prison were low-ranking soldiers and sailors, including midshipmen and junior officers, with a small number of privateers. About 100 senior officers and some civilians "of good social standing", mainly passengers on captured ships and the wives of some officers, were given "parole d'honneur" outside the prison, mainly in Peterborough although some further afield in Northampton, Plymouth, Melrose and Abergavenny. They were afforded the courtesy of their rank within English society.
The Leipzig citizen Rochlitz remarked in his account about the Battle of Leipzig, that large crowds of French POWs were held on fields outside the town, begged passersby for food, and that most of them didn't survive this ordeal.

The extensive period of conflict during the American Revolutionary War and Napoleonic Wars (1793–1815), followed by the Anglo-American War of 1812, led to the emergence of a cartel system for the exchange of prisoners, even while the belligerents were at war. A cartel was usually arranged by the respective armed service for the exchange of like-ranked personnel. The aim was to achieve a reduction in the number of prisoners held, while at the same time alleviating shortages of skilled personnel in the home country.

At the start of the civil war a system of paroles operated. Captives agreed not to fight until they were officially exchanged. Meanwhile, they were held in camps run by their own army where they were paid but not allowed to perform any military duties. The system of exchanges collapsed in 1863 when the Confederacy refused to exchange black prisoners. In the late summer of 1864, a year after the Dix-Hill Cartel was suspended; Confederate officials approached Union General Benjamin Butler, Union Commissioner of Exchange, about resuming the cartel and including the black prisoners. Butler contacted Grant for guidance on the issue, and Grant responded to Butler on August 18, 1864 with his now famous statement. He rejected the offer, stating in essence, that the Union could afford to leave their men in captivity, the Confederacy could not. After that about 56,000 of the 409,000 POWs died in prisons during the American Civil War, accounting for nearly 10% of the conflict's fatalities. Of the 45,000 Union prisoners of war confined in Camp Sumter, located near Andersonville, Georgia, 13,000 (28%) died. At Camp Douglas in Chicago, Illinois, 10% of its Confederate prisoners died during one cold winter month; and Elmira Prison in New York state, with a death rate of 25% (2,963), nearly equalled that of Andersonville.

During the 19th century, there were increased efforts to improve the treatment and processing of prisoners. As a result of these emerging conventions, a number of international conferences were held, starting with the Brussels Conference of 1874, with nations agreeing that it was necessary to prevent inhumane treatment of prisoners and the use of weapons causing unnecessary harm. Although no agreements were immediately ratified by the participating nations, work was continued that resulted in new conventions being adopted and becoming recognized as international law that specified that prisoners of war be treated humanely and diplomatically.

Chapter II of the Annex to the 1907 Hague Convention "IV – The Laws and Customs of War on Land" covered the treatment of prisoners of war in detail. These provisions were further expanded in the 1929 Geneva Convention on the Prisoners of War and were largely revised in the Third Geneva Convention in 1949.

Article 4 of the Third Geneva Convention protects captured military personnel, some guerrilla fighters, and certain civilians. It applies from the moment a prisoner is captured until he or she is released or repatriated. One of the main provisions of the convention makes it illegal to torture prisoners and states that a prisoner can only be required to give their name, date of birth, rank and service number (if applicable).

The ICRC has a special role to play, with regards to international humanitarian law, in restoring and maintaining family contact in times of war, in particular concerning the right of prisoners of war and internees to send and receive letters and cards (Geneva Convention (GC) III, art.71 and GC IV, art.107).

However, nations vary in their dedication to following these laws, and historically the treatment of POWs has varied greatly. During World War II, Imperial Japan and Nazi Germany (towards Soviet POWs and Western Allied commandos) were notorious for atrocities against prisoners of war. The German military used the Soviet Union's refusal to sign the Geneva Convention as a reason for not providing the necessities of life to Soviet POWs; and the Soviets similarly killed Axis prisoners or used them as slave labour. The Germans also routinely executed Western Allied commandos captured behind German lines per the Commando Order. North Korean and North and South Vietnamese forces routinely killed or mistreated prisoners taken during those conflicts.

To be entitled to prisoner-of-war status, captured persons must be lawful combatants entitled to combatant's privilege—which gives them immunity from punishment for crimes constituting lawful acts of war such as killing enemy combatants. To qualify under the Third Geneva Convention, a combatant must be part of a chain of command, wear a "fixed distinctive marking, visible from a distance", bear arms openly, and have conducted military operations according to the laws and customs of war. (The Convention recognizes a few other groups as well, such as "[i]nhabitants of a non-occupied territory, who on the approach of the enemy spontaneously take up arms to resist the invading forces, without having had time to form themselves into regular armed units".)

Thus, uniforms and/or badges are important in determining prisoner-of-war status; and "francs-tireurs", terrorists, saboteurs, mercenaries, and spies do not qualify because they do not always follow the laws and customs of war and therefore they fall under the category of unlawful combatants. In practice, these criteria are rarely interpreted strictly. Guerrillas, for example, usually do not wear a uniform or carry arms openly, but captured guerrillas are often granted POW status.

The criteria are applied primarily to "international" armed conflicts; in civil wars, insurgents are often treated as traitors or criminals by government forces, and are sometimes executed. However, in the American Civil War, both sides treated captured troops as POWs, presumably out of reciprocity, although the Union regarded Confederate personnel as separatist rebels. However, guerrillas and other irregular combatants generally cannot expect to receive benefits from both civilian and military status simultaneously.

Under the Third Geneva Convention, prisoners of war (POW) must be:


In addition, if wounded or sick on the battlefield, the prisoner will receive help from the International Committee of the Red Cross.

When a country is responsible for breaches of prisoner of war rights, those accountable will be punished accordingly. An example of this is the Nuremberg and Tokyo Trials. German and Japanese military commanders were prosecuted for preparing and initiating a war of aggression, murder, ill treatment, and deportation of individuals, and genocide during World War II. Most were executed or sentenced to life in prison for their crimes.

The United States Military Code of Conduct was promulgated in 1955 via under President Dwight D. Eisenhower to serve as a moral code for United States service members who have been taken prisoner. It was created primarily in response to the breakdown of leadership and organization, specifically when U.S. forces were POWs during the Korean War.

When a military member is taken prisoner, the Code of Conduct reminds them that the chain of command is still in effect (the highest ranking service member eligible for command, regardless of service branch, is in command), and requires them to support their leadership. The Code of Conduct also requires service members to resist giving information to the enemy (beyond identifying themselves, that is, "name, rank, serial number"), receiving special favors or parole, or otherwise providing their enemy captors aid and comfort.

Since the Vietnam War, the official U.S. military term for enemy POWs is EPW (Enemy Prisoner of War). This name change was introduced in order to distinguish between enemy and U.S. captives.

In 2000, the U.S. military replaced the designation "Prisoner of War" for captured American personnel with "Missing-Captured". A January 2008 directive states that the reasoning behind this is since "Prisoner of War" is the international legal recognized status for such people there is no need for any individual country to follow suit. This change remains relatively unknown even among experts in the field and "Prisoner of War" remains widely used in the Pentagon which has a "POW/Missing Personnel Office" and awards the Prisoner of War Medal.

During World War I, about eight million men surrendered and were held in POW camps until the war ended. All nations pledged to follow the Hague rules on fair treatment of prisoners of war, and in general the POWs had a much higher survival rate than their peers who were not captured. Individual surrenders were uncommon; usually a large unit surrendered all its men. At Tannenberg 92,000 Russians surrendered during the battle. When the besieged garrison of Kaunas surrendered in 1915, 20,000 Russians became prisoners. Over half the Russian losses were prisoners as a proportion of those captured, wounded or killed. About 3.3 million men became prisoners.

The German Empire held 2.5 million prisoners; Russia held 2.9 million, and Britain and France held about 720,000, mostly gained in the period just before the Armistice in 1918. The US held 48,000. The most dangerous moment for POW's was the act of surrender, when helpless soldiers were sometimes mistakenly shot down. Once prisoners reached a POW camp conditions were better (and often much better than in World War II), thanks in part to the efforts of the International Red Cross and inspections by neutral nations.

There was however much harsh treatment of POWs in Germany, as recorded by the American ambassador to Germany (prior to America's entry into the war), James W. Gerard, who published his findings in "My Four Years in Germany". Even worse conditions are reported in the book "Escape of a Princess Pat" by the Canadian George Pearson. It was particularly bad in Russia, where starvation was common for prisoners and civilians alike; a quarter of the over 2 million POWs held there died. Nearly 375,000 of the 500,000 Austro-Hungarian prisoners of war taken by Russians perished in Siberia from smallpox and typhus. In Germany, food was short, but only 5% died.

The Ottoman Empire often treated prisoners of war poorly. Some 11,800 British soldiers, most of them Indians, became prisoners after the five-month Siege of Kut, in Mesopotamia, in April 1916. Many were weak and starved when they surrendered and 4,250 died in captivity.

During the Sinai and Palestine campaign 217 Australian and unknown numbers of British, New Zealand and Indian soldiers were captured by Ottoman Empire forces. About 50% of the Australian prisoners were light horsemen including 48 missing believed captured on 1 May 1918 in the Jordan Valley. Australian Flying Corps pilots and observers were captured in the Sinai Peninsula, Palestine and the Levant. One third of all Australian prisoners were captured on Gallipoli including the crew of the submarine AE2 which made a passage through the Dardanelles in 1915. Forced marches and crowded railway journeys preceded years in camps where disease, poor diet and inadequate medical facilities prevailed. About 25% of other ranks died, many from malnutrition, while only one officer died.

The most curious case came in Russia where the Czechoslovak Legion of Czechoslovak prisoners (from the Austro-Hungarian army): they were released in 1917, armed themselves, briefly culminating into a military and diplomatic force during the Russian Civil War.

At the end of the war in 1918 there were believed to be 140,000 British prisoners of war in Germany, including thousands of internees held in neutral Switzerland. The first British prisoners were released and reached Calais on 15 November. Plans were made for them to be sent via Dunkirk to Dover and a large reception camp was established at Dover capable of housing 40,000 men, which could later be used for demobilisation.

On 13 December 1918, the armistice was extended and the Allies reported that by 9 December 264,000 prisoners had been repatriated. A very large number of these had been released "en masse" and sent across Allied lines without any food or shelter. This created difficulties for the receiving Allies and many released prisoners died from exhaustion. The released POWs were met by cavalry troops and sent back through the lines in lorries to reception centres where they were refitted with boots and clothing and dispatched to the ports in trains.

Upon arrival at the receiving camp the POWs were registered and "boarded" before being dispatched to their own homes. All commissioned officers had to write a report on the circumstances of their capture and to ensure that they had done all they could to avoid capture. Each returning officer and man was given a message from King George V, written in his own hand and reproduced on a lithograph. It read as follows:
While the Allied prisoners were sent home at the end of the war, the same treatment was not granted to Central Powers prisoners of the Allies and Russia, many of whom had to serve as forced labour, e.g. in France, until 1920. They were released after many approaches by the ICRC to the Allied Supreme Council.

Historian Niall Ferguson, in addition to figures from Keith Lowe, tabulated the total death rate for POWs in World War II as follows:

The Empire of Japan, which had signed but never ratified the 1929 Geneva Convention on Prisoners of War, did not treat prisoners of war in accordance with international agreements, including provisions of the Hague Conventions, either during the Second Sino-Japanese War or during the Pacific War, because the Japanese viewed surrender as dishonorable. Moreover, according to a directive ratified on 5 August 1937 by Hirohito, the constraints of the Hague Conventions were explicitly removed on Chinese prisoners.

Prisoners of war from China, the United States, Australia, Britain, Canada, India, the Netherlands, New Zealand, and the Philippines held by the Japanese armed forces were subject to murder, beatings, summary punishment, brutal treatment, forced labour, medical experimentation, starvation rations, poor medical treatment and cannibalism. The most notorious use of forced labour was in the construction of the Burma–Thailand Death Railway. After 20 March 1943, the Imperial Navy was under orders to execute all prisoners taken at sea.

According to the findings of the Tokyo Tribunal, the death rate of Western prisoners was 27.1%, seven times that of POWs under the Germans and Italians. The death rate of Chinese was much higher. Thus, while 37,583 prisoners from the United Kingdom, Commonwealth, and Dominions, 28,500 from the Netherlands, and 14,473 from the United States were released after the surrender of Japan, the number for the Chinese was only 56. The 27,465 United States Army and United States Army Air Forces POWs in the Pacific Theater had a 40.4% death rate. The War Ministry in Tokyo issued an order at the end of the war to kill all surviving POWs.

No direct access to the POWs was provided to the International Red Cross. Escapes among Caucasian prisoners were almost impossible because of the difficulty of men of Caucasian descent hiding in Asiatic societies.

Allied POW camps and ship-transports were sometimes accidental targets of Allied attacks. The number of deaths which occurred when Japanese "hell ships"—unmarked transport ships in which POWs were transported in harsh conditions—were attacked by US Navy submarines was particularly high. Gavan Daws has calculated that "of all POWs who died in the Pacific War, one in three was killed on the water by friendly fire". Daves states that 10,800 of the 50,000 POWs shipped by the Japanese were killed at sea while Donald L. Miller states that "approximately 21,000 Allied POWs died at sea, about 19,000 of them killed by friendly fire."

Life in the POW camps was recorded at great risk to themselves by artists such as Jack Bridger Chalker, Philip Meninsky, Ashley George Old, and Ronald Searle. Human hair was often used for brushes, plant juices and blood for paint, and toilet paper as the "canvas". Some of their works were used as evidence in the trials of Japanese war criminals.

Research into the conditions of the camps has been conducted by The Liverpool School of Tropical Medicine.

After the French armies surrendered in summer 1940, Germany seized two million French prisoners of war and sent them to camps in Germany. About one third were released on various terms. Of the remainder, the officers and non-commissioned officers were kept in camps and did not work. The privates were sent out to work. About half of them worked for German agriculture, where food supplies were adequate and controls were lenient. The others worked in factories or mines, where conditions were much harsher.

Germany and Italy generally treated prisoners from the British Commonwealth, France, the USA, and other western Allies in accordance with the Geneva Convention, which had been signed by these countries. Consequently, western Allied officers were not usually made to work and some personnel of lower rank were usually compensated, or not required to work either. The main complaints of western Allied prisoners of war in German POW camps—especially during the last two years of the war—concerned shortages of food.

Only a small proportion of western Allied POWs who were Jews—or whom the Nazis believed to be Jewish—were killed as part of the Holocaust or were subjected to other antisemitic policies. For example, Major Yitzhak Ben-Aharon, a Palestinian Jew who had enlisted in the British Army, and who was captured by the Germans in Greece in 1941, experienced four years of captivity under entirely normal conditions for POWs.

However, a small number of Allied personnel were sent to concentration camps, for a variety of reasons including being Jewish. As the US historian Joseph Robert White put it: "An important exception ... is the sub-camp for U.S. POWs at Berga an der Elster, officially called "Arbeitskommando 625" [also known as "Stalag IX-B"]. Berga was the deadliest work detachment for American captives in Germany. 73 men who participated, or 21 percent of the detachment, perished in two months. 80 of the 350 POWs were Jews." Another well-known example was a group of 168 Australian, British, Canadian, New Zealand and US aviators who were held for two months at Buchenwald concentration camp; two of the POWs died at Buchenwald. Two possible reasons have been suggested for this incident: German authorities wanted to make an example of "Terrorflieger" ("terrorist aviators") and/or these aircrews were classified as spies, because they had been disguised as civilians or enemy soldiers when they were apprehended.

Information on conditions in the stalags is contradictory depending on the source. Some American POWs claimed the Germans were victims of circumstance and did the best they could, while others accused their captors of brutalities and forced labour. In any case, the prison camps were miserable places where food rations were meager and conditions squalid. One American admitted "The only difference between the stalags and concentration camps was that we weren't gassed or shot in the former. I do not recall a single act of compassion or mercy on the part of the Germans." Typical meals consisted of a bread slice and watery potato soup which, however, was still more substantial than what Soviet POWs or concentration camp inmates received. Another prisoner stated that "The German plan was to keep us alive, yet weakened enough that we wouldn't attempt escape."

As Soviet ground forces approached some POW camps in early 1945, German guards forced western Allied POWs to walk long distances towards central Germany, often in extreme winter weather conditions. It is estimated that, out of 257,000 POWs, about 80,000 were subject to such marches and up to 3,500 of them died as a result.

In September 1943 after the Armistice, Italian officers and soldiers that in many places waited for clear superior orders, were arrested by Germans and Italian fascists and taken to German internment camps in Germany or Eastern Europe, where they were held for the duration of World War II. The International Red Cross could do nothing for them, as they were not regarded as POWs, but the prisoners held the status of "military internees". Treatment of the prisoners was generally poor. The author Giovannino Guareschi was among those interned and wrote about this time in his life. The book was translated and published as "My Secret Diary". He wrote about the hungers of semi-starvation, the casual murder of individual prisoners by guards and how, when they were released (now from a German camp), they found a deserted German town filled with foodstuffs that they (with other released prisoners) ate.. It is estimated that of the 1,070,000 Italians taken prisoner by the Germans, around 40,000 died in detention and more than 13,000 lost their lives during the transportation from the Greek islands to the mainland.

Germany did not apply the same standard of treatment to non-western prisoners, especially many Polish and Soviet POWs who suffered harsh conditions and died in large numbers while in captivity.

Between 1941 and 1945 the Axis powers took about 5.7 million Soviet prisoners. About one million of them were released during the war, in that their status changed but they remained under German authority. A little over 500,000 either escaped or were liberated by the Red Army. Some 930,000 more were found alive in camps after the war. The remaining 3.3 million prisoners (57.5% of the total captured) died during their captivity. Between the launching of Operation Barbarossa in the summer of 1941 and the following spring, 2.8 million of the 3.2 million Soviet prisoners taken died while in German hands. According to Russian military historian General Grigoriy Krivosheyev, the Axis powers took 4.6 million Soviet prisoners, of whom 1.8 million were found alive in camps after the war and 318,770 were released by the Axis during the war and were then drafted into the Soviet armed forces again. By comparison, 8,348 Western Allied prisoners died in German camps during 1939–45 (3.5% of the 232,000 total).

Some Soviet POWs and forced labourers whom the Germans had transported to Nazi Germany were, on their return to the USSR, treated as traitors and sent to gulag prison-camps.

According to some sources, the Soviets captured 3.5 million Axis servicemen (excluding Japanese) of which more than a million died. One specific example is that of the German POWs after the Battle of Stalingrad, where the Soviets captured 91,000 German troops in total (completely exhausted, starving and sick) of whom only 5,000 survived the captivity.

German soldiers were kept as forced labour for many years after the war. The last German POWs like Erich Hartmann, the highest-scoring fighter ace in the history of aerial warfare, who had been declared guilty of war crimes but without due process, were not released by the Soviets until 1955, three years after Stalin died.

As a result of the Soviet invasion of Poland in 1939, hundreds of thousands of Polish soldiers became prisoners of war in the Soviet Union. Thousands of them were executed; over 20,000 Polish military personnel and civilians perished in the Katyn massacre. Out of Anders' 80,000 evacuees from Soviet Union gathered in the United Kingdom only 310 volunteered to return to Poland in 1947.

Out of the 230,000 Polish prisoners of war taken by the Soviet army, only 82,000 survived.

With the Soviet invasion of Manchuria, in 1945, Japanese soldiers became prisoners in the Soviet Union, where they, just as other Axis POWs, had to work.

There were stories during the Cold War to the effect that 23,000 Americans who had been held in German POW camps were seized by the Soviets and never repatriated. This myth had been perpetuated after the release of people like John H. Noble. Careful scholarly studies have demonstrated this is a myth based on a misinterpretation of a telegram that was talking about Soviet prisoners held in Italy.

During the war, the armies of Western Allied nations such as Australia, Canada, the UK and the US were ordered to treat Axis prisoners strictly in accordance with the Geneva Convention. Some breaches of the Convention took place, however. According to Stephen E. Ambrose, of the roughly 1,000 US combat veterans that he had interviewed, only one admitted to shooting a prisoner, saying that he "felt remorse, but would do it again". However, one-third told him they had seen US troops kill German prisoners.

Towards the end of the war in Europe, as large numbers of Axis soldiers surrendered, the US created the designation of Disarmed Enemy Forces (DEF) so as not to treat prisoners as POWs. A lot of these soldiers were kept in open fields in makeshift camps in the Rhine valley ("Rheinwiesenlager"). Controversy has arisen about how Eisenhower managed these prisoners (see "Other Losses").

After the surrender of Germany in May 1945, the POW status of the German prisoners was in many cases maintained, and they were for several years used as forced labour in countries such as the UK and France. Many died when forced to clear minefields in Norway, France etc.; "by September 1945 it was estimated by the French authorities that two thousand prisoners were being maimed and killed each month in accidents"

In 1946, the UK had more than 400,000 German prisoners, many had been transferred from POW camps in the US and Canada. Many of these were for over three years after the German surrender used as forced labour, as a form of "reparations". A public debate ensued in the UK, where words such as "forced labour", "slaves", "slave labour" were increasingly used in the media and in the House of Commons. In 1947 the Ministry of Agriculture argued against repatriation of working German prisoners, since by then they made up 25 percent of the land workforce, and they wanted to use them also in 1948.

The "London Cage", an MI19 prisoner of war facility in the UK used for interrogating prisoners before they were sent to prison camps during and immediately after World War II, was subject to allegations of torture.

After the German surrender, the International Red Cross was prohibited from providing aid such as food or visiting prisoner camps in Germany. However, after making approaches to the Allies in the autumn of 1945 it was allowed to investigate the camps in the British and French occupation zones of Germany, as well as to provide relief to the prisoners held there. On 4 February 1946, the Red Cross was permitted to visit and assist prisoners also in the US occupation zone of Germany, although only with very small quantities of food. "During their visits, the delegates observed that German prisoners of war were often detained in appalling conditions. They drew the attention of the authorities to this fact, and gradually succeeded in getting some improvements made".

The Allies also shipped POWs between them, with for example 6,000 German officers transferred from Western Allied camps to the Sachsenhausen concentration camp that now was under Soviet Union administration. The US also shipped 740,000 German POWs as forced labourers to France from where newspaper reports told of very bad treatment. Judge Robert H. Jackson, Chief US prosecutor in the Nuremberg trials, in October 1945 told US President Harry S. Truman that the Allies themselves:
have done or are doing some of the very things we are prosecuting the Germans for. The French are so violating the Geneva Convention in the treatment of prisoners of war that our command is taking back prisoners sent to them. We are prosecuting plunder and our Allies are practicing it.

Hungarians became POWs of the Western Allies. Some of these were, like Germans, used as forced labour in France after the cessation of hostilities.
After the war the POWs were handed over to the Soviets, and after the POWs were transported to the USSR for forced labour. It is called even today in Hungary malenkij robot—little work. András Toma, a Hungarian soldier taken prisoner by the Red Army in 1944, was discovered in a Russian psychiatric hospital in 2000. He was probably the last prisoner of war from World War II to be repatriated.

Although thousands of Japanese were taken prisoner, most fought until they were killed or committed suicide. Of the 22,000 Japanese soldiers present at the beginning of the Battle of Iwo Jima, over 20,000 were killed and only 216 were taken prisoner. Of the 30,000 Japanese troops that defended Saipan, fewer than 1,000 remained alive at battle's end. Japanese prisoners sent to camps fared well; however, some Japanese were killed when trying to surrender or were massacred just after they had surrendered (see Allied war crimes during World War II in the Pacific). In some instances, Japanese prisoners were tortured by a variety of methods. A method of torture used by the Chinese National Revolutionary Army (NRA) included suspending the prisoner by the neck in a wooden cage until they died. In very rare cases, some were beheaded by sword, and a severed head was once used as a football by Chinese National Revolutionary Army (NRA) soldiers.

After the war, many Japanese were kept on as Japanese Surrendered Personnel until mid-1947 and used as forced labour doing menial tasks, while 35,000 were kept on in arms within their wartime military organisation and under their own officers and used in combat alongside British troops seeking to suppress the independence movements in the Dutch East Indies and French Indochina.

In 1943, Italy overthrew Mussolini and became a co-belligerent with the Allies. This did not mean any change in status for Italian POWs however, since due to the labour shortages in the UK, Australia and the USA, they were retained as POWs there.

On 11 February 1945, at the conclusion of the Yalta Conference, the United States and the United Kingdom signed a Repatriation Agreement with the USSR. The interpretation of this Agreement resulted in the forcible repatriation of all Soviets (Operation Keelhaul) regardless of their wishes. The forced repatriation operations took place in 1945–1947.

The United States handed over 740,000 German prisoners to France, a signatory of the Geneva Convention. The Soviet Union had not signed the Geneva Convention. According to Edward Peterson, the U.S. chose to hand over several hundred thousand German prisoners to the Soviet Union in May 1945 as a "gesture of friendship". U.S. forces also refused to accept the surrender of German troops attempting to surrender to them in Saxony and Bohemia, and handed them over to the Soviet Union instead. It is also known that 6000 of the German officers who were sent from camps in the West to the Soviets were subsequently imprisoned in the Sachsenhausen concentration camp, which at the time was one of the NKVD special camp.

During the Korean War, the North Koreans developed reputation for severely mistreating prisoners of war (see Crimes against POWs). Their POWs were housed in three camps, according to their potential usefulness to the North Korean army. Peace camps and reform camps were for POWs that were either sympathetic to the cause or who had valued skills that could be useful in the army and thus these enemy soldiers were indoctrinated and sometimes conscripted into the North Korean army. The regular prisoners of war were usually very poorly treated. POWs in peace camps were reportedly treated with more consideration.

In 1952, the 1952 Inter-Camp P.O.W. Olympics were held during 15 and 27 November 1952, in Pyuktong, North Korea. The Chinese hoped to gain worldwide publicity and while some prisoners refused to participate some 500 P.O.W.s of eleven nationalities took part. They were representative of all the prison camps in North Korea and competed in: football, baseball, softball, basketball, volleyball, track and field, soccer, gymnastics, and boxing. For the P.O.W.s this was also an opportunity to meet with friends from other camps. The prisoners had their own photographers, announcers, even reporters, who after each day's competition published a newspaper, the "Olympic Roundup".

Of about 16,500 French soldiers who fought at the Battle of Dien Bien Phu in French Indochina, more than 3,000 were killed in battle, while almost all of the 11,721 men taken prisoner died in the hands of the Viet Minh on death marches to distant POW camps, and in those camps in the last three months of the war.

The Vietcong and the North Vietnamese Army captured many United States service members as prisoners of war during the Vietnam War, who suffered from mistreatment and torture during the war. Some American prisoners were held in the prison called the Hanoi Hilton.
Communist Vietnamese held in custody by South Vietnamese and American forces were also tortured and badly treated. After the war, millions of South Vietnamese servicemen and government workers were sent to "re-education" camps where many perished.

Like in previous conflicts, there has been speculation without evidence that there were a handful of American pilots captured by the North Koreans and the North Vietnamese who were transferred to the Soviet Union and were never repatriated.

Regardless of regulations determining treatment to prisoners, violations of their rights continue to be reported. Many cases of POW massacres have been reported in recent times, including October 13 massacre in Lebanon by Syrian forces and June 1990 massacre in Sri Lanka.

In 1982, during the Falklands War, prisoners were well treated in general by both parties of the conflict, with military commanders dispatching 'enemy' prisoners back to their homelands in record time.

In 1991, during the Persian Gulf War, American, British, Italian, and Kuwaiti POWs (mostly crew members of downed aircraft and special forces) were tortured by the Iraqi secret police. An American military doctor, Major Rhonda Cornum, a 37-year-old flight surgeon captured when her Blackhawk UH-60 was shot down, was also subjected to sexual abuse.

During the 1990s Yugoslav Wars, Serb paramilitary forces supported by JNA forces killed POWs at Vukovar and Škarbrnja while Bosnian Serb forces killed POWs at Srebrenica.

In 2001, there were reports concerning two POWs that India had taken during the Sino-Indian War, Yang Chen and Shih Liang. The two were imprisoned as spies for three years before being interned in a mental asylum in Ranchi, where they spent the next 38 years under a special prisoner status.<br> The last prisoners of Iran–Iraq War (1980–1988) were exchanged in 2003.

This is a list of nations with the highest number of POWs since the start of World War II, listed in descending order. These are also the highest numbers in any war since the Convention Relative to the Treatment of Prisoners of War entered into force on 19 June 1931. The USSR had not signed the Geneva convention.

Movies & Television

Songs


Notes
Bibliography
Primary sources




</doc>
<doc id="25009" url="https://en.wikipedia.org/wiki?curid=25009" title="Privacy">
Privacy

Privacy is the ability of an individual or group to seclude themselves, or information about themselves, and thereby express themselves selectively. The boundaries and content of what is considered private differ among cultures and individuals, but share common themes. When something is private to a "person", it usually means that something is inherently special or sensitive to them. The domain of privacy partially overlaps security (confidentiality), which can include the concepts of appropriate use, as well as protection of information. Privacy may also take the form of bodily integrity.

The right not to be subjected to unsanctioned invasion of privacy by the government, corporations or individuals is part of many countries' privacy laws, and in some cases, constitutions. All countries have laws which in some way limit privacy. An example of this would be law concerning taxation, which normally require the sharing of information about personal income or earnings. In some countries individual privacy may conflict with freedom of speech laws and some laws may require public disclosure of information which would be considered private in other countries and cultures. This was a major concern in the United States, with the Supreme Court passage of Citizens United.

Privacy may be voluntarily sacrificed, normally in exchange for perceived benefits and very often with specific dangers and losses, although this is a very strategic view of human relationships. For example, people may be ready to reveal their name if that allows them to promote trust by others and thus build meaningful social relations. Research shows that people are more willing to voluntarily sacrifice privacy if the data gatherer is seen to be transparent as to what information is gathered and how it is used. In the business world, a person may volunteer personal details (often for advertising purposes) in order to gamble on winning a prize. A person may also disclose personal information as part of being an executive for a publicly traded company in the USA pursuant to federal securities law. Personal information which is voluntarily shared but subsequently stolen or misused can lead to identity theft.

The concept of universal individual privacy is a modern construct primarily associated with Western culture, British and North American in particular, and remained virtually unknown in some cultures until recent times. According to some researchers, this concept sets Anglo-American culture apart even from Western European cultures such as French or Italian. Most cultures, however, recognize the ability of individuals to withhold certain parts of their personal information from wider society—closing the door to one's home, for example.

The distinction or overlap between secrecy and privacy is ontologically subtle, which is why the word "privacy" is an example of an untranslatable lexeme, and many languages do not have a specific word for "privacy". Such languages either use a complex description to translate the term (such as Russian combining the meaning of "уединение"—solitude, "секретность"—secrecy, and "частная жизнь"—private life) or borrow from English "privacy" (as Indonesian "privasi" or Italian "la privacy"). The distinction hinges on the discreteness of interests of parties (persons or groups), which can have emic variation depending on cultural mores of individualism, collectivism, and the negotiation between individual and group rights. The difference is sometimes expressed humorously as "when "I" withhold information, it is privacy; when "you" withhold information, it is secrecy."

A broad multicultural literary tradition going to the beginnings of recorded history discusses the concept of privacy. One way of categorizing all concepts of privacy is by considering all discussions as one of these concepts:


In 1890 the United States jurists Samuel D. Warren and Louis Brandeis wrote "The Right to Privacy", an article in which they argued for the "right to be let alone", using that phrase as a definition of privacy. There is extensive commentary over the meaning of being "let alone", and among other ways, it has been interpreted to mean the right of a person to choose seclusion from the attention of others if they wish to do so, and the right to be immune from scrutiny or being observed in private settings, such as one’s own home. Although this early vague legal concept did not describe privacy in a way that made it easy to design broad legal protections of privacy, it strengthened the notion of privacy rights for individuals and began a legacy of discussion on those rights.

Limited access refers to a person’s ability to participate in society without having other individuals and organizations collect information about them.

Various theorists have imagined privacy as a system for limiting access to one’s personal information. Edwin Lawrence Godkin wrote in the late 19th century that "nothing is better worthy of legal protection than private life, or, in other words, the right of every man to keep his affairs to himself, and to decide for himself to what extent they shall be the subject of public observation and discussion." Adopting an approach similar to the one presented by Ruth Gavison 9 years earlier, Sissela Bok said that privacy is "the condition of being protected from unwanted access by others—either physical access, personal information, or attention."

Control over one's personal information is the concept that "privacy is the claim of individuals, groups, or institutions to determine for themselves when, how, and to what extent information about them is communicated to others." Charles Fried said that "Privacy is not simply an absence of information about us in the minds of others; rather it is the control we have over information about ourselves." Control over personal information is one of the more popular theories of the meaning of privacy. Nevertheless, in the era of big data, control over information is under pressure.

Alan Westin defined four states—or experiences—of privacy: solitude, intimacy, anonymity, and reserve. Solitude is a physical separation from others. Intimacy is a "close, relaxed, and frank relationship between two or more individuals" that results from the seclusion of a pair or small group of individuals. Anonymity is the "desire of individuals for times of 'public privacy.'" Lastly, reserve is the "creation of a psychological barrier against unwanted intrusion"; this creation of a psychological barrier requires others to respect an individual's need or desire to restrict communication of information concerning himself or herself.

In addition to the psychological barrier of reserve, Kirsty Hughes identified three more kinds of privacy barriers: physical, behavioral, and normative. Physical barriers, such as walls and doors, prevent others from accessing and experiencing the individual. (In this sense, "accessing" an individual includes accessing personal information about him or her.) Behavioral barriers communicate to others—verbally, through language, or non-verbally, through personal space, body language, or clothing—that an individual does not want them to access or experience him or her. Lastly, normative barriers, such as laws and social norms, restrain others from attempting to access or experience an individual.

Privacy is sometimes defined as an option to have secrecy. Richard Posner said that privacy is the right of people to "conceal information about themselves that others might use to their disadvantage".

In various legal contexts, when privacy is described as secrecy, a conclusion if privacy is secrecy then rights to privacy do not apply for any information which is already publicly disclosed. When privacy-as-secrecy is discussed, it is usually imagined to be a selective kind of secrecy in which individuals keep some information secret and private while they choose to make other information public and not private.

Privacy may be understood as a necessary precondition for the development and preservation of personhood. Jeffrey Reiman defined privacy in terms of a recognition of one's ownership of his or her physical and mental reality and a moral right to his or her self-determination. Through the "social ritual" of privacy, or the social practice of respecting an individual's privacy barriers, the social group communicates to the developing child that he or she has exclusive moral rights to his or her body—in other words, he or she has moral ownership of his or her body. This entails control over both active (physical) and cognitive appropriation, the former being control over one's movements and actions and the latter being control over who can experience one's physical existence and when.

Alternatively, Stanley Benn defined privacy in terms of a recognition of oneself as a subject with agency—as an individual with the capacity to choose. Privacy is required to exercise choice. Overt observation makes the individual aware of himself or herself as an object with a "determinate character" and "limited probabilities." Covert observation, on the other hand, changes the conditions in which the individual is exercising choice without his or her knowledge and consent.

In addition, privacy may be viewed as a state that enables autonomy, a concept closely connected to that of personhood. According to Joseph Kufer, an autonomous self-concept entails a conception of oneself as a "purposeful, self-determining, responsible agent" and an awareness of one's capacity to control the boundary between self and other—that is, to control who can access and experience him or her and to what extent. Furthermore, others must acknowledge and respect the self's boundaries—in other words, they must respect the individual's privacy.

The studies of psychologists such as Jean Piaget and Victor Tausk show that, as children learn that they can control who can access and experience them and to what extent, they develop an autonomous self-concept. In addition, studies of adults in particular institutions, such as Erving Goffman's study of "total institutions" such as prisons and mental institutions, suggest that systemic and routinized deprivations or violations of privacy deteriorate one's sense of autonomy over time.

Privacy may be understood as a prerequisite for the development of a sense of self-identity. Privacy barriers, in particular, are instrumental in this process. According to Irwin Altman, such barriers "define and limit the boundaries of the self" and thus "serve to help define [the self]." This control primarily entails the ability to regulate contact with others. Control over the "permeability" of the self's boundaries enables one to control what constitutes the self and thus to define what is the self.

In addition, privacy may be seen as a state that fosters personal growth, a process integral to the development of self-identity. Hyman Gross suggested that, without privacy—solitude, anonymity, and temporary releases from social roles—individuals would be unable to freely express themselves and to engage in self-discovery and self-criticism. Such self-discovery and self-criticism contributes to one's understanding of oneself and shapes one's sense of identity.

In a way analogous to how the personhood theory imagines privacy as some essential part of being an individual, the intimacy theory imagines privacy to be an essential part of the way that humans have strengthened or intimate relationships with other humans. Because part of human relationships includes individuals volunteering to self-disclose some information, but withholding other information, there is a concept of privacy as a part of the process by means of which humans establish relationships with each other.

James Rachels advanced this notion by writing that privacy matters because "there is a close connection between our ability to control who has access to us and to information about us, and our ability to create and maintain different sorts of social relationships with different people."

Privacy can mean different things in different contexts; different people, cultures, and nations have different expectations about how much privacy a person is entitled to or what constitutes an invasion of privacy.

Most people have a strong sense of privacy in relation to the exposure of their body to others. This is an aspect of personal modesty. A person will go to extreme lengths to protect this personal modesty, the main way being the wearing of clothes. Other ways include erection of walls, fences, screens, use of cathedral glass, partitions, by maintaining a distance, beside other ways. People who go to those lengths expect that their privacy will be respected by others. At the same time, people are prepared to expose themselves in acts of physical intimacy, but these are confined to exposure in circumstances and of persons of their choosing. Even a discussion of those circumstances is regarded as intrusive and typically unwelcome.

Physical privacy could be defined as preventing "intrusions into one's physical space or solitude."
This would include concerns such as:

An example of the legal basis for the right to physical privacy is the U.S. Fourth Amendment, which guarantees "the right of the people to be secure in their persons, houses, papers, and effects, against unreasonable searches and seizures". Most countries have laws regarding trespassing and property rights also determine the right of physical privacy.

Physical privacy may be a matter of cultural sensitivity, personal dignity, and/or shyness. There may also be concerns about safety, if for example one is wary of becoming the victim of crime or stalking. Civil inattention is a process whereby individuals are able to maintain their privacy within a crowd.

Information or data privacy refers to the evolving relationship between technology and the legal right to, or public expectation of, privacy in the collection and sharing of data about one's self. Privacy concerns exist wherever uniquely identifiable data relating to a person or persons are collected and stored, in digital form or otherwise. In some cases these concerns refer to how data are collected, stored, and associated. In other cases the issue is who is given access to information. Other issues include whether an individual has any ownership rights to data about them, and/or the right to view, verify, and challenge that information.

Various types of personal information are often associated with privacy concerns. Information plays an important role in the decision-action process, which can lead to problems in terms of privacy and availability. First, it allows people to see all the options and alternatives available. Secondly, it allows people to choose which of the options would be best for a certain situation. An information landscape consists of the information, its location in the so-called network, as well as its availability, awareness, and usability. Yet the set-up of the information landscape means that information that is available in one place may not be available somewhere else. This can lead to a privacy situation that leads to questions regarding which people have the power to access and use certain information, who should have that power, and what provisions govern it. For various reasons, individuals may object to personal information such as their religion, sexual orientation, political affiliations, or personal activities being revealed, perhaps to avoid discrimination, personal embarrassment, or damage to their professional reputations.

Financial privacy, in which information about a person's financial transactions is guarded, is important for the avoidance of fraud including identity theft. Information about a person's purchases, for instance, can reveal a great deal about their preferences, places they have visited, their contacts, products (such as medications) they use, their activities and habits, etc. In addition to this, financial privacy also includes privacy over the bank accounts opened by individuals. Information about the bank where the individual has an account with, and whether or not this is in a country that does not share this information with other countries can help countries in fighting tax avoidance.

Internet privacy is the ability to determine what information one reveals or withholds about oneself over the Internet, who has access to such information, and for what purposes one's information may or may not be used. For example, web users may be concerned to discover that many of the web sites which they visit collect, store, and possibly share personally identifiable information about them. Similarly, Internet email users generally consider their emails to be private and hence would be concerned if their email was being accessed, read, stored or forwarded by third parties without their consent. Tools used to protect privacy on the Internet include encryption tools and anonymizing services like I2P and Tor.

Medical privacy Protected Health Information OCR/HIPAA (Health Insurance Portability and Accountability Act of 1996) allows a person to withhold their medical records and other information from others, perhaps because of fears that it might affect their insurance coverage or employment, or to avoid the embarrassment caused by revealing medical conditions or treatments. Medical information could also reveal other aspects of one's personal life, such as sexual preferences or proclivity. A right to sexual privacy enables individuals to acquire and use contraceptives without family, community or legal sanctions.

Political privacy has been a concern since voting systems emerged in ancient times. The secret ballot helps to ensure that voters cannot be coerced into voting in certain ways, since they can allocate their vote as they wish in the privacy and security of the voting booth while maintaining the anonymity of the vote. Secret ballots are nearly universal in modern democracy, and considered a basic right of citizenship, despite the difficulties that they cause (for example the inability to trace votes back to the corresponding voters increases the risk of someone stuffing additional fraudulent votes into the system: additional security controls are needed to minimize such risks).

Corporate privacy refers to the privacy rights of corporate actors like senior executives of large, publicly traded corporations. Desires for corporate privacy can frequently raise issues with obligations for public disclosures under securities and corporate law.

Government agencies, corporations, groups/societies and other organizations may desire to keep their activities or secrets from being revealed to other organizations or individuals, adopting various security practices and controls in order to keep private information confidential. Organizations may seek legal protection for their secrets. For example, a government administration may be able to invoke executive privilege or declare certain information to be classified, or a corporation might attempt to protect valuable proprietary information as trade secrets.

The earliest legislative development of privacy rights began under British common law, which protected "only the physical interference of life and property." Its development from then on became "one of the most significant chapters in the history of privacy law." Privacy rights gradually expanded to include a "recognition of man's spiritual nature, of his feelings and his intellect." Eventually, the scope of those rights broadened even further to include a basic "right to be let alone", and the former definition of "property" would then comprise "every form of possession—intangible, as well as tangible." By the late 19th century, interest in a "right to privacy" grew as a response to the growth of print media, especially newspapers.

Privacy has historical roots in philosophical discussions, the most well-known being Aristotle's distinction between two spheres of life: the public sphere of the "polis", associated with political life, and the private sphere of the "oikos", associated with domestic life. More systematic treatises of privacy in the United States did not appear until the 1890s, with the development of privacy law in America.

As technology has advanced, the way in which privacy is protected and violated has changed with it. In the case of some technologies, such as the printing press or the Internet, the increased ability to share information can lead to new ways in which privacy can be breached. It is generally agreed that the first publication advocating privacy in the United States was the article by Samuel Warren and Louis Brandeis, "The Right to Privacy", 4 "Harvard Law Review" 193 (1890), that was written largely in response to the increase in newspapers and photographs made possible by printing technologies.

New technologies can also create new ways to gather private information. For example, in the United States it was thought that heat sensors intended to be used to find marijuana-growing operations would be acceptable. However, in 2001 in "Kyllo v. United States" (533 U.S. 27) it was decided that the use of thermal imaging devices that can reveal previously unknown information without a warrant does indeed constitute a violation of privacy.

Generally the increased ability to gather and send information has had negative implications for retaining privacy. As large-scale information systems become more common, there is so much information stored in many databases worldwide that an individual has no practical means of knowing of or controlling all of the information about themselves that others may have hold or access. Such information could potentially be sold to others for profit and/or be used for purposes not known to or sanctioned by the individual concerned. The concept of information privacy has become more significant as more systems controlling more information appear. Also the consequences of privacy violations can be more severe. Privacy law in many countries has had to adapt to changes in technology in order to address these issues and, to some extent, maintain privacy rights. But the existing global privacy rights framework has also been criticized as incoherent and inefficient. Proposals such as the APEC Privacy Framework have emerged which set out to provide the first comprehensive legal framework on the issue of global data privacy.

There are various theories about privacy and privacy control. The Invasion Paradigm defines privacy violation as the hostile actions of a wrongdoer who causes direct harm to an individual. This is a reactive view of privacy protection as it waits until there is a violation before acting to protect the violated individual, sometimes through criminal punishments for those who invaded the privacy of others. In the Invasion Paradigm this threat of criminal punishment that is supposed to work as deterrent. The Secrecy paradigm defines a privacy invasion as someone’s concealed information or hidden world being revealed through surveillance. The Negative Freedom Paradigm views privacy as freedom from invasion rather than a right, going against the more popular view of a "right to privacy." Finally, the Inaccessibility Paradigm states that privacy is the state where something is completely inaccessible to others. Daniel Solove, a law professor at George Washington University also has a theory of privacy. He believes that a conceptualized view of privacy will not work because there is no one core element. There are many different, interconnected elements involved in privacy and privacy protection. Therefore, Solove proposes looking at these issues from the bottom up, focusing on privacy problems. People may often overlook the fact that certain elements of privacy problems are due to the structure of privacy itself. Therefore, the architecture must change wherein people must learn to view privacy as a social and legal structure. He also states that people have to redefine the relationship between privacy and businesses and the government. Participation in certain privacy elements of the government and businesses should allow people to choose whether they want to be a part of certain aspects of their work that could be considered privacy invasion.

The Internet has brought new concerns about privacy in an age where computers can permanently store records of everything: "where every online photo, status update, Twitter post and blog entry by and about us can be stored forever", writes law professor and author Jeffrey Rosen.

This currently has an effect on employment. Microsoft reports that 75 percent of U.S. recruiters and human-resource professionals now do online research about candidates, often using information provided by search engines, social-networking sites, photo/video-sharing sites, personal web sites and blogs, and Twitter. They also report that 70 percent of U.S. recruiters have rejected candidates based on internet information. This has created a need by many to control various online privacy settings in addition to controlling their online reputations, both of which have led to legal suits against various sites and employers.

The ability to do online inquiries about individuals has expanded dramatically over the last decade. Facebook for example, as of August 2015, was the largest social-networking site, with nearly 1,490 million members, who upload over 4.75 billion pieces of content daily. Over 83.09 million accounts were fake. Twitter has more than 316 million registered users and over 20 million are fake users. The Library of Congress recently announced that it will be acquiring—and permanently storing—the entire archive of public Twitter posts since 2006, reports Rosen.

Importantly, directly observed behaviour, such as browsing logs, search queries, or contents of the Facebook profile can be automatically processed to infer secondary information about an individual, such as sexual orientation, political and religious views, race, substance use, intelligence, and personality. Effectively, individual views and preferences can be revealed even if they were not directly expressed or indicated (e.g. by stating their political views on their Facebook profile, or visiting a gay community website).

According to some experts, many commonly used communication devices may be mapping every move of their users. Senator Al Franken has noted the seriousness of iPhones and iPads having the ability to record and store users' locations in unencrypted files, although Apple denied doing so.

Andrew Grove, co-founder and former CEO of Intel Corporation, offered his thoughts on internet privacy in an interview published in May 2000:
As with other concepts about privacy, there are various ways to discuss what kinds of processes or actions remove, challenge, lessen, or attack privacy. In 1960 legal scholar William Prosser created the following list of activities which can be remedied with privacy protection:

Building from this and other historical precedents, Daniel J. Solove presented another classification of actions which are harmful to privacy, including collection of information which is already somewhat public, processing of information, sharing information, and invading personal space to get private information.

In the context of harming privacy, information collection means gathering whatever information can be obtained by doing something to obtain it. Surveillance is an example of this, when someone decides to begin watching and recording someone or something, and interrogation is another example of this, when someone uses another person as a source of information.

It can happen that privacy is not harmed when information is available, but that the harm can come when that information is collected as a set then processed in a way that the collective reporting of pieces of information encroaches on privacy. Actions in this category which can lessen privacy include the following:

Information dissemination is an attack on privacy when information which was shared in confidence is shared or threatened to be shared in a way that harms the subject of the information.

There are various examples of this. Breach of confidentiality is when one entity promises to keep a person’s information private, then breaks that promise. Disclosure is making information about a person more accessible in a way that harms the subject of the information, regardless of how the information was collected or the intent of making it available. Exposure is a special type of disclosure in which the information disclosed is emotional to the subject or taboo to share, such as revealing their private life experiences, their nudity, or perhaps private body functions. Increased accessibility means advertising the availability of information without actually distributing it, as in the case of doxxing. Blackmail is making a threat to share information, perhaps as part of an effort to coerce someone. Appropriation is an attack on the personhood of someone, and can include using the value of someone's reputation or likeness to advance interests which are not those of the person being appropriated. Distortion is the creation of misleading information or lies about a person.

Invasion of privacy is a different concept from the collecting, aggregating, and disseminating information because those three are a misuse of available data, whereas invasion is an attack on the right of individuals to keep personal secrets. An invasion is an attack in which information, whether intended to be public or not, is captured in a way that insults the personal dignity and right to private space of the person whose data is taken.

An intrusion is any unwanted entry into a person's private personal space and solitude for any reason, regardless of whether data is taken during that breach of space. "Decisional interference" is when an entity somehow injects itself into the personal decision making process of another person, perhaps to influence that person's private decisions but in any case doing so in a way that disrupts the private personal thoughts that a person has.

Privacy uses the theory of natural rights, and generally responds to new information and communication technologies. In North America, Samuel D. Warren and Louis D. Brandeis wrote that privacy is the "right to be let alone" (Warren & Brandeis, 1890) focuses on protecting individuals. This citation was a response to recent technological developments, such as photography, and sensationalist journalism, also known as yellow journalism.

Privacy rights are inherently intertwined with information technology. In his widely cited dissenting opinion in "Olmstead v. United States" (1928), Brandeis relied on thoughts he developed in his "Harvard Law Review" article in 1890. But in his dissent, he now changed the focus whereby he urged making personal privacy matters more relevant to constitutional law, going so far as saying "the government [was] identified ... as a potential privacy invader." He writes, "Discovery and invention have made it possible for the Government, by means far more effective than stretching upon the rack, to obtain disclosure in court of what is whispered in the closet." At that time, telephones were often community assets, with shared party lines and the potentially nosey human operators. By the time of Katz, in 1967, telephones had become personal devices with lines not shared across homes and switching was electro-mechanical. In the 1970s, new computing and recording technologies began to raise concerns about privacy, resulting in the Fair Information Practice Principles.

In recent years there have been only few attempts to clearly and precisely define a "right to privacy." Some experts assert that in fact the right to privacy "should not be defined as a separate legal right" at all. By their reasoning, existing laws relating to privacy in general should be sufficient. Other experts, such as Dean Prosser, have attempted, but failed, to find a "common ground" between the leading kinds of privacy cases in the court system, at least to formulate a definition. One law school treatise from Israel, however, on the subject of "privacy in the digital environment", suggests that the "right to privacy should be seen as an independent right that deserves legal protection in itself." It has therefore proposed a working definition for a "right to privacy":
"The right to privacy is our right to keep a domain around us, which includes all those things that are part of us, such as our body, home, property, thoughts, feelings, secrets and identity. The right to privacy gives us the ability to choose which parts in this domain can be accessed by others, and to control the extent, manner and timing of the use of those parts we choose to disclose."

Alan Westin believes that new technologies alter the balance between privacy and disclosure, and that privacy rights may limit government surveillance to protect democratic processes. Westin defines privacy as "the claim of individuals, groups, or institutions to determine for themselves when, how, and to what extent information about them is communicated to others". Westin describes four states of privacy: solitude, intimacy, anonymity, and reserve. These states must balance participation against norms:

Each individual is continually engaged in a personal adjustment process in which he balances the desire for privacy with the desire for disclosure and communication of himself to others, in light of the environmental conditions and social norms set by the society in which he lives.
— Alan Westin, Privacy and Freedom, 1968
Under liberal democratic systems, privacy creates a space separate from political life, and allows personal autonomy, while ensuring democratic freedoms of association and expression.

David Flaherty believes networked computer databases pose threats to privacy. He develops 'data protection' as an aspect of privacy, which involves "the collection, use, and dissemination of personal information". This concept forms the foundation for fair information practices used by governments globally. Flaherty forwards an idea of privacy as information control, "[i]ndividuals want to be left alone and to exercise some control over how information about them is used".

Richard Posner and Lawrence Lessig focus on the economic aspects of personal information control. Posner criticizes privacy for concealing information, which reduces market efficiency. For Posner, employment is selling oneself in the labour market, which he believes is like selling a product. Any 'defect' in the 'product' that is not reported is fraud. For Lessig, privacy breaches online can be regulated through code and law. Lessig claims "the protection of privacy would be stronger if people conceived of the right as a property right", and that "individuals should be able to control information about themselves". Economic approaches to privacy make communal conceptions of privacy difficult to maintain.

There have been attempts to reframe privacy as a fundamental human right, whose social value is an essential component in the functioning of democratic societies. Amitai Etzioni suggests a communitarian approach to privacy. This requires a shared moral culture for establishing social order. Etzioni believes that "[p]rivacy is merely one good among many others", and that technological effects depend on community accountability and oversight (ibid). He claims that privacy laws only increase government surveillance by weakening informal social controls. Furthermore, the government is no longer the only or even principle threat to people's privacy. Etzioni notes that corporate data miners, or "Privacy Merchants," stand to profit by selling massive dossiers personal information, including purchasing decisions and Internet traffic, to the highest bidder. And while some might not find collection of private information objectionable when it is only used commercially by the private sector, the information these corporations amass and process is also available to the government, so that it is no longer possible to protect privacy by only curbing the State.

Priscilla Regan believes that individual concepts of privacy have failed philosophically and in policy. She supports a social value of privacy with three dimensions: shared perceptions, public values, and collective components. Shared ideas about privacy allows freedom of conscience and diversity in thought. Public values guarantee democratic participation, including freedoms of speech and association, and limits government power. Collective elements describe privacy as collective good that cannot be divided. Regan's goal is to strengthen privacy claims in policy making: "if we did recognize the collective or public-good value of privacy, as well as the common and public value of privacy, those advocating privacy protections would have a stronger basis upon which to argue for its protection".

Leslie Regan Shade argues that the human right to privacy is necessary for meaningful democratic participation, and ensures human dignity and autonomy. Privacy depends on norms for how information is distributed, and if this is appropriate. Violations of privacy depend on context. The human right to privacy has precedent in the United Nations Declaration of Human Rights: "Everyone has the right to freedom of opinion and expression; this right includes freedom to hold opinions without interference and to seek, receive and impart information and ideas through any media and regardless of frontiers." Shade believes that privacy must be approached from a people-centered perspective, and not through the marketplace.

Most countries give citizen rights to privacy in their constitutions. Representative examples of this include the "Constitution of Brazil", which says "the privacy, private life, honor and image of people are inviolable"; the "Constitution of South Africa" says that "everyone has a right to privacy"; and the "Constitution of the Republic of Korea" says "the privacy of no citizen shall be infringed." Among most countries whose constitutions do not explicitly describe privacy rights, court decisions have interpreted their constitutions to intend to give privacy rights.

Many countries have broad privacy laws outside their constitutions, including Australia’s Privacy Act 1988, Argentina’s Law for the Protection of Personal Data of 2000, Canada’s 2000 Personal Information Protection and Electronic Documents Act, and Japan’s 2003 Personal Information Protection Law.

Beyond national privacy laws, there are international privacy agreements. The United Nations Universal Declaration of Human Rights says "No one shall be subjected to arbitrary interference with his privacy, family, home or correspondence, nor to attacks upon his honor and reputation." The Organisation for Economic Co-operation and Development published its Privacy Guidelines in 1980. The European Union's 1995 Data Protection Directive guides privacy protection in Europe. The 2004 Privacy Framework by the Asia-Pacific Economic Cooperation is a privacy protection agreement for the members of that organization.

In the 1960s people began to consider how changes in technology were bringing changes in the concept of privacy. Vance Packard’s "The Naked Society" was a popular book on privacy from that era and led discourse on privacy at that time.

Approaches to privacy can, broadly, be divided into two categories: free market, and consumer protection. In a free market approach, commercial entities are largely allowed to do what they wish, with the expectation that consumers will choose to do business with corporations that respect their privacy to a desired degree. If some companies are not sufficiently respectful of privacy, they will lose market share. Such an approach may be limited by lack of competition in a market, by enterprises not offering privacy options favorable to the user, or by lack of information about actual privacy practices. Claims of privacy protection made by companies may be difficult for consumers to verify, except when they have already been violated.

In a consumer protection approach, in contrast, it is claimed that individuals may not have the time or knowledge to make informed choices, or may not have reasonable alternatives available. In support of this view, Jensen and Potts showed that most privacy policies are above the reading level of the average person. Therefore, this approach advocates greater government definition and enforcement of privacy standards.

Privacy law is the area of law concerning the protecting and preserving of privacy rights of individuals. While there is no universally accepted privacy law among all countries, some organizations promote certain concepts be enforced by individual countries. For example, the Universal Declaration of Human Rights, article 12, states:

The "Privacy Act 1988" is administered by the Office of the Australian Information Commissioner.

Privacy law has been evolving in Australia for a number of years. The initial introduction of privacy law in 1998 extended to the public sector, specifically to Federal government departments, under the Information Privacy Principles. State government agencies can also be subject to state based privacy legislation. This built upon the already existing privacy requirements that applied to telecommunications providers (under Part 13 of the "Telecommunications Act 1997"), and confidentiality requirements that already applied to banking, legal and patient / doctor relationships.

The "Privacy Act 1988" was then extended to include the private sector in 2000 with the introduction of the National Privacy Principles. These took effect in 2001. Small businesses with an annual turnover of $3m were excluded from meeting the obligations specified in the National Privacy Principles with some exceptions such as those whose primary business was dealing in personal information.

In 2008 the Australian Law Reform Commission (ALRC) conducted a review of Australian Privacy Law. The resulting report For Your Information was one of the largest reports ever released by the ALRC. Amongst its many recommendations were the consolidation of both the Information Privacy Principles and the National Privacy Principles to form what is now known as the Australian Privacy Principles.

This recommendation, and many others, were taken up and implemented by the Australian Government via the Privacy Amendment (Enhancing Privacy Protection) Bill 2012.

The Australian Privacy Principles, along with other key changes to the overall Act, took effect on 12 March 2014. The new structure of the privacy principles follow the information cycle and incorporate key emerging privacy concepts including privacy by design.

There are currently 14 Australian Privacy Principles:


As of 22 February 2018, the Privacy Amendment (Notifiable Data Breaches) Act 2017 will introduce a mandatory data breach notification obligations for all organisations that are subject to Australia’s Privacy Act 1988 (Cth). This includes all Australian-registered companies and foreign-registered companies that carry on business in Australia or that interact with Australian data subjects.

There are a range of other laws that provide privacy protection in Australia. These include, but are not limited to, the "Telecommunications Act 1997", "Spam Act 2006", the "Do Not Call Register Act 2009", general confidentiality obligations arising from certain professional relationships including with doctors, lawyers and other health providers, state based legislation including NSW workplace surveillance laws, state based laws that apply in NSW, Queensland and other states for the handling of health information and the handling of information by state government agencies.

The Constitution of Brazil sets privacy as a major fundamental right. Even the State is not allowed to violate personal data, intimacy, private life, honor and image (article 5, incise X). In extreme situations, a judicial order can authorize some level of disclosure. But some data, such as correspondence, are absolutely inviolable, and not even judicial order can authorize the disclosure.

Criminal Law of the People's Republic of China

Article 245 Whoever unlawfully subjects another person to a body search or a search of his residence or unlawfully intrudes into another person's residence shall be sentenced to fixed-term imprisonment of not more than three years or criminal detention. Any judicial officer who abuses his power and commits the crime mentioned in the preceding paragraph shall be given a heavier punishment.

Article 246 Whoever, by violence or other methods, publicly humiliates another person or invent stories to defame him, if the circumstances are serious, shall be sentenced to fixed-term imprisonment of not more than three years, criminal detention, public surveillance or deprivation of political rights. The crime mentioned in the preceding paragraph shall be handled only upon complaint, except where serious harm is done to public order or to the interests of the State.

Article 252 Whoever conceals, destroys or unlawfully opens another person's letter, thereby infringing upon the citizen's right to freedom of correspondence, if the circumstances are serious, shall be sentenced to fixed-term imprisonment of not more than one year or criminal detention.

Article 253 Any postal worker who opens without authorization or conceals or destroys mail or telegrams shall be sentenced to fixed-term imprisonment of not more than two years or criminal detention. Whoever steals money or property by committing the crime mentioned in the preceding paragraph shall be convicted and given a heavier punishment in accordance with the provisions of Article 264 of this Law.

Canadian privacy law is governed federally by multiple acts, including the Canadian Charter of Rights and Freedoms, and the Privacy Act (Canada). Mostly this legislation concerns privacy infringement by government organizations. Data privacy was first addressed with the Personal Information Protection and Electronic Documents Act, and provincial-level legislation also exists to account for more specific cases personal privacy protection against commercial organizations.

For Europe, Article 8 of the European Convention on Human Rights guarantees the right to respect for private and family life, one's home and correspondence. The European Court of Human Rights in Strasbourg has developed a large body of jurisprudence defining this fundamental right to privacy. The European Union requires all member states to legislate to ensure that citizens have a right to privacy, through directives such as the 1995 Directive 95/46/EC on the protection of personal data. It is regulated in the United Kingdom by the Data Protection Act 1998 and in France data protection is also monitored by the CNIL, a governmental body which must authorize legislation concerning privacy before it can be enacted. In civil law jurisdictions, the right to privacy fell within the ambit of the right to a private life (droit a la vie privee) from which the tort could be claimed. Personality rights and the broader tort based
interpretation of the right to privacy protected correspondence, personal information and dignity. These rights gave rise to causes for damages in most civil law jurisdictions and common law jurisdictions prior to the sui generis development of Data Protection.

Although there are comprehensive regulations for data protection, some studies show that despite the laws, there is a lack of enforcement in that no institution feels responsible to control the parties involved and enforce their laws. The European Union is also championing for the 'Right to be Forgotten' concept (which allows individuals to ask that links leading to information about themselves be removed from internet search engine results) to be adopted by other countries.

In Italy the right to privacy is enshrined in Article 15 of the Constitution, which states:

"Freedom and confidentiality of correspondence and of every other form of communication is inviolable. Limitations may only be imposed by judicial decision stating the reasons and in accordance with the guarantees provided by the law."

In the United Kingdom, it is not possible to bring an action for invasion of privacy. An action may be brought under another tort (usually breach of confidence) and privacy must then be considered under EC law. In the UK, it is sometimes a defence that disclosure of private information was in the public interest.
There is, however, the Information Commissioner's Office (ICO), an independent public body set up to promote access to official information and protect personal information. They do this by promoting good practice, ruling on eligible complaints, giving information to individuals and organisations, and taking action when the law is broken. The relevant UK laws include: Data Protection Act 1998; Freedom of Information Act 2000; Environmental Information Regulations 2004; Privacy and Electronic Communications Regulations 2003. The ICO has also provided a "Personal Information Toolkit" online which explains in more detail the various ways of protecting privacy online.

Although the US Constitution does not explicitly include the right to privacy, individual as well as locational privacy are implicitly granted by the Constitution under the 4th Amendment. The Supreme Court of the United States has found that other guarantees have "penumbras" that implicitly grant a right to privacy against government intrusion, for example in "Griswold v. Connecticut" (1965). In the United States, the right of freedom of speech granted in the First Amendment has limited the effects of lawsuits for breach of privacy. Privacy is regulated in the US by the Privacy Act of 1974, and various state laws. The Privacy Act of 1974 only applies to Federal agencies in the executive branch of the Federal government. Certain privacy rights have been established in the United States via legislation such as the Children's Online Privacy Protection Act (COPPA), the Gramm–Leach–Bliley Act (GLB), and the Health Insurance Portability and Accountability Act (HIPAA).
The Electronic Privacy Information Center's Privacy Index puts Brazil, Australia, Japan and South Africa in the higher level of privacy (around 2.2). On the bottom of the list are the United States and United Kingdom (around 1.4).

There are many means to protect one's privacy on the internet. For example, e-mails can be encrypted (via S/MIME or PGP) and anonymizing proxies or anonymizing networks like I2P and Tor can be used to prevent the internet service providers from knowing which sites one visits and with whom one communicates. Covert collection of personally identifiable information has been identified as a primary concern by the U.S. Federal Trade Commission. Although some privacy advocates recommend the deletion of original and third-party HTTP cookies, Anthony Miyazaki, marketing professor at Florida International University and privacy scholar, warns that the "elimination of third-party cookie use by Web sites can be circumvented by cooperative strategies with third parties in which information is transferred after the Web site's use of original domain cookies." As of December 2010, the Federal Trade Commission is reviewing policy regarding this issue as it relates to behavioral advertising.
Another aspect of privacy on the Internet relates to online social networking. Several online social network sites (OSNs) are among the top 10 most visited websites globally. A review and evaluation of scholarly work regarding the current state of the value of individuals' privacy of online social networking show the following results: "first, adults seem to be more concerned about potential privacy threats than younger users; second, policy makers should be alarmed by a large part of users who underestimate risks of their information privacy on OSNs; third, in the case of using OSNs and its services, traditional one-dimensional privacy approaches fall short". This is exacerbated by the research indicating that personal traits such as sexual orientation, race, religious and political views, personality, or intelligence can be inferred based on the wide variety of digital footprint, such as samples of text, browsing logs, or Facebook Likes.

Increasingly, mobile devices facilitate location tracking. This creates user privacy problems. A user's location and preferences constitute personal information. Their improper use violates that user's privacy. A recent MIT study by de Montjoye et al. showed that 4 spatio-temporal points, approximate places and times, are enough to uniquely identify 95% of 1.5M people in a mobility database. The study
further shows that these constraints hold even when the resolution of the dataset is low. Therefore, even coarse or blurred datasets provide little anonymity.

Several methods to protect user privacy in location-based services have been proposed, including the use of anonymizing servers, blurring of information e.a. Methods to quantify privacy have also been proposed, to calculate the equilibrium between the benefit of providing accurate location information and the drawbacks of risking personal privacy. Users of such services may also choose to display more generic location information (i.e. "In the City" or "Philadelphia" or "Work") to some of their more casual acquaintances while only displaying specific location information, such as their exact address, to closer contacts like spouse, relatives, and good friends.

In recent years, seen with the increasing importance of mobile devices and paired with the "National Do Not Call Registry", telemarketers have turned attention to mobiles. The efforts of telemarketers to use mobile devices have been met with both "Federal Trade Commission" and companies like PrivacyStar. Each year, thousands of complaints are filed to the FTC database with the help of companies and consumers.

The principle of privacy by design states that privacy and data protection are embedded throughout the entire life cycle of technologies, from the early design stage to their deployment, use and ultimate disposal.

The practice of constructing, ostensibly, software or information systems that adhere to given privacy policies and relevant compliances is a developing area and is known as Privacy engineering

Privacy self-synchronization is the mode by which the stakeholders of an enterprise privacy program spontaneously contribute collaboratively to the program's maximum success. The stakeholders may be customers, employees, managers, executives, suppliers, partners or investors. When self-synchronization is reached, the model states that the personal interests of individuals toward their privacy is in balance with the business interests of enterprises who collect and use the personal information of those individuals.

The privacy paradox is a phenomenon in which online users state that they are concerned about their privacy but behave as if they were not. While this term was coined as early as 1998, it wasn't used in its current popular sense until the year 2000. In his article titled "'Opting In': A Privacy Paradox," John Schwartz wrote that "It's one of the more puzzling conundrums of online life. While companies that capitalize on the Internet's powerful potential to invade privacy are denounced as villains of the information age, millions of people type out highly personal data and send it off to Web sites they've barely heard of, with no strong legal protection against misuse of the information. …The paradox helps illustrate the complexity of the debate over privacy."

Susan B. Barnes similarly used the term “privacy paradox” to refer to the ambiguous boundary between private and public space on social media. When compared to adults, young people tend to disclose more information on social media. However, this does not mean that they are not concerned about their privacy. Susan B. Barnes gave a case in her article: in a television interview about Facebook, a student addressed her concerns about disclosing personal information online. However, when the reporter asked to see her Facebook page, she put her home address, phone numbers, and pictures of her young son on the page.

Privacy paradox has been studied and scripted in different research settings. Although several studies have shown this inconsistency between privacy attitudes and behavior among online users, the reason for the paradox still remains unclear. A main explanation for the privacy paradox is that users lack awareness of the risks and the degree of protection. Users may underestimate the harm of disclosing information online. On the other hand, some researchers argue the privacy paradox comes from lack of technology literacy and form the design of sites. For example, users may not know how to change their default settings even though they care about their privacy. Psychologists particularly pointed out that the privacy paradox occurs because users must trade-off between their privacy concerns and impression management. Other individual factors such as gender, age, trust and personality, may also account for the paradox.

The 1993 film "The Pelican Brief", based on the novel of the same name, touches on privacy. In one scene, a law professor discusses the Constitutional right to privacy. One of his students, played by Julia Roberts, argues that the majority opinion in Bowers v Hardwick was wrongly decided.

In the TV series West Wing, in the 1999 episode "Short List", the right to privacy arises during the appointment of a Supreme Court judge. Sam Seabourne ventures the opinion that Internet privacy will be a major social issue in the next two decades.

Selfies are popular today; a search for photos with the hashtag #selfie retrieves over 23 million results on Instagram and "a whopping 51 million with the hashtag #me" However, due to modern corporate and governmental surveillance, this may pose a risk to privacy. In a research which takes a sample size of 3763, researchers found that for selfies, female generally have greater concerns than male social media users. Users who have greater concerns inversely predict their selfie behavior and activity.







</doc>
<doc id="25010" url="https://en.wikipedia.org/wiki?curid=25010" title="Proton–proton chain reaction">
Proton–proton chain reaction

The proton–proton chain reaction is one of two known sets of nuclear fusion reactions by which stars convert hydrogen to helium. It dominates in stars with masses less than or equal to that of the Sun's, whereas the CNO cycle, the other known reaction, is suggested by theoretical models to dominate in stars with masses greater than about 1.3 times that of the Sun's.

In general, proton–proton fusion can occur only if the kinetic energy (i.e. temperature) of the protons is high enough to overcome their mutual electrostatic or Coulomb repulsion.

In the Sun, deuterium-producing events are rare. Diprotons are the much more common result of proton–proton reactions within the star, and diprotons almost immediately decay back into two protons. Since the conversion of hydrogen to helium is slow, the complete conversion of the hydrogen in the core of the Sun is calculated to take more than ten billion years.

Although often called the "proton-proton chain reaction", it is not a chain reaction in the normal sense of the word (at least not Branch I — in Branches II and III helium, which is the product, also serves as a catalyst). It does not produce particles that go on to induce the reaction to continue (such as neutrons given off during fission). In fact, the rate is self-limiting because the heat produced tends toward reducing the density. It is however a chain (like a decay chain) and a reaction, or more accurately a branched chain of reactions starting with two protons coming together and yielding deuterium.

The theory that proton–proton reactions are the basic principle by which the Sun and other stars burn was advocated by Arthur Eddington in the 1920s. At the time, the temperature of the Sun was considered to be too low to overcome the Coulomb barrier. After the development of quantum mechanics, it was discovered that tunneling of the wavefunctions of the protons through the repulsive barrier allows for fusion at a lower temperature than the classical prediction.

Even so, it was unclear how proton–proton fusion might proceed, because the most obvious product, helium-2 (diproton), is unstable and almost instantly dissociates back into two protons. In 1939, Hans Bethe proposed that one of the protons could decay by beta emission into a neutron via the weak interaction during the brief moment of fusion, making deuterium a vital product in the chain. This idea was part of the body of work in stellar nucleosynthesis for which Bethe won the Nobel Prize in Physics in 1967.

The first step involves the fusion of two nuclei (protons) into deuterium, releasing a positron and a neutrino as one proton changes into a neutron. It is a two-stage process; first, two protons fuse to form a diproton:
followed by the beta-plus decay of the diproton to deuterium:
with the overall formula:

This second step is extremely slow because the positron emission of the diproton to deuterium is extremely rare (the vast majority of the time, the diproton decays back into two hydrogen-1 unbound protons through proton emission). This is because the emission of the positron is brought about by the weak nuclear force, which is immensely weaker than the strong nuclear force and the electromagnetic force.

The half-life of a proton in the core of the Sun before it is involved in a successful proton–proton fusion is estimated to be about one billion years, even at the extreme pressures and temperatures found there.

The positron emitted by the decay by beta emission usually annihilates immediately with an electron. Their mass-energies plus their kinetic energy is carried off by two gamma rays (photons) with the mass-energy of 511 keV (thousand electron-volts) apiece.

After it is formed, the deuterium produced in the first stage can fuse with another proton to produce the light isotope of helium, :

This process, mediated by the strong nuclear force rather than the weak force, is extremely fast by comparison to the first step. It is estimated that, under the conditions in the Sun's core, each newly created deuterium nucleus exists for only about four seconds before it is converted to He-3.

In the Sun, each helium-3 nucleus produced in these reactions exists for only about 400 years before it is converted into helium-4. Once the helium-3 has been produced, there are four possible paths to generate . In p-p I, helium-4 is produced by fusing two helium-3 nuclei; the p-p II and p-p III branches fuse with pre-existing to form beryllium-7, which undergoes further reactions to produce two helium-4 nuclei. 

In the Sun, synthesis via branch p-p I occurs with a frequency of 83.30 percent, p-p II with 16.68 percent, and p-p III with 0.02 percent.

There is also the extremely rare p-p IV branch. Other even-rarer reactions may occur. The rate of these reactions is very low due to very small cross-sections, or because the number of reacting particles is so low that any reactions that might happen are statistically insignificant. This is partly why no mass-5 or mass-8 elements are seen. While the reactions that would produce them, such as a proton + helium-4 producing lithium-5, or two helium-4 nuclei coming together to form beryllium-8, may "actually" happen, these elements are not detected because there are no stable isotopes of atomic masses 5 or 8; the resulting products immediately decay into their initial reactants.

The overall reaction is:

4p → + 2e + 2ν

The complete p-p I chain reaction releases a net energy of . Two percent of this energy is lost to the neutrinos that are produced.
The p-p I branch is dominant at temperatures of 10 to .
Below , the P-P chain does not produce much .

The P-P II branch is dominant at temperatures of 14 to .

Note that the energies in the equation above are not the energy released by the reaction. Rather, they are the energies of the neutrinos that are produced by the reaction. 90 percent of the neutrinos produced in the reaction of to carry an energy of , while the remaining 10 percent carry . The difference is whether the lithium-7 produced is in the ground state or an excited (metastable) state, respectively.

The P-P III chain is dominant if the temperature exceeds .

The p-p III chain is not a major source of energy in the Sun (only 0.11 percent), but it was very important in the solar neutrino problem because it generates very high energy neutrinos (up to ).

This reaction is predicted theoretically, but it has never been observed due to its rarity (about in the Sun). In this reaction, helium-3 captures a proton directly to give helium-4, with an even higher possible neutrino energy (up to 18.8 MeV).

Comparing the mass of the final helium-4 atom with the masses of the four protons reveals that 0.7 percent of the mass of the original protons has been lost. This mass has been converted into energy, in the form of gamma rays and neutrinos released during each of the individual reactions. The total energy yield of one whole chain is .

Energy released as gamma rays will interact with electrons and protons and heat the interior of the Sun. Also kinetic energy of fusion products (e.g. of the two protons and the from the p-p I reaction) increases the temperature of plasma in the Sun. This heating supports the Sun and prevents it from collapsing under its own weight.

Neutrinos do not interact significantly with matter and therefore do not help support the Sun against gravitational collapse. Their energy is lost: the neutrinos in the p-p I, p-p II, and p-p III chains carry away 2.0%, 4.0%, and 28.3% of the energy in those reactions, respectively.

Deuterium can also be produced by the rare pep (proton–electron–proton) reaction (electron capture):

In the Sun, the frequency ratio of the pep reaction versus the p-p reaction is 1:400. However, the neutrinos released by the pep reaction are far more energetic: while neutrinos produced in the first step of the p-p reaction range in energy up to , the pep reaction produces sharp-energy-line neutrinos of . Detection of solar neutrinos from this reaction were reported by the Borexino collaboration in 2012.

Both the pep and p-p reactions can be seen as two different Feynman representations of the same basic interaction, where the electron passes to the right side of the reaction as a positron. This is represented in the figure of proton–proton and electron-capture chain reactions in a star, available at the NDM'06 web site.



</doc>
<doc id="25011" url="https://en.wikipedia.org/wiki?curid=25011" title="Plankton">
Plankton

Plankton (singular plankter) are the diverse collection of organisms that live in large bodies of water and are unable to swim against a current. They provide a crucial source of food to many large aquatic organisms, such as fish and whales.

These organisms include bacteria, archaea, algae, protozoa and drifting or floating animals that inhabit—for example—the pelagic zone of oceans, seas, or bodies of fresh water. Essentially, plankton are defined by their ecological niche rather than any phylogenetic or taxonomic classification.

Though many planktonic species are microscopic in size, "plankton" includes organisms over a wide range of sizes, including large organisms such as jellyfish.
Technically the term does not include organisms on the surface of the water, which are called "pleuston"—or those that swim actively in the water, which are called "nekton".

The name "plankton" is derived from the Greek adjective πλαγκτός ("planktos"), meaning "errant", and by extension, "wanderer" or "drifter", and was coined by Victor Hensen in 1887. While some forms are capable of independent movement and can swim hundreds of meters vertically in a single day (a behavior called diel vertical migration), their horizontal position is primarily determined by the surrounding water movement, and plankton typically flow with ocean currents. This is in contrast to nekton organisms, such as fish, squid and marine mammals, which can swim against the ambient flow and control their position in the environment.

Within the plankton, holoplankton spend their entire life cycle as plankton (e.g. most algae, copepods, salps, and some jellyfish). By contrast, meroplankton are only planktic for part of their lives (usually the larval stage), and then graduate to either a nektic (swimming) or benthic (sea floor) existence. Examples of meroplankton include the larvae of sea urchins, starfish, crustaceans, marine worms, and most fish.

The amount and distribution of plankton depends on available nutrients, the state of water and a large amount of other plankton.

The study of plankton is termed planktology and a planktonic individual is referred to as a plankter. The adjective "planktonic" is widely used in both the scientific and popular literature, and is a generally accepted term. However, from the standpoint of prescriptive grammar, the less commonly used "planktic" is more strictly the correct adjective. When deriving English words from their Greek or Latin roots, the gender-specific ending (in this case "-on," which indicates the word is neuter) is normally dropped, using only the root of the word in the derivation.

Plankton are primarily divided into broad functional (or trophic level) groups: 
This scheme divides the plankton community into broad producer, consumer and recycler groups. However, determining the trophic level of many plankton is not always straightforward. For example, although most dinoflagellates are either photosynthetic producers or heterotrophic consumers, many species perform both roles. In this mixed trophic strategy — known as mixotrophy — organisms act as both producers and consumers, either at the same time or switching between modes of nutrition in response to ambient conditions. For instance, relying on photosynthesis for growth when nutrients and light are abundant, but switching to predation when growing conditions are poor. Recognition of the importance of mixotrophy as an ecological strategy is increasing, as well as the wider role this may play in marine biogeochemistry.

Plankton are also often described in terms of size. Usually the following divisions are used:
However, some of these terms may be used with very different boundaries, especially on the larger end. The existence and importance of nano- and even smaller plankton was only discovered during the 1980s, but they are thought to make up the largest proportion of all plankton in number and diversity.

The microplankton and smaller groups are microorganisms and operate at low Reynolds numbers, where the viscosity of water is much more important than its mass or inertia.

Plankton inhabit oceans, seas, lakes, ponds. Local abundance varies horizontally, vertically and seasonally. The primary cause of this variability is the availability of light. All plankton ecosystems are driven by the input of solar energy (but see chemosynthesis), confining primary production to surface waters, and to geographical regions and seasons having abundant light.

A secondary variable is nutrient availability. Although large areas of the tropical and sub-tropical oceans have abundant light, they experience relatively low primary production because they offer limited nutrients such as nitrate, phosphate and silicate. This results from large-scale ocean circulation and water column stratification. In such regions, primary production usually occurs at greater depth, although at a reduced level (because of reduced light).

Despite significant macronutrient concentrations, some ocean regions are unproductive (so-called HNLC regions). The micronutrient iron is deficient in these regions, and adding it can lead to the formation of phytoplankton blooms. Iron primarily reaches the ocean through the deposition of dust on the sea surface. Paradoxically, oceanic areas adjacent to unproductive, arid land thus typically have abundant phytoplankton (e.g., the eastern Atlantic Ocean, where trade winds bring dust from the Sahara Desert in north Africa).

While plankton are most abundant in surface waters, they live throughout the water column. At depths where no primary production occurs, zooplankton and bacterioplankton instead consume organic material sinking from more productive surface waters above. This flux of sinking material, so-called marine snow, can be especially high following the termination of spring blooms.

Aside from representing the bottom few levels of a food chain that supports commercially important fisheries, plankton ecosystems play a role in the biogeochemical cycles of many important chemical elements, including the ocean's carbon cycle.

Primarily by grazing on phytoplankton, zooplankton provide carbon to the planktic foodweb, either respiring it to provide metabolic energy, or upon death as biomass or detritus. Organic material tends to be denser than seawater, so it sinks into open ocean ecosystems away from the coastlines, transporting carbon along with it. This process, called the "biological pump", is one reason that oceans constitute the largest carbon sink on Earth. However, it has been shown to be influenced by increments of temperature.

It might be possible to increase the ocean's uptake of carbon dioxide () generated through human activities by increasing plankton production through "seeding", primarily with the micronutrient iron. However, this technique may not be practical at a large scale. Ocean oxygen depletion and resultant methane production (caused by the excess production remineralising at depth) is one potential drawback.

Phytoplankton absorb energy from the Sun and nutrients from the water to produce their own nourishment or energy. In the process of photosynthesis, phytoplankton release molecular oxygen () into the water as a waste biproduct. It is estimated that about 50% of the world's oxygen is produced via phytoplankton photosynthesis. The rest is produced via photosynthesis on land by plants. Furthermore, phytoplankton photosynthesis has controlled the atmospheric / balance since the early Precambrian Eon.

The growth of phytoplankton populations is dependent on light levels and nutrient availability. The chief factor limiting growth varies from region to region in the world's oceans. On a broad scale, growth of phytoplankton in the oligotrophic tropical and subtropical gyres is generally limited by nutrient supply, while light often limits phytoplankton growth in subarctic gyres. Environmental variability at multiple scales influences the nutrient and light available for phytoplankton, and as these organisms form the base of the marine food web, this variability in phytoplankton growth influences higher trophic levels. For example, at interannual scales phytoplankton levels temporarily plummet during El Niño periods, influencing populations of zooplankton, fishes, sea birds, and marine mammals.

The effects of anthropogenic warming on the global population of phytoplankton is an area of active research. Changes in the vertical stratification of the water column, the rate of temperature-dependent biological reactions, and the atmospheric supply of nutrients are expected to have important impacts on future phytoplankton productivity. Additionally, changes in the mortality of phytoplankton due to rates of zooplankton grazing may be significant.

Freshly hatched fish larvae are also plankton for a few days, as long as it takes before they can swim against currents.

Zooplankton are the initial prey item for almost all fish larvae as they switch from their yolk sacs to external feeding. Fish rely on the density and distribution of zooplankton to match that of new larvae, which can otherwise starve. Natural factors (e.g., current variations) and man-made factors (e.g. river dams) can strongly affect zooplankton, which can in turn strongly affect larval survival, and therefore breeding success.

The importance of both phytoplankton and zooplankton is also well-recognized in extensive and semi-intensive pond fish farming. Plankton population based pond management strategies for fish rearing have been practised by traditional fish farmers for decades, illustrating the importance of plankton even in man-made environments.




</doc>
<doc id="25013" url="https://en.wikipedia.org/wiki?curid=25013" title="Pi Day">
Pi Day

Pi Day is an annual celebration of the mathematical constant (pi). Pi Day is observed on March 14 (3/14 in the "month/day" format) since 3, 1, and 4 are the first three significant digits of . In 2009, the United States House of Representatives supported the designation of Pi Day.

Pi Approximation Day is observed on July 22 (22/7 in the "day/month" format), since the fraction is a common approximation of, which is accurate to two decimal places and dates from Archimedes.

Two Pi Day, also known as Tau Day, is lightly observed on June 28 (6/28 in the "month/day" format).

In 1988, the earliest known official or large-scale celebration of Pi Day was organized by Larry Shaw at the San Francisco Exploratorium, where Shaw worked as a physicist, with staff and public marching around one of its circular spaces, then consuming fruit pies. The Exploratorium continues to hold Pi Day celebrations.

On March 12, 2009, the U.S. House of Representatives passed a non-binding resolution (), recognizing March 14, 2009 as National Pi Day. For Pi Day 2010, Google presented a Google Doodle celebrating the holiday, with the word Google laid over images of circles and pi symbols; and for the 30th anniversary in 2018, it was a Dominique Ansel pie with the circumference divided by its diameter.

The entire month of March 2014 (3/14) was observed by some as "Pi Month". In the year 2015, March 14 was celebrated as "Super Pi Day". It had special significance, as the date is written as 3/14/15 in month/day/year format. At 9:26:53, the date and time together represented the first 10 digits of .

Pi Day has been observed in many ways, including eating pie, throwing pies and discussing the significance of the number , due to a pun based on the words "pi" and "pie" being homophones in English (), and the coincidental circular nature of a pie.

Massachusetts Institute of Technology has often mailed its application decision letters to prospective students for delivery on Pi Day. Starting in 2012, MIT has announced it will post those decisions (privately) online on Pi Day at exactly 6:28 pm, which they have called "Tau Time", to honor the rival numbers pi and tau equally. In 2015, the regular decisions were put online at 9:26 AM, following that year's "pi minute". June 28 is "Two Pi Day", also known as "Tau Day". 2, also known by the Greek letter tau (τ) is a common multiple in mathematical formulae. Some have argued that τ is the more fundamental constant, and that Tau Day should be celebrated instead. Celebrations of this date jokingly suggest eating "twice the pie".

Princeton, New Jersey, hosts numerous events in a combined celebration of Pi Day and Albert Einstein's birthday, which is also March 14. Einstein lived in Princeton for more than twenty years while working at the Institute for Advanced Study. In addition to pie eating and recitation contests, there is an annual Einstein look-alike contest.




</doc>
<doc id="25017" url="https://en.wikipedia.org/wiki?curid=25017" title="Positivism (disambiguation)">
Positivism (disambiguation)

Positivism is a philosophy which states that the only authentic knowledge is scientific knowledge. Positivism was central to the foundation of academic sociology.

Positivism may also refer to:



</doc>
<doc id="25018" url="https://en.wikipedia.org/wiki?curid=25018" title="Pauli effect">
Pauli effect

The Pauli effect is a term referring to the supposed tendency of technical equipment to encounter critical failure in the presence of certain people. The term was coined after mysterious anecdotal stories involving Austrian theoretical physicist Wolfgang Pauli, describing numerous instances in which demonstrations involving equipment suffered technical problems only when he was present.

The Pauli effect is not related with the Pauli exclusion principle, which is a bona fide physical phenomenon named after Pauli. However the Pauli effect was humorously tagged as a second Pauli exclusion principle, according to which "a functioning device and Wolfgang Pauli may not occupy the same room". Pauli himself was convinced that the effect named after him was real. Pauli corresponded with Hans Bender and Carl Jung and saw the effect as an example of the concept of synchronicity.

Since the 20th century, the work of physics research has been divided between theorists and experimentalists (see scientific method). Only a few physicists, such as Enrico Fermi, have been successful in both roles. Lacking an aptitude or interest in experimental work, many theorists have earned a reputation for accidentally breaking experimental equipment. Pauli was exceptional in this regard: it was postulated that he was such a good theorist that any experiments would be compromised by virtue of his presence in the vicinity. For fear of the Pauli effect, the experimental physicist Otto Stern banned Pauli from his laboratory located in Hamburg despite their friendship. Pauli was convinced that the effect named after him was real. He corresponded with Carl Jung and Marie-Louise von Franz about the concept of synchronicity and did so as well with Hans Bender, lecturer at Freiburg university Institut für Grenzgebiete der Psychologie und Psychohygiene, the only parapsychology chair in Germany.

Jung and Pauli saw some parallels between physics and depth psychology. Pauli was among the honored guests at the foundation festivities of the C.G. Jung Institute in Zürich 1948. A famous "Pauli effect" at the ceremony, as he entered, a china flower vase fell on the floor without any obvious reason, caused Pauli to write his article "Background-Physics", in which he tries to find complementary relationships between physics and depth psychology.

An incident occurred in the physics laboratory at the University of Göttingen. An expensive measuring device, for no apparent reason, suddenly stopped working, although Pauli was in fact "absent". James Franck, the director of the institute, reported the incident to his colleague Pauli in Zürich with the humorous remark that at least this time Pauli was innocent. However, it turned out that Pauli on a railway journey to Copenhagen switched trains in Göttingen rail station about the time of failure. The incident is reported in George Gamow's book "Thirty Years That Shook Physics", where it is also claimed the more talented the theoretical physicist, the stronger the effect.

R. Peierls describes a case when at one reception this effect was to be parodied by deliberately crashing a chandelier upon Pauli's entrance. The chandelier was suspended on a rope to be released, but it stuck instead, thus becoming a real example of the Pauli effect.

In 1934, Pauli saw a failure of his car during a honeymoon tour with his second wife as proof of a "real Pauli effect" since it occurred without an obvious external cause.

In February 1950, when he was at Princeton University, the cyclotron burnt, and he asked himself if this mischief belonged to such a Pauli effect, named after him.





</doc>
<doc id="25020" url="https://en.wikipedia.org/wiki?curid=25020" title="Pat Mills">
Pat Mills

Pat Eamon Mills (born 1949) is a British comics writer and editor who, along with John Wagner, revitalised British boys comics in the 1970s, and has remained a leading light in British comics ever since. He has been called "the godfather of British comics".

His comics are notable for their violence and anti-authoritarianism. He is best known for creating "2000 AD" and playing a major part in the development of "Judge Dredd".

Mills started his career as a sub-editor for D. C. Thomson & Co. Ltd, where he met Wagner. In 1971 both left to go freelance, and were soon writing scripts for IPC's girls' and humour comics. After D.C. Thomson launched "Warlord", a successful war-themed weekly, Mills was asked in 1975 to develop a rival title for IPC. Based in the girls' comics department to avoid the attention of the staff of the boys' department, Mills, along with Wagner and Gerry Finley-Day, worked in secret to create "Battle Picture Weekly". "Battle"'s stories were more violent and its characters more working class than IPC's traditional fare, and it was an immediate hit. Having made the comic ready for launch, Mills resigned as editor. He would later write the celebrated First World War series "Charley's War", drawn by Joe Colquhoun, for the title.

After launching "Battle", Mills began developing a new boys' title, "Action", launched in 1976. "Action"'s mix of violence and anti-authoritarianism proved controversial and the title lasted less than two years before being withdrawn in the face of media protests. It was briefly revived in neutered form before being merged into "Battle".

His next creation was the science fiction-themed weekly "2000 AD", launched in 1977. As with "Battle" and "Action" he developed most of the early series before handing them over to other writers. He took over the development of "Judge Dredd" when creator John Wagner temporarily walked out, and wrote many of the early stories, establishing the character and his world, before Wagner returned.

In 1978 IPC launched "Starlord", a short-lived companion title for "2000 AD". Mills contributed "Ro-Busters", a series about a robot disaster squad, which moved to "2000 AD" when "Starlord" was cancelled. "Ro-Busters" was the beginning of a mini-universe of interrelated stories Mills was to create for "2000 AD", including "ABC Warriors" and "Nemesis the Warlock". Artist Kevin O'Neill was involved in the creation of all three. "Nemesis" in particular, featuring a morally ambiguous alien hero fighting a despotic human empire, allowed Mills to work out his feelings towards religion and imperialism. Another strand of his "2000 AD" work was "Sláine", a barbarian fantasy based on Celtic mythology and neo-paganism, which he co-created with his then wife Angela Kincaid (with whom he also created the children's series of books, "The Butterfly Children").

Mills also had a hand in IPC's line of Horror comics aimed at girls such as "Chiller".

He has had little success in American comics, with the exception of Metalzoic and Marshal Law, published by DC and Epic comics respectively in the late 1980s, both drawn by O'Neill.

In 1986 he edited the short-lived comic "Diceman", which featured characters from "2000 AD". He wrote nearly every story.

In 1988 he was involved in the launch of "Crisis", a politically aware "2000 AD" spin-off aimed at older readers. For it he wrote "Third World War", drawn initially by Carlos Ezquerra, a polemical critique of global capitalism and the ways it exploits the developing world. The title lasted until 1991 and launched the careers of talents such as Garth Ennis, John Smith and Sean Phillips.

In 1991 Mills launched "Toxic!", an independent colour newsstand weekly comic with a violent, anarchic tone, perhaps as a reaction against the politically worthy "Crisis", and a creator-owned ideal. Many of the stories were created by Mills and co-writer Tony Skinner, including "Accident Man", an assassin who makes his hits look like accidents. "Toxic!" lasted less than a year, but gave a start to talents such as Duke Mighten and Martin Emond.

In 1995, he broke in the French market, one of his life's goals, with "Sha", created with French artist Olivier Ledroit.

He continues to write "Sláine", "Bill Savage", "Black Siddha" and "ABC Warriors" for "2000 AD", and also the Franco-Belgian comic "Requiem Vampire Knight", with art by Olivier Ledroit and its spin-off Claudia Chevalier Vampire, with art by Franck Tacito.

Two new series, "Greysuit", a super-powered government agent drawn by John Higgins, and "Defoe", a 17th-century zombie hunter drawn by Leigh Gallagher, began in "2000 AD" prog 1540.

Mills has formed Repeat Offenders with artist Clint Langley and Jeremy Davis "to develop graphic novel concepts with big-screen potential" and the first project is a graphic novel called "American Reaper", serialised in the "Judge Dredd Megazine" (#316-ongoing as of October 2011). It has been optioned by Trudie Styler's Xingu Films and Mills has written the screenplay.

He has also written two "Doctor Who" audio plays, "Dead London" (2008) and "The Scapegoat" (2009) for Big Finish Productions, featuring the Eighth Doctor and Lucie Miller. The first audio play was released as the first part of the second season of the Eighth Doctor Adventures and the second as part of the third season. In 2010 Mills adapted a story that had been started by him and Wagner for Doctor Who in the 1980s and was produced by Big Finish as "The Song of Megaptera".

In 2017 he wrote, with Kevin O'Neill, and published two novels, "Serial Killer" and "Goodnight, John-Boy", part of a planned series of four books. Also in that year, he published his memoirs, "Be Pure! Be Vigilant! Behave! 2000 AD and Judge Dredd: The Secret History" in print and as an e-book. Mills also narrated the audiobook version himself. (The title is the catchphrase of the villain in his series "Nemesis the Warlock".)

In 2018 the film "Accident Man" was released, based on his comic strip for "Toxic!"

As well as his influential role in creating and contributing to numerous of British comics, Mills has produced work in both America and Europe.



 


</doc>
<doc id="25021" url="https://en.wikipedia.org/wiki?curid=25021" title="Pearl Index">
Pearl Index

The Pearl Index, also called the Pearl rate, is the most common technique used in clinical trials for reporting the effectiveness of a birth control method. 

formula_1

Three kinds of information are needed to calculate a Pearl Index for a particular study:

There are two calculation methods for determining the Pearl Index:

In the first method, the relative number of pregnancies in the study is divided by the number of months of exposure, and then multiplied by 1200.

In the second method, the number of pregnancies in the study is divided by the number of menstrual cycles experienced by women in the study, and then multiplied by 1300. 1300 instead of 1200 is used on the basis that the length of the average menstrual cycle is 28 days, or 13 cycles per year.

The Pearl Index is sometimes used as a statistical estimation of the number of unintended pregnancies in 100 woman-years of exposure (e.g. 100 women over one year of use, or 10 women over 10 years). It is also sometimes used to compare birth control methods, a lower Pearl index representing a lower chance of getting unintentionally pregnant.

Usually two Pearl Indexes are published from studies of birth control methods: 

The index was introduced by Raymond Pearl in 1933. It has remained popular for over eighty years, in large part because of the simplicity of the calculation.

Like all measures of birth control effectiveness, the Pearl Index is a calculation based on the observations of a given sample population. Thus studies of different populations using the same contraceptive will yield different values for the index. The culture and demographics of the population being studied, and the instruction technique used to teach the method, have significant effects on its failure rate.

The Pearl Index has unique shortcomings, however. It assumes a constant failure rate over time. That is an incorrect assumption for two reasons: first, the most fertile couples will get pregnant first. Couples remaining later in the study are, on average, of lower fertility. Second, most birth control methods have better effectiveness in more experienced users. The longer a couple is in the study, the better they are at using the method. So the longer the study length, the lower the Pearl Index will be - and comparisons of Pearl Indexes from studies of different lengths cannot be accurate.

The Pearl Index also provides no information on factors other than accidental pregnancy which may influence effectiveness calculations, such as:

A common misperception is that the highest possible Pearl Index is 100 - i.e. 100% of women in the study conceive in the first year. However, if all the women in the study conceived in the first month, the study would yield a Pearl Index of 1200 or 1300. The Pearl Index is only accurate as a statistical estimation of per-year risk of pregnancy if the pregnancy rate in the study was very low.

In 1966, two birth control statisticians advocated abandonment of the Pearl Index:



</doc>
<doc id="25022" url="https://en.wikipedia.org/wiki?curid=25022" title="Paul Auster">
Paul Auster

Paul Benjamin Auster (born February 3, 1947) is an American writer and director whose writing blends absurdism, existentialism, crime fiction, and the search for identity and personal meaning. His notable works include "The New York Trilogy" (1987), "Moon Palace" (1989), "The Music of Chance" (1990), "The Book of Illusions" (2002), and "The Brooklyn Follies" (2005). His books have been translated into more than forty languages.

Paul Auster was born in Newark, New Jersey, to Jewish middle-class parents of Polish descent, Queenie (née Bogat) and Samuel Auster. He grew up in South Orange, New Jersey and Newark and graduated from Columbia High School in Maplewood.

After graduating from Columbia University in 1970, he moved to Paris, France where he earned a living translating French literature. Since returning to the U.S. in 1974, he has published poems, essays, and novels of his own, as well as translations of French writers such as Stéphane Mallarmé and Joseph Joubert.
Following his acclaimed debut work, a memoir entitled "The Invention of Solitude", Auster gained renown for a series of three loosely connected detective stories published collectively as "The New York Trilogy". These books are not conventional detective stories organized around a mystery and a series of clues. Rather, he uses the detective form to address existential issues and questions of identity, space, language, and literature, creating his own distinctively postmodern (and critique of postmodernist) form in the process. Comparing the two works, Auster said, "I believe the world is filled with strange events. Reality is a great deal more mysterious than we ever give it credit for. In that sense, the "Trilogy" grows directly out of "The Invention of Solitude"."

The search for identity and personal meaning has permeated Auster's later publications, many of which concentrate heavily on the role of coincidence and random events ("The Music of Chance") or increasingly, the relationships between people and their peers and environment ("The Book of Illusions", "Moon Palace"). Auster's heroes often find themselves obliged to work as part of someone else's inscrutable and larger-than-life schemes. In 1995, Auster wrote and co-directed the films "Smoke" (which won him the Independent Spirit Award for Best First Screenplay) and "Blue in the Face". Auster's more recent works, "Oracle Night" (2003), "The Brooklyn Follies" (2005), and the novella "Travels in the Scriptorium", have also met critical acclaim.

He was on the PEN American Center Board of Trustees from 2004 to 2009, and Vice President during 2005 to 2007.

As of November 2010, Auster has been at work on a new novel, but has said that in the past few years he has found it harder to come up with ideas: "I used to have a backlog of stories, but a few years ago I found the drawers were empty. I guess I’m getting to the point where I tell myself if I can’t write another book it’s not a tragedy. Does it matter if I publish 16 or 17 novels? Unless it’s absolutely urgent, there’s no point in writing."

In 2012, Auster was quoted as saying in an interview that he would not visit Turkey, in protest of its treatment of journalists. The Turkish Prime Minister Recep Tayyip Erdoğan replied: "As if we need you! Who cares if you come or not?" Auster responded: "According to the latest numbers gathered by International PEN, there are nearly one hundred writers imprisoned in Turkey, not to speak of independent publishers such as Ragıp Zarakolu, whose case is being closely watched by PEN Centers around the world".

Auster's most recent memoir, "A Life in Words," will be published in October 2017 by Seven Stories Press. It discusses primarily the craft of writing in relation to Auster's own life, and is based on Auster's dialogues with I.B. Siegumfeldt from 2011 until the book's publication, while the latter was working to found the Center for Paul Auster Studies at the University of Copenhagen.

According to a dissertation by Heiko Jakubzik at the University of Heidelberg, two central influences in Paul Auster's writing are Jacques Lacan's psychoanalysis, and the American transcendentalism of the early to middle 19th century, as exemplified by Henry David Thoreau and Ralph Waldo Emerson.

Lacan's theory declares that we enter the world through words, that we observe the world through our senses, but the world we sense is structured (mediated) in our mind through language. Thus our unconscious also is structured as a language. This leaves us with a sense of anomaly: we can only perceive the world through language, but we have the feeling that something is missing. This is the sense of being outside language. The world can only be constructed through language, but it always leaves something uncovered, something that cannot be told or be thought of, and may only be sensed. This is one of the central themes of Paul Auster's writing.

Lacan is considered to be one of the key figures of French poststructuralism. Some academics are keen to discern traces of other poststructuralist philosophers throughout Auster's oeuvre, mainly Jacques Derrida, Jean Baudrillard and Michel de Certeau, although Auster has claimed to find such philosophies "'unreadable".

The transcendentalists believed that the symbolic order of civilization has separated us from the natural order of the world, and that by moving into nature, as Thoreau did, as he described in "Walden", it would be possible to return to this natural order.

The common factor of both ideas is the question of the meaning of symbols for human beings. Auster's protagonists are often writers who establish meaning in their lives through writing, and they try to find their place within the natural order, to be able to live within "civilization" again.

Edgar Allan Poe, Samuel Beckett and Herman Melville have also had a strong influence on Auster's writing. Not only do their characters reappear in Auster's work (such as William Wilson in "City of Glass" or Hawthorne's Fanshawe in "The Locked Room", both from "The New York Trilogy"), Auster also uses variations on the themes of these writers.

Paul Auster's reappearing subjects are:

Auster claims that people are so influenced by the continuity among them that they do not see the elements of coincidence, inconsistency and contradiction in their own lives. He writes, "This idea of contrasts, contradictions, paradox, I think, gets very much to the heart of what novel writing is for me. It's a way for me to express my own contradictions."

Failure, in Paul Auster's works, is not just the opposite of the happy ending. In "Moon Palace" and "The Book of Illusions", it comes from the individual's uncertainty about the status of their own identity. The protagonists start a search for their own identity and reduce their life to the absolute minimum. From this zero point they gain new strength and start their new life, and they also are able to regain contact with their surroundings. A similar development may also be seen in "City of Glass" and "The Music of Chance". Failure in this context is not the "nothing", it is the beginning of something all new.

Auster's protagonists often go through a process which reduces their support structure to an absolute minimum. They sever all contact with family and friends, go hungry, and lose or give away all their belongings. Out of this state of "nothingness", they either acquire new strength to reconnect with the world, or they fail and disappear for good.

"Over the past twenty-five years," opined Michael Dirda in "The New York Review of Books" in 2008, "Paul Auster has established one of the most distinctive niches in contemporary literature." Dirda also has extolled his loaded virtues in "The Washington Post":

Ever since "City of Glass", the first volume of his "New York Trilogy", Auster has perfected a limpid, confessional style, then used it to set disoriented heroes in a seemingly familiar world gradually suffused with mounting uneasiness, vague menace and possible hallucination. His plots – drawing on elements from suspense stories, existential récit, and autobiography – keep readers turning the pages, but sometimes end by leaving them uncertain about what they've just been through.

Literary critic James Wood, however, offers Auster little praise in his piece "Shallow Graves" in the November 30, 2009, issue of The New Yorker:

What Auster often gets instead is the worst of both worlds: fake realism and shallow skepticism. The two weaknesses are related. Auster is a compelling storyteller, but his stories are assertions rather than persuasions. They declare themselves; they hound the next revelation. Because nothing is persuasively assembled, the inevitable postmodern disassembly leaves one largely untouched. (The disassembly is also grindingly explicit, spelled out in billboard-size type.) Presence fails to turn into significant absence, because presence was not present enough.
Dirda and Wood—both based in the United States—assess Auster's literary qualities more than his view of American society, which cultural historian Morris Berman suggests is the basis for his European popularity:
It’s interesting that the theme of Paul Auster’s novels is that American society is incoherent, that it lacks a true identity, and that it’s nothing more than a hall of mirrors. He’s been saying that for decades and by and large Americans don’t know who Paul Auster is and they don’t read him. Auster is tremendously popular in Europe, he’s been translated into more than twenty languages: those are the bulk of his sales. Americans are not interested in this kind of perception.

Auster was married to the writer Lydia Davis. They have one son together, Daniel Auster.

Auster and his second wife, writer Siri Hustvedt (the daughter of professor and scholar Lloyd Hustvedt), were married in 1981, and they live in Brooklyn. Together they have one daughter, Sophie Auster.












</doc>
<doc id="25030" url="https://en.wikipedia.org/wiki?curid=25030" title="Plain text">
Plain text

In computing, plain text is the data (e.g. file contents) that represent only characters of readable material but not its graphical representation nor other objects (images, etc.). It may also include a limited number of characters that control simple arrangement of text, such as line breaks or tabulation characters. Plain text is different from formatted text, where style information is included, and from "binary files" in which some portions must be interpreted as binary objects (encoded integers, real numbers, images, etc.).

The encoding has traditionally been either ASCII, sometimes EBCDIC. Unicode-based encodings such as UTF-8 and UTF-16 are gradually replacing the older ASCII derivatives limited to 7 or 8 bit codes.

Files that contain markup or other meta-data are generally considered plain-text, as long as the entirety remains in directly human-readable form (as in HTML, XML, and so on (as Coombs, Renear, and DeRose argue, punctuation is itself markup). The use of plain text rather than bit-streams to express markup, enables files to survive much better "in the wild", in part by making them largely immune to computer architecture incompatibilities.

According to The Unicode Standard,

For instance, rich text such as SGML, RTF, HTML, XML, wiki markup, and TeX rely on plain text.

According to The Unicode Standard, plain text has two main properties in regard to rich text:

Files that contain markup or other meta-data are generally considered plain-text, as long as the entirety remains in directly human-readable form (as in HTML, XML, and so on (as Coombs, Renear, and DeRose argue, punctuation is itself markup). The use of plain text rather than bit-streams to express markup, enables files to survive much better "in the wild", in part by making them largely immune to computer architecture incompatibilities.

According to The Unicode Standard,

For instance, rich text such as SGML, RTF, HTML, XML, wiki markup, and TeX rely on plain text.

According to The Unicode Standard, plain text has two main properties in regard to rich text:

The purpose of using plain text today is primarily independence from programs that require their very own special encoding or formatting or file format. Plain text files can be opened, read, and edited with countless text editors and utilities.

A command-line interface allows people to give commands in plain text and get a response, also in plain text.

Many other computer programs are also capable of processing or creating plain text, such as countless programs in DOS, Windows, classic Mac OS, and Unix and its kin; as well as web browsers (a few browsers such as Lynx and the Line Mode Browser produce only plain text for display) and other e-text readers.

Plain text files are almost universal in programming; a source code file containing instructions in a programming language is almost always a plain text file. Plain text is also commonly used for configuration files, which are read for saved settings at the startup of a program.

Plain text is used for much e-mail.

A comment, a ".txt" file, or a TXT Record generally contains only plain text (without formatting) intended for humans to read.

The best format for storing knowledge persistently is plain text, rather than some binary format.

Before the early 1960s, computers were mainly used for number-crunching rather than for text, and memory was extremely expensive. Computers often allocated only 6 bits for each character, permitting only 64 characters—assigning codes for A-Z, a-z, and 0-9 would leave only 2 codes: nowhere near enough. Most computers opted not to support lower-case letters. Thus, early text projects such as Roberto Busa's Index Thomisticus, the Brown Corpus, and others had to resort to conventions such as keying an asterisk preceding letters actually intended to be upper-case.

Fred Brooks of IBM argued strongly for going to 8-bit bytes, because someday people might want to process text; and won. Although IBM used EBCDIC, most text from then on came to be encoded in ASCII, using values from 0 to 31 for (non-printing) control characters, and values from 32 to 127 for graphic characters such as letters, digits, and punctuation. Most machines stored characters in 8 bits rather than 7, ignoring the remaining bit or using it as a checksum.

The near-ubiquity of ASCII was a great help, but failed to address international and linguistic concerns. The dollar-sign ("$") was not so useful in England, and the accented characters used in Spanish, French, German, and many other languages were entirely unavailable in ASCII (not to mention characters used in Greek, Russian, and most Eastern languages). Many individuals, companies, and countries defined extra characters as needed—often reassigning control characters, or using value in the range from 128 to 255. Using values above 128 conflicts with using the 8th bit as a checksum, but the checksum usage gradually died out.

These additional characters were encoded differently in different countries, making texts impossible to decode without figuring out the originator's rules. For instance, a browser might display ¬A rather than ` if it tried to interpret one character set as another. The International Organisation for Standardisation (ISO) eventually developed several code pages under ISO 8859, to accommodate various languages. The first of these (ISO 8859-1) is also known as"Latin-1", and covers the needs of most (not all) European languages that use Latin-based characters (there was not quite enough room to cover them all). ISO 2022 then provided conventions for"switching" between different character sets in mid-file. Many other organisations developed variations on these, and for many years Windows and Macintosh computers used incompatible variations.

The text-encoding situation became more and more complex, leading to efforts by ISO and by the Unicode Consortium to develop a single, unified character encoding that could cover all known (or at least all currently known) languages. After some conflict, these efforts were unified. Unicode currently allows for 1,114,112 code values, and assigns codes covering nearly all modern text writing systems, as well as many historical ones and for many non-linguistic characters such as printer's dingbats, mathematical symbols, etc.

Text is considered plain-text regardless of its encoding. To properly understand or process it the recipient must know (or be able to figure out) what encoding was used; however, they need not know anything about the computer architecture that was used, or about the binary structures defined by whatever program (if any) created the data.

Perhaps the most common way of explicitly stating the specific encoding of plain text is with a MIME type.
For email and http, the default MIME type is "text/plain" -- plain text without markup.
Another MIME type often used in both email and http is "text/html; charset=UTF-8" -- plain text represented using UTF-8 character encoding with HTML markup.
Another common MIME type is "application/json" -- plain text represented using UTF-8 character encoding with JSON markup.

When a document is received without any explicit indication of the character encoding, some applications use charset detection to attempt to guess what encoding was used.

ASCII reserves the first 32 codes (numbers 0–31 decimal) for control characters known as the "C0 set": codes originally intended not to represent printable information, but rather to control devices (such as printers) that make use of ASCII, or to provide meta-information about data streams such as those stored on magnetic tape. They include common characters like the newline and the tab character.

In 8-bit character sets such as Latin-1 and the other ISO 8859 sets, the first 32 characters of the "upper half" (128 to 159) are also control codes, known as the "C1 set". They are rarely used directly; when they turn up in documents which are ostensibly in an ISO 8859 encoding, their code positions generally refer instead to the characters at that position in a proprietary, system-specific encoding, such as Windows-1252 or Mac OS Roman, that use the codes to instead provide additional graphic characters.

Unicode defines additional control characters, including bi-directional text direction override characters (used to explicitly mark right-to-left writing inside left-to-right writing and the other way around) and variation selectors to select alternate forms of CJK ideographs, emoji and other characters.



</doc>
<doc id="25031" url="https://en.wikipedia.org/wiki?curid=25031" title="Presbyterian Church (USA)">
Presbyterian Church (USA)

The Presbyterian Church (USA), or PC (USA), is a mainline Protestant Christian denomination in the United States. A part of the Reformed tradition, it is the largest Presbyterian denomination in the U.S., and known for its relatively progressive stance on doctrine. The PC(USA) was established by the 1983 merger of the Presbyterian Church in the United States, whose churches were located in the Southern and border states, with the United Presbyterian Church in the United States of America, whose congregations could be found in every state. The similarly named Presbyterian Church in America is a separate denomination whose congregations can also trace their history to the various schisms and mergers of Presbyterian churches in the United States.

The denomination had 1,415,053 active members and 19,491 ordained ministers in 9,304 congregations at the end of 2017. This number does not include members who are baptized but who are not confirmed or the inactive members also affiliated. For example, in 2005, the PC(USA) claimed 318,291 baptized, but not confirmed, members and nearly 500,000 inactive members in addition to active members. Its membership has been declining over the past several decades, however, the trend significantly accelerated recent year partly due to breakaway congregations. Average denominational worship attendance dropped to 565,467 in 2017 from 748,774 in 2013. The PC(USA) is the largest Presbyterian denomination in the United States.

Presbyterians trace their history to the Protestant Reformation in the 16th century. The Presbyterian heritage, and much of its theology, began with the French theologian and lawyer John Calvin (1509–64), whose writings solidified much of the Reformed thinking that came before him in the form of the sermons and writings of Huldrych Zwingli. From Calvin's headquarters in Geneva, the Reformed movement spread to other parts of Europe. John Knox, a former Roman Catholic Priest from Scotland who studied with Calvin in Geneva, took Calvin's teachings back to Scotland and led the Scottish Reformation of 1560. Because of this reform movement, the Church of Scotland embraced Reformed theology and presbyterian polity. The Ulster Scots brought their Presbyterian faith with them to Ireland, where they laid the foundation of what would become the Presbyterian Church in Ireland.

Immigrants from Scotland and Ireland brought Presbyterianism to America as early as 1640, and immigration would remain a large source of growth throughout the colonial era. Another source of growth were a number of New England Puritans who left the churches because they preferred presbyterian polity. In 1706, seven ministers led by Francis Makemie established the first American presbytery at Philadelphia, which was followed by the creation of the Synod of Philadelphia in 1717.

The First Great Awakening and the revivalism it generated had a major impact on American Presbyterians. Ministers such as William and Gilbert Tennent, a friend of George Whitefield, emphasized the necessity of a conscious conversion experience and pushed for higher moral standards among the clergy. Disagreements over revivalism, itinerant preaching, and educational requirements for clergy led to a division known as the Old Side–New Side Controversy that lasted from 1741 to 1758.

In the South, the Presbyterians were evangelical dissenters, mostly Scotch-Irish, who expanded into Virginia between 1740 and 1758. Spangler (2008) argues they were more energetic and held frequent services better atuned to the frontier conditions of the colony. Presbyterianism grew in frontier areas where the Anglicans had made little impression. Uneducated whites and blacks were attracted to the emotional worship of the denomination, its emphasis on biblical simplicity, and its psalm singing. Some local Presbyterian churches, such as Briery in Prince Edward County, owned slaves. The Briery church purchased five slaves in 1766 and raised money for church expenses by hiring them out to local planters.

After the United States achieved independence from Great Britain, Presbyterian leaders felt that a national Presbyterian denomination was needed, and the Presbyterian Church in the United States of America (PCUSA) was organized. The first General Assembly was held in Philadelphia in 1789. John Witherspoon, president of Princeton University and the only minister to sign the Declaration of Independence, was the first moderator.

Not all American Presbyterians participated in the creation of the PCUSA General Assembly because the divisions then occurring in the Church of Scotland were replicated in America. In 1751, Scottish Covenanters began sending ministers to America, and the Seceders were doing the same by 1753. In 1858, the majority of Covenanters and Seceders merged to create the United Presbyterian Church of North America (UPCNA).

In the decades after independence, many Americans including Calvinists (Presbyterians and Congregationalists), Methodists, and Baptists were swept up in Protestant religious revivals that would later become known as the Second Great Awakening. Presbyterians also helped to shape voluntary societies that encouraged educational, missionary, evangelical, and reforming work. As its influence grew, many non-Presbyterians feared that the PCUSA's informal influence over American life might effectively make it an established church.

The Second Great Awakening divided the PCUSA over revivalism and fear that revivalism was leading to an embrace of Arminian theology. In 1810, frontier revivalists split from the PCUSA and organized the Cumberland Presbyterian Church. Throughout the 1820s, support and opposition to revivalism hardened into well-defined factions, the New School and Old School respectively. By the 1838, the Old School–New School Controversy had divided the PCUSA. There were now two general assemblies each claiming to represent the PCUSA.

In 1858, the New School split along sectional lines when its Southern synods and presbyteries established the pro-slavery United Synod of the Presbyterian Church. Old School Presbyterians followed in 1861 after the start of hostilities in the American Civil War with the formation of the Presbyterian Church in the Confederate States of America. The Presbyterian Church in the CSA absorbed the smaller United Synod in 1864. After the war, this body was renamed the Presbyterian Church in the United States (PCUS) and was commonly nicknamed the "Southern Presbyterian Church" throughout its history. In 1869, the northern PCUSA's Old School and New School factions reunited as well and was known as the "Northern Presbyterian Church".

The early part of the 20th century saw continued growth in both major sections of the church. It also saw the growth of Fundamentalist Christianity (a movement of those who believed in the literal interpretation of the Bible as the fundamental source of the religion) as distinguished from Modernist Christianity (a movement holding the belief that Christianity needed to be re-interpreted in light of modern scientific theories such as evolution or the rise of degraded social conditions brought on by industrialization and urbanization).

Open controversy was sparked in 1922, when Harry Emerson Fosdick, a modernist pastoring a PCUSA congregation in New York City, preached a sermon entitled "Shall the Fundamentalists Win?" The crisis reached a head the following year when, in response to the New York Presbytery's decision to ordain a couple of men who could not affirm the virgin birth, the PCUSA's General Assembly reaffirmed the "five fundamentals": the deity of Christ, the Virgin Birth, the vicarious atonement, the inerrancy of Scripture, and Christ's miracles and resurrection. This move against modernism caused a backlash in the form of the "Auburn Affirmation" — a document embracing liberalism and modernism. The liberals began a series of ecclesiastical trials of their opponents, expelled them from the church and seized their church buildings. Under the leadership of J. Gresham Machen, a former Princeton Theological Seminary New Testament Professor who had founded Westminster Theological Seminary in 1929, and who was a PCUSA minister, many of these conservatives would establish what became known as the Orthodox Presbyterian Church in 1936. Although the 1930s and 1940s and the ensuing neo-orthodox theological consensus mitigated much of the polemics during the mid-20th century, disputes erupted again beginning in the mid-1960s over the extent of involvement in the civil rights movement and the issue of ordination of women, and, especially since the 1990s, over the issue of ordination of homosexuals.

The Presbyterian Church in the United States of America was joined by the majority of the Cumberland Presbyterian Church, mostly congregations in the border and Southern states, in 1906. In 1920, it absorbed the Welsh Calvinist Methodist Church. The United Presbyterian Church of North America merged with the PCUSA in 1958 to form the United Presbyterian Church in the United States of America (UPCUSA).

Under Eugene Carson Blake, the UPCUSA's stated clerk, the denomination entered into a period of social activism and ecumenical endeavors, which culminated in the development of the Confession of 1967 which was the church's first new confession of faith in three centuries. The 170th General Assembly in 1958 authorized a committee to develop a brief contemporary statement of faith. The 177th General Assembly in 1965 considered and amended the draft confession and sent a revised version for general discussion within the church. The 178th General Assembly in 1966 accepted a revised draft and sent it to presbyteries throughout the church for final ratification. As the confession was ratified by more than 90% of all presbyteries, the 178th General Assembly finally adopted it in 1967. The UPCUSA also adopted a "Book of Confessions "in 1967, which would include the Confession of 1967, the Westminster Confession and Shorter Catechism, the Heidelberg Catechism, the Second Helvetic and Scots Confessions and the Barmen Declaration.

An attempt to reunite the United Presbyterian Church in the USA with the Presbyterian Church in the United States in the late 1950s failed when the latter church was unwilling to accept ecclesiastical centralization. In the meantime, a conservative group broke away from the Presbyterian Church in the United States in 1973, mainly over the issues of women's ordination and a perceived drift toward theological liberalism. This group formed the Presbyterian Church in America (PCA).

Attempts at union between the churches (UPCUSA and PCUS) were renewed in the 1970s, culminating in the merger of the two churches to form the Presbyterian Church (USA) on June 10, 1983. At the time of the merger, the churches had a combined membership of 3,121,238. Many of the efforts were spearheaded by the financial and outspoken activism of retired businessman Thomas Clinton who died two years before the merger. A new national headquarters was established in Louisville, Kentucky in 1988 replacing the headquarters of the UPCUSA in New York City and the PCUS located in Atlanta, Georgia.

The merger essentially consolidated moderate-to-liberal American Presbyterians into one body. Other U.S. Presbyterian bodies (the Cumberland Presbyterians being a partial exception) place greater emphasis on doctrinal Calvinism, literalist hermeneutics, and conservative politics.

For the most part, PC(USA) Presbyterians, not unlike similar mainline traditions such as the Episcopal Church and the United Church of Christ, are fairly progressive on matters such as doctrine, environmental issues, sexual morality, and economic issues, though the denomination remains divided and conflicted on these issues. Like other mainline denominations, the PC(USA) has also seen a great deal of demographic aging, with fewer new members and declining membership since 1967.

In the 1990s, 2000s, and 2010s, the General Assembly of PC(USA) adopted several social justice initiatives, which covered a range of topics including: stewardship of God's creation, world hunger, homelessness, and LGBT issues. As of 2011, the PC(USA) no longer excludes Partnered Gay and Lesbian ministers from the ministry. Previously, the PC(USA) required its ministers to remain ""chastely in singleness or with fidelity in marriage"." Currently, the PC(USA) permits teaching elders to perform same-gender marriages. On a congregational basis, individual sessions (congregational governing bodies) may choose to permit same-gender marriages.

These changes have led to several renewal movements and denominational splinters. Some conservative-minded groups in the PC(USA), such as the Confessing Movement and the Presbyterian Lay Committee (formed in the mid-1960s) have remained in the main body, rather than leaving to form new, break-away groups.

Several Presbyterian denominations have split from PC(USA) or its predecessors over the years. For example, the Orthodox Presbyterian Church broke away from the Presbyterian Church in the USA (PC-USA) in 1936.

More recently formed Presbyterian denominations have posed a threat to modern day PC(USA) congregations disenchanted with the direction of the denomination, but wishing to continue in a Reformed, Presbyterian denomination. The Presbyterian Church in America (PCA), which does not allow ordained female clergy, separated from Presbyterian Church in the United States in 1973 and has subsequently become the second largest Presbyterian denomination in the United States. The Evangelical Presbyterian Church (EPC), which gives local presbyteries the option of allowing ordained female pastors, broke away from the United Presbyterian Church and incorporated in 1981. A PC(USA) renewal movement, Fellowship of Presbyterians (FOP) (now The Fellowship Community), held several national conferences serving disaffecting Presbyterians. FOP's organizing efforts culminated with the founding of ECO: A Covenant Order of Evangelical Presbyterians (ECO), a new Presbyterian denomination that allows ordination of women but is more conservative theologically than PC(USA).

In 2013 the presbyteries ratified the General Assembly's 2012 vote to allow the ordination of openly gay persons to the ministry and in 2014 the General Assembly voted to amend the church's constitution to define marriage as the union of two persons instead of the union of a man and woman, which was ratified (by the presbyteries) in 2015. This has led to the departure of several hundred congregations. The majority of churches leaving the Presbyterian Church (USA) have chosen to join the Evangelical Presbyterian Church or ECO. Few have chosen to join the larger more conservative Presbyterian Church in America, which does not permit female clergy.

Since 1983 the Presbyterian Youth Triennium has been held every three years at Purdue University in West Lafayette, Indiana, U.S. and is open to Presbyterian high school students throughout the world. The very first Youth Triennium was held in 1980 at Indiana University and the conference for teens is an effort of the Presbyterian Church (USA), the largest Presbyterian denomination in the nation; Cumberland Presbyterian Church; and Cumberland Presbyterian Church in America, the first African-American denomination to embrace Presbyterianism in the reformed tradition.

The Constitution of PC(USA) is composed of two portions: Part I, the "Book of Confessions" and Part II, the "Book of Order". The "Book of Confessions" outlines the beliefs of the PC(USA) by declaring the creeds by which the Church's leaders are instructed and led. Complementing that is the "Book of Order" which gives the rationale and description for the organization and function of the Church at all levels. The "Book of Order" is currently divided into four sections – 1) The Foundations of Presbyterian Polity 2) The Form of Government, 3) The Directory For Worship, and 4) The Rules of Discipline.

The Presbyterian Church (U.S.A) has a representative form of government, known as presbyterian polity, with four levels of government and administration, as outlined in the "Book of Order". The councils (governing bodies) are as follows: 

At the congregational level, the governing body is called the "session", from the Latin word "sessio", meaning "a sitting". The session is made up of the pastors of the church and all elders elected and installed to active service. Following a pattern set in the first congregation of Christians in Jerusalem described in the Book of Acts in the New Testament, the church is governed by "presbyters" (a term and category that includes elders and Ministers of Word and Sacrament, historically also referred to as "ruling or canon elders" because they "measure" the spiritual life and work of a congregation and ministers as "teaching elders").

The elders are nominated by a nominating committee of the congregation; in addition, nominations from the floor are permissible. Elders are then elected by the congregation. All elders elected to serve on the congregation's session of elders are required to undergo a period of study and preparation for this order of ministry, after which the session examines the elders-elect as to their personal faith; knowledge of doctrine, government, and discipline contained in the Constitution of the church, and the duties of the office of elder. If the examination is approved, the session appoints a day for the service of ordination and installation. Session meetings are normally moderated by a called and installed pastor and minutes are recorded by a clerk, who is also an ordained presbyter. If the congregation does not have an installed pastor, the Presbytery appoints a minister member or elected member of the presbytery as moderator with the concurrence of the local church session. The moderator presides over the session as first among equals and also serves a "liturgical" bishop over the ordination and installation of elders and deacons within a particular congregation.

The session guides and directs the ministry of the local church, including almost all spiritual and fiduciary leadership. The congregation as a whole has only the responsibility to vote on: 1) the call of the pastor (subject to presbytery approval) and the terms of call (the church's provision for compensating and caring for the pastor); 2) the election of its own officers (elders & deacons); 3) buying, mortgaging, or selling real property. All other church matters such as the budget, personnel matters, and all programs for spiritual life and mission, are the responsibility of the session. In addition, the session serves as an ecclesiastical court to consider disciplinary charges brought against church officers or members.

The session also oversees the work of the deacons, a second body of leaders also tracing its origins to the Book of Acts. The deacons are a congregational-level group whose duty is "to minister to those who are in need, to the sick, to the friendless, and to any who may be in distress both within and beyond the community of faith." In some churches, the responsibilities of the deacons are taken care of by the session, so there is no board of deacons in that church. In some states, churches are legally incorporated and members or elders of the church serve as trustees of the corporation. However, "the power and duties of such trustees shall not infringe upon the powers and duties of the Session or of the board of deacons." The deacons are a ministry board but not a governing body.

A "presbytery" is formed by all the congregations and the Ministers of Word and Sacrament in a geographic area together with elders selected (proportional to congregation size) from each of the congregations. Four special presbyteries are "non-geographical" in that they overlay other English-speaking presbyteries, though they are geographically limited to the boundaries of a particular synod (see below); it may be more accurate to refer to them as "trans-geographical." Three PC(USA) synods have a non-geographical presbytery for Korean language Presbyterian congregations, and one synod has a non-geographical presbytery for Native American congregations, the Dakota Presbytery. There are currently 172 presbyteries for the nearly 10,000 congregations in the PC(USA).

Only the presbytery (not a congregation, session, synod, or General Assembly) has the responsibility and authority to ordain church members to the ministry of Teaching Elder (formerly called Ministry of Word and Sacrament), to install Teaching Elders to (and/or remove them from) congregations, and to remove a minister from the ministry of Teaching Elder. A Teaching Elder is a Presbyterian minister by virtue of membership on a roll of a presbytery. The General Assembly cannot ordain or remove a Teaching Elder, but the Office of the General Assembly does maintain and publish a national directory with the help of each presbytery's stated clerk. Bound versions are published bi-annually with the minutes of the General Assembly. A pastor cannot be a member of the congregation he or she serves as pastor because his or her primary ecclesiastical accountability lies with the presbytery. Members of the congregation generally choose their own pastor with the assistance and support of the presbytery. The presbytery must approve the choice and officially install the pastor at the congregation. Additionally, the presbytery must approve if either the congregation or the pastor wishes to dissolve that pastoral relationship.

The presbytery has authority over many affairs of its local congregations. Only the presbytery can approve the establishment, dissolution, or merger of congregations. The presbytery also maintains a Permanent Judicial Commission, which acts as a court of appeal from sessions, and which exercises original jurisdiction in disciplinary cases against minister members of the presbytery.

A presbytery has two elected officers: a moderator and a stated clerk. The Moderator of the presbytery is elected annually and is either a minister member or an elder commissioner from one of the presbytery's congregations. The Moderator presides at all presbytery assemblies and is the chief overseer at the ordination and installation of ministers in that presbytery. The stated clerk is the chief ecclesial officer and serves as the presbytery's executive secretary and parliamentarian in accordance with the church Constitution and Robert's Rules of Order. While the moderator of a presbytery normally serves one year, the stated clerk normally serves a designated number of years and may be re-elected indefinitely by the presbytery. Additionally, an Executive Presbyter (sometimes designated as General Presbyter, Pastor to Presbytery, Transitional Presbyter) is often elected as a staff person to care for the administrative duties of the presbytery, often with the additional role of a pastor to the pastors. Presbyteries may be creative in the designation and assignment of duties for their staff. A presbytery is required to elect a Moderator and a Clerk, but the practice of hiring staff is optional. Presbyteries must meet at least twice a year, but they have the discretion to meet more often and most do.

"See "Map of Presbyteries and Synods"".

Presbyteries are organized within a geographical region to form a "synod". Each synod contains at least three presbyteries, and its elected voting membership is to include both elders and Ministers of Word and Sacrament in equal numbers. Synods have various duties depending on the needs of the presbyteries they serve. In general, their responsibilities (G-12.0102) might be summarized as: developing and implementing the mission of the church throughout the region, facilitating communication between presbyteries and the General Assembly, and mediating conflicts between the churches and presbyteries. Every synod elects a Permanent Judicial Commission, which has original jurisdiction in remedial cases brought against its constituent presbyteries, and which also serves as an ecclesiastical court of appeal for decisions rendered by its presbyteries' Permanent Judicial Commissions. Synods are required to meet at least biennially. Meetings are moderated by an elected synod Moderator with support of the synod's Stated Clerk. There are currently 16 synods in the PC(USA) and they vary widely in the scope and nature of their work. An ongoing current debate in the denomination is over the purpose, function, and need for synods.

See also the List of Presbyterian Church (USA) synods and presbyteries.

The "General Assembly" is the highest governing body of the PC(USA). Until the 216th assembly met in Richmond, Virginia in 2004, the General Assembly met annually; since 2004, the General Assembly has met biennially in even-numbered years. It consists of commissioners elected by presbyteries (not synods), and its voting membership is proportioned with parity between elders and Ministers of Word and Sacrament. There are many important responsibilities of the General Assembly. Among them, "The Book of Order" lists these four:

The General Assembly elects a moderator at each assembly who moderates the rest of the sessions of that assembly meeting and continues to serve until the next assembly convenes (two years later) to elect a new moderator or co-moderator. Currently, the denomination is served by Co-Moderators the Rev. Denise Anderson and the Rev. Jan Edmiston who were elected as the first co-moderators of the 222nd General Assembly (2016).

A Stated Clerk is elected to a four-year term and is responsible for the Office of the General Assembly which conducts the ecclesiastical work of the church. The Office of the General Assembly carries out most of the ecumenical functions and all of the constitutional functions at the Assembly. The former Stated Clerk of the General Assembly is the Rev. Gradye Parsons, who had served in that role since 2008 and was unanimously reelected in 2012. Rev. Parsons did not stand for re-election at the 222nd General Assembly meeting in 2016, and the Rev. Dr. J. Herbert Nelson was elected Stated Clerk at the 2016 General Assembly meeting in Portland. Nelson is the first African American to be elected to the office, and is a third-generation Presbyterian pastor.

The Stated Clerk is also responsible for the records of the denomination, a function formalized in 1925 when the General Assembly created the "Department of Historical Research and Conservation" as part of the Office of the General Assembly. The current "Department of History" is also known as the Presbyterian Historical Society.

Six agencies carry out the work of the General Assembly. These are the Office of the General Assembly, the Presbyterian Publishing Corporation, the Presbyterian Investment and Loan Program, the Board of Pensions, the Presbyterian Foundation, and the Presbyterian Mission Agency (formerly known as the General Assembly Mission Council).

The General Assembly elects members of the Presbyterian Mission Agency Board (formerly General Assembly Mission Council). There are 48 elected members of the Presbyterian Mission Agency Board (40 voting members; 17 non-voting delegates), who represent synods, presbyteries, and the church at-large. Members serve one six-year term, with the exception of the present Moderator of the General Assembly (one 2-year term), the past Moderator of the General Assembly (one 2-year term), the moderator of Presbyterian Women (one 3-year term), ecumenical advisory members (one 2-year term, eligible for two additional terms), and stewardship and audit committee at-large members (one 2-year term, eligible for two additional terms). Among the elected members' major responsibilities is the coordination of the work of the program areas in light of General Assembly mission directions, objectives, goals and priorities. The PMAB meets three times a year. The General Assembly elects an Executive Director of the Presbyterian Mission Agency who is the top administrator overseeing the mission work of the PC(USA). The current Executive Director of the PMA is Ruling Elder Linda Bryant Valentine.

The General Assembly Permanent Judicial Commission (GAPJC) is the highest Church court of the denomination. It composed of one member elected by the General Assembly from each of its constituent synods (16). It has ultimate appellate jurisdiction over all Synod Permanent Judicial Commission cases involving issues of Church Constitution, and original jurisdiction over a small range of cases. The General Assembly Permanent Judicial Commission issues Authoritative Interpretations of The Constitution of the Presbyterian Church (USA) through its decisions.

The denomination maintains affiliations with ten seminaries in the United States. These are:

Two other seminaries are related to the PC(USA) by covenant agreement: Auburn Theological Seminary in New York, New York, and Evangelical Seminary of Puerto Rico in San Juan, Puerto Rico.

There are numerous colleges and universities throughout the United States affiliated with PC(USA). For a complete list, see the article Association of Presbyterian Colleges and Universities. For more information, see the article PC(USA) seminaries.

While not affiliated with the PC(USA), the president of Fuller Theological Seminary, Mark Labberton, is an ordained minister of the PC(USA) and the seminary educates many candidates for ministry.

When the United Presbyterian Church in the USA merged with the Presbyterian Church in the United States there were 3,131,228 members. Statistics shows steadily decline since 1983. (The combined membership of the PCUS and United Presbyterian Church peaked in 1965 at 4.25 million communicant members.)
The PC(USA) maintains extensive statistics on its members. In 2005, the PC(USA) claimed 2.3 million active members as well as nearly 500,000 inactive members; the total membership, including all categories of membership, was 3.1 million members. In 2012 PC(USA) reported 1.84 million active members, less than half of its peak membership of 4.25 million members in 1965 and down from 1.95 million members in 2011.
Membership decreased by 4.83% in 2013, continuing a three decade-long decline in membership for PC(USA). Recent declines in numbers are consistent with the trends of most mainline Protestant denominations in America since the late 1960s. In 2013, Jan Armstrong, Executive Presbyter of the Presbytery of Santa Barbara, said that the most recent informal OGA (Office of the General Assembly) projections are for an anticipated loss of perhaps 500,000 members over the next 3–4 years, roughly 25% of the denomination's membership.
In 2016 PCUSA total membership was 1,482,767, net loss of 89,893 members. The PCUSA dismissed 99 churches to other denominations in 2016, while dissolving 97 congregations. Seventeen churches were organized during the year and no churches were received from other denominations.

The average Presbyterian Church has 175 members (the mean in 2013). About 25% of the total congregations report between 1 and 50 members. Another 23% report between 51 and 100 members. The average worship attendance as a percentage of membership is 51.7%. The largest congregation in the PC(USA) is Peachtree Presbyterian Church in Atlanta, Georgia, with a reported membership of 8,989 (2009).

Most PC(USA) members are white (92.9%). Other racial and ethnic members include African-Americans (3.1% of the total membership of the denomination), Asians (2.3%), Hispanics (1.2%), Native Americans (0.2%), and others (0.3%). Despite declines in the total membership of the PC(USA), the percentage of racial-ethnic minority members has stayed about the same since 1995. The ratio of female members (58%) to male members (42%) has also remained stable since the mid-1960s. Presbyterians are among the wealthiest Christians denomination in the United States, Presbyterians tend also to be better educated and they have a high number of graduate (64%) and post-graduate degrees (26%) per capita.

According to a 2014 study by the Pew Research Center, Presbyterians ranked as the fourth most financially successful religious group in the United States, with 32% of Presbyterians living in households with incomes of at least $100,000.

The session of the local congregation has a great deal of freedom in the style and ordering of worship within the guidelines set forth in the Directory for Worship section of the "Book of Order". Worship varies from congregation to congregation. The order may be very traditional and highly liturgical, or it may be very simple and informal. This variance is not unlike that seen in the "High Church" and "Low Church" styles of the Anglican Church. The "Book of Order" suggests a worship service ordered around five themes: "gathering around the Word, proclaiming the Word, responding to the Word, the sealing of the Word, and bearing and following the Word into the world." Prayer is central to the service and may be silent, spoken, sung, or read in unison (including The Lord's Prayer). Music plays a large role in most PC(USA) worship services and ranges from chant to traditional Protestant hymns, to classical sacred music, to more modern music, depending on the preference of the individual church and is offered prayerfully and not "for entertainment or artistic display." Scripture is read and usually preached upon. An offering is usually taken.

The Directory for Worship in the Book of Order provides the directions for what must be, or may be included in worship. During the 20th century, Presbyterians were offered optional use of liturgical books:

For more information, see Liturgical book of the Presbyterian Church (USA)

In regard to vestments, the Directory for Worship leaves that decision up to the ministers. Thus, on a given Sunday morning service, a congregation may see the minister leading worship in street clothes, Geneva gown, or an alb. Among the Paleo-orthodoxy and emerging church Presbyterians, clergy are moving away from the traditional black Geneva gown and reclaiming not only the more ancient Eucharist vestments of alb and chasuble, but also cassock and surplice (typically a full length Old English style surplice which resembles the Celtic alb, an ungirdled liturgical tunic of the old Gallican Rite).

The Service for the Lord's Day is the name given to the general format or ordering of worship in the Presbyterian Church as outlined in its Constitution's Book of Order. There is a great deal of liberty given toward worship in that denomination, so while the underlying order and components for the Service for the Lord's Day is extremely common, it varies from congregation to congregation, region to region.

The creation of the Service for the Lord's Day was one of the most positive contributions of the Worshipbook of 1970. The Book of Common Worship of 1993 leaned heavily upon this service.

The Presbyterian Church (USA) has, in the past, been a leading United States denomination in mission work, and many hospitals, clinics, colleges and universities worldwide trace their origins to the pioneering work of Presbyterian missionaries who founded them more than a century ago.

Currently, the church supports about 215 missionaries abroad annually. Many churches sponsor missionaries abroad at the session level, and these are not included in official statistics.

A vital part of the world mission emphasis of the denomination is building and maintaining relationships with Presbyterian, Reformed and other churches around the world, even if this is not usually considered missions.

The PC(USA) is a leader in disaster assistance relief and also participates in or relates to work in other countries through ecumenical relationships, in what is usually considered not missions, but deaconship.

The General Assembly of the Presbyterian Church (USA) determines and approves ecumenical statements, agreements, and maintains correspondence with other Presbyterian and Reformed bodies, other Christians churches, alliances, councils, and consortia. Ecumenical statements and agreements are subject to the ratification of the presbyteries. The following are some of the major ecumenical agreements and partnerships.

The church is committed to "engage in bilateral and multilateral dialogues with other churches and traditions in order to remove barriers of misunderstanding and establish common affirmations." As of 2012 it is in dialog with the Episcopal Church, the Moravian Church, the Korean American Presbyterian Church, the Cumberland Presbyterian Church, the Cumberland Presbyterian Church in America, and the U.S. Conference of Catholic Bishops. It also participates in international dialogues through the World Council of Churches and the World Communion of Reformed Churches. The most recent international dialogues include Pentecostal churches, the Seventh-day Adventist Church, Orthodox Church in America, and others.

In 2011 the National Presbyterian Church in Mexico severed ties with the PC(USA) and in 2015 the Independent Presbyterian Church of Brazil and the Evangelical Presbyterian and Reformed Church of Peru followed suit because of the recent issues of ordaining homosexuals.

The Presbyterian Church (USA) is in corresponding partnership with the National Council of Churches, the World Communion of Reformed Churches, and the World Council of Churches. It is a member of Churches for Middle East Peace.

In 1997 the PCUSA and three other churches of Reformation heritage: the Evangelical Lutheran Church in America, the Reformed Church in America and the United Church of Christ, acted on an ecumenical proposal of historic importance, known as "A Formula of Agreement". The timing reflected a doctrinal consensus which had been developing over the past thirty-two years coupled with an increasing urgency for the church to proclaim a gospel of unity in contemporary society. In light of identified doctrinal consensus, desiring to bear visible witness to the unity of the Church, and hearing the call to engage together in God's mission, it was recommended:

The term "full communion" is understood here to specifically mean that the four churches:


The agreement assumed the doctrinal consensus articulated in A Common Calling:The Witness of Our Reformation Churches in North America Today, and is to be viewed in concert with that document. The purpose of A Formula of Agreement is to elucidate the complementarity of affirmation and admonition as the basic principle of entering into full communion and the implications of that action as described in A Common Calling.

The 209th General Assembly (1997) approved A Formula of Agreement and in 1998 the 210th General Assembly declared full communion among these Protestant bodies.

The Presbyterian Church (USA) is in corresponding partnership with the National Council of Churches, the World Communion of Reformed Churches, Christian Churches Together, and the World Council of Churches.

As of June 2010, the World Alliance of Reformed Churches merged with the Reformed Ecumenical Council to form the World Communion of Reformed Churches. The result was a form of full communion similar to that outline in the Formula of Agreement, including orderly exchange of ministers.

The PC (USA) is one of nine denominations that joined together to form the Consultation on Church Union, which initially sought a merger of the denominations. In 1998 the Seventh Plenary of the Consultation on Church Union approved a document "Churches in Covenant Communion: The Church of Christ Uniting" as a plan for the formation of a covenant communion of churches. In 2002 the nine denominations inaugurated the new relationship and became known as Churches Uniting in Christ. The partnership is considered incomplete until the partnering communions reconcile their understanding of ordination and devise an orderly exchange of clergy.

 Paragraph G-6.0106b of the Book of Order, which was adopted in 1996, prohibited the ordination of those who were not faithful in heterosexual marriage or chaste in singleness. This paragraph was included in the Book of Order from 1997 to 2011, and was commonly referred to by its pre-ratification designation, "Amendment B." Several attempts were made to remove this from the Book of Order, ultimately culminating in its removal in 2011. In 2011, the Presbyteries of the PC(USA) passed Amendment 10-A permitting congregations to ordain openly Gay and Lesbian elders and deacons, and allowing presbyteries to ordain ministers without reference to the fidelity/chastity provision, saying "governing bodies shall be guided by Scripture and the confessions in applying standards to individual candidates".

Many Presbyterian scholars, pastors, and theologians have been heavily involved in the debate over homosexuality, over the years. The Presbyterian Church of India cooperation with Presbyterian Church (USA) was dissolved in 2012 when the PC(USA) voted to ordain openly gay clergy to the ministry. In 2012, the PC(USA) granted permission, nationally, to begin ordaining openly gay and lesbian clergy.

Since 1980, the More Light Churches Network has served many congregations and individuals within American Presbyterianism who promote the full participation of all people in the PC(USA) regardless of sexual orientation or gender identity. The Covenant Network of Presbyterians was formed in 1997 to support repeal of "Amendment B" and to encourage networking amongst like-minded clergy and congregations. Other organizations of Presbyterians, such as the Confessing Movement and the Alliance of Confessing Evangelicals, have organized on the other side of the issue to support the fidelity/chastity standard for ordination, which was removed in 2011.

The Presbyterian Church (USA) voted to allow same-gender marriages on June 19, 2014 during its 221st General Assembly, making it one of the largest Christian denominations in the world to allow same-sex unions. This vote lifted a previous ban, and allows pastors to perform marriages in jurisdictions where it is legal. Additionally, the Assembly approved to amend the Book of Order that would change the definition of marriage from "between a man and a woman" to "between two people, traditionally between a man and a woman."

The 2006 "Report of the Theological Task Force on Peace, Unity, and Purity of the Church", in theory, attempted to find common ground. Some felt that the adoption of this report provided for a clear local option mentioned, while the Stated Clerk of the General Assembly, Clifton Kirkpatrick went on record as saying, "Our standards have not changed. The rules of the Book of Order stay in force and all ordinations are still subject to review by higher governing bodies." The authors of the report stated that it is a compromise and return to the original Presbyterian culture of local controls. The recommendation for more control by local presbyteries and sessions is viewed by its opposition as a method for bypassing the constitutional restrictions currently in place concerning ordination and marriage, effectively making the constitutional "standard" entirely subjective.

In the General Assembly gathering of June 2006, Presbyterian voting Commissioners passed an "authoritative interpretation", recommended by the Theological Task Force, of the "Book of Order" (the church constitution). Some argued that this gave presbyteries the "local option" of ordaining or not ordaining anyone based on a particular presbytery's reading of the constitutional statute. Others argued that presbyteries have always had this responsibility and that this new ruling did not change but only clarified that responsibility. On June 20, 2006, the General Assembly voted 298 to 221 (or 57% to 43%) to approve such interpretation. In that same session on June 20, the General Assembly also voted 405 to 92 (with 4 abstentions) to uphold the constitutional standard for ordination requiring fidelity in marriage or chastity in singleness.

The General Assembly of 2008 took several actions related to homosexuality. The first action was to adopt a different translation of the Heidelberg Catechism from 1962, removing the words "homosexual perversions" among other changes. This will require the approval of the 2010 and 2012 General Assemblies as well as the votes of the presbyteries after the 2010 Assembly. The second action was to approve a new Authoritative Interpretation of G-6.0108 of the "Book of Order" allowing for the ordaining body to make decisions on whether or not a departure from the standards of belief of practice is sufficient to preclude ordination. Some argue that this creates "local option" on ordaining homosexual persons. The third action was to replace the text of "Amendment B" with new text: "Those who are called to ordained service in the church, by their assent to the constitutional questions for ordination and installation (W-4.4003), pledge themselves to live lives obedient to Jesus Christ the Head of the Church, striving to follow where he leads through the witness of the Scriptures, and to understand the Scriptures through the instruction of the Confessions. In so doing, they declare their fidelity to the standards of the Church. Each governing body charged with examination for ordination and/or installation (G-14.0240 and G-14.0450) establishes the candidate's sincere efforts to adhere to these standards." This would have removed the "fidelity and chastity" clause. This third action failed to obtain the required approval of a majority of the presbyteries by June 2009. Fourth, a resolution was adopted to affirm the definition of marriage from Scripture and the Confessions as being between a man and a woman.

In July 2010, by a vote of 373 to 323, the General Assembly voted to propose to the presbyteries for ratification a constitutional amendment to remove from the Book of Order section G-6.0106.b. which included this explicit requirement for ordination: "Among these standards is the requirement to live either in fidelity within the covenant of marriage between a man and a woman (W-4.9001), or chastity in singleness." This proposal required ratification by a majority of the 173 presbyteries within 12 months of the General Assembly's adjournment. A majority of presbytery votes was reached in May 2011. The constitutional amendment took effect July 10, 2011. This amendment shifted back to the ordaining body the responsibility for making decisions about whom they shall ordain and what they shall require of their candidates for ordination. It neither prevents nor imposes the use of the so-called "fidelity and chastity" requirement, but it removes that decision from the text of the constitution and places that judgment responsibility back upon the ordaining body where it had traditionally been prior to the insertion of the former G-6.0106.b. in 1997. Each ordaining body, the session for deacon or elder and the presbytery for minister, is now responsible to make its own interpretation of what scripture and the confessions require of ordained officers.

In June 2014, the General Assembly approved a change in the wording of its constitution to define marriage a contract “between a woman and a man” to being “between two people, traditionally a man and a woman.” It allowed gay and lesbian weddings within the church and further allow clergy to perform same-sex weddings. That revision gave clergy the choice of presiding over same-sex marriages, but clergy was not compelled to perform same-sex marriage.

In PC(USA)'s book of order includes a "trust clause," which grants ownership of church property to the presbytery. Under this trust clause, the presbytery may assert a claim to the property of the congregation in the event of a congregational split, dissolution (closing), or disassociation from the PC(USA). This clause does not prevent particular churches from leaving the denomination, but if they do, they may not be entitled to any physical assets of that congregation unless by agreement with the presbytery. Recently this provision has been vigorously tested in courts of law.

In June 2004, the General Assembly met in Richmond, Virginia and adopted by a vote of 431–62 a resolution that called on the church's committee on Mission Responsibility through Investment (MRTI) "to initiate a process of phased, selective divestment in multinational corporations operating in Israel." The resolution also said "the occupation … has proven to be at the root of evil acts committed against innocent people on both sides of the conflict." The church statement at the time noted that "divestment is one of the strategies that U.S. churches used in the 1970s and 80s in a successful campaign to end apartheid in South Africa."

A second resolution, calling for an end to the construction of a wall by the state of Israel, passed. The resolution opposed to the construction of the Israeli West Bank barrier, regardless of its location, and opposed the United States government making monetary contribution to the construction. The General Assembly also adopted policies rejecting Christian Zionism and allowing the continued funding of conversionary activities aimed at Jews. Together, the resolutions caused tremendous dissent within the church and a sharp disconnect with the Jewish community. Leaders of several American Jewish groups communicated to the church their concerns about the use of economic leverages that apply specifically to companies operating in Israel. Some critics of the divestment policy accused church leaders of anti-Semitism.

In June 2006, after the General Assembly in Birmingham, Alabama changed policy (details), both pro-Israel and pro-Palestinian groups praised the resolution. Pro-Israel groups, who had written General Assembly commissioners to express their concerns about a corporate engagement/divestment strategy focused on Israel, praised the new resolution, saying that it reflected the church stepping back from a policy that singled out companies working in Israel. Pro-Palestinian groups said that the church maintained the opportunity to engage and potentially divest from companies that support the Israeli occupation, because such support would be considered inappropriate according to the customary MRTI process.

In August 2011, the American National Middle Eastern Presbyterian Caucus (NMEPC) endorsed the boycott, divestment, and sanctions (BDS) campaign against Israel.

In January 2014, The PC(USA) published "Zionism unsettled," which was commended as "a valuable opportunity to explore the political ideology of Zionism," One critic claimed it was anti-Zionist and characterised the Israeli-Palestinian as a conflict fueled by a 'pathology inherent in Zionism.' The Simon Wiesenthal Center described the study guide as 'a hit-piece outside all norms of interfaith dialogue. It is a compendium of distortions, ignorance and outright lies – that tragically has emanated too often from elites within this church'. The PC(USA) subsequently withdrew the publication from sale on its website.

On June 20, 2014 the General Assembly in Detroit approved a measure (310–303) calling for divestment from stock in Caterpillar, Hewlett-Packard and Motorola Solutions in protest of Israeli policies on the West Bank. The vote was immediately and sharply criticized by The American Jewish Committee which accused the General Assembly of acting out of anti Semitic motives. Proponents of the measure strongly denied the accusations.






</doc>
<doc id="25033" url="https://en.wikipedia.org/wiki?curid=25033" title="Piña colada">
Piña colada

The piña colada (; , "pineapple," and , "strained") is a sweet cocktail made with rum, coconut cream or coconut milk, and pineapple juice, usually served either blended or shaken with ice. It may be garnished with either a pineapple wedge, maraschino cherry, or both. The piña colada has been the national drink of Puerto Rico since 1978.

The name "piña colada" literally means "strained pineapple", a reference to the freshly pressed and strained pineapple juice used in the drink's preparation.

Two bartenders from Puerto Rico won a contest for the ownership of their national drink. Ramón "Monchito" Marrero Pérez claims to have first made it at the Caribe Hilton Hotel's Beachcomber Bar in San Juan in 1954, using Don Q Gold rum and the then newly-available "coco lópez" cream of coconut. "Coco lópez" was developed in Puerto Rico in 1948 by Don Ramón López-Irizarry, hence the Puerto Rican connection and the 1952 account of the drink's creation. Some say the drink did not acquire its name until the 1960s.

The Caribe Hilton Hotel sits on a peninsula outside San Juan and was the first luxury hotel to open in the region, becoming a popular destination for the rich and famous who helped spread word of the drink.

Ramón Portas Mingot also says he created it in 1963 at the Barrachina Restaurant, 104 Fortaleza Street, Old San Juan. The restaurant stands by his claim to this day.

National Piña Colada Day is celebrated on the islands on 10 July.

The earliest known story states that in the 19th century, Puerto Rican pirate Roberto Cofresí, to boost his crew's morale, gave them a beverage or cocktail that contained coconut, pineapple and white rum. This was what would be later known as the famous piña colada. With his death in 1825, the recipe for the piña colada was lost.

Ramón "Monchito" Marrero claims to have created the Piña Colada in 1954, when a bartender at the Caribe Hilton. After three months of experimentation, Mr. Marrero finally settled upon the recipe for the Piña Colada, which he felt captured the true nature and essence of Puerto Rico. He continued to serve the drink at the Caribe Hilton for 35 years after its creation and was finally rewarded for his efforts in 1978 when Puerto Rico officially proclaimed the cocktail its national drink.

Caribe Hilton possesses two proclamations that state the hotel is the "Birthplace of the Piña Colada". One proclamation was given by Puerto Rico Governor Sila M. Calderón in 2000, and the other was given in 2014 by Governor Alejandro García Padilla as part of the Piña Colada 60th Anniversary celebrations.

The remodeled Caribe Hilton Bar, Caribar Rums & Light Bites, provides a new menu reflecting the Evolution of the Piña Colada, including a contemporary version: the Clear Colada.

Barrachina, a restaurant in Puerto Rico, also claims to be the birthplace of the piña colada:In 1963, on a trip to South America, Barrachina met another popular Spaniard and bartender Ramon Portas Mingot. Don Ramon has worked with the best places in Buenos Aires and associated with "Papillon" the most luxurious bar in Carcao and was also recognized for his cocktail recipe books. Pepe Barrachina and Don Ramon developed a great relationship. While working as the main bartender at Barrachina (a restaurant in Puerto Rico), Ramon mixed pineapple juice, coconut cream, condensed milk and ice in a blender, creating a delicious and refreshing drink, known today as the Piña Colada.
This cocktail gained fame in Puerto Rico from 1978, and it gained worldwide fame after Rupert Holmes released his 1979 song, "Escape (The Piña Colada Song)", which became a popular hit around the world.

Jazz icon and flugelhorn player Chuck Mangione likewise released a tune titled Piña Colada in his 1979 album "Fun and Games".

In "The Godfather Part II" (1974), in the scenes set in Cuba, the characters are offered Piña Coladas several times, even though it is set in 1956 and the drink is said not to have been named as such until at least the 1960s.

The cocktail serves as part of the title of the Garth Brooks song "Two Pina Coladas".

There are many recipes of how to make a piña colada but the one that his friends tell in the book of José L. Díaz de Villegas to be the original recipe created by Monchito, is the following:

Pour 85 grams of coconut cream, 170 grams of pineapple juice and 43 grams of white rum into a blender or shaker with crushed ice, and blend or shake very well until smooth. Pour into chilled glass, garnish with pineapple wedge and/or a maraschino cherry.

Different proportions of the core ingredients, as well as different types of rum, may all be used in the piña colada. Frozen piña coladas are also served. Other named variations include:
Staten Island Ferry is a cocktail consisting of equal parts Malibu rum and pineapple juice served over ice. In flavor it resembles a Piña Colada (due to the coconut flavor of Malibu rum). As it does not require coconut cream, it is thus more easily prepared in bars that lack the specialty ingredients and blender that a Piña Colada would typically require.

Variants of Blue Hawaii with creme of coconut differ from piña colada mainly by including also blue Curaçao.



</doc>
<doc id="25034" url="https://en.wikipedia.org/wiki?curid=25034" title="PackBits">
PackBits

PackBits is a fast, simple lossless compression scheme for run-length encoding of data.

Apple introduced the PackBits format with the release of MacPaint on the Macintosh computer. This compression scheme is one of the types of compression that can be used in TIFF-files. TGA-files also use this RLE compression scheme, but treats data stream as pixels instead of bytes.

A PackBits data stream consists of packets with a one-byte header followed by data. The header is a signed byte; the data can be signed, unsigned, or packed (such as <nowiki>MacPaint</nowiki> pixels).

In the following table, "n" is the value of the header byte as a signed integer.
Note that interpreting 0 as positive or negative makes no difference in the output. Runs of two bytes adjacent to non-runs are typically written as literal data. It should also be noted that there is no way based on the PackBits data to determine the end of the data stream; that is to say, one must already know the size of the compressed or uncompressed data before reading a PackBits data stream to know where it ends.

Apple Computer (see the external link) provides this short example of packed data:
codice_1

The following code, written in Microsoft VBA, unpacks the data:
The same implementation in JS:



</doc>
<doc id="25036" url="https://en.wikipedia.org/wiki?curid=25036" title="Pub rock (Australia)">
Pub rock (Australia)

Pub rock is a style of Australian rock and roll popular throughout the 1970s and 1980s, and still influencing contemporary Australian music in the 2000s decade. The term came from the venues where most of these bands originally played — inner-city and suburban pubs. These often noisy, hot, small and crowded venues were not always ideal as music venues and favoured loud, simple songs based on drums and electric guitar riffs.

The Australian version of pub rock incorporates hard rock, blues rock, and/or progressive rock. In the "Encyclopedia of Australian Rock and Pop" (1999), Australian musicologist Ian McFarlane described how, in the early 1970s, Billy Thorpe & The Aztecs, Blackfeather, and Buffalo pioneered Australia's pub rock movement. Australian rock music journalist Ed Nimmervoll declared that "[t]he seeds for Australian heavy rock can be traced back to two important sources, Billy Thorpe's Seventies Aztecs and Sydney band Buffalo".

The emergence of the Australian version of the pub rock genre and the related pub circuit was the result of several interconnected factors. From the 1950s to the 1970s, mainly because of restrictive state liquor licensing laws, only a small proportion of live pop and rock music in Australia was performed on licensed premises (mostly private clubs or discotheques); the majority of concerts were held in non-licensed venues like community, church or municipal halls. These concerts and dances were 'all-ages' events—often with adult supervision—and alcohol was not served.

During the 1960s, however, Australian states began liberalising their licensing laws. Sunday Observance Acts were repealed, pub opening hours were extended, discriminatory regulations — such as the long-standing ban on women entering or drinking in public bars — were removed, and in the 1970s the age of legal majority was lowered from 21 to 18. Concurrently, the members of the so-called "Baby Boomer" generation — who were the main audience for pop and rock music — were reaching their late teens and early twenties, and were thus able to enter such licensed premises. Pub owners soon realised that providing live music (which was often free) would draw young people to pubs in large numbers, and regular rock performances soon became a fixture at many pubs.

In the early 1970s Billy Thorpe & The Aztecs, Blackfeather, and Buffalo pioneered Australia's pub rock movement. In March 1970 Billy Thorpe & The Aztecs consisted of Thorpe on lead vocals and guitar, Jimmy Thompson on drums, Paul Wheeler on bass guitar and Lobby Loyde (ex-Purple Hearts, Wild Cherries) on lead guitar. They released a cover version of Willie Dixon's "Good Mornin' Little School Girl". They had developed a heavier sound and in July that year, Warren `Pig' Morgan (piano, backing vocals) had joined and the band recorded "The Hoax Is Over", which was released in January 1971. Thorpe described their sound "[It was] like we were standing on a pair of Boeing 747 engines. It cracked the foundations and broke windows in neighbouring buildings".

By early 1971 Blackfeather consisted of Neale Johns on lead vocals, John Robinson on lead guitar (ex-Lonely Ones, Monday's Children, Dave Miller Set), Robert Fortesque on bass guitar and Alexander Kash on drums. Their debut album, "At the Mountains of Madness", appeared in April 1971. In May they had a hit with "Seasons of Change", which peaked at No. 15 on the "Go-Set" National Top 40 Singles Chart. Buffalo formed in August 1971 by Dave Tice on co-lead vocals (ex-Head) with Paul Balbi on drums, John Baxter on guitar, and Peter Wells on bass guitar. Their debut album, "Dead Forever...", appeared in June the following year. According to Australian rock music journalist, Ed Nimmervoll, "The seeds for Australian heavy rock can be traced back to two important sources, Billy Thorpe's Seventies Aztecs and Sydney band Buffalo".

Many city and suburban pubs gained renown for their support of live music, and many prominent Australian bands — including AC/DC, Cold Chisel, The Angels and The Dingoes — developed their style at these venues in the early days of their careers. Australian musicologist, Ian McFarlane, described how AC/DC took "the raw energy of Aussie pub rock, extend its basic guidelines, serve it up to a teenybop "Countdown" audience and still reap the benefits of the live circuit by packing out the pubs". He found that Cold Chisel "fused a combination of rockabilly, hard rock and rough-house soul'n'blues that was defiantly Australian in outlook". He noted The Angels had "a profound effect on the Australian live music scene of the late 1970s/early 1980s. [They] helped redefine the Australian pub rock tradition ... [their] brand of no-frills, hard-driving boogie rock attracted pub goers in unprecedented numbers". The Dingoes provided a "spirited combination of R&B, country and red-hot rock'n'roll was imbued with a delightful sense of time and place" according to McFarlane.

Notable pub rock venues include the Largs Pier Hotel and the Governor Hindmarsh Hotel in Adelaide, the Royal Antler Hotel in Narrabeen, Sydney and the Civic Hotel in Sydney's city centre, the Star Hotel in Newcastle, New South Wales and the Station Hotel in Prahran, Melbourne, which was one of the premier pub-rock venues in Australia for more than two decades, Poyntons Carlton Club Hotel in Carlton Melbourne's first Sunday night live pub rock venue.

As the pub rock phenomenon expanded, hundreds of hotels in capital cities and major towns began providing regular live music, and a thriving circuit evolved, enabling bands to tour up and down the eastern and southern coast of Australia from North Queensland to South Australia.

It could be argued that the very venues many of the bands played in (pubs), had a major influence on the evolution of their music and sound. The venues were more often than not small and the crowds — alcohol-fuelled — were there for the experience rather than to see a "name band". Thus, an emphasis on simple, rhythm-based songs grew. With the sound in many of the rooms far from ideal for live music, an emphasis on a very loud snare and kick-drum and driving bass-guitar grew. Guitarists tended to rely on simple, repetitive riffs, rather than more complex solos or counter-melodies. This might explain why, even in studios and larger arenas and stadiums, many of the bands who originated in pubs relied on an exaggerated drum sound and fairly simple musical arrangements.

A band like Hunters & Collectors, for example, saw their sound harden from their arty origins (which included a brass-section, experimental percussion and complex arrangements) to a more straightforward rock sound with emphasis on drums, bass and simple guitar riffs; a sound that more suited the beer barns they were to play in over their extensive touring career.

Though Australia has a relatively small population, the proportionally high number of venues that bands could play in, mainly along the Eastern coast, meant that a band could tour extensively, often playing every night for long periods. This would allow bands such as AC/DC, Cold Chisel, INXS, Midnight Oil, Rose Tattoo and others to take their live skills into large venues in the US and Europe with ease.




</doc>
<doc id="25037" url="https://en.wikipedia.org/wiki?curid=25037" title="Phonation">
Phonation

The term phonation has slightly different meanings depending on the subfield of phonetics. Among some phoneticians, "phonation" is the process by which the vocal folds produce certain sounds through quasi-periodic vibration. This is the definition used among those who study laryngeal anatomy and physiology and speech production in general. Phoneticians in other subfields, such as linguistic phonetics, call this process "voicing", and use the term "phonation" to refer to any oscillatory state of any part of the larynx that modifies the airstream, of which voicing is just one example. Voiceless and supra-glottal phonations are included under this definition.
The phonatory process, or voicing, occurs when air is expelled from the lungs through the glottis, creating a pressure drop across the larynx. When this drop becomes sufficiently large, the vocal folds start to oscillate. The minimum pressure drop required to achieve phonation is called the phonation threshold pressure, and for humans with normal vocal folds, it is approximately 2–3 cm HO. The motion of the vocal folds during oscillation is mostly lateral, though there is also some superior component as well. However, there is almost no motion along the length of the vocal folds. The oscillation of the vocal folds serves to modulate the pressure and flow of the air through the larynx, and this modulated airflow is the main component of the sound of most voiced phones.

The sound that the larynx produces is a harmonic series. In other words, it consists of a fundamental tone (called the fundamental frequency, the main acoustic cue for the percept pitch) accompanied by harmonic overtones, which are multiples of the fundamental frequency. According to the source–filter theory, the resulting sound excites the resonance chamber that is the vocal tract to produce the individual speech sounds.

The vocal folds will not oscillate if they are not sufficiently close to one another, are not under sufficient tension or under too much tension, or if the pressure drop across the larynx is not sufficiently large. In linguistics, a phone is called voiceless if there is no phonation during its occurrence. In speech, voiceless phones are associated with vocal folds that are elongated, highly tensed, and placed laterally (abducted) when compared to vocal folds during phonation.

Fundamental frequency, the main acoustic cue for the percept "pitch", can be varied through a variety of means. Large scale changes are accomplished by increasing the tension in the vocal folds through contraction of the cricothyroid muscle. Smaller changes in tension can be effected by contraction of the thyroarytenoid muscle or changes in the relative position of the thyroid and cricoid cartilages, as may occur when the larynx is lowered or raised, either volitionally or through movement of the tongue to which the larynx is attached via the hyoid bone. In addition to tension changes, fundamental frequency is also affected by the pressure drop across the larynx, which is mostly affected by the pressure in the lungs, and will also vary with the distance between the vocal folds. Variation in fundamental frequency is used linguistically to produce intonation and tone.

There are currently two main theories as to how vibration of the vocal folds is initiated: the myoelastic theory and the aerodynamic theory. These two theories are not in contention with one another and it is quite possible that both theories are true and operating simultaneously to initiate and maintain vibration. A third theory, the neurochronaxic theory, was in considerable vogue in the 1950s, but has since been largely discredited.

The myoelastic theory states that when the vocal cords are brought together and breath pressure is applied to them, the cords remain closed until the pressure beneath them, the subglottic pressure, is sufficient to push them apart, allowing air to escape and reducing the pressure enough for the muscle tension recoil to pull the folds back together again. The pressure builds up once again until the cords are pushed apart, and the whole cycle keeps repeating itself. The rate at which the cords open and close, the number of cycles per second, determines the pitch of the phonation.

The aerodynamic theory is based on the Bernoulli energy law in fluids. The theory states that when a stream of breath is flowing through the glottis while the arytenoid cartilages are held together (by the action of the interarytenoid muscles), a push-pull effect is created on the vocal fold tissues that maintains self-sustained oscillation. The push occurs during glottal opening, when the glottis is convergent, and the pull occurs during glottal closing, when the glottis is divergent. Such an effect causes a transfer of energy from the airflow to the vocal fold tissues which overcomes losses by dissipation and sustain the oscillation. The amount of lung pressure needed to begin phonation is defined by Titze as the oscillation threshold pressure. During glottal closure, the air flow is cut off until breath pressure pushes the folds apart and the flow starts up again, causing the cycles to repeat.
The textbook entitled Myoelastic Aerodynamic Theory of Phonation by Ingo Titze credits Janwillem van den Berg as the originator of the theory and provides detailed mathematical development of the theory.

This theory states that the frequency of the vocal fold vibration is determined by the chronaxie of the recurrent nerve, and not by breath pressure or muscular tension. Advocates of this theory thought that every single vibration of the vocal folds was due to an impulse from the recurrent laryngeal nerves and that the acoustic center in the brain regulated the speed of vocal fold vibration. Speech and voice scientists have long since left this theory as the muscles have been shown to not be able to contract fast enough to accomplish the vibration. In addition, persons with paralyzed vocal folds can produce phonation, which would not be possible according to this theory. Phonation occurring in excised larynges would also not be possible according to this theory.

In linguistic phonetic treatments of phonation, such as those of Peter Ladefoged, phonation was considered to be a matter of points on a continuum of tension and closure of the vocal cords. More intricate mechanisms were occasionally described, but they were difficult to investigate, and until recently the state of the glottis and phonation were considered to be nearly synonymous.

If the vocal cords are completely relaxed, with the arytenoid cartilages apart for maximum airflow, the cords do not vibrate. This is voiceless phonation, and is extremely common with obstruents. If the arytenoids are pressed together for glottal closure, the vocal cords block the airstream, producing stop sounds such as the glottal stop. In between there is a sweet spot of maximum vibration. Also, the existence of an optimal glottal shape for ease of phonation has been shown, at which the lung pressure required to initiate the vocal cord vibration is minimum. This is modal voice, and is the normal state for vowels and sonorants in all the world's languages. However, the aperture of the arytenoid cartilages, and therefore the tension in the vocal cords, is one of degree between the end points of open and closed, and there are several intermediate situations utilized by various languages to make contrasting sounds.

For example, Gujarati has vowels with a partially lax phonation called breathy voice or murmured, while Burmese has vowels with a partially tense phonation called creaky voice or laryngealized. Both of these phonations have dedicated IPA diacritics, an under-umlaut and under-tilde. The Jalapa dialect of Mazatec is unusual in contrasting both with modal voice in a three-way distinction. (Note that Mazatec is a tonal language, so the glottis is making several tonal distinctions simultaneously with the phonation distinctions.)

The following different positions can be found:
A: Glottis closure,
B: phonation position,
C: whisper position,
D: breath position;
E: respiratory position or resting position;
F: deep breathing position

Javanese does not have modal voice in its stops, but contrasts two other points along the phonation scale, with more moderate departures from modal voice, called slack voice and stiff voice. The "muddy" consonants in Shanghainese are slack voice; they contrast with tenuis and aspirated consonants.

Although each language may be somewhat different, it is convenient to classify these degrees of phonation into discrete categories. A series of seven alveolar stops, with phonations ranging from an open/lax to a closed/tense glottis, are:

The IPA diacritics "under-ring" and "subscript wedge", commonly called "voiceless" and "voiced", are sometimes added to the symbol for a voiced sound to indicate more lax/open (slack) and tense/closed (stiff) states of the glottis, respectively. (Ironically, adding the 'voicing' diacritic to the symbol for a voiced consonant indicates "less" modal voicing, not more, because a modally voiced sound is already fully voiced, at its sweet spot, and any further tension in the vocal cords dampens their vibration.)

Alsatian, like several Germanic languages, has a typologically unusual phonation in its stops. The consonants transcribed (ambiguously called "lenis") are partially voiced: The vocal cords are positioned as for voicing, but do not actually vibrate. That is, they are technically voiceless, but without the open glottis usually associated with voiceless stops. They contrast with both modally voiced and modally voiceless in French borrowings, as well as aspirated word initially.

If the arytenoid cartiledges are parted to admit turbulent airflow, the result is whisper phonation if the vocal folds are adducted, and whispery voice phonation (murmur) if the vocal folds vibrate modally. Whisper phonation is heard in many productions of French "oui!", and the "voiceless" vowels of many North American languages are actually whispered.

It has long been noted that in many languages, both phonologically and historically, the glottal consonants do not behave like other consonants. Phonetically, they have no manner or place of articulation other than the state of the glottis: "glottal closure" for , "breathy voice" for , and "open airstream" for . Some phoneticians have described these sounds as neither glottal nor consonantal, but instead as instances of pure phonation, at least in many European languages. However, in Semitic languages they do appear to be true glottal consonants.

In the last few decades it has become apparent that phonation may involve the entire larynx, with as many as six valves and muscles working either independently or together. From the glottis upward, these articulations are:

Until the development of fiber-optic laryngoscopy, the full involvement of the larynx during speech production was not observable, and the interactions among the six laryngeal articulators is still poorly understood. However, at least two supra-glottal phonations appear to be widespread in the world's languages. These are harsh voice ('ventricular' or 'pressed' voice), which involves overall constriction of the larynx, and faucalized voice ('hollow' or 'yawny' voice), which involves overall expansion of the larynx.

The Bor dialect of Dinka has contrastive modal, breathy, faucalized, and harsh voice in its vowels, as well as three tones. The "ad hoc" diacritics employed in the literature are a subscript double quotation mark for faucalized voice, , and underlining for harsh voice, . Examples are,

Other languages with these contrasts are Bai (modal, breathy, and harsh voice), Kabiye (faucalized and harsh voice, previously seen as ±ATR), Somali (breathy and harsh voice).

Elements of laryngeal articulation or phonation may occur widely in the world's languages as phonetic detail even when not phonemically contrastive. For example, simultaneous glottal, ventricular, and arytenoid activity (for something other than epiglottal consonants) has been observed in Tibetan, Korean, Nuuchahnulth, Nlaka'pamux, Thai, Sui, Amis, Pame, Arabic, Tigrinya, Cantonese, and Yi.

In languages such as French, all obstruents occur in pairs, one modally voiced and one voiceless: [b] [d] [g] [v] [z] [ʒ] → [p] [t] [k] [f] [s] [ʃ].

In English, every voiced fricative corresponds to a voiceless one. For the pairs of English stops, however, the distinction is better specified as voice onset time rather than simply voice: In initial position, /b d g/ are only partially voiced (voicing begins during the hold of the consonant), and /p t k/ are aspirated (voicing begins only well after its release). Certain English morphemes have voiced and voiceless allomorphs, such as: the plural, verbal, and possessive endings spelled "-s" (voiced in "kids" but voiceless in "kits" ), and the past-tense ending spelled "-ed" (voiced in "buzzed" but voiceless in "fished" ).

A few European languages, such as Finnish, have no phonemically voiced obstruents but pairs of long and short consonants instead. Outside Europe, the lack of voicing distinctions is common; indeed, in Australian languages it is nearly universal. In languages without the distinction between voiceless and voiced obstruents, they are realized as voiced in voiced environments, such as between vowels, and voiceless elsewhere.

In phonology, a register is a combination of tone and vowel phonation into a single phonological parameter. For example, among its vowels, Burmese combines modal voice with low tone, breathy voice with falling tone, creaky voice with high tone, and glottal closure with high tone. These four registers contrast with each other, but no other combination of phonation (modal, breath, creak, closed) and tone (high, low, falling) is found.

Among vocal pedagogues and speech pathologists, a vocal register also refers to a particular phonation limited to a particular range of pitch, which possesses a characteristic sound quality. The term "register" may be used for several distinct aspects of the human voice:


Four combinations of these elements are identified in speech pathology: the vocal fry register, the modal register, the falsetto register, and the whistle register.




</doc>
<doc id="25039" url="https://en.wikipedia.org/wiki?curid=25039" title="Principal ideal domain">
Principal ideal domain

In abstract algebra, a principal ideal domain, or PID, is an integral domain in which every ideal is principal, i.e., can be generated by a single element. More generally, a principal ideal ring is a nonzero commutative ring whose ideals are principal, although some authors (e.g., Bourbaki) refer to PIDs as principal rings. The distinction is that a principal ideal ring may have zero divisors whereas a principal ideal domain cannot.

Principal ideal domains are thus mathematical objects that behave somewhat like the integers, with respect to divisibility: any element of a PID has a unique decomposition into prime elements (so an analogue of the fundamental theorem of arithmetic holds); any two elements of a PID have a greatest common divisor (although it may not be possible to find it using the Euclidean algorithm). If "x" and "y" are elements of a PID without common divisors, then every element of the PID can be written in the form "ax" + "by".

Principal ideal domains are noetherian, they are integrally closed, they are unique factorization domains and Dedekind domains. All Euclidean domains and all fields are principal ideal domains.

Principal ideal domains appear in the following chain of class inclusions:

Examples include:

Examples of integral domains that are not PIDs:

The key result is the structure theorem: If "R" is a principal ideal domain, and "M" is a finitely
generated "R"-module, then formula_3 is a direct sum of cyclic modules, i.e., modules with one generator. The cyclic modules are isomorphic to formula_4 for some formula_5 (notice that formula_6 may be equal to formula_7, in which case formula_4 is formula_9).

If "M" is a free module over a principal ideal domain "R", then every submodule of "M" is again free. This does not hold for modules over arbitrary rings, as the example formula_10 of modules over formula_11 shows.

In a principal ideal domain, any two elements "a","b" have a greatest common divisor, which may be obtained as a generator of the ideal "(a,b)".

All Euclidean domains are principal ideal domains, but the converse is not true.
An example of a principal ideal domain that is not a Euclidean domain is the ring formula_12 

Every principal ideal domain is a unique factorization domain (UFD). The converse does not hold since for any UFD "K", "K"["X","Y"] (the rings of polynomials in 2 variables) is a UFD but is not a PID. (To prove this look at the ideal generated by formula_15 It is not the whole ring since it contains no polynomials of degree 0, but it cannot be generated by any one single element.)


The previous three statements give the definition of a Dedekind domain, and hence every principal ideal domain is a Dedekind domain.

Let "A" be an integral domain. Then the following are equivalent.


A field norm is a Dedekind-Hasse norm; thus, (5) shows that a Euclidean domain is a PID. (4) compares to:
An integral domain is a Bézout domain if and only if any two elements in it have a gcd "that is a linear combination of the two." A Bézout domain is thus a GCD domain, and (4) gives yet another proof that a PID is a UFD.





</doc>
<doc id="25040" url="https://en.wikipedia.org/wiki?curid=25040" title="Pioneer program">
Pioneer program

The Pioneer program is a series of United States unmanned space missions that were designed for planetary exploration. There were a number of such missions in the program, but the most notable were Pioneer 10 and Pioneer 11, which explored the outer planets and left the solar system. Pioneer 10 and Pioneer 11 carry a golden plaque, depicting a man and a woman and information about the origin and the creators of the probes, should any extraterrestrials find them someday.

Credit for naming the first probe has been attributed to Stephen A. Saliga, who had been assigned to the Air Force Orientation Group, Wright-Patterson AFB, as chief designer of Air Force exhibits. While he was at a briefing, the spacecraft was described to him, as, a "lunar-orbiting vehicle, with an infrared scanning device." Saliga thought the title too long, and lacked theme for an exhibit design. He suggested, "Pioneer", as the name of the probe, since "the Army had already launched and orbited the Explorer satellite, and their Public Information Office was identifying the Army, as, 'Pioneers in Space,'" and, by adopting the name, the Air Force would "make a 'quantum jump' as to who, really, [were] the 'Pioneers' in space.'"

The earliest missions were attempts to achieve Earth's escape velocity, simply to show it was feasible and study the Moon. This included the first launch by NASA which was formed from the old NACA. These missions were carried out by the US Air Force and Army.



Five years after the early Able space probe missions ended, NASA Ames Research Center used the Pioneer name for a new series of missions, initially aimed at the inner Solar System, before the bold flyby missions to Jupiter and Saturn. While successful, the missions returned much poorer images than the Voyager program probes would five years later. In 1978, the end of the program saw a return to the inner Solar System, with the Pioneer Venus Orbiter and Multiprobe, this time using orbital insertion rather than flyby missions.

The new missions were numbered beginning with Pioneer 6 (alternate names in parentheses).

The spacecraft in Pioneer missions 6, 7, 8, and 9 comprised a new interplanetary space weather network:
Pioneer 6 and Pioneer 9 are in solar orbits with 0.8 AU distance to the Sun. Their orbital periods are therefore slightly shorter than Earth's. Pioneer 7 and Pioneer 8 are in solar orbits with 1.1 AU distance to the Sun. Their orbital periods are therefore slightly longer than Earth's. Since the probes' orbital periods differ from that of the Earth, from time to time, they face a side of the Sun that cannot be seen from Earth. The probes can sense parts of the Sun several days before the Sun's rotation reveals it to ground-based Earth orbiting observatories.






</doc>
<doc id="25041" url="https://en.wikipedia.org/wiki?curid=25041" title="Lockheed P-38 Lightning">
Lockheed P-38 Lightning

The Lockheed P-38 Lightning is a World War II-era American piston-engined fighter aircraft. Developed for the United States Army Air Corps, the P-38 had distinctive twin booms and a central nacelle containing the cockpit and armament. Allied propaganda claimed it had been nicknamed the fork-tailed devil () by the Luftwaffe and by the Japanese. The P-38 was used for interception, dive bombing, level bombing, ground attack, night fighting, photo reconnaissance, radar and visual pathfinding for bombers and evacuation missions, and extensively as a long-range escort fighter when equipped with drop tanks under its wings.

The P-38 was used most successfully in the Pacific Theater of Operations and the China-Burma-India Theater of Operations as the aircraft of America's top aces, Richard Bong (40 victories), Thomas McGuire (38 victories) and Charles H. MacDonald (27 victories). In the South West Pacific theater, the P-38 was the primary long-range fighter of United States Army Air Forces until the appearance of large numbers of P-51D Mustangs toward the end of the war.

The P-38 was unusually quiet for a fighter, since the exhaust was muffled by the turbo-superchargers. It was extremely forgiving and could be mishandled in many ways but the rate of roll in the early versions was too low for it to excel as a dogfighter. The P-38 was the only American fighter aircraft in large-scale production throughout American involvement in the war, from Pearl Harbor to Victory over Japan Day. At the end of the war, orders for 1,887 more were cancelled.

Lockheed designed the P-38 in response to a February 1937 specification from the United States Army Air Corps. Circular Proposal X-608 was a set of aircraft performance goals authored by First Lieutenants Benjamin S. Kelsey and Gordon P. Saville for a twin-engine, high-altitude "interceptor" having "the tactical mission of interception and attack of hostile aircraft at high altitude." In 1977, Kelsey recalled he and Saville drew up the specification using the word "interceptor" as a way to bypass the inflexible Army Air Corps requirement for pursuit aircraft to carry no more than of armament including ammunition, as well as the restriction of single-seat aircraft to one engine. Kelsey was looking for a minimum of of armament. Kelsey and Saville aimed to get a more capable fighter, better at dog-fighting and at high-altitude combat. Specifications called for a maximum airspeed of at least at altitude, and a climb to within six minutes, the toughest set of specifications USAAC had ever presented. The unbuilt Vultee XP1015 was designed to the same requirement, but was not advanced enough to merit further investigation. A similar single-engine proposal was issued at the same time, Circular Proposal X-609, in response to which the Bell P-39 Airacobra was designed. Both proposals required liquid-cooled Allison V-1710 engines with turbo-superchargers and gave extra points for tricycle landing gear.

The Lockheed design team, under the direction of Hall Hibbard and Clarence "Kelly" Johnson, considered a range of twin-engine configurations, including both engines in a central fuselage with push–pull propellers.

The eventual configuration was rare in terms of contemporary fighter aircraft design, with only the preceding Fokker G.1, the contemporary Focke-Wulf Fw 189 Luftwaffe reconnaissance aircraft, and the later Northrop P-61 Black Widow night fighter having a similar planform. The Lockheed team chose twin booms to accommodate the tail assembly, engines, and turbo-superchargers, with a central nacelle for the pilot and armament. The XP-38 gondola mockup was designed to mount two .50-caliber (12.7 mm) M2 Browning machine guns with 200 rounds per gun (rpg), two .30-caliber (7.62 mm) Brownings with 500 rpg, and a T1 Army Ordnance 23 mm (.90 in) autocannon with a rotary magazine as a substitute for the non-existent 25 mm Hotchkiss aircraft autocannon specified by Kelsey and Saville. In the YP-38s, a 37 mm (1.46 in) M9 autocannon with 15 rounds replaced the T1. The 15 rounds were in three five-round clips, an unsatisfactory arrangement according to Kelsey, and the M9 did not perform reliably in flight. Further armament experiments from March to June 1941 resulted in the P-38E combat configuration of four M2 Browning machine guns, and one Hispano 20 mm (.79 in) autocannon with 150 rounds.

Clustering all the armament in the nose was unusual in U.S. aircraft, which typically used wing-mounted guns with trajectories set up to crisscross at one or more points in a convergence zone. Nose-mounted guns did not suffer from having their useful ranges limited by pattern convergence, meaning that good pilots could shoot much farther. A Lightning could reliably hit targets at any range up to , whereas the wing guns of other fighters were optimized for a specific range. The rate of fire was about 650 rounds per minute for the 20×110 mm cannon round (130-gram shell) at a muzzle velocity of about , and for the .50-caliber machine guns (43-gram rounds), about 850 rpm at velocity. Combined rate of fire was over 4,000 rpm with roughly every sixth projectile a 20 mm shell. The duration of sustained firing for the 20 mm cannon was approximately 14 seconds while the .50-caliber machine guns worked for 35 seconds if each magazine was fully loaded with 500 rounds, or for 21 seconds if 300 rounds were loaded to save weight for long distance flying.

The Lockheed design incorporated tricycle undercarriage and a bubble canopy, and featured two turbosupercharged 12-cylinder Allison V-1710 engines fitted with counter-rotating propellers to eliminate the effect of engine torque, with the turbochargers positioned behind the engines, the exhaust side of the units exposed along the dorsal surfaces of the booms. Counter-rotation was achieved by the use of "handed" engines, which meant the crankshaft of each engine turned in the opposite direction of its counterpart, a relatively easy task for a modular-design aircraft powerplant as the V-1710.

The P-38 was the first American fighter to make extensive use of stainless steel and smooth, flush-riveted butt-jointed aluminum skin panels. It was also the first military airplane to fly faster than in level flight.

Lockheed won the competition on 23 June 1937 with its Model 22 and was contracted to build a prototype XP-38 for US$163,000, though Lockheed's own costs on the prototype would add up to US$761,000. Construction began in July 1938, and the XP-38 first flew on 27 January 1939 at the hands of Ben Kelsey.

Kelsey then proposed a speed dash to Wright Field on 11 February 1939 to relocate the aircraft for further testing. General Henry "Hap" Arnold, commander of the USAAC, approved of the record attempt and recommended a cross-country flight to New York. The flight set a speed record by flying from California to New York in seven hours and two minutes, not counting two refueling stops, but the aircraft was downed by carburetor icing short of the Mitchel Field runway in Hempstead, New York and was wrecked. However, on the basis of the record flight, the Air Corps ordered 13 YP-38s on 27 April 1939 for US$134,284 each. (The "Y" in "YP" was the USAAC's designation for a prototype, while the "X" in "XP" was for experimental.) Lockheed's Chief test pilot Tony LeVier angrily characterized the accident as an unnecessary publicity stunt, but according to Kelsey, the loss of the prototype, rather than hampering the program, sped the process by cutting short the initial test series. The success of the aircraft design contributed to Kelsey's promotion to captain in May 1939.
Manufacture of YP-38s fell behind schedule, at least partly because of the need for mass-production suitability making them substantially different in construction from the prototype. Another factor was the sudden required expansion of Lockheed's facility in Burbank, taking it from a specialized civilian firm dealing with small orders to a large government defense contractor making Venturas, Harpoons, Lodestars, Hudsons, and designing the Constellation for TWA. The first YP-38 was not completed until September 1940, with its maiden flight on 17 September. The 13th and final YP-38 was delivered to the Air Corps in June 1941; 12 aircraft were retained for flight testing and one for destructive stress testing. The YPs were substantially redesigned and differed greatly in detail from the hand-built XP-38. They were lighter and included changes in engine fit. The propeller rotation was reversed, with the blades spinning outward (away from the cockpit) at the top of their arc, rather than inward as before. This improved the aircraft's stability as a gunnery platform.

Test flights revealed problems initially believed to be tail flutter. During high-speed flight approaching Mach 0.68, especially during dives, the aircraft's tail would begin to shake violently and the nose would tuck under (see Mach tuck), steepening the dive. Once caught in this dive, the fighter would enter a high-speed compressibility stall and the controls would lock up, leaving the pilot no option but to bail out (if possible) or remain with the aircraft until it got down to denser air, where he might have a chance to pull out. During a test flight in May 1941, USAAC Major Signa Gilkey managed to stay with a YP-38 in a compressibility lockup, riding it out until he recovered gradually using elevator trim. Lockheed engineers were very concerned at this limitation but first had to concentrate on filling the current order of aircraft. In late June 1941, the Army Air Corps was renamed the U.S. Army Air Forces (USAAF), and a total of 65 Lightnings were finished for the service by September 1941 with more on the way for the USAAF, the Royal Air Force (RAF), and the Free French Air Force operating from England.

By November 1941, many of the initial assembly-line challenges had been met, which freed up time for the engineering team to tackle the problem of frozen controls in a dive. Lockheed had a few ideas for tests that would help them find an answer. The first solution tried was the fitting of spring-loaded servo tabs on the elevator trailing edge designed to aid the pilot when control yoke forces rose over , as would be expected in a high-speed dive. At that point, the tabs would begin to multiply the effort of the pilot's actions. The expert test pilot, 43-year-old Ralph Virden, was given a specific high-altitude test sequence to follow and was told to restrict his speed and fast maneuvering in denser air at low altitudes, since the new mechanism could exert tremendous leverage under those conditions. A note was taped to the instrument panel of the test craft underscoring this instruction. On 4 November 1941, Virden climbed into YP-38 #1 and completed the test sequence successfully, but 15 minutes later was seen in a steep dive followed by a high-G pullout. The tail unit of the aircraft failed at about during the high-speed dive recovery; Virden was killed in the subsequent crash. The Lockheed design office was justifiably upset, but their design engineers could only conclude that servo tabs were "not" the solution for loss of control in a dive. Lockheed still had to find the problem; the Army Air Forces personnel were sure it was flutter and ordered Lockheed to look more closely at the tail.

In 1941 flutter was a familiar engineering problem related to a too-flexible tail, but the P-38's empennage was completely skinned in aluminum rather than fabric and was quite rigid. At no time did the P-38 suffer from true flutter. To prove a point, one elevator and its vertical stabilizers were skinned with metal 63% thicker than standard, but the increase in rigidity made no difference in vibration. Army Lieutenant Colonel Kenneth B. Wolfe (head of Army Production Engineering) asked Lockheed to try external mass balances above and below the elevator, though the P-38 already had large mass balances elegantly placed within each vertical stabilizer. Various configurations of external mass balances were equipped, and dangerously steep test flights were flown to document their performance. Explaining to Wolfe in Report No. 2414, Kelly Johnson wrote "the violence of the vibration was unchanged and the diving tendency was naturally the same for all conditions." The external mass balances did not help at all. Nonetheless, at Wolfe's insistence, the additional external balances were a feature of every P-38 built from then on.
Johnson said in his autobiography that he pleaded with NACA to do model tests in its wind tunnel. They already had experience of models thrashing around violently at speeds approaching those requested and did not want to risk damaging their tunnel. Gen. Arnold, head of Army Air Forces, ordered them to run the tests, which were done up to Mach 0.74. The P-38's dive problem was revealed to be the center of pressure moving back toward the tail when in high-speed airflow. The solution was to change the geometry of the wing's lower surface when diving in order to keep lift within bounds of the top of the wing. In February 1943, quick-acting dive flaps were tried and proven by Lockheed test pilots. The dive flaps were installed outboard of the engine nacelles, and in action they extended downward 35° in 1.5 seconds. The flaps did not act as a speed brake; they affected the pressure distribution in a way that retained the wing's lift.

Late in 1943, a few hundred dive flap field modification kits were assembled to give North African, European and Pacific P-38s a chance to withstand compressibility and expand their combat tactics. Unfortunately, these crucial flaps did not always reach their destination. In March 1944, 200 dive flap kits intended for European Theater of Operations (ETO) P-38Js were destroyed in a mistaken identification incident in which an RAF fighter shot down the Douglas C-54 Skymaster (mistaken for an Fw 200) taking the shipment to England. Back in Burbank, P-38Js coming off the assembly line in spring 1944 were towed out to the ramp and modified in the open air. The flaps were finally incorporated into the production line in June 1944 on the last 210 P-38Js. Despite testing having proved the dive flaps effective in improving tactical maneuvers, a 14-month delay in production limited their implementation, with only the final half of all Lightnings built having the dive flaps installed as an assembly-line sequence.

Johnson later recalled:
Buffeting was another early aerodynamic problem. It was difficult to distinguish from compressibility as both were reported by test pilots as "tail shake". Buffeting came about from airflow disturbances ahead of the tail; the airplane would shake at high speed. Leading edge wing slots were tried as were combinations of filleting between the wing, cockpit and engine nacelles. Air tunnel test number 15 solved the buffeting completely and its fillet solution was fitted to every subsequent P-38 airframe. Fillet kits were sent out to every squadron flying Lightnings. The problem was traced to a 40% increase in air speed at the wing-fuselage junction where the thickness/chord ratio was highest. An airspeed of at could push airflow at the wing-fuselage junction close to the speed of sound. Filleting solved the buffeting problem for the P-38E and later models.

Another issue with the P-38 arose from its unique design feature of outwardly rotating (at the "tops" of the propeller arcs) counter-rotating propellers. Losing one of two engines in any twin-engine non-centerline thrust aircraft on takeoff creates sudden drag, yawing the nose toward the dead engine and rolling the wingtip down on the side of the dead engine. Normal training in flying twin-engine aircraft when losing an engine on takeoff is to push the remaining engine to full throttle to maintain airspeed; if a pilot did that in the P-38, regardless of which engine had failed, the resulting engine torque and p-factor force produced a sudden uncontrollable yawing roll, and the aircraft would flip over and hit the ground. Eventually, procedures were taught to allow a pilot to deal with the situation by reducing power on the running engine, feathering the prop on the failed engine, and then increasing power gradually until the aircraft was in stable flight. Single-engine takeoffs were possible, though not with a full fuel and ammunition load.

The engines were unusually quiet because the exhausts were muffled by the General Electric turbo-superchargers on the twin Allison V12s. There were early problems with cockpit temperature regulation; pilots were often too hot in the tropical sun as the canopy could not be fully opened without severe buffeting and were often too cold in northern Europe and at high altitude, as the distance of the engines from the cockpit prevented easy heat transfer. Later variants received modifications (such as electrically heated flight suits) to solve these problems.

On 20 September 1939, before the YP-38s had been built and flight tested, the USAAF ordered 66 initial production P-38 Lightnings, 30 of which were delivered to the USAAF in mid-1941, but not all these aircraft were armed. The unarmed aircraft were subsequently fitted with four .50 in (12.7 mm) machine guns (instead of the two .50 in/12.7 mm and two .30 in/7.62 mm of their predecessors) and a 37 mm (1.46 in) cannon. They also had armored glass, cockpit armor and fluorescent cockpit controls. One was completed with a pressurized cabin on an experimental basis and designated XP-38A. Due to reports the USAAF was receiving from Europe, the remaining 36 in the batch were upgraded with small improvements such as self-sealing fuel tanks and enhanced armor protection to make them combat-capable. The USAAF specified that these 36 aircraft were to be designated P-38D. As a result, there never were any P-38Bs or P-38Cs. The P-38D's main role was to work out bugs and give the USAAF experience with handling the type.

In March 1940, the French and the British, through the Anglo-French Purchasing Committee, ordered a total of 667 P-38s for US$100M, designated Model 322F for the French and Model 322B for the British. The aircraft would be a variant of the P-38E. The overseas Allies wished for complete commonality of Allison engines with the large numbers of Curtiss P-40 Tomahawks both nations had on order, and thus ordered the Model 322 twin right-handed engines instead of counter-rotating ones and without turbo-superchargers. Performance was supposed to be at . After the fall of France in June 1940, the British took over the entire order and gave the aircraft the service name "Lightning." By June 1941, the War Ministry had cause to reconsider their earlier aircraft specifications based on experience gathered in the Battle of Britain and The Blitz. British displeasure with the Lockheed order came to the fore in July, and on 5 August 1941 they modified the contract such that 143 aircraft would be delivered as previously ordered, to be known as "Lightning (Mark) I," and 524 would be upgraded to US-standard P-38E specifications with a top speed of at guaranteed, to be called "Lightning II" for British service. Later that summer an RAF test pilot reported back from Burbank with a poor assessment of the "tail flutter" situation, and the British cancelled all but three of the 143 Lightning Is. As a loss of approximately US$15M was involved, Lockheed reviewed their contracts and decided to hold the British to the original order. Negotiations grew bitter and stalled. Everything changed after the 7 December, 1941 attack on Pearl Harbor after which the United States government seized some 40 of the Model 322s for West Coast defense; subsequently all British Lightnings were delivered to the USAAF starting in January 1942. The USAAF lent the RAF three of the aircraft, which were delivered by sea in March 1942 and were test flown no earlier than May at Cunliffe-Owen Aircraft Swaythling, the Aeroplane and Armament Experimental Establishment and the Royal Aircraft Establishment. The A&AEE example was unarmed, lacked turbochargers and restricted to ; though the undercarriage was praised and flight on one engine described as comfortable. These three were subsequently returned to the USAAF; one in December 1942 and the others in July 1943. Of the remaining 140 Lightning Is, 19 were not modified and were designated by the USAAF as RP-322-I ('R' for 'Restricted', because non-counter-rotating propellers were considered more dangerous on takeoff), while 121 were converted to non-turbo-supercharged counter-rotating V-1710F-2 engines and designated P-322-II. All 121 were used as advanced trainers; a few were still serving that role in 1945. A few RP-322s were later used as test modification platforms such as for smoke-laying canisters. The RP-322 was a fairly fast aircraft below and well-behaved as a trainer.

One result of the failed British/French order was to give the aircraft its name. Lockheed had originally dubbed the aircraft Atalanta from Greek mythology in the company tradition of naming planes after mythological and celestial figures, but the RAF name won out.

The strategic bombing proponents within the USAAF, called the Bomber Mafia by their ideological opponents, had established in the early 1930s a policy against research to create long-range fighters, which they thought would not be practical; this kind of research was not to compete for bomber resources. Aircraft manufacturers understood that they would not be rewarded if they installed subsystems on their fighters to enable them to carry drop tanks to provide more fuel for extended range. Lieutenant Kelsey, acting against this policy, risked his career in late 1941 when he convinced Lockheed to incorporate such subsystems in the P-38E model, without putting his request in writing. It is possible that Kelsey was responding to Colonel George William Goddard's observation that the US sorely needed a high-speed, long-range photo reconnaissance plane. Along with a change order specifying some P-38Es be produced without guns but with photo reconnaissance cameras, to be designated the F-4-1-LO, Lockheed began working out the problems of drop tank design and incorporation. After the attack on Pearl Harbor, eventually about 100 P-38Es were sent to a modification center near Dallas, Texas, or to the new Lockheed assembly plant B-6 (today the Burbank Airport), to be fitted with four K-17 aerial photography cameras. All of these aircraft were also modified to be able to carry drop tanks. P-38Fs were modified as well. Every Lightning from the P-38G onward was drop tank-capable off the assembly line.

In March 1942, General Arnold made an off-hand comment that the US could avoid the German U-boat menace by flying fighters to the UK (rather than packing them onto ships). President Roosevelt pressed the point, emphasizing his interest in the solution. Arnold was likely aware of the flying radius extension work being done on the P-38, which by this time had seen success with small drop tanks in the range of , the difference in capacity being the result of subcontractor production variation. Arnold ordered further tests with larger drop tanks in the range of ; the results were reported by Kelsey as providing the P-38 with a ferrying range. Because of available supply, the smaller drop tanks were used to fly Lightnings to the UK, the plan called Operation Bolero.

Led by two Boeing B-17 Flying Fortresses, the first seven P-38s, each carrying two small drop tanks, left Presque Isle Army Air Field on June 23, 1942 for RAF Heathfield in Scotland. Their first refueling stop was made in far northeast Canada at Goose Bay. The second stop was a rough airstrip in Greenland called Bluie West One, and the third refueling stop was in Iceland at Keflavik. Other P-38s followed this route with some lost in mishaps, usually due to poor weather, low visibility, radio difficulties and navigational errors. Nearly 200 of the P-38Fs (and a few modified Es) were successfully flown across the Atlantic in July–August 1942, making the P-38 the first USAAF fighter to reach Britain and the first fighter ever to be delivered across the Atlantic under its own power. Kelsey himself piloted one of the Lightnings, landing in Scotland on 25 July.

The first unit to receive P-38s was the 1st Fighter Group. After the attack on Pearl Harbor, the unit joined the 14th Pursuit Group in San Diego to provide West Coast defense.

The first Lightning to see active service was the F-4 version, a P-38E in which the guns were replaced by four K17 cameras. They joined the 8th Photographic Squadron in Australia on 4 April 1942. Three F-4s were operated by the Royal Australian Air Force in this theater for a short period beginning in September 1942.

On 29 May 1942, 25 P-38s began operating in the Aleutian Islands in Alaska. The fighter's long range made it well-suited to the campaign over the almost -long island chain, and it was flown there for the rest of the war. The Aleutians were one of the most rugged environments available for testing the new aircraft under combat conditions. More Lightnings were lost due to severe weather and other conditions than enemy action; there were cases where Lightning pilots, mesmerized by flying for hours over gray seas under gray skies, simply flew into the water. On 9 August 1942, two P-38Es of the 343rd Fighter Group, 11th Air Force, at the end of a long-range patrol, happened upon a pair of Japanese Kawanishi H6K "Mavis" flying boats and destroyed them, making them the first Japanese aircraft to be shot down by Lightnings.

After the Battle of Midway, the USAAF began redeploying fighter groups to Britain as part of Operation Bolero and Lightnings of the 1st Fighter Group were flown across the Atlantic via Iceland. On 14 August 1942, Second Lieutenant Elza Shahan of the 27th Fighter Squadron, and Second Lieutenant Joseph Shaffer of the 33rd Squadron operating out of Iceland shot down a Focke-Wulf Fw 200 "Condor" over the Atlantic. Shahan in his P-38F downed the "Condor"; Shaffer, flying either a P-40C or a P-39, had already set an engine on fire. This was the first Luftwaffe aircraft destroyed by the USAAF.

After 347 sorties with no enemy contact, the 1st, 14th and 82nd Fighter Groups were transferred to the 12th Air Force in North Africa as part of the force being built up for Operation Torch. On 19 November 1942, Lightnings escorted a group of B-17 Flying Fortress bombers on a raid over Tunis. On 5 April 1943, 26 P-38Fs of the 82nd claimed 31 enemy aircraft destroyed, helping to establish air superiority in the area and earning it the German nickname ""der Gabelschwanz Teufel"" – the Fork-Tailed Devil. The P-38 remained active in the Mediterranean for the rest of the war. It was in this theatre that the P-38 suffered its heaviest losses in the air. On 25 August 1943, 13 P-38s were shot down in a single sortie by "Jagdgeschwader" 53 Bf 109s without achieving a single kill. On 2 September, 10 P-38s were shot down, in return for a single kill, the 67-victory ace Franz Schiess (who was also the leading "Lightning" killer in the Luftwaffe with 17 destroyed). Kurt Bühligen, third highest scoring German pilot on the Western front with 112 victories, recalled: "The P-38 fighter (and the B-24) were easy to burn. Once in Africa we were six and met eight P-38s and shot down seven. One sees a great distance in Africa and our observers and flak people called in sightings and we could get altitude first and they were low and slow." "General der Jagdflieger" Adolf Galland was unimpressed with the P-38, declaring "it had similar shortcomings in combat to our Bf 110, our fighters were clearly superior to it." Heinz Bäer said that P-38s "were not difficult at all. They were easy to outmaneuver and were generally a sure kill". Experiences over Germany had shown a need for long-range escort fighters to protect the Eighth Air Force's heavy bomber operations. The P-38Hs of the 55th Fighter Group were transferred to the Eighth in England in September 1943, and were joined by the 20th, 364th and 479th Fighter Groups soon after. P-38s soon joined Spitfires in escorting the early Fortress raids over Europe.

Because its distinctive shape was less prone to cases of mistaken identity and friendly fire, Lieutenant General Jimmy Doolittle, Commander of the 8th Air Force, chose to pilot a P-38 during the invasion of Normandy so that he could watch the progress of the air offensive over France. At one point in the mission, Doolittle flick-rolled through a hole in the cloud cover, but his wingman, then-Major General Earle E. Partridge, was looking elsewhere and failed to notice Doolittle's quick maneuver, leaving Doolittle to continue on alone on his survey of the crucial battle. Of the P-38, Doolittle said that it was "the sweetest-flying plane in the sky".

A little-known role of the P-38 in the European theater was that of fighter-bomber during the invasion of Normandy and the Allied advance across France into Germany. Assigned to the IX Tactical Air Command, the 370th Fighter Group and its P-38s initially flew missions from England, dive-bombing radar installations, enemy armor, troop concentrations and flak towers. The 370th's group commander Howard F. Nichols and a squadron of his P-38 Lightnings attacked Field Marshal Günther von Kluge's headquarters in July 1944; Nichols himself skipped a bomb through the front door. The 370th later operated from Cardonville France, flying ground attack missions against gun emplacements, troops, supply dumps and tanks near Saint-Lô in July and in the Falaise–Argentan area in August 1944. The 370th participated in ground attack missions across Europe until February 1945 when the unit changed over to the P-51 Mustang.

On 12 June 1943, a P-38G, while flying a special mission between Gibraltar and Malta or, perhaps, just after strafing the radar station of Capo Pula, landed on the airfield of Capoterra (Cagliari), in Sardinia, from navigation error due to a compass failure. "Regia Aeronautica" chief test pilot "colonnello" (Lieutenant Colonel) Angelo Tondi flew the aircraft to Guidonia airfield where the P-38G was evaluated. On 11 August 1943, Tondi took off to intercept a formation of about 50 bombers, returning from the bombing of Terni (Umbria). Tondi attacked B-17G "Bonny Sue", s.n. 42-30307, that fell off the shore of Torvaianica, near Rome, while six airmen parachuted out. According to US sources, he also damaged three more bombers on that occasion. On 4 September, the 301st BG reported the loss of B-17 "The Lady Evelyn," s.n. 42-30344, downed by "an enemy P-38". War missions for that plane were limited, as the Italian petrol was too corrosive for the Lockheed's tanks. Other Lightnings were eventually acquired by Italy for postwar service.

In a particular case when faced by more agile fighters at low altitudes in a constricted valley, Lightnings suffered heavy losses. On the morning of 10 June 1944, 96 P-38Js of the 1st and 82nd Fighter Groups took off from Italy for Ploiești, the third-most heavily defended target in Europe, after Berlin and Vienna. Instead of bombing from high altitude as had been tried by the Fifteenth Air Force, USAAF planning had determined that a dive-bombing surprise attack, beginning at about with bomb release at or below , performed by 46 82nd Fighter Group P-38s, each carrying one bomb, would yield more accurate results.<ref name="Stanaway ETO/MTO">Stanaway 1998, pp. 43–46.</ref> All of 1st Fighter Group and a few aircraft in 82nd Fighter Group were to fly cover, and all fighters were to strafe targets of opportunity on the return trip; a distance of some , including a circuitous outward route made in an attempt to achieve surprise.

Some 85 or 86 fighters arrived in Romania to find enemy airfields alerted, with a wide assortment of aircraft scrambling for safety. P-38s shot down several, including heavy fighters, transports and observation aircraft. At Ploiești, defense forces were fully alert, the target was concealed by smoke screen, and anti-aircraft fire was very heavy—seven Lightnings were lost to anti-aircraft fire at the target, and two more during strafing attacks on the return flight. German Bf 109 fighters from I./JG 53 and 2./JG 77 fought the Americans. Sixteen aircraft of the 71st Fighter Squadron were challenged by a large formation of Romanian single-seater IAR.81C fighters. The fight took place below in a narrow valley. Herbert Hatch saw two IAR 81Cs that he misidentified as Focke-Wulf Fw 190s hit the ground after taking fire from his guns, and his fellow pilots confirmed three more of his kills. However, the outnumbered 71st Fighter Squadron took more damage than it dished out, losing nine aircraft. In all, the USAAF lost 22 aircraft on the mission. The Americans claimed 23 aerial victories, though Romanian and German fighter units admitted losing only one aircraft each. Eleven enemy locomotives were strafed and left burning, and flak emplacements were destroyed, along with fuel trucks and other targets. Results of the bombing were not observed by the USAAF pilots because of the smoke. The dive-bombing mission profile was not repeated, though the 82nd Fighter Group was awarded the Presidential Unit Citation for its part.

After some disastrous raids in 1944 with B-17s escorted by P-38s and Republic P-47 Thunderbolts, Jimmy Doolittle, then head of the U.S. Eighth Air Force, went to the RAE, Farnborough, asking for an evaluation of the various American fighters. Test pilot Captain Eric Brown, Fleet Air Arm, recalled:

We had found out that the Bf 109 and the FW 190 could fight up to a Mach of 0.75, three-quarters the speed of sound. We checked the Lightning and it couldn't fly in combat faster than 0.68. So it was useless. We told Doolittle that all it was good for was photo-reconnaissance and had to be withdrawn from escort duties. And the funny thing is that the Americans had great difficulty understanding this because the Lightning had the two top aces in the Far East.

After evaluation tests at Farnborough, the P-38 was kept in fighting service in Europe for a while longer. Although many failings were remedied with the introduction of the P-38J, by September 1944, all but one of the Lightning groups in the Eighth Air Force had converted to the P-51 Mustang. The Eighth Air Force continued to conduct reconnaissance missions using the F-5 variant.

The P-38 was used most extensively and successfully in the Pacific theater, where it proved ideally suited, combining excellent performance with exceptional range and the added reliability of two engines for long missions over water. The P-38 was used in a variety of roles, especially escorting bombers at altitudes of . The P-38 was credited with destroying more Japanese aircraft than any other USAAF fighter. Freezing cockpit temperatures were not a problem at low altitude in the tropics. In fact the cockpit was often too hot since opening a window while in flight caused buffeting by setting up turbulence through the tailplane. Pilots taking low altitude assignments often flew stripped down to shorts, tennis shoes, and parachute. While the P-38 could not out-turn the A6M Zero and most other Japanese fighters when flying below , its superior speed coupled with a good rate of climb meant that it could use energy tactics, making multiple high-speed passes at its target. In addition, its tightly grouped guns were even more deadly to lightly armored Japanese warplanes than to German aircraft. The concentrated, parallel stream of bullets allowed aerial victory at much longer distances than fighters carrying wing guns. It is therefore ironic that Dick Bong, the United States' highest-scoring World War II air ace (40 victories solely in P-38s), would fly directly at his targets to make sure he hit them (as he himself acknowledged his poor shooting ability), in some cases flying through the debris of his target (and on one occasion colliding with an enemy aircraft which was claimed as a "probable" victory). The twin Allison engines performed admirably in the Pacific.

General George C. Kenney, commander of the USAAF Fifth Air Force operating in New Guinea, could not get enough P-38s; they had become his favorite fighter in November 1942 when one squadron, the 39th Fighter Squadron of the 35th Fighter Group, joined his assorted P-39s and P-40s. The Lightnings established local air superiority with their first combat action on 27 December 1942. Kenney sent repeated requests to Arnold for more P-38s, and was rewarded with occasional shipments, but Europe was a higher priority in Washington. Despite their small force, Lightning pilots began to compete in racking up scores against Japanese aircraft.

On 2–4 March 1943, P-38s flew top cover for 5th Air Force and Australian bombers and attack aircraft during the Battle of the Bismarck Sea, in which eight Japanese troop transports and four escorting destroyers were sunk. Two P-38 aces from the 39th Fighter Squadron were killed on the second day of the battle: Bob Faurot and Hoyt "Curley" Eason (a veteran with five victories who had trained hundreds of pilots, including Dick Bong). In one notable engagement on 3 March 1943 P-38s escorted 13 Boeing B-17 Flying Fortresses as they bombed the Japanese convoy from a medium altitude of 7,000 feet which dispersed the convoy formation and reduced their concentrated anti-aircraft firepower. A B-17 was shot down and when Japanese Zero fighters machine-gunned some of the B-17 crew members that bailed out in parachutes, three P-38s promptly engaged and shot down five of the Zeros..

The Lightning figured in one of the most significant operations in the Pacific theater: the interception, on 18 April 1943, of Admiral Isoroku Yamamoto, the architect of Japan's naval strategy in the Pacific including the attack on Pearl Harbor. When American codebreakers found out that he was flying to Bougainville Island to conduct a front-line inspection, 16 P-38G Lightnings were sent on a long-range fighter-intercept mission, flying from Guadalcanal at heights of above the ocean to avoid detection. The Lightnings met Yamamoto's two Mitsubishi G4M "Betty" fast bomber transports and six escorting Zeros just as they arrived at the island. The first Betty crashed in the jungle and the second ditched near the coast. Two Zeros were also claimed by the American fighters with the loss of one P-38. Japanese search parties found Yamamoto's body at the jungle crash site the next day.

The P-38's service record shows mixed results, which may reflect more on its employment than on flaws with the aircraft. The P-38's engine troubles at high altitudes only occurred with the Eighth Air Force. One reason for this was the inadequate cooling systems of the G and H models; the improved P-38 J and L had tremendous success flying out of Italy into Germany at all altitudes. Until the -J-25 variant, P-38s were easily avoided by German fighters because of the lack of dive flaps to counter compressibility in dives. German fighter pilots not wishing to fight would perform the first half of a Split S and continue into steep dives because they knew the Lightnings would be reluctant to follow.

On the positive side, having two engines was a built-in insurance policy. Many pilots made it safely back to base after having an engine failure en route or in combat. On 3 March 1944, the first Allied fighters reached Berlin on a frustrated escort mission. Lieutenant Colonel Jack Jenkins of 55FG led the group of P-38H pilots, arriving with only half his force after flak damage and engine trouble took their toll. On the way into Berlin, Jenkins reported one rough-running engine, causing him to wonder if he would ever make it back. The B-17s he was supposed to escort never showed up, having turned back at Hamburg. Jenkins and his wingman were able to drop tanks and outrun enemy fighters to return home with three good engines between them.

In the ETO, P-38s made 130,000 sorties with a loss of 1.3% overall, comparing favorably with ETO P-51s, which posted a 1.1% loss, considering that the P-38s were vastly outnumbered and suffered from poorly thought-out tactics. The majority of the P-38 sorties were made in the period prior to Allied air superiority in Europe, when pilots fought against a very determined and skilled enemy. Lieutenant Colonel Mark Hubbard, a vocal critic of the aircraft, rated it the third best Allied fighter in Europe. The Lightning's greatest virtues were long range, heavy payload, high speed, fast climb and concentrated firepower. The P-38 was a formidable fighter, interceptor and attack aircraft.

In the Pacific theater, the P-38 downed over 1,800 Japanese aircraft, with more than 100 pilots becoming aces by downing five or more enemy aircraft. American fuel supplies contributed to a better engine performance and maintenance record, and range was increased with leaner mixtures. In the second half of 1944, the P-38L pilots out of Dutch New Guinea were flying , fighting for fifteen minutes and returning to base. Such long legs were invaluable until the P-47N and P-51D entered service.

The end of the war left the USAAF with thousands of P-38s rendered obsolete by the jet age. The last P-38s in service with the United States Air Force were retired in 1949. A total of 100 late-model P-38L and F-5 Lightnings were acquired by Italy through an agreement dated April 1946. Delivered, after refurbishing, at the rate of one per month, they finally were all sent to the AMI by 1952. The Lightnings served in 4 "Stormo" and other units including 3 "Stormo", flying reconnaissance over the Balkans, ground attack, naval cooperation and air superiority missions. Due to old engines, pilot errors and lack of experience in operating heavy fighters, a large number of P-38s were lost in at least 30 accidents, many of them fatal. Despite this, many Italian pilots liked the P-38 because of its excellent visibility on the ground and stability on takeoff. The Italian P-38s were phased out in 1956; none survived the scrapyard.

Surplus P-38s were also used by other foreign air forces with 12 sold to Honduras and 15 retained by China. Six F-5s and two unarmed black two-seater P-38s were operated by the Dominican Air Force based in San Isidro Airbase, Dominican Republic in 1947. The majority of wartime Lightnings present in the continental U.S. at the end of the war were put up for sale for US$1,200 apiece; the rest were scrapped. P-38s in distant theaters of war were bulldozed into piles and abandoned or scrapped; very few avoided that fate.

The CIA "Liberation Air Force" flew one P-38M to support the 1954 Guatemalan coup d'etat. On 27 June 1954, this aircraft dropped napalm bombs that destroyed the British cargo ship , which was loading Guatemalan cotton and coffee for Grace Line in Puerto San José. In 1957, five Honduran P-38s bombed and strafed a village occupied by Nicaraguan forces during a border dispute between these two countries concerning part of Gracias a Dios Department.

P-38s were popular contenders in the air races from 1946 through 1949, with brightly colored Lightnings making screaming turns around the pylons at Reno and Cleveland. Lockheed test pilot Tony LeVier was among those who bought a Lightning, choosing a P-38J model and painting it red to make it stand out as an air racer and stunt flyer. Lefty Gardner, former B-24 and B-17 pilot and associate of the Confederate Air Force, bought a mid-1944 P-38L-1-LO that had been modified into an F-5G. Gardner painted it white with red and blue trim and named it "White Lightnin"; he reworked its turbo systems and intercoolers for optimum low-altitude performance and gave it P-38F style air intakes for better streamlining. "White Lightnin" was severely damaged in a crash landing during an air show demonstration and was bought, restored and repainted with a brilliant chrome finish by the company that owns Red Bull. The aircraft is now located in Austria.

F-5s were bought by aerial survey companies and employed for mapping. From the 1950s on, the use of the Lightning steadily declined, and only a little more than two dozen still exist, with few still flying. One example is a P-38L owned by the Lone Star Flight Museum in Galveston, Texas, painted in the colors of Charles H. MacDonald's "Putt Putt Maru". Two other examples are F-5Gs which were owned and operated by Kargl Aerial Surveys in 1946, and are now located in Chino, California at Yanks Air Museum, and in McMinnville, Oregon at Evergreen Aviation Museum. The earliest-built surviving P-38, "Glacier Girl", was recovered from the Greenland ice cap in 1992, fifty years after she crashed there on a ferry flight to the UK, and after a complete restoration, flew once again ten years after her recovery.

Over 10,000 Lightnings were manufactured, becoming the only U.S. combat aircraft that remained in continuous production throughout the duration of American participation in World War II. The Lightning had a major effect on other aircraft; its wing, in a scaled-up form, was used on the Lockheed Constellation.

Delivered and accepted Lightning production variants began with the P-38D model. The few "hand made" YP-38s initially contracted were used as trainers and test aircraft. There were no Bs or Cs delivered to the government as the USAAF allocated the 'D' suffix to all aircraft with self-sealing fuel tanks and armor. Many secondary but still initial teething tests were conducted using the earliest D variants.

The first combat-capable Lightning was the P-38E (and its photo-recon variant the F-4) which featured improved instruments, electrical, and hydraulic systems. Part-way through production, the older Hamilton Standard Hydromatic hollow steel propellers were replaced by new Curtiss Electric duraluminum propellers. The definitive (and now famous) armament configuration was settled upon, featuring four .50 in (12.7 mm) machine guns with 500 rpg, and a 20 mm (.79 in) Hispano autocannon with 150 rounds.

While the machine guns had been arranged symmetrically in the nose on the P-38D, they were "staggered" in the P-38E and later versions, with the muzzles protruding from the nose in the relative lengths of roughly 1:4:6:2. This was done to ensure a straight ammunition-belt feed into the weapons, as the earlier arrangement led to jamming.

The first P-38E rolled out of the factory in October 1941 as the Battle of Moscow filled the news wires of the world. Because of the versatility, redundant engines, and especially high speed and high altitude characteristics of the aircraft, as with later variants over a hundred P-38Es were completed in the factory or converted in the field to a photoreconnaissance variant, the F-4, in which the guns were replaced by four cameras. Most of these early reconnaissance Lightnings were retained stateside for training, but the F-4 was the first Lightning to be used in action in April 1942.

After 210 P-38Es were built, they were followed, starting in April 1942, by the P-38F, which incorporated racks inboard of the engines for fuel tanks or a total of of bombs. Early variants did not enjoy a high reputation for maneuverability, though they could be agile at low altitudes if flown by a capable pilot, using the P-38's forgiving stall characteristics to their best advantage. From the P-38F-15 model onwards, a "combat maneuver" setting was added to the P-38's Fowler flaps. When deployed at the 8° maneuver setting, the flaps allowed the P-38 to out-turn many contemporary single-engined fighters at the cost of some added drag. However, early variants were hampered by high aileron control forces and a low initial rate of roll, and all such features required a pilot to gain experience with the aircraft, which in part was an additional reason Lockheed sent its representative to England, and later to the Pacific Theater.

The aircraft was still experiencing extensive teething troubles as well as being victimized by "urban legends", mostly involving inapplicable twin engine factors which had been designed out of the aircraft by Lockheed. In addition to these, the early versions had a reputation as a "widow maker" as it could enter an unrecoverable dive due to a sonic surface effect at high sub-sonic speeds. The 527 P-38Fs were heavier, with more powerful engines that used more fuel, and were unpopular in the air war in Northern Europe. Since the heavier engines were having reliability problems and with them, without external fuel tanks, the range of the P-38F was reduced, and since drop tanks themselves were in short supply as the fortunes in the Battle of the Atlantic had not yet swung the Allies' way, the aircraft became relatively unpopular in minds of the bomber command planning staffs despite being the longest ranged fighter first available to the 8th Air Force in sufficient numbers for long range escort duties. Nonetheless, General Spaatz, then commander of the 8th Air Force in the UK, said of the P-38F: "I'd rather have an airplane that goes like hell and has a few things wrong with it, than one that won't go like hell and has a few things wrong with it."
The P-38F was followed in early 1943 by the P-38G, using more powerful Allisons of each and equipped with a better radio. A dozen of the planned P-38G production were set aside to serve as prototypes for what would become the P-38J with further uprated Allison V-1710F-17 engines ( each) in redesigned booms which featured chin-mounted intercoolers in place of the original system in the leading edge of the wings and more efficient radiators. Lockheed subcontractors, however, were initially unable to supply both of Burbank's twin production lines with a sufficient quantity of new core intercoolers and radiators. War Production Board planners were unwilling to sacrifice production, and one of the two remaining prototypes received the new engines but retained the old leading edge intercoolers and radiators.

As the P-38H, 600 of these stop-gap Lightnings with an improved 20 mm cannon and a bomb capacity of were produced on one line while the near-definitive P-38J began production on the second line. The Eighth Air Force was experiencing high altitude and cold weather issues which, while not unique to the aircraft, were perhaps more severe as the turbo-superchargers upgrading the Allisons were having their own reliability issues making the aircraft more unpopular with senior officers out of the line. This was a situation unduplicated on all other fronts where the commands were clamoring for as many P-38s as they could get. Both the P-38G and P-38H models' performance was restricted by an intercooler system integral to the wing's leading edge which had been designed for the YP-38's less powerful engines. At the higher boost levels, the new engine's charge air temperature would increase above the limits recommended by Allison and would be subject to detonation if operated at high power for extended periods of time. Reliability was not the only issue, either. For example, the reduced power settings required by the P-38H did not allow the maneuvering flap to be used to good advantage at high altitude. All these problems really came to a head in the unplanned P-38H and sped the Lightning's eventual replacement in the Eighth Air Force; fortunately the Fifteenth Air Force were glad to get them.

Some P-38G production was diverted on the assembly line to F-5A reconnaissance aircraft. An F-5A was modified to an experimental two-seat reconnaissance configuration as the XF-5D, with a plexiglas nose, two machine guns and additional cameras in the tail booms.

The P-38J was introduced in August 1943. The turbo-supercharger intercooler system on previous variants had been housed in the leading edges of the wings and had proven vulnerable to combat damage and could burst if the wrong series of controls were mistakenly activated. In the P-38J series, the streamlined engine nacelles of previous Lightnings were changed to fit the intercooler radiator between the oil coolers, forming a "chin" that visually distinguished the J model from its predecessors. While the P-38J used the same V-1710-89/91 engines as the H model, the new core-type intercooler more efficiently lowered intake manifold temperatures and permitted a substantial increase in rated power. The leading edge of the outer wing was fitted with fuel tanks, filling the space formerly occupied by intercooler tunnels, but these were omitted on early P-38J blocks due to limited availability.

The final 210 J models, designated P-38J-25-LO, alleviated the compressibility problem through the addition of a set of electrically actuated dive recovery flaps just outboard of the engines on the bottom centerline of the wings. With these improvements, a USAAF pilot reported a dive speed of almost , although the indicated air speed was later corrected for compressibility error, and the actual dive speed was lower. Lockheed manufactured over 200 retrofit modification kits to be installed on P-38J-10-LO and J-20-LO already in Europe, but the USAAF C-54 carrying them was shot down by an RAF pilot who mistook the Douglas transport for a German Focke-Wulf Condor. Unfortunately, the loss of the kits came during Lockheed test pilot Tony LeVier's four-month morale-boosting tour of P-38 bases. Flying a new Lightning named "Snafuperman", modified to full P-38J-25-LO specifications at Lockheed's modification center near Belfast, LeVier captured the pilots' full attention by routinely performing maneuvers during March 1944 that common Eighth Air Force wisdom held to be suicidal. It proved too little, too late, because the decision had already been made to re-equip with Mustangs.

The P-38J-25-LO production block also introduced hydraulically boosted ailerons, one of the first times such a system was fitted to a fighter. This significantly improved the Lightning's rate of roll and reduced control forces for the pilot. This production block and the following P-38L model are considered the definitive Lightnings, and Lockheed ramped up production, working with subcontractors across the country to produce hundreds of Lightnings each month.

There were two P-38Ks developed from 1942 to 1943, one official and one an internal Lockheed experiment. The first was actually a battered RP-38E "piggyback" test mule previously used by Lockheed to test the P-38J chin intercooler installation, now fitted with paddle-bladed "high activity" Hamilton Standard Hydromatic propellers similar to those used on the P-47. The new propellers required spinners of greater diameter, and the mule's crude, hand-formed sheet steel cowlings were further stretched to blend the spinners into the nacelles. It retained its "piggyback" configuration that allowed an observer to ride behind the pilot. With Lockheed's AAF representative as a passenger and the maneuvering flap deployed to offset Army Hot Day conditions, the old "K-Mule" still climbed to . With a fresh coat of paint covering its crude hand-formed steel cowlings, this RP-38E acts as stand-in for the "P-38K-1-LO" in the model's only picture.

The 12th G model originally set aside as a P-38J prototype was re-designated P-38K-1-LO and fitted with the aforementioned paddle-blade propellers and new Allison V-1710-75/77 (F15R/L) powerplants rated at at War Emergency Power. These engines were geared 2.36 to 1, unlike the standard P-38 ratio of 2 to 1. The AAF took delivery in September 1943, at Eglin Field. In tests, the P-38K-1 achieved at military power and was predicted to exceed at War Emergency Power with a similar increase in load and range. The initial climb rate was /min and the ceiling was . It reached in five minutes flat; this with a coat of camouflage paint which added weight and drag. Although it was judged superior in climb and speed to the latest and best fighters from all AAF manufacturers, the War Production Board refused to authorize P-38K production due to the two-to-three-week interruption in production necessary to implement cowling modifications for the revised spinners and higher thrust line. Some have also doubted Allison's ability to deliver the F15 engine in quantity. As promising as it had looked, the P-38K project came to a halt.

The P-38L was the most numerous variant of the Lightning, with 3,923 built, 113 by Consolidated-Vultee in their Nashville plant. It entered service with the USAAF in June 1944, in time to support the Allied invasion of France on D-Day. Lockheed production of the Lightning was distinguished by a suffix consisting of a production block number followed by "LO," for example "P-38L-1-LO", while Consolidated-Vultee production was distinguished by a block number followed by "VN," for example "P-38L-5-VN."

The P-38L was the first Lightning fitted with zero-length rocket launchers. Seven high velocity aircraft rockets (HVARs) on pylons beneath each wing, and later, five rockets on each wing on "Christmas tree" launch racks which added to the aircraft. The P-38L also had strengthened stores pylons to allow carriage of bombs or drop tanks.

Lockheed modified 200 P-38J airframes in production to become unarmed F-5B photo-reconnaissance aircraft, while hundreds of other P-38Js and P-38Ls were modified at Lockheed's Dallas Modification Center to become F-5Cs, F-5Es, F-5Fs, and F-5Gs. A few P-38Ls were field-modified to become two-seat TP-38L familiarization trainers. During and after June 1948, the remaining J and L variants were designated ZF-38J and ZF-38L, with the "ZF" designator (meaning "obsolete fighter") replacing the "P for Pursuit" category.

Late model Lightnings were delivered unpainted, as per USAAF policy established in 1944. At first, field units tried to paint them, since pilots worried about being too visible to the enemy, but it turned out the reduction in weight and drag was a minor advantage in combat.

The P-38L-5, the most common sub-variant of the P-38L, had a modified cockpit heating system consisting of a plug-socket in the cockpit into which the pilot could plug his heat-suit wire for improved comfort. These Lightnings also received the uprated V-1710-112/113 (F30R/L) engines, and this dramatically lowered the amount of engine failure problems experienced at high altitude so commonly associated with European operations.

The Lightning was modified for other roles. In addition to the F-4 and F-5 reconnaissance variants, a number of P-38Js and P-38Ls were field-modified as formation bombing "pathfinders" or "droopsnoots", fitted with a glazed nose with a Norden bombsight, or a H2X radar "bombing through overcast" nose. A pathfinder would lead a formation of other P-38s, each overloaded with two bombs; the entire formation releasing when the pathfinder did.

A number of Lightnings were modified as night fighters. There were several field or experimental modifications with different equipment fits that finally led to the "formal" P-38M night fighter, or "Night Lightning". A total of 75 P-38Ls were modified to the Night Lightning configuration, painted flat-black with conical flash hiders on the guns, an AN/APS-6 radar pod below the nose, and a second cockpit with a raised canopy behind the pilot's canopy for the radar operator. The headroom in the rear cockpit was limited, requiring radar operators who were preferably short in stature.

The P-38M was faster than the purpose-built Northrop P-61 Black Widow night fighter. The night Lightnings saw some combat duty in the Pacific towards the end of the war but none engaged in combat.

One of the initial production P-38s had its turbo-superchargers removed, with a secondary cockpit placed in one of the booms to examine how flightcrew would respond to such an "asymmetric" cockpit layout. One P-38E was fitted with an extended central nacelle to accommodate a tandem-seat cockpit with dual controls, and was later fitted with a laminar flow wing.

Very early in the Pacific War, a scheme was proposed to fit Lightnings with floats to allow them to make long-range ferry flights. The floats would be removed before the aircraft went into combat. There were concerns that saltwater spray would corrode the tailplane, and so in March 1942, P-38E "41-1986" was modified with a tailplane raised some , booms lengthened by two feet and a rearward-facing second seat added for an observer to monitor the effectiveness of the new arrangement. A second version was crafted on the same airframe with the twin booms given greater sideplane area to augment the vertical rudders. This arrangement was removed and a final third version was fabricated that had the booms returned to normal length but the tail raised . All three tail modifications were designed by George H. "Bert" Estabrook. The final version was used for a quick series of dive tests on 7 December 1942 in which Milo Burcham performed the test maneuvers and Kelly Johnson observed from the rear seat. Johnson concluded that the raised floatplane tail gave no advantage in solving the problem of compressibility. At no time was this P-38E testbed airframe actually fitted with floats, and the idea was quickly abandoned as the U.S. Navy proved to have enough sealift capacity to keep up with P-38 deliveries to the South Pacific.

Still another P-38E was used in 1942 to tow a Waco troop glider as a demonstration. However, there proved to be plenty of other aircraft, such as Douglas C-47 Skytrains, available to tow gliders, and the Lightning was spared this duty.

Standard Lightnings were used as crew and cargo transports in the South Pacific. They were fitted with pods attached to the underwing pylons, replacing drop tanks or bombs, that could carry a single passenger in a lying-down position, or cargo. This was a very uncomfortable way to fly. Some of the pods were not even fitted with a window to let the passenger see out or bring in light.

Lockheed proposed a carrier-based Model 822 version of the Lightning for the United States Navy. The Model 822 would have featured folding wings, an arresting hook, and stronger undercarriage for carrier operations. The navy was not interested, as they regarded the Lightning as too big for carrier operations and did not like liquid-cooled engines anyway, and the Model 822 never went beyond the paper stage. However, the navy did operate four land-based F-5Bs in North Africa, inherited from the USAAF and redesignated FO-1.

A P-38J was used in experiments with an unusual scheme for mid-air refueling, in which the fighter snagged a drop tank trailed on a cable from a bomber. The USAAF managed to make this work, but decided it was not practical. A P-38J was also fitted with experimental retractable snow ski landing gear, but this idea never reached operational service either.

After the war, a P-38L was experimentally fitted with armament of three .60 in (15.2 mm) machine guns. The .60 in (15.2 mm) caliber cartridge had been developed early in the war for an infantry anti-tank rifle, a type of weapon developed by a number of nations in the 1930s when tanks were lighter but, by 1942, the idea of taking on a tank with a large-caliber rifle was no longer considered to be practical.

The cartridge was not abandoned, with the Americans designing a derivative of the German 15 mm (.59 in) MG 151 cannon to fire it and designating the weapon the "T17". Although 300 of these guns were built and over six million .60 in (15.2 mm) rounds manufactured, some problems with the weapon were never resolved, and the T17 never saw operational service. The cartridge was expanded and reshaped to fit 20 mm projectiles and became a standard U.S. ammunition after the war. The T17-armed P-38L did not go beyond unsuccessful trials.

Another P-38L was modified after the war as a "super strafer," with eight .50 in (12.7 mm) machine guns in the nose and a pod under each wing with two .50 in (12.7 mm) guns, for a total of 12 machine guns. Nothing came of this conversion either.



Civil

The 5,000th Lightning built, a P-38J-20-LO, "44-23296", was painted bright vermilion red, and had the name "YIPPEE" painted on the underside of the wings in big white letters as well as the signatures of hundreds of factory workers. This and other aircraft were used by a handful of Lockheed test pilots including Milo Burcham, Jimmie Mattern and Tony LeVier in remarkable flight demonstrations, performing such stunts as slow rolls at treetop level with one prop feathered to dispel the myth that the P-38 was unmanageable.

In-flight footage of the YIPPEE P-38 can be seen in the pilot episode of the "Green Acres" television series.

On July 15, 1942, a flight of six P-38s and two B-17 bombers, with a total of 25 crew members on board, took off from Presque Isle Air Base in Maine headed for the UK. What followed was a harrowing and life-threatening landing of the entire squadron on a remote ice cap in Greenland. None of the crew was lost and they were all rescued and returned safely home after spending several days on the ice.

Fifty years later a small group of aviation enthusiasts decided to locate those aircraft, which had come to be known as "The Lost Squadron", and to recover one of the lost P-38s. It turned out to be no easy task, as the planes had been buried under 25 stories of ice and drifted over a mile from their original location. The recovered P-38, dubbed "Glacier Girl", was eventually restored to airworthiness.

The American ace of aces and his closest competitor both flew Lightnings and tallied 40 and 38 victories respectively. Majors Richard I. "Dick" Bong and Thomas B. "Tommy" McGuire of the USAAF competed for the top position. Both men were awarded the Medal of Honor.

McGuire was killed in air combat in January 1945 over the Philippines, after accumulating 38 confirmed kills, making him the second-ranking American ace. Bong was rotated back to the United States as America's ace of aces, after making 40 kills, becoming a test pilot. He was killed on 6 August 1945, the day the atomic bomb was dropped on Japan, when his Lockheed P-80 Shooting Star jet fighter flamed out on takeoff.

The famed aviator Charles Lindbergh toured the South Pacific as a civilian contractor for United Aircraft Corporation, comparing and evaluating performance of single- and twin-engined fighters for Vought. He worked to improve range and load limits of the Vought F4U Corsair, flying both routine and combat strafing missions in Corsairs alongside Marine pilots.

Everywhere Lindbergh went in the South Pacific, he was accorded the normal preferential treatment of a visiting colonel, although he had resigned his Air Corps Reserve colonel's commission three years before. In Hollandia, Lindbergh attached himself to the 475th FG, flying P-38s. Although new to the aircraft, Lindbergh was instrumental in extending the range of the P-38 through improved throttle settings, or engine-leaning techniques, notably by reducing engine speed to 1,600 rpm, setting the carburetors for auto-lean and flying at indicated airspeed which reduced fuel consumption to 70 gal/h, about 2.6 mpg. This combination of settings had been considered dangerous and would upset the fuel mixture, causing an explosion.

While with the 475th, he held training classes and took part in a number of Army Air Corps combat missions. On 28 July 1944, Lindbergh shot down a Mitsubishi Ki-51 "Sonia" flown by the veteran commander of 73rd Independent Flying Chutai, Imperial Japanese Army Captain Saburo Shimada. In an extended, twisting dogfight in which many of the participants ran out of ammunition, Shimada turned his aircraft directly toward Lindbergh who was just approaching the combat area. Lindbergh fired in a defensive reaction brought on by Shimada's apparent head-on ramming attack. Hit by cannon and machine gun fire, the "Sonia's" propeller visibly slowed, but Shimada held his course. Lindbergh pulled up at the last moment to avoid collision as the damaged "Sonia" went into a steep dive, hit the ocean and sank. Lindbergh's wingman, ace Joseph E. "Fishkiller" Miller, Jr., had also scored hits on the "Sonia" after it had begun its fatal dive, but Miller was certain the kill credit was Lindbergh's. The unofficial kill was not entered in the 475th's war record. On 12 August 1944, Lindbergh left Hollandia to return to the United States.

The seventh-ranking American ace, Charles H. MacDonald, flew a Lightning against the Japanese, scoring 27 kills in his famous aircraft, the "Putt Putt Maru".

Robin Olds was the last P-38 ace in the Eighth Air Force and the last in the ETO. Flying a P-38J, he downed five German fighters on two separate missions over France and Germany. He subsequently transitioned to P-51s and scored seven more kills. After World War II, he flew F-4 Phantom IIs in Vietnam, ending his career as brigadier general with 16 kills.

Ross is a decorated World War II pilot who flew 96 missions for the U.S. Army Air Forces under the U.S. 8th Air Force's 7th Reconnaissance Group in the 22nd Reconnaissance Squadron. Ross flew the Lockheed P-38 Lightning as a photoreconnaissance pilot out of RAF Mount Farm in England during the war. He received 11 medals and was awarded the Distinguished Flying Cross twice for missions that were integral to Allied victory at the Battle of the Bulge.

At midday on 31 July 1944, the noted aviation pioneer and writer Antoine de Saint-Exupéry ("Night Flight", "Wind, Sand and Stars" and "The Little Prince") vanished in his P-38 of the French "Armée de l'Air's" "Groupe de Chasse II/33", after departing Borgo-Porreta, Corsica. His health, both physically and mentally, had been deteriorating. Saint-Exupéry was said to be intermittently subject to depression and there had been talk of taking him off flying status. He was on a flight over the Mediterranean, from Corsica to mainland France, in an unarmed F-5B photoreconnaissance variant of the P-38J, described as being a "war-weary, non-airworthy craft".

In 2000, a French scuba diver found the partial remnants of a Lightning spread over several thousand square meters of the Mediterranean seabed off the coast of Marseille. In April 2004, the recovered component serial numbers were confirmed as being from Saint-Exupéry's F-5B Lightning. Only a small amount of the aircraft's wreckage was recovered. In June 2004, the recovered parts and fragments were given to the Air and Space Museum of France in Le Bourget, Paris, where Saint-Exupéry's life is commemorated in a special exhibit.

In 1981 and also in 2008, two Luftwaffe fighter pilots, respectively Robert Heichele and Horst Rippert, separately claimed to have shot down Saint-Exupéry's P-38. Both claims were unverifiable and possibly self-promotional, as neither of their units' combat records of action from that period made any note of such a shoot-down.

A P-38 piloted by Clay Tice was the first American aircraft to land in Japan after VJ Day, when he and his wingman set down on Nitagahara because his wingman was low on fuel.

The RAF's notable photoreconnaissance pilot, Wing Commander Adrian Warburton (DSO w/Bar, DFC w/2 Bars) was posted as the RAF Liaison Officer to the USAAF 7th Photographic Reconnaissance Group. On 12 April 1944 he took off in a P-38 with others to photograph targets in Germany. Warburton failed to arrive at the rendezvous point and was never seen again. In 2003, his remains were recovered in Germany from his wrecked aircraft.

Harley Earl arranged for several of his designers to view a YP-38 prototype shortly before World War II, and its design directly inspired the tail fins of the 1948–1949 Cadillac.

The P-38 was also the inspiration for Raymond Loewy and his design team at Studebaker for the 1950 and 1951 model-year Studebakers.

The whine of the speeder bike engines in "Return of the Jedi" was partly achieved by recording the engine noise of a P-38, combined with that of a North American P-51 Mustang.

The Japanese video game company Capcom features the P-38 in its "19XX" series of arcade games, including "", "1942", and "".




</doc>
<doc id="25042" url="https://en.wikipedia.org/wiki?curid=25042" title="Prayer">
Prayer

Prayer is an invocation or act that seeks to activate a rapport with an object of worship, typically a deity, through deliberate communication.

Prayer can take a variety of forms, it can be part of a set liturgy or ritual, 
it can be performed alone, or in groups.
Prayer may take the form of a hymn, incantation, formal creedal statement, or a spontaneous utterance in the praying person. 

The English term "prayer" is from Medieval Latin "precaria" "petition, prayer". 
The Vulgate Latin is "oratio", which translates Greek 
προσευχή in turn the Septuagint translation of Biblical Hebrew "tĕphillah".
In the narrow sense, the term refer to an act of supplication or intercession directed towards a deity, or a deified ancestor. More generally, prayer can also have the purpose of thanksgiving or praise, and in comparative religion is closely associated with more abstract forms of meditation and with charms or spells.
Today, most major religions involve prayer in one way or another; some ritualize the act, requiring a strict sequence of actions or placing a restriction on who is permitted to pray, while others teach that prayer may be practiced spontaneously by anyone at any time.

Various spiritual traditions offer a wide variety of devotional acts. There are morning and evening prayers, graces said over meals, and reverent physical gestures. Some Christians bow their heads and fold their hands. Some Native Americans regard dancing as a form of prayer. Some Sufis whirl. Hindus chant mantras. Jewish prayer may involve swaying back and forth and bowing. Muslims practice "salat" (kneeling and prostration) in their prayers. Quakers keep silent. Some pray according to standardized rituals and liturgies, while others prefer extemporaneous prayers. Still others combine the two.

Friedrich Heiler is often cited in Christian circles for his systematic "Typology of Prayer" which lists six types of prayer: primitive, ritual, Greek cultural, philosophical, mystical, and prophetic. Some forms of prayer require a prior ritualistic form of cleansing or purification such as in ghusl and wudhu.

Prayer may be done privately and individually, or it may be done corporately in the presence of fellow believers. Prayer can be incorporated into a daily "thought life", in which one is in constant communication with a god. Some people pray throughout all that is happening during the day and seek guidance as the day progresses. This is actually regarded as a requirement in several Christian denominations, although enforcement is not possible nor desirable. There can be many different answers to prayer, just as there are many ways to interpret an answer to a question, if there in fact comes an answer. Some may experience audible, physical, or mental epiphanies. If indeed an answer comes, the time and place it comes is considered random.
Some outward acts that sometimes accompany prayer are: anointing with oil; ringing a bell; burning incense or paper; lighting a candle or candles; See, for example, facing a specific direction (i.e. towards Mecca or the East); making the sign of the cross. One less noticeable act related to prayer is fasting.

A variety of body postures may be assumed, often with specific meaning (mainly respect or adoration) associated with them: standing; sitting; kneeling; prostrate on the floor; eyes opened; eyes closed; hands folded or clasped; hands upraised; holding hands with others; a laying on of hands and others. Prayers may be recited from memory, read from a book of prayers, or composed spontaneously as they are prayed. They may be said, chanted, or sung. They may be with musical accompaniment or not. There may be a time of outward silence while prayers are offered mentally. Often, there are prayers to fit specific occasions, such as the blessing of a meal, the birth or death of a loved one, other significant events in the life of a believer, or days of the year that have special religious significance. Details corresponding to specific traditions are outlined below.

Anthopologically, the concept of prayer is closely related to that of surrender and supplication. 
The traditional posture of prayer in medieval Europe is kneeling or supine with clasped hands, in antiquity more typically with raised hands. The early Christian prayer posture was standing, looking up to heaven, with outspread arms and bare head. This is the pre-Christian, pagan prayer posture (except for the bare head, which was prescribed for males in Corintians 11:4, in Roman paganism, the head had to be covered in prayer).
Certain Cretan and Cypriote figures of the Late Bronze Age, with arms raised, have been interpreted as worshippers.
Their posture is similar to the "flight" posture, a crouching posture with raised hands, observed in schizophrenic patients and related to the universal "hands up" gesture of surrender.
The kneeling posture with clasped hands appears to have been introduced only with the beginning high medieval period, presumably adopted from a gesture of feudal homage.

Although prayer in its literal sense is not used in animism, communication with the spirit world is vital to the animist way of life. This is usually accomplished through a shaman who, through a trance, gains access to the spirit world and then shows the spirits' thoughts to the people. Other ways to receive messages from the spirits include using astrology or contemplating fortune tellers and healers. 

Some of the oldest extant literature, such as the Sumerian temple hymns of Enheduanna (c. 23th century BC) are liturgy addressed to deities and thus technically "prayer".
The Egyptian Pyramid Texts of about the same period similarly contain spells or incantations addressed to the gods.
In the loosest sense, in the form of magical thinking combined with animism, 
prayer has been argued as representing a human cultural universal, which would have been present since the emergence of behavioral modernity, by anthropologists such as Sir Edward Burnett Tylor and Sir James George Frazer.

Reliable records are available for the polytheistic religions of the Iron Age, 
most notably Ancient Greek religion (which strongly influenced Roman religion).
These religious traditions were direct developments of the earlier Bronze Age religions.
Ceremonial prayer was highly formulaic and ritualized. 
In ancient polytheism, ancestor worship is indistinguishable from theistic worship (see also Euhemerism).
Vestiges of ancestor worship persist, to a greater or lesser extent, in modern religious traditions throughout the world, most notably in Japanese Shinto and in Chinese folk religion.
The practices involved in Shinto prayer are heavily influenced by Buddhism; Japanese Buddhism has also been strongly influenced by Shinto in turn. Shinto prayers quite frequently consist of wishes or favors asked of the "kami", rather than lengthy praises or devotions.
The practice of votive offering is also universal, and is attested at least since the Bronze Age.
In Shinto, this takes the form of a small wooden tablet, called an "ema".

Prayers in Etruscan were used in the Roman world by augurs and other oracles long after Etruscan became a dead language. The Carmen Arvale and the Carmen Saliare are two specimens of partially preserved prayers that seem to have been unintelligible to their scribes, and whose language is full of archaisms and difficult passages.

Roman prayers and sacrifices were often envisioned as legal bargains between deity and worshipper. The Roman principle was expressed as "do ut des": "I give, so that you may give." Cato the Elder's treatise on agriculture contains many examples of preserved traditional prayers; in one, a farmer addresses the unknown deity of a possibly sacred grove, and sacrifices a pig in order to placate the god or goddess of the place and beseech his or her permission to cut down some trees from the grove.
Celtic, Germanic and Slavic religions are recorded much later, and much more fragmentarily, than the religions of classical antiquity. 
They nevertheless show substantial parallels to the better-attested religions of the Iron Age.
In the case of Germanic religion, the practice of prayer is reliably attested, but no actual liturgy is recorded from the early (Roman era) period. An Old Norse prayer is on record in the form of a dramatization in skaldic poetry. This prayer is recorded in stanzas 2 and 3 of the poem "Sigrdrífumál", compiled in the 13th century "Poetic Edda" from earlier traditional sources, where the valkyrie Sigrdrífa prays to the gods and the earth after being woken by the hero Sigurd.
A prayer to Odin is mentioned in chapter 2 of the "Völsunga saga" where King Rerir prays for a child. In stanza 9 of the poem "Oddrúnargrátr", a prayer is made to "kind wights, Frigg and Freyja, and many gods
In chapter 21 of "Jómsvíkinga saga", wishing to turn the tide of the Battle of Hjörungavágr, Haakon Sigurdsson eventually finds his prayers answered by the goddesses Þorgerðr Hölgabrúðr and Irpa.
Folk religion in the medieval period produced syncretisms between pre-Christian and Christian traditions. An example is 
the 11th-century Anglo-Saxon charm "Æcerbot" for the fertility of crops and land, or the medical "Wið færstice
". The 8th-century Wessobrunn Prayer has been proposed as a Christianized pagan prayer and compared to the pagan "Völuspá" and the Merseburg Incantations, the latter recorded in the 9th or 10th century but of much older traditional origins.

In Australian Aboriginal mythology, prayers to the "Great Wit" are performed by the "clever men" and "clever women", or "kadji". These Aboriginal shamans use maban or mabain, the material that is believed to give them their purported magical powers.
The Pueblo Indians are known to have used prayer sticks, that is, sticks with feathers attached as supplicatory offerings. The Hopi Indians used prayer sticks as well, but they attached to it a small bag of sacred meal.

From Biblical times to today, the most common form of prayer is to directly appeal to God to grant one's requests. This in many ways is the simplest form of prayer. Some have termed this the social approach to prayer. In this view, a person directly enters into God's rest, and asks for their needs to be fulfilled. God listens to the prayer, and may so or not choose to answer in the way one asks of Him. This is the primary approach to prayer found in the Hebrew Bible, the New Testament, most of the Church writings, and in rabbinic literature such as the Talmud.

Atheist arguments against prayer are mostly directed against petitionary prayer in particular. Daniel Dennett argued that petitionary prayer might have the undesirable psychological effect of relieving a person of the need to take active measures.
This potential drawback manifests in extreme forms in such cases as Christian Scientists who rely on prayers instead of seeking medical treatment for family members for easily curable conditions which later result in death.
Christopher Hitchens (2012) argued that praying to a god which is omnipotent and all-knowing would be "presumptuous". For example, he interprets Ambrose Bierce's definition of prayer by stating that "the man who prays is the one who thinks that god has arranged matters all wrong, but who also thinks that he can instruct god how to put them right."

In this view, prayer is not a conversation. Rather, it is meant to inculcate certain attitudes in the one who prays, but not to influence. Among Jews, this has been the approach of Rabbenu Bachya, Rabbi Yehuda Halevi, Joseph Albo, Samson Raphael Hirsch, and Joseph B. Soloveitchik. This view is expressed by Rabbi Nosson Scherman in the overview to the Artscroll Siddur (p. XIII).

Among Christian theologians, E.M. Bounds stated the educational purpose of prayer in every chapter of his book, "The Necessity of Prayer". Prayer books such as the Book of Common Prayer are both a result of this approach and an exhortation to keep it.

In this view, the ultimate goal of prayer is to help train a person to focus on divinity through philosophy and intellectual contemplation (meditation). This approach was taken by the Jewish scholar and philosopher Maimonides and the other medieval rationalists; it became popular in Jewish, Christian, and Islamic intellectual circles, but never became the most popular understanding of prayer among the laity in any of these faiths. In all three of these faiths today, a significant minority of people still hold to this approach.

In this approach, the purpose of prayer is to enable the person praying to gain a direct experience of the recipient of the prayer (or as close to direct as a specific theology permits). This approach is very significant in Christianity and widespread in Judaism (although less popular theologically). In Eastern Orthodoxy, this approach is known as hesychasm. It is also widespread in Sufi Islam, and in some forms of mysticism. It has some similarities with the rationalist approach, since it can also involve contemplation, although the contemplation is not generally viewed as being as rational or intellectual. Christian and Roman Catholic traditions also include an experiential approach to prayer within the practice of Lectio Divina, historically a Benedictine practice in which scripture is read aloud; actively meditated upon using the intellect (but not analysis) possibly using the mind to place the listener within a relationship or dialogue with the text that was read; a prayer spoken; and finally concludes with , a more passive experiential approach than the previous meditation, which is characterized by the Catechism of the Catholic Church as an experience of consciously being attentive, and having a silent love toward God, which the individual experiences without demanding to receive an experience. The experience of God within Christian mysticism has been contrasted with the concept of experiential religion or mystical experience because of a long history or authors living and writing about experience with the divine in a manner that identifies God as unknowable and ineffable, the language of such ideas could be characterized paradoxically as "experiential", as well as without the phenomena of experience.

The notion of "religious experience" can be traced back to William James, who used a term called "religious experience" in his book, "The Varieties of Religious Experience". The origins of the use of this term can be dated further back.

In the 18th, 19th, and 20th centuries, several historical figures put forth very influential views that religion and its beliefs can be grounded in experience itself. While Kant held that moral experience justified religious beliefs, John Wesley in addition to stressing individual moral exertion thought that the religious experiences in the Methodist movement (paralleling the Romantic Movement) were foundational to religious commitment as a way of life.

Wayne Proudfoot traces the roots of the notion of "religious experience" to the German theologian Friedrich Schleiermacher (1768–1834), who argued that religion is based on a feeling of the infinite. The notion of "religious experience" was used by Schleiermacher and Albert Ritschl to defend religion against the growing scientific and secular critique, and defend the view that human (moral and religious) experience justifies religious beliefs.

Such religious empiricism would be later seen as highly problematic and was — during the period in-between world wars — famously rejected by Karl Barth. In the 20th century, religious as well as moral experience as justification for religious beliefs still holds sway. Some influential modern scholars holding this liberal theological view are Charles Raven and the Oxford physicist/theologian Charles Coulson.

The notion of "religious experience" was adopted by many scholars of religion, of which William James was the most influential.

The notion of "experience" has been criticised. Robert Sharf points out that "experience" is a typical Western term, which has found its way into Asian religiosity via western influences. The notion of "experience" introduces a false notion of duality between "experiencer" and "experienced", whereas the essence of kensho is the realisation of the "non-duality" of observer and observed. "Pure experience" does not exist; all experience is mediated by intellectual and cognitive activity. The specific teachings and practices of a specific tradition may even determine what "experience" someone has, which means that this "experience" is not the "proof" of the teaching, but a "result" of the teaching. A pure consciousness without concepts, reached by "cleaning the doors of perception", would be an overwhelming chaos of sensory input without coherence.

In the Hebrew Bible, various forms of prayer appear; the most common forms being petition, thanksgiving, and worship. 
The longest book in the Bible is the Book of Psalms, 150 religious songs which are often regarded as prayers. Other well-known Biblical prayers include the Song of Moses (Exodus 15:1–18), the Song of Hannah (1 Samuel 2:1–10), and the Magnificat (Luke 1:46–55).

Observant Jews pray three times a day, Shacharit, Mincha, and Ma'ariv with lengthier prayers on special days, such as the Shabbat and Jewish holidays including Musaf and the reading of the Torah. The siddur is the prayerbook used by Jews all over the world, containing a set order of daily prayers. Jewish prayer is usually described as having two aspects: "kavanah" (intention) and "keva" (the ritualistic, structured elements).

The most important Jewish prayers are the Shema Yisrael ("Hear O Israel") and the Amidah ("the standing prayer").

Communal prayer is preferred over solitary prayer, and a quorum of 10 adult males (a minyan) is considered by Orthodox Judaism a prerequisite for several communal prayers.
There are also many other ritualistic prayers a Jew performs during their day, such as washing before eating bread, washing after one wakes up in the morning, and doing grace after meals.

In this view, the ultimate goal of prayer is to help train a person to focus on divinity through philosophy and intellectual contemplation. This approach was taken by Maimonides and the other medieval rationalists. One example of this approach to prayer is noted by Rabbi Steven Weil, who was appointed the Orthodox Union's Executive-Vice President in 2009. He notes that the word "prayer" is a derivative of the Latin "precari", which means "to beg". The Hebrew equivalent "tefilah", however, along with its root "pelel" or its reflexive "l’hitpallel", means the act of self-analysis or self-evaluation. This approach is sometimes described as the person praying having a dialogue or conversation with God.

In this view, prayer is not a conversation. Rather, it is meant to inculcate certain attitudes in the one who prays, but not to influence. This has been the approach of Rabbenu Bachya, Yehuda Halevy, Joseph Albo, Samson Raphael Hirsch, and Joseph Dov Soloveitchik. This view is expressed by Rabbi Nosson Scherman in the overview to the Artscroll Siddur (p. XIII); note that Scherman goes on to also affirm the Kabbalistic view (see below).

Kabbalah (Jewish mysticism) uses a series of kavanot, directions of intent, to specify the path the prayer ascends in the dialog with God, to increase its chances of being answered favorably. Kabbalists ascribe a higher meaning to the purpose of prayer, which is no less than affecting the very fabric of reality itself, restructuring and repairing the universe in a real fashion. In this view, every word of every prayer, and indeed, even every letter of every word, has a precise meaning and a precise effect. Prayers thus literally affect the mystical forces of the universe, and repair the fabric of creation.

Among Jews, this approach has been taken by the Chassidei Ashkenaz (German pietists of the Middle-Ages), the Arizal's Kabbalist tradition, Ramchal, most of Hassidism, the Vilna Gaon, and Jacob Emden.

The most recognized prayers in the Christian Bible are the Lord's Prayer (Matthew 6:9–13; Luke 11:2–4) and the Grace (2 Cor 13:14). Whilst the Hail Mary (Luke 1:28; Luke 1:42) is predominantly Roman Catholic.

Christian prayers are quite varied. They can be completely spontaneous, or read entirely from a text, like the Anglican Book of Common Prayer. The most common prayer among Christians is the Lord's Prayer, which according to the gospel accounts (e.g. ) is how Jesus taught his disciples to pray. The Lord's Prayer is a model for prayers of adoration, confession and petition in Christianity.
In medieval England, prayers (particularly the "paternoster") were frequently used as a measure of time in medical and culinary recipe books.

Christians generally pray to God or to the Father. Some Christians (e.g., Catholics, Orthodox) will also ask the righteous in heaven and "in Christ," such as Virgin Mary or other saints to intercede by praying on their behalf (intercession of saints). Formulaic closures include "through our Lord Jesus Christ, Your Son, who lives and reigns with You, in the unity of the Holy Spirit, God, through all the ages of ages," and "in the name of the Father, and the Son, and the Holy Spirit."

It is customary among Protestants to end prayers with "In Jesus' name, Amen" or "In the name of Christ, Amen." However, the most commonly used closure in Christianity is simply "Amen" (from a Hebrew adverb used as a statement of affirmation or agreement, usually translated as "so be it").

In the Western or Latin Rite of the Roman Catholic Church, probably the most common is the Rosary; In the Eastern Church (the Eastern rites of the Catholic Church and Orthodox Church), the Jesus Prayer. The Jesus Prayer is also often repeated as part of the meditative hesychasm practice in Eastern Christianity.

Roman Catholic tradition includes specific prayers and devotions as "acts of reparation" which do not involve a petition for a living or deceased beneficiary, but aim to "repair the sins of others", e.g. for the repair of the sin of blasphemy performed by others.

Other forms of prayer among Catholics would be meditative prayer, contemplative prayer and infused prayer discussed at length by Catholic Saints St. John of the Cross and St. Theresa of Jesus.

In Pentecostal congregations, prayer is often accompanied by speaking in a foreign tongue, a practice now known as glossolalia. Practitioners of Pentecostal glossolalia may claim that the languages they speak in prayer are real foreign languages, and that the ability to speak those languages spontaneously is a gift of the Holy Spirit.

Some people outside of the movement, however, have offered dissenting views. George Barton Cutten suggested that glossolalia was a sign of mental illness. Felicitas Goodman suggested that tongue speakers were under a form of hypnosis. Others suggest that it is a learned behaviour. Some of these views have allegedly been refuted.

Christian Science teaches that prayer is a spiritualization of thought or an understanding of God and of the nature of the underlying spiritual creation. Adherents believe that this can result in healing, by bringing spiritual reality (the "Kingdom of Heaven" in Biblical terms) into clearer focus in the human scene. The world as it appears to the senses is regarded as a distorted version of the world of spiritual ideas. Prayer can heal the distortion. Christian Scientists believe that prayer does not change the spiritual creation but gives a clearer view of it, and the result appears in the human scene as healing: the human picture adjusts to coincide more nearly with the divine reality. Christian Scientists do not practice intercessory prayer as it is commonly understood, and they generally avoid combining prayer with medical treatment in the belief that the two practices tend to work against each other. (However, the choice of healing method is regarded as a matter for the individual, and the Christian Science Church exerts no pressure on members to avoid medical treatment if they wish to avail of it as an alternative to Christian Science healing.) Prayer works through love: the recognition of God's creation as spiritual, intact, and inherently lovable.

Some modalities of alternative medicine employ prayer. A survey released in May 2004 by the National Center for Complementary and Alternative Medicine, part of the National Institutes of Health in the United States, found that in 2002, 43% of Americans pray for their own health, 24% pray for others' health, and 10% participate in a prayer group for their own health.

The Arabic word for prayer is "salah." In Islam, there are five daily obligatory prayers that are considered as one of the pillars of the religion. The command to ritual prayer occurs repeatedly in the Quran.
The prayer is performed by the person while they are facing the Kaaba in Mecca. There is the "call for prayer" ("adhan"), where the "muezzin" calls for all the followers to stand together for the prayer. The prayer consists of actions such as glorifying and praising God (such as mentioning ‘Allāhu Akbar’ (God is Great) while standing, recitation of chapters of the Quran (such as the opening chapter of the book ("Al-Fatiha"), bowing down then praising God, prostrating (sujud) then again praising God and it ends with the words: "Peace be with you and God’s mercy". During the prayer, a Muslim cannot talk or do anything else besides pray. Once the prayer is complete, one can offer personal prayers or supplications to God for their needs that are known as "dua". There are many standard invocations in Arabic to be recited at various times ("e.g." after the prayer) and for various occasions ("e.g." for one's parents) with manners and etiquette such as before eating. Muslims may also say "dua" in their own words and languages for any issue they wish to communicate with God in the hope that God will answer their prayers.
Certain Shi'a sects pray the five daily prayers divided into three separate parts of the day, providing several Hadith as supporting evidence.

Bahá'u'lláh, the Báb, and `Abdu'l-Bahá wrote many prayers for general use, and some for specific occasions, including for unity, detachment, spiritual upliftment, and healing among others. Bahá'ís are also required to recite each day one of three obligatory prayers composed by Bahá'u'lláh. The believers have been enjoined to face in the direction of the Qiblih when reciting their Obligatory Prayer. The longest obligatory prayer may be recited at any time during the day; another, of medium length, is recited once in the morning, once at midday, and once in the evening; and the shortest can be recited anytime between noon and sunset. Bahá'ís also read from and meditate on the scriptures every morning and evening.

In both Buddhism and Hinduism, the repetition of mantras is closely related to the practice of repetitive prayer in 
Western religion (rosary, Jesus prayer).
Many of the most widespread Hindu and Buddhist mantras are in origin invocations of deities, 
e.g. Gayatri Mantra dedicated to Savitr, Pavamana Mantra to Soma Pavamana, 
and many of the Buddhist Dhāraṇī originate as recitations of lists of names or attributes of deities.
Most of the shorter Buddhist mantras originate as the invocation of the name of a specific deity or bodhisattva, 
such as Om mani padme hum being in origin the invocation of a bodhisattva called "Maṇipadma".
However, from an early time these mantras were interpreted in the context of mystical sound symbolism.
The most extreme example of this is the om syllable, which as early as in the Aitareya Brahmana was claimed as equivalent to the entire Vedas (collection of ritual hymns).

In the earliest Buddhist tradition, the Theravada, and in the later Mahayana tradition of Zen (or Chán), prayer plays only an ancillary role. It is largely a ritual expression of wishes for success in the practice and in helping all beings.

The skillful means (Sanskrit: "upāya") of the transfer of merit (Sanskrit: "pariṇāmanā") is an evocation and prayer. Moreover, indeterminate buddhas are available for intercession as they reside in awoken-fields (Sanskrit: "buddha-kshetra").

The "nirmānakāya" of an awoken-field is what is generally known and understood as a mandala. The opening and closing of the ring (Sanskrit: "maṇḍala") is an active prayer. An active prayer is a mindful activity, an activity in which mindfulness is not just cultivated but "is". A common prayer is "May the merit of my practice, adorn Buddhas' Pure Lands, requite the fourfold kindness from above, and relieve the suffering of the three life-journeys below. Universally wishing sentient beings, Friends, foes, and karmic creditors, all to activate the bodhi mind, and all to be reborn in the Pure Land of Ultimate Bliss." (願以此功德 莊嚴佛淨土 上報四重恩 下濟三途苦 普願諸眾生 冤親諸債主 悉發菩提心 同生極樂國)

The Generation Stage (Sanskrit: "utpatti-krama") of Vajrayana involves prayer elements.

The Tibetan Buddhism tradition emphasizes an instructive and devotional relationship to a guru; this may involve devotional practices known as guru yoga which are congruent with prayer. It also appears that Tibetan Buddhism posits the existence of various deities, but the peak view of the tradition is that the deities or yidam are no more existent or real than the continuity (Sanskrit: "santana"; refer mindstream) of the practitioner, environment and activity. But how practitioners engage "yidam" or tutelary deities will depend upon the level or more appropriately "yana" at which they are practicing. At one level, one may pray to a deity for protection or assistance, taking a more subordinate role. At another level, one may invoke the deity, on a more equal footing. And at a higher level one may deliberately cultivate the idea that one has become the deity, whilst remaining aware that its ultimate nature is "śūnyatā". The views of the more esoteric yana are impenetrable for those without direct experience and empowerment.

Pure Land Buddhism emphasizes the recitation by devotees of prayer-like mantras, a practice often called Nembutsu. On one level it is said that reciting these mantras can ensure rebirth into a "Sambhogakāya" land (Sanskrit: "buddha-kshetra") after bodily dissolution, a sheer ball spontaneously co-emergent to a buddha's enlightened intention. According to Shinran, the founder of the Pure Land Buddhism tradition that is most prevalent in the US, "for the long haul nothing is as efficacious as the Nembutsu." On another, the practice is a form of meditation aimed at achieving realization.

But beyond all these practices the Buddha emphasized the primacy of individual practice and experience. He said that supplication to gods or deities was not necessary. Nevertheless, today many lay people in East Asian countries pray to the Buddha in ways that resemble Western prayer—asking for intervention and offering devotion.

Hinduism has incorporated many kinds of prayer (Sanskrit: "prārthanā"), from fire-based rituals to philosophical musings. While chanting involves 'by dictum' recitation of timeless verses or verses with timings and notations, dhyanam involves deep meditation (however short or long) on the preferred deity/God. Again the object to which prayers are offered could be a persons referred as devtas, trinity or incarnation of either devtas or trinity or simply plain formless meditation as practiced by the ancient sages. These prayers can be directed to fulfilling personal needs or deep spiritual enlightenment, and also for the benefit of others. Ritual invocation was part and parcel of the Vedic religion and as such permeated their sacred texts. Indeed, the highest sacred texts of the Hindus, the Vedas, are a large collection of mantras and prayer rituals. Classical Hinduism came to focus on extolling a single supreme force, Brahman, that is made manifest in several lower forms as the familiar gods of the Hindu pantheon. Hindus in India have numerous devotional movements. Hindus may pray to the highest absolute God Brahman, or more commonly to Its three manifestations namely creator god called Brahma, preserver god called Vishnu and destroyer god (so that the creation cycle can start afresh) Shiva, and at the next level to Vishnu's avatars (earthly appearances) Rama and Krishna or to many other male or female deities. Typically, Hindus pray with their hands (the palms) joined together in "pranam". The hand gesture is similar to the popular Indian greeting "namaste".

The Ardās (Punjabi: ਅਰਦਾਸ) is a Sikh prayer that is done before performing or after undertaking any significant task; after reciting the daily Banis (prayers); or completion of a service like the Paath (scripture reading/recitation), kirtan (hymn-singing) program or any other religious program. In Sikhism, these prayers are also said before and after eating. The prayer is a plea to God to support and help the devotee with whatever he or she is about to undertake or has done.

The Ardas is usually always done standing up with folded hands. The beginning of the Ardas is strictly set by the tenth Sikh Guru, Guru Gobind Singh. When it comes to conclusion of this prayer, the devotee uses words like "Waheguru please bless me in the task that I am about to undertake" when starting a new task or "Akal Purakh, having completed the hymn-singing, we ask for your continued blessings so that we can continue with your memory and remember you at all times", etc. The word "Ardās" is derived from Persian word 'Arazdashat', meaning a request, supplication, prayer, petition or an address to a superior authority.

Ardās is a unique prayer based on the fact that it is one of the few well-known prayers in the Sikh religion that was not written in its entirety by the Gurus. The Ardās cannot be found within the pages of the Guru Granth Sahib because it is a continually changing devotional text that has evolved over time in order for it to encompass the feats, accomplishments, and feelings of all generations of Sikhs within its lines. Taking the various derivation of the word Ardās into account, the basic purpose of this prayer is an appeal to Waheguru for his protection and care, as well as being a plea for the welfare and prosperity of all mankind, and a means for the Sikhs to thank Waheguru for all that he has done.

Wiccan prayers can include meditation, rituals and incantations. Prayers are seen as a form of communication with the God and Goddess. This may include prayers for esbat and sabbat celebrations, for dinner, for pre-dawn times or for your own or others safety, for healing or for the dead.

In Raëlism rites and practises vary from initiation ceremonies, to sensual meditation. An initiation ceremony usually involves a Raelian putting water on the forehead of a new member. Such ceremonies are performed on certain special days on the Raelian calendar. Sensual meditation techniques include breathing exercises and various forms of erotic meditation.

In Eckankar, one of the basic forms of prayer includes singing the word "HU" which is pronounced as "hue", a holy name of God. This can be done with eyes closed or open, aloud or silently. Practitioners may experience the divine ECK or Holy Spirit.

Practitioners of theurgy and western esotericism may practice a form of ritual which utilizes both pre-sanctioned prayers and names of God, and prayers "from the heart" that, when combined, allows the participant to ascend spiritually, and in some instances, induce a trance in which God or other spiritual beings may be realized. Very similar to hermetic qabala, and orthodox qabala, it is believed that prayer can influence both the physical and non-physical worlds. The use of ritualistic signs and names are believed to be archetypes in which the subconscious may take form as the Inner God, or another spiritual being, and the "prayer from the heart" to be that spiritual force speaking through the participant.

In Thelema (a religion or system of philosophy that includes both theist as well as atheist practitioners) adherents share a number of practices that are forms of individual prayer, including basic yoga; (asana and pranayama); various forms of ritual magick; rituals of one's own devising (often based upon a syncretism of religions, or Western Esotericism, such as the Lesser Banishing Ritual of the Pentagram and Star Ruby); and performance of Liber Resh vel Helios (aka Liber 200), which consists of four daily adorations to the sun (often consisting of 4 hand/body positions and recitation of a memorized song, normally spoken, addressing different godforms identified with the sun).

While there is no dogma within Thelema that expresses the purpose behind any individual aspirant who chooses to perform "Resh", it may be noted that the practice of "Resh" is not a simple petition toward the sun, nor a form of "worshiping" the celestial body that we call the Sun, but instead uses the positioning of that source of light, which enables life on our planet, as well as uses mythological images of that solar force, so that the individual can perform the prayer, possibly furthering a self-identification with the sun, so "that repeated application of the Liber Resh adorations expands the consciousness of the individual by compelling him to take a different perspective, by inducing him to 'look at things from the point of view of the Sun'.

Prayer is often used
as a means of faith healing in an attempt to use religious or spiritual means to prevent illness, cure disease, or improve health. 

Scientific studies regarding the use of prayer have mostly concentrated on its effect on the healing of sick or injured people. Meta-studies of the studies in this field have been performed showing evidence only for no effect or a potentially small effect. For instance, a 2006 meta analysis on 14 studies concluded that there is "no discernable effect" while a 2007 systemic review of studies on intercessory prayer reported inconclusive results, noting that 7 of 17 studies had "small, but significant, effect sizes" but the review noted that the most methodologically rigorous studies failed to produce significant findings. Some studies have indicated increased medical complications in groups receiving prayer over those without. 
The efficacy of petition in prayer for physical healing to a deity has been evaluated in numerous other studies, with contradictory results. There has been some criticism of the way the studies were conducted.

Some attempt to heal by prayer, mental practices, spiritual insights, or other techniques, claiming they can summon divine or supernatural intervention on behalf of the ill. Others advocate that ill people may achieve healing through prayer performed by themselves. According to the varied beliefs of those who practice it, faith healing may be said to afford gradual relief from pain or sickness or to bring about a sudden "miracle cure", and it may be used in place of, or in tandem with, conventional medical techniques for alleviating or curing diseases. Faith healing has been criticized on the grounds that those who use it may delay seeking potentially curative conventional medical care. This is particularly problematic when parents use faith healing techniques on children.

In 1872, Francis Galton conducted a famous statistical experiment to determine whether prayer had a physical effect on the external environment. Galton hypothesized that if prayer was effective, members of the British Royal family would live longer, given that thousands prayed for their wellbeing every Sunday. He therefore compared longevity in the British Royal family with that of the general population, and found no difference. While the experiment was probably intended to satirize, and suffered from a number of confounders, it set the precedent for a number of different studies, the results of which are contradictory.

Two studies claimed that patients who are being prayed for recover more quickly or more frequently although critics have claimed that the methodology of such studies are flawed, and the perceived effect disappears when controls are tightened. One such study, with a double-blind design and about 500 subjects per group, was published in 1988; it suggested that intercessory prayer by born again Christians had a statistically significant positive effect on a coronary care unit population. Critics contend that there were severe methodological problems with this study. Another such study was reported by Harris et al. Critics also claim that the 1988 study was not fully double-blinded, and that in the Harris study, patients actually had a longer hospital stay in the prayer group, if one discounts the patients in both groups who left before prayers began, although the Harris study did demonstrate the prayed for patients on average received lower course scores (indicating better recovery).

One of the largest randomized, blind clinical trials was a remote "retroactive" intercessory prayer study conducted in Israel by Leibovici. This study used 3393 patient records from 1990–96, and blindly assigned some of these to an intercessory prayer group. The prayer group had shorter hospital stays and duration of fever.

Several studies of prayer effectiveness have yielded null results. A 2001 double-blind study of the Mayo Clinic found no significant difference in the recovery rates between people who were (unbeknownst to them) assigned to a group that prayed for them and those who were not. Similarly, the MANTRA study conducted by Duke University found no differences in outcome of cardiac procedures as a result of prayer. In another similar study published in the "American Heart Journal" in 2006, Christian intercessory prayer when reading a scripted prayer was found to have no effect on the recovery of heart surgery patients; however, the study found patients who had knowledge of receiving prayer had slightly higher instances of complications than those who did not know if they were being prayed for or those who did not receive prayer. Another 2006 study suggested that prayer actually had a significant negative effect on the recovery of cardiac bypass patients, resulting in more frequent deaths and slower recovery time for those patient who received prayers.

Many believe that prayer can aid in recovery, not due to divine influence but due to psychological and physical benefits. It has also been suggested that if a person knows that he or she is being prayed for it can be uplifting and increase morale, thus aiding recovery. (See Subject-expectancy effect.) Many studies have suggested that prayer can reduce physical stress, regardless of the god or gods a person prays to, and this may be true for many worldly reasons. According to a study by Centra State Hospital, "the psychological benefits of prayer may help reduce stress and anxiety, promote a more positive outlook, and strengthen the will to live." Other practices such as yoga, t'ai chi, and meditation may also have a positive impact on physical and psychological health.

Others feel that the concept of conducting prayer experiments reflects a misunderstanding of the purpose of prayer. The previously mentioned study published in the "American Heart Journal" indicated that some of the intercessors who took part in it complained about the scripted nature of the prayers that were imposed to them, saying that this is not the way they usually conduct prayer: 

One scientific movement attempts to track the physical effects of prayer through neuroscience. Leaders in this movement include Andrew Newberg, an Associate Professor at the University of Pennsylvania. In Newberg's brain scans, monks, priests, nuns, sisters and gurus alike have exceptionally focused attention and compassion sites. This is a result of the frontal lobe of the brain’s engagement (Newberg, 2009). Newburg believes that anybody can connect to the supernatural with practice. Those without religious affiliations benefit from the connection to the metaphysical as well. Newberg also states that further evidence towards humans' need for metaphysical relationships is that as science had increased spirituality has not decreased. Newburg believes that at the end of the 18th century, when the scientific method began to consume the human mind, religion could have vanished. However, two hundred years later, the perception of spirituality, in many instances, appears to be gaining in strength (2009). Newberg's research also provides the connection between prayer and meditation and health. By understanding how the brain works during religious experiences and practices Newberg's research shows that the brain changes during these practices allowing an understanding of how religion affects psychological and physical health (2009). For example, brain activity during meditation indicates that people who frequently practice prayer or meditation experience lower blood-pressure, lower heart rates, decreased anxiety, and decreased depression.



</doc>
<doc id="25044" url="https://en.wikipedia.org/wiki?curid=25044" title="Punjabi language">
Punjabi language

Punjabi (; Gurmukhi: ; Shahmukhi: ) is an Indo-Aryan language with more than 100 million native speakers worldwide. It is the native language of the Punjabi people, an ethnic group of the cultural region of Punjab. The Punjab extends from northwest India through eastern Pakistan.

As of 2015, Punjabi is the 10th most widely spoken language in the world. It is the most widely spoken language in Pakistan, the 11th most widely spoken language in India, and the third most-spoken native language in the Indian Subcontinent. In Canada, it is the fifth most-spoken native language, after English, French, Mandarin and Cantonese. It has a significant presence in the United Arab Emirates, the United States, the United Kingdom, Australia, New Zealand, Italy, and the Netherlands.

Punjabi is unusual among Indo-European languages in its use of lexical tone (that is, the way in which the pitch of the voice conveys meaning). The Punjabi language is written in one of two alphabets: Shahmukhi or Gurmukhi. In the Punjab, both writing systems are used (a rare occurrence called synchronic digraphia): Shahmukhi is used mainly by Punjabi Muslims, and Gurmukhi is used mainly by Punjabi Sikhs and Hindus.

The word Punjabi has been derived from the word Panj-āb, Persian for "Five Waters", referring to the five major eastern tributaries of the Indus River. The name of the region was introduced by the Turko-Persian conquerors of South Asia and was a translation of the Sanskrit name for the region, "Panchanada", which means "Land of the Five Rivers".. "Panj" is cognate with Sanskrit "पञ्च ()" and Greek "" "five", and "āb" is cognate with Sanskrit "अप् (áp)" and with the of . The historical Punjab region, now divided between India and Pakistan, is defined physiographically by the Indus River and these five tributaries. One of the five, the Beas River, is a tributary of another, the Sutlej.

Punjabi developed from Sanskrit through Prakrit languages and later Apabhraṃśa (Sanskrit: अपभ्रंश; corruption or corrupted speech) From 600 BC Sanskrit gave birth to many regional languages in different parts of India. All these languages are called Prakrit (Sanskrit: प्राकृत prākṛta) collectively. Shauraseni Prakrit was one of these Prakrit languages, which was spoken in north and north-western India and Punjabi and western dialects of Hindi developed from this Prakrit. Later in northern India Shauraseni Prakrit gave rise to Shauraseni Aparbhsha, a descendent of Prakrit. Punjabi emerged as an Apabhramsha, a degenerated form of Prakrit, in the 7th century A.D. and became stable by the 10th century. By the 10th century, many Nath poets were associated with earlier Punjabi works.

Arabic and Persian influence in the historical Punjab region began with the late first millennium Muslim conquests on the Indian subcontinent. The Persian language was introduced in the subcontinent a few centuries later by various Persianized Central Asian Turkic and Afghan dynasties including that of Mahmud of Ghazni. Many Persian and Arabic words were incorporated in Punjabi. Punjabi has more Persian and Arabic vocabulary than Bengali, Marathi, and Gujarati due to the proximity of the Punjab with western Asia. It is noteworthy that the Hindustani language divided into Hindi, with more Sanskritisation, and Urdu, with more Persianisation, but in Punjabi both Sanskrit and Persian words are used with a liberal approach to language. Later, it was influenced by Portuguese and English, though these influences have been minor in comparison to Persian and Arabic. However, in India, English words in the official language are more widespread than Hindi.

Punjabi is the most widely spoken language in Pakistan, the eleventh -most widely spoken in India and spoken Punjabi diaspora in various countries.

Punjabi is the most widely spoken language in Pakistan, being the native language of % of its population. It is the provincial language in the Punjab Province.

Beginning with the 1981 census, speakers of Saraiki and Hindko were no longer included in the total numbers for Punjabi, which could explain the apparent decrease.

Punjabi is spoken as a native language, second language, or third language by about 30 million people in India. Punjabi is the official language of the Indian states of Punjab, Haryana and Delhi. Some of its major urban centres in northern India are Ambala, Ludhiana, Amritsar, Chandigarh, Jalandhar, and Delhi.

Punjabi is also spoken as a minority language in several other countries where Punjabi people have emigrated in large numbers, such as the United States, Australia, the United Kingdom, and Canada, where it is the fourth-most-commonly used language.
There were 76 million Punjabi speakers in Pakistan in 2008, 33 million in India in 2011, 368,000 in Canada in 2006, and smaller numbers in other countries.
Despite Punjabi's rich literary history, it was not until 1947 that it would be recognized as an official language. Previous governments in the area of the Punjab had favoured Persian, Hindustani, or even earlier standardised versions of local registers as the language of the court or government. After the annexation of the Sikh Empire by the British East India Company following the Second Anglo-Sikh War in 1849, the British policy of establishing a uniform language for administration was expanded into the Punjab. The British Empire employed Hindi and Urdu in its administration of North-Central and North-West India, while in the North-East of India, Bengali was used as the language of administration. Despite its lack of official sanction, the Punjabi language continued to flourish as an instrument of cultural production, with rich literary traditions continuing until modern times. The Sikh religion, with its Gurmukhi script, played a special role in standardising and providing education in the language via Gurdwaras, while writers of all religions continued to produce poetry, prose, and literature in the language.

In India, Punjabi is one of the 22 scheduled languages of India. It is the first official language of the Indian State of Punjab. Punjabi also has second language official status in Delhi along with Urdu, and in Haryana. 
In Pakistan, no regional ethnic language has been granted official status at the national level, and as such Punjabi is not an official language at the national level, even though it is the most spoken language in Pakistan after Urdu, the national language of Pakistan. It is, however, the official provincial language of Punjab, Pakistan, the second largest and the most populous province of Pakistan as well as in Islamabad Capital Territory. The only two official national languages in Pakistan are Urdu and English, which are considered the lingua francas of Pakistan.


The Majhi (ماجھی ਮਾਝੀ) dialect spoken around Amritsar and Lahore is Punjabi's prestige dialect. Majhi is spoken in the heart of Punjab in the region of Majha, which spans Lahore, Amritsar, Gurdaspur, Kasur, Tarn Taran, Faisalabad, Nankana Sahib, Pathankot, Okara, Pakpattan, Sahiwal, Narowal, Sheikhupura, Sialkot, Chiniot, Gujranwala and Gujrat and in Mandi Bahauddin(97’/.) districts.

Majhi retains the nasal consonants and , which have been superseded elsewhere by non-nasals and respectively. The Majhi (and Lahnda) spoken in Pakistan is more Persianized in vocabulary, and the usage of the sounds , and is more common. (Tabbar in both dialects is informal in the following table)

Shahpuri dialect (also known as Sargodha dialect) is mostly spoken in Pakistani Punjab. Its name is derived from former Shahpur District (now Shahpur Tehsil, being part of Sargodha District). It is spoken throughout a widespread area, spoken in Sargodha and Khushab Districts and also spoken in neighbouring Mianwali and Bhakkar Districts. It is mainly spoken on western end of Sindh River to Chennab river crossing Jehlam river.

Malwai is spoken in the eastern part of Indian Punjab and also in Bahawalnagar and Vehari districts of Pakistan. Main areas are Ludhiana, Patiala, Ambala, Bathinda, Mansa, Ganganagar, Malerkotla, Fazilka, Ferozepur, Moga. Malwa is the southern and central part of present-day Indian Punjab. It also includes the Punjabi speaking northern areas of Haryana, viz. Ambala, Hissar, Sirsa, Kurukshetra etc. Not to be confused with the Malvi language, which shares its name.

Doabi is spoken in both the Indian Punjab as well as parts of Pakistan Punjab owing to post-1947 migration of Muslim populace from East Punjab. The word "Do Aabi" means "the land between two rivers" and this dialect was historically spoken between the rivers of the Beas and the Sutlej in the region called Doaba. Regions it is presently spoken includes the Jalandhar, Hoshiarpur and Kapurthala districts in Indian Punjab, specifically in the areas known as the Dona and Manjki, as well as the Toba Tek Singh and Faisalabad districts in Pakistan Punjab where the dialect is known as Faisalabadi Punjabi.

Pwadhi, Powadh, Puadh or Powadha is a region of Punjab and parts of Haryana between the Satluj and Ghaggar rivers. The part lying south, south-east and east of Rupnagar adjacent to Ambala District (Haryana) is Powadhi. The Powadh extends from that part of the Rupnagar District which lies near Satluj to beyond the Ghaggar river in the east up to Kala Amb, which is at the border of the states of Himachal pradesh and Haryana. Parts of Fatehgarh Sahib district, and parts of Patiala districts like Rajpura are also part of Powadh. The language is spoken over a large area in present Punjab as well as Haryana. In Punjab, Kharar, Kurali, Ropar, Nurpurbedi, Morinda, Pail, Rajpura and Samrala are the areas where the Puadhi is spoken and the dialect area also includes Pinjore, Kalka, Ismailabad, Pehowa to Bangar area in Fatehabad district.

Jhangochi (جھنگوچی) dialect is spoken in Pakistani Punjab throughout a widespread area, starting from Khanewal and Jhang at both ends of Ravi and Chenab to Hafizabad district.

Jangli is a dialect of former nomad tribes of areas whose names are often suffixed with 'Bar' derived from jungle bar before irrigation system arrived in the start of the 20th century, for example, Sandal Bar, Kirana Bar, Neeli Bar, Ganji Bar. Former Layllpur and western half of Montgomary district used to speak this dialect.

West of Chenaab river in Jhang district of Pakistani Punjab the dialect of Jhangochi merges with Thalochi and resultant dialect is Chenavari. Name is derived from Chenaab river.

The long vowels (the vowels with ) also have nasal analogues.

Punjabi is a tonal language and in any word there is a choice of three tones, high-falling, low-rising, and level (neutral):

Level tone is found in about 75% of words and is described by some as absence of tone. There are also some words which are said to have rising tone in the first syllable and falling in the second. (Some writers describe this as a fourth tone.) However, a recent acoustic study of six Punjabi speakers in America found no evidence of a separate falling tone following a medial consonant.

It is considered that these tones arose when voiced aspirated consonants (gh, jh, ḍh, dh, bh) lost their aspiration. At the beginning of a word they became voiceless unaspirated consonants (k, c, ṭ, t, p) followed by a high-falling tone; medially or finally they became voiced unaspirated consonants (g, j, ḍ, d, b), preceded by a low-rising tone. (The development of a high-falling tone apparently did not take place in every word, but only in those which historically had a long vowel.)

The presence of an [h] (although the [h] is now silent or very weakly pronounced except word-initially) word-finally (and sometimes medially) also often causes a rising tone before it, for example "cá(h)" "tea".

The Gurmukhi script which was developed in the 16th century has separate letters for voiced aspirated sounds, so it is thought that the change in pronunciation of the consonants and development of tones may have taken place since that time.

Some other languages in Pakistan have also been found to have tonal distinctions, including Burushaski, Gujari, Hindko, Kalami, Shina, and Torwali.

The grammar of the Punjabi language concerns the word order, case marking, verb conjugation, and other morphological and syntactic structures of the Punjabi language. The main article discusses the grammar of Modern Standard Punjabi as defined by the sources cited therein.

Punjabi has two major writing systems in use: Gurmukhi, which is a Brahmic script derived from the Laṇḍā script, and Shahmukhi, which is an Arabic script. The word Gurmukhi means "from the Guru's mouth", and Shahmukhi means "from the King's mouth".

In the Punjab province of Pakistan, the script used is Shahmukhi and differs from the Urdu alphabet in having four additional letters. In the Indian states of Punjab, Haryana and Delhi and other parts of India, the Gurmukhī script is generally used for writing Punjabi. Historically, various local Brahmic scripts including Laṇḍā were also in use.

This sample text was taken from the Punjabi Wikipedia article on Lahore.

Gurmukhi: 

Shahmukhi:

Transliteration: lahaur pākistānī panjāb dī rājdā̀ni ài. lok giṇtī de nāḷ karācī tõ bāad lahaur dūjā sáb tõ vaḍḍā šáir ài. lahor pākistān dā siāsī, rátalī te paṛā̀ī dā gáṛ ài te is laī ínū̃ pākistān dā dil vī kihā jāndā ài. lahaur dariāe rāvī de kaṇḍè te vasdā ài. te isdī lok giṇtī ikk karoṛ de neṛe ài.

Translation: Lahore is the capital city of the Pakistani Punjab. After a number of people from Karachi, Lahore is the second largest city. Lahore is Pakistan's political stronghold and education capital and so it is also the heart of Pakistan. Lahore lies on the bank of the Ravi River. And, its population is close to ten million people.

IPA: 

The "Janamsakhis" (ਜਨਮਸਾਖੀ, ), stories on the life and legend of Guru Nanak (1469–1539), are early examples of Punjabi prose literature.


The Victorian novel, Elizabethan drama, free verse and Modernism entered Punjabi literature through the introduction of British education during the Raj. Nanak Singh (1897–1971), Vir Singh, Ishwar Nanda, Amrita Pritam (1919–2005), Puran Singh (1881–1931), Dhani Ram Chatrik (1876–1957), Diwan Singh (1897–1944) and Ustad Daman (1911–1984), Mohan Singh (1905–78) and Shareef Kunjahi are some legendary Punjabi writers of this period.
After independence of Pakistan and India Najm Hossein Syed, Fakhar Zaman and Afzal Ahsan Randhawa, Shafqat Tanvir Mirza, Ahmad Salim, and Najm Hosain Syed, Munir Niazi, Pir Hadi abdul Mannan enriched Punjabi literature in Pakistan, whereas Amrita Pritam (1919–2005), Jaswant Singh Rahi (1930–1996), Shiv Kumar Batalvi (1936–1973), Surjit Patar (1944–) and Pash (1950–1988) are some of the more prominent poets and writers from India.

When Pakistan was created in 1947, although Punjabi was the majority language in West Pakistan and Bengali the majority in East Pakistan and Pakistan as whole, English and Urdu were chosen as the national languages. The selection of Urdu was due to its association with South Asian Muslim nationalism and because the leaders of the new nation wanted a unifying national language instead of promoting one ethnic group's language over another. Broadcasting in Punjabi language by Pakistan Broadcasting Corporation decreased on TV and radio after 1947. Article 251 of the Constitution of Pakistan declares that these two languages would be the only official languages at the national level, while provincial governments would be allowed to make provisions for the use of other languages. However, in the 1950s the constitution was amended to include the Bengali language. Eventually, Punjabi was granted status as a provincial language in Punjab Province, while the Sindhi language was given official status in 1972 after 1972 Language violence in Sindh.

Despite gaining official recognition at the provincial level, Punjabi is not a language of instruction for primary or secondary school students in Punjab Province (unlike Sindhi and Pashto in other provinces). Pupils in secondary schools can choose the language as an elective, while Punjabi instruction or study remains rare in higher education. One notable example is the teaching of Punjabi language and literature by the University of the Punjab in Lahore which began in 1970 with the establishment of its Punjabi Department.

In the cultural sphere, there are many books, plays, and songs being written or produced in the Punjabi-language in Pakistan. Until the 1970s, there were a large number of Punjabi-language films being produced by the Lollywood film industry, however since then Urdu has become a much more dominant language in film production. Additionally, television channels in Punjab Province (centred on the Lahore area) are broadcast in Urdu. The preeminence of Urdu in both broadcasting and the Lollywood film industry is seen by critics as being detrimental to the health of the language.

The use of Urdu and English as the near exclusive languages of broadcasting, the public sector, and formal education have led some to fear that Punjabi in Pakistan is being relegated to a low-status language and that it is being denied an environment where it can flourish. Several prominent educational leaders, researchers, and social commentators have echoed the opinion that the intentional promotion of Urdu and the continued denial of any official sanction or recognition of the Punjabi language amounts to a process of "Urdu-isation" that is detrimental to the health of the Punjabi language In August 2015, the Pakistan Academy of Letters, International Writer’s Council (IWC) and World Punjabi Congress (WPC) organised the "Khawaja Farid Conference" and demanded that a Punjabi-language university should be established in Lahore and that Punjabi language should be declared as the medium of instruction at the primary level. In September 2015, a case was filed in Supreme Court of Pakistan against Government of Punjab, Pakistan as it did not take any step to implement the Punjabi language in the province. Additionally, several thousand Punjabis gather in Lahore every year on International Mother Language Day.

Hafiz Saeed, chief of Jama'at-ud-Da'wah (JuD) has questioned Pakistan's decision to adopt Urdu as its national language in a country where majority of people speak Punjabi language, citing his interpretation of Islamic doctrine as encouraging education in the mother-tongue. The list of thinktanks, political organisations, cultural projects, and individuals that demand authorities at the national and provincial level to promote the use of the language in the public and official spheres includes:

At the federal level, Punjabi has official status via the Eighth Schedule to the Indian Constitution. At the state level, Punjabi is the sole official language of the state of Punjab, while it has secondary official status in the states of Haryana and Delhi.

Both federal and state laws specify the use of Punjabi in the field of education. The state of Punjab uses the Three Language Formula, and Punjabi is required to be either the medium of instruction, or one of the three languages learnt in all schools in Punjab. Punjabi is also a compulsory language in Haryana, and other states with a significant Punjabi speaking minority are required to offer Punjabi medium education.

There is a vibrant Punjabi language movie industry in India, however Punjabi has a much smaller presence in television. Despite Punjabi having far greater official recognition in India, attitudes of the Punjabi speaking elite towards the language are ambivalent as they are in neighboring Pakistan. There are also claims of state apathy towards the language in non-Punjabi majority states.<ref name="http://www.hindustantimes.com/ 2015"></ref>








</doc>
<doc id="25048" url="https://en.wikipedia.org/wiki?curid=25048" title="Panjabi">
Panjabi

Panjabi may refer to:




</doc>
<doc id="25054" url="https://en.wikipedia.org/wiki?curid=25054" title="Power associativity">
Power associativity

In abstract algebra, power associativity is a property of a binary operation which is a weak form of associativity.

An algebra (or more generally a magma) is said to be power-associative if the subalgebra generated by any element is associative. Concretely, this means that if an element "x" is multiplied by itself several times, it doesn't matter in which order the multiplications are carried out, so for instance .

Every associative algebra is power-associative, but so are all other alternative algebras (like the octonions, which are non-associative) and even some non-alternative algebras like the sedenions and Okubo algebras. Any algebra whose elements are idempotent is also power-associative.

Exponentiation to the power of any positive integer can be defined consistently whenever multiplication is power-associative. For example, there is no need to distinguish whether "x" should be defined as ("xx")"x" or as "x"("xx"), since these are equal. Exponentiation to the power of zero can also be defined if the operation has an identity element, so the existence of identity elements is useful in power-associative contexts.

Over a field of characteristic 0, an algebra is power-associative if and only if it satisfies formula_1 and formula_2, where formula_3 is the associator (Albert 1948).
Over a field of prime characteristic formula_4 there is no finite set of identities that characterizes power-associativity, but there are infinite independent sets, as described by Gainov (1970):


A substitution law holds for real power-associative algebras with unit, which basically asserts that multiplication of polynomials works as expected. For "f" a real polynomial in "x", and for any "a" in such an algebra define "f"("a") to be the element of the algebra resulting from the obvious substitution of "a" into "f". Then for any two such polynomials "f" and "g", we have that .




</doc>
<doc id="25055" url="https://en.wikipedia.org/wiki?curid=25055" title="Pierre de Coubertin">
Pierre de Coubertin

Pierre de Frédy, Baron de Coubertin (; born Pierre de Frédy; 1 January 1863 – 2 September 1937, also known as Pierre de Coubertin and Baron de Coubertin) was a French educator and historian, and founder of the International Olympic Committee, as well as its second President. He is considered the father of the modern Olympic Games. Born into a French aristocratic family, he became an academic and studied a broad range of topics, most notably education and history. He graduated with Law degree & Public affairs from Paris Institute of Political Studies. It was at Sciences Po where he came with the idea of Summer Olympic Games. 

The Pierre de Coubertin medal (also known as the Coubertin medal or the True Spirit of Sportsmanship medal) is an award given by the International Olympic Committee to athletes that demonstrate the spirit of sportsmanship in the Olympic Games.

Pierre de Frédy was born in Paris on 1 January 1863, into an aristocratic family. He was the fourth child of Baron Charles Louis de Frédy, Baron de Coubertin and Marie–Marcelle Gigault de Crisenoy. Family tradition held that the Frédy name had first arrived in France in the early 15th century, and the first recorded title of nobility granted to the family was given by Louis XI to an ancestor, also named Pierre de Frédy, in 1477. But other branches of his family tree delved even further into French history, and the annals of both sides of his family included nobles of various stations, military leaders and associates of kings and princes of France.
His father Charles was a staunch royalist and accomplished artist whose paintings were displayed and given prizes at the Parisian salon, at least in those years when he was not absent in protest of the rise to power of Louis Napoleon. His paintings often centred on themes related to the Roman Catholic Church, classicism, and nobility, which reflected those things he thought most important. In a later semi-fictional autobiographical piece called "Le Roman d'un rallié", Coubertin describes his relationship with both his mother and his father as having been somewhat strained during his childhood and adolescence. His memoirs elaborated further, describing as a pivotal moment his disappointment upon meeting Henri, Count of Chambord, whom the elder Coubertin believed to be the rightful king.

Coubertin grew up in a time of profound change in France: France's defeat in the Franco-Prussian War, the Paris Commune, and the establishment of the French Third Republic, and later the Dreyfus affair. But while these events were the setting of his childhood, his school experiences were just as formative. In October 1874, his parents enrolled him in a new Jesuit school called "Externat de la rue de Vienne", which was still under construction for his first five years there. While many of the school's attendees were day students, Coubertin boarded at the school under the supervision of a Jesuit priest, which his parents hoped would instill him with a strong moral and religious education. There, he was among the top three students in his class, and was an officer of the school's elite academy made up of its best and brightest. This suggests that despite his rebelliousness at home, Coubertin adapted well to the strict rigors of a Jesuit education.

As an aristocrat, Coubertin had a number of career paths from which to choose, including potentially prominent roles in the military or politics. But he chose instead to pursue a career as an intellectual, studying and later writing on a broad range of topics, including education, history, literature and sociology.

The subject which he seems to have been most deeply interested in was education, and his study focused in particular on physical education and the role of sport in schooling. In 1883, he visited England for the first time, and studied the program of physical education instituted by Thomas Arnold at the Rugby School. Coubertin credited these methods with leading to the expansion of British power during the 19th century and advocated their use in French institutions. The inclusion of physical education in the curriculum of French schools would become an ongoing pursuit and passion of Coubertin's.

Coubertin is thought to have exaggerated the importance of sport to Thomas Arnold, whom he viewed as "one of the founders of athletic chivalry". The character-reforming influence of sport with which Coubertin was so impressed is more likely to have originated in the novel "Tom Brown's School Days" rather than exclusively in the ideas of Arnold himself. Nonetheless, Coubertin was an enthusiast in need of a cause and he found it in England and in Thomas Arnold. "Thomas Arnold, the leader and classic model of English educators," wrote Coubertin, "gave the precise formula for the role of athletics in education. The cause was quickly won. Playing fields sprang up all over England".

Intrigued by what he had read about English public schools, in 1883, at the age of twenty, Fredy went to Rugby and to other English schools to see for himself. He described the results in a book, "L'Education en Angleterre", which was published in Paris in 1888. This hero of his book is Thomas Arnold, and on his second visit in 1886, Coubertin reflected on Arnold's influence in the chapel at Rugby School.

What Coubertin saw on the playing fields of Rugby and the other English schools he visited was how "organised sport can create moral and social strength". Not only did organised games help to set the mind and body in equilibrium, it also prevented the time being wasted in other ways. First developed by the ancient Greeks, it was an approach to education that he felt the rest of the world had forgotten and to whose revival he was to dedicate the rest of his life.

As a historian and a thinker on education, Coubertin romanticised ancient Greece. Thus, when he began to develop his theory of physical education, he naturally looked to the example set by the Athenian idea of the gymnasium, a training facility that simultaneously encouraged physical and intellectual development. He saw in these gymnasia what he called a triple unity between old and young, between disciplines, and between different types of people, meaning between those whose work was theoretical and those whose work was practical. Coubertin advocated for these concepts, this triple unity, to be incorporated into schools.

But while Coubertin was certainly a romantic, and while his idealised vision of ancient Greece would lead him later to the idea of reviving the Olympic Games, his advocacy for physical education was based on practical concerns as well. He believed that men who received physical education would be better prepared to fight in wars, and better able to win conflicts like the Franco-Prussian War, in which France had been humiliated. He also saw sport as democratic, in that sports competition crossed class lines, although it did so without causing a mingling of classes, which he did not support.

Unfortunately for Coubertin, his efforts to incorporate more physical education into French schools failed. The failure of this endeavour, however, was closely followed by the development of a new idea, the revival of the ancient Olympic Games, the creation of a festival of international athleticism.

He was the referee of the first ever French championship rugby union final on 20 March 1892, between Racing Club de France and Stade Français.

Coubertin is the instigator of the modern Olympic movement, a man whose vision and political skill led to the revival of the Olympic Games which had been practised in antiquity. Coubertin idealized the Olympic Games as the ultimate ancient athletic competition.

Thomas Arnold, the Head Master of Rugby School, was an important influence on Coubertin's thoughts about education, but his meetings with Dr. William Penny Brookes also influenced his thinking about athletic competition to some extent. A trained physician, Brookes believed that the best way to prevent illness was through physical exercise. In 1850, he had initiated a local athletic competition that he referred to as "Meetings of the Olympian Class" at the Gaskell recreation ground at Much Wenlock, Shropshire. Along with the Liverpool Athletic Club, who began holding their own Olympic Festival in the 1860s, Brookes created a National Olympian Association which aimed to encourage such local competition in cities across Britain. These efforts were largely ignored by the British sporting establishment. Brookes also maintained communication with the government and sporting advocates in Greece, seeking a revival of the Olympic Games internationally under the auspices of the Greek government. There, the philanthropist cousins Evangelos and Konstantinos Zappas had used their wealth to fund Olympics within Greece, and paid for the restoration of the Panathinaiko Stadium that was later used during the 1896 Summer Olympics. The efforts of Brookes to encourage the internationalization of these games came to naught. However, Dr. Brookes did organize a national Olympic Games in London, at Crystal Palace, in 1866 and this was the first Olympics to resemble an Olympic Games to be held outside of Greece. But while others had created Olympic contests within their countries, and broached the idea of international competition, it was Coubertin whose work would lead to the establishment of the International Olympic Committee and the organisation of the first modern Olympic Games.

In 1888, Coubertin founded the Comité pour la Propagation des Exercises Physiques more well known as the Comité Jules Simon. Coubertin's earliest reference to the modern notion of Olympic Games criticizes the idea. The idea for reviving the Olympic Games as an international competition came to Coubertin in 1889, apparently independently of Brookes, and he spent the following five years organizing an international meeting of athletes and sports enthusiasts that might make it happen. Dr Brookes had organised a national Olympic Games that was held at Crystal Palace in London in 1866. In response to a newspaper appeal, Brookes wrote to Coubertin in 1890, and the two began an exchange of letters on education and sport. Although he was too old to attend the 1894 Congress, Brookes would continue to support Coubertin's efforts, most importantly by using his connections with the Greek government to seek its support in the endeavour. While Brookes' contribution to the revival of the Olympic Games was recognised in Britain at the time, Coubertin in his later writings largely neglected to mention the role the Englishman played in their development. He did mention the roles of Evangelis Zappas and his cousin Konstantinos Zappas, but drew a distinction between their founding of athletic Olympics and his own role in the creation of an international contest. However, Coubertin together with A. Mercatis, a close friend of Konstantinos, encouraged the Greek government to utilise part of Konstantinos' legacy to fund the 1896 Athens Olympic Games separately and in addition to the legacy of Evangelis Zappas that Konstantinos had been executor of. Moreover, George Averoff was invited by the Greek government to fund the second refurbishment of the Panathinaiko Stadium that had already been fully funded by Evangelis Zappas forty years earlier.

Coubertin's advocacy for the Games centred on a number of ideals about sport. He believed that the early ancient Olympics encouraged competition among amateur rather than professional athletes, and saw value in that. The ancient practice of a sacred truce in association with the Games might have modern implications, giving the Olympics a role in promoting peace. This role was reinforced in Coubertin's mind by the tendency of athletic competition to promote understanding across cultures, thereby lessening the dangers of war. In addition, he saw the Games as important in advocating his philosophical ideal for athletic competition: that the competition itself, the struggle to overcome one's opponent, was more important than winning. Coubertin expressed this ideal thus:
"L'important dans la vie ce n'est point le triomphe, mais le combat, l'essentiel ce n'est pas d'avoir vaincu mais de s'être bien battu."

"The important thing in life is not the triumph but the struggle, the essential thing is not to have conquered but to have fought well."
As Coubertin prepared for his Congress, he continued to develop a philosophy of the Olympic Games. While he certainly intended the Games to be a forum for competition between amateur athletes, his conception of amateurism was complex. By 1894, the year the Congress was held, he publicly criticised the type of amateur competition embodied in English rowing contests, arguing that its specific exclusion of working-class athletes was wrong. While he believed that athletes should not be paid to be such, he did think that compensation was in order for the time when athletes were competing and would otherwise have been earning money. Following the establishment of a definition for an amateur athlete at the 1894 Congress, he would continue to argue that this definition should be amended as necessary, and as late as 1909 would argue that the Olympic movement should develop its definition of amateurism gradually.

Along with the development of an Olympic philosophy, Coubertin invested time in the creation and development of a national association to coordinate athletics in France, the Union des Sociétés Françaises de Sports Athlétiques (USFSA). In 1889, French athletics associations had grouped together for the first time and Coubertin founded a monthly magazine "La Revue Athletique", the first French periodical devoted exclusively to athletics and modelled on "The Athlete", an English journal established around 1862. Formed by seven sporting societies with approximately 800 members, by 1892 the association had expanded to 62 societies with 7,000 members.

That November, at the annual meeting of the USFSA, Coubertin first publicly suggested the idea of reviving the Olympics. His speech met general applause, but little commitment to the Olympic ideal he was advocating for, perhaps because sporting associations and their members tended to focus on their own area of expertise and had little identity as sportspeople in a general sense. This disappointing result was prelude to a number of challenges he would face in organising his international conference. In order to develop support for the conference, he began to play down its role in reviving Olympic Games and instead promoted it as a conference on amateurism in sport which, he thought, was slowly being eroded by betting and sponsorships. This led to later suggestions that participants were convinced to attend under false pretenses. Little interest was expressed by those he spoke to during trips to the United States in 1893 and London in 1894, and an attempt to involve the Germans angered French gymnasts who did not want the Germans invited at all. Despite these challenges, the USFSA continued its planning for the games, adopting in its first program for the meeting eight articles to address, only one of which had to do with the Olympics. A later program would give the Olympics a much more prominent role in the meeting.

The congress was held on 23 June 1894 at the Sorbonne in Paris. Once there, participants divided the congress into two commissions, one on amateurism and the other on reviving the Olympics. A Greek participant, Demetrius Vikelas, was appointed to head the commission on the Olympics, and would later become the first President of the International Olympic Committee. Along with Coubertin, C. Herbert of Britain's Amateur Athletic Association and W.M. Sloane of the United States helped lead the efforts of the commission. In its report, the commission proposed that Olympic Games be held every four years and that the program for the Games be one of modern rather than ancient sports. They also set the date and location for the first modern Olympic Games, the 1896 Summer Olympics in Athens, Greece, and the second, the 1900 Summer Olympics in Paris. Coubertin had originally opposed the choice of Greece, as he had concerns about the ability of a weakened Greek state to host the competition, but was convinced by Vikelas to support the idea. The commission's proposals were accepted unanimously by the congress, and the modern Olympic movement was officially born. The proposals of the other commission, on amateurism, were more contentious, but this commission also set important precedents for the Olympic Games, specifically the use of heats to narrow participants and the banning of prize money in most contests.

Following the Congress, the institutions created there began to be formalized into the International Olympic Committee (IOC), with Demetrius Vikelas as its first President. The work of the IOC increasingly focused on the planning the 1896 Athens Games, and de Coubertin played a background role as Greek authorities took the lead in logistical organisation of the Games in Greece itself, offering technical advice such as a sketch of a design of a velodrome to be used in cycling competitions. He also took the lead in planning the program of events, although to his disappointment neither polo, football, or boxing were included in 1896. The Greek organizing committee had been informed that four foreign football teams were to participate however not one foreign football team showed up and despite Greek preparations for a football tournament it was cancelled during the Games.

The Greek authorities were frustrated that he could not provide an exact estimate of the number of attendees more than a year in advance. In France, Coubertin's efforts to elicit interest in the Games among athletes and the press met difficulty, largely because the participation of German athletes angered French nationalists who begrudged Germany their victory in the Franco-Prussian War. Germany also threatened not to participate after rumours spread that Coubertin had sworn to keep Germany out, but following a letter to the Kaiser denying the accusation, the German National Olympic Committee decided to attend. Coubertin himself was frustrated by the Greeks, who increasingly ignored him in their planning and who wanted to continue to hold the Games in Athens every four years, against de Coubertin's wishes. The conflict was resolved after he suggested to the King of Greece that he hold pan-Hellenic games in between Olympiads, an idea which the King accepted, although Coubertin would receive some angry correspondence even after the compromise was reached and the King did not mention him at all during the banquet held in honour of foreign athletes during the 1896 Games.

Coubertin took over the IOC presidency when Demetrius Vikelas stepped down after the Olympics in his own country. Despite the initial success, the Olympic Movement faced hard times, as the 1900 (in De Coubertin's own Paris) and 1904 Games were both swallowed by World's Fairs in the same cities, and received little attention. The Paris Games were not organised by Coubertin or the IOC nor were they called Olympics at that time. The St. Louis Games was hardly internationalized.

The 1906 Summer Olympics revived the momentum, and the Olympic Games have come to be regarded as the world's foremost sports competition. Coubertin created the modern pentathlon for the 1912 Olympics, and subsequently stepped down from his IOC presidency after the 1924 Olympics in Paris, which proved much more successful than the first attempt in that city in 1900. He was succeeded as president, in 1925, by Belgian Henri de Baillet-Latour.

Years later Coubertin came out of retirement to lend his prestige to assisting Berlin to land the 1936 games. In exchange, Germany nominated him for the Nobel Peace Prize. The 1935 winner, however, was the anti-Nazi Carl von Ossietzky.

Coubertin won the gold medal for literature at the 1912 Summer Olympics for his poem "Ode to Sport".

In 1911, Pierre de Coubertin founded the inter-religious Scouting organisation aka "Éclaireurs Français" (EF) in France, which later merged to form the Éclaireuses et Éclaireurs de France.

In 1895 Pierre de Coubertin had married Marie Rothan, the daughter of family friends. Their son Jacques (1896–1952) became ill after being in the sun too long when he was a little child. Their daughter Renée (1902–1968) suffered emotional disturbances and never married. Marie and Pierre tried to console themselves with two nephews, but they were killed at the front in World War I. Coubertin died of a heart attack in Geneva, Switzerland on 2 September 1937. Marie died in 1963.

Pierre was the last person to the family name. In the words of his biographer John MacAloon, "The last of his lineage, Pierre de Coubertin was the only member of it whose fame would outlive him."

A number of scholars have criticized Coubertin's legacy. David C. Young believes that Coubertin's assertion that ancient Olympic athletes were amateurs was incorrect. The issue is the subject of scholarly debate. Young and others argue that the athletes of the ancient Games were professional, while opponents led by Pleket argue that the earliest Olympic athletes were in fact amateur, and that the Games only became professionalized after about 480 BC. Coubertin agreed with this latter view, and saw this professionalization as undercutting the morality of the competition.

Further, Young asserts that the effort to limit international competition to amateur athletes, which Coubertin was a part of, was in fact part of efforts to give the upper classes greater control over athletic competition, removing such control from the working classes. Coubertin may have played a role in such a movement, but his defenders argue that he did so unconscious of any class repercussions.

However, it is clear that his romanticized vision of the Olympic Games was fundamentally different from that described in the historical record. For example, Coubertin's idea that participation is more important than winning ("L'important c'est de participer") is at odds with the ideals of the Greeks. The Apostle Paul, writing in the first century to Christians in the city of Corinth where the Isthmian Games were held, reflects this in his writings when he says, "Do you not know that in a race all the runners run, but only one gets the prize? Run in such a way as to get the prize", (1 Corinthians 9:24).

Coubertin's assertion that the Games were the impetus for peace was also an exaggeration; the peace which he spoke of only existed to allow athletes to travel safely to Olympia, and neither prevented the outbreak of wars nor ended ongoing ones.

Scholars have critiqued the idea that athletic competition might lead to greater understanding between cultures and, therefore, to peace. Christopher Hill claims that modern participants in the Olympic movement may defend this particular belief, "in a spirit similar to that in which the Church of England remains attached to the Thirty-Nine Articles of Religion, which a Priest in that Church must sign." In other words, that they may not wholly believe it but hold to it for historical reasons.

Questions have also been raised about the veracity of Coubertin's account of his role in the planning of the 1896 Athens Games. Reportedly, Coubertin played little role in planning, despite entreaties by Vikelas. Young suggests that the story about Coubertin's having sketched the velodrome were untrue, and that he had in fact given an interview in which he suggested he did not want Germans to participate. Coubertin later denied this.

The Olympic motto "Citius, Altius, Fortius" (Faster, Higher, Stronger) was proposed by Coubertin in 1894 and has been official since 1924. The motto was coined by Henri Didon OP, a friend of Coubertin, for a Paris youth gathering of 1891.

The Pierre de Coubertin medal (also known as the Coubertin medal or the True Spirit of Sportsmanship medal) is an award given by the International Olympic Committee to those athletes that demonstrate the spirit of sportsmanship in the Olympic Games. This medal is considered by many athletes and spectators to be the highest award that an Olympic athlete can receive, even greater than a gold medal. The International Olympic Committee considers it as its highest honour.

A minor planet, 2190 Coubertin, was discovered in 1976 by Soviet astronomer Nikolai Stepanovich Chernykh and is named in his honour.

The street where the Olympic Stadium in Montreal is located (which hosted the 1976 Summer Olympic Games) was named after Pierre de Coubertin, giving the stadium the address 4549 Pierre de Coubertin Avenue. It is the only Olympic Stadium in the world that lies on a street named after Coubertin. There are also two schools in Montreal named after Pierre de Coubertin.

He was portrayed by Louis Jourdan in the 1984 NBC miniseries, "".

In 2007, he was inducted into the World Rugby Hall of Fame for his services to the sport of rugby union.

This is a listing of Pierre de Coubertin's books. In addition to these, he wrote numerous articles for journals and magazines:





</doc>
<doc id="25056" url="https://en.wikipedia.org/wiki?curid=25056" title="Polish notation">
Polish notation

Polish notation (PN), also known as normal Polish notation (NPN), Łukasiewicz notation, Warsaw notation, Polish prefix notation or simply prefix notation, is a mathematical notation in which operators precede their operands, in contrast to reverse Polish notation (RPN) in which operators follow their operands. It does not need any parentheses as long as each operator has a fixed number of operands. The description "Polish" refers to the nationality of logician Jan Łukasiewicz, who invented Polish notation in 1924.

The term "Polish notation" is sometimes taken (as the opposite of "infix notation") to also include reverse Polish notation.

When Polish notation is used as a syntax for mathematical expressions by programming language interpreters, it is readily parsed into abstract syntax trees and can, in fact, define a one-to-one representation for the same. Because of this, Lisp (see below) and related programming languages define their entire syntax in terms of prefix notation (and others use postfix notation).

A quotation from a paper by Jan Łukasiewicz, "Remarks on Nicod's Axiom and on "Generalizing Deduction"", page 180, states how the notation was invented:
I came upon the idea of a parenthesis-free notation in 1924. I used that notation for the first time in my article Łukasiewicz(1), p. 610, footnote.

The reference cited by Łukasiewicz is apparently a lithographed report in Polish. The referring paper by Łukasiewicz "Remarks on Nicod's Axiom and on "Generalizing Deduction"" was reviewed by Henry A. Pogorzelski in the "Journal of Symbolic Logic" in 1965. Heinrich Behmann, editor in 1924 of the article of Moses Schönfinkel already had the idea of eliminating parentheses in logic formulas.

Alonzo Church mentions this notation in his classic book on mathematical logic as worthy of remark in notational systems even contrasted to Alfred Whitehead and Bertrand Russell's logical notational exposition and work in Principia Mathematica.

In Łukasiewicz's 1951 book, "Aristotle's Syllogistic from the Standpoint of Modern Formal Logic", he mentions that the principle of his notation was to write the functors before the arguments to avoid brackets and that he had employed his notation in his logical papers since 1929. He then goes on to cite, as an example, a 1930 paper he wrote with Alfred Tarski on the sentential calculus.

While no longer used much in logic, Polish notation has since found a place in computer science.

The expression for adding the numbers 1 and 2 is written in Polish notation as (pre-fix), rather than as (in-fix). In more complex expressions, the operators still precede their operands, but the operands may themselves be expressions including again operators and their operands. For instance, the expression that would be written in conventional infix notation as
can be written in Polish notation as
Assuming a given arity of all involved operators (here the "−" denotes the binary operation of subtraction, not the unary function of sign-change), any well formed prefix representation thereof is unambiguous, and brackets within the prefix expression are unnecessary. As such, the above expression can be further simplified to

The processing of the product is deferred until its two operands are available (i.e., 5 minus 6, and 7). As with "any" notation, the innermost expressions are evaluated first, but in Polish notation this "innermost-ness" can be conveyed by the sequence of operators and operands rather than by bracketing.

In the conventional infix notation parentheses are required to override the standard precedence rules, since, referring to the above example, moving them
or removing them
changes the meaning and the result of the expression. This version is written in Polish notation as

When dealing with non-commutative operations, like division or subtraction, it is necessary to coordinate the sequential arrangement of the operands with the definition of how the operator takes its arguments, i.e., from left to right. For example, , with 10 left to 5, has the meaning of 10 ÷ 5 (read as "divide 10 by 5"), or , with 7 left to 6, has the meaning of 7 - 6 (read as "subtract from 7 the operand 6").

Prefix notation is especially popular with stack-based operations due to its innate ability to easily distinguish order of operations without the need for parentheses. To evaluate order of operations under prefix notation, one does not even need to memorize an operational hierarchy, as with infix notation. Instead, one looks directly to the notation to discover which operator to evaluate first. Reading an expression from left to right, one first looks for an operator and proceeds to look for two operands. If another operator is found before two operands are found, then the old operator is placed aside until this new operator is resolved. This process iterates until an operator is resolved, which must happen eventually, as there must be one more operand than there are operators in a complete statement. Once resolved, the operator and the two operands are replaced with a new operand. Because one operator and two operands are removed and one operand is added, there is a net loss of one operator and one operand, which still leaves an expression with "N" operators and operands, thus allowing the iterative process to continue. This is the general theory behind using stacks in programming languages to evaluate a statement in prefix notation, although there are various algorithms that manipulate the process. Once analyzed, a statement in prefix notation becomes less intimidating to the human mind as it allows some separation from convention with added convenience.



The infix expression ((15 ÷ (7 − (1 + 1))) × 3) − (2 + (1 + 1)) can be written like this in Polish notation:


The following table shows the state of the operator and operand stack at each stage of the above left-to-right algorithm:


The following table shows the state of the operand stack at each stage of the above right-to-left algorithm:

The table below shows the core of Jan Łukasiewicz's notation for sentential logic. Some letters in the Polish notation table stand for particular words in Polish, as shown:

Note that the quantifiers ranged over propositional values in Łukasiewicz's work on many-valued logics.

Bocheński introduced an incompatible system of Polish notation that names all 16 binary connectives of classical propositional logic.

Prefix notation has seen wide application in Lisp s-expressions, where the brackets are required since the operators in the language are themselves data (first-class functions). Lisp functions may also be variadic. The Tcl programming language, much like Lisp also uses Polish notation through the mathop library. The Ambi programming language uses Polish notation for arithmetic operations and program construction.

Postfix notation is used in many stack-oriented programming languages like PostScript and Forth. CoffeeScript syntax also allows functions to be called using prefix notation, while still supporting the unary postfix syntax common in other languages.

The number of return values of an expression equals the difference between the number of operands in an expression and the total arity of the operators minus the total number of return values of the operators.

Polish notation, usually in postfix form, is the chosen notation of certain calculators, notably from Hewlett-Packard. At a lower level, postfix operators are used by some stack machines such as the Burroughs large systems.




</doc>
<doc id="25058" url="https://en.wikipedia.org/wiki?curid=25058" title="Primary school">
Primary school

A primary school (or elementary school in American English and often in Canadian English) is a school in which children receive primary or elementary education from the age of about seven to twelve, coming after preschool , infant school and before secondary school. (In some countries there is an intermediate stage of middle school between primary and secondary education.)

In most parts of the world, primary education is the first stage of compulsory education, and is normally available without charge, but may be offered in a fee-paying independent school. The term grade school is sometimes used in the US, although this term may refer to both primary education and secondary education.

The term "primary school" is derived from the French "école primaire", which was first used in 1802.


In the United States, "primary school" may refer to a school with grades Kindergarten through second grade or third grade. (K-2 or 3). In these municipalities, the "elementary school" includes grade three through five or grades four to six.

In some places, primary schooling has historically further been divided between "lower primary schools" ("LP schools"), which were the elementary schools, and "higher primary schools" ("HP schools"), which were established to provide a more practical instruction to poorer classes than what was provided in the secondary schools.




</doc>
<doc id="25060" url="https://en.wikipedia.org/wiki?curid=25060" title="Preprocessing">
Preprocessing

Preprocessing can refer to the following topics in computer science:



</doc>
<doc id="25061" url="https://en.wikipedia.org/wiki?curid=25061" title="Piedmont">
Piedmont

Piedmont ( ; , ; Piedmontese, Occitan and ; ) is a region in northwest Italy, one of the 20 regions of the country. It borders the Liguria region to the south, the Lombardy and Emilia-Romagna regions to the east and the Aosta Valley region to the northwest; it also borders France to the west and Switzerland to the northeast. It has an area of and a population of 4 377 941 as of 30 November 2017. The capital of Piedmont is Turin.

The name Piedmont comes from medieval Latin Pedemontium or Pedemontis, i.e., "ad pedem montium", meaning “at the foot of the mountains” (the Alps) attested in documents of the end of the 12th century.

Other towns of Piedmont with more than 20,000 inhabitants sorted by population :

Piedmont is surrounded on three sides by the Alps, including Monviso, where the Po rises, and Monte Rosa. It borders with France (Auvergne-Rhône-Alpes and Provence-Alpes-Côte d'Azur), Switzerland (Ticino and Valais) and the Italian regions of Lombardy, Liguria, Aosta Valley and for a very small fragment with Emilia Romagna.
The geography of Piedmont is 43.3% mountainous, along with extensive areas of hills (30.3%) and plains (26.4%).

Piedmont is the second largest of Italy's 20 regions, after Sicily. It is broadly coincident with the upper part of the drainage basin of the river Po, which rises from the slopes of Monviso in the west of the region and is Italy’s largest river. The Po collects all the waters provided within the semicircle of mountains (Alps and Apennines) which surround the region on three sides.

From the highest peaks the land slopes down to hilly areas, (not always, though; sometimes there is a brusque transition from the mountains to the plains) and then to the upper, and then to the lower great Padan Plain. The boundary between the first and the second is characterised by resurgent springs, typical of the Padan Plain which supply fresh water both to the rivers and to a dense network of irrigation canals.

The countryside is very diversified: from the rugged peaks of the massifs of Monte Rosa and of Gran Paradiso, to the damp rice paddies of Vercelli and Novara, from the gentle hillsides of the Langhe and of Montferrat to the plains. 7.6% of the entire territory is considered protected area. There are 56 different national or regional parks, one of the most famous is the Gran Paradiso National Park located between Piedmont and the Aosta Valley.

Piedmont was inhabited in early historic times by Celtic-Ligurian tribes such as the Taurini and the Salassi. They were later subdued by the Romans (c. 220 BC), who founded several colonies there including "Augusta Taurinorum "(Turin) and "Eporedia" (Ivrea). After the fall of the Western Roman Empire, the region was successively invaded by the Burgundians, the Ostrogoths (5th century), East Romans, Lombards (6th century), and Franks (773).

In the 9th–10th centuries there were further incursions by the Magyars and Saracens. At the time Piedmont, as part of the Kingdom of Italy within the Holy Roman Empire, was subdivided into several marches and counties.

In 1046, Oddo of Savoy added Piedmont to their main territory of Savoy, with a capital at Chambéry (now in France). Other areas remained independent, such as the powerful "comuni" (municipalities) of Asti and Alessandria and the marquisates of Saluzzo and Montferrat. The County of Savoy was elevated to a duchy in 1416, and Duke Emanuele Filiberto moved the seat to Turin in 1563. In 1720, the Duke of Savoy became King of Sardinia, founding what evolved into the Kingdom of Sardinia and increasing Turin's importance as a European capital.

The Republic of Alba was created in 1796 as a French client republic in Piedmont. A new client republic, the Piedmontese Republic, existed between 1798 and 1799 before it was reoccupied by Austrian and Russian troops. In June 1800 a third client republic, the Subalpine Republic, was established in Piedmont. It fell under full French control in 1801 and it was annexed by France in September 1802. In the congress of Vienna, the Kingdom of Sardinia was restored, and furthermore received the Republic of Genoa to strengthen it as a barrier against France.

Piedmont was a springboard for Italy's unification in 1859–1861, following earlier unsuccessful wars against the Austrian Empire in 1820–1821 and 1848–1849. This process is sometimes referred to as "Piedmontisation". However, the efforts were later countered by the efforts of rural farmers.

The House of Savoy became Kings of Italy, and Turin briefly became the capital of Italy. However, when the Italian capital was moved to Florence, and then to Rome, the administrative and institutional importance of Piedmont was deeply reduced and the only remaining recognition to Piedmont's historical role was that the crown prince of Italy was known as the Prince of Piedmont. After Italian unification, Piedmont was one of the most important regions in the first Italian industrialization.

Lowland Piedmont is a fertile agricultural region. The main agricultural products in Piedmont are cereals, including rice, representing more than 10% of national production, maize, grapes for wine-making, fruit and milk. With more than 800,000 head of cattle in 2000, livestock production accounts for half of final agricultural production in Piedmont.

Piedmont is one of the great winegrowing regions in Italy. More than half of its of vineyards are registered with DOC designations. It produces prestigious wines as Barolo, Barbaresco, from the Langhe near Alba, and the Moscato d'Asti as well as the sparkling Asti from the vineyards around Asti. Indigenous grape varieties include Nebbiolo, Barbera, Dolcetto, Freisa, Grignolino and Brachetto.

The region contains major industrial centres, the main of which is Turin, home to the FIAT automobile works. Olivetti, once a major electronics industry whose plant was in Scarmagno, near Ivrea, has now turned into a small-scale computer service company. Biella produces tissues and silks. The city of Asti is located about 55 kilometres (34 miles) east of Turin in the plain of the Tanaro River and is one of the most important centers of Montferrat, one of the best known Italian wine districts in the world, declared officially on 22 June 2014 a UNESCO World Heritage site.

Alba is the home of Ferrero's chocolate factories and some mechanical industries. There are links with neighbouring France via the Fréjus and the Colle di Tenda tunnels as well as the Montgenèvre Pass. Piedmont also connects with Switzerland with the Simplon and Great St Bernard passes. It is possible to reach Switzerland via a normal road that crosses Oriental Piedmont starting from Arona and ending in Locarno, on the border with Italy. The region's airport, Turin-Caselle, caters domestic and international flights.
The region has the longest motorway network amongst the Italian regions (about 800 km). It radiates from Turin, connecting it with the other provinces in the region, as well as with the other regions in Italy. In 2001, the number of passenger cars per 1,000 inhabitants was 623 (above the national average of 575).

Tourism in Piedmont employs 75,534 people and currently comprises 17,367 companies operating in the hospitality and catering sector, with 1,473 hotels and tourist accommodations. The sector generates a turnover of €2,671 million, 3.3% of the €80,196 million which represents the total estimated spending on tourism in Italy. The region enjoys almost the same level of popularity among Italians and visitors from oversea. In 2002 there were 2,651,068 total arrivals. International visitors to Piedmont in 2002 accounted for 42% of the total number of tourists with 1,124,696 arrivals. The traditional leading areas for tourism in Piedmont are the Lake District – "Piedmont's riviera", which accounts for 32.84% of total overnight stays, and the metropolitan area of Turin which accounts for 26.51%.

In 2006 Turin hosted the XX Olympic Winter Games and in 2007 it hosted the XXIII Universiade. Alpine tourism tends to concentrate in a few highly developed stations like Alagna Valsesia and Sestriere. Around 1980, the long-distance trail Grande Traversata delle Alpi (GTA) was created to draw more attention to the manyfold of remote, sparsely inhabited valleys.

Since 2006, the Piedmont region has benefited from the start of the Slow Food movement and Terra Madre, events that highlighted the rich agricultural and viticultural value of the Po valley and northern Italy. In the same year, Piemonte Agency for Investments, Export and Tourism was founded in order to strengthen the international role of the area and its potential. It was the first Italian institution bringing together all activities carried out by pre-existing local organizations operating for the internationalization of the territory.

The economy of Piedmont is anchored on a rich history of state support for excellence in higher education, including some of the leading universities in Italy. The Piedmont valley is home to the famous University of Turin, the Polytechnic University of Turin, the University of Eastern Piedmont and, more recently the United Nations Interregional Crime and Justice Research Institute.

The population density in Piedmont is lower than the national average. In 2008 it was equal to 174 inhabitants per km, compared to a national figure of about 200. It rises however to 335 inhabitants per km when just the Metropolitan City of Turin is considered, whereas Verbano-Cusio-Ossola is the less densely populated province (72 inhabitants per km).

The population of Piedmont followed a downward trend throughout the 1980s. This drop is the result of the natural negative balance (of some 3 to 4% per year), while the migratory balance since 1986 has again become positive because of an excess of new immigration over a stable figure for emigration.
The population as a whole has remained stable in the 1990s, although this is the result of a negative natural balance and a positive net migration.

The Turin metro area grew rapidly in the 1950s and 1960s due to an increase of immigrants from southern Italy and Veneto and today it has a population of approximately two million. , the Italian national institute of statistics (ISTAT) estimated that 310,543 foreign-born immigrants live in Piedmont, equal to 7.0% of the total regional population. Most immigrants come from Eastern Europe (mostly from Romania, Poland, and Bulgaria) with smaller communities of African immigrants.

The Regional Government ("Giunta Regionale") is presided by the President of the Region ("Presidente della Regione"), who is elected for a five-year term and is composed by the President and the Ministers, who are currently 14, including a Vice President ("Vice Presidente").
In the last regional election, which took place on 29–30 March 2010, Roberto Cota (Lega Nord) defeated incumbent Mercedes Bresso (Democratic Party). In 2014 Cota chose not to stand again for President and the parties composing his coalition failed to agree on a single candidate, resulting in a landslide victory for Sergio Chiamparino, a Democrat who had been Mayor of Turin from 2001 to 2011.

Piedmont is divided into eight provinces:

As in the rest of Italy, Italian is the official national language. The main local languages are Piedmontese, Insubric (spoken in the eastern part of the region), Occitan (spoken by a minority in the Occitan Valleys situated in the Province of Cuneo and the Metropolitan City of Turin), and Franco-Provençal (spoken by another minority in the alpine heights of the Metropolitan City of Turin), like in the Susa valley and Walser (spoken by a minority in the Province of Vercelli and Province of Verbano-Cusio-Ossola).

Turin hosted the 2006 Winter Olympics.

In football, notable clubs in Piedmont include Turin-based Juventus and Torino, who have won 38 official top-flight league championships (as of the 2014-15 season) between them, more than any other city in Italy. Other smaller teams include the old "Piedmont Quadrilateral" components Novara, Alessandria, Casale, Pro Vercelli. With the pre-World War II success of Pro Vercelli and the dominance of Torino during the "Grande Torino" years and Juventus in more recent times, the region is the most successful in terms of championships won. Also Casale and Novese contributed with one "scudetto" each.

Other local teams include volleyball teams Cuneo (male) and Asystel Novara (female), basketball teams Biella Basketball and Junior Casale, ice hockey team Hockey Club Turin, and roller hockey side Amatori Vercelli, who have won three league titles, an Italian Cup and two CERS Cups.




</doc>
<doc id="25062" url="https://en.wikipedia.org/wiki?curid=25062" title="Palestinian views on the peace process">
Palestinian views on the peace process

Palestinian views on the peace process with Israel are wide ranging. The goal that unites Palestinians is the establishment of a Palestinian state where, among other things, Palestinian refugees may resettle. Some Palestinians want that state to be established in the West Bank and Gaza Strip, whereas other Palestinians want that state to replace the State of Israel.

Palestinians have held diverse views and perceptions of the peace process. A key starting point for understanding these views is an awareness of the differing objectives sought by advocates of the Palestinian cause. 'New Historian' Israeli academic Ilan Pappe says the cause of the conflict from a Palestinian point of view dates back to 1948 with the creation of Israel (rather than Israel’s views of 1967 being the crucial point and the return of occupied territories being central to peace negotiations), and that the conflict has been a fight to bring home refugees to a Palestinian state. Therefore, this for some was the ultimate aim of the peace process, and for groups such as Hamas still is. However, Jerome Slater says that this ‘maximalist’ view of a destruction of Israel in order to regain Palestinian lands, a view held by Arafat and the PLO initially, has steadily moderated from the late 1960s onwards to a preparedness to negotiate and instead seek a two-state solution. The Oslo Accords demonstrated the recognition of this acceptance by the then Palestinian leadership of the state of Israel’s right to exist in return for the withdrawal of Israeli forces from the Gaza Strip and West Bank. However, there are recurrent themes prevalent throughout peace process negotiations including a feeling that Israel offers too little and a mistrust of its actions and motives. Yet, the demand for the "Right of Return" (ROR) by descendants of Palestinian refugees to Israel has remained a cornerstone of the Palestinian view and has been repeatedly enunciated by Palestinian president Mahmud Abbas who is leading the Palestinian peace effort.

The PLO has complex, often contradictory attitudes toward the peace process. Officially, the PLO acceptance of Israel's right to exist in peace was the first of the PLO's obligations in the Oslo Accords. In Yasser Arafat's September 9, 1993 letter to Israeli Prime Minister Yitzhak Rabin, as part of the first Oslo accord, Arafat stated that "The PLO recognizes the right of the State of Israel to exist in peace and security." Remarks from Arafat a shift away from one of the PLO's primary aims—the destruction of Israel.

However, evidence throughout history and even during the 1990s and 2000s have shown that the PLO leadership considered any peace made with Israel to be temporary until the dream of Israel's destruction could be realized. Arafat often spoke of the peace process in terms of "justice" for the Palestinians; terms historian Efraim Karsh described as "euphemisms rooted in Islamic and Arabic history for the liberation of the whole of Palestine from 'foreign occupiers.'" When describing his views of the peace process among Arab leaders and in the media of the Arab world, Arafat's rhetoric became noticeably more bellicose than it was when among Western leaders and media outside of the Arab world. The period saw a disconnect between what the PLO's second in command Abu Iyad referred to as "the language of peace" and support of Palestinian terrorism.

Since the 1990s, there has been a debate within the PLO as to whether to halt terrorist activities completely or to continue attacking Israel as well as negotiate diplomatically with Israel. In practice, terrorism was never fully banned. Furthermore, assassination attempts by radical Palestinian factions within the PLO since the early years of the peace process kept Arafat from expressing full, public support of the peace process or condemnation of terrorism without risking further danger to his own life.

In 2000, after Yasser Arafat rejected the offer made to him by Ehud Barak based on the two-state solution and declined to negotiate for a more favorable offer, it became clear that Arafat would not make a deal with Israel unless it included the full Palestinian right of return, which would demographically destroy the Jewish character of the State of Israel. For this reason, critics of Arafat claim that he put his desire to destroy the Jewish state above his dream of building an autonomous Palestinian state.

The stated goal of Hamas and the Palestinian Islamic Jihad is to conquer Israel and replace it with an Islamist state. Both groups reject the Oslo Accords and other plans for peace with Israel. Throughout the 1990s and 2000s, the two groups worked together to derail the peace process by attacking Israeli civilians. Hamas undertook a ceasefire with Israel in August 2004. The Palestinian Islamic Jihad was unhappy with the ceasefire. In September 2005, Hamas was criticized by Islamic Jihad for calling off rocket attacks on Israel from Gaza.

In 2008, Hamas publicly offered a long-term hudna (truce) with Israel if Israel agreed to return to its 1967 borders and to grant the "right of return" to all Palestinian refugees. In 2010, Ismail Haniyeh announced that Hamas would accept the outcome of a Palestinian referendum on a peace treaty with Israel even if the results were not in line with their ideology. This represented a departure from their earlier insistence that they would not be bound by any such result. In 2012, Mousa Abu Marzook, a high-ranking Hamas official in competition with Haniyeh for Hamas' top leadership post, gave an interview in which he expressed a range of opinions, some of which differed from the organisation's actual stance. He said that Hamas will not recognize Israel and will not feel bound to understand a peace treaty negotiated by Fatah as a recognition of Israel, calling instead for a "hudna" (temporary truce). Abu Marzook echoed Haniyeh's demand that Palestinians should be given the unconditional right to return into what is now Israel proper.

Rashid Abu Shbak, a senior PA security official declared, "The light which has shone over Gaza and Jericho [when the PA assumed control over those areas] will also reach the Negev and the Galilee [which constitute a large portion of pre-1967 Israel]."

The PA's Voice of Palestine radio station broadcast a Friday prayer sermon by Yusuf Abu Sneineh, official preacher at Jerusalem's Al-Aqsa Mosque, over the radio. In it, he asserted, "The struggle we are waging is an ideological struggle and the question is: where has the Islamic land of Palestine gone? Where [are] Haifa and Jaffa, Lod and Ramle, Acre, Safed and Tiberias? Where is Hebron and Jerusalem?"

PA cabinet minister Abdul Aziz Shaheen told the official PA newspaper, "Al-Havat Al-Jadida", on January 4, 1998, "The Oslo accord was a preface for the Palestinian Authority and the Palestinian Authority will be a preface for the Palestinian state which, in its turn, will be a preface for the liberation of the entire Palestinian land."

Faisal Husseini, former Palestinian Authority Minister for Jerusalem, compared the al-Aqsa intifada following the Oslo peace process to the tactic of coming out of the Trojan Horse used by the Greeks in the myth of the Trojan War.




</doc>
<doc id="25063" url="https://en.wikipedia.org/wiki?curid=25063" title="Product ring">
Product ring

In mathematics, it is possible to combine several rings into one large product ring. This is done as follows: if "I" is some index set and "R" is a ring for every "i" in "I", then the cartesian product can be turned into a ring by defining the operations coordinate-wise.

The resulting ring is called a direct product of the rings "R".

An important example is the ring Z/"n"Z of integers modulo "n". If "n" is written as a product of prime powers (see fundamental theorem of arithmetic),

where the "p" are distinct primes, then Z/"n"Z is naturally isomorphic to the product ring

This follows from the Chinese remainder theorem.

If is a product of rings, then for every "i" in "I" we have a surjective ring homomorphism which projects the product on the "i"th coordinate. The product "R", together with the projections "p", has the following universal property: 
This shows that the product of rings is an instance of products in the sense of category theory. 

When "I" is finite, the underlying additive group of coincides with the direct sum of the additive groups of the "R". In this case, some authors call "R" the "direct sum of the rings "R"" and write , but this is incorrect from the point of view of category theory, since it is usually not a coproduct in the category of rings: for example, when two or more of the "R" are nonzero, the inclusion map fails to map 1 to 1 and hence is not a ring homomorphism.

If "A" in "R" is an ideal for each "i" in "I", then is an ideal of "R". If "I" is finite, then the converse is true, i.e., every ideal of "R" is of this form. However, if "I" is infinite and the rings "R" are non-zero, then the converse is false: the set of elements with all but finitely many nonzero coordinates forms an ideal which is not a direct product of ideals of the "R". The ideal "A" is a prime ideal in "R" if all but one of the "A" are equal to "R" and the remaining "A" is a prime ideal in "R". However, the converse is not true when "I" is infinite. For example, the direct sum of the "R" form an ideal not contained in any such "A", but the axiom of choice gives that it is contained in some maximal ideal which is a fortiori prime.

An element "x" in "R" is a unit if and only if all of its components are units, i.e., if and only if is a unit in "R" for every "i" in "I". The group of units of "R" is the product of the groups of units of "R".

A product of two or more non-zero rings always has nonzero zero divisors: if "x" is an element of the product all of whose coordinates are zero except , and "y" is an element of the product with all coordinates zero except (with ), then in the product ring.




</doc>
<doc id="25064" url="https://en.wikipedia.org/wiki?curid=25064" title="Posthumanism">
Posthumanism

Posthumanism or post-humanism (meaning "after humanism" or "beyond humanism") is a term with at least seven definitions according to philosopher Francesca Ferrando:

Philosopher Ted Schatzki suggests there are two varieties of posthumanism of the philosophical kind:

One, which he calls 'objectivism', tries to counter the overemphasis of the subjective or intersubjective that pervades humanism, and emphasises the role of the nonhuman agents, whether they be animals and plants, or computers or other things.

A second prioritizes practices, especially social practices, over individuals (or individual subjects) which, they say, constitute the individual.

There may be a third kind of posthumanism, propounded by the philosopher Herman Dooyeweerd. Though he did not label it as 'posthumanism', he made an extensive and penetrating immanent critique of Humanism, and then constructed a philosophy that presupposed neither Humanist, nor Scholastic, nor Greek thought but started with a different religious ground motive. Dooyeweerd prioritized law and meaningfulness as that which enables humanity and all else to exist, behave, live, occur, etc. ""Meaning" is the "being" of all that has been "created"," Dooyeweerd wrote, "and the nature even of our selfhood." Both human and nonhuman alike function subject to a common 'law-side', which is diverse, composed of a number of distinct law-spheres or "aspects". The temporal being of both human and non-human is multi-aspectual; for example, both plants and humans are bodies, functioning in the biotic aspect, and both computers and humans function in the formative and lingual aspect, but humans function in the aesthetic, juridical, ethical and faith aspects too. The Dooyeweerdian version is able to incorporate and integrate both the objectivist version and the practices version, because it allows nonhuman agents their own subject-functioning in various aspects and places emphasis on aspectual functioning.

Ihab Hassan, theorist in the academic study of literature, once stated:

This view predates most currents of posthumanism which have developed over the late 20th century in somewhat diverse, but complementary, domains of thought and practice. For example, Hassan is a known scholar whose theoretical writings expressly address postmodernity in society. Beyond postmodernist studies, posthumanism has been developed and deployed by various cultural theorists, often in reaction to problematic inherent assumptions within humanistic and enlightenment thought.

Theorists who both complement and contrast Hassan include Michel Foucault, Judith Butler, cyberneticists such as Gregory Bateson, Warren McCullouch, Norbert Wiener, Bruno Latour, Cary Wolfe, Elaine Graham, N. Katherine Hayles, Donna Haraway, Peter Sloterdijk, Stefan Lorenz Sorgner, Evan Thompson, Francisco Varela, Humberto Maturana and Douglas Kellner. Among the theorists are philosophers, such as Robert Pepperell, who have written about a "posthuman condition", which is often substituted for the term "posthumanism".

Posthumanism differs from classical humanism by relegating humanity back to one of many natural species, thereby rejecting any claims founded on anthropocentric dominance. According to this claim, humans have no inherent rights to destroy nature or set themselves above it in ethical considerations "a priori". Human knowledge is also reduced to a less controlling position, previously seen as the defining aspect of the world. Human rights exist on a spectrum with animal rights and posthuman rights. The limitations and fallibility of human intelligence are confessed, even though it does not imply abandoning the rational tradition of humanism.

Proponents of a posthuman discourse, suggest that innovative advancements and emerging technologies have transcended the traditional model of the human, as proposed by Descartes among others associated with philosophy of the Enlightenment period. In contrast to humanism, the discourse of posthumanism seeks to redefine the boundaries surrounding modern philosophical understanding of the human. Posthumanism represents an evolution of thought beyond that of the contemporary social boundaries and is predicated on the seeking of truth within a postmodern context. In so doing, it rejects previous attempts to establish 'anthropological universals' that are imbued with anthropocentric assumptions.

The philosopher Michel Foucault placed posthumanism within a context that differentiated humanism from enlightenment thought. According to Foucault, the two existed in a state of tension: as humanism sought to establish norms while Enlightenment thought attempted to transcend all that is material, including the boundaries that are constructed by humanistic thought. Drawing on the Enlightenment’s challenges to the boundaries of humanism, posthumanism rejects the various assumptions of human dogmas (anthropological, political, scientific) and takes the next step by attempting to change the nature of thought about what it means to be human. This requires not only decentering the human in multiple discourses (evolutionary, ecological, technological) but also examining those discourses to uncover inherent humanistic, anthropocentric, normative notions of humanness and the concept of the human.

Posthumanistic discourse aims to open up spaces to examine what it means to be human and critically question the concept of "the human" in light of current cultural and historical contexts In her book "How We Became Posthuman", N. Katherine Hayles, writes about the struggle between different versions of the posthuman as it continually co-evolves alongside intelligent machines. Such coevolution, according to some strands of the posthuman discourse, allows one to extend their subjective understandings of real experiences beyond the boundaries of embodied existence. According to Hayles's view of posthuman, often referred to as technological posthumanism, visual perception and digital representations thus paradoxically become ever more salient. Even as one seeks to extend knowledge by deconstructing perceived boundaries, it is these same boundaries that make knowledge acquisition possible. The use of technology in a contemporary society is thought to complicate this relationship.

Hayles discusses the translation of human bodies into information (as suggested by Hans Moravec) in order to illuminate how the boundaries of our embodied reality have been compromised in the current age and how narrow definitions of humanness no longer apply. Because of this, according to Hayles, posthumanism is characterized by a loss of subjectivity based on bodily boundaries. This strand of posthumanism, including the changing notion of subjectivity and the disruption of ideas concerning what it means to be human, is often associated with Donna Haraway’s concept of the cyborg. However, Haraway has distanced herself from posthumanistic discourse due to other theorists’ use of the term to promote utopian views of technological innovation to extend the human biological capacity (even though these notions would more correctly fall into the realm of transhumanism).

While posthumanism is a broad and complex ideology, it has relevant implications today and for the future. It attempts to redefine social structures without inherently humanly or even biological origins, but rather in terms of social and psychological systems where consciousness and communication could potentially exist as unique disembodied entities. Questions subsequently emerge with respect to the current use and the future of technology in shaping human existence, as do new concerns with regards to language, symbolism, subjectivity, phenomenology, ethics, justice and creativity.

Sociologist James Hughes comments that there is considerable confusion between the two terms. In the introduction to their book on post- and transhumanism, Robert Ranisch and Stefan Sorgner address the source of this confusion, stating that posthumanism is often used as an umbrella term that includes both transhumanism and critical posthumanism.

Although both subjects relate to the future of humanity, they differ in their view of anthropocentrism. Pramod Nayar, author of "Posthumanism", states that posthumanism has two main branches: ontological and critical. Ontological posthumanism is synonymous with transhumanism. The subject is regarded as “an intensification of humanism.” Transhumanism retains humanism’s focus on the homo sapien as the center of the world but also considers technology to be an integral aid to human progression. Critical posthumanism, however, is opposed to these views. Critical posthumanism “rejects both human exceptionalism (the idea that humans are unique creatures) and human instrumentalism (that humans have a right to control the natural world).” These contrasting views on the importance of human beings are the main distinctions between the two subjects. 

Transhumanism is also more ingrained in popular culture than critical posthumanism, especially in science fiction. The term is referred to by Pramod Nayar as "the pop posthumanism of cinema and pop culture." 

Some critics have argued that all forms of posthumanism, including transhumanism, have more in common than their respective proponents realize. Linking these different approaches, Paul James suggests that 'the key political problem is that, in effect, the position allows the human as a category of being to flow down the plughole of history':

However, some posthumanists in the humanities and the arts are critical of transhumanism (the brunt of Paul James's criticism), in part, because they argue that it incorporates and extends many of the values of Enlightenment humanism and classical liberalism, namely scientism, according to performance philosopher Shannon Bell:
While many modern leaders of thought are accepting of nature of ideologies described by posthumanism, some are more skeptical of the term. Donna Haraway, the author of "A Cyborg Manifesto", has outspokenly rejected the term, though acknowledges a philosophical alignment with posthumanism. Haraway opts instead for the term of companion species, referring to nonhuman entities with which humans coexist.

Questions of race, some argue, are suspiciously elided within the "turn" to posthumanism. Noting that the terms "post" and "human" are already loaded with racial meaning, critical theorist Zakiyyah Iman Jackson argues that the impulse to move "beyond" the human within posthumanism too often ignores "praxes of humanity and critiques produced by black people", including Frantz Fanon and Aime Cesaire to Hortense Spillers and Fred Moten. Interrogating the conceptual grounds in which such a mode of “beyond” is rendered legible and viable, Jackson argues that it is important to observe that ""blackness conditions and constitutes the very nonhuman disruption and/or disruption"" which posthumanists invite. In other words, given that race in general and blackness in particular constitutes the very terms through which human/nonhuman distinctions are made, for example in enduring legacies of scientific racism, a gesture toward a “beyond” actually “returns us to a Eurocentric transcendentalism long challenged”.



</doc>
<doc id="25065" url="https://en.wikipedia.org/wiki?curid=25065" title="Parameter">
Parameter

A parameter (from the Ancient Greek παρά, "para": "beside", "subsidiary"; and μέτρον, "metron": "measure"), generally, is any characteristic that can help in defining or classifying a particular system (meaning an event, project, object, situation, etc.). That is, a parameter is an element of a system that is useful, or critical, when identifying the system, or when evaluating its performance, status, condition, etc.

"Parameter" has more specific meanings within various disciplines, including mathematics, computing and computer programming, engineering, statistics, logic and linguistics. Within and across these fields, careful distinction must be maintained of the different usages of the term "parameter" and of other terms often associated with it, such as argument, property, axiom, variable, function, attribute, etc.

Mathematical functions have one or more arguments that are designated in the definition by variables. A function definition can also contain parameters, but unlike variables, parameters are not listed among the arguments that the function takes. When parameters are present, the definition actually defines a whole family of functions, one for every valid set of values of the parameters. For instance, one could define a general quadratic function by declaring
here, the variable "x" designates the function's argument, but "a", "b", and "c" are parameters that determine which particular quadratic function is being considered. A parameter could be incorporated into the function name to indicate its dependence on the parameter. For instance, one may define the base-"b" logarithm by the formula
where "b" is a parameter that indicates which logarithmic function is being used. It is not an argument of the function, and will, for instance, be a constant when considering the derivative formula_3.

In some informal situations it is a matter of convention (or historical accident) whether some or all of the symbols in a function definition are called parameters. However, changing the status of symbols between parameter and variable changes the function as a mathematical object. For instance, the notation for the falling factorial power
defines a polynomial function of "n" (when "k" is considered a parameter), but is not a polynomial function of "k" (when "n" is considered a parameter). Indeed, in the latter case, it is only defined for non-negative integer arguments. More formal presentations of such situations typically start out with a function of several variables (including all those that might sometimes be called "parameters") such as
as the most fundamental object being considered, then defining functions with fewer variables from the main one by means of currying.

Sometimes it is useful to consider all functions with certain parameters as "parametric family", i.e. as an indexed family of functions. Examples from probability theory are given further below.


W.M. Woods ... a mathematician ... writes ... "... a variable is one of the many things a "parameter" is not." ... The dependent variable, the speed of the car, depends on the independent variable, the position of the gas pedal.

[Kilpatrick quoting Woods] "Now ... the engineers ... change the lever arms of the linkage ... the speed of the car ... will still depend on the pedal position ..." but in a ... different manner". You have changed a parameter"


In the context of a mathematical model, such as a probability distribution, the distinction between variables and parameters was described by Bard as follows:

In analytic geometry, curves are often given as the image of some function. The argument of the function is invariably called "the parameter". A circle of radius 1 centered at the origin can be specified in more than one form:
Hence these equations, which might be called functions elsewhere are in analytic geometry characterized as parametric equations and the independent variables are considered as parameters.

In mathematical analysis, integrals dependent on a parameter are often considered. These are of the form
In this formula, "t" is the argument of the function "F", and on the right-hand side the "parameter" on which the integral depends. When evaluating the integral, "t" is held constant, and so it is considered to be a parameter. If we are interested in the value of "F" for different values of "t", we then consider "t" to be a variable. The quantity "x" is a "dummy variable" or "variable of integration" (confusingly, also sometimes called a "parameter of integration").

In statistics and econometrics, the probability framework above still holds, but attention shifts to estimating the parameters of a distribution based on observed data, or testing hypotheses about them. In frequentist estimation parameters are considered "fixed but unknown", whereas in Bayesian estimation they are treated as random variables, and their uncertainty is described as a distribution.

In estimation theory of statistics, "statistic" or estimator refers to samples, whereas "parameter" or estimand refers to populations, where the samples are taken from. A statistic is a numerical characteristic of a sample that can be used as an estimate of the corresponding parameter, the numerical characteristic of the population from which the sample was drawn.

For example, the sample mean (estimator), denoted formula_9, can be used as an estimate of the "mean" parameter (estimand), denoted "μ", of the population from which the sample was drawn. Similarly, the sample variance (estimator), denoted "S", can be used to estimate the "variance" parameter (estimand), denoted "σ", of the population from which the sample was drawn. (Note that the sample standard deviation ("S") is not an unbiased estimate of the population standard deviation ("σ"): see Unbiased estimation of standard deviation.)

It is possible to make statistical inferences without assuming a particular parametric family of probability distributions. In that case, one speaks of "non-parametric statistics" as opposed to the parametric statistics just described. For example, a test based on Spearman's rank correlation coefficient would be called non-parametric since the statistic is computed from the rank-order of the data disregarding their actual values (and thus regardless of the distribution they were sampled from), whereas those based on the Pearson product-moment correlation coefficient are parametric tests since it is computed directly from the data values and thus estimates the parameter known as the population correlation.

In probability theory, one may describe the distribution of a random variable as belonging to a "family" of probability distributions, distinguished from each other by the values of a finite number of "parameters". For example, one talks about "a Poisson distribution with mean value λ". The function defining the distribution (the probability mass function) is:
This example nicely illustrates the distinction between constants, parameters, and variables. "e" is Euler's number, a fundamental mathematical constant. The parameter λ is the mean number of observations of some phenomenon in question, a property characteristic of the system. "k" is a variable, in this case the number of occurrences of the phenomenon actually observed from a particular sample. If we want to know the probability of observing "k" occurrences, we plug it into the function to get formula_11. Without altering the system, we can take multiple samples, which will have a range of values of "k", but the system is always characterized by the same λ.

For instance, suppose we have a radioactive sample that emits, on average, five particles every ten minutes. We take measurements of how many particles the sample emits over ten-minute periods. The measurements exhibit different values of "k", and if the sample behaves according to Poisson statistics, then each value of "k" will come up in a proportion given by the probability mass function above. From measurement to measurement, however, λ remains constant at 5. If we do not alter the system, then the parameter λ is unchanged from measurement to measurement; if, on the other hand, we modulate the system by replacing the sample with a more radioactive one, then the parameter λ would increase.

Another common distribution is the normal distribution, which has as parameters the mean μ and the variance σ².

In these above examples, the distributions of the random variables are completely specified by the type of distribution, i.e. Poisson or normal, and the parameter values, i.e. mean and variance. In such a case, we have a parameterized distribution.

It is possible to use the sequence of moments (mean, mean square, ...) or cumulants (mean, variance, ...) as parameters for a probability distribution: see Statistical parameter.

In computing, a parameter is defined as "a reference or value that is passed to a function, procedure, subroutine, command, or program". For example, the name of a file, (a parameter), is passed to a computer program, which then performs a specific function; that is, a program may be passed the name of a file on which it will perform the specific function.

In computer programming, two notions of parameter are commonly used, and are referred to as parameters and arguments—or more formally as a formal parameter and an actual parameter.

For example, in the definition of a function such as
"x" is the "formal parameter" (the "parameter") of the defined function.

When the function is evaluated for a given value, as in
3 is the "actual parameter" (the "argument") for evaluation by the defined function; it is a given value (actual value) that is substituted for the "formal parameter" of the defined function. (In casual usage the terms "parameter" and "argument" might inadvertently be interchanged, and thereby used incorrectly.)

These concepts are discussed in a more precise way in functional programming and its foundational disciplines, lambda calculus and combinatory logic. Terminology varies between languages; some computer languages such as C define parameter and argument as given here, while Eiffel uses an alternative convention.

In engineering (especially involving data acquisition) the term "parameter" sometimes loosely refers to an individual measured item. This usage isn't consistent, as sometimes the term "channel" refers to an individual measured item, with "parameter" referring to the setup information about that channel.

"Speaking generally, properties are those physical quantities which directly describe the physical attributes of the system; parameters are those combinations of the properties which suffice to determine the response of the system. Properties can have all sorts of dimensions, depending upon the system being considered; parameters are dimensionless, or have the dimension of time or its reciprocal."

The term can also be used in engineering contexts, however, as it is typically used in the physical sciences.

In environmental science and particularly in chemistry and microbiology, a parameter is used to describe a discrete chemical or microbiological entity that can be assigned a value: commonly a concentration, but may also be a logical entity (present or absent), a statistical result such as a 95%ile value or in some cases a subjective value.

Within linguistics, the word "parameter" is almost exclusively used to denote a binary switch in a Universal Grammar within a Principles and Parameters framework.

In logic, the parameters passed to (or operated on by) an "open predicate" are called "parameters" by some authors (e.g., Prawitz, "Natural Deduction"; Paulson, "Designing a theorem prover"). Parameters locally defined within the predicate are called "variables". This extra distinction pays off when defining substitution (without this distinction special provision must be made to avoid variable capture). Others (maybe most) just call parameters passed to (or operated on by) an open predicate "variables", and when defining substitution have to distinguish between "free variables" and "bound variables".

In music theory, a parameter denotes an element which may be manipulated (composed), separately from the other elements. The term is used particularly for pitch, loudness, duration, and timbre, though theorists or composers have sometimes considered other musical aspects as parameters. The term is particularly used in serial music, where each parameter may follow some specified series. Paul Lansky and George Perle criticized the extension of the word "parameter" to this sense, since it is not closely related to its mathematical sense, but it remains common. The term is also common in music production, as the functions of audio processing units (such as the attack, release, ratio, threshold, and other variables on a compressor) are defined by parameters specific to the type of unit (compressor, equalizer, delay, etc.).



</doc>
<doc id="25066" url="https://en.wikipedia.org/wiki?curid=25066" title="Procedure">
Procedure

Procedure may refer to:


</doc>
<doc id="25071" url="https://en.wikipedia.org/wiki?curid=25071" title="Paavo Nurmi">
Paavo Nurmi

Paavo Johannes Nurmi (; 13 June 1897 – 2 October 1973) was a Finnish middle-distance and long-distance runner. He was nicknamed the "Flying Finn" as he dominated distance running in the early 20th century. Nurmi set 22 official world records at distances between 1500 metres and 20 kilometres, and won nine gold and three silver medals in his twelve events in the Olympic Games. At his peak, Nurmi was undefeated for 121 races at distances from 800 m upwards. Throughout his 14-year career, he remained unbeaten in cross country events and the 10,000 m.

Born into a working-class family, Nurmi left school at the age of twelve to provide for his family. In 1912, he was inspired by the Olympic feats of Hannes Kolehmainen and began developing a strict training program. Nurmi started to flourish during his military service, setting national records en route to his international debut at the 1920 Summer Olympics. After winning a silver medal in the 5000 m, he took gold in the 10,000 m and the cross country events. In 1923, Nurmi became the first runner to hold simultaneous world records in the mile, the 5000 m and the 10,000 m races, a feat which has never since been repeated. He set new world records for the 1500 m and the 5000 m with just an hour between the races, and took gold medals in both distances in less than two hours at the 1924 Olympics. Seemingly unaffected by the Paris heat wave, Nurmi won all his races and returned home with five gold medals, although he was frustrated that Finnish officials had refused to enter him for the 10,000 m.

Struggling with injuries and motivation issues after his exhaustive U.S. tour in 1925, Nurmi found his long-time rivals Ville Ritola and Edvin Wide ever more serious challengers. At the 1928 Summer Olympics, Nurmi recaptured the 10,000 m title but was beaten for the gold in the 5000 m and the 3000 m steeplechase. He then turned his attention to longer distances, breaking the world records for events such as the one hour run and the 25-mile marathon. Nurmi intended to end his career with a marathon gold medal, as his idol Kolehmainen had done. In a controversial case that strained Finland–Sweden relations and sparked an inter-IAAF battle, Nurmi was suspended before the 1932 Games by an IAAF council that questioned his amateur status; two days before the opening ceremonies, the council rejected his entries. Although he was never declared a professional, Nurmi's suspension became definite in 1934 and he retired from running.

Nurmi later coached Finnish runners, raised funds for Finland during the Winter War, and worked as a haberdasher, building contractor, and share trader, eventually becoming one of Finland's richest people. In 1952, he was the lighter of the Olympic Flame at the Summer Olympics in Helsinki. Nurmi's running speed and elusive personality spawned nicknames such as the "Phantom Finn", while his achievements, training methods and running style influenced future generations of middle- and long-distance runners. Nurmi, who rarely ran without a stopwatch in his hand, has been credited for introducing the "even pace" strategy and analytic approach to running, and for making running a major international sport.

Nurmi was born in Turku, Finland, to carpenter Johan Fredrik Nurmi and his wife Matilda Wilhelmiina Laine. Nurmi's siblings, Siiri, Saara, Martti and Lahja, were born in 1898, 1902, 1905 and 1908, respectively. In 1903, the Nurmi family moved from Raunistula into a 40-square-meter apartment in central Turku, where Paavo Nurmi would live until 1932. The young Nurmi and his friends were inspired by the English long-distance runner Alfred Shrubb. They regularly ran or walked six kilometres (four miles) to swim in Ruissalo, and back, sometimes twice a day. By the age of eleven, Nurmi ran the 1500 metres in 5:02. Nurmi's father Johan died in 1910 and his sister Lahja a year later. The family struggled financially, renting out their kitchen to another family and living in a single room. Nurmi, a talented student, left school to work as an errand boy for a bakery. Although he stopped running actively, he got plenty of exercise pushing heavy carts up the steep slopes in Turku. He later credited these climbs for strengthening his back and leg muscles.

At 15, Nurmi rekindled his interest in athletics after being inspired by the performances of Hannes Kolehmainen, who was said to "have run Finland onto the map of the world" at the 1912 Summer Olympics. He bought his first pair of sneakers a few days later. Nurmi trained primarily by doing cross country running in the summers and cross country skiing in the winters. In 1914, Nurmi joined the sports club Turun Urheiluliitto and won his first race on the 3000 metres. Two years later, he revised his training program to include walking, sprints and calisthenics. He continued to provide for his family through his new job at the Ab. H. Ahlberg & Co workshop in Turku, where he worked until he started his military service at a machine gun company in the Pori Brigade in April 1919. During the Finnish Civil War in 1918, Nurmi remained politically passive and concentrated on his work and his Olympic ambitions. After the war, he decided not to join the newly founded Finnish Workers' Sports Federation, but wrote articles for the federation's chief organ and criticized the discrimination against many of his fellow workers and athletes.
In the army, Nurmi quickly impressed in the athletic competitions: While others marched, Nurmi ran the whole distances with a rifle on his shoulder and a backpack full of sand. Nurmi's stubbornness caused him difficulties with his non-commissioned officers, but he was favoured by the superior officers, despite his refusal to take the soldier's oath. As the unit commander Hugo Österman was a known sports aficionado, Nurmi and few other athletes were given free time to practice. Nurmi improvised new training methods in the army barracks; he ran behind trains, holding on to the rear bumper, to stretch his stride, and used heavy iron-clad army boots to strengthen his legs. Nurmi soon began setting personal bests and got close for the Olympic selection. In March 1920, he was promoted to corporal ("alikersantti"). On 29 May 1920, he set his first national record on the 3000 m and went on to win the 1500 m and the 5000 m at the Olympic trials in July.

Nurmi made his international debut in August at the 1920 Summer Olympics in Antwerp, Belgium. He took his first medal by finishing second to Frenchman Joseph Guillemot in the 5000 m. This would remain the only time that Nurmi lost to a non-Finnish runner in the Olympics. He went on to win gold medals in his other three events: the 10,000 m, sprinting past Guillemot on the final curve and improving his personal best by over a minute, the cross country race, beating Sweden's Eric Backman, and the cross country team event where he helped Heikki Liimatainen and Teodor Koskenniemi defeat the British and Swedish teams. Nurmi's success brought electric lighting and running water for his family in Turku. Nurmi, however, was given a scholarship to study at the Teollisuuskoulu industrial school in Helsinki.

Buoyed by his defeat to Guillemot, Nurmi's races became a series of experiments which he analyzed meticulously. Previously known for his blistering pace on the first few laps, Nurmi started to carry a stopwatch and spread his efforts more uniformly over the distance. He aimed to perfect his technique and tactics to a point where the performances of his rivals would be rendered meaningless. Nurmi set his first world record on the 10,000 m in Stockholm in 1921. In 1922, he broke the world records for the 2000 m, the 3000 m and the 5000 m. A year later, Nurmi added the records for the 1500 m and the mile. His feat of holding the world records for the mile, the 5000 m and the 10,000 m at the same time has not been matched by any other athlete before or since. Nurmi also tested his speed in the 800 m, winning the 1923 Finnish Championships with a new national record. After excelling in mathematics, Nurmi graduated as an engineer in 1923 and returned home to prepare for the upcoming Olympic Games.

Nurmi's trip to the 1924 Summer Olympics was endangered by a knee injury in the spring of 1924, but he recovered and resumed training twice a day. On 19 June, Nurmi tried out the 1924 Olympic schedule at the Eläintarha Stadium in Helsinki by running the 1500 m and the 5000 m inside an hour, setting new world records for both distances. In the 1500 m final at the Olympics in Paris, Nurmi ran the first 800 m almost three seconds faster. His only challenger, Ray Watson of the United States, gave up before the last lap and Nurmi was able to slow down and coast to victory ahead of Willy Schärer, H. B. Stallard and Douglas Lowe, still breaking the Olympic record by three seconds. The 5000 m final started in less than two hours, and Nurmi faced a tough challenge from countryman Ville Ritola, who had already won the 3000 m steeplechase and the 10,000 m. Ritola and Edvin Wide figured that Nurmi must be tired and tried to burn him off by running at world-record pace. Realizing that he was now racing the two men and not the clock, Nurmi tossed his stopwatch onto the grass. The Finns later passed the Swede as his pace faded and continued their duel. On the home straight, Ritola sprinted from the outside but Nurmi increased his pace to keep his rival a metre behind.

In the cross country events, the heat of 45 °C (113 °F), caused all but 15 of the 38 competitors to abandon the race. Eight finishers were taken away on stretchers. One athlete began to run in tiny circles after reaching the stadium, until setting off into the stands and knocking himself unconscious. Early leader Wide was among those who blacked out along the course, and was incorrectly reported to have died at the hospital. Nurmi exhibited only slight signs of exhaustion after beating Ritola to the win by nearly a minute and a half. As Finland looked to have lost the team medal, the disoriented Liimatainen staggered into the stadium, but was barely moving forward. An athlete ahead of him fainted 50 metres from the finish, and Liimatainen stopped and tried to find his way off the track, thinking he had reached the finish line. After having ignored shouts and kept the spectators in suspense for a while, he turned into the right direction, realised his situation and reached the finish in 12th place and secured team gold. Those present at the stadium were shocked by what they had witnessed, and Olympic officials decided to ban cross country running from future Games.

In the 3000 m team race on the next day, Nurmi and Ritola again finished first and second, and Elias Katz secured the gold medal for the Finnish team by finishing fifth. Nurmi had won five gold medals in five events, but he left the Games embittered as the Finnish officials had allocated races between their star runners and prevented him from defending his title in the 10,000 m, the distance that was dearest to him. After returning to Finland, Nurmi set a 10,000 m world record that would last for almost 13 years. He now held the 1500 m, the mile, the 3000 m, the 5000 m and the 10,000 m world records simultaneously.

In early 1925, Nurmi embarked on a widely publicised tour of the United States. He competed in 55 events (45 indoors) during a five-month period, starting at a sold-out Madison Square Garden on 6 January. His debut was a copy of his feats in Helsinki and Paris. Nurmi defeated Joie Ray and Lloyd Hahn to win the mile and Ritola to win the 5000 m, again setting new world records for both distances. Nurmi broke ten more indoor world records in regular events and set several new best times for rarer distances. He won 51 of the events, abandoned one race and lost two handicap races along with his final event; a half-mile race at the Yankee Stadium, where he finished second to American track star Alan Helffrich. Helffrich's victory ended Nurmi's 121-race, four-year win streak in individual scratch races at distances from 800 m upwards. Although he hated losing more than anything, Nurmi was the first to congratulate Helffrich. The tour made Nurmi extremely popular in the United States, and the Finn agreed to meet President Calvin Coolidge at the White House. Nurmi left America fearing that he had competed too often and burned himself out.

Nurmi struggled to maintain motivation for running, heightened by his rheumatism and Achilles tendon problems. He quit his job as a machinery draughtsman in 1926 and began studying business intensively. As Nurmi started a new career as a share dealer, his financial advisors included Risto Ryti, director of the Bank of Finland. In 1926, Nurmi broke Wide's world record for the 3000 m in Berlin and then improved the record in Stockholm, despite Nils Eklöf repeatedly trying to slow his pace down in an effort to aid Wide. Nurmi was furious at the Swedes and vowed never to race Eklöf again. In October 1926, he lost a 1500 m race along with his world record to Germany's Otto Peltzer. This marked the first time in over five years and 133 races that Nurmi had been defeated at a distance over 1000 m. In 1927, Finnish officials barred him from international competition for refusing to run against Eklöf at the Finland-Sweden international, cancelling the Peltzer rematch scheduled for Vienna. Nurmi ended his season and threatened, until late November, to withdraw from the 1928 Summer Olympics. At the 1928 Olympic trials, Nurmi was left third in the 1500 m by eventual gold and bronze medalists Harri Larva and Eino Purje, and he decided to concentrate on the longer distances. He added steeplechase to his program, although he had only tried the event twice before, the latest being a two-mile steeplechase victory at the 1922 British Championships.

At the 1928 Olympics in Amsterdam, Nurmi competed in three events. He won the 10,000 m by staying right behind Ritola until sprinting past him on the home straight. Before the 5000 m final, Nurmi injured himself in his qualifying heat for the 3000 m steeplechase. He fell on his back at the water jump, spraining his hip and foot. Lucien Duquesne stopped to help him up, and Nurmi thanked the Frenchman by pacing him past the field and offered him the heat win, which Duquesne gracefully refused. In the 5000 m, Nurmi tried to repeat his move on Ritola but had to watch his teammate pull away instead. Nurmi, looking more exhausted than ever before, only barely managed to keep Wide behind and take silver. Nurmi had little time to rest or nurse his injuries as the 3000 m steeplechase started the next day. Struggling with the hurdles, Nurmi let Finland's steeplechase specialist Toivo Loukola escape into the distance. On the final lap, he sprinted clear of the others and finished nine seconds behind the world-record setting Loukola; Nurmi's time also bettered the previous record. Although Ritola did not finish, Ove Andersen completed a Finnish sweep of the medals.

Nurmi stated to a Swedish newspaper that "this is absolutely my last season on the track. I am beginning to get old. I have raced for fifteen years and have had enough of it." However, Nurmi continued running, turning his attention to longer distances. In October, he broke the world records for the 15 km, the 10 miles and the one hour run in Berlin. Nurmi's one-hour record stood for 17 years, until Viljo Heino ran 129 metres further in 1945. In January 1929, Nurmi started his second U.S. tour from Brooklyn. He suffered his first-ever defeat in the mile to Ray Conger at the indoor Wanamaker Mile. Nurmi was seven seconds slower than in his world record run in 1925, and it was immediately speculated if the mile had become too short a distance for him. In 1930, he set a new world record for the 20 km. In July 1931, Nurmi showed he still had pace for the shorter distances by beating Lauri Lehtinen, Lauri Virtanen and Volmari Iso-Hollo, and breaking the world record on the now-rare two miles. He was the first runner to complete the distance in less than nine minutes. Nurmi planned to compete only in the 10,000 m and the marathon in the 1932 Summer Olympics in Los Angeles, stating that he "won't enter the 5000 metres for Finland has at least three excellent men for that event."

In April 1932, the executive council of the International Amateur Athletics Federation (IAAF) suspended Nurmi from international athletics events pending an investigation into his amateur status by the Finnish Athletics Federation. The Finnish authorities criticized the IAAF for acting without a hearing, but agreed to launch an investigation. It was customary of the IAAF to accept the final decision of its national branch, and the Associated Press wrote that "there is little doubt that if the Finnish federation clears Nurmi the international body will accept its decision without question." A week later, the Finnish Athletics Federation ruled in favor of Nurmi, finding no evidence for the allegations of professionalism. Nurmi was hopeful that his suspension would be lifted in time for the Games.
On 26 June 1932 Nurmi started his first marathon at the Olympic trials. Not drinking a drop of liquid, he ran the old-style 'short marathon' of 40.2 km (25 miles) in 2:22:03.8 — on the pace to finish in about 2:29:00, just under Albert Michelsen's marathon world record of 2:29:01.8. At the time, he led Armas Toivonen, the eventual Olympic bronze medalist, by six minutes. Nurmi's time was the new unofficial world record for the short marathon. Confident that he had done enough, Nurmi stopped and retired from the race owing to problems with his Achilles tendon. The Finnish Olympic Committee entered Nurmi for both the 10,000 m and the marathon. "The Guardian" reported that "some of his trial times were almost unbelievable," and Nurmi went on to train at the Olympic Village in Los Angeles despite his injury. Nurmi had set his heart on ending his career with a marathon gold medal, as Kolehmainen had done shortly after the First World War.

Less than three days before the 10,000 m, a special commission of the IAAF, consisting of the same seven members that had suspended Nurmi, rejected the Finn's entries and barred him from competing in Los Angeles. Sigfrid Edström, president of the IAAF and chairman of its executive council, stated that the full congress of the IAAF, which was scheduled to start the next day, could not reinstate Nurmi for the Olympics but merely review the phases and political angles related to the case. The AP called this "one of the slickest political maneuvers in international athletic history", and wrote that the Games would now be "like Hamlet without the celebrated Dane in the cast." Thousands protested against the action in Helsinki. Details of the case were not released to the press, but the evidence against Nurmi was believed be the sworn statements from German race promoters that Nurmi had received $250–500 per race when running in Germany in autumn 1931. The statements were produced by Karl Ritter von Halt after Edström had sent him increasingly threatening letters, warning that if evidence against Nurmi is not provided, he "will unfortunately have to take stringent action against the German Athletics Association."

On the eve of the marathon, all the entrants of the race except for the Finns, whose positions were known, filed a petition asking Nurmi's entry to be accepted. Edström's right-hand man Bo Ekelund, secretary general of the IAAF and head of the Swedish Athletics Federation, approached the Finnish officials and stated that he might be able to arrange for Nurmi to participate in the marathon outside the competition. However, Finland maintained that as long as the athlete is not declared a professional, he must have the right to participate in the race officially. Although he had been diagnosed with a pulled Achilles tendon two weeks earlier, Nurmi stated he would have won the event by five minutes. The congress concluded without Nurmi being declared a professional, but the council's authority to disbar an athlete was upheld on a 13–12 vote. However, due to the close vote, the matter was postponed until the 1934 meet in Stockholm. Finns charged that the Swedish officials had used devious tricks in their campaign against Nurmi's amateur status, and ceased all athletic relations with Sweden. A year earlier, controversies on the track and in the press had led Finland to withdraw from the Finland-Sweden athletics international. After Nurmi's suspension, Finland did not agree to return to the event until 1939.

Nurmi refused to turn professional, and continued running as amateur in Finland. In 1933, he ran his first 1500 m in three years and won the national title with his best time since 1926. At the IAAF meet in August 1934, Finland launched two proposals that lost. The council then brought forward its resolution empowering it to suspend athletes that it finds in violation of the IAAF amateur code. With a 12–5 vote, with many not voting, Nurmi's suspension from international amateur athletics became definite. Less than three weeks later, Nurmi retired from running with a 10,000 m victory in Viipuri on 16 September 1934. Nurmi remained undefeated in the distance throughout his 14-year top-level career. In cross country running, his win streak lasted 19 years.

While active as a runner, Nurmi was known to be secretive about his training methods. Always running alone, he upped his pace and quickly exhausted anyone who was bold enough to join him. Even his club mate Harri Larva had learned little from him. After ending his career, Nurmi became a coach for the Finnish Athletics Federation and trained runners for the 1936 Summer Olympics in Berlin. In 1935, Nurmi along with the entire board of directors quit the federation after a heated 40–38 vote to resume athletic relations with Sweden. However, Nurmi returned to coaching three months later and the Finnish distance runners went on to take three gold medals, three silvers and a bronze at the Games. In 1936, Nurmi also opened a men's clothing store (haberdashery) in Helsinki. It became a popular tourist attraction, and Emil Zátopek was among those who visited the store trying to meet Nurmi. The Finn spent his time in the back room, running another new business venture; construction. As a contractor, Nurmi built forty apartment buildings in Helsinki with about a hundred flats in each. Within five years, he was rated a millionaire. His fiercest rival Ritola ended up living in one of Nurmi's flats, at half price. Nurmi also made money on the stock market, eventually becoming one of Finland's richest people.

In February 1940, during the Winter War between Finland and the Soviet Union, Nurmi returned to the United States with his protégé Taisto Mäki, who had become the first man to run the 10,000 m under 30 minutes, to raise funds and rally support to the Finnish cause. The relief drive, directed by former president Herbert Hoover, included a coast-to-coast tour by Nurmi and Mäki. Hoover welcomed the two as "ambassadors of the greatest sporting nation in the world." While in San Francisco, Nurmi received news that one of his apprentices, 1936 Olympic champion Gunnar Höckert, had been killed in action. Nurmi left for Finland in late April, and later served in the Continuation War in a delivery company and as a trainer in the military staff. Before he was discharged in January 1942, Nurmi was promoted first to a staff sergeant ("ylikersantti") and later to a sergeant first class ("vääpeli").
In 1952, Nurmi was persuaded by Urho Kekkonen, Prime Minister of Finland and former chairman of the Finnish Athletics Federation, to carry the Olympic torch into the Olympic Stadium at the 1952 Summer Olympics in Helsinki. His appearance astonished the spectators, and "Sports Illustrated" wrote that "his celebrated stride was unmistakable to the crowd. When he came into view, waves of sound began to build throughout the stadium, rising to a roar, then to a thunder. When the national teams, assembled in formation on the infield, saw the flowing figure of Nurmi, they broke ranks like excited schoolchildren, dashing toward the edge of the track." After lighting the flame in the Olympic Cauldron, Nurmi passed the torch to his idol Kolehmainen, who lighted the beacon in the tower. In the cancelled 1940 Summer Olympics, Nurmi had been planned to lead a group of fifty Finnish gold medal winners.

Nurmi felt that he got too much credit as an athlete and too little as a businessman, but his interest in running never died. He even returned to the track himself a few times. In 1946, he faced his old rival Edvin Wide in Stockholm in a benefit for the victims of the Greek Civil War. Nurmi ran for the last time on 18 February 1966 at the Madison Square Garden, invited by the New York Athletic Club. In 1962, Nurmi predicted that welfare countries would start to struggle in the distance events: "The higher the standard of living in a country, the weaker the results often are in the events which call for work and trouble. I would like to warn this new generation: 'Do not let this comfortable life make you lazy. Do not let the new means of transport kill your instinct for physical exercise. Too many young people get used to driving in a car even for small distances.'" In 1966, he took the microphone in front of 300 sports club guests and criticised the state of distance running in Finland, reproaching the sports executives as publicity seekers and tourists, and demanding athletes sacrifice everything to accomplish something. Nurmi lived to see the renaissance of Finnish running in the 1970s, led by athletes such as the 1972 Olympic gold medalists Lasse Virén and Pekka Vasala. He had complimented the running style of Virén, and advised Vasala to concentrate on Kipchoge Keino.

Although he accepted an invitation from President Lyndon B. Johnson to revisit the White House in 1964, Nurmi lived a very secluded life until the late 1960s when he began granting some press interviews. On his 70th birthday, Nurmi agreed to an interview for Yle, Finland's national public-broadcasting company, only after learning that President Kekkonen would act as the interviewer. Suffering from health problems, with at least one heart attack, a stroke and failing eyesight, Nurmi at times spoke bitterly about sports, calling it a waste of time compared to science and art. He died in 1973 in Helsinki and was given a state funeral. Kekkonen attended the funeral and praised Nurmi: "People explore the horizons for a successor. But none comes and none will, for his class is extinguished with him." At the request of Nurmi, who enjoyed classical music and played the violin, Konsta Jylhä's "Vaiennut viulu" ("The Silenced Violin") was played during the ceremony. Nurmi's last record fell in 1996; his 1925 world record for the indoor 2000 m lasted as the Finnish national record for 71 years.

Nurmi was married to socialite Sylvi Laaksonen from 1932 to 1935. Laaksonen, who was not interested in athletics, opposed Nurmi raising their newborn son Matti to be a runner and stated to the Associated Press in 1933, "[H]is concentration on athletics at last forced me to go to the judge for a divorce." Matti Nurmi did become a middle-distance runner, and later a "self-made" businessman. Nurmi's relationship with his son was termed "uneasy". Matti admired his father more as a businessman than as an athlete, and the two never discussed his running career. As a runner, Matti was at his best in the 3000 m, where he equalled his father's time. In the famous race on 11 July 1957 when the "three Olavis" (Salsola, Salonen and Vuorisalo) broke the world record for the 1500 m, Matti Nurmi finished a distant ninth with his personal best, 2.2 seconds slower than his father's world record from 1924. Hollywood actress Maila Nurmi, best known as the horror icon "Vampira", was often referred to as Paavo Nurmi's niece. However, the kinship is not supported by official documents.

Nurmi enjoyed the Finnish sports massage and sauna-bathing traditions, crediting the Finnish sauna for his performances during the Paris heat wave in 1924. He had a versatile diet, although he had practiced vegetarianism between the ages of 15 and 21. Nurmi, who identified as neurasthenic, was known to be "taciturn", "stony-faced" and "stubborn". He was not believed to have had any close friends, but he had occasionally socialized and showed his "sarcastic sense of humour" among the small circles he knew. Acclaimed the biggest sporting figure in the world at his peak, Nurmi was averse to publicity and the media, stating later on his 75th birthday, "[W]orldly fame and reputation are worth less than a rotten lingonberry." French journalist Gabriel Hanot questioned Nurmi's intensive approach to sports and wrote in 1924 that Nurmi "is ever more serious, reserved, concentrated, pessimistic, fanatic. There is such coldness in him and his self-control is so great that never for a moment does he show his feelings." Some contemporary Finns nicknamed him "Suuri vaikenija" (The Great Silent One), and Ron Clarke noted that Nurmi's persona remained a mystery even to Finnish runners and journalists: "Even to them, he was never quite real. He was enigmatic, sphinx-like, a god in a cloud. It was as if he was all the time playing a role in a drama."

Nurmi was more responsive to his fellow athletes than to the media. He exchanged ideas with sprinter Charley Paddock and even trained with his rival Otto Peltzer. Nurmi told Peltzer to forget his opponents: "Conquering yourself is the greatest challenge of an athlete." Nurmi was known to emphasize the importance of psychological strength: "Mind is everything; muscle, pieces of rubber. All that I am, I am because of my mind." Regarding Nurmi's track antics, Peltzer found that "in his impenetrability he was a Buddha gliding on the track. Stopwatch in hand, lap after lap, he ran towards the tape, subject only to the laws of a mathematical table." Marathoner Johnny Kelley, who first met his idol at the 1936 Olympics, said that while Nurmi appeared cold to him at first, the two chatted for quite a while after Nurmi had asked for his name: "He grabbed ahold of me — he was so excited. I couldn't believe it!"

Nurmi's speed and elusive personality led to nicknames such as the "Phantom Finn", the "King of Runners" and "Peerless Paavo", while his mathematical prowess and use of a stopwatch led the press to characterize him as a running machine. One newspaperman dubbed Nurmi "a mechanical Frankenstein created to annihilate time." Phil Cousineau noted that "his own innovation — the tactic of pacing himself with a stopwatch — both inspired and troubled people in an era when the robot was becoming symbolic of the modern soulless human being." Among the popular newspaper rumours about Nurmi was that he had a "freakish heart" with a very low pulse rate. During the debate over his amateur status, Nurmi was joked to have "the lowest heartbeat and the highest asking price of any athlete in the world."

Nurmi broke 22 official world records on distances between 1500 m and 20 km; a record in running. He also set many more unofficial ones for a total of 58. His indoor world records were all unofficial as the IAAF did not ratify indoor records until the 1980s. Nurmi's record for most Olympic gold medals was matched by gymnast Larisa Latynina in 1964, swimmer Mark Spitz in 1972 and fellow track and field athlete Carl Lewis in 1996, and broken by swimmer Michael Phelps in 2008. Nurmi's record for most medals in the Olympic Games stood until Edoardo Mangiarotti won his 13th medal in fencing in 1960. "Time" selected Nurmi as the greatest Olympian of all time in 1996, and IAAF named him among the first twelve athletes to be inducted into the IAAF Hall of Fame in 2012.

Nurmi introduced the "even pace" strategy to running, pacing himself with a stopwatch and spreading his energy uniformly over the race. He reasoned that "when you race against time, you don't have to sprint. Others can't hold the pace if it is steady and hard all through to the tape." Archie Macpherson stated that "with the stopwatch always in his hand, he elevated athletics to a new plane of intelligent application of effort and was the harbinger of the modern scientifically prepared athlete." Nurmi was considered a pioneer also in regards to training; he developed a systematic all-year-round training program that included both long-distance work and interval running. Peter Lovesey wrote in "The Kings of Distance: A Study of Five Great Runners" that Nurmi "accelerated the progress of world records; developed and actually came to personify the analytic approach to running; and he was a profound influence not only in Finland, but throughout the world of athletics. Nurmi, his style, technique and tactics were held to be infallible, and really seemed so, as successive imitators in Finland steadily improved the records." Cordner Nelson, founder of "Track & Field News", credited Nurmi for popularizing running as a spectator sport: "His imprint on the track world was greater than any man’s before or after. He, more than any man, raised track to the glory of a major sport in the eyes of international fans, and they honored him as one of the truly great athletes of all sports.

Nurmi's achievements and training methods inspired future track stars of many generations. Emil Zátopek chanted "I am Nurmi! I am Nurmi!" when he trained as a child, and based his training system on what he was able to find out about Nurmi's methods. Lasse Virén idolized Nurmi and was scheduled to meet him for the first time on the day that Nurmi died. Hicham El Guerrouj was inspired to become a runner so that he could "repeat the achievements of the great man of whom his grandfather spoke." He became the first man after Nurmi to win the 1500 m and the 5000 m at the same Games. Nurmi's influence stretched further than running on the Olympic arena. At the 1928 Olympics, Kazimierz Wierzyński won the lyric gold medal with his poem "Olympic Laurel" that included a verse on Nurmi. In 1936, Ludwig Stubbendorf and his horse "Nurmi" won the individual and team gold medals in eventing.
A bronze statue of Nurmi was sculpted by Wäinö Aaltonen in 1925. The original is held at the art museum Ateneum, but copies cast from the original mould exist in Turku, in Jyväskylä, in front of the Helsinki Olympic Stadium and at the Olympic Museum in Lausanne, Switzerland. In a widely publicized prank by the students of the Helsinki University of Technology, a miniature copy of the statue was discovered from the 300-year-old wreck of the Swedish war ship "Vasa" when it was lifted from the bottom of the sea in 1961. Statues of Nurmi were also sculpted by Renée Sintenis in 1926 and by Carl Eldh, whose 1937 work "Löpare" ("Runners") depicts a battle between Nurmi and Edvin Wide. "Boken om Nurmi" ("The Book about Nurmi"), released in Sweden in 1925, was the first biographical book on a Finnish sportsman. Finnish astronomer Yrjö Väisälä named the main belt asteroid 1740 Paavo Nurmi after Nurmi in 1939, while Finnair named its first DC-8 "Paavo Nurmi" in 1969. Nurmi's former rival Ville Ritola boarded the plane when he moved back to Finland in 1970.

Paavo Nurmi Marathon, held annually since 1969, is the oldest marathon in Wisconsin and the second-oldest in the American Midwest. In Finland, another marathon bearing the name has been held in Nurmi's hometown of Turku since 1992, along with the athletics competition Paavo Nurmi Games that was started in 1957. Finlandia University, an American college with Finnish roots, named their athletic center after Nurmi. A ten-mark bill featuring a portrait of Nurmi was issued by the Bank of Finland in 1987. The other revised bills honored architect Alvar Aalto, composer Jean Sibelius, Enlightenment thinker Anders Chydenius and author Elias Lönnrot, respectively. The Nurmi bill was replaced by a new 20-mark note featuring Väinö Linna in 1993. In 1997, a historic stadium in Turku was renamed the "Paavo Nurmi Stadium". Twenty world records have been set at the stadium, including John Landy's records on the 1500 m and the mile, Nurmi's record on the 3000 m and Zátopek's record on the 10,000 m. In fiction, Nurmi appears in William Goldman's 1974 novel "Marathon Man" as the idol of the protagonist, who aims to become a greater runner than Nurmi. The opera on Nurmi, "Paavo the Great. Great Race. Great Dream.", written by Paavo Haavikko and composed by Tuomas Kantelinen, debuted at the Helsinki Olympic Stadium in 2000. In a 2005 episode of "The Simpsons", Mr. Burns brags that he once outraced Nurmi in his antique motorcar.

The starts figure excludes heats, handicap races, relays, and events where Nurmi raced alone against relay teams.
The starts figure excludes heats, handicap races, relays, and events where Nurmi raced alone against relay teams.



 


</doc>
<doc id="25072" url="https://en.wikipedia.org/wiki?curid=25072" title="Purple Heart">
Purple Heart

The Purple Heart is a United States military decoration awarded in the name of the president to those wounded or killed while serving, on or after April 5, 1917, with the U.S. military. With its forerunner, the Badge of Military Merit, which took the form of a heart made of purple cloth, the Purple Heart is the oldest military award still given to U.S. military members – the only earlier award being the obsolete Fidelity Medallion. The National Purple Heart Hall of Honor is located in New Windsor, New York.

The original Purple Heart, designated as the Badge of Military Merit, was established by George Washington – then the commander-in-chief of the Continental Army – by order from his Newburgh, New York headquarters on August 7, 1782. The Badge of Military Merit was only awarded to three Revolutionary War soldiers by Gen. George Washington himself. General Washington authorized his subordinate officers to issue Badges of Merit as appropriate. From then on, as its legend grew, so did its appearance. Although never abolished, the award of the badge was not proposed again officially until after World War I.

On October 10, 1927, Army Chief of Staff General Charles Pelot Summerall directed that a draft bill be sent to Congress "to revive the Badge of Military Merit". The bill was withdrawn and action on the case ceased January 3, 1928, but the office of the Adjutant General was instructed to file all materials collected for possible future use. A number of private interests sought to have the medal re-instituted in the Army; this included the board of directors of the Fort Ticonderoga Museum in Ticonderoga, New York.

On January 7, 1931, Summerall’s successor, General Douglas MacArthur, confidentially reopened work on a new design, involving the Washington Commission of Fine Arts. Elizabeth Will, an Army heraldic specialist in the Office of the Quartermaster General, was named to redesign the newly revived medal, which became known as the Purple Heart. Using general specifications provided to her, Will created the design sketch for the present medal of the Purple Heart. The new design, which exhibits a bust and profile of George Washington, was issued on the bicentennial of Washington's birth. Will's obituary, in the edition of February 8, 1975 of "The Washington Post" newspaper, reflects her many contributions to military heraldry.

The Commission of Fine Arts solicited plaster models from three leading sculptors for the medal, selecting that of John R. Sinnock of the Philadelphia Mint in May 1931. By Executive Order of the President of the United States, the Purple Heart was revived on the 200th Anniversary of George Washington's birth, out of respect to his memory and military achievements, by War Department , dated February 22, 1932. 
The criteria were announced in a War Department circular dated February 22, 1932, and authorized award to soldiers, upon their request, who had been awarded the Meritorious Service Citation Certificate, Army Wound Ribbon, or were authorized to wear Wound Chevrons subsequent to April 5, 1917, the day before the United States entered World War I. The first Purple Heart was awarded to MacArthur. During the early period of American involvement in World War II (December 7, 1941 – September 22, 1943), the Purple Heart was awarded both for wounds received in action against the enemy and for meritorious performance of duty. With the establishment of the Legion of Merit, by an Act of Congress, the practice of awarding the Purple Heart for meritorious service was discontinued. By , dated December 3, 1942, the decoration was applied to all services; the order required reasonable uniform application of the regulations for each of the Services. This executive order also authorized the award only for wounds received. For both military and civilian personnel during the World War II era, to meet eligibility for the Purple Heart, AR 600-45, dated September 22, 1943, and May 3, 1944, required identification of circumstances.

After the award was re-authorized in 1932 some U.S. Army wounded from conflicts prior to the first World War applied for, and were awarded, the Purple Heart: "...veterans of the Civil War and Indian Wars, as well as the Spanish–American War, China Relief Expedition (Boxer Rebellion), and Philippine Insurrection also were awarded the Purple Heart. This is because the original regulations governing the award of the Purple Heart, published by the Army in 1932, provided that any soldier who had been wounded in any conflict involving U.S. Army personnel might apply for the new medal. There were but two requirements: the applicant had to be alive at the time of application (no posthumous awards were permitted) and he had to prove that he had received a wound that necessitated treatment by a medical officer."

Subject to approval of the Secretary of Defense, , dated February 12, 1952, revised authorizations to include the Service Secretaries. Dated April 25, 1962, , included provisions for posthumous award of the Purple Heart. Dated February 23, 1984, , authorized award of the Purple Heart as a result of terrorist attacks, or while serving as part of a peacekeeping force, subsequent to March 28, 1973.

On June 13, 1985, the Senate approved an amendment to the 1985 Defense Authorization Bill, which changed the precedence of the Purple Heart award, from immediately above the Good Conduct Medal to immediately above the Meritorious Service Medals. Public Law 99-145 authorized the award for wounds received as a result of friendly fire. Public Law 104-106 expanded the eligibility date, authorizing award of the Purple Heart to a former prisoner of war who was wounded after April 25, 1962. The National Defense Authorization Act for Fiscal Year 1998 (Public Law 105-85) changed the criteria to delete authorization for award of the Purple Heart to any civilian national of the United States, while serving under competent authority in any capacity with the Armed Forces. This change was effective May 18, 1998.

During World War II, 1,506,000 Purple Heart medals were manufactured in anticipation of the estimated casualties resulting from the planned Allied invasion of Japan and by the end of the war even accounting for those lost, stolen or wasted, nearly 500,000 remained. To the present date, total combined American military casualties of the seventy years following the end of World War II—including the Korean and Vietnam Wars—have not exceeded that number. In 2003, there remained 120,000 Purple Heart medals in stock. The existing surplus allowed combat units in Iraq and Afghanistan to keep Purple Hearts on-hand for immediate award to soldiers wounded in the field.

The "History" section of the November 2009 edition of "National Geographic" estimated the number of Purple Hearts given. Above the estimates, the text reads, "Any tally of Purple Hearts is an estimate. Awards are often given during conflict; records aren't always exact" (page 33). The estimates are as follows:


The Purple Heart is awarded in the name of the President of the United States to any member of the Armed Forces of the United States who, while serving under competent authority in any capacity with one of the U.S. Armed Services after April 5, 1917, has been wounded or killed. Specific examples of services which warrant the Purple Heart include any action against an enemy of the United States; any action with an opposing armed force of a foreign country in which the Armed Forces of the United States are or have been engaged; while serving with friendly foreign forces engaged in an armed conflict against an opposing armed force in which the United States is not a belligerent party; as a result of an act of any such enemy of opposing armed forces; or as the result of an act of any hostile foreign force. After March 28, 1973, it may be awarded as a result of an international terrorist attack against the United States or a foreign nation friendly to the United States, recognized as such an attack by the Secretary of the Army, or jointly by the Secretaries of the separate armed services concerned if persons from more than one service are wounded in the attack. After March 28, 1973, it may be awarded as a result of military operations while serving outside the territory of the United States as part of a peacekeeping force.

The Purple Heart differs from most other decorations in that an individual is not "recommended" for the decoration; rather he or she is entitled to it upon meeting specific criteria. A Purple Heart is awarded for the first wound suffered under conditions indicated above, but for each subsequent award an oak leaf cluster or 5/16 inch star is worn in lieu of another medal. Not more than one award will be made for more than one wound or injury received at the same instant.

A "wound" is defined as an injury to any part of the body from an outside force or agent sustained under one or more of the conditions listed above. A physical lesion is not required; however, the wound for which the award is made must have required treatment by a medical officer and records of medical treatment for wounds or injuries received in action must have been made a matter of official record. When contemplating an award of this decoration, the key issue that commanders must take into consideration is the degree to which the enemy caused the injury. The fact that the proposed recipient was participating in direct or indirect combat operations is a necessary prerequisite, but is not sole justification for award. The Purple Heart is not awarded for non-combat injuries.

Enemy-related injuries which "justify" the award of the Purple Heart include: injury caused by enemy bullet, shrapnel, or other projectile created by enemy action; injury caused by enemy placed land mine, naval mine, or trap; injury caused by enemy released chemical, biological, or nuclear agent; injury caused by vehicle or aircraft accident resulting from enemy fire; and, concussion injuries caused as a result of enemy generated explosions.

Injuries or wounds which "do not qualify" for award of the Purple Heart include frostbite or trench foot injuries; heat stroke; food poisoning not caused by enemy agents; chemical, biological, or nuclear agents not released by the enemy; battle fatigue; disease not directly caused by enemy agents; accidents, to include explosive, aircraft, vehicular, and other accidental wounding not related to or caused by enemy action; self-inflicted wounds (e.g., a soldier accidentally or intentionally fires their own gun and the bullet strikes his or her leg), except when in the heat of battle, and not involving gross negligence; post-traumatic stress disorders; and jump injuries not caused by enemy action.

It is not intended that such a strict interpretation of the requirement for the wound or injury to be caused by direct result of hostile action be taken that it would preclude the award being made to deserving personnel. Commanders must also take into consideration the circumstances surrounding an injury, even if it appears to meet the criteria. In the case of an individual injured while making a parachute landing from an aircraft that had been brought down by enemy fire; or, an individual injured as a result of a vehicle accident caused by enemy fire, the decision will be made in favor of the individual and the award will be made. As well, individuals wounded or killed as a result of "friendly fire" in the "heat of battle" will be awarded the Purple Heart as long as the "friendly" projectile or agent was released with the full intent of inflicting damage or destroying enemy troops or equipment. Individuals injured as a result of their own negligence, such as by driving or walking through an unauthorized area known to have been mined or placed off limits or searching for or picking up unexploded munitions as war souvenirs, will not be awarded the Purple Heart as they clearly were not injured as a result of enemy action, but rather by their own negligence.

From 1942 to 1997, civilians serving or closely affiliated with the armed forces—as government employees, Red Cross workers, war correspondents, and the like—were eligible to receive the Purple Heart. Among the earliest civilians to receive the award were nine firefighters of the Honolulu Fire Department killed or wounded while fighting fires at Hickam Field during the attack on Pearl Harbor. About 100 men and women received the award, the most famous being newspaperman Ernie Pyle who was awarded a Purple Heart posthumously by the Army after being killed by Japanese machine gun fire in the Pacific Theater, near the end of World War II. Before his death, Pyle had seen and experienced combat in the European Theater, while accompanying and writing about infantrymen for the folks back home.

The most recent Purple Hearts presented to civilians occurred after the terrorist attacks at Khobar Towers, Saudi Arabia, in 1996—for their injuries, about 40 U.S. civil service employees received the award.

However, in 1997, at the urging of the Military Order of the Purple Heart, Congress passed legislation prohibiting future awards of the Purple Heart to civilians. Today, the Purple Heart is reserved for men and women in uniform. Civilian employees of the U.S. Department of Defense who are killed or wounded as a result of hostile action may receive the new Defense of Freedom Medal. This award was created shortly after the terrorist attacks of September 11, 2001.

Animals are generally not eligible for the Purple Heart; however, there have been rare instances when animals holding military rank were honored with the award. An example includes the horse Sergeant Reckless during the Korean War.

The Purple Heart award is a heart-shaped medal within a gold border, 1 inches (35 mm) wide, containing a profile of General George Washington. Above the heart appears a shield of the coat of arms of George Washington (a white shield with two red bars and three red stars in chief) between sprays of green leaves. The reverse consists of a raised bronze heart with the words below the coat of arms and leaves.

The ribbon is 1 and inches (35 mm) wide and consists of the following stripes: inch (3 mm) white 67101; 1 inches (29 mm) purple 67115; and inch (3 mm) white 67101.

Additional awards of the Purple Heart are denoted by oak leaf clusters in the Army and Air Force, and additional awards of the Purple Heart Medal are denoted by 5/16 inch stars in the Navy, Marine Corps, and Coast Guard.

Current active duty personnel are awarded the Purple Heart upon recommendation from their chain of command, stating the injury that was received and the action in which the service member was wounded. The award authority for the Purple Heart is normally at the level of an Army Brigade, Marine Corps Division, Air Force Wing, or Navy Task Force. While the award of the Purple Heart is considered automatic for all wounds received in combat, each award presentation must still be reviewed to ensure that the wounds received were as a result of enemy action. Modern day Purple Heart presentations are recorded in both hardcopy and electronic service records. The annotation of the Purple Heart is denoted both with the service member's parent command and at the headquarters of the military service department. An original citation and award certificate are presented to the service member and filed in the field service record.

During the Vietnam War, Korean War, and World War II, the Purple Heart was often awarded on the spot, with occasional entries made into service records. In addition, during mass demobilizations following each of America's major wars of the 20th century, it was common occurrence to omit mention from service records of a Purple Heart award. This occurred due to clerical errors, and became problematic once a service record was closed upon discharge. In terms of keeping accurate records, it was commonplace for some field commanders to engage in bedside presentations of the Purple Heart. This typically entailed a general entering a hospital with a box of Purple Hearts, pinning them on the pillows of wounded service members, then departing with no official records kept of the visit, or the award of the Purple Heart. Service members, themselves, complicated matters by unofficially leaving hospitals, hastily returning to their units to rejoin battle so as to not appear a malingerer. In such cases, even if a service member had received actual wounds in combat, both the award of the Purple Heart, as well as the entire visit to the hospital, was unrecorded in official records.

Service members requesting retroactive awards of the Purple Heart must normally apply through the National Personnel Records Center. Following a review of service records, qualified Army members are awarded the Purple Heart by the U.S. Army Human Resources Command in Alexandria, Virginia. Air Force veterans are awarded the Purple Heart by the Awards Office of Randolph Air Force Base, while Navy, Marine Corps, and Coast Guard, present Purple Hearts to veterans through the Navy Liaison Officer at the National Personnel Records Center. Simple clerical errors, where a Purple Heart is denoted in military records, but was simply omitted from a (WD AGO Form 53-55 (predecessor to the) DD Form 214 (Report of Separation), are corrected on site at the National Personnel Records Center through issuance of a DD-215 document.

Because the Purple Heart did not exist prior to 1932, decoration records are not annotated in the service histories of veterans wounded, or killed, by enemy action, prior to establishment of the medal. The Purple Heart is, however, retroactive to 1917 meaning it may be presented to veterans as far back as First World War. Prior to 2006, service departments would review all available records, including older service records, and service histories, to determine if a veteran warranted a retroactive Purple Heart. As of 2008, such records are listed as "Archival", by the National Archives and Records Administration, meaning they have been transferred from the custody of the military, and can no longer be loaned and transferred for retroactive medals determination. In such cases, requestors asking for a Purple Heart (especially from records of the First World War) are provided with a complete copy of all available records (or reconstructed records in the case of the 1973 fire) and advised the Purple Heart may be privately purchased if the requestor feels it is warranted.

A clause to the archival procedures was revised in mid-2008, where if a veteran, or, if deceased, an immediate member of the family, requested the Purple Heart, on an Army or Air Force record, the medal could still be granted by the National Archives. In such cases, where a determination was required made by the military service department, photocopies of the archival record, (but not the record itself), would be forwarded to the headquarters of the military branch in question. This stipulation was granted only for the Air Force and Army; Marine Corps, Navy, and Coast Guard archival medals requests are still typically only offered a copy of the file and told to purchase the medal privately. For requests directly received from veterans, these are routed through a Navy Liaison Office, on site at 9700 Page Avenue, St. Louis, MO 63132-5100 (the location of the Military Personnel Records Center).

Due to the 1973 National Archives Fire, a large number of retroactive Purple Heart requests are difficult to verify because all records to substantiate the award may have been destroyed. As a solution to deal with Purple Heart requests, where service records were destroyed in the 1973 fire, the National Personnel Records Center maintains a separate office. In such cases, NPRC searches through unit records, military pay records, and records of the Department of Veterans Affairs. If a Purple Heart is warranted, all available alternate records sources are forwarded to the military service department for final determination of issuance.

The loaning of fire related records to the military has declined since 2006 because a large number of such records now fall into the "archival records" category of military service records. This means the records were transferred from the military to the National Archives, and in such cases, the Purple Heart may be privately purchased by the requestor (see above section of retroactive requests for further details) but is no longer provided by the military service department.

Ten Purple Hearts:

Nine Purple Hearts:

Eight Purple Hearts:



Notes
Bibliography



</doc>
<doc id="25073" url="https://en.wikipedia.org/wiki?curid=25073" title="Polyatomic ion">
Polyatomic ion

A polyatomic ion, also known as a molecular ion, is a charged chemical species (ion) composed of two or more atoms covalently bonded or of a metal complex that can be considered to be acting as a single unit. The prefix "poly-" means "many," in Greek, but even ions of two atoms are commonly referred to as polyatomic. In older literature, a polyatomic ion is also referred to as a radical, and less commonly, as a radical group. In contemporary usage, the term radical refers to free radicals that are (not necessarily charged) species with an unpaired electron. 

An example of a polyatomic ion is the hydroxide ion; consisting of one oxygen atom and one hydrogen atom, hydroxide has a charge of −1. Its chemical formula is . An ammonium ion is made up of one nitrogen atom and four hydrogen atoms: it has a charge of +1, and its chemical formula is .

Polyatomic ions are often useful in the context of acid-base chemistry or in the formation of salts. A polyatomic ion can often be considered as the conjugate acid/base of a neutral molecule. For example, the conjugate base of sulfuric acid (HSO) is the polyatomic hydrogen sulfate anion (). The removal of another hydrogen ion yields the sulfate anion ().

There are two "rules" that can be used for learning the nomenclature of polyatomic anions. First, when the prefix "bi" is added to a name, a hydrogen is added to the ion's formula and its charge is increased by 1, the latter being a consequence of the hydrogen ion's +1 charge. An alternative to the "bi-" prefix is to use the word hydrogen in its place: the anion derived from + , , can be called either bicarbonate or hydrogen carbonate.

Note that many of the common polyatomic anions are conjugate bases of acids derived from the oxides of non-metallic elements. For example, the sulfate anion, , is derived from , which can be regarded as + .

The second rule looks at the number of oxygens in an ion. Consider the chlorine oxoanion family:
First, think of the "-ate" ion as being the "base" name, in which case the addition of a "per-" prefix adds an oxygen. Changing the "-ate" suffix to "-ite" will reduce the oxygens by one, and keeping the suffix "-ite" and adding the prefix "hypo-" reduces the number of oxygens by one more. In all situations, the charge is not affected. The naming pattern follows within many different oxyanion series based on a standard root for that particular series. The "-ite" has one less oxygen than the "-ate", but different "-ate" anions might have different numbers of oxygen atoms.

These rules will not work with all polyatomic anions, but they do work with the most common ones (sulfate, phosphate, nitrate, chlorate).

The following tables give examples of commonly encountered polyatomic ions. Only a few representatives are given, as the number of polyatomic ions encountered in practice is very large.




</doc>
