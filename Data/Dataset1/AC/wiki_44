<doc id="30001" url="https://en.wikipedia.org/wiki?curid=30001" title="Theory of relativity">
Theory of relativity

The theory of relativity usually encompasses two interrelated theories by Albert Einstein: special relativity and general relativity. Special relativity applies to elementary particles and their interactions, describing all their physical phenomena except gravity. General relativity explains the law of gravitation and its relation to other forces of nature. It applies to the cosmological and astrophysical realm, including astronomy.

The theory transformed theoretical physics and astronomy during the 20th century, superseding a 200-year-old theory of mechanics created primarily by Isaac Newton. It introduced concepts including spacetime as a unified entity of space and time, relativity of simultaneity, kinematic and gravitational time dilation, and length contraction. In the field of physics, relativity improved the science of elementary particles and their fundamental interactions, along with ushering in the nuclear age. With relativity, cosmology and astrophysics predicted extraordinary astronomical phenomena such as neutron stars, black holes, and gravitational waves.

Albert Einstein published the theory of special relativity in 1905, building on many theoretical results and empirical findings obtained by Albert A. Michelson, Hendrik Lorentz, Henri Poincaré and others. Max Planck, Hermann Minkowski and others did subsequent work.

Einstein developed general relativity between 1907 and 1915, with contributions by many others after 1915. The final form of general relativity was published in 1916.

The term "theory of relativity" was based on the expression "relative theory" () used in 1906 by Planck, who emphasized how the theory uses the principle of relativity. In the discussion section of the same paper, Alfred Bucherer used for the first time the expression "theory of relativity" ().

By the 1920s, the physics community understood and accepted special relativity. It rapidly became a significant and necessary tool for theorists and experimentalists in the new fields of atomic physics, nuclear physics, and quantum mechanics.

By comparison, general relativity did not appear to be as useful, beyond making minor corrections to predictions of Newtonian gravitation theory. It seemed to offer little potential for experimental test, as most of its assertions were on an astronomical scale. Its mathematics seemed difficult and fully understandable only by a small number of people. Around 1960, general relativity became central to physics and astronomy. New mathematical techniques to apply to general relativity streamlined calculations and made its concepts more easily visualized. As astronomical phenomena were discovered, such as quasars (1963), the 3-kelvin microwave background radiation (1965), pulsars (1967), and the first black hole candidates (1981), the theory explained their attributes, and measurement of them further confirmed the theory.

Special relativity is a theory of the structure of spacetime. It was introduced in Einstein's 1905 paper "On the Electrodynamics of Moving Bodies" (for the contributions of many other physicists see History of special relativity). Special relativity is based on two postulates which are contradictory in classical mechanics:

The resultant theory copes with experiment better than classical mechanics. For instance, postulate 2 explains the results of the Michelson–Morley experiment. Moreover, the theory has many surprising and counterintuitive consequences. Some of these are:

The defining feature of special relativity is the replacement of the Galilean transformations of classical mechanics by the Lorentz transformations. (See Maxwell's equations of electromagnetism).

General relativity is a theory of gravitation developed by Einstein in the years 1907–1915. The development of general relativity began with the equivalence principle, under which the states of accelerated motion and being at rest in a gravitational field (for example, when standing on the surface of the Earth) are physically identical. The upshot of this is that free fall is inertial motion: an object in free fall is falling because that is how objects move when there is no force being exerted on them, instead of this being due to the force of gravity as is the case in classical mechanics. This is incompatible with classical mechanics and special relativity because in those theories inertially moving objects cannot accelerate with respect to each other, but objects in free fall do so. To resolve this difficulty Einstein first proposed that spacetime is curved. In 1915, he devised the Einstein field equations which relate the curvature of spacetime with the mass, energy, and any momentum within it.

Some of the consequences of general relativity are:

Technically, general relativity is a theory of gravitation whose defining feature is its use of the Einstein field equations. The solutions of the field equations are metric tensors which define the topology of the spacetime and how objects move inertially.

Einstein stated that the theory of relativity belongs to a class of "principle-theories". As such, it employs an analytic method, which means that the elements of this theory are not based on hypothesis but on empirical discovery. By observing natural processes, we understand their general characteristics, devise mathematical models to describe what we observed, and by analytical means we deduce the necessary conditions that have to be satisfied. Measurement of separate events must satisfy these conditions and match the theory's conclusions.

Relativity is a falsifiable theory: It makes predictions that can be tested by experiment. In the case of special relativity, these include the principle of relativity, the constancy of the speed of light, and time dilation. The predictions of special relativity have been confirmed in numerous tests since Einstein published his paper in 1905, but three experiments conducted between 1881 and 1938 were critical to its validation. These are the Michelson–Morley experiment, the Kennedy–Thorndike experiment, and the Ives–Stilwell experiment. Einstein derived the Lorentz transformations from first principles in 1905, but these three experiments allow the transformations to be induced from experimental evidence.

Maxwell's equations—the foundation of classical electromagnetism—describe light as a wave that moves with a characteristic velocity. The modern view is that light needs no medium of transmission, but Maxwell and his contemporaries were convinced that light waves were propagated in a medium, analogous to sound propagating in air, and ripples propagating on the surface of a pond. This hypothetical medium was called the luminiferous aether, at rest relative to the "fixed stars" and through which the Earth moves. Fresnel's partial ether dragging hypothesis ruled out the measurement of first-order (v/c) effects, and although observations of second-order effects (v/c) were possible in principle, Maxwell thought they were too small to be detected with then-current technology.

The Michelson–Morley experiment was designed to detect second-order effects of the "aether wind"—the motion of the aether relative to the earth. Michelson designed an instrument called the Michelson interferometer to accomplish this. The apparatus was more than accurate enough to detect the expected effects, but he obtained a null result when the first experiment was conducted in 1881, and again in 1887. Although the failure to detect an aether wind was a disappointment, the results were accepted by the scientific community. In an attempt to salvage the aether paradigm, FitzGerald and Lorentz independently created an "ad hoc" hypothesis in which the length of material bodies changes according to their motion through the aether. This was the origin of FitzGerald–Lorentz contraction, and their hypothesis had no theoretical basis. The interpretation of the null result of the Michelson–Morley experiment is that the round-trip travel time for light is isotropic (independent of direction), but the result alone is not enough to discount the theory of the aether or validate the predictions of special relativity.
While the Michelson–Morley experiment showed that the velocity of light is isotropic, it said nothing about how the magnitude of the velocity changed (if at all) in different inertial frames. The Kennedy–Thorndike experiment was designed to do that, and was first performed in 1932 by Roy Kennedy and Edward Thorndike. They obtained a null result, and concluded that "there is no effect ... unless the velocity of the solar system in space is no more than about half that of the earth in its orbit". That possibility was thought to be too coincidental to provide an acceptable explanation, so from the null result of their experiment it was concluded that the round-trip time for light is the same in all inertial reference frames.

The Ives–Stilwell experiment was carried out by Herbert Ives and G.R. Stilwell first in 1938 and with better accuracy in 1941. It was designed to test the transverse Doppler effect – the redshift of light from a moving source in a direction perpendicular to its velocity—which had been predicted by Einstein in 1905. The strategy was to compare observed Doppler shifts with what was predicted by classical theory, and look for a Lorentz factor correction. Such a correction was observed, from which was concluded that the frequency of a moving atomic clock is altered according to special relativity.

Those classic experiments have been repeated many times with increased precision. Other experiments include, for instance, relativistic energy and momentum increase at high velocities, experimental testing of time dilation, and modern searches for Lorentz violations.

General relativity has also been confirmed many times, the classic experiments being the perihelion precession of Mercury's orbit, the deflection of light by the Sun, and the gravitational redshift of light. Other tests confirmed the equivalence principle and frame dragging.

Far from being simply of theoretical interest, relativitistic effects are important practical engineering concerns. Satellite-based measurement needs to take into account relativistic effects, as each satellite is in motion relative to an Earth-bound user and is thus in a different frame of reference under the theory of relativity. Global positioning systems such as GPS, GLONASS, and the forthcoming Galileo, must account for all of the relativistic effects, such as the consequences of Earth's gravitational field, in order to work with precision. This is also the case in the high-precision measurement of time. Instruments ranging from electron microscopes to particle accelerators would not work if relativistic considerations were omitted.





</doc>
<doc id="30003" url="https://en.wikipedia.org/wiki?curid=30003" title="Telephone">
Telephone

A telephone, or phone, is a telecommunications device that permits two or more users to conduct a conversation when they are too far apart to be heard directly. A telephone converts sound, typically and most efficiently the human voice, into electronic signals that are transmitted via cables and other communication channels to another telephone which reproduces the sound to the receiving user.

In 1876, Scottish emigrant Alexander Graham Bell was the first to be granted a United States patent for a device that produced clearly intelligible replication of the human voice. This instrument was further developed by many others. The telephone was the first device in history that enabled people to talk directly with each other across large distances. Telephones rapidly became indispensable to businesses, government and households and are today some of the most widely used small appliances.

The essential elements of a telephone are a microphone ("transmitter") to speak into and an earphone ("receiver") which reproduces the voice in a distant location. In addition, most telephones contain a "ringer", which produces a sound to announce an incoming telephone call, and a dial or keypad used to enter a telephone number when initiating a call to another telephone. Until approximately the 1970s, most telephones used a rotary dial, which was superseded by the modern dual-tone multi-frequency (DTMF) push-button dial, first introduced to the public by AT&T in 1963. The receiver and transmitter are usually built into a handset which is held up to the ear and mouth during conversation. The dial may be located either on the handset or on a base unit to which the handset is connected. The transmitter converts the sound waves to electrical signals which are sent through a telephone network to the receiving telephone, which converts the signals into audible sound in the receiver or sometimes a loudspeaker. Telephones are duplex devices, meaning they permit transmission in both directions simultaneously.

The first telephones were directly connected to each other from one customer's office or residence to another customer's location. Being impractical beyond just a few customers, these systems were quickly replaced by manually operated centrally located switchboards. This gave rise to landline telephone service in which each telephone is connected by a pair of dedicated wires to a local central office switching system, which developed into fully automated systems starting in the early 1900s. For greater mobility, various radio systems were developed for transmission between mobile stations on ships and automobiles in the mid-20th century. Hand-held mobile phones were introduced for personal service starting in 1973. By the late 1970s, several mobile telephone networks operated around the world. In 1983, the Advanced Mobile Phone System (AMPS) was launched, offering a standardized technology providing portability for users far beyond the personal residence or office. These analog cellular system evolved into digital networks with better security, greater capacity, better regional coverage and lower cost. Today, the worldwide public switched telephone network, with its hierarchical system of many switching centers, can connect any telephone on the network with any other. With the standardized international numbering system, E.164, each telephone line has an identifying telephone number, that may be called from any other, authorized telephone on the network. 

Although originally designed for simple voice communications, convergence has enabled most modern cell phones to have many additional capabilities. They may be able to record spoken messages, send and receive text messages, take and display photographs or video, play music or games, surf the Internet, do road navigation or immerse the user in virtual reality. Since 1999, the trend for mobile phones is smartphones that integrate all mobile communication and computing needs.

A traditional landline telephone system, also known as "plain old telephone service" (POTS), commonly carries both control and audio signals on the same twisted pair ("C" in diagram) of insulated wires, the telephone line. The control and signaling equipment consists of three components, the ringer, the hookswitch, and a dial. The ringer, or beeper, light or other device (A7), alerts the user to incoming calls. The hookswitch signals to the central office that the user has picked up the handset to either answer a call or initiate a call. A dial, if present, is used by the subscriber to transmit a telephone number to the central office when initiating a call. Until the 1960s dials used almost exclusively the rotary technology, which was replaced by dual-tone multi-frequency signaling (DTMF) with pushbutton telephones (A4).

A major expense of wire-line telephone service is the outside wire plant. Telephones transmit both the incoming and outgoing speech signals on a single pair of wires. A twisted pair line rejects electromagnetic interference (EMI) and crosstalk better than a single wire or an untwisted pair. The strong outgoing speech signal from the microphone (transmitter) does not overpower the weaker incoming speaker (receiver) signal with sidetone because a hybrid coil (A3) and other components compensate the imbalance. The junction box (B) arrests lightning (B2) and adjusts the line's resistance (B1) to maximize the signal power for the line length. Telephones have similar adjustments for inside line lengths (A8). The line voltages are negative compared to earth, to reduce galvanic corrosion. Negative voltage attracts positive metal ions toward the wires.

The landline telephone contains a switchhook (A4) and an alerting device, usually a ringer (A7), that remains connected to the phone line whenever the phone is "on hook" (i.e. the switch (A4) is open), and other components which are connected when the phone is "off hook". The off-hook components include a transmitter (microphone, A2), a receiver (speaker, A1), and other circuits for dialing, filtering (A3), and amplification.

A calling party wishing to speak to another party will pick up the telephone's handset, thereby operating a lever which closes the switchhook (A4), which powers the telephone by connecting the transmitter (microphone), receiver (speaker), and related audio components to the line. The off-hook circuitry has a low resistance (less than 300 ohms) which causes a direct current (DC), which comes down the line (C) from the telephone exchange. The exchange detects this current, attaches a digit receiver circuit to the line, and sends a dial tone to indicate readiness. On a modern push-button telephone, the caller then presses the number keys to send the telephone number of the called party. The keys control a tone generator circuit (not shown) that makes DTMF tones that the exchange receives. A rotary-dial telephone uses pulse dialing, sending electrical pulses, that the exchange can count to get the telephone number (as of 2010 many exchanges were still equipped to handle pulse dialing). If the called party's line is available, the exchange sends an intermittent ringing signal (about 75 volts alternating current (AC) in North America and UK and 60 volts in Germany) to alert the called party to an incoming call. If the called party's line is in use, the exchange returns a busy signal to the calling party. However, if the called party's line is in use but has call waiting installed, the exchange sends an intermittent audible tone to the called party to indicate an incoming call.

The ringer of a telephone (A7) is connected to the line through a capacitor (A6), which blocks direct current but passes the alternating current of the ringing signal. The telephone draws no current when it is on hook, while a DC voltage is continually applied to the line. Exchange circuitry (D2) can send an AC current down the line to activate the ringer and announce an incoming call. When there is no automatic exchange, telephones have hand-cranked magnetos to generate a ringing voltage back to the exchange or any other telephone on the same line. When a landline telephone is inactive (on hook), the circuitry at the telephone exchange detects the absence of direct current to indicate that the line is not in use. When a party initiates a call to this line, the exchange sends the ringing signal. When the called party picks up the handset, they actuate a double-circuit switchhook (not shown) which may simultaneously disconnects the alerting device and connects the audio circuitry to the line. This, in turn, draws direct current through the line, confirming that the called phone is now active. The exchange circuitry turns off the ring signal, and both telephones are now active and connected through the exchange. The parties may now converse as long as both phones remain off hook. When a party hangs up, placing the handset back on the cradle or hook, direct current ceases in that line, signaling the exchange to disconnect the call.

Calls to parties beyond the local exchange are carried over trunk lines which establish connections between exchanges. In modern telephone networks, fiber-optic cable and digital technology are often employed in such connections. Satellite technology may be used for communication over very long distances.

In most landline telephones, the transmitter and receiver (microphone and speaker) are located in the handset, although in a speakerphone these components may be located in the base or in a separate enclosure. Powered by the line, the microphone (A2) produces a modulated electric current which varies its frequency and amplitude in response to the sound waves arriving at its diaphragm. The resulting current is transmitted along the telephone line to the local exchange then on to the other phone (via the local exchange or via a larger network), where it passes through the coil of the receiver (A3). The varying current in the coil produces a corresponding movement of the receiver's diaphragm, reproducing the original sound waves present at the transmitter.

Along with the microphone and speaker, additional circuitry is incorporated to prevent the incoming speaker signal and the outgoing microphone signal from interfering with each other. This is accomplished through a hybrid coil (A3). The incoming audio signal passes through a resistor (A8) and the primary winding of the coil (A3) which passes it to the speaker (A1). Since the current path A8 – A3 has a far lower impedance than the microphone (A2), virtually all of the incoming signal passes through it and bypasses the microphone.

At the same time the DC voltage across the line causes a DC current which is split between the resistor-coil (A8-A3) branch and the microphone-coil (A2-A3) branch. The DC current through the resistor-coil branch has no effect on the incoming audio signal. But the DC current passing through the microphone is turned into AC current (in response to voice sounds) which then passes through only the upper branch of the coil's (A3) primary winding, which has far fewer turns than the lower primary winding. This causes a small portion of the microphone output to be fed back to the speaker, while the rest of the AC current goes out through the phone line.

A lineman's handset is a telephone designed for testing the telephone network, and may be attached directly to aerial lines and other infrastructure components.

Before the development of the electric telephone, the term "telephone" was applied to other inventions, and not all early researchers of the electrical device called it "telephone". A communication device for sailing vessels "The Telephone" was the invention of a captain John Taylor in 1844. This instrument used four air horns to communicate with vessels in foggy weather. Later, c. 1860, Johann Philipp Reis used the term in reference to his Reis telephone, his device appears to be the first such device based on conversion of sound into electrical impulses, the term telephone was adopted into the vocabulary of many languages. It is derived from the , "tēle", "far" and φωνή, "phōnē", "voice", together meaning "distant voice".

Credit for the invention of the electric telephone is frequently disputed. As with other influential inventions such as radio, television, the light bulb, and the computer, several inventors pioneered experimental work on "voice transmission over a wire" and improved on each other's ideas. New controversies over the issue still arise from time to time. Charles Bourseul, Antonio Meucci, Johann Philipp Reis, Alexander Graham Bell, and Elisha Gray, amongst others, have all been credited with the invention of the telephone.

Alexander Graham Bell was the first to be awarded a patent for the electric telephone by the United States Patent and Trademark Office (USPTO) in March 1876. The Bell patents were forensically victorious and commercially decisive. That first patent by Bell was the "master patent" of the telephone, from which other patents for electric telephone devices and features flowed.

In 1876, shortly after the telephone was invented, Hungarian engineer Tivadar Puskás invented the telephone switch, which allowed for the formation of telephone exchanges, and eventually networks.


Early telephones were technically diverse. Some used a water microphone, some had a metal diaphragm that induced current in an electromagnet wound around a permanent magnet, and some were dynamic - their diaphragm vibrated a coil of wire in the field of a permanent magnet or the coil vibrated the diaphragm. The sound-powered dynamic variants survived in small numbers through the 20th century in military and maritime applications, where its ability to create its own electrical power was crucial. Most, however, used the Edison/Berliner carbon transmitter, which was much louder than the other kinds, even though it required an induction coil which was an impedance matching transformer to make it compatible with the impedance of the line. The Edison patents kept the Bell monopoly viable into the 20th century, by which time the network was more important than the instrument.

Early telephones were locally powered, using either a dynamic transmitter or by the powering of a transmitter with a local battery. One of the jobs of outside plant personnel was to visit each telephone periodically to inspect the battery. During the 20th century, telephones powered from the telephone exchange over the same wires that carried the voice signals became common.

Early telephones used a single wire for the subscriber's line, with ground return used to complete the circuit (as used in telegraphs). The earliest dynamic telephones also had only one port opening for sound, with the user alternately listening and speaking (or rather, shouting) into the same hole. Sometimes the instruments were operated in pairs at each end, making conversation more convenient but also more expensive.

At first, the benefits of a telephone exchange were not exploited. Instead telephones were leased in pairs to a subscriber, who had to arrange for a telegraph contractor to construct a line between them, for example between a home and a shop. Users who wanted the ability to speak to several different locations would need to obtain and set up three or four pairs of telephones. Western Union, already using telegraph exchanges, quickly extended the principle to its telephones in New York City and San Francisco, and Bell was not slow in appreciating the potential.

Signalling began in an appropriately primitive manner. The user alerted the other end, or the exchange operator, by whistling into the transmitter. Exchange operation soon resulted in telephones being equipped with a bell in a ringer box, first operated over a second wire, and later over the same wire, but with a condenser (capacitor) in series with the bell coil to allow the AC ringer signal through while still blocking DC (keeping the phone "on hook"). Telephones connected to the earliest Strowger switch automatic exchanges had seven wires, one for the knife switch, one for each telegraph key, one for the bell, one for the push-button and two for speaking. Large wall telephones in the early 20th century usually incorporated the bell, and separate bell boxes for desk phones dwindled away in the middle of the century.

Rural and other telephones that were not on a common battery exchange had a magneto hand-cranked generator to produce a high voltage alternating signal to ring the bells of other telephones on the line and to alert the operator. Some local farming communities that were not connected to the main networks set up barbed wire telephone lines that exploited the existing system of field fences to transmit the signal.
In the 1890s a new smaller style of telephone was introduced, packaged in three parts. The transmitter stood on a stand, known as a "candlestick" for its shape. When not in use, the receiver hung on a hook with a switch in it, known as a "switchhook". Previous telephones required the user to operate a separate switch to connect either the voice or the bell. With the new kind, the user was less likely to leave the phone "off the hook". In phones connected to magneto exchanges, the bell, induction coil, battery and magneto were in a separate bell box or "ringer box". In phones connected to common battery exchanges, the ringer box was installed under a desk, or other out of the way place, since it did not need a battery or magneto.

Cradle designs were also used at this time, having a handle with the receiver and transmitter attached, now called a handset, separate from the cradle base that housed the magneto crank and other parts. They were larger than the "candlestick" and more popular.

Disadvantages of single wire operation such as crosstalk and hum from nearby AC power wires had already led to the use of twisted pairs and, for long distance telephones, four-wire circuits. Users at the beginning of the 20th century did not place long distance calls from their own telephones but made an appointment to use a special soundproofed long distance telephone booth furnished with the latest technology.

What turned out to be the most popular and longest lasting physical style of telephone was introduced in the early 20th century, including Bell's 202-type desk set. A carbon granule transmitter and electromagnetic receiver were united in a single molded plastic handle, which when not in use sat in a cradle in the base unit. The circuit diagram of the model 202 shows the direct connection of the transmitter to the line, while the receiver was induction coupled. In local battery configurations, when the local loop was too long to provide sufficient current from the exchange, the transmitter was powered by a local battery and inductively coupled, while the receiver was included in the local loop. The coupling transformer and the ringer were mounted in a separate enclosure, called the subscriber set. The dial switch in the base interrupted the line current by repeatedly but very briefly disconnecting the line 1 to 10 times for each digit, and the hook switch (in the center of the circuit diagram) disconnected the line and the transmitter battery while the handset was on the cradle.

In the 1930s, telephone sets were developed that combined the bell and induction coil with the desk set, obviating a separate ringer box. The rotary dial becoming commonplace in the 1930s in many areas enabled customer-dialed service, but some magneto systems remained even into the 1960s. After World War II, the telephone networks saw rapid expansion and more efficient telephone sets, such as the model 500 telephone in the United States, were developed that permitted larger local networks centered around central offices. A breakthrough new technology was the introduction of Touch-Tone signaling using push-button telephones by American Telephone & Telegraph Company (AT&T) in 1963.

The invention of the transistor in 1947 dramatically changed the technology used in telephone systems and in the long-distance transmission networks. With the development of electronic switching systems in the 1960s, telephony gradually evolved towards digital telephony which improved the capacity, quality, and cost of the network.

The development of digital data communications method, such as the protocols used for the Internet, it became possible to digitize voice and transmit it as real-time data across computer networks, giving rise to the field of Internet Protocol (IP) telephony, also known as voice over Internet Protocol (VoIP), a term that reflects the methodology memorably. VoIP has proven to be a disruptive technology that is rapidly replacing traditional telephone network infrastructure.

As of January 2005, up to 10% of telephone subscribers in Japan and South Korea have switched to this digital telephone service. A January 2005 Newsweek article suggested that Internet telephony may be "the next big thing." As of 2006 many VoIP companies offer service to consumers and businesses.

From a customer perspective, IP telephony uses a high-bandwidth Internet connection and specialized customer premises equipment to transmit telephone calls via the Internet, or any modern private data network. The customer equipment may be an analog telephone adapter (ATA) which interfaces a conventional analog telephone to the IP networking equipment, or it may be an IP Phone that has the networking and interface technology built into the desk-top set and provides the traditional, familiar parts of a telephone, the handset, the dial or keypad, and a ringer in a package that usually resembles a standard telephone set.

In addition, many computer software vendors and telephony operators provide softphone application software that emulates a telephone by use of an attached microphone and audio headset, or loud speaker.

Despite the new features and conveniences of IP telephones, some may have notable disadvantages compared to traditional telephones. Unless the IP telephone's components are backed up with an uninterruptible power supply or other emergency power source, the phone ceases to function during a power outage as can occur during an emergency or disaster when the phone is most needed. Traditional phones connected to the older PSTN network do not experience that problem since they are powered by the telephone company's battery supply, which will continue to function even if there is a prolonged power outage. Another problem in Internet-based services is the lack of a fixed physical location, impacting the provisioning of emergency services such as police, fire or ambulance, should someone call for them. Unless the registered user updates the IP phone's physical address location after moving to a new residence, emergency services can be, and have been, dispatched to the wrong location.

Graphic symbols used to designate telephone service or phone-related information in print, signage, and other media include ℡ (U+2121), ☎ (U+260E), ☏ (U+260F), ✆ (U+2706) and ⌕ (U+2315).

In 2002, only 10% of the world’s population used cell phones and by 2005 that percentage had risen to 46%. By the end of 2009, there were a total of nearly 6 billion mobile and fixed-line telephone subscribers worldwide. This included 1.26 billion fixed-line subscribers and 4.6 billion mobile subscribers.





</doc>
<doc id="30004" url="https://en.wikipedia.org/wiki?curid=30004" title="Telia Company">
Telia Company

Telia Company AB (formerly TeliaSonera) is a Swedish dominant telephone company and mobile network operator present in Sweden, Finland, Norway, Denmark and Baltic States. The company has operations in other countries in Northern and Eastern Europe, and in Central Asia and South Asia, with a total of 182.1 million mobile customers (Q1, 2013). It is headquartered in Stockholm and its stock is traded on the Stockholm Stock Exchange and on the Helsinki Stock Exchange.

Telia Company in its current form was first established as TeliaSonera, as the result of a 2002 merger between the Swedish and Finnish telecommunications companies, Telia and Sonera. This merger followed shortly after Telia's failed merger attempt with Norwegian telecommunications company Telenor, now its chief competitor in the Nordic countries.

Before privatisation, Telia was a state telephone monopoly. Sonera on the other hand had a monopoly only on trunk network calls, while most (c. 75%) of local telecommunication was provided by telephone cooperatives. The separate brand names Telia and Sonera have continued to be used in the Swedish and Finnish markets respectively. Of the stock, 37.3% is owned by the Swedish government, and the rest by institutions, companies, and private investors worldwide. The Finnish government (through Solidium) had 3.2% of shares, but disposed them in February 2018.

The Swedish Kungl. Telegrafverket (literally: "Royal Telegraph Agency") was founded in 1853, when the first electric telegraph line was established between Stockholm and Uppsala. Allmänna Telefon found an equipment supplier in Lars Magnus Ericsson. In this early competition, Telegrafverket with its brand Rikstelefon was a latecomer. However, by securing a national monopoly on long distance telephone lines, it was able with time to control and take over the local networks of quickly growing private telephone companies.

A de facto telephone monopoly position was reached around 1920, and never needed legal sanction. In 1953 the name was modernised to Televerket. On 1 July 1992 this huge government agency's regulating functions was split off into the Swedish Post and Telecom Authority (, PTS), with similar functions as the Federal Communications Commission of the United States. The operation of the state radio and TV broadcast network was spun off into a company named Teracom. On 1 July 1993 the remaining telephone and mobile network operator was transformed into a government-owned shareholding company, named Telia AB. At the height of the dot-com bubble, on 13 June 2000, close to one-third of Telia's shares were introduced on the Stockholm Stock Exchange.

In the 1980s, Televerket was a pioneering mobile network operator with the NMT system, followed in the 1990s by GSM. Private competition in analogue mobile phone systems had already broken the telephone monopoly, and the growing internet allowed more opportunities for competitors. The most important of Telia's Swedish competitors in these areas has been Tele2. When PTS awarded four licenses for the 3rd generation mobile networks in December 2000, Telia was not among the winners, but later established an agreement to build a 3G network jointly with Tele2 using Tele2's licence. SUNAB was founded as the jointly owned company that would in turn build, own and operate the joint 3G network.

The history of Sonera dates back to 1917, when Suomen Lennätinlaitos (Finnish Telegraph Agency) was founded. In 1927, the telegraph agency was merged with the Finnish Post to form a new agency, Post and Telegraph Agency. This agency governed all long distance and international calls until 1994, when competitors were allowed to enter the Finnish market. In the same year, the Post and Telegraph Agency was divided to form two companies, Suomen Posti Oy (Finnish Post), and Telecom Finland Oy. Telecom Finland then changed its name to Sonera in 1998.

During the run up to the 2006 general election the Swedish liberal-conservative Alliance stated as one of its policy aims to reduce government ownership in commercial entities, and specifically to sell its stake in TeliaSonera. The Alliance went on to win the election and formed a coalition government. The sale of TeliaSonera was however presented to the parliament only after the next election in 2010, when the Alliance lost its majority but stayed on as a minority administration.

On 16 March 2011 the Alliance administration lost a parliamentary vote on sale of publicly owned commercial entities, including TeliaSonera, when a coalition of all opposition parties - the Left Party, Social Democratic Party, Green Party and Sweden Democrats - united against the Alliance.

In the beginning of 2008, TeliaSonera announced measures to save nearly 500 million Euros which would include 2900 redundancies: 2000 from Sweden and 900 from Finland. France Télécom (now Orange S.A.) proposed a 33 billion Euro acquisition offer for TeliaSonera on 5 June 2008, which was promptly rejected by the company's board.

In July 2018, Telia Company purchased Bonnier Broadcasting Group from Bonnier Group for 9,2 billion SEK ($1 billion), thus owning TV4 Gruppen (commercial television broadcaster in Sweden), MTV Oy (commercial television broadcaster in Finland) and C More Entertainment (pan-Nordic operator of premium television channels).

TeliaSonera International Carrier (AS1299) is a tier 1 carrier.

Telia Company is now the largest Nordic and Baltic fixed-voice, broadband, and mobile operator by revenue and customer base. It operates Europe's largest and fastest-growing wholesale IP backbone (AS1299) and is the 10th-largest global mobile group by consolidated customers (including ownership stakes in Turkcell, Yoigo, Megafon, NetCom, and others).
Telia Company is a 12.25% stakeholder of the Afghanistan Roshan (telco) cellphone network.

In Denmark Telia Company operates a mobile operator (Telia), a mobile virtual network operator (Call Me), and a broadband supplier (Telia). The company started in 1995, the result of a merger between Telia Stofa and TeliaSonera. Telia Mobile is the third-largest operator and is in fierce competition with Telenor, which is number two in the market. Telia was the fourth operator to launch 3G services and is the only operator to have a nationwide EDGE network.

Telia Broadband was relaunched in 2008 because of the need for TeliaSonera to offer both mobile and broadband in all of their home markets (Sweden, Norway, Denmark and Finland). Telia Broadband was the first operator to launch digital TV with their broadband at no extra cost. Stofa is mainly a cable TV operator, but also supplies broadband via the cable TV network.

Telia Company owns 100% of Eesti Telekom. Eesti Telekom is one of the largest telecommunication companies in the Baltic countries and the largest telecommunications company in Estonia. TeliaSonera and the Estonian government reached a deal over the sale of Eesti Telekom in September 2009. On 20 January 2016, Eesti Telekom switched its name to Telia Eesti.

Telia is the second largest mobile operator in Finland and also one of the biggest providers of landline telephone and internet services. 
Before the rebranding on 23 March 2017, Telia was known in Finland under the brands of Sonera and Tele Finland.

Telia Company operates in Kazakhstan under the brand Kcell.

TeliaSonera owns 49% of LMT (24.5% as TeliaSonera AB and 24.5% as Sonera Holding B.V.). TeliaSonera also owns 49% of Lattelecom, which owns 23% of LMT, which owns "Okarte", "Amigo". It also owns 100% of Telia Latvija, a business cable operator and data centre operator.

TeliaSonera owns 88.15% of Teo LT, the largest landline phone operator in Lithuania, which recently purchased Omnitel, one of largest mobile network operators there. It was previously owned by TeliaSonera group.

In October 2015, TeliaSonera announced the merger of Teo and Omnitel, through the acquisition of Omnitel by Teo.

In February 1, 2017, Omnitel and Teo merged under the name of "Telia Lietuva".

TeliaSonera owns a 74.3% see-through stake of the Moldovan mobile operator Moldcell through Fintur Holdings.

In Norway Telia first entered after the de-regulation in 1998 as a virtual supplier of fixed telephone and Internet services. This was sold to Enitel during the merger attempt with Telenor, but Telia re-entered in 2000 with the purchase of one of the two mobile network operators, NetCom. In 2006 it also bought the virtual mobile provider Chess Communication.

1 March 2016, NetCom was rebranded as Telia Norge.

In Sweden, TeliaSonera operates under the consumer brands Telia and Halebop. On the business side, Skanova Access and Cygate are also used. Main competitors include Tele2, Telenor, 3, ComHem, Boxer and C+.

TeliaSonera owns 38% of Turkcell, the leading mobile operator in Turkey. Turkcell owns 80% of in Belarus and 100% of in Ukraine.

In five years, Ucell, the Uzbek subsidiary, increased the number of its subscribers from 400,000 to 9 million (2012). TeliaSonera is under preliminary investigation by Swedish prosecutors for allegations of bribery and money laundering associated with the acquisition of their 3G license in Uzbekistan from Takilant Limited, registered in Gibraltar. Under these investigations involving four Uzbek nationals, hundreds of millions of francs have been frozen in Swiss banks.

Telia has recently been selling off their shares in companies they own that isn't in their main region of business.

On 15 May 2010 after Azercell went through rebranding, it joined the network of TeliaSonera. On 5 March 2018 Telia confirmed they have sold their stake in Azercell.

TeliaSonera purchased a majority stake in Star-Cell in 2008 which was the number four player in the market at that time. By 2010 it exited Cambodia after a $100 million write down and collapse in subscriber numbers. It was subsequently taken over by a more dominant competitor Smart Mobile.

In 2007-2018, Telia Company has owned 58.55% of the Geocell company, while Turkcell owns the remaining 41.45%. Since 2018 Silknet bought full part of Geocell.

TeliaSonera owned a majority stake in Ncell, the largest mobile operator in Nepal with USD 16.2 billion operating income. On 21 December 2015, TeliaSonera announced its exit from Ncell, selling its 60.4 percent of the shares to Malaysian telecommunications group Axiata. TeliaSonera exited Nepal without settling billions of Capital Gains Tax owed to Nepalese government.

Telia Company owned 25.2% of MegaFon, the second largest mobile phone operator in Russia. In October 2017 Telia Company agreed to sell their entire MegaFon stake for 1 billion USD.

Telia Company owned a 76.6% holding in the Spanish operator Yoigo until 21 June 2016 when it was sold to .

Telia Company owned 60% of mobile phone operator Tcell. Tcell is a merger of Somoncom and Indigo Tajikistan; the merger was completed in July 2012. On 27 April 2017 it was confirmed that Tcell has been sold.

When Telia and Sonera merged in 2002, TeliaSonera used a simple wordmark as the logo. In 2011, TeliaSonera released its new purple pebble logo to the corporation and its affiliate brands. The pebble was designed by Landor Associates.

In 2016, TeliaSonera presented an updated pebble brand profile, designed by Wolff Olins, to be used by all Telia brand companies.

In the past TeliaSonera has been accused of indirectly supporting dictatorships, allowing them to do man-in-the-middle attacks on their citizens. This was disclosed in the Swedish TV show Uppdrag Granskning in 2012. TeliaSonera responded to these allegations with: ""This is happening every day in all countries and applies to all operators. We are obliged to comply with the legislation of each country.""

Further allegations have been presented in Swedish media and elsewhere that TeliaSonera may have illegally, through bribery, acquired licenses in Uzbekistan and Azerbaijan. As a result of internal investigations on these and other potential violations to the company's policies, several senior managers have been dismissed from the company.

TeliaSonera exited Nepal evading approximately 36 billions of Nepalese Rupees Capital Gains Tax owed to Nepalese government, when it sold its stake to Axiata, a Malaysian Telecom Group. In that context, Telia was criticized by media(TV) even in Sweden where its headquarter is located. Also, a group of Nepalese people started a movement 'No Tax.. No Ncell' to boycott services of Ncell in Nepal.




</doc>
<doc id="30005" url="https://en.wikipedia.org/wiki?curid=30005" title="Telefónica">
Telefónica

Telefónica, S.A. () is a Spanish multinational broadband and telecommunications provider with operations in Europe, Asia, and North, Central and South America. Operating globally, it is one of the largest telephone operators and mobile network providers in the world. The company is a component of the Euro Stoxx 50 stock market index.

The company started as a public telecommunications company. Its head office is in the "Distrito Telefónica" in Madrid. As well as the Telefónica brand, it also trades as O2, Vivo and Movistar.

As of May 2017, Telefónica was the 110th largest company in the world, according to "Forbes".

The company was created in Madrid in 1924 as Compañía Telefónica Nacional de España (CTNE) with ITT as one of its major shareholders. Until the liberalisation of the telecom market in 1997, Telefónica was the only telephone operator in Spain and still holds a dominant position (over 75% in 2000). Since 1997, the Spanish government has privatized its interest in the company.

Telefónica is a 100% listed company with more than 1.5 million direct shareholders. Its share capital currently comprises 4.563.996.485 ordinary shares traded on the Spanish Stock Market (Madrid, Barcelona, Bilbao and Valencia) and on those in London, New York, Lima, and Buenos Aires. The five major stockholders include:


Telefónica was the parent of Telefónica Deutschland, which held two alternative IP carriers. The two ISPs, mediaWays and HighwayOne merged in January 2003 after having been purchased by Telefónica in 2001 and February 2002 respectively.

On 26 January 2006 Telefónica completed its £17.7 billion (€25.7 billion) acquisition of the UK-based operator O2 which also provided mobile phone services in Germany under the O2 brand. Following the purchase, Telefónica merged Telefónica Deutschland and O2 Germany to form the current business Telefónica Germany.

Telefónica Germany, purchased competitor E-Plus on 1 October 2014. As part of the purchase, Telefónica reduced its stake in its subsidiary to 62.1%. Integration continues as of August 2015, but the now merged network is Germany's largest in customers.

Telefónica is the second largest corporation in Spain, behind the Santander Group. It owns "Telefónica de España" which is the largest fixed phone and ADSL operator in Spain, "Telefónica Móviles", the largest mobile phone operator in Spain (under the Movistar brand), and Terra Networks, S.A., an Internet subsidiary. Spain now has the most extensive fibre-to-home network in Europe, as of April 2016.

On 31 October 2005, O2 agreed to be taken over by Telefónica, with a cash offer of £17.7 billion, or £2 per share. According to the merger announcement, O2, which provided mobile phone services in the UK, Ireland, Germany and the Isle of Man (uniquely to the O2 group Manx Telecom also offered fixed-line services), retained its name and continued to be based in the United Kingdom, keeping both the brand and the management team. The merger became unconditional on 23 January 2006 and O2 became a wholly owned subsidiary of Telefónica. Manx Telecom was sold by Telefónica Europe in June 2010.

In January 2015, Li Ka-shing entered into talks with Telefónica to buy O2 for around £10.25 billion, aiming to merge it with his subsidiary Three. The acquisition was officially blocked by the European Commission on 11 May 2016, which argued that the merger would reduce consumer choice and lead to a higher cost of services Telefónica began to seek a stock market flotation of the business instead.

In France, since 2011, Telefónica has a joint venture with the French telecommunications company Bouygues Telecom, part of the Bouygues group, to offer global telecommunication services packages to multinational companies. This cooperation was expanded in June 2015 through the creation of a separate joint venture company named Telefónica Global Solutions France, with its own marketing and sales teams offering Telefónica and Bouygues Telecom services packages to corporations.

Telefónica operates the Movistar mobile phone brand throughout Latin America. In Mexico it occupies a distant second place and it is the largest in Chile, Venezuela, Brazil, and Peru.

Telefónica owns "Telefónica de Argentina" which is the largest fixed-line operator in the country. It provides broadband, local and long distance telephone services in southern part of the country as well as the Greater Buenos Aires area. The Telefónica Group has been in the country since 1990. The mobile business is run by Telefónica Móviles through Movistar, a local subsidiary.

Telefónica's largest fixed-line operation in South America is in Brazil, where it provides broadband, local and long distance telephone services in the aforementioned state, which alone represents the highest GDP of South America. It also owns a majority stake in the Brazilian mobile operator Vivo, having agreed on 28 July 2010 to buy Portugal Telecom's stake in the firm for €7.5 billion, after increasing its original offer by €1.8 billion over three months of incident-rich negotiations. The Telefónica group has been in the country since 1996 when it acquired CRT, a fixed-line and mobile operator in the southern part of the country. The landline division is currently part of Brasil Telecom. Telefónica is the parent of Telefônica Vivo.

In 2009, after four big "blackouts" on Telefónica's broadband "Speedy", ANATEL ordered Telefónica to stop sales of its broadband service until improvements were made on the infrastructure to provide better-quality service. After the release of sales of broadband internet in August 2009, ANATEL expects the company's service investments to keep on par with the sales. On 24 July 2010 Telefónica announced that the number of Speedy subscribers had exceeded three million people.

Telefónica owns "Telefónica Chile", formerly CTC (Compañía de Telecomunicaciones de Chile, formerly known as Compañía de Teléfonos de Chile) which is the biggest fixed-line operator and internet service provider in the country. The Telefónica Group has been in the country since 1989. The mobile business is run by Telefónica Móviles through a local subsidiary. On 25 October 2009, Telefónica Chile changed its name to "Movistar", including cellphone, landline, satellite TV, and internet.

On 18 April 2006, Telefónica's president Cesar Alierta signed an agreement with the Colombian government to buy 50% and one share of the state-owned communications company, Colombia Telecomunicaciones (TELECOM). With this sale, Telefónica became the largest Colombian land-line operator, and also gained an important presence in the local, long-distance and broadband market. The mobile business is run by Telefónica Móviles through the brand movistar. It is unknown what will happen with their previous established subsidiary Telefónica Empresas, being most probable a merger with TELECOM. The company is now known as Telefónica - Telecom.

Telefónica signed a contract for 15 years (extendable for 10 additional years) on 12 May 2011 with the government of Costa Rica. It started operations on 2011 under its Movistar branding.

In 2000, Telefónica acquired a 26.5% stake in Tricom when it purchased part of the shares Motorola had obtained in 1993.

After acquiring 100% of OTECEL S.A. (Bellsouth), Telefónica Móviles Ecuador started its operations on 14 October 2004 as Movistar. It offers mobile solutions for the Ecuadorian market and is one of only three mobile operators in Ecuador. Telefónica in Ecuador has started offering 3G service from the second half of 2009.

After acquiring 100% of Paysandú S.A., Telefónica Guatemala Centro América started its operations in 1998 as Telefónica Movistar and just Telefónica for landlines. In 2004, acquired 100% of BellSouth Guatemala, relaunching mobile operations as movistar in 2005, with mobile services based on CDMA technology, in 2004 as Telefónica Movistar launch national service with GSM/GPRS technology, and CDMA 1x EV-DO for data. It offers mobile solutions for the Guatemalan market and is one of only three mobile operators in Guatemala, international operator as Millicom (TIGO) and América Móvil (Claro). Telefónica Móviles Guatemala (renamed in 2005) offers services on UMTS/HSPA since June 2009, and it was the last operator to launch commercial services on this technology, with coverage in all major cities.

Telefónica started its operations in Panama in 2004 as Telefónica acquired 100% of Bellsouth Panama. Since then it has operated using the name Movistar for mobile services. It migrated from CDMA technology used by Bellsouth to GSM 850. It also offers 3G using UMTS 850 and UMTS 1900. In 2015 it launched LTE with coverage expanding in Panama City, Arraijan, Chorrera up to Buenaventura Beach.

The Telefónica Group has been in the country since 1994 and owns the largest fixed-line operator in the country. The local subsidiary offers local, long-distance, and broadband services nationwide. The mobile business is run by Telefónica Móviles through a local subsidiary. The mobile telephone business goes by the name Movistar and competes with major provider Claro. Their main offices are located in Santa Beatriz on Av. Arequipa 1155.

Since January 2011, Telefónica has operated in the market under the Movistar brand.

Telefónica in Puerto Rico has presence through Telefónica Empresas, Telefónica Larga Distancia - TLD, Telefónica International Wholesale Services - TIWS (formerly Emergia) and Atento. Telefónica Moviles, through its Movistar brand, had presence in Puerto Rico until mid-2007 that they sold the Puerto Rico network to a private equity group who renamed it Open Mobile.

In late 2004 Telefónica took over the operations of Telcel Bellsouth in Venezuela, the first and largest mobile operator in the South American country at the time. After re-branding as Movistar, its CDMA2000 EvDO was progressively replaced by a GSM UMTS 3G network. Telefónica is currently rolling out 4G LTE in the country.

Based in Miami, Florida, Telefónica USA, Inc. provides services to U.S.-based multinational companies that have operations in Latin America and Europe. Telefónica USA also operates the KeyCenter™, a data center in Miami built to withstand category 5 hurricanes, from where the company supports Business Continuity and IT services for Enterprise customers in South Florida.

In 2009, China Unicom agreed to a $1Bn cross-holding with Telefónica. In January 2011, the two partners agreed to a further $500 million tie-up in each other. Following completion in late 2011, Telefónica will hold a 9.7% stake in China Unicom, and China Unicom will own 1.4% of the Spanish firm.

In 2018, China Unicom and Telefónica establish a new partnership to combine their services and networks in the internet of things, so as to enable their clients to deploy IoT products ans services in China, Europe and Latin America with a single global IoT SIM card.

In 2005, Telefónica bought "Český Telecom" (Czech Telecom), the former state-owned Czech phone operator which still dominates the Czech fixed-line market. As part of this deal Telefónica also gained its 100% subsidiary Eurotel, one of three mobile phone operators in the Czech Republic. Starting 1 July 2006, both companies were merged into one legal entity and renamed "Telefónica O2 Czech Republic". In 2011, the company was renamed "Telefónica Czech Republic" and in 2013, it was announced that Telefónica would sell its stake in the company to PPF. Under the terms of the sale, the company will continue trading under the O2 brand for a maximum of four years.

During 2006, Telefónica won the tender to become the third mobile phone operator in Slovakia, under the O2 brand. It began providing services on 2 February 2007 under the name Telefónica O2 Slovakia, s.r.o. It initially launched providing only a prepaid service but in mid-2007 began to sell contract phones. The company was sold along with Telefónica Czech Republic to PPF.

O2 in Ireland was purchased by Telefónica as part of its acquisition of O2 plc in the UK in 2005. Telefónica Ireland has become the second largest mobile phone operator in Ireland, operating a GSM/EDGE and high-speed HSPA+ wireless broadband network to residential and business customers through its "O2" brand. Telefónica Ireland also provide fixed broadband to business customers.

It was announced on 24 June 2013 that Telefónica had agreed to sell its O2 Ireland mobile business for at least €780 million ($1 billion) in cash to Hutchison Whampoa's subsidiary 3. O2 was merged into Hutchison Whampoa's subsidiary Three Ireland in March 2015

Telefónica currently owns 46% of Telco, the holding company that controls 22% of Telecom Italia, Italy's former government–owned telephone company. In late 2003, Telefónica announced its intention to acquire the entirety of Telco by January 2014, potentially becoming Telecom Italia's largest shareholder. The plan, was however challenged by the Brazilian competition authority since Telefónica and Telecom Italia, with Vivo and TIM respectively, are the two largest telephone companies competing in Brazil. Subsequently, Telefónica confirmed in September 2014 that it intended to sell its shares in Telecom Italia following the purchase of Global Village Telecom (GVT) in Brazil from Vivendi. Telefónica sold its shares in the business to Vivendi as part of the sale of GVT in June 2015.

The firm provides fixed, mobile and data telecommunications, digital platforms and ICT services to the B2B sector (MNC, Enterprise, SME and Wholesale) through its Telefónica Business Solutions unit.

Customers: Telefónica lists, among other, the following as existing customers: Inditex, Scottish Power, BBVA, Endesa, Ferrovial and FCC.

Full network operations: Argentina, Brazil, Chile, Colombia, Costa Rica, Ecuador, El Salvador, Germany, Guatemala, Mexico, Nicaragua, Panama, Peru, Puerto Rico, Spain, United Kingdom, Uruguay and Venezuela

Commercial offices: Austria, Belgium, Bulgaria, China, Czech Republic, Denmark, Estonia, France, Greece, Hungary, Ireland, Italy, Netherlands, Poland, Portugal, Romania, Singapore, Slovakia, Sweden, Switzerland and USA

Remote operations and network points of presence: Finland, Latvia, Lithuania, Morocco, Norway and Slovenia

Strategic and industrial alliances: China Unicom

It has an extended service reach in 129 additional countries.

"Source :OpesC"
Quarterly Report Jan - Dec 2008 - page 9

In football, Teléfonica is an official sponsor for several national teams like Spain (Movistar+) in Europe and Brazil (vivo), Mexico, Colombia, Peru or Venezuela in America.

O2 are the main sponsors of the England national rugby team.

From 2011, they are to sponsor the Spanish UCI ProTour cycling team known as Movistar Team.

Teléfonica, through Movistar, is the major sponsor of Yamaha Motor Racing, a motorcycle racing team in MotoGP, and was also a major sponsor of one of Suzuki's and Honda's racing teams in MotoGP in the early 2000s.

Within Formula One, Telefónica was a major sponsor of the Renault F1 Team until Fernando Alonso's departure to McLaren in 2007, and were title sponsors of the Spanish Grand Prix from 2006 to 2010. Through its acquisition of O, Telefónica also indirectly sponsored the BMW Sauber F1 Team. "F1 Racing" estimates these sponsorships amount to $18 million, $15 million and $23 million respectively.

They also sponsored the Ford Focus WRC during seasons 2000-2002 when Spanish rally driver Carlos Sainz drove for the team. The sponsorship said Telefónica Movistar on it and the stickers were on the front bumper, the rear 3-quarters and the rear spoiler. As Sainz moved to Citroën team, Telefónica followed and sponsored Citroën rally team in 2003.

Movistar- and Telefónica-sponsored teams contested the round-the-world Volvo Ocean Race in the 2005-06, 2008-09 and 2011-12 events.

Telefónica has received several fines due to convictions over unfair competition, abuse of its position as dominant provider, and antitrust violations through the Commission of Telecommunications, European Commission, and Spanish tribunals. These fines include:


As of 2008, Telefónica had in court two more fines, with a value of 793 million euros.

On 5 July 2007, the European Commission ordered Telefónica to pay a record antitrust fine of almost €152 million for activities in the Spanish broadband market which, according to European Union competition commissioner Neelie Kroes, "harmed Spanish consumers, Spanish businesses and the Spanish economy as a whole, and by extension Europe's economy".

Several consumer groups in Spain have reported unnecessary delays in cancelling Telefónica's ADSL service. These consumer groups also claim that services continue to be billed after being cancelled and that service cancellation requests are ignored.
This has led Spanish people to organize themselves in consumer groups such as the "Asociación de Internautas" and user communities like "Bandaancha" in order to defend themselves from Telefónica's abuses, and to give support and help to each other in their various complaints about Telefónica's unfair practices.

The practices are claimed to include the complex process involved in cancelling lines.
These line cancellation procedures are justified by Telefónica as a way of "defending customers against hoaxes". Furthermore, in areas where ADSL lines are scarce, there are also reports of customers who claim to have had their service cancelled or inexplicably transferred to another customer although they have paid their bills.
This practice is considered by some to be used by Telefónica in certain areas of Spain where there are few broadband connections.

In February 2010, Telefónica CEO Cesar Alierta expressed in a meeting at Bilbao, Spain that his company intends to charge Google and other search engines for the use of their network. Alierta complained that such search engines were benefiting from the platform without contributing to the company's expenses and that such a trend will change in the near future. Additionally he said that Telefónica will seek to push its own content.

Telefónica is a supporter of the Hybrid Broadcast Broadband TV (HbbTV) initiative that is promoting and establishing an open European standard for hybrid set-top boxes for the reception of broadcast TV and broadband multimedia applications with a single user interface, and has run pilot HbbTV services in Spain.

Telefónica's Wayra subsidiary first launched in Latin America and Spain in 2011 to provide seed investment and mentoring to new companies. Since its inception, Wayra has backed over 300 companies including Trustev, Venddo, Cloudwear and NFWare.

As of 1 December 2014, the Firefox web browser includes the "Firefox Hello" WebRTC feature, that allows real-time voice and video online chats. "Firefox Hello" is powered by Telefónica and was also co-developed by Telefónica.

Telefónica Dynamic services offers mobile-money using Sybase 365 Mobile wallet systems, with a service-centre based in Tel-Aviv.

In September 2017, Nokia and Telefónica signed an agreement in order to evaluate technologies enabling an efficient network evolution to 5G in line with Telefónica's business objectives.

On 12 May 2017, Telefónica computer's network was critically attacked by a malware known as WannaCry ransomware attack.



</doc>
<doc id="30006" url="https://en.wikipedia.org/wiki?curid=30006" title="The Silence of the Lambs (film)">
The Silence of the Lambs (film)

The Silence of the Lambs is a 1991 American psychological horror thriller film directed by Jonathan Demme from a screenplay written by Ted Tally, adapted from Thomas Harris's 1988 novel of the same name. The film stars Jodie Foster, Anthony Hopkins, Scott Glenn,
Ted Levine, and Anthony Heald. In the film, Clarice Starling, a young FBI trainee, seeks the advice of the imprisoned Dr. Hannibal Lecter, a brilliant psychiatrist and cannibalistic serial killer to apprehend another serial killer, known only as "Buffalo Bill", who skins his female victims' corpses. 
The novel was Harris's first and second respectively to feature the characters of Starling and Lecter, and was the second adaptation of a Harris novel to feature Lecter, preceded by the Michael Mann-directed "Manhunter" (1986).

"The Silence of the Lambs" was released on February 14, 1991, and grossed $272.7 million worldwide against its $19 million budget, becoming the fifth-highest grossing film of 1991 worldwide. The film premiered at the 41st Berlin International Film Festival, where it competed for the Golden Bear, while Demme received the Silver Bear for Best Director.
Critically acclaimed upon release, it became only the third film, (the other two being "It Happened One Night" and "One Flew Over the Cuckoo's Nest"), to win Academy Awards in all the top five categories: Best Picture, Best Director, Best Actor, Best Actress, and Best Adapted Screenplay. It is also the first (and so far only) Best Picture winner widely considered to be a horror film, and only the third such film to be nominated in the category, after "The Exorcist" (1973) and "Jaws" (1975). 

It is regularly cited by critics, film directors, and audiences alike as one of the greatest and most influential films of all time. In 2018, "Empire" ranked it 48th, on their list of 500 greatest movies of all time. The American Film Institute, ranked it as the 5th greatest and most influential thriller film of all time. The film is considered "culturally, historically or aesthetically" significant by the U.S. Library of Congress and was selected to be preserved in the National Film Registry in 2011. A sequel titled "Hannibal" was released in 2001, in which Hopkins reprised his role. It was followed by two prequels: "Red Dragon" (2002) and "Hannibal Rising" (2007).

FBI trainee Clarice Starling is pulled from her training at the FBI Academy at Quantico, Virginia by Jack Crawford of the Bureau's Behavioral Science Unit. He assigns her to interview Hannibal Lecter, a former psychiatrist and incarcerated cannibalistic serial killer, whose insight might prove useful in the pursuit of a serial killer nicknamed "Buffalo Bill", who skins his female victims' corpses.

Starling travels to the Baltimore State Hospital for the Criminally Insane, where she is led by Frederick Chilton to Lecter's solitary quarters. Although initially pleasant and courteous, Lecter grows impatient with Starling's attempts at "dissecting" him and rebuffs her. As she is leaving, one of the prisoners flicks semen at her. Lecter, who considers this act "unspeakably ugly", calls Starling back and tells her to seek out an old patient of his. This leads her to a storage shed, where she discovers a man's severed head in a abandoned storage facility. She finds a Death's Head Hawkmoth cocoon lodged in the throat of another victim's recovered body. She returns to Lecter, who tells her that the man is linked to Buffalo Bill. He offers to profile Buffalo Bill on the condition that he may be transferred away from Chilton, whom he detests.

Buffalo Bill abducts a Senator's daughter, Catherine Martin. Crawford authorizes Starling to offer Lecter a fake deal, promising a prison transfer if he provides information that helps them find Buffalo Bill and rescue Catherine. Instead, Lecter demands a "quid pro quo" from Starling, offering clues about Buffalo Bill in exchange for personal information. Starling tells Lecter about the murder of her father when she was ten years old. Chilton secretly records the conversation and reveals Starling's deceit before offering Lecter a deal of Chilton's own making. Lecter agrees and is flown to Memphis, Tennessee, where he verbally torments Senator Ruth Martin, and gives her misleading information on Buffalo Bill, including the name "Louis Friend".

Starling notices that "Louis Friend" is an anagram of "iron sulfide"—fool's gold. She visits Lecter, who is now being held in a cage-like cell in a Tennessee courthouse, and asks for the truth. Lecter tells her that all the information she needs is contained in the case file. Rather than give her the real name, he insists that they continue their "quid pro quo" and she recounts a traumatic childhood incident where she was awakened by the sound of spring lambs being slaughtered on a relative's farm in Montana. Starling admits that she still sometimes wakes thinking she can hear lambs screaming, and Lecter speculates that she is motivated to save Catherine in the hope that it will end the nightmares. Lecter gives her back the case files on Buffalo Bill after their conversation is interrupted by Chilton and the police, who escort her from the building. Later that evening, Lecter kills his guards, escapes from his cell, and disappears.

Starling analyzes Lecter's annotations to the case files and realizes that Buffalo Bill knew his first victim personally. Starling travels to the victim's hometown and discovers that Buffalo Bill was a tailor, with dresses and dress patterns identical to the patches of skin removed from each of his victims. She telephones Crawford to inform him that Buffalo Bill is trying to form a "woman suit" out of real skin, but Crawford is already en route to make an arrest, having cross-referenced Lecter's notes with hospital archives and finding a transsexual man named Jame Gumb, who once applied unsuccessfully for a sex-change operation. Starling continues interviewing friends of Buffalo Bill's first victim in Ohio, while Crawford leads an FBI Hostage Rescue Team to Gumb's address in Illinois. The house in Illinois is empty, and Starling is led to the house of "Jack Gordon", whom she realizes is actually Jame Gumb, again by finding a sphinx moth. She pursues him into his multi-room basement, where she discovers that Catherine is still alive, but trapped in a dry well. After turning off the basement lights, Gumb stalks Starling in the dark with night-vision goggles, but gives his position away when he cocks his revolver. Starling reacts just in time and fires all of her rounds at Gumb, killing him.

Sometime later, at the FBI Academy graduation party, Starling receives a phone call from Lecter, who is at an airport in Bimini. He assures her that he does not plan to pursue her and asks her to return the favor, which she says she cannot do. Lecter then hangs up the phone, saying that he is "having an old friend for dinner", and starts following a newly arrived Chilton before disappearing into the crowd.

"The Silence of the Lambs" is based on Thomas Harris' 1988 novel of the same name and is the second film to feature the character Hannibal Lecter following the 1986 film "Manhunter". Prior to the novel's release, Orion Pictures partnered with Gene Hackman to bring the novel to the big screen. With Hackman set to direct and possibly star in the role of Crawford, negotiations were made to split the $500,000 cost of rights between Hackman and the studio. In addition to securing the rights to the novel, producers also had to acquire the rights to the name "Hannibal Lecter", which were owned by "Manhunter" producer Dino De Laurentiis. Owing to the financial failure of the earlier film, De Laurentiis lent the character rights to Orion Pictures for free.

In November 1987, Ted Tally was brought on to write the adaptation; Tally had previously crossed paths with Harris many times, with his interest in adapting "The Silence of the Lambs" originating from receiving an advance copy of the book from Harris himself. When Tally was about halfway through with the first draft, Hackman withdrew from the project and financing fell through. However, Orion Pictures co-founder Mike Medavoy assured Tally to keep writing as the studio itself took care of financing and searched for a replacement director. As a result, Orion Pictures sought director Jonathan Demme to helm the project. With the screenplay not yet completed, Demme signed on after reading the novel. From there, the project quickly took off, as Tally explained, "[Demme] read my first draft not long after it was finished, and we met, then I was just startled by the speed of things. We met in May 1989 and were shooting in November. I don't remember any big revisions."

Jodie Foster was interested in playing the role of Clarice Starling immediately after reading the novel. However, in spite of the fact that Foster had just won an Academy Award for her performance in the 1988 film "The Accused", Demme was not convinced that she was right for the part. Having previously collaborated on "Married to the Mob", Demme's first choice for the role of Starling was Michelle Pfeiffer, who turned it down, later saying, "It was a difficult decision, but I got nervous about the subject matter". As a result, Foster was awarded the role due to her passion towards the character.

For the role of Dr. Hannibal Lecter, Demme originally approached Sean Connery. After the actor turned it down, Anthony Hopkins was then offered the part based on his performance in "The Elephant Man". Other actors considered for the role included Al Pacino, Robert De Niro, Dustin Hoffman, Derek Jacobi and Daniel Day-Lewis.

Gene Hackman was originally going to play Jack Crawford, the Agent-in-Charge of the Behavioral Science Unit of the FBI in Quantico, Virginia but he found the script "too violent." Scott Glenn was then cast in the role. To prepare for the role, Glenn met with John E. Douglas, after whom the character is modeled. Douglas gave Glenn a tour of the Quantico facility and also played for him an audio tape containing various recordings that serial killers Lawrence Bittaker and Roy Norris had made of themselves raping and torturing a 16-year-old girl. According to Douglas, Glenn wept as he experienced the recordings and even changed his liberal stance on the death penalty.

Principal photography for "The Silence of the Lambs" began on November 15, 1989 and concluded on March 1, 1990. Filming primarily took place in and around Pittsburgh, Pennsylvania, with some scenes shot in nearby northern West Virginia. The home of Buffalo Bill used for exterior scenes was in Layton, Pennsylvania. The exterior of the Western Center near Canonsburg, Pennsylvania served as the setting for Baltimore State Hospital for the Criminally Insane. In what was a rare act of cooperation at the time, the FBI allowed scenes to be filmed at the FBI Academy in Quantico; some FBI staff members even acted in bit parts.

The musical score for "The Silence of the Lambs" was composed by Howard Shore, who would also go on to collaborate with Demme on "Philadelphia". Recorded in Munich during the latter half of the summer of 1990, the score was performed by the Munich Symphony Orchestra. "I tried to write in a way that goes right into the fabric of the movie," explained Shore on his approach. "I tried to make the music just fit in. When you watch the movie you are not aware of the music. You get your feelings from all elements simultaneously, lighting, cinematography, costumes, acting, music. Jonathan Demme was very specific about the music." A soundtrack album was released by MCA Records on February 5, 1991. Music from the film was later used in the trailers for its 2001 sequel, "Hannibal".

"The Silence of the Lambs" was released on February 14, 1991, grossing $14 million during its opening weekend. At the time it closed on October 10, 1991, the film had grossed $131 million domestically with a total worldwide gross of $273 million. It was the 5th-highest grossing film of 1991 worldwide.

"The Silence of the Lambs" was a sleeper hit that gradually gained widespread success and critical acclaim. Foster, Hopkins, and Levine garnered much acclaim for their performances. Review aggregator Rotten Tomatoes reports that 95% of 84 film critics have given the film a positive review, with an average rating of 8.7 out of 10. The website's critical consensus reads: "Director Jonathan Demme's smart, taut thriller teeters on the edge between psychological study and all-out horror, and benefits greatly from stellar performances by Anthony Hopkins and Jodie Foster." Metacritic, another review aggregator, assigned the film a weighted average score of 85 out of 100, based on 19 reviews from mainstream critics, indicating "universal acclaim". Audiences polled by CinemaScore gave the film an average grade of "A-" on an A+ to F scale.

Roger Ebert, of "Chicago Sun-Times", specifically mentioned the "terrifying qualities" of Hannibal Lecter. Ebert later added the film to his list of "The Great Movies", recognizing the film as a "horror masterpiece" alongside such classics as "Nosferatu", "Psycho", and "Halloween". However, the film is also notable for being one of two multi-Academy Award winners (the other being "Unforgiven") disapproved of by Ebert's colleague, Gene Siskel. Writing for "Chicago Tribune", Siskel said, "Foster's character, who is appealing, is dwarfed by the monsters she is after. I'd rather see her work on another case."

The film won the Big Five Academy Awards: Best Picture, Best Director (Demme), Best Actor (Hopkins), Best Actress (Foster), and Best Adapted Screenplay (Ted Tally), making it only the third film in history to accomplish that feat. It was also nominated for Best Sound Mixing (Tom Fleischman and Christopher Newman) and Best Film Editing, but lost to "" and "JFK", respectively.

Other awards include being named Best Film by the National Board of Review of Motion Pictures, CHI Awards and PEO Awards. Demme won the Silver Bear for Best Director at the 41st Berlin International Film Festival and was nominated for the Golden Globe Award for Best Director. The film was nominated for the Grand Prix of the Belgian Film Critics Association. It was also nominated for the British Academy Film Award for Best Film. Screenwriter Ted Tally received an Edgar Award for Best Motion Picture Screenplay. The film was awarded Best Horror Film of the Year during the 2nd Horror Hall of Fame telecast, with Vincent Price presenting the award to the film's executive producer Gary Goetzman.

In 1998, the film was listed as one of the 100 greatest films in the past 100 years by the American Film Institute. In 2006, at the Key Art Awards, the original poster for "The Silence of the Lambs" was named best film poster "of the past 35 years". "The Silence of the Lambs" placed seventh on Bravo's "The 100 Scariest Movie Moments" for Lecter's escape scene. The American Film Institute named Hannibal Lecter (as portrayed by Hopkins) the number one film villain of all time and Clarice Starling (as portrayed by Foster) the sixth-greatest film hero of all time. In 2011, ABC aired a prime-time special, "", that counted down the best films chosen by fans based on results of a poll conducted by ABC and "People" magazine. "The Silence of the Lambs" was selected as the 1 Best Suspense/Thriller and Dr. Hannibal Lecter was selected as the 4 Greatest Film Character.

The film and its characters have appeared in the following AFI "100 Years" lists:

In 2015, "Entertainment Weekly"'s 25th anniversary year, it included "The Silence of the Lambs" in its list of the 25 best movies made since the magazine's beginning.

Upon its release, "The Silence of the Lambs" was criticized by members of the LGBT community for its portrayal of Buffalo Bill as bisexual and transsexual. In response to the critiques, Demme replied that Buffalo Bill "wasn't a gay character. He was a tormented man who hated himself and wished he was a woman because that would have made him as far away from himself as he possibly could be." Demme added that he "came to realize that there is a tremendous absence of positive gay characters in movies". Much of the criticism was directed towards Foster, whom the critics alleged was herself a lesbian. 

In a 1992 interview with "Playboy" magazine, notable feminist and women's rights advocate Betty Friedan stated, "I thought it was absolutely outrageous that "The Silence of the Lambs" won four Oscars. […] I'm not saying that the movie shouldn't have been shown. I'm not denying the movie was an artistic triumph, but it was about the evisceration, the skinning alive of women. That is what I find offensive. Not the "Playboy" centerfold."



</doc>
<doc id="30007" url="https://en.wikipedia.org/wiki?curid=30007" title="The Matrix">
The Matrix

The Matrix is a 1999 science fiction action film written and directed by The Wachowski Brothers and starring Keanu Reeves, Laurence Fishburne, Carrie-Anne Moss, Hugo Weaving, and Joe Pantoliano. It depicts a dystopian future in which reality as perceived by most humans is actually a simulated reality called "the Matrix", created by sentient machines to subdue the human population, while their bodies' heat and electrical activity are used as an energy source. Cybercriminal and computer programmer Neo learns this truth and is drawn into a rebellion against the machines, which involves other people who have been freed from the "dream world."

"The Matrix" is known for popularizing a visual effect known as "bullet time", in which the heightened perception of certain characters is represented by allowing the action within a shot to progress in slow-motion while the camera's viewpoint appears to move through the scene at normal speed. The film is an example of the cyberpunk subgenre. It contains numerous references to philosophical and religious ideas, and prominently pays homage to works such as Plato's Allegory of the Cave, Jean Baudrillard's "Simulacra and Simulation" and Lewis Carroll's "Alice's Adventures in Wonderland". The Wachowskis' approach to action scenes drew upon their admiration for Japanese animation and martial arts films, and the film's use of fight choreographers and wire fu techniques from Hong Kong action cinema influenced subsequent Hollywood action film productions.

"The Matrix" was first released in the United States on March 31, 1999, and grossed over $460 million worldwide. It was well-received by critics and won four Academy Awards, as well as other accolades, including BAFTA Awards and Saturn Awards. Reviewers praised "The Matrix" for its innovative visual effects, cinematography and entertainment value. The film has since appeared in lists of the greatest science fiction films, and, in 2012, was added to the National Film Registry for preservation. The success of the film led to the release of two feature film sequels, both written and directed by the Wachowskis: "The Matrix Reloaded" and "The Matrix Revolutions". "The Matrix" franchise was further expanded through the production of comic books, video games and animated short films, in which the Wachowskis were heavily involved, and even inspired books and theories on ideas in religion and philosophy.

A woman is cornered by police in an abandoned hotel; after overpowering them with superhuman abilities, a group of sinister superhuman grey green-suited Agents leads the police in a rooftop pursuit. She answers a ringing public telephone and vanishes.

Computer programmer Thomas Anderson, living a double life as the hacker "Neo", feels something is wrong with the world and is puzzled by repeated online encounters with the cryptic phrase "the Matrix". The woman, Trinity, contacts him, saying that a man named Morpheus can explain its meaning; however, the Agents, led by Agent Smith, apprehend Neo and attempt to threaten him into helping them capture the "terrorist" Morpheus. Undeterred, Neo meets Morpheus, who offers him a choice between a red pill that will show him the truth about the Matrix, and a blue pill that will return him to his former life. After swallowing the red pill, his reality disintegrates and Neo awakens, naked, weak and hairless, in a liquid-filled pod, one of countless others connected by cables to an elaborate electrical system. He is rescued and brought aboard Morpheus' hovercraft, the "Nebuchadnezzar".

As Neo recuperates, Morpheus explains the truth: in the 21st century, intelligent machines waged war against their human creators. When humans blocked the machines' access to solar energy, the machines retaliated by harvesting the humans' bioelectric power. The Matrix is a shared simulation of the world, in which the minds of the harvested humans are trapped and pacified. All free humans live in Zion, the last refuge in the real world. Morpheus and his crew are a group of rebels who hack into the Matrix to "unplug" enslaved humans and recruit them; their understanding of the simulated reality enables them to bend its physical laws, granting them superhuman abilities. Morpheus warns Neo that death within the Matrix also kills the physical body, and that the Agents are powerful sentient programs that eliminate threats to the system. Neo's prowess during virtual combat training lends credence to Morpheus' belief that Neo is "the One", an especially powerful human prophesied to free humans and end the war.

The group enters the Matrix to visit the Oracle, a prophet who predicted the emergence of the One. She implies that Neo is not the One and warns Neo that he will have to choose between Morpheus' life and his own. Before they can leave the Matrix, the group is ambushed by Agents and tactical police alerted by Cypher, a crew member who betrayed Morpheus to Smith in exchange for a comfortable life back in the Matrix. Morpheus allows himself to be captured so Neo and the rest of the crew can escape. Cypher exits the Matrix and murders several crew members as they lie defenseless in the real world. As he prepares to disconnect Neo and Trinity, Tank, a crewman whom he had left for dead, kills him.

In the Matrix, the Agents interrogate Morpheus to learn his access codes to the mainframe computer in Zion. Tank proposes killing Morpheus to prevent this, but Neo, believing that he is not the One, resolves to return to the Matrix to rescue Morpheus; Trinity insists she accompany him. While rescuing Morpheus, Neo gains confidence in his abilities, performing feats comparable to the Agents'. Morpheus and Trinity exit the Matrix, but Smith ambushes and kills Neo before he can leave. In the real world, machines called Sentinels attack the "Nebuchadnezzar". Trinity whispers to Neo that he can't be dead because she loves him and the Oracle told her that she would fall in love with the One. She kisses Neo and he revives with the power to perceive and control the Matrix. He effortlessly defeats Smith and leaves the Matrix just as the ship's electromagnetic pulse weapon disables the attacking Sentinels.

Later, Neo makes a telephone call inside the Matrix, promising the machines that he will show their prisoners "a world where anything is possible". He hangs up and flies into the sky.


In 1994, the Wachowskis presented the script for the film "Assassins" to Warner Bros. Pictures. After Lorenzo di Bonaventura, the president of production of the company at the time, read the script, he decided to buy rights to it and included two more pictures, "Bound" and "The Matrix", in the contract. The first movie The Wachowskis directed, "Bound", then became a critical success. Using this momentum, the siblings later asked to direct "The Matrix".

Producer Joel Silver soon joined the project. Although the project had key supporters like Silver and Di Bonaventura to influence the company, "The Matrix" was still a huge investment for Warner Bros, which had to invest $60 million to create a movie with deep philosophical ideas and difficult special effects. The Wachowskis therefore hired underground comic book artists Geof Darrow and Steve Skroce to draw a 600-page, shot-by-shot storyboard for the entire film. The storyboard eventually earned the studio's approval, and it was decided to film in Australia to make the most of the budget. Soon, "The Matrix" became a co-production of Warner Bros. and the Australian company Village Roadshow Pictures.

The actors of the film were required to be able to understand and explain "The Matrix". "Simulacra and Simulation" was required reading for most of the principal cast and crew. Reeves stated that the Wachowskis had him read "Simulacra and Simulation", "", and Dylan Evans’s "Introducing Evolutionary Psychology" even before they opened up the script, and eventually he was able to explain all the philosophical nuances involved. Moss commented that she had difficulty with this process.

The directors had also been admirers of Hong Kong action cinema for a long time, so they decided to hire the Chinese martial arts choreographer and film director Yuen Woo-ping to work on fight scenes. To prepare for the wire fu, the actors had to train hard for several months. The Wachowskis first scheduled four months for training. Yuen was optimistic but then began to worry when he realized how unfit the actors were.

Yuen let their body style develop and then worked with each actor's strength. He built on Reeves' diligence, Fishburne's resilience, Weaving's precision, and Moss's feminine grace. Yuen designed Moss' moves to suit her deftness and lightness. Prior to the pre-production, Reeves suffered a two-level fusion of his cervical spine which had begun to cause paralysis in his legs, requiring him to undergo neck surgery. He was still recovering by the time of pre-production, but he insisted on training, so Yuen let him practice punches and lighter moves. Reeves trained hard and even requested training on days off. However, the surgery still made him unable to kick for two out of four months of training. As a result, Reeves did not kick much in the film. Weaving had to undergo hip surgery after he sustained an injury during the training process.

In the film, the code that composes the Matrix itself is frequently represented as downward-flowing green characters. This code uses a custom typeface designed by Simon Whiteley, which includes mirror images of half-width kana characters and Western Latin letters and numerals. The color green reflects the green tint commonly used on early monochrome computer monitors. Lynne Cartwright, the Visual Effects Supervisor at Animal Logic, supervised the creation of the film's opening title sequence, as well as the general look of the Matrix code throughout the film, in collaboration with Lindsay Fleay and Justen Marshall. The portrayal resembles the opening credits of the 1995 Japanese cyberpunk film, "Ghost in the Shell", which had a strong influence on the "Matrix" series (see below). It was also used in the subsequent films, on the related website, and in the game "", and its drop-down effect is reflected in the design of some posters for the "Matrix" series. The code received the Runner-up Award in the 1999 Jesse Garson Award for In-film typography or opening credit sequence.

"The Matrix"s production designer, Owen Paterson, used methods to distinguish the "real world" and the Matrix in a pervasive way. The production design team generally placed a bias towards the Matrix code's distinctive green color in scenes set within the simulation, whereas there is an emphasis on the color blue during scenes set in the "real world". In addition, the Matrix scenes' sets were slightly more decayed, monolithic, and grid-like, to convey the cold, logical and artificial nature of that environment. For the "real world", the actors' hair was less styled, their clothing had more textile content, and the cinematographers used longer lenses to soften the backgrounds and emphasize the actors.

The "Nebuchadnezzar" was designed to have a patched-up look, instead of clean, cold and sterile space ship interior sets as used on films like "Star Trek". The wires were made visible to show the ship's working internals, and each composition was carefully designed to convey the ship as "a marriage between Man and Machine". For the scene when Neo wakes up in the pod connected to the Matrix, the pod was constructed to look dirty, used, and sinister. During the testing of a breathing mechanism in the pod, the tester suffered hypothermia in under eight minutes, so the pod had to be heated.

Kym Barrett, costume designer, said that she defined the characters and their environment by their costume. For example, Reeves' office costume was designed for Thomas Anderson to look uncomfortable, disheveled, and out of place. Barrett sometimes used three types of fabric for each costume, and also had to consider the practicality of the acting. The actors needed to perform martial art actions in their costume, hang upside-down without people seeing up their clothing, and be able to work the wires while strapped into the harnesses. For Trinity, Barrett experimented with how each fabric absorbed and reflected different types of light, and was eventually able to make Trinity's costume mercury-like and oil-slick to suit the character. For the Agents, their costume was designed to create a secret service, undercover look, resembling the film "JFK".

The sunglasses, a staple to the film's aesthetics, were commissioned for the film by designer Richard Walker from sunglass maker Blinde Design.

All but a few scenes were filmed at Fox Studios in Sydney, and in the city itself, although recognizable landmarks were not included in order to maintain the impression of a generic American city. The filming helped establish New South Wales as a major film production center. Filming commenced in March 1998 and wrapped in August 1998; principal photography took 118 days.

Due to Reeves' neck injury, some of the action scenes had to be rescheduled to wait for his full recovery. As a result, the filming began with scenes that did not require much physical exertion, such as the scene in Thomas Anderson's office, the interrogation room, or the car ride in which Neo is taken to see the Oracle. Locations for these scenes included Martin Place's fountain in Sydney, half-way between it and the adjacent Colonial Building, and the Colonial Building itself. During the scene set on a government building rooftop, the team filmed extra footage of Neo dodging bullets in case the bullet time process did not work.

Moss performed the shots featuring Trinity at the beginning of the film and all the wire stunts herself. The rooftop set that Trinity uses to escape from Agent Brown early in the film was left over from the production of "Dark City", which has prompted comments due to the thematic similarities of the films. During the rehearsal of the lobby scene, in which Trinity runs on a wall, Moss injured her leg and was ultimately unable to film the shot in one take. She stated that she was under a lot of pressure at the time and was devastated when she realized that she would be unable to do it.

The dojo set was built well before the actual filming. During the filming of these action sequences, there was significant physical contact between the actors, earning them bruises. Because of Reeves's injury and his insufficient training with wires prior to the filming, he was unable to perform the triple kicks satisfactorily and became frustrated with himself, causing the scene to be postponed. The scene was shot successfully a few days later, with Reeves using only three takes. Yuen altered the choreography and made the actors pull their punches in the last sequence of the scene, creating a training feel.

The filmmakers originally planned to shoot the subway scene in an actual subway station, but the complexity of the fight and related wire work required shooting the scene on a set. The set was built around an existing train storage facility, which had real train tracks. Filming the scene when Neo slammed Smith into the ceiling, Chad Stahelski, Reeves' stunt double, sustained several injuries, including broken ribs, knees, and a dislocated shoulder. Another stuntman was injured by a hydraulic puller during a shot where Neo was slammed into a booth. The office building in which Smith interrogated Morpheus was a large set, and the outside view from inside the building was a large, three story high cyclorama. The helicopter was a full-scale light-weight mock-up suspended by a wire rope operated a tilting mechanism mounted to the studio roofbeams. The helicopter had side mounted to it a real minigun, which was set to cycle at half normal full (3000 rounds per min) firing rate. The visual effect of the helicopters rotating blades was effected by using strobe lighting.

To prepare for the scene in which Neo wakes up in a pod, Reeves lost 15 pounds and shaved his whole body to give Neo an emaciated look. The scene in which Neo fell into the sewer system concluded the principal photography. According to "The Art of the Matrix", at least one filmed scene and a variety of short pieces of action were omitted from the final cut of the film.

The film is known for popularizing a visual effect known as "bullet time", which allows a shot to progress in slow-motion while the camera appears to move through the scene at normal speed. Bullet time has been described as "a visual analogy for privileged moments of consciousness within the Matrix", and throughout the film, the effect is used to illustrate characters' exertion of control over time and space. The Wachowskis first imagined an action sequence that slowed time while the camera pivoted rapidly around the subjects, and proposed the effect in their screenplay for the film. When John Gaeta read the script, he pleaded with an effects producer at Manex Visual Effects to let him work on the project, and created a prototype that led to him becoming the film's visual effects supervisor.

The method used for creating these effects involved a technically expanded version of an old art photography technique known as time-slice photography, in which an array of cameras are placed around an object and triggered simultaneously. Each camera is a still-picture camera not a motion picture camera, and it contributes just one frame to the video sequence. When those pictures are shown in sequence, they create the effect of "virtual camera movement"; the illusion of a viewpoint moving around an object that appears frozen in time.

The bullet time effect is similar but slightly more complicated, incorporating temporal motion so that rather than appearing totally frozen, the scene progresses in slow and variable motion. The cameras' positions and exposures were previsualized using a 3D simulation. Instead of firing the cameras simultaneously, the visual effect team fired the cameras fractions of a second after each other, so that each camera could capture the action as it progressed, creating a super slow-motion effect. When the frames were put together, the resulting slow-motion effects reached a frame frequency of 12,000 per second, as opposed to the normal 24 frames per second of film. Standard movie cameras were placed at the ends of the array to pick up the normal speed action before and after. Because the cameras circle the subject almost completely in most of the sequences, computer technology was used to edit out the cameras that appeared in the background on the other side. To create backgrounds, Gaeta hired George Borshukov, who created 3D models based on the geometry of buildings and used the photographs of the buildings themselves as texture.

The photo-realistic surroundings generated by this method were incorporated into the bullet time scene, and linear interpolation filled in any gaps of the still images to produce a fluent dynamic motion; the computer-generated "lead in" and "lead out" slides were filled in between frames in sequence to get an illusion of orbiting the scene. Manex Visual Effects used a cluster farm running the Unix-like operating system FreeBSD to render many of the film's visual effects.

Manex also handled creature effects, such as Sentinels and machines in real world scenes; Animal Logic created the code hallway and the exploding Agent at the end of the film. DFilm managed scenes that required heavy use of digital compositing, such as Neo's jump off a skyscraper and the helicopter crash into a building. The ripple effect in the latter scene was created digitally, but the shot also included practical elements, and months of extensive research were needed to find the correct kind of glass and explosives to use. The scene was shot by colliding a quarter-scale helicopter mock-up into a glass wall wired to concentric rings of explosives; the explosives were then triggered in sequence from the center outward, to create a wave of exploding glass.

The photogrametric and image-based computer-generated background approaches in "The Matrix"s bullet time evolved into innovations unveiled in the sequels "The Matrix Reloaded" and "The Matrix Revolutions". The method of using real photographs of buildings as texture for 3D models eventually led the visual effect team to digitize all data, such as scenes, characters' motions and expressions. It also led to the development of "Universal Capture", a process which samples and stores facial details and expressions at high resolution. With these highly detailed collected data, the team were able to create virtual cinematography in which characters, locations, and events can all be created digitally and viewed through virtual cameras, eliminating the restrictions of real cameras.

Dane A. Davis was responsible for creating the sound effects for the film. The fight scenes sound effects, such as the whipping sounds of punches were created using thin metal rods and recording them, then editing the sounds. The sound of the pod containing a human baby closing required almost fifty sounds put together.

The film's score was composed by Don Davis. He noted that mirrors appear frequently in the film: reflections of the blue and red pills are seen in Morpheus's glasses; Neo's capture by Agents is viewed through the rear-view mirror of Trinity's Triumph Speed Triple motorcycle; Neo observes a broken mirror mending itself; reflections warp as a spoon is bent; the reflection of a helicopter is visible as it approaches a skyscraper. Davis focused on this theme of reflections when creating his score, alternating between sections of the orchestra and attempting to incorporate contrapuntal ideas. Davis' score combines orchestral, choral and synthesizer elements; the balance between these elements varies depending on whether humans or machines are the dominant subject of a given scene.
In addition to Davis' score, "The Matrix" soundtrack also features music from acts such as Rammstein, Rob Dougan, Rage Against the Machine, Propellerheads, Ministry, Deftones, Monster Magnet, The Prodigy, Rob Zombie, Meat Beat Manifesto, and Marilyn Manson.

"The Matrix" draws from and makes reference to numerous cinematic and literary works, and concepts from mythology, religion and philosophy. "The Matrix" also makes reference to the ideas of Buddhism, Christianity, Gnosticism, Hinduism, and Judaism. "The Matrix"s premise resembles the Christian doctrine of the Trinity. Andrew Godoski from "Screened.com" observed Neo's "virgin birth", his doubt in himself, the prophecy of his coming, along with many Christianity references. In "The Matrix", a copy of Jean Baudrillard's "Simulacra and Simulation" is visible on-screen as the book used to conceal disks, and Morpheus quotes its phrase "desert of the real". The book was required reading for the actors prior to filming. Baudrillard himself said that "The Matrix" misunderstands and distorts his work.

Interpretations of "The Matrix" often reference Baudrillard's philosophy to demonstrate that the film is an allegory for contemporary experience in a heavily commercialized, media-driven society, especially in developed countries. The influence of the matrixial theory of Bracha Ettinger articulated in a series of books and essays from the end of the 1980s onwards was brought to the public's attention through the writings of art historians such as Griselda Pollock and film theorists such as Heinz-Peter Schwerfel. Bracha Ettinger's matrixial theory is referred to explicitly quite late in the film through the expression "primal matrix" but it is visualized from the beginning via the alliance between Neo, Trinity and Morpheus, their "co-birthing" in a womb-like "shareable time-space", their co-existence in different dimension at the same time, their relation to the maternal oracle and more. Her "archaic" matrix is always in the now and the future, depends on human affects and desires, and proposes a different relations between the symbolic and the real. This Matrix is fragile yet it is resistant to the dominating Matrix of the mechanical coded simulated and manipulated consciousness that forecloses and rejects it. In the Ettingerian matrixial sphere freedom goes together with responsibility. The links between Neo, Morpheus, Trinity and the Oracle, right from the very beginning and all along the film, manifest the possibility of "transconnectedness" in proximity and in distance, which is not global and can't form a "web of webs". Its webs are always specific, invested by an "Eros of borderlinking" and related to different processes that Ettinger has named "metramorphosis" (feminine-maternal-material morpheus). This is then another kind of Matrix hidden behind the Baudrillard kind.

"The Matrix" belongs to the cyberpunk genre of science fiction, and draws from earlier works in the genre such as "Neuromancer" by William Gibson. For example, the film's use of the term "Matrix" is adopted from Gibson's novel, though L. P. Davies had already used the term "Matrix" fifteen years earlier for a similar concept in his 1969 novel "The White Room" ("It had been tried in the States some years earlier, but their 'matrix' as they called it hadn't been strong enough to hold the fictional character in place"). After watching "The Matrix", Gibson commented that the way that the film's creators had drawn from existing cyberpunk works was "exactly the kind of creative cultural osmosis" he had relied upon in his own writing; however, he noted that the film's Gnostic themes distinguished it from "Neuromancer", and believed that "The Matrix" was thematically closer to the work of science fiction author Philip K. Dick. Other writers have also commented on the similarities between "The Matrix" and Dick's work; one example of such influence is a Philip K. Dick's 1977 conference, in which he stated:

The Wachowskis' approach to action scenes drew upon their admiration for Japanese animation such as "Ninja Scroll" and "Akira". Director Mamoru Oshii's 1995 animated film "Ghost in the Shell" was a particularly strong influence; producer Joel Silver has stated that the Wachowskis first described their intentions for "The Matrix" by showing him that anime and saying, "We wanna do that for real". Mitsuhisa Ishikawa of Production I.G, which produced "Ghost in the Shell", noted that the anime's high-quality visuals were a strong source of inspiration for the Wachowskis. He also commented, "... cyberpunk films are very difficult to describe to a third person. I'd imagine that "The Matrix" is the kind of film that was very difficult to draw up a written proposal for to take to film studios". He stated that since "Ghost in the Shell" had gained recognition in America, the Wachowskis used it as a "promotional tool". The action scenes of "The Matrix" were also strongly influenced by live-action films such as those of director John Woo. The martial arts sequences were inspired by "Fist of Legend", a critically acclaimed 1995 martial arts film starring Jet Li. The fight scenes in "Fist of Legend" led to the hiring of Yuen as fight choreographer.

The film makes several references to Lewis Carroll's "Alice's Adventures in Wonderland". The pods in which the machines keep humans have been compared to images in "Metropolis", and the work of M. C. Escher. The Wachowskis have described Stanley Kubrick's "" as a formative cinematic influence, and as a major inspiration on the visual style they aimed for when making "The Matrix".

Reviewers have commented on similarities between "The Matrix" and other late-1990s films such as "Strange Days", "Dark City", and "The Truman Show". Comparisons have also been made to Grant Morrison's comic series "The Invisibles"; Morrison believes that the Wachowskis essentially plagiarized his work to create the film. Comparisons have also been made between "The Matrix" and the books of Carlos Castaneda.
The similarity of the film's central concept to a device in the long-running series "Doctor Who" has also been noted. As in the film, the Matrix of that series (introduced in the 1976 serial "The Deadly Assassin") is a massive computer system which one enters using a device connecting to the head, allowing users to see representations of the real world and change its laws of physics; but if killed there, they will die in reality.

The Matrix as a generated reality - the invention of malicious machines - is a reference to Descartes' First Meditation, or evil demon. The Meditation hypothesizes that the perceived world might be a comprehensive illusion created to deceive us. The same premise can be found in Hilary Putnam's brain in a vat scenario proposed in the 1980s. One can also make a connection between the premise of "The Matrix" and Plato's Allegory of the Cave; once one accepts that The Matrix is an illusion, then the allegory of the cave becomes clear. The allegory is related to Plato's theory of Forms, which holds that the true essence of an object is not what we perceive with our senses, but rather its quality, and that most people perceive only the shadow of the object and are thus limited to false perception.

Immanuel Kant also has an influence on how individuals within The Matrix interact with one another and with the system. Kant states in his "Critique of Pure Reason" that people come to know and explore our world through synthetic means (language, etc.), and thus this makes it rather difficult to discern truth from falsely perceived views. This means we ourselves are our own agents of deceit, and so in order for one to know truth, one must choose to openly pursue truth. One may examine this explicitly in the scene with Agent Smith's monologue about the first version of the Matrix, which was designed to be a human utopia, a perfect world without suffering and with total happiness. Agent Smith exclaims, "it was a disaster. No one accepted the program. Entire crops [of people] were lost." The machines had to amend their choice of programming in order to make people subservient to them, and so they conceived The Matrix in the image of the world in 1999. The world in 1999 was far from a utopia, but still humans accepted this over the suffering-less utopia. This is Kantian, because the machines wished to impose a perfect world on humans in an attempt to keep people content to remain completely submissive to the machines, both consciously and subconsciously, but humans are not easy to make content.

Morpheus paraphrases the Chinese philosopher Zhuangzi when he asks Neo, “Have you ever had a dream, Neo, that you were so sure was real? What if you weren’t able to wake from that dream? How would you know the difference from the real world and the dream world?”

"The Matrix" was released on VHS and DVD on , 1999 It was also released on Laserdisc in its original aspect ratio of 2.35:1 on September 21, 1999 in the US from Warner Home Video as well as in a cropped 1.33:1 aspect ratio in Hong Kong from ERA Home Entertainment. After its DVD release, it was the first DVD to sell more than one million copies in the US, and went on to be the first to sell more than three million copies in the US. By , 2003, one month after "The Matrix Reloaded" DVD was released, the sales of "The Matrix" DVD had exceeded 30 million copies. The Ultimate Matrix Collection was released on HD DVD on , 2007 and on Blu-ray on , 2008. The film was also released standalone in a 10th anniversary edition Blu-ray in the Digibook format on , 2009, 10 years to the day after the film was released theatrically. In 2010, the film had another DVD release along with the two sequels as "The Complete Matrix Trilogy".

The film earned $171,479,930 (37.0%) in the United States and Canada and $292,037,453 (63.0%) in other countries, for a worldwide total of $463,517,383. In North America, it became the fifth highest grossing film of 1999 and the highest grossing R-rated film of 1999. Worldwide it was the fourth highest grossing film of the year. it was placed 122nd on the list of highest grossing films of all time, and the second highest grossing film in the "Matrix" franchise after "The Matrix Reloaded" ($742.1 million).

"The Matrix" received acclaim from most critics, and is widely regarded as one of the greatest science fiction films of all time. "Entertainment Weekly" called "The Matrix" "the most influential action movie of the generation". Review aggregator Rotten Tomatoes reported an 87% of positive reviews, with a weighted average score of 7.6/10 based upon a sample of 143 reviews. The site's critical consensus reads, "Thanks to the Wachowski Brothers' imaginative vision, "The Matrix" is a smartly crafted combination of spectacular action and groundbreaking special effects". At Metacritic, which assigns a rating out of 100 to reviews from mainstream critics, the film received a score of 73 based on 35 reviews, indicating "generally favorable reviews." Audiences polled by CinemaScore gave the film an average grade of "A-" on an A+ to F scale.

Philip Strick commented in "Sight & Sound", "if the Wachowski Brothers claim no originality of message, they are startling innovators of method," praising the film's details and its "broadside of astonishing images". Roger Ebert praised the film's visuals and premise, but disliked the third act's focus on action. Similarly, "Time Out" praised the "entertainingly ingenious" switches between different realities, Hugo Weaving's "engagingly odd" performance, and the film's cinematography and production design, but concluded, "the promising premise is steadily wasted as the film turns into a fairly routine action pic ... yet another slice of overlong, high concept hokum."

Jonathan Rosenbaum of the "Chicago Reader" reviewed the film negatively, criticizing it as "simpleminded fun for roughly the first hour, until the movie becomes overwhelmed by its many sources ... There's not much humor to keep it all life-size, and by the final stretch it's become bloated, mechanical, and tiresome." Film critic Nick Davis strongly disliked "The Matrix", criticizing aspects such as its unoriginality and its attitudes toward race and gender, concluding that The Wachowskis had raised the bar of filmmaking and special effects, only to waste it on hackneyed, impersonal and political tripe.

Ian Nathan of "Empire" described Carrie-Anne Moss as "a major find", praised the "surreal visual highs" enabled by the bullet time (or "flo-mo") effect, and described the film as "technically mind-blowing, style merged perfectly with content and just so damn cool". Nathan remarked that although the film's "looney plot" would not stand up to scrutiny, that was not a big flaw because ""The Matrix" is about pure experience". Maitland McDonagh said in her review for "TV Guide", "The Wachowski Brothers' through-the-looking-glass plot... manages to work surprisingly well on a number of levels: as a dystopian sci-fi thriller, as a brilliant excuse for the film's lavish and hyperkinetic fight scenes, and as a pretty compelling call to the dead-above-the-eyeballs masses to unite and cast off their chains... This dazzling pop allegory is steeped in a dark, pulpy sensibility that transcends nostalgic pastiche and stands firmly on its own merits."

"Salon"s reviewer Andrew O'Hehir acknowledged that "The Matrix" is a fundamentally immature and unoriginal film ("It lacks anything like adult emotion... all this pseudo-spiritual hokum, along with the overamped onslaught of special effects—some of them quite amazing—will hold 14-year-old boys in rapture, not to mention those of us of all ages and genders who still harbor a 14-year-old boy somewhere inside"), but concluded, "as in "Bound", there's an appealing scope and daring to The Wachowskis' work, and their eagerness for more plot twists and more crazy images becomes increasingly infectious. In a limited and profoundly geeky sense, this might be an important and generous film. The Wachowskis have little feeling for character or human interaction, but their passion for "movies"—for making them, watching them, inhabiting their world—is pure and deep."

Several science fiction creators commented on the film. Author William Gibson, a key figure in cyberpunk fiction, called the film "an innocent delight I hadn't felt in a long time," and stated, "Neo is my favourite-ever science fiction hero, absolutely." Joss Whedon called the film "my number one" and praised its storytelling, structure and depth, concluding, "It works on whatever level you want to bring to it." Filmmaker Darren Aronofsky commented, "I walked out of "The Matrix" ... and I was thinking, 'What kind of science fiction movie can people make now?' The Wachowski Brothers basically took all the great sci-fi ideas of the 20th century and rolled them into a delicious pop culture sandwich that everyone on the planet devoured." Director M. Night Shyamalan expressed admiration for The Wachowskis, stating, "Whatever you think of "The Matrix", every shot is there because of the passion they have! You can see they argued it out!". Actor and screenwriter Simon Pegg said that "The Matrix" provided "the excitement and satisfaction that "" failed to inspire. "The Matrix" seemed fresh and cool and visually breathtaking; making wonderful, intelligent use of CGI to augment the on-screen action, striking a perfect balance of the real and the hyperreal. It was possibly the coolest film I had ever seen." Director Quentin Tarantino counted "The Matrix" as one of his twenty favourite movies from 1992 to 2009.

"The Matrix" received Academy Awards for film editing, sound effects editing, visual effects, and sound. The filmmakers were competing against other films with established franchises, like "", yet they won all four of their nominations. "The Matrix" also received BAFTA awards for Best Sound and Best Achievement in Special Visual Effects, in addition to nominations in the cinematography, production design and editing categories. In 1999, it won Saturn Awards for Best Science Fiction Film and Best Direction.

"The Matrix" had a strong effect on action film-making in Hollywood. The film's incorporation of wire fu techniques, including the involvement of fight choreographer Yuen Woo-ping and other personnel with a background in Hong Kong action cinema, affected the approaches to fight scenes taken by subsequent Hollywood action films, moving them towards more Eastern approaches. The success of "The Matrix" created high demand for those choreographers and their techniques from other filmmakers, who wanted fights of similar sophistication: for example, wire work was employed in "X-Men" (2000) and "Charlie's Angels" (2000), and Yuen Woo-ping's brother Yuen Cheung-Yan was choreographer on "Daredevil" (2003). "The Matrix"s Asian approach to action scenes also created an audience for Asian action films such as "Crouching Tiger, Hidden Dragon" (2000) that they might not otherwise have had.

Following "The Matrix", films made abundant use of slow-motion, spinning cameras, and, often, the bullet time effect of a character freezing or slowing down and the camera dollying around them. The ability to slow down time enough to distinguish the motion of bullets was used as a central gameplay mechanic of several video games, including "Max Payne", in which the feature was explicitly referred to as "bullet time". "The Matrix"s signature special effect, and other aspects of the film, have been parodied numerous times, in comedy films such as "" (1999), "Scary Movie" (2000), "Shrek" (2001), "Kung Pow! Enter the Fist" (2002); "Marx Reloaded" in which the relationship between Neo and Morpheus is represented as an imaginary encounter between Karl Marx and Leon Trotsky; and in video games such as "Conker's Bad Fur Day". It also inspired films featuring a black-clad hero, a sexy yet deadly heroine, and bullets ripping slowly through the air; these included "Charlie's Angels" (2000) featuring Cameron Diaz floating through the air while the cameras flo-mo around her; "Equilibrium" (2003), starring Christian Bale, whose character wore long black leather coats like Reeves' Neo; "Night Watch" (2004), a Russian megahit heavily influenced by "The Matrix" and directed by Timur Bekmambetov, who later made "Wanted" (2008), which also features bullets ripping through air; and "Inception" (2010), which centers on a team of sharply dressed rogues who enter a wildly malleable alternate reality by "wiring in". The original "Tron" (1982) paved the way for "The Matrix", and "The Matrix", in turn, inspired Disney to make its own Matrix with a "Tron" sequel, "" (2010).

Carrie-Anne Moss asserted that prior to being cast in "The Matrix", she had "no career". It launched Moss into international recognition and transformed her career; in a "New York Daily News" interview, she stated, ""The Matrix" gave me so many opportunities. Everything I've done since then has been because of that experience. It gave me so much". The film also created one of the most devoted movie fan-followings since "Star Wars", and was even briefly blamed for the shootings at Columbine High School. The combined success of the "Matrix" trilogy, the "Lord of the Rings" films and the "Star Wars" prequels made Hollywood interested in creating trilogies. Stephen Dowling from the BBC noted that "The Matrix"s success in taking complex philosophical ideas and presenting them in ways palatable for impressionable minds might be its most influential aspect.

In 2001, "The Matrix" placed 66th in the American Film Institute's "100 Years...100 Thrills" list. In 2007, "Entertainment Weekly" called "The Matrix" the best science-fiction piece of media for the past 25 years. In 2009, the film was ranked 39th on "Empire"s reader-, actor- and critic-voted list of "The 500 Greatest Movies of All Time". "The Matrix" was voted as the fourth best sci-fi film in the 2011 list "", based on a poll conducted by ABC and "People". In 2012, the film was selected for preservation in the National Film Registry by the Library of Congress for being "culturally, historically, and aesthetically significant."

The film's mainstream success led to the making of two sequels, "The Matrix Reloaded" and "The Matrix Revolutions", both directed by The Wachowskis. These were filmed back-to-back in one shoot and released on separate dates in 2003. The first film's introductory tale is succeeded by the story of the impending attack on the human enclave of Zion by a vast machine army. The sequels also incorporate longer and more ambitious action scenes, as well as improvements in bullet time and other visual effects.

Also released was "The Animatrix", a collection of nine animated short films, many of which were created in the same Japanese animation style that was a strong influence on the live action trilogy. "The Animatrix" was overseen and approved by The Wachowskis, who only wrote four of the segments themselves but did not direct any of them; much of the project was developed by notable figures from the world of anime.

The franchise also contains three video games: "Enter the Matrix" (2003), which contains footage shot specifically for the game and chronicles events taking place before and during "The Matrix Reloaded"; "The Matrix Online" (2004), an MMORPG which continued the story beyond "The Matrix Revolutions"; and "" (2005), which focuses on Neo's journey through the trilogy of films.

The franchise also includes "The Matrix Comics", a series of comics and short stories set in the world of "The Matrix", written and illustrated by figures from the comics industry. Most of the comics were originally presented for free on the official "Matrix" website; they were later republished, along with some new material, in two printed trade paperback volumes, called "The Matrix Comics, Vol 1 and Vol 2".

In March 2017, Warner Bros. was in early stages of developing a relaunch of the franchise with Zak Penn in talks to write a treatment and interest in getting Michael B. Jordan attached to star. According to "The Hollywood Reporter" neither The Wachowskis nor Joel Silver were involved with the endeavor, although the studio would like to get at minimum the blessing of The Wachowskis.

"The Matrix" was released on DVD on May 15, 2007, a Blu-ray release followed on October 14, 2008. It was also released on 4K HDR Blu-ray on May 22, 2018.




</doc>
<doc id="30010" url="https://en.wikipedia.org/wiki?curid=30010" title="Telegraphy">
Telegraphy

Telegraphy (from Greek: τῆλε "têle", "at a distance" and γράφειν "gráphein", "to write") is the long-distance transmission of textual or symbolic (as opposed to verbal or audio) messages without the physical exchange of an object bearing the message. Thus semaphore is a method of telegraphy, whereas pigeon post is not.

Telegraphy requires that the method used for encoding the message be known to both sender and receiver. Many methods are designed according to the limits of the signalling medium used. The use of smoke signals, beacons, reflected light signals, and flag semaphore signals are early examples.

In the 19th century, the harnessing of electricity led to the invention of electrical telegraphy. The advent of radio in the early 20th century brought about radiotelegraphy and other forms of wireless telegraphy. In the Internet age, telegraphic means developed greatly in sophistication and ease of use, with natural language interfaces that hide the underlying code, allowing such technologies as electronic mail and instant messaging.

The word "telegraph" was first coined by the French inventor of the Semaphore line, Claude Chappe, who also coined the word "semaphore".

A "telegraph" is a device for transmitting and receiving messages over long distances, i.e., for telegraphy. The word "telegraph" alone now generally refers to an electrical telegraph.

Wireless telegraphy is also known as "CW", for continuous wave (a carrier modulated by on-off keying), as opposed to the earlier radio technique of using a spark gap.

Contrary to the extensive definition used by Chappe, Morse argued that the term "telegraph" can strictly be applied only to systems that transmit "and" record messages at a distance. This is to be distinguished from "semaphore", which merely transmits messages. Smoke signals, for instance, are to be considered semaphore, not telegraph. According to Morse, telegraph dates only from 1832 when Pavel Schilling invented one of the earliest electrical telegraphs.

A telegraph message sent by an electrical telegraph operator or telegrapher using Morse code (or a printing telegraph operator using plain text) was known as a "telegram". A "cablegram" was a message sent by a submarine telegraph cable, often shortened to a "cable" or a "wire". Later, a "Telex" was a message sent by a Telex network, a switched network of teleprinters similar to a telephone network.

A "wire picture" or "wire photo" was a newspaper picture that was sent from a remote location by a facsimile telegraph. A "diplomatic telegram", also known as a diplomatic cable, is the term given to a confidential communication between a diplomatic mission and the foreign ministry of its parent country. These continue to be called telegrams or cables regardless of the method used for transmission.

Even though early telegraphic precedents, such as signalling through the lighting of pyres, have existed since ancient times, long-distance telegraphy (transmission of complex messages) started in 1792 in the form of semaphore lines, or optical telegraphs, that sent messages to a distant observer through line-of-sight signals. Commercial electrical telegraphs were introduced from 1837.

The first telegraphs came in the form of optical telegraph, including the use of smoke signals, beacons, or reflected light, which have existed since ancient times. Early proposals for an optical telegraph system were made to the Royal Society by Robert Hooke in 1684 and were first implemented on an experimental level by Sir Richard Lovell Edgeworth in 1767.

The first successful semaphore network was invented by Claude Chappe and operated in France from 1793 to 1846.
During 1790–1795, at the height of the French Revolution, France needed a swift and reliable communication system to thwart the war efforts of its enemies. In 1790, the Chappe brothers set about devising a system of communication that would allow the central government to receive intelligence and to transmit orders in the shortest possible time. On 2 March 1791, at 11 am, they sent the message "si vous réussissez, vous serez bientôt couverts de gloire" (If you succeed, you will soon bask in glory) between Brulon and Parce, a distance of . The first means used a combination of black and white panels, clocks, telescopes, and codebooks to send their message.

In 1792, Claude was appointed "Ingénieur-Télégraphiste" and charged with establishing a line of stations between Paris and Lille, a distance of 230 kilometres (about 143 miles). It was used to carry dispatches for the war between France and Austria. In 1794, it brought news of a French capture of Condé-sur-l'Escaut from the Austrians less than an hour after it occurred.

The Prussian system was put into effect in the 1830s. However, they were highly dependent on good weather and daylight to work and even then could accommodate only about two words per minute. The last commercial semaphore link ceased operation in Sweden in 1880. As of 1895, France still operated coastal commercial semaphore telegraph stations, for ship-to-shore communication.

The first suggestion for using electricity as a means of communication appeared in the "Scots Magazine" in 1753. Using one wire for each letter of the alphabet, a message could be transmitted by connecting the wire terminals in turn to an electrostatic machine, and observing the deflection of pith balls at the far end. Telegraphs employing electrostatic attraction were the basis of early experiments in electrical telegraphy in Europe but were abandoned as being impractical and were never developed into a useful communication system.

One very early experiment in electrical telegraphy was an "electrochemical telegraph" created by the German physician, anatomist, and inventor Samuel Thomas von Sömmering in 1809, based on an earlier, less robust design of 1804 by Spanish polymath and scientist Francisco Salva Campillo. Both their designs employed multiple wires (up to 35) in order to visually represent most Latin letters and numerals. Thus, messages could be conveyed electrically up to a few kilometers (in von Sömmering's design), with each of the telegraph receiver's wires immersed in a separate glass tube of acid. As an electric current was applied by the sender representing each character of a message, it would at the recipient's end electrolyse the acid in its corresponding tube, releasing a stream of hydrogen bubbles next to its associated letter or numeral. The telegraph receiver's operator would visually observe the bubbles and could then record the transmitted message, albeit at a very low baud rate.

The first working telegraph was built by the English inventor Francis Ronalds in 1816 and used static electricity. At the family home on Hammersmith Mall, he set up a complete subterranean system in a 175-yard long trench as well as an eight-mile long overhead telegraph. The lines were connected at both ends to clocks marked with the letters of the alphabet and electrical impulses sent along the wire were used to transmit messages. Offering his invention to the Admiralty in July 1816, it was rejected as "wholly unnecessary". His account of the scheme and the possibilities of rapid global communication in "Descriptions of an Electrical Telegraph and of some other Electrical Apparatus" was the first published work on electric telegraphy and even described the risk of signal retardation due to induction. Elements of Ronalds' design were utilised in the subsequent commercialisation of the telegraph over 20 years later.

An early electromagnetic telegraph design was created by Russian diplomat Pavel Schilling in 1832. He set it up in his apartment in St. Petersburg and demonstrated the long-distance transmission of signals by positioning two telegraphs of his invention in two different rooms of his apartment. Schilling was the first to put into practice the idea of a binary system of signal transmissions.

Carl Friedrich Gauss and Wilhelm Weber built the first electromagnetic telegraph used for "regular" communication in 1833 in Göttingen, connecting Göttingen Observatory and the Institute of Physics, covering a distance of about 1 km. The setup consisted of a coil that could be moved up and down over the end of two magnetic steel bars. The resulting induction current was transmitted through two wires to the receiver, consisting of a galvanometer. The direction of the current could be reversed by commuting the two wires in a special switch. Therefore, Gauss and Weber chose to encode the alphabet in a binary code, using positive and negative currents as the two states.

Telegraph networks were expensive to build, but financing was readily available, especially from London bankers. By 1852, National systems were in operation in major countries:

The first commercial electrical telegraph was co-developed by Sir William Fothergill Cooke and Charles Wheatstone. In May 1837, they patented the Cooke and Wheatstone system, which used a number of needles on a board that could be moved to point to letters of the alphabet. The patent recommended a five-needle system, but any number of needles could be used depending on the number of characters it was required to code. A four-needle system was installed between Euston and Camden Town in London on a rail line being constructed by Robert Stephenson between London and Birmingham. It was successfully demonstrated on 25 July 1837. Euston needed to signal to an engine house at Camden Town to start hauling the locomotive up the incline. As at Liverpool, the electric telegraph was in the end rejected in favour of a pneumatic system with whistles.

Cooke and Wheatstone had their first commercial success with a system installed on the Great Western Railway over the from Paddington station to West Drayton in 1838, the first commercial telegraph in the world. This was a five-needle, six-wire system. The cables were originally installed underground in a steel conduit. However, the cables soon began to fail as a result of deteriorating insulation and were replaced with uninsulated wires on poles. As an interim measure, a two-needle system was used with three of the remaining working underground wires, which despite using only two needles had a greater number of codes. But when the line was extended to Slough in 1843, a one-needle, two-wire system was installed.

From this point, the use of the electric telegraph started to grow on the new railways being built from London. The London and Blackwall Railway (another rope-hauled application) was equipped with the Cooke and Wheatstone telegraph when it opened in 1840, and many others followed. The one-needle telegraph proved highly successful on British railways, and 15,000 sets were still in use at the end of the nineteenth century. Some remained in service in the 1930s. In September 1845, the financier John Lewis Ricardo and Cooke formed the Electric Telegraph Company, the first public telegraphy company in the world. This company bought out the Cooke and Wheatstone patents and solidly established the telegraph business.

As well as the rapid expansion of the use of the telegraphs along the railways, they soon spread into the field of mass communication with the instruments being installed in post offices across the country. The era of mass personal communication had begun.

An electrical telegraph was independently developed and patented in the United States in 1837 by Samuel Morse. His assistant, Alfred Vail, developed the Morse code signalling alphabet with Morse. The first telegram in the United States was sent by Morse on 11 January 1838, across two miles (3 km) of wire at Speedwell Ironworks near Morristown, New Jersey, although it was only later, in 1844, that he sent the message "WHAT HATH GOD WROUGHT" from the Capitol in Washington to the old Mt. Clare Depot in Baltimore. From then on, commercial telegraphy took off in America with lines linking all the major metropolitan centres on the East Coast within the next decade. The overland telegraph connected the west coast of the continent to the east coast by 24 October 1861, bringing an end to the Pony Express.

The Morse telegraphic apparatus was officially adopted as the standard for European telegraphy in 1851. Only Great Britain with its extensive overseas empire kept the needle telegraph of Cooke and Wheatstone. In 1858, Morse introduced wired communication to Latin America when he established a telegraph system in Puerto Rico, then a Spanish Colony. The line was inaugurated on March 1, 1859, in a ceremony flanked by the Spanish and American flags.

Another early system was that of Edward Davy, who demonstrated his in Regent's Park in 1837 and was granted a patent on 4 July 1838. He also developed an electric relay.

Telegraphy was driven by the need to reduce sending costs, either in hand-work per message or by increasing the sending rate. While many experimental systems employing moving pointers and various electrical encodings proved too complicated and unreliable, a successful advance in the sending rate was achieved through the development of telegraphese.
The first system that didn't require skilled technicians to operate was Sir Charles Wheatstone's ABC system in 1840 where the letters of the alphabet were arranged around a clock-face, and the signal caused a needle to indicate the letter. This early system required the receiver to be present in real time to record the message and it reached speeds of up to 15 words a minute.

In 1846, Alexander Bain patented a chemical telegraph in Edinburgh. The signal current made a readable mark on a moving paper tape soaked in a mixture of ammonium nitrate and potassium ferrocyanide, which gave a blue mark when a current was passed through it.
David Edward Hughes invented the printing telegraph in 1855; it used a keyboard of 26 keys for the alphabet and a spinning type wheel that determined the letter being transmitted by the length of time that had elapsed since the previous transmission. The system allowed for automatic recording on the receiving end. The system was very stable and accurate and became the accepted around the world.

The next improvement was the Baudot code of 1874. French engineer Émile Baudot patented a printing telegraph in which the signals were translated automatically into typographic characters. Each character was assigned a unique code based on the sequence of just five contacts. Operators had to maintain a steady rhythm, and the usual speed of operation was 30 words per minute.

By this point, reception had been automated, but the speed and accuracy of the transmission were still limited to the skill of the human operator. The first practical automated system was patented by Charles Wheatstone, the original inventor of the telegraph. The message (in Morse code) was typed onto a piece of perforated tape using a keyboard-like device called the 'Stick Punch'. The transmitter automatically ran the tape through and transmitted the message at the then exceptionally high speed of 70 words per minute.

Teleprinters were invented in order to send and receive messages without the need for operators trained in the use of Morse code. A system of two teleprinters, with one operator trained to use a typewriter, replaced two trained Morse code operators. The teleprinter system improved message speed and delivery time, making it possible for messages to be flashed across a country with little manual intervention.

Early teleprinters used the ITA-1 Baudot code, a five-bit code. This yielded only thirty-two codes, so it was over-defined into two "shifts", "letters", and "figures". An explicit, unshared shift code prefaced each set of letters and figures. In 1901, Baudot's code was modified by Donald Murray and around 1930, the CCITT introduced the International Telegraph Alphabet No. 2 (ITA2) code as an international standard.
By 1935, message routing was the last great barrier to full automation. Large telegraphy providers began to develop systems that used telephone-like rotary dialling to connect teletypewriters. These machines were called "Telex" (TELegraph EXchange). Telex machines first performed rotary-telephone-style pulse dialling for circuit switching and then sent data by Baudot code. This "type A" Telex routing functionally automated message routing.

Telex began in Germany as a research and development program in 1926 that became an operational teleprinter service in 1933. The service was operated by the Reichspost (Reich postal service) and had a speed of 50 baud – approximately 66 words-per-minute.

At the rate of 45.45 (±0.5%) baud—considered speedy at the time—up to 25 telex channels could share a single long-distance telephone channel by using "voice frequency telegraphy multiplexing", making telex the least expensive method of reliable long-distance communication.

Automatic teleprinter exchange service was introduced into Canada by CPR Telegraphs and CN Telegraph in July 1957, and in 1958, Western Union started to build a Telex network in the United States.

Beginning in 1956, telegrams begun to be transmitted over the Telex network using the standard named Gentex in order to lower the costs for some European telecommunications companies by allowing the sending telegraph station to connect directly to the receiving station.

Soon after the first successful telegraph systems were operational, the possibility of transmitting messages across the sea by way of submarine communications cables was first mooted. One of the primary technical challenges was to insulate the submarine cable sufficiently to prevent the current from leaking out into the water. In 1842, a Scottish surgeon William Montgomerie introduced Gutta-percha, the adhesive juice of the "Palaquium gutta" tree, to Europe. Michael Faraday and Wheatstone soon discovered the merits of gutta-percha as an insulator, and in 1845, the latter suggested that it should be employed to cover the wire which was proposed to be laid from Dover to Calais. It was tried on a wire laid across the Rhine between Deutz and Cologne. In 1849, C.V. Walker, electrician to the South Eastern Railway, submerged a two-mile wire coated with gutta-percha off the coast from Folkestone, which was tested successfully.

John Watkins Brett, an engineer from Bristol, sought and obtained permission from Louis-Philippe in 1847 to establish telegraphic communication between France and England. The first undersea cable was laid in 1850 and connected London with Paris. After an initial exchange of greetings between Queen Victoria and President Napoleon, it was almost immediately severed by a French fishing vessel. The line was relaid the next year and then followed by connections to Ireland and the Low Countries.
The Atlantic Telegraph Company was formed in London in 1856 to undertake to construct a commercial telegraph cable across the Atlantic Ocean. It was successfully completed on 27 July 1866, by the ship SS "Great Eastern", captained by Sir James Anderson after many mishaps along the way. Earlier transatlantic submarine cables installations were attempted in 1857, 1858, and 1865. The 1858 cable only operated intermittently for a few days or weeks before it failed. The study of underwater telegraph cables accelerated interest in mathematical analysis of very long transmission lines. An overland telegraph from Britain to India was first connected in 1866 but was unreliable so a submarine telegraph cable was connected in 1870. Several telegraph companies were combined to form the "Eastern Telegraph Company" in 1872.

Australia was first linked to the rest of the world in October 1872 by a submarine telegraph cable at Darwin. This brought news reportage from the rest of the world. The telegraph across the Pacific was completed in 1902, finally encircling the world.

From the 1850s until well into the 20th century, British submarine cable systems dominated the world system. This was set out as a formal strategic goal, which became known as the All Red Line. In 1896, there were thirty cable laying ships in the world and twenty-four of them were owned by British companies. In 1892, British companies owned and operated two-thirds of the world's cables and by 1923, their share was still 42.7 percent. During World War I, Britain's telegraph communications were almost completely uninterrupted while it was able to quickly cut Germany's cables worldwide.

In 1843, Scottish inventor Alexander Bain invented a device that could be considered the first facsimile machine. He called his invention a "recording telegraph". Bain's telegraph was able to transmit images by electrical wires. Frederick Bakewell made several improvements on Bain's design and demonstrated a telefax machine. In 1855, an Italian abbot, Giovanni Caselli, also created an electric telegraph that could transmit images. Caselli called his invention "Pantelegraph". Pantelegraph was successfully tested and approved for a telegraph line between Paris and Lyon.

In 1881, English inventor Shelford Bidwell constructed the "scanning phototelegraph" that was the first telefax machine to scan any two-dimensional original, not requiring manual plotting or drawing. Around 1900, German physicist Arthur Korn invented the "" widespread in continental Europe especially since a widely noticed transmission of a wanted-person photograph from Paris to London in 1908 used until the wider distribution of the radiofax. Its main competitors were the "Bélinographe" by Édouard Belin first, then since the 1930s, the "Hellschreiber", invented in 1929 by German inventor Rudolf Hell, a pioneer in mechanical image scanning and transmission.

The late 1880s through to the 1890s saw the discovery and then development of a newly understood phenomenon into a form of wireless telegraphy, called "Hertzian wave" wireless telegraphy, radiotelegraphy, or (later) simply "radio". Between 1886 and 1888, Heinrich Rudolf Hertz published the results of his experiments where he was able to transmit electromagnetic waves (radio waves) through the air, proving James Clerk Maxwell's 1873 theory of electromagnetic radiation. Many scientists and inventors experimented with this new phenomenon but the general consensus was that these new waves (similar to light) would be just as short range as light, and, therefore, useless for long range communication.

At the end of 1894, the young Italian inventor Guglielmo Marconi began working on the idea of building a commercial wireless telegraphy system based on the use of Hertzian waves (radio waves), a line of inquiry that he noted other inventors did not seem to be pursuing. Building on the ideas of previous scientists and inventors Marconi re-engineered their apparatus by trial and error attempting to build a radio based wireless telegraphic system that would function the same as wired telegraphy. He would work on the system through 1895 in his lab and then in field tests making improvements to extend its range. After many breakthroughs, including applying the wired telegraphy concept of grounding the transmitter and receiver, Marconi was able, by early 1896, to transmit radio far beyond the short ranges that had been predicted. Having failed to interest the Italian government, the 22-year-old inventor brought his telegraphy system to Britain in 1896 and met William Preece, a Welshman, who was a major figure in the field and Chief Engineer of the General Post Office. A series of demonstrations for the British government followed—by March 1897, Marconi had transmitted Morse code signals over a distance of about across Salisbury Plain.

On 13 May 1897, Marconi, assisted by George Kemp, a Cardiff Post Office engineer, transmitted the first wireless signals over water to Lavernock (near Penarth in Wales) from Flat Holm. The message sent was "ARE YOU READY". From his Fraserburgh base, he transmitted the first long-distance, cross-country wireless signal to Poldhu in Cornwall. His star rising, he was soon sending signals across The English channel (1899), from shore to ship (1899) and finally across the Atlantic (1901). A study of these demonstrations of radio, with scientists trying to work out how a phenomenon predicted to have a short range could transmit "over the horizon", led to the discovery of a radio reflecting layer in the Earth's atmosphere in 1902, later called the ionosphere.

Radiotelegraphy proved effective for rescue work in sea disasters by enabling effective communication between ships and from ship to shore. In 1904, Marconi began the first commercial service to transmit nightly news summaries to subscribing ships, which could incorporate them into their on-board newspapers. A regular transatlantic radio-telegraph service was finally begun on 17 October 1907. Notably, Marconi's apparatus was used to help rescue efforts after the sinking of "Titanic". Britain's postmaster-general summed up, referring to the "Titanic" disaster, "Those who have been saved, have been saved through one man, Mr. Marconi...and his marvellous invention."

Around 1965, DARPA commissioned a study of decentralised switching systems. Some of the ideas developed in this study provided inspiration for the development of the ARPANET packet switching research network, which later grew to become the public Internet.

As the PSTN became a digital network, T-carrier "synchronous" networks became commonplace in the U.S. A T1 line has a "frame" of 193 bits that repeats 8000 times per second. The first bit called the "sync" bit alternates between 1 and 0 to identify the start of the frames. The rest of the frame provides 8 bits for each of 24 separate voice or data channels. Customarily, a T-1 link is sent over a balanced twisted pair, isolated with transformers to prevent current flow. Europeans adopted a similar system (E-1) of 32 channels (with one channel for frame synchronisation).

Later, SONET and SDH were adapted to combine carrier channels into groups that could be sent over optic fiber. The capacity of an optic fibre is often extended with wavelength division multiplexing, rather than rerigging new fibre. Rigging several fibres in the same structures as the first fibre is usually easy and inexpensive, and many fibre installations include unused spare "dark fibre", "dark wavelengths", and unused parts of the SONET frame, so-called "virtual channels".

In 2002, the Internet was used by Kevin Warwick at the University of Reading to communicate neural signals, in purely electronic form, telegraphically between the nervous systems of two humans, potentially opening up a new form of communication combining the Internet and telegraphy.

In 2006, a well-defined communication channel used for telegraphy was established by the SONET standard OC-768, which sent about 40 gigabits per second.

The theoretical maximum capacity of an optic fibre is more than 10 bits (one petabit or one quadrillion bits) per second.

Since the Internet operates over any digital transmission medium, further evolution of telegraphic technology will be effectively concealed from users.

E-mail was first invented for CTSS and similar time sharing systems of the era in the mid-1960s. At first, e-mail was possible only between different accounts on the same computer (typically a mainframe). ARPANET allowed different computers to be connected to allow e-mails to be relayed from computer to computer, with the first ARPANET e-mail being sent in 1971. Multics also pioneered instant messaging between computer users in the mid-1970s. With the growth of the Internet, e-mail began to be possible between any two computers with access to the Internet.

Various private networks like UUNET (founded 1987), the Well (1985), and GEnie (1985) had e-mail from the 1970s, but subscriptions were quite expensive for an individual, US$25 to US$50 per month, just for e-mail. Internet use was then largely limited to government, academia, and other government contractors until the net was opened to commercial use in the 1980s.

By the early 1990s, modems made e-mail a viable alternative to Telex systems in a business environment. But individual e-mail accounts were not widely available until local Internet service providers were in place, although demand grew rapidly, as e-mail was seen as the Internet's killer app. It allowed anyone to email anyone, whereas previously, different system had been walled off from each other, such that America Online subscribers could email only other America Online subscribers, Compuserve subscribers could email only other Compuserve subscribers, etc. The broad user base created by the demand for e-mail smoothed the way for the rapid acceptance of the World Wide Web in the mid-1990s. Fax machines were another technology that helped displace the telegram.

On Monday, 12 July 1999, a final telegram was sent from the National Liberty Ship Memorial, the SS "Jeremiah O'Brien", in San Francisco Bay to President Bill Clinton in the White House. Officials of Globe Wireless reported that "The message was 95 words, and it took six or eight minutes to copy it." They then transmitted the message to the White House via e-mail. That event was also used to mark the final commercial U.S. ship-to-shore telegraph message transmitted from North America by Globe Wireless, a company founded in 1911. Sent from its wireless station at Half Moon Bay, California, the sign-off message was a repeat of Samuel F. B. Morse's message 155 years earlier, "What hath God wrought?"

Prior to the electrical telegraph, ancient civilizations, such as Greece, Egypt, and China, transmitted long-distance information using drumbeats, flame beacons, or light flashes with a heliograph. Later, nearly all information was limited to traveling at the speed of a human or animal. The telegraph freed communication from the time constraints of postage and revolutionized the global economy and society. By the end of the 19th century, the telegraph was becoming an increasingly common medium of communication for ordinary people. The telegraph isolated the message (information) from the physical movement of objects or the process.

Telegraphy facilitated the growth of organizations "in the railroads, consolidated financial and commodity markets, and reduced information costs within and between firms". This immense growth in the business sectors influenced society to embrace the use of telegrams.

Worldwide telegraphy changed the gathering of information for news reporting. Messages and information would now travel far and wide, and the telegraph demanded a language "stripped of the local, the regional; and colloquial", to better facilitate a worldwide media language. Media language had to be standardized, which led to the gradual disappearance of different forms of speech and styles of journalism and storytelling.

Numerous newspapers and news outlets in various countries, such as "The Daily Telegraph" in Britain, "The Telegraph" in India, "De Telegraaf" in the Netherlands, and the Jewish Telegraphic Agency in the US, were given names which include the word "telegraph" due to their having received news by means of electric telegraphy. Some of these names are retained even though more sophisticated means are now used.
A newspaper in Indian state of Tamil Nadu is named as Dhina Thanthi which means daily telegraph.

The average length of a telegram in the 1900s in the US was 11.93 words, more than half of the messages were 10 words or fewer.

According to another study, the mean length of the telegrams sent in the UK before 1950 was 14.6 words or 78.8 characters.

For German telegrams, the mean length is 11.5 words or 72.4 characters. At the end of the 19th century, the average length of a German telegram was calculated as 14.2 words.






</doc>
<doc id="30011" url="https://en.wikipedia.org/wiki?curid=30011" title="Transistor">
Transistor

A transistor is a semiconductor device used to amplify or switch electronic signals and electrical power. It is composed of semiconductor material usually with at least three terminals for connection to an external circuit. A voltage or current applied to one pair of the transistor's terminals controls the current through another pair of terminals. Because the controlled (output) power can be higher than the controlling (input) power, a transistor can amplify a signal. Today, some transistors are packaged individually, but many more are found embedded in integrated circuits.

The transistor is the fundamental building block of modern electronic devices, and is ubiquitous in modern electronic systems. Julius Edgar Lilienfeld patented a field-effect transistor in 1926 but it was not possible to actually construct a working device at that time. The first practically implemented device was a point-contact transistor invented in 1947 by American physicists John Bardeen, Walter Brattain, and William Shockley. The transistor revolutionized the field of electronics, and paved the way for smaller and cheaper radios, calculators, and computers, among other things. The transistor is on the list of IEEE milestones in electronics, and Bardeen, Brattain, and Shockley shared the 1956 Nobel Prize in Physics for their achievement.

Most transistors are made from very pure silicon or germanium, but certain other semiconductor materials can also be used. A transistor may have only one kind of charge carrier, in a field effect transistor, or may have two kinds of charge carriers in bipolar junction transistor devices. Compared with the vacuum tube, transistors are generally smaller, and require less power to operate. Certain vacuum tubes have advantages over transistors at very high operating frequencies or high operating voltages. Many types of transistors are made to standardized specifications by multiple manufacturers.

The thermionic triode, a vacuum tube invented in 1907, enabled amplified radio technology and long-distance telephony. The triode, however, was a fragile device that consumed a substantial amount of power. In 1909 physicist William Eccles discovered the crystal diode oscillator. German physicist Julius Edgar Lilienfeld filed a patent for a field-effect transistor (FET) in Canada in 1925, which was intended to be a solid-state replacement for the triode. Lilienfeld also filed identical patents in the United States in 1926 and 1928. However, Lilienfeld did not publish any research articles about his devices nor did his patents cite any specific examples of a working prototype. Because the production of high-quality semiconductor materials was still decades away, Lilienfeld's solid-state amplifier ideas would not have found practical use in the 1920s and 1930s, even if such a device had been built. In 1934, German inventor Oskar Heil patented a similar device in Europe.

From November 17, 1947, to December 23, 1947, John Bardeen and Walter Brattain at AT&T's Bell Labs in Murray Hill, New Jersey of the United States performed experiments and observed that when two gold point contacts were applied to a crystal of germanium, a signal was produced with the output power greater than the input. Solid State Physics Group leader William Shockley saw the potential in this, and over the next few months worked to greatly expand the knowledge of semiconductors. The term "transistor" was coined by John R. Pierce as a contraction of the term "transresistance". According to Lillian Hoddeson and Vicki Daitch, authors of a biography of John Bardeen, Shockley had proposed that Bell Labs' first patent for a transistor should be based on the field-effect and that he be named as the inventor. Having unearthed Lilienfeld’s patents that went into obscurity years earlier, lawyers at Bell Labs advised against Shockley's proposal because the idea of a field-effect transistor that used an electric field as a "grid" was not new. Instead, what Bardeen, Brattain, and Shockley invented in 1947 was the first point-contact transistor. In acknowledgement of this accomplishment, Shockley, Bardeen, and Brattain were jointly awarded the 1956 Nobel Prize in Physics "for their researches on semiconductors and their discovery of the transistor effect".

In 1948, the point-contact transistor was independently invented by German physicists Herbert Mataré and Heinrich Welker while working at the "Compagnie des Freins et Signaux", a Westinghouse subsidiary located in Paris. Mataré had previous experience in developing crystal rectifiers from silicon and germanium in the German radar effort during World War II. Using this knowledge, he began researching the phenomenon of "interference" in 1947. By June 1948, witnessing currents flowing through point-contacts, Mataré produced consistent results using samples of germanium produced by Welker, similar to what Bardeen and Brattain had accomplished earlier in December 1947. Realizing that Bell Labs' scientists had already invented the transistor before them, the company rushed to get its "transistron" into production for amplified use in France's telephone network.

The first bipolar junction transistors were invented by Bell Labs' William Shockley, which applied for patent (2,569,347) on June 26, 1948. On April 12, 1950, Bell Labs chemists Gordon Teal and Morgan Sparks had successfully produced a working bipolar NPN junction amplifying germanium transistor. Bell Labs had made this new "sandwich" transistor discovery announcement, in a press release on July 4, 1951.

The first high-frequency transistor was the surface-barrier germanium transistor developed by Philco in 1953, capable of operating up to . These were made by etching depressions into an N-type germanium base from both sides with jets of Indium(III) sulfate until it was a few ten-thousandths of an inch thick. Indium electroplated into the depressions formed the collector and emitter.

The first "prototype" pocket transistor radio was shown by INTERMETALL (a company founded by Herbert Mataré in 1952) at the "Internationale Funkausstellung Düsseldorf" between August 29, 1953 and September 9, 1953.

The first "production" pocket transistor radio was the Regency TR-1, released in October 1954. Produced as a joint venture between the Regency Division of Industrial Development Engineering Associates, I.D.E.A. and Texas Instruments of Dallas Texas, the TR-1 was manufactured in Indianapolis, Indiana. It was a near pocket-sized radio featuring 4 transistors and one germanium diode. The industrial design was outsourced to the Chicago firm of Painter, Teague and Petertil. It was initially released in one of four different colours: black, bone white, red, and gray. Other colours were to shortly follow. 

The first "production" all-transistor car radio was developed by Chrysler and Philco corporations and it was announced in the April 28th 1955 edition of the Wall Street Journal. Chrysler had made the all-transistor car radio, Mopar model 914HR, available as an option starting in fall 1955 for its new line of 1956 Chrysler and Imperial cars, which first hit the dealership showroom floors on October 21, 1955.

The first working silicon transistor was developed at Bell Labs on January 26, 1954 by Morris Tanenbaum. The first commercial silicon transistor was produced by Texas Instruments in 1954. This was the work of Gordon Teal, an expert in growing crystals of high purity, who had previously worked at Bell Labs. The first MOSFET actually built was by Kahng and Atalla at Bell Labs in 1960.

The transistor is the key active component in practically all modern electronics. Many consider it to be one of the greatest inventions of the 20th century. Its importance in today's society rests on its ability to be mass-produced using a highly automated process (semiconductor device fabrication) that achieves astonishingly low per-transistor costs. The invention of the first transistor at Bell Labs was named an IEEE Milestone in 2009.

Although several companies each produce over a billion individually packaged (known as "discrete") transistors every year,
the vast majority of transistors are now produced in integrated circuits (often shortened to "IC", "microchips" or simply "chips"), along with diodes, resistors, capacitors and other electronic components, to produce complete electronic circuits. A logic gate consists of up to about twenty transistors whereas an advanced microprocessor, as of 2009, can use as many as 3 billion transistors (MOSFETs).
"About 60 million transistors were built in 2002… for [each] man, woman, and child on Earth."

The transistor's low cost, flexibility, and reliability have made it a ubiquitous device. Transistorized mechatronic circuits have replaced electromechanical devices in controlling appliances and machinery. It is often easier and cheaper to use a standard microcontroller and write a computer program to carry out a control function than to design an equivalent mechanical system to control that same function.

The essential usefulness of a transistor comes from its ability to use a small signal applied between one pair of its terminals to control a much larger signal at another pair of terminals. This property is called gain. It can produce a stronger output signal, a voltage or current, which is proportional to a weaker input signal; that is, it can act as an amplifier. Alternatively, the transistor can be used to turn current on or off in a circuit as an electrically controlled switch, where the amount of current is determined by other circuit elements.

There are two types of transistors, which have slight differences in how they are used in a circuit. A "bipolar transistor" has terminals labeled base, collector, and emitter. A small current at the base terminal (that is, flowing between the base and the emitter) can control or switch a much larger current between the collector and emitter terminals. For a "field-effect transistor", the terminals are labeled gate, source, and drain, and a voltage at the gate can control a current between source and drain.

The image represents a typical bipolar transistor in a circuit. Charge will flow between emitter and collector terminals depending on the current in the base. Because internally the base and emitter connections behave like a semiconductor diode, a voltage drop develops between base and emitter while the base current exists. The amount of this voltage depends on the material the transistor is made from, and is referred to as "V".

Transistors are commonly used in digital circuits as electronic switches which can be either in an "on" or "off" state, both for high-power applications such as switched-mode power supplies and for low-power applications such as logic gates. Important parameters for this application include the current switched, the voltage handled, and the switching speed, characterised by the rise and fall times.

In a grounded-emitter transistor circuit, such as the light-switch circuit shown, as the base voltage rises, the emitter and collector currents rise exponentially. The collector voltage drops because of reduced resistance from collector to emitter. If the voltage difference between the collector and emitter were zero (or near zero), the collector current would be limited only by the load resistance (light bulb) and the supply voltage. This is called "saturation" because current is flowing from collector to emitter freely. When saturated, the switch is said to be "on".

Providing sufficient base drive current is a key problem in the use of bipolar transistors as switches. The transistor provides current gain, allowing a relatively large current in the collector to be switched by a much smaller current into the base terminal. The ratio of these currents varies depending on the type of transistor, and even for a particular type, varies depending on the collector current. In the example light-switch circuit shown, the resistor is chosen to provide enough base current to ensure the transistor will be saturated.

In a switching circuit, the idea is to simulate, as near as possible, the ideal switch having the properties of open circuit when off, short circuit when on, and an instantaneous transition between the two states. Parameters are chosen such that the "off" output is limited to leakage currents too small to affect connected circuitry; the resistance of the transistor in the "on" state is too small to affect circuitry; and the transition between the two states is fast enough not to have a detrimental effect.

The common-emitter amplifier is designed so that a small change in voltage ("V") changes the small current through the base of the transistor; the transistor's current amplification combined with the properties of the circuit means that small swings in "V" produce large changes in "V".

Various configurations of single transistor amplifier are possible, with some providing current gain, some voltage gain, and some both.

From mobile phones to televisions, vast numbers of products include amplifiers for sound reproduction, radio transmission, and signal processing. The first discrete-transistor audio amplifiers barely supplied a few hundred milliwatts, but power and audio fidelity gradually increased as better transistors became available and amplifier architecture evolved.

Modern transistor audio amplifiers of up to a few hundred watts are common and relatively inexpensive.

Before transistors were developed, vacuum (electron) tubes (or in the UK "thermionic valves" or just "valves") were the main active components in electronic equipment.

The key advantages that have allowed transistors to replace vacuum tubes in most applications are

Transistors have the following limitations:

Transistors are categorized by

Hence, a particular transistor may be described as "silicon, surface-mount, BJT, n–p–n, low-power, high-frequency switch".

A popular way to remember which symbol represents which type of transistor is to look at the arrow and how it is arranged. Within an NPN transistor symbol, the arrow will Not Point iN. Conversely, within the PNP symbol you see that the arrow Points iN Proudly.

Bipolar transistors are so named because they conduct by using both majority and minority carriers. The bipolar junction transistor, the first type of transistor to be mass-produced, is a combination of two junction diodes, and is formed of either a thin layer of p-type semiconductor sandwiched between two n-type semiconductors (an n–p–n transistor), or a thin layer of n-type semiconductor sandwiched between two p-type semiconductors (a p–n–p transistor). This construction produces two p–n junctions: a base–emitter junction and a base–collector junction, separated by a thin region of semiconductor known as the base region (two junction diodes wired together without sharing an intervening semiconducting region will not make a transistor).

BJTs have three terminals, corresponding to the three layers of semiconductor—an "emitter", a "base", and a "collector". They are useful in amplifiers because the currents at the emitter and collector are controllable by a relatively small base current. In an n–p–n transistor operating in the active region, the emitter–base junction is forward biased (electrons and holes recombine at the junction), and the base-collector junction is reverse biased (electrons and holes are formed at, and move away from the junction), and electrons are injected into the base region. Because the base is narrow, most of these electrons will diffuse into the reverse-biased base–collector junction and be swept into the collector; perhaps one-hundredth of the electrons will recombine in the base, which is the dominant mechanism in the base current. By controlling the number of electrons that can leave the base, the number of electrons entering the collector can be controlled. Collector current is approximately β (common-emitter current gain) times the base current. It is typically greater than 100 for small-signal transistors but can be smaller in transistors designed for high-power applications.

Unlike the field-effect transistor (see below), the BJT is a low-input-impedance device. Also, as the base–emitter voltage ("V") is increased the base–emitter current and hence the collector–emitter current ("I") increase exponentially according to the Shockley diode model and the Ebers-Moll model. Because of this exponential relationship, the BJT has a higher transconductance than the FET.

Bipolar transistors can be made to conduct by exposure to light, because absorption of photons in the base region generates a photocurrent that acts as a base current; the collector current is approximately β times the photocurrent. Devices designed for this purpose have a transparent window in the package and are called phototransistors.

The "field-effect transistor", sometimes called a "unipolar transistor", uses either electrons (in "n-channel FET") or holes (in "p-channel FET") for conduction. The four terminals of the FET are named "source", "gate", "drain", and "body" ("substrate"). On most FETs, the body is connected to the source inside the package, and this will be assumed for the following description.

In a FET, the drain-to-source current flows via a conducting channel that connects the "source" region to the "drain" region. The conductivity is varied by the electric field that is produced when a voltage is applied between the gate and source terminals; hence the current flowing between the drain and source is controlled by the voltage applied between the gate and source. As the gate–source voltage ("V") is increased, the drain–source current ("I") increases exponentially for "V" below threshold, and then at a roughly quadratic rate ("I" ∝ ("V" − "V")) (where "V" is the threshold voltage at which drain current begins) in the "space-charge-limited" region above threshold. A quadratic behavior is not observed in modern devices, for example, at the 65 nm technology node.

For low noise at narrow bandwidth the higher input resistance of the FET is advantageous.

FETs are divided into two families: "junction FET" (JFET) and "insulated gate FET" (IGFET). The IGFET is more commonly known as a "metal–oxide–semiconductor FET" (MOSFET), reflecting its original construction from layers of metal (the gate), oxide (the insulation), and semiconductor. Unlike IGFETs, the JFET gate forms a p–n diode with the channel which lies between the source and drain. Functionally, this makes the n-channel JFET the solid-state equivalent of the vacuum tube triode which, similarly, forms a diode between its grid and cathode. Also, both devices operate in the "depletion mode", they both have a high input impedance, and they both conduct current under the control of an input voltage.

Metal–semiconductor FETs (MESFETs) are JFETs in which the reverse biased p–n junction is replaced by a metal–semiconductor junction. These, and the HEMTs (high-electron-mobility transistors, or HFETs), in which a two-dimensional electron gas with very high carrier mobility is used for charge transport, are especially suitable for use at very high frequencies (microwave frequencies; several GHz).

FETs are further divided into "depletion-mode" and "enhancement-mode" types, depending on whether the channel is turned on or off with zero gate-to-source voltage. For enhancement mode, the channel is off at zero bias, and a gate potential can "enhance" the conduction. For the depletion mode, the channel is on at zero bias, and a gate potential (of the opposite polarity) can "deplete" the channel, reducing conduction. For either mode, a more positive gate voltage corresponds to a higher current for n-channel devices and a lower current for p-channel devices. Nearly all JFETs are depletion-mode because the diode junctions would forward bias and conduct if they were enhancement-mode devices;
most IGFETs are enhancement-mode types.

The bipolar junction transistor (BJT) was the most commonly used transistor in the 1960s and 70s. Even after MOSFETs became widely available, the BJT remained the transistor of choice for many analog circuits such as amplifiers because of their greater linearity and ease of manufacture. In integrated circuits, the desirable properties of MOSFETs allowed them to capture nearly all market share for digital circuits. Discrete MOSFETs can be applied in transistor applications, including analog circuits, voltage regulators, amplifiers, power transmitters and motor drivers.


The types of some transistors can be parsed from the part number. There are three major semiconductor naming standards; in each the alphanumeric prefix provides clues to type of the device.

The "JIS-C-7012" specification for transistor part numbers starts with "2S", e.g. 2SD965, but sometimes the "2S" prefix is not marked on the package – a 2SD965 might only be marked "D965"; a 2SC1815 might be listed by a supplier as simply "C1815". This series sometimes has suffixes (such as "R", "O", "BL", standing for "red", "orange", "blue", etc.) to denote variants, such as tighter "h" (gain) groupings.

The Pro Electron standard, the European Electronic Component Manufacturers Association part numbering scheme, begins with two letters: the first gives the semiconductor type (A for germanium, B for silicon, and C for materials like GaAs); the second letter denotes the intended use (A for diode, C for general-purpose transistor, etc.). A 3-digit sequence number (or one letter then two digits, for industrial types) follows. With early devices this indicated the case type. Suffixes may be used, with a letter (e.g. "C" often means high "h", such as in: BC549C) or other codes may follow to show gain (e.g. BC327-25) or voltage rating (e.g. BUK854-800A). The more common prefixes are:

The JEDEC "EIA370" transistor device numbers usually start with "2N", indicating a three-terminal device (dual-gate field-effect transistors are four-terminal devices, so begin with 3N), then a 2, 3 or 4-digit sequential number with no significance as to device properties (although early devices with low numbers tend to be germanium). For example, 2N3055 is a silicon n–p–n power transistor, 2N1301 is a p–n–p germanium switching transistor. A letter suffix (such as "A") is sometimes used to indicate a newer variant, but rarely gain groupings.

Manufacturers of devices may have their own proprietary numbering system, for example CK722. Since devices are second-sourced, a manufacturer's prefix (like "MPF" in MPF102, which originally would denote a Motorola FET) now is an unreliable indicator of who made the device. Some proprietary naming schemes adopt parts of other naming schemes, for example a PN2222A is a (possibly Fairchild Semiconductor) 2N2222A in a plastic case (but a PN108 is a plastic version of a BC108, not a 2N108, while the PN100 is unrelated to other xx100 devices).

Military part numbers sometimes are assigned their own codes, such as the British Military CV Naming System.

Manufacturers buying large numbers of similar parts may have them supplied with "house numbers", identifying a particular purchasing specification and not necessarily a device with a standardized registered number. For example, an HP part 1854,0053 is a (JEDEC) 2N2218 transistor which is also assigned the CV number: CV7763

With so many independent naming schemes, and the abbreviation of part numbers when printed on the devices, ambiguity sometimes occurs. For example, two different devices may be marked "J176" (one the J176 low-power JFET, the other the higher-powered MOSFET 2SJ176).

As older "through-hole" transistors are given surface-mount packaged counterparts, they tend to be assigned many different part numbers because manufacturers have their own systems to cope with the variety in pinout arrangements and options for dual or matched n–p–n + p–n–p devices in one pack. So even when the original device (such as a 2N3904) may have been assigned by a standards authority, and well known by engineers over the years, the new versions are far from standardized in their naming.

The first BJTs were made from germanium (Ge). Silicon (Si) types currently predominate but certain advanced microwave and high-performance versions now employ the "compound semiconductor" material gallium arsenide (GaAs) and the "semiconductor alloy" silicon germanium (SiGe). Single element semiconductor material (Ge and Si) is described as "elemental".

Rough parameters for the most common semiconductor materials used to make transistors are given in the adjacent table; these parameters will vary with increase in temperature, electric field, impurity level, strain, and sundry other factors.

The "junction forward voltage" is the voltage applied to the emitter–base junction of a BJT in order to make the base conduct a specified current. The current increases exponentially as the junction forward voltage is increased. The values given in the table are typical for a current of 1 mA (the same values apply to semiconductor diodes). The lower the junction forward voltage the better, as this means that less power is required to "drive" the transistor. The junction forward voltage for a given current decreases with increase in temperature. For a typical silicon junction the change is −2.1 mV/°C. In some circuits special compensating elements (sensistors) must be used to compensate for such changes.

The density of mobile carriers in the channel of a MOSFET is a function of the electric field forming the channel and of various other phenomena such as the impurity level in the channel. Some impurities, called dopants, are introduced deliberately in making a MOSFET, to control the MOSFET electrical behavior.

The "electron mobility" and "hole mobility" columns show the average speed that electrons and holes diffuse through the semiconductor material with an electric field of 1 volt per meter applied across the material. In general, the higher the electron mobility the faster the transistor can operate. The table indicates that Ge is a better material than Si in this respect. However, Ge has four major shortcomings compared to silicon and gallium arsenide:
Because the electron mobility is higher than the hole mobility for all semiconductor materials, a given bipolar n–p–n transistor tends to be swifter than an equivalent p–n–p transistor. GaAs has the highest electron mobility of the three semiconductors. It is for this reason that GaAs is used in high-frequency applications. A relatively recent FET development, the "high-electron-mobility transistor" (HEMT), has a heterostructure (junction between different semiconductor materials) of aluminium gallium arsenide (AlGaAs)-gallium arsenide (GaAs) which has twice the electron mobility of a GaAs-metal barrier junction. Because of their high speed and low noise, HEMTs are used in satellite receivers working at frequencies around 12 GHz. HEMTs based on gallium nitride and aluminium gallium nitride (AlGaN/GaN HEMTs) provide a still higher electron mobility and are being developed for various applications.

Max. junction temperature values represent a cross section taken from various manufacturers' data sheets. This temperature should not be exceeded or the transistor may be damaged.

Al–Si junction refers to the high-speed (aluminum–silicon) metal–semiconductor barrier diode, commonly known as a Schottky diode. This is included in the table because some silicon power IGFETs have a "parasitic" reverse Schottky diode formed between the source and drain as part of the fabrication process. This diode can be a nuisance, but sometimes it is used in the circuit.

Discrete transistors can be individually packaged transistors or unpackaged transisor chips (dice). 

Transistors come in many different semiconductor packages (see image). The two main categories are "through-hole" (or "leaded"), and "surface-mount", also known as "surface-mount device" (SMD). The "ball grid array" (BGA) is the latest surface-mount package (currently only for large integrated circuits). It has solder "balls" on the underside in place of leads. Because they are smaller and have shorter interconnections, SMDs have better high-frequency characteristics but lower power rating.

Transistor packages are made of glass, metal, ceramic, or plastic. The package often dictates the power rating and frequency characteristics. Power transistors have larger packages that can be clamped to heat sinks for enhanced cooling. Additionally, most power transistors have the collector or drain physically connected to the metal enclosure. At the other extreme, some surface-mount "microwave" transistors are as small as grains of sand.

Often a given transistor type is available in several packages. Transistor packages are mainly standardized, but the assignment of a transistor's functions to the terminals is not: other transistor types can assign other functions to the package's terminals. Even for the same transistor type the terminal assignment can vary (normally indicated by a suffix letter to the part number, q.e. BC212L and BC212K).

Nowadays most transistors come in a wide range of SMT packages, in comparison the list of available through-hole packages is relatively small, here is a short list of the most common through-hole transistors packages in alphabetical order:
ATV, E-line, MRT, HRT, SC-43, SC-72, TO-3, TO-18, TO-39, TO-92, TO-126, TO220, TO247, TO251, TO262, ZTX851.

Unpackaged transistor chips (die) may be assembled into hybrid devices. The IBM SLT module of the 1960s is one example of such a hybrid circuit module using glass passivated transistor (and diode) die. Other packaging techniques for discrete transistors as chips include Direct Chip Attach (DCA) and Chip On Board (COB).

Researchers have made several kinds of flexible transistors, including organic field-effect transistors. Flexible transistors are useful in some kinds of flexible displays and other flexible electronics.







</doc>
<doc id="30012" url="https://en.wikipedia.org/wiki?curid=30012" title="Time">
Time

Time is the indefinite continued progress of existence and events that occur in apparently irreversible succession from the past through the present to the future. Time is a component quantity of various measurements used to sequence events, to compare the duration of events or the intervals between them, and to quantify rates of change of quantities in material reality or in the conscious experience. Time is often referred to as a fourth dimension, along with three spatial dimensions.

Time has long been an important subject of study in religion, philosophy, and science, but defining it in a manner applicable to all fields without circularity has consistently eluded scholars.
Nevertheless, diverse fields such as business, industry, sports, the sciences, and the performing arts all incorporate some notion of time into their respective measuring systems.

Time in physics is unambiguously operationally defined as "what a clock reads". See Units of Time. Time is one of the seven fundamental physical quantities in both the International System of Units and International System of Quantities. Time is used to define other quantities – such as velocity – so defining time in terms of such quantities would result in circularity of definition. An operational definition of time, wherein one says that observing a certain number of repetitions of one or another standard cyclical event (such as the passage of a free-swinging pendulum) constitutes one standard unit such as the second, is highly useful in the conduct of both advanced experiments and everyday affairs of life. The operational definition leaves aside the question whether there is something called time, apart from the counting activity just mentioned, that flows and that can be measured. Investigations of a single continuum called spacetime bring questions about space into questions about time, questions that have their roots in the works of early students of natural philosophy.

Temporal measurement has occupied scientists and technologists, and was a prime motivation in navigation and astronomy. Periodic events and periodic motion have long served as standards for units of time. Examples include the apparent motion of the sun across the sky, the phases of the moon, the swing of a pendulum, and the beat of a heart. Currently, the international unit of time, the second, is defined by measuring the electronic transition frequency of caesium atoms (see below). Time is also of significant social importance, having economic value ("time is money") as well as personal value, due to an awareness of the limited time in each day and in human life spans.

Generally speaking, methods of temporal measurement, or chronometry, take two distinct forms: the calendar, a mathematical tool for organising intervals of time,
and the clock, a physical mechanism that counts the passage of time. In day-to-day life, the clock is consulted for periods less than a day whereas the calendar is consulted for periods longer than a day. Increasingly, personal electronic devices display both calendars and clocks simultaneously. The number (as on a clock dial or calendar) that marks the occurrence of a specified event as to hour or date is obtained by counting from a fiducial epoch – a central reference point.

Artifacts from the Paleolithic suggest that the moon was used to reckon time as early as 6,000 years ago.
Lunar calendars were among the first to appear, either 12 or 13 lunar months (either 354 or 384 days). Without intercalation to add days or months to some years, seasons quickly drift in a calendar based solely on twelve lunar months. Lunisolar calendars have a thirteenth month added to some years to make up for the difference between a full year (now known to be about 365.24 days) and a year of just twelve lunar months. The numbers twelve and thirteen came to feature prominently in many cultures, at least partly due to this relationship of months to years. Other early forms of calendars originated in Mesoamerica, particularly in ancient Mayan civilization. These calendars were religiously and astronomically based, with 18 months in a year and 20 days in a month, plus five epagomenal days at the end of the year.

The reforms of Julius Caesar in 45 BC put the Roman world on a solar calendar. This Julian calendar was faulty in that its intercalation still allowed the astronomical solstices and equinoxes to advance against it by about 11 minutes per year. Pope Gregory XIII introduced a correction in 1582; the Gregorian calendar was only slowly adopted by different nations over a period of centuries, but it is now the most commonly used calendar around the world, by far.

During the French Revolution, a new clock and calendar were invented in attempt to de-Christianize time and create a more rational system in order to replace the Gregorian calendar. The French Republican Calendar's days consisted of ten hours of a hundred minutes of a hundred seconds, which marked a deviation from the 12-based duodecimal system used in many other devices by many cultures. The system was later abolished in 1806.

A large variety of devices have been invented to measure time. The study of these devices is called horology.

An Egyptian device that dates to c.1500 BC, similar in shape to a bent T-square, measured the passage of time from the shadow cast by its crossbar on a nonlinear rule. The T was oriented eastward in the mornings. At noon, the device was turned around so that it could cast its shadow in the evening direction.

A sundial uses a gnomon to cast a shadow on a set of markings calibrated to the hour. The position of the shadow marks the hour in local time. The idea to separate the day into smaller parts is credited to Egyptians because of their sundials, which operated on a duodecimal system. The importance of the number 12 is due the number of lunar cycles in a year and the number of stars used to count the passage of night.

The most precise timekeeping device of the ancient world was the water clock, or "clepsydra", one of which was found in the tomb of Egyptian pharaoh Amenhotep I (1525–1504 BC). They could be used to measure the hours even at night, but required manual upkeep to replenish the flow of water. The Ancient Greeks and the people from Chaldea (southeastern Mesopotamia) regularly maintained timekeeping records as an essential part of their astronomical observations. Arab inventors and engineers in particular made improvements on the use of water clocks up to the Middle Ages.
In the 11th century, Chinese inventors and engineers invented the first mechanical clocks driven by an escapement mechanism.
The hourglass uses the flow of sand to measure the flow of time. They were used in navigation. Ferdinand Magellan used 18 glasses on each ship for his circumnavigation of the globe (1522).
Incense sticks and candles were, and are, commonly used to measure time in temples and churches across the globe. Waterclocks, and later, mechanical clocks, were used to mark the events of the abbeys and monasteries of the Middle Ages. Richard of Wallingford (1292–1336), abbot of St. Alban's abbey, famously built a mechanical clock as an astronomical orrery about 1330.
Great advances in accurate time-keeping were made by Galileo Galilei and especially Christiaan Huygens with the invention of pendulum driven clocks along with the invention of the minute hand by Jost Burgi.

The English word clock probably comes from the Middle Dutch word "klocke" which, in turn, derives from the medieval Latin word "clocca", which ultimately derives from Celtic and is cognate with French, Latin, and German words that mean bell. The passage of the hours at sea were marked by bells, and denoted the time (see ship's bell). The hours were marked by bells in abbeys as well as at sea.
Clocks can range from watches, to more exotic varieties such as the Clock of the Long Now. They can be driven by a variety of means, including gravity, springs, and various forms of electrical power, and regulated by a variety of means such as a pendulum.

Alarm clocks first appeared in ancient Greece around 250 BC with a water clock that would set off a whistle. This idea was later mechanized by Levi Hutchins and Seth E. Thomas.

A chronometer is a portable timekeeper that meets certain precision standards. Initially, the term was used to refer to the marine chronometer, a timepiece used to determine longitude by means of celestial navigation, a precision firstly achieved by John Harrison. More recently, the term has also been applied to the chronometer watch, a watch that meets precision standards set by the Swiss agency COSC.

The most accurate timekeeping devices are atomic clocks, which are accurate to seconds in many millions of years,
and are used to calibrate other clocks and timekeeping instruments.
Atomic clocks use the frequency of electronic transitions in certain atoms to measure the second. One of the most common atoms used is caesium, most modern atomic clocks probe caesium with microwaves to determine the frequency of these electron vibrations. Since 1967, the International System of Measurements bases its unit of time, the second, on the properties of caesium atoms. SI defines the second as 9,192,631,770 cycles of the radiation that corresponds to the transition between two electron spin energy levels of the ground state of the Cs atom.

Today, the Global Positioning System in coordination with the Network Time Protocol can be used to synchronize timekeeping systems across the globe.
In medieval philosophical writings, the atom was a unit of time referred to as the smallest possible division of time. The earliest known occurrence in English is in Byrhtferth's "Enchiridion" (a science text) of 1010–1012, where it was defined as 1/564 of a "momentum" (1½ minutes), and thus equal to 15/94 of a second. It was used in the "computus", the process of calculating the date of Easter.

, the smallest time interval uncertainty in direct measurements is on the order of 12 attoseconds (1.2 × 10 seconds), about 3.7 × 10 Planck times.

The second (s) is the SI base unit. A minute (min) is 60 seconds in length, and an hour is 60 minutes in length. A day is 24 hours or 86,400 seconds in length.

The Mean Solar Time system defines the second as 1/86,400 of the mean solar day, which is the year-average of the solar day. The solar day is the time interval between two successive solar noons, i.e., the time interval between two successive passages of the Sun across the local meridian. The local meridian is an imaginary line that runs from celestial north pole to celestial south pole passing directly over the head of the observer. At the local meridian the Sun reaches its highest point on its daily arc across the sky.

In 1874 the British Association for the Advancement of Science introduced the CGS (centimetre/gramme/second system) combining fundamental units of length, mass and time. The second is "elastic", because tidal friction is slowing the earth's rotation rate. For use in calculating ephemerides of celestial motion, therefore, in 1952 astronomers introduced the "ephemeris second", currently defined as

The CGS system has been superseded by the "Système international". The SI base unit for time is the SI second. The International System of Quantities, which incorporates the SI, also defines larger units of time equal to fixed integer multiples of one second (1 s), such as the minute, hour and day. These are not part of the SI, but may be used alongside the SI. Other units of time such as the month and the year are not equal to fixed multiples of 1 s, and instead exhibit significant variations in duration.

The official SI definition of the second is as follows:

At its 1997 meeting, the CIPM affirmed that this definition refers to a caesium atom in its ground state at a temperature of 0 K.

The current definition of the second, coupled with the current definition of the metre, is based on the special theory of relativity, which affirms our spacetime to be a Minkowski space. The definition of the second in mean solar time, however, is unchanged.

While in theory, the concept of a single worldwide universal time-scale may have been conceived of many centuries ago, in practicality the technical ability to create and maintain such a time-scale did not become possible until the mid-19th century. The timescale adopted was Greenwich Mean Time, created in 1847. A few countries have replaced it with Coordinated Universal Time, UTC.

With the advent of the industrial revolution, a greater understanding and agreement on the nature of time itself became increasingly necessary and helpful. In 1847 in Britain, Greenwich Mean Time (GMT) was first created for use by the British railways, the British navy, and the British shipping industry. Using telescopes, GMT was calibrated to the mean solar time at the Royal Observatory, Greenwich in the UK.

As international commerce continued to increase throughout Europe, in order to achieve a more efficiently functioning modern society, an agreed upon, and highly accurate international standard of time measurement became necessary. In order to find or determine such a time-standard, three steps had to be followed:

The development of what is now known as UTC time came about historically as an effort which first began as a collaboration between 41 nations, officially agreed to and signed at the International Meridian Conference, in Washington D.C. in 1884. At this conference, the local mean solar time at the Royal Observatory, Greenwich in England was chosen to define the "universal day", counted from 0 hours at Greenwich mean midnight. This agreed with the civil Greenwich Mean Time used on the island of Great Britain since 1847. In contrast astronomical GMT began at mean noon, i.e. astronomical day "X" began at noon of civil day "X". The purpose of this was to keep one night's observations under one date. The civil system was adopted as of 0 hours (civil) 1 January 1925. Nautical GMT began 24 hours before astronomical GMT, at least until 1805 in the Royal Navy, but persisted much later elsewhere because it was mentioned at the 1884 conference. In 1884, the Greenwich meridian was used for two-thirds of all charts and maps as their Prime Meridian.

Among the 41 nations represented at the conference, the advanced time-technologies that had already come into use in Britain were fundamental components of the agreed upon method of arriving at a universal and agreed upon international time. In 1928 Greenwich Mean Time was rebranded for scientific purposes by the International Astronomical Union as Universal Time (UT). This was to avoid confusion with the previous system where the day had begun at noon. As the general public had always begun the day at midnight the timescale continued to be presented to them as Greenwich Mean Time. By 1956, universal time had been split into various versions – UT2, which smoothed for polar motion and seasonal effects, was presented to the public as Greenwich Mean Time. Later, UT1 (which smooths only for polar motion) became the default form of UT used by astronomers and hence the form used in navigation, sunrise and sunset and moonrise and moonset tables where the name Greenwich Mean Time continues to be employed. Greenwich Mean Time is also the preferred method of describing the timescale used by legislators. Even to the present day, UT is still based on an international telescopic system. Observations at the Greenwich Observatory itself ceased in 1954, though the location is still used as the basis for the coordinate system. Because the rotational period of Earth is not perfectly constant, the duration of a second would vary if calibrated to a telescope-based standard like GMT, where the second is defined as 1/86 400 of the mean solar day.

For the better part of the first century following the "International Meridian Conference," until 1960, the methods and definitions of time-keeping that had been laid out at the conference proved to be adequate to meet time tracking needs of science. Still, with the advent of the "electronic revolution" in the latter half of the 20th century, the technologies that had been available at the time of the Convention of the Metre proved to be in need of further refinement in order to meet the needs of the ever-increasing precision that the "electronic revolution" had begun to require.

An invariable second (the "ephemeris second") had been defined, use of which removed the errors in ephemerides resulting from the use of the variable mean solar second as the time argument. In 1960 this ephemeris second was made the basis of the "coordinated universal time" which was being derived from atomic clocks. It is a specified fraction of the mean tropical year as at 1900 and, being based on historical telescope observations, corresponds roughly to the mean solar second of the early nineteenth century.

In 1967 a further step was taken with the introduction of the SI second, essentially the ephemeris second as measured by atomic clocks and formally defined in atomic terms.
The SI second (Standard Internationale second) is based directly on the measurement of the atomic-clock observation of the frequency oscillation of caesium atoms. It is the basis of all atomic timescales, e.g. coordinated universal time, GPS time, International Atomic Time, etc. Atomic clocks do not measure nuclear decay rates, which is a common misconception, but rather measure a certain natural vibrational frequency of caesium-133. Coordinated universal time is subject to one constraint which does not affect the other atomic timescales. As it has been adopted as the civil timescale by some countries (most countries have opted to retain mean solar time) it is not permitted to deviate from GMT by more than 0.9 second. This is achieved by the occasional insertion of a leap second.

Most countries use mean solar time. Australia, Canada (Quebec only), Colombia, France, Germany, New Zealand, Papua New Guinea (Bougainville only), Paraguay, Portugal, Switzerland, the United States and Venezuela use UTC. However, UTC is widely used by the scientific community in countries where mean solar time is official. UTC time is based on the SI second, which was first defined in 1967, and is based on the use of atomic clocks. Some other less used but closely related time-standards include International Atomic Time (TAI), Terrestrial Time, and Barycentric Dynamical Time.

Between 1967 and 1971, UTC was periodically adjusted by fractional amounts of a second in order to adjust and refine for variations in mean solar time, with which it is aligned. After 1 January 1972, UTC time has been defined as being offset from atomic time by a whole number of seconds, changing only when a leap second is added to keep radio-controlled clocks synchronized with the rotation of the Earth.

The Global Positioning System also broadcasts a very precise time signal worldwide, along with instructions for converting GPS time to UTC. GPS-time is based on, and regularly synchronized with or from, UTC-time.

Earth is split up into a number of time zones. Most time zones are exactly one hour apart, and by convention compute their local time as an offset from GMT. For example, time zones at sea are based on GMT. In many locations (but not at sea) these offsets vary twice yearly due to daylight saving time transitions.

These conversions are accurate at the millisecond level for time systems involving earth rotation (UT1 & TT). Conversions between atomic time systems (TAI, GPS, and UTC) are accurate at the microsecond level.

Definitions:

Unlike solar time, which is relative to the apparent position of the Sun, sidereal time is the measurement of time relative to that of a distant star. In astronomy, sidereal time is used to predict when a star will reach its highest point in the sky. Due to Earth's orbital motion around the Sun, a mean solar day is about 3 minutes 56 seconds longer than a mean sidereal day, or more than a mean sidereal day.

Another form of time measurement consists of studying the past. Events in the past can be ordered in a sequence (creating a chronology), and can be put into chronological groups (periodization). One of the most important systems of periodization is the geologic time scale, which is a system of periodizing the events that shaped the Earth and its life. Chronology, periodization, and interpretation of the past are together known as the study of history.

The term "time" is generally used for many close but different concepts, including:

Ancient cultures such as Incan, Mayan, Hopi, and other Native American Tribes – plus the Babylonians, Ancient Greeks, Hinduism, Buddhism, Jainism, and others – have a concept of a wheel of time: they regard time as cyclical and quantic, consisting of repeating ages that happen to every being of the Universe between birth and extinction.

In general, the Islamic and Judeo-Christian world-view regards time as linear
and directional,
beginning with the act of creation by God. The traditional Christian view sees time ending, teleologically,
with the eschatological end of the present order of things, the "end time".

In the Old Testament book Ecclesiastes, traditionally ascribed to Solomon (970–928 BC), time (as the Hebrew word עידן, זמן "`iddan(age, as in "Ice age") zĕman(time)" is often translated) was traditionally regarded as a medium for the passage of predestined events. (Another word, زمان" זמן" "zamān", meant "time fit for an event", and is used as the modern Arabic, Persian, and Hebrew equivalent to the English word "time".)
The Greek language denotes two distinct principles, Chronos and Kairos. The former refers to numeric, or chronological, time. The latter, literally "the right or opportune moment", relates specifically to metaphysical or Divine time. In theology, Kairos is qualitative, as opposed to quantitative.

In Greek mythology, Chronos (Ancient Greek: Χρόνος) is identified as the Personification of Time. His name in Greek means "time" and is alternatively spelled Chronus (Latin spelling) or Khronos. Chronos is usually portrayed as an old, wise man with a long, gray beard, such as "Father Time". Some English words whose etymological root is khronos/chronos include "chronology", "chronometer", "chronic", "anachronism", "synchronise", and "chronicle".

According to Kabbalists, "time" is a paradox and an illusion. Both the future and the past are recognised to be combined and simultaneously present.

Two contrasting viewpoints on time divide prominent philosophers. One view is that time is part of the fundamental structure of the universe – a dimension independent of events, in which events occur in sequence. Isaac Newton subscribed to this realist view, and hence it is sometimes referred to as Newtonian time.
The opposing view is that "time" does not refer to any kind of "container" that events and objects "move through", nor to any entity that "flows", but that it is instead part of a fundamental intellectual structure (together with space and number) within which humans sequence and compare events. This second view, in the tradition of Gottfried Leibniz and Immanuel Kant, holds that "time" is neither an event nor a thing, and thus is not itself measurable nor can it be travelled.

Furthermore, it may be that there is a subjective component to time, but whether or not time itself is "felt", as a sensation, or is a judgment, is a matter of debate.

The "Vedas", the earliest texts on Indian philosophy and Hindu philosophy dating back to the late 2nd millennium BC, describe ancient Hindu cosmology, in which the universe goes through repeated cycles of creation, destruction and rebirth, with each cycle lasting 4,320 million years.
Ancient Greek philosophers, including Parmenides and Heraclitus, wrote essays on the nature of time.
Plato, in the "Timaeus", identified time with the period of motion of the heavenly bodies. Aristotle, in Book IV of his "Physica" defined time as 'number of movement in respect of the before and after'.

In Book 11 of his "Confessions", St. Augustine of Hippo ruminates on the nature of time, asking, "What then is time? If no one asks me, I know: if I wish to explain it to one that asketh, I know not." He begins to define time by what it is not rather than what it is,
an approach similar to that taken in other negative definitions. However, Augustine ends up calling time a "distention" of the mind (Confessions 11.26) by which we simultaneously grasp the past in memory, the present by attention, and the future by expectation.

This view is shared by Abrahamic faiths as they believe time started by creation, therefore the only thing being infinite is God and everything else, including time, is finite.

Isaac Newton believed in absolute space and absolute time; Leibniz believed that time and space are relational.
The differences between Leibniz's and Newton's interpretations came to a head in the famous Leibniz–Clarke correspondence.
Immanuel Kant, in the "Critique of Pure Reason", described time as an "a priori" intuition that allows us (together with the other "a priori" intuition, space) to comprehend sense experience.
With Kant, neither space nor time are conceived as substances, but rather both are elements of a systematic mental framework that necessarily structures the experiences of any rational agent, or observing subject. Kant thought of time as a fundamental part of an abstract conceptual framework, together with space and number, within which we sequence events, quantify their duration, and compare the motions of objects. In this view, "time" does not refer to any kind of entity that "flows," that objects "move through," or that is a "container" for events. Spatial measurements are used to quantify the extent of and distances between objects, and temporal measurements are used to quantify the durations of and between events. Time was designated by Kant as the purest possible schema of a pure concept or category.

Henri Bergson believed that time was neither a real homogeneous medium nor a mental construct, but possesses what he referred to as "Duration". Duration, in Bergson's view, was creativity and memory as an essential component of reality.

According to Martin Heidegger we do not exist inside time, we "are" time. Hence, the relationship to the past is a present awareness of "having been", which allows the past to exist in the present. The relationship to the future is the state of anticipating a potential possibility, task, or engagement. It is related to the human propensity for caring and being concerned, which causes "being ahead of oneself" when thinking of a pending occurrence. Therefore, this concern for a potential occurrence also allows the future to exist in the present. The present becomes an experience, which is qualitative instead of quantitative. Heidegger seems to think this is the way that a linear relationship with time, or temporal existence, is broken or transcended.
We are not stuck in sequential time. We are able to remember the past and project into the future – we have a kind of random access to our representation of temporal existence; we can, in our thoughts, step out of (ecstasis) sequential time.

In 5th century BC Greece, Antiphon the Sophist, in a fragment preserved from his chief work "On Truth", held that: ""Time is not a reality (hypostasis), but a concept (noêma) or a measure (metron).""
Parmenides went further, maintaining that time, motion, and change were illusions, leading to the paradoxes of his follower Zeno.
Time as an illusion is also a common theme in Buddhist thought.

J. M. E. McTaggart's 1908 "The Unreality of Time" argues that, since every event has the characteristic of being both present and not present (i.e., future or past), that time is a self-contradictory idea (see also The flow of time).

These arguments often center on what it means for something to be "unreal". Modern physicists generally believe that time is as "real" as space – though others, such as Julian Barbour in his book "The End of Time", argue that quantum equations of the universe take their true form when expressed in the timeless realm containing every possible "now" or momentary configuration of the universe, called 'platonia' by Barbour.

A modern philosophical theory called presentism views the past and the future as human-mind interpretations of movement instead of real parts of time (or "dimensions") which coexist with the present. This theory rejects the existence of all direct interaction with the past or the future, holding only the present as tangible. This is one of the philosophical arguments against time travel. This contrasts with eternalism (all time: present, past and future, is real) and the growing block theory (the present and the past are real, but the future is not).

Until Einstein's reinterpretation of the physical concepts associated with time and space, time was considered to be the same everywhere in the universe, with all observers measuring the same time interval for any event.
Non-relativistic classical mechanics is based on this Newtonian idea of time.

Einstein, in his special theory of relativity,
postulated the constancy and finiteness of the speed of light for all observers. He showed that this postulate, together with a reasonable definition for what it means for two events to be simultaneous, requires that distances appear compressed and time intervals appear lengthened for events associated with objects in motion relative to an inertial observer.

The theory of special relativity finds a convenient formulation in Minkowski spacetime, a mathematical structure that combines three dimensions of space with a single dimension of time. In this formalism, distances in space can be measured by how long light takes to travel that distance, e.g., a light-year is a measure of distance, and a meter is now defined in terms of how far light travels in a certain amount of time. Two events in Minkowski spacetime are separated by an "invariant interval", which can be either space-like, light-like, or time-like. Events that have a time-like separation cannot be simultaneous in any frame of reference, there must be a temporal component (and possibly a spatial one) to their separation. Events that have a space-like separation will be simultaneous in some frame of reference, and there is no frame of reference in which they do not have a spatial separation. Different observers may calculate different distances and different time intervals between two events, but the "invariant interval" between the events is independent of the observer (and his or her velocity).

In non-relativistic classical mechanics, Newton's concept of "relative, apparent, and common time" can be used in the formulation of a prescription for the synchronization of clocks. Events seen by two different observers in motion relative to each other produce a mathematical concept of time that works sufficiently well for describing the everyday phenomena of most people's experience. In the late nineteenth century, physicists encountered problems with the classical understanding of time, in connection with the behavior of electricity and magnetism. Einstein resolved these problems by invoking a method of synchronizing clocks using the constant, finite speed of light as the maximum signal velocity. This led directly to the result that observers in motion relative to one another measure different elapsed times for the same event.

Time has historically been closely related with space, the two together merging into spacetime in Einstein's special relativity and general relativity. According to these theories, the concept of time depends on the spatial reference frame of the observer, and the human perception as well as the measurement by instruments such as clocks are different for observers in relative motion. For example, if a spaceship carrying a clock flies through space at (very nearly) the speed of light, its crew does not notice a change in the speed of time on board their vessel because everything traveling at the same speed slows down at the same rate (including the clock, the crew's thought processes, and the functions of their bodies). However, to a stationary observer watching the spaceship fly by, the spaceship appears flattened in the direction it is traveling and the clock on board the spaceship appears to move very slowly.

On the other hand, the crew on board the spaceship also perceives the observer as slowed down and flattened along the spaceship's direction of travel, because both are moving at very nearly the speed of light relative to each other. Because the outside universe appears flattened to the spaceship, the crew perceives themselves as quickly traveling between regions of space that (to the stationary observer) are many light years apart. This is reconciled by the fact that the crew's perception of time is different from the stationary observer's; what seems like seconds to the crew might be hundreds of years to the stationary observer. In either case, however, causality remains unchanged: the past is the set of events that can send light signals to an entity and the future is the set of events to which an entity can send light signals.

Einstein showed in his thought experiments that people travelling at different speeds, while agreeing on cause and effect, measure different time separations between events, and can even observe different chronological orderings between non-causally related events. Though these effects are typically minute in the human experience, the effect becomes much more pronounced for objects moving at speeds approaching the speed of light. Subatomic particles exist for a well known average fraction of a second in a lab relatively at rest, but when travelling close to the speed of light they are measured to travel farther and exist for much longer than when at rest. According to the special theory of relativity, in the high-speed particle's frame of reference, it exists, on the average, for a standard amount of time known as its mean lifetime, and the distance it travels in that time is zero, because its velocity is zero. Relative to a frame of reference at rest, time seems to "slow down" for the particle. Relative to the high-speed particle, distances seem to shorten. Einstein showed how both temporal and spatial dimensions can be altered (or "warped") by high-speed motion.

Einstein ("The Meaning of Relativity"): "Two events taking place at the points A and B of a system K are simultaneous if they appear at the same instant when observed from the middle point, M, of the interval AB. Time is then defined as the ensemble of the indications of similar clocks, at rest relative to K, which register the same simultaneously."

Einstein wrote in his book, "Relativity", that simultaneity is also relative, i.e., two events that appear simultaneous to an observer in a particular inertial reference frame need not be judged as simultaneous by a second observer in a different inertial frame of reference.

The animations visualise the different treatments of time in the Newtonian and the relativistic descriptions. At the heart of these differences are the Galilean and Lorentz transformations applicable in the Newtonian and relativistic theories, respectively.

In the figures, the vertical direction indicates time. The horizontal direction indicates distance (only one spatial dimension is taken into account), and the thick dashed curve is the spacetime trajectory ("world line") of the observer. The small dots indicate specific (past and future) events in spacetime.

The slope of the world line (deviation from being vertical) gives the relative velocity to the observer. Note how in both pictures the view of spacetime changes when the observer accelerates.

In the Newtonian description these changes are such that "time" is absolute: the movements of the observer do not influence whether an event occurs in the 'now' (i.e., whether an event passes the horizontal line through the observer).

However, in the relativistic description the "observability of events" is absolute: the movements of the observer do not influence whether an event passes the "light cone" of the observer. Notice that with the change from a Newtonian to a relativistic description, the concept of "absolute time" is no longer applicable: events move up-and-down in the figure depending on the acceleration of the observer.

Time appears to have a direction – the past lies behind, fixed and immutable, while the future lies ahead and is not necessarily fixed. Yet for the most part the laws of physics do not specify an arrow of time, and allow any process to proceed both forward and in reverse. This is generally a consequence of time being modelled by a parameter in the system being analysed, where there is no "proper time": the direction of the arrow of time is sometimes arbitrary. Examples of this include the cosmological arrow of time, which points away from the Big Bang, CPT symmetry, and the radiative arrow of time, caused by light only travelling forwards in time (see light cone). In particle physics, the violation of CP symmetry implies that there should be a small counterbalancing time asymmetry to preserve CPT symmetry as stated above. The standard description of measurement in quantum mechanics is also time asymmetric (see Measurement in quantum mechanics). The second law of thermodynamics states that entropy must increase over time (see Entropy). This can be in either direction – Brian Greene theorizes that, according to the equations, the change in entropy occurs symmetrically whether going forward or backward in time. So entropy tends to increase in either direction, and our current low-entropy universe is a statistical aberration, in the similar manner as tossing a coin often enough that eventually heads will result ten times in a row. However, this theory is not supported empirically in local experiment.

Time quantization is a hypothetical concept. In the modern established physical theories (the Standard Model of Particles and Interactions and General Relativity) time is not quantized.

Planck time (~ 5.4 × 10 seconds) is the unit of time in the system of natural units known as Planck units. Current established physical theories are believed to fail at this time scale, and many physicists expect that the Planck time might be the smallest unit of time that could ever be measured, even in principle. Tentative physical theories that describe this time scale exist; see for instance loop quantum gravity.

Time travel is the concept of moving backwards or forwards to different points in time, in a manner analogous to moving through space, and different from the normal "flow" of time to an earthbound observer. In this view, all points in time (including future times) "persist" in some way. Time travel has been a plot device in fiction since the 19th century. Travelling backwards in time has never been verified, presents many theoretical problems, and may be an impossibility. Any technological device, whether fictional or hypothetical, that is used to achieve time travel is known as a time machine.

A central problem with time travel to the past is the violation of causality; should an effect precede its cause, it would give rise to the possibility of a temporal paradox. Some interpretations of time travel resolve this by accepting the possibility of travel between branch points, parallel realities, or universes.

Another solution to the problem of causality-based temporal paradoxes is that such paradoxes cannot arise simply because they have not arisen. As illustrated in numerous works of fiction, free will either ceases to exist in the past or the outcomes of such decisions are predetermined. As such, it would not be possible to enact the grandfather paradox because it is a historical fact that your grandfather was not killed before his child (your parent) was conceived. This view doesn't simply hold that history is an unchangeable constant, but that any change made by a hypothetical future time traveller would already have happened in his or her past, resulting in the reality that the traveller moves from. More elaboration on this view can be found in the Novikov self-consistency principle.

The specious present refers to the time duration wherein one's perceptions are considered to be in the present. The experienced present is said to be ‘specious’ in that, unlike the objective present, it is an interval and not a durationless instant. The term "specious present" was first introduced by the psychologist E.R. Clay, and later developed by William James.

The brain's judgment of time is known to be a highly distributed system, including at least the cerebral cortex, cerebellum and basal ganglia as its components. One particular component, the suprachiasmatic nuclei, is responsible for the circadian (or daily) rhythm, while other cell clusters appear capable of shorter-range (ultradian) timekeeping.

Psychoactive drugs can impair the judgment of time. Stimulants can lead both humans and rats to overestimate time intervals,
while depressants can have the opposite effect.
The level of activity in the brain of neurotransmitters such as dopamine and norepinephrine may be the reason for this.
Such chemicals will either excite or inhibit the firing of neurons in the brain, with a greater firing rate allowing the brain to register the occurrence of more events within a given interval (speed up time) and a decreased firing rate reducing the brain's capacity to distinguish events occurring within a given interval (slow down time).

Mental chronometry is the use of response time in perceptual-motor tasks to infer the content, duration, and temporal sequencing of cognitive operations.

Children's expanding cognitive abilities allow them to understand time more clearly. Two- and three-year-olds' understanding of time is mainly limited to "now and not now." Five- and six-year-olds can grasp the ideas of past, present, and future. Seven- to ten-year-olds can use clocks and calendars.

In addition to psychoactive drugs, judgments of time can be altered by temporal illusions (like the kappa effect), age,
and hypnosis.
The sense of time is impaired in some people with neurological diseases such as Parkinson's disease and attention deficit disorder.

Psychologists assert that time seems to go faster with age, but the literature on this age-related perception of time remains controversial.
Those who support this notion argue that young people, having more excitatory neurotransmitters, are able to cope with faster external events.

In sociology and anthropology, time discipline is the general name given to social and economic rules, conventions, customs, and expectations governing the measurement of time, the social currency and awareness of time measurements, and people's expectations concerning the observance of these customs by others. Arlie Russell Hochschild and Norbert Elias have written on the use of time from a sociological perspective.

The use of time is an important issue in understanding human behavior, education, and travel behavior. Time-use research is a developing field of study. The question concerns how time is allocated across a number of activities (such as time spent at home, at work, shopping, etc.). Time use changes with technology, as the television or the Internet created new opportunities to use time in different ways. However, some aspects of time use are relatively stable over long periods of time, such as the amount of time spent traveling to work, which despite major changes in transport, has been observed to be about 20–30 minutes one-way for a large number of cities over a long period.

Time management is the organization of tasks or events by first estimating how much time a task requires and when it must be completed, and adjusting events that would interfere with its completion so it is done in the appropriate amount of time. Calendars and day planners are common examples of time management tools.

A sequence of events, or series of events, is a sequence of items, facts, events, actions, changes, or procedural steps, arranged in time order (chronological order), often with causality relationships among the items.
Because of causality, cause precedes effect, or cause and effect may appear together in a single item, but effect never precedes cause. A sequence of events can be presented in text, tables, charts, or timelines. The description of the items or events may include a timestamp. A sequence of events that includes the time along with place or location information to describe a sequential path may be referred to as a world line.

Uses of a sequence of events include stories,
historical events (chronology), directions and steps in procedures,
and timetables for scheduling activities. A sequence of events may also be used to help describe processes in science, technology, and medicine. A sequence of events may be focused on past events (e.g., stories, history, chronology), on future events that must be in a predetermined order (e.g., plans, schedules, procedures, timetables), or focused on the observation of past events with the expectation that the events will occur in the future (e.g., processes, projections). The use of a sequence of events occurs in fields as diverse as machines (cam timer), documentaries ("Seconds From Disaster"), law (choice of law), computer simulation (discrete event simulation), and electric power transmission
(sequence of events recorder). A specific example of a sequence of events is the timeline of the Fukushima Daiichi nuclear disaster.

Although time is regarded as an abstract concept, there is increasing evidence that time is conceptualized in the mind in terms of space. That is, instead of thinking about time in a general, abstract way, humans think about time in a spatial way and mentally organize it as such. Using space to think about time allows humans to mentally organize temporal events in a specific way.

This spatial representation of time is often represented in the mind as a Mental Time Line (MTL). Using space to think about time allows humans to mentally organize temporal order. These origins are shaped by many environmental factors––for example, literacy appears to play a large role in the different types of MTLs, as reading/writing direction provides an everyday temporal orientation that differs from culture to culture. In western cultures, the MTL may unfold rightward (with the past on the left and the future on the right) since people read and write from left to right. Western calendars also continue this trend by placing the past on the left with the future progressing toward the right. Conversely, Arabic, Farsi, Urdu and Israeli-Hebrew speakers read from right to left, and their MTLs unfold leftward (past on the right with future on the left), and evidence suggests these speakers organize time events in their minds like this as well.

This linguistic evidence that abstract concepts are based in spatial concepts also reveals that the way humans mentally organize time events varies across cultures––that is, a certain specific mental organization system is not universal. So, although Western cultures typically associate past events with the left and future events with the right according to a certain MTL, this kind of horizontal, egocentric MTL is not the spatial organization of all cultures. Although most developed nations use an egocentric spatial system, there is recent evidence that some cultures use an allocentric spatialization, often based on environmental features.

A recent study of the indigenous Yupno people of Papua New Guinea focused on the directional gestures used when individuals used time-related words. When speaking of the past (such as "last year" or "past times"), individuals gestured downhill, where the river of the valley flowed into the ocean. When speaking of the future, they gestured uphill, toward the source of the river. This was common regardless of which direction the person faced, revealing that the Yupno people may use an allocentric MTL, in which time flows uphill.

A similar study of the Pormpuraawans, an aboriginal group in Australia, revealed a similar distinction in which when asked to organize photos of a man aging "in order," individuals consistently placed the youngest photos to the east and the oldest photos to the west, regardless of which direction they faced. This directly clashed with an American group which consistently organized the photos from left to right. Therefore, this group also appears to have an allocentric MTL, but based on the cardinal directions instead of geographical features.

The wide array of distinctions in the way different groups think about time leads to the broader question that different groups may also think about other abstract concepts in different ways as well, such as causality and number.



"Leading scholarly organisations for researchers on the history and technology of time and timekeeping"




</doc>
<doc id="30013" url="https://en.wikipedia.org/wiki?curid=30013" title="Tone">
Tone

Tone may refer to:









</doc>
<doc id="30015" url="https://en.wikipedia.org/wiki?curid=30015" title="Tifinagh">
Tifinagh

Tifinagh (; also written in the Berber Latin alphabet; Neo-Tifinagh: ; Tuareg Tifinagh: or ) is an abjad script used to write the Berber languages.

A modern alphabetical derivative of the traditional script, known as Neo-Tifinagh, was introduced in the 20th century. A slightly modified version of the traditional script, called "Tifinagh Ircam", is used in a number of Moroccan elementary schools in teaching the Berber language to children as well as a number of publications.

The word "tifinagh" is thought to be a Tuareg pun meaning "itif" ("discovery") "nnegh" ("our") i.e. "our discovery".

Tifinagh is believed to have descended from the ancient Libyan () or Libyco-Berber script, although its exact evolution is unclear. The latter writing system was widely used in antiquity by speakers of Berber languages throughout Africa and on the Canary Islands. It is attested from the 5rd century BC to the 3rd century AD. The script's origin is considered by most scholars as being of local origin, some scholars however suggest it is related to the Phoenician alphabet.

There are two known variants: eastern and western. The eastern variant was used in what is now Constantine and the Aurès regions of Algeria and in Tunisia and shows a clear Phoenician influence. It is the best-deciphered variant, due to the discovery of several Numidian bilingual inscriptions in Libyan and Punic (notably at Dougga in Tunisia). 22 letters out of the 24 were deciphered. The western variant is more archaic and shows no Phoenician influence (Février 1964–1965). It was used along the Mediterranean coast from Kabylie to the Canary Islands. It used 13 supplementary letters.

The Libyco-Berber script was a pure abjad; it had no vowels. Gemination was not marked. The writing was usually from the bottom to the top, although right-to-left, and even other orders, were also found. The letters would take different forms when written vertically than when they were written horizontally.

The Libyco-Berber script is used today in the form of Tifinagh to write the Tuareg languages, which belong to the Berber branch of the Afroasiatic family. Early uses of the script have been found on rock art and in various sepulchres. Among these are the 1,500 year old monumental tomb of the Tuareg queen Tin Hinan, where vestiges of a Tifinagh inscription have been found on one of its walls.

According to M.C.A. MacDonald, the Tuareg are "an entirely oral society in which memory and oral communication perform all the functions which reading and writing have in a literate society… The Tifinagh are used primarily for games and puzzles, short graffiti and brief messages."

Occasionally, the script has been used to write other neighbouring languages such as Tagdal, which belongs to a separate Songhay family.

Common forms of the letters are illustrated at left, including various ligatures of "t" and "n". Gemination, though phonemic, is not indicated in Tifinagh. The letter "t", +, is often combined with a preceding letter to form a ligature. Most of the letters have more than one common form, including mirror-images of the forms shown here.

When the letters "l" and "n" are adjacent to themselves or to each other, the second is offset, either by inclining, lowering, raising, or shortening it. For example, since the letter "l" is a double line, <nowiki>||</nowiki>, and "n" a single line, <nowiki>|</nowiki>, the sequence "nn" may be written <nowiki>|/</nowiki> to differentiate it from "l". Similarly, "ln" is <nowiki>||/</nowiki>, "nl" <nowiki>|//</nowiki>, "ll" <nowiki>||//</nowiki>, "nnn" <nowiki>|/|</nowiki>, etc.

Traditionally, the Tifinagh script does not indicate vowels except word-finally, where a single dot stands for any vowel. In some areas, Arabic vowel diacritics are combined with Tifinagh letters to transcribe vowels, or "y, w" may be used for long "ī" and "ū".

Neo-Tifinagh is the modern fully alphabetic script developed from earlier forms of Tifinagh. It is written left to right.

Until recently, virtually no books or websites were published in this alphabet, with activists favouring the Latin (or, more rarely, Arabic) scripts for serious use; however, it is extremely popular for symbolic use, with many books and websites written in a different script featuring logos or title pages using Neo-Tifinagh.

In Morocco, use of Neo-Tifinagh was suppressed until recently. The Moroccan state arrested and imprisoned people using this script during the 1980s and 1990s. In 2003, however, the king took a "neutral" position between the claims of Latin script and Arabic script by adopting Neo-Tifinagh; as a result, books are beginning to be published in this script, and it is taught in some schools. However, many independent Berber-language publications are still published using the Berber Latin alphabet. Outside Morocco, it has no official status.

In Algeria, almost all Berber publications use the Berber Latin Alphabet. The Algerian Black Spring was partly caused by the repression of Berber languages.

In Libya, the government of Muammar Gaddafi consistently banned Tifinagh from being used in public contexts such as store displays and banners.

After the Libyan Civil War, the National Transitional Council has shown an openness towards the Berber languages. The rebel Libya TV, based in Qatar, has included the Berber language and the Tifinagh alphabet in some of its programming.

The following are the letters and a few ligatures of traditional Tifinagh and Neo-Tifinagh:

Tifinagh was added to the Unicode Standard in March 2005, with the release of version 4.1.

The Unicode block range for Tifinagh is U+2D30–U+2D7F:




</doc>
<doc id="30018" url="https://en.wikipedia.org/wiki?curid=30018" title="Turkic languages">
Turkic languages

The Turkic languages are a language family of at least thirty-five documented languages, spoken by the Turkic peoples of Eurasia from Eastern Europe, the Caucasus, Central Asia, and West Asia all the way to North Asia (particularly in Siberia) and East Asia (including the Far East). The Turkic languages originated in a region of East Asia spanning Western China to Mongolia, where Proto-Turkic is thought to have been spoken, according to one estimate, around 2,500 years ago, from where they expanded to Central Asia and farther west during the first millennium.

Turkic languages are spoken as a native language by some 170 million people, and the total number of Turkic speakers, including second language speakers, is over 200 million. The Turkic language with the greatest number of speakers is Turkish, spoken mainly in Anatolia and the Balkans; its native speakers account for about 40% of all Turkic speakers.

Characteristic features of Turkish, such as vowel harmony, agglutination, and lack of grammatical gender, are universal within the Turkic family. There is also a high degree of mutual intelligibility among the various Oghuz languages, which include Turkish, Azerbaijani, Turkmen, Qashqai, Gagauz, Balkan Gagauz Turkish, and Oghuz-influenced Crimean Tatar. Although methods of classification vary, the Turkic languages are usually considered to be divided equally into two branches: Oghur, the only surviving member of which is Chuvash, and Common Turkic, which includes all other Turkic languages including the Oghuz subbranch.

Turkic languages show some similarities with the Mongolic, Tungusic, Koreanic, and Japonic languages. These similarities led some linguists to propose an Altaic language family, though this proposal is not widely accepted. Apparent similarities with the Uralic languages family even caused these families to be regarded as one for a long time under the hypothesis of Ural-Altaic languages. However, there has not been sufficient evidence to conclude the existence of either of these macrofamilies, the shared characteristics between the languages being attributed presently to extensive prehistoric language contact.

Turkic languages are null-subject languages, have vowel harmony, extensive agglutination by means of suffixes and postpositions, and lack of grammatical articles, noun classes, and grammatical gender. Subject–object–verb word order is universal within the family. The root of a word is basically of one, two or three consonants.

The geographical distribution of Turkic-speaking peoples across Eurasia ranges from the North-East of Siberia to Turkey in the West, since the Ottoman era (see picture in the box on the right above).

Extensive contact took place between Proto-Turks and Proto-Mongols approximately during the first millennium BC; the shared cultural tradition between the two Eurasian nomadic groups is called the "Turco-Mongol" tradition. The two groups shared a religion, Tengrism, and there exists a multitude of evident loanwords between Turkic languages and Mongolic languages. Although the loans were bidirectional, today Turkic loanwords constitute the largest foreign component in Mongolian vocabulary. The most famous of these loanwords include "lion" (Turkish: "aslan" or "arslan"; Mongolian: "arslan"), "gold" (Turkish: "altın"; Mongolian: "altan" or "alt"), and "iron" (Turkish: "demir"; Mongolian: "tömör").

Some lexical and extensive typological similarities between Turkic and the nearby Tungusic and Mongolic families, as well as the Korean and Japonic families (all formerly widely considered to be part of the so-called Altaic language family) has in more recent years been instead attributed to prehistoric contact amongst the group, sometimes referred to as the Northeast Asian sprachbund. A more recent (circa first millennium BCE) contact between "core Altaic" (Turkic, Mongolic, and Tungusic) is distinguished from this, due to the existence of definitive common words that appear to have been mostly borrowed from Turkic into Mongolic, and later from Mongolic into Tungusic, as Turkic borrowings into Mongolic significantly outnumber Mongolic borrowings into Turkic, and Turkic and Tungusic do not share any words that do not also exist in Mongolic.

Alexander Vovin (2004, 2010) notes that Old Turkic had borrowed significantly from the Ruan-ruan language (the language of the Rouran Khaganate), which Vovin considers to be an extinct non-Altaic language that is not related to any modern-day language.

The first established records of the Turkic languages are the eighth century AD Orkhon inscriptions by the Göktürks, recording the Old Turkic language, which were discovered in 1889 in the Orkhon Valley in Mongolia. The "Compendium of the Turkic Dialects" ("Divânü Lügati't-Türk"), written during the 11th century AD by Kaşgarlı Mahmud of the Kara-Khanid Khanate, constitutes an early linguistic treatment of the family. The "Compendium" is the first comprehensive dictionary of the Turkic languages and also includes the first known map of the Turkic speakers' geographical distribution. It mainly pertains to the Southwestern branch of the family.

The Codex Cumanicus (12th–13th centuries AD) concerning the Northwestern branch is another early linguistic manual, between the Kipchak language and Latin, used by the Catholic missionaries sent to the Western Cumans inhabiting a region corresponding to present-day Hungary and Romania. The earliest records of the language spoken by Volga Bulgars, the parent to today's Chuvash language, are dated to the 13th–14th centuries AD.

With the Turkic expansion during the Early Middle Ages (c. 6th–11th centuries AD), Turkic languages, in the course of just a few centuries, spread across Central Asia, from Siberia to the Mediterranean. Various terminologies from the Turkic languages have passed into Persian, Hindustani, Russian, Chinese, and to a lesser extent, Arabic.

For centuries, the Turkic-speaking peoples have migrated extensively and intermingled continuously, and their languages have been influenced mutually and through contact with the surrounding languages, especially the Iranian, Slavic, and Mongolic languages.

This has obscured the historical developments within each language and/or language group, and as a result, there exist several systems to classify the Turkic languages. The modern genetic classification schemes for Turkic are still largely indebted to Samoilovich (1922).

The Turkic languages may be divided into six branches:

In this classification, Oghur Turkic is also referred to as Lir-Turkic, and the other branches are subsumed under the title of Shaz-Turkic or Common Turkic. It is not clear when these two major types of Turkic can be assumed to have actually diverged.

With less certainty, the Southwestern, Northwestern, Southeastern and Oghur groups may further be summarized as West Turkic, the Northeastern, Kyrgyz-Kipchak and Arghu (Khalaj) groups as East Turkic.

Geographically and linguistically, the languages of the Northwestern and Southeastern subgroups belong to the central Turkic languages, while the Northeastern and Khalaj languages are the so-called peripheral languages.

Hruschka, et al. (2014) use computational phylogenetic methods to calculate a tree of Turkic based on phonological sound changes.

The following isoglosses are traditionally used in the classification of the Turkic languages:
Additional isoglosses include:

<nowiki>*</nowiki>In the standard Istanbul dialect of Turkish, the "ğ" in "dağ" and "dağlı" is not realized as a consonant, but as a slight lengthening of the preceding vowel.

The following table is based upon the classification scheme presented by Lars Johanson (1998)

The following is a brief comparison of cognates among the basic vocabulary across the Turkic language family (about 60 words).

Empty cells do not necessarily imply that a particular language is lacking a word to describe the concept, but rather that the word for the concept in that language may be formed from another stem and is not a cognate with the other words in the row or that a loanword is used in its place.

Also, there may be shifts in the meaning from one language to another, and so the "Common meaning" given is only approximate. In some cases the form given is found only in some dialects of the language, or a loanword is much more common (e.g. in Turkish, the preferred word for "fire" is the Persian-derived "ateş", whereas the native "od" is dead). Forms are given in native Latin orthographies unless otherwise noted.

An endangered language, or moribund language, is a language that is at risk of falling out of use as its speakers die out or shift to speaking another language. Language loss occurs when the language has no more native speakers and becomes a "dead language".

15 Turkic languages exist in endangered languages in Russia:


In Qinghai (Amdo), the Salar language has a heavy Chinese and Tibetan influence. Although of Turkic origin, major linguistic structures have been absorbed from Chinese. Around 20% of the vocabulary is of Chinese origin, and 10% is also of Tibetan origin. Yet the official Communist Chinese government policy deliberately covers up these influences in academic and linguistics studies, trying to emphasize the Turkic element and completely ignoring the Chinese in the Salar language. The Salar language has taken loans and influence from neighboring varieties of Chinese. It is neighboring variants of Chinese which have loaned words to the Salar language. In Qinghai, many Salar men speak both the Qinghai dialect of Chinese and Salar. Rural Salars can speak Salar fluently while urban Salars often assimilate into the Chinese speaking Hui population.

Ethnologue and ISO list an Iranian language "Khalaj" with the same population, but Glottolog states it does not exist. The Khalaj speak their Turkic language and Persian, and the supposed Iranian language of the Khalaj is spurious.
Khorasani Turkic (Khorasani Turkic: "خراسان تركچىسى", Pronunciation: ; ) is an Oghuz Turkic language spoken in northern North Khorasan Province and Razavi Khorasan Province in Iran. Nearly all Khorasani Turkic speakers are also bilingual in Persian.

Many Turkic languages have gone extinct in Afghanistan.
In 1980, Saddam Hussein's government adopted a policy of assimilation of its minorities. Due to government relocation programs, thousands of Iraqi Turkmen were relocated from their traditional homelands in northern Iraq and replaced by Arabs, in an effort to Arabize the region. Furthermore, Iraqi Turkmen villages and towns were destroyed to make way for Arab migrants, who were promised free land and financial incentives. For example, the Ba'th regime recognised that the city of Kirkuk was historically an Iraqi Arab city and remained firmly in its cultural orientation. Thus, the first wave of Arabization saw Arab families move from the centre and south of Iraq into Kirkuk to work in the expanding oil industry. Although the Iraqi Turkmen were not actively forced out, new Arab quarters were established in the city and the overall demographic balance of the city changed as the Arab migrations continued.

Several presidential decrees and directives from state security and intelligence organizations indicate that the Iraqi Turkmen were a particular focus of attention during the assimilation process during the Ba'th regime. For example, the Iraqi Military Intelligence issued directive 1559 on 6 May 1980 ordering the deportation of Iraqi Turkmen officials from Kirkuk, issuing the following instructions: "identify the places where Turkmen officials are working in governmental offices [in order] to deport them to other governorates in order to disperse them and prevent them from concentrating in this governorate [Kirkuk]". In addition, on 30 October 1981, the Revolution's Command Council issued decree 1391, which authorized the deportation of Iraqi Turkmen from Kiruk with paragraph 13 noting that "this directive is specially aimed at Turkmen and Kurdish officials and workers who are living in Kirkuk".

As primary victims of these Arabization policies, the Iraqi Turkmen suffered from land expropriation and job discrimination, and therefore would register themselves as "Arabs" in order to avoid discrimination. Thus, ethnic cleansing was an element of the Ba'thist policy aimed at reducing the influence of the Iraqi Turkmen in northern Iraq's Kirkuk. Those Iraqi Turkmen who remained in cities such as Kirkuk were subject to continued assimilation policies; school names, neighbourhoods, villages, streets, markets and even mosques with names of Turkic origin were changed to names that emanated from the Ba'th Party or from Arab heroes. Moreover, many Iraqi Turkmen villages and neighbourhoods in Kirkuk were simply demolished, particularly in the 1990s.





</doc>
<doc id="30019" url="https://en.wikipedia.org/wiki?curid=30019" title="The Sound of Music">
The Sound of Music

The Sound of Music is a musical with music by Richard Rodgers, lyrics by Oscar Hammerstein II and a book by Howard Lindsay and Russel Crouse. It is based on the memoir of Maria von Trapp, "The Story of the Trapp Family Singers". Set in Austria on the eve of the "Anschluss" in 1938, the musical tells the story of Maria, who takes a job as governess to a large family while she decides whether to become a nun. She falls in love with the children, and eventually their widowed father, Captain von Trapp. He is ordered to accept a commission in the German navy, but he opposes the Nazis. He and Maria decide on a plan to flee Austria with the children. Many songs from the musical have become standards, such as "Edelweiss", "My Favorite Things", "Climb Ev'ry Mountain", "Do-Re-Mi", and the title song "The Sound of Music".

The original Broadway production, starring Mary Martin and Theodore Bikel, opened in 1959 and won five Tony Awards, including Best Musical, out of nine nominations. The first London production opened at the Palace Theatre in 1961. The show has enjoyed numerous productions and revivals since then. It was adapted as a 1965 film musical starring Julie Andrews and Christopher Plummer, which won five Academy Awards. "The Sound of Music" was the last musical written by Rodgers and Hammerstein; Oscar Hammerstein died of cancer nine months after the Broadway premiere.

After viewing "The Trapp Family", a 1956 West German film about the von Trapp family, and its 1958 sequel (""), stage director Vincent J. Donehue thought that the project would be perfect for his friend Mary Martin; Broadway producers Leland Hayward and Richard Halliday (Martin's husband) agreed. The producers originally envisioned a non-musical play that would be written by Lindsay and Crouse and that would feature songs from the repertoire of the Trapp Family Singers. Then they decided to add an original song or two, perhaps by Rodgers and Hammerstein. But it was soon agreed that the project should feature all new songs and be a musical rather than a play.

Details of the history of the von Trapp family were altered for the musical. The real Georg von Trapp did live with his family in a villa in Aigen, a suburb of Salzburg. He wrote to the Nonnberg Abbey in 1926 asking for a nun to help tutor his sick daughter, and the Mother Abbess sent Maria. His wife had died in 1922. The real Maria and Georg married at the Nonnberg Abbey in 1927. Lindsay and Crouse altered the story so that Maria was governess to all of the children, whose names and ages were changed, as was Maria's original surname (the show used "Rainer" instead of "Kutschera"). The von Trapps spent some years in Austria after Maria and the Captain married and was offered a commission in Germany's navy. Since von Trapp opposed the Nazis by that time, the family left Austria after the "Anschluss", going by train to Italy and then traveling on to London and the United States. To make the story more dramatic, Lindsay and Crouse had the family, soon after Maria's and the Captain's wedding, escape over the mountains to Switzerland on foot.

In Salzburg, Austria, just before World War II, nuns from Nonnberg Abbey sing the "Dixit Dominus". One of the postulants, Maria Rainer, is on the nearby mountainside, regretting leaving the beautiful hills ("The Sound of Music") where she was brought up. She returns late. The Mother Abbess and the other nuns consider what to do about her ("Maria"). Maria explains her lateness, saying she was raised on that mountain, and apologizes for singing in the garden without permission. The Mother Abbess joins her in song ("My Favorite Things"). The Mother Abbess tells her that she should spend some time outside the abbey to decide whether she is ready for the monastic life. She will act as the governess to the seven children of a widower, Austro-Hungarian Navy submarine Captain Georg von Trapp.

Maria arrives at the villa of Captain von Trapp. He explains her duties and summons the children with a boatswain's call. They march in, clad in uniforms. He teaches her their individual signals on the call, but she openly disapproves of this militaristic approach. Alone with them, she breaks through their wariness and teaches them the basics of music ("Do-Re-Mi").

Rolf, a young messenger, delivers a telegram and then meets with the oldest child, Liesl, outside the villa. He claims he knows what is right for her because he is a year older than she ("Sixteen Going on Seventeen"). They kiss, and he runs off, leaving her squealing with joy. Meanwhile, the housekeeper, Frau Schmidt, gives Maria material to make new clothes, as Maria had given all her possessions to the poor. Maria sees Liesl slipping in through the window, wet from a sudden thunderstorm, but agrees to keep her secret. The other children are frightened by the storm. Maria sings "The Lonely Goatherd" to distract them.

Captain von Trapp arrives a month later from Vienna with Baroness Elsa Schräder and Max Detweiler. Elsa tells Max that something is preventing the Captain from marrying her. He opines that only poor people have the time for great romances ("How Can Love Survive"). Rolf enters, looking for Liesl, and greets them with "Heil". The Captain orders him away, saying that he is Austrian, not German. Maria and the children leapfrog in, wearing play-clothes that she made from the old drapes in her room. Infuriated, the Captain sends them off to change. She tells him that they need him to love them, and he angrily orders her back to the abbey. As she apologizes, they hear the children singing "The Sound of Music", which she had taught them, to welcome Elsa Schräder. He joins in and embraces them. Alone with Maria, he asks her to stay, thanking her for bringing music back into his house. Elsa is suspicious of her until she explains that she will be returning to the abbey in September.

The Captain gives a party to introduce Elsa, and guests argue over the Nazi German "Anschluss" (annexation) of Austria. Kurt asks Maria to teach him to dance the Ländler. When he fails to negotiate a complicated figure, the Captain steps in to demonstrate. He and Maria dance until they come face-to-face; and she breaks away, embarrassed and confused. Discussing the expected marriage between Elsa and the Captain, Brigitta tells Maria that she thinks Maria and the Captain are really in love with each other. Elsa asks the Captain to allow the children to say goodnight to the guests with a song, "So Long, Farewell". Max is amazed at their talent and wants them for the Kaltzberg Festival, which he is organizing. The guests leave for the dining room, and Maria slips out the front door with her luggage.

At the abbey, Maria says that she is ready to take her monastic vows; but the Mother Abbess realizes that she is running away from her feelings. She tells her to face the Captain and discover if they love each other, and tells her to search for and find the life she was meant to live ("Climb Ev'ry Mountain").

Max teaches the children how to sing on stage. When the Captain tries to lead them, they complain that he is not doing it as Maria did. He tells them that he has asked Elsa to marry him. They try to cheer themselves up by singing "My Favorite Things" but are unsuccessful until they hear Maria singing on her way to rejoin them. Learning of the wedding plans, she decides to stay only until the Captain can arrange for another governess. Max and Elsa argue with the Captain about the imminent "Anschluss", trying to convince him that it is inevitable ("No Way to Stop It"). When he refuses to compromise on his opposition to it, Elsa breaks off the engagement. Alone, the Captain and Maria finally admit their love, desiring only to be "An Ordinary Couple". As they marry, the nuns reprise "Maria" against the wedding processional.

While Maria and the Captain are on their honeymoon, Max prepares the children to perform at the Kaltzberg Festival. Herr Zeller, the "Gauleiter" of the region, demands to know why they are not flying the flag of the Third Reich now that the "Anschluss" has occurred. The Captain and Maria return early from their honeymoon before the Festival. In view of the Nazi German occupation, the Captain decides the children should not sing at the event. Max argues that they would sing for Austria, but the Captain points out that it no longer exists. Maria and Liesl discuss romantic love; Maria predicts that in a few years Liesl will be married ("Sixteen Going on Seventeen (Reprise)"). Rolf enters with a telegram that offers the Captain a commission in the German Navy, and Liesl is upset to discover that Rolf is now a committed Nazi. The Captain consults Maria and decides that they must secretly flee Austria. German Admiral von Schreiber arrives to find out why Captain von Trapp has not answered the telegram. He explains that the German Navy holds him in high regard, offers him the commission, and tells him to report immediately to Bremerhaven to assume command. Maria says that he cannot leave immediately, as they are all singing in the Festival concert; and the Admiral agrees to wait.

At the concert, after the von Trapps sing an elaborate reprise of "Do-Re-Mi", Max brings out the Captain's guitar. Captain von Trapp sings "Edelweiss", as a goodbye to his homeland, while using Austria's national flower as a symbol to declare his loyalty to the country. Max asks for an encore and announces that this is the von Trapp family's last chance to sing together, as the honor guard waits to escort the Captain to his new command. While the judges decide on the prizes, the von Trapps sing "So Long, Farewell", leaving the stage in small groups. Max then announces the runners-up, stalling as much as possible. When he announces that the first prize goes to the von Trapps and they do not appear, the Nazis start a search. The family hides at the Abbey, and Sister Margaretta tells them that the borders have been closed. Rolf comes upon them and calls his lieutenant, but after seeing Liesl he changes his mind and tells him they aren't there. The Nazis leave, and the von Trapps flee over the Alps as the nuns reprise "Climb Ev'ry Mountain".


Sources: IBDB and Guidetomusicaltheatre.com

"The Sound of Music" premiered at New Haven's Schubert Theatre where it played an eight-performance tryout in October and November 1959 before another short tryout in Boston. The musical then opened on Broadway at the Lunt-Fontanne Theatre on November 16, 1959, moved to the Mark Hellinger Theatre on November 6, 1962, and closed on June 15, 1963, after 1,443 performances. The director was Vincent J. Donehue, and the choreographer was Joe Layton. The original cast included Mary Martin (at age 46) as Maria, Theodore Bikel as Captain Georg von Trapp, Patricia Neway as Mother Abbess, Kurt Kasznar as Max Detweiler, Marion Marlowe as Elsa Schräder, Brian Davies as Rolf and Lauri Peters as Liesl. Sopranos Patricia Brooks and June Card were ensemble members in the original production. The show tied for the Tony Award for Best Musical with "Fiorello!". Other awards included Martin for Best Actress in a Musical, Neway for Best Featured Actress, Best Scenic Design (Oliver Smith) and Best Conductor And Musical Director (Frederick Dvonch). Bikel and Kasznar were nominated for acting awards, and Donehue was nominated for his direction. The entire children's cast was nominated for Best Featured Actress category as a single nominee, even though two of the children were boys.

Martha Wright replaced Martin in the role of Maria on Broadway in October 1961, followed by Karen Gantz in July 1962, Jeannie Carson in August 1962 and Nancy Dussault in September 1962. Jon Voight, who eventually married co-star Lauri Peters, was a replacement for Rolf. The national tour starred Florence Henderson as Maria and Beatrice Krebs as Mother Abbess. It opened at the Grand Riviera Theater, Detroit, on February 27, 1961, and closed November 23, 1963, at the O'Keefe Centre, Toronto. Henderson was succeeded by Barbara Meister in June 1962. Theodore Bikel was not satisfied playing the role of the Captain, because of the role's limited singing, and Bikel did not like to play the same role over and over again. In his autobiography, he writes: "I promised myself then that if I could afford it, I would never do a run as long as that again." The original Broadway cast album sold three million copies.

The musical premiered in London's West End at the Palace Theatre on May 18, 1961, and ran for 2,385 performances. It was directed by Jerome Whyte and used the original New York choreography, supervised by Joe Layton, and the original sets designed by Oliver Smith. The cast included Jean Bayless as Maria, followed by Sonia Rees, Roger Dann as Captain von Trapp, Constance Shacklock as Mother Abbess, Eunice Gayson as Elsa Schrader, Harold Kasket as Max Detweiler, Barbara Brown as Liesl, Nicholas Bennett as Rolf and Olive Gilbert as Sister Margaretta.

In 1981, at producer Ross Taylor's urging, Petula Clark agreed to star in a revival of the show at the Apollo Victoria Theatre in London's West End. Michael Jayston played Captain von Trapp, Honor Blackman was the Baroness and June Bronhill the Mother Abbess. Other notable cast members included Helen Anker, John Bennett and Martina Grant. Despite her misgivings that, at age 49, she was too old to play the role convincingly, Clark opened to unanimous rave reviews and the largest advance sale in the history of British theatre at that time. Maria von Trapp, who attended the opening night performance, described Clark as "the best" Maria ever. Clark extended her initial six-month contract to thirteen months. Playing to 101 percent of seating capacity, the show set the highest attendance figure for a single week (October 26–31, 1981) of any British musical production in history (as recorded in "The Guinness Book of Theatre"). It was the first stage production to incorporate the two additional songs ("Something Good" and "I Have Confidence") that Richard Rodgers composed for the film version. "My Favorite Things" had a similar context to the film version, while the short verse "A Bell is No Bell" was extended into a full-length song for Maria and the Mother Abbess. "The Lonely Goatherd" was set in a new scene at a village fair.

The cast recording of this production was the first to be recorded digitally. It was released on CD for the first time in 2010 by the UK label Pet Sounds and included two bonus tracks from the original single issued by Epic to promote the production.

Director Susan H. Schulman staged the first Broadway revival of "The Sound of Music", with Rebecca Luker as Maria and Michael Siberry as Captain von Trapp. It also featured Patti Cohenour as Mother Abbess, Jan Maxwell as Elsa Schrader, Fred Applegate as Max Detweiler, Dashiell Eaves as Rolf, Patricia Conolly as Frau Schmidt and Laura Benanti, in her Broadway debut, as Luker's understudy. Later, Luker and Siberry were replaced by Richard Chamberlain as the Captain and Benanti as Maria. Lou Taylor Pucci made his Broadway debut as the understudy for Kurt von Trapp. The production opened on March 12, 1998, at the Martin Beck Theatre, and closed on June 20, 1999, after 533 performances. This production was nominated for a Tony Award for Best Revival of a Musical. It then toured in North America.

An Andrew Lloyd Webber production opened on November 15, 2006, at the London Palladium and ran until February 2009, produced by Live Nation's David Ian and Jeremy Sams. Following failed negotiations with Hollywood star Scarlett Johansson, the role of Maria was cast through a UK talent search reality TV show called "How Do You Solve a Problem like Maria?" The talent show was produced by (and starred) Andrew Lloyd Webber and featured presenter/comedian Graham Norton and a judging panel of David Ian, John Barrowman and Zoe Tyler.

Connie Fisher was selected by public voting as the winner of the show. In early 2007, Fisher suffered from a heavy cold that prevented her from performing for two weeks. To prevent further disruptions, an alternate Maria, Aoife Mulholland, a fellow contestant on "How Do You Solve a Problem like Maria?", played Maria on Monday evenings and Wednesday matinee performances. Simon Shepherd was originally cast as Captain von Trapp, but after two preview performances he was withdrawn from the production, and Alexander Hanson moved into the role in time for the official opening date along with Lesley Garrett as the Mother Abbess. After Garrett left, Margaret Preece took the role. The cast also featured Lauren Ward as the Baroness, Ian Gelder as Max, Sophie Bould as Liesl, and Neil McDermott as Rolf. Other notable replacements have included Simon Burke and Simon MacCorkindale as the Captain and newcomer Amy Lennox as Liesl. Summer Strallen replaced Fisher in February 2008, with Mulholland portraying Maria on Monday evenings and Wednesday matinees.

The revival received enthusiastic reviews, especially for Fisher, Preece, Bould and Garrett. A cast recording of the London Palladium cast was released. The production closed on February 21, 2009, after a run of over two years and was followed by a UK national tour, described below.


The first Australian production opened at Melbourne's Princess Theatre in 1961 and ran for three years. The production was directed by Charles Hickman, with musical numbers staged by Ernest Parham. The cast included June Bronhill as Maria, Peter Graves as Captain von Trapp and Rosina Raisbeck as Mother Abbess. A touring company then played for years, with Vanessa Lee (Graves' wife) in the role of Maria. The cast recording made in 1961 was the first time a major overseas production featuring Australian artists was transferred to disc.

A Puerto Rican production, performed in English, opened at the Tapia Theatre in San Juan under the direction of Pablo Cabrera in 1966. It starred Camille Carrión as María and Raúl Dávila as Captain Von Trapp, and it featured a young Johanna Rosaly as Liesl. In 1968, the production transferred to the Teatro de la Zarzuela in Madrid, Spain, where it was performed in Spanish with Carrión reprising the role of María, Alfredo Mayo as Captain Von Trapp and Roberto Rey as Max.

In 1988, the Moon Troupe of Takarazuka Revue performed the musical at the Bow Hall (Takarazuka, Hyōgo). Harukaze Hitomi and Gou Mayuka starred. A 1990 New York City Opera production, directed by Oscar Hammerstein II's son, James, featured Debby Boone as Maria, Laurence Guittard as Captain von Trapp, and Werner Klemperer as Max. In the 1993 Stockholm production, Carola Häggkvist played Maria and Tommy Körberg played Captain von Trapp.

An Australian revival played in the Lyric Theatre, Sydney, New South Wales, from November 1999 to February 2000. Lisa McCune played Maria, John Waters was Captain von Trapp, Bert Newton was Max, Eilene Hannan was Mother Abbess, and Rachel Marley was Marta. This production was based on the 1998 Broadway revival staging. The production then toured until February 2001, in Melbourne, Brisbane, Perth and Adelaide. Rachael Beck took over as Maria in Perth and Adelaide, and Rob Guest took over as Captain von Trapp in Perth.


An Austrian production premiered in 2005 at the Volksoper Wien in German. It was directed and choreographed by Renaud Doucet. The cast included Sandra Pires as Maria, Kurt Schreibmayer and Michael Kraus as von Trapp, with Heidi Brunner as Mother Abbess. As of 2012, the production was still in the repertoire of the Volksoper with 12–20 performances per season.

The Salzburg Marionette Theatre has toured extensively with their version that features the recorded voices of Broadway singers such as Christiane Noll as Maria. The tour began in Dallas, Texas, in 2007 and continued in Salzburg in 2008. The director is Richard Hamburger. In 2010, the production was given in Paris, France, with dialogue in French and the songs in English. In 2008, a Brazilian production with Kiara Sasso as Maria and Herson Capri as the Captain played in Rio de Janeiro and São Paulo, and a Dutch production was mounted with Wieneke Remmers as Maria, directed by John Yost.

Andrew Lloyd Webber, David Ian and David Mirvish presented "The Sound of Music" at the Princess of Wales Theatre in Toronto from 2008 to 2010. The role of Maria was chosen by the public through a television show, "How Do You Solve a Problem Like Maria?", which was produced by Lloyd Webber and Ian and aired in mid-2008. Elicia MacKenzie won and played the role six times a week, while the runner-up in the TV show, Janna Polzin, played Maria twice a week. Captain von Trapp was played by Burke Moses. The show ran for more than 500 performances. It was Toronto's longest running revival ever.

A UK tour began in 2009 and visited more than two dozen cities before ending in 2011. The original cast included Connie Fisher as Maria, Michael Praed as Captain von Trapp and Margaret Preece as the Mother Abbess. Kirsty Malpass was the alternate Maria. Jason Donovan assumed the role of Captain Von Trapp, and Verity Rushworth took over as Maria, in early 2011. Lesley Garrett reprised her role as Mother Abbess for the tour's final engagement in Wimbledon in October 2011.

A production ran at the Ópera-Citi theater in Buenos Aires, Argentina in 2011. The cast included Laura Conforte as Maria and Diego Ramos as Captain Von Trapp. A Spanish national tour began in November 2011 at the Auditorio de Tenerife in Santa Cruz de Tenerife in the Canary Islands. The tour visited 29 Spanish cities, spending one year in Madrid's Gran Vía at the Teatro Coliseum, and one season at the Tívoli Theatre in Barcelona. It was directed by Jaime Azpilicueta and starred Silvia Luchetti as Maria and Carlos J. Benito as Captain Von Trapp.

A production was mounted at the Open Air Theatre, Regent's Park from July to September 2013. It starred Charlotte Wakefield as Maria, with Michael Xavier as Captain von Trapp and Caroline Keiff as Elsa. It received enthusiastic reviews and became the highest-grossing production ever at the theatre. In 2014, the show was nominated for Best Musical Revival at the Laurence Olivier Awards and Wakefield was nominated for Best Actress in a Musical.

A brief South Korean production played in 2014, as did a South African production at the Artscape in Cape Town and at the Teatro at Montecasino based on Lloyd Webber and Ian’s London Palladium production. The same year, a Spanish language translation opened at Teatro de la Universidad in San Juan, under the direction of Edgar García. It starred Lourdes Robles as Maria and Braulio Castillo as Captain Von Trapp, with Dagmar as Elsa. A production (in Thai: "มนต์รักเพลงสวรรค์") ran at Muangthai ratchadalai Theatre, Bangkok, Thailand, in April 2015 in the Thai language. The production replaced the song "Ordinary couple" with "Something Good".

A North American tour, directed by Jack O'Brien and choreographed by Danny Mefford, began at the Ahmanson Theatre in Los Angeles in September 2015. The tour is scheduled to run until at least July 2017. Kerstin Anderson plays Maria, with Ben Davis as Capt. von Trapp and Ashley Brown as Mother Abess. The production has received warm reviews.

A UK tour produced by Bill Kenwright began in 2015 and toured into 2016. It was directed by Martin Connor and starred Lucy O'Byrne as Maria. A 2016 Australian tour of the Lloyd Webber production, directed by Sams, included stops in Sydney, Brisbane, Melbourne and Adelaide. The cast included Cameron Daddo as Captain Von Trapp, Marina Prior as Baroness Schraeder and Lorraine Bayly as Frau Schmidt. The choreographer was Arlene Phillips.

On March 2, 1965, 20th Century Fox released a film adaption of the musical starring Julie Andrews as Maria Rainer and Christopher Plummer as Captain Georg von Trapp. It was produced and directed by Robert Wise with the screenplay adaption written by Ernest Lehman. Two songs were written by Rodgers specifically for the film, "I Have Confidence" and "Something Good". The film won five Oscars at the 38th Academy Awards, including Best Picture. 

A live televised production of the musical aired twice in December 2013 on NBC. It was directed by Beth McCarthy-Miller and Rob Ashford. Carrie Underwood starred as Maria Rainer, with Stephen Moyer as Captain von Trapp, Christian Borle as Max, Laura Benanti as Elsa, and Audra McDonald as the Mother Abbess. The production was released on DVD the same month.

British network ITV presented a live version of its own on December 20, 2015. It starred Kara Tointon as Maria, Julian Ovenden as Captain von Trapp, Katherine Kelly as Baroness Schraeder and Alexander Armstrong as Max.

Most reviews of the original Broadway production were favorable. Richard Watts, Jr. of the "New York Post" stated that the show had "strangely gentle charm that is wonderfully endearing. "The Sound of Music" strives for nothing in the way of smash effects, substituting instead a kind of gracious and unpretentious simplicity." The "New York World-Telegram and Sun" pronounced "The Sound of Music" "the loveliest musical imaginable. It places Rodgers and Hammerstein back in top form as melodist and lyricist. The Lindsay-Crouse dialogue is vibrant and amusing in a plot that rises to genuine excitement." The "New York Journal American"s review opined that "The Sound of Music" is "the most mature product of the team ... it seemed to me to be the full ripening of these two extraordinary talents".

Brooks Atkinson of "The New York Times" gave a mixed assessment. He praised Mary Martin's performance, saying "she still has the same common touch ... same sharp features, goodwill, and glowing personality that makes music sound intimate and familiar" and stated that "the best of the "Sound of Music" is Rodgers and Hammerstein in good form". However, he said, the libretto "has the hackneyed look of the musical theatre replaced with "Oklahoma!" in 1943. It is disappointing to see the American musical stage succumbing to the clichés of operetta." Walter Kerr's review in the "New York Herald Tribune" was unfavorable: "Before "The Sound of Music" is halfway through its promising chores it becomes not only too sweet for words but almost too sweet for music", stating that the "evening suffer(s) from little children".

Columbia Masterworks recorded the original Broadway cast album a week after the show's 1959 opening. The album was the label's first deluxe package in a gatefold jacket, priced $1 higher than previous cast albums. It was #1 on Billboard's best-selling albums chart for 16 weeks in 1960. It was released on CD from Sony in the Columbia Broadway Masterworks series. In 1959, singer Patti Page recorded the title song from the show for Mercury Records on the day that the musical opened on Broadway. Since it was recorded a week before the original Broadway cast album, Page was the first artist to record any song from the musical. She featured the song on her TV show, "The Patti Page Olds Show", helping to popularize the musical. The 1960 London production was recorded by EMI and was issued on CD on the Broadway Angel Label.

The 1965 film soundtrack was released by RCA Victor and is one of the most successful soundtrack albums in history, having sold over 20 million copies worldwide. Recent CD editions incorporate musical material from the film that would not fit on the original LP. The label has also issued the soundtrack in German, Italian, Spanish and French editions. RCA Victor also released an album of the 1998 Broadway revival produced by Hallmark Entertainment and featuring the full revival cast, including Rebecca Luker, Michael Siberry, Jan Maxwell and Fred Applegate. The Telarc label made a studio cast recording of "The Sound of Music", with the Cincinnati Pops Orchestra conducted by Erich Kunzel (1987). The lead roles went to opera stars: Frederica von Stade as Maria, Håkan Hagegård as Captain von Trapp, and Eileen Farrell as the Mother Abbess. The recording "includes both the two new songs written for the film version and the three Broadway songs they replace, as well as a previously unrecorded verse of "An Ordinary Couple"". The 2006 London revival was recorded and has been released on the Decca Broadway label. There have been numerous studio cast albums and foreign cast albums issued, though many have only received regional distribution. According to the cast album database, there are 62 recordings of the score that have been issued over the years.

The from the 2013 NBC television production starring Carrie Underwood and Stephen Moyer was released on CD and digital download in December 2013 on the Sony Masterworks label. Also featured on the album are Audra McDonald, Laura Benanti and Christian Borle.





</doc>
<doc id="30021" url="https://en.wikipedia.org/wiki?curid=30021" title="Trip hop">
Trip hop

Trip hop (sometimes used synonymously with "downtempo") is a musical genre that originated in the early 1990s in the United Kingdom, especially Bristol. It has been described as "a fusion of hip hop and electronica until neither genre is recognizable," and may incorporate a variety of styles, including funk, dub, soul, psychedelia, R&B, and house, as well as other forms of electronic music. Trip hop can be highly experimental.

Deriving from later idioms of acid house, the term was first used by the British music media to describe the more experimental variant of breakbeat emerging from the Bristol Sound scene in the early 1990s, which contained influences of soul, funk, and jazz. It was pioneered by acts like Massive Attack, Tricky, and Portishead. Trip hop achieved commercial success in the 1990s, and has been described as "Europe's alternative choice in the second half of the '90s."

The term "trip-hop" first appeared in print in June 1994. Andy Pemberton, a music journalist writing for "Mixmag", used it to describe Mo' Wax Records Artist (U.K.) RPM and (American) DJ Shadow's "In/Flux" single.

In Bristol hip hop began to seep into the consciousness of a subculture already well-schooled in Jamaican forms of music. DJs, MCs, b-boys and graffiti artists grouped together into informal soundsystems. Like the pioneering Bronx crews of DJs Kool Herc, Afrika Bambataa and Grandmaster Flash, the soundsystems provided party music for public spaces, often in the economically deprived council estates from which some of their members originated. Bristol's soundsystem DJs, drawing heavily on Jamaican dub music, typically used a laid-back, slow and heavy drum beat ("down tempo").

Bristol's Wild Bunch crew became one of the soundsystems to put a local spin on the international phenomenon, helping to birth Bristol's signature sound of trip hop, often termed "the Bristol Sound". The Wild Bunch and its associates included at various times in its existence the MC Adrian "Tricky Kid" Thaws, the graffiti artist and lyricist Robert "3D" Del Naja, producer Jonny Dollar and the DJs Nellee Hooper, Andrew "Mushroom" Vowles and Grant "Daddy G" Marshall. As the hip hop scene matured in Bristol and musical trends evolved further toward acid jazz and house in the late 1980s, the golden era of the soundsystem began to end. The Wild Bunch signed a record deal and evolved into Massive Attack, a core collective of 3D, Mushroom and Daddy G, with significant contributions from Tricky Kid (soon shortened to Tricky), Dollar, and Hooper on production duties, along with a rotating cast of other vocalists.

Another influence came from Gary Clail's Tackhead soundsystem. Clail often worked with former The Pop Group singer Mark Stewart. The latter experimented with his band Mark Stewart & the Maffia, which consisted of New York session musicians Skip McDonald, Doug Wimbish, and Keith LeBlanc, who had been a part of the house band for the Sugarhill Records record label. Produced by Adrian Sherwood, the music combined hip hop with experimental rock and dub and sounded like a premature version of what later became trip hop. In 1993, Kirsty MacColl released "Angel", one of the first examples of the genre crossing over to pop, a hybrid that dominated the charts toward the end of the 1990s.

Massive Attack's first album "Blue Lines" was released in 1991 to huge success in the UK. "Blue Lines" was seen widely as the first major manifestation of a uniquely British hip hop movement, but the album's hit single "Unfinished Sympathy" and several other tracks, while their rhythms were largely sample-based, were not seen as hip hop songs in any conventional sense. Produced by Dollar, Shara Nelson (an R&B singer) featured on the orchestral "Unfinished", and Jamaican dance hall star Horace Andy provided vocals on several other tracks, as he would throughout Massive Attack's career. Massive Attack released their second album entitled "Protection" in 1994. Although Tricky stayed on in a lesser role, and Hooper again produced, the fertile dance music scene of the early 1990s had informed the record, and it was seen as an even more significant shift away from the Wild Bunch era.

In the June 1994 issue of UK magazine "Mixmag", music journalist Andy Pemberton used the term "trip hop" to describe the hip hop instrumental "In/Flux", a 1993 single by San Francisco's DJ Shadow, and other similar tracks released on the Mo' Wax label and being played in London clubs at the time. "In/Flux", with its mixed up bpms, spoken word samples, strings, melodies, bizarre noises, prominent bass, and slow beats, gave the listener the impression they were on a musical trip, according to Pemberton. Soon, however, Massive Attack's dubby, jazzy, psychedelic, electronic textures, rooted in hip hop sampling technique but taking flight into many styles, were described by journalists as the template of the eponymous genre.

In 1993, Icelandic musician Björk released "Debut", produced by Wild Bunch member Nellee Hooper. The album, although rooted in four-on-the-floor house music, contained elements of trip hop and is credited as one of the first albums to introduce electronic dance music into mainstream pop. She had been in contact with London's underground electronic music scene and was romantically involved with trip hop musician Tricky. Björk embraced trip hop even more with her 1995 album "Post" by collaborating with Tricky and Howie B. "Homogenic", her 1997 album, has been described as a pinnacle of trip hop music.

1994 and 1995 saw trip hop near the peak of its popularity, with artists such as Howie B and Earthling making significant contributions. Ninja Tune, the independent record label founded by the Coldcut duo, would significantly influence the trip-hop sound in London and beyond with breakthrough artists DJ Food, 9 Lazy 9, Up, Bustle & Out, Funki Porcini and The Herbaliser, among others. The period also marked the debut of two acts who, along with Massive Attack, would define the Bristol scene for years to come.

In 1994 Portishead, a trio comprising singer Beth Gibbons, Geoff Barrow, and Adrian Utley, released their debut album "Dummy". Their background differed from Massive Attack in many ways: one of Portishead's primary influences was 1960s and 1970s film soundtrack LPs. Nevertheless, Portishead shared the scratchy, jazz-sample-based aesthetic of early Massive Attack (whom Barrow had briefly worked with during the recording of "Blue Lines"), and the sullen, fragile vocals of Gibbons also brought them wide acclaim. In 1995, "Dummy" was awarded the Mercury Music Prize as the best British album of the year, giving trip-hop as a genre its greatest exposure yet. Portishead's music, seen as cutting edge in its film-noir feel and stylish, yet emotional appropriations of past sounds, was also widely imitated, causing the band to recoil from the trip-hop label they had inadvertently helped popularize.

Tricky also released his debut solo album "Maxinquaye" in 1995, to great critical acclaim. The album was produced largely in collaboration with Mark Saunders. Tricky employed whispered, often abstract stream-of-consciousness murmuring, remote from the gangsta-rap braggadocio of the mid-1990s US hip hop scene. Even more unusually, however, many of the solo songs on "Maxinquaye" featured little of Tricky's own voice: his then-lover, Martina Topley-Bird, sang them, including her reimagining of Public Enemy's militant 1988 rap "Black Steel in the Hour of Chaos", while other songs were male-female duets dealing with sex and love in oblique ways, over beds of sometimes dissonant samples. Within a year Tricky had released two more full-length albums which were considered even more challenging, without finding the same popularity as his Bristol contemporaries Massive Attack and Portishead. Through his brief collaborations with Björk, however, he also exerted influence closer to the pop and alternative rock mainstream, and he developed a large cult fan-base.

Musician Poe released her 1995 debut "Hello", an album that featured trip-hop elements, to critical praise.

Although not as popular in the United States, bands like Portishead and Sneaker Pimps saw moderate airplay on alternative-rock stations across the country.

After the initial success of trip hop in the mid-1990s, notable "post-trip-hop" artists include Bowery Electric, Esthero, Morcheeba, Sneaker Pimps, Anomie Belle, Alpha, Jaianto, Mudville and Cibo Matto and Lamb. These artists incorporated trip hop into other genres, including ambient, soul, IDM, industrial, dubstep, breakbeat, drum and bass, acid jazz, and new-age. The first printed use of the term "post-trip hop" was in an October 2002 article of "The Independent", and was used to describe the band Second Person.

Trip hop has also influenced artists in other genres, including Gorillaz, Emancipator, Nine Inch Nails, Travis, Queens of the Stone Age, Allflaws, How to Destroy Angels, Beth Orton, The Flaming Lips, , Beck, and Deftones. Several tracks on Australian pop singer Kylie Minogue's 1997 album "Impossible Princess" also displayed a trip hop influence.

Various prominent artists and groups, such as Janet Jackson, Kylie Minogue, Madonna, Björk, and Radiohead, have also been influenced by the genre. Trip hop has spawned several subgenres, including Illbient, (dub-based trip hop which combines ambient and industrial hip hop).

Trip hop continued to influence notable artists in the 2000s. Norwegian avant-garde band Ulver incorporated trip hop in their ambient/electronic/jazzy album "Perdition City". Atmospheric rock band Antimatter included some trip hop elements in their first two albums. Australian composer Rob Dougan proposed a mix of trip hop beats, orchestral music and electronics. RJD2 began his career as a DJ, but in 2001, began releasing albums under El-P's Def Jux Label. Zero 7's album "Simple Things", and in particular, its lead single "Destiny", was regarded highly by underground listeners and achieved significant popularity. In 2006, Gotye debuted his second studio album, "Like Drawing Blood". The songs on the album featured down-tempo hip-hop beats and dub style bass reminiscent of trip hop. Hip hop groups Zion I and the Dub Pistols also displayed heavy trip hop influence. Norwegian singer and songwriter Kate Havnevik is a classically trained musician, but also incorporates trip hop into her work.

Many producers who were not explicitly trip-hop artists also displayed its influence during the early 2000s. Daniel Nakamura, aka Dan The Automator, released two albums that were heavily inspired by trip hop. 2000 album "Deltron 3030", was a concept album about a rapper, portrayed by Del Tha Funkee Homosapien, from the future. 2001 saw the release of his side project, Lovage. "Music to Make Love to Your Old Lady By", with special guests Mike Patton, Prince Paul, Maseo, Damon Albarn, and Afrika Bambaataa. British producer Fatboy Slim's breakthrough album, "Halfway Between the Gutter and The Stars", was his most commercially successful release.

Major notable releases include Massive Attack's "Heligoland" and Dutch's "A Bright Cold Day" in 2010.

DJ Shadow's "The Less You Know, the Better" was released in 2011.

Geoff Barrow's album titled "»" was released in 2012.

Lana Del Rey released her second album, "Born to Die" in 2012, which contained a string of trip hop ballads, topped the charts in eleven countries, including Australia, France, Germany, and the United Kingdom; and has sold 3.4 million copies worldwide as of 2013 according to International Federation of the Phonographic Industry.

Common musical aesthetics include a bass-heavy drumbeat, often emulating the slowed down breakbeat samples typical of hip hop in the 1990s, giving the genre a more psychedelic touch. Vocals in trip hop are often female and feature characteristics of various singing styles including R&B, jazz and rock. The female-dominant vocals of trip hop may be partially attributable to the influence of genres such as jazz and early R&B, in which female vocalists were more common. However, there are notable exceptions - Massive Attack & Groove Armada collaborates with vocalists of mixed genders, Tricky often features vocally in his own productions along with Martina Topley-Bird, and Chris Corner provided vocals for later albums with Sneaker Pimps.

Trip hop is also known for its melancholy sound. This may be partly due to the fact that several acts were inspired by post punk bands; Tricky and Massive Attack both covered and sampled songs of Siouxsie and the Banshees and The Cure. Tricky opened his second album "Nearly God" by a version of "Tattoo", a proto-trip-hop song of Siouxsie and the Banshees initially recorded in 1983.

Trip hop tracks often incorporate Rhodes pianos, saxophones, trumpets, and flutes, and may employ unconventional instruments such as the theremin and Mellotron. Trip hop differs from hip hop in theme and overall tone. Instead of gangsta rap with its hard-hitting lyrics, trip hop offers a more aural atmospherics with instrumental hip hop, turntable scratching, and breakbeat rhythms. Regarded in some ways as a 1990s update of fusion, trip hop may be said to "transcend" the hardcore rap styles and lyrics with atmospheric overtones to create a more mellow tempo.




</doc>
<doc id="30027" url="https://en.wikipedia.org/wiki?curid=30027" title="Tycho Brahe">
Tycho Brahe

Tycho Brahe (; born Tyge Ottesen Brahe; 14 December 154624 October 1601) was a Danish nobleman, astronomer, and writer known for his accurate and comprehensive astronomical and planetary observations. He was born in the then Danish peninsula of Scania. Well known in his lifetime as an astronomer, astrologer and alchemist, he has been described as "the first competent mind in modern astronomy to feel ardently the passion for exact empirical facts." His observations were some five times more accurate than the best available observations at the time.

An heir to several of Denmark's principal noble families, he received a comprehensive education. He took an interest in astronomy and in the creation of more accurate instruments of measurement. As an astronomer, Tycho worked to combine what he saw as the geometrical benefits of the Copernican system with the philosophical benefits of the Ptolemaic system into his own model of the universe, the Tychonic system. His system correctly saw the Moon as orbiting Earth, and the planets as orbiting the Sun, but erroneously considered the Sun to be orbiting the Earth. Furthermore, he was the last of the major naked-eye astronomers, working without telescopes for his observations. In his "De nova stella" ("On the New Star") of 1573, he refuted the Aristotelian belief in an unchanging celestial realm. His precise measurements indicated that "new stars" (stellae novae, now known as supernovae), in particular that of 1572, lacked the parallax expected in sublunar phenomena and were therefore not tailless comets in the atmosphere as previously believed but were above the atmosphere and beyond the moon. Using similar measurements he showed that comets were also not atmospheric phenomena, as previously thought, and must pass through the supposedly immutable celestial spheres.

King Frederick II granted Tycho an estate on the island of Hven and the funding to build Uraniborg, an early research institute, where he built large astronomical instruments and took many careful measurements, and later Stjerneborg, underground, when he discovered that his instruments in Uraniborg were not sufficiently steady. On the island (where he behaved autocratically toward the residents) he founded manufactories, such as a paper mill, to provide material for printing his results. After disagreements with the new Danish king, Christian IV, in 1597, he went into exile, and was invited by the Bohemian king and Holy Roman Emperor Rudolph II to Prague, where he became the official imperial astronomer. He built an observatory at Benátky nad Jizerou. There, from 1600 until his death in 1601, he was assisted by Johannes Kepler, who later used Tycho's astronomical data to develop his three laws of planetary motion.

Tycho's body has been exhumed twice, in 1901 and 2010, to examine the circumstances of his death and to identify the material from which his artificial nose was made. The conclusion was that his death was likely caused by a burst bladder, and not by poisoning as had been suggested, and that the artificial nose was more likely made of brass than silver or gold, as some had believed in his time.

Tycho was born as heir to several of Denmark's most influential noble families and in addition to his immediate ancestry with the Brahe and the Bille families, he also counted the Rud, Trolle, Ulfstand, and Rosenkrantz families among his ancestors. Both of his grandfathers and all of his great grandfathers had served as members of the Danish king's Privy Council. His paternal grandfather and namesake Thyge Brahe was the lord of Tosterup Castle in Scania and died in battle during the 1523 Siege of Malmö during the Lutheran Reformation Wars. His maternal grandfather Claus Bille, lord to Bohus Castle and a second cousin of Swedish king Gustav Vasa, participated in the Stockholm Bloodbath on the side of the Danish king against the Swedish nobles. Tycho's father Otte Brahe, like his father a royal Privy Councilor, married Beate Bille, who was herself a powerful figure at the Danish court holding several royal land titles. Both parents are buried under the floor of Kågeröd Church, four kilometres east of Knutstorp.

Tycho was born at his family's ancestral seat of Knutstorp Castle (Danish: "Knudstrup borg"; Swedish: "Knutstorps borg"), about eight kilometres north of Svalöv in then Danish Scania. He was the oldest of 12 siblings, 8 of whom lived to adulthood. His twin brother died before being baptized. Tycho later wrote an ode in Latin to his dead twin, which was printed in 1572 as his first published work. An epitaph, originally from Knutstorp, but now on a plaque near the church door, shows the whole family, including Tycho as a boy.

When he was only two years old Tycho was taken away to be raised by his uncle Jørgen Thygesen Brahe and his wife Inger Oxe (sister to Peder Oxe, Steward of the Realm) who were childless. It is unclear why the Otte Brahe reached this arrangement with his brother, but Tycho was the only one of his siblings not to be raised by his mother at Knutstorp. Instead, Tycho was raised at Jørgen Brahe's estate at Tosterup and at Tranekær on the island of Langeland, and later at Næsbyhoved Castle near Odense, and later again at the Castle of Nykøbing on the island of Falster. Tycho later wrote that Jørgen Brahe "raised me and generously provided for me during his life until my eighteenth year; he always treated me as his own son and made me his heir".

From ages 6 to 12, Tycho attended Latin school, probably in Nykøbing. At age 12, on 19 April 1559, Tycho began studies at the University of Copenhagen. There, following his uncle's wishes, he studied law, but also studied a variety of other subjects and became interested in astronomy. At the University, Aristotle was a staple of scientific theory, and Tycho likely received a thorough training in Aristotelian physics and cosmology. He experienced the solar eclipse of 21 August 1560, and was greatly impressed by the fact that it had been predicted, although the prediction based on current observational data was a day off. He realized that more accurate observations would be the key to making more exact predictions. He purchased an ephemeris and books on astronomy, including Johannes de Sacrobosco's "De sphaera mundi", Petrus Apianus's "Cosmographia seu descriptio totius orbis" and Regiomontanus's "De triangulis omnimodis".

Jørgen Thygesen Brahe, however, wanted Tycho to educate himself in order to become a civil servant, and sent him on a study tour of Europe in early 1562. 15-year old Tycho was given as mentor the 19-year-old Anders Sørensen Vedel, whom he eventually talked into allowing the pursuit of astronomy during the tour. Vedel and his pupil left Copenhagen in February 1562. On 24 March, they arrived in Leipzig, where they matriculated at the Lutheran Leipzig University. In 1563, he observed a conjunction of Jupiter and Saturn, and noticed that the Copernican and Ptolemaic tables used to predict the conjunction were inaccurate. This led him to realize that progress in astronomy required systematic, rigorous observation, night after night, using the most accurate instruments obtainable. He began maintaining detailed journals of all his astronomical observations. In this period, he combined the study of astronomy with astrology, laying down horoscopes for different famous personalities.

When Tycho and Vedel returned from Leipzig in 1565, Denmark was at war with Sweden, and as vice-admiral of the Danish fleet Jørgen Brahe had become a national hero for having participated in the sinking of the Swedish warship "Mars" during the First battle of Öland (1564). Shortly after Tycho's arrival in Denmark, Jørgen Brahe was defeated in the Action of 4 June 1565, and shortly afterwards died of a fever. Stories have it that he contracted pneumonia after a night of drinking with the Danish King Frederick II when the king fell into the water in a Copenhagen canal and Brahe jumped in after him. Brahe's possessions passed on to his wife Inger Oxe, who considered Tycho with special fondness.

In 1566, Tycho Brahe left to study at the University of Rostock. Here, he studied with professors of medicine at the university's famous medical school. Here, he became interested in medical alchemy and botanical medicine. On 29 December 1566, Tycho lost part of his nose in a sword duel against a fellow Danish nobleman, Manderup Parsberg (his third cousin). Tycho had quarreled with Parsberg at a wedding dance at Professor Lucas Bachmeister's house on 10 December, and again on the 27th, and the two ended up resolving whatever issue they were quarreling about with a duel. Though the two were later reconciled, the duel (in the dark) resulted in Tycho losing the bridge of his nose, and gaining a broad scar across his forehead. At the university, he received the best possible care, and for the rest of his life he wore a prosthetic nose, said to be made of silver and gold, kept in place with a paste or glue. In November 2012, Danish and Czech researchers reported that the prosthetic was made out of brass after chemically analyzing a small bone sample from the nose from the body exhumed in 2010.

In April 1567, Tycho returned home from his travels, with a firm intention of becoming a scientist. Although he had been expected to go into politics and the law, like most of his kinsmen, and although Denmark was still at war with Sweden, his family supported his decision to dedicate himself to the sciences. His father wanted him to take up law, but Tycho was allowed to travel to Rostock and then to Augsburg (where he built a great quadrant), Basel, and Freiburg. In 1568, he was appointed a canon at the Cathedral of Roskilde, a largely honorary position that would allow him to focus on his studies. At the end of 1570, he was informed of his father's ill health, so he returned to Knutstorp Castle, where his father died on 9 May 1571. The war was over, and the Danish lords soon returned to prosperity. Soon, another uncle, Steen Bille, helped him build an observatory and alchemical laboratory at Herrevad Abbey.

Towards the end of 1571, Tycho fell in love with Kirsten, daughter of Jørgen Hansen, the Lutheran minister in Knudstrup. As she was a commoner, Tycho never formally married her, since if he did he would lose his noble privileges. However, Danish law permitted morganatic marriage, which meant that a nobleman and a common woman could live together openly as husband and wife for three years, and their alliance then became a legally binding marriage. However, each would maintain their social status, and any children they had together would be considered commoners, with no rights to titles, landholdings, coat of arms, or even their father's noble name. While King Frederick respected Tycho's choice of wife, himself having been unable to marry the woman he loved, many of Tycho's family members disagreed, and many churchmen would continue to hold the lack of a divinely sanctioned marriage against him. Kirsten Jørgensdatter gave birth to their first daughter, Kirstine (named after Tycho's late sister) on 12October 1573. Kirstine died from the plague in 1576, and Tycho wrote a heartfelt elegy for her tombstone. Together, they had eight children, six of whom lived to adulthood. In 1574, they moved to Copenhagen where their daughter Magdalene was born, later the family followed him into exile. Kirsten and Tycho lived together for almost thirty years until Tycho's death.

On 11 November 1572, Tycho observed (from Herrevad Abbey) a very bright star, now numbered SN 1572, which had unexpectedly appeared in the constellation Cassiopeia. Because it had been maintained since antiquity that the world beyond the Moon's orbit was eternally unchangeable (celestial immutability was a fundamental axiom of the Aristotelian world-view), other observers held that the phenomenon was something in the terrestrial sphere below the Moon. However, in the first instance, Tycho observed that the object showed no daily parallax against the background of the fixed stars. This implied it was at least farther away than the Moon and those planets that do show such parallax. He also found the object did not change its position relative to the fixed stars over several months, as all planets did in their periodic orbital motions, even the outer planets for which no daily parallax was detectable. This suggested it was not even a planet, but a fixed star in the stellar sphere beyond all the planets. In 1573, he published a small book, "De nova stella" thereby coining the term nova for a "new" star (we now classify this star as a supernova and we know that it is 7,500 light-years from Earth). This discovery was decisive for his choice of astronomy as a profession. Tycho was strongly critical of those who dismissed the implications of the astronomical appearance, writing in the preface to "De nova stella": ""O crassa ingenia. O caecos coeli spectatores"" ("Oh thick wits. Oh blind watchers of the sky"). The publication of his discovery made him a well-known name among scientists across Europe.

Tycho continued with his detailed observations, often assisted by his first assistant and student, his younger sister Sophie Brahe. In 1574, Tycho published the observations made in 1572 from his first observatory at Herrevad Abbey. He then started lecturing on astronomy, but gave it up and left Denmark in spring 1575 to tour abroad. He first visited William IV, Landgrave of Hesse-Kassel's observatory at Kassel, then went on to Frankfurt, Basel and Venice, where he acted as an agent for the Danish king, contacting artisans and craftsmen whom the king wanted to work on his new palace at Elsinore. Upon his return, the King wished to repay Tycho's service by offering him a position worthy of his family; he offered him a choice of lordships of militarily and economically important estates, such as the castles of Hammershus or Helsingborg. But Tycho was reluctant to take up a position as a lord of the realm, preferring to focus on his science. He wrote to his friend Johannes Pratensis, "I did not want to take possession of any of the castles our benevolent king so graciously offered me. I am displeased with society here, customary forms and the whole rubbish". Tycho secretly began to plan to move to Basel, wishing to participate in the burgeoning academic and scientific life there. But the King heard of Tycho's plans, and desiring to keep the distinguished scientist, he offered Tycho the island of Hven in Øresund and funding to set up an observatory.
Until then, Hven had been property directly under the Crown, and the 50 families on the island considered themselves to be freeholding farmers, but with Tycho Brahe's appointment as Feudal Lord of Hven, this changed. Tycho took control of agricultural planning, requiring the peasants to cultivate twice as much as they had done before, and he also exacted corvée labor from the peasants for the construction of his new castle. The peasants complained about Brahe's excessive taxation and took him to court. The court established Tycho's right to levy taxes and labor, and the result was a contract detailing the mutual obligations of lord and peasants on the island.

Brahe envisioned his castle Uraniborg as a temple dedicated to the muses of arts and sciences, rather than as a military fortress; indeed, it was named after Urania, the muse of astronomy. Construction began in 1576 (with a laboratory for his alchemical experiments in the cellar). Uraniborg was inspired by the Venetian architect Andrea Palladio, and was one of the first buildings in northern Europe to show influence from Italian renaissance architecture. When he realized that the towers of Uraniborg were not adequate as observatories because of the instruments' exposure to the elements and the movement of the building, he then constructed a second underground observatory at nearby Stjerneborg in 1581. The basement included an alchemical laboratory with 16 furnaces for conducting distillations and other chemical experiments. Unusually for the time, Tycho established Uraniborg as a research centre, where almost 100 students and artisans worked from 1576 to 1597. Uraniborg also contained a printing press and a paper mill, both among the first in Scandinavia, enabling Tycho to publish his own manuscripts, on locally made paper with his own watermark. He created a system of ponds and canals to run the wheels of the paper mill. Over the years he worked on Uraniborg, Tycho was assisted by a number of students and protegés, many of whom went on to their own careers in astronomy: among them were Christian Sørensen Longomontanus, later one of the main proponents of the Tychonic model and Tycho's replacement as royal Danish astronomer; Peder Flemløse; Elias Olsen Morsing; and Cort Aslakssøn. Tycho's instrument-maker Hans Crol also formed part of the scientific community on the island.
He observed the great comet that was visible in the Northern sky from November 1577 to January 1578. Within Lutheranism, it was commonly believed that celestial objects like comets were powerful portents, announcing the coming apocalypse, and in addition to Tycho's observations several Danish amateur astronomers observed the object and published prophesies of impending doom. He was able to determine that the comet's distance to Earth was much greater than the distance of the Moon, so that the comet could not have originated in the "earthly sphere", confirming his prior anti-Aristotelian conclusions about the fixed nature of the sky beyond the Moon. He also realized that the comet's tail was always pointing away from the Sun. He calculated its diameter, mass, and the length of its tail, and speculated about the material it was made of. At this point, he had not yet broken with Copernican theory, and observing the comet inspired him to try to develop an alternative Copernican model in which the Earth was immobile. The second half of his manuscript about the comet dealt with the astrological and apocalyptic aspects of the comet, and he rejected the prophesies of his competitors; instead, making his own predictions of dire political events in the near future. Among his predictions was bloodshed in Moscow and the imminent fall of Ivan the Terrible by 1583.
The support that Tycho received from the Crown was substantial, amounting to 1% of the annual total revenue at one point in the 1580s. Tycho often held large social gatherings in his castle. Pierre Gassendi wrote that Tycho also had a tame elk (moose) and that his mentor the Landgrave Wilhelm of Hesse-Kassel (Hesse-Cassel) asked whether there was an animal faster than a deer. Tycho replied that there was none, but he could send his tame elk. When Wilhelm replied he would accept one in exchange for a horse, Tycho replied with the sad news that the elk had just died on a visit to entertain a nobleman at Landskrona. Apparently, during dinner, the elk had drunk a lot of beer, fallen down the stairs, and died. Among the many noble visitors to Hven was James VI of Scotland, who married the Danish princess Anne. After his visit to Hven in 1590, he wrote a poem comparing Tycho Brahe with Apollon and Phaethon.

As part of Tycho's duties to the Crown in exchange for his estate, he fulfilled the functions of a royal astrologer. At the beginning of each year, he had to present an Almanac to the court, predicting the influence of the stars on the political and economic prospects of the year. And at the birth of each prince, he prepared their horoscopes, predicting their fates. He also worked as a cartographer with his former tutor Anders Sørensen Vedel on mapping out all of the Danish realm. An ally of the king and friendly with Queen Sophie (both his mother Beate Bille and adoptive mother Inger Oxe had been her court maids), he secured a promise from the King that ownership of Hven and Uraniborg would pass to his heirs.

In 1588, Tycho's royal benefactor died, and a volume of Tycho's great two-volume work "Astronomiae Instauratae Progymnasmata" ("Introduction to the New Astronomy") was published. The first volume, devoted to the new star of 1572, was not ready, because the reduction of the observations of 1572–3 involved much research to correct the stars' positions for refraction, precession, the motion of the Sun etc., and was not completed in Tycho's lifetime (it was published in Prague in 1602/03), but the second volume, titled "De Mundi Aetherei Recentioribus Phaenomenis Liber Secundus" ("Second Book About Recent Phenomena in the Celestial World") and devoted to the comet of 1577, was printed at Uraniborg and some copies were issued in 1588. Besides the comet observations, it included an account of Tycho's system of the world. The third volume was intended to treat the comets of 1580 and following years in a similar manner, but it was never published, nor even written, though a great deal of material about the comet of 1585 was put together and first published in 1845 with the observations of this comet.

While at Uraniborg, Tycho Brahe maintained correspondence with scientists and astronomers across Europe. He inquired about other astronomers' observations and shared his own technological advances to help them achieve more accurate observations. Thus, his correspondence was crucial to his research. Often, correspondence was not just private communication between scholars, but also a way to disseminate results and arguments and to build progress and scientific consensus. Through correspondence, Tycho Brahe was involved in several personal disputes with critics of his theories. Prominent among them were John Craig, a Scottish physician who was a strong believer in the authority of the Aristotelian worldview, and Nicolaus Reimers Baer, known as Ursus, an astronomer at the Imperial court in Prague, whom Tycho accused of having plagiarized his cosmological model. Craig refused to accept Brahe's conclusion that the comet of 1577 had to be located within the aetherial sphere rather than within the atmosphere of Earth. Craig tried to contradict Brahe by using his own observations of the comet, and by questioning his methodology. Brahe published an "apologia" (a defense) of his conclusions, in which he provided additional arguments, as well as condemning Craig's ideas in strong language for being incompetent. Another dispute concerned the mathematician Paul Wittich, who, after staying on Hven in 1580, taught Count Wilhelm of Kassel and his astronomer Christoph Rothmann to build copies of Brahe's instruments without permission from Brahe. In turn, Craig, who had studied with Wittich, accused Brahe of minimizing Wittich's role in developing some of the trigonometric methods used by Brahe. In his dealings with these disputes, Tycho Brahe made sure to leverage his support in the scientific community, by publishing and disseminating his own answers and arguments.

When Frederick died in 1588, his son and heir Christian IV was only 11 years old. A regency council was appointed to rule for the young prince-elect until his coronation in 1596. The head of the council (Steward of the Realm) was Christoffer Valkendorff, who disliked Tycho Brahe after a conflict between them, and hence Tycho's influence at the Danish court steadily declined. Feeling that his legacy on Hven was in peril, he approached the Dowager Queen Sophie and asked her to affirm in writing her late husband's promise to endow Hven to Tycho's heirs. Nonetheless, he realized that the young king was more interested in war than in science, and was of no mind to keep his father's promise. King Christian IV followed a policy of curbing the power of the nobility by confiscating their estates to minimize their income bases, by accusing nobles of misusing their offices and of heresies against the Lutheran church. Tycho, who was known to sympathize with the Philippists (followers of Philip Melanchthon), was among the nobles who fell out of grace with the new king. The king's unfavorable disposition towards Tycho was likely also a result of efforts by several of his enemies at court to turn the king against him. Tycho's enemies included, in addition to Valkendorff, the king's doctor Peter Severinus, who also had a personal gripes with Brahe, and several gnesio-Lutheran Bishops who suspected Brahe of heresy — a suspicion motivated by his known Philippist sympathies, his pursuits in medicine and alchemy (both of which he practiced without the church's approval) and his prohibiting the local priest on Hven to include the exorcism in the baptismal ritual. Among the accusations raised against Tycho Brahe were his failure to adequately maintain the royal chapel at Roskilde, and his harshness and exploitation of the Hven peasantry.

The straw that broke the camel's back for Tycho was when a mob of commoners, possibly incited by his enemies at court, rioted in front of his house in Copenhagen. Tycho Brahe left Hven in 1597, bringing some of his instruments with him to Copenhagen, and entrusting others to a caretaker on the island. Shortly before leaving, he completed his star catalogue giving the positions of 1,000 stars. After some unsuccessful attempts at influencing the king to let him return, he finally acquiesced to exile, but he wrote his most famous poem "Elegy to Dania" in which he chided Denmark for not appreciating his genius. The instruments he had used in Uraniborg and Stjerneborg were depicted and described in detail in his book "Astronomiae instauratae mechanica" or "Instruments for the restoration of astronomy", first published in 1598. The King sent two envoys to Hven to describe the instruments left behind by Brahe. Unversed in astronomy, the envoys reported to the king that the large mechanical contraptions such as his large quadrant and sextant were "useless and even harmful".

From 1597 to 1598, he spent a year at the castle of his friend Heinrich Rantzau in Wandesburg outside Hamburg, and then they moved for a while to Wittenberg, where they stayed in the former home of Philip Melanchthon.

In 1599, he obtained the sponsorship of Rudolf II, Holy Roman Emperor and moved to Prague, as Imperial Court Astronomer. Tycho built a new observatory in a castle in Benátky nad Jizerou, 50 km from Prague, and worked there for one year. The emperor then brought him back to Prague, where he stayed until his death. At the imperial court even Tycho's wife and children were treated like nobility, which they had never been at the Danish court.

Tycho received financial support from several nobles in addition to the emperor, including Oldrich Desiderius Pruskowsky von Pruskow, to whom he dedicated his famous "Mechanica". In return for their support, Tycho's duties included preparing astrological charts and predictions for his patrons at events such as births, weather forecasting, and astrological interpretations of significant astronomical events, such as the supernova of 1572 (sometimes called Tycho's supernova) and the Great Comet of 1577.

In Prague, Tycho worked closely with Johannes Kepler, his assistant. Kepler was a convinced Copernican, and considered Tycho's model to be mistaken, and derived from simple "inversion" of the Sun's and Earth's positions in the Copernican model. Together, the two worked on a new star catalogue based on his own accurate positions — this catalogue became the "Rudolphine Tables". Also at the court in Prague was the mathematician Nicolaus Reimers (Ursus), with whom Tycho had previously corresponded, and who, like Tycho, had developed a geo-heliocentric planetary model, which Tycho considered to have been plagiarized from his own. Kepler had previously spoken highly of Ursus, but now found himself in the problematic position of being employed by Tycho and having to defend his employer against Ursus' accusations, even though he disagreed with both of their planetary models. In 1600, he finished the tract "Apologia pro Tychone contra Ursum" (defense of Tycho against Ursus). Kepler had great respect for Tycho's methods and the accuracy of his observations and considered him to be the new Hipparchus, who would provide the foundation for a restoration of the science of astronomy.

Tycho suddenly contracted a bladder or kidney ailment after attending a banquet in Prague, and died eleven days later, on 24 October 1601, at the age of 54. According to Kepler's first-hand account, Tycho had refused to leave the banquet to relieve himself because it would have been a breach of etiquette. After he returned home, he was no longer able to urinate, except eventually in very small quantities and with excruciating pain. The night before he died, he suffered from a delirium during which he was frequently heard to exclaim that he hoped he would not seem to have lived in vain. Before dying, he urged Kepler to finish the "Rudolphine Tables" and expressed the hope that he would do so by adopting Tycho's own planetary system, rather than that of Copernicus. It was reported that Brahe had written his own epitaph, "He lived like a sage and died like a fool." A contemporary physician attributed his death to a kidney stone, but no kidney stones were found during an autopsy performed after his body was exhumed in 1901, and the 20th-century medical assessment is that his death is more likely to have resulted from uremia.

The investigations in the 1990s have suggested that Tycho may not have died from urinary problems, but instead from mercury poisoning. It was speculated that he had been intentionally poisoned. The two main suspects were his assistant, Johannes Kepler, whose motives would be to gain access to Brahe's laboratory and chemicals, and his cousin, Erik Brahe, at the order of friend-turned-enemy Christian IV, because of rumors that Tycho had had an affair with Christian's mother.

In February 2010, the Prague city authorities approved a request by Danish scientists to exhume the remains, and in November 2010 a group of Czech and Danish scientists from Aarhus University collected bone, hair and clothing samples for analysis. The scientists, led by Dr Jens Vellev, analyzed Tycho's beard hair once again. The team reported in November 2012 that not only was there not enough mercury present to substantiate murder, but that there were no lethal levels of any poisons present. The team's conclusion was that "it is impossible that Tycho Brahe could have been murdered". The findings were confirmed by scientists from the University of Rostock, who examined a sample of Brahe's beard hairs that had been taken in 1901. Although traces of mercury were found, these were present only in the outer scales. Therefore, mercury poisoning as the cause of death was ruled out, while the study suggests that the accumulation of mercury may have come from the "precipitation of mercury dust from the air during [Brahe's] long-term alchemistic activities". The hair samples contain 20–100 times the natural concentration of gold until 2 months before his death.

Tycho is buried in the Church of Our Lady before Týn, in Old Town Square near the Prague Astronomical Clock.

Tycho's view of science was driven by his passion for accurate observations, and the quest for improved instruments of measurement drove his life's work. Tycho was the last major astronomer to work without the aid of a telescope, soon to be turned skyward by Galileo and others. Given the limitations of the naked eye for making accurate observations, he devoted many of his efforts to improving the accuracy of the existing types of instrument — the sextant and the quadrant. He designed larger versions of these instruments, which allowed him to achieve much higher accuracy. Because of the accuracy of his instruments, he quickly realized the influence of wind and the movement of buildings, and instead opted to mount his instruments underground directly on the bedrock.

Tycho's observations of stellar and planetary positions were noteworthy both for their accuracy and quantity. With an accuracy approaching one arcminute, his celestial positions were much more accurate than those of any predecessor or contemporary — about five times as accurate as the observations of the contemporary astronomer Wilhelm of Hesse. asserts of Tycho's Star Catalog D, "In it, Tycho achieved, on a mass scale, a precision far beyond that of earlier catalogers. Cat D represents an unprecedented confluence of skills: instrumental, observational, & computational—all of which combined to enable Tycho to place most of his hundreds of recorded stars to an accuracy of ordermag 1'!"
He aspired to a level of accuracy in his estimated positions of celestial bodies of being consistently within a arcminute of their real celestial locations, and also claimed to have achieved this level. But, in fact, many of the stellar positions in his star catalogues were less accurate than that. The median errors for the stellar positions in his final published catalog were about 1.5', indicating that only half of the entries were more accurate than that, with an overall mean error in each coordinate of around 2'. Although the stellar observations as recorded in his observational logs were more accurate, varying from 32.3" to 48.8" for different instruments, systematic errors of as much as 3' were introduced into some of the stellar positions Tycho published in his star catalog — due, for instance, to his application of an erroneous ancient value of parallax and his neglect of polestar refraction. Incorrect transcription in the final published star catalogue, by scribes in Brahe's employ, was the source of even larger errors, sometimes by many degrees.

Celestial objects observed near the horizon and above appear with a greater altitude than the real one, due to atmospheric refraction, and one of Tycho's most important innovations was that he worked out and published the very first tables for the systematic correction of this possible source of error. But, as advanced as they were, they attributed no refraction whatever above 45 degrees altitude for solar refraction, and none for starlight above 20 degrees altitude.

To perform the huge number of multiplications needed to produce much of his astronomical data, Tycho relied heavily on the then new technique of "prosthaphaeresis", an algorithm for approximating products based on trigonometric identities that predated logarithms.

Although Tycho admired Copernicus and was the first to teach his theory in Denmark, he was unable to reconcile Copernican theory with the basic laws of Aristotelian physics, that he considered to be foundational. He was also critical of the observational data that Copernicus built his theory on, which he correctly considered to have a high margin of error. Instead, Tycho proposed a "geo-heliocentric" system in which the Sun and Moon orbited the Earth, while the other planets orbited the Sun. Tycho's system had many of the same observational and computational advantages that Copernicus' system had, and both systems also could accommodate the phases of Venus, although Galilei had yet to discover them. Tycho's system provided a safe position for astronomers who were dissatisfied with older models but were reluctant to accept the heliocentrism and the Earth's motion. It gained a considerable following after 1616 when Rome declared that the heliocentric model was contrary to both philosophy and Scripture, and could be discussed only as a computational convenience that had no connection to fact. Tycho's system also offered a major innovation: while both the purely geocentric model and the heliocentric model as set forth by Copernicus relied on the idea of transparent rotating crystalline spheres to carry the planets in their orbits, Tycho eliminated the spheres entirely. Kepler, as well as other Copernican astronomers, tried to persuade Tycho to adopt the heliocentric model of the solar system, but he was not persuaded. According to Tycho, the idea of a rotating and revolving Earth would be "in violation not only of all physical truth but also of the authority of Holy Scripture, which ought to be paramount."

With respect to physics, Tycho held that the Earth was just too sluggish and heavy to be continuously in motion. According to the accepted Aristotelian physics of the time, the heavens (whose motions and cycles were continuous and unending) were made of "Aether" or "Quintessence"; this substance, not found on Earth, was light, strong, unchanging, and its natural state was circular motion. By contrast, the Earth (where objects seem to have motion only when moved) and things on it were composed of substances that were heavy and whose natural state was rest. Accordingly, Tycho said the Earth was a "lazy" body that was not readily moved. Thus while Tycho acknowledged that the daily rising and setting of the sun and stars could be explained by the Earth's rotation, as Copernicus had said, still such a fast motion could not belong to the earth, a body very heavy and dense and opaque, but rather belongs to the sky itself whose form and subtle and constant matter are better suited to a perpetual motion, however fast. 

With respect to the stars, Tycho also believed that, if the Earth orbited the Sun annually, there should be an observable stellar parallax over any period of six months, during which the angular orientation of a given star would change thanks to Earth's changing position. (This parallax does exist, but is so small it was not detected until 1838, when Friedrich Bessel discovered a parallax of 0.314 arcseconds of the star 61 Cygni.) The Copernican explanation for this lack of parallax was that the stars were such a great distance from Earth that Earth's orbit was almost insignificant by comparison. However, Tycho noted that this explanation introduced another problem: Stars as seen by the naked eye appear small, but of some size, with more prominent stars such as Vega appearing larger than lesser stars such as Polaris, which in turn appear larger than many others. Tycho had determined that a typical star measured approximately a minute of arc in size, with more prominent ones being two or three times as large. In writing to Christoph Rothmann, a Copernican astronomer, Tycho used basic geometry to show that, assuming a small parallax that just escaped detection, the distance to the stars in the Copernican system would have to be 700 times greater than the distance from the sun to Saturn. Moreover, the only way the stars could be so distant and still appear the sizes they do in the sky would be if even average stars were gigantic — at least as big as the orbit of the Earth, and of course vastly larger than the sun. And, Tycho said, the more prominent stars would have to be even larger still. And what if the parallax was even smaller than anyone thought, so the stars were yet more distant? Then they would all have to be even larger still. Tycho saidDeduce these things geometrically if you like, and you will see how many absurdities (not to mention others) accompany this assumption [of the motion of the earth] by inference. Copernicans offered a religious response to Tycho's geometry: titanic, distant stars might seem unreasonable, but they were not, for the Creator could make his creations that large if He wanted. In fact, Rothmann responded to this argument of Tycho's by saying: "[W]hat is so absurd about [an average star] having size equal to the whole [orbit of the Earth]? What of this is contrary to divine will, or is impossible by divine Nature, or is inadmissible by infinite Nature? These things must be entirely demonstrated by you, if you will wish to infer from here anything of the absurd. These things that vulgar sorts see as absurd at first glance are not easily charged with absurdity, for in fact divine Sapience and Majesty is far greater than they understand. Grant the vastness of the Universe and the sizes of the stars to be as great as you like — these will still bear no proportion to the infinite Creator. It reckons that the greater the king, so much greater and larger the palace befitting his majesty. So how great a palace do you reckon is fitting to GOD?".

Religion played a role in Tycho's geocentrism also – he cited the authority of scripture in portraying the Earth as being at rest. He rarely used Biblical arguments alone (to him they were a secondary objection to the idea of Earth's motion) and over time he came to focus on scientific arguments, but he did take Biblical arguments seriously.

Tycho's 1587 geo-heliocentric model differed from those of other geo-heliocentric astronomers, such as Paul Wittich, Reimarus Ursus, Helisaeus Roeslin and David Origanus, in that the orbits of Mars and the Sun intersected. This was because Tycho had come to believe the distance of Mars from the Earth at opposition (that is, when Mars is on the opposite side of the sky from the Sun) was less than that of the Sun from the Earth. Tycho believed this because he came to believe Mars had a greater daily parallax than the Sun. But, in 1584, in a letter to a fellow astronomer, Brucaeus, he had claimed that Mars had been further than the Sun at the opposition of 1582, because he had observed that Mars had little or no daily parallax. He said he had therefore rejected Copernicus's model because it predicted Mars would be at only two-thirds the distance of the Sun. But, he apparently later changed his mind to the opinion that Mars at opposition was indeed nearer the Earth than the Sun was, but apparently without any valid observational evidence in any discernible Martian parallax. Such intersecting Martian and solar orbits meant that there could be no solid rotating celestial spheres, because they could not possibly interpenetrate. Arguably, this conclusion was independently supported by the conclusion that the comet of 1577 was superlunary, because it showed less daily parallax than the Moon and thus must pass through any celestial spheres in its transit.

Tycho's distinctive contributions to lunar theory include his discovery of the variation of the Moon's longitude. This represents the largest inequality of longitude after the equation of the center and the evection. He also discovered librations in the inclination of the plane of the lunar orbit, relative to the ecliptic (which is not a constant of about 5° as had been believed before him, but fluctuates through a range of over a quarter of a degree), and accompanying oscillations in the longitude of the lunar node. These represent perturbations in the Moon's ecliptic latitude. Tycho's lunar theory doubled the number of distinct lunar inequalities, relative to those anciently known, and reduced the discrepancies of lunar theory to about a fifth of their previous amounts. It was published posthumously by Kepler in 1602, and Kepler's own derivative form appears in Kepler's "Rudolphine Tables" of 1627.

Kepler used Tycho's records of the motion of Mars to deduce laws of planetary motion, enabling calculation of astronomical tables with unprecedented accuracy (the "Rudolphine Tables") and providing powerful support for a heliocentric model of the solar system.
Galileo's 1610 telescopic discovery that Venus shows a full set of phases refuted the pure geocentric Ptolemaic model. After that it seems 17th-century astronomy mostly converted to geo-heliocentric planetary models that could explain these phases just as well as the heliocentric model could, but without the latter's disadvantage of the failure to detect any annual stellar parallax that Tycho and others regarded as refuting it. The three main geo-heliocentric models were the Tychonic, the Capellan with just Mercury and Venus orbiting the Sun such as favoured by Francis Bacon, for example, and the extended Capellan model of Riccioli with Mars also orbiting the Sun whilst Saturn and Jupiter orbit the fixed Earth. But the Tychonic model was probably the most popular, albeit probably in what was known as 'the semi-Tychonic' version with a daily rotating Earth. This model was advocated by Tycho's ex-assistant and disciple Longomontanus in his 1622 "Astronomia Danica" that was the intended completion of Tycho's planetary model with his observational data, and which was regarded as the canonical statement of the complete Tychonic planetary system. Longomontanus' work was published in several editions and used by many subsequent astronomers, and through him the Tychonic system was adopted by astronomers as far away as China.

The ardent anti-heliocentric French astronomer Jean-Baptiste Morin devised a Tychonic planetary model with elliptical orbits published in 1650 in a simplified, Tychonic version of the "Rudolphine Tables". Some acceptance of the Tychonic system persisted through the 17th century and in places until the early 18th century; it was supported (after a 1633 decree about the Copernican controversy) by "a flood of pro-Tycho literature" of Jesuit origin. Among pro-Tycho Jesuits, Ignace Pardies declared in 1691 that it was still the commonly accepted system, and Francesco Blanchinus reiterated that as late as 1728. Persistence of the Tychonic system, especially in Catholic countries, has been attributed to its satisfaction of a need (relative to Catholic doctrine) for "a safe synthesis of ancient and modern". After 1670, even many Jesuit writers only thinly disguised their Copernicanism. But in Germany, the Netherlands, and England, the Tychonic system "vanished from the literature much earlier".

James Bradley's discovery of stellar aberration, published in 1729, eventually gave direct evidence excluding the possibility of all forms of geocentrism including Tycho's. Stellar aberration could only be satisfactorily explained on the basis that the Earth is in annual orbit around the Sun, with an orbital velocity that combines with the finite speed of the light coming from an observed star or planet, to affect the apparent direction of the body observed.

Tycho Brahe also worked in medicine and alchemy. He was strongly influenced by Paracelsus, who considered the human body to be directly influenced by celestial bodies. The paracelsian view of man as a microcosm, and astrology as the science tying together the celestial and bodily universes was also shared by Philip Melanchthon, and was precisely one of the points of contention between Melanchthon and Luther, and hence between the philippists and the gnesio-Lutherans. For Tycho Brahe there was a close connection between empiricism and natural science on one hand and religion and astrology on the other. Using his large herbal garden at Uraniborg, Tycho Brahe produced several recipes for herbal medicines, using them to treat illnesses such as fever and plague. In his own time, Tycho was also famous for his contributions to medicine; his herbal medicines were in use as late as the 1900s. The expression Tycho Brahe days, in Scandinavian folklore, refers to a number of "unlucky days" that were featured in many almanacs beginning in the 1700s, but which have no direct connection to Tycho Brahe or his work. Whether because he realized that astrology was not an empirical science or because he feared religious repercussions Brahe seems to have had a somewhat ambiguous relation to his own astrological work. For example, two of his more astrological treatises one on weather predictions and an almanac were published in the names of his assistants, in spite of the fact that he worked on them personally. Some scholars have argued that he lost faith in horoscope astrology over the course of his career, and others that he simply changed his public communication on the topic as he realized that connections with astrology could influence the reception of his empirical astronomical work.

The first biography of Tycho Brahe, which was also the first full-length biography of any scientist, was written by Pierre Gassendi in 1654. In 1779, Tycho de Hoffmann wrote of Brahe's life in his history of the Brahe family. In 1913, Dreyer published Tycho Brahe's collected works, facilitating further research. Early modern scholarship on Tycho Brahe tended to see the shortcomings of his astronomical model, painting him as a mysticist recalcitrant in accepting the Copernican revolution, and valuing mostly his observations that allowed Kepler to formulate his laws of planetary movement. Especially in Danish scholarship, Tycho Brahe was depicted as a mediocre scholar and a traitor to the nation — perhaps because of the important role in Danish historiography of Christian IV as a warrior king. In the second half of the 20th century, scholars began reevaluating is significance and studies by Kristian Peder Moesgaard, Owen Gingerich, Robert Westman, Victor E. Thoren, and John R. Christianson focused on his contributions to science, and demonstrated that while he admired Copernicus he was simply unable to reconcile his basic theory of physics with the Copernican view. Christianson's work showed the influence of Tycho's Uraniborg as a training center for scientists who after studying with Brahe went on to make contributions in various scientific fields.

Although Tycho's planetary model was soon discredited, his astronomical observations were an essential contribution to the scientific revolution. The traditional view of Tycho is that he was primarily an empiricist who set new standards for precise and objective measurements. This appraisal originated in Pierre Gassendi's 1654 biography, "Tychonis Brahe, equitis Dani, astronomorum coryphaei, vita". It was furthered by Johann Dreyer's biography in 1890, which was long the most influential work on Tycho. According to historian of science Helge Kragh, this assessment grew out of Gassendi's opposition to Aristotelianism and Cartesianism, and fails to account for the diversity of Tycho's activities.

Tycho's discovery of the new star was the inspiration for Edgar Allan Poe's poem "Al Aaraaf". In 1998, "Sky & Telescope" magazine published an article by Donald W. Olson, Marilynn S. Olson and Russell L. Doescher arguing, in part, that Tycho's supernova was also the same "star that's westward from the pole" in Shakespeare's "Hamlet".

The lunar crater "Tycho" is named in his honour, as is the crater "Tycho Brahe" on Mars and the minor planet 1677 Tycho Brahe in the asteroid belt. The bright supernova, SN 1572, is also known as "Tycho's Nova" and the Tycho Brahe Planetarium in Copenhagen is also named after him, as is the palm genus Brahea.






</doc>
<doc id="30028" url="https://en.wikipedia.org/wiki?curid=30028" title="The A-Team">
The A-Team

The A-Team is an American action-adventure television series that ran on NBC from 1983 to 1987 about former members of a fictitious United States Army Special Forces unit. The members, after being court-martialed "for a crime they didn't commit", escaped from military prison and, while still on the run, worked as soldiers of fortune. The series was created by Stephen J. Cannell and Frank Lupo. A feature film based on the series was released by 20th Century Fox in 2010.

"The A-Team" was created by writers and producers Stephen J. Cannell and Frank Lupo at the behest of Brandon Tartikoff, NBC's Entertainment president. Cannell was fired from ABC in the early 1980s, after failing to produce a hit show for the network, and was hired by NBC; his first project was "The A-Team." Brandon Tartikoff pitched the series to Cannell as a combination of "The Dirty Dozen", "Mission Impossible", "The Magnificent Seven", "Mad Max" and "Hill Street Blues", with "Mr. T driving the car".

"The A-Team" was not generally expected to become a hit, although Stephen J. Cannell has said that George Peppard suggested it would be a huge hit "before we ever turned on a camera". The show became very popular; the first regular episode, which aired after Super Bowl XVII on January 30, 1983, reached 26.4% of the television audience, placing fourth in the top 10 Nielsen-rated shows. The A-Team was portrayed as acting on the side of good and helping the oppressed.

The show remains prominent in popular culture for its cartoonish violence (in which people were seldom seriously hurt), formulaic episodes, its characters' ability to form weaponry and vehicles out of old parts, and its distinctive theme tune. The show boosted the career of Mr. T, who portrayed the character of B. A. Baracus, around whom the show was initially conceived. Some of the show's catchphrases, such as "I love it when a plan comes together", "Hannibal's on the jazz", and "I ain't gettin' on no plane!" have also made their way onto T-shirts and other merchandise.

The show's name comes from the "A-Teams", the nickname coined for U.S. Special Forces' Operational Detachments Alpha (ODA) during the Vietnam War, although this connection was never mentioned on-screen.

In a 2003 Yahoo! survey of 1,000 television viewers, "The A-Team" was voted the "oldie" television show viewers would most like to see revived, beating out such popular television series from the 1980s as "The Dukes of Hazzard" and "Knight Rider".

"The A-Team" is a naturally episodic show, with few overarching stories, except the characters' continuing motivation to clear their names, with few references to events in past episodes and a recognizable and steady episode structure. In describing the ratings drop that occurred during the show's fourth season, reviewer Gold Burt points to this structure as being a leading cause for the decreased popularity "because the same basic plot had been used over and over again for the past four seasons with the same predictable outcome". Similarly, reporter Adrian Lee called the plots "stunningly simple" in a 2006 article for "The Express" (UK newspaper), citing such recurring elements "as BA's fear of flying, and outlandish finales when the team fashioned weapons from household items". The show became emblematic of this kind of "fit-for-TV warfare" due to its depiction of high-octane combat scenes, with lethal weapons, wherein the participants (with the notable exception of General Fulbright) are never killed and rarely seriously injured ("see also" On-screen violence section).

As the television ratings of "The A-Team" fell dramatically during the fourth season, the format was changed for the show's final season in 1986–87 in a bid to win back viewers. After years on the run from the authorities, the A-Team is finally apprehended by the military. General Hunt Stockwell, a mysterious CIA operative played by Robert Vaughn, propositions them to work for him, whereupon he will arrange for their pardons upon successful completion of several suicide missions. In order to do so, the A-Team must first escape from their captivity. With the help of a new character, Frankie "Dishpan Man" Santana, Stockwell fakes their deaths before a military firing squad. The new status of the A-Team, no longer working for themselves, remained for the duration of the fifth season while Eddie Velez and Robert Vaughn received star billing along with the principal cast. The missions that the team had to perform in season five were somewhat reminiscent of "", and based more around political espionage than beating local thugs, also usually taking place in foreign countries, including successfully overthrowing an island dictator, the rescue of a scientist from East Germany, and recovering top secret Star Wars defense information from Soviet hands. These changes proved unsuccessful with viewers, however, and ratings continued to decline. Only 13 episodes aired in the fifth season. In what was supposed to be the final episode, "The Grey Team" (although "Without Reservations" was broadcast on NBC as the last first-run episode in March 1987), Hannibal, after being misled by Stockwell one time too many, tells him that the team will no longer work for him. At the end, the team discusses what they were going to do if they get their pardon, and it is implied that they would continue doing what they were doing as the A-Team. The character of Howling Mad Murdock can be seen in the final scene wearing a T-shirt that says, "Fini".

During the Vietnam War, the A-Team were members of the 5th Special Forces Group (see episode "West Coast Turnaround"). In episode "Bad Time on the Border", Colonel John "Hannibal" Smith, portrayed by George Peppard, indicated that the A-Team were "ex-Green Berets". During the Vietnam War, the A-Team's commanding officer, Colonel Morrison, gave them orders to rob the Bank of Hanoi to help bring the war to an end. They succeeded in their mission, but on their return to base four days after the end of the war, they discovered that Morrison had been killed by the Viet Cong, and that his headquarters had been burned to the ground. This meant that the proof that the A-Team members were acting under orders had been destroyed. They were arrested, and imprisoned at Fort Bragg, from which they quickly escaped before standing trial.

The origin of the A-Team is directly linked to the Vietnam War, during which the team formed. The show's introduction in the first four seasons mentions this, accompanied by images of soldiers coming out of a helicopter in an area resembling a forest or jungle. Besides this, "The A-Team" would occasionally feature an episode in which the team came across an old ally or enemy from those war days. For example, the first season's final episode "A Nice Place To Visit" revolved around the team traveling to a small town to honor a fallen comrade and end up avenging his death, and in season two's "Recipe For Heavy Bread", a chance encounter leads the team to meet both the POW cook who helped them during the war, and the American officer who sold his unit out.

An article in the "New Statesman" (UK) published shortly after the premiere of "The A-Team" in the United Kingdom, also pointed out "The A-Team's" connection to the Vietnam War, characterizing it as the representation of the idealization of the Vietnam War, and an example of the war slowly becoming accepted and assimilated into American culture.

One of the team's primary antagonists, Col. Roderick Decker (Lance LeGault), had his past linked back to the Vietnam War, in which he and Hannibal had come to fisticuffs in "the DOOM Club" (Da Nang Open Officers' Mess). At other times, members of the team would refer back to a certain tactic used during the War, which would be relevant to the team's present predicament. Often, Hannibal would refer to such a tactic, after which the other members of the team would complain about its failure during the War. This was also used to refer to some of Face's past accomplishments in scamming items for the team, such as in the first-season episode "Holiday In The Hills", in which Murdock fondly remembers Face being able to secure a '53 Cadillac while in the Vietnam jungle.

The team's ties to the Vietnam War were referred to again in the fourth-season finale, "The Sound of Thunder", in which the team is introduced to Tia (Tia Carrere), a war orphan and daughter of fourth season antagonist General Fulbright. Returning to Vietnam, Fulbright is shot in the back and gives his last words as he dies. The 2006 documentary "Bring Back The A-Team" joked that the scene lasted seven and a half minutes, but his death actually took a little over a minute. His murderer, a Vietnamese colonel, is killed in retaliation. Tia then returns with the team to the United States ("see also: casting"). This episode is notable for having one of the show's few truly serious dramatic moments, with each team member privately reminiscing on their war experiences, intercut with news footage from the war with Barry McGuire's "Eve of Destruction" playing in the background.

The show's ties to the Vietnam War are fully dealt with in the opening arc of the fifth season, dubbed "The Court-Martial (Part 1–3)", in which the team is finally court-martialed for the robbery of the bank of Hanoi. The character of Roderick Decker makes a return on the witness stand, and various newly introduced characters from the A-Team's past also make appearances. The team, after a string of setbacks, decides to plead guilty to the crime and they are sentenced to be executed. They escape this fate and come to work for a General Hunt Stockwell, leading into the remainder of the fifth season.

The show ran for five seasons on the NBC television network, from January 23, 1983 to December 30, 1986 (with one additional, previously unbroadcast episode shown on March 8, 1987), for a total of 98 episodes.

"The A-Team" revolves around the four members of a former commando outfit, now mercenaries. Their leader is Lieutenant Colonel/Colonel John "Hannibal" Smith (George Peppard), whose plans tend to be unorthodox but effective. Lieutenant Templeton Peck (Dirk Benedict; Tim Dunigan appeared as Templeton Peck in the pilot), usually called "Face" or "Faceman", is a smooth-talking con man who serves as the team's appropriator of vehicles and other useful items, as well as the team's second-in-command. The team's pilot is Captain H.M. "Howling Mad" Murdock (Dwight Schultz), who has been declared insane and lives in a Veterans' Administration mental institution for the show's first four seasons. Finally, there is the team's strong man, mechanic and Sergeant First Class Bosco "B.A.", or "Bad Attitude", Baracus (Mr. T).

The team belonged to the 5th Special Forces as seen in the left side shoulder patch on Hannibal's uniform in the episode A Nice Place to Visit. A patch on Hannibal's uniform on the right shoulder in the episode "A Nice Place To Visit" indicates he belonged to the 101st Airborne during a prior combat assignment, but that patch was replaced by the 1st Air Cavalry Division patch in the episode "Trial by Fire". The patch worn on the left sleeve according to uniform wear in the Army is the current assignment of the person wearing it and in the episode A Nice Place to Visit shows that the team was assigned to the Special Forces with a tab Airborne over the shoulder patch. Also their berets in that episode are green and have the tab of the 5th Special Forces in Vietnam on them. In the episode "West Coast Turnaround", Hannibal stated they were with the 5th Special Forces Group. Then, in episode "Bad Time on the Border", Hannibal refers to his friends as "ex-Green Berets". Though the name they have adopted comes from the "A-Teams", the nickname coined for Special Forces Operational Detachments Alpha, these detachments usually consisted of "twelve" members; whether the four were considered a "detachment" of their own or had once had eight compatriots who were killed in action was never revealed. In the episode A Nice Place to Visit Ray Brenner is stated to have been a Major and part of Hannibal's team in Vietnam.

For its first season and the first half of the second season, the team was assisted by reporter Amy Amanda Allen (Melinda Culea). In the second half of the second season, Allen was replaced by fellow reporter Tawnia Baker (Marla Heasley). The character of Tia (Tia Carrere), a Vietnam war orphan now living in the United States, was meant to join the Team in the fifth season, but she was replaced by Frankie Santana (Eddie Velez), who served as the team's special effects expert. Velez was added to the opening credits of the fifth season after its second episode.

During their adventures, the A-Team was constantly met by opposition from the Military Police. In the show's first season, the MPs were led by Colonel Francis Lynch (William Lucking), but he was replaced for the second, third, and earlier fourth season by Colonel Roderick Decker (Lance LeGault) and his aide Captain Crane (Carl Franklin). Lynch returned for one episode in the show's third season ("Showdown!") but was not seen after. Decker was also briefly replaced by a Colonel Briggs (Charles Napier) in the third season for one episode ("Fire") when LeGault was unavailable, but returned shortly after. For the latter portion of the show's fourth season, the team was hunted by General Harlan "Bull" Fulbright (Jack Ging), who would later hire the A-Team to find Tia in the season four finale, during which Fulbright was killed.

The fifth season introduced General Hunt Stockwell (Robert Vaughn) who, while serving as the team's primary antagonist, was also the team's boss and joined them on several missions. He was often assisted by Carla (Judith Ledford, sometimes credited as Judy Ledford).

John "Hannibal" Smith is a master of disguise. His most used disguise (onscreen only on the pilot episode) is Mr. Lee, the dry cleaner. This is one of the final parts of the client screening process, as he tells the client where to go in order to make full contact with the A-Team. He dresses most often in a white safari jacket and black leather gloves. He also is constantly seen smoking a cigar. Hannibal carries either a Browning Hi-Power, Colt M1911A1 or a Smith & Wesson Model 39 as a sidearm, most often "Mexican carried" although he uses a holster when on missions. His catchphrase is "I love it when a plan comes together". Often said, usually by B.A., to be "on the jazz" when in the fury of completing a mission.

Templeton "Faceman" Peck is a master of the persuasive arts. The team's scrounger, he can get virtually anything he sets his mind to, usually exploiting women with sympathy-appeal and flirtation. However, he is not without integrity, as stated by Murdock in the episode "Family Reunion": "He would rip the shirt off his back for you, and then scam one for himself." Faceman is also the A-Team's accountant. He dresses suavely, often appearing in suits. Faceman carries a Colt Lawman Mk III revolver for protection, and drives a custom white 1984 Corvette with orange trim.

Bosco "B.A." (Bad Attitude) Baracus is the muscle for the A-Team, able to perform eceptional feats of strength. He is also the team's mechanic. Baracus affects a dislike for Murdock, calling him a "crazy fool", but his true feelings of friendship are revealed when he prevents Murdock from drowning in his desire to live like a fish. Baracus.also has a deep fear of flying, and the others usually have to trick and/or knock him out in order to get him on a plane. It is very rare that Baracus. is awake while flying, and even rarer for him actually to consent to it. When he does, however, he then goes into a catatonic state. Baracus generally wears overalls and leopard or tiger print shirts in the early seasons, then later wears a green jumpsuit in the later seasons. He is almost always seen with about 50 pounds of gold necklaces and rings on every finger, and also wears a weightlifting belt. Baracus's hair is always styled in a mohawk-like cut. He drives a customized black GMC van, which is the team's usual mode of transport.

H.M. "Howling Mad" Murdock is the A-Team's pilot, and can fly any kind of aircraft with considerable skill. However, due to a helicopter crash in Vietnam, Murdock apparently went insane. He lives in a Veterans' Hospital in the mental wing. Whenever the rest of the team requires a pilot, they have to break him out of the hospital, generally using Faceman to do so. In Seasons 1–4, Murdock has a different pet, imaginary friend, or persona in each episode. Whenever one of his pets or imaginary friends is killed by an enemy, Murdock snaps and takes revenge (but never kills). Many times, when Baracus is mad at Murdock for being crazy, Hannibal will side with Murdock in a sympathetic way. Once he is discharged from the hospital in Season 5, Murdock has a different job each episode. Murdock usually wears a leather flight jacket, a baseball cap, and basketball sneakers.

Although the part of Face was written by Frank Lupo and Stephen J. Cannell with Dirk Benedict in mind, NBC insisted that the part should be played by another actor, instead. Therefore, in the pilot, Face was portrayed by Tim Dunigan, who was later replaced by Dirk Benedict, with the comment that Dunigan was "too tall and too young". According to Dunigan: "I look even younger on camera than I am. So it was difficult to accept me as a veteran of the Vietnam War, which ended when I was a sophomore in high school."

Carrere was intended to join the principal cast of the show in its fifth season after appearing in the season four finale, providing a tie to the team's inception during the war. Unfortunately for this plan, Carrere was under contract to "General Hospital", which prevented her from joining "The A-Team." Her character was abruptly dropped as a result.

According to Mr. T's account in "Bring Back... The A-Team" in 2006, the role of B. A. Baracus was written specifically for him. This is corroborated by Stephen J. Cannell's own account of the initial concept proposed by Tartikoff.

James Coburn, who co-starred in "The Magnificent Seven", was considered for the role of Hannibal in "The A-Team", while George Peppard (Hannibal) was the original consideration for the role of Vin (played by Steve McQueen instead) in "The Magnificent Seven". Robert Vaughn, of course, actually appeared in the film.

According to Dirk Benedict, Robert Vaughn was actually added to the cast in season 5 because of his friendship with the notoriously prickly George Peppard. It was hoped that Vaughn would help ease worsening tensions between Peppard and Mr. T. In a later interview, Vaughn recounted how T's verbosity and loud personality would get on everyone's nerves, including his, even though he had been hired specifically because of his easy going and calming personality.

Notable guest stars included:

During the show's first three seasons, "The A-Team" managed to pull in 17% to 20% of the American households on average. The first regular episode ("Children of Jamestown"), reached 26.4% of the television watching audience, placing fourth in the top 10 rated shows, according to the Nielsen ratings. By March, "The A-Team", now on its regular Tuesday timeslot, dropped to the eight spot, but rated a 20.5%. During the sweeps week in May of that year, "The A-Team" dropped again but remained steady at 18.5%, and rose to 18.8% during the second week of May sweeps. These were the highest ratings NBC had achieved in five years. During the second season, the ratings continued to soar, reaching third place in the twenty-highest rated programs, behind "Dallas" and "Simon & Simon", in January (mid-season), while during the third season, it was beaten out only by four other NBC shows, including "The Cosby Show".

The fourth season saw "The A-Team" experience a dramatic fall in ratings, as it started to lose its position while television viewership increased. As such, the ratings, while stable, were relatively less. The season premiere ranked a 17.4% (a 26% audience share on that timeslot) on the Nielsen Rating scale, but after ratings quickly declined. In October, "The A-Team" had fallen to the 19th and by Super Bowl Night had fallen still to 29th the night on which the show had originally scored its first hit three years before. For the remainder of its fourth season "The A-Team" managed to hang around the 20th spot, far from original top 10 position it had enjoyed during its first three seasons.

After four years on Tuesday, NBC decided to move "The A-Team" to a new timeslot on Friday for what would be its final season. Ratings continued to drop, and after seven episodes, "The A-Team" fell out of the top 50 altogether with a 13.3 Nielsen Rating. In November 1986, NBC cancelled the series, declining to order the last nine episodes of what would have been a 22-episode season.

The series has achieved cult status through heavy syndication in the U.S. and internationally. It has also remained popular overseas, such as in the United Kingdom, where the show has been on-air almost continuously in some form since it was first shown in July 1983. It is airing on satellite and cable channel Esquire Network. The series was to begin airing over NBC-TV's OTA digital subchannel network, Cozi TV, in January 2016. Forces TV started showing the series every weekday since October 17, 2016. The series has been airing in Spanish on Telemundo-TV's OTA digital subchannel network, TeleXitos since December 2014. The series is currently available through Starz.

"The A-Team" has been broadcast all over the world; international response has been varied. In 1984, the main cast members of "The A-Team", George Peppard, Mr. T, Dirk Benedict and Dwight Schultz were invited to the Netherlands. George Peppard was the first to receive the invitation and thus thought the invitation applied only to him. When the other cast members were also invited, Peppard declined, leaving only Mr. T, Benedict and Schultz to visit the Netherlands. The immense turn-out for the stars was unforeseen, and they were forced to leave early as a security measure. A video was released with the present actors in which Dwight Schultz apologized and thanked everyone that had attended.

In Australia "The A-Team" was broadcast on Channel Ten. From 2010 7mate has been showing reruns of show. The show was broadcast in New Zealand on TV2. In Brazil, the series was broadcast on SBT from 1984 to 1989, later moving to Rede Globo in the early 1990s. In the UK, the program was shown on ITV, starting on Friday, July 22, 1983; when it returned for its second run (resuming mid-second season) it moved to Saturday evenings. The series continued to be repeated on ITV until 1994. The series was later repeated on UK Gold from 1997 through 2007 at various times. Then in 2002 it took a break from the channel before returning 2005 to 2006. It was also repeated on Bravo from 1997 to 1999. It returned to the channel in 2009. In 2017 the digital channel Spike began showing the series from the beginning. Although ratings soared during its early seasons, many television critics described the show largely as cartoonish and thereby wrote the series off. Most reviews focused on acting and the formulaic nature of the episodes, most prominently the absence of actual killing in a show about Vietnam War veterans.

The violence presented in "The A-Team" is highly sanitized. People do not bleed or bruise when hit (though they might develop a limp or require a sling), nor do the members of the A-Team kill people. The results of violence were only ever presented when it was required for the script. In almost every car crash there is a short take showing the occupants of the vehicle climbing out of the mangled or burning wreck, even in helicopter crashes. However, more of these types of takes were dropped near the end of the fourth season. According to Stephen J. Cannell, this part of the show did become a running joke for the writing staff and they would at times test the limits of realism on purpose.

The show has been described as cartoonish and likened to "Tom and Jerry". Dean P. of the "Courier-Mail" described the violence in the show as "hypocritical" and that "the morality of giving the impression that a hail of bullets does no-one any harm is ignored. After all, Tom and Jerry survived all sorts of mayhem for years with no ill-effects." Television reviewer Ric Meyers joked that the A-Team used "antineutron bullets—they destroy property for miles around, but never harm a human being". According to certain estimates, an episode of the A-Team held up to 46 violent acts. Stephen J. Cannell, co-creator of the show responds: "They were determined to make a point, and we were too big a target to resist. Cartoon violence is a scapegoat issue." Originally, "The A-Team's" status as a hit show remained strong, but it ultimately lost out to more family-oriented shows such as "The Cosby Show", "Who's the Boss?" and "Growing Pains". John J. O'Connor of "The New York Times" wrote in a 1986 article that "...a substantial number of viewers, if the ratings in recent months are to be believed, are clearly fed up with mindless violence of the car-chasing, fist-slugging variety".

During its tenure, the show was occasionally criticized for being sexist. These critiques were based on the notion that most female roles on the show were either a lead-in to the episode's plot, the recipient of Face's affections, or both. The only two regular female members of the cast, Melinda Culea (season 1 and the first half of season 2) and Marla Heasley (the latter half of season 2) did not have long tenures with the show. Both Culea and Heasley had been brought in by the network and producers to stem these critiques, hoping that a female character would properly balance the otherwise all-male cast. Culea was fired during the second season because of creative differences between her and the show's writers; she wanted more lines and more action scenes. Culea's character of Amy Allen suddenly disappeared between two episodes, and was only briefly referred to once in the episode "In Plane Sight", and a couple of times in "The Battle of Bel Air" in which she was cited to have taken a correspondence job overseas (in Jakarta, Indonesia). The latter episode also introduced Heasley's character, Tawnia Baker. The new character was also an assisting reporter character, but with a more fragile and seductive quality to her. Ultimately, she was written out of the show at the start of the third season when the network determined that a female cast member was not necessary. Tawnia left the team on-screen, choosing to marry and move out of Los Angeles.

As Marla Heasley recounts in "Bring Back... The A-Team" (May 18, 2006), although sexism was not prevalent on the set per se, there was a sense that a female character was not necessary on the show. On her first day on set George Peppard took her aside and told her "We don't want you on the show. None of the guys want you here. The only reason you're here is because the network and the producers want you. For some reason they think they need a girl." The interview continues with Heasley noting that on her last day of work Peppard took her aside again, saying: "I'm sorry that this is your last day, but remember what I said the very first day, that we didn't want a girl, has nothing to do with you. You were very professional, but no reason to have a girl." In "Bring Back... the A-Team", Dirk Benedict also remarked that: "It was a guy's show. It was male driven. It was written by guys. It was directed by guys. It was acted by guys. It's about what guys do. We talked the way guys talked. We were the boss. We were the God. We smoked when we wanted. We shot guns when we wanted. We kissed the girls and made them cry... when we wanted. It was the last truly masculine show."

The 1983 GMC Vandura van used by the A-Team, with its characteristic red stripe, black and red turbine mag wheels, and rooftop spoiler, has become an enduring pop culture icon. The customized 1994 Chevrolet G20 used on the A-Team movie was also on display at the 2010 New York International Auto Show.

A number of devices were seen in the back of the van in different episodes, including a mini printing press ("Pros and Cons"), an audio surveillance recording device ("A Small and Deadly War"), Hannibal's disguise kits in various episodes, and a gun storage locker.

Early examples of the van had a red GMC logo on the front grille, and an additional GMC logo on the rear left door. Early in the second season, these logos were blacked out, although GMC continued to supply vans and receive a credit on the closing credits of each episode.

The van was commonly said to be all-black, but the section above the red stripe was metallic gray. The angle of the rear spoiler can also be seen to vary on different examples of the van within the series. Additionally, some versions of the van have a sunroof, whereas others, typically those used for stunts (and including the one displayed in the aforementioned Cars of the Stars Motor Museum) do not. This led to continuity errors in some episodes, such as in the third season's "The Bells of St. Mary's", in a scene where Face (his double) jumps from a building onto the roof of the van with no sunroof. Moments later, in an interior studio shot, Face climbs in through the sunroof. Also, in many stunts where the van would surely be totaled, other makes have been used, such as a black Ford Econoline with red hubcaps painted to simulate the original red turbine mag wheels.

Many GMC/Chevrolet Vandura vans, and many of the very similar Bedford CF vans, were styled after the A-Team's van by fans of the show.

The huge success of the series saw a vast array of merchandise, including toys and snacks released both in America and internationally. There were several sets trading cards and stickers, action figures of the characters were produced by Galoob as well as vehicles, including B.A.'s van and Face's Corvette (available in several different sizes), as well as items such as helicopters, trucks and jeeps to fit in with the line, from model car manufacturer Ertl. Some of the other array of items available included jigsaw puzzles, View-Master reels containing 21 3-D pictures (over three reels) of the second season"A-Team" story "When You Comin' Back, Range Rider?", was produced by View-Master International (available both as a pack of reels, and also as a "gift set" with 3-D viewer), an electric race car track with A-Team vehicle covers instead of normal cars, and a TYCO produced train set with various accessories and pieces themed for the A-Team look. The set includes a Baldwin shark nose engine painted up like the Van and a matching Caboose. 
Following the original cancellation of the series, further merchandise has appeared as the series has achieved cult status, including an "A-Team" van by "Hot Wheels". In 2016 Lego released a pack that includes a B.A. Baracus minifigure and constructible van; the pack will unlock additional "A-Team" themed content in the video game "Lego Dimensions", including all four team members as playable characters.

Marvel Comics produced a three-issue "A-Team" comic book series, which was later reprinted as a trade paperback. Similarly, in the United Kingdom, an "A-Team" comic strip appeared for several years in the 1980s as part of the children's television magazine and comic "Look-In," to tie in with the British run of the series. It was preceded, though, by a short run in the final year (1984) of "TV Comic," drawn by Jim Eldridge.

Several novels were based on the series, the first six published in America by Dell and in Britain by Target Books; the last four were only published in Britain. The first six are credited to Charles Heath. The books are generally found in paperback form, although hardback copies (with different cover artwork) were also released. 

In the United Kingdom from 1985 to 1988, four Annuals were produced, each consisting of text and comic strip stories, puzzles, and photos of the show's stars, with a further one produced by Marvel Comics consisting of several reprinted comic strips, released in 1989/1990. 

A Panini set of stickers, which adapted six TV episodes (from the first and earlier second season) using shots from the episodes, could be stick into an accompanying book, with text under each inserted sticker to narrate the story.


The original main theme composed by Mike Post and Pete Carpenter (in a performance credited to Post) was released on the vinyl LP Mike Post – Television Theme Songs (Elektra Records E1-60028Y, 1982) and again on the Mike Post – Mike Post LP (RCA Records AFL1-5183, 1984), both long out-of-print; however, this was not the same version of the theme as heard on-screen. The theme, as heard on seasons two through four (including the opening narration and sound effects), was also released on TVT's "Television's Greatest Hits: 70s and 80s". A 7" single of the song credited to Post was released on RCA in 1984.

The French version of the song had lyrics, which mirrored the spoken description of the show in the English opening credits. The theme has been ranked among the best TV themes ever written, with TV weatherman Al Roker sharing that opinion, and using the song to "get jazzed up" in the morning.

Though no original music other than the theme has been released, in 1984 EMI issued an album of re-recorded material from the series conducted by Daniel Caine (reissued by Silva Screen on compact disc in 1999, SILVAD 3509).


During its time, "The A-Team" was nominated for three Emmy Awards: In 1983 (Outstanding Film Sound Mixing for a Series) for the pilot episode, in 1984 (Outstanding Film Sound Mixing for a Series) for the episode "When You Comin' Back, Range Rider?" and in 1987 (Outstanding Sound Editing for a Series) for the episode "Firing Line".

The show featured professional wrestlers such as Hulk Hogan, Professor Toru Tanaka, Ricky "The Dragon" Steamboat, The Dynamite Kid, Bobby "The Brain" Heenan, Davey Boy Smith (The British Bulldog), Big John Studd and Greg "The Hammer" Valentine, in most cases playing themselves. In the episode "Body Slam", which featured Hogan, wrestling interviewer and announcer "Mean" Gene Okerlund also appeared.

In addition, the music video for John Cena's "Bad, Bad Man" (on Cena's "You Can't See Me" album) featured the Chain Gang as a three-man A-Team—Cena as Hannibal, plus Cena's cousin Tha Trademarc as Howling Mad and Bumpy Knuckles as B.A.

In early episodes the team used Colt AR-15 SP1 semi-automatic rifles (with automatic sound effects, simulating the M16), while in later seasons they used the Ruger Mini-14, and on rare occasions, the selective fire AC-556K variant of the Mini-14. Hannibal is also seen using an M60 machine gun (which Hannibal called "Baby") in some episodes as well as a Micro-Uzi. MAC-11s with parts added to simulate the Uzi appear in at least two early episodes. Hannibal's sidearms are either a nickel-plated Smith & Wesson Model 59, or a stainless steel Smith & Wesson Model 639. Unusually in the episode "Black Day At Bad Rock" he is seen carrying a Browning Hi-Power. Faceman's usual sidearm is a Colt Lawman III, thou he does use Smith & Wesson revolvers in latter seasons. Many antagonists and members of the team are seen using 1911s as well. Starting from Season 4, the then-exotic Steyr AUG bullpup rifle also became prominent in the series. "So many different firearms were used in the 1980s hit 'The A-Team' that it’s impossible to list them all. For five seasons, the wrongly accused foursome used rifles, handguns, submachine guns and shotguns to bring justice for the little guy while trying to stay out of jail. And the best part had to be that regardless of the number of explosions or rounds fired, nobody ever got seriously hurt except for the occasional flesh wound of a team member." As a result, the "American Rifleman" declared "The A-Team" the Number One Show on Television to regularly feature firearms.

Universal Studios Home Entertainment has released all five seasons of "The A-Team" on DVD in Region 1, 2, and 4. In Region 2, a complete series set entitled "The A-Team--The Ultimate Collection" was released on October 8, 2007. A complete series set was released in Region 1 on June 8, 2010. The set includes 25 discs packaged in a replica of the A-Team's signature black van from the show. The complete series set was released in Region 4 on November 3, 2010.

All 5 seasons were re-released in Region 2 with new packaging on June 21, 2010. The series has been remastered and was released on Blu-ray disc in the United Kingdom on October 17, 2016.

On May 18, 2006, Channel 4 in the UK attempted to reunite the surviving cast members of "The A-Team" for the show "Bring Back..." in an episode titled "Bring Back...The A-Team". Justin Lee Collins presented the challenge, securing interviews and appearances from Dirk Benedict, Dwight Schultz, Marla Heasley, Jack Ging, series co-creator Stephen Cannell, and Mr. T.

Collins eventually managed to bring together Benedict, Schultz, Heasley, Ging and Cannell, along with William Lucking, Lance LeGault, and George Peppard's son, Christian. Mr. T was unable to make the meeting, which took place in the Friar's Club in Beverly Hills, but he did manage to appear on the show for a brief talk with Collins.

A feature film based on "The A-Team" was released on June 11, 2010, and was produced by 20th Century Fox. Both Dirk Benedict (Face) and Dwight Schultz (Murdock) made brief cameo appearances in the film (as a prisoner using a sunbed and a psychiatrist overseeing Murdock's shock therapy, respectively); because of timing issues, these scenes were moved to the end of the credits. They were later reinserted for the extended-cut of the film.

In September 2015, Fox announced that they were developing a reboot "A-Team" series with Chris Morgan as executive producer with Cannell's daughter, Tawnia McKiernan, and Albert Kim writing. The team is to be made up of both male and female characters.





</doc>
<doc id="30029" url="https://en.wikipedia.org/wiki?curid=30029" title="Terry Pratchett">
Terry Pratchett

Sir Terence David John Pratchett (28 April 1948 – 12 March 2015) was an English author of fantasy novels, especially comical works. He is best known for his "Discworld" series of 41 novels. 

Pratchett's first novel, "The Carpet People", was published in 1971. The first "Discworld" novel, "The Colour of Magic", was published in 1983, after which Pratchett wrote an average of two books a year. His 2011 "Discworld" novel "Snuff" became the third-fastest-selling hardback adult-readership novel since records began in the UK, selling 55,000 copies in the first three days. The final "Discworld" novel, "The Shepherd's Crown", was published in August 2015, five months after his death.

Pratchett, with more than 85 million books sold worldwide in 37 languages, was the UK's best-selling author of the 1990s. He was appointed Officer of the Order of the British Empire (OBE) in 1998 and was knighted for services to literature in the 2009 New Year Honours. In 2001 he won the annual Carnegie Medal for "The Amazing Maurice and his Educated Rodents", the first "Discworld" book marketed for children. He received the World Fantasy Award for Life Achievement in 2010.

In December 2007, Pratchett announced that he had been diagnosed with early-onset Alzheimer's disease. He later made a substantial public donation to the Alzheimer's Research Trust (now Alzheimer's Research UK), filmed a television programme chronicling his experiences with the disease for the BBC, and also became a patron for Alzheimer's Research UK. Pratchett died on 12 March 2015 aged 66.

Pratchett was born on 28 April 1948 in Beaconsfield in Buckinghamshire, England (where he attended Holtspur School), the only child of David (1921–2006) and Eileen Pratchett (1922–2007), of Hay-on-Wye. His family moved to Bridgwater, Somerset, briefly in 1957, following which he passed his eleven plus exam in 1959, earning a place in High Wycombe Technical High School (now John Hampden Grammar School) where he was a key member of the debating society and wrote stories for the school magazine. Pratchett described himself as a "non-descript student" and, in his "Who's Who" entry, credits his education to the Beaconsfield Public Library.

His early interests included astronomy. He collected Brooke Bond tea cards about space, owned a telescope and wanted to be an astronomer but lacked the necessary mathematical skills. He developed an interest in reading science fiction and began attending science fiction conventions from about 1963–1964, but stopped when he got his first job a few years later. His early reading included the works of H. G. Wells, Arthur Conan Doyle, and "every book you really ought to read", which he later regarded as "getting an education".

Pratchett published his first short story entitled "Business Rivals" in the High Wycombe Technical School magazine in 1962. It is the tale of a man named Crucible who finds the Devil in his flat in a cloud of sulphurous smoke. "The Hades Business", which was published in the school magazine when he was 13, was published commercially when he was 15.

Pratchett earned five O-levels and started A-level courses in Art, English and History. His initial career choice was journalism and he left school at 17, in 1965, to start an apprenticeship with Arthur Church, the editor of the "Bucks Free Press", where he wrote, amongst other things, over eighty stories for the "Children's Circle" section under the name Uncle Jim. Two of these episodic stories contain characters found in his novel "The Carpet People" (1971). While on day release from his apprenticeship he finished his A-Level in English and took the National Council for the Training of Journalists proficiency course where he received the highest marks of his group.

Pratchett had his writing breakthrough in 1968 when he interviewed Peter Bander van Duren, co-director of a small publishing company, Colin Smythe Ltd. During the meeting, Pratchett mentioned he had written a manuscript, "The Carpet People". Colin Smythe Ltd published the book in 1971, with illustrations by the author. The book received strong, if few, reviews and was followed by the science fiction novels "The Dark Side of the Sun" (10 May 1976) and "Strata" (15 June 1981).

After various positions in journalism, in 1980 Pratchett became Press Officer for the Central Electricity Generating Board (CEGB) in an area which covered four nuclear power stations. He later joked that he had demonstrated "impeccable timing" by making this career change so soon after the Three Mile Island nuclear accident in Pennsylvania, US, and said he would "write a book about my experiences, if I thought anyone would believe it".

The first Discworld novel, "The Colour of Magic", was published in hardback by Colin Smythe Ltd in 1983. The paperback edition was published by Corgi, an imprint of Transworld, in 1985. Pratchett's popularity increased when the BBC's "Woman's Hour" broadcast "The Colour of Magic" as a serial in six parts, and later "Equal Rites". Subsequently, the hardback rights were taken by the publishing house Victor Gollancz Ltd, which remained Pratchett's publisher until 1997, Colin Smythe having become Pratchett's agent. Pratchett was the first fantasy author published by Gollancz.

Pratchett gave up working for the CEGB to make his living through writing in 1987, after finishing the fourth Discworld novel, "Mort". His sales increased quickly and many of his books occupied top places on the best-seller list; he was the UK's best-selling author of the 1990s. According to "The Times", Pratchett was the top-selling and highest earning UK author in 1996. Some of his books have been published by Doubleday, another Transworld imprint. In the US, Pratchett is published by HarperCollins.

According to the "Bookseller's Pocket Yearbook" (2005), in 2003 Pratchett's UK sales amounted to 3.4% of the fiction market by hardback sales and 3.8% by value, putting him in second place behind J. K. Rowling (6% and 5.6%, respectively), while in the paperback sales list Pratchett came 5th with 1.2% and 1.3% by value (behind James Patterson (1.9% and 1.7%), Alexander McCall Smith, John Grisham, and J. R. R. Tolkien). His sales in the UK alone are more than 2.5 million copies a year.

Pratchett married Lyn Purves at the Congregational Church, Gerrards Cross, on 5 October 1968, and they moved to Rowberrow, Somerset, in 1970. Their daughter Rhianna Pratchett, who is also a writer, was born there in 1976. In 1993, the family moved to Broad Chalke, a village west of Salisbury, Wiltshire. He listed his recreations as "writing, walking, computers, life". He described himself as a humanist and was a Distinguished Supporter of Humanists UK (formerly known as the British Humanist Association) and an Honorary Associate of the National Secular Society. He was the patron of the Friends of High Wycombe Library. In 2013 he gave a talk at Beaconsfield Library which he had visited as a child and donated the income from the event to it. On a number of occasions he also visited his former school to speak to the students and look around.

Pratchett was well known for his penchant for wearing large, black fedora hats, as seen on the inside back covers of most of his books. His style has been described as "more that of urban cowboy than city gent."

Concern for the future of civilisation prompted him to install five kilowatts of photovoltaic cells (for solar energy) at his house. Having been interested in astronomy since childhood, he had an observatory built in his garden. An asteroid (127005 Pratchett) is named after him.

On 31 December 2008, it was announced that Pratchett was to be knighted (as a Knight Bachelor) in the Queen's 2009 New Year Honours. He formally received the accolade at Buckingham Palace on 18 February 2009. Afterwards he said, "You can't ask a fantasy writer not to want a knighthood. You know, for two pins I'd get myself a horse and a sword." In late 2009, he did make himself a sword, with the help of his friends. He told a Times Higher Education interviewer that "At the end of last year I made my own sword. I dug out the iron ore from a field about 10 miles away – I was helped by interested friends. We lugged 80 kilos of iron ore, used clay from the garden and straw to make a kiln, and lit the kiln with wildfire by making it with a bow.' Colin Smythe, his longtime friend and agent, donated some pieces of meteoric iron – 'thunderbolt iron' has a special place in magic and we put that in the smelt, and I remember when we sawed the iron apart it looked like silver. Everything about it I touched, handled and so forth ... And everything was as it should have been, it seemed to me."

In 2013 Pratchett was named Humanist of the Year by the British Humanist Association (now known as Humanists UK) for his campaign to fund research into Alzheimers, his contribution to the right to die public debate and his Humanist values.

In August 2007, Pratchett was misdiagnosed as having had a minor stroke a few years before, which doctors believed had damaged the right side of his brain. In December 2007, he announced that he had been newly diagnosed with early-onset Alzheimer's disease, which had been responsible for the "stroke". He had a rare form of posterior cortical atrophy (PCA), a disease in which areas at the back of the brain begin to shrink and shrivel.

Describing the diagnosis as an "embuggerance" in a radio interview, Pratchett appealed to people to "keep things cheerful" and proclaimed that "we are taking it fairly philosophically down here and possibly with a mild optimism." He stated he felt he had time for "at least a few more books yet", and added that while he understood the impulse to ask "is there anything I can do?", in this case he would only entertain such offers from "very high-end experts in brain chemistry." Discussing his diagnosis at the Bath Literature Festival in early 2008, Pratchett revealed that by then he found it too difficult to write dedications when signing books. In his later years Pratchett wrote by dictating to his assistant, Rob Wilkins, or by using speech recognition software.
In March 2008, Pratchett announced he would donate US$1,000,000 (about £494,000) to the Alzheimer's Research Trust, and that he was shocked "to find out that funding for Alzheimer's research is just 3% of that to find cancer cures." He said: "I am, along with many others, scrabbling to stay ahead long enough to be there when the cure comes along."

In April 2008, Pratchett worked with the BBC to make a two-part documentary series about his illness, "Terry Pratchett: Living With Alzheimer's". The first part was broadcast on BBC Two on 4 February 2009, drawing 2.6 million viewers and a 10.4% audience share. The second, broadcast on 11 February 2009, drew 1.72 million viewers and a 6.8% audience share. The documentary won a BAFTA award in the Factual Series category. Pratchett also made an appearance on "The One Show" on 15 May 2008, talking about his condition. He was the subject and interviewee of the 20 May 2008 edition of "On the Ropes" (Radio 4), discussing Alzheimer's and how it had affected his life.

On 8 June 2008, news reports indicated that Pratchett had an experience which he described as: "It is just possible that once you have got past all the gods that we have created with big beards and many human traits, just beyond all that, on the other side of physics, there just may be the ordered structure from which everything flows" and "I don't actually believe in anyone who could have put that in my head". He went into further detail on "Front Row", in which he was asked if this was a shift in his beliefs: "A shift in me in the sense I heard my father talk to me when I was in the garden one day. But I'm absolutely certain that what I heard was my memories of my father. An engram, or something in my head...This is not about God, but somewhere around there is where gods come from."

On 26 November 2008, Pratchett met the Prime Minister Gordon Brown and asked for an increase in dementia research funding. Pratchett tested a prototype device to address his condition. The ability of the device to alter the course of the illness has been met with scepticism from Alzheimer's researchers.

In an article published mid-2009, Pratchett stated that he wished to die by assisted suicide (although he disliked that term) before his disease progressed to a critical point. He later said he felt "it should be possible for someone stricken with a serious and ultimately fatal illness to choose to die peacefully with medical help, rather than suffer." Pratchett was selected to give the 2010 BBC Richard Dimbleby Lecture, entitled "Shaking Hands With Death", broadcast on 1 February 2010. Pratchett introduced his lecture on the topic of assisted death, but the main text was read by his friend Tony Robinson because Pratchett's condition made it difficult for him to read. In June 2011 Pratchett presented a one-off BBC television documentary, "," about assisted suicide. It won the Best Documentary award at the Scottish BAFTAs in November 2011.

In September 2012 Pratchett stated: "I have to tell you that I thought I'd be a lot worse than this by now, and so did my specialist." In the same interview, he stated that the cognitive part of his mind was "untouched" and his symptoms were physical (normal for PCA). However, in July 2014 he cancelled his appearance at the biennial International Discworld Convention, saying: "the Embuggerance is finally catching up with me, along with other age-related ailments".

Pratchett died at his home on the morning of 12 March 2015 from Alzheimer's, according to his publisher. "The Telegraph" reported an unidentified source as saying that despite his previous discussion of assisted suicide, his death had been natural. After Pratchett's death, his assistant, Rob Wilkins, wrote from the official Terry Pratchett Twitter account:

The use of small capitals is a reference to how the character of Death speaks in Pratchett's works.

Many public figures paid tribute following Pratchett's death, including British Prime Minister David Cameron and the comedian Ricky Gervais, and authors including Nick Harkaway, Ursula K. Le Guin, Terry Brooks, Margaret Atwood, George R. R. Martin, and Neil Gaiman. Pratchett was memorialised in a graffito in East London, and the video game company Frontier Developments added a space station to "" named "Pratchett's Disc". Developers of Dota 2, Valve Corporation, added an item to their game called "Octarine Core", in reference to Pratchett's novel "The Colour of Magic". Users of the social news site Reddit organised a tribute by which an HTTP header, "codice_1", is added to a site's responses, a reference to the Discworld novel "Going Postal". In their June 2015 Web Server survey, Netcraft reported that approximately 84,000 websites had been configured with the header. This included the Guardian newspaper website, which, using their estimated page views, Netcraft estimated that the addition would cause terabytes of additional bandwidth per day.

Pratchett's humanist funeral service was held on 25 March 2015.

Pratchett started to use computers for writing as soon as they were available to him. His first computer was a Sinclair ZX81; the first computer he used properly for writing was an Amstrad CPC 464, later replaced by a PC. Pratchett was one of the first authors to routinely use the Internet to communicate with fans, and was a contributor to the Usenet newsgroup alt.fan.pratchett from 1992. However, he did not consider the Internet a hobby, just another "thing to use". He had many computers in his house, with a bank of six monitors rigged up to ease writing. When he travelled, he always took a portable computer with him to write.

His experiments with computer upgrades are reflected in "Hex".

Pratchett was also an avid video game player, and collaborated in the creation of a number of game adaptations of his books. He favoured games that are "intelligent and have some depth", citing "Half-Life 2" and fan missions from "Thief" as examples. Additionally, he played "", which he described as "wonderful", and used many of its non-combat-oriented, fan-made mods. Pratchett wrote dialogue for a mod for "Oblivion" which added a Nord companion named Vilja. He also worked on a similar mod for "" which featured Vilja's "great-great-granddaughter”.

He is also said to have enjoyed playing the first "Tomb Raider" game.

Pratchett had a fascination with natural history that he referred to many times, and he owned a greenhouse full of carnivorous plants.

In 1995, a fossil sea-turtle from the Eocene epoch of New Zealand was named in honour of him "Psephophorus terrypratchetti" by the palaeontologist Richard Köhler.

In 2016, Pratchett fans petitioned the International Union of Pure and Applied Chemistry (IUPAC) to name chemical element 117, temporarily called "ununseptium", as "octarine" with the proposed symbol Oc (pronounced "ook"). The final name chosen for element 117 was "tennessine" with the symbol Ts.

Pratchett was a trustee for the Orangutan Foundation UK but was pessimistic about the animal's future. His activities included visiting Borneo with a Channel 4 film crew to make an episode of "Jungle Quest" in 1995, seeing orangutans in their natural habitat. Following Pratchett's lead, fan events such as the Discworld Conventions have adopted the Orangutan Foundation as their nominated charity, which has been acknowledged by the foundation. One of Pratchett's most popular fictional characters, the Librarian of the Unseen University's Library, is a wizard who was transformed into an orangutan in a magical accident and decides to remain in that condition as it is so convenient for his work.

Pratchett had an observatory in his back garden and was a keen astronomer from childhood. He made an appearance on the BBC programme "The Sky at Night".

Pratchett sponsored a biennial award for unpublished science fiction novelists, the Terry Pratchett First Novel Award. The prize is a publishing contract with his publishers Transworld. In 2011 the award was won jointly by David Logan for "Half Sick of Shadows" and Michael Logan for "Apocalypse Cow". In 2013 the award was won by Alexander Maskill for "The Hive".

In 2015, the estate of the late Sir Terry Pratchett announced an in-perpetuity endowment to the University of South Australia. The Sir Terry Pratchett Memorial Scholarship supports a Masters scholarship at the University's Hawke Research Institute.

Pratchett received a knighthood for "services to literature" in the 2009 UK New Year Honours list. He was previously appointed Officer of the Order of the British Empire, also for "services to literature", in 1998. Following this, Pratchett commented in the Ansible SF/fan newsletter, "I suspect the 'services to literature' consisted of refraining from trying to write any," but added, "Still, I cannot help feeling mightily chuffed about it."

Pratchett was the British Book Awards' 'Fantasy and Science Fiction Author of the Year' for 1994.

Pratchett won the British Science Fiction Award in 1989 for his novel, "Pyramids", and a Locus Award for Best Fantasy Novel in 2008 for "Making Money".

Pratchett was awarded ten honorary doctorates: University of Warwick in 1999, the University of Portsmouth in 2001, the University of Bath in 2003, the University of Bristol in 2004, Buckinghamshire New University in 2008, the University of Dublin in 2008, Bradford University in 2009, University of Winchester in 2009, The Open University in 2013 for his contribution to Public Service and his last, from the University of South Australia, in May 2014.

Pratchett won the 2001 Carnegie Medal from the British librarians, recognising "The Amazing Maurice and His Educated Rodents" as the year's best children's book published in the UK.

"Night Watch" won the 2003 Prometheus Award for best libertarian novel.

In 2003, BBC conducted The Big Read to identify the "Nation's Best-loved Novel" and finally published a ranked list of the "Top 200". Pratchett's highest-ranking novel was "Mort", number 65, but he and Charles Dickens were the only authors with five in the Top 100 (four of his were from the "Discworld" series). He also led all authors with fifteen novels in the Top 200.

Three of the five "Discworld" novels that centre on the "trainee witch" Tiffany Aching won the annual Locus Award for Best Young Adult Book in 2004, 2005 and 2007.

In 2005, "Going Postal" was shortlisted for the Hugo Award for Best Novel; however, Pratchett recused himself, stating that stress over the award would mar his enjoyment of Worldcon.

Pratchett received the NESFA Skylark Award in 2009 and the World Fantasy Award for Life Achievement in 2010. In 2011 he won Margaret A. Edwards Award from the American Library Association, a lifetime honour for "significant and lasting contribution to young adult literature". The librarians cited nine Discworld novels published from 1983 to 2004 and observed that "Pratchett's tales of Discworld have won over generations of teen readers with intelligence, heart, and undeniable wit. Comic adventures that fondly mock the fantasy genre, the Discworld novels expose the hypocrisies of contemporary society in an intricate, ever-expanding universe. With satisfyingly multilayered plots, Pratchett's humor honors the intelligence of the reader. Teens eagerly lose themselves in a universe with no maps."

He was made an adjunct Professor in the School of English at Trinity College Dublin in 2010, with a role in postgraduate education in creative writing and popular literature.

"I Shall Wear Midnight" won the 2010 Andre Norton Award for Young Adult Science Fiction and Fantasy presented by the Science Fiction and Fantasy Writers of America (SFWA) as a part of the Nebula Award ceremony. In 2016, SFWA announced that Sir Terry would be the recipient of the Kate Wilhelm Solstice Award, presented at the 2016 SFWA Nebula Conference.

Pratchett's "Discworld" novels have led to dedicated conventions, the first in Manchester in 1996, then worldwide, often with the author as guest of honour. Publication of a new novel was sometimes accompanied by an international book signing tour; queues were known to stretch outside the bookshop as the author continued to sign books well after the intended finishing time. His fans were not restricted by age or gender, and he received a large amount of fan mail from them. Pratchett enjoyed meeting fans and hearing what they think about his books, saying that since he was well paid for his novels, his fans were "everything" to him.

Pratchett said that to write, you must read extensively, both inside and outside your chosen genre and to the point of "overflow". He advised that writing is hard work, and that writers must "make grammar, punctuation and spelling a part of your life." However, Pratchett enjoyed writing, regarding its monetary rewards as "an unavoidable consequence", rather than the reason for writing.

Although during his early career he wrote for the sci-fi and horror genres, Pratchett later focused almost entirely on fantasy, and said: "It is easier to bend the universe around the story." In the acceptance speech for his Carnegie Medal he said: "Fantasy isn't just about wizards and silly wands. It's about seeing the world from new directions", pointing to J. K. Rowling's "Harry Potter" novels and J. R. R. Tolkien's "The Lord of the Rings". In the same speech, he acknowledged benefits of these works for the genre.

Pratchett believed he owed "a debt to the science fiction/fantasy genre which he grew up out of" and disliked the term "magical realism" which, he said, is "like a polite way of saying you write fantasy and is more acceptable to certain people ... who, on the whole, do not care that much." He expressed annoyance that fantasy is "unregarded as a literary form", arguing that it "is the oldest form of fiction"; he described himself as "infuriated" when novels containing science fiction or fantasy ideas were not regarded as part of those genres. He debated this issue with novelist A. S. Byatt and critic Terry Eagleton, arguing that fantasy is fundamental to the way we understand the world and therefore an integral aspect of all fiction.

On 31 July 2005, Pratchett criticised media coverage of "Harry Potter" author J. K. Rowling, commenting that certain members of the media seemed to think that "the continued elevation of J. K. Rowling can be achieved only at the expense of other writers". Pratchett later denied claims that this was a swipe at Rowling, and said that he was not making claims of plagiarism, but was pointing out the "shared heritage" of the fantasy genre. Pratchett also posted on the "Harry Potter" newsgroup about a media-covered exchange of views with her.

Pratchett is known for a distinctive writing style that included a number of characteristic hallmarks. One example is his use of footnotes, which usually involve a comic departure from the narrative or a commentary on the narrative, and occasionally have footnotes of their own.

Pratchett's earliest Discworld novels were written largely to parody classic sword-and-sorcery fiction (and occasionally science-fiction); as the series progressed, Pratchett dispensed with parody almost entirely, and the Discworld series evolved into straightforward (though still comedic) satire.

Pratchett had a tendency to avoid using chapters, arguing in a Book Sense interview that "life does not happen in regular chapters, nor do movies, and Homer did not write in chapters", adding "I'm blessed if I know what function they serve in books for adults." However, there were exceptions; "Going Postal" and "Making Money" and several of his books for younger readers are divided into chapters. Pratchett offered explanations for his sporadic use of chapters; in the young adult titles, he said that he must use chapters because '[his] editor screams until [he] does', but otherwise felt that they were an unnecessary 'stopping point' that got in the way of the narrative.

Characters, place names, and titles in Pratchett's books often contain puns, allusions and cultural references. Some characters are parodies of well-known characters: for example, Pratchett's character Cohen the Barbarian, also called Ghengiz Cohen, is a parody of Conan the Barbarian and Genghis Khan, and his character Leonard of Quirm is a parody of Leonardo da Vinci.

Another hallmark of his writing was the use of capitalised dialogue without quotation marks, used to indicate the character of Death communicating telepathically into a character's mind. Other characters or types of characters were given similarly distinctive ways of speaking, such as the auditors of reality never having quotation marks, Ankh-Morpork grocers never using punctuation correctly, and golems capitalising each word in everything they say. Pratchett also made up a new colour, octarine, a 'fluorescent greenish-yellow-purple', which is the eighth colour in the "Discworld" spectrum—the colour of magic. Indeed, the number eight itself is regarded in the Discworld as being a magical number; for example, the eighth son of an eighth son will be a wizard, and his eighth son will be a "sourcerer", extremely powerful users of magic with abilities far beyond what most wizards usually achieve (which is one reason why wizards are not allowed to have children).

Discworld novels often included a modern innovation and its introduction to the world's medieval setting, such as a public police force ("Guards! Guards!"), guns ("Men at Arms"), submarines ("Jingo"), cinema ("Moving Pictures"), investigative journalism ("The Truth"), the postage stamp ("Going Postal"), modern banking ("Making Money"), and the steam engine ("Raising Steam"). The "clacks", the tower-to-tower semaphore system that sprang up in later novels, is a mechanical optical telegraph (as created by the Chappe brothers and employed during the French revolution) before wired electric telegraph chains, with all the change and turmoil that such an advancement implies. The resulting social upheaval driven by these changes serves as the setting for the main story.

Pratchett made no secret of outside influences on his work: they were a major source of his humour. He imported numerous characters from classic literature, popular culture and ancient history, always adding an unexpected twist. Pratchett was a crime novel fan, which was reflected in frequent appearances of the Ankh-Morpork City Watch in the "Discworld" series. Pratchett was an only child, and his characters are often without siblings. Pratchett explained, "In fiction, only-children are the interesting ones".

Pratchett's earliest inspirations were "The Wind in the Willows" by Kenneth Grahame, and the works of Isaac Asimov and Arthur C. Clarke. His literary influences were P.G. Wodehouse, Tom Sharpe, Jerome K. Jerome, Roy Lewis, Alan Coren, G. K. Chesterton, and Mark Twain.

While Pratchett's UK publishing history remained quite stable, his relationships with international publishers were turbulent (especially in America). He changed German publishers after an advertisement for Maggi soup appeared in the middle of the German-language version of "Pyramids".

Pratchett began writing the Discworld series in 1983 to "have fun with some of the cliches" and it is a humorous and often satirical sequence of stories set in the colourful fantasy Discworld universe. The series contains various story arcs (or sub-series), and a number of free-standing stories. All are set in an abundance of locations in the same detailed and unified world, such as the Unseen University and 'The Drum/Broken Drum/Mended Drum' public house in the twin city Ankh-Morpork, or places in the various continents, regions and countries on the Disc. Characters and locations reappear throughout the series, variously taking major and minor roles.

The Discworld itself is described as a large disc resting on the backs of four giant elephants, all supported by the giant turtle Great A'Tuin as it swims its way through space. The books are essentially in chronological order, and advancements can be seen in the development of the Discworld civilisations, such as the creation of paper money in Ankh-Morpork.

Many of the novels in Pratchett's Discworld series parody real-world subjects such as film making, newspaper publishing, rock and roll music, religion, philosophy, Ancient Greece, Egyptian history, the Gulf War, Australia, university politics, trade unions, and the financial world. Pratchett also included further parody as a feature within the stories, including such subjects as Ingmar Bergman films, numerous fiction, science fiction, and fantasy characters, and various bureaucratic and ruling systems.

Pratchett wrote or collaborated on a number of Discworld books that are not novels in themselves but serve to accompany the series.

"The Discworld Companion", written with Stephen Briggs, is an encyclopaedic guide to Discworld. The third edition was renamed "The New Discworld Companion", and was published in 2003. The fourth and most recent edition of the companion, "Turtle Recall" was published on 18 October 2012. Briggs also collaborated with Pratchett on a series of fictional Discworld "mapps". The first, "The Streets of Ankh-Morpork" (1993), was illustrated by Stephen Player. It was followed by "The Discworld Mapp" (1995), also illustrated by Stephen Player, which comprises a large, comprehensive map of the Discworld itself with a small booklet that contains short biographies of the Disc's prominent explorers and their discoveries. Two further "mapps" have been released, focusing on particular regions of the Disc: Lancre, and Death's Domain.

Between 1997 and 2015, ten Discworld Diaries were published as collaborations with Briggs or the Discword Emporium. Pratchett and Tina Hannan collaborated on "Nanny Ogg's Cookbook" (1999). The design of this cookbook, illustrated by Paul Kidby, was based on the traditional "Mrs Beeton's Book of Household Management", but with humorous recipes. Pratchett and Bernard Pearson collaborated on "The Discworld Almanak", for the Year of the Prawn, with illustration by Paul Kidby, Pearson and Sheila Watkins.

Collections of Discworld-related art have also been released in book form. "The Pratchett Portfolio" (1996) and "The Art of Discworld" (2004) are collections of paintings of major Discworld characters by Paul Kidby, with details added by Pratchett on the character's origins.

In 2005, Pratchett's first book for very young children was "Where's My Cow?" Illustrated by Melvyn Grant, this is a realisation of the short story Sam Vimes reads to his child in "Thud!".

"The Unseen University Cut Out Book" was published in 2006 developed with Alan Bately and Bernard Pearson. The book contains cut-out templates of seven of the major buildings in the Unseen University.

Following on from the release of Sky's adaptation of "Hogfather", "Terry Pratchett's Hogfather, The Illustrated Screenplay" was released in 2006. It was written by Vadim Jean and "mucked about with by Terry Pratchett". It contains the final shooting script, pictures from the film and additional illustrations by Stephen Player. It was published by Gollancz.

Pratchett and the Discworld Emporium published "The Compleat Ankh-Morpork City Guide" in 2012 which combined a trade directory, gazetteer, laws and ordinances together with a fully revised city map with artwork by Bernard Pearson, Ian Mitchell and Peter Dennis, who followed it with "The Compleat Discworld Atlas" (2015), a much enlarged and updated version of the original 'Mapp' and gazetteer, with information on all the countries of the Discworld.

A number of publications have been released on the back of Pratchett's novels with the participation of the Discworld Emporium:

Pratchett resisted mapping the Discworld for quite some time, noting that a firmly designed map restricts narrative possibility (i.e., with a map, fans would complain if he placed a building on the wrong street, but without one, he could adjust the geography to fit the story).

Pratchett wrote four "Science of Discworld" books in collaboration with Professor of mathematics Ian Stewart and reproductive biologist Jack Cohen, both of the University of Warwick: "The Science of Discworld" (1999), "" (2002), "" (2005), and "" (2013).

All four books have chapters that alternate between fiction and non-fiction: the fictional chapters are set within the Discworld universe, where characters observe, and experiment on, a universe with the same physics as ours. The non-fiction chapters (written by Stewart and Cohen) explain the science behind the fictional events.

In 1999, Pratchett appointed both Cohen and Stewart as "Honorary Wizards of the Unseen University" at the same ceremony at which the University of Warwick awarded him an honorary degree.

Pratchett collaborated with the folklorist Dr Jacqueline Simpson on "The Folklore of Discworld" (2008), a study of the relationship between many of the persons, places and events described in the Discworld books and their counterparts in myths, legends, fairy tales and folk customs on Earth.

Pratchett's first two adult novels, "The Dark Side of the Sun" (1976) and "Strata" (1981), were both science-fiction, the latter taking place partly on a disc-shaped world. Subsequent to these, Pratchett mostly concentrated on his "Discworld" series and novels for children, with two exceptions: "Good Omens" (1990), a collaboration with Neil Gaiman (which was nominated for both Locus and World Fantasy Awards in 1991), a humorous story about the Apocalypse set on Earth, and "Nation" (2008), a book for young adults.

After writing "Good Omens", Pratchett began to work with Larry Niven on a book that would become "Rainbow Mars"; Niven eventually completed the book on his own, but states in the afterword that a number of Pratchett's ideas remained in the finished version.

Pratchett also collaborated with British science fiction author Stephen Baxter on a parallel earth series. The first novel, entitled "The Long Earth" was released on 21 June 2012. A second novel, "The Long War", was released on 18 June 2013. "The Long Mars" was published in 2014. The fourth book in the series, "The Long Utopia", was published in June 2015, and the fifth, "The Long Cosmos", in June 2016.

In 2012, the first volume of Pratchett's collected short fiction was published under the title "A Blink of the Screen". In 2014, a similar collection was published of Pratchett's non-fiction, entitled "A Slip of the Keyboard".

Pratchett's first children's novel was also his first published novel: "The Carpet People" in 1971, which Pratchett substantially rewrote and re-released in 1992. The next, "Truckers" (1988), was the first in "The Nome Trilogy" of novels for young readers, about small gnome-like creatures called "Nomes", and the trilogy continued in "Diggers" (1990) and "Wings" (1990). Subsequently, Pratchett wrote the "Johnny Maxwell" trilogy, about the adventures of a boy called Johnny Maxwell and his friends, comprising "Only You Can Save Mankind" (1992), "Johnny and the Dead" (1993) and "Johnny and the Bomb" (1996).
"Nation" (2008) marked his return to the non-Discworld children's novel, and this was followed in 2012 by "Dodger", a children's novel set in Victorian London. On 21 November 2013 Doubleday Children's released Pratchett's "Jack Dodger's Guide to London".

In September 2014 an anthology of children's stories, "Dragons at Crumbling Castle", written by Pratchett, and illustrated by "Mark Beech", was published. This was followed by another collection, "The Witch's Vacuum Cleaner", also illustrated by Mark Beech, in 2016. A third volume, "Father Christmas's Fake Beard", was released in 2017.


According to Pratchett's assistant Rob Wilkins, Pratchett left "an awful lot" of unfinished writing, "10 titles I know of and fragments from many other bits and pieces." In the past, Pratchett himself mentioned at least two texts, "Scouting for Trolls", and a "Discworld" novel centering on a new character. The notes left behind outline ideas about "how the old folk of the Twilight Canyons solve the mystery of a missing treasure and defeat the rise of a Dark Lord despite their failing memories", "the secret of the crystal cave and the carnivorous plants in the Dark Incontinent", about Constable Feeney of the Watch, first introduced in "Snuff", involving how he "solves a whodunnit among the congenitally decent and honest goblins", and on a second book about Amazing Maurice from "The Amazing Maurice and His Educated Rodents".

Pratchett's daughter is the current custodian of the Discworld franchise, and has stated on several occasions that she has no plans to publish any of her father's unfinished work, or to continue the Discworld on her own.

Pratchett had told Neil Gaiman that anything that he had been working on at the time of his death should be put in the middle of a road and then destroyed by a steamroller crushing it. On 25 August 2017 Rob Wilkins, who manages the Pratchett estate, fulfilled this wish by destroying Terry Pratchett's computer hard-drive. He did this by running it over with a steamroller called "Lord Jericho" at the Great Dorset Steam Fair.

Four graphic novels of Pratchett's work have been released. The first two, originally published in the US, were adaptations of "The Colour of Magic" and "The Light Fantastic" and illustrated by Steven Ross (with Joe Bennett on the latter). The second two, published in the UK, were adaptations of "Mort" (subtitled "A Discworld Big Comic") and "Guards! Guards!", both illustrated by Graham Higgins and adapted by Stephen Briggs. The graphic novels of "The Colour of Magic" and "The Light Fantastic" were republished by Doubleday on 2 June 2008. An adaption of "Small Gods" was published on 28 July 2016.

Pratchett held back from "Discworld" feature films; though the rights to a number of his books have been sold, no films have yet been made, albeit various books have been adapted into feature-length television dramas (see Television section below).




Pratchett had a number of radio adaptations on BBC Radio 4: "The Colour of Magic", "Equal Rites" (on "Woman's Hour"), "Only You Can Save Mankind", "Guards! Guards!", "Wyrd Sisters", "Mort", and "Small Gods" have all been dramatised as serials, as was "Night Watch" in early 2008, and "The Amazing Maurice and his Educated Rodents" as a 90-minute play.

The 4-part BBC Radio 4 adaptation of "Eric" by Robin Brooks again started on 6 March 2013.

"Guards! Guards!" was adapted as a one-hour audio drama by the Atlanta Radio Theatre Company and performed live at Dragon*Con in 2001.

In 2014, a six-part adaption of "Good Omens" aired on BBC Radio 4, and featured cameos by both Terry Pratchett and Neil Gaiman.

"Truckers" was adapted as a stop motion animation series for Thames Television by Cosgrove Hall Films in 1992. "Johnny and the Dead" was made into a TV serial for Children's ITV on ITV, in 1995. "Wyrd Sisters" and "Soul Music" were adapted as animated cartoon series by Cosgrove Hall for Channel 4 in 1996; illustrated screenplays of these were published in 1998 and 1997 respectively. In January 2006, BBC One aired a three-part adaptation of "Johnny and the Bomb".

A two-part, feature-length version of "Hogfather" starring David Jason and the voice of Ian Richardson was first aired on Sky One in the United Kingdom in December 2006, and on ION Television in the US in 2007. Pratchett was opposed to live action films about "Discworld" before because of his negative experience with Hollywood film makers. He changed his opinion when he saw that the director Vadim Jean and producer Rod Brown were very enthusiastic and cooperative.
A two-part, feature-length adaptation of "The Colour of Magic" and its sequel "The Light Fantastic" aired during Easter 2008 on Sky One. A third adaptation, "Going Postal" was aired at the end of May 2010. The Sky adaptations notably feature the author's presence in cameo roles. He is also credited as having "mucked about" with these adaptations.

In 2012, Pratchett founded a television production company of his own, Narrativia, which is to hold the rights to his works, and which is in development of a television series, "The Watch", based on the Ankh-Morpork City Watch.

In 2016, Neil Gaiman stated that Terry had given him his blessing to go forward with an adaptation of "Good Omens" if he so wished. It is currently formatted as a six-part series. In January 2017 Gaiman confirmed the miniseries will be available on Amazon Prime in 2018 and will be broadcast on the BBC after its Amazon release.

Twenty one of Pratchett's novels have been adapted as plays by Stephen Briggs and published in book form. They were first produced by the Studio Theatre Club in Abingdon, Oxfordshire. They include adaptations of "The Truth", "Maskerade", "Mort", "Wyrd Sisters" and "Guards! Guards!" Stage adaptations of Discworld novels have been performed on every continent in the world, including Antarctica.

In addition, "Lords & Ladies" has been adapted for the stage by Irana Brown, and "Pyramids" was adapted for the stage by Suzi Holyoake in 1999 and had a week-long theatre run in the UK. In 2002, an adaptation of "Truckers" was produced as a co-production between Harrogate Theatre, the Belgrade Theatre Coventry and Theatre Royal, Bury St. Edmunds. It was adapted by Bob Eaton, and directed by Rob Swain. The play toured to many venues in the UK between 15 March and 29 June 2002.

A version of "Eric" adapted for the stage by Scott Harrison and Lee Harris was produced and performed by The Dreaming Theatre Company in June/July 2003 inside Clifford's Tower, the 700-year-old castle keep in York. It was revived in 2004 in a tour of England along with Robert Rankin's "The Antipope".

In 2004, a musical adaptation of "Only You Can Save Mankind" was premiered at the Edinburgh Festival, with music by Leighton James House and book and lyrics by Shaun McKenna.

In January 2009, the National Theatre announced that their annual winter family production in 2009 would be a theatrical adaptation of Pratchett's novel "Nation". The novel was adapted by playwright Mark Ravenhill and directed by Melly Still. The production premiered at the Olivier Theatre on 24 November, and ran until 28 March 2010. It was broadcast to cinemas around the world on 30 January 2010.

Pratchett worked with Youth Music Theatre UK to bring adaptations of both "Mort" and "Soul Music" to the stage. In August 2014, an adaptation of "Soul Music" was performed at the Rose Theatre, Kingston.

"GURPS Discworld" (Steve Jackson Games, 1998) and "GURPS Discworld Also" (Steve Jackson Games, 2001) are role-playing source books which were written by Terry Pratchett and Phil Masters, which offer insights into the workings of the Discworld. The first of these two books was re-released in September 2002 under the name of "The Discworld Roleplaying Game", with art by Paul Kidby.

The Discworld universe has been used as a basis for a number of video games on a range of formats, such as the Sega Saturn, the Sony PlayStation, the Philips CD-i, and the 3DO, as well as DOS and Windows-based PCs. The following are the more notable games:

So far there have been five games published relating to Discworld:

A collection of essays about his writings is compiled in the book "Terry Pratchett: Guilty of Literature", edited by Andrew M. Butler, Edward James and Farah Mendlesohn, published by Science Fiction Foundation in 2000 (). A second, expanded edition was published by Old Earth Books in 2004 (). Andrew M. Butler wrote the "Pocket Essentials Guide to Terry Pratchett" published in 2001 (). "Writers Uncovered: Terry Pratchett" is a biography for young readers by Vic Parker, published by Heinemann Library in 2006 ().

A BBC docudrama based on Pratchett's life. "Terry Pratchett: Back In Black" was broadcast in February 2017 and starred Paul Kaye as Pratchett. Neil Gaiman was involved with the project which used Pratchett's own words to create a "surreal", "witty" and "in character" documentary touching on some "important topics". Terry's long term assistant Rob Wilkins stated that Terry was working on this documentary before he died, and according to the BBC, finishing it would "show the author was still having the last laugh".



</doc>
<doc id="30030" url="https://en.wikipedia.org/wiki?curid=30030" title="Treaty of Versailles">
Treaty of Versailles

The Treaty of Versailles () was the most important of the peace treaties that brought World War I to an end. The Treaty ended the state of war between Germany and the Allied Powers. It was signed on 28 June 1919 in Versailles, exactly five years after the assassination of Archduke Franz Ferdinand which directly led to World War I. The other Central Powers on the German side of World War I signed separate treaties. Although the armistice, signed on 11 November 1918, ended the actual fighting, it took six months of Allied negotiations at the Paris Peace Conference to conclude the peace treaty. The treaty was registered by the Secretariat of the League of Nations on 21 October 1919.

Of the many provisions in the treaty, one of the most important and controversial required "Germany [to] accept the responsibility of Germany and her allies for causing all the loss and damage" during the war (the other members of the Central Powers signed treaties containing similar articles). This article, Article 231, later became known as the War Guilt clause. The treaty forced Germany to disarm, make substantial territorial concessions, and pay reparations to certain countries that had formed the Entente powers. In 1921 the total cost of these reparations was assessed at 132 billion marks (then $31.4 billion or £6.6 billion, roughly equivalent to US $442 billion or UK £284 billion in 2018). At the time economists, notably John Maynard Keynes (a British delegate to the Paris Peace Conference), predicted that the treaty was too harsh—a "Carthaginian peace"—and said the reparations figure was excessive and counter-productive, views that, since then, have been the subject of ongoing debate by historians and economists from several countries. On the other hand, prominent figures on the Allied side such as French Marshal Ferdinand Foch criticized the treaty for treating Germany too leniently.

The result of these competing and sometimes conflicting goals among the victors was a compromise that left no one content: Germany was neither pacified nor conciliated, nor was it permanently weakened. The problems that arose from the treaty would lead to the Locarno Treaties, which improved relations between Germany and the other European powers, and the re-negotiation of the reparation system resulting in the Dawes Plan, the Young Plan, and the indefinite postponement of reparations at the Lausanne Conference of 1932.

Although it is often referred to as the "Versailles Conference", only the actual signing of the treaty took place at the historic palace. Most of the negotiations were in Paris, with the "Big Four" meetings taking place generally at the Quai d'Orsay.

On 28 June 1914 the Bosnian-Serb Gavrilo Princip assassinated the heir to the throne of Austria-Hungary, Archduke Franz Ferdinand, in the name of Serbian nationalism. This caused a diplomatic crisis, resulting in Austria-Hungary declaring war on Serbia and sparking the First World War. Due to a variety of reasons, within weeks the major powers of Europe—divided into two alliances known as the Central Powers and the Triple Entente—went to war. As the conflict progressed, additional countries from around the globe became drawn into the conflict on both sides. Fighting would rage across Europe, the Middle East, Africa and Asia for the next four years. In 1917, two revolutions occurred within the Russian Empire, which led to the collapse of the Imperial Government and the rise of the Bolshevik Party led by Vladimir Lenin.

On 6 April 1917, the United States entered the war against the Central Powers. The reasons were twofold: German submarine warfare against merchant ships trading with France and Britain, which led to the sinking of the RMS "Lusitania" and the loss of 128 American lives; and the interception of the German Zimmerman Telegram, urging for Mexico to declare war against the United States. The American war aim was to detach the war from nationalistic disputes and ambitions after the Bolshevik disclosure of secret treaties between the Allies. The existence of these treaties tended to discredit Allied claims that Germany was the sole power with aggressive ambitions.

On 8 January 1918, United States President Woodrow Wilson issued a statement that became known as the Fourteen Points. This speech outlined a policy of free trade, open agreements, democracy, and self-determination. It also called for a diplomatic end to the war, international disarmament, the withdrawal of the Central Powers from occupied territories, the creation of a Polish state, the redrawing of Europe's borders along ethnic lines, and the formation of a League of Nations to guarantee the political independence and territorial integrity of all states. Wilson's speech also responded to Vladimir Lenin's Decree on Peace of November 1917, which proposed an immediate withdrawal of Russia from the war and called for a just and democratic peace uncompromised by territorial annexations. The Fourteen Points were based on the research of the Inquiry, a team of about 150 advisors led by foreign-policy advisor Edward M. House, into the topics likely to arise in the anticipated peace conference.

After the Central Powers launched Operation Faustschlag on the Eastern Front, the new Soviet Government of Russia signed the Treaty of Brest-Litovsk with Germany on 3 March 1918. This treaty ended the war between Russia and the Central powers and annexed of territory and 62 million people. This loss equated to a third of the Russian population, a quarter of its territory, around a third of the country's arable land, three-quarters of its coal and iron, a third of its factories (totalling 54 percent of the nation's industrial capacity), and a quarter of its railroads.

During the autumn of 1918, the Central Powers began to collapse. Desertion rates within the German army began to increase, and civilian strikes drastically reduced war production. On the Western Front, the Allied forces launched the Hundred Days Offensive and decisively defeated the German western armies. Sailors of the Imperial German Navy at Kiel mutinied, which prompted uprisings in Germany, which became known as the German Revolution. The German government tried to obtain a peace settlement based on the Fourteen Points, and maintained it was on this basis that they surrendered. Following negotiations, the Allied powers and Germany signed an armistice, which came into effect on 11 November while German forces were still positioned in France and Belgium.

The terms of the armistice called for an immediate evacuation of German troops from occupied Belgium, France, and Luxembourg within fifteen days. In addition, it established that Allied forces would occupy the Rhineland. In late 1918, Allied troops entered Germany and began the occupation.

Both the German Empire and Great Britain were dependent on imports of food and raw materials, primarily from the Americas, which had to be shipped across the Atlantic Ocean. The Blockade of Germany (1914–1919) was a naval operation conducted by the Allied Powers to stop the supply of raw materials and foodstuffs reaching the Central Powers. The German "Kaiserliche Marine" was mainly restricted to the German Bight and used commerce raiders and unrestricted submarine warfare for a counter-blockade. The German Board of Public Health in December 1918 stated that civilians had died during the Allied blockade, although an academic study in 1928 put the death toll at 

In late 1918, a Polish government was formed and an independent Poland proclaimed. In December, Poles launched an uprising within the German province of Posen. Fighting lasted until February, when an armistice was signed that left the province in Polish hands, but technically still a German possession.

Talks between the Allies to establish a common negotiating position started on 18 January 1919, in the "Salle de l'Horloge" at the French Foreign Ministry on the Quai d'Orsay in Paris. Initially, 70 delegates from 27 nations participated in the negotiations. Russia was excluded due to their signing of a separate peace (the Treaty of Brest-Litovsk) and early withdrawal from the war. Furthermore, German negotiators were excluded to deny them an opportunity to divide the Allies diplomatically.

Initially, a "Council of Ten" (comprising two delegates each from Britain, France, the United States, Italy, and Japan) met officially to decide the peace terms. This council was replaced by the "Council of Five", formed from each countries foreign ministers, to discuss minor matters. Prime Minister of France Georges Clemenceau, Prime Minister of Italy Vittorio Emanuele Orlando, Prime Minister of the United Kingdom David Lloyd George, and President of the United States Woodrow Wilson formed the "Big Four" (at one point becoming the "Big Three" following the temporally withdrawal of Vittorio Emanuele Orlando). These four men met in 145 closed sessions to make all the major decisions, which were later ratified by the entire assembly. The minor powers attended a weekly "Plenary Conference" that discussed issues in a general forum but made no decisions. These members formed over 50 commissions that made various recommendations, many of which were incorporated into the final text of the treaty.

France had lost soldiers killed, including French men aged France had also been more physically damaged than any other nation (the so-called zone rouge (Red Zone)); the most industrialized region and the source of most coal and iron ore in the north-east had been devastated and in the final days of the war mines had been flooded and railways, bridges and factories destroyed. Clemenceau intended to ensure the security of France, by weakening Germany economically, militarily, territorially and by supplanting Germany as the leading producer of steel in Europe. A position, British economist and Versailles negotiator, John Maynard Keynes summarized as attempting to "set the clock back and undo what, since 1870, the progress of Germany had accomplished."

Clemenceau told Wilson: "America is far away, protected by the ocean. Not even Napoleon himself could touch England. You are both sheltered; we are not". The French wanted a frontier on the Rhine, to protect France from a German invasion and compensate for French demographic and economic inferiority. American and British representatives refused the French claim and after two months of negotiations, the French accepted a British pledge to provide an immediate alliance with France if Germany attacked again, and Wilson agreed to put a similar proposal to the Senate. Clemenceau had told the Chamber of Deputies, in December 1918, that his goal was to maintain an alliance with both countries. Clemenceau accepted the offer, in return for an occupation of the Rhineland for fifteen years and that Germany would also demilitarise the Rhineland.

French negotiators wanted reparations, to make Germany pay for the damage caused during the war and to weaken Germany. The French also wanted the iron ore and coal of the Saar Valley, by annexation to France. The French were willing to accept a smaller amount of reparations than the Americans would concede and Clemenceau was willing discuss Germany capacity to pay with the German delegation, before the final settlement was drafted. In April and May 1919, the French and Germans held separate talks, on mutually acceptable arrangements on issues like reparation, reconstruction and industrial collaboration. France, along with the British Dominions and Belgium, opposed mandates and favored annexation of former Germany colonies.

Britain had suffered little land devastation during the war. However, the British wartime coalition was re-elected during the so-called Coupon election at the end of 1918, with a policy of squeezing the German "'til the pips squeak". Public opinion favoured a "just peace", which would force Germany to pay reparations and be unable to repeat the aggression of 1914, although those of a "liberal and advanced opinion" shared Wilson's ideal of a peace of reconciliation.

In private Lloyd George opposed revenge and attempted to compromise between Clemenceau's demands and the Fourteen Points, because Europe would eventually have to reconcile with Germany. Lloyd George wanted terms of reparation that would not cripple the German economy, so that Germany would remain a viable economic power and trading partner. By arguing that British war pensions and widows' allowances should be included in the German reparation sum, Lloyd George ensured that a large amount would go to the British Empire.

Lloyd George also intended to maintain a European balance of power to thwart a French attempt to establish itself as the dominant European Power. A revived Germany would be a counterweight to France and a deterrent to Bolshevik Russia. Lloyd George also wanted to neutralize the German navy to keep the Royal Navy as the greatest naval power in the world; dismantle the German colonial empire with several of its territorial possessions ceded to Britain and others being established as League of Nations mandates, a position opposed by the Dominions.

Prior to the American entry into the war, Wilson had talked of a 'peace without victory'. This position fluctuated following the US entry into the war. Wilson talked of the German aggressors who there could be no compromised peace with. However, on 8 January 1918, Wilson delivered a speech (known as the Fourteen Points) that declared the American peace objectives: the rebuilding of the European economy, self-determination of European ethnic groups, the promotion of free trade, the creation of appropriate mandates for former colonies, and above all, the creation of a powerful League of Nations that would ensure the peace. The aim of the latter was to provide a forum to revise the peace treaties as needed, and deal with problems that arose as a result of the peace and the rise of new states.

Wilson brought along top intellectuals as advisors to the American peace delegation, and the overall American position echoed the Fourteen Points. Wilson firmly opposed harsh treatment on Germany. While the British and French wanted to largely annex the German colonial empire, Wilson saw that as a violation of the fundamental principles of justice and human rights of the native populations, and favored them having the right of self-determination via the creation of mandates. The promoted idea called for the major powers to act as disinterested trustees over a region, aiding the native populations until they could govern themselves. In spite of this position and in order to ensure that Japan did not refuse to join the League of Nations, Wilson favored turning over the former German colony of Shandong, in Eastern China, to Japan rather than return the area to Chinese control. Further confounding the Americans, was US internal partisan politics. In November 1918, the Republican Party won the Senate election by a slim margin. Wilson, a Democrat, refused to include prominent Republicans in the American delegation making his efforts seem partisan, and contributed to a risk of political defeat at home.

In June 1919, the Allies declared that war would resume if the German government did not sign the treaty they had agreed to among themselves. The government headed by Philipp Scheidemann was unable to agree on a common position, and Scheidemann himself resigned rather than agree to sign the treaty. Gustav Bauer, the head of the new government, sent a telegram stating his intention to sign the treaty if certain articles were withdrawn, including Articles 227, 230 and 231. In response, the Allies issued an ultimatum stating that Germany would have to accept the treaty or face an invasion of Allied forces across the Rhine within On 23 June, Bauer capitulated and sent a second telegram with a confirmation that a German delegation would arrive shortly to sign the treaty. On 28 June 1919, the fifth anniversary of the assassination of Archduke Franz Ferdinand (the immediate impetus for the war), the peace treaty was signed. The treaty had clauses ranging from war crimes, the prohibition on the merging of Austria with Germany without the consent of the League of Nations, freedom of navigation on major European rivers, to the returning of a Koran to the king of Hedjaz.

The treaty stripped Germany of of territory and It also required Germany to give up the gains made via the Treaty of Brest-Litovsk and grant independence to the protectorates that had been established. In Western Europe Germany was required to recognize Belgian sovereignty over Moresnet and cede control of the Eupen-Malmedy area. Within six months of the transfer, Belgium was required to conduct a plebiscite on whether the citizens of the region wanted to remain under Belgian sovereignty or return to German control, communicate the results to the League of Nations and abide by the League's decision. To compensate for the destruction of French coal mines, Germany was to cede the output of the Saar coalmines to France and control of the Saar to the League of Nations for 15 years; a plebiscite would then be held to decide sovereignty. The treaty "restored" the provinces of Alsace-Lorraine to France by rescinding the treaties of Versailles and Frankfurt of 1871 as they pertained to this issue. The sovereignty of Schleswig-Holstein was to be resolved by a plebiscite to be held at a future time (see Schleswig Plebiscites).

In Eastern Europe, Germany was to recognize the independence of Czechoslovakia and cede parts of the province of Upper Silesia. Germany had to recognize the independence of Poland and renounce "all rights and title over the territory". Portions of Upper Silesia were to be ceded to Poland, with the future of the rest of the province to be decided by plebiscite. The border would be fixed with regard to the vote and to the geographical and economic conditions of each locality. The province of Posen (now Poznan), which had come under Polish control during the Greater Poland Uprising, was also to be ceded to Poland. Pomerelia (Eastern Pomerania), on historical and ethnic grounds, was transferred to Poland so that the new state could have access to the sea and became known as the Polish Corridor. The sovereignty of part of southern East Prussia was to be decided via plebiscite while the East Prussian Soldau area, which was astride the rail line between Warsaw and Danzig, was transferred to Poland outright without plebiscite. An area of was granted to Poland at the expense of Germany. Memel was to be ceded to the Allied and Associated powers, for disposal according to their wishes. Germany was to cede the city of Danzig and its hinterland, including the delta of the Vistula River on the Baltic Sea, for the League of Nations to establish the Free City of Danzig.

Article 119 of the treaty required Germany to renounce sovereignty over former colonies and Article 22 converted the territories into League of Nations mandates under the control of Allied states. Togoland and German Kamerun (Cameroon) were transferred to France. Ruanda and Urundi were allocated to Belgium, whereas German South-West Africa went to South Africa and the United Kingdom obtained German East Africa. As compensation for the German invasion of Portuguese Africa, Portugal was granted the Kionga Triangle, a sliver of German East Africa in northern Mozambique. Article 156 of the treaty transferred German concessions in Shandong, China, to Japan, not to China. Japan was granted all German possessions in the Pacific north of the equator and those south of the equator went to Australia, except for German Samoa, which was taken by New Zealand.

The treaty was comprehensive and complex in the restrictions imposed upon the post-war German armed forces (the "Reichswehr"). The provisions were intended to make the incapable of offensive action and to encourage international disarmament. Germany was to demobilize sufficient soldiers by 31 March 1920 to leave an army of no more than in a maximum of seven infantry and three cavalry divisions. The treaty laid down the organisation of the divisions and support units, and the General Staff was to be dissolved. Military schools for officer training were limited to three, one school per arm, and conscription was abolished. Private soldiers and non-commissioned officers were to be retained for at least twelve years and officers for a minimum of with former officers being forbidden to attend military exercises. To prevent Germany from building up a large cadre of trained men, the number of men allowed to leave early was limited.

The number of civilian staff supporting the army was reduced and the police force was reduced to its pre-war size, with increases limited to population increases; paramilitary forces were forbidden. The Rhineland was to be demilitarized, all fortifications in the Rhineland and east of the river were to be demolished and new construction was forbidden. Military structures and fortifications on the islands of Heligoland and Düne were to be destroyed. Germany was prohibited from the arms trade, limits were imposed on the type and quantity of weapons and prohibited from the manufacture or stockpile of chemical weapons, armoured cars, tanks and military aircraft. The German navy was allowed six pre-dreadnought battleships and was limited to a maximum of six light cruisers (not exceeding ), twelve destroyers (not exceeding ) and twelve torpedo boats (not exceeding ) and was forbidden submarines. The manpower of the navy was not to exceed including manning for the fleet, coast defences, signal stations, administration, other land services, officers and men of all grades and corps. The number of officers and warrant officers was not allowed to exceed Germany surrendered eight battleships, eight light cruisers, forty-two destroyers, and fifty torpedo boats for decommissioning. Thirty-two auxiliary ships were to be disarmed and converted to merchant use. Article 198 prohibited Germany from having an air force, including naval air forces, and required Germany to hand over all aerial related materials. In conjunction, Germany was forbidden to manufacture or import aircraft or related material for a period of six months following the signing of the treaty.

In Article 231 Germany accepted responsibility for the losses and damages caused by the war "as a consequence of the ... aggression of Germany and her allies." The treaty required Germany to compensate the Allied powers, and it also established an Allied "Reparation Commission" to determine the exact amount which Germany would pay and the form that such payment would take. The commission was required to "give to the German Government a just opportunity to be heard", and to submit its conclusions by . In the interim, the treaty required Germany to pay an equivalent of gold marks ($5 billion) in gold, commodities, ships, securities or other forms. The money would help to pay for Allied occupation costs and buy food and raw materials for Germany.

To ensure compliance, the Rhineland and bridgeheads east of the Rhine were to be occupied by Allied troops for fifteen years. If Germany had not committed aggression, a staged withdrawal would take place; after five years, the Cologne bridgehead and the territory north of a line along the Ruhr would be evacuated. After ten years, the bridgehead at Coblenz and the territories to the north would be evacuated and after fifteen years remaining Allied forces would be withdrawn. If Germany reneged on the treaty obligations, the bridgeheads would be reoccupied immediately.

Part I of the treaty, as per all the treaties signed during the Paris Peace Conference, was the Covenant of the League of Nations, which provided for the creation of the League, an organization for the arbitration of international disputes. Part XIII organized the establishment of the International Labour Officer, to regulate hours of work, including a maximum working day and week; the regulation of the labour supply; the prevention of unemployment; the provision of a living wage; the protection of the worker against sickness, disease and injury arising out of his employment; the protection of children, young persons and women; provision for old age and injury; protection of the interests of workers when employed abroad; recognition of the principle of freedom of association; the organization of vocational and technical education and other measures. The treaty also called for the signatories to sign or ratify the International Opium Convention.

The delegates of the Commonwealth and British Government had mixed thoughts on the treaty, with some seeing the French policy as being greedy and vindictive. Lloyd George and his private secretary Philip Kerr believed in the treaty, although they also felt that the French would keep Europe in a constant state of turmoil by attempting to enforce the treaty. Delegate Harold Nicolson wrote "are we making a good peace?", while General Jan Smuts (a member of the South African delegation) wrote to Lloyd-George, before the signing, that the treaty was unstable and declared "Are we in our sober senses or suffering from shellshock? What has become of Wilson's 14 points?" He wanted the Germans not be made to sign at the "point of the bayonet". Smuts issued a statement condemning the treaty and regretting that the promises of "a new international order and a fairer, better world are not written in this treaty". Lord Robert Cecil said that many within the Foreign Office were disappointed by the treaty. The treaty received widespread approval from the general public. Bernadotte Schmitt wrote that the "average Englishman ... thought Germany got only what it deserved" as a result of the treaty. However, public opinion changed as German complaints mounted.

The surrendering of the German High Seas Fleet following the armistice, its internment, and eventual scuttling at Scapa Flow meant that Britain's primary war goal was achieved prior to the signing of the treaty. As a result, British policy towards Germany began diverging from France's almost from the moment the guns fell silent and focused on establishing Germany as a bulwark against the threat posed by the new Soviet Union. 

By the 1930s, Lloyd George's position on the treaty has changed. In 1938, he published his memoir titled "The Truth About the Peace Treaties", in which he repudiated the terms of the treaty that bore his signature. Prime Minister Ramsay MacDonald, following the German re-militarisation of the Rhineland in 1936, stated that he was "pleased" that the treaty was "vanishing", expressing his hope that the French had been taught a "severe lesson".

The signing of the treaty was met with roars of approval, singing, and dancing from a crowd outside the Palace of Versailles. In Paris proper, people rejoiced at the official end of the war, the return of Alsace and Lorraine to France, and that Germany had agreed to pay reparations. 

While France ratified the treaty and was active in the League, the jubilant mood soon gave way to a political backlash for Clemenceau. The French Right saw the treaty as being too lenient and saw it as failing to achieve all of France's demands. Left-wing politicians attacked the treaty and Clemenceau for being too harsh (the latter turning into a ritual condemnation of the treaty, for politicians remarking on French foreign affairs, as late as August 1939). Marshal Ferdinand Foch stated "this (treaty) is not peace. It is an armistice for twenty years."; a criticism over the failure to annex the Rhineland and for compromising French security for the benefit of the United States and Britain. When Clemenceau stood for election as President of France in January 1920, he was defeated.

Reaction in Italy to the treaty was extremely negative. The country had suffered high casualties, yet failed to achieve most of its major war goals, notably gaining control of the Dalmatian coast and Fiume. President Wilson rejected Italy's claims on the basis of "national self-determination." For their part, Britain and France—who had been forced in the war's latter stages to divert their own troops to the Italian front to stave off collapse—were disinclined to support Italy's position at the peace conference. Differences in negotiating strategy between Premier Vittorio Orlando and Foreign Minister Sidney Sonnino further undermined Italy's position at the conference. A furious Vittorio Orlando suffered a nervous collapse and at one point walked out of the conference (though he later returned). He lost his position as prime minister just a week before the treaty was scheduled to be signed, effectively ending his active political career. Anger and dismay over the treaty's provisions helped pave the way for the establishment of Benito Mussolini's dictatorship three years later.

Portugal entered the war on the Allied side in 1916 primarily to ensure the security of its African colonies, which were threatened with seizure by both Britain and Germany. To this extent, she succeeded in her war aims. The treaty recognized Portuguese sovereignty over these areas and awarded her small portions of Germany's bordering overseas colonies. Otherwise, however, Portugal obtained little at the peace conference. Her promised share of German reparations never materialized, and a seat she coveted on the executive council of the new League of Nations went instead to Spain—which had remained neutral in the war. In the end, Portugal ratified the treaty, but got little out of the war, which cost more than 8,000 Portuguese troops and as many as 100,000 of her African colonial subjects their lives.

After the Versailles conference, Democratic President Woodrow Wilson claimed that "at last the world knows America as the savior of the world!" However, the Republican Party, led by Henry Cabot Lodge, controlled the US Senate after the election of 1918, and the senators were divided into multiple positions on the Versailles question. It proved possible to build a majority coalition, but impossible to build a two-thirds coalition that was needed to pass a treaty.

A discontent bloc of 12–18 "Irreconcilables", mostly Republicans but also representatives of the Irish and German Democrats, fiercely opposed the treaty. One block of Democrats strongly supported the Versailles Treaty, even with reservations added by Lodge. A second group of Democrats supported the treaty but followed Wilson in opposing any amendments or reservations. The largest bloc, led by Senator Lodge, comprised a majority of the Republicans. They wanted a treaty with reservations, especially on Article 10, which involved the power of the League of Nations to make war without a vote by the US Congress. All of the Irreconcilables were bitter enemies of President Wilson, and he launched a nationwide speaking tour in the summer of 1919 to refute them. However, Wilson collapsed midway with a serious stroke that effectively ruined his leadership skills.

The closest the treaty came to passage was on 19 November 1919, as Lodge and his Republicans formed a coalition with the pro-Treaty Democrats, and were close to a two-thirds majority for a Treaty with reservations, but Wilson rejected this compromise and enough Democrats followed his lead to permanently end the chances for ratification. Among the American public as a whole, the Irish Catholics and the German Americans were intensely opposed to the treaty, saying it favored the British.

After Wilson's presidency, his successor Republican President Warren G. Harding continued American opposition to the formation of the League of Nations. Congress subsequently passed the Knox–Porter Resolution bringing a formal end to hostilities between the United States and the Central Powers. It was signed into law by President Harding on 2 July 1921. Soon after, the US–German Peace Treaty of 1921 was signed in Berlin on 25 August 1921, the US–Austrian Peace Treaty of 1921 was signed in Vienna on 24 August 1921, and the US–Hungarian Peace Treaty of 1921 was signed in Budapest on 29 August 1921.

Wilson's former friend Edward Mandell House, present at the negotiations, wrote in his diary on 29 June 1919:

I am leaving Paris, after eight fateful months, with conflicting emotions. Looking at the conference in retrospect, there is much to approve and yet much to regret. It is easy to say what should have been done, but more difficult to have found a way of doing it. To those who are saying that the treaty is bad and should never have been made and that it will involve Europe in infinite difficulties in its enforcement, I feel like admitting it. But I would also say in reply that empires cannot be shattered, and new states raised upon their ruins without disturbance. To create new boundaries is to create new troubles. The one follows the other. While I should have preferred a different peace, I doubt very much whether it could have been made, for the ingredients required for such a peace as I would have were lacking at Paris.

China felt betrayed as the German territory in China was handed to Japan. The sense of betrayal led to great demonstrations in China and the fall of the nascent Chinese Republic's government and poisoned relations with the West. 

On 29 April, the German delegation under the leadership of the Foreign Minister Ulrich Graf von Brockdorff-Rantzau arrived in Versailles. On 7 May, when faced with the conditions dictated by the victors, including the so-called "War Guilt Clause", von Brockdorff-Rantzau replied to Clemenceau, Wilson and Lloyd George: "We know the full brunt of hate that confronts us here. You demand from us to confess we were the only guilty party of war; such a confession in my mouth would be a lie." Because Germany was not allowed to take part in the negotiations, the German government issued a protest against what it considered to be unfair demands, and a "violation of honour", soon afterwards withdrawing from the proceedings of the peace conference.

Germans of all political shades denounced the treaty—particularly the provision that blamed Germany for starting the war—as an insult to the nation's honor. They referred to the treaty as "the "Diktat"" since its terms were presented to Germany on a take-it-or-leave-it basis. Germany′s first democratically elected head of government, Philipp Scheidemann, resigned rather than sign the treaty. In a passionate speech before the National Assembly on 21 March 1919, he called the treaty a "murderous plan" and exclaimed,

After Scheidemann′s resignation, a new coalition government was formed under Gustav Bauer. President Friedrich Ebert knew that Germany was in an impossible situation. Although he shared his countrymen's disgust with the treaty, he was sober enough to consider the possibility that the government would not be in a position to reject it. He believed that if Germany refused to sign the treaty, the Allies would invade Germany from the west—and there was no guarantee that the army would be able to make a stand in the event of an invasion. With this in mind, he asked Field Marshal Paul von Hindenburg if the army was capable of any meaningful resistance in the event the Allies resumed the war. If there was even the slightest chance that the army could hold out, Ebert intended to recommend against ratifying the treaty. Hindenburg—after prodding from his chief of staff, Wilhelm Groener—concluded the army could not resume the war even on a limited scale. However, rather than inform Ebert himself, he had Groener inform the government that the army would be in an untenable position in the event of renewed hostilities. Upon receiving this, the new government recommended signing the treaty. The National Assembly voted in favour of signing the treaty by 237 to 138, with five abstentions (there were 421 delegates in total). This result was wired to Clemenceau just hours before the deadline. Foreign minister Hermann Müller and colonial minister Johannes Bell travelled to Versailles to sign the treaty on behalf of Germany. The treaty was signed on 28 June 1919 and ratified by the National Assembly on 9 July by a vote of 209 to 116.
Conservatives, nationalists and ex-military leaders condemned the treaty. Politicians of the Weimar Republic who supported the treaty, socialists, communists, and Jews were viewed with suspicion as persons of questionable loyalty. It was rumored that Jews had not supported the war and had played a role in selling Germany out to its enemies. Those who seemed to benefit from a weakened Germany and the newly formed Weimar Republic were regarded as having "stabbed Germany in the back". Those who instigated unrest and strikes in the critical military industries on the home front or who opposed German nationalism were seen to have contributed to Germany's defeat. These theories were given credence by the fact that when Germany surrendered in November 1918, its armies were still on French and Belgian territory. Furthermore, on the Eastern Front, Germany had already won the war against Russia and concluded the Treaty of Brest-Litovsk. In the West, Germany had seemed to have come close to winning the war with the Spring Offensive earlier in 1918. Its failure was blamed on strikes in the arms industry at a critical moment of the offensive, leaving soldiers with an inadequate supply of materiel. The strikes were regarded by nationalists as having been instigated by traitors, with the Jews taking most of the blame.

On 5 May 1921, the reparation Commission established the London Schedule of Payments and a final reparation sum of gold marks to be demanded of all the Central Powers. This was the public assessment of what the Central Powers combined could pay, and was also a compromise between Belgian, British, and French demands and assessments. Furthermore, the Commission recognized that the Central Powers could pay little and that the burden would fall upon Germany. As a result the sum was split into different categories, of which Germany was only required to pay gold marks ; this being the genuine assessment of the Commission on what Germany could pay, and allowed the Allied powers to save face with the public by presenting a higher figure. Furthermore, payments made between 1919 and 1921 were taken into account reducing the sum to 41 billion gold marks.

In order to meet this sum, Germany could pay in case or kind: coal, timber, chemical dyes, pharmaceuticals, livestock, agricultural machines, construction materials, and factory machinery. Germany's assistance with the restoration of the university library of Louvain, which was destroyed by the Germans on 25 August 1914, was also credited towards the sum. Territorial changes imposed by the treaty were also factored in. The payment schedule required within twenty-five days and then annually, plus 26 per cent of the value of German exports. The German Government was to issue bonds at five per cent interest and set up a sinking fund of one per cent to support the payment of reparations.

In February and March 1920, the Schleswig Plebiscites were held. The people of Schleswig were presented with only two choices: Danish or German sovereignty. The northern Danish-speaking area voted for Denmark while the southern German-speaking area voted for Germany, resulting in the province being partitioned. The East Prussia plebiscite was held on 11 July 1920. There was a out with the population wishing to remain with Germany. Further plebiscites were held in Eupen, Malmedy, and Prussian Moresnet. On 20 September 1920, the League of Nations allotted these territories to Belgium. These latter plebiscites were followed by a boundary commission in 1922, followed by the new Belgian-German border being recognized by the German Government on on 15 December 1923. The transfer of the Hultschin area, of Silesia, to Czechoslovakia was completed on 3 February 1921.

Following the implementation of the treaty, Upper Silesia was initially governed by Britain, France, and Italy. Between 1919-1921, three major outbreaks of violence took place between German and Polish civilians, resulting in German and Polish military forces also becoming involved. In March 1921, the Inter-Allied Commission held the Upper Silesia plebiscite, which was peaceful despite the previous violence. The plebiscite resulted in the population voting for the province to remain part of Germany. Following the vote, the League of Nations debated the future of the province. In 1922, Upper Silesia was partitioned: Oppeln, in the north-west, remained with Germany while Silesia Province, in the south-east, was transferred to Poland.

Memel remained under the authority of the League of Nations, with a French military garrison, until January 1923. On 9 January 1923, Lithuanian forces invaded the territory during the Klaipėda Revolt. The French garrison withdrew, and in February the Allies agreed to attach Memel as an "autonomous territory" to Lithuania. On 8 May 1924, after negotiations between the Lithuanian Government and the Conference of Ambassadors and action by the League of Nations, the annexation of Memel was ratified. Lithuania accepted the Memel Statute, a power-sharing arrangement to protect non-Lithuanians in the territory and its autonomous status while responsibility for the territory remained with the great powers. The League of Nations mediated between the Germans and Lithuanians on a local level, helping the power-sharing arrangement last until 1939.

On 13 January 1935, 15 years after the Saar Basin had been placed under the protection of the League of Nations, a plebiscite was held to determine the future of the area. were cast, with ( the ballot) in favour of union with Germany; were cast for the status quo, and for union with France. The region returned to German sovereignty on 1 March 1935. When the result was announced including from Germany fled to France.

In late 1918, America, Belgian, British, and French troops entered the Rhineland to enforce the armistice. Prior to the treaty, the occupation force stood at roughly 740,000 men. Following the signing of the peace treaty, the numbers drastically decreased and by 1926 the occupation force numbered only 76,000 men. As part of the 1929 negotiations that would become the Young Plan, Stresemann and Aristide Briand negotiated the early withdrawal of Allied forces from the Rhineland. On 30 June 1930, after speeches and the lowering of flags, the last troops of the Anglo-French-Belgian occupation force withdrew from Germany.

Belgium maintained an occupation force of roughly 10,000 troops throughout the initial years. This figure fell to 7,102 by 1926, and continued to fall as a result of diplomatic developments.

The British Second Army, with some 275,000 veteran soldiers, entered Germany in late 1918. In March 1919, this force became the British Army of the Rhine (BAOR). The total number of troops committed to the occupation rapidly dwindled as veteran soldiers were demobilized, and were replaced by inexperienced men who had finished basic training following the cessation of hostilities. By 1920, the BAOR consisted of only 40,594 men and the following year had been further reduced to 12,421. The size of the BAOR fluctuated over the following years, but never rose above 9,000 men. The British did not adhere to all obligated territorial withdrawals as dictated by Versailles, on account of Germany not meeting her own treaty obligations. A complete withdrawal was considered, but rejected in order to maintain a presence to continue acting as a check on French ambitions and prevent the establishment of an autonomous Rhineland Republic.

The French Army of the Rhine was initially 250,000 men strong, including at a peak 40,000 African colonial troops ("Troupes coloniales"). By 1923, the French occupation force had decreased to roughly 130,000 men, including 27,126 African troops. The troop numbers peaked again at 250,000 during the occupation of the Ruhr, before decreasing to 60,000 men by 1926. Germans viewed the use of French colonial troops as a deliberate act of humiliation, and used their presence to create a propaganda campaign dubbed the Black shame. This campaign lasted throughout the 1920s and 30s, although peaked in 1920 and 1921. For example, a 1921 German Government memo detailed 300 acts of violence from colonial troops, which included 65 murders and 170 sexual offenses. Historical consensus is that the charges were exaggerated for political and propaganda purposes, and that the colonial troops behaved far better than their white counterparts. An estimated 5-800 Rhineland Bastards were born as a result of fraternization between colonial troops and German women, and whom would latter be persecuted.

The United States Third Army entered Germany with . In June 1919, the Third Army demobilized and by 1920 the US occupation force had been reduced to . Wilson further reduced the garrison to , prior to the inauguration of Warren G. Harding in 1921. On 7 January 1923, after the Franco–Belgian occupation of the Ruhr, the US senate legislated the withdrawal of the remaining force. On 24 January, the American garrison started their withdrawal from the Rhineland, with the final troops leaving in early February.

The German economy was so weak that only a small percentage of reparations was paid in hard currency. Nonetheless, even the payment of this small percentage of the original reparations (132 billion gold marks) still placed a significant burden on the German economy. Although the causes of the devastating post-war hyperinflation are complex and disputed, Germans blamed the near-collapse of their economy on the treaty, and some economists estimated that the reparations accounted for as much as one-third of the hyper-inflation.

In March 1921, French and Belgian troops occupied Duisburg, which formed part of the demilitarized Rhineland, according to the Treaty of Versailles. In January 1923, French and Belgian forces occupied the rest of the Ruhr area as a reprisal after Germany failed to fulfill reparation payments demanded by the Versailles Treaty. The German government answered with "passive resistance", which meant that coal miners and railway workers refused to obey any instructions by the occupation forces. Production and transportation came to a standstill, but the financial consequences contributed to German hyperinflation and completely ruined public finances in Germany. Consequently, passive resistance was called off in late 1923. The end of passive resistance in the Ruhr allowed Germany to undertake a currency reform and to negotiate the Dawes Plan, which led to the withdrawal of French and Belgian troops from the Ruhr Area in 1925.

In 1920, the head of the "Reichswehr" Hans von Seeckt clandestinely re-established the General Staff, by expanding the "Truppenamt" (Troop Office); purportedly a human resources section of the army. In March, German troops entered the Rhineland under the guise of attempting to quell possible unrest by communists and in doing so violated the demilitarized zone. In response, French troops advanced further into Germany until the German troops withdrew.

German officials conspired systematically to evade the clauses of the treaty, by failing to meet disarmament deadlines, refusing Allied officials access to military facilities, and maintaining and hiding weapon production. As the treaty did not ban German companies from producing war material outside of Germany, companies moved to the Netherlands, Switzerland, and Sweden. Bofors was bought by Krupp, and in 1921 German troops were sent to Sweden to test weapons. The establishment of diplomatic ties with the Soviet Union, via the Genoa Conference and Treaty of Rapallo, was also used to circumvent the Treaty of Versailles. Publicly, these diplomatic exchanges were largely in regards to trade and future economic cooperation. However, secret military clauses were included that allowed for Germany to develop weapons inside the Soviet Union. Furthermore, it allowed for Germany to establish three training areas for aviation, chemical and tank warfare. In 1923, the British newspaper The Times made several claims about the state of the German Armed Forces: that it had equipment for , was transferring army staff to civilian positions in order to obscure their real duties, and warned of the militarization of the German police force by the exploitation the Krümper system.

The Weimar Government also funded domestic rearmament programs, which were covertly funded with the money camouflaged in "X-budgets", worth up to an additional the disclosed military budget. By 1925, German companies had begun to design tanks and modern artillery. During the year, over half of Chinese arms imports were German and worth "Reichsmarks." In January 1927, following the withdrawal of the Allied disarmament committee, Krupps ramped up production of armor plate and artillery. Production increased so that by 1937, military exports had increased to "Reichsmarks". Production was not the only violation: "Volunteers" were rapidly passed through the army to make a pool of trained reserves, and paramilitary organizations were encouraged with the illegally militarized police. Non-commissioned officers (NCOs) were not limited by the treaty, thus this loophole was exploited and as such the number of NCOs were vastly in excess to the number needed by the "Reichswehr".

In December 1931, the "Reichswehr" finalized a second rearmament plan that called for "Reichsmarks" to be spent over the following five years: this program sought to provide Germany the capability of creating and supplying a defensive force of 21 divisions supported by aircraft, artillery, and tanks. This coincided with a "Reichsmark" programme that planned for additional industrial infrastructure that would be able to permanently maintain this force. As these programs did not require an expansion of the military, they were nominally legal. On 7 November 1932, the Reich Minister of Defense Kurt von Schleicher authorized the illegal "Umbau" Plan for a standing army of 21 divisions based on soldiers and a large militia. Later in the year at the World Disarmament Conference, Germany withdrew to force France and the United Kingdom to accept German equality of status. The United Kingdom attempted to get Germany to return with the promise of all nations maintaining an equality in armaments and security. The British later proposed and agreed to an increase in the "Reichswehr" to men, and for Germany to have an air force half the size of the French. It was also negotiated for the French Army to be reduced. 

In October 1933, following the rise of Adolf Hitler and the founding of Nazi regime, Germany withdrew from League of Nations and the World Disarmament Conference. In March 1935, Germany reintroduced conscription followed by an open rearmament programme, the official unveiling of the Luftwaffe (air force), and signed the Anglo-German Naval Agreement that allowed a surface fleet the size of the Royal Navy. The resulting rearmament programs was allotted "Reichsmarks" over an eight year period.

On 7 March 1936, German troops entered and remilitarized the Rhineland. On 12 March 1938, following German pressure to the collapse the Austrian Government, German troops crossed into Austria and the following day Hitler announced the Anschluss: the annexation of Austria by Germany. The following year, on 23 March 1939, Germany annexed Memel from Lithuania.

According to David Stevenson, since the opening of French archives, most commentators have remarked on French restraint and reasonableness at the conference, though Stevenson notes that "[t]he jury is still out", and that "there have been signs that the pendulum of judgement is swinging back the other way."

In his book "The Economic Consequences of the Peace", John Maynard Keynes referred to the Treaty of Versailles as a "Carthaginian peace", a misguided attempt to destroy Germany on behalf of French revanchism, rather than to follow the fairer principles for a lasting peace set out in President Woodrow Wilson's Fourteen Points, which Germany had accepted at the armistice. He stated: "I believe that the campaign for securing out of Germany the general costs of the war was one of the most serious acts of political unwisdom for which our statesmen have ever been responsible." Keynes had been the principal representative of the British Treasury at the Paris Peace Conference, and used in his passionate book arguments that he and others (including some US officials) had used at Paris. He believed the sums being asked of Germany in reparations were many times more than it was possible for Germany to pay, and that these would produce drastic instability.

French economist Étienne Mantoux disputed that analysis. During the 1940s, Mantoux wrote a posthumously published book titled "The Carthaginian Peace, or the Economic Consequences of Mr. Keynes" in an attempt to rebut Keynes' claims. More recently economists have argued that the restriction of Germany to a small army saved it so much money it could afford the reparations payments.

It has been argued (for instance by historian Gerhard Weinberg in his book "A World At Arms") that the treaty was in fact quite advantageous to Germany. The Bismarckian Reich was maintained as a political unit instead of being broken up, and Germany largely escaped post-war military occupation (in contrast to the situation following World War II). In a 1995 essay, Weinberg noted that with the disappearance of Austria-Hungary and with Russia withdrawn from Europe, that Germany was now the dominant power in Eastern Europe.

The British military historian Correlli Barnett claimed that the Treaty of Versailles was "extremely lenient in comparison with the peace terms that Germany herself, when she was expecting to win the war, had had in mind to impose on the Allies". Furthermore, he claimed, it was "hardly a slap on the wrist" when contrasted with the Treaty of Brest-Litovsk that Germany had imposed on a defeated Russia in March 1918, which had taken away a third of Russia's population (albeit of non-Russian ethnicity), one-half of Russia's industrial undertakings and nine-tenths of Russia's coal mines, coupled with an indemnity of six billion marks. Eventually, even under the "cruel" terms of the Treaty of Versailles, Germany′s economy had been restored to its pre-war status.

Barnett also claims that, in strategic terms, Germany was in fact in a superior position following the Treaty than she had been in 1914. Germany′s eastern frontiers faced Russia and Austria, who had both in the past balanced German power. Barnett asserts that its post-war eastern borders were safer, because the former Austrian Empire fractured after the war into smaller, weaker states, Russia was wracked by revolution and civil war, and the newly restored Poland was no match for even a defeated Germany. In the West, Germany was balanced only by France and Belgium, both of which were smaller in population and less economically vibrant than Germany. Barnett concludes by saying that instead of weakening Germany, the treaty "much enhanced" German power. Britain and France should have (according to Barnett) "divided and permanently weakened" Germany by undoing Bismarck's work and partitioning Germany into smaller, weaker states so it could never have disrupted the peace of Europe again. By failing to do this and therefore not solving the problem of German power and restoring the equilibrium of Europe, Britain "had failed in her main purpose in taking part in the Great War".

The British historian of modern Germany, Richard J. Evans, wrote that during the war the German right was committed to an annexationist program which aimed at Germany annexing most of Europe and Africa. Consequently, any peace treaty that did not leave Germany as the conqueror would be unacceptable to them. Short of allowing Germany to keep all the conquests of the Treaty of Brest-Litovsk, Evans argued that there was nothing that could have been done to persuade the German right to accept Versailles. Evans further noted that the parties of the Weimar Coalition, namely the Social Democratic Party of Germany (SPD), the social liberal German Democratic Party (DDP) and the Christian democratic Centre Party, were all equally opposed to Versailles, and it is false to claim as some historians have that opposition to Versailles also equalled opposition to the Weimar Republic. Finally, Evans argued that it is untrue that Versailles caused the premature end of the Republic, instead contending that it was the Great Depression of the early 1930s that put an end to German democracy. He also argued that Versailles was not the "main cause" of National Socialism and the German economy was "only marginally influenced by the impact of reparations".

Ewa Thompson points out that the treaty allowed numerous nations in Central and Eastern Europe to liberate themselves from oppressive German rule, a fact that is often neglected by Western historiography, more interested in understanding the German point of view. In nations that found themselves free as the result of the treaty—such as Poles or Czechs—it is seen as a symbol of recognition of wrongs committed against small nations by their much larger aggressive neighbours.

Regardless of modern strategic or economic analysis, resentment caused by the treaty sowed fertile psychological ground for the eventual rise of the Nazi Party. The German historian Detlev Peukert wrote that Versailles was far from the impossible peace that most Germans claimed it was during the interwar period, and though not without flaws was actually quite reasonable to Germany. Rather, Peukert argued that it was widely believed in Germany that Versailles was a totally unreasonable treaty, and it was this "perception" rather than the "reality" of the Versailles treaty that mattered. Peukert noted that because of the "millenarian hopes" created in Germany during World War I when for a time it appeared that Germany was on the verge of conquering all of Europe, any peace treaty the Allies of World War I imposed on the defeated "German Reich" were bound to create a nationalist backlash, and there was nothing the Allies could have done to avoid that backlash. Having noted that much, Peukert commented that the policy of rapprochement with the Western powers that Gustav Stresemann carried out between 1923 and 1929 were constructive policies that might have allowed Germany to play a more positive role in Europe, and that it was not true that German democracy was doomed to die in 1919 because of Versailles. Finally, Peukert argued that it was the Great Depression and the turn to a nationalist policy of autarky within Germany at the same time that finished off the Weimar Republic, not the Treaty of Versailles.

French historian Raymond Cartier states that millions of Germans in the Sudetenland and in Posen-West Prussia were placed under foreign rule in a hostile environment, where harassment and violation of rights by authorities are documented. Cartier asserts that, out of 1,058,000 Germans in Posen-West Prussia in 1921, 758,867 fled their homelands within five years due to Polish harassment. In 1926, the Polish Ministry of the Interior estimated the remaining number of Germans at fewer than 300,000. These sharpening ethnic conflicts would lead to public demands to reattach the annexed territory in 1938 and become a pretext for Hitler′s annexations of Czechoslovakia and parts of Poland.

The plebiscites initiated due to the treaty have drawn much comment. Historian Robert Peckham wrote that the issue of Schleswig "was premised on a gross simplification of the region's history. ... Versailles ignored any possibility of there being a third way: the kind of compact represented by the Swiss Federation; a bilingual or even trilingual Schleswig-Holsteinian state" or other options such as "a Schleswigian state in a loose confederation with Denmark or Germany, or an autonomous region under the protection of the League of Nations." In regards to the East Prussia plebiscite, historian Richard Blanke wrote that "no other contested ethnic group has ever, under un-coerced conditions, issued so one-sided a statement of its national preference". Richard Debo wrote "both Berlin and Warsaw believed the Soviet invasion of Poland had influenced the East Prussian plebiscites. Poland appeared so close to collapse that even Polish voters had cast their ballots for Germany".

In regards to the Silesian plebiscite, Blanke observed "given that the electorate was at least 60% Polish-speaking, this means that about one 'Pole' in three voted for Germany" and "most Polish observers and historians" have concluded that the outcome of plebiscite was due to "unfair German advantages of incumbency and socio-economic position". Blanke alleged "coercion of various kinds even in the face of an allied occupation regime" occurred, and that Germany granted votes to those "who had been born in Upper Silesia but no longer resided there". Blanke concluded that despite these protests "there is plenty of other evidence, including Reichstag election results both before and after 1921 and the large-scale emigration of Polish-speaking Upper Silesians to Germany after 1945, that their identification with Germany in 1921 was neither exceptional nor temporary" and "here was a large population of Germans and Poles – not coincidentally, of the same Catholic religion – that not only shared the same living space but also came in many cases to see themselves as members of the same national community". Prince Eustachy Sapieha, the Polish Minister of Foreign Affairs, alleged that Soviet Russia "appeared to be intentionally delaying negotiations" to end the Polish-Soviet War "with the object of influencing the Upper Silesian plebiscite". Once the region was partitioned, both "Germany and Poland attempted to 'cleanse' their shares of Upper Silesia" via oppression resulting in Germans migrating to Germany and Poles migrating to Poland. Despite the oppression and migration, Opole Silesia "remained ethnically mixed."

Frank Russell wrote that, in regards to the Saar plebiscite, the inhabitants "were not terrorized at the polls" and the "totalitarian [Nazi] German regime was not distasteful to most of the Saar inhabitants and that they preferred it even to an efficient, economical, and benevolent international rule." When the outcome of the vote became known, 4,100 (including 800 refugees who had previously fled Germany) residents fled over the border into France.

During the formulation of the treaty, the British wanted Germany to abolish conscription and be allowed to maintain volunteer Army. The French wanted Germany to maintain a conscript army of up to 200,000 men in order to justify their own maintenance of a similar force. Thus the treaty's allowance of 100,000 volunteers was a compromise between the British and French positions. Germany, on the other hand, saw the terms as leaving them defenseless against any potential enemy. Bernadotte Everly Schmitt wrote that "there is no reason to believe that the Allied governments were insincere when they stated at the beginning of Part V of the Treaty ... that in order to facilitate a general reduction of the armament of all nations, Germany was to be required to disarm first." A lack of American ratification of the treaty or joining the League of Nations left France unwilling to disarm, which resulted in a German unwillingness to rearm. Schmitt argued "had the four Allies remained united, they could have forced Germany really to disarm, and the German will and capacity to resist other provisions of the treaty would have correspondingly diminished." 

Max Hantke and Mark Spoerer wrote "military and economic historians [have] found that the German military only insignificantly exceeded the limits" of the treaty prior to 1933. Adam Tooze concurred, and wrote "To put this in perspective, annual military spending by the Weimar Republic was counted not in the billions but in the hundreds of millions of "Reichsmarks""; for example, the Weimar Republic's 1931 program of "Reichsmarks" over five years compared to the Nazi Government's 1933 plan to spend "Reichsmarks" per year. P.M.H. Bell argued that the British Government was aware of latter Weimar rearming, and lent public respectability to the German efforts by not opposing them. Norman Davies wrote that "a curious oversight" of the military restrictions were that they "did not include rockets in its list of prohibited weapons", which provided Wernher von Braun an area to research within eventually resulting in "his break [that] came in 1943" leading to the development of the V-2 rocket.





</doc>
<doc id="30033" url="https://en.wikipedia.org/wiki?curid=30033" title="Mort">
Mort

Mort is a fantasy novel by British writer Terry Pratchett. Published in 1987, it is the fourth "Discworld" novel and the first to focus on the character Death, who only appeared as a side character in the previous novels. The title is the name of its main character and also a play on words: in French, "mort" means "death". The French language edition is titled "Mortimer".

In the BBC's 2003 Big Read contest, viewers voted on the "Nation's Best-loved Book"; "Mort" was among the Top 100 and chosen as the most popular of Pratchett's novels.

In 2004, Pratchett stated that "Mort" was the first Discworld novel with which he was "pleased", stating that in previous books, the plot had existed to support the jokes, but that in "Mort", the plot was integral.

As a teenager, Mort has a personality and temperament that makes him unsuited to the family farming business. Mort's father Lezek takes him to a local hiring fair in the hope that Mort will land an apprenticeship; not only would this provide a job for his son, but it would also make his son's propensity for thinking into someone else's problem. Just before the last stroke of midnight, Death arrives and takes Mort on as an apprentice (though his father thinks he has been apprenticed to an undertaker). Death takes Mort to his domain, where he meets Death's elderly manservant Albert, and his adopted daughter Ysabell. Mort later accompanies Death as he travels to collect the soul of a king, who is due to be assassinated by the scheming Duke of Sto Helit. After Mort unsuccessfully tries to prevent the assassination, Death warns him that all deaths are predetermined, and that he cannot interfere with fate.

Later on, Death assigns Mort to collect the soul of Princess Keli, daughter of the murdered king, but he instead kills the assassin the Duke had sent after her. Keli lives, but shortly after the assassin's death people begin acting as if something had happened without knowing why such as a solemn song being played. She soon finds that the rest of the world no longer acknowledges her existence at all unless she confronts them and even then only in a confused manner which is forgotten immediately after. She subsequently employs the wizard Igneous Cutwell, who is able to see her as he is trained to see things that are invisible to normal people (like death) to make her existence clear to the public. Mort eventually discovers that his actions have created an alternate reality in which Keli lives, but he also learns that it is being overridden by the original reality and will eventually cease to exist, killing Keli. While consulting Cutwell, Mort sees a picture of Unseen University's founder, Alberto Malich, noting that he bears a resemblance to Albert.

Mort and Ysabell travel into the Stack, a library in Death's domain that holds the biographies of everyone who has ever lived, in order to investigate Albert, eventually discovering that he is indeed Malich. They further learn that Malich had feared monsters waiting for him in the afterlife, and performed a reversed version of the Rite of AshkEnte in the hope of keeping Death away from him. However, the spell backfired and sent him to Death's side, where he has remained in order to put off his demise. During this time, Death, yearning to relish what being human is like, travels to Ankh-Morpork to indulge in new experiences, including getting drunk, dancing, gambling and finding a job. Mort in turn starts to become more like Death, adopting his mannerisms and aspects of his personality, while his own is slowly overridden.

Death's absence forces Mort to collect the next two souls, who are both located on separate parts of the Disc, and due to die on the same night that the alternate reality will be destroyed. Before he and Ysabell leave to collect the souls, Mort uses the part of Death within him to force Albert to provide a spell that will slow down the alternate reality's destruction. After Mort and Ysabell leave, Albert returns to Unseen University, under the identity of Malich. His eagerness to live on the Disc is reinvigorated during this time, and he has the wizards perform the Rite of AshkEnte in the hope of finally escaping Death's grasp. The ritual summons both Death and the part of Death that had been taking Mort over, restoring him to normal. Unaware of Albert's treachery, Death takes him back into his service, the Librarian preventing the wizard's escape.

Mort and Ysabell travel to Keli's palace, where the princess and Cutwell have organised a hasty coronation ceremony in the hope that Keli can be crowned queen before the alternate reality is destroyed. With the reality now too small for Albert's spell, Mort and Ysabell save Keli and Cutwell from being destroyed with the alternate reality. They return to Death's domain to find a furious Death waiting for them, the latter having learned of Mort's actions from Albert. Death dismisses Mort and attempts to take the souls of Keli and Cutwell, but Mort challenges him to a duel for them. Though Death eventually wins the duel, he spares Mort's life and sends him back to the Disc.

Death convinces the gods to change the original reality so that Keli rules in place of the Duke, who was inadvertently killed during Death and Mort's duel. Mort and Ysabell – who have fallen in love over the course of the story – get married, and are made Duke and Duchess of Sto Helit by Keli, while Cutwell is made the Master of the Queen's Bedchamber. Death attends Mort and Ysabell's reception, where he warns Mort that he will have to make sure that the original Duke's destiny is fulfilled, and presents him with the alternate reality he created, now shrunk to the size of a large pearl, before the two part on amicable terms.

Mort has been adapted into a graphic novel, Mort: The Big Comic, 1994.

The novel has been adapted by Robin Brooks for BBC Radio Four. Narrated by Anton Lesser, with Geoffrey Whitehead as Death, Carl Prekopp as Mort, Clare Corbett as Ysabell and Alice Hart as Princess Keli, the programme was first broadcast in four parts in mid-2004 and has been repeated frequently, most recently on Radio 4 Extra.

On 15 December 2007 a German language stage musical adaptation premiered in Hamburg, Germany.

A brand new English musical adaptation of Mort was presented in Guildford, Surrey, UK in August 2008 by Youth Music Theatre UK. The adaptation is by Jenifer Toksvig, sister of broadcaster and novelist Sandi Toksvig, and composer Dominic Haslam. A new production was staged at Greenwich Theatre in 2011, directed by Luke Sheppard.

Stephen Briggs also adapted the novel for the stage.


 


</doc>
<doc id="30034" url="https://en.wikipedia.org/wiki?curid=30034" title="Tim Berners-Lee">
Tim Berners-Lee

Sir Timothy John Berners-Lee (born 8 June 1955), also known as TimBL, is an English engineer and computer scientist, best known as the inventor of the World Wide Web. He is currently a professor of Computer Science at the University of Oxford and at Massachusetts Institute of Technology (MIT). He made a proposal for an information management system in March 1989, and he implemented the first successful communication between a Hypertext Transfer Protocol (HTTP) client and server via the internet in mid-November the same year.

Berners-Lee is the director of the World Wide Web Consortium (W3C), which oversees the continued development of the Web. He is also the founder of the World Wide Web Foundation and is a senior researcher and holder of the 3Com founders chair at the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL).
He is a director of the Web Science Research Initiative (WSRI), and a member of the advisory board of the MIT Center for Collective Intelligence. In 2011, he was named as a member of the board of trustees of the Ford Foundation. He is a founder and president of the Open Data Institute.

In 2004, Berners-Lee was knighted by Queen Elizabeth II for his pioneering work. In April 2009, he was elected a foreign associate of the United States National Academy of Sciences. Named in "Time" magazine's list of the , Berners-Lee has received a number of other accolades for his invention. He was honoured as the "Inventor of the World Wide Web" during the 2012 Summer Olympics opening ceremony, in which he appeared in person, working with a vintage NeXT Computer at the London Olympic Stadium. He tweeted "This is for everyone", which instantly was spelled out in LCD lights attached to the chairs of the 80,000 people in the audience. Berners-Lee received the 2016 Turing Award "for inventing the World Wide Web, the first web browser, and the fundamental protocols and algorithms allowing the Web to scale".

Berners-Lee was born in London, England, United Kingdom, one of four children born to Mary Lee Woods and Conway Berners-Lee. His parents worked on the first commercially built computer, the Ferranti Mark 1. He attended Sheen Mount Primary School, and then went on to attend south west London's Emanuel School from 1969 to 1973, at the time a direct grant grammar school, which became an independent school in 1975. A keen trainspotter as a child, he learnt about electronics from tinkering with a model railway. He studied at The Queen's College, Oxford, from 1973 to 1976, where he received a first-class bachelor of arts degree in physics.

After graduation, Berners-Lee worked as an engineer at the telecommunications company Plessey in Poole, Dorset. In 1978, he joined D. G. Nash in Ferndown, Dorset, where he helped create type-setting software for printers.

Berners-Lee worked as an independent contractor at CERN from June to December 1980. While in Geneva, he proposed a project based on the concept of hypertext, to facilitate sharing and updating information among researchers. To demonstrate it, he built a prototype system named ENQUIRE.

After leaving CERN in late 1980, he went to work at John Poole's Image Computer Systems, Ltd, in Bournemouth, Dorset. He ran the company's technical side for three years. The project he worked on was a "real-time remote procedure call" which gave him experience in computer networking. In 1984, he returned to CERN as a fellow.

In 1989, CERN was the largest internet node in Europe, and Berners-Lee saw an opportunity to join hypertext with the internet:

Berners-Lee wrote his proposal in March 1989 and, in 1990, redistributed it. It then was accepted by his manager, Mike Sendall. He used similar ideas to those underlying the ENQUIRE system to create the World Wide Web, for which he designed and built the first Web browser. His software also functioned as an editor (called WorldWideWeb, running on the NeXTSTEP operating system), and the first Web server, CERN HTTPd (short for Hypertext Transfer Protocol daemon).

The first web site was built at CERN. Despite this being an international organisation hosted by Switzerland, the office that Berners-Lee used was just across the border in France. It was put online on 6 August 1991 for the first time:

It provided an explanation of what the World Wide Web was, and how one could use a browser and set up a web server. In a list of 80 cultural moments that shaped the world, chosen by a panel of 25 eminent scientists, academics, writers, and world leaders, the invention of the World Wide Web was ranked number one, with the entry stating, "The fastest growing communications medium of all time, the internet has changed the shape of modern life forever. We can connect with each other instantly, all over the world".

In 1994, Berners-Lee founded the W3C at the Massachusetts Institute of Technology. It comprised various companies that were willing to create standards and recommendations to improve the quality of the Web. Berners-Lee made his idea available freely, with no patent and no royalties due. The World Wide Web Consortium decided that its standards should be based on royalty-free technology, so that they easily could be adopted by anyone.

In 2001, Berners-Lee became a patron of the East Dorset Heritage Trust, having previously lived in Colehill in Wimborne, East Dorset. In December 2004, he accepted a chair in computer science at the School of Electronics and Computer Science, University of Southampton, Hampshire, to work on the Semantic Web.

In a "Times" article in October 2009, Berners-Lee admitted that the initial pair of slashes ("//") in a web address were "unnecessary". He told the newspaper that he easily could have designed web addresses without the slashes. "There you go, it seemed like a good idea at the time", he said in his lighthearted apology.

In June 2009, then-British Prime Minister Gordon Brown announced Berners-Lee would work with the UK government to help make data more open and accessible on the Web, building on the work of the Power of Information Task Force. Berners-Lee and Professor Nigel Shadbolt are the two key figures behind data.gov.uk, a UK government project to open up almost all data acquired for official purposes for free re-use. Commenting on the opening up of Ordnance Survey data in April 2010, Berners-Lee said that: "The changes signal a wider cultural change in government based on an assumption that information should be in the public domain unless there is a good reason not to—not the other way around." He went on to say: "Greater openness, accountability and transparency in Government will give people greater choice and make it easier for individuals to get more directly involved in issues that matter to them."

In November 2009, Berners-Lee launched the World Wide Web Foundation in order to "advance the Web to empower humanity by launching transformative programs that build local capacity to leverage the Web as a medium for positive change."

Berners-Lee is one of the pioneer voices in favour of net neutrality, and has expressed the view that ISPs should supply "connectivity with no strings attached", and should neither control nor monitor the browsing activities of customers without their expressed consent. He advocates the idea that net neutrality is a kind of human network right: "Threats to the internet, such as companies or governments that interfere with or snoop on internet traffic, compromise basic human network rights." Berners-Lee participated in an open letter to the US Federal Communications Commission (FCC). He and 20 other Internet pioneers urged the FCC to cancel a vote on 14 December 2017 to uphold net neutrality. The letter was addressed to Senator Roger Wicker, Senator Brian Schatz, Representative Marsha Blackburn and Representative Michael F. Doyle.

Berners-Lee joined the board of advisors of start-up State.com, based in London. As of May 2012, Berners-Lee is president of the Open Data Institute, which he co-founded with Nigel Shadbolt in 2012.

The Alliance for Affordable Internet (A4AI) was launched in October 2013 and Berners-Lee is leading the coalition of public and private organisations that includes Google, Facebook, Intel, and Microsoft. The A4AI seeks to make internet access more affordable so that access is broadened in the developing world, where only 31% of people are online. Berners-Lee will work with those aiming to decrease internet access prices so that they fall below the UN Broadband Commission's worldwide target of 5% of monthly income.

Berners-Lee holds the founders chair in Computer Science at the Massachusetts Institute of Technology, where he heads the Decentralized Information Group and is leading Solid, a joint project with the Qatar Computing Research Institute that aims to radically change the way Web applications work today, resulting in true data ownership as well as improved privacy. In October 2016, he joined the Department of Computer Science at Oxford University as a professorial research fellow and as a fellow of Christ Church, one of the Oxford colleges.

Berners-Lee married Nancy Carlson, an American computer programmer, in 1990; she was also working in Switzerland, at the World Health Organisation. They had two children and divorced in 2011. 

He formed a relationship with Rosemary Leith, a Canadian internet and banking entrepreneur. Leith studied business at Queen’s University, then moved to Britain to pursue a career in investment and analysis. She worked in the City of London as a principal investor prior to 2000.. She was married to Mark Opzoomer, later the CEO of Rambler Media; the couple had three children, after which she left the financial sector, co-founding a start-up during the dot-com bubble. "Management Today" described her webzine (as it was called then) as "the first web site devoted entirely to those women struggling to strike a healthy balance between work and home life". More recent projects span both finance and internet. In 2011 she chaired the World Economic Forum Global Agenda Council for the Future of Internet Security and from 2015 she has been on the board of YouGov. She is on the advisory board for funding platform AllBright, to support "female entrepreneurs from start-ups to established businesses", and provided funding to Netwealth Investments Ltd. Leith is a fellow at Harvard University's Berkman Klein Center for Internet & Society

In 2014 Berners-Lee and Leith married at the Chapel Royal, St. James's Palace in London. The couple collaborate on projects such as venture capital to support artificial intelligence companies. Leith is a founding director of the World Wide Web Foundation, a non-profit Berners-Lee launched.

Berners-Lee was raised as an Anglican, but in his youth, he turned away from religion. After he became a parent, he became a Unitarian Universalist (UU). He has stated: "Like many people, I had a religious upbringing which I rejected as a teenager... Like many people, I came back to religion when we had children". He and his wife wanted to teach spirituality to their children, and after hearing a Unitarian minister and visiting the UU Church, they opted for it. He is an active member of that church, to which he adheres because he perceives it as a tolerant and liberal belief. He has said: "I believe that much of the philosophy of life associated with many religions is much more sound than the dogma which comes along with it. So I do respect them."

Berners-Lee has received many awards and honours. He was knighted by Queen Elizabeth II in the 2004 New Year Honours "for services to the global development of the internet", and was invested formally on 16 July 2004.

On 13 June 2007, he was appointed to the Order of Merit (OM), an order restricted to 24 (living) members. Bestowing membership of the Order of Merit is within the personal purview of the Queen, and does not require recommendation by ministers or the Prime Minister. He was elected a Fellow of the Royal Society (FRS) in 2001. He has been conferred honorary degrees from a number of Universities around the world, including Manchester (his parents worked on the Manchester Mark 1 in the 1940s), Harvard and Yale.

In 2012, Berners-Lee was among the British cultural icons selected by artist Sir Peter Blake to appear in a new version of his most famous artwork – the Beatles' "Sgt. Pepper's Lonely Hearts Club Band" album cover – to celebrate the British cultural figures of his life that he most admires to mark his 80th birthday.

In 2013, he was awarded the inaugural Queen Elizabeth Prize for Engineering. On 4 April 2017, he received the 2016 ACM Turing Award "for inventing the World Wide Web, the first web browser, and the fundamental protocols and algorithms allowing the Web to scale".




</doc>
<doc id="30035" url="https://en.wikipedia.org/wiki?curid=30035" title="The Legend of Zelda">
The Legend of Zelda

The Legend of Zelda is a high-fantasy action-adventure video-game series created by Japanese game designers Shigeru Miyamoto and Takashi Tezuka. It is primarily developed and published by Nintendo, although some portable installments have been outsourced to Capcom, Vanpool and Grezzo. The series' gameplay incorporates elements of action, adventure and puzzle-solving games.

The series centers on Link, the playable character and chief protagonist. Link is often given the task of rescuing Princess Zelda and the kingdom of Hyrule from Ganon, who is the principal antagonist of the series; however, other settings and antagonists have appeared in several games. The plots commonly involve a relic known as the Triforce, a set of three omnipotent golden triangles. The protagonist in each game is usually not the same incarnation of Link, but a few exceptions exist.

Since the original "The Legend of Zelda" was released in 1986, the series has expanded to include 19 entries on all of Nintendo's major game consoles, as well as a number of spin-offs. An American animated TV series based on the games aired in 1989 and individual manga adaptations commissioned by Nintendo have been produced in Japan since 1997. "The Legend of Zelda" is one of Nintendo's most prominent and successful franchises, selling over 80 million copies as of 2017; many of its games are considered by critics to be among the greatest video games of all time.

"The Legend of Zelda" games feature a mixture of puzzles, action, adventure/battle gameplay, and exploration. These elements have remained constant throughout the series, but with refinements and additions featured in each new game. Later games in the series also include stealth gameplay, where the player must avoid enemies while proceeding through a level, as well as racing elements. Although the games can be beaten with a minimal amount of exploration and side quests, the player is frequently rewarded with helpful items or increased abilities for solving puzzles or exploring hidden areas. Some items are consistent and appear many times throughout the series (such as bombs and bomb flowers, which can be used both as weapons and to open blocked or hidden doorways; boomerangs, which can kill or paralyze enemies; keys for locked doors; magic swords, shields, and bows and arrows), while others are unique to a single game. Though the games contain many role-playing elements ("" is the only one to include an experience system), they emphasize straightforward hack and slash-style combat over the strategic, turn-based or active time combat of games like "Final Fantasy". The game's role-playing elements, however, have led to much debate over whether or not the "Zelda" games should be classified as action role-playing games, a genre on which the series has had a strong influence.

Every game in the main "Zelda" series has consisted of three principal areas: an overworld in which movement is multidirectional, allowing the player some degree of freedom of action; areas of interaction with other characters (merely caves or hidden rooms in the first game, but expanding to entire towns and cities in subsequent games) in which the player gains special items or advice; and dungeons, areas of labyrinthine layout, usually underground, comprising a wide range of difficult enemies, bosses, and items. Each dungeon usually has one major item inside, which is usually essential for solving many of the puzzles within that dungeon and often plays a crucial role in defeating that dungeon's boss, as well as progressing through the game. In nearly every "Zelda" game, navigating a dungeon is aided by locating a map, which reveals its layout, and a magic compass, which reveals the location of significant and smaller items such as keys and equipment. In later games, the series includes a special "big key" that will unlock the door to battle the dungeon's boss enemy and open the item chest.

In most "Zelda" games, the player's life meter is represented as a line of hearts. The life meter is replenished a number of different ways, including picking up hearts left by defeated enemies or destroyed objects, fairies or springs located in specific locations, or consuming items such as potions or food. Fairies can be kept in bottles and act as extra lives, reviving the player if they run out of hearts. Players are able to extend their life meter by finding heart-shaped crystals called "Heart Containers". Full heart containers are usually received at the end of dungeons and dropped by the dungeon boss. Smaller "Pieces of Heart" are awarded for completing certain side quests or found hidden around the game world in various places, and require a certain number (usually four) to form a full heart container. 

The games pioneered a number of features that were to become industry standards. The original "Legend of Zelda" was the first console game with a save function that enabled players to stop playing and then resume later. "The Legend of Zelda: Ocarina of Time" introduced a targeting system that simplified 3D combat.

Games in "The Legend of Zelda" series frequently feature in-game musical instruments, particularly in musical puzzles, which are widespread. Often, instruments trigger game events: for example, the recorder in "The Legend of Zelda" can reveal secret areas, as well as warp Link to the Dungeon entrances. This warping with music feature has also been used in "A Link to the Past" and "Link's Awakening". In "", playing instruments is a core part of the game, with the player needing to play the instrument through the use of the game controller to succeed. "Ocarina of Time" is "[one of the] first contemporary non-dance title[s] to feature music-making as part of its gameplay", using music as a heuristic device and requiring the player to utilise songs to progress in the game – a game mechanic that is also present in "".

"The Legend of Zelda Theme" is a recurring piece of music that was created for the first game of the franchise. The composer and sound director of the series, Koji Kondo, initially planned to use Maurice Ravel's "Boléro" as the game's title theme, but was forced to change it when he learned, late in the game's development cycle, that the copyright for the orchestral piece had not yet expired. As a result, Kondo wrote a new arrangement of the overworld theme within one day. The "Zelda Theme" has topped ScrewAttack's "Top Ten Videogame Themes Ever" list.

Up until "", the "Legend of Zelda" series avoided using voice acting in speaking roles, relying instead on written dialogue. Series producer Eiji Aonuma previously stated that as Link is entirely mute, having the other characters speak while Link remains silent "would be off-putting". Instead of theme music for different locations, "Breath of the Wild" plays natural ambience around the player as main sounds, in addition to some minimalist piano music.

"The Legend of Zelda" was principally inspired by Shigeru Miyamoto's "explorations" as a young boy in the hillsides, forests, and caves surrounding his childhood home in Sonobe, Japan where he ventured into forests with secluded lakes, caves, and rural villages. According to Miyamoto, one of his most memorable experiences was the discovery of a cave entrance in the middle of the woods. After some hesitation, he apprehensively entered the cave, and explored its depths with the aid of a lantern. Miyamoto has referred to the creation of the "Zelda" games as an attempt to bring to life a "miniature garden" for players to play with in each game of the series.

Hearing of American novelist F. Scott Fitzgerald's wife Zelda, Miyamoto thought the name sounded "pleasant and significant". Paying tribute, he chose to name the princess after her, and titled it "The Legend of Zelda".

Link and the fairy were inspired by Peter Pan and Tinker Bell.

The Master Sword was inspired by the Arthurian legend, first mentioned in Welsh mythology; Mabinogion as; 'Caledfwlch' Excalibur. The similarities lay with the swords being kept in stone until the chosen one 'hero' takes it out to save the land.

"The Legend of Zelda" takes place predominantly in a medieval Western Europe-inspired fantasy land called Hyrule, which has developed a deep history and wide geography over the series' many releases. Much of the backstory of the creation of Hyrule was revealed in the games "", "", "", "", "", and "". Hyrule's principal inhabitants are pointy-eared humanoids called Hylians, which include the player character, Link, and the eponymous princess, Zelda.

According to the in-game backstories, the world of Hyrule was created by the three golden goddesses: Din, Farore and Nayru. Before departing, the goddesses left a sacred artifact called the Triforce, which could grant powers to the user. It physically manifests itself as three golden triangles in which each embodies one of the goddesses' virtues: Power, Courage and Wisdom. However, because the Triforce has no will of its own and it could not judge between good and evil, it would grant any wish indiscriminately. Because of this, it was placed within an alternate world called the "Sacred Realm" or the "Golden Land" until one worthy of its power and has balanced virtues of Power, Wisdom, and Courage in their heart could obtain it, in its entirety. If a person is not of a balanced heart, the triforce part that the user mostly believes in will stay with that person and the remainder will seek out others. In order to master and control the triforce as a whole, the user must get the other parts found in other individuals and bring them together to reunite them. The Sacred Realm can itself be affected by the heart of those who enters it: those who are pure will make it a paradise, while those who are evil will transform it into a dark realm.

In "Skyward Sword", the Triforce was sought by a demon king named Demise, and after a long battle, Demise was sealed away within the Temple of the goddess Hylia, guardian of the Triforce. Hylia, placing the Hylians on a floating island (called Skyloft) in the sky to protect them, orchestrated a means to stop the demon from escaping: creating the Goddess Sword (later becoming the Master Sword) for her chosen hero and discarding her divinity to be reborn among the people of Skyloft. In time, Zelda and Link (the reborn Hylia and her predestined warrior), enacted the goddess' plan and Demise was destroyed. However, Demise vowed that his rage would be reborn and forever plague those descended from Link and Zelda. That prophecy came to fruition in , when Ganondorf's attempt to get the Triforce scattered it with him gaining the Triforce of Power. The Triforce of Wisdom ended up with the Hylian princesses descended from Zelda, each named after her, while the Triforce of Courage is passed to a youth named Link across generations. While the Triforces of Power and Wisdom have been part of the series since the original "The Legend of Zelda", it was only in "Zelda II: The Adventure of Link" that the Triforce of Courage was first introduced, being obtained by Link at the end of his quest. The Triforce, or even a piece of it, is not always distributed as a whole. Such as in "The Wind Waker", Link must find all the pieces (called Triforce Shards) of the Triforce of Courage before he can return to Hyrule. Even in the original "The Legend of Zelda", Zelda breaks her Triforce of Wisdom into 8 pieces for Link to find, before she was captured by Ganon.

The fictional universe established by the "Zelda" games sets the stage for each adventure. Some games take place in different lands with their own back-stories. Termina and serve as parallel worlds to Hyrule, is a connected kingdom, and Koholint is an island far away from Hyrule that appears to be part of a dream.

The chronology of the "Legend of Zelda" series was a subject of much debate among fans until an official timeline was released within the "" collector's book, which was first released in Japan in December 2011. Prior to its release, producers confirmed the existence of a confidential document, which connected all the games. Certain materials and developer statements once partially established an official timeline of the released installments. "" is a direct sequel to the original "The Legend of Zelda", and takes place several years later. The third game, "", is a prequel to the first two games, and is directly followed by "Link's Awakening". "" is a prequel that takes the story many centuries back; according to character designer Satoru Takizawa, it was meant to implicitly tell the story of the Imprisoning War from the manual of "A Link to the Past", with "Majora's Mask" directly following its ending. "Skyward Sword" is then a prequel to "Ocarina of Time". "Twilight Princess" is set more than 100 years after "Ocarina of Time".

"The Wind Waker" is parallel, and takes place in the other timeline branch, more than a century after the adult era of "Ocarina of Time". "Phantom Hourglass" is a continuation of the story from "The Wind Waker", and is followed by "Spirit Tracks", which is set about 100 years later on a supercontinent far away from the setting of "The Wind Waker". At the time of its release, "" for the Game Boy Advance was considered the oldest tale in the series' chronology, with "Four Swords Adventures" set sometime after its events. "The Minish Cap" precedes the two games, telling of the origins of villain Vaati and the creation of the Four Sword. "" takes place six generations after "Link to the Past". Important events that occur in the game include the Triforce being reunited, and Ganon being resurrected.

Nintendo's 2011 timeline announcement subsequently posits that following "Ocarina of Time", the timeline splits into three alternate routes: in one, Link fails to defeat Ganon, leading into the Imprisoning War and "A Link to the Past", "Oracle of Seasons" and "Oracle of Ages", "Link's Awakening", "The Legend of Zelda" and "The Adventure of Link". In the second and third, Link is successful, leading to a timeline split between his childhood (when Zelda sends him back in time so he can use the wisdom he has gained to warn the Zelda in the past of the horrifying fate of Hyrule) and adulthood (where the Zelda from the future lives on to try and rebuild the kingdom). His childhood continues with "Majora's Mask", followed by "Twilight Princess" and "Four Swords Adventures". The timeline from his adult life continues into "Wind Waker", "Phantom Hourglass" and "Spirit Tracks".

In the early 2000s, Nintendo of America released a timeline on the official website of the series, which interpreted all stories up to the "Oracle" games as the adventures of a single protagonist named Link. At one point, translator Dan Owsen and his coworkers at Nintendo of America had conceived another complete timeline and intended to make it available online. However, the Japanese series developers rejected the idea so the timeline would be kept open to the imagination of the players.

"Breath of the Wild's" placement is currently unknown, as it contains references to games in all three of the timelines. The only thing known about it is that it takes place thousands of years after "Ocarina of Tim"e.

The central protagonist of "The Legend of Zelda" series, Link is the name of various young men who characteristically wear a green tunic and a pointed cap, and are the bearers of the Triforce of Courage. In most games, the player can give Link a different name before the start of the adventure, and he will be referred by that given name throughout by the non-player characters (NPCs). The various Links each have a special title, such as "Hero of Time", "Hero of the Winds" or "Hero chosen by the gods". Like many silent protagonists in video games, Link does not speak, only producing grunts, yells, or similar sounds. Despite the player not seeing the dialogue, it is referenced second-hand by in-game characters, showing that he is not, in fact, mute. Link is shown as a silent protagonist so that the audience is able to have their own thoughts as to how their Link would answer the characters instead of him having scripted responses.

Princess Zelda is the princess of Hyrule and the guardian of the Triforce of Wisdom. Her name is present in many of her female ancestors and descendants. While most games require Link to save Zelda from Ganon, she sometimes plays a supporting role in battle, using magical powers and weapons such as Light Arrows to aid Link. With the exception of the CD-i games (which were not official Nintendo games), she was not playable in the main series until "Spirit Tracks", where she becomes a spirit and can possess a Phantom Knight that can be controlled by the player. Zelda appears under various other aliases and alter egos, including Sheik (in "") and Tetra (in "" and ")". In "Skyward Sword", it is revealed that the Zelda of that game is a reincarnation of the goddess Hylia, whose power flows through the royal bloodline. The name "Zelda" derives from the American novelist Zelda Fitzgerald.

Ganon, also known as Ganondorf in his humanoid form, is the main antagonist and the final boss in the majority of "The Legend of Zelda" games. In the series, Ganondorf is the leader of a race of desert brigands called the Gerudo, which consists entirely of female warriors save for one man born every one hundred years. He is significantly taller than other human NPCs, but his looks vary between games, often taking the form of a monstrous anthropomorphic boar. His specific motives vary from game to game, but most often his plans include him kidnapping Princess Zelda and planning to achieve domination of Hyrule and presumably the world beyond it. To this end, he seeks the Triforce, a powerful magical relic. He often possesses a portion of the Triforce called the Triforce of Power, which gives him great strength. However, it is often not enough to accomplish his ends, leading him to hunt the remaining Triforce pieces. Unlike Link, Zelda, and most other recurring characters, he is actually the same person in every game, with the exception of "Four Swords Adventures", where he is a reincarnation of the original. In each game the battles with him are different and he fights using different styles. The game "" indicates that Ganon is a reincarnation of an evil deity known as Demise.

"The Legend of Zelda", the first game of the series, was first released in Japan on February 21, 1986, on the Famicom Disk System. A cartridge version, using battery-backed memory, was released in the United States on August 22, 1987, and Europe on November 27, 1987. The game features a "Second Quest," accessible either upon completing the game, or by registering one's name as "ZELDA" when starting a new quest. The Second Quest features different dungeons and item placement, and more difficult enemies.

The second game, "", was released for the Famicom Disk System in Japan on January 14, 1987, and for the Nintendo Entertainment System in Europe in November 1988 and North America in December 1988. The game exchanged the top-down perspective for side-scrolling (though the top-down point of view was retained for overworld areas), and introduced RPG elements (such as experience points) not used previously or thereafter in the series. "The Legend of Zelda" and "Zelda II" were released in gold-coloured cartridges instead of the console's regular grey cartridges. Both were re-released in the final years of the Nintendo Entertainment System with grey cartridges.

Four years later, "" returned to the top-down view (under a 3/4 perspective), and added the concept of an alternate dimension, the Dark World. The game was released for the Super NES on November 21, 1991. It was later re-released for the Game Boy Advance on March 14, 2003, in North America, on a cartridge with "", the first multiplayer "Zelda", and then through Nintendo's Virtual Console service on January 22, 2007. In addition, both this game (unchanged, except for being converted into a downloadable format) and an exclusive "loosely based" sequel (which used the same game engine) called "BS Zelda no Densetsu Inishie no Sekiban" were released on the Satellaview in Japan on March 2, 1997, and March 30, 1997, respectively.

In 1994, near the end of the Famicom's lifespan, the original Famicom game was re-released in cartridge format. A modified version, "BS Zelda no Densetsu", was released for the Super Famicom's satellite-based expansion, Satellaview, on August 6, 1995, in Japan. A second Satellaview game, "BS Zelda no Densetsu MAP2" was released for the Satellaview on December 30, 1995. Both games featured rearranged dungeons, an altered overworld, and new voice-acted plot-lines.

The next game, "", is the first "Zelda" for Nintendo's Game Boy handheld, and the first set outside Hyrule and to exclude Princess Zelda. It was released in 1993, and re-released, in full color, as a launch game for the Game Boy Color in 1998 as "Link's Awakening DX". This re-release features additions such as an extra color-based dungeon and a photo shop that allows interaction with the Game Boy Printer.

After a five-year hiatus, the series made the transition to 3D with "" for the Nintendo 64, which was released in November 1998. This game, initially known as "Zelda 64", retains the core gameplay of the previous 2D games, and was very successful commercially and critically. It is considered by many critics and gamers to be the best video game of all time, and ranks highly on IGN and EGM's "greatest games of all time" lists, as well as scoring perfect scores in several video game publications. In February 2006, it was ranked by "Nintendo Power" as the best game released for a Nintendo console. The game was originally developed for the poorly selling, Japanese-only Nintendo 64DD, but was ported to cartridge format when the 64DD hardware was delayed. A new gameplay mechanic, lock-on targeting (called "Z-targeting" as that is the controller button used), is used in the game, which focuses the camera on a nearby target and alters the player's actions relative to that target. Such mechanics allow precise sword fighting in a 3D space. The game heavily uses context-sensitive button play, which enabled the player to control various actions with Link using only one button on the Nintendo 64's game pad. Each action was handled slightly differently but all used the 'A' button to perform. For instance, standing next to a block and pressing 'A' made Link grab it (enabling him to push/pull it), but moving forwards into a block and pressing 'A' allowed Link to climb the block. The 'B' button was used only as an attack button. The game featured the first appearance of Link's horse, Epona, allowing Link to travel quickly across land and fire arrows from horseback. Those who preordered the game received a gold-coloured cartridge in a limited edition box with a golden plastic card affixed, reading "Collector's Edition". In some stores that had this "Collector's Edition" quickly sell out, a small and rare Zelda pin was given instead. It is the sword and shield emblem with "Zelda" written on it. Very few of them are known to remain.

"Ocarina of Time" was re-released on the GameCube in 2002, when it was offered as a pre-order incentive for "" in the U.S., Canada and Japan. Europe continued to receive it free in every copy of "", except for the discounted Player's Choice version. It includes what is widely believed to be the remnants of a cancelled 64DD expansion for Ocarina of Time known as "Ura Zelda" in early development. Named "", the game was given the addition of revamped, more difficult dungeon layouts. "Ocarina of Time" was included as part of the "" for the GameCube in 2003. It is now available through the Wii's Virtual Console service. In 2011, Nintendo released a new version of the game in stereoscopic 3D for the Nintendo 3DS, "". In July 2015, Nintendo rereleased it for the Wii U Virtual Console.

"Ocarina of Time"s follow-up, "", was released in April 2000. It uses the same 3D game engine as the previous game, and added a time-based concept, in which Link, the protagonist, relives the events of three days as many times as needed to complete the game's objectives. It was originally called "Zelda Gaiden", a Japanese title that translates as "Zelda Side story". Gameplay changed significantly; in addition to the time-limit, Link can use masks to transform into creatures with unique abilities. While "Majora's Mask" retains the graphical style of "Ocarina of Time", it is also a departure, particularly in its atmosphere. It features motion-blur, unlike its predecessor. The game is darker, dealing with death and tragedy in a manner not previously seen in the series, and has a sense of impending doom, as a large moon slowly descends upon the land of Termina to destroy all life. All copies of "" are gold cartridges. A limited "Collector's Edition" lenticular cartridge label was offered as the pre-order incentive. Copies of the game that are not collector's editions feature a normal sticker cartridge label. "Majora's Mask" is included in the "", and is available on the Virtual Console, as well as a 3D port for the portable 3DS console.

The next two games, , were released simultaneously for the Game Boy Color, and interact using passwords or a Game Link Cable. After one game has been completed, the player is given a password that allows the other game to be played as a sequel. They were developed by Flagship in conjunction with Nintendo, with supervision from Miyamoto. After the team experimented with porting the original "The Legend of Zelda" to the Game Boy Color, they decided to make an original trilogy to be called the "Triforce Series". When the password system linking the three games proved too troublesome, the concept was reduced to two games at Miyamoto's suggestion. These two games became "Oracle of Ages", which is more puzzle-based, and "Oracle of Seasons", which is more action-oriented.

When Nintendo revealed the GameCube on August 24, 2000, the day before Nintendo's SpaceWorld 2000 exposition, a software demonstration showed a realistically styled real-time duel between Ganondorf and Link. Fans and the media speculated that the battle might be from a "Zelda" game in development. At Spaceworld 2001, Nintendo showed a cel-shaded "Zelda" game, later released as "" in December 2002. Due to poor reception, nothing further was shown until a playable demonstration was ready. Miyamoto felt "The Wind Waker" would "extend "Zelda"s reach to all ages". The gameplay centres on controlling wind with a baton called the "Wind Waker" and sailing a small boat around an island-filled ocean, retaining similar gameplay mechanics as the previous 3D games in the series.

Following the release of "The Wind Waker" came "The Legend of Zelda: Collector's Edition", which included the original "The Legend of Zelda", "Zelda II", "Ocarina of Time", "Majora's Mask", and a demo of "The Wind Waker". GameSpot noted that "Majora's Mask" suffered from a frame rate which appeared choppier and inconsistencies in the audio. This compilation was never sold commercially, and originally could only be obtained by purchasing a GameCube bundled with the disc (in North America, Europe and Australia), by registering a GameCube and two games at Nintendo.com, or by subscribing or renewing a subscription to "Nintendo Power" (in North America) or Club Nintendo in Sweden. In the UK, 1000 copies were made available through the Club Nintendo Stars Catalogue program. After these were quickly claimed, Nintendo gave a copy to customers who mailed in proof of purchases from select GameCube games.

The next game released in the series was "" for the GameCube, which was released in early 2004 in Japan and America, and January 2005 in Europe. Based on the handheld "", "Four Swords Adventures" was another deviation from previous "Zelda" gameplay, focusing on level-based and multiplayer gameplay. The game contains 24 levels and a map screen; there is no connecting overworld. For multiplayer features, each player must use a Game Boy Advance system linked to the GameCube via a Nintendo GameCube – Game Boy Advance link cable. The game features a single-player campaign, in which using a Game Boy Advance is optional.

"Four Swords Adventures" includes two gameplay modes: "Hyrulean Adventure", with a plot and gameplay similar to other "Zelda" games, and "Shadow Battle", in which multiple Links, played by multiple players, battle each other. The Japanese and Korean versions include an exclusive third segment, "Navi Trackers" (originally designed as the stand-alone game "Tetra's Trackers"), which contains spoken dialogue for most of the characters, unlike other games in "The Legend of Zelda" series.

In November 2004 in Japan and Europe, and January 2005 in America, Nintendo released "" for the Game Boy Advance. In "The Minish Cap" Link can shrink in size using a mystical, sentient hat named Ezlo. While shrunk, he can see previously explored parts of a dungeon from a different perspective, and enter areas through otherwise-impassable openings.

In November 2006, "" was released as the first "Zelda" game on the Wii, and later, in December 2006, as the last official Nintendo game for the GameCube, the console for which it was originally developed. The Wii version features a reversed world where everything that is in the west on the GameCube is in the east on the Wii, and vice versa. The display is mirrored in order to make Link right-handed, to make use of the Wii remote feel more natural. The game chronicles the struggle of an older Link to clear the troubles of the interacting "Twilight Realm", a mysterious force that appears around Hyrule. When he enters this realm, he is transformed into a wolf, and loses the ability to use his sword, shield or other items, but gains other abilities such as sharpened senses from his new form. "Twilight Princess" includes an incarnation of Link's horse, Epona, for fast transportation, and features mounted battle scenarios including boss battles that were not seen in previous games. Twilight Princess diverted from the cel shading of Wind Waker and went for graphics featuring more detailed textures, giving the game a darker atmosphere, thus making it feel more adult than previous games.

At the 2006 Game Developers Conference, a trailer for "" for the Nintendo DS was shown. It revealed traditional top-down "Zelda" gameplay optimised for the DS' features, with a cel-shaded 3d graphical style similar to "The Wind Waker". At E3 2006, Nintendo confirmed the game's status as a direct sequel to "The Wind Waker", and released an extensive playable demo, including a multiplayer mode with "capture the flag" elements. "Phantom Hourglass" was released on June 23, 2007, in Japan, October 1, 2007, in North America and October 19, 2007, in Europe.

The next "Legend of Zelda" for the DS, "", was released December 7, 2009, in North America and December 11, 2009, in the UK. In this game, the 'spirit tracks', railroads which chain an ancient evil, are disappearing from Hyrule. Zelda and Link go to the 'Spirit Tower' (the ethereal point of convergence for the tracks) to find out why. But villains steal Zelda's body for the resurrection of the Demon King. Rendered disembodied, Zelda is left a spirit, and only Link (and a certain few sages) can see her. Together they go on a quest to restore the spirit tracks, defeat the Demon King, and return Zelda to her body. Using a modified engine of that used in "", the notably new feature in this game is that the Phantom Guardians seen in "Phantom Hourglass" are, through a series of events, periodically controllable. It was the first time in the series that both Link & Zelda work together on the quest.

In April 2008, Miyamoto stated that "the "Zelda" team is forming again to work on new games". Miyamoto clarified in July that the "Zelda" team had been working on a new "Zelda" game for the Wii. In January 2010, Nintendo Executive Satoru Iwata stated that the game would be coming out at some time in 2010, and confirmed that the game would make use of the Wii's MotionPlus feature, which had been announced too late to be integrated into the "Twilight Princess" Wii release. The game's subtitle was announced at E3 in 2010 as "", but its release was delayed to 2011. The game, the earliest in the "Legend of Zelda" timeline, reveals the origins of Hyrule, Ganon and many elements featured in previous games. It was released on November 20, 2011; the first run included a 25th Anniversary CD of fully orchestrated music from various Zelda games, including "Skyward Sword".

In addition, Nintendo celebrated the 25th anniversary of "The Legend of Zelda" game by releasing a "Zelda" game for all its current consoles in 2011: "Link's Awakening" in the 3DS's Virtual Console on June 7, "" for the 3DS in mid-June, "Four Swords Anniversary Edition" from September 28, 2011, to February 20, 2012, as a free DSiWare download and "Skyward Sword" for the Wii, which was released on November 18, 2011, in Europe; on November 20, 2011, in the United States; and on November 24, 2011, in Australia. A limited edition "Zelda" 25th anniversary 3DS was released on December 1, 2011, in Australia.

"", a remaster of the original GameCube game, was released by Nintendo on September 20, 2013, digitally on the Nintendo eShop in North America with a retail release on September 26 in Japan, October 4 in North America and Europe, and October 5 in Australia. A month later, Nintendo released "" for the Nintendo 3DS, which takes place in the same setting as "A Link to the Past".

Nintendo released a second 3DS version, "", in North America and Europe on February 13, 2015, and in Japan and Australia on February 14, 2015.

At E3 2015, Nintendo announced "", a cooperative multiplayer game released for the 3DS in October 2015. "", a high-definition remastering of "Twilight Princess", was released for the Wii U in March 2016.

Nintendo showcased a demo reel at E3 2011, which depicted Link fighting a monster in HD. In January 2013, Nintendo revealed that a new "Legend of Zelda" game was being planned for the Wii U. The game was officially teased at E3 2014, and was scheduled to be released in 2015. However, in March 2015, the game was delayed to 2016. In April 2016, the game was delayed again to 2017; it was also announced that it would be simultaneously released on the Wii U and Nintendo Switch. At E3 2016, the game was showcased under the title "". The game was released on March 3, 2017.

A series of video games was developed and released for the Philips CD-i in the early 1990s as a product of a compromise between Philips and Nintendo, after the companies failed to develop a CD-ROM peripheral for the Super NES. Created independently with no observation by or influence from Nintendo, the games are , together with "Zelda's Adventure". Nintendo never acknowledged them in the "Zelda" timeline, and they are considered to be in a separate, self-contained canon. These games are widely acknowledged to be the worst installments in the series.

Three "Zelda"-themed LCD games were created between 1989 and 1992. The "Zelda" version of Nintendo's Game & Watch series was released first in August 1989 as a dual-screen handheld electronic game similar in appearance to today's Nintendo DS. It was re-released in 1998 as a Toymax, Inc. Mini Classic and was later included as an unlockable extra in "Game & Watch Gallery 4", a 2002 compilation for the Game Boy Advance. While the Game & Watch "Zelda" was developed in-house by Nintendo, the subsequent two LCD games were developed by third parties under license by Nintendo. In October 1989, "The Legend of Zelda" was developed by Nelsonic as part of its Game Watch line. This game was an actual digital watch with primitive gameplay based on the original "Legend of Zelda". In 1992, Epoch Co. developed "" for its Barcode Battler II console. The game employed card-scanning technology similar to the later-released Nintendo e-Reader.

Throughout the lifespan of "The Legend of Zelda" series, a number of games (including main series games as well as re-releases and spin-offs) in varying states of completeness have had their releases cancelled. Perhaps the earliest of these was Gottlieb's "The Legend of Zelda Pinball Machine" (cancelled 1993). After securing a license from Nintendo to produce two Nintendo-franchise-based pinball machines, pinball designer Jon Norris was tasked with designing the table. Before it was completed, Gottlieb decided to repurpose the game with an "American Gladiators" theme. Licensing for this version ultimately fell through and the game was released as simply "Gladiators" (November 1993).

In 1998, Nintendo cancelled "The Legend of Zelda: Ocarina of Time Ura". Originally intended as an expansion disk for "" on the Nintendo 64DD, poor sales figures for the N64DD system led Nintendo to cancel its plans for the release. In 2002, Nintendo released a bonus disc called "". It contained emulated versions of "Ocarina of Time" and "Ocarina of Time Master Quest" with a number of modifications originally planned for release in "Ocarina of Time Ura" including GUI textures and text modified to reflect the GameCube.

In 2001, under license from Nintendo, Capcom cancelled the release of "The Legend of Zelda: Mystical Seed of Courage" for Game Boy Color. Working with a Capcom team, Yoshiki Okamoto was originally tasked with designing a series of three "Zelda" games for the Game Boy Color. Referred to as the "Triforce Series", the games were known as "The Legend of Zelda: The Mysterious Acorn: Chapter of Power", "Chapter of Wisdom", and "Chapter of Courage" in Japan and "The Legend of Zelda: Mystical Seed of Power", "Mystical Seed of Wisdom", and "Mystical Seed of Courage" in the US. The games were to interact using a password system, but the limitations of this system and the difficulty of coordinating three games proved too complicated, so the team scaled back to two games at Miyamoto's suggestion. "" was adapted from "Mystical Seed of Power", "" was adapted from "Mystical Seed of Wisdom", and "Mystical Seed of Courage" was canceled.

Before its 2006 release, both Link and Samus from the "Metroid" series were planned to be playable characters for the Wii version of "". However, they didn't make the final release because they weren't Marvel characters.

In 2011, an unnamed Zelda 25th Anniversary Compilation was cancelled. To celebrate the 25th anniversary of the series, Nintendo of America originally had planned to release a compilation of games together for the Wii, similar to the collector's edition disc released for the GameCube in 2003. However Nintendo of Japan's president Satoru Iwata and Shigeru Miyamoto disagreed in releasing it, believing it would be too similar to the Super Mario 25th Anniversary game released in 2010.

As the franchise has grown in popularity, several games have been released that are set within or star a minor character from the universe of "The Legend of Zelda" but are not directly connected to the main "The Legend of Zelda" series. Both map versions of the game "BS Zelda no Densetsu" for the Satellaview (released in August and December 1995) could be considered spin-offs due to the fact that they star the "Hero of Light" (portrayed by either the Satellaview's male or female avatar) as opposed to Link as the protagonist of Hyrule. A third Satellaview game released in March 1997, "BS Zelda no Densetsu Inishie no Sekiban" ("BS The Legend of Zelda: Ancient Stone Tablets") could also be considered a spin-off for the same reason. Other spin-off games include "Freshly-Picked Tingle's Rosy Rupeeland" for the Nintendo DS – an RPG released in September 2006 in Japan (Summer of 2007 in the UK) to star supporting character Tingle. A second Tingle game is "Tingle's Balloon Fight DS" for the Nintendo DS. Here Tingle again stars in this spin-off arcade style platformer, released in April 2007 only in Japan and available solely to Platinum Club Nintendo members. In addition to games in which Link does not star as the protagonist, games such as the shooter game, "Link's Crossbow Training" (for the Wii), have been considered spin-offs due to the lack of a traditional "Save Hyrule" plot-line. Released in November 2007 as a bundle with the Wii Zapper, this game allows players to assume the identity of Link as he progresses through a series of tests to perfect his crossbow marksmanship. "Color Changing Tingle's Love Balloon Trip" was released in Japan in 2009 as a sequel to Freshly-Picked Tingle's Rosy Rupeeland. "Hyrule Warriors", a crossover game combining the setting of Nintendo's "The Legend of Zelda" series and the gameplay of Tecmo Koei's "Dynasty Warriors" series, was announced for the Wii U video game system in December 2013 and was released in North America in September 2014. "Hyrule Warriors Legends", a version for the Nintendo 3DS containing more content and gameplay modifications, was released in March 2016. To commemorate the launch of the My Nintendo loyalty program in March 2016, Nintendo released "My Nintendo Picross: The Legend of Zelda: Twilight Princess", a Picross puzzle game developed by Jupiter for download to the Nintendo 3DS.

"The Legend of Zelda" series has crossed-over into a number of other Nintendo and third party video games. Most prominent of the collaborations would be in the "Super Smash Bros." series of fighting games published by Nintendo. Link appears as a fighter in "Super Smash Bros." for the Nintendo 64, the first entry in the series, and is part of the roster in all subsequent releases in the series as well. Zelda, (who is able to transform into Sheik as well), Ganondorf, and Young Link (the child version of Link from "Ocarina of Time") were added to the player roster for "Super Smash Bros. Melee", and appeared in all subsequent releases except for "Young Link", who is later replaced by "Toon Link" from "The Wind Waker", in subsequent releases "Super Smash Bros. Brawl" and "Super Smash Bros. for Nintendo 3DS and Wii U". Other elements from the series, such as locations and items, are also included throughout the "Smash Bros." series. Outside of the series, Nintendo allowed for the use of Link as a playable character exclusively in the GameCube release of Namco's fighting game "Soulcalibur II".


"The Legend of Zelda" series has received outstanding levels of acclaim from critics and the public. "", "", "", and "" have each received a perfect 40/40 score (10/10 by four reviewers) by Japanese "Famitsu" magazine, making "Zelda" one of the few series with multiple perfect scores. "Ocarina of Time" was even listed by "Guinness World Records" as the highest-rated video game in history, citing its Metacritic score of 99 out of 100. "Computer and Video Games" awarded "The Wind Waker" and "" a score of 10/10. "" has won Gold Award from "Electronic Gaming Monthly". In "Nintendo Power"s Top 200 countdown in 2004, "Ocarina of Time" took first place, and seven other "Zelda" games placed in the top 40. "Twilight Princess" was named Game of the Year by "X-Play", "GameTrailers", "1UP", "Electronic Gaming Monthly", "Spacey Awards", "Game Informer", "GameSpy", "Nintendo Power", "IGN", and many other websites. The editors of review aggregator websites GameRankings, IGN and Metacritic have all given "Ocarina of Time" their highest aggregate scores. "Game Informer" has awarded "The Wind Waker", "Twilight Princess", "Skyward Sword", "A Link Between Worlds" and "Breath of the Wild" with scores of 10/10. "" was named DS Game of the Year by IGN and "GameSpy". Airing December 10, 2011, Spike TV's annual Video Game Awards gave the series the first ever "Hall of Fame Award", which Miyamoto accepted in person. "" and its use of melodic themes to identify different game regions has been called a reverse of Richard Wagner's use of leitmotifs to identify characters and themes. "Ocarina of Time" was so well received that sales increased for real ocarinas. IGN praised the music of "Majora's Mask" for its brilliance despite its heavy use of MIDI. It has been ranked the seventh-greatest game by "Electronic Gaming Monthly", whereas "Ocarina of Time" was ranked eighth. The series won "GameFAQs Best Series Ever" competition.

, "The Legend of Zelda" franchise has sold over 80 million copies, with the original "The Legend of Zelda" being the fourth best-selling NES game of all time. The series was ranked as the 64th top game (collectively) by "Next Generation" in 1996. According to British film magazine "Empire", with "the most vividly-realised world and the most varied game-play of any game on any console, "Zelda" is a solid bet for the best game series ever."

Multiple members of the game industry have expressed how Zelda games have impacted them. Rockstar Games founder and "Grand Theft Auto" director, Dan Houser, stated, "Anyone who makes 3-D games who says they've not borrowed something from "Mario" or "Zelda" [on the Nintendo 64] is lying." Rockstar founder and "Grand Theft Auto" director Sam Houser also cited the influence of "Zelda", describing "Grand Theft Auto III" as "Zelda meets Goodfellas". "Ōkami" director Hideki Kamiya (Capcom, PlatinumGames) states that he has been influenced by "The Legend of Zelda" series in developing the game, citing "" as his favorite game of all time. "Soul Reaver" and "Uncharted" director, Amy Hennig (Crystal Dynamics, Naughty Dog), cited "Zelda" as inspiration for the "Legacy of Kain" series, noting "A Link to the Past"s influence on "Blood Omen" and "Ocarina of Time"'s influence on "Soul Reaver". "Soul Reaver" and "Uncharted" creator, Richard Lemarchand (Crystal Dynamics, Naughty Dog), cited "A Link to the Past"s approach to combining gameplay with storytelling as inspiration for "Soul Reaver". "Wing Commander" and "Star Citizen" director, Chris Roberts (Origin Systems, Cloud Imperium Games), cited "Zelda" as an influence on his action role-playing game, "Times of Lore".

"Souls" creator Hidetaka Miyazaki (FromSoftware) named "A Link To The Past" as one of his favorite role-playing video games. According to Miyazaki, ""The Legend of Zelda" became a sort of textbook for 3D action games." "Ico" director Fumito Ueda (Team Ico) cited "Zelda" as an influence on "Shadow of the Colossus". "Fable" series director Peter Molyneux (Lionhead Studios, Microsoft Studios) stated that "" is one of his favorite games. "I just feel it's jaw-dropping and its use of the hardware was brilliant. And I've played that game through several times," he said to TechRadar. "Darksiders" director David L. Adams (Vigil Games) cited "Zelda" as an influence on his work. "Prince of Persia" and "Assassin's Creed" director Raphael Lacoste (Ubisoft) cited "The Wind Waker" as an influence on "". CD Projekt Red ("The Witcher", "Cyberpunk 2077") cited the "Zelda" series as an influence on "The Witcher" series, including "". "Final Fantasy" and "The 3rd Birthday" director Hajime Tabata (Square Enix) cited "Ocarina of Time" as inspiration for the seamless open world of "Final Fantasy XV".

A 13-episode American animated TV series, adapted by DiC and distributed by Viacom Enterprises, aired in 1989. The animated "Zelda" shorts were broadcast each Friday, instead of the usual "Super Mario Bros." cartoon which was aired during the rest of the week. The series loosely follows the two NES "Zelda" games (the original "The Legend of Zelda" and "The Adventure of Link"), mixing settings and characters from those games with original creations. The show's older incarnations of both Link and Zelda appear in various episodes of "" during its second season.

Valiant Comics released a short series of comics featuring characters and settings from the "Zelda" cartoon as part of their "Nintendo Comics System" line. Manga adaptations of many entries in the series, including "A Link to the Past", "Ocarina of Time", "Majora's Mask", "Oracle of Seasons" and "Oracle of Ages", "Four Swords Adventures", "The Minish Cap", and "Phantom Hourglass", have been produced under license from Nintendo, mostly in Japan. These cartoons are usually not involved with the chronology of the actual games.

A number of official books, novels, and gamebooks have been released based on the series as well. The earliest was "Moblin's Magic Spear", published in 1989 by Western Publishing under their Golden Books Family Entertainment division and written by Jack C. Harris. It took place sometime during the first game. Two gamebooks were published as part of the "Nintendo Adventure Books" series by Archway, both of which were written by Matt Wayne. The first was "The Crystal Trap" (which focuses more on Zelda) and the second was "The Shadow Prince". Both were released in 1992. A novel based on "Ocarina of Time" was released in 1999, written by Jason R. Rich and published by Sybex Inc. under their "Pathways to Adventure" series. Another two gamebooks were released as part of the "You Decide on the Adventure" series published by Scholastic. The first book was based on "Oracle of Seasons" and was released in 2001. The second, based on "Oracle of Ages", was released in 2002. Both were written by Craig Wessel. In 2006, Scholastic released a novel as part of their "Nintendo Heroes" series, "Link and the Portal of Doom". It was written by Tracey West and was set shortly after the events of "Ocarina of Time".

In 2011, to coincide with the 25th anniversary of the series, an art book was published exclusively in Japan under the name "" by Shogakukan. It contains concept art from the series's conception to the release of "Skyward Sword" in 2011 and multiple essays about the production of the games, as well as an overarching timeline of the series. It also includes a prequel manga to "Skyward Sword" by Zelda manga duo Akira Himekawa. The book received an international release by publisher Dark Horse Comics on January 29, 2013; it took the number one spot on Amazon's sales chart, taking the spot away from E. L. James's "50 Shades of Grey" trilogy. Dark Horse released "The Legend of Zelda: Art & Artifacts", a follow-up art book to "Hyrule Historia" containing additional artwork and interviews, in North America on February 21, 2017, and in Europe on February 23, 2017.

Taking place in Cologne, Germany, on September 23, 2010, the video game music concert "Symphonic Legends" focused on music from Nintendo and, among others, featured games such as "The Legend of Zelda". Following an intermission, the second half of the concert was entirely dedicated to an expansive symphonic poem dedicated to the series. The 35-minute epic tells the story of Link's evolution from child to hero.

To celebrate the 25th anniversary of the series in 2011, Nintendo commissioned an original symphony, "". The show was originally performed in the fall of 2011 in Los Angeles and consists of live performances of much of the music from the series. It has since been scheduled for 18 shows so far throughout the United States and Canada. Nintendo released a CD, "The Legend of Zelda 25th Anniversary Special Orchestra CD". Featuring eight tracks from live performances of the symphony, the CD is included alongside the special edition of "The Legend of Zelda: Skyward Sword" for the Wii. Nintendo would later celebrate "The Legend of Zelda" 30th anniversary with an album which was released in Japan in February 2017.

In 2007, Imagi Animation Studios, who provided the animation for "TMNT" and "Astro Boy", created a pitch reel for a computer-animated "The" "Legend of Zelda" movie. Nintendo did not take the studio up on their offer due to the failure of the live-action movie adaption of "Super Mario Bros."

In 2013, Aonuma stated that, if development of a film were to move forward, the company would want to use the opportunity to embrace audience interaction in some capacity.

"The Legend of Zelda"-themed "Monopoly" board game was released in the United States on September 15, 2014. A "Clue" board game in the style of "The Legend of Zelda" series was released in June 2017. A "UNO"-styled "The Legend of Zelda" game was announced in February 2018 for release exclusively at GameStop in North America.

Works cited


</doc>
<doc id="30036" url="https://en.wikipedia.org/wiki?curid=30036" title="Tor Nørretranders">
Tor Nørretranders

Tor Nørretranders (born June 20, 1955) is a Danish author of popular science. He was born in Copenhagen, Denmark. His books and lectures have primarily been focused on light popular science and its role in society, often with Nørretranders' own advice about how society should integrate new findings in popular science. He introduced the notion of exformation in his book The User Illusion.

Tor Nørretranders' mother is Yvonne Levy (1920-) and his father was Bjarne Nørretranders (1922-1986). Tor Nørretranders graduated at "Det frie gymnasium" in 1973 and reached a cand.techn.soc-degree from Roskilde University (Roskilde) in 1982, specialized in environment planning and its scientific theoretic basis. He lives north of Copenhagen with his wife Rikke Ulk and three children.





 

</doc>
<doc id="30038" url="https://en.wikipedia.org/wiki?curid=30038" title="Thomas Henry Huxley">
Thomas Henry Huxley

Thomas Henry Huxley (4 May 1825 – 29 June 1895) was an English biologist specialising in comparative anatomy. He is known as "Darwin's Bulldog" for his advocacy of Charles Darwin's theory of evolution.

Huxley's famous debate in 1860 with Samuel Wilberforce was a key moment in the wider acceptance of evolution and in his own career. Huxley had been planning to leave Oxford on the previous day, but, after an encounter with Robert Chambers, the author of "Vestiges", he changed his mind and decided to join the debate. Wilberforce was coached by Richard Owen, against whom Huxley also debated about whether humans were closely related to apes.

Huxley was slow to accept some of Darwin's ideas, such as gradualism, and was undecided about natural selection, but despite this he was wholehearted in his public support of Darwin. Instrumental in developing scientific education in Britain, he fought against the more extreme versions of religious tradition.

Originally coining the term in 1869, Huxley elaborated on "agnosticism" in 1889 to frame the nature of claims in terms of what is knowable and what is not. Huxley statesAgnosticism, in fact, is not a creed, but a method, the essence of which lies in the rigorous application of a single principle... the fundamental axiom of modern science... In matters of the intellect, follow your reason as far as it will take you, without regard to any other consideration... In matters of the intellect, do not pretend that conclusions are certain which are not demonstrated or demonstrable. Use of that term has continued to the present day (see Thomas Henry Huxley and agnosticism).. Much of Huxley's agnosticism is influenced by Kantian views on human perception and the ability to rely on rational evidence rather than belief systems.

Huxley had little formal schooling and was virtually self-taught. He became perhaps the finest comparative anatomist of the later 19th century. He worked on invertebrates, clarifying relationships between groups previously little understood. Later, he worked on vertebrates, especially on the relationship between apes and humans. After comparing "Archaeopteryx" with "Compsognathus", he concluded that birds evolved from small carnivorous dinosaurs, a theory widely accepted today.

The tendency has been for this fine anatomical work to be overshadowed by his energetic and controversial activity in favour of evolution, and by his extensive public work on scientific education, both of which had significant effects on society in Britain and elsewhere.

Thomas Henry Huxley was born in Ealing, which was then a village in Middlesex. He was the second youngest of eight children of George Huxley and Rachel Withers. Like some other British scientists of the nineteenth century such as Alfred Russel Wallace, Huxley was brought up in a literate middle-class family which had fallen on hard times. His father was a mathematics teacher at Ealing School until it closed, putting the family into financial difficulties. As a result, Thomas left school at age 10, after only two years of formal schooling. Huxley’s parents were Anglicans, although it was against organized religion Huxley sympathized with the town’s Nonconformist.

Despite this unenviable start, Huxley was determined to educate himself. He became one of the great autodidacts of the nineteenth century. At first he read Thomas Carlyle, James Hutton's "Geology", and Hamilton's "Logic". In his teens he taught himself German, eventually becoming fluent and used by Charles Darwin as a translator of scientific material in German. He learned Latin, and enough Greek to read Aristotle in the original.

Later on, as a young adult, he made himself an expert, first on invertebrates, and later on vertebrates, all self-taught. He was skilled in drawing and did many of the illustrations for his publications on marine invertebrates. In his later debates and writing on science and religion his grasp of theology was better than most of his clerical opponents. Huxley, a boy who left school at ten, became one of the most knowledgeable men in Britain.

He was apprenticed for short periods to several medical practitioners: at 13 to his brother-in-law John Cooke in Coventry, who passed him on to Thomas Chandler, notable for his experiments using mesmerism for medical purposes. Chandler's practice was in London's Rotherhithe amidst the squalor endured by the Dickensian poor. Here Thomas would have seen poverty, crime and rampant disease at its worst. Next, another brother-in-law took him on: John Salt, his eldest sister's husband. Now 16, Huxley entered Sydenham College (behind University College Hospital), a cut-price anatomy school whose founder, Marshall Hall, discovered the reflex arc. All this time Huxley continued his programme of reading, which more than made up for his lack of formal schooling.

A year later, buoyed by excellent results and a silver medal prize in the Apothecaries' yearly competition, Huxley was admitted to study at Charing Cross Hospital, where he obtained a small scholarship. At Charing Cross, he was taught by Thomas Wharton Jones, Professor of Ophthalmic Medicine and Surgery at University College London. Jones had been Robert Knox's assistant when Knox bought cadavers from Burke and Hare. The young Wharton Jones, who acted as go-between, was exonerated of crime, but thought it best to leave Scotland. He was a fine teacher, up-to-date in physiology and also an ophthalmic surgeon. In 1845, under Wharton Jones' guidance, Huxley published his first scientific paper demonstrating the existence of a hitherto unrecognised layer in the inner sheath of hairs, a layer that has been known since as Huxley's layer. No doubt remembering this, and of course knowing his merit, later in life Huxley organised a pension for his old tutor.

At twenty he passed his First M.B. examination at the University of London, winning the gold medal for anatomy and physiology. However, he did not present himself for the final (Second M.B.) exams and consequently did not qualify with a university degree. His apprenticeships and exam results formed a sufficient basis for his application to the Royal Navy.

Aged 20, Huxley was too young to apply to the Royal College of Surgeons for a licence to practise, yet he was 'deep in debt'. So, at a friend's suggestion, he applied for an appointment in the Royal Navy. He had references on character and certificates showing the time spent on his apprenticeship and on requirements such as dissection and pharmacy. Sir William Burnett, the Physician General of the Navy, interviewed him and arranged for the College of Surgeons to test his competence (by means of a "viva voce").

Finally Huxley was made Assistant Surgeon ('surgeon's mate') to HMS "Rattlesnake", about to start for a voyage of discovery and surveying to New Guinea and Australia. The "Rattlesnake" left England on 3 December 1846 and, once they had arrived in the southern hemisphere, Huxley devoted his time to the study of marine invertebrates. He began to send details of his discoveries back to England, where publication was arranged by Edward Forbes FRS (who had also been a pupil of Knox). Both before and after the voyage Forbes was something of a mentor to Huxley.

Huxley's paper "On the anatomy and the affinities of the family of Medusae" was published in 1849 by the Royal Society in its "Philosophical Transactions". Huxley united the Hydroid and Sertularian polyps with the Medusae to form a class to which he subsequently gave the name of "Hydrozoa". The connection he made was that all the members of the class consisted of two cell layers, enclosing a central cavity or stomach. This is characteristic of the phylum now called the "Cnidaria". He compared this feature to the serous and mucous structures of embryos of higher animals. When at last he got a grant from the Royal Society for the printing of plates, Huxley was able to summarise this work in "The Oceanic Hydrozoa", published by the Ray Society in 1859.

The value of Huxley's work was recognised and, on returning to England in 1850, he was elected a Fellow of the Royal Society. In the following year, at the age of twenty-six, he not only received the Royal Society Medal but was also elected to the Council. He met Joseph Dalton Hooker and John Tyndall, who remained his lifelong friends. The Admiralty retained him as a nominal assistant-surgeon, so he might work on the specimens he collected and the observations he made during the voyage of the "Rattlesnake". He solved the problem of "Appendicularia", whose place in the animal kingdom Johannes Peter Müller had found himself wholly unable to assign. It and the Ascidians are both, as Huxley showed, tunicates, today regarded as a sister group to the vertebrates in the phylum "Chordata". Other papers on the morphology of the cephalopods and on brachiopods and rotifers are also noteworthy. The "Rattlesnake"'s official naturalist, John MacGillivray, did some work on botany, and proved surprisingly good at notating Australian aboriginal languages. He wrote up the voyage in the standard Victorian two volume format.

Huxley effectively resigned from the navy (by refusing to return to active service) and, in July 1854, he became Professor of Natural History at the Royal School of Mines and naturalist to the British Geological Survey in the following year. In addition, he was Fullerian Professor at the Royal Institution 1855–58 and 1865–67; Hunterian Professor at the Royal College of Surgeons 1863–69; President of the British Association for the Advancement of Science 1869–1870; President of the Quekett Microscopical Club 1878; President of the Royal Society 1883–85; Inspector of Fisheries 1881–85; and President of the Marine Biological Association 1884–1890.

The thirty-one years during which Huxley occupied the chair of natural history at the Royal School of Mines included work on vertebrate palaeontology and on many projects to advance the place of science in British life. Huxley retired in 1885, after a bout of depressive illness which started in 1884. He resigned the presidency of the Royal Society in mid-term, the Inspectorship of Fisheries, and his chair (as soon as he decently could) and took six months' leave. His pension was a fairly handsome £1200 a year.

In 1890, he moved from London to Eastbourne where he edited the nine volumes of his "Collected Essays". In 1894 he heard of Eugene Dubois' discovery in Java of the remains of "Pithecanthropus erectus" (now known as "Homo erectus"). Finally, in 1895, he died of a heart attack (after contracting influenza and pneumonia), and was buried in North London at St Marylebone. This small family plot had been purchased upon the death of his beloved youngest son Noel, who died of scarlet fever in 1860; Huxley's wife Henrietta Anne née Heathorn and son Noel are also buried there. No invitations were sent out, but two hundred people turned up for the ceremony; they included Joseph Dalton Hooker, William Henry Flower, Mulford B. Foster, Edwin Lankester, Joseph Lister and, apparently, Henry James.

Huxley and his wife had five daughters and three sons:

Noel Huxley (1856–1860), died aged 4.
Jessie Oriana Huxley (1856–1927), married architect Fred Waller in 1877.
Marian Huxley (1859–1887), married artist John Collier in 1879.
Leonard Huxley (1860–1933), married Julia Arnold.
Rachel Huxley (1862–1934), married civil engineer Alfred Eckersley in 1884.
Henrietta (Nettie) Huxley (1863–1940), married Harold Roller, travelled Europe as a singer.
Henry Huxley (1865–1946), became a fashionable general practitioner in London.
Ethel Huxley (1866–1941) married artist John Collier (widower of sister) in 1889.

From 1870 onwards, Huxley was to some extent drawn away from scientific research by the claims of public duty. He served on eight Royal Commissions, from 1862 to 1884. From 1871 to 1880 he was a Secretary of the Royal Society and from 1883 to 1885 he was president. He was president of the Geological Society from 1868 to 1870. In 1870, he was president of the British Association at Liverpool and, in the same year was elected a member of the newly constituted London School Board. He was president of the Quekett Microscopical Club from 1877 to 1879. He was the leading person amongst those who reformed the Royal Society, persuaded government about science, and established scientific education in British schools and universities. Before him, science was mostly a gentleman's occupation; after him, science was a profession.

He was awarded the highest honours then open to British men of science. The Royal Society, who had elected him as Fellow when he was 25 (1851), awarded him the Royal Medal the next year (1852), a year before Charles Darwin got the same award. He was the youngest biologist to receive such recognition. Then later in life came the Copley Medal in 1888 and the Darwin Medal in 1894; the Geological Society awarded him the Wollaston Medal in 1876; the Linnean Society awarded him the Linnean Medal in 1890. There were many other elections and appointments to eminent scientific bodies; these and his many academic awards are listed in the "Life and Letters". He turned down many other appointments, notably the Linacre chair in zoology at Oxford and the Mastership of University College, Oxford.

In 1873 the King of Sweden made Huxley, Hooker and Tyndall Knights of the Order of the Polar Star: they could wear the insignia but not use the title in Britain. Huxley collected many honorary memberships of foreign societies, academic awards and honorary doctorates from Britain and Germany. He also became foreign member of the Royal Netherlands Academy of Arts and Sciences in 1892.

As recognition of his many public services he was given a pension by the state, and was appointed Privy Councillor in 1892.

Despite his many achievements he was given no award by the British state until late in life. In this he did better than Darwin, who got no award of any kind from the state. (Darwin's proposed knighthood was vetoed by ecclesiastical advisers, including Wilberforce) Perhaps Huxley had commented too often on his dislike of honours, or perhaps his many assaults on the traditional beliefs of organised religion made enemies in the establishment—he had vigorous debates in print with Benjamin Disraeli, William Ewart Gladstone and Arthur Balfour, and his relationship with Lord Salisbury was less than tranquil.

Huxley was for about thirty years evolution's most effective advocate, and for some Huxley was ""the" premier advocate of science in the nineteenth century [for] the whole English-speaking world".

Though he had many admirers and disciples, his retirement and later death left British zoology somewhat bereft of leadership. He had, directly or indirectly, guided the careers and appointments of the next generation, but none were of his stature. The loss of Francis Balfour in 1882, climbing the Alps just after he was appointed to a chair at Cambridge, was a tragedy. Huxley thought he was "the only man who can carry out my work": the deaths of Balfour and W. K. Clifford were "the greatest losses to science in our time".

The first half of Huxley's career as a palaeontologist is marked by a rather strange predilection for 'persistent types', in which he seemed to argue that evolutionary advancement (in the sense of major new groups of animals and plants) was rare or absent in the Phanerozoic. In the same vein, he tended to push the origin of major groups such as birds and mammals back into the Palaeozoic era, and to claim that no order of plants had ever gone extinct.

Much paper has been consumed by historians of science ruminating on this strange and somewhat unclear idea. Huxley was wrong to pitch the loss of orders in the Phanerozoic as low as 7%, and he did not estimate the number of new orders which evolved. Persistent types sat rather uncomfortably next to Darwin's more fluid ideas; despite his intelligence, it took Huxley a surprisingly long time to appreciate some of the implications of evolution. However, gradually Huxley moved away from this conservative style of thinking as his understanding of palaeontology, and the discipline itself, developed.

Huxley's detailed anatomical work was, as always, first-rate and productive. His work on fossil fish shows his distinctive approach: whereas pre-Darwinian naturalists collected, identified and classified, Huxley worked mainly to reveal the evolutionary relationships between groups.

The lobed-finned fish (such as coelacanths and lung fish) have paired appendages whose internal skeleton is attached to the shoulder or pelvis by a single bone, the humerus or femur. His interest in these fish brought him close to the origin of tetrapods, one of the most important areas of vertebrate palaeontology.

The study of fossil reptiles led to his demonstrating the fundamental affinity of birds and reptiles, which he united under the title of "Sauropsida". His papers on "Archaeopteryx" and the origin of birds were of great interest then and still are.

Apart from his interest in persuading the world that man was a primate, and had descended from the same stock as the apes, Huxley did little work on mammals, with one exception. On his tour of America Huxley was shown the remarkable series of fossil horses, discovered by O. C. Marsh, in Yale's Peabody Museum. Marsh was part palaeontologist, part robber baron, a man who had hunted buffalo and met Red Cloud (in 1874). Funded by his uncle George Peabody, Marsh had made some remarkable discoveries:
the huge Cretaceous aquatic bird "Hesperornis", and the dinosaur footprints along the Connecticut River were worth the trip by themselves, but the horse fossils were really special.

The collection at that time went from the small four-toed forest-dwelling "Orohippus" from the Eocene through three-toed species such as "Miohippus" to species more like the modern horse. By looking at their teeth he could see that, as the size grew larger and the toes reduced, the teeth changed from those of a browser to those of a grazer. All such changes could be explained by a general alteration in habitat from forest to grassland. And, it is now known, that is what did happen over large areas of North America from the Eocene to the Pleistocene: the ultimate causative agent was global temperature reduction (see Paleocene–Eocene Thermal Maximum). The modern account of the evolution of the horse has many other members, and the overall appearance of the tree of descent is more like a bush than a straight line.

The horse series also strongly suggested that the process was gradual, and that the origin of the modern horse lay in North America, not in Eurasia. If so, then something must have happened to horses in North America, since none were there when Europeans arrived. The experience was enough for Huxley to give credence to Darwin's gradualism, and to introduce the story of the horse into his lecture series.

Huxley was originally not persuaded of "development theory", as evolution was once called. This can be seen in his savage review of Robert Chambers' "Vestiges of the Natural History of Creation", a book which contained some quite pertinent arguments in favour of evolution. Huxley had also rejected Lamarck's theory of transmutation, on the basis that there was insufficient evidence to support it. All this scepticism was brought together in a lecture to the Royal Institution, which made Darwin anxious enough to set about an effort to change young Huxley's mind. It was the kind of thing Darwin did with his closest scientific friends, but he must have had some particular intuition about Huxley, who was from all accounts a most impressive person even as a young man.

Huxley was therefore one of the small group who knew about Darwin's ideas before they were published (the group included Joseph Dalton Hooker and Charles Lyell). The first publication by Darwin of his ideas came when Wallace sent Darwin his famous paper on natural selection, which was presented by Lyell and Hooker to the Linnean Society in 1858 alongside excerpts from Darwin's notebook and a Darwin letter to Asa Gray. Huxley's famous response to the idea of natural selection was "How extremely stupid not to have thought of that!" However, he never conclusively made up his mind about whether natural selection was the main method for evolution, though he did admit it was a hypothesis which was a good working basis.

Logically speaking, the prior question was whether evolution had taken place at all. It is to this question that much of Darwin's "On the Origin of Species" was devoted. Its publication in 1859 completely convinced Huxley of evolution and it was this and no doubt his admiration of Darwin's way of amassing and using evidence that formed the basis of his support for Darwin in the debates that followed the book's publication.

Huxley's support started with his anonymous favourable review of the "Origin" in the "Times" for 26 December 1859, and continued with articles in several periodicals, and in a lecture at the Royal Institution in February 1860. At the same time, Richard Owen, whilst writing an extremely hostile anonymous review of the "Origin" in the "Edinburgh Review", also primed Samuel Wilberforce who wrote one in the "Quarterly Review", running to 17,000 words. The authorship of this latter review was not known for sure until Wilberforce's son wrote his biography. So it can be said that, just as Darwin groomed Huxley, so Owen groomed Wilberforce; and both the proxies fought public battles on behalf of their principals as much as themselves. Though we do not know the exact words of the Oxford debate, we do know what Huxley thought of the review in the "Quarterly":

Since Lord Brougham assailed Dr Young, the world has seen no such specimen of the insolence of a shallow pretender to a Master in Science as this remarkable production, in which one of the most exact of observers, most cautious of reasoners, and most candid of expositors, of this or any other age, is held up to scorn as a "flighty" person, who endeavours "to prop up his utterly rotten fabric of guess and speculation," and whose "mode of dealing with nature" is reprobated as "utterly dishonourable to Natural Science."

If I confine my retrospect of the reception of the "Origin of Species" to a twelvemonth, or thereabouts, from the time of its publication, I do not recollect anything quite so foolish and unmannerly as the "Quarterly Review" article...

Huxley said "I am Darwin's bulldog". While the second half of Darwin's life was lived mainly within his family, the younger combative Huxley operated mainly out in the world at large. A letter from Huxley to Ernst Haeckel (2 November 1871) states: "The dogs have been snapping at [Darwin's] heels too much of late." At Oxford and Cambridge Universities, "Bulldog" was and still is student slang for a university policeman, whose job was to corral errant students and maintain their moral rectitude.

Famously, Huxley responded to Wilberforce in the debate at the British Association meeting, on Saturday 30 June 1860 at the Oxford University Museum. Huxley's presence there had been encouraged on the previous evening when he met Robert Chambers, the Scottish publisher and author of "Vestiges", who was walking the streets of Oxford in a dispirited state, and begged for assistance. The debate followed the presentation of a paper by John William Draper, and was chaired by Darwins's former botany tutor John Stevens Henslow. Darwin's theory was opposed by the Lord Bishop of Oxford, Samuel Wilberforce, and those supporting Darwin included Huxley and their mutual friends Hooker and Lubbock. The platform featured Brodie and Professor Beale, and Robert FitzRoy, who had been captain of HMS "Beagle" during Darwin's voyage, spoke against Darwin.

Wilberforce had a track record against evolution as far back as the previous Oxford B.A. meeting in 1847 when he attacked Chambers' "Vestiges". For the more challenging task of opposing the "Origin", and the implication that man descended from apes, he had been assiduously coached by Richard Owen – Owen stayed with him the night before the debate. On the day Wilberforce repeated some of the arguments from his "Quarterly Review" article (written but not yet published), then ventured onto slippery ground. His famous jibe at Huxley (as to whether Huxley was descended from an ape on his mother's side or his father's side) was probably unplanned, and certainly unwise. Huxley's reply to the effect that he would rather be descended from an ape than a man who misused his great talents to suppress debate—the exact wording is not certain—was widely recounted in pamphlets and a spoof play.

The letters of Alfred Newton include one to his brother giving an eye-witness account of the debate, and written less than a month afterwards. Other eyewitnesses, with one or two exceptions (Hooker especially thought "he" had made the best points), give similar accounts, at varying dates after the event. The general view was and still is that Huxley got much the better of the exchange though Wilberforce himself thought he had done quite well. In the absence of a verbatim report differing perceptions are difficult to judge fairly; Huxley wrote a detailed account for Darwin, a letter which does not survive; however, a letter to his friend Frederick Daniel Dyster does survive with an account just three months after the event.

One effect of the debate was to increase hugely Huxley's visibility amongst educated people, through the accounts in newspapers and periodicals. Another consequence was to alert him to the importance of public debate: a lesson he never forgot. A third effect was to serve notice that Darwinian ideas could not be easily dismissed: on the contrary, they would be vigorously defended against orthodox authority. A fourth effect was to promote professionalism in science, with its implied need for scientific education. A fifth consequence was indirect: as Wilberforce had feared, a defence of evolution did undermine literal belief in the Old Testament, especially the Book of Genesis. Many of the liberal clergy at the meeting were quite pleased with the outcome of the debate; they were supporters, perhaps, of the controversial "Essays and Reviews". Thus both on the side of science, and on the side of religion, the debate was important, and its outcome significant. (see also below)

That Huxley and Wilberforce remained on courteous terms after the debate (and able to work together on projects such as the Metropolitan Board of Education) says something about both men, whereas Huxley and Owen were never reconciled.

For nearly a decade his work was directed mainly to the relationship of man to the apes. This led him directly into a clash with Richard Owen, a man widely disliked for his behaviour whilst also being admired for his capability. The struggle was to culminate in some severe defeats for Owen. Huxley's Croonian Lecture, delivered before the Royal Society in 1858 on "The Theory of the Vertebrate Skull" was the start. In this, he rejected Owen's theory that the bones of the skull and the spine were homologous, an opinion previously held by Goethe and Lorenz Oken.

From 1860–63 Huxley developed his ideas, presenting them in lectures to working men, students and the general public, followed by publication. Also in 1862 a series of talks to working men was printed lecture by lecture as pamphlets, later bound up as a little green book; the first copies went on sale in December. Other lectures grew into Huxley's most famous work "Evidence as to Man's place in Nature" (1863) where he addressed the key issues long before Charles Darwin published his "Descent of Man" in 1871.

Although Darwin did not publish his "Descent of Man" until 1871, the general debate on this topic had started years before (there was even a precursor debate in the 18th century between Monboddo and Buffon). Darwin had dropped a hint when, in the conclusion to the "Origin", he wrote: "In the distant future... light will be thrown on the origin of man and his history". Not so distant, as it turned out. A key event had already occurred in 1857 when Richard Owen presented (to the Linnean Society) his theory that man was marked off from all other mammals by possessing features of the brain peculiar to the genus "Homo". Having reached this opinion, Owen separated man from all other mammals in a subclass of its own. No other biologist held such an extreme view. Darwin reacted "Man...as distinct from a chimpanzee [as] an ape from a platypus... I cannot swallow that!" Neither could Huxley, who was able to demonstrate that Owen's idea was completely wrong.
The subject was raised at the 1860 BA Oxford meeting, when Huxley flatly contradicted Owen, and promised a later demonstration of the facts. In fact, a number of demonstrations were held in London and the provinces. In 1862 at the Cambridge meeting of the B.A. Huxley's friend William Flower gave a public dissection to show that the same structures (the posterior horn of the lateral ventricle and hippocampus minor) were indeed present in apes. The debate was widely publicised, and parodied as the "Great Hippocampus Question". It was seen as one of Owen's greatest blunders, revealing Huxley as not only dangerous in debate, but also a better anatomist.

Owen conceded that there was something that could be called a hippocampus minor in the apes, but stated that it was much less developed and that such a presence did not detract from the overall distinction of simple brain size.

Huxley's ideas on this topic were summed up in January 1861 in the first issue (new series) of his own journal, the "Natural History Review": "the most violent scientific paper he had ever composed". This paper was reprinted in 1863 as chapter 2 of "Man's Place in Nature", with an addendum giving his account of the Owen/Huxley controversy about the ape brain. In his "Collected Essays" this addendum was removed.

The extended argument on the ape brain, partly in debate and partly in print, backed by dissections and demonstrations, was a landmark in Huxley's career. It was highly important in asserting his dominance of comparative anatomy, and in the long run more influential in establishing evolution amongst biologists than was the debate with Wilberforce. It also marked the start of Owen's decline in the esteem of his fellow biologists.

The following was written by Huxley to Rolleston before the BA meeting in 1861:

During those years there was also work on human fossil anatomy and anthropology. In 1862 he examined the Neanderthal skull-cap, which had been discovered in 1857. It was the first pre-"sapiens" discovery of a fossil man, and it was immediately clear to him that the brain case was surprisingly large.

Perhaps less productive was his work on physical anthropology, a topic which fascinated the Victorians. Huxley classified the human races into nine categories, and discussed them under four headings as: Australoid, Negroid, Xanthocroic and Mongoloid types. Such classifications depended mainly on appearance and anatomical characteristics.
Huxley was certainly not slavish in his dealings with Darwin. As shown in every biography, they had quite different and rather complementary characters. Important also, Darwin was a field naturalist, but Huxley was an anatomist, so there was a difference in their experience of nature. Lastly, Darwin's views on science were different from Huxley's views. For Darwin, natural selection was the best way to explain evolution because it explained a huge range of natural history facts and observations: it solved problems. Huxley, on the other hand, was an empiricist who trusted what he could see, and some things are not easily seen. With this in mind, one can appreciate the debate between them, Darwin writing his letters, Huxley never going quite so far as to say he thought Darwin was right.

Huxley's reservations on natural selection were of the type "until selection and breeding can be seen to give rise to varieties which are infertile with each other, natural selection cannot be proved". Huxley's position on selection was agnostic; yet he gave no credence to any other theory. Despite this concern about evidence, Huxley saw that if evolution came about through variation, reproduction and selection then other things would also be subject to the same pressures. This included ideas because they are invented, imitated and selected by humans: ‘The struggle for existence holds as much in the intellectual as in the physical world. A theory is a species of thinking, and its right to exist is coextensive with its power of resisting extinction by its rivals.’ This is the same idea as meme theory put forward by Richard Dawkins in 1976.

Darwin's part in the discussion came mostly in letters, as was his wont, along the lines: "The empirical evidence you call for is both impossible in practical terms, and in any event unnecessary. It's the same as asking to see every step in the transformation (or the splitting) of one species into another. My way so many issues are clarified and problems solved; no other theory does nearly so well".

Huxley's reservation, as Helena Cronin has so aptly remarked, was contagious: "it spread itself for years among all kinds of doubters of Darwinism". One reason for this doubt was that comparative anatomy could address the question of descent, "but not the question of mechanism".

Huxley was a pallbearer at the funeral of Charles Darwin on 26 April 1882.

In November 1864, Huxley succeeded in launching a dining club, the X Club, composed of like-minded people working to advance the cause of science; not surprisingly, the club consisted of most of his closest friends. There were nine members, who decided at their first meeting that there should be no more. The members were: Huxley, John Tyndall, J. D. Hooker, John Lubbock (banker, biologist and neighbour of Darwin), Herbert Spencer (social philosopher and sub-editor of the Economist), William Spottiswoode (mathematician and the Queen's Printer), Thomas Hirst (Professor of Physics at University College London), Edward Frankland (the new Professor of Chemistry at the Royal Institution) and George Busk, zoologist and palaeontologist (formerly surgeon for HMS "Dreadnought"). All except Spencer were Fellows of the Royal Society. Tyndall was a particularly close friend; for many years they met regularly and discussed issues of the day. On more than one occasion Huxley joined Tyndall in the latter's trips into the Alps and helped with his investigations in glaciology.

There were also some quite significant X-Club satellites such as William Flower and George Rolleston, (Huxley protegés), and liberal clergyman Arthur Stanley, the Dean of Westminster. Guests such as Charles Darwin and Hermann von Helmholtz were entertained from time to time.

They would dine early on first Thursdays at a hotel, planning what to do; high on the agenda was to change the way the Royal Society Council did business. It was no coincidence that the Council met later that same evening. First item for the Xs was to get the Copley Medal for Darwin, which they managed after quite a struggle.

The next step was to acquire a journal to spread their ideas. This was the weekly "Reader", which they bought, revamped and redirected. Huxley had already become part-owner of the "Natural History Review" bolstered by the support of Lubbock, Rolleston, Busk and Carpenter (X-clubbers and satellites). The journal was switched to pro-Darwinian lines and relaunched in January 1861. After a stream of good articles the "NHR" failed after four years; but it had helped at a critical time for the establishment of evolution. The "Reader" also failed, despite its broader appeal which included art and literature as well as science. The periodical market was quite crowded at the time, but most probably the critical factor was Huxley's time; he was simply over-committed, and could not afford to hire full-time editors. This occurred often in his life: Huxley took on too many ventures, and was not so astute as Darwin at getting others to do work for him.

However, the experience gained with the "Reader" was put to good use when the X Club put their weight behind the founding of "Nature" in 1869. This time no mistakes were made: above all there was a permanent editor (though not full-time), Norman Lockyer, who served until 1919, a year before his death. In 1925, to celebrate his centenary, "Nature" issued a supplement devoted to Huxley.

The peak of the X Club's influence was from 1873 to 1885 as Hooker, Spottiswoode and Huxley were Presidents of the Royal Society in succession. Spencer resigned in 1889 after a dispute with Huxley over state support for science. After 1892 it was just an excuse for the surviving members to meet. Hooker died in 1911, and Lubbock (now Lord Avebury) was the last surviving member.

Huxley was also an active member of the Metaphysical Society, which ran from 1869 to 1880. It was formed around a nucleus of clergy and expanded to include all kinds of opinions. Tyndall and Huxley later joined The Club (founded by Dr. Johnson) when they could be sure that Owen would not turn up.

When Huxley himself was young there were virtually no degrees in British universities in the biological sciences and few courses. Most biologists of his day were either self-taught, or took medical degrees. When he retired there were established chairs in biological disciplines in most universities, and a broad consensus on the curricula to be followed. Huxley was the single most influential person in this transformation.

In the early 1870s the Royal School of Mines moved to new quarters in South Kensington; ultimately it would become one of the constituent parts of Imperial College London. The move gave Huxley the chance to give more prominence to laboratory work in biology teaching, an idea suggested by practice in German universities. In the main, the method was based on the use of carefully chosen types, and depended on the dissection of anatomy, supplemented by microscopy, museum specimens and some elementary physiology at the hands of Foster.

The typical day would start with Huxley lecturing at 9am, followed by a program of laboratory work supervised by his demonstrators. Huxley's demonstrators were picked men—all became leaders of biology in Britain in later life, spreading Huxley's ideas as well as their own. Michael Foster became Professor of Physiology at Cambridge; E. Ray Lankester became Jodrell Professor of Zoology at University College London (1875–91), Professor of Comparative Anatomy at Oxford (1891–98) and Director of the Natural History Museum (1898–1907); S.H. Vines became Professor of Botany at Cambridge; W.T. Thiselton-Dyer became Hooker's successor at Kew (he was already Hooker's son-in-law!); T. Jeffery Parker became Professor of Zoology and Comparative Anatomy at University College, Cardiff; and William Rutherford became the Professor of Physiology at Edinburgh. William Flower, Conservator to the Hunterian Museum, and THH's assistant in many dissections, became Sir William Flower, Hunterian Professor of Comparative Anatomy and, later, Director of the Natural History Museum. It's a remarkable list of disciples, especially when contrasted with Owen who, in a longer professional life than Huxley, left no disciples at all. "No one fact tells so strongly against Owen... as that he has never reared one pupil or follower".

Huxley's courses for students were so much narrower than the man himself that many were bewildered by the contrast: "The teaching of zoology by use of selected animal types has come in for much criticism"; Looking back in 1914 to his time as a student, Sir Arthur Shipley said "Darwin's later works all dealt with living organisms, yet our obsession was with the dead, with bodies preserved, and cut into the most refined slices". E.W MacBride said "Huxley... would persist in looking at animals as material structures and not as living, active beings; in a word... he was a necrologist. To put it simply, Huxley preferred to teach what he had actually seen with his own eyes.

This largely morphological program of comparative anatomy remained at the core of most biological education for a hundred years until the advent of cell and molecular biology and interest in evolutionary ecology forced a fundamental rethink. It is an interesting fact that the methods of the field naturalists who led the way in developing the theory of evolution (Darwin, Wallace, Fritz Müller, Henry Bates) were scarcely represented at all in Huxley's program. Ecological investigation of life in its environment was virtually non-existent, and theory, evolutionary or otherwise, was at a discount. Michael Ruse finds no mention of evolution or Darwinism in any of the exams set by Huxley, and confirms the lecture content based on two complete sets of lecture notes.

Since Darwin, Wallace and Bates did not hold teaching posts at any stage of their adult careers (and Műller never returned from Brazil) the imbalance in Huxley's program went uncorrected. It is surely strange that Huxley's courses did not contain an account of the evidence collected by those naturalists of life in the tropics; evidence which they had found so convincing, and which caused their views on evolution by natural selection to be so similar. Desmond suggests that "[biology] had to be simple, synthetic and assimilable [because] it was to train teachers and had no other heuristic function". That must be part of the reason; indeed it does help to explain the stultifying nature of much school biology. But zoology as taught at all levels became far too much the product of one man.

Huxley was comfortable with comparative anatomy, at which he was the greatest master of the day. He was not an all-round naturalist like Darwin, who had shown clearly enough how to weave together detailed factual information and subtle arguments across the vast web of life. Huxley chose, in his teaching (and to some extent in his research) to take a more straightforward course, concentrating on his personal strengths.

Huxley was also a major influence in the direction taken by British schools: in November 1870 he was voted onto the London School Board. In primary schooling, he advocated a wide range of disciplines, similar to what is taught today: reading, writing, arithmetic, art, science, music, etc. In secondary education he recommended two years of basic liberal studies followed by two years of some upper-division work, focusing on a more specific area of study. A practical example of the latter is his famous 1868 lecture "On a Piece of Chalk" which was first published as an essay in "Macmillan's Magazine" in London later that year. The piece reconstructs the geological history of Britain from a simple piece of chalk and demonstrates science as "organized common sense".

Huxley supported the reading of the Bible in schools. This may seem out of step with his agnostic convictions, but he believed that the Bible's significant moral teachings and superb use of language were relevant to English life. "I do not advocate burning your ship to get rid of the cockroaches".
However, what Huxley proposed was to create an "edited version" of the Bible, shorn of "shortcomings and errors... statements to which men of science absolutely and entirely demur... These tender children [should] not be taught that which you do not yourselves believe". The Board voted against his idea, but it also voted against the idea that public money should be used to support students attending church schools. Vigorous debate took place on such points, and the debates were minuted in detail. Huxley said "I will never be a party to enabling the State to sweep the children of this country into denominational schools". The Act of Parliament which founded board schools permitted the reading of the Bible, but did not permit any denominational doctrine to be taught.

It may be right to see Huxley's life and work as contributing to the secularisation of British society which gradually occurred over the following century. Ernst Mayr said "It can hardly be doubted that [biology] has helped to undermine traditional beliefs and value systems"  — and Huxley more than anyone else was responsible for this trend in Britain. Some modern Christian apologists consider Huxley the father of antitheism, though he himself maintained that he was an agnostic, not an atheist. He was, however, a lifelong and determined opponent of almost all organised religion throughout his life, especially the "Roman Church... carefully calculated for the destruction of all that is highest in the moral nature, in the intellectual freedom, and in the political freedom of mankind". In the same line of thought, in an article in "Popular Science", Huxley used the expression "the so-called Christianity of Catholicism," explaining: "I say 'so-called' not by way of offense, but as a protest against the monstruous assumption that Catholic Christianity is explicitly or implicitly contained in any trust-worthy record of the teaching of Jesus of Nazareth."

Vladimir Lenin remarked (in "Materialism and empirio-criticism") "In Huxley's case... agnosticism serves as a fig-leaf for materialism" (see also the Debate with Wilberforce above).

Huxley's interest in education went still further than school and university classrooms; he made a great effort to reach interested adults of all kinds: after all, he himself was largely self-educated. There were his lecture courses for working men, many of which were published afterwards, and there was the use he made of journalism, partly to earn money but mostly to reach out to the literate public. For most of his adult life he wrote for periodicals—the "Westminster Review", the "Saturday Review", the "Reader", the "Pall Mall Gazette", "Macmillan's Magazine", the "Contemporary Review". Germany was still ahead in formal science education, but interested people in Victorian Britain could use their initiative and find out what was going on by reading periodicals and using the lending libraries.

In 1868 Huxley became Principal of the South London Working Men's College in Blackfriars Road. The moving spirit was a portmanteau worker, Wm. Rossiter, who did most of the work; the funds were put up mainly by F.D. Maurice's Christian Socialists. At sixpence for a course and a penny for a lecture by Huxley, this was some bargain; and so was the free library organised by the college, an idea which was widely copied. Huxley thought, and said, that the men who attended were as good as any country squire.

The technique of printing his more popular lectures in periodicals which were sold to the general public was extremely effective. A good example was "The physical basis of life", a lecture given in Edinburgh on 8 November 1868. Its theme — that vital action is nothing more than "the result of the molecular forces of the protoplasm which displays it" — shocked the audience, though that was nothing compared to the uproar when it was published in the "Fortnightly Review" for February 1869. John Morley, the editor, said "No article that had appeared in any periodical for a generation had caused such a sensation". The issue was reprinted seven times and protoplasm became a household word; "Punch" added 'Professor Protoplasm' to his other soubriquets.

The topic had been stimulated by Huxley seeing the cytoplasmic streaming in plant cells, which is indeed a sensational sight. For these audiences Huxley's claim that this activity should not be explained by words such as vitality, but by the working of its constituent chemicals, was surprising and shocking. Today we would perhaps emphasise the extraordinary structural arrangement of those chemicals as the key to understanding what cells do, but little of that was known in the nineteenth century.

When the Archbishop of York thought this 'new philosophy' was based on Auguste Comte's positivism, Huxley corrected him: "Comte's philosophy [is just] Catholicism minus Christianity" (Huxley 1893 vol 1 of Collected Essays "Methods & Results" 156). A later version was "[positivism is] sheer Popery with M. Comte in the chair of St Peter, and with the names of the saints changed". (lecture on "The scientific aspects of positivism" Huxley 1870 "Lay Sermons, Addresses and Reviews" p. 149). Huxley's dismissal of positivism damaged it so severely that Comte's ideas withered in Britain.

During his life, and especially in the last ten years after retirement, Huxley wrote on many issues relating to the humanities.

Perhaps the best known of these topics is "Evolution and Ethics", which deals with the question of whether biology has anything particular to say about moral philosophy. Both Huxley and his grandson Julian Huxley gave Romanes Lectures on this theme. For a start, Huxley dismisses religion as a source of moral authority. Next, he believes the mental characteristics of man are as much a product of evolution as the physical aspects. Thus, our emotions, our intellect, our tendency to prefer living in groups and spend resources on raising our young are part and parcel of our evolution, and therefore inherited.

Despite this, the "details" of our values and ethics are not inherited: they are partly determined by our culture, and partly chosen by ourselves. Morality and duty are often at war with natural instincts; ethics cannot be derived from the "struggle for existence": "Of moral purpose I see not a trace in nature. That is an article of exclusively human manufacture." It is therefore our responsibility to make ethical choices (see Ethics and Evolutionary ethics). This seems to put Huxley as a compatibilist in the Free Will vs Determinism debate. In this argument Huxley is diametrically opposed to his old friend Herbert Spencer.

Huxley's dissection of Rousseau's views on man and society is another example of his later work. The essay undermines Rousseau's ideas on man as a preliminary to undermining his ideas on the ownership of property. Characteristic is: "The doctrine that all men are, in any sense, or have been, at any time, free and equal, is an utterly baseless fiction."

Huxley's method of argumentation (his strategy and tactics of persuasion in speech and print) is itself much studied. His career included controversial debates with scientists, clerics and politicians; persuasive discussions with Royal Commissions and other public bodies; lectures and articles for the general public, and a mass of detailed letter-writing to friends and other correspondents. A large number of textbooks have excerpted his prose for anthologies.

Huxley worked on ten Royal and other commissions (titles somewhat shortened here). The Royal Commission is the senior investigative forum in the British constitution. A rough analysis shows that five commissions involved science and scientific education; three involved medicine and three involved fisheries. Several involve difficult ethical and legal issues. All deal with possible changes to law and/or administrative practice.



In 1855, he married Henrietta Anne Heathorn (1825–1915), an English émigrée whom he had met in Sydney. They kept correspondence until he was able to send for her. They had five daughters and three sons:


Huxley's relationships with his relatives and children were genial by the standards of the day—so long as they lived their lives in an honourable manner, which some did not. After his mother, his eldest sister Lizzie was the most important person in his life until his own marriage. He remained on good terms with his children, more than can be said of many Victorian fathers. This excerpt from a letter to Jessie, his eldest daughter is full of affection:

Huxley's descendants include children of Leonard Huxley:


Other significant descendants of Huxley, such as Sir Crispin Tickell, are treated in the Huxley family.

Biographers have sometimes noted the occurrence of mental illness in the Huxley family. His father became "sunk in worse than childish imbecility of mind", and later died in Barming Asylum; brother George suffered from "extreme mental anxiety" and died in 1863 leaving serious debts. Brother James, a well known psychiatrist and Superintendent of Kent County Asylum, was at 55 "as near mad as any sane man can be"; and there is more. His favourite daughter, the artistically talented Mady (Marian), who became the first wife of artist John Collier, was troubled by mental illness for years. She died of pneumonia in her mid-twenties.

About Huxley himself we have a more complete record. As a young apprentice to a medical practitioner, aged thirteen or fourteen, Huxley was taken to watch a post-mortem dissection. Afterwards he sank into a 'deep lethargy' and though Huxley ascribed this to dissection poisoning, Bibby and others may be right to suspect that emotional shock precipitated the depression. Huxley recuperated on a farm, looking thin and ill.

The next episode we know of in Huxley's life when he suffered a debilitating depression was on the third voyage of HMS "Rattlesnake" in 1848. Huxley had further periods of depression at the end of 1871, and again in 1873. Finally, in 1884 he sank into another depression, and this time it precipitated his decision to retire in 1885, at the age of only 60. This is enough to indicate the way depression (or perhaps a moderate bi-polar disorder) interfered with his life, yet unlike some of the other family members, he was able to function extremely well at other times.

The problems continued sporadically into the third generation. Two of Leonard's sons suffered serious depression: Trevennen committed suicide in 1914 and Julian suffered a breakdown in 1913, and five more later in life.

Darwin's ideas and Huxley's controversies gave rise to many cartoons and satires. It was the debate about man's place in nature that roused such widespread comment: cartoons are so numerous as to be almost impossible to count; Darwin's head on a monkey's body is one of the visual clichés of the age. The "Great Hippocampus Question" attracted particular attention:






 


</doc>
<doc id="30039" url="https://en.wikipedia.org/wiki?curid=30039" title="Triumph of the Will">
Triumph of the Will

Triumph of the Will () is a 1935 Nazi propaganda film directed, produced, edited, and co-written by Leni Riefenstahl. It chronicles the 1934 Nazi Party Congress in Nuremberg, which was attended by more than 700,000 Nazi supporters. The film contains excerpts from speeches given by Nazi leaders at the Congress, including Adolf Hitler, Rudolf Hess and Julius Streicher, interspersed with footage of massed Sturmabteilung (SA) and Schutzstaffel (SS) troops and public reaction. Hitler commissioned the film and served as an unofficial executive producer; his name appears in the opening titles. The film's overriding theme is the return of Germany as a great power, with Hitler as the leader who will bring glory to the nation. Because the film was made after the 1934 Night of the Long Knives (on 30 June), many prominent Sturmabteilung (SA) members are absent—they were murdered in that Party purge, organised and orchestrated by Hitler to replace the SA with the Schutzstaffel (SS) as his main paramilitary force.

"Triumph of the Will" was released in 1935 and became a prominent example of propaganda in film history. Riefenstahl's techniques—such as moving cameras, aerial photography, the use of long focus lenses to create a distorted perspective, and the revolutionary approach to the use of music and cinematography—have earned "Triumph of the Will" recognition as one of the greatest propaganda films in history. Riefenstahl helped to stage the scenes, directing and rehearsing some of them at least fifty times. Riefenstahl won several awards, not only in Germany but also in the United States, France, Sweden and other countries. The film was popular in the Third Reich, and has continued to influence films, documentaries and commercials to this day. In Germany, the film is not censored but the courts commonly classify it as Nazi propaganda which requires an educational context to public screenings.

An earlier film by Riefenstahl—"The Victory of Faith (Der Sieg des Glaubens)"—showed Hitler and SA leader Ernst Röhm together at the 1933 Nazi party congress. After Röhm's murder, the party attempted the destruction of all copies, leaving only one known to have survived in Britain. The direction and sequencing of images is almost the same as that Riefenstahl used in "Triumph of the Will" a year later.

Frank Capra's seven-film series "Why We Fight" is said to have been directly inspired by, and the United States' response to, "Triumph of the Will".

The film begins with a prologue, the only commentary in the film. It consists of the following text, shown sequentially, against a grey background:

Day 1: The film opens with shots of the clouds above the city, and then moves through the clouds to float above the assembling masses below, with the intention of portraying beauty and majesty of the scene. The cruciform shadow of Hitler's plane is visible as it passes over the tiny figures marching below, accompanied by an orchestral arrangement of the "Horst-Wessel-Lied". Upon arriving at the Nuremberg airport, Hitler and other Nazi leaders emerge from his plane to thunderous applause and a cheering crowd. He is then driven into Nuremberg, through equally enthusiastic people, to his hotel where a night rally is later held.

Day 2: The second day begins with images of Nuremberg at dawn, accompanied by an extract from the Act III Prelude ("Wach Auf!") of Richard Wagner's "Die Meistersinger von Nürnberg". Following this is a montage of the attendees preparing for the opening of the Reich Party Congress, and footage of the top Nazi officials arriving at the Luitpold Arena. The film then cuts to the opening ceremony, where Rudolf Hess announces the start of the Congress. The camera then introduces much of the Nazi hierarchy and covers their opening speeches, including Joseph Goebbels, Alfred Rosenberg, Hans Frank, Fritz Todt, Robert Ley and Julius Streicher. Then the film cuts to an outdoor rally for the "Reichsarbeitsdienst" (Labor Service), which is primarily a series of quasi-military drills by men carrying spades. This is also where Hitler gives his first speech on the merits of the Labour Service and praising them for their work in rebuilding Germany. The day then ends with a torchlight SA parade in which Viktor Lutze speaks to the crowds.

Day 3: The third day starts with a Hitler Youth rally on the parade ground. Again the camera covers the Nazi dignitaries arriving and the introduction of Hitler by Baldur von Schirach. Hitler then addresses the Youth, describing in militaristic terms how they must harden themselves and prepare for sacrifice. Everyone present, including General Werner von Blomberg, then assemble for a military pass and review, featuring Wehrmacht cavalry and various armored vehicles. That night Hitler delivers another speech to low-ranking party officials by torchlight, commemorating the first year since the Nazis took power and declaring that the party and state are one entity.

Day 4: The fourth day is the climax of the film, where the most memorable of the imagery is presented. Hitler, flanked by Heinrich Himmler and Viktor Lutze, walks through a long wide expanse with over 150,000 SA and SS troops standing at attention, to lay a wreath at a First World War memorial. Hitler then reviews the parading SA and SS men, following which Hitler and Lutze deliver a speech where they discuss the Night of the Long Knives purge of the SA several months prior. Lutze reaffirms the SA's loyalty to the regime, and Hitler absolves the SA of any crimes committed by Ernst Röhm. New party flags are consecrated by letting them touch the "Blutfahne" (the same cloth flag said to have been carried by the fallen Nazis during the Beer Hall Putsch) and, following a final parade in front of the Nuremberg Frauenkirche, Hitler delivers his closing speech. In it he reaffirms the primacy of the Nazi Party in Germany, declaring, "All loyal Germans will become National Socialists. Only the best National Socialists are party comrades!" Hess then leads the assembled crowd in a final "Sieg Heil" salute for Hitler, marking the close of the party congress. The entire crowd sings the "Horst-Wessel-Lied" as the camera focuses on the giant Swastika banner, which fades into a line of silhouetted men in Nazi party uniforms, marching in formation as the lyrics "Comrades shot by the Red Front and the Reactionaries march in spirit together in our columns" are sung.

Riefenstahl, a popular German actress, had directed her first film called "Das blaue Licht" ("The Blue Light") in 1932. Around the same time she first heard Hitler speak at a Nazi rally and, by her own admission, was impressed. She later began a correspondence with him that would last for years. Hitler, by turn, was equally impressed with "Das blaue Licht", and in 1933 asked her to direct a film about the Nazis' annual Nuremberg Rally. The Nazis had only recently taken power amid a period of political instability (Hitler was the fourth Chancellor of Germany in less than a year) and were considered an unknown quantity by many Germans, to say nothing of the world.

In "Mein Kampf", Hitler talks of the success of British propaganda in World War I, believing people's ignorance meant simple repetition and an appeal to feelings over reason would suffice. Hitler chose Riefenstahl as he wanted the film as "artistically satisfying" as possible to appeal to a non-political audience, but he also believed that propaganda must admit no element of doubt. As such, "Triumph of the Will" may be seen as a continuation of the unambiguous World War I-style propaganda, though heightened by the film's artistic or poetic nature.

Riefenstahl was initially reluctant, not because of any moral qualms, but because she wanted to continue making feature films. Hitler persisted and Riefenstahl eventually agreed to make a film at the 1933 Nuremberg Rally called "Der Sieg des Glaubens" ("Victory of Faith"). However the film had numerous technical problems, including a lack of preparation (Riefenstahl reported having just a few days) and Hitler's apparent unease at being filmed. To make matters worse, Riefenstahl had to deal with infighting by party officials, in particular Joseph Goebbels who tried to have the film released by the Propaganda Ministry. Though "Der Sieg des Glaubens" apparently did well at the box office, it later became a serious embarrassment to the Nazis after SA Leader Ernst Röhm, who had a prominent role in the film, was executed during the Night of the Long Knives. All references to Röhm were ordered to be erased from German history, which included the destruction of all copies of "Der Sieg des Glaubens". It was considered lost until a copy turned up in the 1990s in the United Kingdom.

In 1934, Riefenstahl had no wish to repeat the fiasco of "Der Sieg des Glaubens" and initially recommended fellow director Walter Ruttmann. Ruttmann's film, which would have covered the rise of the Nazi Party from 1923 to 1934 and been more overtly propagandistic (the opening text of "Triumph of the Will" was his), did not appeal to Hitler. He again asked Riefenstahl, who finally relented (there is still debate over how willing she was) after Hitler guaranteed his personal support and promised to keep other Nazi organizations, specifically the Propaganda Ministry, from meddling with her film.

The film follows a script similar to "Der Sieg des Glaubens", which is evident when one sees both films side by side. For example, the city of Nuremberg scenes—even to the shot of a cat included in the city driving sequence in both films. Furthermore, Herbert Windt reused much of his musical score for that film in "Triumph des Willens", which he also scored. Riefenstahl shot "Triumph of the Will" on a budget of roughly 280,000RM (approx. $110K USD 1934, $1.54M 2015). With that said, there were extensive preparations facilitated by the cooperation of party members, the military, and vital help from high-ranking Nazis like Goebbels. As Susan Sontag observed, "The Rally was planned not only as a spectacular mass meeting, but as a spectacular propaganda film." Albert Speer, Hitler's personal architect, designed the set in Nuremberg and did most of the coordination for the event. Pits were dug in front of the speakers' platform so Riefenstahl could get the camera angles she wanted, and tracks were laid so that her cameramen could get traveling shots of the crowd. When rough cuts weren't up to par, major party leaders and high-ranking public officials reenacted their speeches in a studio for her. Riefenstahl also used a film crew that was extravagant by the standards of the day. Her crew consisted of 172 people, including 10 technical staff, 36 cameramen and assistants (operating in 16 teams with 30 cameras), nine aerial photographers, 17 newsreel men, 12 newsreel crew, 17 lighting men, two photographers, 26 drivers, 37 security personnel, four labor service workers, and two office assistants. Many of her cameramen also dressed in SA uniforms so they could blend into the crowds.

Riefenstahl had the difficult task of condensing an estimated 61 hours of film into two hours. She labored to complete the film as fast as she could, going so far as to sleep in the editing room filled with hundreds of thousands of feet of film footage.

"Triumph of the Will" is sometimes seen as an example of Nazi political religion. The primary religion in Germany before the Second World War was Christianity. With the primary sects being Roman Catholic and Protestant, the Christian views in this movie are clearly meant to allow the movie to better connect with the intended audience.

Religion is a major theme in "Triumph of the Will". The film opens with Hitler descending god-like out of the skies past twin cathedral spires. It contains many scenes of church bells ringing, and individuals in a state of near-religious fervor, as well as a prominent shot of Reich Protestant Bishop Ludwig Müller standing in his vestments among high-ranking Nazis. It is probably not a coincidence that the final parade of the film was held in front of the Nuremberg Frauenkirche. In his final speech in the film, Hitler also directly compares the Nazi party to a holy order, and the consecration of new party flags by having Hitler touch them to the "blood banner" has obvious religious overtones. Hitler himself is portrayed in a messianic manner, from the opening where he descends from the clouds in a plane, to his drive through Nuremberg where even a cat stops what it is doing to watch him, to the many scenes where the camera films from below and looks up at him: Hitler, standing on his podium, will issue a command to hundreds of thousands of followers. The audience happily complies in unison. As Frank P. Tomasulo comments, "Hitler is cast as a veritable German Messiah who will save the nation, if only the citizenry will put its destiny in his hands."

Germany had not seen images of military power and strength since the end of World War I, and the huge formations of men would remind the audience that Germany was becoming a great power once again. Though the Labor Service men carried spades, they handled them as if they were rifles. The Eagles and Swastikas could be seen as a reference to the Roman Legions of antiquity. The large mass of well-drilled party members could be seen in a more ominous light, as a warning to dissidents thinking of challenging the regime.

Hitler's arrival in an airplane should also be viewed in this context. According to Kenneth Poferl, "Flying in an airplane was a luxury known only to a select few in the 1930s, but Hitler had made himself widely associated with the practice, having been the first politician to campaign via air travel. Victory reinforced this image and defined him as the top man in the movement, by showing him as the only one to arrive in a plane and receive an individual welcome from the crowd. Hitler's speech to the SA also contained an implied threat: if he could have Röhm, the commander of the hundreds of thousands of troops on the screen, shot, it was only logical to assume that Hitler could get away with having anyone executed."

It was very important to Adolf Hitler that his propaganda messages carry a unified theme. If a country isn't unified in saying the enemy is bad, the audience starts to have doubts. Unity is seen throughout this film, even in the camps where soldiers live. The camp outside of Nuremberg is very uniform and clean; the tents are aligned in perfect rows, each one the same as the next. The men there also make a point not to wear their shirts, because their shirts display their rankings and status. Shirtless they are all equals, unified. When they march, it is in unison and they all carry their weapons identically, one to another.

Hitler's message to the workers also includes the notion of unity:

Children were also used to convey unity: 

"Triumph of the Will" has many scenes that blur the distinction between the Nazi Party, the German state, and the German people. Germans in peasant farmers' costumes and other traditional clothing greet Hitler in some scenes. The torchlight processions, though now associated by many with the Nazis, would remind the viewer of the medieval Karneval celebration. The old flag of Imperial Germany is also shown several times flying alongside the Swastika, and there is a ceremony where Hitler pays his respects to soldiers who died in World War I (as well as to President Paul von Hindenburg, who had died a month before the convention). There is also a scene where the Labor Servicemen individually call out which town or area in Germany they are from, reminding the viewers that the Nazi Party had expanded from its stronghold in Bavaria to become a pan-German movement.

Among the themes presented, the desire for pride in Germany and the purification of the German people is well exemplified through the speeches and ideals of the Third Reich in "Triumph of the Will".

In every speech given and shown in "Triumph of the Will", pride is one of the major focuses. Hitler advocates to the people that they should not be satisfied with their current state and they should not be satisfied with the descent from power and greatness Germany has endured since World War I. The German people should believe in themselves and the movement that is occurring in Germany. Hitler promotes pride in Germany through the unification of it. Unifying Germany would force the elimination of what does not amount to the standards of the Nazi regime.

To unify Germany, Hitler believes purification would have to take place. This meant not only eliminating the citizens of Germany who are not of the Aryan race, but the sick, weak, handicapped, or any other citizens deemed unhealthy or impure. In "Triumph of the Will", Hitler preaches to the people that Germany must take a look at itself and seek out that which does not belong: "[T]he elements that have become bad, and therefore do not belong with us!" Though within the context, he seems to be referring to the corrupt elements of the power structure, it later could seem in hindsight to imply that the elimination of the "inferior" people of Germany would, in theory, return Germany to its once prideful and powerful former self. Julius Streicher stresses the importance of purification in his speech, a direct reference to his own virulent anti-semitism. Hundreds of thousands mentally sick and disabled would be murdered in the Action T4, a programme run directly from Hitler's Chancellery ("Kanzlei des Führers").

Hitler preaches to the people in his speeches that they should believe in their country and themselves. The German people are better than what they have become because of the impurities in society. Hitler wants them to believe in him and believe what he wants to do for his people, and what he is doing is for the country's and people's benefit. Hess says in the last scene of "Triumph of the Will", "Heil Hitler, hail victory, hail victory!" Everyone in attendance cheers in support. This verbal sign represents their faith to their leader and his most trusted advisors that they believe in the Nazi cause. This is directly following Hitler's finale, "Long live the National Socialist Movement! Long live Germany!" and the crowd erupts with cheering and the fulfillment of pride for themselves and their political party.

In the closing speech of "Triumph of the Will", Hitler enters the room from the back, appearing to emerge from the people. After a one sentence introduction, he tells his faithful Nazis how the German nation has subordinated itself to the Nazi Party because its leaders are mostly of Germans. He promises that the new state that the Nazis have created will endure for thousands of years. Hitler says that the youth will carry on after the old have weakened. They close with a chant, "Hitler is the Party, Hitler." The camera focuses on the large Swastika above Hitler and the film ends with the images of this Swastika imposed on Nazis marching in a few columns. His speech brought attention to the rally and created a huge turnout in the following years. He attracted many people in the way that he addressed the issues and his people. He spoke to them as if it were a sermon and engaged the people. In 1934, over a million Germans participated in the Nuremberg Rally.

"Triumph of the Will" premiered on 28 March 1935 at the Berlin Ufa Palace Theater and was an instant success. Within two months the film had earned 815,000 Reichsmark, and Ufa considered it one of the three most profitable films of that year. Hitler praised the film as being an "incomparable glorification of the power and beauty of our Movement." For her efforts, Riefenstahl was rewarded with the German Film Prize ("Deutscher Filmpreis"), a gold medal at the 1935 Venice Biennale, and the Grand Prix at the 1937 World Exhibition in Paris. However, there were few claims that the film would result in a mass influx of "converts" to fascism and the Nazis apparently did not make a serious effort to promote the film outside of Germany. Film historian Richard Taylor also said that "Triumph of the Will" was not generally used for propaganda purposes inside the Third Reich. "The Independent" wrote in 2003: ""Triumph of the Will" seduced many wise men and women, persuaded them to admire rather than to despise, and undoubtedly won the Nazis friends and allies all over the world."

The reception in other countries was not always as enthusiastic. British documentarian Paul Rotha called it tedious, while others were repelled by its pro-Nazi sentiments. During World War II, Frank Capra helped to create a direct response, through the film series called "Why We Fight", a series of newsreels commissioned by the United States government that spliced in footage from "Triumph of the Will", but recontextualized it so that it promoted the cause of the Allies instead. Capra later remarked that "Triumph of the Will" "fired no gun, dropped no bombs. But as a psychological weapon aimed at destroying the will to resist, it was just as lethal." Clips from "Triumph of the Will" were also used in an Allied propaganda short called "General Adolph Takes Over", set to the British dance tune "The Lambeth Walk". The legions of marching soldiers, as well as Hitler giving his Nazi salute, were made to look like wind-up dolls, dancing to the music. The Danish resistance used to take over cinemas and force the projectionist to show "Swinging the Lambeth Walk" (as it was also known); Erik Barrow has said: "The extraordinary risks were apparently felt justified by a moment of savage anti-Hitler ridicule." Also during World War II, the poet Dylan Thomas wrote a screenplay for and narrated "These Are The Men", a propaganda piece using "Triumph of the Will" footage to discredit Nazi leadership.

One of the best ways to gauge the response to "Triumph of the Will" was the instant and lasting international fame it gave Riefenstahl. "The Economist" said it "sealed her reputation as the greatest female filmmaker of the 20th century." For a director who made eight films, only two of which received significant coverage outside of Germany, Riefenstahl had unusually high name recognition for the remainder of her life, most of it stemming from "Triumph of the Will". However, her career was also permanently damaged by this association. After the war, Riefenstahl was imprisoned by the Allies for four years for allegedly being a Nazi sympathizer and was permanently blacklisted by the film industry. When she died in 2003–68 years after the film's premiere—her obituary received significant coverage in many major publications, including the Associated Press, "The Wall Street Journal", "The New York Times", and "The Guardian", most of which reaffirmed the importance of "Triumph of the Will".

Like American filmmaker D. W. Griffith's "The Birth of a Nation", "Triumph of the Will" has been criticized as a use of spectacular filmmaking to promote a profoundly unethical system. In her defense, Riefenstahl claimed that she was naïve about the Nazis when she made it and had no knowledge of Hitler's genocidal or anti-semitic policies. She also pointed out that "Triumph of the Will" contains "not one single anti-semitic word", although it does contain a veiled comment by Julius Streicher, the notorious Jew-baiter (who was hanged after the Nuremberg trials), that "a people that does not protect its racial purity will perish".

However, Roger Ebert has observed that for some, "the very absence of anti-semitism in "Triumph of the Will" looks like a calculation; excluding the central motif of almost all of Hitler's public speeches must have been a deliberate decision to make the film more efficient as propaganda."

Riefenstahl also repeatedly defended herself against the charge that she was a Nazi propagandist, saying that "Triumph of the Will" focuses on images over ideas, and should therefore be viewed as a "Gesamtkunstwerk" (holistic work of art). In 1964, she returned to this topic, saying:

However, Riefenstahl was an active participant in the rally, though in later years she downplayed her influence significantly, claiming, "I just observed and tried to film it well. The idea that I helped to plan it is downright absurd." Ebert states that "Triumph of the Will" is "by general consent [one] of the best documentaries ever made", but added that because it reflects the ideology of a movement regarded by many as evil, it poses "a classic question of the contest between art and morality: Is there such a thing as pure art, or does all art make a political statement?" When reviewing the film for his "Great Movies" collection, Ebert reversed his opinion, characterizing his earlier conclusion as "the received opinion that the film is great but evil" and calling it "a terrible film, paralyzingly dull, simpleminded, overlong and not even 'manipulative', because it is too clumsy to manipulate anyone but a true believer".

Susan Sontag considers "Triumph of the Will" the "most successful, most purely propagandistic film ever made, whose very conception negates the possibility of the filmmaker's having an aesthetic or visual conception independent of propaganda." Sontag points to Riefenstahl's involvement in the planning and design of the Nuremberg ceremonies as evidence that Riefenstahl was working as a propagandist, rather than as an artist in any sense of the word. With some 30 cameras and a crew of 150, the marches, parades, speeches, and processions were orchestrated like a movie set for Riefenstahl's film. Further, this was not the first political film made by Riefenstahl for the Third Reich (there was "Victory of Faith", 1933), nor was it the last ("Day of Freedom", 1935, and "Olympia", 1938). "Anyone who defends Riefenstahl's films as documentary", Sontag states, "if documentary is to be distinguished from propaganda, is being disingenuous. In "Triumph of Will", the document (the image) is no longer simply the record of reality; 'reality' has been constructed to serve the image."

Brian Winston's essay on the film in "The Movies as History" is largely a critique of Sontag's analysis. Winston argues that any filmmaker could have made the film look impressive because the Nazis' "mise en scène" was impressive, particularly when they were offering it for camera re-stagings. In form, the film alternates repetitively between marches and speeches. Winston asks the viewers to consider if such a film should be seen as anything more than a pedestrian effort. Like Rotha, he finds the film tedious, and believes anyone who takes the time to analyze its structure will quickly agree.

The first controversy over "Triumph of the Will" occurred even before its release, when several generals in the Wehrmacht protested over the minimal army presence in the film. Only one scene—the review of the German cavalry—actually involved the German military. The other formations were party organizations that were not part of the military.

The opposition of the generals, was not simply out of personalized pique or vanity. As produced by Riefenstahl, "Triumph of the Will", posits Germany as a leaderless mass of lost souls without any organizing institutions, or antecedent institutional leaders. And that the "new order" embodied by the Nazi Party and Hitler, provides a both new, and a singular/saving leader and institutional framework for the whole of the German nation.

However, the Army had been, and had seen itself as being, an institution that held shared responsibility for the leadership of the nation and state since at least the time of Fredrick the Great. The leaders of that Army had also been viewed throughout the history of the German-speaking peoples as an integral part of the leadership cadre. By omitting the Army (along with other institutions, e.g., the nobility, the Church, academia, business), the film demonstrated that the Army, as well as its leaders, was "disappeared" from what the Army considered to be its shared leadership role in the state, National Socialist or otherwise. The Army's leaders vehemently disagreed with this implied assertion of the film.
Hitler proposed his own "artistic" compromise where "Triumph of the Will" would open with a camera slowly tracking down a row of all the "overlooked" generals (and placate each general's ego). According to her own testimony, Riefenstahl refused his suggestion and insisted on keeping artistic control over "Triumph of the Will". She did agree to return to the 1935 rally to make a film exclusively about the Wehrmacht, which became "" ("Day of Freedom: Our Armed Forces").

"Triumph of the Will" remains well known for its striking visuals. As one historian notes, "many of the most enduring images of the [Nazi] regime and its leader derive from Riefenstahl's film."

Extensive excerpts of the film were used in Erwin Leiser's documentary "Mein Kampf", produced in Sweden in 1960. Riefenstahl unsuccessfully sued the Swedish production company Minerva-Film for copyright violation, although she did receive forty thousand marks in compensation from German and Austrian distributors of the film.

In 1942, Charles A. Ridley of the British Ministry of Information made a short propaganda film, "Lambeth Walk – Nazi Style", which edited footage of Hitler and German soldiers from the film to make it appear they were marching and dancing to the song "The Lambeth Walk". The targeted-at-Nazis parody of "The Lambeth Walk" (a British dance that had been popular in swing clubs in Germany which the Nazis denounced as "Jewish mischief and animalistic hopping") so enraged Joseph Goebbels that reportedly he ran out of the screening room kicking chairs and screaming profanities. The propaganda film was distributed uncredited to newsreel companies, who would supply their own narration.

Charlie Chaplin's satire "The Great Dictator" (1940) was inspired in large part by "Triumph of the Will". Frank Capra used significant footage, with a mocking narration in the first installment of the propagandistic film produced by the United States Army "Why We Fight" as an exposure of Nazi militarism and totalitarianism to American soldiers and sailors. The film has been studied by many contemporary artists, including film directors Peter Jackson, George Lucas and Ridley Scott.

The most notable use of "Triumph of the Will" in popular culture is found in the Monty Python sketch "The Funniest Joke in the World", where footage from the film is used with superimposed humorous subtitles.





</doc>
<doc id="30040" url="https://en.wikipedia.org/wiki?curid=30040" title="Titanium">
Titanium

Titanium is a chemical element with symbol Ti and atomic number 22. It is a lustrous transition metal with a silver color, low density, and high strength. Titanium is resistant to corrosion in sea water, aqua regia, and chlorine.

Titanium was discovered in Cornwall, Great Britain, by William Gregor in 1791, and was named by Martin Heinrich Klaproth after the Titans of Greek mythology. The element occurs within a number of mineral deposits, principally rutile and ilmenite, which are widely distributed in the Earth's crust and lithosphere, and it is found in almost all living things, water bodies, rocks, and soils. The metal is extracted from its principal mineral ores by the Kroll and Hunter processes. The most common compound, titanium dioxide, is a popular photocatalyst and is used in the manufacture of white pigments. Other compounds include titanium tetrachloride (TiCl), a component of smoke screens and catalysts; and titanium trichloride (TiCl), which is used as a catalyst in the production of polypropylene.

Titanium can be alloyed with iron, aluminium, vanadium, and molybdenum, among other elements, to produce strong, lightweight alloys for aerospace (jet engines, missiles, and spacecraft), military, industrial processes (chemicals and petrochemicals, desalination plants, pulp, and paper), automotive, agri-food, medical prostheses, orthopedic implants, dental and endodontic instruments and files, dental implants, sporting goods, jewelry, mobile phones, and other applications.

The two most useful properties of the metal are corrosion resistance and strength-to-density ratio, the highest of any metallic element. In its unalloyed condition, titanium is as strong as some steels, but less dense. There are two allotropic forms and five naturally occurring isotopes of this element, Ti through Ti, with Ti being the most abundant (73.8%). Although they have the same number of valence electrons and are in the same group in the periodic table, titanium and zirconium differ in many chemical and physical properties.

As a metal, titanium is recognized for its high strength-to-weight ratio. It is a strong metal with low density that is quite ductile (especially in an oxygen-free environment), lustrous, and metallic-white in color. The relatively high melting point (more than 1,650 °C or 3,000 °F) makes it useful as a refractory metal. It is paramagnetic and has fairly low electrical and thermal conductivity.

Commercially pure (99.2% pure) grades of titanium have ultimate tensile strength of about 434 MPa (63,000 psi), equal to that of common, low-grade steel alloys, but are less dense. Titanium is 60% denser than aluminium, but more than twice as strong as the most commonly used 6061-T6 aluminium alloy. Certain titanium alloys (e.g., Beta C) achieve tensile strengths of over 1,400 MPa (200,000 psi). However, titanium loses strength when heated above .

Titanium is not as hard as some grades of heat-treated steel; it is non-magnetic and a poor conductor of heat and electricity. Machining requires precautions, because the material can gall unless sharp tools and proper cooling methods are used. Like steel structures, those made from titanium have a fatigue limit that guarantees longevity in some applications.

The metal is a dimorphic allotrope of an hexagonal α form that changes into a body-centered cubic (lattice) β form at . The specific heat of the α form increases dramatically as it is heated to this transition temperature but then falls and remains fairly constant for the β form regardless of temperature.

Like aluminium and magnesium, titanium metal and its alloys oxidize immediately upon exposure to air. Titanium readily reacts with oxygen at in air, and at in pure oxygen, forming titanium dioxide. It is, however, slow to react with water and air at ambient temperatures because it forms a passive oxide coating that protects the bulk metal from further oxidation. When it first forms, this protective layer is only 1–2 nm thick but continues to grow slowly; reaching a thickness of 25 nm in four years.

Atmospheric passivation gives titanium excellent resistance to corrosion, almost equivalent to platinum. Titanium is capable of withstanding attack by dilute sulfuric and hydrochloric acids, chloride solutions, and most organic acids. However, titanium is corroded by concentrated acids. As indicated by its negative redox potential, titanium is thermodynamically a very reactive metal that burns in normal atmosphere at lower temperatures than the melting point. Melting is possible only in an inert atmosphere or in a vacuum. At , it combines with chlorine. It also reacts with the other halogens and absorbs hydrogen.

Titanium is one of the few elements that burns in pure nitrogen gas, reacting at to form titanium nitride, which causes embrittlement. Because of its high reactivity with oxygen, nitrogen, and some other gases, titanium filaments are applied in titanium sublimation pumps as scavengers for these gases. Such pumps inexpensively and reliably produce extremely low pressures in ultra-high vacuum systems.

Titanium is the ninth-most abundant element in Earth's crust (0.63% by mass) and the seventh-most abundant metal. It is present as oxides in most igneous rocks, in sediments derived from them, in living things, and natural bodies of water. Of the 801 types of igneous rocks analyzed by the United States Geological Survey, 784 contained titanium. Its proportion in soils is approximately 0.5 to 1.5%.

Common titanium-containing minerals are anatase, brookite, ilmenite, perovskite, rutile, and titanite (sphene). Akaogiite is an extremely rare mineral consisting of titanium dioxide. Of these minerals, only rutile and ilmenite have economic importance, yet even they are difficult to find in high concentrations. About 6.0 and 0.7 million tonnes of those minerals were mined in 2011, respectively. Significant titanium-bearing ilmenite deposits exist in western Australia, Canada, China, India, Mozambique, New Zealand, Norway, Sierra Leone, South Africa, and Ukraine. About 186,000 tonnes of titanium metal sponge were produced in 2011, mostly in China (60,000 t), Japan (56,000 t), Russia (40,000 t), United States (32,000 t) and Kazakhstan (20,700 t). Total reserves of titanium are estimated to exceed 600 million tonnes.

The concentration of titanium is about 4 picomolar in the ocean. At 100 °C, the concentration of titanium in water is estimated to be less than 10 M at pH 7. The identity of titanium species in aqueous solution remains unknown because of its low solubility and the lack of sensitive spectroscopic methods, although only the 4+ oxidation state is stable in air. No evidence exists for a biological role, although rare organisms are known to accumulate high concentrations of titanium.

Titanium is contained in meteorites, and it has been detected in the Sun and in M-type stars (the coolest type) with a surface temperature of . Rocks brought back from the Moon during the Apollo 17 mission are composed of 12.1% TiO. It is also found in coal ash, plants, and even the human body. Native titanium (pure metallic) is very rare.

Naturally occurring titanium is composed of 5 stable isotopes: Ti, Ti, Ti, Ti, and Ti, with Ti being the most abundant (73.8% natural abundance). Eleven radioisotopes have been characterized, the most stable being Ti with a half-life of 63 years; Ti, 184.8 minutes; Ti, 5.76 minutes; and Ti, 1.7 minutes. All the other radioactive isotopes have half-lives less than 33 seconds and the majority, less than half a second.

The isotopes of titanium range in atomic weight from 39.99 u (Ti) to 57.966 u (Ti). The primary decay mode before the most abundant stable isotope, Ti, is electron capture and the primary mode after is beta emission. The primary decay products before Ti are element 21 (scandium) isotopes and the primary products after are element 23 (vanadium) isotopes.

Titanium becomes radioactive upon bombardment with deuterons, emitting mainly positrons and hard gamma rays.

The +4 oxidation state dominates titanium chemistry, but compounds in the +3 oxidation state are also common. Commonly, titanium adopts an octahedral coordination geometry in its complexes, but tetrahedral TiCl is a notable exception. Because of its high oxidation state, titanium(IV) compounds exhibit a high degree of covalent bonding. Unlike most other transition metals, simple aquo Ti(IV) complexes are unknown.

The most important oxide is TiO, which exists in three important polymorphs; anatase, brookite, and rutile. All of these are white diamagnetic solids, although mineral samples can appear dark (see rutile). They adopt polymeric structures in which Ti is surrounded by six oxide ligands that link to other Ti centers.

The term "titanates" usually refers to titanium(IV) compounds, as represented by barium titanate (BaTiO). With a perovskite structure, this material exhibits piezoelectric properties and is used as a transducer in the interconversion of sound and electricity. Many minerals are titanates, e.g. ilmenite (FeTiO). Star sapphires and rubies get their asterism (star-forming shine) from the presence of titanium dioxide impurities.

A variety of reduced oxides of titanium are known. TiO, described as a Ti(IV)-Ti(III) species, is a purple semiconductor produced by reduction of TiO with hydrogen at high temperatures, and is used industrially when surfaces need to be vapour-coated with titanium dioxide: it evaporates as pure TiO, whereas TiO evaporates as a mixture of oxides and deposits coatings with variable refractive index. Also known is TiO, with the corundum structure, and TiO, with the rock salt structure, although often nonstoichiometric.

The alkoxides of titanium(IV), prepared by reacting TiCl with alcohols, are colourless compounds that convert to the dioxide on reaction with water. They are industrially useful for depositing solid TiO via the sol-gel process. Titanium isopropoxide is used in the synthesis of chiral organic compounds via the Sharpless epoxidation.

Titanium forms a variety of sulfides, but only TiS has attracted significant interest. It adopts a layered structure and was used as a cathode in the development of lithium batteries. Because Ti(IV) is a "hard cation", the sulfides of titanium are unstable and tend to hydrolyze to the oxide with release of hydrogen sulfide.

Titanium nitride (TiN) is a member of a family of refractory transition metal nitrides and exhibits properties similar to both covalent compounds including; thermodynamic stability, extreme hardness, thermal/electrical conductivity, and a high melting point. TiN has a hardness equivalent to sapphire and carborundum (9.0 on the Mohs Scale), and is often used to coat cutting tools, such as drill bits. It is also used as a gold-colored decorative finish and as a barrier metal in semiconductor fabrication. Titanium carbide, which is also very hard, is found in cutting tools and coatings.

Titanium tetrachloride (titanium(IV) chloride, TiCl) is a colorless volatile liquid (commercial samples are yellowish) that, in air, hydrolyzes with spectacular emission of white clouds. Via the Kroll process, TiCl is produced in the conversion of titanium ores to titanium dioxide, e.g., for use in white paint. It is widely used in organic chemistry as a Lewis acid, for example in the Mukaiyama aldol condensation. In the van Arkel process, titanium tetraiodide (TiI) is generated in the production of high purity titanium metal.

Titanium(III) and titanium(II) also form stable chlorides. A notable example is titanium(III) chloride (TiCl), which is used as a catalyst for production of polyolefins (see Ziegler-Natta catalyst) and a reducing agent in organic chemistry.

Owing to the important role of titanium compounds as polymerization catalyst, compounds with Ti-C bonds have been intensively studied. The most common organotitanium complex is titanocene dichloride ((CH)TiCl). Related compounds include Tebbe's reagent and Petasis reagent. Titanium forms carbonyl complexes, e.g. (CH)Ti(CO).

Following the success of platinum-based chemotherapy, titanium(IV) complexes were among the first non-platinum compounds to be tested for cancer treatment. The advantage of titanium compounds lies in their high efficacy and low toxicity. In biological environments, hydrolysis leads to the safe and inert titanium dioxide. Despite these advantages the first candidate compounds failed clinical trials. Further development resulted in the creation of potentially effective, selective, and stable titanium-based drugs. Unfortunately, their mode of action is not yet well understood.

Titanium was discovered in 1791 by the clergyman and amateur geologist, William Gregor, as an inclusion of a mineral in Cornwall, Great Britain. Gregor recognized the presence of a new element in ilmenite when he found black sand by a stream and noticed the sand was attracted by a magnet. Analyzing the sand, he determined the presence of two metal oxides: iron oxide (explaining the attraction to the magnet) and 45.25% of a white metallic oxide he could not identify. Realizing that the unidentified oxide contained a metal that did not match any known element, Gregor reported his findings to the Royal Geological Society of Cornwall and in the German science journal "Crell's Annalen".

Around the same time, Franz-Joseph Müller von Reichenstein produced a similar substance, but could not identify it. The oxide was independently rediscovered in 1795 by Prussian chemist Martin Heinrich Klaproth in rutile from Boinik (German name Bajmócska), a village in Hungary (now Bojničky in Slovakia). Klaproth found that it contained a new element and named it for the Titans of Greek mythology. After hearing about Gregor's earlier discovery, he obtained a sample of manaccanite and confirmed that it contained titanium.

The currently known processes for extracting titanium from its various ores are laborious and costly; it is not possible to reduce the ore by heating with carbon (as in iron smelting) because titanium combines with the carbon to produce titanium carbide. Pure metallic titanium (99.9%) was first prepared in 1910 by Matthew A. Hunter at Rensselaer Polytechnic Institute by heating TiCl with sodium at 700–800 °C under great pressure in a batch process known as the Hunter process. Titanium metal was not used outside the laboratory until 1932 when William Justin Kroll proved that it can be produced by reducing titanium tetrachloride (TiCl) with calcium. Eight years later he refined this process with magnesium and even sodium in what became known as the Kroll process. Although research continues into more efficient and cheaper processes (e.g., FFC Cambridge, Armstrong), the Kroll process is still used for commercial production.

Titanium of very high purity was made in small quantities when Anton Eduard van Arkel and Jan Hendrik de Boer discovered the iodide, or crystal bar, process in 1925, by reacting with iodine and decomposing the formed vapours over a hot filament to pure metal.

In the 1950s and 1960s, the Soviet Union pioneered the use of titanium in military and submarine applications (Alfa class and Mike class) as part of programs related to the Cold War. Starting in the early 1950s, titanium came into use extensively in military aviation, particularly in high-performance jets, starting with aircraft such as the F-100 Super Sabre and Lockheed A-12 and SR-71.

Recognizing the strategic importance of titanium, the U.S. Department of Defense supported early efforts of commercialization.

Throughout the period of the Cold War, titanium was considered a strategic material by the U.S. government, and a large stockpile of titanium sponge was maintained by the Defense National Stockpile Center, which was finally depleted in the 2000s. According to 2006 data, the world's largest producer, Russian-based VSMPO-AVISMA, was estimated to account for about 29% of the world market share. As of 2015, titanium sponge metal was produced in six countries: China, Japan, Russia, Kazakhstan, the US, Ukraine, and India. (in order of output).

In 2006, the U.S. Defense Advanced Research Projects Agency (DARPA) awarded $5.7 million to a two-company consortium to develop a new process for making titanium metal powder. Under heat and pressure, the powder can be used to create strong, lightweight items ranging from armour plating to components for the aerospace, transport, and chemical processing industries.

The processing of titanium metal occurs in four major steps: reduction of titanium ore into "sponge", a porous form; melting of sponge, or sponge plus a master alloy to form an ingot; primary fabrication, where an ingot is converted into general mill products such as billet, bar, plate, sheet, strip, and tube; and secondary fabrication of finished shapes from mill products.
Because it cannot be readily produced by reduction of its dioxide, titanium metal is obtained by reduction of TiCl with magnesium metal in the Kroll process. The complexity of this batch production in the Kroll process explains the relatively high market value of titanium, despite the Kroll process being less expensive than the Hunter process. To produce the TiCl required by the Kroll process, the dioxide is subjected to carbothermic reduction in the presence of chlorine. In this process, the chlorine gas is passed over a red-hot mixture of rutile or ilmenite in the presence of carbon. After extensive purification by fractional distillation, the TiCl is reduced with 800 °C molten magnesium in an argon atmosphere. Titanium metal can be further purified by the van Arkel–de Boer process, which involves thermal decomposition of titanium tetraiodide.
A more recently developed batch production method, the FFC Cambridge process, consumes titanium dioxide powder (a refined form of rutile) as feedstock and produces titanium metal, either powder or sponge. The process involves fewer steps than the Kroll process and takes less time. If mixed oxide powders are used, the product is an alloy.

Common titanium alloys are made by reduction. For example, cuprotitanium (rutile with copper added is reduced), ferrocarbon titanium (ilmenite reduced with coke in an electric furnace), and manganotitanium (rutile with manganese or manganese oxides) are reduced.

About fifty grades of titanium and titanium alloys are designed and currently used, although only a couple of dozen are readily available commercially. The ASTM International recognizes 31 grades of titanium metal and alloys, of which grades one through four are commercially pure (unalloyed). Those four vary in tensile strength as a function of oxygen content, with grade 1 being the most ductile (lowest tensile strength with an oxygen content of 0.18%), and grade 4 the least ductile (highest tensile strength with an oxygen content of 0.40%). The remaining grades are alloys, each designed for specific properties of ductility, strength, hardness, electrical resistivity, creep resistance, specific corrosion resistance, and combinations thereof.

In addition to the ASTM specifications, titanium alloys are also produced to meet aerospace and military specifications (SAE-AMS, MIL-T), ISO standards, and country-specific specifications, as well as proprietary end-user specifications for aerospace, military, medical, and industrial applications.

Titanium powder is manufactured using a flow production process known as the Armstrong process that is similar to the batch production Hunter process. A stream of titanium tetrachloride gas is added to a stream of molten sodium metal; the products (sodium chloride salt and titanium particles) is filtered from the extra sodium. Titanium is then separated from the salt by water washing. Both sodium and chlorine are recycled to produce and process more titanium tetrachloride.

All welding of titanium must be done in an inert atmosphere of argon or helium to shield it from contamination with atmospheric gases (oxygen, nitrogen, and hydrogen). Contamination causes a variety of conditions, such as embrittlement, which reduce the integrity of the assembly welds and lead to joint failure.

Commercially pure flat product (sheet, plate) can be formed readily, but processing must take into account the fact that the metal has a "memory" and tends to spring back. This is especially true of certain high-strength alloys. Titanium cannot be soldered without first pre-plating it in a metal that is solderable. The metal can be machined with the same equipment and the same processes as stainless steel.

Titanium is used in steel as an alloying element (ferro-titanium) to reduce grain size and as a deoxidizer, and in stainless steel to reduce carbon content. Titanium is often alloyed with aluminium (to refine grain size), vanadium, copper (to harden), iron, manganese, molybdenum, and other metals. Titanium mill products (sheet, plate, bar, wire, forgings, castings) find application in industrial, aerospace, recreational, and emerging markets. Powdered titanium is used in pyrotechnics as a source of bright-burning particles.

About 95% of all titanium ore is destined for refinement into titanium dioxide (), an intensely white permanent pigment used in paints, paper, toothpaste, and plastics. It is also used in cement, in gemstones, as an optical opacifier in paper, and a strengthening agent in graphite composite fishing rods and golf clubs.

Because titanium alloys have high tensile strength to density ratio, high corrosion resistance, fatigue resistance, high crack resistance, and ability to withstand moderately high temperatures without creeping, they are used in aircraft, armour plating, naval ships, spacecraft, and missiles. For these applications, titanium is alloyed with aluminium, zirconium, nickel, vanadium, and other elements to manufacture a variety of components including critical structural parts, fire walls, landing gear, exhaust ducts (helicopters), and hydraulic systems. In fact, about two thirds of all titanium metal produced is used in aircraft engines and frames. The titanium 6AL-4V alloy accounts for almost 50% of all alloys used in aircraft applications.

The Lockheed A-12 and its development the SR-71 "Blackbird" were two of the first aircraft frames where titanium was used, paving the way for much wider use in modern military and commercial aircraft. An estimated 59 metric tons (130,000 pounds) are used in the Boeing 777, 45 in the Boeing 747, 18 in the Boeing 737, 32 in the Airbus A340, 18 in the Airbus A330, and 12 in the Airbus A320. The Airbus A380 may use 77 metric tons, including about 11 tons in the engines. In aero engine applications, titanium is used for rotors, compressor blades, hydraulic system components, and nacelles. An early use in jet engines was for the Orenda Iroquois in the 1950s.

Because titanium is resistant to corrosion by sea water, it is used to make propeller shafts, rigging, and heat exchangers in desalination plants; heater-chillers for salt water aquariums, fishing line and leader, and divers' knives. Titanium is used in the housings and components of ocean-deployed surveillance and monitoring devices for science and the military. The former Soviet Union developed techniques for making submarines with hulls of titanium alloys forging titanium in huge vacuum tubes.

Titanium is used in the walls of the Juno spacecraft's vault to shield on-board electronics.

Welded titanium pipe and process equipment (heat exchangers, tanks, process vessels, valves) are used in the chemical and petrochemical industries primarily for corrosion resistance. Specific alloys are used in oil and gas downhole applications and nickel hydrometallurgy for their high strength (e. g.: titanium beta C alloy), corrosion resistance, or both. The pulp and paper industry uses titanium in process equipment exposed to corrosive media, such as sodium hypochlorite or wet chlorine gas (in the bleachery). Other applications include ultrasonic welding, wave soldering, and sputtering targets.

Titanium tetrachloride (TiCl), a colorless liquid, is important as an intermediate in the process of making TiO and is also used to produce the Ziegler–Natta catalyst. Titanium tetrachloride is also used to iridize glass and, because it fumes strongly in moist air, it is used to make smoke screens.

Titanium metal is used in automotive applications, particularly in automobile and motorcycle racing where low weight and high strength and rigidity are critical. The metal is generally too expensive for the general consumer market, though some late model Corvettes have been manufactured with titanium exhausts, and a Corvette Z06's LT4 supercharged engine uses lightweight, solid titanium intake valves for greater strength and resistance to heat.

Titanium is used in many sporting goods: tennis rackets, golf clubs, lacrosse stick shafts; cricket, hockey, lacrosse, and football helmet grills, and bicycle frames and components. Although not a mainstream material for bicycle production, titanium bikes have been used by racing teams and adventure cyclists.

Titanium alloys are used in spectacle frames that are rather expensive but highly durable, long lasting, light weight, and cause no skin allergies. Many backpackers use titanium equipment, including cookware, eating utensils, lanterns, and tent stakes. Though slightly more expensive than traditional steel or aluminium alternatives, titanium products can be significantly lighter without compromising strength. Titanium horseshoes are preferred to steel by farriers because they are lighter and more durable.

Titanium has occasionally been used in architecture. The 42.5-m (139 foot) Monument to Yuri Gagarin, the first man to travel in space (), as well as the 110-m (360.9 feet) Monument to the Conquerors of Space on top of the Cosmonaut Museum in Moscow are made of titanium for the metal's attractive colour and association with rocketry. The Guggenheim Museum Bilbao and the Cerritos Millennium Library were the first buildings in Europe and North America, respectively, to be sheathed in titanium panels. Titanium sheathing was used in the Frederic C. Hamilton Building in Denver, Colorado.

Because of titanium's superior strength and light weight relative to other metals (steel, stainless steel, and aluminium), and because of recent advances in metalworking techniques, its use has become more widespread in the manufacture of firearms. Primary uses include pistol frames and revolver cylinders. For the same reasons, it is used in the body of laptop computers (for example, in Apple's PowerBook line).

Some upmarket lightweight and corrosion-resistant tools, such as shovels and flashlights, are made of titanium or titanium alloys.

Because of its durability, titanium has become more popular for designer jewelry (particularly, titanium rings). Its inertness makes it a good choice for those with allergies or those who will be wearing the jewelry in environments such as swimming pools. Titanium is also alloyed with gold to produce an alloy that can be marketed as 24-carat gold because the 1% of alloyed Ti is insufficient to require a lesser mark. The resulting alloy is roughly the hardness of 14-carat gold and is more durable than pure 24-carat gold.

Titanium's durability, light weight, and dent and corrosion resistance make it useful for watch cases. Some artists work with titanium to produce sculptures, decorative objects and furniture.

Titanium may be anodized to vary the thickness of the surface oxide layer, causing optical interference fringes and a variety of bright colors. With this coloration and chemical inertness, titanium is a popular metal for body piercing.

Titanium has a minor use in dedicated non-circulating coins and medals. In 1999, Gibraltar released world's first titanium coin for the millennium celebration. The Gold Coast Titans, an Australian rugby league team, award a medal of pure titanium to their player of the year.

Because titanium is biocompatible (non-toxic and not rejected by the body), it has many medical uses, including surgical implements and implants, such as hip balls and sockets (joint replacement) and dental implants that can stay in place for up to 20 years. The titanium is often alloyed with about 4% aluminium or 6% Al and 4% vanadium.

Titanium has the inherent ability to osseointegrate, enabling use in dental implants that can last for over 30 years. This property is also useful for orthopedic implant applications. These benefit from titanium's lower modulus of elasticity (Young's modulus) to more closely match that of the bone that such devices are intended to repair. As a result, skeletal loads are more evenly shared between bone and implant, leading to a lower incidence of bone degradation due to stress shielding and periprosthetic bone fractures, which occur at the boundaries of orthopedic implants. However, titanium alloys' stiffness is still more than twice that of bone, so adjacent bone bears a greatly reduced load and may deteriorate.

Because titanium is non-ferromagnetic, patients with titanium implants can be safely examined with magnetic resonance imaging (convenient for long-term implants). Preparing titanium for implantation in the body involves subjecting it to a high-temperature plasma arc which removes the surface atoms, exposing fresh titanium that is instantly oxidized.

Titanium is used for the surgical instruments used in image-guided surgery, as well as wheelchairs, crutches, and any other products where high strength and low weight are desirable.

Titanium dioxide nanoparticles are widely used in electronics and the delivery of pharmaceuticals and cosmetics.

Because of it is corrosion resistance, containers made of titanium have been studied for the long-term storage of nuclear waste. Containers lasting more than 100,000 years are thought possible with manufacturing conditions that minimize material defects. A titanium "drip shield" could also be installed over containers of other types to enhance their longevity.

The fungal species "Marasmius oreades" and "Hypholoma capnoides" can bioconvert titanium in titanium polluted soils.

Titanium is non-toxic even in large doses and does not play any natural role inside the human body. An estimated quantity of 0.8 milligrams of titanium is ingested by humans each day, but most passes through without being absorbed in the tissues. It does, however, sometimes bio-accumulate in tissues that contain silica. One study indicates a possible connection between titanium and yellow nail syndrome. An unknown mechanism in plants may use titanium to stimulate the production of carbohydrates and encourage growth. This may explain why most plants contain about 1 part per million (ppm) of titanium, food plants have about 2 ppm, and horsetail and nettle contain up to 80 ppm.

As a powder or in the form of metal shavings, titanium metal poses a significant fire hazard and, when heated in air, an explosion hazard. Water and carbon dioxide are ineffective for extinguishing a titanium fire; Class D dry powder agents must be used instead.

When used in the production or handling of chlorine, titanium should not be exposed to dry chlorine gas because it may result in a titanium–chlorine fire. Even wet chlorine presents a fire hazard when extreme weather conditions cause unexpected drying.

Titanium can catch fire when a fresh, non-oxidized surface comes in contact with liquid oxygen. Fresh metal may be exposed when the oxidized surface is struck or scratched with a hard object, or when mechanical strain causes a crack. This poses a limitation to its use in liquid oxygen systems, such as those in the aerospace industry. Because titanium tubing impurities can cause fires when exposed to oxygen, titanium is prohibited in gaseous oxygen respiration systems. Steel tubing is used for high pressure systems (3,000 p.s.i.) and aluminium tubing for low pressure systems.




</doc>
<doc id="30041" url="https://en.wikipedia.org/wiki?curid=30041" title="Technetium">
Technetium

Technetium is a chemical element with symbol Tc and atomic number 43. It is the lightest element whose isotopes are all radioactive; none are stable, excluding the fully ionized state of Tc. Nearly all technetium is produced synthetically, and only about 18000 tons can be found at any given time in the Earth's crust. Naturally occurring technetium is a spontaneous fission product in uranium ore and thorium ore, the most common source, or the product of neutron capture in molybdenum ores. The chemical properties of this silvery gray, crystalline transition metal are intermediate between rhenium and manganese, which it lies between in group 7 of the periodic table. The most common naturally occurring isotope is Tc.

Many of technetium's properties were predicted by Dmitri Mendeleev before the element was discovered. Mendeleev noted a gap in his periodic table and gave the undiscovered element the provisional name "ekamanganese" ("Em"). In 1937, technetium (specifically the technetium-97 isotope) became the first predominantly artificial element to be produced, hence its name (from the Greek , meaning "synthetic or artificial", + 

One short-lived gamma ray-emitting nuclear isomer of technetium—technetium-99m—is used in nuclear medicine for a wide variety of diagnostic tests, such as bone cancer diagnoses. The ground state of this nuclide, technetium-99, is used as a gamma-ray-free source of beta particles. Long-lived technetium isotopes produced commercially are by-products of the fission of uranium-235 in nuclear reactors and are extracted from nuclear fuel rods. Because no isotope of technetium has a half-life longer than 4.2 million years (technetium-98), the 1952 detection of technetium in red giants, which are billions of years old, helped to prove that stars can produce heavier elements.

From the 1860s through 1871, early forms of the periodic table proposed by Dmitri Mendeleev contained a gap between molybdenum (element 42) and ruthenium (element 44). In 1871, Mendeleev predicted this missing element would occupy the empty place below manganese and have similar chemical properties. Mendeleev gave it the provisional name "ekamanganese" (from "eka"-, the Sanskrit word for "one)" because the predicted element was one place down from the known element manganese.

Many early researchers, both before and after the periodic table was published, were eager to be the first to discover and name the missing element. Its location in the table suggested that it should be easier to find than other undiscovered elements.

German chemists Walter Noddack, Otto Berg, and Ida Tacke reported the discovery of element 75 and element 43 in 1925, and named element 43 "masurium" (after Masuria in eastern Prussia, now in Poland, the region where Walter Noddack's family originated). The group bombarded columbite with a beam of electrons and deduced element 43 was present by examining X-ray diffraction spectrograms. The wavelength of the X-rays produced is related to the atomic number by a formula derived by Henry Moseley in 1913. The team claimed to detect a faint X-ray signal at a wavelength produced by element 43. Later experimenters could not replicate the discovery, and it was dismissed as an error for many years. Still, in 1933, a series of articles on the discovery of elements quoted the name "masurium" for element 43. Whether the 1925 team actually did discover element 43 is still debated.

The discovery of element 43 was finally confirmed in a December 1936 experiment at the University of Palermo in Sicily by Carlo Perrier and Emilio Segrè. In mid-1936, Segrè visited the United States, first Columbia University in New York and then the Lawrence Berkeley National Laboratory in California. He persuaded cyclotron inventor Ernest Lawrence to let him take back some discarded cyclotron parts that had become radioactive. Lawrence mailed him a molybdenum foil that had been part of the deflector in the cyclotron.

Segrè enlisted his colleague Perrier to attempt to prove, through comparative chemistry, that the molybdenum activity was indeed from an element with the atomic number 43. In 1937 they succeeded in isolating the isotopes technetium-95m and technetium-97. University of Palermo officials wanted them to name their discovery ""panormium"", after the Latin name for Palermo, "Panormus". In 1947 element 43 was named after the Greek word "τεχνητός", meaning "artificial", since it was the first element to be artificially produced. Segrè returned to Berkeley and met Glenn T. Seaborg. They isolated the metastable isotope technetium-99m, which is now used in some ten million medical diagnostic procedures annually.

In 1952, astronomer Paul W. Merrill in California detected the spectral signature of technetium (specifically wavelengths of 403.1 nm, 423.8 nm, 426.2 nm, and 429.7 nm) in light from S-type red giants. The stars were near the end of their lives, yet were rich in this short-lived element, indicating that it was being produced in the stars by nuclear reactions. This evidence bolstered the hypothesis that heavier elements are the product of nucleosynthesis in stars. More recently, such observations provided evidence that elements are formed by neutron capture in the s-process.

Since that discovery, there have been many searches in terrestrial materials for natural sources of technetium. In 1962, technetium-99 was isolated and identified in pitchblende from the Belgian Congo in extremely small quantities (about 0.2 ng/kg); there it originates as a spontaneous fission product of uranium-238. The Oklo natural nuclear fission reactor contains evidence that significant amounts of technetium-99 were produced and have since decayed into ruthenium-99.

Technetium is a silvery-gray radioactive metal with an appearance similar to platinum, commonly obtained as a gray powder. The crystal structure of the pure metal is hexagonal close-packed. Atomic technetium has characteristic emission lines at these wavelengths of light: 363.3 nm, 403.1 nm, 426.2 nm, 429.7 nm, and 485.3 nm.

The metal form is slightly paramagnetic, meaning its magnetic dipoles align with external magnetic fields, but will assume random orientations once the field is removed. Pure, metallic, single-crystal technetium becomes a type-II superconductor at temperatures below 7.46 K. Below this temperature, technetium has a very high magnetic penetration depth, greater than any other element except niobium.

Technetium is located in the seventh group of the periodic table, between rhenium and manganese. As predicted by the periodic law, its chemical properties are between those two elements. Of the two, technetium more closely resembles rhenium, particularly in its chemical inertness and tendency to form covalent bonds. Unlike manganese, technetium does not readily form cations (ions with a net positive charge). Technetium exhibits nine oxidation states from −1 to +7, with +4, +5, and +7 being the most common. Technetium dissolves in aqua regia, nitric acid, and concentrated sulfuric acid, but it is not soluble in hydrochloric acid of any concentration.

Metallic technetium slowly tarnishes in moist air and, in powder form, burns in oxygen.

Technetium can catalyse the destruction of hydrazine by nitric acid, and this property is due to its multiplicity of valencies. This caused a problem in the separation of plutonium from uranium in nuclear fuel processing, where hydrazine is used as a protective reductant to keep plutonium in the trivalent rather than the more stable tetravalent state. The problem was exacerbated by the mutually-enhanced solvent extraction of technetium and zirconium at the previous stage, and required a process modification.

The most prevalent form of technetium that is easily accessible is sodium pertechnetate, Na[TcO]. The majority of this material is produced by radioactive decay from [MoO]:
Pertechnetate (tetroxidotechnetate) behaves analogously to perchlorate, with which it is isostructural. It is tetrahedral. Unlike permanganate (), it is only a weak oxidizing agent.

Related to pertechnetate is heptoxide. This pale-yellow, volatile solid is produced by oxidation of Tc metal and related precursors:
It is a very rare example of a molecular metal oxide, other examples being OsO and RuO. It adopts a centrosymmetric structure with two types of Tc−O bonds with 167 and 184 pm bond lengths.

Technetium heptoxide hydrolyzes to pertechnetate and pertechnetic acid, depending on the pH: 

Dark red, hygroscopic HTcO is a strong acid. In concentrated sulfuric acid, [TcO] converts to the octahedral form TcO(OH)(HO), the conjugate base of the hypothetical triaquo complex [TcO(HO)].

Technetium forms a dioxide, disulfide, diselenide, and ditelluride. An ill-defined TcS forms upon treating pertechnate with hydrogen sulfide. It thermally decomposes into disulfide and elemental sulfur. Similarly the dioxide can be produced by reduction of the TcO.

Unlike the case for rhenium, a trioxide has not been isolated for technetium. However, TcO has been identified in the gas phase using mass spectrometry.

Technetium forms the simple complex . The potassium salt is isostructural with .

The following binary (containing only two elements) technetium halides are known: TcF, TcF, TcCl, TcBr, TcBr, α-TcCl, β-TcCl, TcI, α-TcCl, and β-TcCl. The oxidation states range from Tc(VI) to Tc(II). Technetium halides exhibit different structure types, such as molecular octahedral complexes, extended chains, layered sheets, and metal clusters arranged in a three-dimensional network. These compounds are produced by combining the metal and halogen or by less direct reactions.

TcCl is obtained by chlorination of Tc metal or TcO Upon heating, TcCl gives the corresponding Tc(III) and Tc(II) chlorides.

The structure of TcCl is composed of infinite zigzag chains of edge-sharing TcCl octahedra. It is isomorphous to transition metal tetrachlorides of zirconium, hafnium, and platinum.

Two polymorphs of technetium trichloride exist, α- and β-TcCl. The α polymorph is also denoted as TcCl. It adopts a confacial bioctahedral structure. It is prepared by treating the chloro-acetate Tc(OCCH)Cl with HCl. Like ReCl, the structure of the α-polymorph consists of triangles with short M-M distances. β-TcCl features octahedral Tc centers, which are organized in pairs, as seen also for molybdenum trichloride. TcBr does not adopt the structure of either trichloride phase. Instead it has the structure of molybdenum tribromide, consisting of chains of confacial octahedra with alternating short and long Tc—Tc contacts. TcI has the same structure as the high temperature phase of TiI, featuring chains of confacial octahedra with equal Tc—Tc contacts.

Several anionic technetium halides are known. The binary tetrahalides can be converted to the hexahalides [TcX] (X = F, Cl, Br, I), which adopt octahedral molecular geometry. More reduced halides form anionic clusters with Tc–Tc bonds. The situation is similar for the related elements of Mo, W, Re. These clusters have the nuclearity Tc, Tc, Tc, and Tc. The more stable Tc and Tc clusters have prism shapes where vertical pairs of Tc atoms are connected by triple bonds and the planar atoms by single bonds. Every technetium atom makes six bonds, and the remaining valence electrons can be saturated by one axial and two bridging ligand halogen atoms such as chlorine or bromine.

Technetium forms a variety of coordination complexes with organic ligands. Many have been well-investigated because of their relevance to nuclear medicine.

Technetium forms a variety of compounds with Tc–C bonds, i.e. organotechnetium complexes. Prominent members of this class are complexes with CO, arene, and cyclopentadienyl ligands. The binary carbonyl Tc(CO) is a white volatile solid. In this molecule, two technetium atoms are bound to each other; each atom is surrounded by octahedra of five carbonyl ligands. The bond length between technetium atoms, 303 pm, is significantly larger than the distance between two atoms in metallic technetium (272 pm). Similar carbonyls are formed by technetium's congeners, manganese and rhenium. Interest in organotechnetium compounds has also been motivated by applications in nuclear medicine. Unusual for other metal carbonyls, Tc forms aquo-carbonyl complexes, prominent being [Tc(CO)(HO)].

Technetium, with atomic number (denoted "Z") 43, is the lowest-numbered element in the periodic table of which all isotopes are radioactive. The second-lightest exclusively radioactive element, promethium, has an atomic number of 61. Atomic nuclei with an odd number of protons are less stable than those with even numbers, even when the total number of nucleons (protons + neutrons) is even, and odd numbered elements have fewer stable isotopes.

The most stable radioactive isotopes are technetium-98 with a half-life of 4.2 million years (Ma), technetium-97 with 2.6 Ma, and technetium-99 with 211,000 years. Thirty other radioisotopes have been characterized with mass numbers ranging from 85 to 118. Most of these have half-lives that are less than an hour, the exceptions being technetium-93 (half-life: 2.73 hours), technetium-94 (half-life: 4.88 hours), technetium-95 (half-life: 20 hours), and technetium-96 (half-life: 4.3 days).

The primary decay mode for isotopes lighter than technetium-98 (Tc) is electron capture, producing molybdenum ("Z" = 42). For technetium-98 and heavier isotopes, the primary mode is beta emission (the emission of an electron or positron), producing ruthenium ("Z" = 44), with the exception that technetium-100 can decay both by beta emission and electron capture.

Technetium also has numerous nuclear isomers, which are isotopes with one or more excited nucleons. Technetium-97m (Tc; 'm' stands for metastability) is the most stable, with a half-life of 91 days (0.0965 MeV). This is followed by technetium-95m (half-life: 61 days, 0.03 MeV), and technetium-99m (half-life: 6.01 hours, 0.142 MeV). Technetium-99m emits only gamma rays and decays to technetium-99.

Technetium-99 (Tc) is a major product of the fission of uranium-235 (U), making it the most common and most readily available isotope of technetium. One gram of technetium-99 produces 6.2×10 disintegrations a second (that is, 0.62 GBq/g).

Technetium occurs naturally in the Earth's crust in minute concentrations of about 0.003 parts per trillion. This totals about 18000 tonnes at any given time, assuming the mass of the Earth's crust is 60000000000000000000006×10 kilograms. Technetium is so rare because technetium-98's half-life is only 4.2 million years. More than a thousand of such periods have passed since the formation of the Earth, so the probability for the survival of even one atom of primordial technetium is effectively zero. However, small amounts exist as spontaneous fission products in uranium ores. A kilogram of uranium contains an estimated 1 nanogram (10 g) of technetium. Some red giant stars with the spectral types S-, M-, and N contain a spectral absorption line indicating the presence of technetium. These red-giants are known informally as technetium stars.

In contrast to the rare natural occurrence, bulk quantities of technetium-99 are produced each year from spent nuclear fuel rods, which contain various fission products. The fission of a gram of uranium-235 in nuclear reactors yields 27 mg of technetium-99, giving technetium a fission product yield of 6.1%. Other fissile isotopes produce similar yields of technetium, such as 4.9% from uranium-233 and 6.21% from plutonium-239. An estimated 49,000 TBq (78 metric tons) of technetium was produced in nuclear reactors between 1983 and 1994, by far the dominant source of terrestrial technetium. Only a fraction of the production is used commercially.

Technetium-99 is produced by the nuclear fission of both uranium-235 and plutonium-239. It is therefore present in radioactive waste and in the nuclear fallout of fission bomb explosions. Its decay, measured in becquerels per amount of spent fuel, is the dominant contributor to nuclear waste radioactivity after about 10 to 10 years after the creation of the nuclear waste. From 1945 to 1994, an estimated 160 TBq (about 250 kg) of technetium-99 was released into the environment during atmospheric nuclear tests. The amount of technetium-99 from nuclear reactors released into the environment up to 1986 is on the order of 1000 TBq (about 1600 kg), primarily by nuclear fuel reprocessing; most of this was discharged into the sea. Reprocessing methods have reduced emissions since then, but as of 2005 the primary release of technetium-99 into the environment is by the Sellafield plant, which released an estimated 550 TBq (about 900 kg) from 1995–1999 into the Irish Sea. From 2000 onwards the amount has been limited by regulation to 90 TBq (about 140 kg) per year. Discharge of technetium into the sea resulted in contamination of some seafood with minuscule quantities of this element. For example, European lobster and fish from west Cumbria contain about 1 Bq/kg of technetium.

The metastable isotope technetium-99m is continuously produced as a fission product from the fission of uranium or plutonium in nuclear reactors:

Because used fuel is allowed to stand for several years before reprocessing, all molybdenum-99 and technetium-99m is decayed by the time that the fission products are separated from the major actinides in conventional nuclear reprocessing. The liquid left after plutonium–uranium extraction (PUREX) contains a high concentration of technetium as but almost all of this is technetium-99, not technetium-99m.

The vast majority of the technetium-99m used in medical work is produced by irradiating dedicated highly enriched uranium targets in a reactor, extracting molybdenum-99 from the targets in reprocessing facilities, and recovering at the diagnostic center the technetium-99m produced upon decay of molybdenum-99. Molybdenum-99 in the form of molybdate is adsorbed onto acid alumina () in a shielded column chromatograph inside a technetium-99m generator ("technetium cow", also occasionally called a "molybdenum cow"). Molybdenum-99 has a half-life of 67 hours, so short-lived technetium-99m (half-life: 6 hours), which results from its decay, is being constantly produced. The soluble pertechnetate can then be chemically extracted by elution using a saline solution. A drawback of this process is that it requires targets containing uranium-235, which are subject to the security precautions of fissile materials.

Almost two-thirds of the world's supply comes from two reactors; the National Research Universal Reactor at Chalk River Laboratories in Ontario, Canada, and the High Flux Reactor at Nuclear Research and Consultancy Group in Petten, Netherlands. All major reactors that produce technetium-99m were built in the 1960s and are close to the end of life. The two new Canadian Multipurpose Applied Physics Lattice Experiment reactors planned and built to produce 200% of the demand of technetium-99m relieved all other producers from building their own reactors. With the cancellation of the already tested reactors in 2008, the future supply of technetium-99m became problematic.

The Chalk River reactor was shut down for maintenance in August 2009, and reopened in August 2010. The Petten reactor had a 6-month scheduled maintenance shutdown on Friday, February 19, 2010, and reopened September 2010. With millions of procedures relying on technetium-99m every year, the low supply has left a gap, leaving some practitioners to revert to techniques not used for 20 years. Somewhat allaying this issue is an announcement from the Polish Maria research reactor that they have developed a technique to isolate technetium.

The long half-life of technetium-99 and its potential to form anionic species creates a major concern for long-term disposal of radioactive waste. Many of the processes designed to remove fission products in reprocessing plants aim at cationic species such as caesium (e.g., caesium-137) and strontium (e.g., strontium-90). Hence the pertechnetate escapes through those processes. Current disposal options favor burial in continental, geologically stable rock. The primary danger with such practice is the likelihood that the waste will contact water, which could leach radioactive contamination into the environment. The anionic pertechnetate and iodide tend not to adsorb into the surfaces of minerals, and are likely to be washed away. By comparison plutonium, uranium, and caesium tend to bind to soil particles. Technetium could be immobilized by some environments, such as microbial activity in lake bottom sediments, and the environmental chemistry of technetium is an area of active research.

An alternative disposal method, transmutation, has been demonstrated at CERN for technetium-99. In this process, the technetium (technetium-99 as a metal target) is bombarded with neutrons to form the short-lived technetium-100 (half-life = 16 seconds) which decays by beta decay to ruthenium-100. If recovery of usable ruthenium is a goal, an extremely pure technetium target is needed; if small traces of the minor actinides such as americium and curium are present in the target, they are likely to undergo fission and form more fission products which increase the radioactivity of the irradiated target. The formation of ruthenium-106 (half-life 374 days) from the 'fresh fission' is likely to increase the activity of the final ruthenium metal, which will then require a longer cooling time after irradiation before the ruthenium can be used.

The actual separation of technetium-99 from spent nuclear fuel is a long process. During fuel reprocessing, it comes out as a component of the highly radioactive waste liquid. After sitting for several years, the radioactivity reduces to a level where extraction of the long-lived isotopes, including technetium-99, becomes feasible. A series of chemical processes yields technetium-99 metal of high purity.

Molybdenum-99, which decays to form technetium-99m, can be formed by the neutron activation of molybdenum-98. When needed, other technetium isotopes are not produced in significant quantities by fission, but are manufactured by neutron irradiation of parent isotopes (for example, technetium-97 can be made by neutron irradiation of ruthenium-96).

The feasibility of technetium-99m production with the 22-MeV-proton bombardment of a molybdenum-100 target in medical cyclotrons following the reaction Mo(p,2n)Tc was demonstrated in 1971. The recent shortages of medical technetium-99m reignited the interest in its production by proton bombardment of isotopically-enriched (>99.5%) molybdenum-100 targets. Other techniques are being investigated for obtaining molybdenum-99 from molybdenum-100 via (n,2n) or (γ,n) reactions in particle accelerators.

Technetium-99m ("m" indicates that this is a metastable nuclear isomer) is used in radioactive isotope medical tests. For example Technetium-99m is a radioactive tracer that medical imaging equipment tracks in the human body. It is well suited to the role because it emits readily detectable 140 keV gamma rays, and its half-life is 6.01 hours (meaning that about 94% of it decays to technetium-99 in 24 hours). The chemistry of technetium allows it to be bound to a variety of biochemical compounds, each of which determines how it is metabolized and deposited in the body, and this single isotope can be used for a multitude of diagnostic tests. More than 50 common radiopharmaceuticals are based on technetium-99m for imaging and functional studies of the brain, heart muscle, thyroid, lungs, liver, gall bladder, kidneys, skeleton, blood, and tumors.

The longer-lived isotope, technetium-95m with a half-life of 61 days, is used as a radioactive tracer to study the movement of technetium in the environment and in plant and animal systems.

Technetium-99 decays almost entirely by beta decay, emitting beta particles with consistent low energies and no accompanying gamma rays. Moreover, its long half-life means that this emission decreases very slowly with time. It can also be extracted to a high chemical and isotopic purity from radioactive waste. For these reasons, it is a National Institute of Standards and Technology (NIST) standard beta emitter, and is used for equipment calibration. Technetium-99 has also been proposed for optoelectronic devices and nanoscale nuclear batteries.

Like rhenium and palladium, technetium can serve as a catalyst. In processes such as the dehydrogenation of isopropyl alcohol, it is a far more effective catalyst than either rhenium or palladium. However, its radioactivity is a major problem in safe catalytic applications.

When steel is immersed in water, adding a small concentration (55 ppm) of potassium pertechnetate(VII) to the water protects the steel from corrosion, even if the temperature is raised to . For this reason, pertechnetate has been used as an anodic corrosion inhibitor for steel, although technetium's radioactivity poses problems that limit this application to self-contained systems. While (for example) can also inhibit corrosion, it requires a concentration ten times as high. In one experiment, a specimen of carbon steel was kept in an aqueous solution of pertechnetate for 20 years and was still uncorroded. The mechanism by which pertechnetate prevents corrosion is not well understood, but seems to involve the reversible formation of a thin surface layer (passivation). One theory holds that the pertechnetate reacts with the steel surface to form a layer of technetium dioxide which prevents further corrosion; the same effect explains how iron powder can be used to remove pertechnetate from water. (Activated carbon can also be used for the same purpose.) The effect disappears rapidly if the concentration of pertechnetate falls below the minimum concentration or if too high a concentration of other ions is added.

As noted, the radioactive nature of technetium (3 MBq/L at the concentrations required) makes this corrosion protection impractical in almost all situations. Nevertheless, corrosion protection by pertechnetate ions was proposed (but never adopted) for use in boiling water reactors.

Technetium plays no natural biological role and is not normally found in the human body. Technetium is produced in quantity by nuclear fission, and spreads more readily than many radionuclides. It appears to have low chemical toxicity. For example, no significant change in blood formula, body and organ weights, and food consumption could be detected for rats which ingested up to 15 µg of technetium-99 per gram of food for several weeks. The radiological toxicity of technetium (per unit of mass) is a function of compound, type of radiation for the isotope in question, and the isotope's half-life.

All isotopes of technetium must be handled carefully. The most common isotope, technetium-99, is a weak beta emitter; such radiation is stopped by the walls of laboratory glassware. The primary hazard when working with technetium is inhalation of dust; such radioactive contamination in the lungs can pose a significant cancer risk. For most work, careful handling in a fume hood is sufficient, and a glove box is not needed.





</doc>
<doc id="30042" url="https://en.wikipedia.org/wiki?curid=30042" title="Tin">
Tin

Tin is a chemical element with the symbol Sn (from ) and atomic number 50. It is a post-transition metal in group 14 of the periodic table. It is obtained chiefly from the mineral cassiterite, which contains stannic oxide, SnO. Tin shows a chemical similarity to both of its neighbors in group 14, germanium and lead, and has two main oxidation states, +2 and the slightly more stable +4. Tin is the 49th most abundant element and has, with 10 stable isotopes, the largest number of stable isotopes in the periodic table, thanks to its magic number of protons. It has two main allotropes: at room temperature, the stable allotrope is β-tin, a silvery-white, malleable metal, but at low temperatures it transforms into the less dense grey α-tin, which has the diamond cubic structure. Metallic tin does not easily oxidize in air.

The first tin alloy used on a large scale was bronze, made of tin and copper, from as early as 3000 BC. After 600 BC, pure metallic tin was produced. Pewter, which is an alloy of 85–90% tin with the remainder commonly consisting of copper, antimony, and lead, was used for flatware from the Bronze Age until the 20th century. In modern times, tin is used in many alloys, most notably tin/lead soft solders, which are typically 60% or more tin and in the manufacture of transparent, electrically conducting films of indium tin oxide in optoelectronic applications. Another large application for tin is corrosion-resistant tin plating of steel. Because of the low toxicity of inorganic tin, tin-plated steel is widely used for food packaging as tin cans. However, some organotin compounds can be almost as toxic as cyanide.

Tin is a soft, malleable, ductile and highly crystalline silvery-white metal. When a bar of tin is bent, a crackling sound known as the "tin cry" can be heard from the twinning of the crystals. Tin melts at low temperatures of about , the lowest in group 14. The melting point is further lowered to for 11 nm particles.
β-tin (the metallic form, or white tin, BCT structure), which is stable at and above room temperature, is malleable. In contrast, α-tin (nonmetallic form, or gray tin), which is stable below , is brittle. α-tin has a diamond cubic crystal structure, similar to diamond, silicon or germanium. α-tin has no metallic properties at all because its atoms form a covalent structure in which electrons cannot move freely. It is a dull-gray powdery material with no common uses other than a few specialized semiconductor applications. These two allotropes, α-tin and β-tin, are more commonly known as "gray tin" and "white tin", respectively. Two more allotropes, γ and σ, exist at temperatures above   and pressures above several GPa. In cold conditions, β-tin tends to transform spontaneously into α-tin, a phenomenon known as "tin pest". Although the α-β transformation temperature is nominally , impurities (e.g. Al, Zn, etc.) lower the transition temperature well below and, on the addition of Sb or Bi, the transformation might not occur at all, increasing the durability of the tin.

Commercial grades of tin (99.8%) resist transformation because of the inhibiting effect of the small amounts of bismuth, antimony, lead, and silver present as impurities. Alloying elements such as copper, antimony, bismuth, cadmium, and silver increase its hardness. Tin tends rather easily to form hard, brittle intermetallic phases, which are often undesirable. It does not form wide solid solution ranges in other metals in general, and few elements have appreciable solid solubility in tin. Simple eutectic systems, however, occur with bismuth, gallium, lead, thallium and zinc.

Tin becomes a superconductor below 3.72 K and was one of the first superconductors to be studied; the Meissner effect, one of the characteristic features of superconductors, was first discovered in superconducting tin crystals.

Tin resists corrosion from water, but can be attacked by acids and alkalis. Tin can be highly polished and is used as a protective coat for other metals. A protective oxide (passivation) layer prevents further oxidation, the same that forms on pewter and other tin alloys. Tin acts as a catalyst when oxygen is in solution and helps to accelerate the chemical reaction.

Tin has ten stable isotopes, with atomic masses of 112, 114 through 120, 122 and 124, the greatest number of any element. Of these, the most abundant are Sn (almost a third of all tin), Sn, and Sn, while the least abundant is Sn. The isotopes with even mass numbers have no nuclear spin, while those with odd have a spin of +1/2. Tin, with its three common isotopes Sn, Sn and Sn, is among the easiest elements to detect and analyze by NMR spectroscopy, and its chemical shifts are referenced against .

This large number of stable isotopes is thought to be a direct result of the atomic number 50, a "magic number" in nuclear physics. Tin also occurs in 29 unstable isotopes, encompassing all the remaining atomic masses from 99 to 137. Apart from Sn, with a half-life of 230,000 years, all the radioisotopes have a half-life of less than a year. The radioactive Sn, discovered in 1994, and Sn are one of the few nuclides with a "doubly magic" nucleus: despite being unstable, having very lopsided proton-neutron ratios, they represent endpoints beyond which stability drops off rapidly. Another 30 metastable isomers have been characterized for isotopes between 111 and 131, the most stable being Sn with a half-life of 43.9 years.

The relative differences in the abundances of tin's stable isotopes can be explained by their different modes of formation in stellar nucleosynthesis. Sn through Sn inclusive are formed in the s-process (slow neutron capture) in most stars and hence they are the most common isotopes, while Sn and Sn are only formed in the r-process (rapid neutron capture) in supernovae and are less common. (The isotopes Sn through Sn also receive contributions from the r-process.) Finally, the rarest proton-rich isotopes, Sn, Sn, and Sn, cannot be made in significant amounts in the s- or r-processes and are considered among the p-nuclei, whose origins are not well understood yet. Some speculated mechanisms for their formation include proton capture as well as photodisintegration, although Sn might also be partially produced in the s-process, both directly, and as the daughter of long-lived In.

The word "tin" is shared among Germanic languages and can be traced back to reconstructed Proto-Germanic "*tin-om"; cognates include German ', Swedish ' and Dutch '. It is not found in other branches of Indo-European, except by borrowing from Germanic (e.g., Irish ' from English).

The Latin name ' originally meant an alloy of silver and lead, and came to mean 'tin' in the 4th century BC—the earlier Latin word for it was ', or "white lead". ' apparently came from an earlier ' (meaning the same substance), the origin of the Romance and Celtic terms for "tin". The origin of '/' is unknown; it may be pre-Indo-European.

The ' speculates on the contrary that ' is derived from (the ancestor of) Cornish "", and is proof that Cornwall in the first centuries AD was the main source of tin.

Tin extraction and use can be dated to the beginnings of the Bronze Age around 3000 BC, when it was observed that copper objects formed of polymetallic ores with different metal contents had different physical properties. The earliest bronze objects had a tin or arsenic content of less than 2% and are therefore believed to be the result of unintentional alloying due to trace metal content in the copper ore. The addition of a second metal to copper increases its hardness, lowers the melting temperature, and improves the casting process by producing a more fluid melt that cools to a denser, less spongy metal. This was an important innovation that allowed for the much more complex shapes cast in closed moulds of the Bronze Age. Arsenical bronze objects appear first in the Near East where arsenic is commonly found in association with copper ore, but the health risks were quickly realized and the quest for sources of the much less hazardous tin ores began early in the Bronze Age. This created the demand for rare tin metal and formed a trade network that linked the distant sources of tin to the markets of Bronze Age cultures.

Cassiterite (SnO), the tin oxide form of tin, was most likely the original source of tin in ancient times. Other forms of tin ores are less abundant sulfides such as stannite that require a more involved smelting process. Cassiterite often accumulates in alluvial channels as placer deposits because it is harder, heavier, and more chemically resistant than the accompanying granite. Cassiterite is usually black or generally dark in color, and these deposits can be easily seen in river banks. Alluvial (placer) deposits could be easily collected and separated by methods similar to gold panning.

In the great majority of its compounds, tin has the oxidation state II or IV.

Halide compounds are known for both oxidation states. For Sn(IV), all four halides are well known: SnF, SnCl, SnBr, and SnI. The three heavier members are volatile molecular compounds, whereas the tetrafluoride is polymeric. All four halides are known for Sn(II) also: SnF, SnCl, SnBr, and SnI. All are polymeric solids. Of these eight compounds, only the iodides are colored.

Tin(II) chloride (also known as stannous chloride) is the most important tin halide in a commercial sense. Illustrating the routes to such compounds, chlorine reacts with tin metal to give SnCl whereas the reaction of hydrochloric acid and tin produces SnCl and hydrogen gas. Alternatively SnCl and Sn combine to stannous chloride by a process called comproportionation:

Tin can form many oxides, sulfides, and other chalcogenide derivatives. The dioxide SnO (cassiterite) forms when tin is heated in the presence of air. SnO is amphoteric, which means that it dissolves in both acidic and basic solutions. Stannates with the structure [Sn(OH)], like K[Sn(OH)], are also known, though the free stannic acid H[Sn(OH)] is unknown.

Sulfides of tin exist in both the +2 and +4 oxidation states: tin(II) sulfide and tin(IV) sulfide (mosaic gold).
Stannane (SnH), with tin in the +4 oxidation state, is unstable. Organotin hydrides are however well known, e.g. tributyltin hydride (Sn(CH)H). These compound release transient tributyl tin radicals, which are rare examples of compounds of tin(III).

Organotin compounds, sometimes called stannanes, are chemical compounds with tin–carbon bonds. Of the compounds of tin, the organic derivatives are the most useful commercially. Some organotin compounds are highly toxic and have been used as biocides. The first organotin compound to be reported was diethyltin diiodide ((CH)SnI), reported by Edward Frankland in 1849.

Most organotin compounds are colorless liquids or solids that are stable to air and water. They adopt tetrahedral geometry. Tetraalkyl- and tetraaryltin compounds can be prepared using Grignard reagents:
The mixed halide-alkyls, which are more common and more important commercially than the tetraorgano derivatives, are prepared by redistribution reactions:

Divalent organotin compounds are uncommon, although more common than related divalent organogermanium and organosilicon compounds. The greater stabilization enjoyed by Sn(II) is attributed to the "inert pair effect". Organotin(II) compounds include both stannylenes (formula: RSn, as seen for singlet carbenes) and distannylenes (RSn), which are roughly equivalent to alkenes. Both classes exhibit unusual reactions.

Tin is generated via the long s-process in low-to-medium mass stars (with masses of 0.6 to 10 times that of Sun), and finally by beta decay of the heavy isotopes of indium.

Tin is the 49th most abundant element in Earth's crust, representing 2 ppm compared with 75 ppm for zinc, 50 ppm for copper, and 14 ppm for lead.

Tin does not occur as the native element but must be extracted from various ores. Cassiterite (SnO) is the only commercially important source of tin, although small quantities of tin are recovered from complex sulfides such as stannite, cylindrite, franckeite, canfieldite, and teallite. Minerals with tin are almost always associated with granite rock, usually at a level of 1% tin oxide content.

Because of the higher specific gravity of tin dioxide, about 80% of mined tin is from secondary deposits found downstream from the primary lodes. Tin is often recovered from granules washed downstream in the past and deposited in valleys or the sea. The most economical ways of mining tin are by dredging, hydraulicking, or open pits. Most of the world's tin is produced from placer deposits, which can contain as little as 0.015% tin.

About 253,000 tonnes of tin have been mined in 2011, mostly in China (110,000 t), Indonesia (51,000 t), Peru (34,600 t), Bolivia (20,700 t) and Brazil (12,000 t). Estimates of tin production have historically varied with the dynamics of economic feasibility and the development of mining technologies, but it is estimated that, at current consumption rates and technologies, the Earth will run out of mine-able tin in 40 years. Lester Brown has suggested tin could run out within 20 years based on an extremely conservative extrapolation of 2% growth per year.
Secondary, or scrap, tin is also an important source of the metal. Recovery of tin through secondary production, or recycling of scrap tin, is increasing rapidly. Whereas the United States has neither mined since 1993 nor smelted tin since 1989, it was the largest secondary producer, recycling nearly 14,000 tonnes in 2006.

New deposits are reported in southern Mongolia, and in 2009, new deposits of tin were discovered in Colombia by the Seminole Group Colombia CI, SAS.

Tin is produced by carbothermic reduction of the oxide ore with carbon or coke. Both reverberatory furnace and electric furnace can be used.

The ten largest companies produced most of the world's tin in 2007. 

Most of the world's tin is traded on the London Metal Exchange (LME), from 8 countries, under 17 brands.

An International Tin Council was established in 1947 to control the price of tin, until it collapsed in 1985. In 1984, an "Association of Tin Producing Countries" was created, with Australia, Bolivia, Indonesia, Malaysia, Nigeria, Thailand, and Zaire as members.

Tin is unique among other mineral commodities because of the complex agreements between producer countries and consumer countries dating back to 1921. The earlier agreements tended to be somewhat informal and sporadic and led to the "First International Tin Agreement" in 1956, the first of a continuously numbered series that effectively collapsed in 1985. Through this series of agreements, the International Tin Council (ITC) had a considerable effect on tin prices. The ITC supported the price of tin during periods of low prices by buying tin for its buffer stockpile and was able to restrain the price during periods of high prices by selling tin from the stockpile. This was an anti-free-market approach, designed to assure a sufficient flow of tin to consumer countries and a profit for producer countries. However, the buffer stockpile was not sufficiently large, and during most of those 29 years tin prices rose, sometimes sharply, especially from 1973 through 1980 when rampant inflation plagued many world economies.

During the late 1970s and early 1980s, the U.S. Government tin stockpile was in an aggressive selling mode, partly to take advantage of the historically high tin prices. The sharp recession of 1981–82 proved to be quite harsh on the tin industry. Tin consumption declined dramatically. The ITC was able to avoid truly steep declines through accelerated buying for its buffer stockpile; this activity required the ITC to borrow extensively from banks and metal trading firms to augment its resources. The ITC continued to borrow until late 1985 when it reached its credit limit. Immediately, a major "tin crisis" followed — tin was delisted from trading on the London Metal Exchange for about three years, the ITC dissolved soon afterward, and the price of tin, now in a free-market environment, plummeted sharply to $4 per pound and remained at that level through the 1990s. The price increased again by 2010 with a rebound in consumption following the 2008–09 world economic crisis, accompanying restocking and continued growth in consumption by the world's developing economies.

London Metal Exchange (LME) is the principal trading site for tin. Other tin contract markets are Kuala Lumpur Tin Market (KLTM) and Indonesia Tin Exchange (INATIN).

The price per kg over years:

In 2006, about half of all tin produced was used in solder. The rest was divided between tin plating, tin chemicals, brass and bronze alloys, and niche uses.

Tin has long been used in alloys with lead as solder, in amounts 5 to 70% w/w. Tin with lead forms a eutectic mixture at the weight proportion of 61.9% tin and 38.1% lead (the atomic proportion: 73.9% tin and 26.1% lead), with melting temperature of 183°C (361.4°F) . Such solders are primarily used for joining pipes or electric circuits. Since the European Union Waste Electrical and Electronic Equipment Directive (WEEE Directive) and Restriction of Hazardous Substances Directive came into effect on 1 July 2006, the lead content in such alloys has decreased. Replacing lead has many problems, including a higher melting point, and the formation of tin whiskers causing electrical problems. Tin pest can occur in lead-free solders, leading to loss of the soldered joint. Replacement alloys are rapidly being found, although problems of joint integrity remain.

Tin bonds readily to iron and is used for coating lead, zinc and steel to prevent corrosion. Tin-plated steel containers are widely used for food preservation, and this forms a large part of the market for metallic tin. A tinplate canister for preserving food was first manufactured in London in 1812. Speakers of British English call them "tins", while speakers of American English call them "cans" or "tin cans". One derivation of such use is the slang term "tinnie" or "tinny", meaning "can of beer" in Australia. The tin whistle is so called because it was first mass-produced in tin-plated steel. Copper cooking vessels such as saucepans and frying pans are frequently lined with a thin plating of tin, since the combination of acid foods with copper can be toxic.

Tin in combination with other elements forms a wide variety of useful alloys. Tin is most commonly alloyed with copper. Pewter is 85–99% tin; bearing metal has a high percentage of tin as well. Bronze is mostly copper (12% tin), while addition of phosphorus gives phosphor bronze. Bell metal is also a copper-tin alloy, containing 22% tin. Tin has sometimes been used in coinage; for example, it once formed a single-digit percentage (usually five percent or less) of American and Canadian pennies. Because copper is often the major metal in such coins, sometimes including zinc, these could be called bronze and/or brass alloys.

The niobium-tin compound NbSn is commercially used in coils of superconducting magnets for its high critical temperature (18 K) and critical magnetic field (25 T). A superconducting magnet weighing as little as two kilograms is capable of the magnetic field of a conventional electromagnet weighing tons.

A small percentage of tin is added to zirconium alloys for the cladding of nuclear fuel.

Most metal pipes in a pipe organ are of a tin/lead alloy, with 50/50 being the most common composition. The proportion of tin in the pipe defines the pipe's tone, since tin has a desirable tonal resonance. When a tin/lead alloy cools, the lead cools slightly faster and produces a mottled or spotted effect. This metal alloy is referred to as spotted metal. Major advantages of using tin for pipes include its appearance, its workability, and resistance to corrosion.

The oxides of indium and tin are electrically conductive and transparent, and are used to make transparent electrically conducting films with applications in Optoelectronics devices such as liquid crystal displays.

Punched tin-plated steel, also called pierced tin, is an artisan technique originating in central Europe for creating housewares that are both functional and decorative. Decorative piercing designs exist in a wide variety, based on local tradition and the artisan's personal creations. Punched tin lanterns are the most common application of this artisan technique. The light of a candle shining through the pierced design creates a decorative light pattern in the room where it sits. Lanterns and other punched tin articles were created in the New World from the earliest European settlement. A well-known example is the Revere lantern, named after Paul Revere.

Before the modern era, in some areas of the Alps, a goat or sheep's horn would be sharpened and a tin panel would be punched out using the alphabet and numbers from one to nine. This learning tool was known appropriately as "the horn". Modern reproductions are decorated with such motifs as hearts and tulips.

In America, pie safes and food safes were in use in the days before refrigeration. These were wooden cupboards of various styles and sizes – either floor standing or hanging cupboards meant to discourage vermin and insects and to keep dust from perishable foodstuffs. These cabinets had tinplate inserts in the doors and sometimes in the sides, punched out by the homeowner, cabinetmaker or a tinsmith in varying designs to allow for air circulation while excluding flies. Modern reproductions of these articles remain popular in North America.

Window glass is most often made by floating molten glass on molten tin (float glass), resulting in a flat and flawless surface. This is also called the "Pilkington process".

Tin is also used as a negative electrode in advanced Li-ion batteries. Its application is somewhat limited by the fact that some tin surfaces catalyze decomposition of carbonate-based electrolytes used in Li-ion batteries.

Tin(II) fluoride is added to some dental care products as stannous fluoride (SnF). Tin(II) fluoride can be mixed with calcium abrasives while the more common sodium fluoride gradually becomes biologically inactive in the presence of calcium compounds. It has also been shown to be more effective than sodium fluoride in controlling gingivitis.

Of all the chemical compounds of tin, the organotin compounds are most heavily used. Worldwide industrial production probably exceeds 50,000 tonnes.

The major commercial application of organotin compounds is in the stabilization of PVC plastics. In the absence of such stabilizers, PVC would otherwise rapidly degrade under heat, light, and atmospheric oxygen, resulting in discolored, brittle products. Tin scavenges labile chloride ions (Cl), which would otherwise initiate loss of HCl from the plastic material. Typical tin compounds are carboxylic acid derivatives of dibutyltin dichloride, such as the dilaurate.

Some organotin compounds are relatively toxic, with both advantages and problems. They are used for biocidal properties as fungicides, pesticides, algaecides, wood preservatives, and antifouling agents. Tributyltin oxide is used as a wood preservative. Tributyltin was used as additive for ship paint to prevent growth of marine organisms on ships, with use declining after organotin compounds were recognized as persistent organic pollutants with an extremely high toxicity for some marine organisms (the dog whelk, for example). The EU banned the use of organotin compounds in 2003, while concerns over the toxicity of these compounds to marine life and damage to the reproduction and growth of some marine species (some reports describe biological effects to marine life at a concentration of 1 nanogram per liter) have led to a worldwide ban by the International Maritime Organization. Many nations now restrict the use of organotin compounds to vessels greater than long.

Some tin reagents are useful in organic chemistry. In the largest application, stannous chloride is a common reducing agent for the conversion of nitro and oxime groups to amines. The Stille reaction couples organotin compounds with organic halides or pseudohalides.

Tin forms several inter-metallic phases with lithium metal, making it a potentially attractive material for battery applications. Large volumetric expansion of tin upon alloying with lithium and instability of the tin-organic electrolyte interface at low electrochemical potentials are the greatest challenges to employment in commercial cells. The problem was partially solved by Sony. Tin inter-metallic compound with cobalt and carbon has been implemented by Sony in its Nexelion cells released in the late 2000s. The composition of the active material is approximately SnCoC. Recent research showed that only some crystalline facets of tetragonal (beta) Sn are responsible for undesirable electrochemical activity.

Cases of poisoning from tin metal, its oxides, and its salts are almost unknown. On the other hand, certain organotin compounds are almost as toxic as cyanide.

Exposure to tin in the workplace can occur by inhalation, skin contact, and eye contact. The Occupational Safety and Health Administration (OSHA) has set the legal limit (permissible exposure limit) for tin exposure in the workplace as 2 mg/m over an 8-hour workday. The National Institute for Occupational Safety and Health (NIOSH) has determined a recommended exposure limit (REL) of 2 mg/m over an 8-hour workday. At levels of 100 mg/m, tin is immediately dangerous to life and health.





</doc>
<doc id="30043" url="https://en.wikipedia.org/wiki?curid=30043" title="Tellurium">
Tellurium

Tellurium is a chemical element with symbol Te and atomic number 52. It is a brittle, mildly toxic, rare, silver-white metalloid. Tellurium is chemically related to selenium and sulfur. It is occasionally found in native form as elemental crystals. Tellurium is far more common in the universe as a whole than on Earth. Its extreme rarity in the Earth's crust, comparable to that of platinum, is due partly to its high atomic number, but also to its formation of a volatile hydride which caused it to be lost to space as a gas during the hot nebular formation of the planet.

Tellurium-bearing compounds were first discovered in 1782 in a gold mine in Zlatna, Romania by Austrian mineralogist Franz-Joseph Müller von Reichenstein, although it was Martin Heinrich Klaproth who named the new element in 1798 after the Latin word for "earth", "tellus". Gold telluride minerals are the most notable natural gold compounds. However, they are not a commercially significant source of tellurium itself, which is normally extracted as a by-product of copper and lead production.

Commercially, the primary use of tellurium is copper and steel alloys, where it improves machinability. Applications in CdTe solar panels and semiconductors also consume a considerable portion of tellurium production.

Tellurium has no biological function, although fungi can use it in place of sulfur and selenium in amino acids such as tellurocysteine and telluromethionine. In humans, tellurium is partly metabolized into dimethyl telluride, (CH)Te, a gas with a garlic-like odor exhaled in the breath of victims of tellurium exposure or poisoning.

Tellurium has two allotropes, crystalline and amorphous. When crystalline, tellurium is silvery-white with a metallic luster. It is a brittle and easily pulverized metalloid. Amorphous tellurium is a black-brown powder prepared by precipitating it from a solution of tellurous acid or telluric acid (Te(OH)). Tellurium is a semiconductor that shows a greater electrical conductivity in certain directions depending on atomic alignment; the conductivity increases slightly when exposed to light (photoconductivity). When molten, tellurium is corrosive to copper, iron, and stainless steel. Of the chalcogens, tellurium has the highest melting and boiling points, at and , respectively.

Tellurium adopts a polymeric structure consisting of zig-zag chains of Te atoms. This gray material resists oxidation by air and is not volatile.

Naturally occurring tellurium has eight isotopes. Six of those isotopes, Te, Te, Te, Te, Te, and Te, are stable. The other two, Te and Te, have been found to be slightly radioactive, with extremely long half-lives, including 2.2 × 10 years for Te. This is the longest known half-life among all radionuclides and is about 160 trillion (10) times the age of the known universe. Stable isotopes comprise only 33.2% of naturally occurring tellurium.

A further 30 artificial radioisotopes of tellurium are known, with atomic masses ranging from 105 to 142 and with half-lives of 19 days or less. Also, 17 nuclear isomers are known, with half-lives up to 154 days. Tellurium (Te to Te ) are among the lightest elements known to undergo alpha decay.

The atomic mass of tellurium (127.60 g·mol) exceeds that of iodine (126.90 g·mol), the next element in the periodic table.

With an abundance in the Earth's crust comparable to that of platinum (about 1 µg/kg), tellurium is one of the rarest stable solid elements. In comparison, even the rarest of the stable lanthanides have crustal abundances of 500 µg/kg (see Abundance of the chemical elements).

This rarity of tellurium in the Earth's crust is not a reflection of its cosmic abundance. Tellurium is more abundant than rubidium in the cosmos, though rubidium is 10,000 times more abundant in the Earth's crust. The rarity of tellurium on Earth is thought to be caused by conditions during the formation of the Earth, when the stable form of certain elements, in the absence of oxygen and water, was controlled by the reductive power of free hydrogen. Under this scenario, certain elements that form volatile hydrides, such as tellurium, were severely depleted through evaporation of these hydrides. Tellurium and selenium are the heavy elements most depleted by this process.

Tellurium is sometimes found in its native (i.e., elemental) form, but is more often found as the tellurides of gold such as calaverite and krennerite (two different polymorphs of AuTe), petzite, AgAuTe, and sylvanite, AgAuTe. The city of Telluride, Colorado, was named in hope of a strike of gold telluride (which never materialized, though gold metal ore was found). Gold itself is usually found uncombined, but when found as a chemical compound, it is most often combined with tellurium.

Although tellurium is found with gold more often than in uncombined form, it is found even more often combined as tellurides of more common metals (e.g. melonite, NiTe). Natural tellurite and tellurate minerals also occur, formed by oxidation of tellurides near the Earth's surface. In contrast to selenium, tellurium does not usually replace sulfur in minerals because of the great difference in ion radii. Thus, many common sulfide minerals contain substantial quantities of selenium and only traces of tellurium.

In the gold rush of 1893, miners in Kalgoorlie discarded a pyritic material as they searched for pure gold, and it was used to fill in potholes and build sidewalks. In 1896, that tailing was discovered to be calaverite, a telluride of gold, and it sparked a second gold rush that included mining the streets.

Tellurium (Latin "tellus" meaning "earth") was discovered in the 18th century in a gold ore from the mines in Zlatna, near today's city of Alba Iulia, Romania. This ore was known as "Faczebajer weißes blättriges Golderz" (white leafy gold ore from Faczebaja, German name of Facebánya, now Fața Băii in Alba County) or "antimonalischer Goldkies" (antimonic gold pyrite), and according to Anton von Rupprecht, was "Spießglaskönig" ("argent molybdique"), containing native antimony. In 1782 Franz-Joseph Müller von Reichenstein, who was then serving as the Austrian chief inspector of mines in Transylvania, concluded that the ore did not contain antimony but was bismuth sulfide. The following year, he reported that this was erroneous and that the ore contained mostly gold and an unknown metal very similar to antimony. After a thorough investigation that lasted three years and included more than fifty tests, Müller determined the specific gravity of the mineral and noted that when heated, the new metal gives off a white smoke with a radish-like odor; that it imparts a red color to sulfuric acid; and that when this solution is diluted with water, it has a black precipitate. Nevertheless, he was not able to identify this metal and gave it the names "aurum paradoxium" (paradoxical gold) and "metallum problematicum" (problem metal), because it did not exhibit the properties predicted for antimony.

In 1789, a Hungarian scientist, Pál Kitaibel, discovered the element independently in an ore from Deutsch-Pilsen that had been regarded as argentiferous molybdenite, but later he gave the credit to Müller. In 1798, it was named by Martin Heinrich Klaproth, who had earlier isolated it from the mineral calaverite.

The 1960s brought an increase in thermoelectric applications for tellurium (as bismuth telluride), and in free-machining steel alloys, which became the dominant use.

The principal source of tellurium is from anode sludges from the electrolytic refining of blister copper. It is a component of dusts from blast furnace refining of lead. Treatment of 1000 tons of copper ore typically yields one kilogram (2.2 pounds) of tellurium. 

The anode sludges contain the selenides and tellurides of the noble metals in compounds with the formula MSe or MTe (M = Cu, Ag, Au). At temperatures of 500 °C the anode sludges are roasted with sodium carbonate under air. The metal ions are reduced to the metals, while the telluride is converted to sodium tellurite.

Tellurites can be leached from the mixture with water and are normally present as hydrotellurites HTeO in solution. Selenites are also formed during this process, but they can be separated by adding sulfuric acid. The hydrotellurites are converted into the insoluble tellurium dioxide while the selenites stay in solution.

The metal is produced from the oxide (reduced) either by electrolysis or by reacting the tellurium dioxide with sulfur dioxide in sulfuric acid.

Commercial-grade tellurium is usually marketed as 200-mesh powder but is also available as slabs, ingots, sticks, or lumps. The year-end price for tellurium in 2000 was US$14 per pound. In recent years, the tellurium price was driven up by increased demand and limited supply, reaching as high as US$100 per pound in 2006. Despite the expectation that improved production methods will double production, the United States Department of Energy (DoE) anticipates a supply shortfall of tellurium by 2025.

Tellurium is produced mainly in the United States, Peru, Japan and Canada. The British Geological Survey gives the following production numbers for 2009: United States 50 t, Peru 7 t, Japan 40 t and Canada 16 t.

Tellurium belongs to the chalcogen (group 16) family of elements on the periodic table, which also includes oxygen, sulfur, selenium and polonium: Tellurium and selenium compounds are similar. Tellurium exhibits the oxidation states −2, +2, +4 and +6, with +4 being most common.

Reduction of Te metal produces the tellurides and polytellurides, Te. The −2 oxidation state is exhibited in binary compounds with many metals, such as zinc telluride, , produced by heating tellurium with zinc. Decomposition of with hydrochloric acid yields hydrogen telluride (), a highly unstable analogue of the other chalcogen hydrides, , and :

The +2 oxidation state is exhibited by the dihalides, , and . The dihalides have not been obtained in pure form, although they are known decomposition products of the tetrahalides in organic solvents, and the derived tetrahalotellurates are well-characterized:

where X is Cl, Br, or I. These anions are square planar in geometry. Polynuclear anionic species also exist, such as the dark brown , and the black .

Fluorine forms two halides with tellurium: the mixed-valence and . In the +6 oxidation state, the structural group occurs in a number of compounds such as , , , and . The square antiprismatic anion is also attested. The other halogens do not form halides with tellurium in the +6 oxidation state, but only tetrahalides (, and ) in the +4 state, and other lower halides (, , , and two forms of ). In the +4 oxidation state, halotellurate anions are known, such as and . Halotellurium cations are also attested, including , found in .


Tellurium monoxide was first reported in 1883 as a black amorphous solid formed by the heat decomposition of in vacuum, disproportionating into tellurium dioxide, and elemental tellurium upon heating. Since then, however, existence in the solid phase is doubted and in dispute, although it is known as a vapor fragment; the black solid may be merely an equimolar mixture of elemental tellurium and tellurium dioxide.

Tellurium dioxide is formed by heating tellurium in air, where it burns with a blue flame. Tellurium trioxide, β-, is obtained by thermal decomposition of . The other two forms of trioxide reported in the literature, the α- and γ- forms, were found not to be true oxides of tellurium in the +6 oxidation state, but a mixture of , and . Tellurium also exhibits mixed-valence oxides, and .

The tellurium oxides and hydrated oxides form a series of acids, including tellurous acid (), orthotelluric acid () and metatelluric acid (). The two forms of telluric acid form "tellurate" salts containing the TeO and TeO anions, respectively. Tellurous acid forms "tellurite" salts containing the anion TeO. Other tellurium cations include , which consists of two fused tellurium rings and the polymeric .

When tellurium is treated with concentrated sulfuric acid, the result is a red solution of the Zintl ion, . The oxidation of tellurium by in liquid produces the same square planar cation, in addition to the trigonal prismatic, yellow-orange :

Other tellurium Zintl cations include the polymeric and the blue-black , consisting of two fused 5-membered tellurium rings. The latter cation is formed by the reaction of tellurium with tungsten hexachloride:

Interchalcogen cations also exist, such as (distorted cubic geometry) and . These are formed by oxidizing mixtures of tellurium and selenium with or .


Tellurium does not readily form analogues of alcohols and thiols, with the functional group –TeH, that are called tellurols. The –TeH functional group is also attributed using the prefix "tellanyl-". Like HTe, these species are unstable with respect to loss of hydrogen. Telluraethers (R–Te–R) are more stable, as are telluroxides.

The largest consumer of tellurium is metallurgy in iron, stainless steel, copper, and lead alloys. The addition to steel and copper produces an alloy more machinable than otherwise. It is alloyed into cast iron for promoting chill for spectroscopy, where the presence of electrically conductive free graphite tends to interfere with spark emission testing results. In lead, tellurium improves strength and durability, and decreases the corrosive action of sulfuric acid.

Tellurium is used in cadmium telluride (CdTe) solar panels. National Renewable Energy Laboratory lab tests of tellurium demonstrated some of the greatest efficiencies for solar cell electric power generators. Massive commercial production of CdTe solar panels by First Solar in recent years has significantly increased tellurium demand. Replacing some of the cadmium in CdTe by zinc, producing (Cd,Zn)Te, produces a solid-state X-ray detector, providing an alternative to single-use film badges.

Infrared sensitive semiconductor material is formed by alloying tellurium with cadmium and mercury to form mercury cadmium telluride.

Organotellurium compounds such as dimethyl telluride, diethyl telluride, diisopropyl telluride, diallyl telluride and methyl allyl telluride are precursors for synthesizing metalorganic vapor phase epitaxy growth of II-VI compound semiconductors. Diisopropyl telluride (DIPTe) is the preferred precursor for low-temperature growth of CdHgTe by MOVPE. The greatest purity metalorganics of both selenium and tellurium are used in these processes. The compounds for semiconductor industry and are prepared by adduct purification.

Tellurium, as tellurium suboxide, is used in the media layer of rewritable optical discs, including ReWritable Compact Discs (CD-RW), ReWritable Digital Video Discs (DVD-RW), and ReWritable Blu-ray Discs.

Tellurium dioxide is used to create acousto-optic modulators (AOTFs and AOBSs) for confocal microscropy.

Tellurium is used in the new phase change memory chips developed by Intel. Bismuth telluride (BiTe) and lead telluride are working elements of thermoelectric devices. Lead telluride is used in far-infrared detectors.


Tellurium has no known biological function, although fungi can incorporate it in place of sulfur and selenium into amino acids such as telluro-cysteine and telluro-methionine. Organisms have shown a highly variable tolerance to tellurium compounds. Many bacteria, such as "Pseudomonas aeruginosa", take up tellurite and reduce it to elemental tellurium, which accumulates and causes a characteristic and often dramatic darkening of cells. In yeast, this reduction is mediated by the sulfate assimilation pathway. Tellurium accumulation seems to account for a major part of the toxicity effects. Many organisms also metabolize tellurium partly to form dimethyl telluride, although dimethyl ditelluride is also formed by some species. Dimethyl telluride has been observed in hot springs at very low concentrations.

Tellurium and tellurium compounds are considered to be mildly toxic and need to be handled with care, although acute poisoning is rare. Tellurium poisoning is particularly difficult to treat as many chelation agents used in the treatment of metal poisoning will increase the toxicity of tellurium. Tellurium is not reported to be carcinogenic.

Humans exposed to as little as 0.01 mg/m or less in air exude a foul garlic-like odor known as "tellurium breath".
This is caused by the body converting tellurium from any oxidation state to dimethyl telluride, (CH)Te. This is a volatile compound with a pungent garlic-like smell. Even though the metabolic pathways of tellurium are not known, it is generally assumed that they resemble those of the more extensively studied selenium because the final methylated metabolic products of the two elements are similar.

People can be exposed to tellurium in the workplace by inhalation, ingestion, skin contact, and eye contact. The Occupational Safety and Health Administration (OSHA) limits (permissible exposure limit) tellurium exposure in the workplace to 0.1 mg/m over an eight-hour workday. The National Institute for Occupational Safety and Health (NIOSH) has set the recommended exposure limit (REL) at 0.1 mg/m over an eight-hour workday. In concentrations of 25 mg/m, tellurium is immediately dangerous to life and health.




</doc>
<doc id="30044" url="https://en.wikipedia.org/wiki?curid=30044" title="Thorium">
Thorium

Thorium is a weakly radioactive metallic chemical element with symbol Th and atomic number 90. Thorium is silvery and tarnishes black when it is exposed to air, forming thorium dioxide; it is moderately hard, malleable, and has a high melting point. Thorium is an electropositive actinide whose chemistry is dominated by the +4 oxidation state; it is quite reactive and can ignite in air when finely divided.

All known thorium isotopes are unstable. The most stable isotope, Th, has a half-life of 14.05 billion years, or about the age of the universe; it decays very slowly via alpha decay, starting a decay chain named the thorium series that ends at stable Pb. In the universe, thorium and uranium are the only two radioactive elements that still occur naturally in large quantities as primordial elements. It is estimated to be over three times more abundant than uranium in the Earth's crust, and is chiefly refined from monazite sands as a by-product of extracting rare-earth metals.

Thorium was discovered in 1829 by the Norwegian amateur mineralogist Morten Thrane Esmark and identified by the Swedish chemist Jöns Jacob Berzelius, who named it after Thor, the Norse god of thunder. Its first applications were developed in the late 19th century. Thorium's radioactivity was widely acknowledged during the first decades of the 20th century. In the second half of the century, thorium was replaced in many uses due to concerns about its radioactivity.

Thorium is still being used as an alloying element in TIG welding electrodes but is slowly being replaced in the field with different compositions. It was also a material in high-end optics and scientific instrumentation, and as the light source in gas mantles, but these uses have become marginal. It has been suggested as a replacement for uranium as nuclear fuel in nuclear reactors, and several thorium reactors have been built.

Thorium is a moderately soft, paramagnetic, bright silvery radioactive actinide metal. In the periodic table, it lies to the right of actinium, to the left of protactinium, and below cerium. Pure thorium is very ductile and, as normal for metals, can be cold-rolled, swaged, and drawn. At room temperature, thorium metal has a face-centred cubic crystal structure; it has two other forms, one at high temperature (over 1360 °C; body-centred cubic) and one at high pressure (around 100 GPa; body-centred tetragonal).

Thorium metal has a bulk modulus (a measure of resistance to compression of a material) of 54 GPa, about the same as tin's (58.2 GPa). Aluminium's is 75.2 GPa; copper's 137.8 GPa; and mild steel's is 160–169 GPa. Thorium is about as hard as soft steel, so when heated it can be rolled into sheets and pulled into wire.

Thorium is nearly half as dense as uranium and plutonium, and is harder than either of them. It becomes superconductive below 1.4 K. Thorium's melting point of 1750 °C is above both those of actinium (1227 °C) and protactinium (1568 °C). At the start of period 7, from francium to thorium, the melting points of the elements increase (as in other periods), because the number of delocalised electrons each atom contributes increases from one in francium to four in thorium, leading to greater attraction between these electrons and the metal ions as their charge increases from one to four. After thorium, there is a new downward trend in melting points from thorium to plutonium, where the number of f electrons increases from about 0.4 to about 6: this trend is due to the increasing hybridisation of the 5f and 6d orbitals and the formation of directional bonds resulting in more complex crystal structures and weakened metallic bonding. (The f-electron count for thorium is a non-integer due to a 5f–6d overlap.) Among the actinides up to californium, which can be studied in at least milligram quantities, thorium has the highest melting and boiling points and second-lowest density; only actinium is lighter. Thorium's boiling point of 4788 °C is the fifth-highest among all the elements with known boiling points.

The properties of thorium vary widely depending on the degree of impurities in the sample. The major impurity is usually thorium dioxide (ThO); even the purest thorium specimens usually contain about a tenth of a percent of the dioxide. Experimental measurements of its density give values between 11.5 and 11.66 g/cm: these are slightly lower than the theoretically expected value of 11.7 g/cm calculated from thorium's lattice parameters, perhaps due to microscopic voids forming in the metal when it is cast. These values lie between those of its neighbours actinium (10.1 g/cm) and protactinium (15.4 g/cm), part of a trend across the early actinides.

Thorium can form alloys with many other metals. Addition of small proportions of thorium improves the mechanical strength of magnesium, and thorium-aluminium alloys have been considered as a way to store thorium in proposed future thorium nuclear reactors. Thorium forms eutectic mixtures with chromium and uranium, and it is completely miscible in both solid and liquid states with its lighter congener cerium.

All but two elements up to bismuth (element 83) have an isotope that is practically stable for all purposes ("classically stable"), with the exceptions being technetium and promethium (elements 43 and 61). All elements from polonium (element 84) onward are measurably radioactive. Th is one of the three nuclides beyond bismuth (the other two being U and U) that have half-lives measured in billions of years; its half-life is 14.05 billion years, about three times the age of the earth, and slightly longer than the age of the universe. Four-fifths of the thorium present at Earth's formation has survived to the present. Th is the only isotope of thorium occurring in quantity in nature. Its stability is attributed to its closed nuclear shell with 142 neutrons. Thorium has a characteristic terrestrial isotopic composition, with atomic weight 232.0377(4). It is one of only three radioactive elements (along with protactinium and uranium) that occur in large enough quantities on Earth for a standard atomic weight to be determined.

Thorium nuclei are susceptible to alpha decay because the strong nuclear force cannot overcome the electromagnetic repulsion between their protons. The alpha decay of Th initiates the 4"n" decay chain which includes isotopes with a mass number divisible by 4 (hence the name; it is also called the thorium series after its progenitor). This chain of consecutive alpha and beta decays begins with the decay of Th to Ra and terminates at Pb. Any sample of thorium or its compounds contains traces of these daughters, which are isotopes of thallium, lead, bismuth, polonium, radon, radium, and actinium. Natural thorium samples can be chemically purified to extract useful daughter nuclides, such as Pb, which is used in nuclear medicine for cancer therapy. Th also very occasionally undergoes spontaneous fission rather than alpha decay, and has left evidence of doing so in its minerals (as trapped xenon gas formed as a fission product), but the partial half-life of this process is very large at over 10 years and alpha decay predominates.
Thirty radioisotopes have been characterised, which range in mass number from 209 to 238. After Th, the most stable of them (with respective half-lives) are Th (75,380 years), Th (7,340 years), Th (1.92 years), Th (24.10 days), and Th (18.68 days). All of these isotopes occur in nature as trace radioisotopes due to their presence in the decay chains of Th, U, U, and Np: the last of these is long extinct in nature due to its short half-life (2.14 million years), but is continually produced in minute traces from neutron capture in uranium ores. All of the remaining thorium isotopes have half-lives that are less than thirty days and the majority of these have half-lives that are less than ten minutes.

In deep seawaters the isotope Th makes up to 0.04% of natural thorium. This is because its parent U is soluble in water, but Th is insoluble and precipitates into the sediment. Uranium ores with low thorium concentrations can be purified to produce gram-sized thorium samples of which over a quarter is the Th isotope, since Th is one of the daughters of U. The International Union of Pure and Applied Chemistry (IUPAC) reclassified thorium as a binuclidic element in 2013; it had formerly been considered a mononuclidic element.

Thorium has three known nuclear isomers (or metastable states), Th, Th, and Th. Th has the lowest known excitation energy of any isomer, measured to be . This is so low that when it undergoes isomeric transition, the emitted gamma radiation is in the ultraviolet range.

Different isotopes of thorium are chemically identical, but have slightly differing physical properties: for example, the densities of pure Th, Th, Th, and Th are respectively expected to be 11.5, 11.6, 11.6, and 11.7 g/cm. The isotope Th is expected to be fissionable with a bare critical mass of 2839 kg, although with steel reflectors this value could drop to 994 kg. Th is not fissionable, but it is fertile as it can be converted to fissile U by neutron capture and subsequent beta decay.

Two radiometric dating methods involve thorium isotopes: uranium–thorium dating, based on the decay of U to Th, and ionium–thorium dating, which measures the ratio of Th to Th. These rely on the fact that Th is a primordial radioisotope, but Th only occurs as an intermediate decay product in the decay chain of U. Uranium–thorium dating is a relatively short-range process because of the short half-lives of U and Th relative to the age of the Earth: it is also accompanied by a sister process involving the alpha decay of U into Th, which very quickly becomes the longer-lived Pa, and this process is often used to check the results of uranium–thorium dating. Uranium–thorium dating is commonly used to determine the age of calcium carbonate materials such as speleothem or coral, because uranium is more soluble in water than thorium and protactinium, which are selectively precipitated into ocean-floor sediments, where their ratios are measured. The scheme has a range of several hundred thousand years. Ionium–thorium dating is a related process, which exploits the insolubility of thorium (both Th and Th) and thus its presence in ocean sediments to date these sediments by measuring the ratio of Th to Th. Both of these dating methods assume that the proportion of Th to Th is a constant during the period when the sediment layer was formed, that the sediment did not already contain thorium before contributions from the decay of uranium, and that the thorium cannot migrate within the sediment layer.

A thorium atom has 90 electrons, of which four are valence electrons. Three atomic orbitals are theoretically available for the valence electrons to occupy: 5f, 6d, and 7s. Despite thorium's position in the f-block of the periodic table, it has an anomalous [Rn]6d7s electron configuration in the ground state, as the 5f and 6d subshells in the early actinides are very close in energy, even more so than the 4f and 5d subshells of the lanthanides: thorium's 6d subshells are lower in energy than its 5f subshells, because its 5f subshells are not well-shielded by the filled 6s and 6p subshells and are destabilised. This is due to relativistic effects, which become stronger near the bottom of the periodic table, specifically the relativistic spin–orbit interaction. The closeness in energy levels of the 5f, 6d, and 7s energy levels of thorium results in thorium almost always losing all four valence electrons and occurring in its highest possible oxidation state of +4. This is different from its lanthanide congener cerium, in which +4 is also the highest possible state, but +3 plays an important role and is more stable. Thorium is much more similar to the transition metals zirconium and hafnium than to cerium in its ionisation energies and redox potentials, and hence also in its chemistry: this transition-metal-like behaviour is the norm in the first half of the actinide series.

Despite the anomalous electron configuration for gaseous thorium atoms, metallic thorium shows significant 5f involvement. This was first realised in 1995, when it was pointed out that a hypothetical metallic state of thorium that had the [Rn]6d7s configuration with the 5f orbitals above the Fermi level should be hexagonal close packed like the group 4 elements titanium, zirconium, and hafnium, and not face-centred cubic as it actually is. The actual crystal structure can only be explained when the 5f states are invoked, proving that thorium, and not protactinium, acts as the first actinide metallurgically. The 5f character of thorium is also clear in the rare and highly unstable +3 oxidation state, in which thorium exhibits the electron configuration [Rn]5f.

Tetravalent thorium compounds are usually colourless or yellow, like those of silver or lead, as the Th ion has no 5f or 6d electrons. Thorium chemistry is therefore largely that of an electropositive metal forming a single diamagnetic ion with a stable noble-gas configuration, indicating a similarity between thorium and the main group elements of the s-block. Thorium and uranium are the most investigated of the radioactive elements because their radioactivity is low enough not to require special handling in the laboratory.

Thorium is a highly reactive and electropositive metal. With a standard reduction potential of −1.90 V for the Th/Th couple, it is somewhat more electropositive than zirconium or aluminium. Finely divided thorium metal can exhibit pyrophoricity, spontaneously igniting in air. When heated in air, thorium turnings ignite and burn with a brilliant white light to produce the dioxide. In bulk, the reaction of pure thorium with air is slow, although corrosion may occur after several months; most thorium samples are contaminated with varying degrees of the dioxide, which greatly accelerates corrosion. Such samples slowly tarnish, becoming grey and finally black at the surface.

At standard temperature and pressure, thorium is slowly attacked by water, but does not readily dissolve in most common acids, with the exception of hydrochloric acid, where it dissolves leaving a black insoluble residue of ThO(OH,Cl)H. It dissolves in concentrated nitric acid containing a small quantity of catalytic fluoride or fluorosilicate ions; if these are not present, passivation by the nitrate can occur, as with uranium and plutonium.

Most binary compounds of thorium with nonmetals may be prepared by heating the elements together. In air, thorium burns to form ThO, which has the fluorite structure. Thorium dioxide is a refractory material, with the highest melting point (3390 °C) of any known oxide. It is somewhat hygroscopic and reacts readily with water and many gases; it dissolves easily in concentrated nitric acid in the presence of fluoride. When heated, it emits intense blue light through incandescence; the light becomes white when ThO is mixed with its lighter homologue cerium dioxide (CeO, ceria): this is the basis for its previously common application in gas mantles. Several binary thorium chalcogenides and oxychalcogenides are also known with sulfur, selenium, and tellurium.

All four thorium tetrahalides are known, as are some low-valent bromides and iodides: the tetrahalides are all 8-coordinated hygroscopic compounds that dissolve easily in polar solvents such as water. Many related polyhalide ions are also known. Thorium tetrafluoride has a monoclinic crystal structure like those of zirconium tetrafluoride and hafnium tetrafluoride, where the Th ions are coordinated with F ions in somewhat distorted square antiprisms. The other tetrahalides instead have dodecahedral geometry. Lower iodides ThI (black) and ThI (gold-coloured) can also be prepared by reducing the tetraiodide with thorium metal: they do not contain Th(III) and Th(II), but instead contain Th and could be more clearly formulated as electride compounds. Many polynary halides with the alkali metals, barium, thallium, and ammonium are known for thorium fluorides, chlorides, and bromides. For example, when treated with potassium fluoride and hydrofluoric acid, Th forms the complex anion , which precipitates as an insoluble salt, KThF.

Thorium borides, carbides, silicides, and nitrides are refractory materials, like those of uranium and plutonium, and have thus received attention as possible nuclear fuels. All four heavier pnictogens (phosphorus, arsenic, antimony, and bismuth) also form binary thorium compounds. Thorium germanides are also known. Thorium reacts with hydrogen to form the thorium hydrides ThH and ThH, the latter of which is superconducting below 7.5–8 K; at standard temperature and pressure, it conducts electricity like a metal. The hydrides are thermally unstable and readily decompose upon exposure to air or moisture.

In an acidic aqueous solution, thorium occurs as the tetrapositive aqua ion [Th(HO)], which has tricapped trigonal prismatic molecular geometry: at pH < 3, the solutions of thorium salts are dominated by this cation. The Th ion is the largest of the tetrapositive actinide ions, and depending on the coordination number can have a radius between 0.95 and 1.14 Å. It is quite acidic due to its high charge, slightly stronger than sulfurous acid: thus it tends to undergo hydrolysis and polymerisation (though to a lesser extent than Fe), predominantly to [Th(OH)] in solutions with pH 3 or below, but in more alkaline solution polymerisation continues until the gelatinous hydroxide Th(OH) forms and precipitates out (though equilibrium may take weeks to be reached, because the polymerisation usually slows down before the precipitation). As a hard Lewis acid, Th favours hard ligands with oxygen atoms as donors: complexes with sulfur atoms as donors are less stable and are more prone to hydrolysis.

High coordination numbers are the rule for thorium due to its large size. Thorium nitrate pentahydrate was the first known example of coordination number 11, the oxalate tetrahydrate has coordination number 10, and the borohydride (first prepared in the Manhattan Project) has coordination number 14. These thorium salts are known for their high solubility in water and polar organic solvents.

Many other inorganic thorium compounds with polyatomic anions are known, such as the perchlorates, sulfates, sulfites, nitrates, carbonates, phosphates, vanadates, molybdates, and chromates, and their hydrated forms. They are important in thorium purification and the disposal of nuclear waste, but most of them have not yet been fully characterised, especially regarding their structural properties. For example, thorium nitrate is produced by reacting thorium hydroxide with nitric acid: it is soluble in water and alcohols and is an important intermediate in the purification of thorium and its compounds. Thorium complexes with organic ligands, such as oxalate, citrate, and EDTA, are much more stable. In natural thorium-containing waters, organic thorium complexes usually occur in concentrations orders of magnitude higher than the inorganic complexes, even when the concentrations of inorganic ligands are much greater than those of organic ligands.

Most of the work on organothorium compounds has focused on the cyclopentadienyl complexes and cyclooctatetraenyls. Like many of the early and middle actinides (up to americium, and also expected for curium), thorium forms a cyclooctatetraenide complex: the yellow Th(CH), thorocene. It is isotypic with the better-known analogous uranium compound uranocene. It can be prepared by reacting KCH with thorium tetrachloride in tetrahydrofuran (THF) at the temperature of dry ice, or by reacting thorium tetrafluoride with MgCH. It is unstable in air and decomposes in water or at 190 °C. Half sandwich compounds are also known, such as ("η"-CH)ThCl(THF), which has a piano-stool structure and is made by reacting thorocene with thorium tetrachloride in tetrahydrofuran.

The simplest of the cyclopentadienyls are Th(CH) and Th(CH): many derivatives are known. The former (which has two forms, one purple and one green) is a rare example of thorium in the formal +3 oxidation state; a formal +2 oxidation state occurs in a derivative. The chloride derivative [Th(CH)Cl] is prepared by heating thorium tetrachloride with limiting K(CH) used (other univalent metal cyclopentadienyls can also be used). The alkyl and aryl derivatives are prepared from the chloride derivative and have been used to study the nature of the Th–C sigma bond.

Other organothorium compounds are not well-studied. Tetrabenzylthorium, Th(CHCH), and tetraallylthorium, Th(CH), are known, but their structures have not been determined. They decompose slowly at room temperature. Thorium forms the monocapped trigonal prismatic anion [Th(CH)], heptamethylthorate, which forms the salt [Li(tmeda)][ThMe] (tmeda= MeNCHCHNMe). Although one methyl group is only attached to the thorium atom (Th–C distance 257.1 pm) and the other six connect the lithium and thorium atoms (Th–C distances 265.5–276.5 pm), they behave equivalently in solution. Tetramethylthorium, Th(CH), is not known, but its adducts are stabilised by phosphine ligands.

Th is a primordial nuclide, having existed in its current form for over ten billion years; it was forged in the cores of dying stars through the r-process and scattered across the galaxy by supernovae and neutron star mergers. The letter "r" stands for "rapid neutron capture", and occurs in core-collapse supernovae, where heavy seed nuclei such as Fe rapidly capture neutrons, running up against the neutron drip line, as neutrons are captured much faster than the resulting nuclides can beta decay back toward stability. Neutron capture is the only way for stars to synthesise elements beyond iron because of the increased Coulomb barriers that make interactions between charged particles difficult at high atomic numbers and the fact that fusion beyond Fe is endothermic. Because of the abrupt loss of stability past Bi, the r-process is the only process of stellar nucleosynthesis that can create thorium and uranium; all other processes are too slow and the intermediate nuclei alpha decay before they capture enough neutrons to reach these elements.
In the universe, thorium is among the rarest of the primordial elements, because it is one of the two elements that can be produced only in the r-process (the other being uranium), and also because it has slowly been decaying away from the moment it formed. The only primordial elements rarer than thorium are thulium, lutetium, tantalum, and rhenium, the odd-numbered elements just before the third peak of r-process abundances around the heavy platinum group metals, as well as uranium. Neutron capture by nuclides beyond "A"= 209 often results in nuclear fission instead of neutron absorption, reducing the fraction of nuclei that cross the gap of instability past bismuth to become actinides such as thorium. In the distant past the abundances of thorium and uranium were enriched by the decay of plutonium and curium isotopes, and thorium was enriched relative to uranium by the decay of U to Th and the natural depletion of U, but these sources have long since decayed and no longer contribute.

In the Earth's crust, thorium is much more abundant: with an abundance of 8.1 parts per million (ppm), it is one of the most abundant of the heavy elements, almost as abundant as lead (13 ppm) and more abundant than tin (2.1 ppm). This is because thorium is likely to form oxide minerals that do not sink into the core; it is classified as a lithophile. Common thorium compounds are also poorly soluble in water. Thus, even though the Earth contains the same abundances of the elements as the Solar System as a whole, there is more accessible thorium than heavy platinum group metals in the crust.

Natural thorium is usually almost pure Th, which is the longest-lived and most stable isotope of thorium, having a half-life comparable to the age of the universe. Its radioactive decay is the largest single contributor to the Earth's internal heat; the other major contributors are the shorter-lived primordial radionuclides, which are U, K, and U in descending order of their contribution. (At the time of the Earth's formation, K and U contributed much more by virtue of their short half-lives, but they have decayed more quickly, leaving the contribution from Th and U predominant.) Its decay accounts for a gradual decrease of thorium content of the Earth: the planet currently has around 85% of the amount present at the formation of the Earth. The other natural thorium isotopes are much shorter-lived; of them, only Th is usually detectable, occurring in secular equilibrium with its parent U, and making up at most 0.04% of natural thorium.

Thorium only occurs as a minor constituent of most minerals, and was for this reason previously thought to be rare. Soil normally contains about 6 ppm of thorium.

In nature, thorium occurs in the +4 oxidation state, together with uranium(IV), zirconium(IV), hafnium(IV), and cerium(IV), and also with scandium, yttrium, and the trivalent lanthanides which have similar ionic radii. Because of thorium's radioactivity, minerals containing it are often metamict (amorphous), their crystal structure having been damaged by the alpha radiation produced by thorium. An extreme example is ekanite, (Ca,Fe,Pb)(Th,U)SiO, which almost never occurs in nonmetamict form due to the thorium it contains.

Monazite (chiefly phosphates of various rare-earth elements) is the most important commercial source of thorium because it occurs in large deposits worldwide, principally in India, South Africa, Brazil, Australia, and Malaysia. It contains around 2.5% thorium on average, although some deposits may contain up to 20%. Monazite is a chemically unreactive mineral that is found as yellow or brown sand; its low reactivity makes it difficult to extract thorium from it. Allanite (chiefly silicates-hydroxides of various metals) can have 0.1–2% thorium and zircon (chiefly zirconium silicate, ZrSiO) up to 0.4% thorium.

Thorium dioxide occurs as the rare mineral thorianite. Due to its being isotypic with uranium dioxide, these two common actinide dioxides can form solid-state solutions and the name of the mineral changes according to the ThO content. Thorite (chiefly thorium silicate, ThSiO), also has a high thorium content and is the mineral in which thorium was first discovered. In thorium silicate minerals, the Th and ions are often replaced with M (where M= Sc, Y, or Ln) and phosphate () ions respectively. Because of the great insolubility of thorium dioxide, thorium does not usually spread quickly through the environment when released. The Th ion is soluble, especially in acidic soils, and in such conditions the thorium concentration can reach 40 ppm.

In 1815, the Swedish chemist Jöns Jacob Berzelius analysed an unusual sample of gadolinite from a copper mine in Falun, central Sweden. He noted impregnated traces of a white mineral, which he cautiously assumed to be an earth (oxide in modern chemical nomenclature) of an unknown element. Berzelius had already discovered two elements, cerium and selenium, but he had made a public mistake once, announcing a new element, "gahnium", that turned out to be zinc oxide. Berzelius privately named the putative element "thorium" in 1817 and its supposed oxide "thorina" after Thor, the Norse god of thunder. In 1824, after more deposits of the same mineral in Vest-Agder, Norway, were discovered, he retracted his findings, as the mineral (later named xenotime) proved to be mostly yttrium orthophosphate.

In 1828, Morten Thrane Esmark found a black mineral on Løvøya island, Telemark county, Norway. He was a Norwegian priest and amateur mineralogist who studied the minerals in Telemark, where he served as vicar. He commonly sent the most interesting specimens, such as this one, to his father, Jens Esmark, a noted mineralogist and professor of mineralogy and geology at the Royal Frederick University in Christiania (today called Oslo). The elder Esmark determined that it was not a known mineral and sent a sample to Berzelius for examination. Berzelius determined that it contained a new element. He published his findings in 1829, having isolated an impure sample by reducing KThF with potassium metal. Berzelius reused the name of the previous supposed element discovery and named the source mineral thorite.

Berzelius made some initial characterisations of the new metal and its chemical compounds: he correctly determined that the thorium–oxygen mass ratio of thorium oxide was 7.5 (its actual value is close to that, ~7.3), but he assumed the new element was divalent rather than tetravalent, and so calculated that the atomic mass was 7.5 times that of oxygen (120 amu); it is actually 15 times as large. He determined that thorium was a very electropositive metal, ahead of cerium and behind zirconium in electropositivity. Metallic thorium was isolated for the first time in 1914 by Dutch entrepreneurs Dirk Lely Jr. and Lodewijk Hamburger.

In the periodic table published by Dmitri Mendeleev in 1869, thorium and the rare-earth elements were placed outside the main body of the table, at the end of each vertical period after the alkaline earth metals. This reflected the belief at that time that thorium and the rare-earth metals were divalent. With the later recognition that the rare earths were mostly trivalent and thorium was tetravalent, Mendeleev moved cerium and thorium to group IV in 1871, which also contained the modern carbon group (group 14) and titanium group (group 4), because their maximum oxidation state was +4. Cerium was soon removed from the main body of the table and placed in a separate lanthanide series; thorium was left with group 4 as it had similar properties to its supposed lighter congeners in that group, such as titanium and zirconium.

While thorium was discovered in 1828 its first application dates only from 1885, when Austrian chemist Carl Auer von Welsbach invented the gas mantle, a portable source of light which produces light from the incandescence of thorium oxide when heated by burning gaseous fuels. Many applications were subsequently found for thorium and its compounds, including ceramics, carbon arc lamps, heat-resistant crucibles, and as catalysts for industrial chemical reactions such as the oxidation of ammonia to nitric acid.

Thorium was first observed to be radioactive in 1898, by the German chemist Gerhard Carl Schmidt and later that year, independently, by the Polish-French physicist Marie Curie. It was the second element that was found to be radioactive, after the 1896 discovery of radioactivity in uranium by French physicist Henri Becquerel. Starting from 1899, the British physicist Ernest Rutherford and the American electrical engineer Robert Bowie Owens studied the radiation from thorium; initial observations showed that it varied significantly. It was determined that these variations came from a short-lived gaseous daughter of thorium, which they found to be a new element. This element is now named radon, the only one of the rare radioelements to be discovered in nature as a daughter of thorium rather than uranium.

After accounting for the contribution of radon, Rutherford, now working with the British physicist Frederick Soddy, showed how thorium decayed at a fixed rate over time into a series of other elements in work dating from 1900 to 1903. This observation led to the identification of the half-life as one of the outcomes of the alpha particle experiments that led to their disintegration theory of radioactivity. The biological effect of radiation was discovered in 1903. The newly discovered phenomenon of radioactivity excited scientists and the general public alike. In the 1920s, thorium's radioactivity was promoted as a cure for rheumatism, diabetes, and sexual impotence. In 1932, most of these uses were banned in the United States after a federal investigation into the health effects of radioactivity. 10,000 individuals in the United States had been injected thorium during X-ray diagnosis; they were later found to suffer health issues such as leukaemia and abnormal chromosomes. Public interest in radioactivity had declined by the end of the 1930s.

Up to the late 19th century, chemists unanimously agreed that thorium and uranium were analogous to hafnium and tungsten; the existence of the lanthanides in the sixth row was considered to be a one-off fluke. In 1892, British chemist Henry Bassett postulated a second extra-long periodic table row to accommodate known and undiscovered elements, considering thorium and uranium to be analogous to the lanthanides. In 1913, Danish physicist Niels Bohr published a theoretical model of the atom and its electron orbitals, which soon gathered wide acceptance. The model indicated that the seventh row of the periodic table should also have f-shells filling before the d-shells that were filled in the transition elements, like the sixth row with the lanthanides preceding the 5d transition metals. The existence of a second inner transition series, in the form of the actinides, was not accepted until similarities with the electron structures of the lanthanides had been established; Bohr suggested that the filling of the 5f orbitals may be delayed to after uranium.

It was only with the discovery of the first transuranic elements, which from plutonium onward have dominant +3 and +4 oxidation states like the lanthanides, that it was realised that the actinides were indeed filling f-orbitals rather than d-orbitals, with the transition-metal-like chemistry of the early actinides being the exception and not the rule. In 1945, when American physicist Glenn T. Seaborg and his team had discovered the transuranic elements americium and curium, he realised that thorium was the second member of the actinide series and was filling an f-block row, instead of being the heavier congener of hafnium filling a fourth d-block row.

In the 1990s, most applications that do not depend on thorium's radioactivity declined quickly due to safety and environmental concerns as suitable safer replacements were found. Despite its radioactivity, the element has remained in use for applications where no suitable alternatives could be found. A 1981 study by the Oak Ridge National Laboratory in the United States estimated that using a thorium mantle every weekend would be safe for a person, but this was not the case for the dose received by people manufacturing the mantles or for the soils around some factory sites. Some manufacturers have changed to other materials, such as yttrium. As recently as 2007, some companies continued to manufacture and sell thorium mantles without giving adequate information about their radioactivity, with some even falsely claiming them to be non-radioactive.

Thorium has been used as a power source. The earliest thorium-based reactor was built at the Indian Point Energy Center in the United States in 1962. India has one of the largest supplies of thorium in the world and not much uranium, and in the 1950s targeted achieving energy independence with their three-stage nuclear power programme. In most countries, uranium was relatively abundant and the progress of thorium-based reactors was slow; in the 20th century, three reactors were built in India and twelve elsewhere. Large-scale research was begun in 1996 by the International Atomic Energy Agency to study the use of thorium reactors; a year later, the United States Department of Energy started their research. Alvin Radkowsky of Tel Aviv University in Israel was the head designer of Shippingport Atomic Power Station in Pennsylvania, the first American civilian reactor to breed thorium. He founded a consortium to develop thorium reactors, which included other laboratories: Raytheon Nuclear Inc. and Brookhaven National Laboratory in the United States, and the Kurchatov Institute in Russia. In the 21st century, thorium's potential for reducing nuclear proliferation and its waste characteristics led to renewed interest in the thorium fuel cycle.

During the Cold War the United States explored the possibility of using Th as a source of U to be used in a nuclear bomb; they fired a test bomb in 1955. They concluded that a U-fired bomb would be a very potent weapon, but it bore few sustainable "technical advantages" over the contemporary uranium–plutonium bombs, especially since U is difficult to produce isotopically pure.

The low demand makes working mines for extraction of thorium alone not profitable, and it is almost always extracted with the rare earths, which themselves may be by-products of production of other minerals. The current reliance on monazite for production is due to thorium being largely produced as a by-product; other sources such as thorite contain more thorium and could easily be used for production if demand rose. Present knowledge of the distribution of thorium resources is poor, as low demand has led to exploration efforts being relatively minor. In 2014, world production of the monazite concentrate, from which thorium would be extracted, was 2,700 tonnes.

The common production route of thorium constitutes concentration of thorium minerals; extraction of thorium from the concentrate; purification of thorium; and (optionally) conversion to compounds, such as thorium dioxide.

There are two categories of thorium minerals for thorium extraction: primary and secondary. Primary deposits occur in acidic granitic magmas and pegmatites. They are concentrated, but of small size. Secondary deposits occur at the mouths of rivers in granitic mountain regions. In these deposits, thorium is enriched along with other heavy minerals. Initial concentration varies with the type of deposit.

For the primary deposits, the source pegmatites, which are usually obtained by mining, are divided into small parts and then undergo flotation. Alkaline earth metal carbonates may be removed after reaction with hydrogen chloride; then follow thickening, filtration, and calcination. The result is a concentrate with rare-earth content of up to 90%. Secondary materials (such as coastal sands) undergo gravity separation. Magnetic separation follows, with a series of magnets of increasing strength. Monazite obtained by this method can be as pure as 98%.

Industrial production in the 20th century relied on treatment with hot, concentrated sulfuric acid in cast iron vessels, followed by selective precipitation by dilution with water, as on the subsequent steps. This method relied on the specifics of the technique and the concentrate grain size; many alternatives have been proposed, but only one has proven effective economically: alkaline digestion with hot sodium hydroxide solution. This is more expensive than the original method but yields a higher purity of thorium; in particular, it removes phosphates from the concentrate.

Acid digestion is a two-stage process, involving the use of up to 93% sulfuric acid at 210–230 °C. First, 60% sulfuric acid is added, thickening the reaction mixture as products are formed. Then, fuming sulfuric acid is added and the mixture is kept at the same temperature for another five hours to reduce the volume of solution remaining after dilution. The concentration of the sulfuric acid is selected based on reaction rate and viscosity, which both increase with concentration, albeit with viscosity retarding the reaction. Increasing the temperature also speeds up the reaction, but temperatures of 300 °C and above must be avoided, because they cause insoluble thorium pyrophosphate to form. Since dissolution is very exothermic, the monazite sand cannot be added to the acid too quickly. Conversely, at temperatures below 200 °C the reaction does not go fast enough for the process to be practical. To ensure that no precipitates form to block the reactive monazite surface, the mass of acid used must be twice that of the sand, instead of the 60% that would be expected from stoichiometry. The mixture is then cooled to 70 °C and diluted with ten times its volume of cold water, so that any remaining monazite sinks to the bottom while the rare earths and thorium remain in solution. Thorium may then be separated by precipitating it as the phosphate at pH 1.3, since the rare earths do not precipitate until pH 2.

Alkaline digestion is carried out in 30–45% sodium hydroxide solution at about 140 °C for about three hours. Too high a temperature leads to the formation of poorly soluble thorium oxide and an excess of uranium in the filtrate, and too low a concentration of alkali leads to a very slow reaction. These reaction conditions are rather mild and require monazite sand with a particle size under 45 μm. Following filtration, the filter cake includes thorium and the rare earths as their hydroxides, uranium as sodium diuranate, and phosphate as trisodium phosphate. This crystallises trisodium phosphate decahydrate when cooled below 60 °C; uranium impurities in this product increase with the amount of silicon dioxide in the reaction mixture, necessitating recrystallisation before commercial use. The hydroxides are dissolved at 80 °C in 37% hydrochloric acid. Filtration of the remaining precipitates followed by addition of 47% sodium hydroxide results in the precipitation of thorium and uranium at about pH 5.8. Complete drying of the precipitate must be avoided, as air may oxidise cerium from the +3 to the +4 oxidation state, and the cerium(IV) formed can liberate free chlorine from the hydrochloric acid. The rare earths again precipitate out at higher pH. The precipitates are neutralised by the original sodium hydroxide solution, although most of the phosphate must first be removed to avoid precipitating rare-earth phosphates. Solvent extraction may also be used to separate out the thorium and uranium, by dissolving the resultant filter cake in nitric acid. The presence of titanium hydroxide is deleterious as it binds thorium and prevents it from dissolving fully.

High thorium concentrations are needed in nuclear applications. In particular, concentrations of atoms with high neutron capture cross-sections must be very low (for example, gadolinium concentrations must be lower than one part per million by weight). Previously, repeated dissolution and recrystallisation was used to achieve high purity. Today, liquid solvent extraction procedures involving selective complexation of Th are used. For example, following alkaline digestion and the removal of phosphate, the resulting nitrato complexes of thorium, uranium, and the rare earths can be separated by extraction with tributyl phosphate in kerosene.

Non-radioactivity-related uses have been in decline since the 1950s due to environmental concerns largely stemming from the radioactivity of thorium and its decay products.

Most thorium applications use its dioxide (sometimes called "thoria" in the industry), rather than the metal. This compound has a melting point of 3300 °C (6000 °F), the highest of all known oxides; only a few substances have higher melting points. This helps the compound remain solid in a flame, and it considerably increases the brightness of the flame; this is the main reason thorium is used in gas mantles. All substances emit energy (glow) at high temperatures, but the light emitted by thorium is nearly all in the visible spectrum, hence the brightness of thorium mantles. Energy, some of it in the form of visible light, is emitted when thorium is exposed to a source of energy itself, such as a cathode ray, heat or ultraviolet light. This effect is shared by cerium dioxide, which converts ultraviolet light into visible light more efficiently, but thorium dioxide gives a higher flame temperature, emitting less infrared light. Thorium in mantles, though still common, has been progressively replaced with yttrium since the late 1990s. According to the 2005 review by the United Kingdom's National Radiological Protection Board, "although [thoriated gas mantles] were widely available a few years ago, they are not any more."

During the production of incandescent filaments, recrystallisation of tungsten is signifiantly lowered by adding small amounts of thorium dioxide to the tungsten sintering powder before drawing the filaments. A small addition of thorium to tungsten thermocathodes considerably reduces the work function of electrons; as a result, electrons are emitted at considerably lower temperatures. Tungsten forms a one-atom-thick layer on the surface of thorium. The work function from a thorium surface is lowered possibly because of the electric field on the interface between thorium and tungsten formed due to thorium's greater electropositivity. Since the 1920s, thoriated tungsten wires have been used in electronic tubes and in the cathodes and anticathodes of X-ray tubes and rectifiers. Thanks to the reactivity of thorium with atmospheric oxygen and nitrogen, thorium also marks impurities in the evacuated tubes. The introduction of transistors in the 1950s significantly diminished this use, but not entirely. Thorium dioxide is used in gas tungsten arc welding (GTAW) to increase the high-temperature strength of tungsten electrodes and improve arc stability. Thorium oxide is being replaced in this use with other oxides, such as those of zirconium, cerium, and lanthanum.

Thorium dioxide is found in heat-resistant ceramics, such as high-temperature laboratory crucibles, either as the primary ingredient or as an addition to zirconium dioxide. An alloy of 90% platinum and 10% thorium is an effective catalyst for oxidising ammonia to nitrogen oxides, but this has been replaced by an alloy of 95% platinum and 5% rhodium because of its better mechanical properties and greater durability.

When added to glass, thorium dioxide helps increase its refractive index and decrease dispersion. Such glass finds application in high-quality lenses for cameras and scientific instruments. The radiation from these lenses can darken them and turn them yellow over a period of years and degrade film, but the health risks are minimal. Yellowed lenses may be restored to their original colourless state by lengthy exposure to intense ultraviolet radiation. Thorium dioxide has since been replaced by rare-earth oxides in this application, as they provide similar effects and are not radioactive.

Thorium tetrafluoride is used as an antireflection material in multilayered optical coatings. It is transparent to electromagnetic waves having wavelengths in the range of 0.35–12 µm, a range that includes near ultraviolet, visible and mid infrared light. Its radiation is primarily due to alpha particles, which can be easily stopped by a thin cover layer of another material. Replacements for thorium tetrafluoride are being developed as of the 2010s.

The main nuclear power source in a reactor is the neutron-induced fission of a nuclide; the synthetic fissile nuclei U and Pu can be bred from neutron capture by the naturally occurring quantity nuclides Th and U. U occurs naturally and is also fissile. In the thorium fuel cycle, the fertile isotope Th is bombarded by slow neutrons, undergoing neutron capture to become Th, which undergoes two consecutive beta decays to become first Pa and then the fissile U:

U is fissile and can be used as a nuclear fuel in the same way as U or Pu. When U undergoes nuclear fission, the neutrons emitted can strike further Th nuclei, continuing the cycle. This parallels the uranium fuel cycle in fast breeder reactors where U undergoes neutron capture to become U, beta decaying to first Np and then fissile Pu.

Thorium is more abundant than uranium and can satisfy world energy demands for longer.

Th absorbs neutrons more readily than U, and U has a higher probability of fission upon neutron capture (92.0%) than U (85.5%) or Pu (73.5%). It also releases more neutrons upon fission on average. A single neutron capture by U produces transuranic waste along with the fissile Pu, but Th only produces this waste after five captures, forming Np. This number of captures does not happen for 98–99% of the Th nuclei because the intermediate products U or U undergo fission, and fewer long-lived transuranics are produced. Because of this, thorium is a potentially attractive alternative to uranium in mixed oxide fuels to minimise the generation of transuranics and maximise the destruction of plutonium.

Thorium fuels also result in a safer and better-performing reactor core because thorium dioxide has a higher melting point, higher thermal conductivity, and a lower coefficient of thermal expansion and is more stable chemically than the now-common fuel uranium dioxide, which can further oxidise to triuranium octoxide (UO).

The used fuel is difficult and dangerous to reprocess because many of the daughters of Th and U are strong gamma emitters. All U production methods result in impurities of U, either from parasitic knock-out (n,2n) reactions on Th, Pa, or U that result in the loss of a neutron, or from double neutron capture of Th, an impurity in natural Th:

U by itself is not particularly harmful, but quickly decays to produce the strong gamma emitter Tl. (Th follows the same decay chain, but its much longer half-life means that the quantities of Tl produced are negligible.) These impurities of U make U easy to detect and dangerous to work on, and the impracticality of their separation limits the possibilities of nuclear proliferation using U as the fissile material. Pa has a relatively long half-life of 27 days and a high cross section for neutron capture. Thus it is a neutron poison: instead of rapidly decaying to the useful U, a significant amount of Pa converts to U and consumes neutrons, degrading the reactor efficiency. To avoid this, Pa is extracted from the active zone of thorium molten salt reactors during their operation, so that it only decays to U.

The irradiation of Th with neutrons, followed by its processing, need to be mastered before these advantages can be realised, and this requires more advanced technology than the uranium and plutonium fuel cycle; research continues in this area. Others cite the low commercial viability of the thorium fuel cycle: the international Nuclear Energy Agency predicts that the thorium cycle will never be commercially viable while uranium is available in abundance—a situation which may persist "in the coming decades". The isotopes produced in the thorium fuel cycle are mostly not transuranic, but some of them are still very dangerous, such as Pa, which has a half-life of 32,760 years and is a major contributor to the long-term radiotoxicity of spent nuclear fuel.

Thorium has no known biological role.

Natural thorium decays very slowly compared to many other radioactive materials, and the emitted alpha radiation cannot penetrate human skin. As a result, handling small amounts of thorium, such as those in gas mantles, is considered safe, although the use of such items may pose some risks. Exposure to an aerosol of thorium, such as contaminated dust, can lead to increased risk of cancers of the lung, pancreas, and blood, as lungs and other internal organs can be penetrated by alpha radiation. Exposure to thorium internally leads to increased risk of liver diseases.

The decay products of Th include more dangerous radionuclides such as radium and radon. Although relatively little of those products are created as the result of the slow decay of thorium, a proper assessment of the radiological toxicity of Th must include the contribution of its daughters, some of which are dangerous gamma emitters, and which are built up quickly following the initial decay of Th due to the absence of long-lived nuclides along the decay chain. As the dangerous daughters of thorium have much lower melting points than thorium dioxide, they are volatilised every time the mantle is heated for use. In the first hour of use large fractions of the thorium daughters Ra, Ra, Pb, and Bi are released. Most of the radiation dose by a normal user arises from inhaling the radium, resulting in a radiation dose of up to 0.2 millisieverts per use, about a third of the dose sustained during a mammogram.

Some nuclear safety agencies make recommendations about the use of thorium mantles and have raised safety concerns regarding their manufacture and disposal; the radiation dose from one mantle is not a serious problem, but that from many mantles gathered together in factories or landfills is.

Thorium is odourless and tasteless. The chemical toxicity of thorium is low because thorium and its most common compounds (mostly the dioxide) are poorly soluble in water, precipitating out before entering the body as the hydroxide. Some thorium compounds are chemically moderately toxic, especially in the presence of strong complex-forming ions such as citrate that carry the thorium into the body in soluble form. If a thorium-containing object has been chewed or sucked, it loses 0.4% of thorium and 90% of its dangerous daughters to the body. Three quarters of the thorium that has penetrated the body accumulates in the skeleton. Absorption through the skin is possible, but is not a likely means of exposure. Thorium's low solubility in water also means that excretion of thorium by the kidneys and faeces is rather slow.

Tests on the thorium uptake of workers involved in monazite processing showed thorium levels above recommended limits in their bodies, but no adverse effects on health were found at those moderately low concentrations. No chemical toxicity has yet been observed in the tracheobronchial tract and the lungs from exposure to thorium. People who work with thorium compounds are at a risk of dermatitis. It can take as much as thirty years after the ingestion of thorium for symptoms to manifest themselves.

Powdered thorium metal is pyrophoric: it ignites spontaneously in air. In 1964, the United States Department of the Interior listed thorium as "severe" on a table entitled "Ignition and explosibility of metal powders". Its ignition temperature was given as 270 °C (520 °F) for dust clouds and 280 °C (535 °F) for layers. Its minimum explosive concentration was listed as 0.075 oz/cu ft (0.075 kg/m); the minimum igniting energy for (non-submicron) dust was listed as 5 mJ.

In 1956, the Sylvania Electric Products explosion occurred during reprocessing and burning of thorium sludge in New York City, United States. Nine people were injured; one died of complications caused by third-degree burns.

Thorium exists in very small quantities everywhere on Earth although larger amounts exist in certain parts: the average human contains about 40 micrograms of thorium and typically consumes three micrograms per day. Most thorium exposure occurs through dust inhalation; some thorium comes with food and water, but because of its low solubility, this exposure is negligible.

Exposure is raised for people who live near thorium deposits or radioactive waste disposal sites, those who live near or work in uranium, phosphate, or tin processing factories, and for those who work in gas mantle production. Thorium is especially common in the Tamil Nadu coastal areas of India, where residents may be exposed to a naturally occurring radiation dose ten times higher than the worldwide average. It is also common in northern Brazilian coastal areas, from south Bahia to Guarapari, a city with highly radioactive Monazite sand beaches, with radiation levels up to 50 times higher than world average background radiation.



</doc>
<doc id="30045" url="https://en.wikipedia.org/wiki?curid=30045" title="Terbium">
Terbium

Terbium is a chemical element with symbol Tb and atomic number 65. It is a silvery-white, rare earth metal that is malleable, ductile, and soft enough to be cut with a knife. The ninth member of the lanthanide series, terbium is a fairly electropositive metal that reacts with water, evolving hydrogen gas. Terbium is never found in nature as a free element, but it is contained in many minerals, including cerite, gadolinite, monazite, xenotime, and euxenite.

Swedish chemist Carl Gustaf Mosander discovered terbium as a separate elemental compound in 1843. He detected it as an impurity in yttrium oxide, YO. Yttrium and terbium are named after the village of Ytterby in Sweden. Terbium was not isolated in pure form until the advent of ion exchange techniques.

Terbium is used to dope calcium fluoride, calcium tungstate and strontium molybdate, materials that are used in solid-state devices, and as a crystal stabilizer of fuel cells which operate at elevated temperatures. As a component of Terfenol-D (an alloy that expands and contracts when exposed to magnetic fields more than any other alloy), terbium is of use in actuators, in naval sonar systems and in sensors.

Most of the world's terbium supply is used in green phosphors. Terbium oxide is in fluorescent lamps and television and monitor cathode ray tubes (CRTs). Terbium green phosphors are combined with divalent europium blue phosphors and trivalent europium red phosphors to provide trichromatic lighting technology, a high-efficiency white light used for standard illumination in indoor lighting.

Terbium is a silvery-white rare earth metal that is malleable, ductile and soft enough to be cut with a knife. It is relatively stable in air compared to the earlier, more reactive lanthanides in the first half of the lanthanide series. Terbium exists in two crystal allotropes with a transformation temperature of 1289 °C between them. The 65 electrons of a terbium atom are arranged in the electron configuration [Xe]4f6s; normally, only three electrons can be removed before the nuclear charge becomes too great to allow further ionization, but in the case of terbium, the stability of the half-filled [Xe]4f configuration allows further ionization of a fourth electron in the presence of very strong oxidizing agents such as fluorine gas.

The terbium(III) cation is brilliantly fluorescent, in a bright lemon-yellow color that is the result of a strong green emission line in combination with other lines in the orange and red. The yttrofluorite variety of the mineral fluorite owes its creamy-yellow fluorescence in part to terbium. Terbium easily oxidizes, and is therefore used in its elemental form specifically for research. Single terbium atoms have been isolated by implanting them into fullerene molecules.

Terbium has a simple ferromagnetic ordering at temperatures below 219 K. Above 219 K, it turns into a helical antiferromagnetic state in which all of the atomic moments in a particular basal plane layer are parallel, and oriented at a fixed angle to the moments of adjacent layers. This unusual antiferromagnetism transforms into a disordered paramagnetic state at 230 K.

The most common oxidation state of terbium is +3, as in . The +4 state is known in TbO and TbF.
Terbium burns readily to form a mixed terbium(III,IV) oxide:

In solution, terbium forms only trivalent ions. Terbium is quite electropositive and reacts slowly with cold water and quite quickly with hot water to form terbium hydroxide:

Terbium metal reacts with all the halogens, forming white trihalides:

Terbium dissolves readily in dilute sulfuric acid to form solutions containing the pale pink terbium(III) ions, which exist as [Tb(OH)] complexes:

Terbium combines with nitrogen, carbon, sulfur, phosphorus, boron, selenium, silicon and arsenic at elevated temperatures, forming various binary compounds such as TbH, TbH, TbB, TbS, TbSe, TbTe and TbN. In those compounds, Tb mostly exhibits the oxidation states +3 and sometimes +2. Terbium(II) halogenides are obtained by annealing Tb(III) halogenides in presence of metallic Tb in tantalum containers. Terbium also forms sesquichloride TbCl, which can be further reduced to TbCl by annealing at 800 °C. This terbium(I) chloride forms platelets with layered graphite-like structure.

Other compounds include 
Terbium(IV) fluoride is a strong fluorinating agent, emitting relatively pure atomic fluorine when heated rather than the mixture of fluoride vapors emitted from CoF or CeF.

Naturally occurring terbium is composed of its only stable isotope, terbium-159; the element is thus called mononuclidic and monoisotopic. Thirty-six radioisotopes have been characterized, with the heaviest being terbium-171 (with atomic mass of 170.95330(86) u) and lightest being terbium-135 (exact mass unknown). The most stable synthetic radioisotopes of terbium are terbium-158, with a half-life of 180 years, and terbium-157, with a half-life of 71 years. All of the remaining radioactive isotopes have half-lives that are much less than a quarter of a year, and the majority of these have half-lives that are less than half a minute. The primary decay mode before the most abundant stable isotope, Tb, is electron capture, which results in production of gadolinium isotopes, and the primary mode after is beta minus decay, resulting in dysprosium isotopes.

The element also has 27 nuclear isomers, with masses of 141–154, 156, and 158 (not every mass number corresponds to only one isomer). The most stable of them are terbium-156m, with half-life of 24.4 hours and terbium-156m2, with half-life of 22.7 hours; this is longer than half-lives of most ground states of radioactive terbium isotopes, except only those with mass numbers 155–161.

Swedish chemist Carl Gustaf Mosander discovered terbium in 1843. He detected it as an impurity in yttrium oxide, YO. Yttrium is named after the village of Ytterby in Sweden. Terbium was not isolated in pure form until the advent of ion exchange techniques.

Mosander first separated yttria into three fractions, all named for the ore: yttria, erbia, and terbia. "Terbia" was originally the fraction that contained the pink color, due to the element now known as erbium. "Erbia" (containing what we now call terbium) originally was the fraction that was essentially colorless in solution. The insoluble oxide of this element was noted to be tinged brown.

Later workers had difficulty in observing the minor colorless "erbia", but the soluble pink fraction was impossible to miss. Arguments went back and forth as to whether erbia even existed. In the confusion, the original names got reversed, and the exchange of names stuck, so that the pink fraction referred eventually to the solution containing erbium (which in solution, is pink). It is now thought that workers using double sodium or potassium sulfates to remove ceria from yttria inadvertently lost the terbium into the ceria-containing precipitate. What is now known as terbium was only about 1% of the original yttria, but that was sufficient to impart a yellowish color to the yttrium oxide. Thus, terbium was a minor component in the original fraction containing it, where it was dominated by its immediate neighbors, gadolinium and dysprosium.

Thereafter, whenever other rare earths were teased apart from this mixture, whichever fraction gave the brown oxide retained the terbium name, until at last, the brown oxide of terbium was obtained in pure form. The 19th century investigators did not have the benefit of the UV fluorescence technology to observe the brilliant yellow or green Tb(III) fluorescence that would have made terbium easier to identify in solid mixtures or solutions.

Terbium is contained along with other rare earth elements in many minerals, including monazite ((Ce,La,Th,Nd,Y)PO with up to 0.03% terbium), xenotime (YPO) and euxenite ((Y,Ca,Er,La,Ce,U,Th)(Nb,Ta,Ti)O with 1% or more terbium). The crust abundance of terbium is estimated as 1.2 mg/kg. No terbium-dominant mineral has yet been found.

Currently, the richest commercial sources of terbium are the ion-adsorption clays of southern China; the concentrates with about two-thirds yttrium oxide by weight have about 1% terbia. Small amounts of terbium occur in bastnäsite and monazite; when these are processed by solvent extraction to recover the valuable heavy lanthanides as samarium-europium-gadolinium concentrate, terbium is recovered therein. Due to the large volumes of bastnäsite processed relative to the ion-adsorption clays, a significant proportion of the world's terbium supply comes from bastnäsite.

Crushed terbium-containing minerals are treated with hot concentrated sulfuric acid to produce water-soluble sulfates of rare earths. The acidic filtrates are partially neutralized with caustic soda to pH 3–4. Thorium precipitates out of solution as hydroxide and is removed. After that the solution is treated with ammonium oxalate to convert rare earths into their insoluble oxalates. The oxalates are decomposed to oxides by heating. The oxides are dissolved in nitric acid that excludes one of the main components, cerium, whose oxide is insoluble in HNO. Terbium is separated as a double salt with ammonium nitrate by crystallization.

The most efficient separation routine for terbium salt from the rare-earth salt solution is ion exchange. In this process, rare-earth ions are sorbed onto suitable ion-exchange resin by exchange with hydrogen, ammonium or cupric ions present in the resin. The rare earth ions are then selectively washed out by suitable complexing agent. As with other rare earths, terbium metal is produced by reducing the anhydrous chloride or fluoride with calcium metal. Calcium and tantalum impurities can be removed by vacuum remelting, distillation, amalgam formation or zone melting.

Terbium is used as a dopant in calcium fluoride, calcium tungstate, and strontium molybdate, materials that are used in solid-state devices, and as a crystal stabilizer of fuel cells which operate at elevated temperatures, together with ZrO.

Terbium is also used in alloys and in the production of electronic devices. As a component of Terfenol-D, terbium is used in actuators, in naval sonar systems, sensors, in the SoundBug device (its first commercial application), and other magnetomechanical devices. Terfenol-D is a terbium alloy that expands or contracts in the presence of a magnetic field. It has the highest magnetostriction of any alloy.

Terbium oxide is used in green phosphors in fluorescent lamps and color TV tubes. Sodium terbium borate is used in solid state devices. The brilliant fluorescence allows terbium to be used as a probe in biochemistry, where it somewhat resembles calcium in its behavior. Terbium "green" phosphors (which fluoresce a brilliant lemon-yellow) are combined with divalent europium blue phosphors and trivalent europium red phosphors to provide the trichromatic lighting technology which is by far the largest consumer of the world's terbium supply. Trichromatic lighting provides much higher light output for a given amount of electrical energy than does incandescent lighting.

Terbium is also used to detect endospores, as it acts as an assay of dipicolinic acid based on photoluminescence.

As with the other lanthanides, terbium compounds are of low to moderate toxicity, although their toxicity has not been investigated in detail. Terbium has no known biological role.



</doc>
<doc id="30046" url="https://en.wikipedia.org/wiki?curid=30046" title="Tungsten">
Tungsten

Tungsten, or wolfram, is a chemical element with symbol W (referring to wolfram) and atomic number 74. The name "tungsten" comes from the former Swedish name for the tungstate mineral "scheelite", from "tung sten" "heavy stone". Tungsten is a rare metal found naturally on Earth almost exclusively combined with other elements in chemical compounds rather than alone. It was identified as a new element in 1781 and first isolated as a metal in 1783. Its important ores include wolframite and scheelite.

The free element is remarkable for its robustness, especially the fact that it has the highest melting point of all the elements discovered, melting at 3422 °C (6192 °F, 3695 K). It also has the highest boiling point, at 5930 °C (10706 °F, 6203 K). Its density is 19.3 times that of water, comparable to that of uranium and gold, and much higher (about 1.7 times) than that of lead. Polycrystalline tungsten is an intrinsically brittle and hard material (under standard conditions, when uncombined), making it difficult to work. However, pure single-crystalline tungsten is more ductile and can be cut with a hard-steel hacksaw.

Tungsten's many alloys have numerous applications, including incandescent light bulb filaments, X-ray tubes (as both the filament and target), electrodes in TIG welding, superalloys, and radiation shielding. Tungsten's hardness and high density give it military applications in penetrating projectiles. Tungsten compounds are also often used as industrial catalysts.

Tungsten is the only metal from the third transition series that is known to occur in biomolecules that are found in a few species of bacteria and archaea. It is the heaviest element known to be essential to any living organism. Tungsten interferes with molybdenum and copper metabolism and is somewhat toxic to animal life.

In its raw form, tungsten is a hard steel-grey metal that is often brittle and hard to work. If made very pure, tungsten retains its hardness (which exceeds that of many steels), and becomes malleable enough that it can be worked easily. It is worked by forging, drawing, or extruding. Tungsten objects are also commonly formed by sintering.

Of all metals in pure form, tungsten has the highest melting point (3422 °C, 6192 °F), lowest vapor pressure (at temperatures above 1650 °C, 3000 °F), and the highest tensile strength. Although carbon remains solid at higher temperatures than tungsten, carbon sublimes at atmospheric pressure instead of melting, so it has no melting point. Tungsten has the lowest coefficient of thermal expansion of any pure metal. The low thermal expansion and high melting point and tensile strength of tungsten originate from strong covalent bonds formed between tungsten atoms by the 5d electrons.
Alloying small quantities of tungsten with steel greatly increases its toughness.

Tungsten exists in two major crystalline forms: α and β. The former has a body-centered cubic structure and is the more stable form. The structure of the β phase is called A15 cubic; it is metastable, but can coexist with the α phase at ambient conditions owing to non-equilibrium synthesis or stabilization by impurities. Contrary to the α phase which crystallizes in isometric grains, the β form exhibits a columnar habit. The α phase has one third of the electrical resistivity and a much lower superconducting transition temperature T relative to the β phase: ca. 0.015 K vs. 1–4 K; mixing the two phases allows obtaining intermediate T values. The T value can also be raised by alloying tungsten with another metal (e.g. 7.9 K for W-Tc). Such tungsten alloys are sometimes used in low-temperature superconducting circuits.

Naturally occurring tungsten consists of five isotopes whose half-lives are so long that they can be considered stable. Theoretically, all five can decay into isotopes of element 72 (hafnium) by alpha emission, but only W has been observed to do so with a half-life of years; on average, this yields about two alpha decays of W per gram of natural tungsten per year. The other naturally occurring isotopes have not been observed to decay, constraining their half-lives to be at least 4 × 10 years.

Another 30 artificial radioisotopes of tungsten have been characterized, the most stable of which are W with a half-life of 121.2 days, W with a half-life of 75.1 days, W with a half-life of 69.4 days, W with a half-life of 21.6 days, and W with a half-life of 23.72 h. All of the remaining radioactive isotopes have half-lives of less than 3 hours, and most of these have half-lives below 8 minutes. Tungsten also has 4 meta states, the most stable being W ("t" 6.4 minutes).

Elemental tungsten resists attack by oxygen, acids, and alkalis.

The most common formal oxidation state of tungsten is +6, but it exhibits all oxidation states from −2 to +6. Tungsten typically combines with oxygen to form the yellow tungstic oxide, WO, which dissolves in aqueous alkaline solutions to form tungstate ions, .

Tungsten carbides (WC and WC) are produced by heating powdered tungsten with carbon. WC is resistant to chemical attack, although it reacts strongly with chlorine to form tungsten hexachloride (WCl).

In aqueous solution, tungstate gives the heteropoly acids and polyoxometalate anions under neutral and acidic conditions. As tungstate is progressively treated with acid, it first yields the soluble, metastable "paratungstate A" anion, , which over time converts to the less soluble "paratungstate B" anion, . Further acidification produces the very soluble metatungstate anion, , after which equilibrium is reached. The metatungstate ion exists as a symmetric cluster of twelve tungsten-oxygen octahedra known as the Keggin anion. Many other polyoxometalate anions exist as metastable species. The inclusion of a different atom such as phosphorus in place of the two central hydrogens in metatungstate produces a wide variety of heteropoly acids, such as phosphotungstic acid HPWO.

Tungsten trioxide can form intercalation compounds with alkali metals. These are known as "bronzes"; an example is sodium tungsten bronze.

In 1781, Carl Wilhelm Scheele discovered that a new acid, tungstic acid, could be made from scheelite (at the time named tungsten). Scheele and Torbern Bergman suggested that it might be possible to obtain a new metal by reducing this acid. In 1783, José and Fausto Elhuyar found an acid made from wolframite that was identical to tungstic acid. Later that year, at the Royal Basque Society in the town of Bergara, Spain, the brothers succeeded in isolating tungsten by reduction of this acid with charcoal, and they are credited with the discovery of the element.

The strategic value of tungsten came to notice in the early 20th century. British authorities acted in 1912 to free the Carrock mine from the German owned Cumbrian Mining Company and, during World War I, restrict German access elsewhere. In World War II, tungsten played a more significant role in background political dealings. Portugal, as the main European source of the element, was put under pressure from both sides, because of its deposits of wolframite ore at Panasqueira. Tungsten's desirable properties such as resistance to high temperatures, its hardness and density, and its strengthening of alloys made it an important raw material for the arms industry, both as a constituent of weapons and equipment and employed in production itself, e.g., in tungsten carbide cutting tools for machining steel.

The name "tungsten" (from the Swedish "tung sten", "heavy stone") is used in English, French, and many other languages as the name of the element, but not in the Nordic countries. Tungsten was the old Swedish name for the mineral scheelite. "Wolfram" (or "volfram") is used in most European (especially Germanic and Slavic) languages and is derived from the mineral wolframite, which is the origin of the chemical symbol W. The name "wolframite" is derived from German ""wolf rahm"" ("wolf soot" or "wolf cream"), the name given to tungsten by Johan Gottschalk Wallerius in 1747. This, in turn, derives from ""lupi spuma"", the name Georg Agricola used for the element in 1546, which translates into English as "wolf's froth" and is a reference to the large amounts of tin consumed by the mineral during its extraction.

Tungsten is found mainly in the minerals wolframite (iron–manganese tungstate (Fe,Mn)WO, which is a solid solution of the two minerals ferberite FeWO, and hübnerite MnWO) and scheelite (calcium tungstate (CaWO). Other tungsten minerals range in their level of abundance from moderate to very rare, and have almost no economical value.

Tungsten forms chemical compounds in oxidation states from -II to VI. Higher oxidation states, always as oxides, are relevant to its terrestrial occurrence and its biological roles, mid-level oxidation states are often associated with metal clusters, and very low oxidation states are typically associated with CO complexes. Mo and W chemistry shows strong similarities. The relative rarity of tungsten(III), for example, contrasts with the pervasiveness of the chromium(III) compounds. The highest oxidation state is seen in tungsten(VI) oxide (WO). The trioxide, which is volatile at high temperatures, is the precursor to virtually all other Mo compounds as well as alloys. Molybdenum has several oxidation states, the most stable being +4 and +6 (bolded in the table at left). 

Tungsten(VI) oxide is soluble in aqueous base , forming tungstate (WO). This oxyanion condenses at lower pH values, forming polyoxotungstates. 

The broad range of oxidation states of tungsten is reflected in it various chlorides:

Organotungsten compounds are numerous and also span a range of oxidation states. Notable examples include the trigonal prismatic W(CH) and octahedral W(CO).

About 61,300 tonnes of tungsten concentrates were produced in the year 2009, and in 2010, world production of tungsten was about 68,000 tonnes. The main producers were as follows (data in tonnes):

There is additional production in the U.S., but the amount is proprietary company information. U.S. reserves are 140,000 tonnes. US industrial use of wolfram is 20,000 tonnes: 15,000 tonnes are imported and the remaining 5,000 tonnes come from domestic recycling.

Tungsten is considered to be a conflict mineral due to the unethical mining practices observed in the Democratic Republic of the Congo.

There is a large deposit of tungsten ore on the edge of Dartmoor in the United Kingdom, which was exploited during World War I and World War II as the Hemerdon Mine. With recent increases in tungsten prices, as of 2014 this mine has been reactivated.

Tungsten is extracted from its ores in several stages. The ore is eventually converted to tungsten(VI) oxide (WO), which is heated with hydrogen or carbon to produce powdered tungsten. Because of tungsten's high melting point, it is not commercially feasible to cast tungsten ingots. Instead, powdered tungsten is mixed with small amounts of powdered nickel or other metals, and sintered. During the sintering process, the nickel diffuses into the tungsten, producing an alloy.

Tungsten can also be extracted by hydrogen reduction of WF:

or pyrolytic decomposition:

Tungsten is not traded as a futures contract and cannot be tracked on exchanges like the London Metal Exchange. The prices are usually quoted for tungsten concentrate or WO. If converted to the metal equivalent, they were about US$19 per kilogram in 2009.

Approximately half of the tungsten is consumed for the production of hard materials – namely tungsten carbide – with the remaining major use being in alloys and steels. Less than 10% is used in other chemical compounds.

Tungsten is mainly used in the production of hard materials based on tungsten carbide, one of the hardest carbides, with a melting point of 2770 °C. WC is an efficient electrical conductor, but WC is less so. WC is used to make wear-resistant abrasives, and "carbide" cutting tools such as knives, drills, circular saws, milling and turning tools used by the metalworking, woodworking, mining, petroleum and construction industries. Carbide tooling is actually a ceramic/metal composite, where metallic cobalt acts as a binding (matrix) material to hold the WC particles in place. This type of industrial use accounts for about 60% of current tungsten consumption.

The jewelry industry makes rings of sintered tungsten carbide, tungsten carbide/metal composites, and also metallic tungsten. WC/metal composite rings use nickel as the metal matrix in place of cobalt because it takes a higher luster when polished. Sometimes manufacturers or retailers refer to tungsten carbide as a metal, but it is a ceramic. Because of tungsten carbide's hardness, rings made of this material are extremely abrasion resistant, and will hold a burnished finish longer than rings made of metallic tungsten. Tungsten carbide rings are brittle, however, and may crack under a sharp blow.

The hardness and density of tungsten are applied in obtaining heavy metal alloys. A good example is high speed steel, which can contain as much as 18% tungsten. Tungsten's high melting point makes tungsten a good material for applications like rocket nozzles, for example in the UGM-27 Polaris submarine-launched ballistic missile. Tungsten alloys are used in a wide range of different applications, including the aerospace and automotive industries and radiation shielding. Superalloys containing tungsten, such as Hastelloy and Stellite, are used in turbine blades and wear-resistant parts and coatings.

Quenched (martensitic) tungsten steel (approx. 5.5% to 7.0% W with 0.5% to 0.7% C) was used for making hard permanent magnets, due to its high remanence and coercivity, as noted by John Hopkinson (1849 - 1898) as early as 1886. The magnetic properties of a metal or an alloy are very sensitive to microstructure. For example, while the element tungsten is not ferromagnetic (but iron is), when present in steel in these proportions, it stabilizes the martensite phase, which has an enhanced ferromagnetism, as compared to the ferrite (iron) phase, due to its greater resistance to magnetic domain wall motion.

Tungsten's heat resistance makes it useful in arc welding applications when combined with another highly-conductive metal such as silver or copper. The silver or copper provides the necessary conductivity and the tungsten allows the welding rod to withstand the high-temperatures of the arc welding environment.

Tungsten, usually alloyed with nickel and iron or cobalt to form heavy alloys, is used in kinetic energy penetrators as an alternative to depleted uranium, in applications where uranium's radioactivity is problematic even in depleted form, or where uranium's additional pyrophoric properties are not required (for example, in ordinary small arms bullets designed to penetrate body armor). Similarly, tungsten alloys have also been used in cannon shells, grenades and missiles, to create supersonic shrapnel. Germany used tungsten during World War II to produce shells for anti-tank gun designs using the Gerlich squeeze bore principle to achieve very high muzzle velocity and enhanced armor penetration from comparatively small caliber and light weight field artillery. The weapons were highly effective but a shortage of tungsten used in the shell core limited that effectiveness.

Tungsten has also been used in Dense Inert Metal Explosives, which use it as dense powder to reduce collateral damage while increasing the lethality of explosives within a small radius.

Tungsten(IV) sulfide is a high temperature lubricant and is a component of catalysts for hydrodesulfurization. MoS is more commonly used for such applications.

Tungsten oxides are used in ceramic glazes and calcium/magnesium tungstates are used widely in fluorescent lighting. Crystal tungstates are used as scintillation detectors in nuclear physics and nuclear medicine. Other salts that contain tungsten are used in the chemical and tanning industries.
Tungsten oxide (WO) is incorporated into selective catalytic reduction (SCR) catalysts found in coal-fired power plants. These catalysts convert nitrogen oxides (NO) to nitrogen (N) and water (HO) using ammonia (NH). The tungsten oxide helps with the physical strength of the catalyst and extends catalyst life.

Applications requiring its high density include weights, counterweights, ballast keels for yachts, tail ballast for commercial aircraft, and as ballast in race cars for NASCAR and Formula One; depleted uranium is also used for these purposes, due to similarly high density. Seventy-five-kg blocks of tungsten were used as "cruise balance mass devices" on the entry vehicle portion of the 2012 Mars Science Laboratory spacecraft. It is an ideal material to use as a dolly for riveting, where the mass necessary for good results can be achieved in a compact bar. High-density alloys of tungsten with nickel, copper or iron are used in high-quality darts (to allow for a smaller diameter and thus tighter groupings) or for fishing lures (tungsten beads allow the fly to sink rapidly). Some cello C strings are wound with tungsten. The extra density gives this string more projection and often cellists will buy just this string and use it with three strings from a different set. Tungsten is used as an absorber on the electron telescope on the Cosmic Ray System of the two Voyager spacecraft.

Sodium tungstate is used in Folin-Ciocalteu's reagent, a mixture of different chemicals used in the "Lowry Assay" for protein content analysis.

Its density, similar to that of gold, allows tungsten to be used in jewelry as an alternative to gold or platinum. Metallic tungsten is hypoallergenic, and is harder than gold alloys (though not as hard as tungsten carbide), making it useful for rings that will resist scratching, especially in designs with a brushed finish.

Because the density is so similar to that of gold (tungsten is only 0.36% less dense), tungsten can also be used in counterfeiting of gold bars, such as by plating a tungsten bar with gold, which has been observed since the 1980s, or taking an existing gold bar, drilling holes, and replacing the removed gold with tungsten rods. The densities are not exactly the same, and other properties of gold and tungsten differ, but gold-plated tungsten will pass superficial tests.

Gold-plated tungsten is available commercially from China (the main source of tungsten), both in jewelry and as bars.

Because it retains its strength at high temperatures and has a high melting point, elemental tungsten is used in many high-temperature applications, such as light bulb, cathode-ray tube, and vacuum tube filaments, heating elements, and rocket engine nozzles. Its high melting point also makes tungsten suitable for aerospace and high-temperature uses such as electrical, heating, and welding applications, notably in the gas tungsten arc welding process (also called tungsten inert gas (TIG) welding).
Because of its conductive properties and relative chemical inertness, tungsten is also used in electrodes, and in the emitter tips in electron-beam instruments that use field emission guns, such as electron microscopes. In electronics, tungsten is used as an interconnect material in integrated circuits, between the silicon dioxide dielectric material and the transistors. It is used in metallic films, which replace the wiring used in conventional electronics with a coat of tungsten (or molybdenum) on silicon.

The electronic structure of tungsten makes it one of the main sources for X-ray targets, and also for shielding from high-energy radiations (such as in the radiopharmaceutical industry for shielding radioactive samples of FDG). It is also used in gamma imaging as a material from which coded apertures are made, due to its excellent shielding properties. Tungsten powder is used as a filler material in plastic composites, which are used as a nontoxic substitute for lead in bullets, shot, and radiation shields. Since this element's thermal expansion is similar to borosilicate glass, it is used for making glass-to-metal seals. In addition to its high melting point, when tungsten is doped with potassium, it leads to an increased shape stability (compared to non-doped tungsten). This ensures that the filament does not sag, and no undesired changes occur.

Through top-down nanofabrication processes, tungsten nanowires have been fabricated and studied since 2002. Due to a particularly high surface to volume ratio, the formation of a surface oxide layer and the single crystal nature of such material, the mechanical properties differ fundamentally from those of bulk tungsten. Such tungsten nanowires have potential applications in nanoelectronics and importantly as pH probes and gas sensors. In similarity to silicon nanowires, tungsten nanowires are frequently produced from a bulk tungsten precursor followed by a thermal oxidation step to control morphology in terms of length and aspect ratio. Using the Deal–Grove model it is possible to predict the oxidation kinetics of nanowires fabricated through such thermal oxidation processing.

Tungsten, at atomic number 74, is the heaviest element known to be biologically functional, with the next heaviest being iodine ("Z" = 53). It is used by some bacteria and archaea, but not in eukaryotes. For example, enzymes called oxidoreductases use tungsten similarly to molybdenum by using it in a tungsten-pterin complex with molybdopterin (molybdopterin, despite its name, does not contain molybdenum, but may complex with either molybdenum or tungsten in use by living organisms). Tungsten-using enzymes typically reduce carboxylic acids to aldehydes. The tungsten oxidoreductases may also catalyse oxidations. The first tungsten-requiring enzyme to be discovered also requires selenium, and in this case the tungsten-selenium pair may function analogously to the molybdenum-sulfur pairing of some molybdenum cofactor-requiring enzymes. One of the enzymes in the oxidoreductase family which sometimes employ tungsten (bacterial formate dehydrogenase H) is known to use a selenium-molybdenum version of molybdopterin. Acetylene hydratase is an unusual metalloenzyme in that it catalyzes a hydration reaction. Two reaction mechanisms have been proposed, in one of which there is a direct interaction between the tungsten atom and the C≡C triple bond. Although a tungsten-containing xanthine dehydrogenase from bacteria has been found to contain tungsten-molydopterin and also non-protein bound selenium, a tungsten-selenium molybdopterin complex has not been definitively described.

In soil, tungsten metal oxidizes to the tungstate anion. It can be selectively or non-selectively imported by some prokaryotic organisms and may substitute for molybdate in certain enzymes. Its effect on the action of these enzymes is in some cases inhibitory and in others positive. The soil's chemistry determines how the tungsten polymerizes; alkaline soils cause monomeric tungstates; acidic soils cause polymeric tungstates.

Sodium tungstate and lead have been studied for their effect on earthworms. Lead was found to be lethal at low levels and sodium tungstate was much less toxic, but the tungstate completely inhibited their reproductive ability.

Tungsten has been studied as a biological copper metabolic antagonist, in a role similar to the action of molybdenum. It has been found that tetrathiotungstates may be used as biological copper chelation chemicals, similar to the tetrathiomolybdates.
Tungsten is essential for some archaea. The following tungsten-utilizing enzymes are known:
A "wtp" system is known to selectively transport tungsten in archaea:

Because tungsten is rare and its compounds are generally inert, the effects of tungsten on the environment are limited.
It was first believed to be relatively inert and an only slightly toxic metal, beginning in the year 2000, the risk exerted by tungsten alloys, its dusts and particulates to induce cancer and several other adverse effects in animals as well as humans has been highlighted from in vitro and in vivo experiments.
The median lethal dose LD depends strongly on the animal and the method of administration and varies between 59 mg/kg (intravenous, rabbits) and 5000 mg/kg (tungsten metal powder, intraperitoneal, rats).

People can be exposed to tungsten in the workplace by breathing it in, swallowing it, skin contact, and eye contact. The National Institute for Occupational Safety and Health (NIOSH) has set a recommended exposure limit (REL) of 5 mg/m over an 8-hour workday and a short term limit of 10 mg/m.

Tungsten is unique amongst the elements in that it has been the subject of patent proceedings. In 1928, a US court rejected General Electric's attempt to patent it, overturning granted in 1913 to William D. Coolidge.



</doc>
<doc id="30047" url="https://en.wikipedia.org/wiki?curid=30047" title="Thulium">
Thulium

Thulium is a chemical element with symbol Tm and atomic number 69. It is the thirteenth and third-last element in the lanthanide series. Like the other lanthanides, the most common oxidation state is +3, seen in its oxide, halides and other compounds; because it occurs so late in the series, however, the +2 oxidation state is also stabilized by the nearly full 4f shell that results. In aqueous solution, like compounds of other late lanthanides, soluble thulium compounds form coordination complexes with nine water molecules.

In 1879, the Swedish chemist Per Teodor Cleve separated from the rare earth oxide erbia another two previously unknown components, which he called holmia and thulia; these were the oxides of holmium and thulium, respectively. A relatively pure sample of thulium metal was first obtained in 1911.

Thulium is the second-least abundant of the lanthanides, after radioactively unstable promethium which is only found in trace quantities on Earth. It is an easily workable metal with a bright silvery-gray luster. It is fairly soft and slowly tarnishes in air. Despite its high price and rarity, thulium is used as the radiation source in portable X-ray devices, and in some solid-state lasers. It has no significant biological role and is not particularly toxic.

Pure thulium metal has a bright, silvery luster, which tarnishes on exposure to air. The metal can be cut with a knife, as it has a Mohs hardness of 2 to 3; it is malleable and ductile. Thulium is ferromagnetic below 32K, antiferromagnetic between 32 and 56K, and paramagnetic above 56K.

Thulium has two major allotropes: the tetragonal α-Tm and the more stable hexagonal β-Tm.

Thulium tarnishes slowly in air and burns readily at 150°C to form thulium(III) oxide:

Thulium is quite electropositive and reacts slowly with cold water and quite quickly with hot water to form thulium hydroxide:

Thulium reacts with all the halogens. Reactions are slow at room temperature, but are vigorous above 200°C:

Thulium dissolves readily in dilute sulfuric acid to form solutions containing the pale green Tm(III) ions, which exist as [Tm(OH)] complexes:

Thulium reacts with various metallic and non-metallic elements forming a range of binary compounds, including TmN, TmS, TmC, TmC, TmH, TmH, TmSi, TmGe, TmB, TmB and TmB. In those compounds, thulium exhibits valence states +2 and +3, however, the +3 state is most common and only this state has been observed in thulium solutions. Thulium exists as a Tm ion in solution. In this state, the thulium ion is surrounded by nine molecules of water. Tm ions exhibit a bright blue luminescence.

Thulium's only known oxide is TmO. This oxide is sometimes called "thulia". Reddish-purple thulium(II) compounds can be made by the reduction of thulium(III) compounds. Examples of thulium(II) compounds include the halides (except the fluoride). Some hydrated thulium compounds, such as TmCl·7HO and Tm(CO)·6HO are green or greenish-white. Thulium dichloride reacts very vigorously with water. This reaction results in hydrogen gas and Tm(OH) exhibiting a fading reddish color. Combination of thulium and chalcogens results in thulium chalcogenides.

Thulium reacts with hydrogen chloride to produce hydrogen gas and thulium chloride. With nitric acid it yields thulium nitrate, or Tm(NO).

The isotopes of thulium range from Tm to Tm. The primary decay mode before the most abundant stable isotope, Tm, is electron capture, and the primary mode after is beta emission. The primary decay products before Tm are element 68 (erbium) isotopes, and the primary products after are element 70 (ytterbium) isotopes.

Thulium-169 is thulium's longest-lived and most abundant isotope. It is the only isotope of thulium that is thought to be stable, although it is predicted to undergo alpha decay to holmium-165 with a very long half-life. After thulium-169, the next-longest-lived isotopes are thulium-171, which has a half-life of 1.92 years, and thulium-170, which has a half-life of 128.6 days. Most other isotopes have half-lives of a few minutes or less. Thirty-five isotopes and 26 nuclear isomers of thulium have been detected. Most isotopes of thulium lighter than 169 atomic mass units decay via electron capture or beta-plus decay, although some exhibit significant alpha decay or proton emission. Heavier isotopes undergo beta-minus decay.

Thulium was discovered by Swedish chemist Per Teodor Cleve in 1879 by looking for impurities in the oxides of other rare earth elements (this was the same method Carl Gustaf Mosander earlier used to discover some other rare earth elements). Cleve started by removing all of the known contaminants of erbia (ErO). Upon additional processing, he obtained two new substances; one brown and one green. The brown substance was the oxide of the element holmium and was named holmia by Cleve, and the green substance was the oxide of an unknown element. Cleve named the oxide thulia and its element thulium after Thule, an Ancient Greek place name associated with Scandinavia or Iceland. Thulium's atomic symbol was once Tu, but this was changed to Tm.

Thulium was so rare that none of the early workers had enough of it to purify sufficiently to actually see the green color; they had to be content with spectroscopically observing the strengthening of the two characteristic absorption bands, as erbium was progressively removed. The first researcher to obtain nearly pure thulium was Charles James, a British expatriate working on a large scale at New Hampshire College in Durham. In 1911 he reported his results, having used his discovered method of bromate fractional crystallization to do the purification. He famously needed 15,000 purification operations to establish that the material was homogeneous.

High-purity thulium oxide was first offered commercially in the late 1950s, as a result of the adoption of ion-exchange separation technology. Lindsay Chemical Division of American Potash & Chemical Corporation offered it in grades of 99% and 99.9% purity. The price per kilogram has oscillated between US$4,600 and $13,300 in the period from 1959 to 1998 for 99.9% purity, and it was second highest for lanthanides behind lutetium.

The element is never found in nature in pure form, but it is found in small quantities in minerals with other rare earths. Thulium is often found with minerals containing yttrium and gadolinium. In particular, thulium occurs in the mineral gadolinite. However, thulium also occurs in the minerals monazite, xenotime, and euxenite. Thulium has not been found in prevalence over the other rare earths in any mineral yet. Its abundance in the Earth's crust is 0.5 mg/kg by weight and 50 parts per billion by moles. Thulium makes up approximately 0.5 parts per million of soil, although this value can range from 0.4 to 0.8 parts per million. Thulium makes up 250 parts per quadrillion of seawater. In the solar system, thulium exists in concentrations of 200 parts per trillion by weight and 1 part per trillion by moles. Thulium ore occurs most commonly in China. However, Australia, Brazil, Greenland, India, Tanzania, and the United States also have large reserves of thulium. Total reserves of thulium are approximately 100,000 tonnes. Thulium is the least abundant lanthanide on earth except for promethium.

Thulium is principally extracted from monazite ores (~0.007% thulium) found in river sands, through ion-exchange. Newer ion-exchange and solvent-extraction techniques have led to easier separation of the rare earths, which has yielded much lower costs for thulium production. The principal sources today are the ion adsorption clays of southern China. In these, where about two-thirds of the total rare-earth content is yttrium, thulium is about 0.5% (or about tied with lutetium for rarity). The metal can be isolated through reduction of its oxide with lanthanum metal or by calcium reduction in a closed container. None of thulium's natural compounds are commercially important. Approximately 50 tonnes per year of thulium oxide are produced. In 1996, thulium oxide cost US$20 per gram, and in 2005, 99%-pure thulium metal powder cost US$70 per gram.

Thulium has a few applications:

Holmium-chromium-thulium triple-doped yttrium aluminum garnet (Ho:Cr:Tm:YAG, or Ho,Cr,Tm:YAG) is an active laser medium material with high efficiency. It lases at 2080 nm and is widely used in military applications, medicine, and meteorology. Single-element thulium-doped YAG (Tm:YAG) lasers operate at 2,01 μm. The wavelength of thulium-based lasers is very efficient for superficial ablation of tissue, with minimal coagulation depth in air or in water. This makes thulium lasers attractive for laser-based surgery.

Despite its high cost, portable X-ray devices use thulium that has been bombarded in a nuclear reactor as a radiation source. These sources have a useful life of about one year, as tools in medical and dental diagnosis, as well as to detect defects in inaccessible mechanical and electronic components. Such sources do not need extensive radiation protection – only a small cup of lead.

Thulium-170 is gaining popularity as an X-ray source for cancer treatment via brachytherapy. This isotope has a half-life of 128.6 days and five major emission lines of comparable intensity (at 7.4, 51.354, 52.389, 59.4 and 84.253 keV). Thulium-170 is one of the four most popular radioisotopes for use in industrial radiography.

Thulium has been used in high-temperature superconductors similarly to yttrium. Thulium potentially has use in ferrites, ceramic magnetic materials that are used in microwave equipment. Thulium is also similar to scandium in that it is used in arc lighting for its unusual spectrum, in this case, its green emission lines, which are not covered by other elements. Because thulium fluoresces with a blue color when exposed to ultraviolet light, thulium is put into euro banknotes as a measure against counterfeiting. The blue fluorescence of Tm-doped calcium sulfate has been used in personal dosimeters for visual monitoring of radiation. Tm-doped halides which Tm is in its 2+ valence state, are promising luminescent materials that can make efficient electricity generating windows based on the principle of a luminescent solar concentrator, possible .

Soluble thulium salts are mildly toxic, but insoluble thulium salts are completely nontoxic. When injected, thulium can cause degeneration of the liver and spleen and can also cause hemoglobin concentration to fluctuate. Liver damage from thulium is more prevalent in male mice than female mice. Despite this, thulium has a low level of toxicity. In humans, thulium occurs in the highest amounts in the liver, kidneys and bones. Humans typically consume several micrograms of thulium per year. The roots of plants do not take up thulium, and the dry weight of vegetables usually contains one part per billion of thulium. Thulium dust and powder are toxic upon inhalation or ingestion and can cause explosions. Radioactive thulium isotopes can cause radiation poisoning.



</doc>
<doc id="30048" url="https://en.wikipedia.org/wiki?curid=30048" title="Tantalum">
Tantalum

Tantalum is a chemical element with symbol Ta and atomic number 73. Previously known as "tantalium", its name comes from "Tantalus", a villain from Greek mythology. Tantalum is a rare, hard, blue-gray, lustrous transition metal that is highly corrosion-resistant. It is part of the refractory metals group, which are widely used as minor components in alloys. The chemical inertness of tantalum makes it a valuable substance for laboratory equipment and a substitute for platinum. Its main use today is in tantalum capacitors in electronic equipment such as mobile phones, DVD players, video game systems and computers.
Tantalum, always together with the chemically similar niobium, occurs in the mineral groups tantalite, columbite and coltan (a mix of columbite and tantalite, though not recognised as a separate mineral species).

Tantalum was discovered in Sweden in 1802 by Anders Ekeberg. One year earlier, Charles Hatchett had discovered columbium (now niobium), and in 1809 the English chemist William Hyde Wollaston compared its oxide, columbite with a density of 5.918 g/cm, to that of tantalum, tantalite with a density of 7.935 g/cm. He concluded that the two oxides, despite their difference in measured density, were identical and kept the name tantalum. After Friedrich Wöhler confirmed these results, it was thought that columbium and tantalum were the same element. This conclusion was disputed in 1846 by the German chemist Heinrich Rose, who argued that there were two additional elements in the tantalite sample, and he named them after the children of Tantalus: niobium (from Niobe, the goddess of tears), and pelopium (from Pelops). The supposed element "pelopium" was later identified as a mixture of tantalum and niobium, and it was found that the niobium was identical to the columbium already discovered in 1801 by Hatchett.

The differences between tantalum and niobium were demonstrated unequivocally in 1864 by Christian Wilhelm Blomstrand, and Henri Etienne Sainte-Claire Deville, as well as by Louis J. Troost, who determined the empirical formulas of some of their compounds in 1865. Further confirmation came from the Swiss chemist Jean Charles Galissard de Marignac, in 1866, who proved that there were only two elements. These discoveries did not stop scientists from publishing articles about the so-called "ilmenium" until 1871. De Marignac was the first to produce the metallic form of tantalum in 1864, when he reduced tantalum chloride by heating it in an atmosphere of hydrogen. Early investigators had only been able to produce impure tantalum, and the first relatively pure ductile metal was produced by Werner von Bolton in Charlottenburg in 1903. Wires made with metallic tantalum were used for light bulb filaments until tungsten replaced it in widespread use.

The name tantalum was derived from the name of the mythological Tantalus, the father of Niobe in Greek mythology. In the story, he had been punished after death by being condemned to stand knee-deep in water with perfect fruit growing above his head, both of which eternally "tantalized" him. (If he bent to drink the water, it drained below the level he could reach, and if he reached for the fruit, the branches moved out of his grasp.) Anders Ekeberg wrote "This metal I call "tantalum" ... partly in allusion to its incapacity, when immersed in acid, to absorb any and be saturated."

For decades, the commercial technology for separating tantalum from niobium involved the fractional crystallization of potassium heptafluorotantalate away from potassium oxypentafluoroniobate monohydrate, a process that was discovered by Jean Charles Galissard de Marignac in 1866. This method has been supplanted by solvent extraction from fluoride-containing solutions of tantalum.

Tantalum is dark (blue-gray), dense, ductile, very hard, easily fabricated, and highly conductive of heat and electricity. The metal is renowned for its resistance to corrosion by acids; in fact, at temperatures below 150 °C tantalum is almost completely immune to attack by the normally aggressive aqua regia. It can be dissolved with hydrofluoric acid or acidic solutions containing the fluoride ion and sulfur trioxide, as well as with a solution of potassium hydroxide. Tantalum's high melting point of 3017 °C (boiling point 5458 °C) is exceeded among the elements only by tungsten, rhenium and osmium for metals, and carbon.

Tantalum exists in two crystalline phases, alpha and beta. The alpha phase is relatively ductile and soft; it has body-centered cubic structure (space group "Im3m", lattice constant "a" = 0.33058 nm), Knoop hardness 200–400 HN and electrical resistivity 15–60 µΩ⋅cm. The beta phase is hard and brittle; its crystal symmetry is tetragonal (space group "P42/mnm", "a" = 1.0194 nm, "c" = 0.5313 nm), Knoop hardness is 1000–1300 HN and electrical resistivity is relatively high at 170–210 µΩ⋅cm. The beta phase is metastable and converts to the alpha phase upon heating to 750–775 °C. Bulk tantalum is almost entirely alpha phase, and the beta phase usually exists as thin films obtained by magnetron
sputtering, chemical vapor deposition or electrochemical deposition from an eutectic molten salt solution.

Natural tantalum consists of two isotopes: Ta (0.012%) and Ta (99.988%). Ta is a stable isotope. Ta ("m" denotes a metastable state) is predicted to decay in three ways: isomeric transition to the ground state of Ta, beta decay to W, or electron capture to Hf. However, radioactivity of this nuclear isomer has never been observed, and only a lower limit on its half-life of 2.0 × 10 years has been set. The ground state of Ta has a half-life of only 8 hours. Ta is the only naturally occurring nuclear isomer (excluding radiogenic and cosmogenic short-living nuclides). It is also the rarest isotope in the Universe, taking into account the elemental abundance of tantalum and isotopic abundance of Ta in the natural mixture of isotopes (and again excluding radiogenic and cosmogenic short-living nuclides).

Tantalum has been examined theoretically as a "salting" material for nuclear weapons (cobalt is the better-known hypothetical salting material). An external shell of Ta would be irradiated by the intensive high-energy neutron flux from a hypothetical exploding nuclear weapon. This would transmute the tantalum into the radioactive isotope Ta, which has a half-life of 114.4 days and produces gamma rays with approximately 1.12 million electron-volts (MeV) of energy apiece, which would significantly increase the radioactivity of the nuclear fallout from the explosion for several months. Such "salted" weapons have never been built or tested, as far as is publicly known, and certainly never used as weapons.

Tantalum can be used as a target material for accelerated proton beams for the production of various short-lived isotopes including Li, Rb, and Yb.

Tantalum forms compounds in oxidation states -III to V. Most commonly encountered are oxides of Ta(V), which includes all minerals. The chemical properties of Ta and Nb are very similar.

Tantalum pentoxide (TaO) is the most important compound from the perspective of applications. Oxides of tantalum in lower oxidation states are numerous, including many defect structures, are lightly studied or poorly characterized.

Tantalates, compounds containing [TaO] or [TaO] are numerous. Lithium tantalate (LiTaO) adopts a perovskite structure. Lanthanum tantalate (LaTaO) contains isolated tetrahedra.

As in the cases of other refractory metals, the hardest known compounds of tantalum are nitrides and carbides. Tantalum carbide, TaC, like the more commonly used tungsten carbide, is a hard ceramic that is used in cutting tools. Tantalum(III) nitride is used as a thin film insulator in some microelectronic fabrication processes.

The best studied chalcogenide is TaS, a layered semiconductor, as seen for other transition metal dichalcogenides. A tantalum-tellurium alloy forms quasicrystals.

Tantalum halides span the oxidation states of +5, +4, and +3. Tantalum pentafluoride (TaF) is a white solid with a melting point of 97.0 °C. The anion [TaF] is used for its separation from niobium. The chloride , which exists as a dimer, is the main reagent in synthesis of new Ta compounds. It hydrolyzes readily to an oxychloride. The lower halides and , feature Ta-Ta bonds.

Organotantalum compounds include pentamethyltantalum, mixed alkyltantalum chlorides, alkyltantalum hydrides, alkylidene complexes as well as cyclopentadienyl derivatives of the same. Diverse salts and substituted derivatives are known for the hexacarbonyl [Ta(CO)] and related isocyanides.
Tantalum is estimated to make up about 1 ppm or 2 ppm of the Earth's crust by weight. There are many species of tantalum minerals, only some of which are so far being used by industry as raw materials: tantalite (a series consisting of tantalite-(Fe), tantalite-(Mn) and tantalite-(Mg)) microlite (now a group name), wodginite, euxenite (actually euxenite-(Y)), and polycrase (actually polycrase-(Y)). Tantalite (Fe, Mn)TaO is the most important mineral for tantalum extraction. Tantalite has the same mineral structure as columbite (Fe, Mn) (Ta, Nb)O; when there is more tantalum than niobium it is called tantalite and when there is more niobium than tantalum is it called columbite (or niobite). The high density of tantalite and other tantalum containing minerals makes the use of gravitational separation the best method. Other minerals include samarskite and fergusonite.

The primary mining of tantalum is in Australia, where the largest producer, Global Advanced Metals, formerly known as Talison Minerals, operates two mines in Western Australia, Greenbushes in the Southwest and Wodgina in the Pilbara region. The Wodgina mine was reopened in January 2011 after mining at the site was suspended in late-2008 due to the global financial crisis. Less than a year after it reopened, Global Advanced Metals announced that due to again "... softening tantalum demand ...", and other factors, tantalum mining operations were to cease at the end of February 2012. Wodgina produces a primary tantalum concentrate which is further upgraded at the Greenbushes operation before being sold to customers. Whereas the large-scale producers of niobium are in Brazil and Canada, the ore there also yields a small percentage of tantalum. Some other countries such as China, Ethiopia, and Mozambique mine ores with a higher percentage of tantalum, and they produce a significant percentage of the world's output of it. Tantalum is also produced in Thailand and Malaysia as a by-product of the tin mining there. During gravitational separation of the ores from placer deposits, not only is cassiterite (SnO) found, but a small percentage of tantalite also included. The slag from the tin smelters then contains economically useful amounts of tantalum, which is leached from the slag.

World tantalum mine production has undergone an important geographic shift since the start of the 21st century when production was predominantly from Australia and Brazil. Beginning in 2007 and through 2014, the major sources of tantalum production from mines dramatically shifted to the DRC, Rwanda, and some other African countries. Future sources of supply of tantalum, in order of estimated size, are being explored in Saudi Arabia, Egypt, Greenland, China, Mozambique, Canada, Australia, the United States, Finland, and Brazil.

It is estimated that there are less than 50 years left of tantalum resources, based on extraction at current rates, demonstrating the need for increased recycling.

Tantalum is considered a conflict resource. Coltan, the industrial name for a columbite–tantalite mineral from which niobium and tantalum are extracted, can also be found in Central Africa, which is why tantalum is being linked to warfare in the Democratic Republic of the Congo (formerly Zaire). According to an October 23, 2003 United Nations report, the smuggling and exportation of coltan has helped fuel the war in the Congo, a crisis that has resulted in approximately 5.4 million deaths since 1998 – making it the world’s deadliest documented conflict since World War II. Ethical questions have been raised about responsible corporate behavior, human rights, and endangering wildlife, due to the exploitation of resources such as coltan in the armed conflict regions of the Congo Basin. However, although important for the local economy in Congo, the contribution of coltan mining in Congo to the world supply of tantalum is usually small. The United States Geological Survey reports in its yearbook that this region produced a little less than 1% of the world's tantalum output in 2002–2006, peaking at 10% in 2000 and 2008.

The stated aim of the "Solutions for Hope Tantalum Project" is to "source conflict-free tantalum from the Democratic Republic of Congo"

Several steps are involved in the extraction of tantalum from tantalite. First, the mineral is crushed and concentrated by gravity separation. This is generally carried out near the mine site.

The refining of tantalum from its ores is one of the more demanding separation processes in industrial metallurgy. The chief problem is that tantalum ores contain significant amounts of niobium, which has chemical properties almost identical to those of Ta. A large number of procedures have been developed to address this challenge.

In modern times, the separation is achieved by hydrometallurgy. Extraction begins with leaching the ore with hydrofluoric acid together with sulfuric acid or hydrochloric acid. This step allows the tantalum and niobium to be separated from the various non-metallic impurities in the rock. Although Ta occurs as various minerals, it is conveniently represented as the pentoxide, since most oxides of tantalum(V) behave similarly under these conditions. A simplified equation for its extraction is thus:

Completely analogous reactions occur for the niobium component, but the hexafluoride is typically predominant under the conditions of the extraction.
These equations are simplified: it is suspected that bisulfate (HSO) and chloride compete as ligands for the Nb(V) and Ta(V) ions, when sulfuric and hydrochloric acids are used, respectively. The tantalum and niobium fluoride complexes are then removed from the aqueous solution by liquid-liquid extraction into organic solvents, such as cyclohexanone, octanol, and methyl isobutyl ketone. This simple procedure allows the removal of most metal-containing impurities (e.g. iron, manganese, titanium, zirconium), which remain in the aqueous phase in the form of their fluorides and other complexes.

Separation of the tantalum "from" niobium is then achieved by lowering the ionic strength of the acid mixture, which causes the niobium to dissolve in the aqueous phase. It is proposed that oxyfluoride H[NbOF] is formed under these conditions. Subsequent to removal of the niobium, the solution of purified HTaF] is neutralised with aqueous ammonia to precipitate hydrated tantalum oxide as a solid, which can be calcined to tantalum pentoxide (TaO).

Instead of hydrolysis, the H[TaF] can be treated with potassium fluoride to produce potassium heptafluorotantalate:
Unlike H[TaF], the potassium salt is readily crystallized and handled as a solid.

K[TaF] can be converted to metallic tantalum by reduction with sodium, at approximately 800 °C in molten salt.

In an older method, called the Marignac process, the mixture of H[TaF] and H[NbOF] was converted to a "mixture" of K[TaF] and K[NbOF], which was then be separated by fractional crystallization, exploiting their different water solubilities.

Electrolysis using a modified version of the Hall–Héroult process. Instead of requiring the input oxide and output metal to be in liquid form, tantalum electrolysis operates on non-liquid powdered oxides. The initial discovery came in 1997 when Cambridge University researchers immersed small samples of certain oxides in baths of molten salt and reduced the oxide with electric current. The cathode uses powdered metal oxide. The anode is made of carbon. The molten salt at is the electrolyte. The first refinery has enough capacity to supply 3–4% of annual global demand.

All welding of tantalum must be done in an inert atmosphere of argon or helium in order to shield it from contamination with atmospheric gases. Tantalum is not solderable. Grinding tantalum is difficult, especially so for annealed tantalum. In the annealed condition, tantalum is extremely ductile and can be readily formed as metal sheets.

The major use for tantalum, as the metal powder, is in the production of electronic components, mainly capacitors and some high-power resistors. Tantalum electrolytic capacitors exploit the tendency of tantalum to form a protective oxide surface layer, using tantalum powder, pressed into a pellet shape, as one "plate" of the capacitor, the oxide as the dielectric, and an electrolytic solution or conductive solid as the other "plate". Because the dielectric layer can be very thin (thinner than the similar layer in, for instance, an aluminium electrolytic capacitor), a high capacitance can be achieved in a small volume. Because of the size and weight advantages, tantalum capacitors are attractive for portable telephones, personal computers, automotive electronics and Cameras.

Tantalum is also used to produce a variety of alloys that have high melting points, strength, and ductility. Alloyed with other metals, it is also used in making carbide tools for metalworking equipment and in the production of superalloys for jet engine components, chemical process equipment, nuclear reactors, and missile parts. Because of its ductility, tantalum can be drawn into fine wires or filaments, which are used for evaporating metals such as aluminium. Since it resists attack by body fluids and is nonirritating, tantalum is widely used in making surgical instruments and implants. For example, porous tantalum coatings are used in the construction of orthopedic implants due to tantalum's ability to form a direct bond to hard tissue.

Tantalum is inert against most acids except hydrofluoric acid and hot sulfuric acid, and hot alkaline solutions also cause tantalum to corrode. This property makes it a useful metal for chemical reaction vessels and pipes for corrosive liquids. Heat exchanging coils for the steam heating of hydrochloric acid are made from tantalum. Tantalum was extensively used in the production of ultra high frequency electron tubes for radio transmitters. Tantalum is capable of capturing oxygen and nitrogen by forming nitrides and oxides and therefore helped to sustain the high vacuum needed for the tubes when used for internal parts such as grids and plates.

The high melting point and oxidation resistance lead to the use of the metal in the production of vacuum furnace parts. Tantalum is extremely inert and is therefore formed into a variety of corrosion resistant parts, such as thermowells, valve bodies, and tantalum fasteners. Due to its high density, shaped charge and explosively formed penetrator liners have been constructed from tantalum. Tantalum greatly increases the armor penetration capabilities of a shaped charge due to its high density and high melting point. It is also occasionally used in precious watches e.g. from Audemars Piguet, F.P. Journe, Hublot, Montblanc, Omega, and Panerai. Tantalum is also highly bioinert and is used as an orthopedic implant material. The high stiffness of tantalum makes it necessary to use it as highly porous foam or scaffold with lower stiffness for hip replacement implants to avoid stress shielding. Because tantalum is a non-ferrous, non-magnetic metal, these implants are considered to be acceptable for patients undergoing MRI procedures. The oxide is used to make special high refractive index glass for camera lenses.

Tantalum receives far less attention in the environmental field than it does in other geosciences. Upper Crust Concentrations (UCC) and the Nb/Ta ratio in the upper crust and in minerals are available because these measurements are useful as a geochemical tool. The latest values for UCC and the Nb/Ta(w/w) ratio in the upper crust stand at 0.92 ppm and 12.7 respectively.

Little data is available on tantalum concentrations in the different environmental compartments, especially in natural waters where reliable estimates of ‘dissolved’ tantalum concentrations in seawater and freshwaters have not even been produced. Some values on dissolved concentrations in oceans have been published, but they are contradictory. Values in freshwaters fare little better, but, in all cases, they are probably below 1 ng Lsince ‘dissolved’ concentrations in natural waters are well below most current analytical capabilities. Analysis requires pre-concentration procedures that, for the moment, do not give consistent results. And in any case, tantalum appears to be present in natural waters mostly as particulate matter rather than dissolved.

Values for concentrations in soils, bed sediments and atmospheric aerosols are easier to come by. Values in soils are close to 1 ppm and thus to UCC values. This indicates detrital origin. For atmospheric aerosols the values available are scattered and limited. When tantalum enrichment is observed, it is probably due to loss of more water-soluble elements in aerosols in the clouds.

Pollution linked to human use of the element has not been detected. Tantalum appears to be a very conservative element in biogeochemical terms, but its cycling and reactivity are still not fully understood.

Compounds containing tantalum are rarely encountered in the laboratory. The metal is highly biocompatible and is used for body implants and coatings, therefore attention may be focused on other elements or the physical nature of the chemical compound.

People can be exposed to tantalum in the workplace by breathing it in, skin contact, or eye contact. The Occupational Safety and Health Administration (OSHA) has set the legal limit (permissible exposure limit) for tantalum exposure in the workplace as 5 mg/m over an 8-hour workday. The National Institute for Occupational Safety and Health (NIOSH) has set a recommended exposure limit (REL) of 5 mg/m over an 8-hour workday and a short-term limit of 10 mg/m. At levels of 2500 mg/m, tantalum is immediately dangerous to life and health.



</doc>
<doc id="30051" url="https://en.wikipedia.org/wiki?curid=30051" title="Torch">
Torch

A torch is a stick with combustible material at one end, which is ignited and used as a light source. Torches have been used throughout history, and are still used in processions, symbolic and religious events, and in juggling entertainment. In some countries, the word "torch" is used as the term for a battery-operated portable light.

From the Old French ""torche"" meaning "twisted thing", hence "torch formed of twisted tow dipped in wax", probably from Vulgar Latin *"torca", alteration of Late Latin "torqua", variant of classical Latin "torques" "collar of twisted metal", from "torquere" "to twist".

Torch construction has varied through history depending on the torch's purpose. Torches were usually constructed of a wooden stave with one end wrapped in a material which was soaked in a flammable substance. In ancient Rome some torches were made of sulfur mixed with lime. This meant that the fire would not diminish after being plunged into water. Modern procession torches are made from coarse hessian rolled into a tube and soaked in wax. There is usually a wooden handle and a cardboard collar to deflect any wax droplets. They are an easy, safe and relatively cheap way to hold a flame aloft in a parade, or to provide illumination in any after-dark celebration.

Modern torches suitable for juggling are made of a wooden and metal or metal only stave with one end wrapped in a Kevlar wick. This wick is soaked in a flammable liquid, usually paraffin (kerosene).

The torch is a common emblem of both enlightenment and hope. Thus the Statue of Liberty, actually "Liberty Enlightening the World", lifts her torch. Crossed reversed torches were signs of mourning that appear on Greek and Roman funerary monuments—a torch pointed downwards symbolizes death, while a torch held up symbolizes life, truth and the regenerative power of flame. The torch is also a symbol used by political parties, for instance by both Labour (from 1918 to 1980) and the Conservatives (from 1983 to 2006) in the UK, and the Malta Labour Party. In the seals of schools in the Philippines, the torch symbolizes the vision of education to provide enlightenment to all the students.

A torch carried in relay by cross-country runners is used to light the Olympic flame which burns without interruption until the end of the Games. These torches and the relay tradition were introduced in the 1936 Summer Olympics by Carl Diem, the chairman of the event because during the duration of the Ancient Olympic Games in Olympia, a sacred flame burnt inside of the temple of Hera, kept in custody by her priestess.

Juggling torches are often used as a prop in toss juggling: they can be flipped into the air in an end-over-end motion while being juggled, in the same manner as juggling clubs or juggling knives, but because of their sound and 'trail of flame', they can appear much more impressive to audiences. To a skilled juggler, there is only a slight chance of being burned, but they are still dangerous.

In former times, liturgical torches were carried in Eucharistic processions simply to give light. The Church eventually adopted their use for Solemn High Masses.

According to Adrian Fortescue, the more correct form of liturgical torches are non-freestanding (i.e. cannot stand up on their own). However, today, even in the Vatican, freestanding, tall candles in ornate candle-stick holders have replaced the former type. The torches are carried by torchbearers, who enter at the Sanctus and leave after Communion.

Anglicans of the High Church and some Lutherans use torches in some of their liturgical celebrations as well.
The association of a torch with love may date to the Greek and Roman tradition of a wedding torch,
lit in the bride’s hearth on her wedding night, then used to light the hearth in her new home. Such a torch is associated with the Greek god of marriage Hymen.

The idiom to carry a torch (for someone) means to love or to be romantically infatuated with someone, especially when such feelings are not reciprocated. It is often used to characterize a situation in which a romantic relationship has ended, but where one partner still loves the other. It is considered by some to be dated, but still in wide usage. A torch song is typically a sentimental love song in which a singer laments an unrequited love.




</doc>
<doc id="30052" url="https://en.wikipedia.org/wiki?curid=30052" title="Thule (disambiguation)">
Thule (disambiguation)

Thule is a semi-mythical place, usually an island.

Thule may also refer to:




</doc>
<doc id="30054" url="https://en.wikipedia.org/wiki?curid=30054" title="The Qt Company">
The Qt Company

The Qt Company (pronounced "cute"; formerly Trolltech) is a software company based in Espoo, Finland. It oversees the development of its Qt application framework within the Qt Project. It was formed following the acquisition of Qt by Digia, but was later spun off into a separate, publicly traded company.

It has core R&D in Oslo, Norway, as well as large engineering teams in Berlin, Germany and Oulu, Finland. The Qt Company operates in China, Finland, Germany, Norway, Russia, South Korea, Japan, India, and the United States.

The company provides software development platforms and frameworks, as well as expert consulting services. Its flagship product is Qt, a multi-platform Graphical User Interface (GUI) framework written in C++. Qt is popular with application developers using C++ but is supported by bindings for other programming languages too, such as Python. Qt also includes packages such as data structures and a networking library. The popular, Free, and cross-platform KDE Plasma desktop environment and software compilation uses the Qt library. The company also employs several KDE developers.

In 2001 Trolltech introduced Qtopia which is based on Qt. Qtopia is an application platform for Linux-based devices such as mobile phones, portable media players, and home media. It is also used in many non-consumer products such as medical instruments and industrial devices. Qtopia Phone Edition was released in 2004, and their Greenphone smartphone is based on this platform.

Trolltech was founded by Eirik Chambe-Eng and Haavard Nord on 4 March 1994. They started writing Qt in 1991, and since then Qt has steadily expanded and improved. Trolltech completed an initial public offering (IPO) on the Oslo Stock Exchange in July, 2006.

On 28 January 2008, Nokia Corporation announced that they had entered into an agreement that Nokia would make a public voluntary tender offer to acquire Trolltech. The total cost for Nokia was approximately €104 million. On 5 June 2008 Nokia’s voluntary tender offer was approved for all the shares in Trolltech. By 17 June 2008, Nokia had completed its acquisition of Trolltech. On 30 September 2008, Trolltech was renamed as Qt Software, and Qtopia was renamed as Qt Extended. On 11 August 2009, the company's name was changed to Qt Development Frameworks.

Nokia sold the commercial licensing business of Qt to Digia on March 2011. The remainder of the assets were subsequently acquired by Digia in 2012.

In September 2014, Digia formed The Qt Company, a wholly owned subsidiary dedicated to the development and governance of the Qt platform. In May 2016, the company went public on NASDAQ Helsinki as QTCOM.


</doc>
<doc id="30056" url="https://en.wikipedia.org/wiki?curid=30056" title="Trojan horse (computing)">
Trojan horse (computing)

In computing, a Trojan horse, or Trojan, is any malicious computer program which misleads users of its true intent. The term is derived from the Ancient Greek story of the deceptive wooden horse that led to the fall of the city of Troy.

Trojans are generally spread by some form of social engineering, for example where a user is duped into executing an e-mail attachment disguised to be unsuspicious, (e.g., a routine form to be filled in), or by clicking on some fake advertisement on social media or anywhere else . Although their payload can be anything, many modern forms act as a backdoor, contacting a controller which can then have unauthorized access to the affected computer. Trojans may allow an attacker to access users' personal information such as banking information, passwords, or personal identity. It can infect other devices connected to the network. Ransomware attacks are often carried out using a Trojan.

Unlike computer viruses and worms, Trojans generally do not attempt to inject themselves into other files or otherwise propagate themselves.

This terminology occurs for the first time in a US Air Force report in 1974 on the analysis of vulnerability in computer systems. It was made popular by Ken Thompson in his Turing lecture which he gave at the reception of the Turing Award in 1983, attributed to him for having created UNIX. His conference is subtitled:
He mentioned that he knew about the possible existence of Trojan horses in a report on the security of Multics of which he was unfortunately unable to find a reference. However Paul Karger and Roger Schell affirm that this is their above cited report.

Trojan in this way may require interaction with a malicious controller (not necessarily distributing the Trojan) to fulfill their purpose. It is possible for those involved with Trojans to scan computers on a network to locate any with a Trojan installed, which the hacker can then control.

Some Trojans take advantage of a security flaw in older versions of Internet Explorer and Google Chrome to use the host computer as an anonymizer proxy to effectively hide Internet usage, enabling the controller to use the Internet for illegal purposes while all potentially incriminating evidence indicates the infected computer or its IP address. The host's computer may or may not show the internet history of the sites viewed using the computer as a proxy. The first generation of anonymizer Trojan horses tended to leave their tracks in the page view histories of the host computer. Later generations of the Trojan tend to "cover" their tracks more efficiently. Several versions of Sub7 have been widely circulated in the US and Europe and became the most widely distributed examples of this type of Trojan.

In German-speaking countries, spyware used or made by the government is sometimes called "govware". Govware is typically a Trojan software used to intercept communications from the target computer. Some countries like Switzerland and Germany have a legal framework governing the use of such software. Examples of govware Trojans include the Swiss MiniPanzer and MegaPanzer and the German "state trojan" nicknamed R2D2. German govware works by exploiting security gaps unknown to the general public and accessing smartphone data before it becomes encrypted via other applications.

Due to the popularity of botnets among hackers and the availability of advertising services that permit authors to violate their users' privacy, Trojans are becoming more common. According to a survey conducted by BitDefender from January to June 2009, "Trojan-type malware is on the rise, accounting for 83-percent of the global malware detected in the world." Trojans have a relationship with worms, as they spread with the help given by worms and travel across the internet with them. BitDefender has stated that approximately 15% of computers are members of a botnet, usually recruited by a Trojan infection.






</doc>
<doc id="30057" url="https://en.wikipedia.org/wiki?curid=30057" title="Tokyo">
Tokyo

, officially , is one of the 47 prefectures of Japan and has been the capital since 1869. The Greater Tokyo Area is the most populous metropolitan area in the world. It is the seat of the Emperor of Japan, the Japanese government and the National Diet. Tokyo is in the Kantō region on the southeastern side of the main island Honshu and includes the Izu Islands and Ogasawara Islands. Tokyo was formerly named Edo when "Shōgun" Tokugawa Ieyasu made the city as his headquarters in 1603. It became the capital after Emperor Meiji moved his seat to the city from Kyoto in 1868; at that time Edo was renamed Tokyo. Tokyo Metropolis was formed in 1943 from the merger of the former and the .

Tokyo has 39 million residents, 50% more people than any other urban area, with a $2.5 trillion economy larger than that of any other city; if it were a country, Tokyo would be the 8th largest economy in the world. Tokyo is often referred to as a city, but is officially known and governed as a "metropolitan prefecture", which differs from and combines elements of a city and a prefecture, a characteristic unique to Tokyo. The Tokyo Metropolitan Government administers the 23 Special Wards of Tokyo (each governed as an individual city), which cover the area that was the city of Tokyo before it merged and became the metropolitan prefecture in 1943, the 30 municipalities in the western part of the prefecture, and the two outlying island chains. The population of the special wards is over 9 million people, with the total population of the prefecture exceeding 13 million. The prefecture is part of the world's most populous metropolitan area with upwards of 37.8 million people and the world's largest urban agglomeration economy. In 2011, the city hosted 51 of the Fortune Global 500 companies, the highest number of any city in the world at that time. Tokyo ranked third (twice) in the International Financial Centres Development Index. The city is also home to various television networks such as Fuji TV, Tokyo MX, TV Tokyo, TV Asahi, Nippon Television, NHK and the Tokyo Broadcasting System.

Tokyo is ranked first in the Global Economic Power Index and third in the Global Cities Index. The city is considered an alpha+ world city – as listed by the GaWC's 2008 inventory – and in 2014, Tokyo was ranked first in the "Best overall experience" category of "TripAdvisor"'s World City Survey (the city also ranked first in the following categories: "helpfulness of locals", "nightlife", "shopping", "local public transportation" and "cleanliness of streets"). In 2015, Tokyo was ranked as the 11th most expensive city for expatriates, according to the Mercer consulting firm, and also the world's 11th most expensive city, according to the Economist Intelligence Unit's cost-of-living survey. In 2015, Tokyo was named the Most Liveable City in the world by the magazine "Monocle". The Michelin Guide has awarded Tokyo by far the most Michelin stars of any city in the world. Tokyo was ranked first out of all sixty cities in the 2017 Safe Cities Index. The QS Best Student Cities ranked Tokyo as the 3rd-best city in the world to be a university student in 2016 and 2nd in 2018. Tokyo hosted the 1964 Summer Olympics, the 1979 G-7 summit, the 1986 G-7 summit, and the 1993 G-7 summit, and will host the 2019 Rugby World Cup, the 2020 Summer Olympics and the 2020 Summer Paralympics.

 Tokyo was originally known as , which means "estuary". Its name was changed to when it became the imperial capital with the arrival of Emperor Meiji in 1868, in line with the East Asian tradition of including the word capital () in the name of the capital city (like Kyoto (), Beijing () and Nanjing ()). During the early Meiji period, the city was also called "Tōkei", an alternative pronunciation for the same characters representing "Tokyo", making it a kanji homograph. Some surviving official English documents use the spelling "Tokei"; however, this pronunciation is now obsolete.

The name Tokyo was first suggested in 1813 in the book (Secret Plan of Commingling), written by Satō Nobuhiro. When Ōkubo Toshimichi proposed the renaming to the government during the Meiji Restoration, according to Oda Kanshi (織田完之), he got the idea from that book.

Tokyo was originally a small fishing village named Edo, in what was formerly part of the old Musashi Province. Edo was first fortified by the Edo clan, in the late twelfth century. In 1457, Ōta Dōkan built Edo Castle. In 1590, Tokugawa Ieyasu was transferred from Mikawa Province (his life-long base) to Kantō region. When he became "shōgun" in 1603, Edo became the center of his ruling. During the subsequent Edo period, Edo grew into one of the largest cities in the world with a population topping one million by the 18th century. But Edo was Tokugawa's home and was not capital of Japan. (That caused Meiji Restoration in 1868.) The Emperor himself lived in Kyoto from 794 to 1868 as capital of Japan. During Edo era, the city enjoyed a prolonged period of peace known as the "Pax Tokugawa", and in the presence of such peace, Edo adopted a stringent policy of seclusion, which helped to perpetuate the lack of any serious military threat to the city. The absence of war-inflicted devastation allowed Edo to devote the majority of its resources to rebuilding in the wake of the consistent fires, earthquakes, and other devastating natural disasters that plagued the city. However, this prolonged period of seclusion came to an end with the arrival of American Commodore Matthew C. Perry in 1853. Commodore Perry negotiated the opening of the ports of Shimoda and Hakodate, leading to an increase in the demand for new foreign goods and subsequently a severe rise in inflation. Social unrest mounted in the wake of these higher prices and culminated in widespread rebellions and demonstrations, especially in the form of the "smashing" of rice establishments. Meanwhile, supporters of the Meiji Emperor leveraged the disruption that these widespread rebellious demonstrations were causing to further consolidate power by overthrowing the last Tokugawa "shōgun", Yoshinobu, in 1867. After 265 years, the "Pax Tokugawa" came to an end. 

In 1869, the 17-year-old Emperor Meiji moved to Edo, and in accordance the city was renamed Tokyo (meaning Eastern Capital). The city was divided into Yamanote and Shitamachi. Tokyo was already the nation's political and cultural center, and the emperor's residence made it a de facto imperial capital as well, with the former Edo Castle becoming the Imperial Palace. The city of Tokyo was officially established on May 1, 1889.

Central Tokyo, like Osaka, has been designed since about 1900 to be centered on major railway stations in a high-density fashion, so suburban railways were built relatively cheaply at street level and with their own right-of-way. Though expressways have been built in Tokyo, the basic design has not changed.

Tokyo went on to suffer two major catastrophes in the 20th century: the 1923 Great Kantō earthquake, which left 140,000 dead or missing; and World War II.

In 1943, the city of Tokyo merged with the prefecture of Tokyo to form the "Metropolitan Prefecture" of Tokyo. Since then, the Tokyo Metropolitan Government served as both the prefecture government for Tokyo, as well as administering the special wards of Tokyo, for what had previously been Tokyo City. World War II wrought widespread destruction of most of the city due to the persistent Allied air raids on Japan and the use of incendiary bombs. The bombing of Tokyo in 1944 and 1945 is estimated to have killed between 75,000 and 200,000 civilians and left more than half of the city destroyed. The deadliest night of the war came on March 9–10, 1945, the night of the American "Operation Meetinghouse" raid; as nearly 700,000 incendiary bombs rained on the eastern half of the city, mainly in heavily residential wards. Two-fifths of the city were completely burned, more than 276,000 buildings were demolished, 100,000 civilians were killed, and 110,000 more were injured. Between 1940 and 1945, the population of Japan's capital city dwindled from 6,700,000 to less than 2,800,000, with the majority of those who lost their homes living in "ramshackle, makeshift huts".

After the war, Tokyo was completely rebuilt, and was showcased to the world during the 1964 Summer Olympics. The 1970s brought new high-rise developments such as Sunshine 60, a new and controversial airport at Narita in 1978 (some distance outside city limits), and a population increase to about 11 million (in the metropolitan area).

Tokyo's subway and commuter rail network became one of the busiest in the world as more and more people moved to the area. In the 1980s, real estate prices skyrocketed during a real estate and debt bubble. The bubble burst in the early 1990s, and many companies, banks, and individuals were caught with mortgage backed debts while real estate was shrinking in value. A major recession followed, making the 1990s Japan's "Lost Decade", from which it is now slowly recovering.

Tokyo still sees new urban developments on large lots of less profitable land. Recent projects include Ebisu Garden Place, Tennozu Isle, Shiodome, Roppongi Hills, Shinagawa (now also a Shinkansen station), and the Marunouchi side of Tokyo Station. Buildings of significance are demolished for more up-to-date shopping facilities such as Omotesando Hills.

Land reclamation projects in Tokyo have also been going on for centuries. The most prominent is the Odaiba area, now a major shopping and entertainment center. Various plans have been proposed for transferring national government functions from Tokyo to secondary capitals in other regions of Japan, in order to slow down rapid development in Tokyo and revitalize economically lagging areas of the country. These plans have been controversial within Japan and have yet to be realized.

The 2011 Tōhoku earthquake and tsunami that devastated much of the northeastern coast of Honshu was felt in Tokyo. However, due to Tokyo's earthquake-resistant infrastructure, damage in Tokyo was very minor compared to areas directly hit by the tsunami, although activity in the city was largely halted. The subsequent nuclear crisis caused by the tsunami has also largely left Tokyo unaffected, despite occasional spikes in radiation levels.

On September 7, 2013, the IOC selected Tokyo to host the 2020 Summer Olympics. Tokyo will be the first Asian city to host the Olympic Games twice.

The mainland portion of Tokyo lies northwest of Tokyo Bay and measures about east to west and north to south. The average elevation in Tokyo is .
Chiba Prefecture borders it to the east, Yamanashi to the west, Kanagawa to the south, and Saitama to the north. Mainland Tokyo is further subdivided into the special wards (occupying the eastern half) and the Tama area () stretching westwards.

Also within the administrative boundaries of Tokyo Metropolis are two island chains in the Pacific Ocean directly south: the Izu Islands, and the Ogasawara Islands, which stretch more than away from the mainland. Because of these islands and the mountainous regions to the west, Tokyo's overall population density figures far under-represent the real figures for the urban and suburban regions of Tokyo.

Under Japanese law, Tokyo is designated as a , translated as "metropolis". Its administrative structure is similar to that of Japan's other prefectures. The 23 special wards ( -ku), which until 1943 constituted the city of Tokyo, are now separate, self-governing municipalities, each having a mayor, a council, and the status of a city.

In addition to these 23 special wards, Tokyo also includes 26 more cities (市 -shi), five towns ( -chō or machi), and eight villages ( -son or -mura), each of which has a local government. The Tokyo Metropolitan Government, which administers the whole metropolis, is headed by a publicly elected governor and metropolitan assembly. Its headquarters are located in Shinjuku Ward.

The of Tokyo comprise the area formerly incorporated as Tokyo City. On July 1, 1943, Tokyo City was merged with forming the current "metropolitan prefecture". As a result, unlike other city wards in Japan, these wards are not conterminous with a larger incorporated city.

While falling under the jurisdiction of Tokyo Metropolitan Government, each ward is also a borough with its own elected leader and council, like other cities of Japan. The special wards use the word "city" in their official English name (e.g. Chiyoda City).

The wards differ from other cities in having a unique administrative relationship with the prefectural government. Certain municipal functions, such as waterworks, sewerage, and fire-fighting, are handled by the Tokyo Metropolitan Government. To pay for the added administrative costs, the prefecture collects municipal taxes, which would usually be levied by the city.

The special wards of Tokyo are:





The "three central wards" of Tokyo – Chiyoda, Chūō and Minato – are the business core of the city, with a daytime population more than seven times higher than their nighttime population. Chiyoda Ward is unique in that it is in the very heart of the former Tokyo City, yet is one of the least populated wards. It is occupied by many major Japanese companies, and is also the seat of the national government, and the Japanese emperor. It is often called the "political center" of the country. Akihabara, known for being an otaku cultural center and a shopping district for computer goods, is also located in Chiyoda.

To the west of the special wards, Tokyo Metropolis consists of cities, towns and villages that enjoy the same legal status as those elsewhere in Japan.

While serving as "bed towns" for those working in central Tokyo, some of them also have a local commercial and industrial base. Collectively, these are often known as the Tama area or Western Tokyo.

Twenty-six cities lie within the western part of Tokyo:





The Tokyo Metropolitan Government has designated Hachiōji, Tachikawa, Machida, Ōme and Tama New Town as regional centers of the Tama area, as part of its plans to disperse urban functions away from central Tokyo.

The far west of the Tama area is occupied by the district ("gun") of Nishi-Tama. Much of this area is mountainous and unsuitable for urbanization. The highest mountain in Tokyo, Mount Kumotori, is high; other mountains in Tokyo include Takasu (), Odake (), and Mitake (). Lake Okutama, on the Tama River near Yamanashi Prefecture, is Tokyo's largest lake. The district is composed of three towns (Hinode, Mizuho and Okutama) and one village (Hinohara).

Tokyo has numerous outlying islands, which extend as far as from central Tokyo. Because of the islands' distance from the administrative headquarters of the Tokyo Metropolitan Government in Shinjuku, local subprefectural branch offices administer them.

The Izu Islands are a group of volcanic islands and form part of the Fuji-Hakone-Izu National Park. The islands in order from closest to Tokyo are Izu Ōshima, Toshima, Nii-jima, Shikine-jima, Kōzu-shima, Miyake-jima, Mikurajima, Hachijō-jima, and Aogashima. The Izu Islands are grouped into three subprefectures. Izu Ōshima and Hachijojima are towns. The remaining islands are six villages, with Niijima and Shikinejima forming one village.

The Ogasawara Islands include, from north to south, Chichi-jima, Nishinoshima, Haha-jima, Kita Iwo Jima, Iwo Jima, and Minami Iwo Jima. Ogasawara also administers two tiny outlying islands: Minami Torishima, the easternmost point in Japan and at the most distant island from central Tokyo, and Okinotorishima, the southernmost point in Japan. Japan's claim on an exclusive economic zone (EEZ) surrounding Okinotorishima is contested by China and South Korea as they regard Okinotorishima as uninhabitable rocks which have no EEZ. The Iwo chain and the outlying islands have no permanent population, but host Japanese Self-Defense Forces personnel. Local populations are only found on Chichi-jima and Haha-jima. The islands form both Ogasawara Subprefecture and the village of Ogasawara, Tokyo.

As of March 31, 2008, 36% of the total land area of the prefecture was designated as Natural Parks (second only to Shiga Prefecture), namely the Chichibu Tama Kai, Fuji-Hakone-Izu, and Ogasawara National Parks (the last a UNESCO World Heritage Site); Meiji no Mori Takao Quasi-National Park; and Akikawa Kyūryō, Hamura Kusabana Kyūryō, Sayama, Takao Jinba, Takiyama, and Tama Kyūryō Prefectural Natural Parks.

A number of museums are located in Ueno Park: Tokyo National Museum, National Museum of Nature and Science, Shitamachi Museum and National Museum for Western Art, among others. There are also art works and statues at several places in the park. There is also a zoo in the park, and the park is a popular destination to view cherry blossoms.
Tokyo is near the boundary of three plates, making it an extremely active region for smaller quakes and slippage which frequently affect the urban area with swaying as if in a boat, although epicenters within mainland Tokyo (excluding Tokyo's 2000 km long island jurisdiction) are quite rare. It's not uncommon in the metro area to have hundreds of these such minor quakes (magnitudes 4–6) that can be felt in single year, something local residents merely brush off but can be a source of anxiety to not only to foreign visitors but Japanese from elsewhere as well. They rarely cause much damage (sometimes a few injuries) as they are either too small or far away as quakes tend to dance around the region. Particularly active are offshore regions and to a lesser extent Chiba and Ibaraki.

Tokyo has been hit by powerful megathrust earthquakes in 1703, 1782, 1812, 1855, 1923, and much more indirectly (some liquefaction in landfill zones) in 2011; the frequency of direct and large quakes is a relative rarity. The 1923 earthquake, with an estimated magnitude of 8.3, killed 142,000 people, the last time the urban area was directly hit. The 2011 quake focus was hundreds of km away and resulted in no direct deaths in the metropolitan area.

The former city of Tokyo and the majority of mainland Tokyo lie in the humid subtropical climate zone (Köppen climate classification "Cfa"), with hot, humid summers and generally cool winters with cold spells. The region, like much of Japan, experiences a one-month seasonal lag, with the warmest month being August, which averages , and the coolest month being January, averaging . The record low temperature is on January 13, 1876 while the record high is on July 20, 2004.
The record highest "low" temperature is on August 12, 2013, city of Tokyo is one of the only 7 observation points, which has the over- highest "low" record in japan.

The western mountainous area of mainland Tokyo, Okutama also lies in the humid subtropical climate (Köppen classification "Cfa").

Tokyo's offshore territories' climates vary significantly from the city. The climate of Chichi-jima in Ogasawara village is on the boundary between the tropical savanna climate (Köppen classification "Aw") and the humid subtropical climate (Köppen classification "Cfa"). It is approximately 1,000 km south of the Greater Tokyo Area resulting in different climatic conditions.

Tokyo's easternmost territory, the island of Minamitorishima in Ogasawara village, is in the tropical savanna climate zone (Köppen classification "Aw"). Tokyo's Izu and Ogasawara islands are affected by an average of 5.4 typhoons a year, compared to 3.1 in mainland Kantō.

Architecture in Tokyo has largely been shaped by Tokyo's history. Twice in recent history has the metropolis been left in ruins: first in the 1923 Great Kantō earthquake and later after extensive firebombing in World War II. Because of this, Tokyo's urban landscape consists mainly of modern and contemporary architecture, and older buildings are scarce. Tokyo features many internationally famous forms of modern architecture including Tokyo International Forum, Asahi Beer Hall, Mode Gakuen Cocoon Tower, NTT Docomo Yoyogi Building and Rainbow Bridge. Tokyo also features two distinctive towers: Tokyo Tower, and the new Tokyo Skytree, which is the tallest tower in both Japan and the world, and the second tallest structure in the world after the Burj Khalifa in Dubai.

Tokyo also contains numerous parks and gardens. There are four national parks in Tokyo Prefecture, including the Fuji-Hakone-Izu National Park, which includes all of the Izu Islands.

Tokyo has enacted a measure to cut greenhouse gases. Governor Shintaro Ishihara created Japan's first emissions cap system, aiming to reduce greenhouse gas emission by a total of 25% by 2020 from the 2000 level. Tokyo is an example of an urban heat island, and the phenomenon is especially serious in its special wards. According to the Tokyo Metropolitan Government, the annual mean temperature has increased by about over the past 100 years. Tokyo has been cited as a "convincing example of the relationship between urban growth and climate."

In 2006, Tokyo enacted the "10 Year Project for Green Tokyo" to be realised by 2016. It set a goal of increasing roadside trees in Tokyo to 1 million (from 480,000), and adding 1,000 ha of green space 88 of which will be a new park named "Umi no Mori" (sea forest) which will be on a reclaimed island in Tokyo Bay which used to be a landfill. From 2007 to 2010, 436 ha of the planned 1,000 ha of green space was created and 220,000 trees were planted bringing the total to 700,000. In 2014, road side trees in Tokyo have increased to 950,000, and a further 300 ha of green space has been added.
As of October 2012, the official intercensal estimate showed 13.506 million people in Tokyo with 9.214 million living within Tokyo's 23 wards. During the daytime, the population swells by over 2.5 million as workers and students commute from adjacent areas. This effect is even more pronounced in the three central wards of Chiyoda, Chūō, and Minato, whose collective population as of the 2005 National Census was 326,000 at night, but 2.4 million during the day.

In 1889, the Ministry of Home Affairs recorded 1,375,937 people in Tokyo City and a total of 1,694,292 people in Tokyo-fu. In the same year, a total of 779 foreign nationals were recorded as residing in Tokyo. The most common nationality was British (209 residents), followed by United States nationals (182) and nationals of the Qing dynasty (137).

Tokyo has the largest metropolitan economy in the world. According to a study conducted by PricewaterhouseCoopers, the Tokyo urban area of 38 million people had a total GDP of $2 trillion in 2012 (at purchasing power parity), which topped that list. 51 of the companies listed on the Fortune Global 500 are based in Tokyo, almost twice that of the second-placed city (Paris).

Tokyo is a major international finance center; it houses the headquarters of several of the world's largest investment banks and insurance companies, and serves as a hub for Japan's transportation, publishing, electronics and broadcasting industries. During the centralised growth of Japan's economy following World War II, many large firms moved their headquarters from cities such as Osaka (the historical commercial capital) to Tokyo, in an attempt to take advantage of better access to the government. This trend has begun to slow due to ongoing population growth in Tokyo and the high cost of living there.

Tokyo was rated by the Economist Intelligence Unit as the most expensive (highest cost-of-living) city in the world for 14 years in a row ending in 2006.

Tokyo emerged as a leading international financial center (IFC) in the 1960s and has been described as one of the three "command centers" for the world economy, along with New York City and London. In the 2017 Global Financial Centres Index, Tokyo was ranked as having the fifth most competitive financial center in the world (alongside cities such as London, New York City, San Francisco, Chicago, Sydney, Boston, and Toronto in the top 10), and third most competitive in Asia (after Singapore and Hong Kong). The Japanese financial market opened up slowly in 1984 and accelerated its internationalisation with the "Japanese Big Bang" in 1998. Despite the emergence of Singapore and Hong Kong as competing financial centers, the Tokyo IFC manages to keep a prominent position in Asia. The Tokyo Stock Exchange is Japan's largest stock exchange, and third largest in the world by market capitalization and fourth largest by share turnover. In 1990 at the end of the Japanese asset price bubble, it accounted for more than 60% of the world stock market value. Tokyo had 8,460 ha (20,900 acres) of agricultural land as of 2003, according to the Ministry of Agriculture, Forestry and Fisheries, placing it last among the nation's prefectures. The farmland is concentrated in Western Tokyo. Perishables such as vegetables, fruits, and flowers can be conveniently shipped to the markets in the eastern part of the prefecture. "Komatsuna" and spinach are the most important vegetables; as of 2000, Tokyo supplied 32.5% of the "komatsuna" sold at its central produce market.

With 36% of its area covered by forest, Tokyo has extensive growths of cryptomeria and Japanese cypress, especially in the mountainous western communities of Akiruno, Ōme, Okutama, Hachiōji, Hinode, and Hinohara. Decreases in the price of timber, increases in the cost of production, and advancing old age among the forestry population have resulted in a decline in Tokyo's output. In addition, pollen, especially from cryptomeria, is a major allergen for the nearby population centers. Tokyo Bay was once a major source of fish. Most of Tokyo's fish production comes from the outer islands, such as Izu Ōshima and Hachijō-jima. Skipjack tuna, nori, and "aji" are among the ocean products.

Tourism in Tokyo is also a contributor to the economy. In 2006, 4.81 million foreigners and 420 million Japanese visits to Tokyo were made; the economic value of these visits totaled 9.4 trillion yen according to the Tokyo Metropolitan Government. Many tourists visit the various downtowns, stores, and entertainment districts throughout the neighbourhoods of the special wards of Tokyo; particularly for school children on class trips, a visit to Tokyo Tower is "de rigueur". Cultural offerings include both omnipresent Japanese pop culture and associated districts such as Shibuya and Harajuku, subcultural attractions such as Studio Ghibli anime center, as well as museums like the Tokyo National Museum, which houses 37% of the country's artwork national treasures (87/233).

The Tsukiji Fish Market in Tokyo is the biggest wholesale fish and seafood market in the world, and also one of the largest wholesale food markets of any kind. The Tsukiji market holds strong to the traditions of its predecessor, the Nihombashi fish market, and serves some 50,000 buyers and sellers every day. Retailers, whole-sellers, auctioneers, and public citizens alike frequent the market, creating a unique microcosm of organized chaos that still continues to fuel the city and its food supply after over four centuries.

Tokyo, as the center of the Greater Tokyo Area, is Japan's largest domestic and international hub for rail and ground. However, its airspace has been under US military's exclusive rights after WW2 and some flights routes are returned to Japan. Public transportation within Tokyo is dominated by an extensive network of clean and efficient trains and subways run by a variety of operators, with buses, monorails and trams playing a secondary feeder role. There are up to 62 electric train lines and more than 900 train stations in Tokyo.

As the result of WW2, Japanese planes are forbidden to fly over Tokyo. Therefore Japan constructed airports outside Tokyo. Narita International Airport in Chiba Prefecture is the major gateway for international travelers to Japan. Japan's flag carrier Japan Airlines, as well All Nippon Airways have a hub at this airport. Haneda Airport on the reclaimed land at Ōta offers domestic and international flights. 

Various islands governed by Tokyo have their own airports. Hachijō-jima (Hachijojima Airport), Miyakejima (Miyakejima Airport), and Izu Ōshima (Oshima Airport) have services to Tokyo International and other airports.

Rail is the primary mode of transportation in Tokyo, which has the most extensive urban railway network in the world and an equally extensive network of surface lines. JR East operates Tokyo's largest railway network, including the Yamanote Line loop that circles the center of downtown Tokyo. Two different organisations operate the subway network: the private Tokyo Metro and the governmental Tokyo Metropolitan Bureau of Transportation. The Metropolitan Government and private carriers operate bus routes and one tram route. Local, regional, and national services are available, with major terminals at the giant railroad stations, including Tokyo, Shinagawa, and Shinjuku.

Expressways link the capital to other points in the Greater Tokyo area, the Kantō region, and the islands of Kyushu and Shikoku. In order to build them quickly before the 1964 Summer Olympics, most were constructed above existing roads. Other transportation includes taxis operating in the special wards and the cities and towns. Also long-distance ferries serve the islands of Tokyo and carry passengers and cargo to domestic and foreign ports.

Tokyo has many universities, junior colleges, and vocational schools. Many of Japan's most prestigious universities are in Tokyo, including University of Tokyo, Hitotsubashi University, Tokyo Institute of Technology, Waseda University, Tokyo University of Science, and Keio University. Some of the biggest national universities in Tokyo are:

There is only one non-national public university: Tokyo Metropolitan University.

There are also a few universities well known for classes conducted in English and for the teaching of the Japanese language. They include:

Tokyo is also the headquarters of the United Nations University.

For an extensive list, see List of universities in Tokyo.

Publicly run kindergartens, elementary schools (years 1 through 6), and Primary schools (7 through 9) are operated by local wards or municipal offices. Public Secondary schools in Tokyo are run by the Tokyo Metropolitan Government Board of Education and are called "Metropolitan High Schools". Tokyo also has many private schools from kindergarten through high school:

Tokyo has many museums. In Ueno Park, there is the Tokyo National Museum, the country's largest museum and specializing in traditional Japanese art; the National Museum of Western Art and Ueno Zoo. Other museums include the National Museum of Emerging Science and Innovation in Odaiba; the Edo-Tokyo Museum in Sumida, across the Sumida River from the center of Tokyo; the Nezu Museum in Aoyama; and the National Diet Library, National Archives, and the National Museum of Modern Art, which are near the Imperial Palace.

Tokyo has many theatres for performing arts. These include national and private theatres for traditional forms of Japanese drama. Noteworthy are the National Noh Theatre for noh and the Kabuki-za for kabuki. Symphony orchestras and other musical organisations perform modern and traditional music. Tokyo also hosts modern Japanese and international pop, and rock music at venues ranging in size from intimate clubs to internationally known arenas such as the Nippon Budokan.

Many different festivals occur throughout Tokyo. Major events include the Sannō at Hie Shrine, the Sanja at Asakusa Shrine, and the biennial Kanda Festivals. The last features a parade with elaborately decorated floats and thousands of people. Annually on the last Saturday of July, an enormous fireworks display over the Sumida River attracts over a million viewers. Once cherry blossoms bloom in spring, many residents gather in Ueno Park, Inokashira Park, and the Shinjuku Gyoen National Garden for picnics under the blossoms.

Harajuku, a neighbourhood in Shibuya, is known internationally for its youth style, fashion and cosplay.

Cuisine in Tokyo is internationally acclaimed. In November 2007, Michelin released their first guide for fine dining in Tokyo, awarding 191 stars in total, or about twice as many as Tokyo's nearest competitor, Paris. As of 2017, 227 restaurants in Tokyo have been awarded (92 in Paris). Twelve establishments were awarded the maximum of three stars (Paris has 10), 54 received two stars, and 161 earned one star.

Tokyo, with a diverse array of sports, is home to two professional baseball clubs, the Yomiuri Giants who play at the Tokyo Dome and Tokyo Yakult Swallows at Meiji-Jingu Stadium. The Japan Sumo Association is also headquartered in Tokyo at the Ryōgoku Kokugikan sumo arena where three official sumo tournaments are held annually (in January, May, and September). Football clubs in Tokyo include F.C. Tokyo and Tokyo Verdy 1969, both of which play at Ajinomoto Stadium in Chōfu, and FC Machida Zelvia at Nozuta Stadium in Machida. Basketball clubs include the Hitachi SunRockers, Toyota Alvark Tokyo and Tokyo Excellence.

Tokyo hosted the 1964 Summer Olympics, thus becoming the first Asian city to host the Summer Games. The National Stadium, also known as the Olympic Stadium, was host to a number of international sporting events. In 2016, it was to be replaced by the New National Stadium. With a number of world-class sports venues, Tokyo often hosts national and international sporting events such as basketball tournaments, women's volleyball tournaments, tennis tournaments, swim meets, marathons, rugby union and sevens rugby games, football, American football exhibition games, judo, and karate. Tokyo Metropolitan Gymnasium, in Sendagaya, Shibuya, is a large sports complex that includes swimming pools, training rooms, and a large indoor arena. According to Around the Rings, the gymnasium has played host to the October 2011 artistic gymnastics world championships, despite the International Gymnastics Federation's initial doubt in Tokyo's ability to host the championships following the March 11 tsunami. Tokyo was selected to host the 2020 Summer Olympics and the 2020 Summer Paralympics on September 7, 2013.

As the largest population center in Japan and the site of the country's largest broadcasters and studios, Tokyo is frequently the setting for many Japanese movies, television shows, animated series ("anime"), web comics, light novels, video games, and comic books ("manga"). In the "kaiju" (monster movie) genre, landmarks of Tokyo are routinely destroyed by giant monsters such as Godzilla and Gamera.

Some Hollywood directors have turned to Tokyo as a backdrop for movies set in Japan. Postwar examples include "Tokyo Joe", "My Geisha", "Tokyo Story" and the James Bond film "You Only Live Twice"; recent examples include "Kill Bill", "", "Lost in Translation", "Babel", and "Inception".

Japanese author Haruki Murakami has based some of his novels in Tokyo (including "Norwegian Wood"), and David Mitchell's first two novels "number9dream" and "Ghostwritten" featured the city. Contemporary British painter Carl Randall spent 10 years living in Tokyo as an artist, creating a body of work depicting the cities crowded streets and public spaces.

Tokyo is the founder member of the Asian Network of Major Cities 21 and is a member of the Council of Local Authorities for International Relations. Tokyo was also a founding member of the C40 Cities Climate Leadership Group.

, Tokyo has twinning or friendship agreements with the following twelve cities and states:





</doc>
<doc id="30058" url="https://en.wikipedia.org/wiki?curid=30058" title="Trojan War">
Trojan War

In Greek mythology, the Trojan War was waged against the city of Troy by the Achaeans (Greeks) after Paris of Troy took Helen from her husband Menelaus, king of Sparta. The war is one of the most important events in Greek mythology and has been narrated through many works of Greek literature, most notably Homer's "Iliad". The core of the "Iliad" (Books II – XXIII) describes a period of four days and two nights in the tenth year of the decade-long siege of Troy; the "Odyssey" describes the journey home of Odysseus, one of the war's heroes. Other parts of the war are described in a cycle of epic poems, which have survived through fragments. Episodes from the war provided material for Greek tragedy and other works of Greek literature, and for Roman poets including Virgil and Ovid.

The war originated from a quarrel between the goddesses Hera, Athena, and Aphrodite, after Eris, the goddess of strife and discord, gave them a golden apple, sometimes known as the Apple of Discord, marked "for the fairest". Zeus sent the goddesses to Paris, who judged that Aphrodite, as the "fairest", should receive the apple. In exchange, Aphrodite made Helen, the most beautiful of all women and wife of Menelaus, fall in love with Paris, who took her to Troy. Agamemnon, king of Mycenae and the brother of Helen's husband Menelaus, led an expedition of Achaean troops to Troy and besieged the city for ten years because of Paris' insult. After the deaths of many heroes, including the Achaeans Achilles and Ajax, and the Trojans Hector and Paris, the city fell to the ruse of the Trojan Horse. The Achaeans slaughtered the Trojans (except for some of the women and children whom they kept or sold as slaves) and desecrated the temples, thus earning the gods' wrath. Few of the Achaeans returned safely to their homes and many founded colonies in distant shores. The Romans later traced their origin to Aeneas, Aphrodite's son and one of the Trojans, who was said to have led the surviving Trojans to modern-day Italy.

The ancient Greeks believed that Troy was located near the Dardanelles and that the Trojan War was a historical event of the 13th or 12th century BC, but by the mid-19th century, both the war and the city were widely seen as non-historical. In 1868, however, the German archaeologist Heinrich Schliemann met Frank Calvert, who convinced Schliemann that Troy was a real city at what is now Hissarlik in Turkey. On the basis of excavations conducted by Schliemann and others, this claim is now accepted by most scholars.

Whether there is any historical reality behind the Trojan War remains an open question. Many scholars believe that there is a historical core to the tale, though this may simply mean that the Homeric stories are a fusion of various tales of sieges and expeditions by Mycenaean Greeks during the Bronze Age. Those who believe that the stories of the Trojan War are derived from a specific historical conflict usually date it to the 12th or 11th centuries BC, often preferring the dates given by Eratosthenes, 1194–1184 BC, which roughly corresponds with archaeological evidence of a catastrophic burning of Troy VII.

The events of the Trojan War are found in many works of Greek literature and depicted in numerous works of Greek art. There is no single, authoritative text which tells the entire events of the war. Instead, the story is assembled from a variety of sources, some of which report contradictory versions of the events. The most important literary sources are the two epic poems traditionally credited to Homer, the "Iliad" and the "Odyssey", composed sometime between the 9th and 6th centuries BC. Each poem narrates only a part of the war. The "Iliad" covers a short period in the last year of the siege of Troy, while the "Odyssey" concerns Odysseus's return to his home island of Ithaca following the sack of Troy and contains several flashbacks to particular episodes in the war.

Other parts of the Trojan War were told in the poems of the Epic Cycle, also known as the Cyclic Epics: the "Cypria", "Aethiopis", "Little Iliad", "Iliou Persis", "Nostoi", and "Telegony". Though these poems survive only in fragments, their content is known from a summary included in Proclus' "Chrestomathy". The authorship of the Cyclic Epics is uncertain. It is generally thought that the poems were written down in the 7th and 6th century BC, after the composition of the Homeric poems, though it is widely believed that they were based on earlier traditions.
Both the Homeric epics and the Epic Cycle take origin from oral tradition. Even after the composition of the "Iliad", "Odyssey", and the Cyclic Epics, the myths of the Trojan War were passed on orally in many genres of poetry and through non-poetic storytelling. Events and details of the story that are only found in later authors may have been passed on through oral tradition and could be as old as the Homeric poems. Visual art, such as vase painting, was another medium in which myths of the Trojan War circulated.

In later ages playwrights, historians, and other intellectuals would create works inspired by the Trojan War. The three great tragedians of Athens- Aeschylus, Sophocles, and Euripides— wrote a number of dramas that portray episodes from the Trojan War. Among Roman writers the most important is the 1st century BC poet Virgil. In Book 2 of the "Aeneid", Aeneas narrates the sack of Troy; this section of the poem is thought to rely on material from the Cyclic Epic "Iliou Persis".

The following summary of the Trojan War follows the order of events as given in Proclus' summary, along with the "Iliad", "Odyssey", and "Aeneid", supplemented with details drawn from other authors.

According to Greek mythology, Zeus had become king of the gods by overthrowing his father Cronus; Cronus in turn had overthrown his father Uranus. Zeus was not faithful to his wife and sister Hera, and had many relationships from which many children were born. Since Zeus believed that there were too many people populating the earth, he envisioned Momus or Themis, who was to use the Trojan War as a means to depopulate the Earth, especially of his demigod descendants.

These can be supported by Hesiod's account:Now all the gods were divided through strife; for at that very time Zeus who thunders on high was meditating marvelous deeds, even to mingle storm and tempest over the boundless earth, and already he was hastening to make an utter end of the race of mortal men, declaring that he would destroy the lives of the demi-gods, that the children of the gods should not mate with wretched mortals, seeing their fate with their own eyes; but that the blessed gods henceforth even as aforetime should have their living and their habitations apart from men. But on those who were born of immortals and of mankind verily Zeus laid toil and sorrow upon sorrow.

Zeus came to learn from either Themis or Prometheus, after Heracles had released him from Caucasus, that, like his father Cronus, he would be overthrown by one of his sons. Another prophecy stated that a son of the sea-nymph Thetis, with whom Zeus fell in love after gazing upon her in the oceans off the Greek coast, would become greater than his father. Possibly for one or both of these reasons, Thetis was betrothed to an elderly human king, Peleus son of Aeacus, either upon Zeus' orders, or because she wished to please Hera, who had raised her.

All of the gods were invited to Peleus and Thetis' wedding and brought many gifts, except Eris (the goddess of discord), who was stopped at the door by Hermes, on Zeus' order. Insulted, she threw from the door a gift of her own: a golden apple (το μήλον της έριδος) on which was inscribed the word καλλίστῃ "Kallistēi" ("To the fairest"). The apple was claimed by Hera, Athena, and Aphrodite. They quarreled bitterly over it, and none of the other gods would venture an opinion favoring one, for fear of earning the enmity of the other two. Eventually, Zeus ordered Hermes to lead the three goddesses to Paris, a prince of Troy, who, unaware of his ancestry, was being raised as a shepherd in Mount Ida, because of a prophecy that he would be the downfall of Troy. After bathing in the spring of Ida, the goddesses appeared to him naked, either for the sake of winning or at Paris' request. Paris was unable to decide between them, so the goddesses resorted to bribes. Athena offered Paris wisdom, skill in battle, and the abilities of the greatest warriors; Hera offered him political power and control of all of Asia; and Aphrodite offered him the love of the most beautiful woman in the world, Helen of Sparta. Paris awarded the apple to Aphrodite, and, after several adventures, returned to Troy, where he was recognized by his royal family.
Peleus and Thetis bore a son, whom they named Achilles. It was foretold that he would either die of old age after an uneventful life, or die young in a battlefield and gain immortality through poetry. Furthermore, when Achilles was nine years old, Calchas had prophesied that Troy could not again fall without his help. A number of sources credit Thetis with attempting to make Achilles immortal when he was an infant. Some of these state that she held him over fire every night to burn away his mortal parts and rubbed him with ambrosia during the day, but Peleus discovered her actions and stopped her. According to some versions of this story, Thetis had already killed several sons in this manner, and Peleus' action therefore saved his son's life. Other sources state that Thetis bathed Achilles in the Styx, the river that runs to the underworld, making him invulnerable wherever he was touched by the water. Because she had held him by the heel, it was not immersed during the bathing and thus the heel remained mortal and vulnerable to injury (hence the expression "Achilles heel" for an isolated weakness). He grew up to be the greatest of all mortal warriors. After Calchas' prophesy, Thetis hid Achilles in Skyros at the court of King Lycomedes, where he was disguised as a girl. At a crucial point in the war, she assists her son by providing weapons divinely forged by Hephaestus (see below).

The most beautiful woman in the world was Helen, one of the daughters of Tyndareus, King of Sparta. Her mother was Leda, who had been either raped or seduced by Zeus in the form of a swan. Accounts differ over which of Leda's four children, two pairs of twins, were fathered by Zeus and which by Tyndareus. However, Helen is usually credited as Zeus' daughter, and sometimes Nemesis is credited as her mother. Helen had scores of suitors, and her father was unwilling to choose one for fear the others would retaliate violently.

Finally, one of the suitors, Odysseus of Ithaca, proposed a plan to solve the dilemma. In exchange for Tyndareus' support of his own suit towards Penelope, he suggested that Tyndareus require all of Helen's suitors to promise that they would defend the marriage of Helen, regardless of whom he chose. The suitors duly swore the required oath on the severed pieces of a horse, although not without a certain amount of grumbling.

Tyndareus chose Menelaus. Menelaus was a political choice on her father's part. He had wealth and power. He had humbly not petitioned for her himself, but instead sent his brother Agamemnon on his behalf. He had promised Aphrodite a hecatomb, a sacrifice of 100 oxen, if he won Helen, but forgot about it and earned her wrath. Menelaus inherited Tyndareus' throne of Sparta with Helen as his queen when her brothers, Castor and Pollux, became gods, and when Agamemnon married Helen's sister Clytemnestra and took back the throne of Mycenae.

Paris, under the guise of a supposed diplomatic mission, went to Sparta to get Helen and bring her back to Troy. Before Helen could look up to see him enter the palace, she was shot with an arrow from Eros, otherwise known as Cupid, and fell in love with Paris when she saw him, as promised by Aphrodite. Menelaus had left for Crete to bury his uncle, Crateus.

According to one account, Hera, still jealous over the judgement of Paris, sent a storm. The storm caused the lovers to land in Egypt, where the gods replaced Helen with a likeness of her made of clouds, Nephele. The myth of Helen being switched is attributed to the 6th century BC Sicilian poet Stesichorus. For Homer the true Helen was in Troy. The ship then landed in Sidon before reaching Troy. Paris, fearful of getting caught, spent some time there and then sailed to Troy.

Paris' abduction of Helen had several precedents. Io was taken from Mycenae, Europa was taken from Phoenicia, Jason took Medea from Colchis, and the Trojan princess Hesione had been taken by Heracles, who gave her to Telamon of Salamis. According to Herodotus, Paris was emboldened by these examples to steal himself a wife from Greece, and expected no retribution, since there had been none in the other cases.

According to Homer, Menelaus and his ally, Odysseus, traveled to Troy, where they unsuccessfully sought to recover Helen by diplomatic means.

Menelaus then asked Agamemnon to uphold his oath, which, as one of Helen's suitors, was to defend her marriage regardless of which suitor had been chosen. Agamemnon agreed and sent emissaries to all the Achaean kings and princes to call them to observe their oaths and retrieve Helen.

Since Menelaus's wedding, Odysseus had married Penelope and fathered a son, Telemachus. In order to avoid the war, he feigned madness and sowed his fields with salt. Palamedes outwitted him by placing his infant son in front of the plough's path, and Odysseus turned aside, unwilling to kill his son, so revealing his sanity and forcing him to join the war.

According to Homer, however, Odysseus supported the military adventure from the beginning, and traveled the region with Pylos' king, Nestor, to recruit forces.

At Skyros, Achilles had an affair with the king's daughter Deidamia, resulting in a child, Neoptolemus. Odysseus, Telamonian Ajax, and Achilles' tutor Phoenix went to retrieve Achilles. Achilles' mother disguised him as a woman so that he would not have to go to war, but, according to one story, they blew a horn, and Achilles revealed himself by seizing a spear to fight intruders, rather than fleeing. According to another story, they disguised themselves as merchants bearing trinkets and weaponry, and Achilles was marked out from the other women for admiring weaponry instead of clothes and jewelry.

Pausanias said that, according to Homer, Achilles did not hide in Skyros, but rather conquered the island, as part of the Trojan War.

The Achaean forces first gathered at Aulis. All the suitors sent their forces except King Cinyras of Cyprus. Though he sent breastplates to Agamemnon and promised to send 50 ships, he sent only one real ship, led by the son of Mygdalion, and 49 ships made of clay. Idomeneus was willing to lead the Cretan contingent in Mycenae's war against Troy, but only as a co-commander, which he was granted. The last commander to arrive was Achilles, who was then 15 years old.

Following a sacrifice to Apollo, a snake slithered from the altar to a sparrow's nest in a plane tree nearby. It ate the mother and her nine babies, then was turned to stone. Calchas interpreted this as a sign that Troy would fall in the tenth year of the war.

When the Achaeans left for the war, they did not know the way, and accidentally landed in Mysia, ruled by King Telephus, son of Heracles, who had led a contingent of Arcadians to settle there. In the battle, Achilles wounded Telephus, who had killed Thersander. Because the wound would not heal, Telephus asked an oracle, "What will happen to the wound?". The oracle responded, "he that wounded shall heal". The Achaean fleet then set sail and was scattered by a storm. Achilles landed in Scyros and married Deidamia. A new gathering was set again in Aulis.

Telephus went to Aulis, and either pretended to be a beggar, asking Agamemnon to help heal his wound, or kidnapped Orestes and held him for ransom, demanding the wound be healed. Achilles refused, claiming to have no medical knowledge. Odysseus reasoned that the spear that had inflicted the wound must be able to heal it. Pieces of the spear were scraped off onto the wound, and Telephus was healed. Telephus then showed the Achaeans the route to Troy.

Some scholars have regarded the expedition against Telephus and its resolution as a derivative reworking of elements from the main story of the Trojan War, but it has also been seen as fitting the story-pattern of the "preliminary adventure" that anticipates events and themes from the main narrative, and therefore as likely to be "early and integral".

Eight years after the storm had scattered them, the fleet of more than a thousand ships was gathered again. But when they had all reached Aulis, the winds ceased. The prophet Calchas stated that the goddess Artemis was punishing Agamemnon for killing either a sacred deer or a deer in a sacred grove, and boasting that he was a better hunter than she. The only way to appease Artemis, he said, was to sacrifice Iphigenia, who was either the daughter of Agamemnon and Clytemnestra, or of Helen and Theseus entrusted to Clytemnestra when Helen married Menelaus. Agamemnon refused, and the other commanders threatened to make Palamedes commander of the expedition. According to some versions, Agamemnon relented and performed the sacrifice, but others claim that he sacrificed a deer in her place, or that at the last moment, Artemis took pity on the girl, and took her to be a maiden in one of her temples, substituting a lamb. Hesiod says that Iphigenia became the goddess Hecate.

The Achaean forces are described in detail in the Catalogue of Ships, in the second book of the "Iliad". They consisted of 28 contingents from mainland Greece, the Peloponnese, the Dodecanese islands, Crete, and Ithaca, comprising 1186 pentekonters, ships with 50 rowers. Thucydides says that according to tradition there were about 1200 ships, and that the Boeotian ships had 120 men, while Philoctetes' ships only had the fifty rowers, these probably being maximum and minimum. These numbers would mean a total force of 70,000 to 130,000 men. Another catalogue of ships is given by the "Bibliotheca" that differs somewhat but agrees in numbers. Some scholars have claimed that Homer's catalogue is an original Bronze Age document, possibly the Achaean commander's order of operations. Others believe it was a fabrication of Homer.

The second book of the "Iliad" also lists the Trojan allies, consisting of the Trojans themselves, led by Hector, and various allies listed as Dardanians led by Aeneas, Zeleians, Adrasteians, Percotians, Pelasgians, Thracians, Ciconian spearmen, Paionian archers, Halizones, Mysians, Phrygians, Maeonians, Miletians, Lycians led by Sarpedon and Carians. Nothing is said of the Trojan language; the Carians are specifically said to be barbarian-speaking, and the allied contingents are said to have spoken multiple languages, requiring orders to be translated by their individual commanders. The Trojans and Achaeans in the "Iliad" share the same religion, same culture and the enemy heroes speak to each other in the same language, though this could be dramatic effect.

Philoctetes was Heracles' friend, and because he lit Heracles's funeral pyre when no one else would, he received Heracles' bow and arrows. He sailed with seven ships full of men to the Trojan War, where he was planning on fighting for the Achaeans. They stopped either at Chryse Island for supplies, or in Tenedos, along with the rest of the fleet. Philoctetes was then bitten by a snake. The wound festered and had a foul smell; on Odysseus's advice, the Atreidae ordered Philoctetes to stay on Lemnos. Medon took control of Philoctetes's men. While landing on Tenedos, Achilles killed king Tenes, son of Apollo, despite a warning by his mother that if he did so he would be killed himself by Apollo. From Tenedos, Agamemnon sent an embassy to Priam, composed of Menelaus, Odysseus, and Palamedes, asking for Helen's return. The embassy was refused.

Philoctetes stayed on Lemnos for ten years, which was a deserted island according to Sophocles' tragedy "Philoctetes", but according to earlier tradition was populated by Minyans.

Calchas had prophesied that the first Achaean to walk on land after stepping off a ship would be the first to die. Thus even the leading Greeks hesitated to land. Finally, Protesilaus, leader of the Phylaceans, landed first. Odysseus had tricked him, in throwing his own shield down to land on, so that while he was first to leap off his ship, he was not the first to land on Trojan soil. Hector killed Protesilaus in single combat, though the Trojans conceded the beach. In the second wave of attacks, Achilles killed Cycnus, son of Poseidon. The Trojans then fled to the safety of the walls of their city. The walls served as sturdy fortifications for defense against the Greeks; the build of the walls was so impressive that legend held that they had been built by Poseidon and Apollo during a year of forced service to Trojan King Laomedon. Protesilaus had killed many Trojans but was killed by Hector in most versions of the story, though others list Aeneas, Achates, or Ephorbus as his slayer. The Achaeans buried him as a god on the Thracian peninsula, across the Troad. After Protesilaus' death, his brother, Podarces, took command of his troops.

The Achaeans besieged Troy for nine years. This part of the war is the least developed among surviving sources, which prefer to talk about events in the last year of the war. After the initial landing the army was gathered in its entirety again only in the tenth year. Thucydides deduces that this was due to lack of money. They raided the Trojan allies and spent time farming the Thracian peninsula. Troy was never completely besieged, thus it maintained communications with the interior of Asia Minor. Reinforcements continued to come until the very end. The Achaeans controlled only the entrance to the Dardanelles, and Troy and her allies controlled the shortest point at Abydos and Sestus and communicated with allies in Europe.

Achilles and Ajax were the most active of the Achaeans, leading separate armies to raid lands of Trojan allies. According to Homer, Achilles conquered 11 cities and 12 islands. According to Apollodorus, he raided the land of Aeneas in the Troad region and stole his cattle. He also captured Lyrnassus, Pedasus, and many of the neighbouring cities, and killed Troilus, son of Priam, who was still a youth; it was said that if he reached 20 years of age, Troy would not fall. According to Apollodorus,
He also took Lesbos and Phocaea, then Colophon, and Smyrna, and Clazomenae, and Cyme; and afterwards Aegialus and Tenos, the so-called Hundred Cities; then, in order, Adramytium and Side; then Endium, and Linaeum, and Colone. He took also Hypoplacian Thebes and Lyrnessus, and further Antandrus, and many other cities.

Kakrides comments that the list is wrong in that it extends too far into the south. Other sources talk of Achilles taking Pedasus, Monenia, Mythemna (in Lesbos), and Peisidice.

Among the loot from these cities was Briseis, from Lyrnessus, who was awarded to him, and Chryseis, from Hypoplacian Thebes, who was awarded to Agamemnon. Achilles captured Lycaon, son of Priam, while he was cutting branches in his father's orchards. Patroclus sold him as a slave in Lemnos, where he was bought by Eetion of Imbros and brought back to Troy. Only 12 days later Achilles slew him, after the death of Patroclus.

Ajax son of Telamon laid waste the Thracian peninsula of which Polymestor, a son-in-law of Priam, was king. Polymestor surrendered Polydorus, one of Priam's children, of whom he had custody. He then attacked the town of the Phrygian king Teleutas, killed him in single combat and carried off his daughter Tecmessa. Ajax also hunted the Trojan flocks, both on Mount Ida and in the countryside.

Numerous paintings on pottery have suggested a tale not mentioned in the literary traditions. At some point in the war Achilles and Ajax were playing a board game ("petteia"). They were absorbed in the game and oblivious to the surrounding battle. The Trojans attacked and reached the heroes, who were only saved by an intervention of Athena.

Odysseus was sent to Thrace to return with grain, but came back empty-handed. When scorned by Palamedes, Odysseus challenged him to do better. Palamedes set out and returned with a shipload of grain.

Odysseus had never forgiven Palamedes for threatening the life of his son. In revenge, Odysseus conceived a plot where an incriminating letter was forged, from Priam to Palamedes, and gold was planted in Palamedes' quarters. The letter and gold were "discovered", and Agamemnon had Palamedes stoned to death for treason.

However, Pausanias, quoting the "Cypria", says that Odysseus and Diomedes drowned Palamedes, while he was fishing, and Dictys says that Odysseus and Diomedes lured Palamedes into a well, which they said contained gold, then stoned him to death.

Palamedes' father Nauplius sailed to the Troad and asked for justice, but was refused. In revenge, Nauplius traveled among the Achaean kingdoms and told the wives of the kings that they were bringing Trojan concubines to dethrone them. Many of the Greek wives were persuaded to betray their husbands, most significantly Agamemnon's wife, Clytemnestra, who was seduced by Aegisthus, son of Thyestes.

Near the end of the ninth year since the landing, the Achaean army, tired from the fighting and from the lack of supplies, mutinied against their leaders and demanded to return to their homes. According to the Cypria, Achilles forced the army to stay. According to Apollodorus, Agamemnon brought the Wine Growers, daughters of Anius, son of Apollo, who had the gift of producing by touch wine, wheat, and oil from the earth, in order to relieve the supply problem of the army.

Chryses, a priest of Apollo and father of Chryseis, came to Agamemnon to ask for the return of his daughter. Agamemnon refused, and insulted Chryses, who prayed to Apollo to avenge his ill-treatment. Enraged, Apollo afflicted the Achaean army with plague. Agamemnon was forced to return Chryseis to end the plague, and took Achilles' concubine Briseis as his own. Enraged at the dishonour Agamemnon had inflicted upon him, Achilles decided he would no longer fight. He asked his mother, Thetis, to intercede with Zeus, who agreed to give the Trojans success in the absence of Achilles, the best warrior of the Achaeans.

After the withdrawal of Achilles, the Achaeans were initially successful. Both armies gathered in full for the first time since the landing. Menelaus and Paris fought a duel, which ended when Aphrodite snatched the beaten Paris from the field. With the truce broken, the armies began fighting again. Diomedes won great renown amongst the Achaeans, killing the Trojan hero Pandaros and nearly killing Aeneas, who was only saved by his mother, Aphrodite. With the assistance of Athena, Diomedes then wounded the gods Aphrodite and Ares. During the next days, however, the Trojans drove the Achaeans back to their camp and were stopped at the Achaean wall by Poseidon. The next day, though, with Zeus' help, the Trojans broke into the Achaean camp and were on the verge of setting fire to the Achaean ships. An earlier appeal to Achilles to return was rejected, but after Hector burned Protesilaus' ship, he allowed his close friend and relative Patroclus to go into battle wearing Achilles' armour and lead his army. Patroclus drove the Trojans all the way back to the walls of Troy, and was only prevented from storming the city by the intervention of Apollo. Patroclus was then killed by Hector, who took Achilles' armour from the body of Patroclus.
Achilles, maddened with grief, swore to kill Hector in revenge. He was reconciled with Agamemnon and received Briseis back, untouched by Agamemnon. He received a new set of arms, forged by the god Hephaestus, and returned to the battlefield. He slaughtered many Trojans, and nearly killed Aeneas, who was saved by Poseidon. Achilles fought with the river god Scamander, and a battle of the gods followed. The Trojan army returned to the city, except for Hector, who remained outside the walls because he was tricked by Athena. Achilles killed Hector, and afterwards he dragged Hector's body from his chariot and refused to return the body to the Trojans for burial. The Achaeans then conducted funeral games for Patroclus. Afterwards, Priam came to Achilles' tent, guided by Hermes, and asked Achilles to return Hector's body. The armies made a temporary truce to allow the burial of the dead. The "Iliad" ends with the funeral of Hector.

Shortly after the burial of Hector, Penthesilea, queen of the Amazons, arrived with her warriors. Penthesilea, daughter of Otrere and Ares, had accidentally killed her sister Hippolyte. She was purified from this action by Priam, and in exchange she fought for him and killed many, including Machaon (according to Pausanias, Machaon was killed by Eurypylus), and according to one version, Achilles himself, who was resurrected at the request of Thetis. In another version, Penthesilia was killed by Achilles who fell in love with her beauty after her death. Thersites, a simple soldier and the ugliest Achaean, taunted Achilles over his love and gouged out Penthesilea's eyes. Achilles slew Thersites, and after a dispute sailed to Lesbos, where he was purified for his murder by Odysseus after sacrificing to Apollo, Artemis, and Leto.

While they were away, Memnon of Ethiopia, son of Tithonus and Eos, came with his host to help his stepbrother Priam. He did not come directly from Ethiopia, but either from Susa in Persia, conquering all the peoples in between, or from the Caucasus, leading an army of Ethiopians and Indians. Like Achilles, he wore armour made by Hephaestus. In the ensuing battle, Memnon killed Antilochus, who took one of Memnon's blows to save his father Nestor. Achilles and Memnon then fought. Zeus weighed the fate of the two heroes; the weight containing that of Memnon sank, and he was slain by Achilles. Achilles chased the Trojans to their city, which he entered. The gods, seeing that he had killed too many of their children, decided that it was his time to die. He was killed after Paris shot a poisoned arrow that was guided by Apollo. In another version he was killed by a knife to the back (or heel) by Paris, while marrying Polyxena, daughter of Priam, in the temple of Thymbraean Apollo, the site where he had earlier killed Troilus. Both versions conspicuously deny the killer any sort of valour, saying Achilles remained undefeated on the battlefield. His bones were mingled with those of Patroclus, and funeral games were held. Like Ajax, he is represented as living after his death in the island of Leuke, at the mouth of the Danube River, where he is married to Helen.

A great battle raged around the dead Achilles. Ajax held back the Trojans, while Odysseus carried the body away. When Achilles' armour was offered to the smartest warrior, the two that had saved his body came forward as competitors. Agamemnon, unwilling to undertake the invidious duty of deciding between the two competitors, referred the dispute to the decision of the Trojan prisoners, inquiring of them which of the two heroes had done most harm to the Trojans. Alternatively, the Trojans and Pallas Athena were the judges in that, following Nestor's advice, spies were sent to the walls to overhear what was said. A girl said that Ajax was braver:
<poem>
For Aias took up and carried out of the strife the hero, Peleus'
son: this great Odysseus cared not to do.
To this another replied by Athena's contrivance:
Why, what is this you say? A thing against reason and untrue!
Even a woman could carry a load once a man had put it on her
shoulder; but she could not fight. For she would fail with fear
if she should fight. (Scholiast on Aristophanes, Knights 1056 and Aristophanes ib)
</poem>
According to Pindar, the decision was made by secret ballot among the Achaeans. In all story versions, the arms were awarded to Odysseus. Driven mad with grief, Ajax desired to kill his comrades, but Athena caused him to mistake the cattle and their herdsmen for the Achaean warriors. In his frenzy he scourged two rams, believing them to be Agamemnon and Menelaus. In the morning, he came to his senses and killed himself by jumping on the sword that had been given to him by Hector, so that it pierced his armpit, his only vulnerable part. According to an older tradition, he was killed by the Trojans who, seeing he was invulnerable, attacked him with clay until he was covered by it and could no longer move, thus dying of starvation.

After the tenth year, it was prophesied that Troy could not fall without Heracles' bow, which was with Philoctetes in Lemnos. Odysseus and Diomedes retrieved Philoctetes, whose wound had healed. Philoctetes then shot and killed Paris.

According to Apollodorus, Paris' brothers Helenus and Deiphobus vied over the hand of Helen. Deiphobus prevailed, and Helenus abandoned Troy for Mt. Ida. Calchas said that Helenus knew the prophecies concerning the fall of Troy, so Odysseus waylaid Helenus. Under coercion, Helenus told the Achaeans that they would win if they retrieved Pelops' bones, persuaded Achilles' son Neoptolemus to fight for them, and stole the Trojan Palladium.

The Greeks retrieved Pelop's bones, and sent Odysseus to retrieve Neoptolemus, who was hiding from the war in King Lycomedes's court in Scyros. Odysseus gave him his father's arms. Eurypylus, son of Telephus, leading, according to Homer, a large force of "Kêteioi", or Hittites or Mysians according to Apollodorus, arrived to aid the Trojans. He killed Machaon and Peneleos, but was slain by Neoptolemus.

Disguised as a beggar, Odysseus went to spy inside Troy, but was recognized by Helen. Homesick, Helen plotted with Odysseus. Later, with Helen's help, Odysseus and Diomedes stole the Palladium.

The end of the war came with one final plan. Odysseus devised a new ruse—a giant hollow wooden horse, an animal that was sacred to the Trojans. It was built by Epeius and guided by Athena, from the wood of a cornel tree grove sacred to Apollo, with the inscription:

The hollow horse was filled with soldiers led by Odysseus. The rest of the army burned the camp and sailed for Tenedos.

When the Trojans discovered that the Greeks were gone, believing the war was over, they "joyfully dragged the horse inside the city", while they debated what to do with it. Some thought they ought to hurl it down from the rocks, others thought they should burn it, while others said they ought to dedicate it to Athena.

Both Cassandra and Laocoön warned against keeping the horse. While Cassandra had been given the gift of prophecy by Apollo, she was also cursed by Apollo never to be believed. Serpents then came out of the sea and devoured either Laocoön and one of his two sons, Laocoön and both his sons, or only his sons, a portent which so alarmed the followers of Aeneas that they withdrew to Ida. The Trojans decided to keep the horse and turned to a night of mad revelry and celebration. Sinon, an Achaean spy, signaled the fleet stationed at Tenedos when "it was midnight and the clear moon was rising" and the soldiers from inside the horse emerged and killed the guards.

The Achaeans entered the city and killed the sleeping population. A great massacre followed which continued into the day.
<poem>
Blood ran in torrents, drenched was all the earth,
As Trojans and their alien helpers died.
Here were men lying quelled by bitter death
All up and down the city in their blood.
</poem>

The Trojans, fuelled with desperation, fought back fiercely, despite being disorganized and leaderless. With the fighting at its height, some donned fallen enemies' attire and launched surprise counterattacks in the chaotic street fighting. Other defenders hurled down roof tiles and anything else heavy down on the rampaging attackers. The outlook was grim though, and eventually the remaining defenders were destroyed along with the whole city.

Neoptolemus killed Priam, who had taken refuge at the altar of Zeus of the Courtyard. Menelaus killed Deiphobus, Helen's husband after Paris' death, and also intended to kill Helen, but, overcome by her beauty, threw down his sword and took her to the ships.

Ajax the Lesser raped Cassandra on Athena's altar while she was clinging to her statue. Because of Ajax's impiety, the Acheaens, urged by Odysseus, wanted to stone him to death, but he fled to Athena's altar, and was spared.

Antenor, who had given hospitality to Menelaus and Odysseus when they asked for the return of Helen, and who had advocated so, was spared, along with his family. Aeneas took his father on his back and fled, and, according to Apollodorus, was allowed to go because of his piety.

The Greeks then burned the city and divided the spoils. Cassandra was awarded to Agamemnon. Neoptolemus got Andromache, wife of Hector, and Odysseus was given Hecuba, Priam's wife.

The Achaeans threw Hector's infant son Astyanax down from the walls of Troy, either out of cruelty and hate or to end the royal line, and the possibility of a son's revenge. They (by usual tradition Neoptolemus) also sacrificed the Trojan princess Polyxena on the grave of Achilles as demanded by his ghost, either as part of his spoil or because she had betrayed him.

Aethra, Theseus' mother, and one of Helen's handmaids, was rescued by her grandsons, Demophon and Acamas.

The gods were very angry over the destruction of their temples and other sacrilegious acts by the Achaeans, and decided that most would not return home. A storm fell on the returning fleet off Tenos island. Additionally, Nauplius, in revenge for the murder of his son Palamedes, set up false lights in Cape Caphereus (also known today as Cavo D'Oro, in Euboea) and many were shipwrecked.


According to the "Odyssey", Menelaus's fleet was blown by storms to Crete and Egypt, where they were unable to sail away due to calm winds. Only five of his ships survived. Menelaus had to catch Proteus, a shape-shifting sea god, to find out what sacrifices to which gods he would have to make to guarantee safe passage. According to some stories the Helen who was taken by Paris was a fake, and the real Helen was in Egypt, where she was reunited with Menelaus. Proteus also told Menelaus that he was destined for Elysium (Heaven) after his death. Menelaus returned to Sparta with Helen eight years after he had left Troy.

Agamemnon returned home with Cassandra to Argos. His wife Clytemnestra (Helen's sister) was having an affair with Aegisthus, son of Thyestes, Agamemnon's cousin who had conquered Argos before Agamemnon himself retook it. Possibly out of vengeance for the death of Iphigenia, Clytemnestra plotted with her lover to kill Agamemnon. Cassandra foresaw this murder, and warned Agamemnon, but he disregarded her. He was killed, either at a feast or in his bath, according to different versions. Cassandra was also killed. Agamemnon's son Orestes, who had been away, returned and conspired with his sister Electra to avenge their father. He killed Clytemnestra and Aegisthus and succeeded to his father's throne.

Odysseus' ten-year journey home to Ithaca was told in Homer's "Odyssey". Odysseus and his men were blown far off course to lands unknown to the Achaeans; there Odysseus had many adventures, including the famous encounter with the Cyclops Polyphemus, and an audience with the seer Teiresias in Hades. On the island of Thrinacia, Odysseus' men ate the cattle sacred to the sun-god Helios. For this sacrilege Odysseus' ships were destroyed, and all his men perished. Odysseus had not eaten the cattle, and was allowed to live; he washed ashore on the island of Ogygia, and lived there with the nymph Calypso. After seven years, the gods decided to send Odysseus home; on a small raft, he sailed to Scheria, the home of the Phaeacians, who gave him passage to Ithaca.
Once in his home land, Odysseus traveled disguised as an old beggar. He was recognised by his dog, Argos, who died in his lap. He then discovered that his wife, Penelope, had been faithful to him during the 20 years he was absent, despite the countless suitors that were eating his food and spending his property. With the help of his son Telemachus, Athena, and Eumaeus, the swineherd, he killed all of them except Medon, who had been polite to Penelope, and Phemius, a local singer who had only been forced to help the suitors against Penelope. Penelope tested Odysseus and made sure it was him, and he forgave her. The next day the suitors' relatives tried to take revenge on him but they were stopped by Athena.

The "Telegony" picks up where the "Odyssey" leaves off, beginning with the burial of the dead suitors, and continues until the death of Odysseus. Some years after Odysseus' return, Telegonus, the son of Odysseus and Circe, came to Ithaca and plundered the island. Odysseus, attempting to fight off the attack, was killed by his unrecognized son. After Telegonus realized he had killed his father, he brought the body to his mother Circe, along with Telemachus and Penelope. Circe made them immortal; then Telegonus married Penelope and Telemachus married Circe.

The journey of the Trojan survivor Aeneas and his resettling of Trojan refugees in Italy are the subject of the Latin epic poem "The Aeneid" by Virgil. Writing during the time of Augustus, Virgil has his hero give a first-person account of the fall of Troy in the second of the "Aeneid" 's twelve books; the Trojan Horse, which does not appear in "The Iliad", became legendary from Virgil's account.

Aeneas leads a group of survivors away from the city, among them his son Ascanius (also known as Iulus), his trumpeter Misenus, father Anchises, the healer Iapyx, his faithful sidekick Achates, and Mimas as a guide. His wife Creusa is killed during the sack of the city. Aeneas also carries the Lares and Penates of Troy, which the historical Romans claimed to preserve as guarantees of Rome's own security.

The Trojan survivors escape with a number of ships, seeking to establish a new homeland elsewhere. They land in several nearby countries that prove inhospitable, and are finally told by an oracle that they must return to the land of their forebears. They first try to establish themselves in Crete, where Dardanus had once settled, but find it ravaged by the same plague that had driven Idomeneus away. They find the colony led by Helenus and Andromache, but decline to remain. After seven years they arrive in Carthage, where Aeneas has an affair with Queen Dido. (Since according to tradition Carthage was founded in 814 BC, the arrival of Trojan refugees a few hundred years earlier exposes chronological difficulties within the mythic tradition.) Eventually the gods order Aeneas to continue onward, and he and his people arrive at the mouth of the Tiber River in Italy. Dido commits suicide, and Aeneas's betrayal of her was regarded as an element in the long enmity between Rome and Carthage that expressed itself in the Punic Wars and led to Roman hegemony.

At Cumae, the Sibyl leads Aeneas on an archetypal descent to the underworld, where the shade of his dead father serves as a guide; this book of the "Aeneid" directly influenced Dante, who has Virgil act as his narrator's guide. Aeneas is given a vision of the future majesty of Rome, which it was his duty to found, and returns to the world of the living. He negotiates a settlement with the local king, Latinus, and was wed to his daughter, Lavinia. This triggered a war with other local tribes, which culminated in the founding of the settlement of Alba Longa, ruled by Aeneas and Lavinia's son Silvius. Roman myth attempted to reconcile two different founding myths: three hundred years later, in the more famous tradition, Romulus founded Rome after murdering his brother Remus. The Trojan origins of Rome became particularly important in the propaganda of Julius Caesar, whose family claimed descent from Venus through Aeneas's son Iulus (hence the Latin "gens" name "Iulius"), and during the reign of Augustus; see for instance the "Tabulae Iliacae" and the "Troy Game" presented frequently by the Julio-Claudian dynasty.

Since this war was considered among the ancient Greeks as either the last event of the mythical age or the first event of the historical age, several dates are given for the fall of Troy. They usually derive from genealogies of kings. Ephorus gives 1135 BC, Sosibius 1172 BC, Eratosthenes 1184 BC/1183 BC, Timaeus 1193 BC, the Parian marble 1209 BC/1208 BC, Dicaearchus 1212 BC, Herodotus around 1250 BC, Eretes 1291 BC, while Douris 1334 BC. As for the exact day Ephorus gives 23/24 Thargelion (May 6 or 7), Hellanicus 12 Thargelion (May 26) while others give the 23rd of Sciroforion (July 7) or the 23rd of Ponamos (October 7).

The glorious and rich city Homer describes was believed to be Troy VI by many twentieth century authors, destroyed in 
1275 BC, probably by an earthquake. Its follower Troy VIIa, destroyed by fire at some point during the 1180s BC, was long considered a poorer city, but since the excavation campaign of 1988 it has risen to the most likely candidate.

The historicity of the Trojan War is still subject to debate. Most classical Greeks thought that the war was a historical event, but many believed that the Homeric poems had exaggerated the events to suit the demands of poetry. For instance, the historian Thucydides, who is known for being critical, considers it a true event but doubts that 1,186 ships were sent to Troy. Euripides started changing Greek myths at will, including those of the Trojan War. Near year 100, Dio Chrysostom argued that while the war was historical, it ended with the Trojans winning, and the Greeks attempted to hide that fact. Around 1870 it was generally agreed in Western Europe that the Trojan War had never happened and Troy never existed. Then Heinrich Schliemann popularized his excavations at Hisarlik, which he and others believed to be Troy, and of the Mycenaean cities of Greece. Today many scholars agree that the Trojan War is based on a historical core of a Greek expedition against the city of Troy, but few would argue that the Homeric poems faithfully represent the actual events of the war.

In November 2001, geologist John C. Kraft and classicist John V. Luce presented the results of investigations into the geology of the region that had started in 1977. The geologists compared the present geology with the landscapes and coastal features described in the "Iliad" and other classical sources, notably Strabo's "Geographia". Their conclusion was that there is regularly a consistency between the location of Troy as identified by Schliemann (and other locations such as the Greek camp), the geological evidence, and descriptions of the topography and accounts of the battle in the "Iliad".

In the twentieth century scholars have attempted to draw conclusions based on Hittite and Egyptian texts that date to the time of the Trojan War. While they give a general description of the political situation in the region at the time, their information on whether this particular conflict took place is limited. Andrew Dalby notes that while the Trojan War most likely did take place in some form and is therefore grounded in history, its true nature is and will be unknown. The Tawagalawa letter mentions a kingdom of "Ahhiyawa" (Achaea, or Greece) that lies beyond the sea (that would be the Aegean) and controls Milliwanda, which is identified with Miletus. Also mentioned in this and other letters is the Assuwa confederation made of 22 cities and countries which included the city of "Wilusa" (Ilios or Ilium). The Milawata letter implies this city lies on the north of the Assuwa confederation, beyond the Seha river. While the identification of Wilusa with Ilium (that is, Troy) is always controversial, in the 1990s it gained majority acceptance. In the Alaksandu treaty (c. 1280 BC) the king of the city is named Alaksandu, and Paris's name in the "Iliad" (among other works) is Alexander. The Tawagalawa letter (dated c. 1250 BC) which is addressed to the king of Ahhiyawa actually says: "Now as we have come to an agreement on Wilusa over which we went to war ..."

Formerly under the Hittites, the Assuwa confederation defected after the battle of Kadesh between Egypt and the Hittites (c. 1274 BC). In 1230 BC Hittite king Tudhaliya IV (c. 1240–1210 BC) campaigned against this federation. Under Arnuwanda III (c. 1210–1205 BC) the Hittites were forced to abandon the lands they controlled in the coast of the Aegean. It is possible that the Trojan War was a conflict between the king of Ahhiyawa and the Assuwa confederation. This view has been supported in that the entire war includes the landing in Mysia (and Telephus' wounding), Achilles's campaigns in the North Aegean and Telamonian Ajax's campaigns in Thrace and Phrygia. Most of these regions were part of Assuwa. 
That most Achaean heroes did not return to their homes and founded colonies elsewhere was interpreted by Thucydides as being due to their long absence. Nowadays the interpretation followed by most scholars is that the Achaean leaders driven out of their lands by the turmoil at the end of the Mycenaean era preferred to claim descent from exiles of the Trojan War.

The inspiration provided by these events produced many literary works, far more than can be listed here. The siege of Troy provided inspiration for many works of art, most famously Homer's "Iliad", set in the last year of the siege. Some of the others include "Troades" by Euripides, "Troilus and Criseyde" by Geoffrey Chaucer, "Troilus and Cressida" by William Shakespeare, "Iphigenia" and "Polyxena" by Samuel Coster, "Palamedes" by Joost van den Vondel and "Les Troyens" by Hector Berlioz.

Films based on the Trojan War include "Helen of Troy" (1956), "The Trojan Horse" (1961) and "Troy" (2004). The war has also been featured in many books, television series, and other creative works.



</doc>
<doc id="30059" url="https://en.wikipedia.org/wiki?curid=30059" title="Troy">
Troy

Troy (, "Troia" or Τροίας, "Troias" and , "Ilion" or , "Ilios"; and ; Hittite: "Wilusha" or "Truwisha"; ) was a city in the far northwest of the region known in late Classical antiquity as Asia Minor, now known as Anatolia in modern Turkey, near (just south of) the southwest mouth of the Dardanelles strait and northwest of Mount Ida. The present-day location is known as Hisarlik. It was the setting of the Trojan War described in the Greek Epic Cycle, in particular in the "Iliad", one of the two epic poems attributed to Homer. Metrical evidence from the "Iliad" and the "Odyssey" suggests that the name ("Ilion") formerly began with a digamma: ("Wilion"); this is also supported by the Hittite name for what is thought to be the same city, Wilusa.

A new capital called Ilium (from Greek: Ἴλιον, "Ilion") was founded on the site in the reign of the Roman Emperor Augustus. It flourished until the establishment of Constantinople, became a bishopric and declined gradually in the Byzantine era, but is now a Latin Catholic titular see.

In 1865, English archaeologist Frank Calvert excavated trial trenches in a field he had bought from a local farmer at Hisarlik, and in 1868, Heinrich Schliemann, a wealthy German businessman and archaeologist, also began excavating in the area after a chance meeting with Calvert in Çanakkale. These excavations revealed several cities built in succession. Schliemann was at first skeptical about the identification of Hisarlik with Troy, but was persuaded by Calvert and took over Calvert's excavations on the eastern half of the Hisarlik site, which was on Calvert's property. Troy VII has been identified with the city called Wilusa by the Hittites, the probable origin of the Greek Ἴλιον, and is generally (but not conclusively) identified with Homeric Troy.

Today, the hill at Hisarlik has given its name to a small village near the ruins, which supports the tourist trade visiting the Troia archaeological site. It lies within the province of Çanakkale, some 30 km south-west of the provincial capital, also called Çanakkale. The nearest village is Tevfikiye. The map here shows the adapted Scamander estuary with Ilium a little way inland across the Homeric plain. Due to Troy's location near the Aegean Sea, the Sea of Marmara, and the Black Sea, it was a central hub for the military and trade.

Troy was added to the UNESCO World Heritage list in 1998.

Ancient Greek historians variously placed the Trojan War in the 12th, 13th, or 14th centuries BC: Eratosthenes to 1184 BC, Herodotus to 1250 BC, and Duris of Samos to 1334 BC. Modern archaeologists associate Homeric Troy with archaeological Troy VII.

In the "Iliad", the Achaeans set up their camp near the mouth of the River Scamander (presumably modern Karamenderes), where they had beached their ships. The city of Troy itself stood on a hill, across the plain of Scamander, where the battles of the Trojan War took place. The site of the ancient city is some 5 km from the coast today, but 3,000 years ago the mouths of Scamander were much closer to the city, discharging into a large bay that formed a natural harbor, which has since been filled with alluvial material. Recent geological findings have permitted the identification of the ancient Trojan coastline, and the results largely confirm the accuracy of the Homeric geography of Troy.

In November 2001, the geologist John C. Kraft from the University of Delaware and the classicist John V. Luce from Trinity College, Dublin, presented the results of investigations, begun in 1977, into the geology of the region. They compared the present geology with the landscapes and coastal features described in the "Iliad" and other classical sources, notably Strabo's "Geographia", and concluded that there is a regular consistency between the location of Schliemann's Troy and other locations such as the Greek camp, the geological evidence, descriptions of the topography and accounts of the battle in the "Iliad".

Besides the "Iliad", there are references to Troy in the other major work attributed to Homer, the "Odyssey", as well as in other ancient Greek literature (such as Aeschylus's Oresteia). The Homeric legend of Troy was elaborated by the Roman poet Virgil in his "Aeneid". The Greeks and Romans took for a fact the historicity of the Trojan War and the identity of Homeric Troy with the site in Anatolia. Alexander the Great, for example, visited the site in 334 BC and there made sacrifices at tombs associated with the Homeric heroes Achilles and Patroclus.

After the 1995 find of a Luwian biconvex seal at Troy VII, there has been a heated discussion over the language that was spoken in Homeric Troy. Frank Starke of the University of Tübingen recently demonstrated that the name of Priam, king of Troy at the time of the Trojan War, is connected to the Luwian compound "Priimuua", which means "exceptionally courageous". "The certainty is growing that Wilusa/Troy belonged to the greater Luwian-speaking community," although it is not entirely clear whether Luwian was primarily the official language or in daily colloquial use.

With the rise of critical history, Troy and the Trojan War were, for a long time, consigned to the realms of legend. However, the true location of ancient Troy had from classical times remained the subject of interest and speculation.

The Troad peninsula was anticipated to be the location. Early modern travellers in the 16th and 17th centuries, including Pierre Belon and Pietro Della Valle, had identified Troy with Alexandria Troas, a ruined town approximately 20 km south of the currently accepted location. In the late 18th century, Jean Baptiste LeChevalier had identified a location near the village of as the site of Troy, a mound approximately 5 km south of the currently accepted location. LeChavalier's location, published in his "Voyage de la Troade", was the most commonly accepted theory for almost a century.

In 1822, the Scottish journalist Charles Maclaren was the first to identify with confidence the position of the city as it is now known.

In 1866, Frank Calvert, the brother of the United States' consular agent in the region, made extensive surveys and published in scholarly journals his identification of the hill of New Ilium (which was on farmland owned by his family) on the same site. The hill, near the city of Çanakkale, was known as Hisarlik.

In 1868, German archaeologist Heinrich Schliemann visited Calvert and secured permission to excavate Hisarlik. In 1871–73 and 1878–79, he excavated the hill and discovered the ruins of a series of ancient cities dating from the Bronze Age to the Roman period. Schliemann declared one of these cities—at first Troy I, later Troy II—to be the city of Troy, and this identification was widely accepted at that time. Schliemann's finds at Hisarlik have become known as Priam's Treasure. They were acquired from him by the Berlin museums, but significant doubts about their authenticity persist.
Schliemann became interested in digging at the mound of Hisarlik at the persuasion of Frank Calvert. The British diplomat, considered a pioneer for the contributions he made to the archaeology of Troy, spent more than 60 years in the Troad (modern day Biga peninsula, Turkey) conducting field work. As Calvert was a principal authority on field archaeology in the region, his findings supplied evidence that Homeric Troy might exist in the hill, and played a major role in directing Heinrich Schliemann to dig at the Hisarlik. However, Schliemann downplayed his collaboration with Calvert when taking credit for the findings, such that Susan Heuek Allen recently described Schliemann as a "relentlessly self-promoting amateur archaeologist".

Schliemann's excavations were condemned by later archaeologists as having destroyed the main layers of the real Troy. Kenneth W. Harl in the Teaching Company's "Great Ancient Civilizations of Asia Minor" lecture series sarcastically claims that Schliemann's excavations were carried out with such rough methods that he did to Troy what the Greeks couldn't do in their times, destroying and levelling down the entire city walls to the ground. Other scholars agree that the damage caused to the site is irreparable. Although his work is largely rejected, his recorded findings and artifacts added knowledge regarding ancient Western history.

After Schliemann, the site was further excavated under the direction of Wilhelm Dörpfeld and later Carl Blegen (1932–38).

These excavations have shown that there were at least nine cities built, one on top of the other, at this site. In his research, Blegen came to a conclusion that Troy's nine levels could be further divided into forty-six sublevels .

In 1988, excavations were resumed by a team from the University of Tübingen and the University of Cincinnati under the direction of Professor Manfred Korfmann, with Professor Brian Rose overseeing Post-Bronze Age (Greek, Roman, Byzantine) excavation along the coast of the Aegean Sea at the Bay of Troy. Possible evidence of a battle was found in the form of bronze arrowheads and fire-damaged human remains buried in layers dated to the early 12th century BC. The question of Troy's status in the Bronze-Age world has been the subject of a sometimes acerbic debate between Korfmann and the Tübingen historian Frank Kolb in 2001–2002.

In August 1993, following a magnetic imaging survey of the fields below the fort, a deep ditch was located and excavated among the ruins of a later Greek and Roman city. Remains found in the ditch were dated to the late Bronze Age, the alleged time of Homeric Troy. It is claimed by Korfmann that the ditch may have once marked the outer defences of a much larger city than had previously been suspected. The latter city has been dated by his team to about 1250 BC, and it has been also suggested — based on recent archeological evidence uncovered by Professor Manfred Korfmann's team — that this was indeed the Homeric city of Troy.

The archaeological site of Troy was added to the UNESCO World Heritage list in 1998.

In summer 2006, the excavations continued under the direction of Korfmann's colleague Ernst Pernicka, with a new digging permit.

In 2013, an international team made up of cross-disciplinary experts led by William Aylward, an archaeologist at the University of Wisconsin-Madison, was to carry out new excavations. This activity was to be conducted under the auspices of Çanakkale Onsekiz Mart University and was to use the new technique of "molecular archaeology". A few days before the Wisconsin team was to leave, Turkey cancelled about 100 excavation permits, including Wisconsin's.

In March 2014, it was announced that a new excavation would take place to be sponsored by a private company and carried out by Çanakkale Onsekiz Mart University. This will be the first Turkish team to excavate and is planned as a 12-month excavation led by associate professor Rüstem Aslan. The University's rector stated that "Pieces unearthed in Troy will contribute to Çanakkale’s culture and tourism. Maybe it will become one of Turkey’s most important frequented historical places.”

The walls of Troy, first erected in the Bronze Age between 3000 and 2600 BC, are its main defense. The remains of the walls have been studied through the aforementioned excavations that shed light onto the historical city itself and the mythological implications as the walls protected the citadel during the Trojan War. The fortifications display the importance of defense to the Trojans and how warfare is a prominent issue for ancient cities.

The walls surround the city, lasting for several hundred meters and at the time they were built, they were over 17 feet tall. They were made of limestone with watchtowers and brick ramparts, or elevated mounds that serve as protective barriers. Throughout all of the phases, the walls served as the largest fortification for the city of Troy to protect the Trojans against any enemies. Defense mechanisms like the Walls of Troy shed light onto the larger topic of warfare in ancient times. Warfare was a large issue in not only Ancient Greece, but locations nearby, such as Asia Minor.

When Troy was destroyed each time, the citizens would build upon the previous settlement, causing the layers to pile on top of one another. The layers of ruins in the citadel at Hisarlik are numbered Troy ITroy IX, with various subdivisions:


The first city on the site was founded in the 3rd millennium BC. During the Bronze Age, the site seems to have been a flourishing mercantile city, since its location allowed for complete control of the Dardanelles, through which every merchant ship from the Aegean Sea heading for the Black Sea had to pass. Around 1900 BC a mass migration was set off by the Hittites to the east. Cities to the east of Troy were destroyed, and although Troy was not burned, the next period shows a change of culture indicating a new people had taken over Troy. The first phase of the city is characterized by a smaller citadel, around 300 ft in diameter, with 20 rectangular houses surrounded by massive walls, towers, and gateways. Troy II doubled in size and had a lower town and the upper citadel, with the walls protecting the upper acropolis which housed the megaron-style palace for the king. The second phase was destroyed by a large fire, but the Trojans rebuilt, creating a fortified citadel larger than Troy II, but which had smaller and more condensed houses, suggesting an economic decline. This trend of making a larger circuit, or extent of the walls, continued with each rebuild, for Troy III, IV, and V. Therefore, even in the face of economic troubles, the walls remained as elaborate as before, indicating their focus on defense and protection.

When Schliemann came across Troy II, in 1871, he believed he had found Homer's city. Schliemann and his team unearthed a large feature he dubbed the Scaean Gate, a western gate unlike the three previously found leading to the Pergamos. This gate, as he describes, was the gate that Homer had featured. As Schliemann states in his publication "Troja":
"I have proved that in a remote antiquity there was in the plain of Troy a large city, destroyed of old by a fearful catastrophe, which had on the hill of Hisarlık only its Acropolis with its temples and a few other large edifices, southerly, and westerly direction on the site of the later Ilium; and that, consequently, this city answers perfectly to the Homeric description of the sacred site of Ilios."

Troy VI was destroyed around 1250 BC, probably by an earthquake. Only a single arrowhead was found in this layer, and no remains of bodies. However, the town quickly recovered and was rebuilt in a layout that was more orderly. This rebuild continued the trend of having a heavily fortified citadel to preserve the outer rim of the city in the face of earthquakes and sieges of the central city.

Troy VIIa, which has been dated to the mid-to-late-13th century BC, is the most often cited candidate for the Troy of Homer. Troy VIIa appears to have been destroyed by war. The evidence of fire and slaughter around 1184 BC, which brought Troy VIIa to a close, led to this phase being identified with the city besieged by the Greeks during the Trojan War. This was immortalized in the "Iliad" written by Homer.

Initially, the layers of Troy VI and VII were overlooked entirely, because Schliemann favoured the burnt city of Troy II. It was not until the need to close "Calvert's Thousand Year Gap" arose—from Dörpfeld's discovery of Troy VI—that archaeology turned away from Schliemann's Troy and began working towards finding Homeric Troy once more.

"Calvert's Thousand Year Gap" (1800–800 BC) was a period not accounted for by Schliemann's archaeology and thus constituting a hole in the Trojan timeline. In Homer's description of the city, a section of one side of the wall is said to be weaker than the rest. During his excavation of more than three hundred yards of the wall, Dörpfeld came across a section very closely resembling the Homeric description of the weaker section. Dörpfeld was convinced he had found the walls of Homer's city, and now he would excavate the city itself. Within the walls of this stratum (Troy VI), much Mycenaean pottery dating from Late Helladic (LH) periods III A and III B (1400–1200 BC) was uncovered, suggesting a relation between the Trojans and Mycenaeans. The great tower along the walls seemed likely to be the "Great Tower of Ilios".

The evidence seemed to indicate that Dörpfeld had stumbled upon Ilios, the city of Homer's epics. Schliemann himself had conceded that Troy VI was more likely to be the Homeric city, but he never published anything stating so. The only counter-argument, confirmed initially by Dörpfeld (who was as passionate as Schliemann about finding Troy), was that the city appeared to have been destroyed by an earthquake, not by men. There was little doubt that this was the Troy of which the Mycenaeans would have known.

In 480 BC, the Persian king Xerxes sacrificed 1,000 cattle at the sanctuary of Athena Ilias while marching through the Hellespontine region towards Greece. Following the Persian defeat in 480–479, Ilion and its territory became part of the continental possessions of Mytilene and remained under Mytilenaean control until the unsuccessful Mytilenean revolt in 428–427. Athens liberated the so-called Actaean cities including Ilion and enrolled these communities in the Delian League. Athenian influence in the Hellespont waned following the oligarchic coup of 411, and in that year the Spartan general Mindaros emulated Xerxes by likewise sacrificing to Athena Ilias. From c. 410–399, Ilion was within the sphere of influence of the local dynasts at Lampsacus (Zenis, his wife Mania, and the usurper Meidias) who administered the region on behalf of the Persian satrap Pharnabazus.

In 399, the Spartan general Dercylidas expelled the Greek garrison at Ilion who were controlling the city on behalf of the Lampsacene dynasts during a campaign which rolled back Persian influence throughout the Troad. Ilion remained outside the control of the Persian satrapal administration at Dascylium until the Peace of Antalcidas in 387–386. In this period of renewed Persian control c. 387–367, a statue of Ariobarzanes, the satrap of Hellespontine Phrygia, was erected in front of the temple of Athena Ilias. In 360–359 the city was briefly controlled by Charidemus of Oreus, a Euboean mercenary leader who occasionally worked for the Athenians. In 359, he was expelled by the Athenian Menelaos son of Arrabaios, whom the Ilians honoured with a grant of proxeny—this is recorded in the earliest civic decree to survive from Ilion. In May 334 Alexander the Great crossed the Hellespont and came to the city, where he visited the temple of Athena Ilias, made sacrifices at the tombs of the Homeric heroes, and made the city free and exempt from taxes. According to the so-called 'Last Plans' of Alexander which became known after his death in June 323, he had planned to rebuild the temple of Athena Ilias on a scale that would have surpassed every other temple in the known world.

Antigonus Monophthalmus took control of the Troad in 311 and created the new city of Antigoneia Troas which was a synoikism of the cities of Skepsis, Kebren, Neandreia, Hamaxitos, Larisa, and Kolonai. In c. 311–306 the "koinon "of Athena Ilias was founded from the remaining cities in the Troad and along the Asian coast of the Dardanelles and soon after succeeded in securing a guarantee from Antigonus that he would respect their autonomy and freedom (he had not respected the autonomy of the cities which were synoikized to create Antigoneia). The "koinon "continued to function until at least the 1st century AD and primarily consisted of cities from the Troad, although for a time in the second half of the 3rd century it also included Myrlea and Chalcedon from the eastern Propontis. The governing body of the "koinon "was the "synedrion" on which each city was represented by two delegates. The day-to-day running of the "synedrion", especially in relation to its finances, was left to a college of five "agonothetai", on which no city ever had more than one representative. This system of equal (rather than proportional) representation ensured that no one city could politically dominate the "koinon". The primary purpose of the "koinon "was to organize the annual Panathenaia festival which was held at the sanctuary of Athena Ilias. The festival brought huge numbers of pilgrims to Ilion for the duration of the festival as well as creating an enormous market (the "panegyris") which attracted traders from across the region. In addition, the "koinon "financed new building projects at Ilion, for example a new theatre c. 306 and the expansion of the sanctuary and temple of Athena Ilias in the 3rd century, in order to make the city a suitable venue for such a large festival.

In the period 302–281, Ilion and the Troad were part of the kingdom of Lysimachus, who during this time helped Ilion synoikize several nearby communities, thus expanding the city's population and territory. Lysimachus was defeated at the Battle of Corupedium in February 281 by Seleucus I Nikator, thus handing the Seleucid kingdom control of Asia Minor, and in August or September of 281 when Seleucus passed through the Troad on his way to Lysimachia in the nearby Thracian Chersonese Ilion passed a decree in honour of him, indicating the city's new loyalties. In September Seleucus was assassinated at Lysimachia by Ptolemy Keraunos, making his successor, Antiochus I Soter, the new king. In 280 or soon after Ilion passed a long decree lavishly honouring Antiochus in order to cement their relationship with him. During this period Ilion still lacked proper city walls except for the crumbling Troy VI fortifications around the citadel, and in 278 during the Gallic invasion the city was easily sacked. Ilion enjoyed a close relationship with Antiochus for the rest of his reign: for example, in 274 Antiochus granted land to his friend Aristodikides of Assos which for tax purposes was to be attached to the territory of Ilion, and c. 275–269 Ilion passed a decree in honour of Metrodoros of Amphipolis who had successfully treated the king for a wound he received in battle.

The city was destroyed by Sulla's rival, the Roman general Fimbria, in 85 BC following an eleven-day siege. Later that year when Sulla had defeated Fimbria he bestowed benefactions on Ilion for its loyalty which helped with the city's rebuilding. Ilion reciprocated this act of generosity by instituting a new civic calendar which took 85 BC as its first year. However, the city remained in financial distress for several decades, despite its favoured status with Rome. In the 80s BC, Roman "publicani" illegally levied taxes on the sacred estates of Athena Ilias and the city was required to call on L. Julius Caesar for restitution; while in 80 BC, the city suffered an attack by pirates. In 77 BC the costs of running the annual festival of the "koinon" of Athena Ilias became too pressing for both Ilion and the other members of the "koinon" and L. Julius Caesar was once again required to arbitrate, this time reforming the festival so that it would be less of a financial burden. In 74 BC the Ilians once again demonstrated their loyalty to Rome by siding with the Roman general Lucullus against Mithridates VI. Following the final defeat of Mithridates in 63–62, Pompey rewarded the city's loyalty by becoming the benefactor of Ilion and patron of Athena Ilias. In 48 BC, Julius Caesar likewise bestowed benefactions on the city, recalling the city's loyalty during the Mithridatic Wars, the city's connection with his cousin L. Julius Caesar, and the family's claim that they were ultimately descended from Venus through the Trojan prince Aeneas and therefore shared kinship with the Ilians.

In 20 BC, the Emperor Augustus visited Ilion and stayed in the house of a leading citizen, Melanippides son of Euthydikos. As a result of his visit, he also financed the restoration and rebuilding of the sanctuary of Athena Ilias, the bouleuterion (council house) and the theatre. Soon after work on the theatre was completed in 12–11 BC, Melanippides dedicated a statue of Augustus in the theatre to record this benefaction.

A new city called Ilium (from Greek Ilion) was founded on the site in the reign of the Roman Emperor Augustus. It flourished until the establishment of Constantinople, became a bishopric in the Roman province Hellespontus (civil Diocese of Asia), but declined gradually in the Byzantine era

No later than the 4th century, it was a suffragan of the provincial capital's Metropolitan Archdiocese of Cyzicus, in the sway of the Patriarchate of Constantinople.
Several bishops are historically documented :

The diocese was nominally restored no later than 1926 as Latin Titular bishopric of Ilium (Latin) / Ilio (Curiate Italian) / Ilien(sis) (Latin adjective).

It is vacant for decades, having had the following incumbents, so far of the fitting Episcopal (lowest) rank :

A small minority of contemporary writers argue that Homeric Troy was not at the Hisarlik site, but elsewhere in Anatolia or outside it—e.g. in England, Pergamum, Scandinavia, or Herzegovina. These proposals have not been accepted by mainstream scholarship.

In the 1920s, the Swiss scholar Emil Forrer claimed that the placenames Wilusa and Taruisa found in Hittite texts should be identified with Ilion and Troia, respectively. He further noted that the name of Alaksandu, a king of Wilusa mentioned in a Hittite treaty, is quite similar to Homer's Paris, whose birthname was Alexandros. Subsequent to this, the Tawagalawa letter (CTH 181) was found to document an unnamed Hittite king's correspondence to the king of the Ahhiyawa, referring to an earlier "Wilusa episode" involving hostility on the part of the Ahhiyawa. The Hittite king was long held to be Mursili II (c. 1321–1296), but, since the 1980s, his son Hattusili III (1265–1240) is commonly preferred, although his other son Muwatalli (c. 1296–1272) remains a possibility.

Inscriptions of the New Kingdom of Egypt also record a nation T-R-S as one of the Sea Peoples who attacked Egypt during the XIX and XX Dynasties. An inscription at Deir el-Medina records a victory of Ramesses III over the Sea Peoples, including one named "Tursha" (Egyptian: ["twrš3"]). It is probably the same as the earlier "Teresh" (Egyptian: ["trš.w"]) on the stele commemorating Merneptah's victory in a Libyan campaign around 1220 BC.

These identifications were rejected by many scholars as being improbable or at least unprovable. However, Trevor Bryce championed them in his 1998 book "The Kingdom of the Hittites", citing a piece of the Manapa-Tarhunda letter referring to the kingdom of Wilusa as beyond the land of the Seha River (the classical Caicus and modern Bakırçay) and near the land of "Lazpa" (Lesbos). Recent evidence also adds weight to the theory that Wilusa is identical to archaeological Troy. Hittite texts mention a water tunnel at Wilusa, and a water tunnel excavated by Korfmann, previously thought to be Roman, has been dated to around 2600 BC. The identifications of Wilusa with Troy and of the Ahhiyawa with Homer's Achaeans remain somewhat controversial but gained enough popularity during the 1990s to be considered majority opinion. That agrees with metrical evidence in the Iliad that the name ᾽Ιλιον (Ilion) for Troy was formerly Ϝιλιον (Wilion) with a digamma.

Such was the fame of the Epic Cycle in Roman and Medieval times that it was built upon to provide a starting point for various founding myths of national origins. The most influential, Virgil's "Aeneid", traces the journeys of the Trojan prince Aeneas, supposed ancestor of the founders of Rome and the Julio-Claudian dynasty. In a later era, the heroes of Troy, both those noted in Homer and those invented for the purpose, often continued to appear in the origin stories of the nations of Early Medieval Europe. The "Roman de Troie" was common cultural ground for European dynasties, as a Trojan pedigree was both gloriously ancient and established an equality with the ruling class of Rome. A Trojan pedigree could justify the occupation of parts of Rome's former territories.

On that basis, the Franks filled the lacunae of their legendary origins with Trojan and pseudo-Trojan names: in Fredegar's 7th-century chronicle of Frankish history, Priam appears as the first king of the Franks. The Trojan origin of France was such an established article of faith that in 1714, the learned Nicolas Fréret was Bastilled for showing through historical criticism that the Franks had been Germanic, a sore point counter to Valois and Bourbon propaganda.

In similar manner, Geoffrey of Monmouth reworked earlier material such as the "Historia Brittonum" to trace the legendary kings of the Britons from a supposed descendant of Aeneas called Brutus.

Likewise, Snorri Sturluson, in the prologue to his Icelandic "Prose Edda", traced the genealogy of the ancestral figures in Norse mythology to characters appearing at Troy in Homer's epic, notably making Thor to be the son of Memnon. Sturluson referred to these figures as having made a journey across Europe towards Scandinavia, setting up kingdoms as they went.

The Icelandic national bard and possibly most important source of Norse Mythology, Snorri Sturluson, identifies Troy with Åsgard. About it were 12 kingdoms and 12 chiefs. One of them, Múnón, married Priam's daughter, Tróán, and had by her a son, Trór, to be pronounced Thor in Old Norse. Similarly the Áss Vidarr is identified with Aeneas.


Bibliography – Works cited



</doc>
<doc id="30061" url="https://en.wikipedia.org/wiki?curid=30061" title="Tübingen">
Tübingen

Tübingen (, ) is a traditional university town in central Baden-Württemberg, Germany. It is situated south of the state capital, Stuttgart, on a ridge between the Neckar and Ammer rivers. about one in three people living in Tübingen is a student.

Immediately north of the city lies the Schönbuch, a densely wooded nature park. The Swabian Alb mountains rise about (beeline Tübingen City to Roßberg - 869 m) to the southeast of Tübingen.

The Ammer and Steinlach rivers discharge into the Neckar river, which flows right through the town, just south of the medieval old town in an easterly direction. Large parts of the city are hilly, with the Schlossberg and the Österberg in the city centre and the Schnarrenberg and Herrlesberg, among others, rising immediately adjacent to the inner city.

The highest point is at about above sea level near Bebenhausen in the Schönbuch forest, while the lowest point is in the town's eastern Neckar valley.
Nearby the Botanical Gardens of the city's university, in a small forest called Elysium, lies the geographical centre of the state of Baden-Württemberg.

Tübingen is the capital of an eponymous district and an eponymous administrative region ("Regierungsbezirk"), before 1973 called "Südwürttemberg-Hohenzollern".

Tübingen is, with nearby Reutlingen (about east), one of the two centre cities of the Neckar-Alb region.

Administratively, it is not part of the Stuttgart Region, bordering it to the north and west (Esslingen district in the north and Böblingen district in the west). However, the city and northern parts of its district can be regarded as belonging to that region in a wider regional and cultural context.

The area was probably first settled in the 12th millennium BC. The Romans left some traces here in AD 85, when they built a Limes frontier wall at the Neckar. Tübingen itself dates from the 6th or 7th century, when the region was populated by the Alamanni. Some even argue that the Battle of Solicinium was fought at Spitzberg, a mountain in Tübingen, in AD 367, although there is no evidence for this.

Tübingen first appears in official records in 1191, and the local castle, "Hohentübingen", has records going back to 1078 when it was besieged by Henry IV, king of Germany, its name transcribed in Medieval Latin as "Tuingia" and "Twingia".

From 1146, Count Hugo V (1125–52) was promoted to count palatine, as Hugo I, establishing Tübingen as the capital of a County Palatine of Tübingen.
By 1231, Tübingen was a "civitas" indicating recognition of civil liberties and a court system.

In 1262, an Augustinian monastery was established by Pope Alexander IV in Tübingen, in 1272, a Franciscan monastery followed. The latter existed until Duke Ulrich of Würtemmberg disestablished it in 1535 in course of the Protestant Reformation, which the Duchy of Württemberg followed. In 1300, a Latin school (today's Uhland-Gymnasium) was founded.

In 1342, the county palatine was sold to Ulrich III, Count of Württemberg and incorporated into the County of Württemberg.

Between 1470 and 1483, St. George's Collegiate Church was built. The collegiate church offices provided the opportunity for what soon afterwards became the most significant event in Tübingen's history: the founding of the Eberhard Karls University by Duke Eberhard im Bart of Württemberg in 1477, thus making it one of the oldest universities in Central Europe. It became soon renowned as one of the most influential places of learning in the Holy Roman Empire, especially for theology (a Protestant faculty, Tübinger Stift, was established in 1535 in the former Augustinian monastery). Today, the university is still the biggest source of income for the residents of the city and one of the biggest universities in Germany with more than 22,000 students.

Between 1622 and 1625, the Catholic League occupied Lutheran Württemberg in the course of the Thirty Years' War. In the summer of 1631, the city was raided. In 1635/36 the city was hit by the Plague. In 1638, Swedish troops conquered Tübingen. Towards the end of the war, French troops occupied the city from 1647 until 1649.

In 1789, parts of the old town burned down, but were later rebuilt in the original style. In 1798 the "Allgemeine Zeitung", a leading newspaper in early 19th-century Germany, was founded in Tübingen by Johann Friedrich Cotta. From 1807 until 1843, the poet Friedrich Hölderlin lived in Tübingen in a tower overlooking the Neckar.

In the Nazi era, the Tübingen Synagogue was burned in the Kristallnacht on November 9, 1938. The Second World War left the city largely unscathed, mainly because of the peace initiative of a local doctor, Theodor Dobler. It was occupied by the French army and became part of the French occupational zone. From 1946 to 1952, Tübingen was the capital of the newly formed state of Württemberg-Hohenzollern (as ), before the state of Baden-Württemberg was created by merging Baden, Württemberg-Baden and Württemberg-Hohenzollern. The French troops had a garrison stationed in the south of the city until the end of the Cold War in the 1990s.

In the 1960s, Tübingen was one of the centres of the German student movement and the Protests of 1968 and has ever since shaped left and green political views. Some radicalized Tübingen students supported the leftist Rote Armee Fraktion terrorist group, with active member Gudrun Ensslin, a local and a Tübingen student from 1960 to 1963, joining the group in 1968.

Although noticing such things today is largely impossible, as recently as the 1950s, Tübingen was a very socioeconomically divided city, with poor local farmers and tradesmen living along the "Stadtgraben" (City Canal) and students and academics residing around the "Alte Aula" and the "Burse", the old university buildings. There, hanging on the "Cottahaus", a sign commemorates Goethe's stay of a few weeks while visiting his publisher. The German tendency to memorialize every minor presence of its historical greats (comparable to the statement "Washington slept here" in the United States) is parodied on the building next door. This simple building, once a dormitory, features a plain sign with the words ""Hier kotzte Goethe"" (lit.: "Goethe puked here").

In the second half of the 20th century, Tübingen's administrative area was extended beyond what is now called the "core town" to include several outlying small towns and villages. Most notable among these is Bebenhausen, a village clustered around a castle and Bebenhausen Abbey, a Cistercian cloister about north of Tübingen.

, the city had 89,000 inhabitants. Life in the city is dominated by its roughly 25,800 students. Tübingen is best described as a mixture of old and distinguished academic flair, including liberal and green politics on one hand and traditional German-style student fraternities on the other, with rural-agricultural environs and shaped by typical Lutheran-Pietist characteristics, such as austerity and a Protestant work ethic, and traditional Swabian elements, such as frugality, order, and tidiness. The city is home to many picturesque buildings from previous centuries and lies on the River Neckar.

, the German weekly magazine "Focus" published a national survey according to which Tübingen had the highest quality of life of all cities in Germany. Factors taken into consideration included the infrastructure, the integration of bicycle lanes into the road system, a bus system connecting surrounding hills and valleys, late-night services, areas of the town that can be reached on foot, the pedestrianised old town, and other amenities and cultural events offered by the university. Tübingen is the city with the youngest average population in Germany.

In central Tübingen, the Neckar divides briefly into two streams, forming the elongated "Neckarinsel" (Neckar Island), famous for its "Platanenallee" with high plane trees, some of which are more than 200 years old. Pedestrians can reach the island via stairs on the narrow ends leading down from two bridges spanning the Neckar. During the summer, the "Neckarinsel" is occasionally the venue for concerts, plays, and literary readings. The row of historical houses across one side of the elongated "Neckarinsel" is called the "Neckarfront" and includes the house with adjoining tower where poet Friedrich Hölderlin stayed for the last 36 years of his life, as he struggled with mental instability.

Tübingen's "Altstadt" (old town) survived the Second World War due to the city's lack of heavy industry. The result is a growing domestic tourism business. as visitors come to wander through one of the few completely intact historic "Altstädte" in Germany. The highlights of Tübingen include its crooked cobblestone lanes, narrow-stair alleyways picking their way through the hilly terrain, streets lined with canals, and well-maintained traditional half-timbered houses.

Old town landmarks include the "Rathaus" (City Hall) on "Marktplatz" (Market Square) and the castle, "Schloß Hohentübingen", now part of the University of Tübingen. The central landmark is the "Stiftskirche" (Collegiate Church). Along with the rest of the city, the Stiftskirche was one of the first to convert to Martin Luther's protestant church. As such, it maintains (and carefully defends) several "Roman Catholic" features, such as patron saints. Below the "Rathaus" is a quiet, residential street called the "Judengasse", the former Jewish neighborhood of Tübingen until the town's Jews were expelled in 1477. On the street corner is a plaque commemorating the fate of Tübingen's Jews.

The centre of Tübingen is the site of weekly and seasonal events, including regular market days on the "Holzmarkt" by the Stiftskirche and the "Marktplatz" by the Rathaus, an outdoor cinema in winter and summer, festive autumn and Christmas markets and Europe's largest Afro-Brazilian festival.

Students and tourists also come to the Neckar River in the summer to visit beer gardens or go boating in "Stocherkähne", the Tübingen equivalent of Oxford and Cambridge punts, only slimmer. A "Stocherkahn" carries up to 20 people. On the second Thursday of June, all "Stocherkahn" punts take part in a major race, the "Stocherkahnrennen".

Bebenhausen Abbey lies in the village of Bebenhausen, a district of Tübingen. A subdivision of the pilgrimage route Way of St. James starts here and runs through Tübingen.

Tübingen has a notable arts culture as well as nightlife. In addition to the full roster of official and unofficial university events that range from presentations by the university's official poet in residence to parties hosted by the student associations of each faculty, the town can boast of several choirs, theatre companies and nightclubs. Also, Tübingen's "Kunsthalle" (art exhibition hall), on the "Wanne", houses two or three exhibits of international note each year.

There are several festivals and open air markets on a regular basis:



Notable Tübingen residents and scholars included the poets Friedrich Hölderlin, Eduard Mörike and Ludwig Uhland, the neurologist Alois Alzheimer from whom Alzheimer's disease takes its name, and Friedrich Miescher who was the first to discover nucleic acids. Wilhelm Schickard who was the main precursor to the mechanical calculator, was born in nearby Herrenberg. Georg Wilhelm Friedrich Hegel, Friedrich Schelling, David Friedrich Strauss, and Johannes Kepler studied in Tübingen at the Tübinger Stift, and Joseph Alois Ratzinger (Pope Benedict XVI) held a chair in dogmatic theology at the University. Hermann Hesse worked in Tübingen as a bookseller trainee from 1895 to 1899. The most famous composer of Tübingen was Friedrich Silcher, who worked as the university's music director from 1817 until 1860. And desert artist Carl Eytel studied forestry at Tübingen before emigrating to America in 1885 and eventually settling in Palm Springs, California.

Tübingen also is the home of scholars of international renown such as the Idealist philosopher Immanuel Hermann von Fichte, the theologian Hans Küng, jurisprudent Gerhard Anschütz, famous author Walter Jens, as well as Christiane Nüsslein-Volhard. Slovene refugee Protestant preacher Primož Trubar, who published the first two books in the Slovene language and is regarded as the key consolidator of the Slovene identity, lived in Tübingen and its suburb Derendingen and is buried there. Martin Luther's companion Philipp Melanchthon, called "Praeceptor Germaniae" (Teacher of Germany), studied here from 1512 to 1514.

Former President of Germany Horst Köhler is a Tübingen alumnus as well, as was former Chancellor of Germany Kurt Georg Kiesinger. Nobel laureate and humanitarian Albert Schweitzer published his PhD thesis in Tübingen in 1899.

Tübingen is also the hometown of former track and field athlete Dieter Baumann, winner of the 5000m at the 1992 Summer Olympics. In 1990, the award-winning Israeli human rights lawyer Felicia Langer accepted a teaching position in Tübingen and has resided there since then.

American soccer coach Sigi Schmid, who has won Major League Soccer championships with the Los Angeles Galaxy and Columbus Crew and was an assistant coach for the U.S. at the 1994 FIFA World Cup, was born in Tübingen and moved to Torrance, California as a child.
Sung Yuri, a South Korean top actress and the youngest member of the K-Pop girl group Fin.K.L., was born in Tübingen in 1981. Her father, Sung Chong Hyon, received his doctorate degree in theology from Tübingen University and is currently a professor of New Testament at the Presbyterian College and Theological Seminary in Seoul, South Korea.

Greek singer Despina Vandi was born in Tübingen, although her family moved back to Greece when Vandi was six years old.

Tübingen is divided into 22 districts, a town core of twelve districts (population of about 51 000) and ten outer districts (suburbs) (population of about 31 000):

Core city districts:

Outer districts:

Since World War II, Tübingen's population has almost doubled from about 45,000 to the current 88,000, also due to the incorporation of formerly independent villages into the city in the 1970s.

Currently, Lord Mayor Boris Palmer (Green Party) has set the ambitious goal of increasing the population of Tübingen to reach 100,000 within the next years. To achieve this, the city is closing gaps between buildings within the city proper by allowing new houses there; this is also to counter the tendency of urban sprawl and land consumption that has been endangering the preservation of rural landscapes of Southern Germany. 

¹ census result

Tübingen is twinned with:
In November 2009 Tübingen's city council voted to enter into talks with the city of Moshi in Tanzania, with the aim of Moshi becoming Tübingen's eleventh twin city.

For their commitment to their international partnership, the Council of Europe awarded the Europe Prize to Tübingen and Aix-en-Provence in 1965. The city's dedication to a European understanding is also reflected in the naming of several streets and squares, including the large "Europaplatz" (Europe Square) outside the railway station.

By plane: Tübingen is about from the Baden-Württemberg state airport ("Landesflughafen Stuttgart", also called Stuttgart Airport).

By automobile: Tübingen is on the "Bundesstraße 27" (a "federal road") that crosses through Baden-Württemberg, connecting the town with Würzburg, Heilbronn, Stuttgart and the "Landesflughafen" (Stuttgart Airport) to the north and Rottweil and Donaueschingen to the south.

By rail: Tübingen Hauptbahnhof is on the regional train line Neckar-Alb Railway-Bahn ("Neckar-Alb-Bahn") from Stuttgart Hauptbahnhof via Esslingen and Reutlingen to Tübingen. The average time of travel to Stuttgart is 1:01 hrs., with some trains taking only 45 mins. Other regional lines are the "Hohenzollerische Landesbahn", connecting the town with Hechingen and Sigmaringen (so-called Zollernalb Railway), "Zollernalbbahn" and connections to Herrenberg (Ammer Valley Railway, "Ammertalbahn") and Horb (Upper Neckar Railway, "Obere Neckarbahn"). Since 2009, there is also a daily direct Intercity link to Mannheim, Cologne and Düsseldorf as well as to Berlin.

Local public transport: The town, due to its high student population, features an extensive public bus network with more than 20 lines connecting the city districts and places outside of Tübingen such as Ammerbuch, Gomaringen and Nagold. There are also several night bus lines in the early hours every Thursday to Sunday. A direct bus is available to Stuttgart Airport (via Leinfelden-Echterdingen) as well as to Böblingen and Reutlingen.

The Eberhard Karls University of Tübingen dates from 1477, making it one of the oldest in Germany. The city is also host to several research institutes including the Max Planck Institute for Biological Cybernetics, Max Planck Institute for Developmental Biology, Max Planck Institute for Intelligent Systems, The Friedrich Miescher Laboratory of the MPG (and formerly the Max Planck Institute for Biology) and the Hertie-Institute for Clinical Brain Research. The university also maintains an excellent botanical garden, the Botanischer Garten der Universität Tübingen.

More than 10,000 children and young adults in Tübingen regularly attend school. There are 30 schools in the town, some of which consist of more than one type of school. Of these, 17 are primary schools while the others are for secondary education: four schools are of the lowest rank, "Hauptschule", three of the middle rank, "Realschule", and six are "Gymnasien" (grammar schools). There also are four vocational schools ("Berufsschule") and three special needs schools.

Primary schools
Hauptschulen

Realschulen

Gymnasien

Vocational schools ("Berufsschulen")




</doc>
